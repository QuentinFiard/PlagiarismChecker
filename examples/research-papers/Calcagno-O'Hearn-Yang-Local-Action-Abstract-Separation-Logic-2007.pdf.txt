

Local Action and Abstract Separation Logic
Cristiano CalcagnoImperial College, London Peter W. O'HearnQueen Mary, University of London

Hongseok YangQueen Mary, University of London

Abstract
Separation logic is an extension of Hoare's logic whichsupports a local way of reasoning about programs that mutate memory. We present a study of the semantic structureslying behind the logic. The core idea is of a local action, a
state transformer that mutates the state in a local way. Weformulate local actions for a class of models called separation algebras, abstracting from the RAM and other specificconcrete models used in work on separation logic. Local
actions provide a semantics for a generalized form of (sequential) separation logic. We also show that our condi-tions on local actions allow a general soundness proof for a

separation logic for concurrency, interpreted over arbitraryseparation algebras.

1 Introduction

Separation logic is an extension of Hoare's logic whichhas been used to attack the old problem of reasoning about
the mutation of data structures in memory [33, 17, 23, 34].Separation logic derives its power from an interplay between the separating conjunction connective * and proofrules for commands that use *. Chief among these are the
frame rule [17, 23] and the concurrency rule [22].

{p} C {q}{
p * r} C {q * r} FrameRule

{p1} C1 {q1} {p2} C2 {q2}{

p1 * p2} C1 k C2 {q1 * q2} ConcurrencyRule

The frame rule codifies an intuition of local reasoning. Theidea is that, if we establish a given Hoare triple, then the

precondition contains all the resources that the commandwill access during computation (other than resources allocated after the command starts). As a consequence, anyadditional state will remain unchanged; so the invariant assertion R in the rule (the frame axiom), can be freely tackedonto the precondition and the postcondition. Similarly, the

concurrency rule states that processes that operate on sepa-rate resources can be reasoned about independently.

Syntactically, the concurrency and frame rules arestraightforward. But, the reason for their soundness is subtle, and rests on observations about the local way that im-perative programs work [37]. Typically, a program accesses
a circumscribed collection of resources; for example, thememory cells accessed during execution (the memory footprint). Our purpose in this paper is to describe these seman-tic assumptions in a general way, for a collection of models
that abstract away from the RAM and other concrete modelsused in work on separation logic.

By isolating the circumscription principles for a classof models, the essential assumptions needed to justify the
logic become clearer. In particular, our treatment of concur-rency shows that soundness of a concurrent version of separation logic relies only on locality properties of the prim-itive actions (basic commands) in the programming language. Soundness of the concurrent logic was very diffi-cult to come by, originally, even for a particular separation
algebra (the RAM model); it was proven in a remarkablework of Brookes [12]. Our treatment of concurrency builds
on Brookes's original insights, but makes several differentchoices in formulation which allow for a more general proof
that applies to arbitrary separation algebras. We show thatas long as the primitive commands in a language satisfy the
frame rule, one obtains a model of a concurrent logic. Thisis in contrast to Brookes's original and further papers on
concurrent separation logics [10, 11, 16, 15], all of whichhave proven soundness for particular models in a way that
relies on very specific interpretations of the primitive ac-tions, rather than for a class of models.

This paper will not contain any examples of using thelogic; see, e.g., [36, 28, 5, 4] and their references.

Warning. In this paper we avoid the traditional Hoarelogic punning of program variables as logical variables, to
avoid nasty side conditions in the proof rules; see [9, 27] forfurther discussion. This is for theoretical simplicity; our results can be extended to cover variable alteration, as is donein most separation logic papers, with their associated modifies clauses. (Furthermore, avoiding the pun is more in linewith real languages like C or ML, even if it departs slightly
from the theoretical tradition in program logic.)

2 Separation Algebras and Predicates

Most papers on separation logic make use of a domainof heaps, which is equipped with a partial operator for gluing together heaps that are separate in some sense (varioussenses have appeared in the literature). We abstract from
this situation with the following definition.
Definition 1 (Separation Algebra) A separation algebra
is a cancellative, partial commutative monoid (\Sigma , *, u) . Apartial commutative monoid is given by a partial binary

operation where the unity, commutativity and associativitylaws hold for the equality that means both sides are defined and equal, or both are undefined. The cancellative
property says that for each oe 2 \Sigma , the partial function
oe * (*) : \Sigma  * \Sigma  is injective. The induced separateness
(#) and substate (_) relations are given by

oe0#oe1 iff oe0 * oe1 is defined
oe0 _ oe2 iff 9oe1. oe2 = oe0 * oe1.

Examples of separation algebras:

1. Heaps, as finite partial functions from l-values to r-values

H = L *fin RV
where the empty partial function is the unit and where
h0 * h1 takes the union of partial functions when h0and

h1 have disjoint domains of definition. h0 * h1 isundefined when

h0(l) and h1(l) are both defined for atleast one l-value

l 2 L. By taking L to be the set ofnatural numbers and

RV the set of integers we obtainthe RAM model [23, 34]. By taking

L to be a set oflocations and
RV to be certain tuples of values or nilwe obtain models where the heap consists of records

[33, 17]. And by taking L to be sequences of fieldnames we obtain a model of hierarchical storage [1].

2. Heaps with permissions [8],

HPerm = L *fin RV * P
where P is a permission algebra (i.e., a set with a par-tial commutative and associative operation ffi satisfying the cancellativity condition). h0 * h1 is again theunion when the domains are disjoint. Some overlap
is allowed, though: when h0(l) = (rv, p0), h1(l) =

(rv, p1) and p0 ffi p1 is defined then h0 and h1 are com-patible at

l. When all common l-values are compatible,
h0 * h1 is defined, and (h0 * h1)(l) = (rv, p0 ffi p1) forall compatible locations

l. An example of a permissionalgebra is the interval (0

, 1] of rational numbers, withffi being addition but undefined when permissions add

up to more than 1.
Another permission algebra is given by the set{

R, RW } of read and read-write permissions, where
R ffi R = R and RW ffi p is undefined. At first sight,it might be thought that this algebra models the idea of

many readers and a single writer. But, unfortunately,it does not allow conversion of a total (

RW ) permis-sion to several read permissions, or vice versa. In contrast, the algebra (0, 1] does allow such conversion us-ing identities such as 1

/2 + 1/2 = 1; see [8].

3. Variables as resource [9, 27] is S * H, where H is asabove and

S = Var *fin Val
has the "union of disjoint functions" partial monoidstructure. Variables-as-resource models can also be

mixed with the permission construction.
4. Multisets over a given set of Places, with * as multisetunion, which can be used to model states in Petri nets

without capacity [32].
5. The monoid [Places *fin {marked, unmarked}] ofpartial functions, again with union of functions with

disjoint domain, can be used to model Petri nets withcapacity 1. Note that the * operation in nets with capacity 1 is partial, while in nets without capacity it istotal.

Definition 2 Let \Sigma  be a separation algebra. Predicatesover \Sigma  are just elements of the powerset

P (\Sigma ). It has an
ordered total commutative monoid structure (*, emp) givenby

p * q = {oe0 * oe1 | oe0#oe1 ^ oe0 2 p ^ oe1 2 q}emp = {

u}

P (\Sigma ) is in fact a boolean BI algebra, where p * (*) and
p u (*) have right adjoints [30]. Because they are left ad-joints they preserve all joins, so we automatically get two

distributive lawsF

X * p = F{x * p | x 2 X}F
X u p = F{x u p | x 2 X}.

Similar laws do not hold generally for d, but the predi-cates

p that satisfy an analogue of the first law play a crucialrole in this work.

2

Definition 3 (Precise Predicates) A predicate p 2 P (\Sigma ) isprecise if for every

oe 2 \Sigma , there exists at most one oep _ oe
such that oep 2 p. We let Prec denote the set of precisepredicates.

Examples of Predicates.

1. In the heap model, if l 2 L is an l-value and rv 2 R anr-value, then the predicate

l 7! rv 2 P (\Sigma ) is the set{
oe} consisting of a single state oe where oe(l) = rv and
oe(l0) is undefined for other l-values l0. It is precise.

2. l0 7! rv0 * l1 7! rv1 is the set {oe} where oe is definedonly on locations

l0 and l1, mapping them to rv0 and
rv1. Again, this predicate is precise.

3. l0 7! rv0 t l1 7! rv1 is the disjunction, i.e. the set{

oe0, oe1} where oei maps li to rvi and is undefined else-where.

l0 7! rv0 t l1 7! rv1 is not a precise predicate.

Lemma 4 (Precision Characterization) 1. Everysingleton predicate {

oe} is precise.

2. p is precise iff for all nonempty X ` P (\Sigma ),l

X * p = l{x * p | x 2 X}
Condition 2 in this lemma can be taken as a basis for a def-inition of precision in a complete lattice endowed with an
ordered commutative monoid (rather than the specific lat-tices

P (\Sigma )). Also, the assumption that oe * (*) be injective isequivalent to the requirementl

X * {oe} = l{x * {oe} | x 2 X} for all nonempty X.
Precision plays a greater role here than in previous work,where it arose as a technical reaction to soundness problems
in proof rules for information hiding [25, 12, 22]. This prop-erty is used in the characterization of the lattice structure of
local functions, in the definition of the "best" or largest localaction below, and again later when we turn to concurrency.

3 Local Actions
Conceptual Development. In [37] a soundness proof wasgiven for separation logic in terms of an operational semantics for the RAM (heaps) model. The development thererevolved around relations

R ` \Sigma  * (\Sigma  [ {fault})
(oe, oe0) 2 R signifies that the program can deliver finalstate

oe0 when started in oe, and (oe, fault) 2 R signifiesthat a memory fault can occur (by dereferencing a dangling

pointer). In terms of these relations, two properties wereidentified that correspond to the frame rule:

1. Safety Monotonicity: (oe, fault) 62 R and oe _ oe0implies (

oe0, fault) 62 R.

2. Frame Property: If (oe0, fault) 62 R, oe = oe0*oe1 and(

oe, oe0) 2 R then 9oe00. oe0 = oe00 * oe1 and (oe0, oe00) 2 R.

The first condition says that if a state has enough resourcefor safe execution of a command, then so do superstates.

The second condition says that if a little state oe0 has enoughresource for the command to execute safely, then execution
on any bigger state can be tracked back to the small state.These two conditions can be shown to be equivalent to
the frame rule: a relation R satisfies Safety Monotonicityand the Frame Property iff the frame rule is sound for it.
But, the formulation of the second property is unpleasant: itis a tabulation of a true operational fact (as shown in [37]),
but in developing our theory we seek a simpler condition.The first step to this simpler formulation is to make use
of the fact that fault trumps; that is, in separation logicHoare triples are interpreted so that fault falsifies a triple
[17, 37, 34]. The result is that Hoare triples cannot distin-guish between a command that just faults, and one that nondeterministically chooses between faulting and terminatingnormally. This suggests that in the semantics we can use
functions from states to the powerset P (\Sigma ), together withfault, rather than relations as above.

But, order-theoretically, where should fault go? The an-swer is on the top, as in functions

f : \Sigma  ! P (\Sigma )?.
Conceptually, faulting is like Scott's top: an inconsistentor over-determined value. Technically, putting fault on the

top allows us to characterize the pointwise order in termsof Hoare triples (Proposition 7), which shows that it is the
correct order for our purposes.This much is mostly a standard essay on relations versus
functions into powersets. The payoff comes in the treatmentof locality. Using functions into the (topped) powerset, we
can work with a much simpler condition:

locality : oe1#oe2 implies f (oe1 * oe2) v (f oe1) * {oe2}.
Here, the * operation is extended with ?, by p * ? = ? *
p = ?. It can be verified that a relation R satisfies SafetyMonotonicity and Frame Property iff the corresponding

function func(R) : \Sigma  ! P (\Sigma )? satisfies locality.1
Aside on total correctness. The use of P (\Sigma )? above isstrongly oriented to a partial correctness logic, where divergence does not falsify a Hoare triple. The empty set repre-sents divergence. To account for total correctness we would
just have to flip P (\Sigma )? upside down, obtaining (P (\Sigma )?)op.In total correctness divergence and faulting are identified.

1func(R)oe returns ? when (oe, fault) 2 R, even if we also have
(oe, oe0) 2 R for some oe0 6= fault.

3

Technical Development. We now make the main defini-tions following on from these ideas.
Definition 5 P (\Sigma )? is obtained by adding a new greatest
element to P (\Sigma ). It has a total commutative monoid structure, keeping the unit emp the same as in P (\Sigma ), and ex-tending * so that

p * ? = ? * p = ?.

Definition 6 (Semantic Hoare Triple) If p, q 2 P (\Sigma ) and
f : \Sigma  ! P (\Sigma )? then

hhpii f hhqii holds iff for all oe 2 p. f oe v q

This is fault-avoiding because the postcondition does notinclude ?. A justification for putting

fault on the top isthe following.

Proposition 7 (Order Characterization) f v g iff for all
p, q 2 P (\Sigma ), hhpii g hhqii implies hhpii f hhqii

Definition 8 (Local Action) Suppose \Sigma  is a separation algebra. A local action f : \Sigma  ! P (\Sigma )? is a function satis-fying the locality condition:

oe1#oe2 implies f (oe1 * oe2) v (f oe1) * {oe2}.
We let LocAct denote the set of local actions, with pointwiseorder.

Lemma 9 LocAct is a complete lattice, with meets and
joins defined pointwise (and inherited from the function
space [\Sigma  ! P (\Sigma )?]).

The proof is straightforward, but it is instructive to give partof it to show a use of precision in action.

Proof: Assume that oe = oe0#oe1. Then we can show thatthe pointwise meet is local

(d F )(oe0 * oe1) = d{f (oe0 * oe1) | f 2 F }v d{

f (oe0) * {oe1} | f 2 F }= \Gamma d{

f (oe0) | f 2 F }\Delta  * {oe1}= ((d
F )oe0) * {oe1}.

The second-last step used that {oe1} is precise (Lemma 4).

Given any precondition p1 and postcondition p2, we candefine the best or largest local action satisfying the triple
hhp1ii - hhp2ii2.
Definition 10 (Best Local Action) bla[p1, p2] is the func-tion of type \Sigma  !

P (\Sigma )? defined by

bla[p1, p2](oe) = l{p2 * {oe0} | oe = oe0 * oe1, oe1 2 p1}.

2This is an analogue of the "specification statement" studied in the refinement literature

Lemma 11 Let f = bla[p1, p2]. The following hold:

* f is a local action;

* hhp1ii f hhp2ii;

* If hhp1ii t hhp2ii and t is local then t v f.

Local actions form a one-object category (a monoid),where the identity is bla[emp

, emp] and the composition
f; g functionally composes f with the obvious lifting g# :
P (\Sigma )? ! P (\Sigma )?.3 This structure is used in the semanticsof

skip and sequential composition in Figure 1.

Examples.

1. For the Heaps model, the function f which always re-turns emp is not local. The function

f that sets allallocated locations to some specific r-value (say, 0) is

not local. For, f applied to a singleton heap [l 7! 2] re-turns [

l 7! 0]. According to locality, it should not alterany location other than

l. But, f([l 7! 2, l0 7! 2]) ={[
l 7! 0, l0 7! 0]}. Such a function is not definable inthe languages used in separation logic (and is typically

not definable in, say, C or Java.). In contrast, the op-erations of heap mutation and allocation and disposal
are local actions (see the next section).
2. Any transition on a Petri net without capacity definesa local action on the multiset monoid (in fact, a deterministic local action). Any transition on a net withcapacity 1 determines a local action on the separation
algebra [Places *fin {marked, unmarked}]. Interest-ingly, transitions for nets with capacity do not define
local actions on the separation algebra which is the setof places with union of disjoint subsets as *.

3. Generally, bla[p, emp] is the local action that disposesof, or annihilates,

p. Similarly, bla[emp, p] allocates p,or lets the knowledge of

p materialize.

The annihilation bla[p, emp] behaves strangely when p isnot precise. For example, when

p is l0 7! r0 t l1 7! r1 for
l0 6= l1 in the heap model, bla[p, emp] on the heap [l0 7! r0]disposes

l0, but diverges on [l0 7! r0, l1 7! r1]. However,in case
p is precise, the definition is well-behaved, in thesense that it simply removes part of the state satisfying

p.

4 Programming Language

The commands of our language are as follows:

C ::= c | skip | C; C | C + C | C?
3How to make this into a more genuine, many object, category is not
completely obvious.

4

JcKv = v(c)J
skipKvoe = {oe}J
C1; C2Kv = (JC1Kv); (JC2Kv)J

C?Kv = FnJC nKvJ
C1 + C2Kv = JC1Kv t JC2Kv

- v : PrimCommands ! LocAct
- JCKv 2 LocAct

- (f ; g)oe = ae ? if f oe = ?F{goe0 | oe0 2 f oe} otherwise

Figure 1. Denotational Semantics
Here, c ranges over an unspecified collectionPrimCommands of primitive commands, + is nondeterministic choice, ; is sequential composition, and (*)?is Kleene-star (iterated ;). We use + and (*)

? instead of

conditionals and while loops for theoretical simplicity:given appropriate primitive actions the conditionals and

loops can be encoded, but we do not need to explicitlyconsider boolean conditions in the abstract theory.

The denotational semantics of commands is given in Fig-ure 1. The meanings of primitive commands are given by
a valuation v. The meaning of Kleene-star is a local actionbecause of Lemma 9.

Example Language and Model. We illustrate this defini-tion with a particular concrete model and several primitive
commands. As a model we take

\Sigma  = S * H = (Var *fin RV ) * (L *fin RV )
as in Section 2. We assume further that L ` RV .For

x, y 2 Var and l 2 L, we can define

load (l, x)= d

rv bla[l 7! rv * x 7! - , l 7! rv * x 7! rv]

store(x, l)= d

rv bla[l 7! - * x 7! rv , l 7! rv * x 7! rv]

move(x, y)= d

rv bla[x 7! rv * y 7! - , x 7! rv * y 7! rv]

Here, load is the analogue of the assembly language in-struction that retrieves a value from memory and puts it in

a register, while store takes a value from the register bankand puts it into memory, and move copies a value from one
register to another. Here the use of d is the meet of localactions (not just assertions), and is essentially being used to

model universal quantification outside of a triple to treat rvas if it were a ghost variable.

Primitive commands free(l) and new (x) for disposingand allocating heap locations denote the following best local actions.

free(l) = bla[l 7! -, emp]new (

x) = bla[x 7! -, Fl x 7! l * l 7! -]

So, allocation and deallocation are special cases of the gen-eral concepts of materialization and annihilation. In these

definitions l 7! - is the predicate denoting {oe} where oe(l)is defined and where

oe(l0) is undefined for l0 6= l. In thepostcondition for new (

x) we are using Fl to play the roleof existential quantification in the evident way.4

We have used the best local actions bla[-, -] to definethese functions, but we could also define them by more explicit reference to states. For example, load(l, x) is

*oe.if (l, x 2 dom(oe)) then (oe|x:=oe(l)) else ?
where we use (oe|x:=rv) for updating a partial function.In this model we can have boolean expressions for testing, say, whether two locations have the same value ([l] ==[

l0]). Following [17], we call a predicate p intuitionistic if
p * true = p, and define the intuitionistic negation ~ip of
p to be {oe | 8oe0. oe * oe0 62 p}. Generally, we can pre-sume a collection of primitive boolean expressions

b, whichgive rise to primitive commands
assume(B) for some in-tuitionistic predicate
B 2 P (\Sigma ). Our valuation v has tomap
assume(B) to a local action v(assume(B)) 2 LocActwhich returns an input state

oe if B holds in oe; diverges if~

iB holds; faults otherwise. Then, we can encode condi-tionals and loops as

(assume(B); C1) + (assume(~iB); C2)(

assume(B); C)?; assume(~iB)

The point of this is just to make clear that, in the generaltheory, we do not need to consider boolean expressions explicitly: the assume statements can be taken to be givenprimitive commands, in which case their use in loops and
conditionals can be encoded in terms of the more basic non-deterministic choice and Kleene iteration.5

5 Sequential Abstract Separation Logic

The rules for Abstract Separation Logic are in Figure 2.Note that we have to require that

I be nonempty in the con-junction rule because {true}
C{true} does not generallyhold in separation logic (because of the fault-avoiding interpretation of triples).

4This would sometimes be written 9l.x 7! l * l 7! -, and we are just
using the ability of a complete Boolean algebra to interpret quantification.5

If we wanted to include booleans explicitly in the general theory wecould use "local booleans", functions

\Sigma  ! {t, f}? that are monotone wrtthe _ order on
\Sigma .

5

STRUCTURAL RULES
{p} C {q}{
p * r} C {q * r}

p0 v p {p} C {q} q v q0{

p0} C {q0}

{pi} C {qi}, all i 2 I{F

i2I pi} C {Fi2I qi}

{pi} C {qi}, all i 2 I{d

i2I pi} C {di2I qi} I 6= ;
BASIC CONSTRUCTS

{p} skip {p} {

p} C1 {q} {q} C2 {r}{

p} C1; C2 {r}

{p} C1 {q} {p} C2 {q}{

p} C1 + C2 {q} {

p} C {p}{
p} C? {p}

Figure 2. Rules of Abstract Separation Logic
Definition 12 (Axioms) An axiom set Ax is a set of triples

{p}c{q}
for primitive commands c, where there is at least one axiomfor each primitive command.6

Definition 13 (Proof-theoretic Consequence Relation)
We write Ax ` {

p} C {q},

to mean that {p} C {q} is derivable from Ax using the rules
in Figure 2.

The semantics of judgements is based on a notion of val-uation, that maps primitive commands to local actions.

Definition 14 (Satisfaction) Suppose that we have a valuation v as in Figure 1. We say that v satisfies {p} C {q} just
if hhpii JCKv hhqii is true according to Definition 6.

Definition 15 (Semantic Consequence Relation) Wewrite

Ax |= {p} C {q}
to mean that for all valuations v, if v satisfies Ax then vsatisfies {

p} C {q}.

Theorem 16 (Soundness) All of the proof rules preserve
semantic validity (Ax |= {p} C {q}). As a result, a proof-theoretic consequence is also a semantic consequence:

Ax ` {p} C {q} implies Ax |= {p} C {q}.
The soundness of the frame rule follows Definition 8,and the other rules are straightforward. We have also proven

the converse of Theorem 16, included in the longer versionof this paper [13].

6The canonical axiom {false} c {false} can be taken when a specific
choice is not desired.

6 A Logic for Concurrency

We add three new command forms for parallel composi-tion, lock declarations

`.C, and critical sections.7

C ::= * * * | C k C | `.C | with ` do C
This language assumes that there is a fixed infinite setLocks, from which the

`'s are drawn. The basic constrainton the critical sections is that different

with ` do C for thesame
` must be executed with mutual exclusion. In imple-mentation terms, we can consider the critical section as being implemented by P(`); C; V (`) where P(`) and V (`)are Dijkstra's operations on (binary) mutex semaphore

`.
The program logic will manipulate an environment map-ping locks to precise predicates.

Env = Locks *fin Prec.
The need for precision of these predicates (the lock invari-ants) can be seen from the Reynolds counterexample for
concurrent separation logic [22, 12].

The judgments of the concurrency logic are of the form

j B {p}C{q}
where j 2 Env defines all the lock variables free in C. Therules for concurrency are in Figure 3.

Definition 17 (Proof-theoretic Consequence Relation, II)We write

j; Ax ` {p} C {q},
to mean that j B {p} C {q} is derivable from assumptions

j0 B {p} c {q}, where {p} c {q} 2 Ax and j0 2 Env ,
by the rules in Figure 3.

7 A Concurrency Model

In broad outline, our semantics for the concurrent logicfollows that of Brookes [12]. First, we define an interleaving semantics based on action traces. This is a denotationalbut completely syntactic model, that resolves all the concurrency for us. Second, we give a way to "execute" thetraces in given states. Brookes did this using an additional
"local enabling relation" defined for the traces. Here, traceexecution just uses the denotational semantics in terms of
local functions. This allows us to formulate our model forarbitrary separation algebras.

7In [22] a conditional notion of critical section was used for convenience, but this can be encoded in terms of simple sections and assume.

6

j B {p1} C1 {q1} j B {p2} C2 {q2}

j B {p1 * p2} C1 k C2 {q1 * q2}

j, ` 7! r B {p} C {q}
j B {p * r} `.C {q * r}

j B {p * r} C {q * r}
j, ` 7! r B {p} with ` do C {q}

Plus the rules from Figure 2 with jB added uniformly

Figure 3. Rules for Concurrency
T (c) = {c} T (skip) = {skip} T (C1; C2) = {o/1; o/2 | o/i 2 T (Ci)}
T (C1 + C2) = T (C1) [ T (C2) T (C?) = (T (C))? T (C1 k C2) = {o/1 zip o/2 | o/i 2 T (Ci)}
T (`.C) = {(V (`); o/; P(`)) - ` | o/ 2 T (C) is `-synchronized} T (with ` do C) = {P(`); o/ ; V (`) | o/ 2 T (C)}

where o/1 zip o/2 and the auxiliary o/1 zip0 o/2 are defined as follows:

fl ::= skip | act(`) | check(c, c)
ffl zip o/ = o/ o/ zip ffl = o/ ffl zip0 o/ = o/ o/ zip0 ffl = o/
(c1; o/1) zip (c2; o/2) = check(c1, c2); ((c1; o/1) zip0 (c2; o/2)) (fl; o/1) zip o/2 = (fl; o/1) zip0 o/2
o/1 zip (fl; o/2) = o/1 zip0 (fl; o/2) (ff1; o/1) zip0 (ff2; o/2) = (ff1; (o/1 zip (ff2; o/2))) [ (ff2; ((ff1; o/1) zip o/2))

Figure 4. Trace Semantics
Syntactic Trace Model The traces will be made up of theprimitive actions of our programming language, plus two
additional semaphore operations to model entry and exitfrom critical regions.

Definition 18 An atomic action ff is a primitive command
or skip or a race-check or an `-action act(`).

ff ::= c | skip | check(c, c) | act(`)
act(`) ::= P(`) | V (`)

A trace o/ is a sequential composition of atomic actions:

o/ ::= ff; * * * ; ff
We write ffl for the empty trace, o/ -` for the trace obtained bydeleting all

`-actions from o/ , and o/|` for the trace obtainedby removing all non` actions from o/ .

Definition 19 A trace o/ is `-synchronized if o/ |` is an element of the regular language (P(`); V (`))?.

We are going, in what follows, to concentrate on `-synchronized traces only. This is justified for two reasons.

First, any P(`) will have a matching V (`) because thesemaphore operations will be generated in traces by entry to
and exit from critical regions with ` do C. The second rea-son can be stated logically and operationally. Operationally,

if one critical region for ` is nested within another regionfor the same

` then the inner region can never be executed.Logically, the proof rule for critical regions can never be

used on the inner region, because the rule for with ` do Cin Figure 3 deletes

` from the environment.

The set of traces T (C) of a command C is defined inFigure 4. Most cases are straightforward. The traces of

`.Care obtained by restricting to the
`-synchronized traces of Cand deleting
`-actions. The deletion of `-actions is justifiedby Lemma 21, since

`-actions behave like skip when ` ismapped to emp by the environment

j. The semantics of `.Cstarts with a V (
`) and ends with a P(`) to model the ideathat the lock declaration begins by transferring state into the

lock ` and terminates by releasing it. This follows the viewof P(

`) and V (`) as resource ownership transformers [22],formalized below using the annihilation and materialization

operations discussed at the end of Section 3. The criticalregion

with ` do C just inserts mutex operations before andafter
C. The traces of C1 k C2 are interleavings, exceptthat any time two primitive actions can potentially execute

at the same time we insert a check for races. We remark thatraces are not

detected at this stage: we merely insert checkstatements that will be evaluated at execution time.

Executing Traces As an individual trace is just a sequen-tial composition of simple commands, we can define its de7

notational semantics following Figure 1.J

cKvj = v(c) JskipKvjoe = {oe}J

C1; C2Kvj = (JC1Kvj); (JC2Kvj)J

P (`)Kvj = bla[emp, j(`)]J
V (`)Kvj = bla[j(`), emp]J
check(c1, c2)Kvj = check(v(c1), v(c2))

where check(f, g) is defined as follows:

check(f, g)(oe) = 8!: {

oe} if 9oef oeg. oef * oeg = oe ^

f (oef ) 6= ? ^ g(oeg) 6= ?? otherwise

In words, check (f, g)(oe) faults if we cannot find a parti-tion

oef *oeg of oe where the components of the partition con-tain sufficient resource for

f and g individually. In case theentire state
oe has enough resource for both f and g (mean-ing they don't deliver ?), check (

f, g)(oe) skips. In differentmodels, this sense of race takes on a different import. For

example, in the plain heap model, by this definition racingmeans that two operations touch the same location, even if
they are only reading the same location, while in permissionmodels two operations can read the same location without it
being judged a race. Note, though, that this determination,whether or not we have a race, is not something that must be
added to a model: it is always completely determined justby the * operation.

Lemma 20 Jcheck(c1, c2)Kvj is local.

A crucial property of trace execution is the following,which it relies essentially on lock invariants being precise.

Lemma 21 If o/ is an `-synchronized trace thenJ

V (`); o/ ; P(`)Kvj w Jo/ - `Kvj

Interpreting the Logic. We can now define a semanticsof Hoare triples that takes the lock invariants into account.

Definition 22 (Semantic Consequence Relation, II)Given a set of traces

S, we define the semanticsJ
SKvj = Fo/2SJo/ Kvj. We write

j; Ax |=I {p} C {q}
to mean that for all valuations v, if v satisfies Ax thenhh

pii JT (C)Kvj hhqii is true according to Definition 6.

The following lemma is the essential part of the proof ofsoundness for parallel composition.

Lemma 23 (Parallel Decomposition Lemma) If oe = oe1 *
oe2 and Jo/iKvjoei v qi for i = 1, 2, and o/ 2 (o/1 zip o/2) thenJ

o/ Kvjoe v q1 * q2.

Proof: The proof is by induction on the definition of zipand zip0. The first interesting case involves race checking. Consider o/1 = c1; o/ 01 and o/2 = c2; o/02. Then
o/ = check(c1, c2); o/ 0 for some o/0 2 (o/1 zip0 o/2). SinceJ

ci; o/iKvjoei v qi, we have JciKvjoei 6= ?, hence

check(Jc1Kvj, Jc2Kvj)(oe1 * oe2) = oe1 * oe2 6= ?.
That is, Jcheck(c1, c2)Kvjoe = oe. Induction hypothesis on
o/0 gives Jcheck(c1, c2); o/ 0Kvjoe v q1 * q2.

The other interesting case is the interleaving case of
zip0 (the bottom right equality in Figure 4). Consider
o/1 = ff1; o/ 01 and o/2 = ff2; o/ 02. and suppose that o/ 2(

ff1; (o/ 01 zip (ff2; o/ 02))) (the other case being symmetrical).Then there is

o/0 2 (o/ 01 zip (ff2; o/ 02)) with o/ = ff1; o/ 0.
Since Jo/iKvjoei v qi by assumption, we know thatJ
o/ 01Kvjoe01 v q1 for each oe01 2 v(ff1)oe1, where v(ffi)oei 6= ?by the execution semantics of sequential composition and

the fact that q1 6= ?. By induction hypothesis, for anysuch

oe01 where oe01#oe2, we have Jo/ 0Kvj(oe01 * oe2) v q1 * q2.This says exactly that J

o/ 0Kvj(oe0) v q1 * q2, for all oe0 2
v(ff1)oe1 * {oe2}. Since ff1 satisfies the locality conditionwe have

v(ff1)(oe1 * oe2) v v(ff1)oe1 * {oe2}, and Jo/ Kvjoe v
q1 * q2 by the semantics of sequential composition.

Note the use of the locality property for the basic actions ff(including semaphore operations) near the end of this proof.

Theorem 24 (Soundness, II) All of the proof rules pre-serve validity. As a result,

j; Ax ` {p} C {q} implies j; Ax |=I {p} C {q}
Proof: The proof is by induction on the derivation of
j; Ax ` {p} C {q}. For the rules in Figure 2 the proof isstraightforward. We consider the rules in Figure 3.

For the parallel rule, assume j; Ax |=I {pi} Ci {qi} for
i = 1, 2. We need to show j; Ax |=I {p1*p2} C1 k C2 {q1*
q2}. Consider a valuation v that satisfies Ax and a trace o/ 2
T (C1 k C2). We require hhp1 * p2ii [[o/ ]]vj hhq1 * q2ii. Take
oe = oe1 * oe2 such that oei 2 pi for i = 1, 2. We need to showthat J

o/ Kvjoe v q1 * q2. Since o/ 2 T (C1 k C2), we have
o/ = o/1zipo/2 for o/i 2 T (Ci). By assumption, Jo/iKvjoei v qifor

i = 1, 2. Lemma 23 gives Jo/ Kvjoe v q1 *q2, as required.
For the lock declaration rule, assume (j|`:=r); Ax |=I{
p} C {q}. We need to show j; Ax |=I {p * r} `.C {q * r}.Consider a valuation

v that satisfies Ax and a trace o/ 2
T (`.C). We need to show that hhp * rii [[o/ ]]vj hhq * rii holds.Take

oe 2 p * r. We need to prove that Jo/ Kvjoe v q *
r. Since o/ 2 T (`.C), we have (V (`); o/ 0; P(`)) - ` for `-synchronized

o/ 0 2 T (C). By assumption and the semanticsof P(
`) and V (`) we have JV (`); o/ 0; P(`)Kv(j|`:=r)oe v
q * r. Lemma 21 gives JV (`); o/ 0; P(`)Kv(j|`:=r) w Jo/ 0 -
`Kvj. Since o/ = (o/0 - `), we have shown Jo/ Kvjoe v q * r.

8

For the critical region rule, the traces of with ` do C areof the form P(

`); o/ 0; V (`). Given {p * r}C{q * r} and atrace
o/ 0 of C, we can reason sequentially as follows, whereintermediate assertions indicate use of the sequencing rule

{p} P (`) {p * r} o/0 {q * r} V (`){q}
This overall pre and post is what we need to establish forany trace of

with ` do C. The given preconditions and post-conditions for

P (`) and V (`) follow from their semanticdefinitions as best local actions: you use

p as a frame axiomin the
P case, and q as a frame axiom in the V case.Because failure of a race check results in value ?, and

because a Hoare triple is falsified by ?, the theorem alsoimplies that any proven program is race-free. This notion
of race-freedom is relative to the given separation algebra.In a plain heap model [

L *fin R] any access to a commonlocation is regarded as a race, while in permission models

concurrent reads are not judged racy.
Remarks on other rules. We did not include the auxil-iary variable elimination rule, which comes to separation

logic from Owicki and Gries. This rule requires variablesto be present in \Sigma , while the general notion of separation
algebra does not require variables to be present. It is easy tovalidate the rule in \Sigma 's that contain variables-as-resource. It
is possible, though, on the general level, to validate a ver-sion of Milner's expansion law, which captures part of the
import of the use of auxiliary variables.Neither did we explicitly include the Hoare logic rule
for introducing existentials [23]; it, semantically, just boilsdown to the disjunction rule. Finally, we did not include a
version of the substitution rule from [23]. This would re-quire formulation of a notion of parameterized local action.

8 Conclusion and Related Work

There are three main precursors to this work. The firstis the model theory of BI [24, 31], which Pym emphasized
can be understood as providing a general model of resource.At first, models of BI were given in terms of total commutative monoids and then, prodded by the development in [17],in terms of partial monoids. Separation algebras are a special case of the models in [30], corresponding to (certain)Boolean BI algebras.

The second precursor is [37], which identified SafetyMonotonicity and the Frame Property, conditions on an
operational semantics corresponding to the frame rule. Incomparison to [37] the main step forward - apart from concurrency and consideration of a class of models rather thana single one - is the use of functions into the poset

P (\Sigma )?instead of relations satisfying Safety Monotonicity and the

Frame Property. This shift has led to dramatic simplifica-tions. For example, the formulation of the best state transformers (Definition 10) is much simpler and easier to un-derstand than its relational cousin in [25].

The relational version of local actions for separation al-gebras was used in [18]. This was based on Safety Monotonicity and the Frame Property, prior to our move to thetopped powerset. Also, the focus there was on program refinement, rather than abstract separation logic.

The third precursor is Brookes's proof of the soundnessof concurrent separation logic, for the RAM model [12].

One of the key insights of Brookes's work shows up againhere, where the semantics is factored into two parts: i) a
(stateless) trace model, where interleaving is done on the(syntactic) actions; ii) a semantics that interprets the actions' effects on states. With this factoring concurrency ishandled in the action-trace model, in a way that is largely independent of the meanings of the primitive commands, andthis means that the imperative (state transforming) meaning
of commands needs only to be given in a sequential set-ting, for the traces, after concurrency has been resolved by
interleaving. We attempted to prove soundness for an inter-leaving operational semantics of concurrency in the style of
Plotkin, but doing so directly turned out to be difficult, par-ticularly in the case of lock (resource) declarations: these
are handled easily via filtering in the trace semantics.

There are, though, several differences in our seman-tics and Brookes's. Most importantly, Brookes's traces are

made up of items that are tightly tied to the RAM model,and are not themselves primitive commands in the language
under consideration. Because we use the primitive com-mands themselves (plus semaphore operations) as the elements of the interleaving, we are able to see that soundnessdepends only on the locality properties of the primitive commands: this gives a sharper explanation of the conditionsneeded for soundness, and it transfers immediately to the
more general class of models. Our proof of soundness for aninfinite class of models is (arguably) simpler than Brookes's
proof for a single model; for example, our Lemma 23 isconsiderably simpler in its statement than Brookes's Parallel Decomposition Lemma. There are other detailed differ-ences, such as that we detect races while executing traces,
after interleaving, while Brookes detects races at an earlierstage (during interleaving). This being said, we fully acknowledge the influence of Brookes's original analysis.

The concurrency model given in this paper is still re-moved from the way that programs work in two respects

(even under timeslicing on a single-CPU machine). Thefirst is that the semantics of lock declarations

`.C simplydrops all
`-actions from traces. The second is that we pre-sume that traces have structure inspired by the intuition of

mutual exclusion, but we do not explicitly represent block-ing or busy-waiting in the semaphores used in their interpretation. In the long version of the paper [13] we justify theseaspects of the model by connecting it to an operational semantics in the style of Plotkin.8

8Also, because of race-freedom it should be possible to connect to a

9

In formulating our results we have not aimed for themaximum possible generality. Our results on the sequential
subset of ASL could almost certainly be redone using con-text logic [14], which replaces the primitive of separation
by the primitive of pulling a state apart into a state-with-a-hole (a context) and its filler; more work on context logic
would be required to generalize our more significant resultson concurrency. Abstract predicates and higher-order separation logic have been used to approach modules, whilethe treatment here avoids higher-order predicates [26, 6].
Finally, it would be desirable to go beyond algebra and for-mulate the essence of local action at a categorical level, perhaps on the level of the general theory of effects [19, 29].Rather than shooting for maximum generality, we have
chosen a tradeoff between complexity and generality, thatdemonstrates the existence of at least one abstract account
of a basis for local reasoning about programs. It is but onepossible path through the subject. Recent work on the logic
for low-level code sometimes chooses to reflect locality ina novel interpretation of Hoare triples [7] rather than in the
semantics of commands, or to express locality explicitly bypolymorphism [20, 3]. The work on Boogie [2] achieves
modularity using ideas that have hints of the primitives inseparation logic [21], and a study of the abstract principles
underlying Boogie could be valuable. And, it does not ap-pear that the locality condition in our model can be used to
explain the "procedure local semantics" of [35]. Generally,we believe that there is more to be learnt about local reasoning about programs, particularly concurrent programs, andabout semantics expressing local program behaviour.

Acknowledgments. We are grateful to Philippa Gard-ner and Martin Hyland for trenchant criticisms at decisive
points in this work.We acknowledge the financial support of the EPSRC.

References

[1] A. Ahmed, L. Jia, and D. Walker. Reasoning about hierarchicalstorage. In 18th LICS, pp33-44, 2003.

[2] M. Barnett, R. DeLine, M. Fahndrich, K.R.M. Leino, andW. Schulte. Verification of object-oriented programs with invariants. Journal of Object Technology, 3(6):27-56, 2004.
[3] N. Benton. Abstracting allocation. In CSL 2006, pp182-196, 2006.
[4] J. Berdine, C. Calcagno, and P.W. O'Hearn. Smallfoot: Automaticmodular assertion checking with separation logic. In 4th FMCO,

pp115-137, 2006.
[5] J. Berdine, B. Cook, D. Distefano, and P. O'Hearn. Automatic ter-mination proofs for programs with shape-shifting heaps. In 18th

CAV, pp386-400, 2006.
[6] L. Birkedal and N. Torp-Smith. Higher-order separation logic andabstraction. submitted.

[7] L. Birkedal and H. Yang. Relational parametricity and separationlogic. In 10th FOSSACS, LNCS 4423, pp93-107, 2007.
[8] R. Bornat, C. Calcagno, P. O'Hearn, and M. Parkinson. Permissionaccounting in separation logic. In 32nd POPL, pp59-70, 2005.

weak memory model, but we have not formulated such a connection.

[9] R. Bornat, C. Calcagno, and H. Yang. Variables as resource in sep-aration logic. In 21st MFPS, pp247-276, 2005.
[10] S. Brookes. A grainless semantics for parallel programs with sharedmutable data. In 21st MFPS, pp277-307, 2005.
[11] S. Brookes. Variables as resource for shared-memory programs:Semantics and soundness. In 22nd MFPS, pp123-150, 2006.
[12] S. D. Brookes. A semantics for concurrent separation logic. Pro-ceedings of the 15th CONCUR, London. August, 2004.
[13] C. Calcagno, P. O'Hearn, and H. Yang. Local Action and AbstractSeparation Logic (Longer version).

www.dcs.qmul.ac.uk/,ohearn/papers/asl-long.pdf, 2007.
[14] C. Calcagno, P. Gardner, and U. Zarfaty. Context logic and treeupdate. In 32nd POPL, pp271-282, 2005.

[15] X. Feng, R. Ferreira, and Z. Shao. On the relationship between con-current separation logic and assume-guarantee reasoning. In 16th

ESOP, to appear, 2007.
[16] J. Hayman and G. Winskel. Independence and concurrent separationlogic. In 21st LICS, pp147-156, 2006.

[17] S. Isthiaq and P. W. O'Hearn. BI as an assertion language for muta-ble data structures. In 28th POPL, pages 36-49, 2001.
[18] I. Mijajlovic, N. Torp-Smith, and P. O'Hearn. Refinement and sep-aration contexts. Proceedings of FSTTCS, 2004.
[19] E. Moggi. Notions of computation and monads. Information andComputation 93(1), pp55-92, 1991.
[20] A. Nanevski, G. Morrisett, and L. Birkedal. Polymorphism andseparation in Hoare type theory. In ICFP 2006, pages 62-73, 2006.
[21] D. A. Naumann and M. Barnett. Towards imperative modules: Rea-soning about invariants and sharing of mutable state. In 19th LICS,

2004.
[22] P. O'Hearn. Resources, concurrency and local reasoning. Theoret-ical Computer Science 375(1-3), pp271-307, May 2007. (Preliminary version appeared in CONCUR'04, LNCS 3170, 49-67.)
[23] P. O'Hearn, J. Reynolds, and H. Yang. Local reasoning about pro-grams that alter data structures. In 15th CSL, pp1-19, 2001.

[24] P. W. O'Hearn and D. J. Pym. The logic of bunched implications.Bulletin of Symbolic Logic, 5(2):215-244, June 99.
[25] P. W. O'Hearn, H. Yang, and J. C. Reynolds. Separation and infor-mation hiding. In 31st POPL, pages 268-280, 2004.
[26] M. Parkinson and G. Bierman. Separation logic and abstraction. In32nd POPL, pp59-70, 2005.
[27] M. Parkinson, R. Bornat, and C. Calcagno. Variables as resource inHoare logics. In 21st LICS, 2006.
[28] M. Parkinson, R. Bornat, and P. O'Hearn. Modular verification of anon-blocking stack. In 34th POPL, 2007.
[29] A.J. Power and E.P. Robinson. Premonoidal categories and notionsof computation. Math. Struct. Comp. Sci. 7(5), pp453-468, 1997.
[30] D. Pym, P. O'Hearn, and H. Yang. Possible worlds and resources:the semantics of BI. Theoretical Computer Science, 315(1):257-

305, 2004.
[31] D.J. Pym. The Semantics and Proof Theory of the Logic of BunchedImplications. Kluwer Applied Logic Series, 2002.

[32] W. Reisig. Petri nets. EATCS Monographs, vol. 4, 1995.
[33] J. C. Reynolds. Intuitionistic reasoning about shared mutable datastructure. In Millennial Perspectives in Computer Science, pp 303-

321, 2000. Palgrave.
[34] J. C. Reynolds. Separation logic: A logic for shared mutable datastructures. In 17th LICS, pp 55-74, 2002.

[35] N. Rinetzky, J. Bauer, T. Reps, M. Sagiv, and R. Wilhelm. A se-mantics for procedure local heaps and its abstractions. 32nd POPL,

pp296-309, 2005.
[36] N. Torp-Smith, L. Birkedal, and J. Reynolds. Local reasoning abouta copying garbage collector. In 31st POPL, pp220-231, 2004.

[37] H. Yang and P. O'Hearn. A semantic basis for local reasoning. In5th FOSSACS, LNCS 2303, 2002.

10