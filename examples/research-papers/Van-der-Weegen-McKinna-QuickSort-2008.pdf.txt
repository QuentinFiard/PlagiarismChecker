

A Machine-checked Proof of the Average-case

Complexity of Quicksort in Coq

Eelis van der Weegen? and James McKinnaeelis@eelis.net, james.mckinna@cs.ru.nl
Institute for Computing and Information Sciences

Radboud University Nijmegen
Heijendaalseweg 135, 6525 AJ Nijmegen, The Netherlands

Abstract. As a case-study in machine-checked reasoning about the
complexity of algorithms in type theory, we describe a proof of the
average-case complexity of Quicksort in Coq. The proof attempts to follow a textbook development, at the heart of which lies a technical lemma
about the behaviour of the algorithm for which the original proof only
gives an intuitive justification.
We introduce a general framework for algorithmic complexity in type theory, combining some existing and novel techniques: algorithms are given
a shallow embedding as monadically expressed functional programs; we
introduce a variety of operation-counting monads to capture worst- and
average-case complexity of deterministic and nondeterministic programs,
including the generalization to count in an arbitrary monoid; and we give
a small theory of expectation for such non-deterministic computations,
featuring both general map-fusion like results, and specific counting arguments for computing bounds.
Our formalization of the average-case complexity of Quicksort includes
a fully formal treatment of the `tricky' textbook lemma, exploiting the
generality of our monadic framework to support a key step in the proof,
where the expected comparison count is translated into the expected
length of a recorded list of all comparisons.

1 Introduction
Proofs of the O(n log n) average-case complexity of Quicksort [1] are includedin many textbooks on computational complexity [9, for example]. This paper
documents what the authors believe to be the first fully formal machine-checkedversion of such a proof, developed using the Coq proof assistant [2].

The formalisation is based on the "paper proof" in [9], which consists of threeparts. The first part shows that the total number of comparisons performed
by the algorithm (the usual complexity metric for sorting algorithms) can bewritten as a sum of expected comparison counts for individual pairs of input
list elements. The second part derives from the algorithm a specific formula for

? Research carried out as part of the Radboud Master's programme in "Foundations"

2
this expectation. The third and last part employs some analysis involving theharmonic series to derive the

O(n log n) bound from the sum-of-expectations.

Of these three parts, only the first two involve the actual algorithm itself--the third part is strictly numerical. While the original proof provides a thorough

treatment of the third part, its treatment of the first two parts is informal intwo major ways.

First, it never actually justifies anything in terms of the algorithm's formalsemantics. Indeed, it does not even formally define the algorithm in the first
place, relying instead on assertions which are taken to be intuitively true. Whilethis practice is common and perfectly reasonable for paper proofs intended for
human consumption, it is a luxury we can not afford ourselves.

Second, the original proof (implicitly) assumes that the input list does notcontain any duplicate elements, which significantly simplifies its derivation of

the formula for the expected comparison count for pairs of individual input listelements. We take care to avoid appeals to such an assumption.

The key to giving a proper formal treatment of both these aspects lies inusing an appropriate representation of the algorithm, capable of capturing its
computational behaviour--specifically, its use of comparisons--in a way suit-able for subsequent formal reasoning. The approach we take is to consider such
operation-counting as a side effect, and to use the general framework of monadsfor representing side-effecting computation in pure functional languages. Accordingly we use a shallow embedding, in which the algorithm, here Quicksort,is written as a monadically expressed functional program in Coq. This definition
is then instantiated with refinements of operation-counting monads to make thecomparison count observable.

The embedding is introduced in section 2, where we demonstrate its useby first giving a simple deterministic monadic Quicksort definition, and then
instantiating it with a simple operation counting monad that lets us prove itsquadratic worst-case complexity.

For the purposes of the more complex average-case theorem, we then give(in section 3) a potentially-nondeterministic monadic Quicksort definition, and
compose a monad that combines operation counting with nondeterminism, sup-porting a formal definition of the notion of the expected comparison count, with
which we state the main theorem in section 4.

The next two sections detail the actual formalised proof. Section 5 corre-sponds to the first part in the original proof described above, showing how the

main theorem can be split into a lemma (stated in terms of another specializedmonad) giving a formula for the expected comparison count for individual pairs
of input elements, and a strictly numerical part. Since we were able to fairly di-rectly transcribe the latter from the paper proof, using the existing real number
theory in the Coq standard library with few complications and additions, weomit discussion of it here and refer the interested reader to the paper proof.

Section 6 finishes the proof by proving the lemma about the expected com-parison count for individual input list elements. Since this is the part where the
original proof omits the most detail, and makes the assumption regarding dupli3
cate elements, and where we really have to reason in detail about the behaviourof the algorithm, it is by far the most involved part of the formalisation.

Section 7 ends with conclusions and final remarks.The Coq source files containing the entire formalisation can be downloaded
from http://www.eelis.net/research/quicksort/. We used Coq version 8.2.
Related work In his Ph.D thesis [12], Hurd presents an approach to formalanalysis of probabilistic programs based on a comprehensive formalisation of
measure-theoretic constructions of probability spaces, representing probabilisticprograms using a state-transforming monad in which bits from an infinite supply
of random bits may be consumed. He even mentions the problem of proving theaverage-case complexity of Quicksort, but leaves it for future work.

In [11], Audebaud and Paulin-Mohring describe a different monadic approachin which programs are interpreted directly as measures representing probability
distributions. A set of axiomatic rules is defined for estimating the probabilitythat programs interpreted this way satisfy certain properties.

Compared to these approaches, our infrastructure for reasoning about non-deterministic programs is rather less ambitious, in that we only consider finite
expectation based on na"ive counting probability, using a monad for nondeter-minism which correctly supports weighted expectation. In particular, we do not
need to reason explicitly with probability distributions.A completely different approach to type-theoretic analysis of computational
complexity is to devise a special-purpose type theory in which the types of termsinclude some form of complexity guarantees. Such an approach is taken in [4],
for example.

2 A Shallow Monadic Embedding
As stated before, the key to giving a proper formal treatment of those parts ofthe proof for which the original contents itself with appeals to intuition, lies in
the use of an appropriate representation of the algorithm. Indeed, we cannoteven formally state the main theorem until we have both an algorithm definition
and the means to denote its use of comparisons.Since we are working in Coq, we already have at our disposal a full functional
programming language, in the form of Coq's CIC [3]. However, just writingthe algorithm as an ordinary Coq function would not let us observe its use
of comparisons. We can however see comparison counting as a side effect. Asis well known and standard practice in functional languages such as Haskell,
side effects can be represented using monads: a side-effecting function f fromA to B is represented as a function A ! M B where M is a type constructor
encapsulating the side effects. "Identity" and "composition" for such functionsare given by ret (for "return") of type A ! M A and bind (infix:

>>=) of typeM A ! (A ! M B) ! M B satisfying certain identities (the monad laws). For

a general introduction to monadic programming and monad laws, see [5].Furthermore, we use Haskell's "do-notation", declared in Coq as follows

4

Notation "x <- y ; z" := (bind y (*x : ) z ))
and freely use standard monadic functions such as:

liftM : 8 (M : Monad) (A B : Set), (A ! B ) ! (M A ! M B)filterM : 8 (M : Monad ) (A : Set)

, (A ! M bool ) ! list A ! M (list A)

Here, the Coq type Monad is a dependent record containing the (coercible)carrier of type Set ! Set, along with the bind and ret operations, and proofs of

the three monad laws.We now express Quicksort in this style, parameterizing it on both the monad
itself and on the comparison operation. A deterministic Quicksort that simplyselects the head of the input list as its pivot element, and uses two simple filter
passes to partition the input list, looks as follows:

Variables (M : Monad) (T : Set) (le : T ! T ! M bool ).
Definition gt (x y : T ) : M bool := liftM negb (le x y).
Program Fixpoint qs (l : list T ) {measure length l } : M (list T ) :=

match l with| nil ) ret nil

| pivot :: t )lower  filterM (gt pivot) t

>>= qs;upper  filterM (le pivot) t
>>= qs;ret (lower ++ pivot :: upper )

end.
We use Coq's Program Fixpoint facility [7] to cope with Quicksort's non-structural recursion, specifying list length as an input measure function that is

separately shown to strongly decrease for each recursive call. For this definitionof qs, these proof obligations are trivial enough for Coq to prove mostly by itself.

For recursive functions defined this way, Coq does not automatically definecorresponding induction principles matching the recursive call structure. Hence,
for this qs definition as well as the one we will introduce in section 3, we hadto define these induction principles manually. To make their use as convenient
as possible, we further customized and specialized them to take advantage ofspecific monad properties. We will omit further discussion of these issues in this
paper, and will henceforth simply say: "by induction on qs, ...".By instantiating the above definitions with the right monad, we can transparently insert comparison-counting instrumentation into the algorithm, which willprove to be sufficient to let us reason about its complexity. But before we do so,
let us note that if the above definitions are instead instantiated with the identitymonad and an ordinary elementwise comparison on T , then the monadic scaffolding melts away, and the result is equivalent to an ordinary non-instrumented,non-monadic version, suitable for extraction and correctness proofs (which are
included in the formalisation for completeness). This means that while we willinstantiate the definitions with less trivial monads to support our complexity
proofs, we can take some comfort in knowing that the object of those proofs is,

5
in a very concrete sense, the actual Quicksort algorithm (as one would write it ina functional programming language), rather than some idealized model thereof.

For reasons that will become clear in later sections, we construct the monadwith which we will instantiate the above definitions using a monad transformer
[8] MMT (for "monoid monad transformer"), which piggybacks a monoid ontoan existing monad by pairing.

Variables (monoid : Monoid) (monad : Monad).
Let CMMT (T : Set) : Set := monad (monoid * T ).
Let retMMT (T : Set) : T ! CMMT T := ret ffi pair (monoid zero monoid).
Let bindMMT (A B : Set) (a : CMMT A) (ab : A ! CMMT B) : CMMT B :=x  a; y  ab (snd x ); ret (monoid mult monoid (fst x ) (fst y)

, snd y).

Definition MMT : Monad := Build Monad CMMT bindMMT retMMT .

(In the interest of brevity, we omit proofs of the monad laws for MMT and allother monads defined in this paper. These proofs can all be found in the Coq

code.)We now use MMT to piggyback the additive monoid structure on N onto
the identity monad, and lift elementwise comparison into the resulting monad,which we call SP (for "simply-profiled").

Definition SP : Monad := MMT (N, 0, +) IdMonad .
Definition leSP (x y : N) : SP bool := (1, le x y).

When instantiated with this monad and comparison operation, qs produces thecomparison count as part of its result.

Definition qsSP := qs SP leSP .
Eval compute in qsSP (3 :: 1 :: 0 :: 4 :: 5 :: 2 :: nil ).= (16

, 0 :: 1 :: 2 :: 3 :: 4 :: 5 :: nil)

Defining cost and result as the first and second projection, respectively, we triv-ially have identities such as cost (ret

SP x ) = 0, cost (leSP x y) = 1, andcost (x
>>=SP f ) = cost x + cost (f (result x )). This very modest amountof machinery is sufficient for a straightforward proof of Quicksort's quadratic

worst-case complexity.
Proposition. qs worst : 8 l, cost (qsSP l) 6 (length l )2.1
Proof. The proof is by induction on qs. For l = nil, we have cost (qsSP nil) =cost (ret nil) = 0 6 (length l)

2. For l = h :: t, the cost decomposes into

cost (filter (le h) t) + cost (qsSP (result (filter (le h) t))) +cost (filter (gt h) t) + cost (qs

SP (result (filter (gt h) t))) +cost (ret (result (qs
SP (result (filter (le h) t))) ++h :: result (qs
SP (result (filter (gt h) t))))).
1 We do not use big-O notation for this simple statement, as it would only obfuscate.

Big-O complexity is discussed in section 4.

6
The filter costs are easily proved (by induction on t) to be length t each. Thecost of the final ret is 0 by definition. The induction hypothesis applies to the
recursive qsSP calls. Furthermore, by induction on t, we can easily prove

length (result (filter (le h) t)) + length (result (filter (gt h) t)) 6 length t,
because the two predicates filtered on are mutually exclusive. Abstracting thefilter terms as flt and flt0, this leaves

length flt + length flt0 6 length t !length t + (length flt)

2 + length t + (length flt0)2 + 0 6 (S (length t))2,

which is true by elementary arithmetic. ut

We now extend the technique to prepare for the average-case proof.

3 Nondeterminism and Expected Values
The version of Quicksort used in the average-case complexity proof in [9] differsfrom the one presented in the last section in two ways. This is also reflected in
our formalisation.First, the definition of qs is modified to use a single three-way partition pass,
instead of two calls to filter , thus avoiding the pathological quadratic behaviourwhich can arise when the input list does not consist of distinct elements.

Second, and more significantly, we use nondeterministic pivot selection, thusavoiding the pathological quadratic behaviour from which any deterministic
pivot selection strategy inevitably suffers. While this means that we have provedour result for a subtly different presentation of Quicksort, this nevertheless follows the textbook treatment, in line with common practice.These two modifications together greatly simplify the formalisation, because
they remove the need to carefully track input distributions in order to showthat `good' inputs (for which the original deterministic version of the algorithm
performs well) sufficiently outnumber `bad' inputs (for which the original versionperforms poorly). They further ensure that the

O(n log n) average-case boundholds not just averaged over all possible input lists, but for each individual input

list as well. In particular, it means that once we prove that the bound holds foran arbitrary input, the global bound immediately follows.

This also means that for a key lemma near the end of our proof, we can usestraightforward induction over the algorithm's recursive call structure, without
having to show that given appropriately distributed inputs, the partition stepyields lists that are again appropriately distributed. Such issues are a major technical concern in more ambitious approaches to average-case complexity analysis[10, for example] and to the analysis of probabilistic algorithms.

The second modification is based on a new monad (again defined using MMT ,but this time transforming a nondeterminism monad) with which the new definition can be instantiated, capturing the expected comparison count.

7
The first modification is relatively straightforward. Instead of calling filterM ,which uses a two-way comparison operation producing a monadic bool, we define
a function partition. It takes a three-way comparison operation producing amonadic comparison, which is an enumeration with values Lt, Eq, and Gt. We
represent the resulting partitioning by a function of type comparison ! list Trather than a record or tuple type containing three lists, because in the actual
formalisation, this saves us from having to constantly map comparison values tocorresponding record field accessors or tuple projections. This is only a matter
of minor convenience; a record or tuple could have been used instead withoutproblems.

Variables (T : Set) (M : Monad) (cmp : T ! T ! M comparison).
Fixpoint partition (t : T ) (l : list T ) : M (comparison ! list T ) :=match l with

| nil ) ret (const nil )| h :: l 0 )

c  cmp h t; f  partition t l 0;ret (

*c0 ) if c = c0 then h :: f c0 else f c0)end
.

Next, we redefine qs to use partition, and have it take as an additional param-eter a pick operation, representing nondeterministic selection of an element of a

non-empty list of choices. An ne list T is a non-empty list of T 's, inductivelydefined in the obvious way.

Variable pick : 8 A : Set, ne list A ! M A.
Program Fixpoint qs (l : list T ) {measure length l } : M (list T ) :=

match l with| nil ) ret nil

| )i  pick [0

... length l - 1];let pivot := nth l i in

part  partition pivot (remove l i);low  qs (part Lt);
upp  qs (part Gt);ret (low ++ pivot :: part Eq ++ upp)
end.
The functions nth and remove select and remove the nth element of a list,respectively.

Note that the deterministic Quicksort definition in section 2 could also havebeen implemented with a partition pass instead, which might well have made
the worst-case proof even simpler. We chose not to do this, in order to emphasisethat the properties the average-case proof demands of the algorithm rule out the
na"ive but familiar implementation using filter passes.Nondeterminism can now be emulated by instantiating these definitions with
a suitable monad and pick operation. A deterministic, non-instrumented version

8
can still be obtained, simply by using the identity monad and any deterministicpick operation, such as head or `median-of-three' (not considered here).

Let us now consider what kind of nondeterminism monad would be suitablefor reasoning about the expected value of a nondeterministic program like

x  pick [0, 1]; if x = 0 then ret 0 else pick [1, 2].
When executed in the list monad (commonly used to emulate nondeterministiccomputation), this program produces [0

, 1, 2] as its list of possible outcomes.Unfortunately, the information that 0 is a more likely outcome than 1 or 2 has

been lost. Such relative probabilities are critical to the notion of an expectedvalue: the expected value of the program above is avg [0

, avg [1, 2]] = 34 6= 1 =avg [0
, 1, 2]. This makes list nondeterminism unsuitable for our purposes.Using tree nondeterminism instead solves the problem: we introduce the type

ne tree of non-empty trees, building on ne list:

Inductive ne tree (T : Set) : Set :=| Leaf : T ! ne tree T

| Node : ne list (ne tree T ) ! ne tree T .
Definition retne tree {A : Set } : A ! ne tree A := Leaf .
Fixpoint bind ne tree (A B : Set)(m : ne tree A) (k : A ! ne tree B) : ne tree B :=

match m with| Leaf a ) k a

| Node ts ) Node (ne list.map (*x ) bind ne tree x k) ts)
end.

Definition Mne tree : Monad := Build Monad ne tree bindne tree retne tree.
Definition pickne tree (T : Set) : ne list T ! Mne tree T:= Node ffi ne list

.map Leaf .

We use non-empty trees because we do not consider partial functions, and usingpotentially empty trees would complicate the definition of a tree's average value

below. This is also why we used ne list for pick .With this monad and pick operation, the same program now produces the tree
Node [Leaf 0, Node [Leaf 1, Leaf 2]], which preserves the relative probabilities.The expected value now coincides with the weighted average of these trees:

Definition ne tree.avg : ne tree R ! R := ne tree.fold id ne list.avg.
Relative probabilities are also the reason we use an n-ary choice primitiverather than a binary one, because correctly emulating (that is, without skewing

the relative probabilities) an n-ary choice by a sequence of binary choices is onlypossible when

n is a power of two.To denote the expected value of a discrete measure f of the output of a

program, we define

Definition expec (T : Set) (f : T ! N) : ne tree T ! R:= ne tree

.avg ffi ne tree.map f .

9
Thus, given a program P of type Mne tree (list bool ), expec length P denotesthe expected length of the result list, if we interpret values of type

Mne tree Tas nondeterministically computed values of type T .

The function expec gives rise to a host of identities, such as

0 <= expec f t
expec (*x ) f x + g x ) t = expec f t + expec g t

expec ((*c) ffi f ) = (*c) ffi expec f
(8 x 2 t ! f x 6 g x ) ! expec f t <= expec g t

(8 x 2 t ! f x = c) ! expec f t = c

(8 x 2 t ! f x = 0) $ expec f t = 0

expec f (t >>= (ret ffi g)) = expec (f ffi g) t

expec (f ffi g) t = expec f (ne tree.map g t) (1)

To form the monad with which we will instantiate qs for the main theorem,we now piggyback the additive monoid on N onto

Mne tree using MMT , and callthe result NDP (for "nondeterministically profiled"):

Definition MNDP : Monad := MMT (N, 0, +) Mne tree.
Definition cmpNDP (x y : T ) : MNDP bool := retne tree (1, cmp x y).
Definition qsNDP := qs MNDP cmpNDP (lift pick ne tree).

We can now denote the expected comparison count for a qsNDP application byexpec cost (qs

NDP l ), and will use this in our statement of the main theorem inthe next section.

But before we do so, we define a slight refinement of expec that specificallyobserves the monoid component of computations in monads formed by transforming Mne tree using MMT (like NDP).

Definition monoid expec (m : Monoid) (f : m ! N) {A : Set }: (MMT m

Mne tree A) ! R := expec (f ffi fst).

Since cost = fst, we have expec cost t = monoid expec id t.In addition to all the identities monoid expec inherits from expec, it has some

of its own. One identity states that if one transforms Mne tree using a monoidm, then for a monoid homomorphism h from m to the additive monoid on N,
monoid expec h distributes over bind, provided that the expected monoid valueof the right hand side does not depend on the computed value of the left hand
side:

monoid expec plus : 8 (m : Monoid) (h : m ! (N, 0, +)),monoid homo h ! 8 (A B : Set)

(f : MMT m Mne tree A) (g : A ! MMT m Mne tree B ) :(8 x y 2 f ! monoid expec h (g (snd x )) = monoid expec h (g (snd y)))

,monoid expec h (f
>>= g) =monoid expec h f + monoid expec h (g (snd (ne tree

.head f ))).

10

Since id is a monoid homomorphism, monoid expec plus applies to NDP andexpec cost. In section 5, we will use monoid expec plus with another monoid and
homomorphism.

4 The Statement
The last thing needed before the main theorem can be stated, is the notion ofbig-O complexity. We use the standard textbook definition, except that we make
explicit how we measure inputs to f , namely with respect to a measure functionm:

Definition bigO (X : Set) (m : X ! N) (f : X ! R) (g : N ! R) : Prop:= 9 c n

, 8 x , n 6 m x ! f x 6 c * g (m x ).

Notation "wrt m, f = O (g)" := bigO m f g.

We now state the main theorem.

Theorem qs avg : wrt length, expec cost ffi qsNDP = O (*n ) n * log2 n).
Thanks to the property discussed at the start of the previous section, qs avgfollows as a corollary from the stronger statement

qs expec cost : 8 l , expec cost (qsNDP l ) 6 2 * length l * (1 + log2 (length l )),
the proof of which is described in the next two sections.

5 Reduction to Pairwise Comparison Counts
As described in the introduction, the key ingredient in the proof is a lemmagiving a formula for the expected comparison count for individual pairs of input
list elements, indexed a certain way. More specifically, if X j XI0 . . . XIn-1 isthe input list, with

I a permutation of [0 ... n - 1] such that X0 . . . Xn is sorted,then the expected comparison count for any

Xi and Xj with i < j is at most2
/(1 + j - i). In other words, the expected comparison count for two input listelements is bounded by a simple function of the number of list elements that

separate the two in the sort order. We prove this fact in the next section, butfirst show how qs expec cost follows from it.

Combined with the observation that the total expected comparison countought to equal the sum of the expected comparison count for each individual
pair of input elements, the property described above suggests breaking up theinequality into

expec cost (qsNDP l) 6 X

(i,j)2IJ

ecc i j 6 2 * length l * (1 + log2 (length l )),

where IJ := {(i, j) 2 [0, length l ) | i < j}, and ecc i j := 2 / (1 + j - i).

11
The right-hand inequality is a strictly numerical affair, requiring a bit ofanalysis involving the harmonic series. As stated before, this part of the proof
was fairly directly transcribed from the paper proof, with few complications andadditions, and so we will not discuss it.

The left inequality is the challenging one. To bring it closer to the indexsummation, we first write l on the left-hand side as map (nth (sort l)) li,
where sort may be any sorting function (including qs itself), and where li is apermutation of [0

... n - 1] such that map (nth (sort l )) li = l (such an li caneasily be proven to exist).

Next, we introduce a specialized monad and comparison operation that goone step further in focusing specifically on these indices.

Definition MonoidU : Monoid := (list (N * N), nil , ++).
Definition U : Monad := MMT Monoid U Mne tree.
Definition lookup cmp (x y : N) : comparison :=cmp (nth (sort l ) x ) (nth (sort l ) y)

.

Definition unordered nat pair (x y : N) : N * N :=

if x 6 y then (x , y) else (y, x ).

Definition cmpU (x y : N) : U comparison :=ret (unordered nat pair x y :: nil

, lookup cmp x y).

Definition qsU : list N ! list N := qs U cmpU pick U .

The function qsU operates directly on lists of indices into sort l . Comparison ofindices is defined by comparison of the values they denote in sort l. Furthermore,

rather than producing a grand total comparison count the way NDP does, Urecords every pair of indices compared, by using MMT with Monoid

U , the freemonoid over N * N pairs, instead of the additive monoid on N we used until now.

We now rewrite

expec cost (qsNDP (map (nth (sort l )) li))= monoid expec length (qs

U li ) = expec (length ffi fst) (qsU li).
The first equality expresses that the expected number of comparisons countedby NDP is equal to the expected length of the list of comparisons recorded by

U . In the formalisation, this is a separate lemma proved by induction on qs. Thesecond equality merely unfolds the definition of monoid expec.

After rewriting with identity 1 in section 3 on page 9, the goal becomes

expec length (ne tree.map fst (qsU li)) 6 X

(i,j)2IJ

ecc i j .

We now invoke another lemma which bounds a nondeterministically computedlist's expected length by the expected number of occurrences of specific values
in that list. More specifically, it states that8

(X : Set) (fr : X ! R) (q : list X ) (t : ne tree (list X )),(8 x 2 q

, expec (count x ) t 6 fr x ) !

(8 x /2 q, expec (count x ) t = 0) ! expec length t 6 X

x2q fr x

.

12
We end up with two subgoals, the first of which is

8 (i, j ) /2 IJ , expec (count (i, j )) (ne tree.map fst (qsU li)) = 0.
Rewriting this using identity 1 from section 3 in reverse, then rewriting the expecas a monoid expec, and then generalizing the premise, results in

8 i j li, (i /2 li . j /2 li ) ! monoid expec (count (i, j )) (qsU li) = 0 (2)
which can be shown by induction on qs, although we will not do so in this paper.We will use this property again in the next section.

The second subgoal, expressed with monoid expec, becomes

8 (i, j ) 2 IJ , monoid expec (count (i, j )) (qsU li) 6 ecc i j (3)
which corresponds exactly to the property described at the beginning of thissection. We prove it in the next section.

6 Finishing the Proof
Again, the proof of (3) is by induction on qs. But to get a better inductionhypothesis, we drop the (i

, j ) 2 IJ premise (because as was shown in the lastsection, the statement is also true if (i

, j ) /2 IJ ), and add a premise saying li isa permutation of a contiguous sequence of indices.

8 i j , i < j ! 8 (li : list N) (b : N), Permutation [b ... b + length li - 1] li !monoid expec (count (i

, j )) (qsU li) 6 ecc i j .

In the base case, li is nil, and the left-hand side of the inequality reduces to 0.In the recursive case, qs unfolds:

monoid expec (count (i, j )) (pi  pick [0

... n - 1];let pivot := nth li pi in

part  partitionU pivot (remove li pi );lower  qs

U (part Lt);upper  qs

U (part Gt);ret (lower ++ pivot :: part Eq ++ upper )

) 6 ecc i j .
Since cmpU is deterministic, partitionU is as well. Furthermore, since we knowexactly what monadic effects partition

U has, we can split those effects off andrevert to simple effect-free filter passes. Finally, we rewrite using the following

monoid expec identity:

monoid expec f (pick l >>= m) = avg (map (monoid expec f ffi m) l ).
This way, the goal ends up in a form using less monadic indirection:

13
avg (map (monoid expec (count (i, j )) ffi (*pi )

let pivot := nth li pi inlet rest := remove li pi in

let flt := *c ) filter ((= c) ffi lookup cmp pivot) rest inne tree

.map (map fst (++map (unordered nat pair pivot) rest)) (lower  qs

U (flt Lt);upper  qs

U (flt Gt);ret (lower ++ pivot :: flt Eq ++ upper)

))) [0 ... n - 1]) 6 ecc i j .
Here, map fst applies a function to a pair's first component.We now distinguish between five different cases that can occur for the nondeterministically picked pivot (which, because we are in the U monad, is anindex). It can either be less than i, equal to i, between i and j , equal to j , or
greater than j . Each case occurs a certain number of times, and has an asso-ciated expected number of (i

, j ) comparisons (coming either from the map fstterm representing the partition pass, or from the two recursive qs

U calls). Torepresent this split, we first rewrite the right-hand side of the inequality to

ecc i j * (i - b) + 1 + 0 + 1 + ecc i j * (b + n - j)

n .
This form reflects the facts that

- the case where pivot is less than i occurs i - b times, and in each instance,the expected number of (i

, j ) comparisons is no more than ecc i j ;- the case where the pivot is equal to i occurs once, and in this case no more

than a single (i, j ) comparison is expected;- in the case where pivot lies between i and j , the number of expected (i

, j )comparisons is 0, and hence it does not matter how often this case occurs;

- the case where the pivot is equal to j occurs once, and in this case no morethan a single (i

, j ) comparison is expected;- the case where the pivot is greater than j occurs b + n - j times, and in each

instance, the expected number of (i, j ) comparisons is no more than ecc i j .
With the right-hand side of the inequality in this form, we unfold the avg appli-cation on the left into sum (

...) / n, and then cancel the division by n on bothsides. Next, to actually realize the split, we apply a specialized lemma stating

that8

b i j X f n (li : list N)(g : [0

... n - 1] ! U X ), Permutation [b ... b + length li - 1] li !b 6 i
< j < b + S n ! 8 ca cb, 0 6 ca ! 0 6 cb !(8 pi
, nth li pi < i ! expec f (g pi) 6 ca) !(8 pi
, nth li pi = i ! expec f (g pi) 6 cb) !(8 pi
, i < nth li pi < j ! expec f (g pi ) = 0) !(8 pi
, nth li pi = j ! expec f (g pi ) 6 cb) !(8 pi
, j < nth li pi ! expec f (g pi ) 6 ca) !sum (map (expec f ffi g) [0

. . n ]) 6ca * (i - b) + cb + 0 + cb + ca * (b + n - j )

.

14
Five subgoals remain after applying this lemma--one for each listed case. Thefirst one reads

8 pi ,let pivot := nth li pi in

let rest := remove li pi inpivot

< i !monoid expec (count (i

, j ))(ne tree
.map (map fst (++map (unordered nat pair pivot) rest)) (foo  qs

U (filter ((= Lt) ffi lookup cmp pivot) rest);bar  qs

U (filter ((= Gt) ffi lookup cmp pivot) rest);ret (foo ++ (pivot :: filter ((= Gt) ffi lookup cmp pivot) rest) ++ bar)))

6 ecc i j .
Since count (i, j ) is a monoid homomorphism, we may rewrite using anotherlemma saying that

8 (m : Monoid) (h : m ! (N, 0, +)), monoid homo h !8 (g : m) (A : Set) (t : MMT m

Mne tree A),monoid expec h (ne tree
.map (map fst (monoid mult m g)) t) =h g + monoid expec h t
.

This leaves

count (i, j ) (map (unordered nat pair pivot) rest) +monoid expec (count (i

, j ))(foo  qs

U (filter ((= Lt) ffi lookup cmp pivot) rest);bar  qs
U (filter ((= Gt) ffi lookup cmp pivot) rest);ret (foo ++ (nth v pi :: filter ((= Eq) ffi lookup cmp pivot) rest) ++ bar))

6 ecc i j .
From pivot < i and i < j , we have pivot < j . Since each of the comparisons inmap (unordered nat pair pivot) rest involves the pivot element, it follows that

none of them can represent comparisons between i and j . Hence, the first termvanishes. Furthermore, monoid expec plus lets us distribute monoid expec over
the bind applications. Since the ret term does not produce any comparisonseither (by definition), its monoid expec term vanishes, too. What remains are
the two recursive calls:

monoid expec (count (i, j )) (qsU (filter ((= Lt) ffi lookup cmp pivot) rest)) +monoid expec (count (i

, j )) (qsU (filter ((= Gt) ffi lookup cmp pivot) rest))6 ecc i j
.

All indices in the first filtered list denote elements less than the element denotedby the pivot. Since the former precede the latter in sort l, it must be the case

that these indices are all less than pivot. And since pivot < i, it follows that thefirst qs

U term will produce no (i, j ) comparisons (using property (2) at the endof section 5 on page 12). Hence, the first monoid expec term vanishes, leaving

15
monoid expec (count (i, j ))(qs

U (filter ((= Gt) ffi lookup cmp pivot) rest)) 6 ecc i j .

We now compare nth (sort l ) i with nth (sort l ) pivot.

- If the two are equal, then i will not occur in the filter term, and so (again)no (i

, j ) comparisons are performed.
- If nth (sort l ) i<nth (sort l ) pivot, then we must have i<pivot, contradictingthe assumption that pivot

< i.
- If nth (sort l ) i > nth (sort l ) pivot, then we apply the induction hypothesis.For this, it must be shown that filtering the list of indices preserves contiguity,

which follows from the fact that the indices share the order of the elementsthey denote in sort l .

This concludes the case where pivot < i. The case where j < pivot is symmetric.The other three cases use similar arguments. The proof is now complete.

7 Final Remarks
In the interest of brevity, we have omitted lots of detail and various lemmas inthe description of the proof. Still, the parts shown are reasonably faithful to the
actual formalisation, with two notable exceptions.First, we have pretended to have used ordinary natural numbers as indices
into ordinary lists, completely ignoring issues of index validity that could not beignored in the actual formalisation. There, we use vectors (lists whose size is part
of their type) and bounded natural numbers in many places instead. Using thesesubstantially reduces the amount of i

<length l proofs that need to be produced,converted, and passed around, but this solution is still far from painless.

Second, using the Program facility to deal with Quicksort's non-structuralrecursion is not completely as trivial as we made it out to be. Since the recursive calls are nested in lambda abstractions passed to the bind operation ofan unspecified monad, the relation between their arguments and the function's
parameters is not locally known, resulting in unprovable proof obligations. Tomake these provable, we

\Sigma -decorated the types of filter and partition in theactual formalisation with modest length guarantees.

The formalised development successfully adopted from the original proof theidea of using a nondeterministic version of the algorithm to make the

O(n log n)bound hold for any input list, the idea of taking an order-indexed perspective

to reduce the problem to a sum-of-expected-comparison-counts, and the use ofthe standard bound for harmonic series for the strictly numerical part. However, for the actual reduction and the derivation of the formula for the expectedcomparison count, the intuitive arguments essentially had to be reworked from
scratch, building on the monadic representation of the algorithm and the variouscomparison counting/nondeterminism monads.

The shallow monadic embedding provides a simple but effective representa-tion of the algorithm. Being parameterized on the monad used, it allows a single

16
definition to be instantiated either with basic monads (like the identity monador bare nondeterminism monads) to get a non-instrumented version suitable for
extraction and correctness proofs, or with MMT -transformed monads to supportcomplexity proofs. Furthermore, since this approach lets us re-use all standard
Coq data types and facilities, including the powerful Program Fixpoint com-mand, the actual algorithm definition itself is reasonably clean.

We have shown that it is straightforward to give a fully formal treatmentin type theory of a classical result in complexity theory. This clearly shows the
utility and applicability of the general monadic approach we have developed.

References

1. Hoare, C.: Quicksort. The Computer Journal 5 (1962) 10-15
2. The Coq Development Team: The Coq Proof Assistant Reference Manual - Version

V8.2. (February 2009) http://coq.inria.fr.
3. Bertot, Y., Cast'eran, P.: Coq'Art: Interactive Theorem Proving and Program

Development. Texts in Theoretical Computer Science. Springer (2004)
4. Constable, R.L.: Expressing computational complexity in constructive type theory.

In Leivant, D., ed.: LCC '94. Volume 960 of LNCS., Springer (1995) 131-144
5. Wadler, P.: Monads for functional programming. In Jeuring, J., Meijer, E., eds.:

Advanced Functional Programming. Volume 925 of LNCS., Springer (1995) 24-52
6. Sedgewick, R.: The analysis of quicksort programs. Acta Inf. 7 (1977) 327-355
7. Sozeau, M.: Subset coercions in Coq. In Altenkirch, T., McBride, C., eds.: Types

for Proofs and Programs. Volume 4502 of LNCS. Springer (2007) 237-252
8. Liang, S., Hudak, P., Jones, M.P.: Monad transformers and modular interpreters.

In: POPL '95, ACM (1995) 333-343
9. Cormen, T., Leiserson, C., Rivest, R., Stein, C.: Introduction to Algorithms, Second Edition. MIT Press (September 2001)
10. Schellekens, M.: A Modular Calculus for the Average Cost of Data Structuring.

Springer (2008)
11. Audebaud, P., Paulin-Mohring, C.: Proofs of Randomized Algorithms in Coq. In

Uustalu, T., ed.: MPC'06. Volume 4014 of LNCS., Springer (2006) 49-68
12. Hurd, J.: Formal Verification of Probabilistic Algorithms. PhD thesis, University

of Cambridge (2002)