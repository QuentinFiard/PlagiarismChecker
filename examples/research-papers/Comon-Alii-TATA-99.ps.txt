

Tree
Automata
Techniques and
Applications

Hubert Comon Max Dauchet
R'emi Gilleron Denis Lugiez
Sophie Tison Marc Tommasi

Contents
Introduction 7
Preliminaries 11
1 Recognizable Tree Languages and Finite Tree Automata 13

1.1 Finite Tree Automata . . . . . . . . . . . . . . . . . . . . . . . . 14
1.2 The pumping Lemma for Recognizable Tree Languages . . . . . . 22
1.3 Closure Properties of Recognizable Tree Languages . . . . . . . . 23
1.4 Tree homomorphisms . . . . . . . . . . . . . . . . . . . . . . . . . 25
1.5 Minimizing Tree Automata . . . . . . . . . . . . . . . . . . . . . 29
1.6 Top Down Tree Automata . . . . . . . . . . . . . . . . . . . . . . 31
1.7 Decision problems and their complexity . . . . . . . . . . . . . . 32
1.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
1.9 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . 38

2 Regular grammars and regular expressions 41

2.1 Tree Grammar . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

2.1.1 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.1.2 Regular tree grammar and recognizable tree languages . . 44
2.2 Regular expressions. Kleene's theorem for tree languages. . . . . 44

2.2.1 Substitution and iteration . . . . . . . . . . . . . . . . . . 45
2.2.2 Regular expressions and regular tree languages. . . . . . . 47
2.3 Regular equations. . . . . . . . . . . . . . . . . . . . . . . . . . . 50
2.4 Context-free word languages and regular tree languages . . . . . 52
2.5 Beyond regular tree languages: context-free tree languages . . . . 55

2.5.1 Context-free tree languages . . . . . . . . . . . . . . . . . 55
2.5.2 IO and OI tree grammars . . . . . . . . . . . . . . . . . . 56
2.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
2.7 Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . . 58

3 Automata and n-ary relations 59

3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
3.2 Automata on tuples of finite trees . . . . . . . . . . . . . . . . . . 61

3.2.1 Three notions of recognizability . . . . . . . . . . . . . . . 61
3.2.2 Examples of the three notions of recognizability . . . . . . 63
3.2.3 Comparisons between the three classes . . . . . . . . . . . 65
3.2.4 Closure properties for Rec\Theta  and Rec; cylindrification and

projection . . . . . . . . . . . . . . . . . . . . . . . . . . . 66

4 CONTENTS

3.2.5 Closure of GTT by composition and iteration . . . . . . . 68
3.3 The logic WSkS . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72

3.3.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
3.3.2 Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
3.3.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
3.3.4 Restricting the syntax . . . . . . . . . . . . . . . . . . . . 74
3.3.5 Definable sets are recognizable sets . . . . . . . . . . . . . 75
3.3.6 Recognizable sets are definable . . . . . . . . . . . . . . . 78
3.3.7 Complexity issues . . . . . . . . . . . . . . . . . . . . . . 79
3.3.8 Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . 79
3.4 Examples of applications . . . . . . . . . . . . . . . . . . . . . . . 80

3.4.1 Terms and sorts . . . . . . . . . . . . . . . . . . . . . . . 80
3.4.2 The encompassment theory for linear terms . . . . . . . . 81
3.4.3 The first-order theory of a reduction relation: the case

where no variables are shared . . . . . . . . . . . . . . . . 83
3.4.4 Reduction strategies . . . . . . . . . . . . . . . . . . . . . 84
3.4.5 Application to higher-order matching . . . . . . . . . . . 86
3.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
3.6 Bibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . . . . 92

3.6.1 Automata and Logic . . . . . . . . . . . . . . . . . . . . . 92
3.6.2 Surveys . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
3.6.3 ???? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92

4 Automata with constraints 95

4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
4.2 Automata with equality and disequality constraints . . . . . . . . 96

4.2.1 The most general class . . . . . . . . . . . . . . . . . . . . 96
4.2.2 Reducing non-determinism and closure properties . . . . . 99
4.2.3 Undecidability of emptiness . . . . . . . . . . . . . . . . . 101
4.3 Automata with constraints between brothers . . . . . . . . . . . 102

4.3.1 Closure properties . . . . . . . . . . . . . . . . . . . . . . 104
4.3.2 Emptiness decision . . . . . . . . . . . . . . . . . . . . . . 104
4.3.3 Applications . . . . . . . . . . . . . . . . . . . . . . . . . 107
4.4 Reduction automata . . . . . . . . . . . . . . . . . . . . . . . . . 108

4.4.1 Definition and closure properties . . . . . . . . . . . . . . 108
4.4.2 Emptiness decision . . . . . . . . . . . . . . . . . . . . . . 109
4.4.3 Other decidable questions . . . . . . . . . . . . . . . . . . 111
4.4.4 Complexity issues and restricted classes . . . . . . . . . . 111
4.4.5 Application to the encompassment theory . . . . . . . . . 111
4.5 Tree Automata with Arithmetic Constraints . . . . . . . . . . . . 111

4.5.1 Flat Trees . . . . . . . . . . . . . . . . . . . . . . . . . . 112
4.5.2 Automata with Arithmetic Constraints . . . . . . . . . . 113
4.5.3 Reducing non-determinism . . . . . . . . . . . . . . . . . 115
4.5.4 Closure Properties of Semi linear Flat Languages . . . . . 116
4.5.5 Decision of Emptiness . . . . . . . . . . . . . . . . . . . . 117
4.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
4.7 Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . . 123

CONTENTS 5
5 Tree Set Automata 125

5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
5.2 Definitions and examples . . . . . . . . . . . . . . . . . . . . . . . 130

5.2.1 Generalized tree sets . . . . . . . . . . . . . . . . . . . . . 130
5.2.2 Tree Set Automata . . . . . . . . . . . . . . . . . . . . . . 130
5.2.3 Hierarchy of GTSA-recognizable languages . . . . . . . . 133
5.2.4 Regular generalized tree sets, regular runs . . . . . . . . . 134
5.3 Closure and decision properties . . . . . . . . . . . . . . . . . . . 137

5.3.1 Closure properties . . . . . . . . . . . . . . . . . . . . . . 137
5.3.2 Emptiness property . . . . . . . . . . . . . . . . . . . . . 140
5.3.3 Other decision results . . . . . . . . . . . . . . . . . . . . 141
5.4 Applications to set constraints . . . . . . . . . . . . . . . . . . . 142

5.4.1 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . 142
5.4.2 Set constraints and automata . . . . . . . . . . . . . . . . 143
5.4.3 Decidability results for set constraints . . . . . . . . . . . 144
5.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
5.6 Bibliographical notes . . . . . . . . . . . . . . . . . . . . . . . . . 146

6 Tree transducers 149

6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
6.2 The word case . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149

6.2.1 Introduction to rational transducers . . . . . . . . . . . . 149
6.2.2 The homomorphic approach . . . . . . . . . . . . . . . . . 153
6.3 Introduction to tree transducers . . . . . . . . . . . . . . . . . . . 155
6.4 Properties of tree transducers . . . . . . . . . . . . . . . . . . . . 159

6.4.1 Bottom-up tree transducers . . . . . . . . . . . . . . . . . 159
6.4.2 Top-down tree transducers . . . . . . . . . . . . . . . . . 162
6.4.3 Main properties . . . . . . . . . . . . . . . . . . . . . . . . 164
6.5 Homomorphisms and tree transducers . . . . . . . . . . . . . . . 165
6.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
6.7 Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . . 169

6 CONTENTS

Introduction
During the past few years, several of us have been asked many times about references on finite tree automata. On one hand, this is the witness of the liveness of
this field. On the other hand, it was difficult to answer. Besides several excellent
survey chapters on more specific topics, there is only one monograph devoted
to tree automata by G'ecseg and Steinby. Unfortunately, it is now impossible
to find a copy of it and a lot of work has been done on tree automata since
the publication of this book. Actually using tree automata has proved to be a
powerful approach to simplify and extend previously known results, and also to
find new results. For instance recent works use tree automata for application
in abstract interpretation using set constraints, rewriting, automated theorem
proving and program verification.

Tree automata have been designed a long time ago in the context of circuit
verification. Many famous researchers contributed to this school which was
headed by A. Church in the late 50's and the early 60's: B. Trakhtenbrot,
J.R. B"uchi, M.O. Rabin, Doner, Thatcher, etc. Many new ideas came out of
this program. For instance the connections between automata and logic. Tree
automata also appeared first in this framework, following the work of Doner,
Thatcher and Wright. In the 70's many new results were established concerning
tree automata, which lose a bit their connections with the applications and were
studied for their own. In particular, a problem was the very high complexity
of decision procedures for the monadic second order logic. Applications of tree
automata to program verification revived in the 80's, after the relative failure
of automated deduction in this field. It is possible to verify temporal logic
formulas (which are particular Monadic Second Order Formulas) on simpler
(small) programs. Automata, and in particular tree automata, also appeared
as an approximation of programs on which fully automated tools can be used.
New results were obtained connecting properties of programs or type systems
or rewrite systems with automata.

Our goal is to fill in the existing gap and to provide a textbook which presents
the basics of tree automata and several variants of tree automata which have
been devised for applications in the aforementioned domains. We shall discuss
only finite tree automata, and the reader interested in infinite trees should consult any recent survey on automata on infinite objects and their applications
(See the bibliography). The second main restriction that we have is to focus on
the operational aspects of tree automata. This book should appeal the reader
who wants to have a simple presentation of the basics of tree automata, and
to see how some variations on the idea of tree automata have provided a nice
tool for solving difficult problems. Therefore, specialists of the domain probably
know almost all the material embedded. However, we think that this book can

8 Introduction

be helpful for many researchers who need some knowledge on tree automata.
This is typically the case of PhD a student who may find new ideas and guess
connections with his (her) own work.

Again, we recall that there is no presentation nor discussion of tree automata
for infinite trees. This domain is also in full development mainly due to applications in program verification and several surveys on this topic do exist. We
have tried to present a tool and the algorithms devised for this tool. Therefore,
most of the proofs that we give are constructive and we have tried to give as
many complexity results as possible. We don't claim to present an exhaustive
description of all possible finite tree automata already presented in the literature
and we did some choices in the existing menagerie of tree automata. Although
some works are not described thoroughly (but they are usually described in exercises), we think that the content of this book gives a good flavor of what can
be done with the simple ideas supporting tree automata.

This book is an open work and we want it to be as interactive as possible.
Readers and specialists are invited to provide suggestions and improvements.
Submissions of contributions to new chapters and improvements of existing ones
are welcome.

Among some of our choices, let us mention that we have not defined any
precise language for describing algorithms which are given in some pseudo algorithmic language. Also, there is no citation in the text, but each chapter ends
with a section devoted to bibliographical notes where credits are made to the
relevant authors. Exercises are also presented at the end of each chapter.

Tree Automata and Their Applications is composed of six main chapters
(numbered 1- 6). The first one presents tree automata and defines recognizable
tree languages. The reader will find the classical algorithms and the classical
closure properties of the class of recognizable tree languages. Complexity results are given when they are available. The second chapter gives alternative
presentation of recognizable tree languages which may be more relevant in some
situations. This includes regular tree grammars, regular tree expressions and
regular equations. The description of properties relating regular tree languages
and context-free word languages form the last part of this chapter. In Chapter 3, we show the deep connections between logic and automata. In particular,
we prove in full details the correspondence between finite tree automata and
the weak monadic second order logic with k successors. We also sketch several
applications in various domains.

Chapter 4 presents a basic variation of automata, more precisely automata
with equality constraints. An equality constraint restricts the application of
rules to trees where some subtrees are equal (with respect to some equality
relation). Therefore we can discriminate more easily between trees that we
want to accept and trees that we must reject. Several kinds of constraints are
described, both originating from the problem of non-linearity in trees (the same
variable may occur at different positions).

In Chapter 5 we consider automata which recognize sets of sets of terms.
Such automata appeared in the context of set constraints which themselves are
used in program analysis. The idea is to consider, for each variable or each
predicate symbol occurring in a program, the set of its possible values. The
program gives constraints that these sets must satisfy. Solving the constraints
gives an upper approximation of the values that a given variable can take. Such
an approximation can be used to detect errors at compile time: it acts exactly as

Introduction 9
a typing system which would be inferred from the program. Tree set automata
(as we call them) recognize the sets of solutions of such constraints (hence sets
of sets of trees). In this chapter we study the properties of tree set automata
and their relationship with program analysis.

Originally, automata were invented as an intermediate between function description and their implementation by a circuit. The main related problem in
the sixties was the synthesis problem: which arithmetic recursive functions can
be achieved by a circuit ? So far, we only considered tree automata which accepts sets of trees or sets of tuples of trees (Chapter 3 or sets of sets of trees
(Chapter 5). However, tree automata can also be used as a computational
device. This is the subject of Chapter 6 where we study tree transducers.

10 Introduction

Preliminaries
Signature, Terms and Contexts
A ranked alphabet is a couple (F; Arity) where F is a (finite) set and Arity is
a mapping from F into N. The arity of a symbol f 2 F is Arity(f). The set of
symbols of arity p is denoted by Fp. Elements of arity 0, 1, : : : p are respectively
called constants, unary, : : : p-ary symbols. We suppose that F contains at least
one constant. In the examples, we use parenthesis and commas for a short
declaration of symbols with arity. For instance, f(; ) is a short declaration for a
symbol f of arity 2.

Example 1. Let F = fcons(; ); nil; ag. Here cons is a binary symbol, nil and
a are constants. A term cons(a; cons(a; nil)) is also represented in a graphical
way:

a

a nil

cons
cons

Let X be a set of symbols called variables. T (F; X ) denotes the set of
terms over the ranked alphabet F and the set of variables X . It is the smallest
set defined by F0 ` T (F; X ), X ` T (F; X ) and if p * 1, f 2 Fp and t1; : : : ; tp 2
T (F; X ), then f(t1; : : : ; tp) 2 T (F; X ).

If X = ; then T (F; X ) is also written T (F). Terms in T (F) are called
ground terms. A term in T (F; X ) is linear if each variable occurs at most
once in t.

Let Xn be a set of n variables. A linear term C 2 T (F; Xn) is called a
context and the expression C[t1; : : : ; tn] for t1; : : : ; tn 2 T (F) denotes the
term in T (F) obtained from C by replacing for each i 2 f1; : : :; ng xi by ti.
We denote by Cn(F) the set of contexts over (x1; : : : ; xn) and C(F) the set of
contexts containing a single variable.

N denotes the set of natural numbers and N\Lambda  denotes the set of finite strings
over N.

A finite ordered tree t over a set of labels E is a mapping from a prefixclosed set Pos(t) ` N\Lambda  into E. Thus, a term t 2 T (F; X ) may be viewed as
a finite ordered tree, the leaves of which are labeled with variables or constant

12 Preliminaries

symbols and the internal nodes are labeled with symbols of positive arity, with
out-degree equal to the arity of the label, i.e. a term t 2 T (F; X ) can also be
defined as a partial function t : N\Lambda  ! F [ X with domain Pos(t) satisfying the
following properties:

- Pos(t) is nonempty and prefix-closed.
- For each p 2 Pos(t), if t(p) 2 Fn, then fijpi 2 Pos(t)g = f1; : : :; ng.
- For each p 2 Pos(t), if t(p) 2 X , then fijpi 2 Pos(t)g = ;.
Each element of Pos(t) is called a position. A frontier position is a
position p such that 8ff 2 N, pff 62 Pos(t). The set of frontier position is
denoted by FPos(t). Each position p in t such that t(p) 2 X is called a variable
position. The set of variable position of p is denoted by VPos(t).

A subterm tjp of a term t 2 T (F; X ) at position p is defined by the following:

- Pos(tjp) = fi j pi 2 Pos(t)g,
- 8j 2 Pos(tjp), tjp(j) = t(pj).
We denote by t[u]p the term obtained by replacing in t the subterm tjp by
u. We have Head(t) = f if and only if t(") = f, that is f is the root symbol
of t.

Functions on terms
The size of a term t, denoted by ktk and the height of t, denoted by Height(t)
are inductively defined by:

- Height(t) = 0, ktk = 0 if t 2 X ,
- Height(t) = 1, ktk = 1 if t 2 F0,
- Height(t) = 1 + max(fHeight(ti) j i 2 f1; : : : ; ngg), ktk = Pi2f1;:::;ng ktik

if Head(t) 2 Fn.
We denote by \Xi  the subterm ordering, i.e. we write t \Xi  t0 if t0 is a subterm
of t. We denote t \Lambda  t0 if t \Xi  t0 and t 6= t0. A set of terms F is said to be closed
if it is closed under the subterm ordering, i.e. 8t 2 F (t \Xi  t0 ) t0 2 F ).

A substitution (respectively a ground substitution) oe is a mapping from
X into T (F; X ) (respectively into T (F)) where there are only finitely many
variables not mapped to themselves. The domain of a substitution oe is the
subset of variables x 2 X such that oe(x) 6= x. fx1 t1; : : : ; xn tng denotes
the substitution which is the identity on X n fx1; : : : ; xng and which maps
xi 2 X on tiT (F; X ), for every index 1 ^ i ^ n. Substitutions can be extended
to T (F; X ) in such a way that:

8f 2 Fn; 8t1; : : :; tn 2 T (F; X ) oe(f(t1; : : : ; tn)) = f(oe(t1); : : : ; oe(tn)):
We confuse a substitution and its extension to T (F; X ). Substitutions will
often be used in postfix notation: toe is the result of applying oe to the term t.

Chapter 1
Recognizable Tree
Languages and Finite Tree
Automata

In this chapter, we present basic results on finite tree automata in the style
of the undergraduate textbook on finite automata by Hopcroft and Hullman
[HU79]. We suppose that the reader is familiar with finite automata. Words
over finite alphabet can be viewed as unary terms. For instance a word abb
over A = fa; bg can be viewed as a unary term t = a(b(b(]))) over the ranked
alphabet F = fa(); b(); ]g where ] is a new constant symbol. The theory of tree
automata arises as a straightforward extension of the theory of word automata
when words are viewed as unary terms.

In Section 1.1, we define bottom-up finite tree automata where "bottom-up"
has the following sense: assuming a graphical representation of trees or ground
terms with the root symbol at the top, an automaton starts its computation at
the leaves and moves upward. Recognizable tree languages are the languages
recognized by some finite tree automata. We consider the deterministic case
and the nondeterministic case and prove the equivalence. In Section 1.2, we
prove a pumping lemma for recognizable tree languages. This lemma is useful
for proving that some tree languages are not recognizable. In Section 1.3, we
prove the basic closure properties for set operations. In Section 1.4, we define
tree homomorphisms and study the closure properties under these tree transformations. In this Section appears the first difference between the word case
and the tree case. Indeed, if recognizable word languages are closed under homomorphisms, recognizable tree languages are closed only under a subclass of
tree homomorphisms: linear homomorphisms where duplication of trees is forbidden. We will see all along this textbook that non linearity is one of the main
difficulty for the tree case. In Section 1.5, we prove a Myhill-Nerode Theorem
for tree languages and the existence of a unique minimal automaton. In Section 1.6, we define top-down tree automata. A second difference appears with
the word case because it is proved that deterministic top-down tree automata
are strictly less powerful than nondeterministic ones. The last section of the
present chapter gives a list of complexity results.

14 Recognizable Tree Languages and Finite Tree Automata

1.1 Finite Tree Automata
Nondeterministic Finite Tree Automata
A finite Tree Automaton (NFTA) over F is a tuple A = (Q; F; Qf; \Delta ) where
Q is a set of (unary) states, Qf ` Q is a set of final states, and \Delta  is a set of
transition rules of the following type :

f(q1(x1); : : : ; qn(xn)) ! q(f(x1; : : : ; xn));
where n * 0, f 2 Fn, q; q1; : : : ; qn 2 Q, x1; : : : ; xn 2 X .

Tree automata over F run on ground terms over F. An automaton starts at
the leaves and moves upward, associating along a run a state with each subterm
inductively. Let us note that there is no initial state in a NFTA, but, when
n = 0, i.e. when the symbol is a constant symbol a, a transition rule is of
the form a ! q(a). Therefore, the transition rules for the constant symbols
can be considered as the "initial" rules. If the direct subterms u1; : : : ; un of
t = f(u1; : : : ; un) are labeled with states q1; : : : ; qn, then the term t will be
labeled by some state q with f(q1(x1); : : : ; qn(xn)) ! q(f(x1; : : : ; xn)) 2 \Delta .
We now formally define the move relation defined by an NFTA.

Let A = (Q; F; Qf; \Delta ) be an NFTA over F. The move relation !A is
defined by: let t, t0 2 T (F [ Q),

t !A t0 , 8???!???:

9C 2 C(F [ Q); 9u1; : : : ; un 2 T (F);
9f(q1(x1); : : : ; qn(xn)) ! q(f(x1; : : : ; xn)) 2 \Delta ;
t = C[f(q1(u1); : : : ; qn(un))];
t0 = C[q(f(u1; : : : ; un))]:

\Lambda \Gamma !
A is the reflexive and transitive closure of !A.

Example 2. Let F = ff(; ); g(); ag. Consider the automaton A = (Q; F; Qf; \Delta )
defined by: Q = fqa; qg; qf g, Qf = fqf g, and \Delta  is the following set of transition
rules:

f a ! qa(a) g(qa(x)) ! qg(g(x))

g(qg(x)) ! qg(g(x)) f(qg(x); qg(y)) ! qf (f(x; y)) g

We give two examples of reductions with the move relation !A

a a

f

!A

a
qa a

f

!A

a
qa

a
qa
f

1.1 Finite Tree Automata 15

a
g

a
g
f

\Lambda \Gamma !
A

a
qa

g

a
qa

g
f

\Lambda \Gamma !
A

a
g
qg

a
g
qg
f

!A

a
g

a
g
f
qf

A ground term t in T (F) is accepted by a finite tree automaton A =
(Q; F; Qf; \Delta ) if

t \Lambda \Gamma !A q(t)

for some state q in Qf . The reader should note that our definition corresponds
to the notion of nondeterministic finite tree automaton because our finite tree
automaton model allows zero, one or more transition rules with the same lefthand side. Therefore there are possibly more than one reduction starting with
the same ground term. And, a ground term t is accepted if there is one reduction
(among all possible reductions) starting from this ground term and leading to a
configuration of the form q(t) where q is a final state. The tree language L(A)
recognized by A is the set of all ground terms accepted by A. A set L of ground
terms is recognizable if L = L(A) for some NFTA A. The reader should also
note that when we talk about the set recognized by a finite tree automaton A
we are referring to the specific set L(A), not just any set of ground terms all of
which happen to be accepted by A. Two NFTA are said to be equivalent if
they recognize the same tree languages.

Example 3. Let F = ff(; ); g(); ag. Consider the automaton A = (Q; F; Qf; \Delta )
defined by: Q = fq; qg; qf g, Qf = fqfg, and \Delta  =

f a ! q(a) g(q(x)) ! q(g(x))

g(q(x)) ! qg(g(x)) g(qg(x)) ! qf (g(x))
f(q(x); q(y)) ! q(f(x; y)) g:

We now consider a ground term t and exhibit three different reductions of
term t w.r.t. move relation !A.

t = g(g(f(g(a); a))) \Lambda \Gamma !A g(g(f(qg(g(a)); q(a))))
t = g(g(f(g(a); a))) \Lambda \Gamma !A g(g(q(f(g(a); a)))) \Lambda \Gamma !A q(t)
t = g(g(f(g(a); a))) \Lambda \Gamma !A g(g(q(f(g(a); a)))) \Lambda \Gamma !A qf (t)

The term t is accepted by A because of the third reduction. It is easy to
prove that L(A) is the set of ground instances of g(g(x)).

The set of transition rules of a NFTA A can also be defined as a ground
rewrite system, i.e. a set of ground transition rules of the form: f(q1; : : : ; qn) !

16 Recognizable Tree Languages and Finite Tree Automata

q. A move relation !A can be defined like previously. The only difference is
that, now, we "forget" the ground subterms. And, a term t is accepted by a
NFTA A if

t \Lambda \Gamma !A q

for some final state q in Qf . Unless it is stated otherwise, we will now refer
to the definition with a set of ground transition rules. Considering a reduction
starting from a ground term t and leading to a state q with the move relation,
it is useful to remember the "history" of the reduction, i.e. to remember in
which state are reduced the ground subterms of t. For this, we will adopt the
following definitions. Let t be a ground term and A be a NFTA, a run r of A
on t is a mapping r : Pos(t) ! Q compatible with \Delta , i.e. for every position
p in Pos(t), if t(p) = f 2 Fn, r(p) = q, r(pi) = qi for each i 2 f1; : : : ; ng, then
f(q1; : : : ; qn) ! q 2 \Delta . A run r of A on t is successful if r(ffl) is a final state.
And a ground term t is accepted by a NFTA A if there is a successful run r of
A on t.

Example 4. Let F = for(; ); and(; ); not(); 0; 1g. Consider the automaton
A = (Q; F; Qf ; \Delta ) defined by: Q = fq0; q1g, Qf = fq1g, and \Delta  =

f 0 ! q0 1 ! q1

not(q0) ! q1 not(q1) ! q0
and(q0; q0) ! q0 and(q0; q1) ! q0
and(q1; q0) ! q0 and(q1; q1) ! q1

or(q0; q0) ! q0 or(q0; q1) ! q1
or(q1; q0) ! q1 or(q1; q1) ! q1 g:

A ground term over F can be viewed as a boolean formula without variable and a
run on such a ground term can be viewed as the evaluation of the corresponding
boolean formula. For instance, we give a reduction for a ground term t and the
corresponding run given as a tree

0 1

or
not

1

0
not
or
and

\Lambda \Gamma !

A q0: ; the run r:

q0 q1

q1
q0

q1

q0
q1
q1
q0

The tree language recognized by A is the set of true boolean expressions over
F.

NFTA with ffl-rules
Like in the word case, it is convenient to allow ffl-moves in the reduction of
a ground term by an automaton, i.e. the current state is changed but no new
symbol of the term is processed. This is done by introducing a new type of rules

1.1 Finite Tree Automata 17
in the set of transition rules of an automaton. A NFTA with ffl-rules is like
a NFTA except that now the set of transition rules contains ground transition
rules of the form f(q1; : : : ; qn) ! q, and ffl-rules of the form q ! q0. The ability
to make ffl-moves does not allow the NFTA to accept non recognizable sets. But
the use of NFTA with ffl-rules are useful in some constructions and simplify some
proofs.

Example 5. Let F = fcons(; ); s(); 0; nilg. Consider the automaton A =
(Q; F; Qf; \Delta ) defined by: Q = fqNat; qList; qList\Lambda g, Qf = fqListg, and \Delta  =

f 0 ! qNat s(qNat) ! qNat

nil ! qList cons(qNat; qList) ! qList\Lambda 
qList\Lambda  ! qListg:

The recognized tree language is the set of Lisp-like lists of integers. If the final
state set is Qf = fqList\Lambda g, then the recognized tree language is the set of non
empty Lisp-like lists of integers. The ffl-rule qList\Lambda  ! qList says that a non empty
list is a list. The reader should recognize the definition of an order-sorted algebra
with the sorts Nat, List, and List\Lambda  (which stands for the non empty lists), and
the inclusion List\Lambda  ` List (see Section 3.4.1).

Theorem 1 (The equivalence of NFTA's with and without ffl-rules). If
L is recognized by a NFTA with ffl-rules, then L is recognized by a NFTA without
ffl-rules.

Proof. Let A = (Q; F; Qf; \Delta ) be a NFTA with ffl-rules. Consider the subset
\Delta ffl consisting of those ffl-rules in \Delta . We denote by ffl-closure(q) the set of all
states q0 in Q such that there is a reduction of q into q0 using rules in \Delta ffl. The
computation of such a set is equivalent to the question of what vertices can be
reached from a given vertex in a directed graph. This can be done in quadratic
time. Now let us define the NFTA A0 = (Q; F; Qf; \Delta 0) where \Delta 0 is defined by:

f(q1; : : : ; qn) ! q0 2 \Delta 0 , f(q1; : : : ; qn) ! q 2 \Delta ; q0 2 ffl-closure(q):
The proof of equivalence is an easy induction on the length of reductions.
Unless it is stated otherwise, we will now consider NFTA without ffl-rules.

Deterministic Finite Tree Automata
Our definition of tree automata corresponds to the notion of nondeterministic
finite tree automata. We will now define deterministic tree automata (DFTA)
which are a special case of NFTA. It will turn out that, like in the word case, any
language recognized by a NFTA can also be recognized by a DFTA. However,
the NFTA are useful in proving theorems in tree language theory.

A tree automaton A = (Q; F; Qf; \Delta ) is deterministic (DFTA) if there is
no two rules with the same left-hand side (and no ffl-rule). Given a DFTA, there
is at most one run for every ground term, i.e. for every ground term t, there is
at most one state q such that t \Lambda \Gamma !A q. The latter property could be consider

18 Recognizable Tree Languages and Finite Tree Automata

as a definition of deterministic tree automata, but the reader should note that
it is not equivalent to the former one because the property could be satisfied
even if there are two rules with the same left-hand side if some states are not
accessible (see example 6).

It is also useful to consider tree automata such that there is at least one
run for every ground term. This leads to the following definition. A NFTA A
is complete if there is at least one rule f(q1; : : : ; qn) ! q 2 \Delta  for all n * 0,
f 2 Fn, and q1; : : : ; qn 2 Q. Let us note that for a complete DFTA there is
exactly one run for every ground term. Lastly, for practical reasons, it is usual
to consider automata in which unnecessary states are eliminated. A state q is
accessible if there exists a ground term t such that t \Lambda \Gamma !A q. A NFTA A is said

to be reduced if all its states are accessible.

Example 6.

The automaton defined in Example 3 is reduced, not complete, and it is not
deterministic because there are two rules of left-hand side g(q(x)). Let us also
note (see Example 3) that at least two runs (one is successful) can be defined
on the term g(g(f(g(a); a))).

The automaton defined in Example 4 is a complete and reduced DFTA.
Let F = fg(); ag. Consider the automaton A = (Q; F; Qf; \Delta ) defined by:
Q = fq0; q1; qg, Qf = fq0g, and \Delta  is the following set of transition rules:

f a ! q0 g(q0) ! q1

g(q1) ! q0 g(q) ! q0

g(q) ! q1g:

This automaton is not deterministic because there are two rules of left-hand
side g(q), it is not reduced because state q is not accessible. Nevertheless, one
should note that there is at most one run for every ground term t.

Let F = ff(; ); g(); ag. Consider the automaton A = (Q; F; Qf; \Delta ) defined
in Example 2 by: Q = fqa; qg; qfg, Qf = fqf g, and \Delta  is the following set of
transition rules:

f a ! qa g(qa) ! qg

g(qg) ! qg f(qg; qg) ! qf g:

This automaton is deterministic and reduced. It is not complete because, for
instance, there is no transition rule of left-hand side f(qa; qa). It is easy to define
a deterministic and complete automaton A0 recognizing the same language by
adding a "dead state". The automaton A0 = (Q0; F; Qf; \Delta 0) is defined by:
Q0 = Q [ fssg, \Delta 0 = \Delta [

f g(qf ) ! ss g(ss) ! ss

f(qa; qa) ! ss f(qa; qg) ! ss

: : : f(ss; ss) ! ss g:

It is easy to generalize the construction given in Example 6 of a complete
NFTA equivalent to a given NFTA: add a "dead state" ss and all transition
rules of right-hand side ss such that the automaton is complete. The reader

1.1 Finite Tree Automata 19
should note that this construction could be expensive because it may require
O(jFj \Theta  jQjArity(F)) new rules where Arity(F) is the maximal arity of symbols
in F. Therefore we have the following:

Theorem 2. Let L be a recognizable set of ground terms. Then there exists a
complete finite tree automaton that accepts L.

We now give an algorithm which outputs a reduced NFTA equivalent to a
given NFTA as input. The main loop of this algorithm computes the set of
accessible states.

Reduction Algorithm RED
input: NFTA A = (Q; F; Qf; \Delta )
begin

Set Marked to ; /* Marked is the set of accessible states */
repeat

Set Marked to Marked [ fqg
where

f 2 Fn, q1; : : : ; qn 2 Marked , f(q1; : : : ; qn) ! q 2 \Delta 
until no state can be added to Marked
Set Qr to Marked
Set Qrf to Qf " Marked
Set \Delta r to ff(q1; : : : ; qn) ! q 2 \Delta  j q; q1; : : : ; qn 2 Marked g
output: DFTA Ar = (Qr; F; Qrf ; \Delta r)
end

Obviously all states in the set Marked are accessible, and an easy induction
shows that all accessible states are in the set Marked . And, the NFTA Ar
accepts the tree language L(A). Consequently we have:

Theorem 3. Let L be a recognizable set of ground terms. Then there exists a
reduced finite tree automaton that accepts L.

Now, we consider the reduction of nondeterminism. Since every DFTA is
a NFTA, it is clear that the class of recognizable languages includes the class
of languages accepted by DFTA's. However it turns out that these classes are
equal. We prove that, for every NFTA, we can construct an equivalent DFTA.
The proof is similar to the proof of equivalence between DFA's and NFA's in
the word case. The proof is based on the "subset construction". Consequently,
the number of states of the equivalent DFTA can be exponential in the number
of states of the given NFTA (see Example 8). But, in practice, it often turns
out that many states are not accessible. Therefore, we will present in the proof
of the following theorem a construction of a DFTA where only the accessible
states are considered, i.e. the given algorithm outputs an equivalent and reduced
DFTA from a given NFTA as input.

Theorem 4 (The equivalence of DFTA's and NFTA's). Let L be a recognizable set of ground terms. Then there exists a DFTA that accepts L.

Proof. First, we give a theoretical construction of a DFTA equivalent to a
NFTA. Let A = (Q; F; Qf; \Delta ) be a NFTA. Define a DFTA Ad = (Qd; F; Qdf ; \Delta d),

20 Recognizable Tree Languages and Finite Tree Automata

as follows. The states of Qd are all the subsets of the state set Q of A. That is,
Qd = 2Q. We denote by s a state of Qd, i.e. s = fq1; : : : ; qng for some states
q1; : : : ; qn 2 Q. We define

f(s1; : : : ; sn) ! s 2 \Delta d
if and only if

s = fq 2 Q j 9q1 2 s1; : : : ; 9qn 2 sn; f(q1; : : : ; qn) ! q 2 \Delta g:
And Qdf is the set of all states in Qd containing a final state of A. We now give
an algorithmic construction where only the accessible states are considered.

Determinization Algorithm DET
input: NFTA A = (Q; F; Qf; \Delta )
begin

/* A state s of the equivalent DFTA is in 2Q */
Set Qd to ;; set \Delta d to ;
repeat

Set Qd to Qd [ fsg; Set \Delta d to \Delta d [ ff(s1; : : : ; sn) ! sg
where

f 2 Fn, s1; : : : ; sn 2 Qd,
s = fq 2 Q j 9q1 2 s1; : : : ; qn 2 sn; f(q1; : : : ; qn) ! q 2 \Delta g
until no rule can be added to \Delta 
Set Qdf to fs 2 Qd j s " Qf 6= ;g
output: DFTA Ad = (Qd; F; Qdf ; \Delta d)
end

It is immediate from the definition of the determinization algorithm that
Ad is a deterministic and reduced tree automaton. In order to prove that
L(A) = L(Ad), we now prove that:

(t \Lambda \Gamma \Gamma !A

d s) , (s = fq 2 Q j t

\Lambda \Gamma !
A qg):

The proof is an easy induction on the structure of terms.

ffl base case: let us consider t = a 2 F0. Then, there is only one rule a ! s

in \Delta d where s = fq 2 Q j a ! q 2 \Delta g. Consequently, the base case is
straightforward.

ffl induction step: let us consider a term t = f(t1; : : : ; tn). First, let us

suppose that t \Lambda \Gamma \Gamma !A

d f(s1; : : : ; sn) !A

d s. By induction hypothesis, we

have si = fq 2 Q j ti \Lambda \Gamma !A qg, for each i 2 f1; : : : ; ng. By construction
of the rule f(s1; : : : ; sn) ! s 2 \Delta d in the determinization algorithm, it is
immediate that s = fq 2 Q j t \Lambda \Gamma !A qg. Second, if s = fq 2 Q j t \Lambda \Gamma !A qg,

it is easy to prove that t \Lambda \Gamma \Gamma !A

d s.

1.1 Finite Tree Automata 21
Example 7. Let F = ff(; ); g(); ag. Consider the automaton A = (Q; F; Qf; \Delta )
defined in Example 3 by: Q = fq; qg; qfg, Qf = fqf g, and \Delta  =

f a ! q g(q) ! q

g(q) ! qg g(qg) ! qf
f(q; q) ! q g:

Given A as input, the determinization algorithm outputs the DFTA Ad =
(Qd; F; Qdf ; \Delta d) defined by: Qd = ffqg; fq; qgg; fq; qg; qfgg, Qdf = ffq; qg; qf gg,
and \Delta d =

f a ! fqg

g(fqg) ! fq; qgg
g(fq; qgg) ! fq; qg; qf g g
[ f f(s1; s2) ! fqg j s1; s2 2 Qd g:

We now give an example where an exponential blow-up occurs in the determinization process. This example is the same used in the word case.

Example 8. Let F = ff(); g(); ag and let n be an integer. And let us consider
the tree language

L = ft 2 T (F) j the symbol at position 1n is fg:
Let us consider the NFTA A = (Q; F; Qf; \Delta ) defined by: Q = fq; q1; : : : ; qn+1g,
Qf = fqn+1g, and \Delta  =

f a ! q f(q) ! q

g(q) ! q f(q) ! q1
g(q1) ! q2 f(q1) ! q2

: : :
g(qn) ! qn+1 f(qn) ! qn+1 g:

The NFTA A = (Q; F; Qf ; \Delta ) accepts the tree language L, and it has n +
2 states. The corresponding DFTA has 2n+1 states because the automaton
has to keep in memory the n + 1 last symbols of the input tree. Moreover
this automaton is minimal in the number of states (minimal tree automata are
defined in Section 1.5).

If a finite tree automaton is deterministic, we can replace the transition
relation \Delta  by a transition function ffi. Therefore, it is sometimes convenient to
consider a DFTA A = (Q; F; Qf ; ffi) where

ffi : [

n

Fn \Theta  Qn ! Q :

The computation of such an automaton on a term t as input tree can be viewed
as an evaluation of t on finite domain Q. Indeed, define the labeling function^
ffi : T (F) ! Q inductively by

^ffi(f(t1; : : : ; tn)) = ffi(f; ^ffi(t1); : : : ; ^ffi(tn)) :

22 Recognizable Tree Languages and Finite Tree Automata

We shall for convenience confuse ffi and ^ffi.

We now make clear the connections between our definitions and the language
theoretical definitions of tree automata and of recognizable tree languages. Indeed, the reader should note that a DFTA is just a finite F-algebra A consisting
of a finite carrier jAj = Q and a distinguished n-ary function fA : Qn ! Q for
each n-ary symbol f 2 F together with a specified subset Qf of Q. A ground
term t is accepted by A if ffi(t) = q 2 Qf where ffi is the unique F-algebra
homomorphism ffi : T (F) ! A.

Example 9. Let F = ff(; ); ag and consider the F-algebra A with jAj =
Q = Z2 = f0; 1g, fA = + where the sum is formed modulo 2, aA = 1, and let
Qf = f0g. A and Qf defines a DFTA. The recognized tree language is the set
of ground terms over F with an even number of leaves.

Since DFTA and NFTA accept the same sets of tree languages, we shall not
distinguish between them unless it becomes necessary, but shall simply refer to
both as tree automata (FTA).

1.2 The pumping Lemma for Recognizable Tree

Languages

We now give an example of a tree language which is not recognizable.

Example 10. Let F = ff(; ); g(); ag. Let us consider the tree language
L = ff(gi(a); gi(a)) j i ? 0g. Let us suppose that L is recognizable by an
automaton A having k states. Now, consider the term t = f(gk(a); gk(a)). t
belongs to L, therefore there is a successful run of A on t. As k is the cardinality
of the state set, there are two distinct positions along the first branch of the term
labeled with the same state. Therefore, one could cut the first branch between
these two positions leading to a term t0 = f(gj (a); gk(a)) with j ! k such that
a successful run of A can be defined on t0. This leads to a contradiction with
L(A) = L.

This (sketch of) proof can be generalized by proving a pumping lemma
for recognizable tree languages. This lemma is extremely useful in proving that
certain sets of ground terms are not recognizable. It is also useful for solving
decision problems like emptiness and finiteness of a recognizable tree language
(see Section 1.7).

Pumping Lemma. Let L be a recognizable set of ground terms. Then, there
exists a constant k ? 0 satisfying: for every ground term t in L such that
Height(t) ? k, there exist a context C 2 C(F), a non trivial context C0 2 C(F),
and a ground term u such that t = C[C0[u]] and, for all n * 0 C[C0

n [u]] 2 L.

Proof. Let A = (Q; F; Qf; \Delta ) be a FTA such that L = L(A) and let k = jQj
be the cardinality of the state set Q. Let us consider a ground term t in L
such that Height(t) ? k and consider a successful run r of A on t. Now let us

1.3 Closure Properties of Recognizable Tree Languages 23
consider a path in t of length strictly greater than k. As k is defined to be the
cardinality of the state set Q, there are two positions p1 ! p2 along this path
such that r(p1) = r(p2) = q for some state q. Let u be the ground subterm of t
at position p2. Let u0 be the ground subterm of t at position p1, there exists a
non trivial context C0 such that u0 = C0[u]. Now define the context C such that
t = C[C0[u]]. Consider a term C[C0

n [u]] for some integer n ? 1, a successful run

can be defined on this term. Indeed suppose that r corresponds to the reduction
t \Lambda \Gamma !A qf where qf is a final state of A, then we have:

C[C0

n[u]] \Lambda \Gamma !

A C[C

0n[q]] \Lambda \Gamma !

A C[C

0n\Gamma 1 [q]] : : : \Lambda \Gamma !

A C[q]

\Lambda \Gamma !
A qf :

The same holds when n = 0.

Example 11. Let F = ff(; ); ag. Let us consider the tree language L = ft 2
T (F) j jPos(t)j is a prime numberg. We can prove that L is not recognizable.
For all k ? 0, consider a term t in L whose height is greater than k. For all
contexts C, non trivial contexts C0, and terms u such that t = C[C0[u]], there
exists n such that C[C0

n[u]] 62 L.

?From the Pumping Lemma, it is immediate to derive the following corollary:
Corollary 1. Let A = (Q; F; Qf; \Delta ) be a FTA. Then L(A) is non empty if and
only there exists a term t in L(A) with Height(t) ^ jQj. Then L(A) is infinite
if and only if there exists a term t in L(A) with jQj ! Height(t) ^ 2 \Theta  jQj.

1.3 Closure Properties of Recognizable Tree Languages

A closure property of a class of (tree) languages is the fact that the class
is closed under a particular operation. We are interested in effective closure
properties where, given representations for languages in the class, there is an
algorithm to construct a representation for the language that results by applying
the operation to these languages. Let us note that the equivalence between
NFTA and DFTA is effective, thus we may choose the representation that suits
us best. Nevertheless, the determinization algorithm may output a DFTA whose
number of states is exponential in the number of states of the given NFTA.
For the different closure properties, we give effective constructions and we give
the properties of the resulting FTA depending on the properties of the given
FTA as input. In this section, we consider the Boolean set operations: union,
intersection, and complementation. Other operations will be studied in the next
sections. Complexity results are given in Section 1.7.

Theorem 5. The class of recognizable tree languages is closed under union,
under complementation, and under intersection.

24 Recognizable Tree Languages and Finite Tree Automata

Union
Let L1 and L2 be two recognizable tree languages. Thus there are tree automata A1 = (Q1; F; Qf1; \Delta 1) and A2 = (Q2; F; Qf2; \Delta 2) with L1 = L(A1)
and L2 = L(A2). Since we may rename states of a tree automaton, without
loss of generality, we may suppose that Q1 " Q2 = ;. Now, let us consider
the FTA A = (Q; F; Qf ; \Delta ) defined by: Q = Q1 [ Q2, Qf = Qf1 [ Qf2, and
\Delta  = \Delta 1[\Delta 2. The equality between L(A) and L(A1)[L(A2) is straightforward.
Let us note that A is nondeterministic and not complete, even if A1 and A2 are
deterministic and complete.

We now give another construction which preserves determinism. The intuitive idea is to process in parallel a term by the two automata. For this we
consider a product automaton. Let us suppose that A1 and A2 are complete.
And, let us consider the FTA A = (Q; F; Qf; \Delta ) defined by: Q = Q1 \Theta  Q2,
Qf = Qf1 \Theta  Q2 [ Q1 \Theta  Qf2, and \Delta  = \Delta 1 \Theta  \Delta 2 where

\Delta 1 \Theta  \Delta 2 = ff((q1; q01); : : : ; f(qn; q0n)) ! (q; q0) j

f(q1; : : : ; qn) ! q 2 \Delta 1 f(q01; : : : ; q0n) ! q0 2 \Delta 2g

It is easy to prove that L(A) = L(A1) [ L(A2). The reader should note that the
hypothesis that the two given tree automata are complete is crucial in the proof.
Indeed, suppose for instance that a ground term t is accepted by A1 but not by
A2. Moreover suppose that A2 is not complete and that there is no run of A2
on t, then the product automaton does not accept t because there is no run of
the product automaton on t. The reader should also note that the construction
preserves determinism, i.e. if the two given automata are deterministic, then
the product automaton is also deterministic.

Complementation
Let L be a recognizable tree language. Let A = (Q; F; Qf; \Delta ) be a complete
DFTA such that L(A) = L. Now, complement the final state set to recognize
the complement of L. That is, let Ac = (Q; F; Qcf; \Delta ) with Qcf = Q \Gamma  Qf ,
the DFTA Ac recognizes the tree language T (F) \Gamma  L. If you are given with a
NFTA, first, it is necessary to apply the determinization algorithm, and second
complement the final state set. This could lead to an exponential blow-up.

Intersection
Closure under intersection follows from closure under union and complementation because

L1 " L2 = L1 [ L2:

But if the recognizable tree languages are defined by NFTA, we have to use
the complementation construction, therefore the determinization process is used
leading to an exponential blow-up. Consequently, we now give a direct construction which does not use the determinization algorithm. Let A1 = (Q1; F; Qf1; \Delta 1)
and A2 = (Q2; F; Qf2; \Delta 2) be FTA such that L(A1) = L1 and L(A2) = L2.
And, consider the FTA A = (Q; F; Qf; \Delta ) defined by: Q = Q1 \Theta  Q2, Qf =
Qf1 \Theta  Qf2, and \Delta  = \Delta 1 \Theta  \Delta 2. A recognizes L1 " L2. Moreover the reader
should note that A is deterministic if A1 and A2 are deterministic.

1.4 Tree homomorphisms 25
1.4 Tree homomorphisms
We now consider tree transformations and study the closure properties under
these tree transformations. In this section we are interested with tree transformations preserving the structure of trees. Thus, we restrict ourselves to tree
homomorphisms. Tree homomorphisms are a generalization of homomorphisms
for words (considered as unary terms) to the case of arbitrary ranked alphabets. In the word case, it is known that the class of regular sets is closed under
homomorphisms and inverse homomorphisms. The situation is different in the
tree case because if recognizable tree languages are closed under inverse homomorphisms, they are closed only under a subclass of homomorphisms, i.e.
linear homomorphisms (duplication of terms is forbidden). First, we define tree
homomorphisms.

Let F and F0 be two sets of function symbols, possibly not disjoint. For
each n ? 0 such that F contains a symbol of arity n, we define a set of variables
Xn = fx1; : : : ; xng disjoint from F and F0.

Let hF be a mapping which, with f 2 F of arity n, associates a term
tf 2 T (F; Xn). The tree homomorphism h : T (F) ! T (F0) determined by
hF is defined as follows:

ffl h(a) = ta 2 T (F0) for each a 2 F of arity 0,
ffl h(f(t1; : : : ; tn)) = tf fx1  h(t1); : : : ; xn  h(tn)g

Example 12. Let F = fg(; ; ); a; bg and F0 = ff(; ); a; bg. Let us consider the
tree homomorphism h determined by hF defined by: hF(g) = f(x1; f(x2; x3)),
hF (a) = a and hF (b) = b. For instance, we have:

If t =

a

b b b

g a
g

, then h(t) =

a

b

b b

f
f a

f
f

This homomorphism can be used to transform ternary trees into binary trees.
Let us now consider F = fand(; ); or(; ); not(); 0; 1g and F0 = for(; ); not(); 0; 1g.
Let us consider the tree homomorphism h determined by hF defined by: hF (and) =
not(or(not(x1); not(x2)), and hF is the identity otherwise. This homomorphism
transforms a boolean formula in an equivalent boolean formula which does not
contain and.

A tree homomorphism is linear if for each f 2 F of arity n, hF (f) = tf is a
linear term of T (F; Xn). The following example shows that tree homomorphisms
do not always preserve recognizability.

26 Recognizable Tree Languages and Finite Tree Automata

Example 13. Let F = ff(); g(); ag and F0 = ff0(; ); g(); ag. Let us consider
the tree homomorphism h determined by hF defined by: hF(f) = f0(x1; x1),
hF (g) = g(x1), and hF (a) = a. h is not linear. Let L = ff(gi(a)) j i * 0g,
then L is a recognizable tree language. h(L) = ff0(gi(a); gi(a)) j i * 0g is not
recognizable (see Example 10).

Theorem 6 (Linear homomorphisms preserve recognizability). Let h be
a linear tree homomorphism and L be a recognizable tree language, then h(L) is
a recognizable tree language.

Proof. Let L be a recognizable tree language. Let A = (Q; F; Qf; \Delta ) be a
reduced DFTA such that L(A) = L. Let h be a tree homomorphism from
T (F) into T (F0) determined by a mapping hF . First, let us define a NFTA
A0 = (Q0; F0; Q0f ; \Delta 0).

Let us consider a rule r = f(q1; : : : ; qn) ! q in \Delta . Let us consider the linear
term tf = hF (f) 2 T (F0; Xn) and the set of positions Pos(tf ). We define a set
of states Qr = fqrp j p 2 Pos(tf )g, and we define a set of rules \Delta r as follows:
for all positions p in Pos(()tf )

ffl if tf (p) = g 2 F0k, then g(qrp1; : : : ; qrpk) ! qrp 2 \Delta r,
ffl if tf (p) = xi, then qi ! qrp 2 \Delta r,
ffl qrffl ! q 2 \Delta r.
The preceding construction is made for each rule in \Delta . We suppose that all the
set states Qr are disjoint and that they are disjoint from Q. Now define A0 by:

ffl Q0 = Q [ Sr2\Delta  Qr,
ffl Q0f = Qf ,
ffl \Delta 0 = Sr2\Delta  \Delta r.
Second, we have to prove that h(L) = L(A0).
h(L) ` L(A0): We prove that if t \Lambda \Gamma !A q then h(t) \Lambda \Gamma \Gamma !A0 q by induction on the

length of the reduction of ground term t 2 T (F) by automaton A.

ffl Base case. Suppose that t !A q. Then t = a 2 F0 and a ! q 2 \Delta .

Then, by definition of A0, it is easy to prove that h(a) = ta \Lambda \Gamma \Gamma !A0 q.

ffl Induction step.

Suppose that t = f(u1; : : : ; un), then h(t) = tf fx1 h(u1); : : : ; xn
h(un)g. Moreover suppose that t \Lambda \Gamma !A f(q1; : : : ; qn) !A q. By induction hypothesis, we have h(ui) \Lambda \Gamma \Gamma !A0 qi, for each i in f1; : : : ; ng. Now
by definition of A0, it is easy to prove that tf fx1q1; : : : ; xnqng.

h(L) ' L(A0). We prove that if t0 \Lambda \Gamma \Gamma !A0 q 2 Q then t0 = h(t) with t \Lambda \Gamma !A q. The

proof is by induction on the number of terms in T (F0 [Q) in the reduction
t0 \Lambda \Gamma \Gamma !A0 q 2 Q.

1.4 Tree homomorphisms 27

ffl Base case. Suppose that t0 \Lambda \Gamma \Gamma !A0 q 2 Q and no state in Q occurs

in the reduction. Then, because the state sets \Delta r are disjoint, only
rules of some \Delta r can be used in the reduction. Thus, t0 is ground and
t0 = hF (f) for some symbol f 2 F. Therefore there is some ground

term u with Head(()u) = f such that t0 = h(u) and u \Lambda \Gamma !q . This

holds because the automaton is reduced.
ffl Induction step. Suppose that

t0 \Lambda \Gamma \Gamma !A0 vfx01q1; : : : ; x0mqmg \Lambda \Gamma \Gamma !A0 q

where v is a linear term in T (F0; Xm), t0 = vfx01 u01; : : : ; x0m
u0mg, u0i \Lambda \Gamma \Gamma !A0 qi 2 Q, and no state in Q occurs in the reduction of

vfx01  q1; : : : ; x0m  qmg in q. The reader should note that different variables can be substituted by the same state. By induction
hypothesis, there are terms u1; : : : ; um in L such that u0i = h(ui)
for each i in f1; : : : ; mg. Then, because the state sets \Delta r are disjoint, only rules of some \Delta r can be used in the reduction of vfx01
q1; : : : ; x0m qmg in q. Thus, there exists some linear term tf such
that vfx01 q1; : : : ; x0m qmg = tf [x1  q1; : : : ; xn  qn] for some
symbol f 2 Fn and r = f(q1; : : : ; qn) ! q 2 \Delta . Now consider the
term f(v1; : : : ; vn), where vi = ui if xi occurs in tf and vi is some

term such that vi \Lambda \Gamma !A qi otherwise (such a vi always exists because

A is reduced). We have t0 = h(t) with t \Lambda \Gamma !A q. Note that if qi occurs
more than once, you can substitute qi by any term satisfying the
conditions. The proof does not work for the non linear case because
you have to check that different occurrences of some state qi corresponding to the same variable xj 2 Var(tf ) can only be substituted
by equal terms.

Only linear tree homomorphisms preserve recognizability. But, now we show
that arbitrary inverse homomorphisms preserve recognizability.

Theorem 7 (Inverse homomorphisms preserve recognizability). Let h
be a linear tree homomorphism and L be a recognizable tree language, then
h\Gamma 1(L) is a recognizable tree language.

Proof. Let h be a tree homomorphism from T (F) into T (F0) determined by a
mapping hF . Let A0 = (Q0; F0; Q0f ; \Delta 0) be a DFTA such that L(A0) = L. We
define a DFTA A = (Q; F; Qf; \Delta ) by Q = Q0, Qf = Q0f and \Delta  is defined by
the following:

if tf fx1q1; : : : ; xnqng \Lambda \Gamma \Gamma !A0 q then f(q1; : : : ; qn) ! q 2 \Delta :

It is obvious that \Delta  is computable. It is easy to show by induction on the
structure of ground term t that t \Lambda \Gamma !A q if and only if h(t) \Lambda \Gamma \Gamma !A0 q.

28 Recognizable Tree Languages and Finite Tree Automata

It can be proved that the class of recognizable tree languages is the smallest
class of tree languages closed by linear tree homomorphisms and inverse tree homomorphisms. Tree homomorphisms do not in general preserve recognizability,
therefore let us consider the following problem: given as instance a recognizable
tree language L and a tree homomorphism h, is the set h(L) recognizable ? To
our knowledge it is not known whether this problem is decidable. The reader
should note that if this problem is decidable, the problem whether the set of
normal forms of a rewrite system is recognizable is easily shown decidable (see
Exercises 6 and 10).

As a conclusion we consider different special types of tree homomorphisms.
These homomorphisms will be used in the next sections in order to simplify
some proofs and will be useful in Chapter 6. Let h be a tree homomorphism
determined by hF . The tree homomorphism h is said to be:

ffl ffl-free if for each symbol f 2 F, tf is not reduced to a variable.
ffl symbol to symbol if for each symbol f 2 F, Height(tf ) = 1. The reader

should note that with our definitions a symbol to symbol tree homomorphism is ffl-free. A linear symbol to symbol tree homomorphism changes
the label of the input symbol, possibly erases some subtrees and possibly
modifies order of subtrees.

ffl complete if for each symbol f 2 Fn, Var(tf ) = Xn.
ffl a delabeling if h is a complete, linear, symbol to symbol tree homomorphism. Such a delabeling only changes the label of the input symbol and
possibly order of subtrees.

ffl alphabetic if for each symbol f 2 Fn, tf = g(x1; : : : ; xn), where g 2 F0n.
As a corollary of Theorem 6, alphabetic tree homomorphisms, delabelings and
linear, symbol to symbol tree homomorphisms preserve recognizability. It is
easy to prove that for all these classes of tree homomorphisms, given h and
a FTA A such that L(A) = L as instance, a FTA for the recognizable tree
language h(L) can be constructed in linear time. The same holds for h\Gamma 1(L).

Example 14. Let F = ff(; ); g(); ag and F0 = ff0(; ); g0(); a0g. Let us consider
some tree homomorphisms h determined by different hF .

ffl hF(f) = x1, hF (g) = f0(x1; x1), and hF (a) = a0. h is not linear, not

ffl-free, and not complete.

ffl hF(f) = g0(x1), hF (g) = f0(x1; x1), and hF (a) = a0. h is a non linear

symbol to symbol tree homomorphism. h is not complete.

ffl hF(f) = f0(x2; x1), hF (g) = g0(x1), and hF (a) = a0. h is a delabeling.
ffl hF(f) = f0(x1; x2), hF (g) = g0(x1), and hF (a) = a0. h is an alphabetic

tree homomorphism.

1.5 Minimizing Tree Automata 29
1.5 Minimizing Tree Automata
In this section, we prove that, like in the word case, there exists a unique minimal
automaton in the number of states for a given recognizable tree language.

A Myhill-Nerode Theorem for Tree Languages
The Myhill-Nerode Theorem is a classical result in the theory of finite automata. This theorem gives a characterization of the recognizable sets and it
has numerous applications. A consequence of this theorem, among other consequences, is that there is essentially a unique minimum state DFA for every
recognizable language over finite alphabet. The Myhill-Nerode Theorem generalizes in a straightforward way to automata on finite trees.

An equivalence relation j on T (F) is a congruence on T (F) if for every
f 2 Fn

ui j vi 1 ^ i ^ n ) f(u1; : : : ; un) j f(v1; : : : ; vn) :

It is of finite index if there are only finitely many j-classes. Equivalently a
congruence is an equivalence relation closed under context, i.e. for all contexts
C 2 C(F), if u j v, then C[u] j C[v]. For a given tree language L, let us define
the congruence jL on T (F) by: u jL v if for all contexts C 2 C(F),

C[u] 2 L , C[v] 2 L:
We are now ready to give the Theorem:
Myhill-Nerode Theorem. The following three statements are equivalent:

(i) L is a recognizable tree language
(ii) L is the union of some equivalence classes of a congruence of finite index
(iii) the relation jL is a congruence of finite index.
Proof.

ffl (i) ) (ii) Assume that L is recognized by some complete DFTA A =

(Q; F; Qf; ffi). We consider ffi as a transition function. Let us consider
the relation jA defined on T (F) by: u jA v if ffi(u) = ffi(v). Clearly
jA is a congruence relation and it is of finite index, since the number of
equivalence classes is at most the number of states in Q. Furthermore, L
is the union of those equivalence classes that include a term u such that
ffi(u) is a final state.

ffl (ii) ) (iii) Let us denote by , the congruence of finite index. And let us

assume that u , v. By an easy induction on the structure of terms, it can
be proved that C[u] , C[v] for all contexts C 2 C(F). Now, L is the union
of some equivalence classes of ,, thus we have C[u] 2 L , C[v] 2 L. Thus
u jL v, and the equivalence class of u in , is contained in the equivalence
class of u in jL. Consequently, the index of jL is lower than the index
of , which is finite.

30 Recognizable Tree Languages and Finite Tree Automata

ffl (iii) ) (i) Let Qmin be the finite set of equivalence classes of jL. And

let us denote by [u] the equivalence class of a term u. Let the transition
function ffimin be defined by:

ffimin(f([u1]; : : : ; [un])) = [f(u1; : : : ; un)]:
The definition of ffimin is consistent because jL is a congruence. And
let Qminf = f[u] j u 2 Lg. The DFTA Amin = (Qmin; F; Qminf ; ffimin)
recognizes the tree language L.

As a corollary of the Myhill-Nerode Theorem, we can deduce an other algebraic characterization of recognizable tree languages. This characterization
is a reformulation of the definition of recognizability. A set of ground terms
L is recognizable if and only if there exist a finite F-algebra A, a F-algebra
homomorphism OE : T (F) ! A and a subset A0 of the carrier jAj of A such
that L = OE\Gamma 1(A0).

Minimization of Tree Automata
First, we prove the existence and uniqueness of the minimum DFTA for a recognizable tree language. It is a consequence of the Myhill-Nerode Theorem
because of the following result:

Corollary 2. The minimum DFTA recognizing a recognizable tree language L
is unique up to a renaming of the states and is given by Amin in the proof of
Myhill-Nerode Theorem.

Proof. Assume that L is recognized by some DFTA A = (Q; F; Qf; ffi). The
relation jA is a refinement of jL (see the proof of Myhill-Nerode Theorem).
Therefore the number of states of A is greater than or equal to the number of
states of Amin. If equality holds, A is reduced, i.e. all states are accessible,
because otherwise a state could be removed leading to a contradiction. Let q
be a state in Q and let u be such that ffi(u) = q. The state q can be identified
with the state ffimin(u). This identification is consistent and defines a one to one
correspondence between Q and Qmin.

Second, we give a minimization algorithm for finding the minimum state
DFTA equivalent to a given reduced DFTA. We confuse an equivalence relation
and the sequence of its equivalence classes.

Minimization Algorithm MIN
input: complete and reduced DFTA A = (Q; F; Qf ; ffi)
begin

Set P to fQf ; Q \Gamma  Qf g /* P is the initial equivalence relation*/
repeat

P 0 = P
/* Refine equivalence P in P 0 */
qP 0q0 if

qP q0 and

1.6 Top Down Tree Automata 31

8f 2 Fn8q1; : : : ; qi\Gamma 1; qi+1; : : : ; qn 2 Q
ffi(f(q1; : : : ; qi\Gamma 1; q; qi+1; : : : ; qn))P ffi(f(q1; : : : ; qi\Gamma 1; q0; qi+1; : : : ; qn))
until P 0 = P
Set Qmin to the set of equivalence classes of P
/* we denote by [q] the equivalence class of state q w.r.t. P */
Set ffimin to ff([q1]; : : : ; [qn]) ! [f(q1; : : : ; qn)]g
Set Qminf to f[q] j q 2 Qf g
output: DFTA Amin = (Qmin; F; Qminf ; ffimin)
end

The DFTA constructed by the algorithm MIN is the minimum state DFTA
for its tree language. Indeed, let A = (Q; F; Qf; \Delta ) the DFTA to which is
applied the algorithm and let T = L(A). It is easy to show that, when the main
loop terminates, the congruence relations P and jT are equal.

1.6 Top Down Tree Automata
Tree automata that we have defined in the previous sections are also known as
bottom-up tree automata because these automata start their computation at
the leaves of trees. In this section we define top-down tree automata. Such an
automaton starts its computation at the root in an initial state and then simultaneously works down the paths of the tree level by level. The tree automaton
accepts a tree if a run built up in this fashion can be defined. It appears that
top-down tree automata and bottom-up tree automata have the same expressive power. An important difference between bottom-up tree automata and
top-down automata appears in the question of determinism since deterministic
top-down tree automata are strictly less powerful than nondeterministic ones
and therefore are strictly less powerful that bottom-up tree automata. Intuitively, it is due to the following: tree properties specified by deterministic
top-down tree automata can depend only on path properties. We now make
precise these remarks and first, let us formally define top-down tree automata.

A nondeterministic top-down finite Tree Automaton (top-down NFTA)
over F is a tuple A = (Q; F; I; \Delta ) where Q is a set of states (states are unary
symbols), I ` Q is a set of initial states, and \Delta  is a set of rewrite rules of the
following type :

q(f(x1; : : : ; xn)) ! f(f1(x1); : : : ; fn(xn));
where n * 0, f 2 Fn, q; q1; : : : ; qn 2 Q, x1; : : : ; xn 2 X .

When n = 0, i.e. when the symbol is a constant symbol a, a transition rule
of top-down NFTA is of the form q(a) ! a. A top-down automaton starts at the
root and moves downward, associating along a run a state with each subterm
inductively. We do not define formally define the move relation !A defined by a
top-down NFTA because the definition is easily deduced from the corresponding
definition for bottom-up NFTA. The tree language L(A) recognized by A is the
set of all ground terms t for which there is an initial state q in I such that

q(t) \Lambda \Gamma !A t:

32 Recognizable Tree Languages and Finite Tree Automata

The expressive power of bottom-up and top-down tree automata is the same.
Indeed, we have the following Theorem:

Theorem 8 (The equivalence of top-down and bottom-up NFTA's). The
class of languages accepted by top-down NFTA's is exactly the class of recognizable tree languages.

Proof. The proof is left to the reader. Hint. Reverse the arrows and exchange
the sets of initial and final states.

Top-down and bottom-up tree automata have the same expressive power
because they define the same classes of tree languages. Nevertheless they do
not have the same behavior from an algorithmic point of view because nondeterminism can not be reduced in the class of top-down tree automata.

Proposition 1 (Top-down NFTA's and top-down DFTA's). A top-down
finite Tree Automaton (Q; F; I; \Delta ) is deterministic (top-down DFTA) if there
is one initial state and no two rules with the same left-hand side. Top-down
DFTA's are strictly less powerful than top-down NFTA's, i.e. there exists a
recognizable tree language which is not accepted by a top-down DFTA.

Proof. Let F = ff(; ); a; bg. And let us consider the recognizable tree language
T = ff(a; b); f(b; a)g. Now let us suppose there exists a top-down DFTA that
accepts T , the automaton should accept the term f(a; a) leading to a contradiction.

1.7 Decision problems and their complexity
In this section, we study some decision problems and their complexity. The size
of an automaton will be the size of its representation. More formally:

Definition 1. Let A = (Q; F; Qf; \Delta ) be an NFTA over F. The size of a rule
f(q1(x1); : : : ; qn(xn)) ! q(f(x1; : : : ; xn)) is arity(f) + 1. The size of A noted
kAk, is defined by:

kAk = jQj + X

f(q1(x1);::: ;qn(xn))!q(f(x1;::: ;xn))2\Delta 

(arity(f) + 2):

We will work in the frame of RAM machines, with uniform measure.
Membership
Instance A tree automaton and a ground term.
Answer "yes" if and only if the term is recognized by the automaton.

Clearly, the recognizable tree languages are recursive as a NFTA can be
viewed as an acceptance algorithm.

Theorem 9. Membership can be decided in linear time for DFTA, in polynomial time for NFTA.

Proof. In the deterministic case, an algorithm for testing membership in O(ktk+
kAk) is easy to obtain. For the nondeterministic case, the idea is similar as in the
word case: the algorithm determinizes along the computation. The complexity
of the algorithm will be in O(ktk \Theta  kAk).

1.7 Decision problems and their complexity 33
Emptiness
Instance A tree automaton

Answer "yes" if and only if the recognized language is empty.
Theorem 10. It can be decided in linear time whether the language accepted
by a finite tree automaton is empty.

Proof. The minimal height of accepted terms can be bounded by the number of
states using Corollary 1; so, as membership is decidable, emptiness is decidable.
Of course, this approach does not provide a practicable algorithm. To get an
efficient algorithm, it suffices to notice that a NFTA accepts at least one tree
if and only if there is an accessible final state: this algorithm can be viewed
as a least fix-point computation.In other words, the language recognized by
a reduced automaton is empty if and only if the set of final states is non
empty. Reducing an automaton can be done in O(jQj \Theta  kAk) by the reduction
algorithm given in Section 1.1. Actually, this algorithm can be improved by
choosing an adequate data structure in order to get a linear algorithm (see
exercise 16). This linear least fixpoint computation holds in serveral frameworks.
For example, it can be viewed as the satisfiability test of a set of propositional
Horn formulae. The reduction is easy and linear: each state q can be associated
with a propositional variable Xq and each rule r : f(q1; : : : ; qn) ! q can be
associated with a propositional Horn formula Fr = Xq . :Xq1 . \Delta  \Delta  \Delta  . :Xqn . It
is straightforward that satisfiability of fFrg [ f:Xq=q 2 Qf g is equivalent to
emptiness of the language recognized by (Q; F; Qf ; \Delta ). So, as satisfiability of a
set of propositional Horn formulae can be decided in linear time, we get a linear
algorithm for testing emptiness for NFTA.

The emptiness problem is P-complete with respect to logspace reductions,
even when restricted to deterministic tree automata. The proof can easily be
done since the problem is very close to the solvable path systems problem which
is known to be P-complete (see exercise 17).

Intersection non-emptiness
Instance A finite sequence of tree automata.

Answer "yes" if and only if there is at least one term recognized by each

automaton of the sequence.

Theorem 11. The intersection problem for tree automata is EXPTIME-complete.
Proof. By constructing the product automata for the n automata, and then
testing non-emptiness, we get an algorithm in O(kA1k \Theta  \Delta  \Delta  \Delta \Theta  kAnk). The proof
of EXPTIME-hardness is based on simulation of an alternating linear spacebounded Turing machine. Roughly speaking, with such a machine and an input
of length n can be associated polynomially n tree automata whose intersection
corresponds to the set of accepting computations on the input. It is worth
noting that the result holds for deterministic top down tree automata as well as
for deterministic bottom-up ones.

34 Recognizable Tree Languages and Finite Tree Automata

Finiteness
Instance A tree automaton
Answer "yes" if and only if the recognized language is finite.
Theorem 12. Finiteness can be decided in polynomial time.
Proof. Let us consider a NFTA A = (Q; F; Qf; \Delta ). Deciding finiteness of A is
direct by Corollary 1: it suffices to find an accepted term t s.t. jQj ! ktk ^
2 \Lambda  jQj. A more efficient way to test finiteness is to check the existence of a loop:
the language is infinite if and only if there is a loop on some state, i.e. there
exist a state q and a context C such that C[q] \Lambda \Gamma !A q. For a given q, deciding if

there is a loop on q can be done in linear time. So, finiteness can be decided in
quadratic time, more precisely in O(jQj \Theta  kAk).

Emptiness of the complement
Instance A tree automaton.
Answer "yes" if and only if every term is accepted by the automaton

Deciding whether a deterministic tree automaton recognizes the set of all
terms is polynomial for a fixed alphabet: we just have to check whether the
automaton is complete (which can be done in O(jFj \Theta  jQjArity(F))) and then it
remains only to check that all accessible states are final. For nondeterministic
automata, the following result proves in some sense that determinization with
its exponential cost is unavoidable:

Theorem 13 (Seidl [Sei90]). The problem whether a tree automaton accepts
the set of all terms is EXPTIME-complete for nondeterministic tree automata.

Proof. The proof of this theorem is once more based on simulation of linear space
bounded alternating Turing machine: indeed, the complement of the accepting
computations on an input w can be coded polynomially in a recognizable tree
langauge.

Equivalence
Instance Two tree automata
Answer "yes" if and only if the automata recognize the same language.
Theorem 14. Equivalence is decidable for tree automata.
Proof. Clearly, as the class of recognizable sets is effectively closed under complementation and intersection, and as emptiness is decidable, equivalence is
decidable. For two deterministic complete automata A1 and A2, we get by
these means an algorithm in O(kA1k \Theta  kA2k). (An other way is to compare
the minimal automata). For nondeterministic ones, this approach leads to an
exponential algorithm.

As we have proved that deciding whether an automaton recognizes the set
of all ground terms is EXPTIME-hard, we get immediately:

Corollary 3. The inclusion problem and the equivalence problem for NFTA's
are EXPTIME-complete.

1.8 Exercises 35
1.8 Exercises
Exercise 1. Let F = ff(; ); g(); ag. Define a top-down NFTA, a NFTA and a DFTA
for the set G(t) of ground instances of term t = f(f(a; x); g(y)). Is it possible to define
a top-down DFTA for this language?

Exercise 2. Let F = ff(; ); g(); ag. Define a top-down NFTA, a NFTA and a DFTA
for the set of terms which have a ground instance of term t = f(a; g(y)) as a subterm.
Is it possible to define a top-down DFTA for this language?

Exercise 3. Let F = fg(); ag. Is the set of ground terms whose height is even
recognizable? Let F = ff(; ); g(); ag. Is the set of ground terms whose height is even
recognizable?

Exercise 4. Let F = ff(; ); ag. Prove that the set L = ff(t; t) j t 2 T (F)g is
not recognizable. Let F be any ranked alphabet which contains at least one constant
symbol a and one binary symbol f(; ). Prove that the set L = ff(t; t) j t 2 T (F)g is
not recognizable.

Exercise 5. Prove the equivalence between top-down NFTA and NFTA.
Exercise 6. Let F = ff(; ); g(); ag and F0 = ff0(; ); g(); ag. Let us consider the
tree homomorphism h determined by hF defined by: hF (f) = f0(x1; x2), hF (g) =
f0(x1; x1), and hF (a) = a. Is h(T (F)) recognizable? Let L1 = fgi(a) j i * 0g, then
L1 is a recognizable tree language, is h(L1) recognizable? Let L2 be the recognizable
tree language defined by L2 = L(A) where A = (Q; F; Qf ; \Delta ) is defined by: Q =
fqa; qg; qf g, Qf = fqf g, and \Delta  is the following set of transition rules:

f a ! qa g(qa) ! qg

f(qa; qa) ! qf f(qg; qg) ! qf
f(qa; qg) ! qf f(qg; qa) ! qf
f(qa; qf ) ! qf f(qf; qa) ! qf
f(qg; qf ) ! qf f(qf ; qg) ! qf
f(qf; qf ) ! qf g:

Is h(L2) recognizable?
Exercise 7. Let F1 = for(; ); and(; ); not(); 0; 1; xg. A ground term over F can be
viewed as a boolean formula over variable x. Define a DFTA which recognizes the set
of satisfiable boolean formulae over x. Let Fn = for(; ); and(; ); not(); 0; 1; x1; : : : ; xng.
A ground term over F can be viewed as a boolean formula over variable x1; : : : ; xn.
Define a DFTA which recognizes the set of satisfiable boolean formulae over x1; : : : ; xn.

Exercise 8. Let t be a linear term in T (F; X ). Prove that the set of ground instances
of term t is recognizable. Let R be a set of linear terms in T (F; X ). Prove that the
set G(R) of ground instances of set R is recognizable.

Exercise 9. Let R be a set of linear terms in T (F; X ). We define the set Red(R) of
reducible terms for R to be the set of ground terms which have a ground instance of
some term in R as a subterm. Prove that the set Red(R) is recognizable.

Exercise 10. We consider the following two problems. First, given as instance a recognizable tree language L and a tree homomorphism h, is the set h(L) recognizable?
Second, given as instance a set R of terms in T (F; X ), is the set Red(R) recognizable? Prove that if the first problem is decidable, the second problem is easily shown
decidable.

36 Recognizable Tree Languages and Finite Tree Automata

Exercise 11. Let R be a set of linear terms in T (F; X ). A term t is inductively
reducible for R if all the ground instances of term t are reducible for R. Prove that
inductive reducibility of a linear term t for a set of linear terms R is decidable.

Exercise 12. Let F = ff(; ); a; bg.

1. Let us consider the set of ground terms L1 defined by the following two conditions:

ffl f(a; b) 2 L1,
ffl t 2 L1 ) f(a; f(t; b)) 2 L1.

Prove that the set L1 is recognizable.
2. Prove that the set L2 = ft 2 T (F) j jtja = jtjbg is not recognizable where jtja

(respectively jtjb) denotes the number of a (respectively the number of b) in t.

3. Let L be a recognizable tree language over F. Let us suppose that f is a

commutative symbol. Let C(L) be the congruence closure of set L for the set
of equations C = ff(x; y) = f(y; x)g. Prove that C(L) is recognizable.

4. Let L be a recognizable tree language over F. Let us suppose that f is a commutative and associative symbol. Let AC(L) be the congruence closure of set L
for the set of equations AC = ff(x; y) = f(y; x); f(x; f(y; z)) = f(f(x; y); z)g.
Prove that in general AC(L) is not recognizable.

5. Let L be a recognizable tree language over F. Let us suppose that f is an

associative symbol. Let A(L) be the congruence closure of set L for the set of
equations A = ff(x; f(y; z)) = f(f(x; y); z)g. Prove that in general A(L) is not
recognizable.

Exercise 13. Consider the complement problem:

ffl Instance A term t 2 T (F; X ) and terms t1; : : : ; tn,
ffl Question There is a ground instance of t which is not an instance of any ti.
Prove that the complement problem is decidable whenever term t and all terms ti are
linear. Extend the proof to handle the case where t is a term (not necessarily linear).

Exercise 14. Let F be a ranked alphabet and suppose that F contains some symbols
which are commutative and associative. The set of ground AC-instances of a term t
is the AC-congruence closure of set G(t). Prove that the set of ground AC-instances
of a linear term is recognizable. Prove that the AC-complement problem is decidable
where the AC-complement problem is defined by:

ffl Instance A linear term t 2 T (F; X ) and linear terms t1; : : : ; tn,
ffl Question There is a ground AC-instance of t which is not an AC-instance of

any ti.

Exercise 15. Let F be a ranked alphabet and X be a countable set of variables. Let
S be a rewrite system on T (F; X ) (the reader is referred to [DJ90]) and L be a set of
ground terms. We denote by S\Lambda (L) the set of reductions of terms in L by S and by
S(L) the set of ground S-normal forms of set L. Formally,

S\Lambda (L) = ft 2 T (F) j 9u 2 L u \Lambda ! tg;
S(L) = ft 2 T (F) j t 2 IRR(S) and 9u 2 L u \Lambda ! tg = IRR(S) " S\Lambda (L):
We consider the two following decision problems:
(1rst order reachability)

1.8 Exercises 37

ffl Instance A rewrite system S, two ground terms u and v,
ffl Question v 2 S\Lambda (fug).

(2nd order reachability)

ffl Instance A rewrite system S, two recognizable tree languages L and L0,
ffl Question S\Lambda (L) ` L0.

1. Let us suppose that rewrite system S satisfies:

(PreservRec) If L is recognizable, then S\Lambda (L) is recognizable.
What can be said about the two reachability decision problems? Give a sufficient condition on rewrite system S satisfying (PreservRec) such that S satisfies
(NormalFormRec) where (NormalFormRec) is defined by:

(NormalFormRec) If L is recognizable, then S(L) is recognizable.
2. Let F = ff(; ); g(); h(); ag. Let L = ff(t1; t2) j t1; t2 2 T (fg(); h(); agg, and S

is the following set of rewrite rules:

f f(g(x); h(y)) ! f(x; y) f(h(x); g(y)) ! f(x; y)

g(h(x)) ! x h(g(x)) ! x

f(a; x) ! x f(x; a) ! x g

Are the sets L, S\Lambda (L), and S(L) recognizable?
3. Let F = ff(; ); g(); h(); ag. Let L = fg(hn(a)) j n * 0g, and S is the following

set of rewrite rules:

f g(x) ! f(x; x) g
Are the sets L, S\Lambda (L), and S(L) recognizable?
4. Let us suppose now that rewrite system S is linear and monadic, i.e. all rewrite

rules are of one of the following three types:

(1) l ! a ; a 2 F0
(2) l ! x ; x 2 Var(l)
(3) l ! f(x1; : : : ; xp) ; x1; : : : ; xp 2 Var(l); f 2 Fp

where l is a linear term (no variable occurs more than once in t) whose height
is greater than 1. Prove that a linear and monadic rewrite system satisfies
(PreservRec). Prove that (PreservRec) is false if the right-hand side of rules of
type (3) may be non linear.

Exercise 16. Design a linear algorithm for testing emptiness of the language recognized by a tree automaton:

Instance A tree automaton
Answer "yes" if and only if the language recognized is empty.

Hint: Choose a suitable data structure for the automaton. For example, a state
could be associated with the list of the "adresses" of the rules whose left-hand side
contain it (eventually, a rule can be repeated); each rule could be just represented by
a counter initialized at the arity of the corresponding symbol and by the state of the
right-hand side. Activating a state will decrement the counters of the corresponding
rules. When the counter of a rule becomes null, the rule can be applied: the right-hand
side state can be activated.

Exercise 17.

The Solvable Path Problem is the following:

38 Recognizable Tree Languages and Finite Tree Automata

Instance a finite set X and three sets R ae X \Theta  X \Theta  X; Xs ae X and Xt ae X.
Answer "yes" if and only if Xt " A is non empty, where A is the least subset A of X

such that Xs ae A and if y; z 2 A and (x; y; z) 2 R, then x 2 A.

Prove that this P \Gamma  complete problem is log-space reducible to the emptiness
problem for tree automata.

1.9 Bibliographic Notes
Tree automata were introduced by Doner [Don65, Don70] and Thatcher and
Wright [TW65, TW68]. Their goal was to prove the decidability of the weak
second order theory of multiple successors. The original definitions are based
on the algebraic approach and involve heavy use of universal algebra and/or
category theory.

Many of the basic results presented in this chapter are the straightforward
generalization of the corresponding results for finite automata. It is difficult to
attribute a particular result to any one paper. Thus, we only give a list of some
important contributions consisting of the above mentioned papers of Doner,
Thatcher and Wright and also Eilenberg and Wright [EW67], Thatcher [Tha70],
Brainerd [Bra68, Bra69], Arbib and Give'on [AG68]. All the results of this
chapter and a more complete and detailed list of references can be found in the
textbook of G'ecseg and Steinby [GS84] and also in their recent survey [GS96].
For an overview of the notion of recognizability in general algebraic structures
see Courcelle [Cou89] and the fundamental paper of Mezei and Wright [MW67].
In Nivat and Podelski [NP89] and [Pod92], the theory of recognizable tree languages is reduced to the theory of recognizable sets in an infinitely generated
free monoid.

The results of Sections 1.1, 1.2, and 1.3 were noted in many of the papers
mentioned above, but, in this textbook, we present these results in the style of
the undergraduate textbook on finite automata by Hopcroft and Ullman [HU79].
Tree homomorphisms were defined as a special case of tree transducers, see
Thatcher [Tha73]. The reader is referred to the bibliographic notes in Chapter
6 of the present textbook for detailed references. The reader should note that
our proof of preservation of recognizability by tree homomorphisms and inverse
tree homomorphisms is a direct construction using FTA. A more classical proof
can be found in [GS84] and uses regular tree grammars (see chapter 2).

Minimal tree recognizers and Nerode's congruence appear in Brainerd [Bra68,
Bra69], Arbib and Give'on [AG68], and Eilenberg and Wright [EW67]. The
proof we presented here is by Kozen [Koz92] (see also F"ul"op and V'agv"olgyi
[FV89]). Top-down tree automata were first defined by Rabin [Rab69]. The
reader is referred to [GS84] and [GS96] for more references and for the study
of some subclasses of recognizable tree languages such as the tree languages
recognized by deterministic top-down tree automata.

Some results of sections 1.7 are "folklore" results. Many interesting results
concerning complexity and tree automata can be found in Seidl [Sei89], [Sei90].
The EXPTIME-hardness of the problem of intersection non-emptiness is often
used; this problem is close to problems of type inference and an idea of the proof
can be found in [FSVY91]. A proof for deterministic top-down automata can
be found in [Sei94b]. A detailed proof in the deterministic bottum-up case as

1.9 Bibliographic Notes 39
well as some other results about complexity and tree automata can be found
in [Vea97a], [Vea97b].

Recently, applications of tree automata theory to automatic deduction and
to the theory of rewriting systems were studied. Numerous exercises of the
present section introduce these applications. These applications are studied in
more details in Section 3.4. Most of the recent results about tree automata
and rewrite systems are collected in Gilleron and Tison [GT95]. Let S be a
term rewrite system (see for example Dershowitz and Jouannaud [DJ90] for
a survey on rewrite systems), If S is left-linear the set IRR(S) of irreducible
ground terms w.r.t. S is a recognizable tree language. This result first appears
in Gallier and Book [GB85] and is the subject of Exercise 9. However not
every recognizable tree language is the set of irreducible terms w.r.t. a rewrite
system S (see F"ul"op and V'agv"olgyi [FV88]). It was proved that the problem
whether, given a rewrite system S as instance, the set of irreducible terms is
recognizable is decidable (Kucherov [Kuc91]). The problem of preservation of
regularity by tree homomorphisms is not known decidable. Exercise 10 shows
that this problem is stronger than the previous one.

The notion of inductive reducibility (or ground reducibility) was introduced
in automatic deduction. A term t is S-inductively (or S-ground) reducible for
S if all the ground instances of term t are reducible for S. Inductive reducibility
is decidable for linear term t and left-linear rewrite system S. This is Exercise 11, see also Section 3.4.2. Inductive reducibility is decidable for finite S
(see Plaisted [Pla85]). Complement problems are also introduced in automatic
deduction. They are the subject of exercises 13 and 14. The complement problem for linear terms was proved decidable by Lassez and Marriott [LM87] and
the AC-complement problem by Lugiez and Moysset [LM94].

The reachability problem is defined in Exercise 15. It is well known that this
problem is undecidable in general. It is decidable for rewrite systems preserving
recognizability, i.e. such that for every recognizable tree language L, the set
of reductions of terms in L by S is recognizable. This is true for linear and
monadic rewrite systems (right-hand sides have depth less than 1). This result
was obtained by K. Salomaa [Sal88] and is the matter of Exercise 15. This is
true also for linear and semi-monadic (variables in the right-hand sides have
depth at most 1) rewrite systems, Coquid'e et al. [CDGV94]. Other interesting
results can be found in [Jac96].

Chapter 2
Regular grammars and
regular expressions

2.1 Tree Grammar
In the previous chapter, we have studied regular tree languages from the acceptor point of view, using tree automata. In this chapter we study regular
languages from the generation point of view, using tree grammars. Again, we
shall find that many properties and concepts on word languages smoothly generalize to tree language and that algebraic characterization of regular languages
do exist for tree languages. Actually, this is not surprising since tree languages
can be seen as word languages on an infinite alphabet of contexts with one hole.
We shall show also that the set of derivations of a context-free language is a
regular tree language.

2.1.1 Definitions
When we write programs, we often have to know how to produce the elements of
the data structures that we use. For instance, a definition of the lists of integers
in a functional language like ML is similar to the following definition.

N at = 0 j s(N at)
List = nil j cons(N at; List)

This definition is nothing but a tree grammar in disguise, more precisely the
set of lists of integers is the tree language generated by the grammar with axiom
List, non-terminal symbols List; N at, terminal symbols 0; s; nil; cons and rules

N at ! 0
N at ! s(N at)
List ! nil
List ! cons(N at; List)

Tree grammars are similar to word grammars except that basic objects are
trees, therefore terminals and non-terminals may have an arity greater than 0.
More precisely, a tree grammar G = (A; N; F; R) is composed of an axiom
A, a set N of non-terminal symbols with A 2 N , a set F of terminal

42 Regular grammars and regular expressions

symbols, a set R of production rules of the form ff ! fi where ff; fi are trees
of T (F [ N [ X ) where X is a set of dummy variables and ff contains at least
one non-terminal. Moreover we require that F " N = ; and that each element
of N [ F has a fixed arity and the arity of the axiom A is 0. In this chapter, we
shall concentrate on regular tree grammars where a regular tree grammar
G = (A; N; F; R) is a tree grammar where all non-terminal symbols have arity
0 and production rules have the form X ! fi, with X a non-terminal of N and
fi a tree of T (F [ N ).

Example 15. The grammar G with axiom List, non-terminals List; N at
terminals 0; nil; s(); cons(; ), rules

List ! nil
List ! cons(N at; List)
N at ! 0
N at ! s(N at)

is a regular tree grammar.

A tree grammar is used to build terms from the axiom, using the corresponding derivation relation. Basically the idea is to replace a non-terminal
X by the right-hand side ff of a rule X ! ff. More precisely, given a regular
tree grammar G = (A; N; F; R), the derivation relation ! associated to G is
a relation on pairs of terms of TF[N such that s ! t if and only if there is a
rule X ! ff 2 R, a context C such that s = C[X] and t = C[ff]. The language
generated by G, denoted by L(G), is the set of terms of TF which can be reached

by successive derivations starting from the axiom, i.e. L(G) = fs 2 TF j A +! sg
with +! the transitive closure of !.

Example 16. Let G be the grammar of the previous example, then a derivation
of cons(s(0); nil) from List is

List !G cons(N at; List) !G cons(s(N at); List) !G cons(s(N at); nil) !G cons(s(0); nil)
and the language generated by G is the set of lists of non-negative integers.

From the example, we can see that trees are generated top-down by replacing
a leaf by some other term. When X is a non-terminal of a regular tree grammar
G, we denote by LG(X) the language generated by the grammar G0 identical to
G but with X as axiom. When there is no ambiguity on the grammar referred to,
we drop the subscript G. We say that two grammars G and G0 are equivalent
when they generate the same language. Grammar can contain useless rules or
non-terminals and we want to get rid of these while preserving the generated
language. A non-terminal is reachable if there is a derivation from the axiom
containing this non-terminal. A non-terminal X is productive if LG(X) is nonempty. A regular tree grammar is reduced if and only if all its non-terminals are
reachable and productive. Given a grammar G = (A; N; F; R), we can compute
the set of reachable terminals and the set of productive terminals using the
sequences (RE)n and (P R)n which are defined in the following way.

2.1 Tree Grammar 43

P R0 = ;
P Rn = P Rn\Gamma 1

[
fX 2 N j 9(X ! ff) 2 R and each non-terminal of ff is in P Rn\Gamma 1g

and

RE0 = fAg
REn = REn\Gamma 1

[
fX 2 N j 9(X0 ! ff) 2 R such that X0 2 REn\Gamma 1 and X occurs in ffg

For each sequence, there is an index such that all elements of the sequence
with greater index are identical and this element is the set of productive (resp.
reachable) non-terminals of G. Each regular tree grammar is equivalent to a
reduced tree grammar which is computed with the following cleaning algorithm.

Computation of an equivalent reduced grammar
input: a regular tree grammar G = (A; N; F; R).

1. Compute the set of productive literals NPR using the sequence (P R)n and

let G0 = (A; N 0; F; R) where N 0 = N " NPR and R0 is the subset of R
involving rules containing only productive non-terminals.

2. Compute the set NRE of reachable terminals NRE using the sequence

(RE)n and let G00 = (A; N 0 " NRE; F; R00) where R00 is the subset of R0
involving rules containing only reachable terminals.

output: G00
The equivalence of G; G0 and G00 is straightforward. Moreover each nonterminal X of G00 must appear in a derivation A \Lambda ! C[X] \Lambda ! C[s] which proves
that G00 is reduced. The reader should notice that to exchange the two steps
of the computation may result in a grammar which is not reduced: consider G
with axiom X, non-terminals X; A; B, terminal a; f(; ) and rules X ! Z; X !
a; A ! f(A; B); B ! a).

Actually, we shall use even simpler grammars, i.e. normalized regular tree
grammar, where the production rules have the form X ! f(X1; : : : ; Xn) or
X ! a where f; a are symbols of F and X; X1; : : : ; Xn are non-terminals. The
following propositions shows that this is not a restriction.

Proposition 2. A regular tree grammar is equivalent to a normalized regular
tree grammar.

Proof. Replace a rule X ! f(s1; : : : ; sn) by X ! f(X1; : : : ; Xn) with Xi = si
if si 2 N otherwise Xi is a new non-terminal. In the last case add the rule
Xi ! si. Iterating this process one gets a equivalent grammar with rules of the
form X ! f(X1; : : : ; Xn) or X ! a or X1 ! X2. The last rules are replaced

by the rules X1 ! ff for all ff 62 N such that X1 +! Xi and Xi ! ff 2 R (these
X0is are easily computed using a transitive closure algorithm).

From now on, we assume that all grammars are normalized, unless this is
stated otherwise explicitly.

44 Regular grammars and regular expressions

2.1.2 Regular tree grammar and recognizable tree languages

Given some normalized regular tree grammar G = (A; N; F; RG), we show how
to build a tree automaton which recognizes L(G). We define A = (Q; F; Qf; \Delta )
by

ffl Q = fqX j X 2 N g
ffl Qf = fqAg
ffl qX ! f(qX1 ; : : : ; qXn) 2 \Delta  if and only if X ! f(X1; : : : ; Xn) 2 RG.
A standard proof by induction on derivation length yields L(G) = L(A). Therefore we have proved that the languages generated by regular tree grammar are
recognizable languages.

The next question to ask is whether recognizable tree languages can be
generated by regular tree grammars. If L is a regular tree language, there exists
a top-down tree automata A = (Q; F; Qf; \Delta ) such that L = L(A). We define
G = (A; N; F; RG) with A a new symbol, N = fXq j q 2 Qg, RG = fXq !
f(Xq1 ; : : : ; Xqn ) j q ! f(q1; : : : ; qn) 2 Rg [ fA ! XI j XI 2 Qf g. A standard
proof by induction on derivation length yields L(G) = L(A).

Combining these two properties, we get the equivalence between recognizable
languages and the languages generated by regular tree grammars.

Theorem 15. A tree language is recognizable if and only if it is generated by a
regular tree grammar.

2.2 Regular expressions. Kleene's theorem for

tree languages.

Going back to our example of lists of nonnegative numbers, we can write the
sets defined by the non-terminals N at and List as follows.

N at = f0; s(0); s(s(0)); : : : g
List = fnil; cons( ; nil); cons( ; cons( ; nil); : : : g

where stands for any element of N at. There is some regularity in each set
which reminds of the regularity obtained with regular word expressions constructed with the union, concatenation and iteration operators. Therefore we
can try to use the same idea to denotes the sets N at and List. However, since
we are dealing with trees and not words, we must put some information to indicate where concatenation and iteration must take place, this is done by using a
new symbol which behaves as a constant. Moreover, since we have two independent iterations, the first one for N at and the second one for List, we shall use
two different new symbols 21 and 22 and a natural extension of regular word
expression leads us to denote the sets N at and List as follows.

N at = s(21)\Lambda ;21 :21 0
List = nil + cons( (s(21)\Lambda ;21 :21 0) ; 22)\Lambda ;22 :22 nil

2.2 Regular expressions. Kleene's theorem for tree languages. 45
We are going to show that this is a general phenomenon and that we can define
a notion of regular expressions for trees and that Kleene's theorem for word can
be generalized to trees. As in the example, we must introduce a particular set
of constants K which are used to indicate the positions where concatenation
and iteration take place in trees. This explains why the syntax of regular tree
expressions is more cumbersome than the syntax of word regular expressions.
These new constants are usually denoted by 21; 22; : : : . Therefore, in this
section, we consider trees constructed on F [ K where K is a distinguished finite
set of symbols of arity 0 disjoint from F.

2.2.1 Substitution and iteration
First, we have to generalize the notion of substitution to languages, replacing some 2i by a tree of some language Li. The main difference with term
substitution is that different occurrences of the same constant 2i can be replaced by different terms of Li. Given a tree t of T (F [ K), 21; : : : ; 2n symbols of K and L1; : : : ; Ln languages of T (F [ K), we define the tree substitution (substitution for short) of 21; : : : ; 2n by L1; : : : ; Ln in t, denoted by
tf21L1; : : : ; 2nLng, by the following identities.

ffl 2if21L1; : : : ; 2nLng = Li for i = 1; : : : ; n,
ffl af21L1; : : : ; 2nLng = fag for all a 2 F [ K such that arity of a is 0

and a 6= 21; : : : ; a 6= 2n,

ffl f(s1; : : : ; sn)f21 L1; : : : ; 2n Lng = ff(t1; : : : ; tn) j ti 2 sif21 L1; : : : ; 2n

Lngg

Example 17. Let F = f0; nil; s(); cons(; )g and K = f21; 22g, let t =
cons(21; cons(21; 22)) and let
L1 = f0; s(0)g then tf21 Lgg = fcons(0; cons(0; 22)); cons(0; cons(s(0); 22));
cons(s(0); cons(0; 22)); cons(s(0); cons(s(0); 22))g

Symbols of K are mainly used to distinguish places where the substitution
must take place, and they are usually not relevant. For instance, if t is a tree
on the alphabet F [ f2g and L be a language of trees on the alphabet F, then
the trees of tf2 ! Lg don't contain the symbol 2.

The substitution operation generalizes to languages in a straightforward way.
When L; L1; : : : ; Ln are languages of T (F[K) and 21; : : : ; 2n are elements of K,
we define Lf21L1; : : : ; 2nLng as the set f tf21L1; : : : ; 2nLng j t 2
Lg.

Now, we can define the concatenation operation for tree languages. Given L
and M two languages of TF[K, and 2 be a element of K, the concatenation
of M to L through 2, denoted by L :2 M , is the set of trees obtained by
substituting the occurrence of 2 in trees of L by trees of M , i.e. L :2 M =
ftf2M g j t 2 Lg.

To define the closure of a language, we must define the sequence of successive
iterations. Given L a language of T (F [K) and 2 an element of K, the sequence
Ln;2 is defined by the equalities.

46 Regular grammars and regular expressions

ffl L0; 2 = f2g
ffl Ln+1; 2 = Ln; 2 [ Ln; 2 :2 L
The closure L\Lambda ;2 of L is the union of all Ln; 2 for nonnegative n, i.e., L\Lambda ;2 =
[nLn;2 From the definition, one gets that f2g ` L\Lambda ;2 for any L.

Example 18. Let F = f0; nil; s(); cons(; )g, let L = f0; cons(0; 2)g and
M = fnil; cons(s(0); 2)g, then

L :2 M = f0; cons(0; nil); cons(0; cons(s(0); 2))g
L\Lambda ;2 = f2g [ f0; cons(0; 2)g [ f0; cons(0; nil); cons(0; cons(s(0); 2))g [ : : :

We prove now that the substitution and concatenation operations yield regular languages when they are applied to regular languages.

Proposition 3. Let L be a regular tree language on F [ K, let L1; : : : ; Ln be
regular tree languages on F [K, let 21; : : : ; 2n 2 X, then Lf21 L1; : : : ; 2n
Lngg is a regular tree language.

Proof. Since L is regular, there exists some normalized regular tree grammar
G = (A; N; F [ K; R) such that L = L(G), and for each i = 1; : : : ; n there
exists a normalized grammar Gi = (Ai; Ni; F [ K; Ri) such that Li = L(Gi).
We can assume that the sets of non-terminals are pairwise disjoint. The idea
of the proof is to construct a grammar which starts by generating trees like
G but replaces the generation of a symbol 2i by the generation of a tree of
Li via a branching towards the axiom of Gi. More precisely, we show that
Lf21L1; : : : ; 2nLng = L(G0) where G0 = (A; N 0; F [ K; R0) such that

ffl N 0 = N [ N1 [ : : : [ Nn,
ffl R0 contains the rules of Ri and the rules of R but the rules X ! 2i which

are replaced by rule X ! Ai, where Ai is the axiom of Li.

ci ci
X ! ci X ! ci

Ai +! s Ai +! s0

2.2 Regular expressions. Kleene's theorem for tree languages. 47

A straightforward induction on the height of trees proves that G0 generates
each tree of Lf21L1; : : : ; 2nLng.

The converse is to prove that L(G0) ` Lf21 L1; : : : ; 2n Lng which is
done by induction on the derivation length. We prove by induction on the
derivation length the following property.

X +! s0 where s0 2 T (F [ K) using the rules of G0

if and only if

there is some s such that X +! s using the rules of G and

s0 2 sf21L1; : : : ; 2nLng.

ffl base case: X ! s in one step. Therefore this derivation is a derivation of

the grammar G and no 2i occurs in s, yielding s 2 Lf21L1; : : : ; 2n
Lng

ffl induction step: we assume that the property is true for any terminal

and derivation of length less than n. Let X be such that X ! s0 in n

steps. This derivation can be decomposed as X ! s1 +! s0. We distinguish
several cases depending on the rule used in the derivation X ! s1.

- the rule is X ! f(X1; : : : ; Xm), therefore s0 = f(t1; : : : ; tm) and ti 2

L(Xi)f21 L1; : : : ; 2n Lng, therefore s0 2 L(X)f21 L1; : : : ; 2n
Lng,

- the rule is X ! Ai, therefore X ! 2i 2 R and s0 2 Li and s0 2

L(X)f21L1; : : : ; 2nLng.

- the rule X ! a with a 2 F, a of arity 0, a 6= 21; : : : ; a 6= 2n are not

considered since no further derivation can be done.

The following proposition states that regular languages are stable also under
the iteration operation.

Proposition 4. Let L be a regular tree language of TF[K, let 2 2 K, then L\Lambda ;2
is a regular tree language of TF[K.

Proof. There exists a normalized regular grammar G = (A; N; F [ K; R) such
that L = L(G) and we obtain from G a grammar G0 = (A0; N [ fA0g; F [ K; R0)
for L\Lambda ;2 by replacing rules leading to 2 such as X ! 2 by rules X ! A leading
to the axiom. Moreover we add the rule A0 ! 2 to generate f2g = L0;2 and
the rule A0 ! A to generate Li;2 for i ? 0. By construction G0 generates the
elements of L\Lambda ;2.

Conversely a proof by induction on the length on the derivation proves that
L(G0) ` L\Lambda ;2.

2.2.2 Regular expressions and regular tree languages.
Now, we can define regular tree expression in the flavor of regular word expression using the +; :2;\Lambda ;2 operators.

Definition 2. The set Regexp(F; K) of regular tree expressions on F and
K is the smallest set such that:

48 Regular grammars and regular expressions

ffl the empty set ; is in Regexp(F; K)
ffl if a 2 F0 [ K is a constant, then a 2 Regexp(F; K),
ffl if f 2 Fn has arity n ? 0 and E1; : : : ; En are regular expressions of

Regexp(F; K) then f(E1; : : : ; En) is a regular expression of Regexp(F; K),

ffl if E1; E2 are regular expressions of Regexp(F; K) then (E1 + E2) is a

regular expression of Regexp(F; K),

ffl if E1; E2 are regular expressions of Regexp(F; K) and 2 is an element of

K then E1 :2 E2 is a regular expression of Regexp(F; K),

ffl if E is a regular expression of Regexp(F; K) and 2 is an element of K

then E\Lambda ;2 is a regular expression of Regexp(F; K).

Each regular expression E represents a set of terms of T (F [ K) which we
denote [[E]] and which is formally defined by the following equalities.

ffl [[;]] = ;,
ffl [[a]] = fag for a 2 F0 [ K,
ffl [[f(E1; : : : ; En)]] = ff(s1; : : : ; sn) j s1 2 [[E1]]; : : : ; sn 2 [[En]]g,
ffl [[E1 + E2]] = [[E1]] [ [[E2]],
ffl [[E1:2 E2]] = [[E1]]f2[[E2]]g,
ffl [[E\Lambda ;2]] = [[E]]\Lambda ;2

Example 19. Let F = f0; nil; s(); cons(; )g and 2 2 K then
nil +(cons(0; 2)\Lambda ;2):2nil is a regular expression of Regexp(F; K) which denotes
the set of lists of zeros fnil; cons(0; nil); cons(0; cons(0; nil)); : : :g

In the remaining of this section, we compare the relative expressive power
of regular expressions and regular languages. It is easy to prove that for each
regular expression E, the set [[E]] is a regular tree language. The proof is done
by structural induction on E. The first three cases are obvious and the two last
cases are consequences of propositions 4 and 3. The converse, i.e. a regular tree
language can be denoted by a regular expression, is more involved and requires
a similar proof than Kleene's theorem for word language. Let us state the result
first.

Proposition 5. Let A = (Q; F; QF ; \Delta ) be a bottom-up tree automaton, then
there exists a regular expression E of Regexp(F; Q) such that L(A) = [[E]].

The occurrence of symbols of Q in the regular expression denoting L(A)
doesn't cause any trouble since we have seen that a regular expression of Regexp(F; Q)
can denote a language of TF .

Proof. The proof is similar to the proof for word languages and word automata.
For each 1 ^ i; j; ^ jQj; K ` Q, we define the set T (i; j; K) as the set of trees t
of T (F [ K) such that

2.2 Regular expressions. Kleene's theorem for tree languages. 49

ffl if an element of K appears in t then it is a leaf,
ffl each leaf of t is in K or no leaf is in K,
ffl there is a run r of A such that

- r(ffl) = qi,
- for each p 2 Pos(()t) such that p is not a position of leaf nor of the

root, r(p) 2 fq1; : : : ; qjg.

Roughly speaking, a term is in T (i; j; K) if we can reach qi at the root by
using only states in fq1; : : : ; qjg when we assume that the leaves are states
of K. By definition, L(A) the language accepted by A is the union of the
T (i; jQj; ;)'s for i such that qi is a final state: these terms are the terms of
T (F) such that there is a successful run using any possible state of Q. Now, we
prove by induction on j that T (i; j; K) can be denoted by a regular expression
of Regexp(F; Q).

ffl Base case j = 0. The set T (i; 0; K) is the set of trees t where the root is

labelled by qi, the leaves are in F [ K and no internal node is labelled
by some q. Therefore there exist a1; : : : ; an; a 2 F [ K such that t =
f(a1; : : : ; an) or t = a, hence T (i; j; ;) is finite and can be denoted by a
regular expression of Regexp(F [ Q).

ffl Induction case. Let us assume that for any i0; K0 ` Q and 0 ^ j0 ! j, the

set T (i0; j0; K0) can be denoted by a regular expression. We can write the
following equality:

T (i; j; K) = T (i; j \Gamma  1; K)

[
T (i; j \Gamma  1; K [ fqjg) :qj T (j; j; K [ fqjg) \Lambda ;qj :qj T (j; j; K)

The inclusion of T (i; j; K) in the right-hand side of the equality can be
easily seen from the next picture.

Decomposition of a term of T (i; j; K)
T (i; j; K) qi

qj

qj

qj
T (j; j; K)

T (j; j; K [ fqjg) \Lambda ;qj :qj T (j; j; K)

50 Regular grammars and regular expressions

The converse inclusion is also not difficult. By definition, we have that:
T (i; j \Gamma  1; K) ` T (i; j; K)
and we can easily prove by induction on the number of occurrences of qj
that:
T (i; j \Gamma  1; K [ fqjg) :qj T (j; j \Gamma  1; K [ fqjg) \Lambda ;qj :qj T (j; j \Gamma  1; K) ` T (i; j; K)

By induction hypothesis, each set of the right-hand side of the equality
defining T (i; j; K) can be denoted by a regular expression of Regex(F [Q).
This yields the desired result because the union of these sets is represented
by the sum of the corresponding expressions.

Since we have already seen that regular expressions denotes recognizable tree
languages and that recognizable languages are regular, we can state Kleene's
theorem for tree languages.

Theorem 16. A tree language is recognizable if and only if it can be denoted
by a regular tree expression.

2.3 Regular equations.
Looking at our example of the set of lists of natural numbers, we can realize that
these lists can be defined by equations instead of grammar rules. For instance,
denoting set union by +, we could replace the grammar given in section 2.1.1
by the following equations.

N at = 0 + s(N at)
List = nil + cons(N at; List)

where the variables are List and N at. To get the usual lists of nonnegative
numbers, we must restrict ourselves to the least fixed-point solution of this
set of equations. Such systems of equations do not always have solution nor
does a least solution always exist. Therefore we shall study regular equation
systems defined as follows.

Definition 3. Let X1; : : : ; Xn be variables denoting sets of trees, let sji be terms
of TF (X) for 1 ^ j ^ ni, 1 ^ i ^ n, then a regular equation system S is a set
of equations of the form:

X1 = s11 + : : : + s1n1

: : :
Xp = sp1 + : : : + spnp

A solution of S is any n-tuple (L1; : : : ; Ln) of languages of TF such that

L1 = s11fX1L1; : : : ; XnLng [ : : : [ s1n1fX1L1; : : : ; XnLng

: : :
Lp = sp1fX1L1; : : : ; XnLng [ : : : [ spnp fX1L1; : : : ; XnLng

2.3 Regular equations. 51

We define the ordering ` on T (F)\Theta : : :\Theta T (F) by (L1; : : : ; Ln) ` (L01; : : : ; L0n)
if and only if Li ` L0i for all i = 1; : : : ; n. From the definition, we have that
(;; : : : ; ;) is the smallest element of ` and that each increasing sequence has an
upper bound. The fixed-point operator T S associated with an equation system
S is an operator from (T (F); : : : ; T (F)) into (T (F); : : : ; T (F)) such that

T S(L1; : : : ; Ln) = (L01; : : : ; L0n)

where

L01 = L1 [ s11fX1L1; : : : ; XnLng [ : : : [ s1n1 fX1L1; : : : ; XnLng

: : :
L0p = Lp [ sp1fX1L1; : : : ; XnLng [ : : : [ spnp fX1L1; : : : ; XnLng

Example 20. Let S be

N at = 0 + s(N at)
List = nil + cons(N at; List)

then

T S(;; ;) = (f0g; fnilg)
T S2(;; ;) = (f0; s(0)g; fnil; cons(0; nil)g)

Using a classical approach we use the fixed-point operator to compute the
least fixed-point solution of a system of equations.

Proposition 6. The fixed-point operator T S is continuous and its least fixedpoint T S!(;; : : : ; ;) is the least solution of S.

Proof. We show that T S is continuous in order to use Knaster-Tarski's theorem
on continuous operators. By construction, T S is monotonous, and the last
point is to prove that if S1 ` S2 ` : : : is an increasing sequence of n-tuples of
languages, the equality T S(Si*1 Si) = Si*1 T S(Si)) holds. By definition, each

Si can be written as (Si1; : : : ; Sin).

ffl We have that Si=1;::: T S(Si) ` T S(Si=1;:::(Si)) holds since the sequence

S1 ` S2 ` : : : is increasing and the operator T S is monotonous.

ffl Conversely we have to prove that T S(Si=1;:::(Si) ` Si=1;::: T S(Si)) holds.

Let (U1; : : : ; Un) 2 Si=1;::: Si, then there exists i1; : : : ; in such that U1 `

Si11 ; : : : ; Un ` Sinn , therefore (U1; : : : ; Un) ` (SN1 ; : : : ; SNn ) for N =
M axfip j p = 1; : : : ; ng since the sequence S1; S2; : : : is increasing. Therefore T S(U1; : : : ; Un) ` Si=1;::: T S(Si)) and we are done.

We have introduced systems of regular equations to get the algebraic characterization of regular tree languages stated in the following theorem.

Theorem 17. The least fixed-point solution of a system of regular equations
is a tuple of regular tree languages. Conversely each regular tree language is a
component of the least solution of a system of regular equations.

52 Regular grammars and regular expressions

Proof. Let S be a system of regular equations, and let Gi = (Xi; fX1; : : : ; Xng; F; R)
where R = [k=1;:::;nfXk ! s1k; : : : ; Xk ! sjkk g if the kth equation of S is
Xk = s1k + : : : + sjkk . We show that L(Xk) is the kth component of (L1; : : : ; Ln)
the least fixed-point solution of S.

ffl We prove that T Sp(;; : : : ; ;) ` (L(X1); : : : ; L(Xn)) by induction on p.

Let us assume that this property holds for all q ^ p. Let (u1; : : : ; un) 2
T Sk+1(;; : : : ; ;), then for each i there is some sji such that ui = sij fX1 !
v1; : : : ; Xn ! vng with (v1; : : : ; vn) 2 T Sk(;; : : : ; ;), therefore ui 2
L(Xi) using the induction hypothesis.

ffl We prove now that (L(X1); : : : ; L(Xn)) ` T S!(;; : : : ; ;) by induction

on derivation length. Let us assume that for each i, for each m ^ p,
the implication Xi !q ui implies that ui 2 T Sm(;; : : : ; ;) holds. Let
Xi !p+1 vi, then vi = sji (u1; : : : ; un) with Xj !m uj for some m ^ p.
By induction hypothesis uj 2 T Sm(;; : : : ; ;) ` T Sk(;; : : : ; ;) and we are
done.

Conversely, given a regular grammar G = (X; fX1; : : : ; Xng; F; R), with
R = fX1 ! s11; : : : ; X1 ! s1p1 ; : : : ; Xn ! sn1 ; : : : ; Xn ! snpn g, a similar proof
yields that the least solution of the system

X1 = s11 + : : : + s1p1

: : :
Xn = sn1 + : : : + snpn

is (L(X1); : : : ; L(Xn)).

Example 21. The grammar with axiom List, non-terminals List; N at terminals 0; s(); nil; cons(; ) and rules

List ! nil
List ! cons(N at; List)
N at ! 0
N at ! s(N at)

generates the first component of the least solution of the system given in the
previous example.

2.4 Context-free word languages and regular tree

languages

Context-free word languages and regular tree languages are strongly related.
This is not surprising since derivation trees of context-free languages and derivations of tree grammars look alike. For instance let us consider the context-free
language of arithmetic expressions on +,\Lambda  and a variable x. A context-free word
grammar generating this set is E ! x j E + E j E \Lambda  E where E is the axiom.
The generation of a word from the axiom can be described by a derivation tree

2.4 Context-free word languages and regular tree languages 53
which has the axiom at the root and where the generated word can be read
by picking up the leaves of the tree from the left to the right (computing what
we call the yield of the tree). The rules for constructing derivation trees show
some regularity, which suggests that this set of trees is regular. The aim of this
section is to show that this is true indeed. However, there are some traps which
must be avoided when linking tree and word languages. First, we describe how
to link word and trees. We shall use the symbols of F to build trees but also
words on the alphabet F. The Yield operator computes a word from a tree by
concatenating the leaves of the tree from the left to the right. More precisely,
it is defined as follows.

Yield(a) = a
Yield(f(s1; : : : ; sn)) = Yield(s1) : : : Yield(sn)

Example 22. Let F = fx; +; \Lambda ; E(; ; )g and s = E(x; \Lambda ; E(x; +; x)). Then
Yield(s) = x \Lambda  x + x which is a word on F (note that\Lambda  and + are not the usual
binary operator by syntactical symbols of arity 0. If t = E(E(x; \Lambda ; x); +; x) then
Yield(t) = x \Lambda  x + x also.

Before connecting word languages and tree languages, we recall that a contextfree word grammar G is a tuple (A; N; T; R) where A is the axiom, N the set
of non-terminals letters, T the set of terminal letters, R the set of production
rules of the form X ! ff with X 2 N; ff 2 (T [ N )\Lambda . To relate tree languages
and word languages, we must introduce the notion of arity in some way, therefore we give a definition of derivation trees more precise than the classical one.
For each X 2 N , we introduce a new symbol denoted by (X; m) whenever there
is a rule X ! ff where m is the length of the word ff. Let G be the set composed
of these new symbols and of the symbols of T . The set of derivation trees issued
from a 2 G, denoted by D(G; a) is the smallest set such that:

ffl D(G; a) = fag if a 2 T ,
ffl (a; 0) 2 D(G; a) if a ! ffl 2 R where ffl is the empty word,
ffl (a; p)(t1; : : : ; tp) 2 D(G; (a; p)) if t1 2 D(G; a1); : : : ; tp 2 D(G; ap) and

(a ! a1 : : : ap) 2 R where ai 2 G.

The set of derivation trees of G is D(G) = [(A;i)2GD(G; (A; i)). By definition,
the language generated by a context-free word grammar G is the set of words
computed by applying the Yield operator to derivation trees of G. The next
theorem states how context-free word languages and regular tree languages are
related.

Theorem 18. The following statement holds.

1. Let G be a context-free word grammar, then the set of derivation trees of

L(G) is a regular tree language.

2. Let L be a regular tree language then Yield(L) is a context-free word language.

54 Regular grammars and regular expressions

3. There exists a regular tree language which is not the set of derivation trees

of a context-free language.

Proof. We give the proofs of the three statements.

1. Let G = (A; N; T; R) be a context-free word language. We consider the

tree grammar G0 = (A; N; F; R0)) such that

ffl the axiom and the set of non-terminal symbols of G and G0 are the

same,

ffl F = T [ f(X; n) j X 2 N; 9X ! ff 2 R with ff of length ng,
ffl if (X ! a1 : : : ap) 2 R then (X ! (X; p)(a1; : : : ; ap)) 2 R0

Then L(G) = fYield(s) j s 2 L(G0)g. The proof is a standard induction on
derivation length. It is interesting to remark that there may and usually
does exist several tree languages (not necessarily regular) such that the
corresponding word language obtained via the Yield operator is a given
context-free word language.

2. Let G be a normalized tree grammar (A; X; N; R). We build the word

context-free grammar G0 = (A; X; N; R0) such that a rule X ! X1 : : : Xn
(resp. X ! a) is in R0 if and only if the rule X ! f(X1; : : : ; Xn) (resp.
X ! a) is in R for some f. It is straightforward to prove by induction on
the length of derivation that L(G0) = Yield(L(G)).

3. Let G be the regular tree grammar with axiom X, non-terminals X; Y; Z,

terminals q; b; f; h and rules

X ! f(Y; Z)
Y ! h(a; Y; b)
Y ! a
Z ! h(a; Z; b)
Z ! b

Assume that L(G) is the set of derivation trees of some context-free word
grammar. The following tree is in L(G) (arity have been indicated explicitly to make the link with derivation trees):

f; 2

a a b ba b

h; 3 h; 3

f(h(a; a; b); h(a; b; b))

To generate the first node one must have a rule F ! HH where F is the
axiom and rules H +! aab. H +! abb to get the inner nodes. Therefore the
following tree:

2.5 Beyond regular tree languages: context-free tree languages 55

f; 2

a a b ba a

h; 3 h; 3

f(h(a; a; b); h(a; a; b))

should be in L(G) which is not the case.
2.5 Beyond regular tree languages: context-free

tree languages

For word language, the story doesn't end with regular languages but there is a
strict hierarchy.

regular ae context-free ae recursively enumerable
Recursively enumerable tree languages are languages generated by tree grammar as defined in the beginning of the chapter, and this class is far too general
for having good properties. Actually, any Turing machine can be simulated by
a one rule rewrite system which shows how powerful tree grammars are (any
grammar rule can be seen as a rewrite rule by considering both terminals and
non-terminals as syntactical symbols). Therefore, most of the research has been
done on context-free tree languages which we describe now.

2.5.1 Context-free tree languages
A context-free tree grammar is a tree grammar G = (A; N; F; R) where
the rules have the form X(x1; : : : ; xn) ! t with t a tree of TF[fx1;::: ;xng,
x1; : : : ; xn 2 X and X a non-terminal of arity n. The definition of the derivation relation is slightly more complicated than for regular tree grammar: a term
t derives a term t0 if no variable of X occurs in t or t0, there is a rule l ! r
of the grammar, a substitution oe such that the domain of oe is included in X
and a context C such that t = C[loe] and t0 = C[roe]. The context-free tree
language L(G) is the set of trees which can be derived from the axiom of the
context-free tree grammar G.

Example 23. The grammar of axiom P rog, set of non-terminals fP rog; N g,
set of terminals f0; s; cond(; ; ); eq(; ); times(; ); fact(); dec()g and rules

P rog ! fact(N )
N ! 0
N ! s(N )
fact(x) ! cond(eq(x; 0); s(0); times(x; fact(dec(x))))

56 Regular grammars and regular expressions

where X = fxg is an context-free tree grammar. The reader can easily see that
the last rule is the classical definition of the factorial function.

Algebraic tree grammar have been extensively studied in connection with the
theory of recursive program scheme. Looking at a non-terminal F as a function
symbols, a production rule F (x1; : : : ; n) ! t can be seen as a definition of the
function F . Since the term t may contain F , recursive definitions are possible.
Since we know that such recursive definitions may not give the same results
depending on the evaluation strategy, IO and OI tree grammars have been
introduced to account for such differences.

2.5.2 IO and OI tree grammars
A context-free grammar is IO (IO for innermost-outermost) if we restrict legal
derivations to derivations where the innermost terminals are derived first. This
control corresponds to call by value evaluation. A context-free grammar is
OI (OI for outermost-innermost) if we restrict legal derivations to derivations
where the outermost terminals are derived first. This corresponds to call by
name evaluation. Therefore, given one context-free grammar G, we can define
IO-G and OI-G and the next example shows that the languages generated by
these grammars may be different.

Example 24. Let G be the context-free grammar with axiom A, non-terminals
fA; S; Bg, terminals fb; s; 0g) and rules A ! B(S)

S ! s(S)
S ! 0
B(x) ! b(x; x)
Then outermost-innermost derivations have the form

A ! B(S) ! b(S; S) \Lambda ! b(sn(0); sm(0))
while innermost-outermost derivations have the form

A ! B(S) \Lambda ! B(sn(0)) ! b(sn(0); sn(0))
Therefore L(OI-G) = fb(sn(0); sm(0)) j n; m 2 Ng and
L(IO-G) = fb(sn(0); sn(0)) j n 2 Ng.

* A COMPLETER *

2.6 Exercises
Exercise 18. Show that the image of a regular tree language by a linear homomorphism is a regular tree language using regular tree grammars. Show that the inverse
image of a regular tree language is a regular tee language using regular tree language.

Exercise 19. Let F be a signature containing a binary symbol f. Let =E be the
congruence generated by a finite set of equations. Let t a term, we define GrIns(t) =
fs ground term j s =E toeg.

2.6 Exercises 57

1. E1 = ff(x; y) = f(y; x)g. Find a regular grammar generating GrIns(t) if t is a

linear term.

2. Same question with E2 = ff(x; f(y; z)) = f(f(x; y); z)g and E1 [ E2.

Exercise 20. Let F be a signature, we define set expressions by the following
grammar.

sexp ::= ? j ? j X j f(sexp; : : : ; sexp) j f\Gamma 1(i) (sepx) j sexp " sexp
where X 2 X , f 2 F (including constants, and f\Gamma 1(i) denotes the ith projection associated to the n-ary symbol f for i = 1; : : : ; n (i.e. f\Gamma 1(i) (f(t1; : : : ; tn) = ti otherwise ? ).
An interpretation I assigns a set of ground terms to each variable and it is extended
to any set expression by setting I(?) = ;

I(?) = T (F)
I(s1 " s2) = I(s1) " I(s2)
I(f(t1; : : : ; tn)) = f(I(t1); : : : ; I(tn))
I(f\Gamma 1(i) (t)) = f\Gamma 1(i) (I(t))
A set expression grammar G = (A; N; F; R) is defined as tree grammar except that
production rules have the form X ! sexp. The language generated by G is L(G) =

fI(t) j A \Lambda ! t t groundg.

1. Find I(G) for the grammar G with axiom A, non-terminals A, signature fa; fg

and rules

A ! a
A ! f(a) " f(a)

The goal of the exercise is to show that there exists a regular tree grammar G
such that L(G) = I(G).

2. Compute a set expression grammar G1 such that I(G) = I(G1) and all rules of

G1 have the form X ! s1 " : : :" sm where the si's have the form ff(X1; : : : ; Xn)
with ff 2 F or a projection.

3. Compute a set expression grammar G1 equivalent to G1 such that all productions

of G2 have the form X ! s1": : :"sm where the si's have the form f(X1; : : : ; Xn)
with f 2 F.

4. Compute a regular tree grammar G equivalent to G2.

Exercise 21. (Local languages) Let t be a term of T (F), then we define fork(t) as
follows.

ffl fork(c) = ;
ffl fork(f(t1; : : : ; tn)) = ff(root(t1); : : : ; root(tn))g [i=ni=1 fork(ti)

A language L is local if and only if there exists a set F 0 ` F and a set G ` for(F)
s.t. t 2 L if and only if root(t) 2 F0 and fork(t) ` G.

Show that a language is local if and only if it is the set of derivation tree of a
context-free word language.

Exercise 22. The pumping lemma for context-free word language states that for
each context-free language L, there is some constant k * 1 such that each z 2 L of
length greater than or equal to k can be written z = uvwxy such that vx is not the
empty word, vwx has length less than or equal to k, and for each n * 0, the word
uvnwxny is in L. Prove this result using the pumping lemma of tree languages and
the results of this chapter.

58 Regular grammars and regular expressions

Exercise 23. Find a non regular tree language L such that Yield(L) is a context-free
word language.

Exercise 24. Show that a tree language L such that Yield(L) is a regular word
language is a regular tree language.

2.7 Bibliographic notes
The classical reference of algebraic aspects of regular tree language is [GS84]
which contains most of the results on these features.

Chapter 3

Automata and n-ary
relations

3.1 Introduction
As early as in the 50s, automata, and in particular tree automata, played an
important role in the development of verification . Several well-known logicians,
such as A. Church, J.R. B"uchi, Elgott, MacNaughton, M. Rabin and others
contributed to what is called "the trinity" by Trakhtenbrot: Logic, Automata
and Verification (of Boolean circuits).

The idea is simple: given a formula OE with free variables x1; :::; xn and a domain of interpretation D, OE defines the subset of Dn containing all assignments
of the free variables x1; : : : ; xn that satisfy OE. Hence formulas in this case are
just a way of defining subsets of Dn (also called n-ary relations on D). In case
n = 1 (and, as we will see, also for n ? 1), finite automata provide another
way of defining subsets of Dn. In 1960, B"uchi realized that these two ways
of defining relations over the free monoid f0; : : : ; ng\Lambda  coincide when the logic
is the sequential calculus, also called weak second-order monadic logic with one
successor, WS1S. This result was extended to tree automata: Doner, Thatcher
and Wright showed that the definability in the weak second-order monadic logic
with k successors, WSkS coincide with the recognizability by a finite tree automaton. These results imply in particular the decidability of WSkS, following
the decision results on tree automata (see chapter 1).

These ideas are the basis of several decision techniques for various logics
some of which will be listed in section 3.4 In order to illustrate this correspondence, consider Presburger's arithmetic: the atomic formulas are equalities and
inequalities s = t or s * t where s; t are sums of variables and constants. For
instance x + y + y = z + z + z + 1 + 1, also written x + 2y = 3z + 2, is an atomic
formula. In other words, atomic formulas are linear Diophantine (in)equations.
Then atomic formulas can be combined using any logical connectives among
^; .; : and quantifications 8; 9. For instance 8x(8y::(x = 2y)).(9y:x = 2y+1))
is a (true) formula of Presburger's arithmetic. Formulas are interpreted in the
natural numbers (non-negative integers), each symbol having its expected meaning. A solution of a formula OE(x) whose only free variable is x, is an assignment
of x to a natural number n such that OE(n) holds true in the interpretation. For

60 Automata and n-ary relations

00
0

10
1

11
0

01
1

0
10

01
0

00
1

11
1

Figure 3.1: The automaton with accepts the solutions of x = y + z
instance, if OE(x) is the formula 9y:x = 2y, its solutions are the even numbers.

Writing integers in base 2, they can be viewed as elements of the free monoid
f0; 1g\Lambda , i.e. words of 0s and 1s. The representation of a natural number is not
unique as 01 = 1, for instance. Tuples of natural numbers are displayed by
stacking their representations in base 2 and aligning on the right, then completing with some 0s on the left in order to get a rectangle of bits. For instance the

pair (13,6) is represented as 10 11 01 10 (or 00 10 11 01 10 as well). Hence, we can see the
solutions of a formula as a subset of (f0; 1gn)\Lambda  where n is the number of free
variables of the formula.

It is not difficult to see that the set of solutions of any atomic formula is
recognized by a finite word automaton working on the alphabet f0; 1gn. For
instance, the solutions of x = y + z are recognized by the automaton of figure
3.1.

Then, and that is probably one of the key ideas, each logical connective
corresponds to a basic operation on automata (here word automata): . is a
union, ^ and intersection, : a complement, 9x a projection (an operation which
will be defined in section 3.2.4). It follows that the set of solutions of any
Presburger formula is recognized by a finite automaton.

In particular, a closed formula (without free variable), holds true in the
interpretation if the initial state of the automaton is also final. It holds false
otherwise. Therefore, this gives both a decision technique for Presburger formulas by computing automata and an effective representation of the set of solutions
for open formulas.

The example of Presburger's arithmetic we just sketched is not isolated.
That is one of the purposes of this chapter to show how to relate finite tree
automata and formulas.

In general, the problem with these techniques is to design an appropriate
notion of automaton, which is able to recognize the solutions of atomic formulas
and which has the desired closure and decision properties. We have to cite here
the famous Rabin automata which work on infinite trees and which have indeed
the closure and decidability properties, allowing to decide the full second-order
monadic logic with k successors (a result due to M. Rabin, 1969). It is however
out of the scope of this book to survey automata techniques in logic and computer science. We restrict our attention to finite automata on finite trees and
refer to the excellent surveys [Rab77, Tho90] for more details on other applications of automata to logic.

3.2 Automata on tuples of finite trees 61

We start this chapter by reviewing some possible definitions of automata
on pairs (or, more generally, tuples) of finite trees in section 3.2. We define in
this way several notions of recognizability for relations, which are not necessary
unary, extending the frame of chapter 1. This extension is necessary since,
automata recognizing the solutions of formulas actually recognize n-tuples of
solutions, if there are n free variables in the formula.

The most natural way of defining a notion of recognizability on tuples is to
consider products of recognizable sets. Though this happens to be sometimes
sufficient, this notion is often too weak. For instance the example of figure 3.1
could not be defined as a product of recognizable sets. Rather, we stacked the
words and recognized these codings. Such a construction can be generalized to
trees (we have to overlap instead of stacking) and gives rise to a second notion
of recognizability. We will also introduce a third class called "Ground Tree
Transducers" which is weaker than the second class above but enjoys stronger
closure properties, for instance by iteration. Its usefulness will become evident
in section 3.4.

Next, in section 3.3, we introduce the weak second-order monadic logic with
k successor and show Thatcher and Wright's theorem which relates this logic
with finite tree automata. This is a modest insight into the relations between
logic and automata.

Finally in section 3.4 we survey a number of applications, mostly issued
from Term Rewriting or Constraint Solving. We do not detail this part (we give
references instead). The goal is to show how the simple techniques developed
before can be applied to various questions, with a special emphasis on decision
problems. We consider the theories of sort constraints in section 3.4.1, the theory
of linear encompassment in section 3.4.2, the theory of ground term rewriting
in section 3.4.3 and reduction strategies in orthogonal term rewriting in section
3.4.4. Other examples are given as exercises in section 3.5 or considered in
chapters 4 and 5.

3.2 Automata on tuples of finite trees
3.2.1 Three notions of recognizability
Let Rec\Theta  be the subset of n-ary relations on T (F) which are finite unions of
products S1 \Theta  : : : \Theta  Sn where S1; : : : ; Sn are recognizable subsets of T (F). This
notion of recognizability of pairs is the simplest one can imagine. Automata for
such relations consist of pairs of tree automata which work independently. This
notion is however quite weak, as e.g. the diagonal

\Delta  = f(t; t) j t 2 T (F)g
does not belong to Rec\Theta . Actually the relation R 2 Rec\Theta  does not really relate
its components !

The second notion of recognizability is used in the correspondence with
WSkS and is strictly stronger than the above one. Roughly, it consists in overlapping the components of a n-tuple, yielding a term on a product alphabet.
Then define Rec as the set of sets of pairs of terms whose overlapping coding is
recognized by a tree automaton on the product alphabet.

62 Automata and n-ary relations

f , f ! ff
g f gf
a a aa

g a ga
a ? aa a ?

Figure 3.2: The overlap of two terms

Let us first define more precisely the notion of "coding". (This is illustrated
by an example on figure 3.2). We let F0 = (F [f?g)n, where ? is a new symbol.
This is the idea of "stacking" the symbols, as in the introductory example of
Presburger's arithmetic. Let k be the maximal arity of a function symbol in F.
Assuming ? has arity 0, the arities of function symbols in F 0 are defined by
a(f1 : : : fn) = max(a(f1); : : : ; a(fn)).

The coding of two terms t1; t2 2 T (F) is defined by induction:

[f(t1; : : : ; tn); g(u1; : : : ; um)] def= fg([t1; u1]; : : : [tm; um]; [tm+1; ?];: : : ; [tn; ?])
if n * m and

[f(t1; : : : ; tn); g(u1; : : : ; um)] def= fg([t1; u1]; : : : [tn; un]; [?;un+1]; : : : ; [?;um])
if m * n.

More generally, the coding of n terms f1(t11; : : : ; tk11 ); : : : ; fn(t1; : : : ; tknn ) is
defined as

f1 : : : fn([t11; : : : ; t1n]; : : : ; [tm1 ; : : : ; tmn ])
where m is the maximal arity of f1; : : : ; fn 2 F and tji is, by convention, ?
when j ? ki.

Definition 4. Rec is the set of relations R ` T (F)n such that

f[t1; : : : ; tn] j (t1; : : : ; tn) 2 Rg
is recognized by a finite tree automaton on the alphabet F0 = (F [ f?g)n.

For example, consider the diagonal \Delta , it is in Rec since its coding is recognized by the bottom-up tree automaton whose only state is q (also a final state)
and transitions are the rules ff(q; : : : ; q) ! q for all symbols f 2 F.

One drawback of this second notion of recognizability is that it is not closed
under iteration. More precisely, there is a binary relation R which belongs to
Rec and whose transitive closure is not in Rec (see section 3.5). For this reason,
a third class of recognizable sets of pairs of trees was introduced: the Ground
Tree Transducers (GTT for short) .

3.2 Automata on tuples of finite trees 63

t = 

t'=

t1 tn t'1 t'n

q1 qn

C

Figure 3.3: GTT acceptance
Definition 5. A GTT is a pair of bottom-up tree automata (A1; A2) working
on the same alphabet. Their sets of states may however share some symbols (the
synchronization states).

A pair (t; t0) is recognized by a GTT (A1; A2) if there is a context C 2 Cn(F)
such that t = C[t1; : : : ; tn], t0 = C[t01; : : : ; t0n] and there are states q1; : : : ; qn of

both automata such that, for all i, ti \Lambda \Gamma \Gamma !A

1 qi and t

0i \Lambda \Gamma \Gamma !

A2 qi

The recognizability by a GTT is depicted on figure 3.3. For instance, \Delta  is
accepted by a GTT. Another typical example is the binary relation "one step
rewriting" for term rewriting system whose left members are linear and whose
right hand sides are ground (see section 3.4.3).

3.2.2 Examples of the three notions of recognizability
The first example illustrates Rec\Theta . It will be developed in a more general
framework in section 3.4.2.

Example 25. Consider the alphabet F = ff; g; ag where f is binary, g is unary
and a is a constant. Let P be the predicate which is true on t if there are terms
t1; t2 such that f(g(t1); t2) is a subterm of t. Then the solutions of P (x) . P (y)
define a relation in Rec\Theta , using twice the following automaton :

Q = fqf ; qg; q?g
Qf = fqf g
T = f a ! q? f(q?; q?) ! q?

g(q?) ! q? f(qf ; q?) ! qf

g(qf ) ! qf f(qg; q?) ! qf
g(q?) ! qg f(q?; qf ) ! qf g

For instance the pair (g(f(g(a); g(a))); f(g(g(a)); a)) is accepted by the pair
of automata.

64 Automata and n-ary relations

The second example illustrates Rec. Again, it is a first account of the developments of section 3.4.4

Example 26. Let F = ff; g; a; \Omega g where f is binary, g is unary, a and \Omega  are
constants. Let R be the set of terms (t; u) such that u can be obtained from t
by replacing each occurrence of \Omega  by some term in T (F) (each occurrence of \Omega 
needs not be replaced with the same term). Using the notations of chapter 2

R(t; u) () u 2 t:\Omega T (F)
R is recognized by the following automaton (on codings of pairs):

Q = fq; q0g
Qf = fq0g
T = f ? a(q) ! q ? f(q; q) ! q

? g(q) ! q \Omega f(q; q) ! q0

? \Omega  ! q ff(q0; q0) ! q0

aa ! q0 gg(q0) ! q0
\Omega \Omega  ! q0 \Omega g(q) ! q0

\Omega a ! q0g

For instance, the pair (f(g(\Omega ); g(\Omega )); f(g(g(a)); g(\Omega ))) is accepted by the
automaton: the overlap of the two terms yields

[tu] = ff(gg(\Omega g(? a)); gg(\Omega \Omega ))
And the reduction:

[tu] \Lambda \Gamma ! ff(gg(\Omega g(q)); gg(q0 ))

\Lambda \Gamma ! ff(gg(q0); q0)

! ff(q0; q0)
! q0

The last example illustrates the recognition by a GTT. It comes from the
theory of rewriting; further developments and explanations on this theory are
given in section 3.4.3.

Example 27. Let F = f\Theta ; +; 0; 1g. Let R be the rewrite system 0 \Theta  x ! 0.
The many-steps reduction relation defined by R: \Lambda \Gamma !R is recognized by the

GTT(A1; A2) defined as follows:

T1 = f 0 ! q? q? + q? ! q?

1 ! q? q? \Theta  q? ! q?
0 ! q0 q0 \Theta  q? ! q0g
T2 = f 0 ! q0g

3.2 Automata on tuples of finite trees 65

Rec

ffl
ffl

GTTRec\Theta 
fflffl

Rc
\Delta 
T(F)2fa; f(a)g2

Figure 3.4: The relations between the three classes
Then, for instance, the pair (1 + ((0 \Theta  1) \Theta  1); 1 + 0) is accepted by the GTT
since

1 + ((0 \Theta  1) \Theta  1) \Lambda \Gamma \Gamma !A

1 1 + (q0 \Theta  q?) \Theta  q? \Gamma \Gamma !A1 1 + (q0 \Theta  q?) \Gamma \Gamma !A1 1 + q0

one one hand and 1 + 0 \Gamma \Gamma !A

2 1 + q0 on the other hand.

3.2.3 Comparisons between the three classes
We study here the inclusion relations between the three classes: Rec\Theta ; Rec; GT T .

Proposition 7. Rec\Theta  ae Rec and the inclusion is strict.
Proof. To show that any relation in Rec\Theta  is also in Rec, we have to construct
from two automata A1 = (Q1; F; Qf1; R1); A2 = (F; Q2; Qf2; R2) an automaton
which recognizes the overlaps of the terms in the languages. We define such
an automaton A = (Q; (F [ f?g)2; Qf ; R) by: Q = (Q1 [ fq?g) \Theta  (Q2 [ q?g),
Qf = Qf1 \Theta  Qf2 and R is the set of rules:

ffl [f ?]((q1; q?); : : : ; (qn; q?)) \Gamma ! (q; q?) if f(q1; : : : ; qn) ! q 2 R1

ffl [? f]((q?; q1); : : : ; (q?; qn)) \Gamma ! (q?; q) if f(q1; : : : ; qn) ! q 2 R2
ffl fg((q1; q01); : : : ; (qm; q0m); (qm+1; q?); : : : ; (qn; q?)) ! (q; q0) if f(q1; : : : ; qn) !

q 2 R1 and g(q01; : : : ; q0m) ! q0 2 R2 and n * m

ffl fg((q1; q01); : : : ; (qn; q0n); (q?; qn+1); : : : ; (q?; qm)) ! (q; q0) if f(q1; : : : ; qn) !

q 2 R1 and g(q01; : : : ; q0m) ! q0 2 R2 and m * n

The proof that A indeed accepts L(A1) \Theta  L(A2) is left to the reader.

Now, the inclusion is strict since e.g. \Delta  2 Rec n Rec\Theta .

Proposition 8. GTT ae Rec and the inclusion is strict.
Proof. Let (A1; A2) be a GTT accepting R. We have to construct an automaton
A which accepts the codings of pairs in R.

66 Automata and n-ary relations

Let A0 = (Q0; F; Qf0; T0) be the automaton constructed in the proof of
proposition 7. [t; u] \Lambda \Gamma \Gamma !A

0 (q1; q2) if and only if t

\Lambda \Gamma \Gamma !
A1 q1 and u

\Lambda \Gamma \Gamma !
A2 q2. Now we
let A = (Q0 [ fqf g; F; Qf = fqf g; T ). T consists of T0 plus the following rules:

(q; q) ! qf ff(qf ; : : : ; qf) ! qf
For every symbol f 2 F and every state q 2 Q0.

If (t; u) is accepted by the GTT, then

t \Lambda \Gamma \Gamma !A

1 C[q1; : : : ; qn]p

1;::: ;pn

\Lambda \Gamma \Gamma 

A2 u:

Then

[t; u] \Lambda \Gamma \Gamma !A

0 [C; C][(q1; q1); : : : ; (qn; qn)]p

1;::: ;pn

\Lambda \Gamma !

A [C; C][qf; : : : ; qf ]p1;::: ;pn

\Lambda \Gamma !
A qf

Conversely, if [t; u] is accepted by A then [t; u] \Lambda \Gamma !A qf . By definition of A, there
should be a sequence:

[t; u] \Lambda \Gamma !A C[(q1; q1); : : : ; (qn; qn)]p1;::: ;pn \Lambda \Gamma !A C[qf; : : : ; qf]p1;::: ;pn \Lambda \Gamma !A qf

Indeed, we let pi be the positions at which one of the ffl-transitions steps (q; q) !
qf is applied. (n * 0). Now, C[qf ; : : : ; qf ]p1;::: ;pmqf if and only if C can be
written [C1; C1] (the proof is left to the reader).

Concerning the strictness of the inclusion, it will be a consequence of propositions 7 and 9.

Proposition 9. GTT 6` Rec\Theta  and Rec\Theta  6` GTT.
Proof. \Delta  is accepted by a GTT (with no state and no transition) but it does
not belong to Rec\Theta . On the other hand, if F = ff; ag, then fa; f(a)g2 is in
Rec\Theta  (it is the product of two finite languages) but it is not accepted by any
GTT since any GTT accepts at least \Delta .

Finally, there is an example of a relation Rc which is in Rec and not in the
union Rec\Theta  [ GTT; consider for instance the alphabet fa(); b(); 0g and the one
step reduction relation associated with the rewrite system a(x) ! x. In other
words,

(u; v) 2 Rc () 9C 2 C(F); 9t 2 T (F); u = C[a(t)]&v = C[t]
It is left as an exercise to prove that Rc 2 Rec n (Rec\Theta  [ GTT).

3.2.4 Closure properties for Rec\Theta  and Rec; cylindrification

and projection

Let us start with the classical closure properties.
Proposition 10. Rec\Theta  and Rec are closed under Boolean operations.

The proof of this proposition is straightforward and left as an exercise.
These relations are also closed under cylindrification and projection. Let us
first define these operations which are specific to automata on tuples:

3.2 Automata on tuples of finite trees 67
Definition 6. If R ` T (F)n (n * 1) and 1 ^ i ^ n then the ith projection of
R is the relation Ri ` T (F)n\Gamma 1 defined by

Ri(t1; : : : ; tn\Gamma 1) , 9t 2 T (F) R(t1; : : : ; ti\Gamma 1; t; ti; : : : ; tn)
When n = 1, T (F)n\Gamma 1 is by convention a singleton set f?g (so as to keep
the property that T (F)n+1 = T (F) \Theta  T (F)n). f?g is assumed to be a neutral
element w.r.t. Cartesian product. In such a situation, a relation R ` T (F)0 is
either ; or f?g (it is a propositional variable).

Definition 7. If R ` T (F)n (n * 0) and 1 ^ i ^ n + 1, then the ith cylindrification of R is the relation Ri ` T (F)n+1 defined by

Ri(t1; : : : ; ti\Gamma 1; t; ti; : : : ; tn) , R(t1; : : : ; tn)
Proposition 11. Rec\Theta  and Rec are effectively closed under projection and
cylindrification. Actually, ith projection can be computed in linear time and
the ith cylindrification of A can be computed in linear time (assuming that the
size of the alphabet is constant).

Proof. For Rec\Theta , this property is easy: projection on the ith component simply
amounts to remove the ith automaton. Cylindrification on the ith component
simply amounts to insert as a ith automaton, an automaton accepting all terms.

Assume that R 2 Rec. The ith projection of R is simply its image by the
following linear tree homomorphism:

hi([f1; : : : ; fn](t1; : : : ; tk)) def= [f1 : : : fi\Gamma 1fi+1 : : : fn](hi(t1); : : : ; hi(tm))
in which m is the arity of [f1 : : : fi\Gamma 1fi+1 : : : fn] (which is smaller or equal to
k). Hence, by theorem 6, the ith projection of R is recognizable (and we can
extract from the proof a linear construction of the automaton).

Similarly, the ith cylindrification is obtained as an inverse homomorphic
image, hence is recognizable thanks to theorem 7.

Note that using the above construction, the projection of a deterministic
automaton may be non-deterministic (see exercises and

Example 28. Let F = ff; g; ag where f is binary, g is unary and a is a
constant. Consider the following automaton A on F0 = (F [ f?g)2:1 The set
of states is fq1; q2; q3; q4; q5g and the set of final states is fq3g

a ? ! q1 f ? (q1; q1) ! q1
g ? (q1) ! q1 fg(q2; q1) ! q3

ga(q1) ! q2 f ? (q4; q1) ! q4
g ? (q1) ! q4 fa(q4; q1) ! q2

gg(q3) ! q3 ff(q3; q3) ! q3

aa ! q5 ff(q3; q5) ! q3
gg(q5) ! q5 ff(q5; q3) ! q3
ff(q5; q5) ! q5

1This automaton accepts the set of pairs of terms (u; v) such that u can be rewritten in
one or more steps to v by the rewrite system f(g(x);y) ! g(a).

68 Automata and n-ary relations

The second projection of this automaton gives:

a ! q2 g(q3) ! q3
a ! q5 g(q5) ! q5
a ! q4 g(q2) ! q3
f(q3; q3) ! q3 f(q3; q5) ! q3
f(q5; q5) ! q5 f(q5; q3) ! q3

Which accepts the terms containing g(a) as a subterm2.

3.2.5 Closure of GTT by composition and iteration
Theorem 19. If R ` T (F)2 is recognized by a GTT, then its transitive closure
R\Lambda  is also recognized by a GTT.

The detailed proof is technical, so let us show it on a picture and explain it
informally.

We consider two terms (t; v) and (v; u) which are both accepted by the GTT
and we wish that (t; u) is also accepted. For simplicity, consider only one state q

such that t \Lambda \Gamma \Gamma !A

1 C[q]

\Lambda \Gamma \Gamma 
A2 v and v

\Lambda \Gamma \Gamma !
A1 C

0[q1; : : : ; qn] \Lambda \Gamma \Gamma 

A2 u. There are actually
two cases: C can be "bigger" than C0 or "smaller". Assume it is smaller. Then

q is reached at a position inside C0: C0 = C[C00]p. The situation is depicted
on figure 3.5. Along the reduction of v to q by A2, we enter a configuration
C00[q01; : : : ; q0n]. The idea now is to add to A2 ffl-transitions from qi to q0i. In this
way, as can easily be seen on figure 3.5, we get a reduction from u to C[q], hence
the pair (t; u) is accepted.

WARNING: The proof should be "simplified": instead of the conditions

LAn2 (q) " LAn1 (q0) 6= ; and q 2 Q1 " Q2, which are "non-local", use the

inference rule

f(q1; : : : ; qn) \Gamma \Gamma !A

1 q f(q

01; : : : ; q0n) \Gamma \Gamma !

A2 q

0 q1 ' q01 \Delta  \Delta  \Delta  qn ' q0n

q ' q0
where ' is moreover reflexive transitive (and symmetric when it makes sense)

on Q1 \Theta  Q2.
This has to be worked out: it is more beautiful but conceptually more

complicated in my opinion.

Proof. Let A1 and A2 be the pair of automata defining the GTT which accepts
R. We compute by induction the automata An1 ; An2 . A0i = Ai and An+1i is
obtained by adding new transitions to Ani : Let Qi be the set of states of Ai
(and also the set of states of Ani ).

ffl If LAn2 (q) " LAn1 (q0) 6= ;, q 2 Q1 " Q2 and q 6 \Lambda \Gamma \Gamma !An

1 q

0, then An+11 is obtained

from An1 by adding the ffl-transition q ! q0 and An+12 = An2 .
2i.e. the terms that are obtained by applying at least one rewriting step using f(g(x); y) !
g(a)

3.2 Automata on tuples of finite trees 69

q'nq'1

q1 qnA1 A2

A2

A1

A2

q

C =

t =

C' =

v =
u =
Figure 3.5: The proof of theorem 19

70 Automata and n-ary relations

ffl If LAn1 (q) " LAn2 (q0) 6= ;, q 2 Q1 " Q2 and q 6 \Lambda \Gamma \Gamma !An

2 q

0, then An+12 is obtained

from An2 by adding the ffl-transition q ! q0 and An+11 = An1 .
If there are several ways of obtaining An+1i from Ani using these rules, we don't
care which of these ways is used.

First, these completion rules are decidable by the decision properties of chapter 1. Their application also terminates as at each application strictly decreases
k1(n) + k2(n) where ki(n) is the number of pairs of states (q; q0) 2 Q1 [ Q2 such
that there is no ffl-transition in Ani from q to q0. We let A\Lambda i be a fixed point of
this computation. We show that (A\Lambda 1; A\Lambda 2) defines a GTT accepting R\Lambda .

ffl Each pair of terms accepted by the GTT (A\Lambda 1; A\Lambda 2) is in R\Lambda : we show by

induction on n that each pair of terms accepted by (An1 ; An2 ) is in R\Lambda .
For n = 0, this follows from the hypothesis. Let us now assume that
An+11 is obtained by adding q ! q0 to the transitions of An1 (The other
case is symmetric). Let (t; u) be accepted by the GTT (An+11 ; An+12 ).
By definition, there is a context C and positions p1; : : : ; pk such that
t = C[t1; : : : ; tk]p1;::: ;pk, u = C[u1; : : : ; uk]p1;::: ;pk and there are states

q1; : : : ; qk 2 Q1 " Q2 such that, for all i, ti \Lambda \Gamma \Gamma \Gamma !

An+11 qi and ui

\Lambda \Gamma \Gamma !
An2 qi.

We prove the result by induction on the number m of times q ! q0 is
applied in the reductions ti \Lambda \Gamma \Gamma \Gamma !

An+11 qi. If m = 0. Then this is the first

induction hypothesis: (t; u) is accepted by (An1 ; An2 ), hence (t; u) 2 R\Lambda .
Now, assume that, for some i,

ti \Lambda \Gamma \Gamma \Gamma !

An+11 t

0i[q]p \Lambda \Gamma \Gamma \Gamma !

q!q0 t

0i[q0]p \Lambda \Gamma \Gamma !

An1 qi

By definition, there is a term v such that v \Lambda \Gamma \Gamma !An

2 q and v

\Lambda \Gamma \Gamma !
An1 q

0. Hence

ti[v]p \Lambda \Gamma \Gamma \Gamma !

An+11 qi

And the number of reduction steps using q ! q0 is strictly smaller here
than in the reduction from ti to qi. Hence, by induction hypothesis,
(t[v]pip; u) 2 R\Lambda . On the other hand, (t; t[v]pip) is accepted by the GTT

(An+11 ; An2 ) since tjpip \Lambda \Gamma \Gamma \Gamma !

An+11 q and v

\Lambda \Gamma \Gamma !
An2 q. Moreover, by construction,
the first sequence of reductions uses strictly less than m times the transition q ! q0. Then, by induction hypothesis, (t; t[v]pip) 2 R\Lambda . Now from
(t; t[v]pip 2 R\Lambda  and (t[v]pip; u) 2 R\Lambda , we conclude (t; u) 2 R\Lambda .

ffl If (t; u) 2 R\Lambda , then (t; u) is accepted by the GTT (A\Lambda 1; A\Lambda 2). Let us prove

the following intermediate result:

Lemma 1. if t \Lambda \Gamma \Gamma !A\Lambda 

1 q, v

\Lambda \Gamma \Gamma !
A\Lambda 2 q, v

\Lambda \Gamma \Gamma !
A\Lambda 1 C[q1; : : : ; qn]p1;::: ;pn and u

\Lambda \Gamma \Gamma !
A\Lambda 2 C[q1; : : : ; qn]p1;::: ;pn,

then u \Lambda \Gamma \Gamma !A\Lambda 

2 q (and hence (t; u) is accepted by the GTT)

3.2 Automata on tuples of finite trees 71

Let v \Lambda \Gamma \Gamma !A\Lambda 

2 C[q

01; : : : ; q0n]p

1;::: ;pn

\Lambda \Gamma \Gamma !

A\Lambda 2 q. For each i, vjpi 2 LA

\Lambda 
2 (q

0i)"LA\Lambda 

1(qi)

and qi 2 Q1 " Q2. Hence, by construction, qi \Gamma \Gamma !A\Lambda 

2 q

0i. It follows that

u \Lambda \Gamma \Gamma !A\Lambda 

2 C[q1; : : : q

n]p1;::: ;pn \Lambda \Gamma \Gamma !A\Lambda 

2 C[q

01; : : : ; q0n]p

1;::: ;pn

\Lambda \Gamma \Gamma !

A\Lambda 2 q

Which proves our lemma.
Symmetrically, if t \Lambda \Gamma \Gamma !A\Lambda 

1 C[q1; : : : ; q

n]p1;::: ;pn , v \Lambda \Gamma \Gamma !A\Lambda 

2 C[q1; : : : ; q

n]p1;::: ;pn ,

v \Lambda \Gamma \Gamma !A\Lambda 

1 q and u

\Lambda \Gamma \Gamma !
A\Lambda 2 q, then t

\Lambda \Gamma \Gamma !
A\Lambda 1 q

Now, let (t; u) 2 Rn: we prove that (t; u) is accepted by the GTT (A\Lambda 1; A\Lambda 2)
by induction on n. If n = 1, then the result follows from the inclusion of L(A1; A2) in L(A\Lambda 1; A\Lambda 2). Now, let v be such that (t; v) 2 R and
(v; u) 2 Rn\Gamma 1. By induction hypothesis, both (t; v) and (v; u) are accepted by the GTT (A\Lambda 1; A\Lambda 2): there are context C and C0 and positions
p1; : : : ; pk; p01; : : : ; p0m such that t = C[t1; : : : ; tk]p1;::: ;pk, v = C[v1; : : : ; vk]p1;::: ;pk,
v = C0[v01; : : : ; v0m]p01;::: ;p0m , u = C0[u1; : : : ; um] and states q1; : : : ; qk; q01; : : : ; q0m 2

Q1 " Q2 such that for all i; j, ti \Lambda \Gamma \Gamma !A\Lambda 

1 qi, vi

\Lambda \Gamma \Gamma !
A\Lambda 2 qi, v

0j \Lambda \Gamma \Gamma !

A\Lambda 1 q

0j, uj \Lambda \Gamma \Gamma !

A\Lambda 2 q

0j.

Let C00 be the largest context more general than C and C0; the positions of
C00 are the positions of both C[q1; : : : ; qn]p1;::: ;pn and C0[q01; : : : ; q0m]p01;::: ;p0m .
C00, p001; : : : ; p00l are such that:

- For each 1 ^ i ^ l, there is a j such that either pj = p00i or p0j = p00i
- For all 1 ^ i ^ n there is a j such that pi * p00j
- For all 1 ^ i ^ m there is a j such that p0i * p00j
- the positions p00j are pairwise incomparable w.r.t. the prefix ordering.

Let us fix a j 2 [1::l]. Assume that p00j = pi (the other case is symmetric).
We can apply our lemma to tj = tjp00j (in place of t), vj = vjp00j (in place

of v) and ujp00j (in place of u), showing that ujp00j \Lambda \Gamma \Gamma !A\Lambda 

2 q

i. If we let now

q00j = qi when p00j = pi and q00j = q0i when p00j = p0i, we get

t \Lambda \Gamma \Gamma !A\Lambda 

1 C

00[q001 ; : : : ; q00l ]p00

1 ;::: ;p00l

\Lambda \Gamma \Gamma 

A\Lambda 2 u

which completes the proof.

Proposition 12. If R and R0 are in GTT then their composition R ffi R0 is also
in GTT.

Proof. Let (A1; A2) and (A01; A02) be the two pairs of automata which recognize
R and R0 respectively. The construction of the GTT (A\Lambda 1; A\Lambda 2) accepting RffiR0 is
similar to the proof of theorem 19: we construct a sequence of automata An1 ; An2
by induction on n, with A01 = A1 and A02 = A02 and

ffl If there is a state q of A2 and a state q0 of both A01 and An2 such that

there is a term t accepted in both q by A2 and q0 by A01, then we add the
transition q0 ! q to An2 and An1 remains unchanged

72 Automata and n-ary relations

ffl If there is a state q of A01 and a state q0 of both An1 and A2 such that there

is a term t accepted in both state q0 by A2 and in state q by A01, then we
add the transition q0 ! q to An1 and An2 remains unchanged.

Figure 3.5 also illustrates this construction, with slight changes.

The proof goes on like in theorem 19 with slight changes. (Actually, it is a
bit simpler here).

GTTs do not have much other good closure properties (see the exercises).

3.3 The logic WSkS
3.3.1 Syntax
Terms of WSkS are formed out of the constant ffl, first-order variable symbols
(typically written with lower-case letters x; y; z; x0; x1; :::) and unary symbols
1; : : : ; n written in postfix notation. For instance x1123; ffl2111 are terms. The
latter will be often written omitting ffl (e.g. 2111 instead of ffl2111).

Atomic formulas are either equalities s = t between terms, inequalities s ^ t
or s * t between terms, or membership constraints t 2 X where t is a term and
X is a second-order variable symbol. Second-order variables will be typically
denoted using upper-case letters.

Formulas are built from the atomic formulas using the logical connectives
^; .; :; ); (; , and the quantifiers 9x; 8x; 9X; 8X; we may quantify both firstorder and second-order variables.

As usual, we do not need all this artillery: we may stick to a subset of
logical connectives (and even a subset of atomic formulas as it will be discussed
in section 3.3.4). For instance OE ,  is an abbreviation for (OE ) ) ^ ( ) OE),
OE (  is another way of writing  ( OE, OE )  is an abbreviation for (:OE) . ,
8x:OE stands for :9x::OE etc ... We will use the extended syntax for convenience,
but we will restrict ourselves to the atomic formulas s = t; s ^ t; t 2 X and the
logical connectives .; :; 9x; 9X in the proofs.

The set of free variables of a formula OE is defined as usual.

3.3.2 Semantics
We consider the particular interpretation where terms are strings belonging to
f1; : : : ; kg\Lambda , = is the equality of strings, ^ is interpreted as the prefix ordering.
Second order variables are interpreted as finite subsets of f1; : : : ; kg\Lambda , 2 is then
the membership.

Let t1; : : : ; tn 2 f1; : : : ; kg\Lambda  and S1; : : : ; Sn be finite subsets of f1; : : : ; kg\Lambda .
Given a formula OE(x1; : : : ; xn; X1; : : : ; Xm) with free variables x1; : : : ; xn; X1; : : : ; Xm,
the assignment fx1 7! t1; : : : xn 7! tn; X1 7! S1; : : : Xm 7! Smg satisfies OE,
which is written oe j= OE (or also t1; : : : ; tn; S1; : : : ; Sm j= OE) if replacing the
variables with their corresponding value, the formula holds in the above model.

Remark: the logic SkS is defined as above, except that set variables may be
interpreted as infinite sets.

3.3 The logic WSkS 73
3.3.3 Examples
We list below a number of formulas defining predicates on sets and singletons.
After these examples, we may use the below-defined abbreviations as if there
were primitives of the logic.

X is a subset of Y :

X ` Y def= 8x:(x 2 X ) x 2 Y )

Finite union:

X =

n[

i=1

Xi def=

n^

i=1

Xi ` X ^ 8x:(x 2 X )

n.

i=1

x 2 Xn)

Disjointness:

X " Y = ; def= 8x::(x 2 X) . :(x 2 Y )
Partition:

Partition(X; X1; : : : ; Xn) def= X =

n[

i=1

Xi ^

n\Gamma 1^

i=1

n^
j=i+1

Xi " Xj = ;

X is closed under prefix:

PrefixClosed(X) def= 8z:8y:(z 2 X ^ y ^ z) ) y 2 X
Set equality:

Y = X def= Y ` X ^ X ` Y
Emptiness:

X = ; def= 8Y:(Y ` X ) Y = X)
X is a Singleton:

Sing(X) def= 8Y (Y ` X ) (Y = X . Y = ;)
The prefix ordering:

x ^ y def= 8X:(x 2 X ^ (8z:(z 2 X )

k^

i=1

zi 2 X))) ) y 2 X

"every set containing x and closed by successors contains y"
This shows that ^ can be removed from the syntax of WSkS formulas
without decreasing the expressive power of the logic.

74 Automata and n-ary relations

Coding of trees: assume that k is the maximal arity of a function symbol

in F. If t 2 T (F) C(t) is the tuples of sets (S; Sf1 ; : : : ; Sfn ) if F =
ff1; : : : ; fng, S = Sni=1 Sfi and Sfi is the set of positions in t which are
labeled with fi.

For instance C(f(g(a); f(a; b))) is the tuple S = f\Lambda ; 1; 11; 2; 21; 22g, Sf =
f\Lambda ; 2g, Sg = f1g, Sa = f11; 21g, Sb = f22g.

(S; Sf1 ; : : : ; Sfn ) is the coding of some t 2 T (F):

Term(X; X1; : : : ; Xn) def= Partition(X; X1; : : : ; Xn) ^PrefixClosed(X)

^ Vki=1 Va(fj)=i (Vil=1 8x:(x 2 Xfj ) xl 2 X)

^ Vkl=i+1 8y:(y 2 Xfj ) xl =2 X))

3.3.4 Restricting the syntax
If we consider that a first-order variable is a singleton set, it is possible to
transform any formula into an equivalent one which does not contain any firstorder variable.

More precisely, we consider now that formulas are built upon the atomic
formulas:

X ` Y; Sing(X); X = Y i; X = ffl
using the logical connectives and second-order quantification only. Let us
call this new syntax the restricted syntax.

These formulas are interpreted as expected. In particular Sing(X) holds true
when X is a singleton set and X = Y i holds true when X and Y are singleton
sets fsg and ftg respectively and s = ti. Let us write j=2 the satisfaction relation
for this new logic.

Proposition 13. There is a translation T from WSkS formulas to the restricted
syntax such that

s1; : : : ; sn; S1; : : : ; Sm j= OE(x1; : : : ; xn; X1; : : : ; Xm)
if and only if

fs1g; : : : ; fsng; S1; : : : ; Sm j=2 T (OE(Xx1; : : : ; Xxn; X1; : : : ; Xm))
Conversely, there is a translation T 0 such from the restricted syntax to WSkS
such that

S1; : : : ; Sm j= T 0(OE(x1; : : : ; xn; X1; : : : ; Xm))
if and only if

S1; : : : ; Sm j=2 OE(X1; : : : ; Xm))
Proof. First, according to the previous section, we can restrict our attention to
formulas built upon the only atomic formulas t 2 X and s = t. Then, each
atomic formula is flattened according to the rules:

ti 2 X ! 9y:y = ti ^ y 2 X
xi = yj ! 9z:z = xi ^ z = yj

ti = s ! 9z:z = t ^ zi = s

3.3 The logic WSkS 75
The last rule assumes that t is not a variable

Next, we associate a second-order variable Xy to each first-order variable y
and transform the flat atomic formulas:

T (y 2 X) def= Xy ` X
T (y = xi) def= Xy = Xxi

T (x = ffl) def= Xx = ffl

Now, T (OE . ) def= T (OE) . T (), T (:(OE)) def= :T (OE), T (9X:OE) def= 9XT (OE),
T (9y:OE) def= 9XySing(Xy) ^ T (OE).

For the converse, the translation T 0 has been given in the previous section,
except for the atomic formulas X = Y i (which becomes Sing(X) ^ Sing(Y ) ^
9x9y:x 2 X ^ y 2 Y ^ x = yi) and X = ffl (which becomes Sing(X) ^ 8x:x 2
X ) 8y:x ^ y).

3.3.5 Definable sets are recognizable sets
Definition 8. A set L of tuples of finite sets of words is definable in WSkS if
there is a formula OE of WSkS with free variables X1; : : : ; Xn such that (S1; : : : ; Sn) 2
L if and only if S1; : : : ; Sn j= OE.

Each tuple of finite sets of words S1; : : : ; Sn ` f1; : : : ; kg\Lambda  is identified to
a finite tree (S1; : : : ; Sn), over the alphabet f0; 1; ?gn where any strings containing a 0 or a 1 is k-ary and ?n is a constant, in the following way3:

Pos((S1; : : : ; Sn),) def= fpi j 9p0 2

n[

i=1

Si; p ^ p0; i 2 f1; : : : ; kg

is the set of prefixes of words in some Si. The symbol at position p: (S1; : : : ; Sn),(p) =
ff1 : : : ffn is defined as follows:

ffl ffi = 1 if and only if p 2 Si
ffl ffi = 0 if and only if p =2 Si and 9p0 2 Si and p ^pref p0
ffl ffi =? otherwise.

Example 29. Consider for instance S1 = fffl; 11g, S2 = ;, S3 = f11; 22g three
subsets of f1; 2g\Lambda . Then the coding (S1; S2; S3), is depicted on figure 3.6.

Lemma 2. If a set L of tuples of finite subsets of f1; : : : ; kg\Lambda  is definable thene
L def= f(S1; : : : ; Sn), j (S1; : : : ; Sn) 2 Lg is in Rec.

3This is very similar to the coding of section 3.2.1, except that we slightly simplify here,
avoiding the introduction of an extra constant.

76 Automata and n-ary relations

0 0
11 1

1 0

0

Figure 3.6: An example of a tree coding a triple of finite sets of strings

0

q'q
1

qq

q'

q q'

0

qq'

q'

Figure 3.7: The automaton for Sing(X)
Proof. By proposition 13, if L is definable in WSkS, it is also definable with the
restricted syntax. We are going now to prove the lemma by induction on the
structure of the formula OE which defines L. We assume that all variables in OE
are bound at most once in the formula and we also assume a fixed total ordering
^ on the variables. If  is a subformula of OE with free variables Y1 ! : : : ! Yn,
we construct an automaton A working on the alphabet f0; 1; ?gn such that
(S1; : : : ; Sn) j=2  if and only if (S1; : : : ; Sn), 2 L(A)

The base case consists in constructing an automaton for each atomic formula.
(We assume here that k = 2 for simplicity, but this works of course for arbitrary
k).

The automaton ASing(X) is depicted on figure 3.7. The only final state is

q0.

The automaton AX`Y (with X ! Y ) is depicted on figure 3.8. The only
state (which is also final) is q.

The automaton AY =X1 is depicted on figure 3.9. The only final state is q00.
An automaton for Y = X2 is obtained in a similar way.

The automaton for X = ffl is depicted on figure 3.10.
Now, for the induction step, we have several cases to investigate:

ffl If OE is a disjunction OE1 . OE2, where ~Xi are the set of free variables of

OEi respectively. Then we we first cylindrify the automata for OE1 and OE2
respectively in such a way that they recognize the solutions of OE1 and

3.3 The logic WSkS 77

q

1
q q

q

00
q q

q q

qq
11

0
q q

q

q q

q01

Figure 3.8: The automaton for X ` Y

q
00
q''

q''1

q

q
01

q q

q'

q'

q''

00 q''
q q''

Figure 3.9: The automaton for Y = X1

q

q
1 q'
q

Figure 3.10: The automaton for X = ffl

78 Automata and n-ary relations

OE2, with free variables ~X1 [ ~X2. (See section 3.2.4).More precisely, let

~X1 [ ~X2 = fY1; : : : ; Yng with Y1 ! : : : ! Yn. Then we successively apply

the ith cylindrification to the automaton of OE1 (resp. OE2) for the variables
Yi which are not free in OE1 (resp. OE2). Then the automaton AOE is obtained
as the union of these automata. (Rec is closed under union by proposition
10).

ffl If OE is a formula :OE1 then AOE is the automaton accepting the complement

of AOE1.

ffl If OE is a formula 9X:OE1. Assume that X correspond to the ith component.

Then AOE is the ith projection of AOE1

3.3.6 Recognizable sets are definable
As in previous section, we use a representation of (tuples of) terms as tuples of
set variables; if (t1; : : : ; tn) 2 T (F)n, we write [t1; : : : ; tn] the (jFj + 1)n + 1-
tuple of finite sets which represents it: one set for the positions of [t1; : : : ; tn]
and one set for each element of the alphabet F [ f?g . As it has been seen
in previous section, there is a WSkS formula Term([t1; : : : ; tn]) which expresses
the image of the coding.

Lemma 3. Every relation in Rec is definable. More precisely, if R 2 Rec there
is a formula OE such that (S1; : : : ; Sm) j=2 OE if and only if there is (t1; : : : ; tn) 2
R such that (S1; : : : ; Sm) = [t1; : : : ; tn].

Proof. Let A be the automaton which accepts the set of terms [t1; : : : ; tn] for
(t1; : : : ; tn) 2 R. The terminal alphabet of A is F0 = (F [ f?g)n, the set
of states Q, the final states Qf and the set of transition rules T . Let F0 =
ff1; : : : ; fmg and Q = fq1; : : : ; qlg. The following formula OEA (with m + 1 free
variables) defines the set f[t1; : : : ; tn] j (t1; : : : ; tn) 2 Rg.

9Yq1; : : : ; 9Yql:

Term(X; Xf1; : : : ; Xfm )
^ Partition(X; Yq1 ; : : : ; Yql)
^ Wq2Qf ffl 2 Yq

^ 8x: Vf2F0 ((x 2 Xf ^ x 2 Yq) ) ( .

f(q1;::: ;qs)!q2T

s^
i=1

xi 2 Xqi ))

We have to prove two inclusions. First assume that (S; S1; : : : ; Sm) j=2 OE.
Then (S; S1; : : : ; Sm) j= Term(X; Xf1 ; : : : ; Xfm ), hence there is a term u 2
T (F)0 whose set of position is S and such that for all i, Si is the set of positions
labeled with fi. Now, there is a partition Eq1; : : : ; Eql of S which satisfies

S; S1; : : : ; Sm; Eq1; : : : ; Eql j= 8x: ^

f2F0

((x 2 Xf ^ x 2 Yq) ) ( .

f(q1;::: ;qs)!q2T

s^
i=1

xi 2 Xqi ))

This implies that the labeling Eq1; : : : ; Eql is compatible with the transition
rules: it defines a run of the automaton. Finally, the condition that the root \Lambda 

3.3 The logic WSkS 79
belongs to Eqf for some final state qf implies that the run is successful, hence
that u is accepted by the automaton.

Conversely, if u is accepted by the automaton, then there is a successful run
of A on u and we can label its positions with states in such a way that this
labeling is compatible with the transition rules in A.

Putting together lemmas 2 and 3, we can state the following slogan (which
is not very precise; the precise statements are given by the lemmas):

Theorem 20. L is definable if and only if L is in Rec.

And, as a consequence:
Theorem 21 ([TW68]). WSkS is decidable.
Proof. Given a formula OE of WSkS, by lemma 2, we can compute a finite tree
automaton which has the same solutions as OE. Now, assume that OE has no free
variable. Then the alphabet of the automaton is empty (or, more precisely, it
contains the only constant ? according to what we explained in section 3.2.4)

3.3.7 Complexity issues
We have seen in chapter 1 that, for finite tree automata, emptiness can be decided in linear time (and is PTIME-complete) and that inclusion is EXPTIMEcomplete. Considering WSkS formulas with a fixed number of quantifiers alternations N , the decision method sketched in the previous section will work
in time which is a tower of exponentials, the height of the tower being O(N ).
This is so because each time we encounter a sequence 8X; 9Y , the existential
quantification corresponds to a projection, which may yield a non-deterministic
automaton, even if the input automaton was deterministic. Then the elimination
of 8X requires a determinization (because we have to compute a complement
automaton) which requires in general exponential time and exponential space.

Actually, it is not really possible to do much better since, even when k = 1,
deciding a formula of WSkS requires non-elementary time, as shown in [SM73].

3.3.8 Extensions
There are several extensions of the logic, which we already mentioned: though
quantification is restricted to finite sets, we may consider infinite sets as models
(this is what is often called weak second-order monadic logic with k successors
and also written WSkS), or consider quantifications on arbitrary sets (this is
the full SkS).

These logics require more sophisticated automata which recognize sets of
infinite terms. The proof of theorem 21 carries over these extensions, with the
provision that the devices enjoy the required closure and decidability properties.
But this becomes much more intricate in the case of infinite terms. Indeed, for
infinite terms, it is not possible to design bottom-up tree automata. We have to
use a top-down device. But then, as mentioned in chapter 1, we cannot expect
to reduce the non-determinism. Now, the closure by complement becomes problematic because the usual way of computing the complement uses reduction of
non-determinism as a first step.

80 Automata and n-ary relations

It is out of the scope of this book to define and study automata on infinite
objects (see [Tho90] instead). Let us simply mention that the closure under complement for Rabin automata which work on infinite trees (this result is known
as Rabin's theorem) is one of the most difficult results in the field

3.4 Examples of applications
3.4.1 Terms and sorts
The most basic example is what is known in the algebraic specification community as order-sorted signatures . These signatures are exactly what we called
bottom-up tree automata. There are only differences in the syntax. For instance, the following signature:

SORTS:Nat; int
SUBSORTS : Nat ^ int
FUNCTION DECLARATIONS:

0 : ! Nat
+ : Nat \Theta  Nat ! Nat
s : Nat ! Nat
p : Nat ! int
+ : int \Theta  int ! int
abs : int ! Nat
fact : Nat ! Nat
: : :

is an automaton whose states are Nat; int with an ffl-transition from Nat to int
and each function declaration corresponds to a transition of the automaton. For
example +(Nat; Nat) ! Nat. The set of well-formed terms (as in the algebraic
specification terminology) is the set of terms recognized by the automaton in
any state.

More general typing systems also correspond to more general automata (as
will be seen e.g. in the next chapter).

This correspondence is not surprising; types and sorts are introduced in order
to prevent run-time errors by some "abstract interpretation" of the inputs. Tree
automata and tree grammars also provide such a symbolic evaluation mechanism. For other applications of tree automata in this direction, see e.g. chapter
5.

From what we have seen in this chapter, we can go beyond simply recognizing the set of well-formed terms. Consider the following sort constraints (the
alphabet F of function symbols is given):

The set of sort expressions SE is the least set such that

ffl SE contains a finite set of sort symbols S, including the two particular

symbols ?S and ?S.

ffl If s1; s2 2 SE, then s1 . s2, s1 ^ s2, :s1 are in SE
ffl If s1; : : : ; sn are in SE and f is a function symbol of arity n, then f(s1; : : : ; sn) 2

SE.

3.4 Examples of applications 81

t
u

Figure 3.11: u encompasses t
The atomic formulas are expressions t 2 s where t 2 T (F; X ) and s 2 SE.
The formulas are arbitrary first-order formulas built on these atomic formulas.

These formulas are interpreted as follows: we are giving an order-sorted signature (or a tree automaton) whose set of sorts is S. We define the interpretation[[\Delta ]]S
of sort expressions as follows:

ffl if s 2 S, [[s]]S is the set of terms in T (F) that are accepted in state s.
ffl [[?S]]S = T (F) and [[?S]]S = ;
ffl [[s1 . s2]]S = [[s1]]S [ [[s2]]S, [[s1 ^ s2]]S = [[s1]]S " [[s2]]S, [[:s]]S = T (F) n [[s]]S
ffl [[f(s1; : : : ; sn)]]S = ff(t1; : : : ; tn) j t1 2 [[s1]]S; : : :tn 2 [[sn]]Sg
An assignment oe, mapping variables to terms in T (F), satisfies t 2 s (we
also say that oe is a solution of t 2 s) if toe 2 [[s]]S. Solutions of arbitrary formulas
are defined as expected. Then

Theorem 22. Sort constraints are decidable.

The decision technique is based on automata computations, following the
closure properties of Rec\Theta .

3.4.2 The encompassment theory for linear terms
Definition 9. If t 2 T (F; X ) and u 2 T (F), u encompasses t if there is a substitution oe such that toe is a subterm of u. (See figure 3.11.) This binary relation
is denoted t \Delta \Theta u or, seen as a unary relation on ground terms parametrized by
t: \Delta \Theta t(u).

Encompassment plays an important role in rewriting: a term t is reducible
by a term rewriting system R if and only if t encompasses at least one left hand
side of a rule.

The relationship with tree automata is given by the proposition:

Proposition 14. If t is linear, then the set of terms that encompass t is recognized by an NFTA of size O(jtj).

Proof. To each non-variable subterm v of t we associate a state qv. In addition
we have a state q?. The only final state is qt. The transition rules are:

ffl f(q?; : : : ; q?) ! q? for all function symbols.

82 Automata and n-ary relations

ffl f(qt1; : : : ; qtn) ! qf(t1;::: ;tn) if f(t1; : : : ; tn) is a subterm of t and qti is

actually q? is ti is a variable.

ffl f(q? : : : ; q?; qt; q?; : : : ; q?) ! qt for all function symbols f whose arity is

at least 1.

The proof that this automaton indeed recognizes the set of terms that encompass
t is left to the reader.

Note that the automaton may be non deterministic.
Corollary 4. If R is a term rewriting system whose all left members are linear,
then the set of reducible terms in T (F), as well as the set of irreducible terms
in T (F) are recognized by a finite tree automaton.

Proof. This is a consequence of theorem 5.

The theory of reducibility associated with a set of term S ` T (F; X ) is the
set of first-order formulas built on the unary predicate symbols Et, t 2 S and
interpreted as the set of terms encompassing t.

Theorem 23. The reducibility theory associated with a set of linear terms is
decidable.

Proof. By proposition 13, the set of solutions of an atomic formula is recognizable, hence definable in WSkS by lemma 3. Hence, any first-order formula
built on these atomic predicate symbols can be translated into a (second-order)
formula of WSkS which has the same models (up to the coding of terms into
tuples of sets). Then, by theorem 21, the reducibility theory associated with a
set of linear terms is decidable.

Note however that we do not use here the full power of WSkS. Actually,
the solutions of a Boolean combination of atomic formulas are in Rec\Theta . So, we
cannot apply the complexity results for WSkS here. (In fact, the complexity of
the reducibility theory is unknown so far).

Let us simply show an example of an interesting property of rewrite systems
which can be expressed in this theory.

Definition 10. Given a term rewriting system R, a term t is ground reducible
if, for every ground substitution oe, toe is reducible by R.

Note that a term might be irreducible and still ground reducible. For instance consider the alphabet F = f0; sg and the rewrite system R = fs(s(0)) !
0g. Then the term s(s(x) is irreducible by R, but all its ground instances are
reducible.

It turns out that ground reducibility of t is expressible in the encompassment
theory by the formula:

8x:( \Delta \Theta t(x) )

n.

i=1

\Delta \Theta li (x))

If l1; : : : ; ln are the left hand sides of the rewrite system. By theorem 23,
if t; l1; : : : ; ln are linear, then ground reducibility is decidable. Actually, it has
been shown that this problem is EXPTIME-complete, but is beyond the scope
of this book to give the proof.

3.4 Examples of applications 83
3.4.3 The first-order theory of a reduction relation: the

case where no variables are shared

We consider again an application of tree automata to decision problem in logic
and term rewriting.

Consider the following logical theory. Let L be the set of all first-order
formulas using no function symbols and a single binary predicate symbol !.

Given a rewrite system R, interpreting ! as \Gamma !R , yields the theory of one

step rewriting; interpreting ! as \Lambda \Gamma !R yields the theory of rewriting.

Both theories are undecidable for arbitrary R. They become however decidable if we restrict our attention to term rewriting systems in which each variable
occurs at most once. Basically, the reason is given by the following:

Proposition 15. If R is a linear rewrite system such that left and right members of the rules do not share variables, then \Lambda \Gamma !R is recognized by a GTT.

Proof. As in the proof of proposition 14, we can construct in linear time a
(non-deterministic) automaton which accepts the set of instances of a linear
term. For each rule li ! ri we can construct a pair (Ai; A0i) of automata which
respectively recognize the set of instances of li and the set of instances of ri.
Assume that the sets of states of the Ais are pairwise disjoint and that each
Ai has a single final state qif . We may assume a similar property for the A0is:
they do not share states and for each i, the only common state between Ai and
A0i is qif (the final state for both of them). Then A (resp. A0) is the union of
the Ais: the states are the union of all sets of states of the Ais (resp. A0is),
transitions and final states are also unions of the transitions and final states of
each individual automaton.

We claim that (A; A0) defines a GTT whose closure by iteration (A\Lambda ; A0\Lambda )

(which is again a GTT according to theorem 19) accepting \Lambda \Gamma !R . For, assume

first that u p\Gamma \Gamma \Gamma \Gamma !l

i!ri v. Then ujp is an instance lioe of li, hence is accepted in state

qif . vjp is an instance ri` of ri, hence accepted in state qif . Now, v = u[ri`]p,

hence (u; v) is accepted by the GTT (A; A0). It follows that if u \Lambda \Gamma !R v, (u; v) is
accepted by (A\Lambda ; A0\Lambda ).

Conversely, assume that (u; v) is accepted by (A; A0), then

u \Lambda \Gamma !A C[q1; : : : ; qn]p1;::: ;pn \Lambda \Gamma \Gamma A0 v

Moreover, each qi is some state qjf , which, by definition, implies that ujpi is an
instance of lj and vjpi is an instance of rj. Now, since lj and rj do not share

variables, for each i, ujpi \Gamma !R vjpi. Which implies that u \Lambda \Gamma !R v. Now, if (u; v) is

accepted by (A\Lambda ; A0\Lambda ), u can be rewritten in v by the transitive closure of \Lambda \Gamma !R ,
which is \Lambda \Gamma !R itself.

Theorem 24. If R is a linear term rewriting system such that left and right
members of the rules do not share variables, then the first-order theory of rewriting is decidable.

84 Automata and n-ary relations

Proof. By proposition 15, \Lambda \Gamma !R is recognized by a GTT. From proposition 8,

\Lambda \Gamma !
R is in Rec. By lemma 3, there is a WSkS formula whose solutions are exactly
the pairs (s; t) such that s \Lambda \Gamma !R t. Finally, by theorem 21, the first-order theory

of \Lambda \Gamma !R is decidable.

3.4.4 Reduction strategies
So far, we gave examples of first-order theories (or constraint systems) which
can be decided using tree automata techniques. Other examples will be given
in the next two chapters. We give here another example of application in a
different spirit: we are going to show how to decide the existence (and compute) "optimal reduction strategies" in term rewriting systems. Informally, a
reduction sequence is optimal when every redex which is contracted along this
sequence has to be contracted in any reduction sequence yielding a normal form.
For example, if we consider the rewrite system fx . ? ! ?; ? . x ! ?g, there
is no optimal sequential reduction strategy in the above sense since, given an
expression e1 . e2, where e1 and e2 are unevaluated, the strategy should specify which of e1 or e2 has to be evaluated first. However, if we start with e1,
then maybe e2 will reduce to ? and the evaluation step on e1 was unnecessary.
Symmetrically, evaluating e2 first may lead to unnecessary computations. An
interesting question is to give sufficient criteria for a rewrite system to admit
optimal strategies and, in case there is such a strategy, give it explicitly.

The formalization of these notions was given by Huet and L'evy in [HL91]
who introduce the notion of sequentiality. We give briefly a summary of (part
of) their definitions.

F is a fixed alphabet of function symbols and F\Omega  = F [ f\Omega g is the alphabet
F enriched with a new constant \Omega  (whose intended meaning is "unevaluated
term").

We define on T (F\Omega ) the relation "less evaluated than" as:

u v v if and only if either u = \Omega  or else u = f(u1; : : : ; un), v =
f(v1; : : : ; vn) and for all i, ui v vi

Definition 11. A predicate P on T (F\Omega ) is monotonic if u 2 P and u v v
implies v 2 P .

For example, a monotonic predicate of interest for rewriting is the predicate
NR: t 2 NR if and only if there is a term u 2 T (F) such that u is irreducible

by R and t \Lambda \Gamma !R u.

Definition 12. Let P be a monotonic predicate on T (F\Omega ). If R is a term
rewriting system and t 2 T (F\Omega ), a position p of \Omega  in t is an index for P if for
all terms u 2 T F O such that t v u and u 2 P , then ujp 6= \Omega 

In other words: it is necessary to evaluate t at position p in order to have
the predicate P satisfied.

Example 30. Let R = ff(g(x); y) ! g(f(x; y)); f(a; x) ! a; b ! g(b)g.
Then 1 is an index of f(\Omega ; \Omega ) for NR: any reduction yielding a normal form

3.4 Examples of applications 85
without \Omega  will have to evaluate the term at position 1. More formally, every
term f(t1; t2) which can be reduced to a term in T (F) in normal form satisfies
t1 6= \Omega . On the contrary, 2 is not an index of f(\Omega ; \Omega ) since f(a; \Omega ) \Lambda \Gamma !R a.

Definition 13. A monotonic predicate P is sequential if every term t such that:

ffl t =2 P
ffl there is u 2 T (F), t v u and u 2 P
has an index for P .

If NR is sequential, the reduction strategy consisting of reducing an index
is optimal for non-overlapping and left linear rewrite systems.

Now, the relationship with tree automata is given by the following result:

Theorem 25. If P is definable in WSkS, then the sequentiality of P is also
definable in WSkS.

For instance, if R is a rewrite system whose left and right members do
not share variables, then NR is recognizable (by propositions 15 and 8), hence
definable in WSkS by lemma 3 and the sequentiality of R is decidable by theorem
25.

In general, the sequentiality of NR is undecidable. However, one can notice
that, if R and R0 are two rewrite systems such that \Gamma !R ` \Gamma \Gamma !R0 , then a

position p which is an index for R0 is also an index for R. (And thus, R is
sequential whenever R0 is sequential).

For instance, we may approximate the term rewriting system, replacing all
right hand sides by a new variable which does not occur in the corresponding
left member. Let R? be this approximation and N ? be the predicate NR?. (This
is the approximation considered by Huet and L'evy).

Another, refined, approximation consists in renaming all variables of the
right hand sides of the rules in such a way that all right hand sides become
linear and do not share variables with their left hand sides. Let R0 be such an
approximation of R. The predicate N FR0 is written N V .

Proposition 16. If R is left linear, then the predicates N F ? and N V are definable in WSkS and their sequentiality is decidable.

Proof. The approximations R? and R0 satisfy the hypotheses of proposition 15
and hence \Lambda \Gamma \Gamma !R? and \Lambda \Gamma \Gamma !R0 are recognized by GTTs. On the other hand, the

set of terms in normal form for a left linear rewrite system is recognized by a
finite tree automaton (see corollary 4). By proposition 8 and lemma 3, all these
predicates are definable in WSkS. Then N ? and N V are also definable in WSkS.
For instance for NV :

N V (t) def= 9u:t \Lambda \Gamma \Gamma !R0 u ^ N F (u)

Then, by theorem 25, the sequentiality of N ? and N V are definable in WSkS
and by theorem 21 they are decidable.

86 Automata and n-ary relations

3.4.5 Application to higher-order matching
We give here a last application (but the list is not closed!), in the typed lambdacalculus.

To be self-contained, let us first recall some basic definitions in typed lambda
calculus.

The set of types of the simply typed lambda calculus is the least set containing the constant o (basic type) and such that o/ ! o/ 0 is a type whenever o/ and
o/ 0 are types.

Using the so-called Curryfication, any type o/ ! (o/ 0 ! o/ 00) is written o/; o/ 0 !
o/ 00. In this way all non-basic types are of the form o/1; : : : ; o/n ! o with intuitive
meaning that this is the type of functions taking n arguments of respective types
o/1; : : : ; o/n and whose result is a basic type o.

The order of a type o/ is defined by:

ffl O(o) = 1
ffl O(o/1; : : : ; o/n ! o) = 1 + maxfO(o/1); : : : ; O(o/n)g
Given, for each type o/ a set of variables Xo/ of type o/ and a set Co/ of constants
of type o/ , the set of terms (of the simply typed lambda calculus) is the least
set \Lambda  such that:

ffl x 2 Xo/ is a term of type o/
ffl c 2 Co/ is a term of type o/
ffl If x1 2 Xo/1; : : : ; xn 2 Xo/n and t is a term of type o/ , then *x1; : : : xn : t is

a term of type o/1; : : : ; o/n ! o/

ffl If t is a term of type o/1; : : : ; o/n ! o/ and t1; : : : ; tn are terms of respective

types o/1; : : : ; o/n, then t(o/1; : : : ; o/n) is a term of type o/ .

The order of a term t is the order of its type o/ (t).

The set of free variables Var(t) of a term t is defined by:

ffl Var(x) = fxg if x is a variable
ffl Var(c) = ; if c is a constant
ffl Var(*x1 : : : ; xn : t) = Var(t) n fx1; : : : ; xng
ffl Var(t(u1; : : : ; un)) = Var(t) [ Var(t1) [ : : : [ Var(tn)
Terms are always assumed to be in j-long form, i.e. they are assumed to
be in normal form with respect to the rule:

(j) t ! *x1 : : : xn:t(x1; : : : ; xn) if o/ (t) = o/1; : : : o/n ! o/

and xi 2 Xo/i n Var(t) for all i

We define the ff-equivalence =ff on \Lambda  as the least congruence relation such
that: *x1; : : : ; xn : t =ff *x01 : : : ; x0n : t0 when

ffl t0 is the term obtained from t by substituting for every index i, every free

occurrence of xi with x0i.

3.4 Examples of applications 87

ffl There is no subterm of t in which, for some index i, both xi and x0i occur

free.

In the following, we consider only lambda terms modulo ff-equivalence. Then
we may assume that, in any term, a variable x cannot occur twice in a

The fi-reduction is defined on \Lambda  as the least binary relation \Gamma !fi such that

ffl *x1 : : : xn : t(t1; : : : ; tn) \Gamma !fi tfx1t1; : : : ; xntng
ffl for every context C, C[t] \Gamma !fi C[u] whenever t \Gamma !fi u
It is well-known that fij-reduction is terminating and confluent on \Lambda  and,
for every term t 2 \Lambda , we let t # be the unique normal form of t.

A matching problem is an equation s = t where s; t 2 \Lambda  and Var(t) = ;.
A solution of a matching problem is a substitution oe of the free variables of t
such that soe #= t #.

Whether or not the matching problem is decidable is an open question at the
time we write this book. However, it can be decided when every free variable
occurring in s is of order less or equal to 4. We sketch here how tree automata
may help in this matter. We will consider only two special cases here, leaving
the general case as well as details of the proofs as exercises.

First consider a problem

(1) x(s1; : : : ; sn) = t
where x is a third order variable and s1; : : : ; sn; t are terms without free variables.

The first result states that the set of solutions is recognizable by a 2-
automaton. 2-automata are a slight extension of finite tree automata: we
assume here that the alphabet contains a special symbol 2. Then a term u is
accepted by a 2-automaton A if and only if there is a term v which is accepted
(in the usual sense) by A and such that u is obtained from v by replacing each
occurrence of the symbol 2 with a term (of appropriate type). Note that two
distinct occurrences of 2 need not to be replaced with the same term.

We consider the automaton As1;::: ;sn;t defined by: F consists of all symbols
occurring in t plus the variable symbols x1; : : : ; xn whose types are respectively
the types of s1; : : : ; sn and the constant 2.

The set of states Q consists of all subterms of t, which we write qu (instead
of u) and a state q2. In addition, we have the final state qf .

The transition rules \Delta  consist in

ffl The rules

f(qt1; : : : ; qtn) ! qf(t1;::: ;tn)
each time qf(t1;::: ;tn) 2 Q
ffl For i = 1; : : : ; n, the rules

xi(qt1; : : : ; qtn) ! qu
where u is a subterm of t such that si(t1; : : : ; tn) #= u and tj = 2 whenever si(t1; : : : ; tj\Gamma 1; 2; tj+1; : : : ; tn) #= u.

88 Automata and n-ary relations

ffl the rule *x1; : : : ; *xn:qt ! qf
Theorem 26. The set of solutions of (1) (up to ff-conversion) is accepted by
the 2-automaton As1;::: ;sn;t.

More about this result, its proof and its extension to fourth order will be
given in the exercises. Let us simply give an example.

Example 31. Let us consider the interpolation equation

x(*y1*y2:y1; *y3:f(y3; y3)) = f(a; a)
where y1; y2 are assumed to be of base type o. Then F = fa; f; x1; 2og. Q =
fqa; qf(a;a); q2og and the rules of the automaton are:

a ! qa f(qa; qa) ! qf(a;a)
2o ! q2o x1(qa; q2o) ! qa
x1(qf(a;a); q2o) ! qf(a;a) x2(qa) ! qf(a;a)

*x1*x2:qf(a;a) ! qf

For instance the term *x1*x2:x1(x2(x1(x1(a; 2o); 2o)); 2o) is accepted by
the automaton :

*x1*x2:x1(x2(x1(x1(a; 2o); 2o)); 2o) \Lambda \Gamma !A *x1*x2:x1(x2(x1(x1(qa; q2o); q2o)); q2o)

\Gamma !A *x1*x2:x1(x2(x1(qa; q2o)); q2o)
\Gamma !A *x1*x2:x1(x2(qa); q2o)
\Gamma !A *x1*x2:x1(qf(a;a); q2o)
\Gamma !A *x1*x2:qf(a;a)
\Gamma !A qf

And indeed, for every terms t1; t2; t3, *x1*x2:x1(x2(x1(x1(a; t1); t2)); t3) is a
solution of the interpolation problem.

3.5 Exercises
Exercise 25. Let F be the alphabet consisting of finitely many unary function
symbols a1; : : : ; an and a constant 0.

1. Show that the set S of pairs (of words) f(an1 (a1(a2(ap2(0)))); an1 (ap2(0))) j n; p 2

Ng is in Rec. Show that S\Lambda  is not in Rec, hence that Rec is not closed under
transitive closure.

2. More generally, show that, for any finite rewrite system R (on the alphabet F

!), the reduction relation \Gamma !

R is in Rec.

3. Is there any hope to design a class of tree languages which contains Rec, which is

closed by all Boolean operations and by transitive closure and for which emptiness is decidable ? Why ?

3.5 Exercises 89
Exercise 26. Show that the set of pairs f(t; f(t; t0)) j t; t0 2 T (F)g is not in Rec.
Exercise 27. Show that if a binary relation is recognized by a GTT, then its inverse
is also recognized by a GTT.

Exercise 28. Give an example of two relations that are recognized by GTTs and
whose union is not recognized by any GTT.

Similarly, show that the class of relations recognized by a GTT is not closed by
complement. Is the class closed by intersection ?

Exercise 29. Give an example of a n-ary relation such that its ith cylindrification
followed by its ith projection does not give back the original relation. On the contrary,
show that ith projection followed by ith cylindrification gives back the original relation.

Exercise 30. About Rec and bounded delay relations. We assume that F only
contains unary function symbols and a constant, i.e. we consider words rather than
trees and we write u = a1 : : : an instead of u = a1(: : : (an(0)) : : : ). Similarly, u \Delta  v
corresponds to the usual concatenation of words.

A binary relation R on T (F) is called a bounded delay relation if and only if

9k=8(u; v) 2 R; juj \Gamma  jvj ^ k
R preserves the length if and only if

8(u; v) 2 R; juj = jvj
If A, B are two binary relations, we write A \Delta  B (or simply AB) the relation

A \Delta  B def= f(u; v)=9(u1; v1) 2 A; (u2; v2) 2 Bu = u1:u2; v = v1:v2g
Similarly, we write (in this exercise !)

A\Lambda  = f(u; v)=9(u1; v1) 2 A; : : : ; (un; vn) 2 A; u = u1 : : : un; v = v1 : : : vng
1. Given A; B 2 Rec, is A \Delta  B necessary in Rec ? is A\Lambda  necessary in Rec ? Why ?
2. Show that if A 2 Rec preserves the length, then A\Lambda  2 Rec.
3. Show that if A; B 2 Rec and A is of bounded delay, then A \Delta  B 2 Rec.
4. The family of rational relations is the smallest set of subsets of T (F)2 which contains the finite subsets of T (F)2 and which is closed under union, concatenation
(\Delta ) and \Lambda .

Show that, if A is a bounded delay rational relation, then A 2 Rec. Is the
converse true ?

Exercise 31. Let R0 be the rewrite system fx\Theta 0 ! 0; 0\Theta x ! 0g and F = f0; 1; s; \Theta g

1. Construct explicitly the GTT accepting \Lambda \Gamma \Gamma !

R0 .

2. et R1 = R0 [ fx \Theta  1 ! xg. Show that \Lambda \Gamma \Gamma !

R1 is is not recognized by a GTT.

3. Using a construction similar to the transitive closure of GTTs, show that the

set ft 2 T (F) j 9u 2 T (F); t \Lambda \Gamma !R u; u 2 NF g where NF is the set of terms in

normal form for R1 is recognized by a finite tree automaton.

Exercise 32. (*) More generally, prove that given any rewrite system fli ! ri j 1 ^
i ^ ng such that

90 Automata and n-ary relations

1. for all i, li and ri are linear
2. for all i, if x 2 Var(li) " Var(ri), then x occurs at depth at most one in li.

the set ft 2 T (F) j 9u 2 NF; t \Lambda \Gamma !R ug is recognized by finite tree automaton.

What are the consequences of this result ?
(See [Jac96] for details about this results and its applications)

Exercise 33. Show that the set of pairs f(f(t; t0); t) j t; t0 2 T (F)g is not definable
in WSkS.

Exercise 34. Show that the set of pairs of words f(w; w0) j l(w) = l(w0)g, where l(x)
is the length of x, is not definable in WSkS.

Exercise 35. Let F = fa1; : : : ; an; 0g where each ai is unary and 0 is a constant.
Consider the following constraint system: terms are built on F, the binary symbols
"; [, the unary symbol : and set variables. Formulas are conjunctions of inclusion
constraints t ` t0. The formulas are interpreted by assigning to variables finite subsets
of T (F), with the expected meaning for other symbols.

Show that the set of solutions of such constraints is in Rec2. What can we conclude
?

(*) What happens if we remove the condition on the ai's to be unary?

Exercise 36. Complete the proof of proposition 12.
Exercise 37. Show that the subterm relation is not definable in WSkS.

Given a term t Write a WSkS formula OEt such that a term u j= OEt if and only if t
is a subterm of u.

Exercise 38. Define in SkS "X is finite". (Hint: express that every totally ordered
subset of X has an upper bound and use K"onig's lemma)

Exercise 39. Give a direct construction of an automaton recognizing the solutions
of 8X:OE from an automaton recognizing OE (i.e. without computing twice the complement). Show that this operation can be done in simply exponential time and that this
is the best that can be expected.

Exercise 40. (*) Let R be a finite rewrite system whose all left and right members
are ground.

1. Let Termination(x) be the predicate on T (F) which holds true on t when there

is no infinite sequence of reductions starting from t. Show that adding this
predicate as an atomic formula in the first-order theory of rewriting, this theory
remains decidable for ground rewrite systems.

2. Generalize these results to the case where the left members of R are linear and

the right members are ground.

Exercise 41. The complexity of automata recognizing the set of irreducible ground
terms.

1. For each n 2 N, give a linear rewrite system Rn whose size is O(n) and such

that the minimal automaton accepting the set of irreducible ground terms has
a size O(2n).

2. Assume that for any two strict subterms s; t of left hand side(s) of R, if s and t

are unifiable, then s is an instance of t or t is an instance of s. Show that there
is a NFTA A whose size is linear in R and which accepts the set of irreducible
ground terms.

3.5 Exercises 91
Exercise 42. Prove theorem 25.
Exercise 43. The Propositional Linear time Temporal Logic. The logic PTL
is defined as follows:

Syntax P is a finite set of propositional variables. Each symbol of P is a formula (an

atomic formula). If OE and  are formulas, then the following are formulas:

OE ^ ; OE . ; OE ! ; :OE; OEU; NOE; LOE

Semantics Let P \Lambda  be the set of words over the alphabet P . A word w 2 P \Lambda  is

identified with the sequence of letters w(0)w(1) : : : w(jwj \Gamma  1). w(i::j) is the
word w(i) : : : w(j). The satisfaction relation is defined by:

ffl if p 2 P , w j= p if and only if w(0) = p
ffl The interpretation of logical connectives is the usual one
ffl w j= NOE if and only if jwj * 2 and w(1::jwj \Gamma  1) j= OE
ffl w j= LOE if and only if jwj = 1
ffl w j= OEU if and only if there is an index i 2 [0::jwj] such that for all

j 2 [0::i], w(j::jwj \Gamma  1) j= OE and w(i::jwj \Gamma  1) j= .

Let us recall that the language defined by a formula OE is the set of words w such
that w j= OE.

1. What it is the language defined by N(p1Up2) (with p1; p2 2 P ) ?
2. Give PTL formulas defining respectively P \Lambda p1P \Lambda , p\Lambda 1, (p1p2)\Lambda .
3. Give a first-order WS1S formula (i.e. without second-order quantification and

containing only one free second-order variable) which defines the same language
as N(p1Up2)

4. For any PTL formula, give a first-order WS1S formula which defines the same

language.

5. Conversely, show that any language defined by a first-order WS1S formula is

definable by a PTL formula.

Exercise 44. The temporal logic CTL ** To be completed **
Exercise 45. About 3rd-order interpolation problems

1. Prove theorem 26.
2. Show that the size of the automaton As1;::: ;sn;t is O(n \Theta  jtj)
3. Given k automata of the form As1;::: ;sn;t show that their intersection is a finite

union of automata whose size is bounded by (a constant times) the sum of the
sizes of each automaton. (Note that this contrasts with the general case of tree
automata, since intersection requires the product of the sizes of each component
automaton)

4. Deduce from the last question that the existence of a solution to a system of

interpolation equations of the form x(s1; : : : ; sn) = t (where x is a third order
variable in each equation) is in NP. (Note that this contrasts with theorem 11).

Exercise 46. About general third order matching.

1. How is it possible to modify the construction of As1;::: ;sn;t so as to forbid some

symbols of t to occur in the solutions ?

92 Automata and n-ary relations

2. Consider a third order matching problem u = t where t is in normal form and

does not contain any free variable. Let x1; : : : ; xn be the free variables of u and
xi(s1; : : : ; sm) be the subterm of u at position p. Show that, for every solution
oe, either u[2]poe #=ff t or else that xioe(s1oe; : : : ; smoe) # is in the set Sp defined
as follows: v 2 Sp if and only if there is a subterm t0 of t and there are positions
p1; : : : ; pk of t0 and variables z1; : : : ; zk which are bound above p in u such that
v = t0[z1; : : : ; zk]p1;::: ;pk .

3. By guessing the results of xioe(s1oe; : : : ; smoe) and using the previous exercise,

show that general third order matching is in NP.

Exercise 47. About fourth-order matching.

** a completer **

3.6 Bibliographic Notes
3.6.1 Automata and Logic
The development of automata in relation with logic and verification (in the
sixties) is reported in [Tra95]. This research program was explained by A.
Church himself in 1962 [Chu62].

Milestones of the decidability of monadic second-order logic are the papers
[B"uc60] [Rab69].

3.6.2 Surveys
There are numerous surveys on automata and logic. Let us mention some of
them: M.O. Rabin [Rab77] surveys the decidable theories; W. Thomas [?, ?]
provides an excellent survey of relationships between automata and logic. J.-E.
Pin

Concerning applications of tree automata, the reader is also referred to
[Dau94] which reviews a number of applications of Tree automata to rewriting and constraints .

** paragraphe a completer **

3.6.3 ????
GTT were introduced in [DTHL87].

Theorem ?? is proved in [TW68].
For other applications of tree automata in the direction of program verification, see e.g. chapter 5 or e.g. [Jon87].

On the relation between sorts and automata [Com89] (See [CD94] for more
details and proof of more general results).

Concerning encompassment, M. Dauchet et al gave a more general result
(dropping the linearity requirement) in [DCC95]. We will come back to this
result in the next chapter.

About the theory of rewriting, both the theory of one step and the theory
of many steps rewriting are undecidable for arbitrary R [Tre96].

About properties of ground rewrite systems and GTT[DTHL87] [DT90]]
Extensions of the theory, including some function symbols, or other predicate
symbols like the parallel rewriting or the termination predicate (Terminate(t)

3.6 Bibliographic Notes 93
holds if there is no infinite reduction sequence starting from t), or fair termination etc... remain decidable [DT90]. **Mauvaise citation !? See also the
exercises.

Concerning rewriting strategies: [HL91] [Oya93] [Com95] [Jac96] [?]
Concerning higher-order matching: ???
Concerning temporal logics: ??
** a completer [LM93] [?] [Uri92]Chapter 4

Automata with constraints
4.1 Introduction
A typical example of a language which is not recognized by a finite tree automaton is the set of terms ff(t; t) j t 2 T (F)g. The reason is that the two
sons of the root are recognized independently and only a fixed finite amount of
information can be carried up to the root position, whereas t could be arbitrarily large. Therefore, as seen in the application section of the previous chapter,
this imposes some linearity conditions. (Typically when automata techniques
are applied to rewrite systems or to sort constraints). The shift from linear to
non linear situations can also be seen as a generalization from tree automata
to DAG (directed acyclic graphs) automata. This is the purpose of the present
chapter: how is it possible to extend the definitions of tree automata in order to
extend the applications of the previous chapter to (some) non-linear situations
?

Such an extension has been studied in the early 80s by M. Dauchet and J.
Mongy. They define a class of automata which (when working in a top-down
fashion) allows duplications. Considering bottom-up automata, this amounts to
check equalities between subtrees. This yields the RATEG class . Unfortunately,
this class is not closed under complement. If we consider its closure, we get the
class of automata with equality and disequality constraints. This class is studied
in section 4.2.

Unfortunately, the emptiness problem is undecidable for the class RATEG
(and hence for automata with equality and disequality constraints).

Several decidable subclasses have been studied in the literature. The most
remarkable ones are

ffl The class of automata with constraints between brothers which, roughly

allows for equality (or disequality) tests only between positions which have
the same ancestors. For instance, the set of terms f(t; t) is recognized by
such an automaton. This class is interesting because all properties of
tree automata carry over this extension and hence most applications of
tree automata can be extended, replacing linearity conditions with such
restrictions on non-linearities.

We study this class in section 4.3.

96 Automata with constraints

ffl The class of reduction automata which, roughly, allow arbitrary disequality

constraints but only finitely many equality constraints on each run of the
automaton. For instance the set of terms f(t; t) also belongs to this class.
Though closure properties have to be handled with care (with the definition sketched above, the class is not closed by complement), reduction
automata are interesting because for example the set of irreducible terms
(w.r.t. an arbitrary, possibly non-linear) rewrite system is recognized by
an automaton of the class. Then the decidability of ground reducibility
is a direct consequence of emptiness decidability for reduction automata.
There is also a logical counterpart: the encompassment theory already
studied in the linear case in the previous chapter and which can be shown
decidable in the general case using a similar technique.

Reduction automata are studied in section 4.4.

We also consider in this chapter automata with arithmetic constraints. They
naturally appear when some function symbols are assumed to be associative and
commutative (AC). In such a situation, the sons of an AC symbol can be permuted and the relevant information is then the number of occurrences of the
same subtree in the multisets of sons. These integer variables (number of occurrences) are subject to arithmetic constraints which must belong to a decidable
fragment of arithmetic in order to keep closure and decidability properties.

4.2 Automata with equality and disequality constraints

4.2.1 The most general class
An equality constraint (resp. a disequality constraint) is a predicate on T (F)
written ss = ss0 (resp. ss 6= ss0) where ss; ss0 2 f1; : : : ; kg\Lambda . Such a predicate is
satisfied on a term t, which we write t j= ss = ss0, if ss; ss0 2 Pos(t) and tjss = tjss0
(resp. ss = ss0 is not satisfied on t).

An automaton with equality and disequality constraints is a tuple (F; Q; Qf; T )
where F is a finite ranked alphabet, Q is a finite set of states, Qf is a subset of
Q of finite states and T is a set of transition rules of of the form

f(q1; : : : ; qn) c\Gamma ! q

where f 2 F, q1; : : : ; qn:q 2 Q, c is a Boolean combination of equality constraints.

The satisfaction relation j= is extended as usual to any Boolean combination
of equality and disequality constraints.

We will write for short AWEDC the class of automata with equality and
disequality constraints.

An automaton A 2 AW EDC accepts (or recognizes a term t 2 T (F) if there
is a mapping ae from Pos(t) into T (called a run) such that:

ffl ae(\Lambda ) 2 Qf

ffl if t(p) = f and ae(p) = q, then there is a transition rule f(q1; : : : ; qn) c\Gamma ! q

in T such that for all 1 ^ i ^ n, ae(pi) = qi and tjp j= c.

4.2 Automata with equality and disequality constraints 97

Note that we do not have here exactly the same definition of a run as in
chapter 1: instead of the state, we keep also the rule which yielded this state.
This will be useful in emptiness decision for non-deterministic automata.

The language accepted (or recognized) by an automaton A 2 AW EDC is the
set of terms t 2 T (F) that are accepted by A.

Example 32. Balanced complete binary trees over the alphabet f (binary) and
a (constant) are recognized by the automaton (fqg; fqg; \Delta ) where \Delta  consists of
the following rules:

a ! q
f(q; q) 1=2\Gamma \Gamma ! q

For example, t = f(f(a; a); f(a; a)) is accepted since the mapping which associates q to every position of t is a successful run: for every position p of t such
that t(p) = f, tjp\Delta 1 = tp\Delta 2, hence tjp j= 1 = 2.

Example 33.

Consider the following automaton: F = f0; s; fg where 0 is a constant, s is
unary and f has arity 4. Q = fqn; q0; qf g, Qf = fqf g

0 ! q0 s(q0) ! qn
s(qn) ! qn f(q0; q0; qn; qn) 3=4\Gamma \Gamma ! qf

f(q0; q0; q0; q0) ! qf f(q0; qn; q0; qn) 2=4\Gamma \Gamma ! qf
f(qf ; qn; qn; qn) 14=4^21=12^131=3\Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma ! qf

This automaton computes the sum of two natural numbers written in base
one in the following sense: if t is accepted by A then t = f(t1; sn(0); sm(0); sn+m(0))
for some t1 and n; m * 0. Conversely, if for each n; m * 0, there is a term
f(t1; sn(0); sm(0); sn+m(0)) which is accepted by the automaton.

For instance the term depicted on figure 4.1 is accepted by the automaton.
Similarly, it is possible to design an automaton of the class AWEDC which
"computes the multiplication" (see exercises)

In order to consider the complexity of operations on automata of the class
AWEDC, we have to precise a representation of the automata and estimate the
space which is necessary for this representation.

If c is a Boolean combination of equality and disequality constraints, its size
is defined by induction:

ffl jss = ss0j def= jss 6= ss0j def= jssj + jss0j
ffl jc ^ c0j def= jc . c0j def= jcj + jc0j + 1
ffl j:cj def= jcj + 1

98 Automata with constraints

s
s
s

f
f
f s

s

s
s

s
s

s
s
s

ss
sss

s0 0 0
0

0

0 0

0

0

0

Figure 4.1: A computation of the sum of two natural numbers
Now, deciding whether t j= c depends on the representation of t. If t is
represented as a directed acyclic graph (a DAG) with maximal sharing, then this
can be decided in O(jcj) on a RAM. Otherwise, it requires to compute first this
representation of t, and hence can be computed in time at most O(jtj log jtj+jcj).

From now on, we assume, for complexity analysis, that the terms are represented with maximal sharing in such a way that checking an equality or a
disequality constraint on t can be completed in a time which is independent of
jtj.

The size of an automaton A 2 AW EDC is

jAj def= jQj + X

f(q1;::: ;qn)

c\Gamma ! q2T

n + 2 + jcj

An automaton A in AWEDC is deterministic if for every t 2 T (F), there
is at most one state q such that t \Lambda \Gamma !A q. It is completely specified if for every

t 2 T (F) there is at least one state q such that t \Lambda \Gamma !A q.

When every constraint is a tautology, then our definition of automata reduces to the definition of chapter 1. However, in such a case, the notions of
determinacy do not fully coincide, as noticed in chapter 1, page 18.

Proposition 17. Given t 2 T (F) and A 2 AW EDC, deciding whether t 2 A
can be completed in polynomial time (linear time for a deterministic automaton).

Proof. Because of the DAG representation, the satisfaction of a constraint ss =
ss0 on t can be completed in time O(jssj + jss0j).

4.2 Automata with equality and disequality constraints 99
4.2.2 Reducing non-determinism and closure properties
Proposition 18. For every automaton A 2 AW EDC, there is a completely
specified automaton A0 which accepts the same language as A. The computation of A0 can be performed in polynomial time (for a fixed alphabet). If A is
deterministic, then A0 is deterministic.

Proof. The proof is the same as in 2: we add a trash state and every transition
is possible to the trash state. However, this does not keep the determinism
of the automaton. We need a more careful computation in order to keep the
determinism.

We also add a single trash state q?. The additional transitions are computed
as follows: for each function symbol f 2 F and each tuple of states (including
the trash state) q1; : : : ; qn, if there is no transition f(q1; : : : ; qn) c\Gamma ! q 2 T , then

we simply add the rule f(q1; : : : ; qn) ! q?. Otherwise, let f(q1; : : : ; qn) c

i\Gamma ! qi

(i = 1; ::m) be all rules in T whose left member is f(q1; : : : ; qn). We add the
rules f(q1; : : : ; qn) c

0\Gamma ! q

? where c0 def= :

m.

i=1

ci.

Proposition 19. For every automaton A 2 AW EDC, there is a deterministic automaton A0 which accepts the same language as A. Moreover, if A is
completely specified, then A0 is completely specified. A0 can be computed in
exponential time.

Proof. The construction is the same as in theorem 4: states of A0 are sets of
states of A. Final states of A0 are those which contain at least one final state
of A. The only difference is the computation of the constraint: if S1; : : : ; Sn; S
are sets of states, in the deterministic automaton, the rule f(S1; : : : ; Sn) c\Gamma ! S

is labeled by a constraint c defined by:

( ^

q2S .q

i2Si;f(q1;::: ;qn)

cr\Gamma ! q2\Delta 

cr) ^ ( ^

q =2S ^qi2Si;f(q1;::: ;qn) cr\Gamma ! q2\Delta 

:cr)

Let us prove that t is accepted by A in state q1; : : : ; qk (and no other states) if
and only if there t is accepted by A0 in the state fq1; : : : ; qkg:

) Assume t n\Gamma !A qi (i = 1; : : : ; k). We prove, by induction on n, that

t n\Gamma \Gamma !A0 fq1; : : : ; qkg:
If n = 1, then t is a constant and t ! S is a rule of A0 where S =
fq j a \Gamma !A qg.

Assume now n ? 1. Let for each i = 1; ::k,

t = f(t1; : : : ; tp) m\Gamma !A f(qi1; : : : ; qip) \Gamma !A qi

and f(qi1; : : : ; qip) c

i\Gamma ! qi be a rule of A such that t j= ci. By induction

hypothesis, each term tj is accepted by A0 in Sj = fq1j ; : : : ; qkj g[S0j. Moreover, by definition of S = fq1; : : : ; qkg, for every rule f(q001 ; : : : ; q00p) c

00\Gamma ! q00

100 Automata with constraints

in A such that q00 =2 S and for every j, qj 2 Sj, t 6j= c00. Then t satisfies
the above defined constraint c.

( Assume t n\Gamma \Gamma !A0 S. We prove by induction on n that, for every q 2 S, t n\Gamma !A q.

If n = 1, then S is the set of states q such that t \Gamma !A q, hence the property.
Assume now that

t = f(t1; : : : ; tp) n\Gamma \Gamma !A0 f(S1; : : : ; Sp) \Gamma \Gamma !A0 S:

Let f(S1; : : : ; Sp) c\Gamma ! S be the last rule used in this reduction. Then
t j= c and, by definition of c, for every state q 2 S, there is a rule
f(q1; : : : ; qn) c

r\Gamma ! q 2 \Delta  such that qi 2 Si and t j= cr. Now, by induction hypothesis, for each i, ti m

i\Gamma \Gamma !

A0 Si implies ti

mi\Gamma \Gamma !

A qi and hence
t n\Gamma !A f(q1; : : : ; qp) \Gamma !A q.

Now, we have to prove that A0 is deterministic indeed. Assume that t A

0\Gamma \Gamma !

S
and t A

0\Gamma \Gamma !

S

0. Assume moreover that S 6= S0 and that t is the smallest term

(in size) with the property of being recognized in two different states. Then
t \Lambda \Gamma \Gamma !A0 f(S1; : : : ; Sn) and f(S1; : : : ; Sn) A

0\Gamma \Gamma ! S and f(S

1; : : : ; Sn)

A0\Gamma \Gamma ! S0. By

symmetry, we may assume that there is a q 2 S such that q =2 S0. Then, by
definition, there is a rule f(q1; : : : ; qn) c

r\Gamma ! q 2 \Delta  such that t j= cr and qi 2 Si

and there is no rule f(q1; : : : ; qn) c

0
r\Gamma ! q such that t j= c0

r.

Example 34. Consider the following automaton on the alphabet F = fa; fg
where a is a constant and f is a binary symbol: Q = fq; q?g, Qf = fqg and \Delta 
contains the following rules:

a ! q f(q; q) 1=2\Gamma \Gamma ! q f(q; q) ! q?
f(q?; q) ! q? f(q; q?) ! q? f(q?; q?) ! q?

This is the completely specified version of the automaton of example 32.

Then the deterministic automaton computed as in the previous proposition

4.2 Automata with equality and disequality constraints 101
is given by:

a ! fqg f(fqg; fqg) 1=2^?\Gamma \Gamma \Gamma \Gamma \Gamma ! fqg
f(fqg; fqg) 1=2\Gamma \Gamma ! fq; q?g f(fqg; fqg) 16=2\Gamma \Gamma ! fq?g

f(fqg; fq?g) ! fq?g f(fq?g; fqg) ! fq?g
f(fq?g; fq?g) ! fq?g f(fq; q?g; fqg) 1=2^?\Gamma \Gamma \Gamma \Gamma \Gamma ! fqg

f(fq; q?g; fqg) 1=2\Gamma \Gamma ! fq; q?g f(fq; q?g; fq?g) \Gamma ! fq?g
f(fq; q?g; fq; q?g) 1=2\Gamma \Gamma ! fq; q?g f(fq; q?g; fqg) 16=2\Gamma \Gamma ! fq?g

f(fqg; fq; q?g) 1=2\Gamma \Gamma ! fq; q?g f(fqg; fq; q?g) 16=2\Gamma \Gamma ! fq?g

f(fq; q?g; fqg) 16=2\Gamma \Gamma ! fq?g f(fqg; fq; q?g) 1=2^?\Gamma \Gamma \Gamma \Gamma \Gamma ! fqg
f(fq; q?g; fq; q?g) 1=2^?\Gamma \Gamma \Gamma \Gamma \Gamma ! fqg f(fq?g; fq; q?g) \Gamma ! fq?g

For instance, the constraint 1 = 2^ ? is obtained by the conjunction of the label
of f(q; q) 1=2\Gamma \Gamma ! q and the negation of the constraint labelling f(q; q) \Gamma ! q?,
(which is ?).

Some of the constraints, such as 1 = 2^ ? are unsatisfiable, hence the
corresponding rules can be removed. If we finally rename the two accepting
states fqg and fq; q?g into a single state qf (this is possible since all replacing
one of these states by the other in any left hand side of a transition rule, we get
another transition rule), then we get a simplified version of the deterministic
automaton:

a ! qf f(qf ; qf ) 1=2\Gamma \Gamma ! qf
f(qf ; qf) 16=2\Gamma \Gamma ! q? f(q?; qf) ! q?

f(qf ; q?) ! q? f(q?; q?) ! q?

Proposition 20. The class AWEDC is effectively closed by all Boolean operations. Union requires linear time, intersection requires quadratic time and
complement requires exponential time.

Proof. The proof of this proposition can be obtained from the proof of theorem 5 (chapter 1, pages 23-24) with straightforward modifications. The only
difference lies in the product automaton: we have to consider conjunctions of

constraints. More precisely, if f(q1; : : : ; qn) c\Gamma !A q and f(q01; : : : ; q0n) c

0\Gamma \Gamma !

A0 q

0,

then f((q1; q01); : : : ; (qn; q0n)) c^c

0\Gamma \Gamma \Gamma \Gamma !

A\Theta A0 (q; q

0).

4.2.3 Undecidability of emptiness
Theorem 27. The emptiness problem for AWEDC is undecidable.
Proof. We reduce the Post Correspondence Problem (PCP). If w1; : : : ; wn and
w01; : : : ; w0n are the word sequences of the PCP problem over the alphabet fa; bg,
we let F contain h (ternary), a; b (unary) and 0 (constant).

102 Automata with constraints

If w 2 fa; bg\Lambda , w = a1 : : : ak and t 2 T (F), we write w(t) the term a1(: : : (ak(t)) : : : ) 2
T (F)

Now, we construct A = (F; Q; Qf ; T ) 2 AW EDC as follows:

ffl Q contains a state for each prefix of one of the words wi; w0i as well as 3

extra states: q0, q and qf . Qf = fqf g.

ffl T contains the following rules:

a(q0) ! qa a(qwi) ! qa

b(q0) ! qb b(qwi) ! qb
b(qw0i) ! qb a(qw0i) ! qa

b(qp) ! qb\Delta p a(qp) ! qa\Delta p

for every word wi; w0i and for every prefix p of one of the words wi; w0i such
that a \Delta  p (resp. b \Delta  p) is also a prefix of one of the wi; w0i. T also contains
the rules:

h(qwi; q; qw0i) 1\Delta 1

jwij=2\Delta 1^3\Delta 1jw0ij=2\Delta 3\Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma ! q

h(q0; q0; q0) ! q
h(qwi; q; qw0i) 1\Delta 1

jwij=2\Delta 1^3\Delta 1jw0ij^1=3\Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma ! q

f

0 ! q0

The rule with left member h(q0; q0; q0) constructs the beginning of a Post
sequence. The rules with left members h(qwi; q:qw0i) ensure that we indeed
construct a successor in the PCP sequences: the constraint expresses that the
subterm at position 1 is obtained by concatenating some wi with the term at
position 2 \Delta  1 and that the subterm at position 3 is obtained by concatenating
w0i (with the same index i) with the subterm at position 2 \Delta  3. Finally, entering
the final state is subject to the additional constraint 1 = 3. This last constraint
expresses that we succeeded in constructing two identical words with the wi
sequences and the w0i sequences respectively. (See figure 4.2).

The details that this automaton indeed accepts the solutions of the PCP are
left to the reader.

Then the language accepted by A is empty if and only if the PCP has a
solution. Since PCP is undecidable, emptiness of A is also undecidable.

4.3 Automata with constraints between brothers

The negative results of the previous section led to look for subclasses which have
the desired closure properties, contain (properly) the classical tree automata and
still keep the decidability of emptiness. This is the purpose of the class AWCBB:

An automaton A 2 AW EDC is an automaton with constraints between
brothers if every equality (resp disequality) constraint has the form i = j (resp.
i 6= j) where i; j 2 N+.

AWCBB is the set automata with constraints between brothers.

4.3 Automata with constraints between brothers 103

h
hw w

\Delta \Delta 

\Delta 

h

h
wi w0i

v v0

v v0\Delta 

\Delta \Delta 

h

0 00

Figure 4.2: An automaton in AWEDC accepting the solutions of PCP

104 Automata with constraints

Example 35. The set of terms ff(t; t) j t 2 T (F)g is accepted by an automaton
of the class AWCBB.

4.3.1 Closure properties
Proposition 21. AWCBB is a stable subclass of AWEDC w.r.t. Boolean operations (union, intersection, complementation).

Proof. It is sufficient to check that the constructions of proposition 20 preserve
the property of being a member of AWCBB.

Note that the complexity of each such construction is the same as in the
unconstrained case: union and intersection are polynomial, complementation
requires determinization and is exponential.

4.3.2 Emptiness decision
To decide emptiness we would like to design for instance a "cleaning algorithm"
as in theorem 10. As in this result, the correctness and completeness of the
marking technique relies on a pumping lemma. Is there an analog of lemma 1
in the case of automata of the class AWCBB ?

There are additional difficulties. For instance consider the following example.

Example 36. A contains only one state and the rules

a ! q f(q; q) 16=2\Gamma \Gamma ! q

b ! q

Now consider the term f(f(a; b); b) which is accepted by the automaton. f(a; b)
and b yield the same state q. Hence, for a classical finite tree automaton, we
may replace f(a; b) with b and still get a term which is accepted by A. This is
not the case here since, replacing f(a; b) with b we get the term f(b; b) which
is not accepted. The reason of this phenomenon is easy to understand: some
constraint which was satisfied before the pumping is no longer valid after the
pumping.

Hence the problem is to preserve the satisfaction of constraints along term
replacements. First, concerning equality constraints, we may see the terms as
DAGs in which each pair of subterms which is checked for equality is considered
as a single subterm referenced in two different ways. Then replacing one of
its occurrences automatically replaces the other occurrences and preserves the
equality constraints. This is what is formalized below.

4.3 Automata with constraints between brothers 105
Preserving the equality constraints Let t be a term accepted by the automaton A. Let ae be a run of the automaton on t. With every position p of t,
we associate the conjunction c(p) of atomic constraints that are checked by ae(p)

and satisfied by t. More precisely: let ae(p) = f(q1; : : : ; qn) c\Gamma ! q. c(p) def= OE(c; p)

where OE is recursively defined by: OE(?; p) def= ?, OE(c1 ^c2; p) def= OE(c1; p)^OE(c2; p)
and OE(c1 . c2; p) = OE(c1; p) if tjp j= c1, OE(c1 . c2; p) = OE(c2; p) otherwise.
tjp j= c(p) by a simple induction.

Now, we define the equivalence relation =t on the set of positions of t as the
least equivalence relation such that:

ffl if i = j 2 c(p), then p \Delta  i =t p \Delta  j
ffl if p =t p0 and p \Delta  ss 2 Pos(t), then p \Delta  ss =t p0 \Delta  ss
Of course, if p =t p0, then tjp = tjp0 (but the converse is not necessarily true).
Also note (and this is a property of the class AWCBB) that p =t p0 implies that
the sizes of p and p0 are the same, hence, if p 6= p0, they are incomparable w.r.t.
the prefix ordering. We can also derive from this remark that each equivalence
class is finite.

Example 37. Consider the automaton whose transition rules are:

r1 : f(q; q) ! q r2 : a ! q
r3 : f(q; q) 1=2\Gamma \Gamma ! qf r4 : b ! q
r5 : f(q; qf ) ! qf r6 : f(qf ; q) ! qf
r7 : f(q; qf ) ! q r8 : f(qf ; q) ! q

Let t = f(b; f(f(f(a; a); f(a; b)); f(f(a; a); f(a; b)))). A possible run of A on t
is

r5(r4; r3(r1(r1(r2; r2); r1(r2; r5)); r8(r3(r2; r2); r1(r2; r5))))
Equivalence classes of positions are:

f\Lambda g; f1g; f2g; f21; 22g; f211; 221g; f212; 222g;
f2111; 2211; 2112; 2212g; f2121; 2221g; f2122; 2222g

Let us recall that a pumping, for finite bottom-up tree automata, is defined
as a pair (u(v(t)); u(vn(t))) where v(t) and t are accepted in the same state. We
consider here a position p (corresponding to the term v(t)) and its equivalence
class [p] modulo =t. The simultaneous replacement on [p] with t in u, written
u[t][p], is defined as the term obtained by successively replacing the subterm at
position p0 with t for each position p0 2 [p]. Since any two positions in [p] are
incomparable, the replacement order is irrelevant. Now, a pumping is a pair
(u[v(t)]p; u[vn(t)][p]) where v(t) and t are accepted in the same state.

Preserving the disequality constraints We have seen on example 36 that,
if t is accepted by the automaton, replacing one of its subterms, say u, with a
term v accepted in the same state as u, does not necessary yield an accepted

106 Automata with constraints

term. However, the idea is now that, if we have sufficiently many such candidates v, at least one of the replacements will keep the satisfaction of disequality
constraints.

This is the purpose of the following lemma which states that minimal accepted terms cannot contain too many subterms accepted in the same state.

Lemma 4. Given any total simplification ordering, a minimal term accepted
by a deterministic automaton in AWCBB contains at most jQj \Theta  N distinct
subterms where N is the maximal arity of a function symbol and jQj is the
number of states of the automaton.

Proof. If ae is a run, let o/ ae be the mapping from positions to states such that
o/ ae(p) is the target state of ae(p).

If t is accepted by the automaton (let ae be a successful run on t) and contains
at least 1 + jQj \Theta  N distinct subterms, then there are at least N + 1 positions
p1; : : : ; pN+1 such that o/ ae(p1) = : : : = o/ ae(pN+1) and tjp1; : : : ; tjpN+1 are distinct. Assume for instance that tjpN+1 is the largest term (in the given total
simplification ordering) among tjp1; : : : tjpN+1. We claim that one of the terms

vi def= t[tjpi][pN+1] (i ^ N ) is accepted by the automaton.

First note that, by determinacy, for each position p 2 [pN+1], ae(p) =
ae(pN+1) = ae(pi). Hence we may define unambiguously the run ae0 by:

ffl ae0(ss) = ae(ss) if ss is not a prefix of any position in [pN+1]
ffl ae0(p \Delta  ss) = ae(pi \Delta  ss) if p 2 [pN+1] and ss 2 Pos(tjpi ).
It remains to show that ae0 is a run, i.e. that the constraints are satisfied.
Concerning equality constraints, this follows the construction of the equivalence
classes (details are left to the reader).

Concerning disequality constraints, we choose i in such a way that all subterms at brother positions w.r.t. pN+1 are distinct from tjpi (this choice is
possible since N is the maximal arity of a function symbol). We get a replacement as depicted on figure 4.3.

Let pN+1 = ss \Delta  k where k 2 N (ss is the position "iimmediately above pN+1).
Every disequality at ss is satisfied by choice of i. Moreover, if p0 2 [pN+1] and
p0 = ss0 \Delta k0 with k0 2 N, then every disequality at ss0 is satisfied since vijss = vijss0 .

Hence we constructed a term which is smaller than t and which is accepted
by the automaton. This yields the lemma.

Theorem 28. Emptiness can be decided in polynomial time for deterministic
automata in AWCBB.

Proof. The basic idea is that, if we have enough distinct terms in states q1; : : : ; qn,
then the transition f(q1; : : : ; qn) c\Gamma ! q is possible. Use a marking algorithm (as

in theorem 3) and keep for each state the terms that are known to be accepted
in this state. It is sufficient to keep at most N terms in each state (N is the
maximal arity of a function symbol) according to lemma 4. More precisely, we
use the following algorithm:

input: AWCBB A = (Q; F; Qf; \Delta )
begin

4.3 Automata with constraints between brothers 107

+ Replacement
pN+1

=

= \Delta  \Delta  \Delta  6= \Delta  \Delta  \Delta  = \Delta  \Delta  \Delta  6= \Delta  \Delta  \Delta 

pN+1

=

= \Delta  \Delta  \Delta  6= \Delta  \Delta  \Delta  = \Delta  \Delta  \Delta  6= \Delta  \Delta  \Delta 

Figure 4.3: Constructing a smaller term accepted by the automaton

- M arked is a mapping which associates each state with a set of
terms accepted in that state.

Set M arked to the function which maps each state to the ;
repeat

Set M arked(q) to M arked(q) [ ftg
where

f 2 Fn, t1 2 M arked(q1); : : : ; tn 2 M arked(qn),
f(q1; : : : ; qn) c\Gamma ! q 2 \Delta ,

t = f(t1; : : : ; tn) and t j= c,
jM arked(q)j ^ N \Gamma  1,
until no term can be added to any M arked(q)
output: true if, for every state qf 2 Qf , M arked(qf ) = ;.
end

For non-deterministic automata, the problem is NP-complete (see the exercises). An exponential algorithm is derived from proposition 19 and theorem
28.

4.3.3 Applications
The main difference between AWCBB and NFTA is the non-closure of AWCBB
under projection and cylindrification. Actually, the shift from automata on trees
to automata on tuples of trees cannot be extended to the class AWCBB.

As long as we are interested in automata recognizing sets of trees, all results
on NFTA (and all applications) can be extended to the class AWCBB (with an
increased complexity). For instance, theorem 22 can be extended to interpretations of sorts as languages accepted by AWCBB. The proposition 14 can be

108 Automata with constraints

easily generalized to the case of non-linear terms in which non-linearities only
occur between brother positions, provided that we replace NFTA with AWCBB.
Theorem 23 can also be generalized to the theory of encompassment w.r.t. nonlinear terms (provided that non-linearities only occur between brother positions). However, we can no longer invoke an embedding into WSkS. The important point is that this theory only requires the weak notion of recognizability
on tuples (Rec\Theta ). Hence we do not need automata on tuples, but only tuples of automata. As an example of application, we get a decision algorithm
for ground reducibility of a term t w.r.t. left hand sides t1; : : : ; tn, provided
that all non-linearities in t; t1; : : : ; tn occur at brother positions: simply compute the automata Ai accepting the terms that encompass ti and check that
L(A) ` L(A1) [ : : : [ L(An).

Finally, the application on reduction strategies does not carry over the case
of non-linear terms because there really need automata on tuples.

4.4 Reduction automata
As we have seen above, the first-order theory of finitely many unary encompassment predicates \Delta \Theta t1; : : : ; \Delta \Theta tn is decidable when non-linearities in the terms ti
are restricted to brother positions. What happens when we drop the restrictions
and consider arbitrary terms t1; : : : ; tn; t ? It turns out that the theory remains
decidable, as we will see. Intuitively, we cannot use the same proof as for theorem 27 because in the automaton accepting the set of terms encompassing t,
we may only check for a bounded number of equalities along each branch. That
is the idea of the next definitions of reduction automata.

4.4.1 Definition and closure properties
A reduction automaton A is a member of AWEDC such that there is an ordering
on the states of A such that,

For each rule f(q1; : : : ; qn) ss

1=ss2^c\Gamma \Gamma \Gamma \Gamma \Gamma \Gamma ! q, q is strictly smaller than

each qi.
In case of an automaton with ffl-transitions q ! q0 we also require q0 to be
not larger than q.

Example 38. Consider the set of terms encompassing f(f(x; y); x). It is
accepted by the following reduction automaton:

a ! qa f(q?; q?) ! qf(x;y)
qa ! q? f(qf(x;y); q?) 11=2\Gamma \Gamma \Gamma ! qf
qf(x;y) ! q? f(q?; qf) ! qf
f(qf ; q?) ! qf

where the final state is qf and qf is minimal in the ordering on states.

This construction can be generalized, along the lines of the proof of proposition 14:

4.4 Reduction automata 109
Proposition 22. The set of terms encompassing a term t is accepted by a deterministic and completely specified reduction automaton.

As usual, we are now interested in closure properties:
Proposition 23. The class of reduction automata is closed under union and
intersection. It is not closed under complementation.

The proof of these properties are left as exercises.
The weak point is the non-closure under complement (it is not possible to
reduce the non-determinism). For instance such a closure property is required if
we follow the straightforward translation of ground reducibility into automata.
We still have a weak version of stability:

Proposition 24. ffl With each reduction automaton, we can associate a

completely specified reduction automaton which accepts the same language.
Moreover, this construction preserves the determinism.

ffl The class of completely specified deterministic reduction automata is closed

under complement.

4.4.2 Emptiness decision
Theorem 29. Emptiness is decidable for the class of reduction automata.

The proof of this result is quite complicated and gives quite high upper
bounds on the complexity (a tower of several exponentials). Hence, we are not
going to reproduce it here. Let us only sketch how it works, in the case of
deterministic reduction automata.

As in section 4.3.2, we have both to preserve equality and disequality constraints.

Concerning equality constraints, we also define an equivalence relation between positions (of equal subtrees). We cannot claim any longer that two equivalent positions do have the same length. However, there some of the properties
of the equivalence classes are preserved: first, they are all finite and their cardinal can be bounded by a number which only depends on the automaton (this
is not true actually for the class AWCBB). Then, we can compute a bound b2
(which only depends on the automaton) such that the difference of the lengths
of two equivalent positions is smaller than b2. As in section 4.3.2, equalities are
not a real problem, as soon as the automaton is deterministic. Indeed, pumping
can then be defined on equivalence classes of positions. If the automaton is not
deterministic, the problem is more difficult since we cannot guarantee that we
reach the same state at two equivalent positions, hence we have to restrict our
attention to some particular runs of the automaton.

Handling disequalities requires more care; the number of distinct subterms
of a minimal accepted term can no longer be bounded by jQj \Theta  N where N is
the maximal number of disequality constraints in a rule. The problem is the
possible "overlap" of disequalities checked by the automaton. As in example
36, a pumping may yield a term which is no longer accepted, since a disequality
checked somewhere in the term is no longer satisfied. In such a case, we say that
the pumping creates an equality. Then, we distinguish two kinds of equalities
created by a pumping: the close equalities and the remote equalities. Roughly,

110 Automata with constraints

Figure 4.4: A close equality is created
p p2

p p1

p

p p p2

p p1
p

p

Figure 4.5: A remote equality is created
an equality created by a pumping (t[v(u)]p; t[u]p) is a pair of positions (ssss1; ssss2)
of t[v(u)]p which was checked for disequality by the run ae at position ss on
t[v(u)]p and such that t[u]pjssss1 = t[u]pjssss2. It is a close equality if ss ^ p ! ssss1
or ss ^ p ! ssss2. Otherwise (p * ssss1 or p * ssss2), it is a remote equality. The
different situations are depicted on figures 4.4 and 4.5.

One possible proof sketch now is

ffl First show that it is sufficient to consider equalities that are created at

positions around which the states are incomparable w.r.t. ?

ffl Next, show that, for a deep enough path, there is at least one pumping

which does not yield a close equality (this makes use of a combinatorial
argument; the bound is an exponential in the maximal size of a constraint).

ffl For remote equalities, pumping is not sufficient. However, if some pumping creates a remote equality indeed, this means that there are "big"equal
terms in t. Then we switch to another branch of the tree, combining pumping in both subtrees to find one (again using a combinatorial argument)
such that no equality is created.

Of course, this is a very sketchy proof. The reader is referred to the bibliography for more information about the proof.

4.5 Tree Automata with Arithmetic Constraints 111
4.4.3 Other decidable questions
The results here are quite difficult to establish. We only mention them for sake
of completeness.

Theorem 30. Finiteness of the language is decidable for the class of reduction
automata.

Corollary 5. Finiteness of the language of ground normal forms is decidable.
Theorem 31. The membership of the language of ground normal forms to the
class of recognizable tree languages is decidable.

4.4.4 Complexity issues and restricted classes
There are two classes of automata with equality and disequality constraints for
which tighter complexity results are known:

ffl For the class of automata containing only disequality constraints, emptiness can be decided in deterministic exponential time.

ffl For the class of deterministic reduction automata for which the constraints

"cannot overlap", emptiness can be decided in polynomial time.

4.4.5 Application to the encompassment theory
Consider the encompassment theory of section 3.4.2: there are unary predicate symbols \Delta \Theta t which are interpreted as the set of terms which encompass t.
However, we accept now non linear terms t as indices.

The relation between this theory and reduction automata is given by the
following proposition, whose proof is left to the reader:

Proposition 25. The set of terms encompassing a term t is recognized by a
deterministic reduction automaton.

This yields the following result:
Theorem 32. The reducibility theory associated with a set of terms is decidable.

And, as in the previous chapter, we have, as an immediate corollary:
Corollary 6. Ground reducibility is decidable.

4.5 Tree Automata with Arithmetic Constraints
Tree automata deal with finite trees which have a width bounded by the maximal arity of the signature but there is no limitation on the depth of the trees.
A natural idea is to relax the restriction on the width of terms by allowing
function of variadic arity. This has been considered by several authors for applications to graph theory, typing in object-oriented languages, temporal logic
and automated deduction. In these applications, variadic functions are set or
multiset constructors in some sense, therefore they enjoy additional properties
like associativity and/or commutativity and several types of tree automata have

112 Automata with constraints

been designed for handling these properties. We describe here a class of tree
automata which recognize terms build with usual function symbols and multiset
constructors. Therefore we no longer deal with terms, but with so-called flat
terms. Equality on these terms is no longer the syntactical identity, but it is
extended by the equality of multisets under permutation of their elements. To
recognize sets of flat terms with automata, we shall use constrained rules where
the constraints are Presburger's arithmetic formulas which set conditions on the
multiplicities of terms in multisets. These automata enjoy similar properties to
NFTA and are used to test completeness of function definitions and inductive
reducibility when associative-commutative functions are involved, provided that
some syntactical restrictions hold.

4.5.1 Flat Trees
The set of function symbols G is composed of F, the set of function symbols
and of M, the set of function symbols for building multisets. For simplicity we
shall assume that there is only one symbol of the latter form, denoted by t and
written as an infix operator. The set of variables is denoted by X . Flat terms
are defined by the following grammar.

n; m ::= 1 j 2 j 3 : : :
s; t ::= x j f(s1; : : : ; sn) j n1:t1 t : : : t np:tp

with x 2 X , n * 0 is the arity of f, p * 1 and Pi=pi=1 ni * 2. Moreover the
inequality ti 6=P tj holds for i 6= j for 1 ^ i; j ! n, where =P is defined as the
smallest congruence such that

ffl x =P x,
ffl f(s1; : : : ; sn) =P f(t1; : : : ; tn) if si =P ti for i = 1; : : : ; n, f 2 F,
ffl n1:s1 t : : : t np:sp =P m1:t1 t : : : t mq:tq if p = q and there is some

permutation oe on f1; : : : ; ng such that si =P toe(i) and ni = moe(i) for
i = 1; : : : ; n.

Example 39. 3:a and 3:a t 2:f(x; b) are flat terms, but 2:a t 1:a t f(x; b) is
not since 2:a and 1:a must be grouped together to make 3:a.

The usual notions on terms can be generalized easily for flat terms. We
recall only what is needed in the following. A flat term is ground if it contains
no variables. The root of a flat term t is defined by

ffl root(x) = x,
ffl root(f(s1; : : : ; sn)) = g,
ffl root(s1 t : : : t sn) = t.
Our notion of subterm is slightly different from the usual one. We say that
s is a subterm of t if and only if

ffl either s and t are identical,

4.5 Tree Automata with Arithmetic Constraints 113

ffl or t = f(s1; : : : ; sn) and s is a subterm of some si,
ffl or t = n1:t1 t : : : t np:tp and s is a subterm of some ti.
For simplicity, we extend t to an operation between flat terms s; t denoting
(any) flat term obtained by regrouping elements of sort F in s and t which
are equivalent modulo =P , leaving the other elements unchanged. For instance
s = 2:a t 1:f(a; a) and t = 3:b t 2:f(a; a) yields s t t = 2:a t 3:b t 3:f(a; a).

4.5.2 Automata with Arithmetic Constraints
There is some regularity in flat terms that is likely to be captured by some class
of automata-like recognizers. For instance, the set of flat terms such that all
integer coefficients occurring in the terms are even, seems to be easily recognizable, since the predicate even(n) can be easily decided. The class of automata
that we describe now has been designed for accepting such sets of ground flat
terms. A f lat tree automaton with arithmetic constraints (NFTAC) over G is
a tuple (QF ; Qt; G; Qf ; \Delta ) where

ffl QF [ Qt is a finite set of states, such that

- QF are the set of states of sort F,
- Qt is the set of states of sort t,
- QF " Qt = ;,

ffl Qf ` QF t Qt is the set of final states,
ffl \Delta  is a set of rules of the form:

- f(q1; : : : ; qn) ! q, for n * 0; f 2 Fn, q of sort F,
- N:q c(N)\Gamma ! q0, where q has sort F, q0 has sort t, and c is a Presburger's

arithmetic formula with the unique free variable N ,

- q1 t q2 ! q3 where q1; q2; q3 have sort t.

Moreover we require that

- q1 t q2 ! q3 is a rule of \Delta  implies that q2 t q1 ! q3 is also a rule of

\Delta ,

- q1 t (q2 t q3) ! q4 is a rule of \Delta  implies that (q1 t q2) t q3 ! q4 is

also a rule of \Delta  where q t q0 denotes any state q00 such that there is
a rule q t q0 ! q00.

These two conditions on \Delta  will ensure that two flat terms equivalent modulo
=P reach the same states.

Example 40. Let F = fa; fg and let A = (QF ; Qt; G; Qf ; \Delta ) where

QF = fqg; Qt = fqtg,
Qf = fqug,

114 Automata with constraints

\Delta  = f a \Gamma ! q

f( ; ) \Gamma ! q

N:q 9n:N=2n\Gamma ! qt
qt t qt \Gamma ! qt
g
where stands for q or qt.

Let A = (QF ; Qt; G; Qf; \Delta ) be a flat tree automaton. The move relation
!A is defined by: let t; t0 2 F (F [ Q; X), then t !A t0 if and only if there is a
context C 2 C(G [ Q) such that t = C[s] and t0 =P C[s0] where

ffl either there is some f(q1; : : : ; qn) ! q0 2 \Delta  and s = f(q1; : : : ; qn), s0 = q0,

ffl or there is some N:q c(N)\Gamma ! q0 2 \Delta  and s = n:q with j= c(n), s0 = q0,
ffl or there is some q1 t q2 ! q3 2 \Delta  and s = q1 t q2, s0 = q3.
\Lambda !A is the reflexive and transitive closure of !A.

Example 41. Using the automaton of the previous example, one has
2:at6:f(a; a)t2:f(a; 2:a) \Lambda !A 2:qt6:f(q; q)t2:f(q; 2:q) \Lambda !A 2:qt6:qt2:f(q; qt) \Lambda !A 2:qt

6:q t 2:q \Lambda !A qt t qt t qt \Lambda !A qt t qt \Lambda !A qt

We can define now semi linear flat languages. Let A = (QF ; Qt; G; Qf ; \Delta )
be a flat tree automaton. A ground flat term t is accepted by A, if there is some
q 2 Qf such that t \Lambda !A q. The flat tree language L(A) accepted by A is the set
of all ground flat terms accepted by A. A set of flat terms is semi linear if there
L = L(A) for some NFTAC A. Two flat tree automata are equivalent if they
recognize the same language.

Example 42. The language of terms accepted by the automaton of example
39 is the set of ground flat terms with root t such that for each subterm n1:s1 t
: : : t np:sp we have that ni is an even number.

Flat tree automata are designed to take into account the =P relation, which
is stated by the next proposition.

Proposition 26. Let s, t, be two flat terms such that s =P t, let A be a flat
tree automaton, then s !A q implies t !A q.

Proof. The proof is by structural induction on s.

Our definition of flat tree automata corresponds to nondeterministic flat
tree automata. We now define deterministic flat tree automata (DFTAC). Let
A = (QF ; Qt; G; Qf; \Delta ) a NFTAC over G.The automaton A is complete if for

each ground flat term t, there a state such that t \Lambda !A q. The automaton A is
deterministic if for each ground flat term t, there is at most one state q such
that t \Lambda !A q. A state q is accessible if there is one ground flat term t such that
t \Lambda !A q. The automaton is reduced if all states are accessible.

4.5 Tree Automata with Arithmetic Constraints 115
4.5.3 Reducing non-determinism
As for usual tree automata, there is an algorithm for computing an equivalent DFTAC from any NFTA which proves that a language recognized by a
NFTAC is also recognized by a DFTAC. The algorithm is similar to the determinization algorithm of the class AWEDC: the ambiguity arising from overlapping constraints is lifted by considering mutually exclusive constraints which
cover the original constraints, and using sets of states allows to get rid of the
non-determinism of rules having the same left-hand side. We simply have to
distinguish between states of QF and states of Qt.

Determinization algorithm
input A a NFTA automaton.
begin

A state [q] of the equivalent DFTA is in 2QF [ 2Qt.
Set QdF = ;, Qdt = ;, Rd = ;.
repeat

for each f of arity n, [q]1; : : : ; [q]n 2 QdF [ Qdt do

let [q] = fq j 9f(q1; : : : ; qn) ! q 2 R with qi 2 [q]i for i =

1; : : : ; ng

in

Set QdF to QdF [ f[q]g
Set Rd to Rd [ ff([q]1; : : : ; [q]n) ! [q]g

endfor
for each [q] 2 QF do
for each [q0] ` fq00 j 9N:q c(N)\Gamma ! q00 2 R with q 2 [q]g do

let C be (Vq2[q] W N:q ci(N)\Gamma ! q00 2 R

q00 2 [q0]

ci)^(Vq62[q] V N:q ci(N)\Gamma ! q00 2 R

q00 2 [q0]

:ci)

in Set Qdt to QdF [ f[q0]g

Set Rd to Rd [ fN:[q] C(N)\Gamma ! [q0]g

endfor
endfor

for each [q]1; [q]2 2 Qqt do

let [q] = fq j 9q1 2 [q]1; q2 2 [q]2; q1 t q2 ! q3 2 Rg
in Set Qdt to QdF [ f[q]g

Set Rd to Rd [ f[q]1 t [q]2 ! [q]g

endfor

116 Automata with constraints

until no rule can be added to R
Set Qdf = f[q] 2 Qd j [q] " Qf 6= ;g,

end
output: Ad = (QdF ; Qdt; F; Qdf ; Rd)
Proposition 27. The previous algorithm terminates and computes a deterministic flat tree automaton equivalent to the initial one.

Proof. The termination is obvious. The proof of the correctness relies on the
following lemma:

Lemma 5. t \Lambda !Ad[q] if and only if t \Lambda !A q for all q 2 [q].

The proof is by structural induction on t and follows the same pattern as
the proof for the class AWEDC.

Therefore we have proved the following theorem.
Theorem 33. (The equivalence between DFTAC and NFTAC). Let L be a semi
linear set of flat terms, then there exists a DFTAC that accepts L.

4.5.4 Closure Properties of Semi linear Flat Languages
Given an automaton A = (Q; G; Qf; \Delta ), it is easy to construct a equivalent
complete automaton. If A is not complete then

ffl add two new trash states qt of sort F and qtt of sort t,
ffl For each f 2 F, q1; : : : ; qn 2 Q[fqt; qtt g, such that there is no rule having

f(q1; : : : ; qn) as left-hand side, then add f(q1; : : : ; qn) ! qt.

ffl For each q of sort F, let c1(N ); : : : ; cm(N ) be the conditions of the rules

N:q c

i(N)\Gamma ! q0.

- If the formula 9N (c1(N ) . : : : . cm(N )) is not equivalent to true,

then add the rule N:q :(c

1.:::.cm)(N)\Gamma ! qt

t .

- If there are some q; q0 of sort t such that there is no rule qtq0 ! x; q",

then add the rules q t q0 ! qtt and q0 t q ! qtt .

- If there is some rule (q1 t q2) t q3 ! qtt (resp. q1 t (q2 t q3) ! qtt ,

add the rule q1 t (q2 t q3) ! qtt (resp. (q1 t q2) t q3 ! qtt ) if it is
missing.

This last step ensures that we build a flat tree automaton, and it is straightforward to see that this automaton is equivalent to the initial one (same proof
as for DFTA). This is stated by the following proposition.

Theorem 34. For each automaton A, there exists a complete equivalent automaton B.

4.5 Tree Automata with Arithmetic Constraints 117
Example 43. The automaton of example 39 is not complete. It can be
completed by adding the states qt; qtt , the rules N:qt N*0\Gamma ! qtt

N:q 9n N=2n+1\Gamma ! q
f( ; ) \Gamma ! qt
where stands for q; qt; qt; qtt if the rule is not already in \Delta .

Theorem 35. The class of semi linear flat languages is closed under union.
Proof. Let L (resp. M ) be a semi linear flat language recognized by A =
(QF ; Qt; G; Qf; \Delta ) (resp. B = (Q0F ; Q0t; G; Q0f ; \Delta 0)), then L [ M is recognized
by C = (QF [ Q0F ; Qt [ Q0t; G; Qf [ Q0f ; \Delta  [ \Delta 0).

Theorem 36. The class of semi linear flat languages is closed under complementation.

Proof. Let A be an automaton recognizing L. Compute a complete automaton
B equivalent to A. Compute a deterministic automaton C equivalent to B using
the determinization algorithm. The automaton C is still complete, and we get an
automaton recognizing the complement of L by exchanging final and non-final
states in C.

From the closure under union and complement, we get the closure under
intersection (a direct construction of an automaton recognizing the intersection
also exists).

Theorem 37. The class of semi linear flat languages is closed under intersection.

4.5.5 Decision of Emptiness
The last important property to state is that the emptiness of the language recognized by a flat tree automaton is decidable. The decision procedure relies
on an algorithm similar to the decision procedure for tree automata combined
to a decision procedure for Presburger's arithmetic. However a straightforward
modification of the algorithm doesn't work. Assume that the automaton contains the rule qt t qt ! q0t and assume that there is some flat term t such that
1:t !A qt. From these two hypothesis, we can not infer that 1:t t 1:t !A q0t
since 1:t t 1:t is not a flat term contrary to 2:t. Therefore the decision procedure involves some combinatorics in order to ensure that we always deal with
correct flat terms. From now on, let A = (QF; Qt; G; Qf; \Delta ) be some given
deterministic flat tree automaton and let M be the number of states of sort t.
First, we need to control the possible infinite number of solutions of Presburger's
conditions.

Proposition 28. There is some computable B such that for each condition
c(N ) of the rules of A, either each integer n validating c is less than B or there
are at least M + 1 integers less than B validating c.

118 Automata with constraints

Proof. First, we check if c(N ) has a finite number of solutions by deciding if
9P : c(N ) ) N ! P is true. If c(N ) has a finite number of solutions, it is
easy to find a bound B1 on these solutions by testing 9n : n ? k ^ c(n) for
k = 1; 2; : : :, and if c(N ) has an infinite number of solutions, one computes the
first M ones by checking j= c(k) for k = 1; 2; : : :. The bound B is the maximum
of B0 and of the maximal values needed to get M solutions for conditions having
an infinite set of solutions.

Now we control the maximal width of terms needed to reach a state.
Proposition 29. The following equivalence holds. t \Lambda !A q if and only if there
is some s such that s \Lambda !A q and for each subterm n1:v1 t : : : np:vp of s, we have
p ^ M and ni ^ B.

Proof. The bound on the coefficients ni is a direct consequence of the previous
proposition. The proof on p is by structural induction on t. The only non-trivial
case is for t = m1:t1 t : : : t mq:tq. Let us assume that t is the term with the
smallest value of q. First we show that q ^ M . Let qti be the states such that
ni:ti !A qti (ni:ti). For j = 1; : : : ; q, let qt[1;::: ;j] be the jth state obtained when

accepting t, i.e. (q1 t q2) t : : : t qj) = qt[1;::: ;j]. Since q ? M , the pigeonhole
principle yields that q[1;:::;j1] = q[1;:::;j2] for some 1 ^ j1 ! j2 ^ q. Therefore
the term t = m1:t1 t : : : t mj1 :tj1 t mj2+1:tj2+1 t : : : mq:tq also reach the state
q which contradicts our hypothesis that q is minimal. Now, we can use the
induction hypothesis to replace each ti by some si reaching the same state and
satisfying the required conditions.

A term s such that for all subterm n1:v1 t : : : np:vp of s, we have p ^ M and
ni ^ B will be called small. We define some extension of the move relation !nA
by:

ffl t !1A q if and only if t !A q,
ffl t !nA q if and only if t \Lambda !A q and

- either t = f(t1; : : : ; tn) and for i = 1; : : : ; n we have ti !n\Gamma 1A qi(ti),
- or t = n1:t1 t : : : t np:tp and for i = 1; : : : ; p, we have ti !n\Gamma 1A qi(ti).

We set Lnq = ft !pA q j p ^ n and t is smallg with the convention L0q = ;
and Lq = S1n=1 Lnq . Using the previous propositions, it is straightforward to
see that there is some t such that t !A q if and only if some s 2 Lq such that
s !A q. The decision algorithm will compute an approximation Rnq of these Lnq
such that Rnq 6= ; if and only if Lnq 6= ;. Some technical definition is needed
first. Let L be a set of flat term, then we define k L kP as the number of distinct
equivalence classes of terms for the =P relation such that one representant of
the class occurs in L. The reader will check easily that the equivalence class of
a flat term for the =P relation is finite.

The decision algorithm is the following one.
begin

for each state q do set R0q to ;.
i=1.
repeat

4.5 Tree Automata with Arithmetic Constraints 119

for each state q do set Riq to Ri\Gamma 1q

if k Riq kP ^ M then

repeat

add to Riq all flat terms t = f(t1; : : : ; tn)
or t = n1:t1 t : : : t np:tp
such that p ^ M ,nj ^ B, tj 2 Ri\Gamma 1q0 for some q0 and t \Gamma ! q.

until no new term can be added or k Riq kP ? M
endif
i=i+1

until 9q 2 Qf such that Riq 6= ; or 8q; Riq = Ri\Gamma 1q

if 9q 2 QF s.t. Riq 6= ;
then return not empty
else return empty endif

end
Proposition 30. The algorithm terminates after n iterations for some n and
Rnq = ; if and only if Lq = ;

Proof. This algorithm terminates since we always deal with finite sets of flat
terms. Moreover either one Riq increases or else all the Riq's are left untouched
in the repeat : : : until loop, therefore the termination condition will be satisfied after n iteration since equivalence classes for =P are finite.

By construction we have Rmq ` Lmq , but we need the following additional
property.

Lemma 6. Rmq = Lmq or Rmq ` Lmq and k Rmq kP ? M

The proof is by induction on m.
Base case m = 0. Obvious from the definitions.
Induction step. We assume that the property is true for m and we prove
that it holds for m + 1.
Either Lmq = ; therefore Rmq = ; and we are done, or Lmq 6= ;, which we assume
form now on.

ffl q has sort F.

- Either there is some rule f(q1; : : : ; qn) ! q such that Rmqi 6= ; for

i = 1; : : : ; n and that for some q0 in q1; : : : ; qn, we have k Rmq0 kP ? M .
Then we can construct at least M + 1 terms t = f(t1; : : : ; t0; : : : ; tn)
where t0 2 Rmq0 , such that t 2 Rm+1q by giving M + 1 non equivalent
values to t0. This yields that k Rm+1q kP ? M .

- Or there is no rule as above, therefore Rm+1q = Lm+1q .

120 Automata with constraints

ffl q has sort t.

For each small term t = n1:t1 t : : : t np:tp such that t 2 Lm+1q , there are
some terms s1; : : : ; sn in Rmqi such that ti !A qi(ti) implies that si !A qi(si).
What we must prove is that k Rmqi kP ? M implies k Rm+1q kP ? M . Since
A is deterministic, we have that s !A q and t !A q0(t) with q 6= q0 implies
s 6=P t. Let S be the set of states occurring in the sequence q1; : : : ; qp.
We prove by induction on the cardinal of S that if there is some qi such
that k Rmqi kP ? M , we can build at least M + 1 terms in Rm+1q otherwise
we build at least one term of Rm+1q .

- Base case. S = fq0g, therefore all the qi are equal to q0. Either

k Rmq0 kP ^ M and we are done or k Rmq0 kP ? M and we know that
there are s1; : : : ; sM+1; : : : pairwise non equivalent terms reaching q0.
Therefore, there are at least CMM+1 * M + 1 different non equivalent
possible terms ni1:si1 t : : : t nip:sip . Moreover each of these terms S
satisfies s !m+1A q, which proves the result.

- Induction case. Let S = S0 [ fq0g where the property is true for S0.

We can assume that k Rmq0 kP ^ M (otherwise all k Rmqi kP are less
than or equal to M ).

Let i1; : : : ; ik be the positions of q0 in q1; : : : ; qn, let j1; : : : ; jl be the
positions of the states different from q0 in q1; : : : ; qn. By induction
hypothesis, there are sj's such that nj1:sj1 t : : :t njl:sjl is a valid flat
term. Since A is deterministic and q0 is different from all element of
S0, we know that si 6=P sj for any i 2 fi1; : : : ; ikg, j 2 fj1; : : : ; jkg.
Therefore, we use the same reasoning as in the previous case to build
at least CkM+1 * M +1 pairwise non equivalent flat terms s = n1:s1 t

: : : t np:sp such that s !m+1A q.

The termination of the algorithm implies that for each m * n, Rmq = Lmq or
Rmq ` Lmq and k Rmq kP ? M . Therefore Lq = ; if and only if Rnq = ;.

The following theorem summarizes the previous results.
Theorem 38. Let A be a DFTAC, then it is decidable whether the language
accepted by A is empty or not.

The reader should see that the property that A deterministic is crucial in
proving the emptiness decision property. Therefore proving the emptiness of the
language recognized by a NFTAC implies to compute an equivalent DF T AC
first. Another point is that the previous algorithm can be easily modified to
compute the set of accessible states of A.

4.6 Exercises
Exercise 48.

1. Show that the automaton A+ of example 33 accepts only terms of the form

f(t1; sn(0); sm(0); sn+m(0))

2. Conversely, show that, for every pair of natural numbers (n; m), there exists a

term t1 such that f(t1; sn(0); sm(0); sn+m(0)) is accepted by A+.

4.6 Exercises 121

3. Construct an automaton A\Theta  of the class AWEDC which has the same properties

as above, replacing + with \Theta 

4. Give a proof that emptiness is decidable for the class AWEDC, reducing Hilbert's

tenth problem.

Exercise 49. Give an automaton of the class AWCBB which accepts the set of terms
t (over the alphabet fa(0); b(0); f(2)g) having a subterm of the form f(u; u). (i.e the
set of terms that are reducible by a rule f(x; x) ! v).

Exercise 50. Show that the emptiness decision is NP-complete for the class AWCBB.
Show that it remains NP-complete even if we assume that each constraint is a conjunction of equalities.

Exercise 51. Show that the class AWCBB is not closed under linear tree homomorphisms. Is it closed under inverse image of such morphisms ?

Exercise 52. Give an example of two automata in AWCBB such that the set of pairs
of terms recognized respectively by the automata is not itself a member of AWCBB.

Exercise 53. Show that the class of (languages recognized by) reduction automata
is closed under intersection and union. Give an example showing that it is not closed
under complement.

Exercise 54. Show that the class of languages recognized by reduction automata is
preserved under linear tree homomorphisms. Show however that this is no longer true
for arbitrary tree homomorphisms.

Exercise 55. Let A be a reduction automaton. We define a ternary relation q w\Gamma ! q0
contained in Q \Theta  N\Lambda  \Theta  Q as follows:

ffl for i 2 N, q i\Gamma ! q0 if and only if there is a rule f(q1; : : : ; qn) c\Gamma !

A q

0 with qi = q

ffl q i\Delta w\Gamma \Gamma ! q0 if and only if there is a state q00 such that q i\Gamma ! q00 and q00 w\Gamma ! q0.
Moreover, we say that a state q 2 Q is a constrained state if there is a rule f(q1; : : : ; qn) c\Gamma !A q
in A such that c is not a valid constraint.

We say that the the constraints of A cannot overlap if, for each rule f(q1; : : : ; qn) c\Gamma ! q

and for each equality (resp. disequality) ss = ss0 of c, there is no strict prefix p of ss
and no constrained state q0 such that q0 p\Gamma ! q.

1. Consider the rewrite system on the alphabet ff(2); g(1); a(0)g whose left members are f(x; g(x)); g(g(x)); f(a; a). Compute a reduction automaton, whose
constraints do not overlap and which accepts the set of irreducible ground terms.

2. Show that emptiness can be decided in polynomial time for reduction automata

whose constraints do not overlap. (Hint: it is similar to the proof of theorem
28.)

3. Show that any language recognized by a reduction automaton whose constraints

do not overlap is an homomorphic image of a language in the class AWCBB.
Give an example showing that the converse is false.

Exercise 56. Prove the proposition 25 along the lines of proposition 14.
Exercise 57. The purpose of this exercise is to give a construction of an automaton
with disequality constraints (no equality constraints) whose emptiness is equivalent to
the ground reducibility of a given term t with respect to a given term rewriting system
R.

122 Automata with constraints

1. Give a direct construction of an automaton with disequality constraints ANF(R)

which accepts the set of irreducible ground terms

2. Show that the class of languages recognized by automata with disequality constraints is closed under intersection. Hence the set of irreducible ground instances of a linear term is recognized by an automaton with disequality constraints.

3. Let ANF(R) = (QNF; QfNF; \Delta NF). We compute ANF;t def= (QNF;t; QfNF;t; \Delta NF;t)

as follows:

ffl QNF;t def= ftoejp j p 2 P os(t)g\Theta QNF where oe ranges over substitutions from

NLV (t) (the set of variables occurring at least twice in t) into QfNF.

ffl For all f(q1; : : : ; qn) c\Gamma ! q 2 \Delta NF, and all u1; : : : ; un 2 ftoejp j p 2 P os(t)g,

\Delta NF;t contains the following rules:

- f([qu1; q1]; : : : ; [qun; qn]) c^c

0\Gamma \Gamma \Gamma ! [q

f(u1;::: ;un); q] if f(u1; : : : ; un) = toe0

and c0 is constructed as sketched below.
- f([qu1; q1]; : : : ; [qun; qn]) c\Gamma ! [qf(u1;::: ;un); q] if [qf(u1;::: ;un); q] 2 QNF;t

and we are not in the first case.
- f([qu1; q1]; : : : ; [qun; qn]) c\Gamma ! [qq; q] in all other cases

c0 is constructed as follows. From f(u1; : : : ; un) we can retrieve the rules applied
at position p in t. Assume that the rule at p checks ss1 6= ss2. This amounts to
check pss1 6= pss2 at the root position of t. Let D be all disequalities pss1 6= pss2
obtained in this way. The non linearity of t implies some equalities: let E be
the set of equalities p1 = p2, for all positions p1; p2 such that tjp1 = tjp2 is a
variable. Now, c0 is the set of disequalities ss 6= ss0 which are not in D and that
can be inferred from D; E using the rules

pp1 6= p2; p = p0 ` p0p1 6= p2
p 6= p0; pp1 = p2 ` p0p1 6= p2

For instance, let t = f(x; f(x; y)) and assume that the automaton ANF contains a rule f(q; q) 16=2\Gamma \Gamma ! q. Then the automaton ANF;t will contain the rule

f([qq; q]; [qf(q;q); q]) 16=2^16=22\Gamma \Gamma \Gamma \Gamma \Gamma \Gamma \Gamma ! q.
The final states are [qu; qf ] where qf 2 QfNF and u is an instance of t.
Prove that ANF;t accepts at least one term if and only if t is not ground reducible
by R.

Exercise 58. Prove theorem 32 along the lines of the proof of theorem 23.
Exercise 59. Show that the algorithm for deciding emptiness of deterministic complete flat tree automaton works for non-deterministic flat tree automata such that for
each state q the number of non-equivalent terms reaching q is 0 or greater than or
equal to 2.

Exercise 60. (Feature tree automata)
Let F be a finite set of feature symbols (or attributes) denoted by f; g; : : : and S be
a set of constructor symbols (or sorts) denoted by A; B; : : : . In this exercise and the
next one, a tree is a rooted directed acyclic graph, a multitree is a tree such that the
nodes are labeled over S and the edges over F. A multitree is either (A; ;) or (A; E)
where E is a finite multiset of pairs (f; t) with f a feature and t a multitree. A feature
tree is a multitree such that the edges outgoing from the same node are labeled by
different features. The + operation takes a multitree t = (A; E), a feature f and a
multitree t0 to build the multitree (A; E [ (f; t0)) denoted by t + ft0.

4.7 Bibliographic notes 123

1. Show that t + f1t1 + f2t2 = t + f2t2 + f1t1 (OI axiom: order independence

axiom) and that the algebra of multitrees is isomorphic to the quotient of the
free term algebra over f+g [ F [ S by OI.

2. A deterministic M-automaton is a triple (A; h; Qf ) where A is an finite f+g [

F [ S-algebra, h : M ! A is a homomorphism, Qf (the final states) is a subset
of the set of the values of sort M. A tree is accepted if and only if h(t) 2 Qf .

(a) Show that a M-automaton can be identified with a bottom-up tree automaton such that all trees equivalent under OI reach the same states.

(b) A feature tree automaton is a M-automaton such that for each sort s (M

or F), for each q the set of the c's of arity 0 interpreted as q in A is finite
or co-finite. Give a feature tree to recognize the set of natural numbers
where n is encoded as (0; fsuc; (0; f: : : ; (0; ;)g)g) with n edges labeled by
suc.

(c) Show that the class of languages accepted by feature tree automata is

closed under boolean operations and that the emptiness of a language
accepted by a feature automaton is decidable.

(d) A non-deterministic feature tree automaton is a tuple (Q; P; h; Qf ) such

that Q is the set of states of sort M, P the set of states of sort F, h is
composed of three functions h1 : S ! 2Q; h2 : F ! 2P and the transition
function + : Q \Theta  P \Theta  Q ! 2Q. Moreover q + p1q1 + p2q2 = q + p2q2 + p1q1
for each q; q1; q2; p1; p2, fs 2 S j p 2 h1(s)g and ff 2 F j p 2 h2(f)g are
finite or co-finite for each p. Show that any non-deterministic feature tree
automaton is equivalent to a deterministic feature tree automaton.

Exercise 61. (Characterization of recognizable flat feature languages)
A flat feature tree is a feature tree of depth 1 where depth is defined by depth((A; ;)) =
0 and depth((A; E)) = 1+maxfdepth(t) j (f; t) 2 Eg Counting constraints are defined
by: C(x) ::= card(' 2 F j j9y:(x'y ^ T yg = n mod m

Sx
C(x) . C(x)
C(x) ^ C(x)
where n; m are integers, S and T finite or co-finite subsets of S, F a finite or co-finite
subset of F and n mod 0 is defined as n. The semantics of the first type of constraint
is: C(x) holds if the number of edges of x going from the root to a node labeled by a
symbol of T is equal to n mod m. The semantics of Sx is: Sx holds if the root of x is
labeled by a symbol of S.

1. Show that the constraints are closed under negation. Show that the following

constraints can be expressed in the constraint language (F is a finite subset of
F, f 2 F , A 2 S): there is one edge labeled f from the root, a given finite
subset of F. There is no edge labeled f from the root, the root is labeled by A.

2. A set L of flat multitrees is counting definable if and only if there some counting

constraint C such that L = fx j C(x) holdsg. Show that a set of flat feature trees
is counting definable if and only if it is recognizable by a feature tree automaton.
hint: identify flat trees with multisets over (F [frootg)\Theta S and + with multiset
union.

4.7 Bibliographic notes
RATEG appeared in Mongy's thesis [Mon81].

124 Automata with constraints

Unfortunately, as shown in [Mon81] the emptiness problem is undecidable
for the class RATEG (and hence for AWEDC). The undecidability can be even
shown for a more restricted class of automata with equality tests between cousins
(see [Tom92]).

The most remarkable subclasses. [BT92, DCC95, CCC+94].
the encompassment theory already studied in the linear case in the previous
chapter and which can be shown decidable in the general case using a similar
technique [DCC95].

[[BT92]] theorem 28
There have been many work dealing with automata where the width of
terms is not bounded. In [Cou89], Courcelle devises an algebraic notion of recognizability and studies the case of equational theories. Then he gives several
equational theories corresponding to several notions of trees like ordered or unordered, ranked or unranked trees and provides the tree automata to accept
these objects. Actually the axioms used for defining these notions are commutativity (for unordered) or associativity (for unranked) and what is needed is to
build tree automata such that all element of the same equivalence class reach
the same state. Trees can be also defined as finite, acyclic rooted ordered graphs
of bounded degree. Courcelle [Cou92] has devised a notion of of recognizable
set of graphs and suggests to devise graph automata for accepting recognizable
graphs of bounded tree width. He gives such automata for trees defined as unbounded, unordered, undirected, unrooted trees (therefore these are not what
we call tree in this book). Actually, he shows that recognizable sets of graphs
are (homomorphic image of) sets of equivalence class of terms, where the equivalence relation is the congruence induced by a set of equational axioms including
associativity-commutativity axiom and identity element. He gives several equivalent notions for recognizability from which he gets the definitions of automata
for accepting recognizable languages.

Feature tree are a generalization of first-order trees introduced for modeling
record structures. A feature tree is a finite tree whose nodes are labelled by
constructor symbols and edges are labelled by feature symbols Niehren and
Podelski [NP93] have studied the algebraic structures of feature trees and have
devised feature tree automata for recognizing sets of feature trees. They have
shown that this class of feature trees enjoy the same properties as regular tree
language and give a characterization of these sets using counting constraints
which are a subset of Presburger's arithmetic formulas. See exercise 60 for more
details.

Chapter 5
Tree Set Automata

5.1 Introduction
"The notion of type expresses the fact that one just cannot apply any operator
to any value. Inferring and checking a program's type is then a proof of partial
correction" quoting Marie-Claude Gaudel. "The main problem in this field is to
be flexible while remaining rigorous, that is to allow polymorphism (a value can
have more than one type) in order to avoid repetitions and write very general
programs while preserving decidability of their correction with respect to types."

On that score, set constraints formalism is a compromise between power of
expression and decidability. This has been the object of active research for a
few years.

Set constraints are relations between sets of terms. For instance, let us define
the natural numbers with 0 and the successor relation denoted by s. Thus, the
constraint

Nat = 0 [ s(Nat) (5.1)
corresponds to this definition. Let us consider the following system:

Nat = 0 [ s(Nat)

List = cons(Nat; List) [ nil
List+ ` List
car(List+) ` s(Nat)

(5.2)

The first constraint defines natural numbers. The second constraint codes the
set of LISP-like lists of natural numbers. The empty list is nil and other lists
are obtained the constructor symbol cons. The last two constraints represent
the set of lists with a non zero first element.

Set constraints are the essence of Set Based Analysis. The basic idea is to
reason about program variables as sets of possible values. Set Based Analysis involves first writing set constraints expressing relationships between sets
of program values, and then solving the system of set constraints. The single approximation is: all dependencies between the values of program variables
are ignored. Techniques developed for Set Based Analysis have been successfully applied in program analysis and type inference and the technique can be
combined with others [HJ92].

126 Tree Set Automata

Set constraints have also been used to define a constraint logic programming
language over sets of ground terms that generalizes ordinary logic programming
over an Herbrand domain [Koz94].

In a more general way, a system of set constraints is a conjunction of positive
constraints of the form exp ` exp01 and negative constraints of the form exp 6`
exp0. Right hand side and left hand side of these inequalities are set expressions.
Set expressions are built with

ffl function symbols: in our example 0, s, cons, nil are function symbols.
ffl operators: union [, intersection ", complement ,
ffl projection symbols: for instance, in the last equation of system (5.2) car

denotes the first component of cons. In the set constraints syntax, this is
written cons\Gamma 1(1).

ffl set variables like Nat or List.
An interpretation assigns to each set variable a set of terms only built with
function symbols. A solution is an interpretation which satisfies the system.
For example, f0; s(0); s(s(0)); : : :g is a solution of Equation (5.1).

In the set constraint formalism, set inclusion and set union express in a
natural way parametric polymorphism: List ` nil [ cons(X; List).

In logic or functional programming, one often use dynamic procedures to
deal with type. In other words, a run-time procedure checks whether or not an
expression is well-typed. This permits maximum programming flexibility at the
potential cost of efficiency and security. Static analysis partially avoids these
drawbacks with type inference and type checking procedures. The information
extracted at compile time is also used for optimization.

Basically, program sources are analyzed at compile time and an ad hoc formalism is used to represent the result of the analysis. For types considered as
sets of values, the set constraints formalism is well suited to represent them and
to express their relations. Numerous inference and type checking algorithms in
logic, functional and imperative programming are based on a resolution procedure for set constraints.

Most of the earliest algorithms consider systems of set constraints with weak
power of expression. More often than not, these set constraints always have a
least solution -- w.r.t. inclusion -- which corresponds to a (tuple of) regular
set of terms. In this case, types are usual sorts. A sort signature defines a
tree automaton (See 3.4.1 for the correspondence between automata and sorts).
Therefore, these methods are closely related and use classical algorithms on
finite tree automata.

In order to obtain a more precise information, it is necessary to enrich the
set constraints vocabulary. In the one hand, with a large vocabulary an analysis
can be accurate and relevant, but on the other hand, solutions are difficult to
obtain.

1exp = exp0 for exp ` exp0 ^ exp0 ` exp.

5.1 Introduction 127

Nonetheless, an essential property must be preserved: the decidability of
satisfiability. There must exists a procedure which determines whether or not a
system of set constraints has solutions. In other words, extracted information
must be sufficient to say whether the objects of an analyzed program have a type.
It is crucial, therefore, to know which classes of set constraints are decidable,
and identifying the complexity of set constraints is of paramount importance.

A second important characteristic to preserve is to represent solutions in a
convenient way. We want to obtain a kind of solved form from which one can
decide whether a system has solutions and one can "compute" them.

In this chapter, we present an automata-based algorithm for solving systems
of positive and negative systems of set constraints where no projection symbol
occurs. We define a new class of automata recognizing sets of (codes of) n-tuples
of tree languages. Given a system of set constraints, there exists an automaton
which recognizes the set of solutions of the system. Therefore properties of our
class of automata directly translate to set constraints.

In order to introduce our automata, we discuss the case of unary symbols,
i.e. the case of strings over finite alphabet. For instance, let us consider the
following constraints over the alphabet composed of two unary symbols a and
b and a constant 0:

Xaa [ Xbb ` X (5.3)

Y ` X

This system of set constraints can be encoded in a formula of the monadic
second order theory of 2 successors named a and b:

8u u 2 X ) (uaa 2 X ^ ubb 2 X)) ^
8u u 2 X ) u 2 Y

We have depicted in Fig 5.1 (a beginning of) an infinite tree which is a model
of the formula. Each node of the tree is labelled with a couple of points. The two
components correspond to sets X and Y . A black point in the first component
means that the current node belongs to X. Conversely, a white point in the
first component means that the current node does not belong to X. Here we
have X = f"; aa; bb; : : :g and Y = f"; bb; : : :g.

Such a tree language is Rabin-recognizable by a tree automaton which must
avoid forbidden patterns depicted in Figure 5.2.

Given a ranked alphabet of unary symbols and one constant and a system
of set constraints over fX1; : : : ; Xng, one can encode a solution with a f0; 1gnvalued infinite tree and the set of solutions is recognized by an infinite tree
automaton. Therefore, decidability of satisfiability of systems of set constraints
can easily be derived from Rabin's Tree Theorem [Rab69] because infinite tree
automata can be considered as an acceptor model for n-tuples of word languages
over finite alphabet2.

2The entire class of Rabin's tree languages is not captured by solutions of set of words
constraints. Set of words constraints define a class of languages which is strictly smaller than
B"uchi tree automata.

128 Tree Set Automata

Figure 5.1: A solution of the set constraint 5.3

?

?
??

?

?

??

Figure 5.2: The set of forbidden patterns

5.1 Introduction 129

We extend this method to set constraints with symbols of arbitrary arity.
Therefore, we define an acceptor model for mappings from T (F), where F is a
ranked alphabet, into a set E = f0; 1gn of labels. Our automata can be viewed
as an extension of infinite tree automata, but we will use weaker acceptance
condition. The acceptance conditions are: the range of a successful run is in
a specified set of accepting set of states. We will prove that we can design an
automaton which recognizes the set of solutions of a system of both positive
and negative set constraints. For instance, let us consider the following system:

Y 6` ? (5.4)
X ` f(Y; , X) [ a (5.5)

where ? stands for the empty set and , stands for the complement symbol.

The underlying structure is different than in the previous example since it is
now the whole set of terms on the alphabet composed of a binary symbol f and
a constant a. Having a representation of this structure in mind is non trivial.
One can imagine a directed graph whose vertices are terms and such that there
exists an edge between each couple of terms in the direct subterm relation (see
figure 5.3).

f(f(a,a),a) f(a,f(a,a))

f(a,a)

f

f f

a

f
f(f(f(a,a),a),a) ... ... ...
Figure 5.3: The (beginning of the) underlying structure for a two letter alphabet
ff(; ); ag.

An automaton have to associate a state with each node following a finite set
of rules. In the case of the example above, states are also couples of? or? .

Each vertex is of infinite out-degree, nonetheless one can define as in the
word case forbidden patterns for incoming vertices such an automaton have to
avoid in order to satisfy Eq. (5.5) (see Fig. 5.4, Pattern ? stands for? or? ).

The acceptance condition is illustrated using Eq. (5.4). Indeed, to describe a
solution of the system of set constraints, the pattern ? must occur somewhere
in a successful "run" of the automaton.

Consequently, decidability of systems of set constraints is a consequence
of decidability of emptiness in our class of automata. Emptiness decidability
is easy for automata without acceptance conditions (the case of positive set
constraints only). The proof is more difficult and technical in the general case
and is not presented here. Moreover, and this is the main advantage of an

130 Tree Set Automata

?
f

???

?
??

f

?

Figure 5.4: Forbidden patterns for (5.5).
automaton-based method, properties of recognizable sets directly translate to
sets of solutions of systems of set constraints. Therefore, we are able to prove
nice properties. For instance, we can prove that a non empty set of solutions
always contain a regular solution. Moreover we can prove the decidability of
existence of finite solutions.

5.2 Definitions and examples
Infinite tree automata are an acceptor model for infinite trees, i.e. for mappings
from A\Lambda  into E where A is a finite alphabet and E is a finite set of labels. We
define and study F-generalized tree set automata which are an acceptor model
for maps from T (F) into E where F is a finite ranked alphabet and E is a finite
set of labels.

5.2.1 Generalized tree sets
Let F be a ranked alphabet and E be a finite set. An E-valued F-generalized
tree set g is a map from T (F) into E. We denote by GE the set of E-valued
F-generalized tree sets.

For the sake of brevity, we do not mention the signature F which strictly
speaking is in order in generalized tree sets. We also use the abbreviation GTS
for generalized tree sets.

Throughout the chapter, if c 2 f0; 1gn, then ci denotes the ith component
of the tuple c.

If we consider the set E = f0; 1gn for some n, a generalized tree set g in
Gf0;1gn can be considered as a n-tuple (L1; : : : ; Ln) of tree languages over the
ranked alphabet F where Li = ft 2 T (F) j g(t)i = 1g.

We will need in the paper the following operations on generalized tree sets.
Let g (resp. g0) be a generalized tree set in GE (resp. GE0). The generalized
tree set g " g0 2 GE\Theta E0 is defined by g " g0(t) = (g(t); g0(t)), for each term t
in T (F). Conversely let g be a generalized tree set in GE\Theta E0 and consider the
projection ss from E \Theta  E0 into the E-component then ss(g) is the generalized
tree set in GE defined by ss(g)(t) = ss(g(t)). Let G ` GE\Theta E0 and G0 ` GE, then
ss(G) = fss(g) j g 2 Gg and ss\Gamma 1(G0) = fg 2 GE\Theta E0 j ss(g) 2 G0g.

5.2.2 Tree Set Automata
A generalized tree set automaton A = (Q; \Delta ; \Omega ) (GTSA) over a finite set
E consist of a finite state set Q, a transition relation \Delta  ` Sp Qp \Theta  Fp \Theta  E \Theta  Q

and a set \Omega  ` 2Q of accepting sets of states.

5.2 Definitions and examples 131

A run of A on a generalized tree set g 2 GE is a map r : T (F) ! Q with :

(r(t1); : : : ; r(tp); f; g(b(t1; : : : ; tp)); r(f(t1; : : : ; tp))) 2 \Delta 
for t1; : : : ; tp 2 T (F) and f 2 Fp. The run r is successful if the range of r is
in \Omega  i.e. r(T (F)) 2 \Omega .

A generalized tree set g 2 GE is accepted by the automaton A if some run
r of A on g is successful. We denote by L(A) the set of E-valued generalized
tree sets accepted by a generalized tree set automaton A over E. A set G ` GE
is recognizable if G = L(A) for some generalized tree set automaton A.

In the following, a rule (q1; : : : ; qp; f; l; q) is also denoted by f(q1; : : : ; qp) l! q.
Consider a term t = f(t1; : : : ; tp) and a rule f(q1; : : : ; qp) l! q, this rule can
be applied in a run r on a generalized tree set g for the term t if r(t1) = q1,
: : : ,r(tp) = qp, t is labeled by l, i.e. g(t) = l. If the rule is applied, then r(t) = q.

A generalized tree set automaton A = (Q; \Delta ; \Omega ) over E is
ffl deterministic if for each tuple (q1; : : : ; qp; f; l) 2 Qp \Theta  Fp \Theta  E there is

at most one state q 2 Q such that (q1; : : :; qp; f; l; q) 2 \Delta .

ffl strongly deterministic if for each tuple (q1; : : : ; qp; f) 2 Qp \Theta  Fp there

is at most one pair (l; q) 2 E \Theta  Q such that (q1; : : : ; qp; f; l; q) 2 \Delta .

ffl complete if for each tuple (q1; : : : ; qp; f; l) 2 Qp \Theta  Fp \Theta  E there is at least

one state q 2 Q such that (q1; : : : ; qp; f; l; q) 2 \Delta .

ffl simple if \Omega  is "subset-closed", that is ! 2 \Omega  ) (8!0 ` ! !0 2 \Omega ).
Successfulness for simple automata just implies some states are not assumed
along a run. For instance, if the accepting set of a GTSA A is \Omega  = 2Q then A
is simple and any run is successful. But, if \Omega  = Q, then A is not simple and
each state must be assumed at least once in a successful run. The definition
of simple automata will be clearer with the relationships with set constraints
and the emptiness property (see Section 5.4). Briefly, positive set constraints
are connected with simple GTSA for which the proof of emptiness decision is
straightforward. Another and equivalent definition for simple GTSA relies on
the acceptance condition : a run r is successful if and only if r(T (F)) ` ! 2 \Omega .

There is in general an infinite number of runs -- and hence an infinite number of GTS -- even in the case of deterministic generalized tree set automata
(see example 44.2). Nonetheless, given a GTS g, there is at most one run on
g in a deterministic generalized tree set automata. But, in the case of strongly
deterministic generalized tree set automata, there is at most one run (see example 44.1) and therefore there is at most one GTS recognized.

Example 44.
Ex. 44.1 Let E = f0; 1g, F = fcons(; ); s(); nil; 0g. Let A = (Q; \Delta ; \Omega ) be

defined by Q = fNat; List; Termg, \Omega  = 2Q, and \Delta  is the following set of
rules: 0 0

! Nat ; s(Nat) 0! Nat ; nil 1! List ;

cons(Nat; List) 1! List ;

cons(q; q0) 0! Term 8(q; q0) 6= (Nat; List) ;

s(q) 0! Term 8q 6= Nat :

132 Tree Set Automata

A is strongly deterministic, simple, and not complete. L(A) is a singleton
set reduced to a generalized tree set g 2 Gf0;1gn. Indeed, there is a unique
run r on a unique generalized tree set g. Run r maps every natural number
on state Nat, every list on state List and the other terms on state Term.
Therefore g maps a natural number on 0, a list on 1 and the other terms on
0. Hence, L(A) is the regular tree language L of Lisp-like lists of natural
numbers.

Ex. 44.2 Let E = f0; 1g, F = fcons(; ); s(); nil; 0g, and let A0 = (Q0; \Delta 0; \Omega 0)

be defined by Q0 = Q, \Omega 0 = \Omega , and

\Delta 0 = \Delta  [ fcons(Nat; List) 0! List; nil 0! Listg:

A0 is deterministic, simple, and not complete, and L(A0) is the set of subsets
of the regular tree language L of Lisp-like lists of natural numbers. Indeed,
successful runs can now be defined on generalized tree sets g such that a
term in L is labeled by 0 or 1.

Ex. 44.3 Let E = f0; 1g2, F = fcons(; ); s(); nil; 0g, and let A = (Q; \Delta ; \Omega )

be defined by Q = fNat; Nat0; List; Termg, \Omega  = 2Q, and \Delta  is the following
set of rules:

0 (0;0)! Nat ; 0 (1;0)! Nat0 ; s(Nat) (0;0)! Nat
s(Nat) (1;0)! Nat0 ; s(Nat0) (0;0)! Nat ; s(Nat0) (1;0)! Nat0

nil (0;1)! List ; cons(Nat0; List) (0;1)! List ;

s(q) (0;0)! Term 8q 6= Nat
cons(q; q0) (0;0)! Term 8(q; q0) 6= (Nat0; List)

A is deterministic, simple, and not complete, and L(A) is the set of 2-tuples
of tree languages (N 0; L0) where N 0 is a subset of the regular tree language
of natural numbers and L0 is the set of Lisp-like lists of natural numbers
over N 0.

Let us remark that the set N 0 may be non-regular. For instance, one can
define a run on a characteristic generalized tree set gp of Lisp-like lists of
prime numbers. The generalized tree set gp is such that gp(t) = (1; 0) when
t is a (code of a) prime number.

In the previous examples, we only consider simple generalized tree set automata. Moreover all runs are successful runs. The following examples are
non-simple generalized tree set automata in order to make clear the interest of
acceptance conditions. For this compare the sets of generalized tree sets obtained in examples 44.3 and 45 and note that with acceptance conditions, we
can express that a set is non empty.

Example 45. Example 44.3 continued

Let E = f0; 1g2, F = fcons; nil; s; 0g, and let A0 = (Q0; \Delta 0; \Omega 0) be defined by
Q0 = Q, \Delta 0 = \Delta , and \Omega 0 = f! 2 2Q j Nat0 2 !g. A0 is deterministic, not simple,
and not complete, and L(A0) is the set of 2-tuples of tree languages (N 0; L0)
where N 0 is a subset of the regular tree language of natural numbers and L0 is

5.2 Definitions and examples 133
the set of Lisp-like lists of natural numbers over N 0, and N 0 6= ;. Indeed, for a
successful r on g, there must be a term t such that r(t) = Nat0 therefore, there
must be a term t labelled by (1; 0), henceforth N 0 6= ;.

5.2.3 Hierarchy of GTSA-recognizable languages
Let us define:

ffl RGTS, the class of languages recognizable by GTSA,
ffl RDGTS, the class of languages recognizable by deterministic GTSA,
ffl RSGTS, the class of languages recognizable by Simple GTSA.
The three classes defined above are proved to be different. They are also
closely related to classes of languages defined from the set constraint theory
point of view.

RGTS
RDGTS

RSGTS

Figure 5.5: Classes of GTSA-recognizable languages
Classes of GTSA-recognizable languages have also different closure properties. We will prove in Section 5.3.1 that RSGTS and the entire class RGTS
are closed under union, intersection, projection and cylindrification; RDGTS is
closed under complementation and intersection.

We propose three examples that illustrate the differences between the three
classes. First, RDGTS is not a subset of RSGTS.

Example 46.

Let us consider the deterministic but non-simple GTSA A1 = (Q1; \Delta 1; \Omega 1)
where \Delta 1 is:

a 0! q0; a 1! q1;
f(q0) 0! q0; f(q1) 0! q0;
f(q0) 1! q1; f(q1) 1! q0:

and \Omega  = ffq0; q1g; fq1gg. Hence

L(A1) = fL j L 6= ;g

134 Tree Set Automata

is not in RSGTS.

Let us suppose that there exists a simple GTSA As with n states such that
L(A1) = L(As). Hence, As recognizes also each one of the singleton sets ffi(a)g
for i in Nat. Let us consider some i greater than n, we can deduce that a run r on
the GTS g associated with ffi(a)g maps two terms fk(a) and fl(a), k ! l ! i
on the same state. We have g(t) = 0 for every term t \Theta  f l(a) and r "loops"
between fk(a) and fl(a). Therefore, one can build another run on a GTS g0
such that g0(t) = 0 for each t 2 T (F). Since As is simple, g0 is recognized,
hence the empty set is recognized which contradicts the hypothesis.

Basically, using simple GTSA it is not possible to enforce a state to be
assumed somewhere by every run. Consequently, it is not possible to express
global properties of generalized tree languages such as non-emptiness.

Second, RSGTS is not a subset of RDGTS.

Example 47. Let us consider the non-deterministic but simple GTSA A2 =
(Q2; \Delta 2; \Omega 2) where \Delta 2 is:

a 0! qf j qg; a 1! qf j qg;
f(qf ) 1! qf j qg; g(qg) 1! qf j qg;
f(qg) 0! qf j qg; g(qf ) 0! qf j qg;

and \Omega  = 2fqf ;qgg. It is easy to prove

L(A2) = fL j 8t f(t) 2 L , g(t) 62 Lg:
The proof that no deterministic GTSA recognizes L(A2) is left to the reader.

We terminate with an example of a non-deterministic and non-simple generalized tree set automaton. This example will be used in the proof of Proposition 34.

Example 48. Let E = f0; 1g, F = ff; ag where a is a constant and f is unary.
Let A = (Q; \Delta ; \Omega ) be defined by Q = fq; q0g, \Omega  = fQg, and \Delta  is the following
set of rules: a 1

! q ; a 1! q0 ; a 0! q0 ; f(q) 1! q ;f(q0) 0

! q0 ; f(q0) 1! q0 ; f(q0) 1! q ;

The proof that A is not deterministic, not simple, and not complete, and
L(A) = fL ` T (F) j 9t 2 T (F) ((t 2 L) ^ (8t0 2 T (F) (t \Theta  t0) ) (t0 2 L)))g is
left as an exercise to the reader.

5.2.4 Regular generalized tree sets, regular runs
As we mentioned it in Example 44.3, the set recognized by a GTSA may contain graphs corresponding to non-regular languages. But regularity is of major

5.2 Definitions and examples 135
interest for practical reasons because it implies a graph or a language to be
finitely defined.

A generalized tree set g 2 GE is regular if there exist a finite set R, a map
ff : T (F) ! R, and a map fi : R ! E satisfying the following two properties.

1. g = fffi (or g = fi ffi ff),
2. ff is closed under contexts, i.e. for all context c and terms t1, t2, we have

(ff(t1) = ff(t2)) ) (ff(c[t1]) = ff(c[t2]))

In the case E = f0; 1gn, regular generalized tree sets will correspond to
n-tuples of regular tree languages.

Although the definition of regularity leads to the definition of regular run --
because a run can be considered as a generalized tree set in GQ, we use stronger
conditions for a run to be regular. Indeed, regularity of generalized tree sets and
regularity of runs do not correspond in general. For instance, one could define
regular runs on non-regular generalized tree sets in the case of non-strongly
deterministic generalized tree set automata, and one could define non-regular
runs on regular generalized tree sets in the case of non-deterministic generalized
tree set automata.

Therefore, we only consider regular runs on regular generalized tree sets:

A run r on a generalized tree set g is regular if r " g 2 GE\Theta Q is
regular. Consequently, r and g are regular generalized tree sets.

Proposition 31. Let A be a generalized tree set automaton, if g is a regular
generalized tree set in L(A) then there exists a regular A-run on g.

Proof. Consider a generalized tree set automaton A = (Q; \Delta ; \Omega ) over E and a
regular generalized tree set g in L(A) and let r be a successful run on g. Let L be
a closed tree language such that F0 ` L and r(L) = r(T (F)). The generalized
tree set g is regular, therefore there exist a finite set R, a mapping ff : T (F) ! R
closed under context and a mapping fi : R ! E such that g = fffi. We now
define a regular run r0 on g.

Let L? = L [ f?g where ? is a new symbol and let OE be the mapping from
T (F) into Q \Theta  R \Theta  L? defined by OE(t) = (r(t); ff(t); u) where u = t if t 2 L and
u = ? otherwise. Hence R0 = OE(T (F)) is a finite set because R0 ` Q \Theta  R \Theta  L?.
For each ae in R0, fix tae 2 T (F) such that OE(tae) = ae.

The run r0 is now (regularly) defined via two mappings ff0 and fi0. Let fi0 be
the projection from Q \Theta  R \Theta  L? into Q and let ff0 : T (F) ! R0 be inductively
defined by :

8a 2 F0 ff0(a) = OE(a);
and

8f 2 Fp8t1; : : : ; tp 2 T (F)

ff0(f(t1; : : :; tp)) = OE(f(tff0(t1); : : : ; tff0(tp))):
Let r0 = ff0fi0. First we can easily prove by induction that 8t 2 L ff0(t) = OE(t)
and deduce that 8t 2 L r0(t) = r(t). Thus r0 and r coincide on L. It remains
to prove that (1) the mapping ff0 is closed under context, (2) r0 is a run on g
and (3) r0 is a successful run.

136 Tree Set Automata

(1) From the definition of ff0 we can easily derive that the mapping ff0 is closed

under context.

(2) We prove that the mapping r0 = ff0fi0 is a run on g, that is if t = f(t1; : : : ; tp)

then (r0(t1); : : : ; r0(tp); f; g(t); r0(t)) 2 \Delta .

Let us consider a term t = f(t1; : : :; tp). From the definitions of ff0, fi0, and r0,
we get r0(t) = r(t0) with t0 = f(tff0(t1); : : : ; tff0(tp)). The map r is a run on g,
hence (r(tff0(t1)); : : : ; r(tff0(tp)); f; g(t0); r(t0)) 2 \Delta , and thus it suffices to prove
that g(t) = g(t0) and, for all i, r0(ti) = r(tff0(ti)).

Let i 2 f1; : : : ; pg, r0(ti) = fi0(ff0(ti)) by definition of r0. By definition of
tff0(ti), ff0(ti) = OE(tff0(ti)), therefore r0(ti) = fi0(OE(tff0(ti))). Now, using the
definitions of OE and fi0, we get r0(ti) = r(tff0(ti)).

In order to prove that g(t) = g(t0), we prove that ff(t) = ff(t0). Let ss be
the projection from R0 into R. We have ff(t0) = ss(OE(t0)) by definition of
OE and ss. We have ff(t0) = ss(ff0(t)) using definitions of t0 and ff0. Now
ff(t0) = ss(OE(tff0(t))) from the definition of tff0(t). And then ff(t0) = ff(tff0(t))
by definition of ss and OE. Therefore it remains to prove that ff(tff0(t)) = ff(t).
The proof is by induction on the structure of terms.

If t 2 F0 then tff0(t) = t, so the property holds (note that this property holds
for all t 2 L). Let us suppose that t = f(t1; : : :; tp) and ff(tff0(ti)) = ff(ti) 8i 2
f1; : : : ; pg. First, using induction hypothesis and closure under context of ff,
we get

ff(f(t1; : : : ; tp)) = ff(f(tff0(t1); : : : ; tff0(tp)))

Therefore,

ff(f(t1; : : : ; tp)) = ff(f(tff0(t1); : : : ; tff0(tp)))

= ss(OE(f(tff0(t1); : : : ; tff0(tp)))) ( def. of OE and ss)
= ss(ff0(f(t1; : : : ; tp))) ( def. of ff0)
= ss(OE(tff0(f(t1;:::;tp)))) ( def. of tff0(f(t1;:::;tp)))
= ff(tff0(f(t1;:::;tp))) ( def. of OE and ss):

(3) We have r0(T (F)) = r0(L) = r(L) = r(T (F)) using the definition of r0, the

definition of L, and the equality r0(L) = r(L). The run r is a successful run.
Consequently r0 is a successful run.

Proposition 32. A non-empty recognizable set of generalized tree sets contains
a regular generalized tree set.

Proof. Let us consider a generalized tree set automaton A and a successful run
r on a generalized tree set g. There exists a closed tree language F such that
r(F ) = r(T (F)). We define a regular run rr on a regular generalized tree set
gg in the following way.

Run rr coincide with r on F : 8t 2 F , rr(t) = r(t) and gg(t) = g(t). Runs
rr and gg are inductively defined on T (F) n F : given q1; : : : ; qp in r(T (F)), fix

5.3 Closure and decision properties 137
a rule f(q1; : : : ; qp) l! q such that q 2 r(T (F)). The rule exists since r is a run.
Therefore, 8t = f(t1; : : :; tp) 62 F such that rr(ti) = qi, we define rr(t) = q and
gg(t) = l following the fixed rule f(q1; : : : ; qp) l! q.

From the preceding, we can also deduce that a finite and recognizable set of
generalized tree sets only contains regular generalized tree sets.

5.3 Closure and decision properties
5.3.1 Closure properties
This section is dedicated to the study of classical closure properties on GTSArecognizable languages. For all positive results -- union, intersection, projection, inverse projection -- the proofs are constructive. We show that the class
of recognizable sets of generalized tree sets is not closed under complementation
and non-determinism cannot be reduced for generalized tree set automata.

Set operations on sets of graphs have to be distinguished from set operations
on sets of terms. In particular, in the case where E = f0; 1gn, if G1 and
G2 are sets of graphs in GE, G1 = (L11; : : : ; L1n) and G2 = (L21; : : : ; L2n), then
G1 [ G2 contains all graphs in G1 and G2. This is clearly different from the set
(L11 [ L21; : : : ; L1n [ L2n).

Proposition 33. The class RGTS is closed under intersection and union, i.e.
if G1, G2 ` GE are recognizable, then G1 [ G2 and G1 " G2 are recognizable.

This proof is an easy modification of the classical proof of closure properties
for automata.

Proof. Let A1 = (Q1; \Delta 1; \Omega 1) and A2 = (Q2; \Delta 2; \Omega 2) be two generalized tree
set automata over E. Without loss of generality we suppose that Q1 " Q2 = ;.

Let A = (Q; \Delta ; \Omega ) with Q = Q1 [ Q2, \Delta  = \Delta 1 [ \Delta 2, and \Omega  = \Omega 1 [ \Omega 2. It is
immediate that L(A) = L(A1) [ L(A2).

We denote by ss1 and ss2 the projections from Q1 \Theta  Q2 into respectively Q1
and Q2. Let A0 = (Q0; \Delta 0; \Omega 0) with Q0 = Q1 \Theta  Q2, \Delta 0 is defined by

(f(q1; : : : ; qp) l! q 2 \Delta 0) , (8i 2 f1; 2g f(ssi(q1); : : : ; ssi(qp)) l! ssi(q) 2 \Delta i) ;

where q1; : : : ; qp; q 2 Q0, f 2 Fp, l 2 E, and \Omega 0 is defined by

\Omega 0 = f! 2 2Q

0 j ss

i(!) 2 \Omega i ; i 2 f1; 2gg:

One can easily verify that L(A0) = L(A1) " L(A2) :

Let us remark that the previous constructions also prove that the class RSGTS
is closed under union and intersection.

The class languages recognizable by deterministic generalized tree set automata is closed under complementation. But, this property is false in the case
of GTSA-recognizable languages.

138 Tree Set Automata

Proposition 34. (a) Let A be a generalized tree set automaton, there exists

a complete generalized tree set automaton Ac such that L(A) = L(Ac).

(b) If Acd is a deterministic and complete generalized tree set automaton, there

exists a generalized tree set automaton A0 such that L(A0) = GE \Gamma  L(Acd).

(c) The class of GTSA-recognizable languages is not closed under complementation.

(d) Non-determinism can not be reduced for generalized tree set automata.
Proof. (a) Let A = (Q; \Delta ; \Omega ) be a generalized tree set automaton over E and let
q0 be a new state, i.e. q0 62 Q. Let Ac = (Qc; \Delta c; \Omega c) be defined by Qc = Q[fq0g,
\Omega c = \Omega , and

\Delta c = \Delta  [ f(q1; : : : ; qp; f; l; q0) j f(q1; : : : ; qp; f; l)g \Theta  Q " \Delta  = ;;

q1; : : : ; qp 2 Qc; f 2 Fp; l 2 Eg:

Ac is complete and L(A) = L(Ac). Note that Ac is simple if A is simple.
(b) Acd = (Q; \Delta ; \Omega ) be a deterministic and complete generalized tree set
automaton over E. The automaton A0 = (Q0; \Delta 0; \Omega 0) with Q0 = Q, \Delta 0 = \Delta ,
and \Omega 0 = 2Q \Gamma  \Omega  recognizes the set GE \Gamma  L(Acd).

(c) E = f0; 1g, F = fc; ag where a is a constant and c is of arity 1. Let
G = fg 2 Gf0;1gn j 9t 2 T (F) ((g(t) = 1) ^ (8t0 2 T (F) (t \Theta  t0) ) (g(t0) = 1)))g.

Clearly, G is recognizable (see Example 48). Let G = Gf0;1gn \Gamma  G, we have
G = fg 2 Gf0;1gn j 8t 2 T (F) 9t0 2 T (F) (t \Theta  t0) ^ (g(t0) = 0)g and G
is not recognizable. Let us suppose that G is recognized by an automaton
A = (Q; \Delta ; \Omega ) with Card(Q) = k \Gamma  2 and let us consider the generalized tree
set g defined by: g(ci(a)) = 0 if i = k \Theta  z for some integer z, and g(ci(a)) = 1
otherwise. The generalized tree set g is in G and we consider a successful
run r on g. We have r(T (F)) = ! 2 \Omega  therefore there exists some integer
n such that r(fg(ci(a)) j i ^ ng) = !. Moreover we can suppose that n is
a multiple of k. As Card(Q) = k \Gamma  2 there are two terms u and v in the set
fci(a) j n + 1 ^ i ^ n + k \Gamma  1g such that r(u) = r(v). Consequently, a
successful run g0 could be defined from g on the generalized tree set g0 defined
by g0(t) = g(t) if t = ci(a) when i ^ n, and g0(t) = 1 otherwise. This leads to a
contradiction because g0 62 G.

(d) This result is a consequence of (b) and (c).

We will now prove the closure under projection and inverse projection. We
will first prove a stronger lemma.

Lemma 7. Let G ` GE1 be a GTSA-recognizable language and let R ` E1\Theta E2.
Let R(G) = fg0 2 GE2 j 9g 2 G 8t 2 T (F) (g(t); g0(t)) 2 Rg.

The set R(G) is recognizable.

Proof. Let A = (Q; \Delta ; \Omega ) such that L(A) = G. Let A0 = (Q0; \Delta 0; \Omega 0) where
Q0 = Q, \Delta 0 = ff(q1; : : :; qp) l

0! q j 9l 2 E

1 f(q1; : : :; qp) l! q 2 \Delta  and (l; l0) 2 Rg

and \Omega 0 = \Omega . We prove that R(G) = L(A0).

5.3 Closure and decision properties 139
' Let g0 2 L(A0) and a successful run r0 on g0. We construct a generalized tree

set g such that (g; g0) 2 R and such that r0 is also a successful A-run on
g.

Let a be a constant. According to the definition of \Delta 0, a g

0(a)! r0(a) 2 \Delta 0

implies that there exists la such that (la; g0(a)) 2 R and a la! r0(a) 2 \Delta .
So let g(a) = la.

Let t = f(t1; : : :; tp) with 8i r0(ti) = qi. There exists a rule f(q1; : : : ; qp) g

0(t)! r0(t)

in \Delta 0 because r0 is a run and again, from the definition of \Delta 0 there exists
lt such that f(q1; : : : ; qp) lt! r0(t) in \Delta  with (lt(t); g0(t)) 2 R. So, we define
lt = g(t). Clearly, g is a generalized tree set and r0 is a successful run on
g.

` Let g0 2 R(G) and let g 2 G such that 8t 2 T (F) (g(t); g0(t)) 2 R. One can

easily prove that any successful A-run on g is also a successful A0-run on
g0.

Corollary 7. (a) The class of GTSA-recognizable languages is closed under

projection and inverse projection.

(b) Let G ` GE and G0 ` GE0 be two GTSA-recognizable languages. The set

G " G0 = fg " g0 j g 2 G; g0 2 G0g is a GTSA-recognizable language in
GE\Theta E0.

Proof. (a) The case of projection is an immediate consequence of Lemma 7

using E1 = E \Theta  E0, E2 = E, and R = ss where ss is the projection from
E \Theta  E0 into E. The case of inverse projection is proved in a similar way.

(b) Consequence of (a) and of Proposition 33 because G " G0 = ss\Gamma 11 (G) "

ss\Gamma 12 (G0) where ss1 (respectively ss2) is the projection from E \Theta  E0 into E
(respectively into E0).
Let us remark that the construction preserves simplicity, so RSGTS is closed
under projection and inverse projection.

We now consider the case E = f0; 1gn and we give two propositions without
proof. Proposition 35 can easily be deduced from Corollary 7. The proof of
Proposition 36 would be an extension of constructions made in Examples 44.1
and 44.2.

Proposition 35. Let A and A0 be two generalized tree set automata over f0; 1gn.

(a) f(L1 [ L01; : : : ; Ln [ L0n) j (L1; : : : ; Ln) 2 L(A) and (L01; : : : ; L0n) 2 L(A0)g

is recognizable.

(b) f(L1 " L01; : : : ; Ln " L0n) j (L1; : : : ; Ln) 2 L(A) and (L01; : : : ; L0n) 2 L(A0)g

is recognizable.

(c) f(L1; : : : ; Ln) j (L1; : : :; Ln) 2 L(A)g is recognizable, where Li = T (F) \Gamma 

Li, 8i.

140 Tree Set Automata

Proposition 36. Let E = f0; 1gn and let (F1; : : : ; Fn) be a n-tuple of regular
tree languages. There exist deterministic simple generalized tree set automata
A , A0, and A00 such that

ffl L(A) = f(F1; : : : ; Fn)g;
ffl L(A0) = f(L1; : : : ; Ln) j L1 ` F1; : : : ; Ln ` Fng;
ffl L(A00) = f(L1; : : : ; Ln) j F1 ` L1; : : : ; Fn ` Lng.

5.3.2 Emptiness property
Theorem 39. The emptiness property is decidable in the class of generalized
tree set automata. Given a generalized tree set automaton A, it is decidable
whether L(A) = ;.

Labels of the generalized tree sets are meaningless for the emptiness decision thus we consider "label-free" generalized tree set automata. Briefly, the
transition relation of a "label-free" generalized tree set automata is a relation
\Delta  ` [p Qp \Theta  Fp \Theta  Q.

The emptiness decision algorithm for simple generalized tree set automata
is straightforward. Indeed, Let ! be a subset of Q and let COND(!) be the
following condition:

8p 8f 2 Fp 8q1; : : : ; qp 2 ! 9q 2 ! (q1; : : : ; qp; f; q) 2 \Delta 

We easily prove that there exists a set ! satisfying COND(!) if and only if
there exists an A-run. Therefore, the emptiness problem for simple generalized
tree set automata is decidable because 2Q is finite and COND(!) is decidable.
Decidability of the emptiness problem for simple generalized tree set automata
is NP-complete (see Prop. 37).

The proof is more intricate in the general case, and it is not given in this
book. Without the property of simple GTSA, we have to deal with a reachability
problem of a set of states since we have to check that there exists ! 2 \Omega  and a
run r such that r assumes exactly all the states in !.

Let us consider a GTSA A with n states. The proof shows that one had to
consider at most all closed tree languages of size lower than B(A), a polynomial
in n, in order to decide emptiness for A. Let us remark that the polynomial
bound B(A) can be computed.

We conclude this section with a complexity result of the emptiness problem
in the class of generalized tree set automata.

Proposition 37. The emptiness problem in the class of (simple) generalized
tree set automata is NP-complete.

Proof. Let A = (Q; \Delta ; \Omega ) be a generalized tree set automaton over E. Let
n = Card(Q).

We first give a non-deterministic and polynomial algorithm for deciding
emptiness: (1) take a closed tree language F of size lower than B(A); (2) take
a run r on F ; (3) compute r(F ); (4) check whether r(F ) = ! is a member of \Omega ;
(5) check whether ! satisfies COND(!).

5.3 Closure and decision properties 141

From Theorem 39, this algorithm is correct and complete. Moreover, this
algorithm is polynomial in n since the size of F is polynomial in n: step (2)
consists in labeling the nodes of F with states following the rules of the automaton - so there is a polynomial number of states, step (3) consists in collecting
the states; step (4) is polynomial and non-deterministic and finally, step (5) is
polynomial.

We reduce the satisfiability problem of boolean expressions into the emptiness problem for generalized tree set automata. We first build a generalized
tree set automaton A such that L(A) is the set of (codes of) satisfiable boolean
expressions over n variables fx1; : : :; xng.

Let F = F0 [ F1 [ F2 where F0 = fx1; : : : ; xng, F1 = f:g, and F2 = f^; .g.
A boolean expression is a term of T (F). Let Bool = f0; 1g be the set of boolean
values. Let A = (Q; \Delta ; \Omega ), be a generalized tree set automaton such that
Q = fq0; q1g, \Omega  = 2Q and \Delta  is the following set of rules:

xj i! qi where j 2 f1; : : :; ng and i 2 Bool
:(qi) :i! q:i where i 2 Bool
.(qi1; qi2) i1.i2! qi1.i2 where i1; i2 2 Bool
^(qi1; qi2) i1^i2! qi1^i2 where i1; i2 2 Bool

One can easily prove that L(A) = fLv j v is a valuation of fx1; : : : ; xngg
where Lv = ft j t is a boolean expression which is true under vg. Now, we can
derive an algorithm for the satisfiability of any boolean expression e: build Ae
a strongly deterministic generalized tree set automaton such that L(A) is the
set fL j e 2 Lg; build Ae " A and decide emptiness.

We get then the reduction because Ae " A is empty if and only if e is not
satisfiable.

Now, it remains to prove that the reduction is polynomial. The size of A
is 2 \Lambda  n + 10. The size of Ae is the length of e plus a constant. So we got the
result.

5.3.3 Other decision results
Proposition 38. The inclusion problem and the equivalence problem for deterministic generalized tree set automata are decidable.

Proof. These results are a consequence of the closure properties under intersection and complementation (Propositions 33, 34), and the decidability of the
emptiness property (Theorem 39).

Proposition 39. Let A be a generalized tree set automaton. It is decidable
whether or not L(A) is a singleton set.

Proof. Let A be a generalized tree set automaton. First it is decidable whether
L(A) is empty or not (Theorem 39). Second if L(A) is non empty then a regular
generalized tree set g in L(A) can be defined (see the proof of Theorem 39).
Construct the strongly deterministic generalized tree set automaton A0 such
that L(A0) is a singleton set reduced to the generalized tree set g. Finally, build

142 Tree Set Automata

A " A0 to decide the equivalence of A and A0. Note that we can build A0, since
A0 is deterministic (see Proposition 34).

Proposition 40. Let L = (L1; : : : ; Ln) be a tuple of regular tree language and
let A be a generalized tree set automaton over f0; 1gn. It is decidable whether
L 2 L(A).

Proof. This result just follows from closure under intersection and emptiness
decidability.

First construct a (strongly deterministic) generalized tree set automaton AL
such that L(A) is reduced to the singleton set fLg. Second, construct A " AL
and decide whether L(A " AL) is empty or not.

Proposition 41. Given a generalized tree set automaton over E = f0; 1; gn
and I ` f1; : : : ; ng. The following two problems are decidable:

1. It is decidable whether or not there exists (L1; : : : ; Ln) in L(A) such that

all the Li are finite for i 2 I.

2. Let x1 : : : ; xn be natural numbers. It is decidable whether or not there

exists (L1; : : : ; Ln) in L(A) such that Card(Li) = xi for each i 2 I.

The proof is technical and not given in this book. It relies on a lemma of
the emptiness decision proof.

5.4 Applications to set constraints
In this section, we consider the satisfiability problem for systems of set constraints. We show a decision algorithm using generalized tree set automata.

5.4.1 Definitions
Let F be a finite and non-empty set of function symbols. Let X be a set of
variables. We consider special symbols ?, ?, ,, [, " of arity 0, 0, 1, 2, 2. A
set expression is a term in TF0(X ) where F0 = F [ f?; ?; ,; [; "g.

A set constraint is either a positive set constraint of the form e ` e0 or a
negative set constraint of the form e 6` e0 (or :(e ` e0)) where e and e0 are set

expressions, and a system of set constraints is defined by Vki=1 SCi where the
SCi are set constraints.

An interpretation I is a mapping from X into 2T(F). It can immediately be
extended to each expression in the following way:

I(?) = T (F);
I(?) = ;;
I(f(e1; : : : ; ep)) = f(I(e1); : : : ; I(ep));

I(, e) = T (F) n I(e);
I(e [ e0) = I(e) [ I(e0);
I(e " e0) = I(e) " I(e0):

5.4 Applications to set constraints 143

We deduce an interpretation of set constraints in Bool = f0; 1g, the Boolean
values. For a system of set constraints SC, all the interpretations I such that
I(SC) = 1 are called solutions of SC. In the remainder, we will consider systems
of set constraints of n variables X1; : : : ; Xn. We will confuse a solution I of a
system of set constraints and a n-tuple of tree languages (I(X1); : : : ; I(Xn)).
We denote by SOL(SC) the set of all solutions of a system of set constraints
SC.

5.4.2 Set constraints and automata
Proposition 42. Let SC be a system of set constraints (respectively of positive
set constraints) of n variables X1; : : : ; Xn, there exists a deterministic (respectively deterministic and simple) generalized tree set automaton A over f0; 1gn
such that G(A) is the set of characteristic generalized tree sets of the n-tuples
(L1; : : : ; Ln) of solutions of SC.

Proof. First we reduce the problem to a single set constraint. Let SC =
C1 ^ : : : ^ Ck be a system of set constraints. A solution of SC satisfies all
the constraints Ci. Let us suppose that, for every i, there exists a deterministic
generalized tree set automaton Ai such that SOL(Ci) = G(Ai). As all variables
in fX1; : : : ; Xng do not necessarily occur in Ci, using Corollary 7, we can construct a deterministic generalized tree set automaton Ani over f0; 1gn satisfying:
G(Ani ) is the set of (L1; : : :; Ln) which corresponds to solutions of Ci when restricted to the variables of Ci. Using closure under intersection (Proposition
33), we can construct a deterministic generalized tree set automaton A over
f0; 1gn such that SOL(SC) = G(A).

Therefore we prove the result for a set constraint SC of n variables X1; : : : ; Xn.
Let E(exp) be the set of set variables and the set of set expression exp with a
root symbol in F occurring in exp:

E(exp) = \Phi exp0 2 TF0 (X ) j exp0 \Theta  exp and such that

either Head(exp0) 2 F or exp0 2 X \Psi :

If SC j exp1 ` exp2 or SC j exp1 6` exp2 then E(SC) = E(exp1)[E(exp2).
Let us consider a set constraint SC and let ' be a mapping ' from E(SC)
into Bool. Such a mapping is easily extended first to any set expression of
SC and second to the set constraint SC. The symbols [, ", ,, ` and 6` are
respectively interpreted as ., ^, :, ) and : ).

We now define the generalized tree set automaton A = (Q; \Delta ; \Omega ) over E =
f0; 1gn.

ffl The set of states is Q is the set f' j ' : E(SC) ! Boolg.
ffl The transition relation is defined as follows: f('1; : : : ; 'p) l! ' 2 \Delta  where

'1; : : : ; 'p 2 Q, f 2 Fp, l = (l1; : : : ; ln) 2 f0; 1gn, and ' 2 Q satisfies:

144 Tree Set Automata

8i 2 f1; : : : ; ng

'(Xi) = li (5.6)
8e 2 E(SC) such that Head(e) 2 F

('(e) = 1) , ` e = f(e1; : : : ; ep)8i 1 ^ i ^ p '

i(ei) = 1 ' (5.7)

ffl The set of accepting sets of states \Omega  is defined depending on the case of a

positive or a negative set constraint.

- If SC is positive, \Omega  = f! 2 2Q j 8' 2 ! '(SC) = 1g;
- If SC is negative, \Omega  = f! 2 2Q j 9' 2 ! '(SC) = 1g.

In the case of a positive set constraint, we can choose the state set Q = f' j
'(SC) = 1g and \Omega  = 2Q. Consequently, A is deterministic and simple.

The correctness of this construction is easy to prove and is left to the reader.

5.4.3 Decidability results for set constraints
We now summarize results on set constraints. These results are immediate
consequences of the results of Section 5.4.2.

Proposition 43. 1. The satisfiability problem for systems of set constraints

is decidable. There exists a regular solution, that is a tuple of regular tree
languages, in any non-empty set of solutions.

2. Given SC and SC0 systems of set constraints, it is decidable whether or

not SOL(SC) ` SOL(SC0).

3. Given SC a system of set constraints, it is decidable whether or not there

is a unique solution in SOL(SC).

4. Given SC a system of set constraints over (X1; : : : ; Xn) and I ` f1; : : : ; ng,

it is decidable whether or not there is a solution (L1; : : : ; Ln) 2 SOL(SC)
such that all the Li are finite for all i.

5. Given SC a system of set constraints over (X1; : : : ; Xn) and a n-tuple

(L1; : : : ; Ln) of regular tree languages, it is decidable whether or not (L1; : : : ; Ln) 2
SOL(SC).

Proof. We use Proposition 42 to encode sets of solutions of systems of set constraints with generalized tree set automata and then, each point is deduced from
Theorem 39, or Propositions 36, 41, 38, 39.

Proposition 44. Let SC be a system of positive set constraints, it is decidable
whether or not there is a least solution in SOL(SC).

5.4 Applications to set constraints 145
Proof. Let SC be a system of positive set constraints. Let A be the deterministic, simple generalized tree set automaton over f0; 1gn such that L(A) =
SOL(SC) (see Proposition 42). We define a partial ordering _ on Gf0;1gn by :

8l; l0 2 f0; 1gn l _ l0 , (8i l(i) ^ l0(i))
8g; g0 2 Gf0;1gn g _ g0 , (8t 2 T (F) g(t) _ g0(t))

The problem we want to deal with is to decide whether or not there exists a
least generalized tree set w.r.t. _ in G(A). To this aim, we first build a minimal
solution if it exists, and second, we verify that this solution is unique.

Let ! be a subset of states such that COND(!) (see the sketch of proof
page 140). Let A! = (!; \Delta !; 2!) be the generalized tree set automaton A
restricted to state set !.

Now let \Delta !min defined by: for each (q1; : : : ; qp; f) 2 !p \Theta  Fp, choose one
rule (q1; : : : ; qp; f; l; q) such that l is minimal w.r.t. _ in the set \Delta !. Let
A!min = (!; \Delta !min; 2!). Consequently,

1. There exists only one run r! on a unique generalized tree set g! in

A!min because for all q1; : : : ; qp 2 ! and f 2 Fp there is only one rule
(q1; : : : ; qp; f; l; q) in \Delta !min;

2. the run r! on g! is regular;
3. the generalized tree set g! is minimal w.r.t. _ in G(A!).

Points 1 and 2 are straightforward. The third point follows from the fact
that A is deterministic. Indeed, let us suppose that there exists a run r0 on a
generalized tree set g0 such that g0 OE g!. Therefore, 8t g0(t) _ g!(t) and there
exists (w.l.o.g.) a minimal term u = f(u1; : : :; up) w.r.t. the subterm ordering
such that g0(u) OE g!(u). Since A is deterministic and 8v \Delta  u g!(v) = g0(v), we
have r!(ui) = r0(ui). Hence, the rule (r!(u1); : : : ; r!(up); f; g!(u); r!(u)) is not
such that g!(u) is minimal in \Delta !, which contradicts the hypothesis.

Consider the generalized tree sets g! for all subsets of states ! satisfying
COND(!). It is decidable whether or not there is a minimal generalized tree set
among them (each defines a n-tuple of regular tree languages and inclusion is
decidable for regular tree languages). Either there exists a minimal generalized
tree set g, then g is minimal in G(A) and it defines a n-tuple (F1; : : : ; Fn)
of regular tree languages, or not and in this case there is no least generalized
tree set g in G(A). If exists, there is a deterministic, simple generalized tree
set automaton A0 such that G(A0) is the set of characteristic generalized tree
sets of all (L1; : : : ; Ln) satisfying F1 ` L1; : : : ; Fn ` Ln (see Proposition 36).
Let A00 be the deterministic generalized tree set automaton such that G(A00) =
G(A) " G(A0) (see Proposition 33). There exists a least generalized tree set
w.r.t. _ in G(A) if and only if the generalized tree set automata A and A00 are
equivalent. Since equivalence of generalized tree set automata is decidable (see
Proposition 38) we get the result.

146 Tree Set Automata

5.5 Exercises
5.6 Bibliographical notes
We now survey decidability results for satisfiability of set constraints and some
complexity issues.

Decision procedures for solving set constraints arise with [Rey69], and Mishra
[Mis84]. The aim of these works was to obtain new tools for type inference and
type checking [AM91, Hei92, HJ90b, JM79, Mis84, Rey69].

First consider systems of set constraints of the form:

X1 = exp1; : : : ; Xn = expn (5.8)
where the Xi are distinct variables and the expi are disjunctions of set expressions of the form f(Xi1 ; : : : ; Xip) with f 2 Fp. These systems of set constraints
are essentially tree automata, therefore they have a unique solution and each
Xi is interpreted as a regular tree language.

Suppose now the expi are set expressions without complement symbols. Such
systems are always satisfiable and have a least solution which is regular. For
example, the system

Nat = s(Nat) [ 0
X = X " Nat
List = cons(X; List) [ nil

has a least solution

Nat = fsi(0) j i * 0g ; X = ; ; List = fnilg:
[HJ90a] investigate the class of definite set constraints which are of the form
exp ` exp0, where no complement symbol occur and exp0 contains no set operation. Definite set constraints have a least solution whenever they have a solution.
The algorithm presented in [HJ90a] provides a specific set of transformation
rules and, when there exists a solution, the result is a regular presentation of
the least solution, in other words a system of the form (5.8).

Solving definite set constraints is EXPTIME-complete [CP97]. Many developments or improvements of Heinzte and Jaffar's method have been proposed
and some are based on tree automata [DTT97].

The class of positive set constraints is the class of systems of set constraints
of the form exp ` exp0, where no projection symbol occur. In this case, when a
solution exists, set constraints do not necessarily have a least solution. Several
algorithms for solving systems in this class were proposed, [AW92] generalize the
method of [HJ90a], [GTT93] give an automata-based algorithm, and [BGW93]
use the decision procedure for the first order theory of monadic predicates.
Results on the computational complexity of solving systems of set constraints
are presented in a paper of [AKVW93]. The systems form a natural complexity
hierarchy depending on the number of elements of F of each arity. The problem
of existence of a solution of a system of positive set constraints is NEXPTIMEcomplete.

The class of positive and negative set constraints is the class of systems of set
constraints of the form exp ` exp0 or exp 6` exp0, where no projection symbol

5.6 Bibliographical notes 147
occur. In this case, when a solution exists, set constraints do not necessarily
have, neither a minimal solution, nor a maximal solution. Let F = fa; b()g.
Consider the system (b(X) ` X) ^ (X 6` ?), this system has no minimal
solution. Consider the system (X ` b(X) [ a) ^ (? 6` X), this system has
no maximal solution. The satisfiability problem in this class turned out to
be much more difficult than the positive case. [AKW95] give a proof based
on a reachability problem involving Diophantine inequalities. NEXPTIMEcompleteness was proved by [Ste94]. [CP94a] gives a proof based on the ideas
of [BGW93].

The class of positive set constraints with projections is the class of systems of
set constraints of the form exp ` exp0 with projection symbols. Set constraints
of the form f\Gamma 1i (X) ` Y can easily be solved, but the case of set constraints of
the form X ` f\Gamma 1i (Y ) is more intricate. The problem was proved decidable by
[CP94b].

The expressive power of these classes of set constraints have been studied and
have been proved to be different [Sey94]. In [CK96, Koz93], an axiomatization is
proposed which enlightens the reader on relationships between many approaches
on set constraints.

Furthermore, set constraints have been studied in a logical and topological
point of view [Koz95, MGKW96]. This last paper combine set constraints with
Tarskian set constraints, a more general framework for which many complexity results are proved or recalled. Tarskian set constraints involves variables,
relation and fonction symbols interpreted relative to a first order structure.

Topological characterizations of classes of GTSA recognizable sets, have also
been studied in [Tom94, Sey94]. Every set in RSGTS is a compact set and every
set in RGTS is the intersection between a compact set and an open set. These
remarks give also characterizations for the different classes of set constraints.

Chapter 6
Tree transducers

6.1 Introduction
Finite state transformations of words, also called a-transducers or rational transducers, model many kinds of processes, as coffee machines or lexical translators.
But these transformations are not powerful enough to model syntax directed
transformations, and compiler theory is an important motivation to the study
of finite state transformations of trees. Indeed, translation of natural or computing languages is directed by syntactical trees, and a translator from Latex
into HTML is a tree transducer. Unfortunately, from a theoretical point of
view, tree transducers do not inherit nice properties of word transducers, and
the classification is very intricate. So, in the present chapter we focus on some
aspects. In Sections 6.2 and 6.3, toy examples introduce intuitively the notions
of transducers. In Section 6.2, we summarize main results in the word case.
Indeed, this book is mainly concerned with trees, but the word case is useful to
understand the tree case and its difficulties. The bimorphism characterization
is the ideal illustration of the link between the "machine" point of view and
the "homomorphic" one. In Section 6.3, we motivate and illustrate bottom-up
and top-down tree transducers, using compilation as leitmotiv. We precisely
define and present the main classes of tree transducers and their properties in
Section 6.4, where we remark that general classes are not closed under composition, mainly because of alternation of copying and nondeterministic processing.
Nevertheless most useful classes, as these used in Section 6.3, have closure properties. In Section 6.5 we present the homomorphic point of view. Most of the
proofs are tedious and are omitted. The reader can find more results and details
in exercises and bibliographic notes.

6.2 The word case
6.2.1 Introduction to rational transducers
We suppose that the reader knows roughly popular notions of language theory :
homomorphisms on words, finite automata, rational expressions, regular grammars. See for example the recent survey of A. Mateescu and A. Salomaa [MS96].
A rational transducer is a finite word automaton with output. In a word au150 Tree transducers

tomaton, a transition rule f(q) ! q0(f) means "if the FA is in some state q,
if it reads the input symbol f, the FA enters state q' and moves its head one
symbol to the right". For defining a rational transducer, it suffices to add an
output, and a transition rule f(q) ! q0(m) means "if the transducer is in some
state q, if it reads the input symbol f, the FA enters state q', writes the word m
on the output tape, and moves its head one symbol to the right". Remark that
with these notations, we identify a finite automaton with a rational transducer
which writes what it reads. m is not necessarily a symbol but can be a word,
including the empty word. Furthermore, we assume that it is not necessary to
read an input symbol, i.e. we accept transition rules of the form ffl(q) ! q0(m)
(ffl denotes the empty word).

Graph presentations of finite automata are popular and convenient. So is it
for rational transducers. The rule f(q) ! q0(m) will be drawn

q q'f / m

Example 49. Let F = fh; i; ; ; 0; 1; A; :::; Zg. In the following, we will consider
the language L1 defined on F by the regular grammar (the axiom is program):

program ! h instruct
instruct ! LOAD register j STORE register j MULT register j ADD register
register ! 1tailregister
tailregister ! 0tailregister j 1tailregister j ; instruct j i
( a ! bjc is an abbreviation for the set of rules fa ! b; a ! cg)
L1 is recognized by the deterministic automaton A1 of Figure 6.1
Semantic of L1 is well known : LOAD i loads the content of register i in the
accumulator; STORE i stores the content of the accumulator in register i; ADD
i adds in the accumulator the contents of the accumulator and of register i;
MULT i multiplies in the accumulator the contents of the accumulator and of
register i.

A rational transducer is a tuple R = (Q; F; F 0; Qi; Qf ; \Delta ) where Q is a set
of states, F and F0 are finite nonempty sets of input letters and output letters,
Qi; Qf ` Q are sets of initial and final states and \Delta  is a set of transduction
rules of the following type :

f(q) ! q0(m);

where f 2 F [ f"g , m 2 F0

\Lambda  , q; q0 2 Q.

R is "-free if there is no rule f(q) ! q0(m) with f = " in \Delta .
The move relation !R is defined by: let t; t0 2 F\Lambda , u 2 F0

\Lambda , q; q0 2 Q,

f 2 F, m 2 F0

\Lambda ,

(tqft0; u) !R (tfq0t; um) , f(q) ! q0(m) 2 \Delta :
!\Lambda R is the reflexive and transitive closure of !R. A (partial) transduction of
R (on tt0t00) is a sequence of move steps of the form (tqt0t00; u) !\Lambda R(tt0q0t00; uu0).
A transduction of R from t 2 F\Lambda  into u 2 F0

\Lambda  is a transduction of the form

(qt; ffl) !\Lambda R(tq0; u) with q 2 Qi and q0 2 Qf .

6.2 The word case 151

Instruct

Begin

Register
Tailregister

end

O AL D

ROT
U L T
S E

M

A D D

!

1
?
;

0,1

Figure 6.1: A recognizer of L1

152 Tree transducers

The transformation TR induced by R can now be defined formally as follows:

TR = f(t; u) j (qt; ") \Lambda !R (tq0; u) with t 2 F\Lambda ; u 2 F0

\Lambda ; q 2 Q

i; q0 2 Qf g:

A relation in F\Lambda  \Theta  F0

\Lambda  is a rational transduction if and only if it is induced

by some rational transducer. We also need the following definitions: let t 2 F \Lambda ,
TR(t) = fu j (t; u) 2 TRg. The translated of a language L is obviously the
language defined by TR(L) = fu j 9t 2 L; u 2 TR(t)g.

Example 50.
Ex. 50.1 Let us name French-L1 the translation of L1 in French (LOAD is

translated into CHARGER and STORE into STOCKER). The transducer of Figure 6.2 realizes this translation. This example illustrates the use of rational
transducers as lexical transducers.

Instruct

Begin

Register
Tailregister

end

O/" A/"L/" D/CHARGER

R/"O/"T/"
U/" L/" T/MULT
S/" E/STOCKER

M/"

A/" D/" D/ADD

h=h

1=1

1=1

0=0i=i
; =;

Figure 6.2: A rational transducer from L1 into French-L1.
Ex. 50.2 Let us consider the rational transducer Diff defined by Q = fqi; qs; ql; qdg,

F = F0 = fa; bg, Qi = fqig, Qf = fqs; ql; qdg, and \Delta  is the following set of
rules:

type i a(qi) ! qi(a), b(qi) ! qi(b)
type s ffl(qi) ! a(qs), ffl(qi) ! b(qs), ffl(qs) ! a(qs), ffl(qs) ! b(qs)

6.2 The word case 153

type l a(qi) ! ffl(ql), b(qi) ! ffl(ql), a(ql) ! ffl(ql), b(ql) ! ffl(ql)
type d a(qi) ! qd(b), b(qi) ! qd(a), a(qd) ! ffl(qd), b(qd) ! ffl(qd),

ffl(qd) ! a(qd), ffl(qd) ! b(qd).

It is easy to prove that TDiff = f(m; m0) j m 6= m0; m; m0 2 fa; bg\Lambda g.

We give without proofs some properties of rational transducers. For more
details, see [Sal73] or [MS96] and Exercises 62, 63, 65 for 1, 4 and 5. The
homomorphic approach presented in the next Section can be used as an elegant
way to prove 2 and 3 (Exercise 67).

Proposition 45 (Main properties of rational transducers).

1. The class of rational transductions is closed under union but not under

intersection.

2. The class of rational transductions is closed under composition.
3. Regular languages and context-free languages are closed under rational

transduction.

4. Equivalence of rational transductions is undecidable.
5. Equivalence of deterministic rational transductions is decidable.

6.2.2 The homomorphic approach
A bimorphism is defined as triple B = (\Phi ; L; \Psi ) where L is a recognizable
language and \Phi  and \Psi  are homomorphisms. The transformation induced by
B is the relation (also denoted by B) defined by B = f(\Phi (t); \Psi (t)) j t 2 Lg.
(\Phi ; L; \Psi ) is "-free if \Phi  is "-free (an homomorphism is "-free if the image of a
letter is never reduced to "). Two bimorphisms are equivalent if they induce
the same transformation.

We can state the following Theorem, generally known as Nivat Theorem [Niv68]
(see Exercises 66 and 67 for a sketch of proof).

Theorem 40 (Bimorphism theorem). Given a rational transducer, an equivalent bimorphism can be constructed. Conversely, any bimorphism defines a
rational transduction. The transducer is "-free if and only if the bimorphism is
"-free.

Example 51.
Ex. 51.1 The relation f(a(ba)n; an) j n 2 Ng [ f((ab)n; b3n) j n 2 Ng is

processed by transducer R and bimorphism B of Figure 6.3

Ex. 51.2 Automaton L of Figure 6.4 and morphisms \Phi  and \Psi  bellow define

a bimorphism equivalent to transducer of Figure 6.2

\Phi (fi) = h \Phi (*) = LOAD \Phi (oe) = STORE \Phi (_) = MULT
\Phi (ff) = ADD \Phi (ae) =; \Phi (!) = 1 \Phi (i) = 0
\Phi (`) =i
\Psi (fi) = h \Psi (*) = CHARGER \Psi (oe) = STOCKER \Psi (_) = MULT
\Psi (ff) = ADD \Psi (ae) =; \Psi (!) = 1 \Psi (i) = 0
\Psi (`) =i

154 Tree transducers

a=" b=bbb b=bbb

a="

a="

a=a
b="

C
B
C
A

\Phi  \Psi 

\Phi (A) = a \Psi (A) = "
\Phi (B) = ba \Psi (B) = a
\Phi (C) = ab \Psi (C) = bbb

Figure 6.3: a bimorphism B = f(\Phi (t); \Psi (t)) j t 2 AB\Lambda  +CC\Lambda g and an equivalent
transducer R

6.3 Introduction to tree transducers 155

Begin Instruct Register

Tailregister

end

!
ae

i; !

*; oe; _; fffi

`
Figure 6.4: The control automaton L
Nivat characterization of rational transducers makes intuitive sense. Automaton L can be seen as a control of the actions, morphism \Psi  as output
function and \Phi \Gamma 1 as input function. \Phi \Gamma 1 analyses the input -- it is a kind
of part of lexical analyzer -- and it generates symbolic names; regular grammatical structure on theses symbolic names is controlled by L. Examples 50.2
and 51.2 are an obvious illustration. L is the common structure to English and
French versions, \Phi  generates the English version and \Psi  generates the French
one. This idea is the major idea of compilation, but compilation of computing
languages or translation of natural languages are directed by syntax, that is to
say by syntactical trees. This is the motivation of the rest of the chapter. But
unfortunately, from a formal point of view, we will lose most of the best results
of the word case, namely Nivat theorem. Power of non-linear tree transducers
will explain in part this complication, but even in the linear case, there is a
new phenomena in trees, the understanding of which can be introduced by the
"problem of homomorphism inversion" that we introduce in Exercise 68.

6.3 Introduction to tree transducers
Tree transducers and their generalizations model many syntax directed transformations (see exercises). We use here a toy example of compiler to illustrate
how usual tree transducers can be considered as modules of compilers.

We consider a simple class of arithmetic expressions (with usual syntax) as
source language. We suppose that this language is analyzed by a LL1 parser.
We consider two target languages : L1 which is defined in section 6.2 and
an other language L2. A transducer A translates syntactical trees in abstract
trees (Figure 6.5). A second tree transducer R illustrates connections between
transducers and attributes, it decorates abstract trees with numbers of registers

156 Tree transducers

(Figure 6.7). Thus R translates abstract trees into attributed abstract trees.
Then, the tree transducers T1 and T2 generate target programs in L1 and L2,
respectively, starting from attributed abstract trees (Figures 6.7 and 6.8). Note
that they generate trees, but programs are Leaves of these trees. The reader
should also remark that T2 is not linear. To illustrate non determinism, we
also introduce a transducer A0 which realizes the inverse transformation of A.
A0 is non deterministic because some parentheses are optional in the source
language (Figure 6.6). So composition of transducers model succession of passes
of compilation, and when a class of transducers is closed by composition (see
section 6.4), we get universal constructions to reduce the number of compiler
passes and to meta-optimize compilers.

We now define the source language. Let us consider the terminal alphabet
f(; ); +; \Theta ; a; b; : : :; zg. First, the context-free word grammar G1 is defined by
the following set of rules (E is the axiom):

f E ! M j M + E

M ! F j F \Theta  M

F ! I j (E)

I ! a j b j \Delta  \Delta  \Delta  j z g

Equivalently, a context-free word grammar G2 is defined by the following set of
rules (E is the axiom):

f E ! M E0

E0 ! +E j ffl
M ! F M 0
M 0 ! \Theta M j ffl

F ! I j (E)

I ! a j b j \Delta  \Delta  \Delta  j z g

Let E be the axiom of G1 and G2. The semantic of these two grammars is
obvious. It is easy to prove that they are equivalent, i.e. they define the same
source language. G1 is more natural, but G2 could be preferred for syntactical
analysis reason, because G2 is LL1 and G1 is not LL. We consider syntactical
trees as derivation trees for the tree grammar G2. Let us consider the word
u = (a + b) \Theta  c. u belongs to the source language. We define the abstract tree
associated with u as the tree \Theta (+(a; b); c) defined over F = f+(; ); \Theta (; ); a; b; cg.
Abstract trees are ground terms over F. It is easier to evaluate expressions or
compute attributes over abstract trees than over syntactical trees. The following
transformation associates with a syntactical tree t its corresponding abstract
tree A(t).

I(x) ! x F (x) ! x
M (x; M 0(ffl)) ! x E(x; E0(ffl)) ! x
M (x; M 0(\Theta ; y)) ! \Theta (x; y) E(x; E0(+; y)) ! +(x; y)

F ((; x; )) ! x

We have not precisely defined the use above of the arrow !, but it is intuitive. Likewise we introduce examples before definitions of different kinds of
tree transducers (section 6.4 supplies a formal frame).

6.3 Introduction to tree transducers 157
A : an example of bottom-up tree transducer
The following linear deterministic bottom-up tree transducer A carries out transformation of derivation trees for G2 into the corresponding abstract trees. " is
identified as a constant symbol in syntactical trees. The states of A are q, q",
qI, qF , qM0", qE0", qE, q\Theta , qM0\Theta , q+, qE0+, q(, and q). The final state is qE. The
set of transduction rules is the following set of rules:

a ! q(a) b ! q(b)

c ! q(c) " ! q"(")

) ! q)()) ( ! q((()
+ ! q+(+) \Theta  ! q\Theta (\Theta )
I(q(x)) ! qI(x) F (qI(x)) ! qF (x)
M 0(q"(x)) ! qM0"(x) E0(q"(x)) ! qE0"(x)
M (qF (x); qM0"(y)) ! qM(x) E(qM(x); qE0"(y)) ! qE(x)

M 0(q\Theta (x); qM(y)) ! qM0\Theta (y) M (qF (x); qM0\Theta (y)) ! qM(\Theta (x; y))

E0(q+(x); qE(y)) ! qE0+(y) E(qM (x); qE0+(y)) ! qE(+(x; y))
F (q((x); qE(y); q)(z)) ! qF (y)

The notion of (successful) run is an intuitive generalization of the notion of
run for finite tree automata. The reader should note that FTA can be considered
as a special case of bottom-up tree transducers whose output is equal to the
input. We give in Figure 6.5 an example of run of A which realizes the translation
of the derivation tree t of the expression (a + b) \Theta  c for context-free grammar
G2 into the corresponding abstract tree \Theta (+(a; b); c).

t !\Lambda A

(
q(

a
qM

b
qE0+
E

)
q)
F

"
qM0\Theta 
M

c
qE0"
E

!\Lambda A

a b

+
qF

"
qM0\Theta 
M

c
qE0"
E

!\Lambda A

a b

+ c

\Theta 
qE

Figure 6.5: Example of run of A
A0 : an example of top-down tree transducer
The inverse transformation A\Gamma 1, which computes the set of derivation trees of
G2 associated with an abstract tree, is computed by a nondeterministic topdown tree transducer A0. The states of A0 are qE, qF , qM. The initial state is
qE. The set of transduction rules is the following set of rules:

158 Tree transducers

qE(x) ! E(qM(x); E0(")) qE(+(x; y)) ! E(qM (x); E0(+; qE(y)))
qM (x) ! M (qF (x); M 0(")) qM(\Theta (x; y)) ! M (qF (x); M 0(\Theta ; qM(y)))

qF (x) ! F ((; qE(x); )) qF (a) ! F (I(a))

qF (b) ! F (I(b)) qF (c) ! F (I(c))

The transducer A0 is non deterministic because there are ffl-rules like qE(x) !
E(qM(x); E0(")) in the set of transition rules. We give in the Figure 6.5 an example of run of A0 which realizes the translation of the abstract tree +(a; \Theta (b; c))
into a syntactical tree t0 of the word a + b \Theta  c.

a

b c

\Theta 
+
qE

!A0

a
qM

+

b c

\Theta 
qE
E0
E

!\Lambda A0

a
I
F

ffl
M 0
M

+

b c

\Theta 
qE
E0
E

!\Lambda A0 t0

Figure 6.6: Example of run of A0
Compilation
The compiler now transforms abstract trees into programs for some target languages. We consider two target languages. The first one is L1 of Section 6.2.
To simplify, we omit ";", because they are not necessary -- we introduced semicolons in Section 6.2 to avoid "-rules, but this is a technical detail, because word
(and tree) automata with "-rules are equivalent to usual ones. The second one is
an other very simple language L2, namely sequences of two instructions +(i; j; k)
(put the sum of contents of registers i and j in the register k) and \Theta (i; j; k). In
a first pass, we attribute to each node of the abstract tree the minimal number
of registers necessary to compute the corresponding subexpression in the target
language. The second pass generates target programs.

First pass computation of register numbers by a deterministic linear bottomup transducer R.

States of a tree automaton can be considered as values of (finitely valued) attributes, but formalism of tree automata does not allow decorating
nodes of trees with the corresponding values. On the other hand, this decoration is easy with a transducer. Computation of finitely valued inherited
(respectively synthesized) attributes is modeled by top-down (respectively
bottom-up) tree transducers. Here, we use a bottom-up tree transducer
R. States of R are q0; : : :; qn. All states are final states. The set of rules

6.4 Properties of tree transducers 159

is defined by:

a ! q0(a) b ! q0(b)

c ! q0(c)
+(qi(x); qi(y)) ! qi+1(i + 1 + (x; y)) \Theta (qi(x); qi(y)) ! qi+1(i + 1 \Lambda  (x; y))
if i ? j
+(qi(x); qj(y)) ! qi(i + (x; y) \Theta (qi(x); qj(y)) ! qi(i \Theta  (x; y))
if i ! j, we permute the order of subtrees
+(qi(x); qj(y)) ! qj(j + (y; x)) \Theta (qi(x); qj(y)) ! qj(j \Theta  (y; x))

A run t !\Lambda R qi(u) means that i registers are necessary to evaluate t. Root
of t is then relabelled in u by symbol i+ or i\Theta  .

Second pass generation of target programs in L1 or L2, by top-down deterministic transducers T1 and T2. T1 contains only one state q. The set
of rules of T1 is the following:

q(i + (x; y)) ! \Pi (q(x); STOREi; q(y); ADDi; STOREi)
q(i \Theta  (x; y)) ! \Pi (q(x); STOREi; q(y); MULTi; STOREi)

q(a) ! \Pi (LOAD; a)

q(b) ! \Pi (LOAD; b)
q(c) ! \Pi (LOAD; c)

where \Pi (; ; ; ; ) and \Pi (; ) are new symbols.
The set state of T2 is fq; q0g where q0 is the initial state. The set of rules
of T2 is the following:

q(i + (x; y)) ! #(q(x); q(y); +; (; q0(x); q0(y); i; )) q0(i + (x; y)) ! i

q(i \Lambda  (x; y)) ! #(q(x); q(y); \Theta ; (; q0(x); q0(y); i; )) q0(i \Lambda  (x; y)) ! i

q(a) ! " q0(a) ! a

q(b) ! " q0(b) ! b
q(c) ! " q0(c) ! c

where # is a new symbol of arity 8.
The reader should note that the target programs are the words formed
with the leaves of the trees, i.e. the yields of the trees. Examples of
transductions realized by T1 and T2 are given in Figures 6.7 and 6.8.
The reader should also note that T1 is an homomorphism. Indeed, an
homomorphism can be considered as a particular case of deterministic
transducer, namely a transducer with only one state (we can consider it
as bottom-up as well as top-down). The reader should also note that T2
is deterministic but not linear.

6.4 Properties of tree transducers
6.4.1 Bottom-up tree transducers
We now give formal definitions. In this section, we consider academic examples,
without intuitive semantic, to illustrate phenomena and properties. Tree transducers are both generalization of word transducers and tree automata. We first

160 Tree transducers

a

b c

+ d

\Theta 
+

!\Lambda R

a

b c
1+ d

1\Theta 
1+

q1

= q1(u):

q(u) !\Lambda T1

L b

\Pi  S1

L c

\Pi  A1 S1
\Pi  S1

L d

\Pi  M1 S1
\Pi  S1

L a

\Pi  A1 S1
\Pi 

where L stands for LOAD, S stands for STORE, A stands for ADD, M stands for MULT.
The corresponding program is the yield of this tree:
LOADbSTORE1LOADcADD1STORE1STORE1LOADdMULT1STORE1STORE1LOADaADD1STORE1

Figure 6.7: decoration with synthesized attributes of an abstract tree, and translation into a target program of L1

q(u) !\Lambda T2

ffl ffl + ( b c 1 )

] ffl + ( 1 d 1 )

] ffl \Theta  ( 1 a 1 )

]

The corresponding program is the yield of this tree: +(bc1) \Theta  (1d1) + (1a1)

Figure 6.8: translation of an abstract tree into a target program of L2

6.4 Properties of tree transducers 161
consider bottom-up tree transducers. A transition rule of a NFTA is of the type
f(q1(x1); : : : ; qn(xn)) ! q(f(x1; : : : ; xn)). Here we extend the definition (as we
did in the word case), accepting to change symbol f into any term.

A bottom-up Tree Transducer (NUTT ) is a tuple U = (Q; F; F0; Qf ; \Delta )
where Q is a set of (unary) states, F and F0 are finite nonempty sets of input
symbols and output symbols, Qf ` Q is a set of final states and \Delta  is a set of
transduction rules of the following two types:

f(q1(x1); : : : ; qn(xn)) ! q(u) ;
where f 2 Fn, u 2 T (F0; Xn), q; q1; : : :; qn 2 Q , or

q(x1) ! q0(u) ("-rule);
where u 2 T (F0; X1), q; q0 2 Q.

As for NFTA, there is no initial state, because when a symbol is a leave a
(i.e. a constant symbol), transduction rules are of the form a ! q(u), where u
is a ground term. These rules can be considered as "initial rules". The move
relation !U is defined by: Let t; t0 2 T (F [ F0 [ Q),

t !U t0 ,

8????!

????:

9f(q1(x1); : : : ; qn(xn)) ! q(u) 2 \Delta 
9C 2 C(F [ F0 [ Q)
9u1; : : : ; un 2 T (F0)
t = C[f(q1(u1); : : : ; qn(un))]
t0 = C[q(ufx1u1; : : : ; xnung)]

This definition includes the case of "-rule as a particular case. !\Lambda U is the
reflexive and transitive closure of !U . A transduction of U from a ground term
t 2 T (F) to a ground term t0 2 T (F0) is a sequence of move steps of the form
t !\Lambda U q(t0), such that q is a final state. The transformation induced by U is the
relation (also denoted by U ) defined by:

U = f(t; t0) j t \Lambda !U q(t0); t 2 T (F); t0 2 T (F0); q 2 Qf g:

The domain of U is the set ft 2 T (F) j (t; t0) 2 U g. The image of a set of
ground terms L by U is the set U (L) = ft0 2 T (F0) j 9t 2 L; (t; t0) 2 U g.

A transducer is "-free if it contains no "-rule. It is linear if all transition rules are linear (no variable occurs twice in the right-hand side). It
is non-erasing if, for every rule, at least one symbol of F0 occurs in the
right-hand side. It is said to be complete (or non-deleting) if, for every rule
f(q1(x1); : : : ; qn(xn)) ! q(u) , for every xi(1 ^ i ^ n), xi occurs at least once
in u. It is deterministic (DUTT ) if it is "-free and there is no two rules with
the same left-hand side.

Example 52.
Ex. 52.1 Tree transducer A defined in Section 6.3 is a linear DUTT. Tree

transducer R in Section 6.3 is a linear and complete DUTT.

Ex. 52.2 States of U1 are q; q0; F = ff(); ag; F0 = fg(; ); f(); f0(); ag; q0 is

the final state; the set of transduction rules is defined by:

a ! q(a)
f(q(x)) ! q(f(x)) j q(f0(x)) j q0(g(x; x))

162 Tree transducers

U1 is a complete, non linear NUTT. We now give the transductions of
the ground term f(f(f(a))). For the sake of simplicity, fffa stands for
f(f(f(a))). We have:

U1(ffffag) = fg(ffa; ffa); g(ff 0 a; ff0a); g(f0fa; f0fa); g(f0f0a; f0f0a)g:

U1 illustrates an ability of NUTT, that we describe following G'ecseg and
Steinby.

U- "Nprocess and copy" A NUTT can first process an input subtree nondeterministically and then make copies of the resulting
output tree.

Ex. 52.3 States of U2 are q; q0; F = F0 = ff(); f0(); ag; q is the final state;

the set of transduction rules is defined by:

a ! q(a)
f(q(x)) ! q0(a)
f0(q0(x)) ! q(a)

U2 is a non complete DUTT. The tree transformation induced by U2 isae

(t; a) j t is accepted by the DFTA of final state q and rulesa ! q(a); f(q(x)) ! q0(f(x)); f0(q0(x)) ! q(f0(x)) oe :
U- "check and delete" A NUTT can first check regular constraints
on input subterms and delete these subterms afterwards.

Bottom-up tree transducers translate the input trees from leaves to root, so
bottom-up tree transducers are also called frontier-to-root transducers. Topdown tree transducers work in opposite direction.

6.4.2 Top-down tree transducers
A top-down Tree Transducer (NDTT ) is a tuple D = (Q; F; F0; Qi; \Delta )
where Q is a set of (unary) states, F and F0 are finite nonempty sets of input
symbols and output symbols, Qi ` Q is a set of initial states and \Delta  is a set of
transduction rules of the following two types:

q(f(x1; : : : ; xn)) ! u[q1(xi1); : : : ; qp(xip)] ;
where f 2 Fn, u 2 Cp(F0), q, q1; : : : ; qp 2 Q, , xi1; : : : ; xip 2 Xn, or

q(x) ! u[q1(x); : : : ; qp(x)] ("-rule);
where u 2 Cp(F0), q, q1; : : : ; qp 2 Q, x 2 X .

As for top-down NFTA, there is no final state, because when a symbol is a
leave a (i.e. a constant symbol), transduction rules are of the form q(a) ! u,
where u is a ground term. These rules can be considered as "final rules". The
move relation !D is defined by: Let t; t0 2 T (F [ F0 [ Q),

6.4 Properties of tree transducers 163

t !D t0 ,

8????!

????:

9q(f(x1; : : : ; xn)) ! u[q1(xi1); : : : ; qp(xip)] 2 \Delta 
9C 2 C(F [ F0 [ Q)
9u1; : : : ; un 2 T (F)
t = C[q(f(u1; : : : ; un))]
t0 = C[u[q1(v1); : : : ; qp(vp)])] where vj = uk if xij = xk

This definition includes the case of "-rule as a particular case. !\Lambda D is the
reflexive and transitive closure of !D. A transduction of D from a ground term
t 2 T (F) to a ground term t0 2 T (F0) is a sequence of move steps of the form
q(t) !\Lambda D t0, where q is an initial state. The transformation induced by D is the
relation (also denoted by D) defined by:

D = f(t; t0) j q(t) \Lambda !D t0; t 2 T (F); t0 2 T (F0); q 2 Qig:

The domain of D is the set ft 2 T (F) j (t; t0) 2 Dg. The image of a set
of ground terms L by D is the set D(L) = ft0 2 T (F0) j 9t 2 L; (t; t0) 2 Dg.
"-free, linear, non-erasing, complete (or non-deleting), deterministic top-down
tree transducers are defined as in the bottom-up case.

Example 53.
Ex. 53.1 Tree transducers A0, T1, T2 defined in Section 6.3 are examples of

NDTT.

Ex. 53.2 Let us now define a non-deterministic and non linear NDTT D1.

States of D1 are q; q0. The set of input symbols is F = ff(); ag. The set of
output symbols is F0 = fg(; ); f(); f0(); ag. q is the initial state. The set of
transduction rules is defined by:

q(f(x)) ! g(q0(x); q0(x)) (copying rule)
q0(f(x)) ! f(q0(x)) j f0(q0(x)) (non deterministic relabeling)

q0(a) ! a

D1 transduces f(f(f(a))) (or briefly fffa) into the set
fg(ffa; ffa); g(f f a; ff 0a); g(ffa; f0fa); : : : ; g(f0f0a; f0fa); g(f0f0a; f0f0a)g:
D1 illustrates a new property.

D- "copy and Nprocess" A NDTT can first make copies of an
input subtree and then process different copies independently and
nondeterministically .

164 Tree transducers

6.4.3 Main properties
In this Section, we use the tree transducers U1, U2 and D1 of the previous
Section in order to point out differences between top-down and bottom-up tree
transducers, and prove 1 and 2 of the following theorem. In the linear case,
inclusions or equalities arise ( 3).

Theorem 41 (Comparison Theorem).

1. There is no top-down tree transducer equivalent to U1 or to U2.
2. There is no bottom-up tree transducer equivalent to D1.
3. Any linear top-down tree transducer is equivalent to a linear bottom-up tree

transducer. In the linear complete case, classes of bottom-up and top-down
tree transducers are equal.

It is not hard to verify that neither NUTT nor NDTT are closed under
composition. Then, comparison of D-property "copy and Nprocess" and U property "Nprocess and copy" suggests an important question:

does alternation of copying and non-determinism induces an infinite
hierarchy of transformations?

The answer is affirmative [Eng78, Eng82], but it was a relatively long-standing
open problem. The fact that top-down transducers copy before non-deterministic
processes, and bottom-up transducers copy after non-deterministic processes
(see Exercise 72) suggests too that we get by composition two intricate infinite
hierarchies of transformation. The following theorem summarizes results.

Theorem 42 (Hierarchy theorem). By composition of NUTT, we get an infinite hierarchy of transformations. Any composition of n NUTT can be processed by composition of n+1 NDTT, and conversely (i.e. any composition of n
NDTT can be processed by composition of n + 1 NUTT).

Transducer A0 of Section 6.3 shows that it can be useful to consider "-rules,
but usual definitions of tree transducers in literature exclude this case of non
determinism. This does not matter, because it is easy to check that all important
results of closure or non-closure hold simultaneously for general classes and "-
free classes. Deleting is also a minor variety. Indeed, it gives rise to the "check
and delete" property, which is specific to bottom-up transducers, but it does
not matter for hierarchy theorem, which remains true if we consider complete
transducers.

Section 6.3 suggests that for practical use, non-determinism and non-linearity
are rare. Then, it is important to note than if we suppose linearity or determinism, hierarchy theorem collapses. Following results supply algorithms to
compose or simplify transducers.

Theorem 43 (Composition Theorem).

1. The class of linear bottom-up transductions is closed under composition.
2. The class of deterministic bottom-up transductions is closed under composition.

6.5 Homomorphisms and tree transducers 165

3. The class of linear top-down transductions is included in the class of linear bottom-up transductions. These classes are equivalent in the complete
case.

4. Any composition of deterministic top-down transducers is equivalent to a

deterministic complete top-down transducer composed with a linear homomorphism.

The reader should note that bottom-up determinism and top-down determinism are incomparable (see Exercise 69). We now give a decidability result:

Theorem 44 (Equivalence Theorem). Equivalence of deterministic tree transducers is decidable.

Idea of the proof is the same as in the word case, but it is much more
tedious [Esi83, Zac79].

Theorem 45 (Recognizability Theorem). The domain of a tree transducer
is a recognizable tree language. The image of a recognizable tree language by a
linear tree transducer is recognizable.

6.5 Homomorphisms and tree transducers
Exercise 71 illustrates how decomposition of transducers using homomorphisms
can help to get composition results, but we are far from the nice bimorphism
theorem of the word case, and in the tree case, there is no illuminating theorem,
but many complicated partial statements. Seminal paper of Engelfriet contains
a lot of decomposition and composition theorems. Here, we present only the
most significant results.

A delabeling is a linear, complete, and symbol-to-symbol tree homomorphism (see Section 1.4). This very special kind of homomorphism changes only
the label of the input letter and possibly order of subtrees. Definition of tree
bimorphisms is not necessary, it is the same as in the word case. We get the
following characterization theorem. We say that a bimorphism is linear, or
complete, etc. if the two morphisms are linear, complete, etc. respectively.

Theorem 46. The class of bottom-up tree transductions is equivalent to the
class of bimorphisms (\Phi ; L; \Psi ) where \Phi  is a delabeling. Tree transduction and
morphism \Psi  are simultaneously linear, complete, "-free.

Remark that Nivat Theorem illuminates the symmetry of word transductions : the inverse relation of a rational transduction is a rational transduction.
In the tree case, non-linearity breaks obviously this symmetry, because a tree
transducer can copy an input tree and process several copies, but it can never
check equality of subtrees of an input tree. If we want to consider symmetric
relations, we have two main situations. In the general (non-linear) case, composition of two bimorphisms simulates a Turing machine by classical techniques.
In the linear and the linear complete cases, we get the following results.

Theorem 47 (Tree Bimorphisms). .

1. The class LCFB of linear complete "-free tree bimorphisms satisfies LCFB ae

LCFB2 = LCFB3.

166 Tree transducers

2. The class LB of linear tree bimorphisms satisfies LB ae LB2 ae LB3 ae

LB4 = LB5.

Proof of point 1 requires many refinements.
Figure 6.9 illustrates why LCFB 6= LCFB2. This example shows a stronger
fact: the relation cannot be processed by any bimorphism, even non-linear, nor
by any bottom-up transducer, though the transformation is only "local" (i.e. if
we look pairs from far, both terms have the same shape). The intuitive interest
of the class LCFB2 is to capture exactly this kind of "local" transformation. A
direct characterization of these transformations is given in [AD82] by a special
class of top-down tree transducers, which are not linear but are "globally" linear,
and which are used to prove LCFB2 = LCFB3.

In Figure 6.9, we use twice the same homomorphism \Phi (a) = a; \Phi (f(x)) =
f(x); \Phi (g(x; y)) = g(x; y)); \Phi (h(x; y; z)) = g(x; g(y; z)).

For any subterms (t1; : : : ; t2p+2) , let

t = h(t1; t2; h(t3; t4; h(t2i+1; t2i+2; : : : ; h(t2p\Gamma 1; t2p; g(t2p+1; t2p+2) : : : )))
and
t0 = g(t1; h(t2; t3; h(t4; : : : ; h(t2i; t2i+1; h(t2i+2; t2i+3; : : :; h(t2p; t2p+1; t2p+2) : : : ))):
We get t0 2 (\Phi  ffi \Phi \Gamma 1)(t). Assume that \Phi  ffi \Phi \Gamma 1 can be processed by some
\Psi \Gamma 1 ffi \Psi 0. Consider for simplicity subterms ti of kind fni(a). Roughly, if lengths
of ti are different enough, \Psi  and \Psi 0 can be supposed linear complete. Suppose
that for some u we have \Psi (u) = t and \Psi 0(u) = t0, then for any context u0
of u, \Psi (u0) is a context of t with an odd number of variables, and \Psi 0(u0) is
a context of t0 with an even number of variables. That is impossible because
homomorphisms are linear complete.

Point 2 is a refinement of point 1 (see Exercise 76).

Figure 6.9: a "local" transformation which cannot be processed by any bimorphism

Non-linearity introduces an evident gap between word transductions and
tree transductions. In the linear case, if a generalization of the inverse homomorphism property of words \Phi \Gamma 1(M M 0) = \Phi \Gamma 1(M )\Phi \Gamma 1(M 0) remained true,
we could inverse linear homomorphism symbol to symbol and deduce closure
properties and equivalences between bimorphisms and transducers as the word
case. Unfortunately, this property fails in the usual algebraic frame, and it is
necessary to extend it (Exercise 77).

6.6 Exercises
Exercises 62 to 68 are devoted to the word case, which is out of scoop of this
book. For this reason, we give precise hints for these exercises.

Exercise 62. The class of rational transductions is closed under rational operations.
Hint: for closure under union, connect a new initial state to initial state with LkL

6.6 Exercises 167
rules (parallel composition). For concatenation, connect by the same way final states
of the first transducer to initial states of the second (serial composition). For iteration,
connect final states to initial states (loop operation).

Exercise 63. The class of rational transductions is not closed under intersection. Hint:
consider rational transductions f(anbp; an) j n; p 2 Ng and f(anbp; ap) j n; p 2 Ng.

Exercise 64. Equivalence of rational transductions is undecidable. Hint: Associate
the transduction TP = f(f(u); g(u)) j u 2 \Sigma + with each instance P = (f; g) of the
Post correspondance Problem. Consider Diff of example 50.2. Diff not = Diff [ TP if
and only if P satisfies Post property.

Exercise 65. Equivalence of deterministic rational transductions is decidable. Hint:
design a pumping lemma to reduce the problem to a bounded one by suppression of
loops (if the difference of lengths between two transduced subwords is not bounded,
the two transducers cannot be equivalent).

Exercise 66. Build a rational transducer equivalent to a bimorphism. Hint: let f(q) !
q0(f) a transition rule of L. If \Phi (f) = ", introduce transduction rule "(q) ! q0(\Psi (f)).
If \Phi (f) = a0 : : : an, introduce new states q1; : : : ; qng and transduction rules a0(q) !
q1("); : : : ai(qi) ! qi+1("); : : : an(qn) ! q0(\Psi (f)).

Exercise 67. Build a bimorphism equivalent to a rational transducer. Hint: consider
the set \Delta  of transition rules as a new alphabet. We may speak of the first state q and
the second state q0 in a letter "f(q) ! q0(m)". The control language L is the set of
words over this alphabet, such that (i) the first state of the first letter is initial (ii) the
second state of the last letter is final (iii) in every two consecutive letters of a word,
the first state of the second equals the second state of the first. We define \Phi  and \Psi  by
\Phi (f(q)\Gamma  ? q0(m)) = f and \Psi (f(q)\Gamma  ? q0(m)) = m.

Exercise 68. Homomorphism inversion and applications. An homomorphism \Phi  is
non-increasing if for every symbol a, \Phi (a) is the empty word or a symbol.

1. For any morphism \Phi , find a bimorphism (\Phi 0; L; \Psi ) equivalent to \Phi \Gamma 1, with \Phi 0

non-increasing, and such that furthermore \Phi 0 is "-free if \Phi  is "-free. Hint: \Phi \Gamma 1
is equivalent to a transducer R (Exercise 66), and the output homomorphism \Phi 0
associated to R as in Exercise 67 is non-increasing. Furthermore, if \Phi  is "-free,
R and \Phi 0 are "-free.

2. Let \Phi  and \Psi  two homomorphism. If \Phi  is non-increasing, build a transducer

equivalent to \Psi  ffi \Phi \Gamma 1 (recall that this notation means that we apply \Psi  before
\Phi \Gamma 1). Hint and remark: as \Phi  is non-increasing, \Phi \Gamma 1 satisfies the inverse homomorphism property \Phi \Gamma 1(MM0) = \Phi \Gamma 1(M)\Phi \Gamma 1(M0) (for any pair of words or
languages M and M0). This property can be used to do constructions "symbol
by symbol". Here, it suffices that the transducer associates \Phi \Gamma 1(\Psi (a)) with a,
for every symbol a of the domain of \Psi .

3. Application: prove that classes of regular and context-free languages are closed

under bimorphisms (we admit that the intersection of a regular language with
a regular or context-free language, is respectively regular or context-free).

4. Other application: prove that bimorphisms are closed under composition. Hint

: remark that for any application f and set E, f(x; f(x)) j f(x) 2 Eg =
f(x; f(x)) j x 2 f\Gamma 1(E)g.

Exercise 69. We identify tree over symbols of arity 1 or 0 with words. Let relations
U = f(fna; fna) j n 2 Ng [ f(fnb; gnb) j n 2 Ng and D = f(ffna; ffna) j n 2

168 Tree transducers

Ng [ f(gfna; gfnb) j n 2 Ng. Prove that U is a deterministic linear complete bottomup transduction but not a deterministic top-down transduction. Prove that D is a
deterministic linear complete top-down transduction but not a deterministic bottomup transduction.

Exercise 70. Prove point 3 of Comparison Theorem. Hint. Use rule-by-rule techniques as in Exercise 71.

Exercise 71. Prove Composition Theorem. Hints: Prove 1 and 2 using composition
"rule-by-rule", illustrated as following. States of A ffi B are products of states of A
and states of B. Let f(q(x)) !A q0(g(x; g(x; a))) and g(q1(x); g(q2(y); a) !B q4(u).
Subterms substituted to x and y in the composition must be equal, and determinism
implies q1 = q2. Then we build new rule f((q; q1)(x)) !AffiB(q0; q4)(u). To prove 3
for example, associate q(g(x; y)) ! u(q0(x); q00(y)) with g(q0(x); q00(y)) ! q(u), and
inversely. For 4, Using ad hoc kinds of "rule-by-rule" constructions, prove DDTT ae
DCDTTffiLHOM and LHOMffiDCDTT ae DCDTTffiLHOM (L means linear, C complete,
D deterministic - and suffix DTT means top-down tree transducer as usually).

Exercise 72. Prove NDTT = HOM ffi NLDTT and NUTT = HOM ffi NLBTT. Hint: to
prove NDTT ae HOM ffi NLDTT use a homomorphism H to produce in advance as may
copies of subtrees of the input tree as the NDTT may need, ant then simulate it by a
linear NDTT.

Exercise 73. use constructions of composition theorem to reduce the number of
passes in process of Section 6.3.

Exercise 74. Prove recognizability theorem. Hint: as in exercise 71, "naive" constructions work.

Exercise 75. Prove Theorem 46. Hint: "naive" constructions work.
Exercise 76. Prove point 2 of Theorem 47. Hint: E denote the class of homomorphisms which are linear and symbol-to-symbol. L, LC, LCF denotes linear, linear complete, linear complete "-free homomorphisms, respectively. Prove LCS =
L ffi E = E ffi L and E\Gamma 1 ffi L ae L ffi E\Gamma 1. Deduce from these properties and from
point 1 of Theorem 47 that LB4 = E ffi LCFB2 ffi E\Gamma 1. To prove that LB3 6= LB4,
consider \Psi 1 ffi \Psi \Gamma 12 ffi \Phi  ffi \Phi \Gamma 1 ffi \Psi 2 ffi \Psi \Gamma 11 , with \Phi  of point 1 of Theorem 47; \Psi 1 identity on a, f(x), g(x; y), h(x; y; z), \Psi 1(e(x)) = x; \Psi 2 identity on a, f(x), g(x; y) and
\Psi 2(c(x; y; z) = b(b(x; y); z).

Exercise 77. Sketch of proof of LCFB2 = LCFB3 (difficult). Distance D(x; y; u) of
two nodes x and y in a tree u is the sum of the lengths of two branches which join x
and y to their younger common ancestor in u. D(x; u) denotes the distance of x to
the root of u.

Let H the class of deterministic top-down transducers T defined as follows: q0; : : : ; qn
are states of the transducer, q0 is the initial state. For every context, consider the result ui of the run starting from qi(u). 9k; 8 context u such that for every variable x
of u, D(x; u) ? k:

ffl u0 contains at least an occurrence of each variable of u,
ffl for any i, ui contains at least a non variable symbol,
ffl if two occurrences x0 and x00 of a same variable x occur in ui, D(x0; x"; ui) ! k.
Remark that LCF is included in H and that there is no right hand side of rule with
two occurrences of the same variable associated with the same state. Prove that

1. LCF\Gamma 1 ` Delabeling\Gamma 1 ffi H

6.7 Bibliographic notes 169

2. H ffi Delabeling\Gamma 1 ` Delabeling\Gamma 1 ffi H
3. H ` LCFB2
4. Conclude. Compare with Exercise 68
5. Define an algebraic structure on tuples of trees which generalizes the usual structure on trees, such that H becomes a class of homomorphisms.

Exercise 78. Prove that the image of a recognizable tree language by a linear tree
transducer is recognizable.

6.7 Bibliographic notes
First of all, let us precise that several surveys have been devoted (at least in
part) to tree transducers for 25 years. J.W. Thatcher [Tha73], one of the main
pioneer, did the first one in 1973, and F. G'ecseg and M. Steinby the last one
in 1996 [GS96]. Transducers are formally studied too in the book of F. G'ecseg
and M. Steinby [GS84] and in the survey of J.-C. Raoult [Rao92]. Survey of M.
Dauchet and S. Tison [DT92] develops links with homomorphisms.

In section 6.2, some examples are inspired by the old survey of Thatcher,
because seminal motivation remain, namely modelization of compilers or, more
generally, of syntax directed transformations as interfacing softwares, which are
always up to date. Among main precursors, we can distinguish D. Knuth (1968)
(as for most of the area in computer sciences!), Thatcher, W.S. Brainerd [Bra69],
A. Aho, J.D. Ullman [AU71], M. A. Arbib, E. G. Manes [AM78]. First approaches where very intricate with practice of compilation, and in some way,
present tree transducers are evolutions of Generalized syntax directed translations (B.S. Backer [Bak78] for example), which translate trees into strings. But
crucial role of tree structure have increased later.

Many generalizations have been introduced, for example Generalized finite
state transformations which generalize both the top-down and the bottom-up
tree transducers (J. Engelfriet [Eng77]); modular tree transducers (H. Vogler [EV91]);
synchronized tree automata (K. Salomaa [Sal94]); alternating tree automata
(G.Slutzki [Slu85]); deterministic top-down tree transducers with iterated lookahead (G. Slutzki, S. V`agv"olgyi [SV95]). Ground tree transducers GTT are
studied in Chapter 3 of this book. The first and the most natural generalization
was introduction of top-down tree transducers with look-ahead. We have seen
that "check and delete" property is specific to bottom-up tree transducers, and
that missing of this property in the non-complete top-down case induces non
closure under composition, even in the linear case (see theorem of composition).
Top-down transducers with regular look-ahead are able to recognize before the
application of a rule at a node of an input tree whether the subtree at a son of
this node belongs to a given recognizable tree language. This definition remains
simple and gives to top-down transducers a property equivalent to "check and
delete".

Contribution of Engelfriet to the theory of tree transducers is important,
especially for composition, decomposition and hierarchy main results ([Eng75,
Eng78, Eng82]).

We did not many discuss complexity and decidability in this chapter, because the situation is classical. As many problems are undecidable in the word
case, they are obviously undecidable in the tree case. Equivalence decidability

170 Tree transducers

states as in the word case for deterministic or finite-valued tree transducers (Z.
Zachar [Zac79], Z. Esik [Esi83], H. Seidl [Sei92, Sei94a]). Complexity results
are neither surprising nor exciting: most of problems are untractable in the
worst case, but empirically "not so much complex", though almost neither deep
analysis of algorithms nor average complexity results exist. The problem is the
same, but accentuated, as for words automata. Word automata are a basic
model for critical (real-time) program checking, but there is a lake of "algorithmic engineering" to get efficient algorithms. The bimorphism point of view is
very illuminating in the general word case, it links algorithmic and algebraic
point of view. Our thesis is that it is so illuminating in the tree case for linear
transformations, and that the class LCFB2 captures exactly the notion of "local
transformation", and that these results could be exported in physical studies.

This chapter assumes subjectivity about the subject. Presentation, results
and bibliography are chosen, then incomplete. Opinion of authors is

? It is useful for every theoretical computer scientist to know main notions

about tree transducers, because they are THE model of syntax directed
manipulations, and that the hart of software manipulations and interfaces
are syntax directed.

? and tree transducers are an essential frame to develop practical modular

syntax directed algorithms, thought an effort of algorithmic engineering
remains to do.

? and tree transducers theory can be fertilized by other area or can be useful

for other areas (example: Ground tree transducers for decidability of the
first order theory of ground rewriting).

A reader who would became fanatic of tree transducers theory after reading
this chapter (my god!), would begin by reading through the ages, the old but nice
survey of Thatcher for motivations, Engelfriet papers for basic results, perhaps
Arnold, Dauchet [AD82] for bimorphisms point of view, and G'ecseg and M.
Steinby [GS96] for a formal and recent survey, with complete bibliography.

Bibliography
[AD82] A. Arnold and M. Dauchet. Morphismes et bimorphismes d'arbres.

Theorical Computer Science, 20:33-93, 1982.

[AG68] M. A. Arbib and Y. Give'on. Algebra automata I: Parallel programming as a prolegomena to the categorical approach. Information
and Control, 12(4):331-345, April 1968.

[AKVW93] A. Aiken, D. Kozen, M. Vardi, and E. Wimmers. The complexity

of set constraints. In B"orger et al. [BGM93], pages 1-17. Techn.
Report 93-1352, Cornell University.

[AKW95] Alexander Aiken, Dexter Kozen, and Ed Wimmers. Decidability of

systems of set constraints with negative constraints. Information
and Computation, 122(1):30-44, October 1995.

[AM78] M.A. Arbib and E.G. Manes. Tree transformations and semantics

of loop-free programs. Acta Cybernetica, 4:11-17, 1978.

[AM91] A. Aiken and B. R. Murphy. Implementing regular tree expressions.

In Proceedings of the ACM conf. on Functional Programming Languages and Computer Architecture, pages 427-447, 1991.

[AU71] A. V. Aho and J. D. Ullmann. Translations on a context-free grammar. Information and Control, 19:439-475, 1971.

[AW92] A. Aiken and E.L. Wimmers. Solving Systems of Set Constraints.

In zzzzzlics7 [zzz92], pages 329-340.

[Bak78] B.S. Baker. Generalized syntax directed translation, tree transducers, and linear space. Journal of Comput. and Syst. Sci., 7:876-891,
1978.

[BGM93] E. B"orger, Y. Gurevich, and K. Meinke, editors. Proceedings of

Computer Science Logic, volume 832 of Lecture Notes in Computer
Science, 1993.

[BGW93] L. Bachmair, H. Ganzinger, and U. Waldmann. Set constraints are

the monadic class. In Proceedings, Eighth Annual IEEE Symposium on Logic in Computer Science, pages 75-83. IEEE Computer
Society Press, 19-23 June 1993.

[Bra68] Walter S. Brainerd. The minimalization of tree automata. Information and Control, 13(5):484-491, November 1968.

172 BIBLIOGRAPHY

[Bra69] W. S. Brainerd. Tree generating regular systems. Information and

Control, 14(2):217-231, February 1969.

[BT92] B. Bogaert and S. Tison. Equality and disequality constraints on direct subterms in tree automata. In Patrice Enjalbert, Alain Finkel,
and Klaus W. Wagner, editors, 9th Annual Symposium on Theoretical Aspects of Computer Science, volume 577 of Lecture Notes
in Computer Science, pages 161-171, 1992.

[B"uc60] J.R. B"uchi. On a decision method in a restricted second order

arithmetic. In Stanford Univ. Press., editor, Proc. Internat. Congr.
on Logic, Methodology and Philosophy of Science, pages 1-11, 1960.

[CCC+94] A.C. Caron, H. Comon, J.L. Coquid'e, M. Dauchet, and F. Jacquemard. Pumping, cleaning and symbolic constraints solving. In Proceedings, International Colloquium Automata Languages and Programming, volume 820 of Lecture Notes in Computer Science, pages
436-449, 1994.

[CD94] Hubert Comon and Catherine Delor. Equational formulae

with membership constraints. Information and Computation,
112(2):167-216, August 1994.

[CDGV94] J.L. Coquide, M. Dauchet, R. Gilleron, and S. Vagvolgyi. Bottomup tree pushdown automata : Classification and connection with
rewrite systems. Theorical Computer Science, 127:69-98, 1994.

[Chu62] A. Church. Logic, arithmetic, automata. In Proc. International

Mathematical Congress, 1962.

[CK96] A. Cheng and D. Kozen. A complete Gentzen-style axiomatization

for set constraints. In Proceedings, International Colloquium Automata Languages and Programming, volume 1099 of Lecture Notes
in Computer Science, pages 134-145, 1996.

[Com89] H. Comon. Inductive proofs by specification transformations. In

Proceedings, Third International Conference on Rewriting Techniques and Applications, volume 355 of Lecture Notes in Computer
Science, pages 76-91, 1989.

[Com95] H. Comon. Sequentiality, second-order monadic logic and tree automata. In zzzzzlics10 [zzz95].

[Cou89] B. Courcelle. On Recognizable Sets and Tree Automata, chapter

Resolution of Equations in Algebraic Structures. Academic Press,
m. Nivat and Ait-Kaci edition, 1989.

[Cou92] B. Courcelle. Recognizable sets of unrooted trees. In M. Nivat

and A. Podelski, editors, Tree Automata and Languages. Elsevier
Science, 1992.

[CP94a] W. Charatonik and L. Pacholski. Negative set constraints with

equality. In zzzzzlics9 [zzz94], pages 128-136.

BIBLIOGRAPHY 173
[CP94b] W. Charatonik and L. Pacholski. Set constraints with projections

are in NEXPTIME. In Proceedings of the 35th Symp. Foundations
of Computer Science, pages 642-653, 1994.

[CP97] W. Charatonik and A. Podelski. Set Constraints with Intersection. In Proceedings, 12th Annual IEEE Symposium on Logic in
Computer Science. IEEE Computer Society Press, 1997.

[Dau94] M. Dauchet. Rewriting and tree automata. In H. Comon and J.-P.

Jouannaud, editors, Proc. Spring School on Theoretical Computer
Science: Rewriting, Lecture Notes in Computer Science, Odeillo,
France, 1994. Springer Verlag.

[DCC95] M. Dauchet, A.-C. Caron, and J.-L. Coquid'e. Reduction properties

and automata with constraints. Journal of Symbolic Computation,
20:215-233, 1995.

[DJ90] N. Dershowitz and J.P. Jouannaud. Handbook of Theoretical Computer Science, volume B, chapter Rewrite Systems, pages 243-320.
Elsevier, 1990.

[Don65] J. E. Doner. Decidability of the weak second-order theory of two

successors. Notices Amer. Math. Soc., 12:365-468, March 1965.

[Don70] J. E. Doner. Tree acceptors and some of their applications. Journal

of Comput. and Syst. Sci., 4:406-451, 1970.

[DT90] M. Dauchet and S. Tison. The theory of ground rewrite systems is

decidable. In zzzzzlics5 [zzz90], pages 242-248.

[DT92] M. Dauchet and S. Tison. Structural complexity of classes of tree

languages. In M. Nivat and A. Podelski, editors, Tree Automata
and Languages, pages 327-353. Elsevier Science, 1992.

[DTHL87] Max Dauchet, Sophie Tison, Thierry Heuillard, and Pierre Lescanne. Decidability of the confluence of ground term rewriting
systems. In Proceedings, Symposium on Logic in Computer Science, pages 353-359. The Computer Society of the IEEE, 22-25
June 1987.

[DTT97] P. Devienne, JM. Talbot, and S. Tison. Solving classes of set constraints with tree automata. In G. Smolka, editor, Proceedings
of the 3th International Conference on Principles and Practice of
Constraint Programming, Lecture Notes in Computer Science, oct
1997. to appear.

[Eng75] J. Engelfriet. Bottom-up and top-down tree transformations. a

comparision. Mathematical System Theory, 9:198-231, 1975.

[Eng77] J. Engelfriet. Top-down tree transducers with regular look-ahead.

Mathematical System Theory, 10:198-231, 1977.

[Eng78] J. Engelfriet. A hierarchy of tree transducers. In Proceedings of the

third Les Arbres en Alg`ebre et en Programmation, pages 103-106,
Lille, 1978.

174 BIBLIOGRAPHY

[Eng82] J. Engelfriet. Three hierarchies of transducers. Mathematical System Theory, 15:95-125, 1982.

[Esi83] Z. Esik. Decidability results concerning tree transducers. Acta

Cybernetica, 5:303-314, 1983.

[EV91] J. Engelfriet and H. Vogler. Modular tree transducers. Theorical

Computer Science, 78:267-303, 1991.

[EW67] S. Eilenberg and J. B. Wright. Automata in general algebras. Information and Control, 11(4):452-470, 1967.

[FSVY91] T. Fr"uhwirth, E. Shapiro, M.Y. Vardi, and E. Yardeni. Logic Programs as Types for Logic Programs. In Proceedings, Sixth Annual
IEEE Symposium on Logic in Computer Science. IEEE Computer
Society Press, 15-18 July 1991.

[FV88] Z. F"ul"op and S. V'agv"olgyi. A characterization of irreducible sets

modulo left-linear term rewiting systems by tree automata. Un
type rr ??, Research Group on Theory of Automata, Hungarian
Academy of Sciences, H-6720 Szeged, Somogyi u. 7. Hungary, 1988.

[FV89] Z. F"ul"op and S. V'agv"olgyi. Congruential tree languages are the

same as recognizable tree languages-A proof for a theorem of D.
kozen. Bulletin of the European Association of Theoretical Computer Science, 39, 1989.

[Gan96] H. Ganzinger, editor. Proceedings. Seventh International Conference on Rewriting Techniques and Applications, volume 1103 of
Lecture Notes in Computer Science, 1996.

[GB85] J.H. Gallier and R.V. Book. Reductions in tree replacement systems. Theorical Computer Science, 37(2):123-150, 1985.

[GS84] F. G'ecseg and M. Steinby. Tree Automata. Akademiai Kiado, 1984.
[GS96] F. G'ecseg and M. Steinby. Tree languages. In G. Rozenberg and

A. Salomaa, editors, Handbook of Formal Languages, volume 3,
pages 1-68. Springer Verlag, 1996.

[GT95] R. Gilleron and S. Tison. Regular tree languages and rewrite systems. Fundamenta Informaticae, 24:157-176, 1995.

[GTT93] R. Gilleron, S. Tison, and M. Tommasi. Solving systems of set

constraints with negated subset relationships. In Proceedings of
the 34th Symp. on Foundations of Computer Science, pages 372-
380, 1993. Full version in the LIFL Tech. Rep. IT-247.

[Hei92] N. Heintze. Set Based Program Analysis. PhD thesis, Carnegie

Mellon University, 1992.

[HJ90a] N. Heintze and J. Jaffar. A Decision Procedure for a Class of Set

Constraints. In zzzzzlics5 [zzz90], pages 42-51.

BIBLIOGRAPHY 175
[HJ90b] N. Heintze and J. Jaffar. A finite presentation theorem for approximating logic programs. In Proceedings of the 17th ACM Symp. on
Principles of Programming Languages, pages 197-209, 1990. Full
version in the IBM tech. rep. RC 16089 (#71415).

[HJ92] N. Heintze and J. Jaffar. An engine for logic program analysis. In

zzzzzlics7 [zzz92], pages 318-328.

[HL91] G'erard Huet and Jean-Jacques L'evy. Computations in orthogonal rewriting systems I. In J.-L. Lassez and G. Plotkin, editors,
Computational Logic: Essays in Honor of Alan Robinson, pages
395-414. MIT Press, 1991. This paper was written in 1979.

[HU79] J.E. Hopcroft and J.D. Ullman. Introduction to Automata Theory,

Languages, and Computation. Addison Wesley, 1979.

[Jac96] Florent Jacquemard. Decidable approximations of term rewriting

systems. In Ganzinger [Gan96].

[JM79] N.D. Jones and S.S. Muchnick. Flow Analysis and Optimization of

LISP-like Structures. In Proceedings of the 6th ACM Symposium
on Principles of Programming Languages, pages 244-246, 1979.

[Jon87] Neil Jones. Abstract interpretation of declarative languages, chapter

Flow analysis of lazy higher-order functional programs, pages 103-
122. Ellis Horwood Ltd, 1987.

[Koz92] D. Kozen. On the Myhill-Nerode theorem for trees. Bulletin of

the European Association of Theoretical Computer Science, 47:170-
173, June 1992.

[Koz93] D. Kozen. Logical aspects of set constraints. In B"orger et al.

[BGM93], pages 175-188.

[Koz94] D. Kozen. Set constraints and logic programming. In Proceedings,

First International Conference on Constraints in Computational
Logics, volume 845 of Lecture Notes in Computer Science. Springer
Verlag, 1994. To appear in Information and Computation.

[Koz95] D. Kozen. Rational spaces and set constraints. In Proceedings of

the 6th International Joint Conference on Theory and Practice of
Software Development, volume 915 of Lecture Notes in Computer
Science, pages 42-61, 1995.

[Kuc91] G. A. Kucherov. On relationship between term rewriting systems

and regular tree languages. In R. Book, editor, Proceedings. Fourth
International Conference on Rewriting Techniques and Applications, volume 488 of Lecture Notes in Computer Science, pages
299-311, April 1991.

[LM87] J.-L. Lassez and K. Marriott. Explicit representation of terms

defined by counter examples. Journal of Automated Reasoning,
3(3):301-318, September 1987.

176 BIBLIOGRAPHY

[LM93] D. Lugiez and J.-L. Moysset. Complement problems and tree automata in AC-like theories. In Patrice Enjalbert, Alain Finkel,
and Klaus W. Wagner, editors, 10th Annual Symposium on Theoretical Aspects of Computer Science, volume 665 of Lecture Notes
in Computer Science, pages 515-524, W"urzburg, 25-27 February
1993.

[LM94] Denis Lugiez and Jean-Luc Moysset. Tree automata help one to

solve equational formulae in ac-theories. Journal of Symbolic Computation, 18(4):297-318, 1994.

[MGKW96] D. McAllester, R. Givan, D. Kozen, and C. Witty. Tarskian set constraints. In Proceedings, 11th Annual IEEE Symposium on Logic in
Computer Science, pages 138-141. IEEE Computer Society Press,
27-30 July 1996.

[Mis84] P. Mishra. Towards a Theory of Types in PROLOG. In Proceedings

of the 1st IEEE Symposium on Logic Programming, pages 456-461,
Atlantic City, 1984.

[Mon81] J. Mongy. Transformation de noyaux reconnaissables d'arbres.

For^ets RATEG. PhD thesis, Laboratoire d'Informatique Fondamentale de Lille, Universit'e des Sciences et Technologies de Lille,
Villeneuve d'Ascq, France, 1981.

[MS96] A. Mateescu and A. Salomaa. Aspects of classical language theory.

In G. Rozenberg and A. Salomaa, editors, Handbook of Formal
Languages, volume 1, pages 175-246. Springer Verlag, 1996.

[MW67] J. Mezei and J. B. Wright. Algebraic automata and context-free

sets. Information and Control, 11:3-29, 1967.

[Niv68] M. Nivat. Transductions des langages de Chomsky. Th`ese d'etat,

Paris, 1968.

[NP89] M. Nivat and A. Podelski. Resolution of Equations in Algebraic

Structures, volume 1, chapter Tree monoids and recognizable sets
of finite trees, pages 351-367. Academic Press, New York, 1989.

[NP93] Joachim Niehren and Andreas Podelski. Feature automata and

recognizable sets of feature trees. In Proceedings TAPSOFT'93,
volume 668 of Lecture Notes in Computer Science, pages 356-375,
1993.

[Oya93] M. Oyamaguchi. NV-sequentiality: a decidable condition for callby-need computations in term rewriting systems. SIAM Journal
on Computing, 22(1):114-135, 1993.

[Pla85] D.A. Plaisted. Semantic confluence tests and completion method.

Information and Control, 65:182-215, 1985.

[Pod92] Podelski. A monoid approach to tree automata. In Nivat and Podelski, editors, Tree Automata and Languages, Studies in Computer
Science and Artificial Intelligence 10, North-Holland. 1992.

BIBLIOGRAPHY 177
[Rab69] M.O. Rabin. Decidability of Second-Order Theories and Automata

on Infinite Trees. Transactions of the American Mathematical Society, 141:1-35, 1969.

[Rab77] M.O. Rabin. Handbook of Mathematical Logic, chapter Decidable

theories, pages 595-627. North Holland, 1977.

[Rao92] J.-C. Raoult. A survey of tree transductions. In M. Nivat and

A. Podelski, editors, Tree Automata and Languages, pages 311-
325. Elsevier Science, 1992.

[Rey69] J.C. Reynolds. Automatic Computation of Data Set Definition.

Information Processing, 68:456-461, 1969.

[Sal73] A. Salomaa. Formal Languages. Academic Press, New York, 1973.
[Sal88] K. Salomaa. Deterministic tree pushdown automata and monadic

tree rewriting systems. Journal of Comput. and Syst. Sci., 37:367-
394, 1988.

[Sal94] K. Salomaa. Synchronized tree automata. Theorical Computer

Science, 127:25-51, 1994.

[Sei89] H. Seidl. Deciding equivalence of finite tree automata. In Annual

Symposium on Theoretical Aspects of Computer Science, 1989.

[Sei90] H. Seidl. Deciding equivalence of finite tree automata. SIAM Journal on Computing, 19, 1990.

[Sei92] H. Seidl. Single-valuedness of tree transducers is decidable in polynomial time. Theorical Computer Science, 106:135-181, 1992.

[Sei94a] H. Seidl. Equivalence of finite-valued tree transducers is decidable.

Mathematical System Theory, 27:285-346, 1994.

[Sei94b] H. Seidl. Haskell overloading is DEXPTIME-complete. Information

Processing Letters, 52(2):57-60, 1994.

[Sey94] F. Seynhaeve. Contraintes ensemblistes. Master's thesis, LIFL,

1994.

[Slu85] G. Slutzki. Alternating tree automata. Theorical Computer Science, 41:305-318, 1985.

[SM73] L.J. Stockmeyer and A.R. Meyer. Word problems requiring exponential time. In Proc. 5th ACM Symp. on Theory of Computing,
pages 1-9, 1973.

[Ste94] K. Stefansson. Systems of set constraints with negative constraints

are nexptime-complete. In zzzzzlics9 [zzz94], pages 137-141.

[SV95] G. Slutzki and S. Vagvolgyi. Deterministic top-down tree transducers with iterated look-ahead. Theorical Computer Science, 143:285-
308, 1995.

178 BIBLIOGRAPHY

[Tha70] J. W. Thatcher. Generalized sequential machines. Journal of Comput. and Syst. Sci., 4:339-367, 1970.

[Tha73] J.W. Thatcher. Tree automata: an informal survey. In A.V. Aho,

editor, Currents in the theory of computing, pages 143-178. Prentice Hall, 1973.

[Tho90] W. Thomas. Handbook of Theoretical Computer Science, volume B,

chapter Automata on Infinite Objects, pages 134-191. Elsevier,
1990.

[Tom92] M. Tommasi. Automates d'arbres avec tests d''egalit'e entre cousins

germains. M'emoire de DEA, Univ. Lille I, 1992.

[Tom94] M. Tommasi. Automates et contraintes ensemblistes. PhD thesis,

LIFL, 1994.

[Tra95] Boris Trakhtenbrot. Origins and metamorphoses of the trinity:

Logic, nets, automata. In zzzzzlics10 [zzz95].

[Tre96] Ralf Treinen. The first-order theory of one-step rewriting is undecidable. In Ganzinger [Gan96], pages 276-286.

[TW65] J. W. Thatcher and J. B. Wright. Generalized finite automata.

Notices Amer. Math. Soc., 820, 1965. Abstract No 65T-649.

[TW68] J.W. Thatcher and J.B. Wright. Generalized finite automata with

an application to a decision problem of second-order logic. Mathematical System Theory, 2:57-82, 1968.

[Uri92] T. E. Uribe. Sorted Unification Using Set Constraints. In D. Kapur, editor, Proceedings of the 11th International Conference on
Automated Deduction, New York, 1992.

[Vea97a] M. Veanes. On computational complexity of basic decision problems of finite tree automata. Technical report, Uppsala Computing
Science Department, 1997.

[Vea97b] M. Veanes. On simultaneous Rigid E-Unification. PhD thesis,

Uppsala, 1997.

[Zac79] Z. Zachar. The solvability of the equivalence problem for deterministic frontier-to-root tree transducers. Acta Cybernetica, 4:167-177,
1979.

[zzz90] IEEE Computer Society Press. Proceedings, Fifth Annual IEEE

Symposium on Logic in Computer Science, 4-7 June 1990.

[zzz92] IEEE Computer Society Press. Proceedings, Seventh Annual IEEE

Symposium on Logic in Computer Science, 22-25 June 1992.

[zzz94] IEEE Computer Society Press. Proceedings, Ninth Annual IEEE

Symposium on Logic in Computer Science, 4-7 July 1994.

[zzz95] IEEE Computer Society Press. Proceedings, Tenth Annual IEEE

Symposium on Logic in Computer Science, 26-29 June 1995.

Index
ff-equivalence, 86
fi-reduction, 87
ffl-free, 28
ffl-rules, 17
j-long form, 86
j=, 72, 96
Rec, 62
Rec\Theta , 61
AWCBB, 102

axiom, 41
equivalent, 42
non-terminal, 41
regular tree grammars, 42
terminal, 41

acceptance

by an automaton, 96
accessible, 18
alphabetic, 28
arity, 11
automaton

2-automaton, 87
reduction automaton, 108
with constraints between brothers, 102
with equality and disequality constraints, 96

bimorphism

word, 153

closed, 12
closure, 46
closure properties

for Rec\Theta ,Rec, 66
for GTTs, 68
closure property, 23

complementation, 23
intersection, 23
union, 23
complete, 28

complete specification

of an automaton with constraints,

98
concatenation, 45
congruence, 29

finite index, 29
constraint

disequality constraint, 96
equality constraint, 96
context, 11
context-free tree grammar, 55
context-free tree language, 55
context-free word grammar, 53
cylindrification, 67

definable

set, 75
delabeling, 28
derivation relation, 42
derivation trees, 53
determinacy

of an automaton with constraints,

98
determinization, 19, 99
DFTA, see tree automaton
domain, 12
DUTT, see tree transducer

encompassment, 81, 96
encompassment theory, 111
equivalent, 15

f, 113
Flat terms, 112
free variables, 86
frontier position, 12
FTA, see tree automaton

generalized tree set, 130

accepted, 131
regular, 135

180 INDEX

generalized tree set automaton, 130,

see GTSA
ground reducibility, 82, 108, 111
ground rewriting

theory of, 84
ground substitution, 12
ground terms, 11
Ground Tree Transducer, 62
GTS, see generalized tree set
GTSA

complete, 131
deterministic, 131
run, 131
simple, 131
strongly deterministic, 131
sucessful run, 131
GTT, 62, 63

height, 12
index, 84
IO, 56

language

accepted by an automaton with

constraints, 97
recognizable, 15
recognized, 15
linear, 11, 25
local, 57

matching problem, 87
monotonic

predicate, 84
move relation

for NFTA, 14
for rational transducers, 150
Myhill-Nerode Theorem, 29

NBTT, see tree transducer
NDTT, see tree transducer
NFTA, see tree automaton
normalized, 43

OI, 56
order, 86
order-sorted signatures, 80
overlapping constraints, 121

position, 12
Presburger's arithmetic, 59

production rules, 42
productive, 42
program analysis, 125
projection, 67
pumping lemma, 22

for automata with constraints

between brothers, 105

Rabin

automaton, 60, 80
theorem, 80
ranked alphabet, 11
RATEG, 95
reachable, 42
recognition

by an automaton, 96
reduced, 42
reducibility

theory, 82
reducibility theory, 111
regular equation systems, 50
regular tree expressions, 47
relation

rational relation, 89
of bounded delay, 89
replacement

simultaneous replacement, 105
root symbol, 12
rules

ffl-rules, 17
run, 16

of an automaton, 96
successful, 16

sequential calculus, 59
sequentiality, 85
set constraints, 125
size, 12

of a constraint, 97
of an automaton with constraints,

98
SkS, 72
solution, 87
sort

constraint, 80
expression, 80
symbol, 80
state

accessible, 18
dead, 18

INDEX 181
substitution, 12
subterm, 12
subterm ordering, 12
symbol to symbol, 28
synchronization states, 63

temporal logic

propositional linear time temporal logic, 91
term

accepted, 15
in the simply typed lambda calculus, 86
well-formed, 80
terms, 11, 86
theory

of reducibility, 82
transducer

"-free, 150
rational, 150
transition rules, 96
tree, 11
tree automaton

product, 24
tree homomorphism

ffl-free, 28
tree automaton

generalized, see GTSA
reduced, 19
tree automaton, 14

complete, 18
deterministic, 17
reduced, 18
reduction automaton, 96
top down, 31
with ffl-rules, 17
with constraints between brothers, 95
tree grammar, 41
tree homomorphism, 25

alphabetic, 28
complete, 28
delabeling, 28
linear, 25
symbol to symbol, 28
tree substitution, 45
tree transducer

"-free, 161
bottom-up, 161
complete, 161

deterministic, 161
linear, 161
non-erasing, 161
top-down, 162
type

in the simply typed lambda calculus, 86
type inference, 125

variable position, 12
variables, 11

Weak Second-order monadic logic with

K successors, 79
WS1S, 59
WSkS, 59, 72, 79

Yield, 53