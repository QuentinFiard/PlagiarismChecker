

Artificial Intelligence 140 (2002) 1-37

www.elsevier.com/locate/artint

Binary vs. non-binary constraints \Delta 
Fahiem Bacchus a, Xinguang Chen b, Peter van Beek c,*, Toby Walsh d

a Department of Computer Science, University of Toronto, Toronto, ON, Canada
b Department of Computing Science, University of Alberta, Edmonton, AB, Canada

c Department of Computer Science, University of Waterloo, Waterloo, ON, Canada

d Department of Computer Science, University of York, York, England, UK

Received 17 January 2001; received in revised form 11 December 2001

Abstract

There are two well known transformations from non-binary constraints to binary constraints
applicable to constraint satisfaction problems (CSPs) with finite domains: the dual transformation
and the hidden (variable) transformation. We perform a detailed formal comparison of these two
transformations. Our comparison focuses on two backtracking algorithms that maintain a local
consistency property at each node in their search tree: the forward checking and maintaining arc
consistency algorithms. We first compare local consistency techniques such as arc consistency in
terms of their inferential power when they are applied to the original (non-binary) formulation and
to each of its binary transformations. For example, we prove that enforcing arc consistency on the
original formulation is equivalent to enforcing it on the hidden transformation. We then extend these
results to the two backtracking algorithms. We are able to give either a theoretical bound on how
much one formulation is better than another, or examples that show such a bound does not exist. For
example, we prove that the performance of the forward checking algorithm applied to the hidden
transformation of a problem is within a polynomial bound of the performance of the same algorithm
applied to the dual transformation of the problem. Our results can be used to help decide if applying
one of these transformations to all (or part) of a constraint satisfaction model would be beneficial.
(C) 2002 Elsevier Science B.V. All rights reserved.

Keywords: Non-binary constraints; Constraint satisfaction; Dual encoding; Hidden variable encoding

\Delta  This paper includes results that first appeared in [1,4,23]. This research has been supported in part by
the Canadian Government through their NSERC and IRIS programs, and by the EPSRC Advanced Research
Fellowship program.*

Corresponding author.
E-mail addresses: fbacchus@cs.toronto.edu (F. Bacchus), xinguang@cs.ualberta.ca (X. Chen),
vanbeek@uwaterloo.ca (P. van Beek), tw@cs.york.ac.uk (T. Walsh).

0004-3702/02/$ - see front matter (C) 2002 Elsevier Science B.V. All rights reserved.
PII: S0004-3702(02)0021 0-2

2 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
1. Introduction

To model a problem as a constraint satisfaction problem (CSP), we specify a searchspace using a set of variables each of which can be assigned a value from some finite
domain of values. To specify the assignments that solve the problem, the model includesconstraints that restrict the set of acceptable assignments. Each constraint is over some
subset of the variables and imposes a restriction on the simultaneous values these variablesmay take. In general, there are many possible ways of modeling a problem as a CSP. Each
model might contain a different set of variables, domains, and constraints. The choice ofmodel can have a large impact on the time it takes to find a solution [3,17,21], and various
modeling techniques have been developed, including adding redundant and symmetry-breaking constraints [9,22,25], adding hidden variables [6,24], aggregating or grouping
variables together [3,7], and transforming a CSP model into an equivalent representationover a different set of variables [7,11,19,26].

One important modeling decision is the arity of the constraints used. Constraints can beeither binary over pairs of variables, or non-binary over three or more variables. Although
a problem may be naturally modeled with non-binary constraints, these constraints canbe easily (and automatically) transformed into binary constraints. Many CSP search
algorithms are designed specifically for binary constraints, and furthermore, like allmodeling decisions, the choice of binary or non-binary constraints can have a significant
impact on the time it takes to solve the CSP.In general, there is much research that remains to be done on the question of which
modeling techniques one should choose when attacking a particular problem. In thispaper, we formally study the effectiveness of two modeling techniques that can be used to
transform a general (non-binary) CSP model into an equivalent binary CSP: the dual andhidden transformations [7,19]. Our results give some guidance on the question of choosing
between binary and non-binary constraints. Further, the dual and hidden transformationscan be seen as extensions of the widely used techniques of aggregating variables together or
adding hidden variables to reduce the arity of constraints and thus our results also provideinformation about these modeling techniques.

The choice of a CSP model also depends on the algorithm that will be used to solve themodel. We focus here on backtracking search algorithms that maintain a local consistency
property at each node in their search tree. Various types of local consistency have beendefined, and algorithms developed for enforcing them (e.g., [5,13,14]). Algorithms that
maintain a local consistency property during backtracking search (e.g., [8,10,15,16,20])can detect dead-ends sooner and thus have the potential of significantly reducing the size
of the tree they have to search. Such algorithms have demonstrated significant empiricaladvantages and are the algorithms of choice in practice. Hence, they are the most relevant
objects of study.We compare the performance of local consistency techniques and backtracking
algorithms on three different models of a problem: the original formulation, the dualtransformation, and the hidden transformation. For the local consistency techniques, we
establish whether a local consistency property on one model is stronger than or equivalentto a local consistency property on another. Among other results, we prove that arc
consistency on the original formulation is equivalent to arc consistency on the hidden

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 3
transformation, but that arc consistency on the dual transformation is stronger than arcconsistency on the original formulation. For backtracking algorithms, we give either a
theoretical bound on how much better one model can be over another when using agiven algorithm, or we give examples to show that no such polynomial bound exists. For
example, we prove that the performance of an algorithm that maintains arc consistencywhen applied to the original formulation is equal to its performance when applied to the
hidden transformation. As another example, we also show that the performance of theforward checking algorithm on the hidden transformation is never more than a polynomial
factor worse than its performance on the dual, but that its performance on the dualcan be an exponential factor worse than its performance on the hidden. Hence we have
good theoretical reasons to prefer using the forward checking algorithm on the hiddentransformation rather than on the dual transformation. In this way, our results can provide
general guidelines as to which transformation, if any, should be applied to a non-binaryCSP.

2. Background

In this section, we formally define constraint satisfaction problems and the dual andhidden transformations. In addition we briefly review local consistency techniques and the
search tree explored by backtracking algorithms.
2.1. Basic definitions
Definition 1 (Constraint Satisfaction Problem (CSP)). A constraint satisfaction problem,P, is a tuple

(V, D, C) whose components are defined below.

* V = {x1, . . . , xn} is a finite set of n variables.* D = {dom

(x1), . . . , dom(xn)} is a set of domains. Each variable x \Sigma  V has acorresponding finite domain of possible values, dom

(x).* C = {
C1, . . . , Cm} is a set of m constraints. Each constraint C \Sigma  C is a pair
(vars(C), rel(C)) defined as follows.1. vars

(C) is an ordered subset of the variables, called the constraint scheme. The sizeof vars

(C) is known as the arity of the constraint. A binary constraint has arityequal to 2; a non-binary constraint has arity greater than 2.

2. rel(C) is a set of tuples over vars(C), called the constraint relation, that specifiesthe allowed combinations of values for the variables in vars

(C). A tuple over anordered set of variables
X = {x1, . . . , xk} is an ordered list of values (a1, . . . , ak)such that
ai \Sigma  dom(xi), i = 1, . . . , k. A tuple over X can also be viewed as a set ofvariable-value assignments {

x1 \Upsilon  a1, . . . , xk \Upsilon  ak}.

Throughout the paper, we use n, d, m, and r to denote the number of variables, thesize of the largest domain, the number of constraints, and the arity of the largest constraint
scheme in the CSP, respectively. As well, we assume throughout that for any variable x \Sigma  V,there is at least one constraint

C \Sigma  C such that x \Sigma  vars(C).

4 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
Example 1. Propositional satisfiability (SAT) problems can be formulated as CSPs.
Consider a SAT problem with 6 propositions, x1, . . . , x6, and 4 clauses, (1) x1 \Phi  x3 \Phi  x6,
(2) ~x1 \Phi  ~x3 \Phi  x4, (3) x4 \Phi  ~x5 \Phi  x6 and (4) x2 \Phi  x4 \Phi  ~x5. In one CSP representation
of this SAT problem, there is a variable for each proposition, x1, . . . , x6, each variable
has the domain of values {0, 1}, and there is a constraint for each clause, C1(x1, x3, x6),
C2(x1, x3, x4), C3(x4, x5, x6) and C4(x2, x4, x5). Each constraint specifies the value
combinations that will make its corresponding clause true. For example, C4(x2, x4, x5),
the constraint associated with the clause x2 \Phi  x4 \Phi  ~x5, allows all tuples over the variables
x2, x4, and x5 except the falsifying assignment (0, 0, 1).

We use the notation vars(t) to denote the set of variables a tuple t is over. If X is any
subset of vars(t) then t[X] is used to denote the tuple over X that is obtained by restricting
t to the variables in X. Given a constraint C and a subset of its variables S fi vars(C),
the projection jSC is a new constraint, where vars(jSC) = S and rel(jSC) = {t[S] | t \Sigma 
rel(C)}.

An assignment to a set of variables X is simply a tuple over X. An assignment t
is consistent if, for all constraints C such that vars(C) fi vars(t), t[vars(C)] \Sigma  rel(C).
A solution to a CSP is a consistent assignment to all of the variables in the CSP. If no
solution exists, the CSP is said to be insoluble.

Local consistency is an important concept in CSPs. Local consistencies are properties
of CSPs that are defined over "local" parts of the CSP, e.g., properties defined over subsets
of the variables and constraints of the CSP. Many local consistency properties on CSPs
have been defined (see [5] for a large collection).

Local consistency properties are generally neither necessary nor sufficient conditions
for a CSP to be soluble. For example, it is quite possible for a CSP that is not arc consistent
to have solutions, and for an arc consistent CSP to be insoluble. The importance of local
consistency properties arise instead from the existence of (typically polynomial) algorithms
for enforcing these properties.

We say that a local consistency property LC can be enforced if there exists a
(computable) function from CSPs to new CSPs, such that if P is a CSP then LC(P) is
a new CSP with the same set of solutions (and thus it must necessarily have the same set
of variables).1 We call applying this function to a CSP enforcing the local consistency.
Furthermore, we require that LC(P) satisfy the property LC, i.e., enforcing LC must yield
a CSP satisfying LC, and that if P satisfies LC then LC(P) = P, i.e., enforcing a local
consistency on a CSP that already satisfies it does not change the CSP. The reason for
enforcing a local consistency property is that often LC(P) is easier to solve than P.

In this paper we further restrict our attention to local consistency properties whose
enforcement involves only three types of transformations to the CSP: (1) the domains of
some of the variables might be reduced, (2) some constraint relations might be reduced
(i.e., elements of rel(C) might be removed), and (3) some new constraints might be added

1 Note that we use the notation LC to denote the property of a problem P, and LC(P) to denote the problem
resulting from enforcing the property LC.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 5
to the CSP.2 Note however, in all cases the variables of the CSP are unchanged and theirdomain of values can only be reduced.

A CSP is said to be empty if at least one of its variables has an empty domain or at leastone of its constraints has an empty relation. An empty CSP is obviously insoluble. Given
a local consistency property LC, we say that a CSP P is not empty after enforcing LC ifLC

(P) is not empty.One of the most important local consistency properties is arc consistency [13,14].

Definition 2 (Arc consistency). Let P = (V, D, C) be a CSP. Given a constraint C and avariable

x \Sigma  vars(C), a value a \Sigma  dom(x) has a support in C if there is a tuple t \Sigma  rel(C)such that

t[x] = a. t is then called a support for {x \Upsilon  a} in C. C is arc consistent iffeach value

a of each variable x \Sigma  vars(C) has a support in C. The entire CSP, P, is arc
consistent iff it has non-empty domains and each of its constraints is arc consistent.

Arc consistency can be enforced on a CSP by repeatedly removing unsupported valuesfrom the domains of its variables to create a subdomain.

Definition 3 (Subdomain). A subdomain Dffi of a CSP P = (V, D, C), is a set of domains,{

domDffi(x1), . . . , domDffi(xn)}, where domDffi(xi) fi dom(xi), for each xi \Sigma  V. We say asubdomain is

empty if it contains at least one empty domain. We say a subdomain Dffiis arc consistent iff the CSP Pffi =

(V, Dffi, Cffi) is arc consistent, where Cffi are the originalconstraints C reduced so they contain only tuples over Dffi.3

Definition 4 (Arc consistency closure). An algorithm that enforces arc consistencycomputes the maximum arc consistent subdomain, and when applied to a CSP, P =
(V, D, C), it gives rise to a new arc consistent CSP called the arc consistency closure ofP, which we denote by

ac(P). We have that ac(P) = (V, Dac(P), Cac(P)), where Dac(P)is the maximum arc consistent subdomain of P, and Cac

(P) are the original constraints C

reduced so that they contain only tuples over the subdomain Dac(P).

Constraint satisfaction problems are often solved using backtracking search (for adetailed presentation see, for example, [12,25]). A backtracking search may be seen as
traversing a search tree. In this approach we identify tuples (assignments of values tovariables) with nodes: the empty tuple is the root of the tree, the first level nodes are
1-tuples (an assignment of a value to a single variable), the second level nodes are 2-tuples(a first level assignment extended by selecting an unassigned variable, called the current
variable, and assigning it a value from its domain), and so on. We say that a backtracking

2 Only in Section 3.3 will we consider local consistency properties that might add new constraints.
3 According to Definition 1, the tuples of each constraint must only contain values that are in the domains

of the variables. A constraint can be reduced by deleting from the relation all tuples that contain a value a that
was removed in the process of enforcing arc consistency. However, arc consistency algorithms do not normally
physically remove tuples from the constraint relations of P as this requires that the relations be represented
extensionally. Nevertheless, it is always implicit that the constraint relations are tuples over the reduced variable
domains.

6 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
algorithm visits a node in the search tree if at some stage of the algorithm's executionthe algorithm tries to extend the tuple of assignments at the node. The nodes visited by a
backtracking algorithm form a subset of all the nodes belonging to the search tree. We callthis subset, together with the connecting edges, the search tree visited by a backtracking
algorithm.The chronological backtracking algorithm (BT) is the starting point for all of the more
sophisticated backtracking algorithms. BT checks a constraint only if all the variables in itsscheme have been instantiated. In contrast, the more widely used backtracking algorithms
enforce a local consistency property at each node visited in the backtracking search. Theconsistency enforcement algorithm is applied to the

induced CSP. This is the original CSP
reduced by the current assignment.

Definition 5 (Induced CSP). Given an assignment t of some of the variables of a CSP P,
the CSP induced by t, denoted by P|t , is the same as P except that the domain of eachvariable

x \Sigma  vars(t) contains only one value t[x], the value that has been assigned to x by t,
and the constraints are reduced so that they contain only tuples over the reduced domains.

If the induced CSP is empty after enforcing the local consistency, the instantiation of thecurrent variable cannot be extended to a solution and it should be uninstantiated; otherwise,
the instantiation of the current variable is accepted and the search continues to the nextlevel. The forward checking algorithm (FC) [10,15,25] enforces arc consistency only on the
constraints which have exactly one uninstantiated variable. By comparison, on a problem
that is not empty after enforcing arc consistency, the maintaining arc consistency or really-full lookahead algorithms [8,16,20], as their names suggest, enforce full arc consistency

on the induced CSP.
2.2. Dual and hidden transformations

The dual and hidden transformations are two general methods for converting a non-binary CSP into an equivalent binary CSP. The dual transformation comes from the
relational database community and was introduced to the CSP community by Dechter and
Pearl [7].The hidden transformation, on the other hand, arose from the work of the philosopher

Peirce. In particular, Rossi et al. [19] credit Peirce [18] with first showing that binaryrelations have the same expressive power as non-binary relations. Peirce's method for
representing non-binary relations with a collection of binary relations forms the foundationof the hidden transformation.

In the dual transformation, the constraints of the original formulation become variablesin the new representation. We refer to these variables, which represent the original
constraints, as the dual variables, and the variables in the original CSP as the ordinary
variables. The domain of each dual variable is exactly the set of tuples that are in the
original constraint relation. There is a binary constraint, called a dual constraint, betweentwo dual variables iff the two original constraints share some variables. A dual constraint

prohibits pairs of tuples that do not agree on the shared variables.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 7
Definition 6 (Dual transformation). Given a CSP P = (V, D, C), its dual transformation
dual(P) = (Vdual(P), Ddual(P), Cdual(P)) is defined as follows.

* Vdual(P) = {c1, . . . , cm} where c1, . . . , cm are called dual variables. For each constraint

Ci of P there is a unique corresponding dual variable ci . We use vars(ci) and rel(ci)to denote the corresponding sets vars

(Ci) and rel(Ci) (given that the context is notambiguous).

* Ddual(P) = {dom(c1), . . . , dom(cm)} is the set of domains for the dual variables. Foreach dual variable

ci, dom(ci) = rel(Ci), i.e., each value for ci is a tuple over vars(Ci).An assignment of a value

t to a dual variable ci , ci \Upsilon  t, can thus be viewed as beinga sequence of assignments to the ordinary variables

x \Sigma  vars(ci) where each suchordinary variable is assigned the value
t[x].* Cdual
(P) is a set of binary constraints over Vdual(P) called the dual constraints. There

is a dual constraint between dual variables ci and cj if S = vars(ci) ffl vars(cj ) i= j.In this dual constraint a tuple

ti \Sigma  dom(ci ) is compatible with a tuple tj \Sigma  dom(cj ) iff
ti [S] = tj [S], i.e., the two tuples have the same values over their common variables.

It is important to note that in our definition all of the constraints of P are converted to dualvariables, even the binary and unary constraints.

Example 2. In the dual transformation of the CSP given in Example 1, there are 4 dualvariables,

c1, . . . , c4, one for each constraint in the original formulation as shown in Fig. 1.For example, the dual variable

c1 corresponds to the non-binary constraint C1(x1, x3, x6)and the domain of
c1 contains all possible tuples except (0, 0, 0). As an example of adual constraint, the constraint between

c1 (C1(x1, x3, x6)) and c2 (C2(x1, x3, x4)) requiresthat the first and second arguments of the tuples assigned to

c1 and c2 agree. Hence,{
c1 \Upsilon  (0, 0, 1)} is compatible with {c2 \Upsilon  (0, 0, 0)}, but {c1 \Upsilon  (0, 0, 1)} is incompatiblewith {

c2 \Upsilon  (0, 1, 0)}.

In the hidden transformation, the set of variables consists of all the ordinary variables inthe original formulation with their original domains plus all the dual variables as defined by
the dual transformation. There is a binary constraint, called a hidden constraint, betweena dual variable and each of the ordinary variables in the constraint represented by the dual

Fig. 1. The dual transformation of the CSP in Example 1.

8 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
variable. A hidden constraint enforces the condition that a value of the ordinary variable
must be the same as the value assigned to it by the tuple that is the value of the dualvariable.

Definition 7 (Hidden transformation). Given a CSP P = (V, D, C), its hidden transforma-tion

hidden(P) = (Vhidden(P), Dhidden(P), Chidden(P)) is defined as follows.

* Vhidden(P) = {x1, . . . , xn} ` {c1, . . . , cm}, where x1, . . . , xn is the original set ofvariables in V (called the

ordinary variables) and c1, . . . , cm are dual variables
generated from the constraints in C. There is a unique dual variable ci corresponding
to each constraint Ci \Sigma  C. When dealing with the hidden transformation, the dualvariables are sometimes called hidden variables [6].

* Dhidden(P) = {dom(x1), . . . , dom(xn)} ` {dom(c1), . . . , dom(cm)}. For each dual variable ci, dom(ci ) = rel(Ci ).* Chidden

(P) is a set of binary constraints over Vhidden(P) called the hidden constraints.

For each dual variable c, there is a hidden constraint between c and each of the ordinaryvariables

x \Sigma  vars(c). This constraint specifies that a tuple t \Sigma  dom(c) is compatible
with a value a \Sigma  dom(x) iff t[x] = a.

The hidden transformation has some special properties. The constraint graph of the
hidden transformation is a bipartite graph, as ordinary variables are only constrained
with dual variables, and vice versa, and the hidden constraints are one-way functionalconstraints, in which a tuple in the domain of a dual variable is compatible with at most

one value in the domain of the ordinary variable. The dual transformation can in fact be
built from the hidden transformation by composing the hidden constraints between the dualvariables and the ordinary variables to obtain dual constraints between the dual variables,

and then discarding the hidden constraints and ordinary variables [23]. Note that we need
not add hidden variables for binary constraints. However, as we obtain similar results ifhidden variables are only introduced for ternary and higher arity constraints, we do not

consider this further.
Example 3. In the hidden transformation of the CSP given in Example 1, there are 10
variables (6 ordinary variables and 4 dual variables), as shown in Fig. 2. As an example
of a hidden constraint, the constraint between c1 (C1(x1, x3, x6)) and x1 requires that thefirst argument of the tuple assigned to

c1 agrees with the value assigned to x1. Hence,{
c1 \Upsilon  (0, 0, 1)} is compatible with {x1 \Upsilon  0}, and {c1 \Upsilon  (0, 0, 1)} is incompatible with{
x1 \Upsilon  1}.

In the following, we call a CSP instance P the original formulation with respect to its
dual transformation and hidden transformation. Because we usually deal with more than
one formulation of P simultaneously, we use the notation Vf (P), Df (P) and Cf (P) todenote the set of variables, the set of domains and the set of constraints in P after it has

been reformulated by some transformation f (to become a new CSP f (P)). Also, we use
domf (P)(x) to denote the domain of variable x in f (P).

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 9
Fig. 2. The hidden transformation of the CSP in Example 1.
3. Local consistency techniques

In this section, we compare the strength of arc consistency on the original formulation,and on the dual and hidden transformations. We show that arc consistency on the original
formulation and the hidden transformation are equivalent, but arc consistency on the dualtransformation is stronger. We then compare several stronger local consistency properties
defined over the binary constraints in the dual and hidden formulations. We establish ahierarchy, with respect to a simple ordering relation, for the various combinations of local
consistency and problem formulation.Debruyne and Bessie`re [5] compare local consistency properties defined on binary
CSPs. They define a local consistency property LC1 to be stronger than another LC2(LC

1 'DB LC2) iff in any CSP instance in which LC1 holds, then LC2 holds, and LC1to be strictly stronger than LC

2 (LC1 ^DB LC2) if LC1 'DB LC2 and not LC2 'DB LC1.However, their definition of ordering among different local consistency properties

does not provide sufficient discrimination for our purposes as we wish to simultaneouslycompare changes in problem formulation and local consistency properties. To this end we
define the following ordering relation.
Definition 8. Given two local consistency properties LC1 and LC2, and two transforma-tions A and B for CSP problems (perhaps identity transformations), LC

1 on A is tighterthan LC
2 on B, written LC1(A) ' LC2(B), iff

given any problem P, if A(P) is not empty after enforcing LC1,
then B(P) is also not empty after enforcing LC2.LC

1 on A is strictly tighter than LC2 on B, LC1(A) ^ LC2(B), iff LC1(A) ' LC2(B) andnot LC

2(B) ' LC1(A). And LC1 on A is equivalent to LC2 on B, LC1(A) * LC2(B),iff LC
1(A) ' LC2(B) and LC2(B) ' LC1(A). If the transformations are identical; i.e.,A = B, then we simply write LC

1 ' LC2.

10 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37

The ordering relation we define is motivated by our desire to examine backtrackingsearch algorithms in which some form of local consistency is maintained during search. In
such algorithms it is the occurrence of an empty subproblem at a node of the search tree thatjustifies backtracking. Thus if LC

1 is tighter than LC2 it follows (using the contrapositiveform of the definition: if P is empty after enforcing LC

2, then P is also empty afterenforcing LC
1) that when an algorithm that maintains LC2 backtracks at a node, thenan algorithm that maintains LC

1 would backtrack at that node as well.Debruyne and Bessie`re's ordering relation is defined by whether or not a problem

satisfies some local consistency property, whereas our ordering relation is defined bywhether or not a non-empty subproblem satisfies some local consistency property.
This distinction is important. For example, there exist problems for which the dualtransformation is arc consistent but the original formulation is not, and problems where
the original formulation is arc consistent while the dual is not. Thus, under Debruyne andBessie`re's ordering (suitably modified to deal with two different problem formulations)
arc consistency on these two formulations would be incomparable. Under our orderingrelation, however, arc consistency on the dual transformation can be shown to be
strictly tighter than arc consistency on the original formulation. As the following lemmademonstrates, Debruyne and Bessie`re's ordering relation is stronger than ours. The relation
^DB is therefore unable to make as fine distinctions between different local consistenciesas the relation '.

Lemma 1. LC1 'DB LC2 implies LC1 ' LC2.
Proof. Let P be a problem which is not empty after enforcing LC1. Then there is a non-empty subdomain of P in which LC

1 holds and hence LC2 holds, since LC1 ^DB LC2.Therefore P is also not empty after enforcing LC

2, and LC1 ' LC2. \Delta 

Note also that LC1 ^DB LC2 implies LC1 ' LC2, but not necessarily LC1 ^ LC2. Inparticular, LC

2 'DB LC1 failing to hold does not imply that LC2 ' LC1 also fails to hold,as an ' ordering might exist between LC

2 and LC1 even though no 'DB ordering exists.

3.1. Arc consistency on the hidden transformation

Consider a CSP P with 4 variables, x1, . . . , x4, each with domain {0, 1, 2} andconstraints given by,

x1 + x2 < x3, x1 + x3 < x4 and x2 + x3 < x4. Fig. 3 showsthe mappings between P, its arc consistency closure

ac(P), its hidden transformationhidden
(P), and the arc consistency closure of its hidden transformation ac(hidden(P)). Itturns out that

ac(hidden(P)) is the same as the hidden transformation of the arc consistencyclosure
hidden(ac(P)). In this example, an ordinary variable has the same domain in ac(P)and ac
(hidden(P)) and the domain of a dual variable in ac(hidden(P)) is the same as theset of tuples in the corresponding constraint that remain after enforcing arc consistency on

the original formulation. We show in the following that these properties are true in general.
Lemma 2. If P is arc consistent; i.e., P = ac(P), then hidden(P) is empty if and only if Pis empty.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 11
Fig. 3. An example to show the mappings between an original CSP, its hidden transformation, its arc consistency
closure, the arc consistency closure of its hidden transformation, and the hidden transformation of its arc
consistency closure.

Proof. If P is empty then either it has an empty variable domain or an empty constraintrelation or both. In either of these cases

hidden(P) will have an empty variable domain.That is, for any P, if P is empty, then
hidden(P) is empty. (We do not need arc consistencyfor this direction.)

If hidden(P) is empty then we have one of two cases. (1) hidden(P) has an emptyvariable domain. In this case P must also be empty. Otherwise, (2) there are no empty
variable domains but hidden(P) has an empty constraint relation. We claim that case (2)cannot occur if P is arc consistent. Let

Cx,c be any of the hidden constraints, and say thatit is a constraint between an ordinary variable

x and a dual variable c. dom(x) is not emptyso it must contain at least one value
a. Furthermore, since P is arc consistent there must bea tuple
t in dom(c) such that the pair (x, t) is a support for a in Cx,c. That is, rel(Cx,c) mustcontain at least the pair

(x, t). So none of the constraints of hidden(P) can be empty. \Delta 

12 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
Theorem 1. Given a CSP P,

(1) P is arc consistent if and only if hidden(P) is arc consistent,
(2) hidden(ac(P)) = ac(hidden(P)), and
(3) arc consistency on P is equivalent to arc consistency on hidden(P); i.e., ac *

ac(hidden).

Proof. (1) If the original formulation P is not arc consistent, then there is at least one value
a in the domain of an ordinary variable x and a constraint C such that x \Upsilon  a does not have
a support in C. Hence, in hidden(P), x \Upsilon  a will not have a support in the hidden constraint
between the ordinary variable x and the corresponding dual variable c, and hidden(P)
is not arc consistent either. On the other hand, suppose hidden(P) is not arc consistent.
Since by definition for every constraint C, rel(C) contains only tuples whose values are in
the product of the domains of vars(C), each tuple in the domain of a dual variable must
have a support in a hidden constraint between the dual variable and an ordinary variable.
Hence, for hidden(P) not to be arc consistent there must be a value a of an ordinary
variable x and a dual variable c such that {x \Upsilon  a} does not have a support in the hidden
constraint between x and c; thus {x \Upsilon  a} cannot have a support in the corresponding
original constraint C. Therefore, the original formulation P is not arc consistent either.

(2) First, hidden(P), hidden(ac(P)), and ac(hidden(P)) all have the same set of
variables (ordinary and dual) and the same constraint schemes since (a) enforcing arc
consistency does not alter the variables or the constraint schemes of a problem and (b)
the variables of the hidden are completely determined by the variables and the schemes of
the constraints of the original problem.

Second, the set of domains of hidden(ac(P)), Dhidden(ac(P)), is a subdomain of
hidden(P): enforcing ac on P reduces the variable domains and the constraint relations,
which simply has the effect, after applying the hidden transformation, of reducing the
domains of the ordinary and dual variables from their state in hidden(P). Furthermore,
by (1) hidden(ac(P)) must be arc consistent. Thus Dhidden(ac(P)) is also a subdomain
of ac(hidden(P)) as Dac(hidden(P)) is the (unique) maximal arc consistent subdomain of
hidden(P). This means that for every variable q (ordinary or dual) domhidden(ac(P))(q) fi
domac(hidden(P))(q).

Third, we show for every variable q, domac(hidden(P))(q) fi domhidden(ac(P))(q), and
hence that Dhidden(ac(P)) = Dac(hidden(P)). There are two cases to consider. (a) q is an ordinary variable. Since, ac(hidden(P)) is arc consistent, each value a \Sigma  domac(hidden(P))(q)
must have a supporting tuple in every dual variable c that q is constrained with. Furthermore, these supporting tuples must themselves have supports in every ordinary variable
that c is constrained with. In other words, a has a support in each constraint by a tuple
consisting of values from Dac(hidden(P)). Thus the set of domains of the ordinary variables
in ac(hidden(P)) are an arc consistent subdomain of P, and by maximality we must have
that domac(hidden(P))(q) fi domac(P)(q). Furthermore domac(P)(q) = domhidden(ac(P))(q)
by the construction of the hidden. Thus for ordinary variables domac(hidden(P))(q) fi
domhidden(ac(P))(q). (b) q is a dual variable. From (a) we know that every tuple t \Sigma 
domac(hidden(P))(q) consists of values of ordinary variables taken from Dac(P). Hence, in

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 13
ac(P), t will be in the constraint relation of the constraint corresponding to q, and thus twill also be in domhidden

(ac(P))(q).

Finally, in any hidden formulation the hidden constraints have the same intension. Thusgiven that the variable domains Dhidden

(ac(P)) and Dac(hidden(P)) are identical all of the

constraint relations (extensions) will be the same in hidden(ac(P)) and ac(hidden(P)).(The constraint schemes are determined by the dual variables which also agree in

these two formulations.) Hence, hidden(ac(P)) and ac(hidden(P)) have the same setof variables, domains for these variables, and constraints. That is, they are syntactically
identical.(3) Since ac

(P) is arc consistent, ac(P) is empty iff ac(hidden(P)) is empty by (2) andLemma 2. \Delta 

Corollary 1. In any CSP P, for each of the ordinary variables x in P, domac(P)(x) =domhidden

(ac(P))(x) = domac(hidden(P))(x).

Proof. The first equality follows from the construction of the hidden; the second followsfrom (2) of Theorem 1. \Delta 

3.2. Arc consistency on the dual transformation

We have proven that the original formulation is arc consistent if and only if its hiddentransformation is arc consistent. However, such an equivalence does not hold for the dual
transformation.
Example 4. Consider a CSP P with four Boolean variables and constraints:

C1(x1, x2, x3) = {(0, 0, 0), (1, 1, 1)},
C2(x2, x3, x4) = {(0, 0, 0), (1, 1, 1)},
C3(x1, x3, x4) = {(0, 0, 1), (1, 1, 0)}.
The original formulation P is arc consistent. In its dual transformation, let the dualvariables

c1, c2, and c3 correspond to the above constraints, respectively. Because neitherof the tuples

(0, 0, 0) and (1, 1, 1) in the domain c2 has a support in the dual constraintbetween
c2 and c3, the domain of c2 is empty after enforcing arc consistency on thedual transformation. Thus dual

(P) is not arc consistent and ac(dual(P)) is empty; i.e.,ac i' ac
(dual).

Example 5. Consider a CSP P with three Boolean variables and constraints:

C1(x1, x2) = {(1, 1)},
C2(x2, x3) = {(1, 1)},
C3(x1, x3) = {(1, 1)}.
The dual transformation dual(P) is arc consistent. However, the original formulation isnot arc consistent, because the value 0 for each of the variables will be removed from its

domain when enforcing arc consistency.

14 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37

We can show that if the dual transformation is not empty after enforcing arc consistency,
then the original formulation is not empty either after enforcing arc consistency; i.e.,
ac(dual) ' ac. Together with Example 4 this shows that ac(dual) ^ ac.

Lemma 3. If a subdomain Dffi of a dual transformation dual(P) is arc consistent, then for
each pair of dual variables ci and cj in dual(P) such that S = vars(ci) ffl vars(cj ) i= j,

and for each x \Sigma  S, j{x}domDffi(ci) = j{x}domDffi(cj ).

Proof. For each x \Sigma  S and each tuple t \Sigma  j{x}domDffi(ci) there is a tuple ti \Sigma  domDffi (ci)
such that ti[x] = t. Because Dffi is arc consistent, there must also be a tuple tj \Sigma 

domDffi(cj ) such that ti[S] = tj [S]. Thus t = ti[x] = tj [x]. Because t \Sigma  j{x}domDffi(cj ),
we have j{x}domDffi(ci) fi j{x}domDffi (cj ). Similarly, we can show that j{x}domDffi(cj ) fi
j{x}domDffi(ci). Therefore, j{x}domDffi (ci) = j{x}domDffi(cj ). \Delta 

From the arc consistency closure of dual(P)), ac(dual(P)), we can construct asubdomain for the original formulation P (in Theorem 2 below we show that this
subdomain is in fact an arc consistent subdomain of P ).

Definition 9. Let Ddualac(P) denote the subdomain for the ordinary variables in P that isconstructed from the domains for the dual variables in

ac(dual(P)) as follows: for each
ordinary variable x in P, choose a dual variable c in ac(dual(P)) such that x \Sigma  vars(c)

and set domDdualac

(P) (x) to be j{

x}domac(dual(P))(c). Note that each domD

dualac(P)(x) is well

defined as (1) by our assumption that each variable is constrained by at least one constraint,
it is always possible to choose one such c, and (2) by Lemma 3, if there is more than onesuch

c the result does not depend on the dual variable we choose.

For example, the dual transformation of the CSP in Example 5 is arc consistent.Hence Dac

(dual(P)) is {dom(c1) = {(1, 1)}, dom(c2) = {(1, 1)}, dom(c3) = {(1, 1)}}, andD

dualac(P) is {dom(x1) = {1}, dom(x2) = {1}, dom(x3) = {1}}.

Theorem 2. Given a CSP P, arc consistency on dual(P) is strictly tighter than arc
consistency on P; i.e., ac(dual) ^ ac.

Proof. We show that if ac(dual(P)) is not empty, then neither is ac(P); i.e., ac(dual) ' ac.Because the domain of each dual variable in

ac(dual(P)) is not empty, its projection over
an ordinary variable cannot be empty either. So there is no empty domain in Ddualac(P).

In P, for each ordinary variable x, each value a \Sigma  domDdualac

(P)(x), and each constraint C,

where x \Sigma  vars(C), let a be the projection of the tuple t of the corresponding dual variable
c. For each of the variables y \Sigma  vars(C), t[y] \Sigma  domDdualac

(P)(y). Thus t is a support for

{x \Upsilon  a} in constraint C, and furthermore t is a tuple of values all of which come fromDdualac

(P). Therefore, Ddualac(P) is a non-empty arc consistent subdomain of P and thus

ac(P) is not empty.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 15
Example 4 shows that arc consistency on the dual transformation may be strictlytighter than arc consistency on the original formulation; i.e.,

ac i' dual(ac). Therefore,ac
(dual) ^ ac. \Delta 

By combining Theorem 1 and Theorem 2, we can make the following comparisonbetween arc consistency on the dual transformation and on the hidden transformation.

Corollary 2. Given a CSP P, arc consistency on dual(P) is strictly tighter than arc
consistency on hidden(P); i.e., ac(dual) ^ ac(hidden).

3.3. Beyond arc consistency

Because the dual and hidden transformations are binary CSPs, we can enforce localconsistency properties that are defined only over binary constraints. Following [5], a
binary CSP is (i,j )-consistent if it is not empty and any consistent assignment over ivariables can be extended to a consistent assignment involving

j additional variables.A CSP is arc consistent (AC) if it is (1,1)-consistent. A CSP is path consistent (PC) if

it is (2,1)-consistent. A CSP is strongly path consistent (SPC) if it is (i,1)-consistent foreach 1 \Delta 

i \Delta  2. A CSP is path inverse consistent (PIC) if it is (1,2)-consistent. A CSPis neighborhood inverse consistent (NIC) if any instantiation of a single variable

x canbe extended to a consistent assignment over all the variables that are constrained with

x, called the neighborhood of x. A CSP is restricted path consistent (RPC) if it is arcconsistent and whenever there is a value of a variable that is consistent with just one
value of an adjoining variable, every other variable has a value that is compatible withthis pair of values. A CSP is singleton arc consistent (SAC) if it is not empty, and the
CSP induced by any instantiation of a single variable is not empty after enforcing arcconsistency.

Debruyne and Bessie`re [5] demonstrated that, SPC ^DB SAC ^DB PIC ^DB RPC ^DBAC, and NIC ^

DB PIC, where "^DB" is the ordering relation defined in their paper, asdiscussed in Section 3. Thus, by Lemma 1 we immediately have that SPC ' SAC ' PIC

' RPC ' AC, and NIC ' PIC.
Theorem 3. Given a CSP P, neighborhood inverse consistency on hidden(P) is equivalent
to arc consistency on hidden(P); i.e., nic(hidden) * ac(hidden).

Proof. Since nic ' ac, we immediately have nic(hidden) ' ac(hidden). Conversely,suppose ac

(hidden(P)) is not empty. For a dual variable c, its neighborhood in
ac(hidden(P)) is vars(c). Thus an instantiation of c with a tuple t from its domain in
ac(hidden(P)) can be extended to a consistent assignment of its neighboring variables,where for each of the ordinary variables

x \Sigma  vars(c), x is instantiated with t[x] (t[x]must be in the domain of
x because it is the only support for t in the hidden constraintbetween
x and c). For an ordinary variable x, x only has constraints with dual variables.An instantiation of

x with a value a from its domain in ac(hidden(P)) can be extended to aconsistent assignment including all its neighborhood, where for each of the dual variables

c in its neighborhood, c is instantiated with a tuple t such that t[x] = a (also, such a tuple

16 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
must exist because {x \Upsilon  a} has at least one support in the hidden constraint between xand

c). Therefore, the hidden transformation is not empty after enforcing neighborhoodinverse consistency; i.e., nic

(hidden(P)) is not empty. In fact, ac(hidden(P)) is alreadyneighborhood inverse consistent. \Delta 

Because neighborhood inverse consistency on the hidden transformation collapses downonto arc consistency those consistencies that are weaker than neighborhood inverse consistency but tighter than arc consistency, e.g., path inverse consistency and restricted pathconsistency, are also equivalent to arc consistency. That is,

nic(hidden) * pic(hidden) *rpc
(hidden) * ac(hidden) (and by the equivalence ac(hidden) * ac established in Theo-rem 1, each of these local consistencies on the hidden transformation is in turn also equivalent to arc consistency on the original formulation).However, neighborhood inverse consistency on the dual transformation does not
collapse. It is strictly tighter than arc consistency. In fact, the even weaker restricted pathconsistency is strictly tighter than arc consistency on the dual.

Example 6. Consider a CSP with three Boolean variables and constraints:

C1(x1, x2) = {(0, 0), (1, 1)},
C2(x2, x3) = {(0, 0), (1, 1)},
C3(x1, x3) = {(0, 1), (1, 0)}.

The dual transformation of this problem is arc consistent but not restricted path consistent(RPC). Furthermore, enforcing RPC on the dual transformation yields an empty CSP. Thus

we have that rpc(dual) ^ ac(dual); i.e., rpc is strictly tighter on the dual.Along with the previous orderings this immediately gives that both

pic(dual) ^
ac(dual), and nic(dual) ^ ac(dual).

Although neighborhood inverse consistency and path inverse consistency on the hiddentransformation do not provide any additional power over arc consistency, the same is not
true for singleton arc consistency.
Example 7. Consider a CSP with three parity constraints: even(x1 + x2 + x3), even(x1 +
x3 + x4), and even(x1 + x2 + x4). If x1 is set to 1, and the other variables havedomain {0

, 1} then the hidden transformation is arc consistent but not singleton arcconsistent. Furthermore, enforcing singleton arc consistency on this problem yields an

empty CSP. Thus we have sac(hidden) ^ ac(hidden) and sac(hidden) ^ nic(hidden) (since
nic(hidden) * ac(hidden)).

Theorem 4. Given a CSP P, singleton arc consistency on dual(P) is tighter than singletonarc consistency on hidden

(P); i.e., sac(dual) ' sac(hidden).

Proof. First we define a function , from the arc consistent subdomains of dual(P) tosubdomains of

hidden(P). Let D be an arc consistent subdomain of dual(P). In , (D)each dual variable

c will have the same domain as it did in D, domD(c) = dom,(D)(c),

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 17
and the domain of each ordinary variable x, dom,(D)(x), is set to be equal to j{x}domD(c)
for some dual variable c such that x \Sigma  vars(c). , is well defined, as from Lemma 3 we
know that since D is an arc consistent subdomain of dual(P), dom,(D)(x) is independent
of which dual variable c we choose to project.

, has three relevant properties. (1) , (D) is an arc consistent subdomain of hidden(P).
For each ordinary variable x we have that dom,(D)(x) = j{x}domD(c) for every dual
variable c that x is constrained with. Thus, every value of x has a support in each of
the dual variables it is constrained with (take one of the tuples whose projection was that
value), and every tuple t of every dual variable c has a support in each of the ordinary
variables it is constrained with (take the projection of t on that variable). (2) If Dffi is a
subdomain of D, then , (Dffi) is a subdomain of , (D). This is obvious from the definition
of , . (3) , (D) is an empty subdomain, if and only if D is an empty subdomain.4 The only
non-trivial case is when , (D) contains an empty domain for an ordinary variable x. But in
that case there must be a dual variable c with x \Sigma  vars(c) such that j{x}domD(c) = j.
And this can only be the case if domD(c) is itself empty; i.e., D contains an empty
domain.

Now we show that if sac(dual(P)) is not empty then neither is sac(hidden(P)); i.e.,
sac(dual) ' sac(hidden). Let Dd = Dsac(dual(P)) and Dh = , (Dd ). Our claim is that Dh is
a non-empty singleton arc consistent subdomain of hidden(P).

First, since sac(dual(P)) is arc consistent and non-empty, Dsac(dual(P)) = Dd is an arc
consistent and non-empty subdomain of dual(P). Thus, Dd is a non-empty member of the
domain of the function , and by (3) Dh = , (Dd) is non-empty and we need only prove
that it is singleton arc consistent.

Let c be a dual variable, and t a tuple in domDh (c). We must show that Dh|c\Upsilon t (i.e.,D

h in which domDh(c) has been reduced to the singleton {t}) contains a non-empty arcconsistent subdomain. However, since D

d is singleton arc consistent, Dd |c\Upsilon t contains anon-empty arc consistent subdomain ac
(Dd |c\Upsilon t ). , (ac(Dd |c\Upsilon t )) is easily seen to be a

subdomain of Dh|c\Upsilon t , and thus by (1) and (3) , (ac(Dd |c\Upsilon t )) must be a non-empty arc
consistent subdomain of Dh|c\Upsilon t . On the other hand, let x be an ordinary variable and a a
value in its domain. To show that Dh|x\Upsilon a contains a non-empty arc consistent subdomain,
we choose any dual variable c that x is constrained with, and a tuple t from the domain
of c such that t[x] = a. Now if we consider Dd|c\Upsilon t and its non-empty arc consistent
subdomain ac(Dd|c\Upsilon t ), we can similarly show that , (ac(Dd|c\Upsilon t )) is a non-empty arc
consistent subdomain of Dh|x\Upsilon a. \Delta 

In the hidden transformation, for each pair of dual variables ci and cj , where vars(ci) ffl
vars(cj ) i= j, enforcing strong path consistency adds a constraint between ci and cj . This
constraint ensures that a tuple from ci agrees with a tuple from cj on the shared ordinary
variables. The constraint is identical to the dual constraint between ci and cj in the dual
transformation. Thus, strong path consistency on the hidden transformation must be as
strong as on the dual. In fact, we can show their equivalence.

4 By Definition 3 a subdomain is empty if it contains an empty domain for some variable.

18 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
Fig. 4. The hierarchy of relations between consistencies on the original, dual, and hidden formulations.
A bi-directional arrow is equivalence, *, a double headed arrow is the strictly tighter relation, ^, and an ordinary
arrow is the tighter relation, '.

Theorem 5. Given a CSP P, strong path consistency on hidden(P) is equivalent to strong
path consistency on dual(P); i.e., spc(hidden) * spc(dual).

Proof. See [4]. \Delta 

Fig. 4 summarizes our results. If there is a directed path between consistency propertiesA and B, then A is tighter than B. If the path contains a strictly tighter than link then A is
strictly tighter than B. Note that some of the relationships between consistency propertiesare not completely characterized. For example, it is an open question whether or not
sac(hidden) ' sac(dual).

4. Backtracking algorithms

In this section, we compare the performance of three backtracking algorithms--thechronological backtracking algorithm, the forward checking algorithm, and the maintaining (generalized) arc consistency algorithm--when solving the original formulation andthe dual and hidden transformations of a problem. Our results are proven under the assumption that a backtracking algorithm finds all solutions to a problem.Given two backtracking algorithms and two formulations of a problem we identify
whether or not the relation "one combination can be only polynomially worse than anothercombination" holds. To formalize this relation we must first specify quantitative measures
of the size of a CSP and the cost of solving a CSP using a given algorithm.We denote by size

(P) the size of a CSP P . Consistent with real-world practice,we assume that the domains of the variables are represented extensionally and that the

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 19
constraints are represented intensionally. Thus, to specify the variables, domains, andconstraints of a (possibly transformed) CSP P takes O

(n + nd + mr) space, where ndenotes the number of variables,
d the size of the largest domain, m the number ofconstraints, and
r the arity of the largest constraint scheme in P. Since the dual andthe hidden are transformations of an original (non-binary) formulation P, we can also

specify their sizes in terms of the parameters of P. In particular, let n, d, m, and rbe the parameters of an original (non-binary) formulation P. In the worst case, the
transformation dual(P) takes O(m + mdr + m2) space and the transformation hidden(P)takes O

((n + m) + (nd + mdr ) + mr) space. Thus, the dual and hidden transformationscan require space that grows exponentially with the arity of the constraints in the original

formulation. In practice, one would certainly want to limit the arity of the constraints towhich these transformations are applied.

To solve a CSP with a backtracking algorithm, one must specify the variable orderingthe algorithm uses to determine which variable to instantiate next. It is well known that the
variable ordering used can have an exponential effect on the cost of solving a CSP. Thusan exponentially difference in performance between two algorithm/formulation pairs is
always trivially possible under particular variable orderings. Hence, to formalize a sensiblenotion of "only polynomially worse" we must do so in a way that is independent of any
particular variable ordering. In our definitions we achieve this independence by quantifyingover all possible orderings.

Formally, we define a variable ordering function ae to be a mapping from a tuple t (anode making a, possibly empty, set of variable-value assignments) and a CSP P to a new
variable not in vars(t). We say that a variable ordering ae is an ordering for a problem Pif it is defined over the variables of P. In addition, we say that an algorithm

A uses thevariable ordering
ae if ae characterizes the choices made by A at the various nodes A visitsas it does its backtracking search; i.e.,

A next instantiates the variable x when it is at node
n if and only if ae(n) = x.We denote by cost

(A, P, ae) the cost of solving a CSP P using an algorithm A anda variable ordering
ae. This cost is determined by the number of nodes visited by thealgorithm and the cost at each node. In turn, the cost at each node is determined by the cost

of enforcing the local consistency property maintained by the backtracking algorithm andthe cost, if any, of determining the next variable to instantiate (the cost of the function

ae).

Definition 10. Let A-A denote algorithm A applied to problems transformed by atransformation A. Given two backtracking algorithms

A and B (possibly identical), andtwo transformations A and B for CSP problems (perhaps identity transformations),

1. A-A can be only polynomially worse than B-B, written A-A *poly B-B, iff given any CSPP and variable ordering

aeB for B(P), there is a variable ordering aeA for A(P) suchthat,

cost(A, A(P), aeA)

cost(B, B(P), aeB) \Delta  polynomial function of min(size(A(P)), size(B(P)).

That is, the cost of solving A(P) using A and aeA is at most a polynomial factor worsethan the cost of solving B

(P) using B and aeB.

20 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37

2. A-A can be superpolynomially worse than B-B, written A-A *superpoly B-B, iff A-A i*poly

B-B (i.e., the negation of polynomially worse), iff there exists a CSP P and a variableordering

aeB for B(P), such that for any variable ordering aeA for A(P),

cost(A, A(P), aeA)

cost(B, B(P), aeB) > superpolynomial function of min(size(A(P)), size(B(P)).

That is, the cost of solving A(P) using A and aeA is at least a superpolynomial factorworse than the cost of solving B

(P) using B and aeB.

To prove a relationship A-A *poly B-B, we (1) establish that the number of nodes visitedby

A on A is at most a polynomial factor more than the number of nodes visited by Bon B, (2) establish that the time complexity of enforcing the local consistency property

maintained by A at each node is at most a polynomial factor worse than the time complexityof enforcing the local consistency property maintained by

B at each node, and (3) establishthat the time complexity of
aeA is at most a polynomial factor worse than the timecomplexity of
aeB. In turn, to prove condition (1), we establish a correspondence betweenthe nodes in the ordered search tree generated by

aeA that are visited by A and the nodesin the ordered search tree generated by
aeB that are visited by B. In the definition of
A-A *poly B-B, the existential (there is a variable ordering aeA) occurs within the scope oftwo universal quantifiers (any CSP P and any variable ordering

aeB) and thus aeA candepend on both P and
aeB. To prove condition (3), we show how to construct aeA givenonly polynomial access to

aeB and polynomial additional computation.

4.1. Discussion

Every variable ordering ae for a CSP instance P generates a complete ordered search treefor P. Starting with the root of the tree being the empty tuple, at every node

n we apply ae tothat node to obtain the variable
x = ae(n) that is to be instantiated by the children of n. Thenthe children of
n will be all of the possible extensions of n that can be made by assigning
x values from its domain. This process is continued recursively until we reach nodes thatassign all of the variables of the CSP instance. Our formalization of variable orderings

encompasses both static variable orderings (in which ae returns the same variable at everynode that assigns the same number of variables) and dynamic orderings (in which

ae canreturn a different variable at each node). Further, it assumes a static (possibly heuristically

derived) of the values of each variable. The children of a node are thus ordered in the searchtree left to right following this ordering.5

If we apply A to solve P using ae as the variable ordering, then A will search in thisordered search tree. Due to the constraints imposed by

ae on A's operation, A cannot visita node (assignment) not in this ordered search tree. Depending on how

A operates, it willvisit some subset of the nodes in this search tree. We refer to the sub-tree (of the ordered

5 Our results would go through unchanged if the value ordering is dynamic assuming that all children of a
given node are instantiations of the same variable. All that would be needed is for ae to return in addition to
the next variable an ordering over its domain. However, we avoid doing this since it would make the notation
unnecessarily complicated.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 21
Fig. 5. The ordered search tree generated by a variable ordering.
search tree) visited by a backtracking algorithm on the original formulation as the original
search tree, the sub-tree visited when solving the dual transformation as the dual search
tree, and the one visited when solving the hidden transformation as the hidden search
tree. All of these sub-trees are defined with respect to particular variable orderings (each
of which generates a particular ordered search tree). Fig. 5 shows an example of a CSP
instance P, variable ordering ae for P, and the complete search tree generated by ae.As we have defined them, a variable ordering can play either a descriptive or a

prescriptive role. Say that we run A on A(P) and we use some heuristic function to
compute the next variable to instantiate at every node of the search tree. This heuristicfunction could use various pieces of the state of the program in computing its answer. For

example, in an algorithm like FC, the minimum remaining values heuristic uses the domain
sizes of the uninstantiated variables in computing the next variable. In this case, ae playsa descriptive role. After

A has run on A(P) there will be some set of variable ordering
decisions that it has made that can be captured by specifying a variable ordering function
ae, and we can say that A has used ae when solving A(P). Note that there will in generalbe many different variable orderings that describe

A's behavior on A(P). In particular, A
will only visit a subset of the possible tuples that could be generated from the variables
and values of A(P), and ae need only agree with A on those tuples A actually visits. How aemaps the other tuples to variables can be decided arbitrarily.

On the other hand, ae can also be used in a prescriptive role. If ae can be computed
externally to A, then whenever A visits a node n it can invoke the computation of ae(n) totell it what variable to instantiate next.

In our definitions the variable ordering for B-B is descriptive while the variable ordering
for A-A is prescriptive. In particular, we have that B achieves some level of performancewhen solving B

(P), and that the variable ordering it used to achieve this performance is
described by aeB. Then when we use A to solve A(P) we assume that there is a variable
ordering aeA that can be computed externally to A to prescribe the variable ordering itshould use when solving A

(P). The definitions specify conditions on A's performance onA
(P) under all possible aeA.The relation

A-A *superpoly B-B means that there is a problem P such that when B solvesB
(P) using a variable ordering described by aeB it achieves a performance that is superpolynomially better than that of A on A(P) no matter what variable ordering is prescribedfor

A to use.

22 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37

The relation A-A *poly B-B means that for any problem P the performance achieved by
B when solving B(P) using a variable ordering described by aeB can always be matched
within a polynomial by A when solving A(P) using a prescribed variable ordering aeA.

Two potentially problematic cases arise from the fact that each algorithm utilizes a
different variable ordering. First, if B used an exponential computation to compute its
variable ordering, then it would seem to be unfair to compare A's performance with it--B
might have unmatchable performance simply due to its superior variable ordering. Second,
if A used exponential resources to compute its variable ordering, then it would seem to
be unfair to say that it was polynomially as good as B--it could be that B needed only
polynomial resources to compute its ordering and yet A needed exponential resources to
achieve similar performance. Both of these problems are resolved by our use of a ratio of
costs as the metric for comparison. In particular, in the first case A would also be allowed
to use exponential resources to compute its variable ordering, and in the second case if A
used exponentially more resources than B in computing its variable ordering then the "only
polynomially worse" relation would not hold.

We have used quantification as a mechanism for removing any dependence on a
particular variable ordering in our definitions. Quantification allows us to achieve a number
of useful properties.

First, we need to compare the performance of algorithms on problems that contain different sets of variables. For example, the original formulation and the dual transformation
contain completely different sets of variables. Hence, it is not possible to simply assume
that the same variable ordering is used in each algorithm, as is commonly done. By quantifying over possible variable orderings we have the freedom to allow each algorithm to
employ a different variable ordering.

Second, since different variable orderings can yield such tremendous differences in
practice, it is not desirable to fix the variable ordering used by an algorithm independently
of the problem. By quantifying over all possible variable orderings we do not need to fix
the variable ordering.

Finally, another seemingly plausible way of comparing algorithm and problem
formulation combinations is to compare their performance when they are both using the
best possible variable ordering. That is, to look at cost(A, A(P), aeA)/cost(B, B(P), aeB)
under the condition that aeA is the best possible variable ordering for A on problem A(P),
and similarly for aeB. However, the practical impact of such an approach would be limited
since determining the best possible variable ordering for a given algorithm and problem
combination is at least as hard as solving the problem itself. With quantification we achieve
something that is both stronger and more useful. In particular, it is easy to see that if
A-A *poly B-B holds, it then also holds if we restrict our attention to the best possible variable
ordering for each combination. The advantage of our stronger formulation is that it tells
us something about many different variable orderings, not only the best ones, and thus our
results have a much greater practical impact. For example, if we have A-A *poly B-B then no
matter what variable ordering we use for B we know that there exists a variable ordering
for A that will achieve a comparable performance. Importantly, the variable ordering for A
need not be the best possible; in fact, in most of our proofs of this relation we show a way
of constructing the ordering for A from the ordering for B.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 23
4.2. Forward checking algorithm (FC)

In this section, we compare the performance of the forward checking backtrackingalgorithm (FC) [10,15,25] on the three models.
We can make things simpler by restricting the class of variable orderings that we need toconsider for FC-hidden (FC applied to the hidden transformation). In particular, we assume
that any variable ordering for FC-hidden always instantiates all of the ordinary variablesprior to instantiating any dual variable. Due to the following result this restriction does not
affect either of the two relations *poly or *superpoly.
Theorem 6. Given a CSP P and a variable ordering ae for the hidden transformation
hidden(P), we can construct (in polynomial time given polynomial time access to ae) anew variable ordering

aeffi that instantiates all of the ordinary variables of hidden(P) prior
to instantiating any dual variable such that FC-hidden using aeffi visits at most O(rd) timesas many nodes as it visits when using

ae, where d is the size of the largest domain and r is
the arity of the largest constraint scheme in P .

Proof. See [4]. \Delta 

In fact we can go even further, and assume that FC-hidden explores a search treecontaining the ordinary variables only. Using one of the above restricted variable orderings,
FC-hidden will have instantiated all ordinary variables prior to instantiating any dualvariable. Due to the nature of the constraints in the hidden, once all of the ordinary variables
have been consistently instantiated, there will be only one consistent tuple in the domainof each dual variable; FC will prune away all of the other, inconsistent, tuples. FC will
then proceed to descend in a backtrack free manner down the single remaining branch toinstantiate all of the dual variables. Thus we can stop the search once all of the ordinary
variables have been assigned--we already have a solution. That is, we need only considerthe top part of the search tree where the ordinary variables are being instantiated, and we
can consider FC-hidden and FC-orig to be exploring the same search tree consisting of allof the ordinary variables.

We now present examples that allow us to prove some relationships between the threeproblem formulations.

Example 8. Consider a non-binary CSP with only one constraint over n Boolean variables,
C(x1, . . . , xn) = {x1 = x2 = * * * = xn}. FC applied to this formulation visits O(2n) nodesand performs O

(2n) consistency checks to find all solutions irrespective of the variableordering used. There are only two nodes in the search tree for FC-dual, representing

the two possible solutions. FC-hidden visits O(n) nodes and performs O(n) consistencychecks.

Theorem 7. FC-orig can be super-polynomially worse than FC-dual and FC-hidden; i.e.,FC-orig *

superpoly FC-dual and FC-orig *superpoly FC-hidden.

Proof. See Example 8. \Delta 

24 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
Example 9. Consider the non-binary CSP with n Boolean variables x1, . . . , xn and nconstraints given by {

x1}, {~x1 \Phi  x2}, {~x1 \Phi  ~x2 \Phi  x3}, . . . , {~x1 \Phi  * * * \Phi  ~xnss1 \Phi  xn}. FCapplied to this formulation visits

n nodes and performs 2n consistency checks when usingthe static variable ordering
x1, . . . , xn. FC-hidden performs at least 2n ss 1 consistencychecks irrespective of the variable ordering used, as the domain of the dual variable

associated with the constraint {~x1 \Phi  * * * \Phi  ~xnss1 \Phi  xn} costs that much to filter onceany one of the ordinary variables is instantiated.

Theorem 8. FC-hidden can be super-polynomially worse than FC-orig; i.e., FC-hidden*

superpoly FC-orig.

Proof. See Example 9. \Delta 
Example 10. Consider a CSP with 2n variables, x1, . . . , x2n, each with domain {1, . . . , n},and

n constraints,

C1(x1, x2, xn+1) = {x1 = x2},
C2(x2, x3, xn+2) = {x2 = x3},
...

Cnss1(xnss1, xn, x2nss1) = {xnss1 = xn},
Cn(x1, xn, x2n) = {x1 i= xn}.

The problem is insoluble because the first n ss 1 constraints force x1 = xn and thelast constraint forces

x1 i= xn. Note that in each of the above constraints, the variable
xn+i merely increases the arity and the number of tuples of the constraint. Given thelexicographic static variable ordering

x1, . . . , x2n, FC-orig and FC-hidden will search npaths, {
x1 \Upsilon  1, . . . , xn \Upsilon  1}, {x1 \Upsilon  2, . . . , xn \Upsilon  2}, . . . , {x1 \Upsilon  n, . . . , xn \Upsilon  n}: at eachnode, there is only one value in the domain of the current variable that is consistent with

every uninstantiated variable. Thus FC-orig and FC-hidden visit O(n3) nodes to concludethat the problem is insoluble. However, irrespective of the variable ordering used, along
those paths where all of the xi are set to the same value, FC-dual has to instantiate at leastlog

(n) ss 1 dual variables to reach a dead-end. In particular, it must instantiate enough ofthe dual variables

c1, . . . , cnss1 to allow it to conclude that x1 = xn, which will then yield acontradiction with the last dual variable

cn. However, even under the restriction that eachof the variables
xi get the same value, FC-dual must additionally "instantiate" a variablefrom
xn+1, . . . , x2n at each stage that has no influence on the failure. This will cause itto backtrack uselessly to try

n different ways of setting each dual variable using differentvalues for these variables.

The best variable ordering strategy for FC-dual along these paths is to repeatedlysplit the set of ordinary variables

x1, . . . , xn by instantiating the dual variable over themid-point variables, so as to most quickly derive a relation between

x1 and xn. Forexample, FC-dual would first branch on the dual variable corresponding to the constraint

C(xn/2, xn/2+1, xn+n/2), thus instantiating the two mid-point variables in the sequence
x1, . . . , xn. In the next two branches it would split the subproblems involving x1, . . . , xn/2

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 25
and xn/2+1, . . . , xn. Continuing this way it can instantiate all of the variables x1, . . . , xnby instantiating O

(log(n)) dual variables and thus conclude that x1 = xn to obtain acontradiction. Once failure has been detected FC must then backtrack and try the other

O(n) consistent values of each dual variable. Hence, FC-dual has to explore at leastO

(nlog(n)ss1) nodes.

Theorem 9. FC-dual can be super-polynomially worse than FC-orig and FC-hidden; i.e.,FC-dual *

superpoly FC-orig and FC-dual *superpoly FC-hidden.

Proof. See Example 10. \Delta 

Now we turn to the relation between FC-dual and FC-hidden. In Example 8, we observethat FC-hidden visits O

(n) times as many nodes as FC-dual does. As we now show, thisbound is true in general. We then show that FC-hidden *

poly FC-dual.Let P be any CSP instance, and let
aedual be any variable ordering for dual(P). Wemust show that there exists a variable ordering

aehidden such that the performance of FC on
hidden(P) using aehidden is within a polynomial of its performance on dual(P) using aedual.First, we show how to construct

aehidden using aedual, then we show that under this variableordering a polynomial bound is achieved.

Let n = {z1 \Upsilon  a1, . . . , zk \Upsilon  ak} be a sequence of assignments to ordinary variables;i.e., a possible node in the search tree explored by FC-hidden. We need to compute
aehidden(n); i.e., the next variable to be assigned by FC-hidden when and if it visits n. Thiswill be the variable instantiated by the children of

n. Once we can compute aehidden(n) forany node
n, we will have determined the function aehidden, and hence the ordered search treegenerated by

aehidden and searched by FC-hidden. To do this we establish a correspondencebetween the nodes in the ordered search tree generated by

aedual, Tdual, and nodes thatwould be in the ordered search tree generated by
aehidden, Thidden. Using Theorem 6 wecan consider
Thidden to be an ordered search tree over only the ordinary variables (i.e., theoriginal variables of P).

The correspondence is based on the simple observation that every assignment to a dualvariable

c by FC-dual corresponds to a sequence of assignments to the ordinary variablesin vars
(c). Each node nd in Tdual is a sequence of assignments to dual variables. Letthis sequence of assignments be {

c1 \Upsilon  t1, . . . , ck \Upsilon  tk}, where ti is a tuple of values inthe domain of the dual variable
ci. Each dual variable represents a constraint (from theoriginal formulation P ) over some set of ordinary variables. Let vars

(ci) = {zci1 , . . . , zciri }be the set of ordinary variables associated with the dual variable
ci with ri being thearity of
ci. Assigning ci a value assigns a value to every variable in vars(ci). Given alexicographic ordering of the ordinary variables,

ci \Upsilon  ti thus corresponds to a sequence ofassignments to the ordinary variables in
vars(ci): {z1 \Upsilon  ti [z1], . . . , zri \Upsilon  ti[zri ]}, where
t[x] is the value that tuple t assigns to variable x. Thus we can convert each node nd in
Tdual, nd = {c1 \Upsilon  t1, . . . , ck \Upsilon  tk} into a sequence of assignments to ordinary variables{

zc11 \Upsilon  t1[zc11 ], . . . , zc1r1 \Upsilon  t1[zc1r1 ], . . . , zck1 \Upsilon  tk[zck1 ], . . . , zckrk \Upsilon  tk[zckrk ]}.If no ordinary variable is assigned two different values in this sequence, then for each

variable in the sequence we can delete all but its first assignment. This will yield a non-repeating sequence of assignments to ordinary variables. The fundamental property of

26 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
aehidden is that each such non-repeating sequence generated by the nodes of Tdual will be anode in the ordered search tree

Thidden. We define a function, d ae h from nodes of Tdual tothe nodes of
Thidden. Given a node nd of Tdual, d ae h(nd) is the non-repeating sequence ofassignments to ordinary variables generated as just described. If

nd contains two differentassignments to an ordinary variable, then we leave d ae h
(nd ) undefined (in this case thereis no corresponding node in
Thidden).One thing to note about the function

d ae h is that if n1 and n2 are nodes of Tdual suchthat d ae h is defined on both nodes and

n1 is an ancestor of n2 then d ae h(n1) will bea sub-sequence of or will be equal to
d ae h(n2). This means that either d ae h(n1) is thesame node as
d ae h(n2) or that d ae h(n1) is an ancestor of d ae h(n2) in Thidden.

Example 11. For example, the sequence of assignments nd = {c1(x1, x2, x5) \Upsilon  (0, 1, 0),
c2(x3, x4, x5) \Upsilon  (1, 0, 0), c3(x4, x5) \Upsilon  (0, 0)}, yields the sequence of assignments toordinary variables {

x1 \Upsilon  0, x2 \Upsilon  1, x5 \Upsilon  0, x3 \Upsilon  1, x4 \Upsilon  0, x5 \Upsilon  0, x4 \Upsilon  0,
x5 \Upsilon  0}. No variable is assigned two different values in this sequence, so d ae h(nd ) ={

x1 \Upsilon  0, x2 \Upsilon  1, x5 \Upsilon  0, x3 \Upsilon  1, x4 \Upsilon  0} is the non-repeating sequence, and thissequence of assignments will be a node in

Thidden. On the other hand, the sequence
nffid = {c1(x1, x2) \Upsilon  (0, 1), c2(x1, x3) \Upsilon  (1, 0)} has two different assignments to x1 sod ae h

(nffid ) remains undefined, and nffid does not have a corresponding node in Thidden.

To compute aehidden(n) for some node n (which could be the empty set of assignments)we start by setting

nd = j; i.e., the root of Tdual. At each iteration d ae h(nd) will be aprefix of (or sometimes equal to)

n and we will extend nd so that it covers more of n untild ae h
(nd ) is a super-sequence of n. To extend nd we examine aedual(nd ). Let aedual(nd) = c.
c is the next dual variable assigned by the children of nd . Let oez = {z1, . . . , zk} be thelexicographically ordered sequence of ordinary variables that will be

newly assigned by c(these are the variables in vars
(c) that have not already been assigned in nd ), and let oey ={
y1, . . . , yi} be the sequence of variables assigned by n that come after d ae h(nd ). (Notethat either of, or both of, these sequences could be empty.) There are three possibilities.

1. These two sequences do not match (i.e., neither is a prefix of the other). In this case ndoes not have a matching node in

Tdual, and we can terminate the process and choose
aehidden(n) arbitrarily.2. oe

z is a sub-sequence of or is equal to oey. In this case n assigns a value to each of thevariables

zi. In addition, all of the other variables in vars(c) (the ones that are notnewly assigned by

c) will have been assigned by previous assignments in n. Thusthere is only one tuple of values that can be assigned to

c that will be compatiblewith
n. Let this tuple be t. We check that t is in dom(c). If it is, then nd will have achild that makes the new assignment

c \Upsilon  t, and we extend nd by including that newassignment (i.e., we move
nd to this single matching child). d ae h(nd ) will still be aprefix of
n and we can continue to the next iteration. Otherwise, if t /\Sigma  dom(c), then nhas no matching node in

Tdual and we can terminate the process and choose aehidden(n)arbitrarily.

3. oez is a strict super-sequence of oey. In this case we set aehidden(n) to be the first ordinaryvariable

zi in oez that is unassigned by n.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 27
The time complexity of the above process for computing aehidden is at most a polynomialfactor worse than the time complexity of

aedual, as it only requires polynomial time accessto
aedual. (In particular, we do not need to do any search in Tdual to compute aehidden, ratherwe only need to follow one path of

Tdual.)6Given a problem
hidden(P), the variable ordering aehidden generates an ordered searchtree
Thidden. Using d ae h, we can define an "inverse" function h ae d that maps nodes of
Thidden to nodes of Tdual. The function is used in the proofs of Lemma 4 and Theorem 11.If

n is a node in Thidden (i.e., a non-repeating sequence of assignments to ordinary variablesthat occurs in

Thidden) then h ae d(n) is the first node of Tdual in a breadth-first orderingof
Tdual that makes all of the same assignments as n. Formally, h ae d(n) is defined tobe the

shallowest (closest to the root) and leftmost node nd \Sigma  Tdual such that d ae h(nd )is a super-sequence of

n (not necessarily proper). If there is no such node in Tdual then
h ae d(n) is undefined.

Example 12. Consider the ordered search tree Tdual shown in Fig. 6 and the correspondingordered search tree

Thidden generated by aehidden shown in Fig. 7. h ae d({x1 \Upsilon  a,
x2 \Upsilon  a, x3 \Upsilon  b}) = n3 (nodes in the diagram include all assignments made along thearcs from the node to the root of the tree). Similarly,

h ae d(x1 \Upsilon  a, x2 \Upsilon  a, x3 \Upsilon  b,
x4 \Upsilon  b) = n3. So additional assignments in Thidden do not move to new nodes in Tdualif the dual node contains extra ordinary variables. On the other hand,

h ae d(x1 \Upsilon  a,
x2 \Upsilon  a, x3 \Upsilon  a, x4 \Upsilon  a) = n2, while h ae d(x1 \Upsilon  a, x2 \Upsilon  a, x3 \Upsilon  a, x4 \Upsilon  a,
x5 \Upsilon  b) = n8. So an additional assignment can move down through many nodes in Tdual,as many as is needed to find the first descendant that assigns the new variable. In this case

we had to move down two levels to find a node assigning x5.
Lemma 4. The number of nodes in Thidden that are mapped to the same node in Tdual
by the function h ae d is at most r, the maximum arity of a constraint in the original
formulation.

Proof. Say that the nodes n1, . . . , nk in Thidden are all different and yet h ae d(n1) = * * * =
h ae d(nk) = nd . By the definition of h ae d, d ae h(nd) must be a super-sequence of all ofthese nodes. Hence, they must in fact all be of different lengths, and we can consider them

to be arranged in increasing length. We also see that ni must be a sub-sequence of nj if
j \Theta  i. d ae h(nd) might be equal to nk, but it must be a proper super-sequence of all of theother nodes. Furthermore, if

pn is nd 's parent (in Tdual) then d ae h(pn) must be a propersub-sequence of all of these nodes. (Otherwise,

h ae d(n1) would not be nd as pd wouldhave been a shallower node satisfying
h ae d's definition.) Since nd instantiates only onemore dual variable than
pd , d ae h(nd) can be at most r assignments (to ordinary variables)

6 This is an important, albeit technical point. The number of tuples in the domain of a dual variable can be
exponential in n. So a node nd might have an exponential number of child nodes. However, in this procedure
we need never search the child nodes to find the correct extension of nd . In case (2) we always know the tuple
of assignments that must be the extension and we can test whether or not this extension exists with a single
constraint check. In case (3) we can compute the next variable to assign directly from the constraint's scheme
without looking at the possible assignments to the constraint.

28 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37

Fig. 6. A sample ordered search tree for FC-dual.
Fig. 7. The ordered search tree for FC-hidden that arises from Fig. 6. The nodes that are the values of the function
h ae d refer to the ordered search tree of Fig. 6.

longer than d ae h(pd ). Putting these constraints together we see that the sequence of nodes
n1, . . . , nk can only be at most r long. \Delta 

The final component we need to prove that FC-hidden *poly FC-dual is to recall acharacterization of the nodes visited by FC that is due to Kondrak and van Beek [12].

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 29
Given a CSP P and a tuple of assignments t, we say that t is consistent with a variable if
t can be extended to a consistent assignment including that variable. It is easy to see thatif an assignment

t is consistent with every variable, any subtuple tffi fi t is also consistentwith every variable.

Theorem 10 (Kondrak and van Beek [12]). FC visits a node n (in the ordered search
tree it is exploring) if and only if n is consistent and its parent is consistent with everyvariable.

From this result it follows that if a node n is visited by FC and then FC subsequentlyvisits a child of

n then n must be consistent with every variable. That is, all parent nodesin the search tree explored by FC must be consistent with every variable.

Theorem 11. FC-hidden can be only polynomially worse than FC-dual; i.e., FC-hidden*

poly FC-dual.

Proof. Using the formalism just developed we must first show that the number of nodesvisited by FC-hidden (FC solving

hidden(P)) using aehidden is within a polynomial of thenumber of nodes visited by FC-dual (FC solving dual

(P)) using aedual.That FC-hidden uses
aehidden means that it searches in the tree Thidden, and similarly FC-dual searches in the tree

Tdual. If n is a parent node in the sub-tree of Thidden that is visitedby FC, then by Theorem 10

n must be consistent with every variable. We claim that forevery such parent node
h ae d(n) is defined, and that FC-dual visits h ae d(n) in Tdual. Weprove this claim by induction.

The base of the induction is when n is the root of Thidden. In this case h ae d(n) is theroot of

Tdual, and FC-dual visits it. Let n be a node that is consistent with every variable,and let

p be n's parent. p is also consistent with every variable, as we observed above.Thus by induction

h ae d(p) = pd is defined, and FC-dual visits it. Note that all of pd 'sancestors must map to proper sub-sequences of

p (and n) under d ae h, since pd is theshallowest node to map to a super-sequence of
p. We have two cases.

1. d ae h(pd ) is a proper super-sequence of p. n must next assign the ordinary variable

aehidden(p), which by construction must be the first ordinary variable not assigned by pin the sequence

d ae h(pd). Furthermore, all of pd 's siblings assign values to the samedual variable. Thus they all assign the same sequence of new ordinary variables as

pd ,and in particular
pd and all of its siblings must assign all of the ordinary variablesassigned by
n.Let the last dual variable assigned by

pd be c. Since n is consistent with every variable,there must be at least one tuple
t in dom(c) that is consistent with n. Furthermore,since
pd 's parent makes fewer assignments to ordinary variables than does n, pd 'sparent must also be consistent with

c \Upsilon  t. (Remember that the dual constraints onlyrequire agreement on the shared ordinary variables.) Hence,

pd 's parent must havea child node making the assignment
c \Upsilon  t, this child node is itself consistent, andFC-dual must visit this child node. All such child nodes (siblings of

pd ) yield super-sequences of
n under the mapping d ae h and they are the shallowest nodes to do so:

30 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37

their parent maps to a proper sub-sequence of n. We may take the leftmost such childto be

h ae d(n), and we have also shown that FC-dual visits h ae d(n).2. d ae h

(pd ) = p. In this case p and thus n assigns every ordinary variable in the dualvariables of

pd . Starting at pd we can descend in the tree Tdual. At each stage weexamine the dual variable

c assigned by the children of pd . If n assigns all of thevariables of
c, then there can be at most one tuple t in dom(c) that is consistent with n.Furthermore, since

n is consistent with every variable, including c, such a tuple mustexist. Since
pd makes fewer assignments to ordinary variables than n it too must beconsistent with every variable, with

c \Upsilon  t, and no other value in dom(c). Thus sinceFC-dual visits
pd it will visit the child nd of pd making the assignment c \Upsilon  t and noother children. Now we set

pd to be nd and repeat the argument until we set pd to bea node that makes a super-set (or the same set) of the assignments made by

n. At thispoint, we are back to case one above.

So we have that for each parent node n in the sub-tree visited by FC-hidden, there isa corresponding node h ae d

(n) in the sub-tree visited by FC-dual. Furthermore, at most
r nodes can be mapped to the same node by h ae d (by Lemma 4), so there are at most
r times as many parent nodes visited by FC-hidden as nodes visited by FC-dual. Now,since each parent node in

Thidden can have at most d children (only ordinary variables areinstantiated by FC-hidden and

d is the maximum number of values these variables possess)the total number of nodes visited by FC-hidden is at most

d times the number of parentnodes visited, and at most
rd times the number of nodes FC-dual visits. To complete theproof, we note that both FC-dual and FC-hidden filter only dual variables and at most

mof them when forward checking at a node and that therefore the number of consistency

checks performed at each node are polynomially related. \Delta 

We summarize the relations between FC on the different formulations in Fig. 8.
4.3. Maintaining (generalized) arc consistency algorithm (MAC)

In this section, we compare the performance of an algorithm that maintains (general-ized) arc consistency or really-full lookahead [8,16,20] on the three models. We refer to
the algorithm as MAC; namely, maintaining generalized arc consistency algorithm.We begin by characterizing the nodes visited by MAC. The algorithm enforces arc
consistency on the CSP induced by the current assignment (see Definition 5). Given aCSP and an assignment

t, we say t is arc consistent if the CSP induced by t is not emptyafter enforcing arc consistency. It is easy to see that if an assignment

t is arc consistent,any subtuple
tffi fi t is also arc consistent.

Theorem 12. MAC will visit a node n (in the ordered search tree it is exploring) if and only
if n's parent is arc consistent and the value assigned to the current variable by n has not
been removed from its domain when enforcing arc consistency on n's parent.

Proof. We prove this by induction on the length of n. The claim is vacuously true when nis the empty sequence of assignments. Say that

n is of length k, and let p be n's parent. If

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 31
Fig. 8. Summary of the relations between the combinations of algorithms and formulations. A solid directed edge
from A-A to B-B means A-A *poly B-B and a dashed directed edge means A-A *superpoly B-B.

n is visited then it is clear that p must have yielded a non-empty CSP after MAC enforced
arc consistency on it; i.e., p must have been arc consistent, and the new assignment made
at n must have survived arc consistency. Conversely, suppose p was arc consistent and that
n survives enforcing arc consistency at p. Since p is itself arc consistent, it must have had
an arc consistent parent, and it must have survived the enforcement of arc consistency at
its parent. Hence, by induction MAC will have visited p. But then once MAC visits p and
enforces arc consistency there, it will have a non-empty CSP in which n survived. Thus it
must continue on to visit n. \Delta 

Note this also means that MAC will visit a node n (in the ordered search tree it is
exploring) if n is arc consistent (as then its parent would be arc consistent, and it would
have survived the enforcement of arc consistency at its parent).

32 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37

Just as in the case of FC-hidden, MAC-hidden does not need to instantiate all the
variables in order to find a solution. A variable ordering for MAC-hidden that instantiates
all the ordinary variables first is at worst polynomially bounded compared to any other
variable ordering strategy.

Theorem 13. Given a CSP P and a variable ordering ae for the hidden transformation
hidden(P), we can construct (in polynomial time given polynomial time access to ae) a
new variable ordering aeffi that instantiates all of the ordinary variables of hidden(P) prior
to instantiating any dual variable such that MAC-hidden using aeffi visits at most O(r) times
as many nodes as it visits when using ae, where r is the arity of the largest constraint scheme
in P .

Proof. See [4]. \Delta 

Given the above, we can again assume that MAC-hidden only instantiates the ordinary
variables during its search.We know from Theorem 1 that arc consistency on the hidden transformation is

equivalent to arc consistency on the original formulation. Because MAC-orig and MAChidden explore the same search tree, we expect they should visit the same nodes.

Lemma 5. Given an assignment t of a CSP P, ac(P|t ) is empty iff ac(hidden(P)|t ) is
empty. Furthermore, for each ordinary variable x, x has the same domain in ac(P|t ) and
ac(hidden(P)|t ).

Proof. Since ac(P|t ) is arc consistent, ac(P|t ) is empty iff hidden(ac(P|t )) is empty (by
Lemma 2) iff ac(hidden(P|t )) is empty (by Theorem 1). Furthermore, for each ordinary
variable x we have that domac(P|t)(x) = domac(hidden(P|t)) (by Corollary 1). Now consider
the two problems hidden(P|t )) and hidden(P)|t . In P|t (Definition 5) the domain of each
ordinary variable x \Sigma  vars(t) is reduced to the singleton value assigned to that variable by
t, {t[x]}. The domains of the other variables are unaffected. However, all of the constraints
of P|t have also been reduced so that they contain only tuples over the reduced variable
domains. Thus the hidden transformation hidden(P|t ) will contain dual variables in which
any tuple incompatible with t has been removed. In hidden(P)|t on the other hand, the
dual variables will not be reduced, they will contain the same set of tuples as the original
constraints of P. However, every tuple in the domain of a dual variable c in hidden(P)|t
that is not in the domain of c in hidden(P|t ) must be arc inconsistent. It assigns an ordinary
variable a value that no longer exists in the domain of that variable. So enforcing arc
consistency will remove all of these tuples. Clearly if we sequence arc consistency so
that we remove these values first, we will first transform hidden(P)|t to hidden(P|t ) after
which the continuation of arc consistency enforcement must yield the same final CSP. That
is, ac(hidden(P|t )) = ac(hidden(P)|t), and thus ac(P|t) is empty iff ac(hidden(P)|t ) isempty. Furthermore, for every variable

domac(hidden(P|t)) = domac(hidden(P)|t), and thus for
every ordinary variable domac(P|t)(x) = domac(hidden(P)|t). \Delta 

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 33
Theorem 14. MAC-orig can be only polynomially worse than MAC-hidden, and vice versa;
i.e., MAC-orig *poly MAC-hidden and MAC-hidden *poly MAC-orig.

Proof. Since MAC-orig and MAC-hidden search over the same variables, the same
variable ordering can be used by both formulations. Let ae be the variable ordering usedand let

Tae be the ordered search tree induced by ae for a CSP P. Both MAC-orig and MAC-hidden will search in

Tae . We show that they both visit the same nodes in Tae. The parent p of
node n is arc consistent in P iff ac(P|p) is not empty (by definition) iff ac(hidden(P)|p) isnot empty (by Lemma 5) iff

p is arc consistent in hidden(P). Furthermore, once we enforcearc consistency at
p in P the domains of all of the uninstantiated (ordinary) variableswill be the same as their domains in

ac(P|p) which will be the same as their domains
in ac(hidden(P)|p) (by Lemma 5). Thus n will survive arc consistency enforcement at pin P iff it survives arc consistency enforcement at

p in hidden(P). Hence, by Theorem 12,MAC will visit
n in P iff MAC visits n in hidden(P).
To complete the proof, we note that arc consistency on a CSP P takes O(mdr) time inthe worst case and arc consistency on

hidden(P) takes O(mrdr+1) time [2], where d, m,and
r denote the size of the largest domain, the number of constraints, and the arity of thelargest constraint scheme in P, respectively. \Delta 

The following example shows that MAC-orig and MAC-hidden can be exponentiallybetter than MAC-dual.
Example 13. Consider a CSP with n + n(n ss 1)/2 variables x1, . . . , xn, and y1, . . . ,
yn(nss1)/2, each with domain {1, . . . , n ss 1}, and n(n ss 1)/2 constraints,

C(x1, x2, y1) = {x1 i= x2},
C(x1, x3, y2) = {x1 i= x3},
...

C(xnss1, xn, yn(nss1)/2) = {xnss1 i= xn}.
It is a pigeon-hole problem with an extra variable yi in each constraint. The pigeon-hole
problem is insoluble but highly locally consistent. MAC-orig and MAC-hidden have toinstantiate at least

n ss 2 variables before an induced CSP is empty after enforcing arcconsistency and they visit O

(n!) nodes to conclude the problem is insoluble. It can be seen
that MAC-dual has the same pruning power as MAC-orig because each pair of originalconstraints share at most one variable. However, at each node of the dual search tree, MACdual has to additionally instantiate a variable yi, which has no influence on the failure. Asa result, MAC-dual has to explore a factor of O

(nn) more nodes and is thus exponentially
worse than MAC-orig and MAC-hidden.

The following example shows the converse: if two original constraints share more thanone variable, arc consistency on the dual is tighter than on the original formulation, and
MAC-dual can be super-polynomially better than MAC-orig and MAC-hidden.

34 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
Example 14. Consider a CSP with 4n + 2 variables, x1, . . . , x4n+2, each with domain{1

, . . . , n}, and 2n + 1 constraints,

C(x1, x2, x3, x4) = \Delta (x1 + x2 mod 2) i= (x3 + x4 mod 2)\Theta ,
C(x3, x4, x5, x6) = \Delta (x3 + x4 mod 2) i= (x5 + x6 mod 2)\Theta ,
...

C(x4nss1, x4n, x4n+1, x4n+2) = \Delta (x4nss1 + x4n mod 2) i= (x4n+1 + x4n+2 mod 2)\Theta ,
C(x4n+1, x4n+2, x1, x2) = \Delta (x4n+1 + x4n+2 mod 2) i= (x1 + x2 mod 2)\Theta .

(x1 + x2 mod 2) = 0 implies (x3 + x4 mod 2) = 1 implies (x5 + x6 mod 2) = 0 implies
. . . implies (x4n+1 + x4n+2 mod 2) = 0. But then the last constraint also implies (x1 +
x2 mod 2) = 1. Thus the problem is insoluble. When enforcing arc consistency at a nodein the original search tree, no values will be removed from the domain of an ordinary

variable unless the variable is the last uninstantiated variable in a constraint. The bestvariable ordering strategy in the original formulation is to divide the problem in half by first
branching on the variables x1, x2, x2n+1 and x2n+2. Then we can branch on an insolublesubproblem consisting of

x3, . . . , x2n, or x2n+3, . . . , x4n+2. By this divide-and-conquerapproach, the maximum depth of the original search tree is O

(log(n)) and the number ofnodes explored by MAC-orig and MAC-hidden is O
(nlog(n)). In the dual transformation,on the other hand, the dual constraints form a cycle in the constraint graph. Once a dual

variable is instantiated, the cycle is broken so that the induced CSP is empty after enforcingarc consistency. Thus MAC-dual only needs to instantiate one variable to conclude the
problem is insoluble and it visits O(n4) nodes. MAC-dual is therefore super-polynomiallybetter than MAC-orig and MAC-hidden.

Theorem 15. MAC-dual can be super-polynomially worse than MAC-orig and MAChidden; i.e., MAC-dual *superpoly MAC-orig and MAC-dual *superpoly MAC-hidden.

Proof. See Example 13. \Delta 
Theorem 16. MAC-orig and MAC-hidden can be super-polynomially worse than MACdual; i.e., MAC-orig *superpoly MAC-dual and MAC-hidden *superpoly MAC-dual.

Proof. See Example 14. \Delta 

MAC-dual can be super-polynomially better because it enforces a stronger consistencyon the dual transformation and MAC-hidden can be super-polynomially better because it
makes fewer instantiations at each stage during the backtracking search.Fig. 8 summarizes our results. For completeness, we summarize in the diagram
our results for the chronological backtracking algorithm (BT). However, for reasons oflength, we do not present the proofs of these results. Such proofs, using an alternative
formalization, can be found in [4]. As can be seen, BT-dual can be only polynomiallyworse than BT-hidden, and vice versa. On the other hand, BT-dual and BT-hidden can be
super-polynomially worse than BT-orig, and vice versa.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 35
Also included in the diagram are results due to Kondrak and van Beek [12] betweendifferent algorithms applied to the same problem formulation. For example, consider the
relation FC-hidden *poly BT-hidden. Since the same problem is being solved, Kondrak andvan Beek's result that FC always visits the same or fewer nodes than BT, can be directly
applied.7 Then, since arc consistency is O(md2) and forward checking is O(md) for binaryproblems with

m constraints and domain size d, it follows that FC-hidden *poly BT-hidden.Interestingly, although it is easily shown that MAC-orig always visits the same or fewer

nodes than FC-orig, we have that MAC-orig *superpoly FC-orig, since there exist problemswhere MAC-orig can perform exponentially more constraint checks than FC-orig.

Furthermore, we can use properties of *poly to draw additional conclusions from thediagram. Whenever we are comparing formulations that are all polynomially related in size
the relation *poly is transitive. Thus, for example, since the hidden and dual transformations(although exponentially larger than the original formulation) are polynomially related in
size, from MAC-hidden *poly FC-hidden and FC-hidden *poly FC-dual, we can conclude that
MAC-hidden *poly FC-dual. Similarly, from MAC-dual *poly FC-dual and FC-dual *poly BT-dual,
we can conclude that MAC-dual *poly BT-dual. Note that the *superpoly relation is not transitive.
So, for example, we cannot conclude that since FC-hidden *superpoly FC-orig and FC-orig*

superpoly FC-dual we have that FC-hidden *superpoly FC-dual. In fact, as shown in Theorem 11,FC-hidden *

poly FC-dual.

5. Conclusion

We compared three possible models for a constraint satisfaction problem--the originalformulation, the dual transformation, and the hidden transformation--with respect to the
effectiveness of various local consistency properties and the performance of three differentbacktracking algorithms. To our knowledge, this is the first comprehensive attempt to
evaluate constraint modeling techniques in a formal way.We studied arc consistency on the original formulation, and its dual and hidden
transformations. We showed that arc consistency on the dual transformation is tighter thanarc consistency on the original formulation, which itself is equivalent to arc consistency
on the hidden transformation. We then considered local consistencies that are defined overbinary constraints. For example, we showed that singleton arc consistency on the dual is
tighter than singleton arc consistency on the hidden.We then compared the performance of three different backtracking algorithms on a nonbinary CSP and on its dual and hidden transformations. Considering the forward checkingalgorithm, FC-dual can be super-polynomially worse than FC-orig and FC-hidden, and
FC-orig can be super-polynomially worse than FC-dual and FC-hidden. However, the costto solve FC-hidden can be at most a polynomial factor worse than the cost to solve FCdual. Turning to the algorithm that maintains arc consistency, MAC-orig and MAC-hiddenvisit the same nodes and have the same cost at each node, while MAC-dual can be super7 Kondrak and van Beek prove their results for static variable orderings. However, their results also hold when
the algorithm searches a fixed ordered search tree, as is allowed by the definition of *poly.

36 F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37
polynomially worse than MAC-orig and MAC-hidden because it may have to make manymore instantiations at each node of the search tree. Furthermore, MAC-orig and MAChidden can be super-polynomially worse than MAC-dual because MAC-dual enforces astronger consistency property than MAC-orig or MAC-hidden do.

Our results can be used by practitioners to help build efficient models for real-worldconstraint satisfaction problems. Our objective is to provide some general guidelines as to
whether or not, or under which conditions, the dual or hidden transformation should beapplied to a non-binary CSP. For example, if the performance of formulation A is bounded
by a polynomial from formulation B but can be super-polynomially better than B, thenwe are assured that the performance of A cannot be much worse than that of B, and that
furthermore A has the potential to provide a dramatic improvement over B. Thus, A maybe preferred in the hope that it can provide super-polynomial savings over B and given
that in the worst case, it cannot lose too much. On the other hand, if two formulations areequivalent for a certain backtracking algorithm, there is little to be gained from developing
both models.

References

[1] F. Bacchus, P. van Beek, On the conversion between non-binary and binary constraint satisfaction problems,

in: Proc. AAAI-98, Madison, WI, 1998, pp. 311-318.[2] C. Bessie`re, J.-C. Re'gin, Arc consistency for general constraint networks: Preliminary results, in: Proc.

IJCAI-97, Nagoya, Japan, 1997, pp. 398-404.[3] J.E. Borrett, Formulation selection for constraint satisfaction problems: A heuristic approach, Ph.D. Thesis,
University of Essex, 1998.
[4] X. Chen, A theoretical comparison of selected CSP solving and modeling techniques, Ph.D. Thesis,

University of Alberta, Edmonton, AB, 2000.[5] R. Debruyne, C. Bessie`re, Domain filtering consistencies, J. Artificial Intelligence Res. 14 (2001) 205-230.

[6] R. Dechter, On the expressiveness of networks with hidden variables, in: Proc. AAAI-90, Boston, MA, 1990,

pp. 556-562.[7] R. Dechter, J. Pearl, Tree clustering for constraint networks, Artificial Intelligence 38 (1989) 353-366.

[8] J. Gaschnig, Experimental case studies of backtrack vs. Waltz-type vs. new algorithms for satisficing

assignment problems, in: Proc. Second Canadian Conference on Artificial Intelligence, Toronto, ON, 1978,
pp. 268-277.[9] L. Getoor, G. Ottosson, M. Fromherz, B. Carlson, Effective redundant constraints for online scheduling, in:

Proc. AAAI-97, Providence, RI, 1997, pp. 302-307.[10] R.M. Haralick, G.L. Elliott, Increasing tree search efficiency for constraint satisfaction problems, Artificial
Intelligence 14 (1980) 263-313.
[11] P. Je'gou, Decomposition of domains based on the micro-structure of finite constraint satisfaction problems,

in: Proc. AAAI-93, Washington, DC, 1993, pp. 731-736.[12] G. Kondrak, P. van Beek, A theoretical evaluation of selected backtracking algorithms, Artificial

Intelligence 89 (1997) 365-387.[13] A.K. Mackworth, Consistency in networks of relations, Artificial Intelligence 8 (1977) 99-118.
[14] A.K. Mackworth, On reading sketch maps, in: Proc. IJCAI-77, Cambridge, MA, 1977, pp. 598-606.
[15] J.J. McGregor, Relational consistency algorithms and their application in finding subgraph and graph

isomorphisms, Inform. Sci. 19 (1979) 229-250.[16] B.A. Nadel, Constraint satisfaction algorithms, Comput. Intelligence 5 (1989) 188-224.

[17] B.A. Nadel, Representation selection for constraint satisfaction: A case study using n-queens, IEEE Expert 5

(1990) 16-23.[18] C.S. Peirce, in: C. Hartshorne, P. Weiss (Eds.), in: Collected Papers, Vol. III, Harvard University Press,

Harvard, 1933, Cited in: F. Rossi, C. Petrie, V. Dhar, 1989.

F. Bacchus et al. / Artificial Intelligence 140 (2002) 1-37 37
[19] F. Rossi, C. Petrie, V. Dhar, On the equivalence of constraint satisfaction problems, Technical Report ACTAI-222-89, MCC, Austin, TX, 1989. A shorter version appears in: Proc. ECAI-90, Stockholm, Sweden,
pp. 550-556.
[20] D. Sabin, E.C. Freuder, Contradicting conventional wisdom in constraint satisfaction, in: Proc. ECAI-94,

Amsterdam, 1994, pp. 125-129.
[21] H. Simonis, Standard models for finite domain constraint solving, Tutorial presented at PACT'97 Conference

London, UK, 1997.
[22] B. Smith, S.C. Brailsford, P.M. Hubbard, H.P. Williams, The progressive party problem: Integer linear

programming and constraint programming compared, Constraints 1 (1996) 119-138.
[23] K. Stergiou, T. Walsh, Encodings of non-binary constraint satisfaction problems, in: Proc. AAAI-99,

Orlando, FL, 1999, pp. 163-168.
[24] P. van Beek, X. Chen, CPlan: A constraint programming approach to planning, in: Proc. AAAI-99, Orlando,

FL, 1999, pp. 585-590.
[25] P. Van Hentenryck, Constraint Satisfaction in Logic Programming, MIT Press, Cambridge, MA, 1989.
[26] R. Weigel, C. Bliek, B. Faltings, On reformulation of constraint satisfaction problems, in: Proc. 13th

European Conference on Artificial Intelligence, Brighton, UK, 1998, pp. 254-258.