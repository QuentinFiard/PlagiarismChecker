

# TOWARDS  A  THEORY  OF  TYPE  STRUCTURE 
John  C.  Reynolds 
Syracuse  University 
Syracuse,  New  York  13210,  U.S.A. 

Introduction 

The  type  structure  of  programming  languages  has  been  the  subject  of  an 
active  development  characterized  by  continued  controversy  over  basic 
principles. (I-7)  In  this  paper,  we  formalize  a  view  of  these  principles 
somewhat  similar  to  that  of  J.  H.  Morris. (5)  We  introduce  an  extension  of 

the  typed  lambda  calculus  which  permits  user-defined  types  and  polymorphic 
functions,  and  show  that  the  semantics  of  this  language  satisfies  a 
representation  theorem  which  embodies  our  notion  of  a  "correct"  type  structure. 

We  start  with  the  belief  that  the meaning  of  a  syntactically  valid 
program  in  a  "type-correct"  language  should  never  depend  upon  the  particular 

representations  used  to  implement  its  primitive  types.  For  example,  suppose 
that  S  and  S'  are  two  sets  such  that  the  members  of  S  can  be  used  to 
"represent"  the  members  of  S'.  We  can  conceive  of  running  the  same  program 
on  two  machines  M  and  M'  in which  the  same  primitive  type,  say  inteser,  ranges 
over  the  sets  S  and  S'  respectively.  Then  if  every"integer"input  to M 
represents  the  corresponding  input  to M',  and  if  M  interprets  every  primitive 
operation  involving  integers  in  a way  which  represents  the  interpretation 
of  M',  we  expect  that  every  integer  output  of  M  should represent  the 

corresponding  output  of  M'.  Of  course,  this  idea  requires  a  precise  definition 
of  the  notion  of  "represents";  we  will  supply  such  a  definition  after 

formalizing  our  illustrative  language. 

The  essential  thesis  of  Reference  5  is  that  this  property  of  representation 
independenceshould  hold  for  user-defined  types  as  well  as  primitive  types. 
The  introduction  of  a  user-defined  type  t  should  partition  a program  into 

#Work  supported  by  Rome  Air  Force  Development  Center  Contract  No. 

30602~72-C-0281  ,  ARPA  Contract  No.  DAHC04-72-C-0003  ~ and  National 

Science  Foundation  Grant  GJ-41540. 

409 
an  "outer"  region  in which  t behaves  like  a primitive  type  and  is manipulated 
by  various  primitive  operations  which  are  used  but  not  defined,  and  an  "inner" 

region  in which  the  representation  of  t  is  defined  in  terms  of  other  types, 
and  the  primitive  operations  on  t  are  defined  in  terms  of  this  representationo 
We  expect  that  the  meaning  of  such  a program will  remain  unchanged  if  the  inner 

region  is  altered  by  changing  the  representation  of  the  type  and  redefining  its 
primitive  operations  in  a  consistent  manner. 

We  also wish  to  consider  the  old  but  neglected  problem  of  polymorphic 
functions,  originally  posed  by  Strachey.  Consider  the  construction  of  a 
program  in which  several  different  types  of  arrays  must  be  sorted.  We  can 

conceive  of  a  "polymorphic  sort  function"  which,  for  any  type  t,  accepts  an 
array  with  elements  of  type  t and  a binary  ordering  predicate  whose  arguments 
must  be  of  type  t,  and  produces  an  array with  elements  of  type  t.  We would 

like  to  define  such  a  function,  and  to have  each  call  of  the  function 
syntactically  checked  to  insure  that  it  is  type-correct  for  some  t.  But  in  a 

typed  language  a  separate  sort  function  must  be  defined  for  each 
type,  while  in  a  typeless  language  syntactic  checking  is  lost.  We  suggest  that 
a  solution  to  this  problem  is  to  permit  types  themselves  to  be  passed  as  a 

special  kind  of  parameter,  whose  usage  is  restricted  in  a way which  permits 

the  syntactic  checking  of  type  correctness. 

An  Illustrative  Language 

To  illustrate  these  ideas,  we  introduce  an  extension  of  the  typed  lambda (8) 
~calculus  w~ich  permits  the  binding  of  type  variables.  Although  this  language 

is  hardly  an  adequate  vehicle  for  programming,  it  seems  to  pose  the  essense  of 

the  type  structure  problem,  and  it  is  simple  enough  to  permit  a brief  but 
rigorous  exposition  of  its  semantics. 

We  begin  with  a  typed  lambda  calculus  in which  the  type  of  every  expression 
can be  deduced  from  the  type  of  its  free  variables.  For  this  purpose  it  is 
sufficient  to  supply,  at  each  point  of  variable  binding,  a  type  expression 
describing  the variable  being  bound.  For  example, 

~x  C t.  x 
denotes  the  identity  function  for  objects  of  type  t,  and 

410 
%f  s  t  / t.  Xx  s  t.  f(f(x)) 
denotes  the  doubling  functional  for  functions  over  t. 

It  is  evident  that  the meaning  of  such  expressions  depends  upon  both 
their  free  normal  variables  and  their  free  type  variables  (e.g.,  t  in  the  above 
examples).  This  suggests  the  addition  of  a  facility  for  binding  type  variables 

to  create  functions  from  types  to values,  called  polymorphic  functions.  For 
example, 

At.  Xx  s  t.  x 
is  the  polymorphic  identity  function,  which  maps  t into  the  identity  function 

for  objects  of  type  t,  and 

At.  If  e  t  + t.  %x  e  t.  f(f(x)) 

is  the  polymorphic  doubling  functional,  which  maps  t  into  the  doubling  functional 
for  functions  over  t. 

The  next  step  is  to  permit  the  application  of  polymorphic  functions  to  type 
expressions,  and  to  introduce  a new  form  of  beta-reduction  for  such  applications. 

In  general,  if  r  is  a normal  expression  and w  is  a type  expression,  then 

(At.  r)[w] 
denotes  the  application  of  the  polymorphic  function  At.  r to  the  type w,  and 

is  reducible  to  the  expression  obtained  from  r by  replacing  every  free  occurrence 

of  t by w  (after  possible  alpha-conversion  to  avoid  collision  of variables). 
For  example,  the  application  of  the  polymorphic  identity  function  to  the  type 
integer  /  real, 

(At.  Xx  c t.  x)[integer  +  real] 
reduces  to  the  identity  functional  for  functions  from  integer  to  real, 

Xx  s integer  /  real.  x 
Finally,  we  must  introduce  a new kind  of  type  expression  to  describe  the 
types  of  polymorphic  functions.  We write  At.  w to  denote  the  type  of  polymorphic 
function  which,  when  applied  to  the  type  t,  produces  a value  of  type w.  Thus 
if  the  expression  r has  the  type w,  then  the  expression  At.  r has  the  type  At.  w. 
For  example,  the  type  of  the  polymorphic  identity  function  is  At.  t  / t,  while 

the  type  of  the  polymorphic  doubling  functional  is  gt.  (t  / t)  +  (t /  t). 

411 
In  providing  polymorphic  functions,  we  also  provide  user-defined  types. 
For  example,  suppose  outer  is  an  expression  in  which  cmp  is  a  primitive  type 

(i.e.,  a  free  type  variable)  intended  to  denote  complex  numbers,  add  and  magn 
are  primitive  functions  (i.e.,  free  normal  variables)  intended  to  denote 
addition  and  magnitude  functions  for  complex  numbers,  and  i  is  a primitive 

constant  (i.e.,  a  free  normal  variable)  intended  to  denote  the  square  root  of  -i. 
Suppose  we  wish  to  represent  complex  numbers  by  pairs  of  reals,  and  to  represent 

addition,  magnitude,  and  the  square  root  of  -i  by  the  expressions. 

addrep  ~  (real  x  real)  x  (real  x  real)  /  (real  x  real) 
magnrep  s  (real  x  real)  +  real 

irep  ~  (real  *  real) 

This  representation  can  be  specified  by  the  expression 

(Acmp.  %add  s  cmp  x  cmp  +  cmp.  %magn  s  cmp  *  real.  %i  s  cmp.  outer) 

[real  x  real]  (addrep)  (magnrep)  (irep) 
(Our  illustrative  language  does  not  include  the  Cartesian  product,  but  its 
addition  should  not  pose  any  significant  problems.)  Admittedly,  this  is  hard 
to  read,  but  the  problem  should  be  amenable  to  judicious  syntactic  sugaring. 

We  now  proceed  to  develop  a  formal  definition  of  our  illustrative 
language,  culminating  in  a  "representation  theorem"  which  asserts  its  type 
correctness. 

Notational  Preliminaries 

For  sets  S  and  S',  we  write  S  x  S' to  denote  the  Cartesian  product  of  S  and 

S ,S S',  S~S'  or  to  denote  the  set  of  functions  from  S  to  S',  and  when  S  and  S' 

are  domains  (in  the  sense  of  Scott)  S  +  S' to  denote  the  set  of  continuous 

functions  from  S  to  S'.  If  F  is  a  function  which  maps  each  member  of  S  into 
a  set,  we  write  H  F(x)  to  denote  the  set  of  functions  f  such  that  the  domain 

xcS 
of  f  is  S  and,  for  each  x  c S,  f(x)  ~  F(x). 

For  f  ~  S -~S',  x  g S,  x'  ~  S',  we  write  [flxlx']  to  denote  the  function 
%y  g  S.  if  y  =  x then  x'  else  f(y). 

412 
Syntax 

To  formalize  the  syntax  of  our  language,  we  begin  with  two  disjoint, 
countably  infinite  sets:  the  set  T  of  type ~ariables  and  the  set  V  of  normal 
variables.  Then  W,  the  set  of t_~  expressions,is  the minimal  set  satisfying: 

(la)  If  t  s  T then: 

t~W. 
(ib)  If Wl,  w  2  ~  W then: 

(w  I  /  w 2)  ~  W. 
(ic)  If  t  a  T and w  ~  W then: 

(At. w)  ~ W. 
(To  keep  the  syntax  simple,  we  have  specified  complete  parenthesization,  but 
in writing  particular  type  expressions  we  will  omit  parentheses  according  to 
common  usage.) 

From  the  fact  that  At.  w is  supposed  to  bind  the  occurrences  of  t  in w, 
one  can  define  the notions  of  free  and  bound  occurrences  of  type  variables, 
and  of  alpha-conversion  of  type  expressions  in  an  obvious  manner.  We write 
w  =  w' to  indicate  that  w  and w'  are  alpha-convertible.  (In a more  complex 

language,  the  relation  = might  be  larger;  the  idea  is  that  it must  be  a 
decidable  equivalence  relation  which  implies  that  w  and w'  have  the  same 
meaning.) 

One  can  also  define  the  notion  of  substitution  in  an  obvious  manner. 

We write  w  I  I~  2 to  denote  the  type  expression  obtained  from w  I by  replacing  every 

free  occurrence  of  t by w2,  after  alpha-convering  w  I so  that  no  type  variable 
occurs  both  bound  in w  I and  free  in w 2. 

To  define  normal  expressions,  we must  capture  the  idea  that  every  normal 
expression  has  an  explicit  type.  Specifically,  an  assignment  of  a  type 
expression  to  every  normal  variable  which  occurs  free  in  a normal  expression  r 
must  induce  an  assignment  of  a  type  expression  to  r  itself  which  is  unique 

(to within  alpha-conversion).  For  all  Q  e  V ~W  and w  ~  W we write  RQw  to 
denote  the  set  of normal  expressions  for which  the  assignment  of  Q(x)  to  each 
normal  variable  x will  induce  the  assignment  of w  to  the normal  expression  itself. 

413 
Then  RQw  is  the  minimal  family  of  sets  satisfying: 

(2a)  If  Q  ~ V~W  and  x  E  V then: 

x  s RQQ(x ) 

,  ,  RQw ~ (2b)  If  Q  ~ V~W,  Wl,  Wl,  w  2  ~ W,  w  I  =  w I,  r  I  e RQ(wl/w2 ),  and  r  2  s  ~ then: 
(r  I  r  2)  s RQw 2 
(2c)  If  Q  ~ V~W,  w  I,  w  2  s W,  x  s V,  and  r  s R[QiXlWl]  w2  then: 

(%x  c  w  I.  r)  s RQ(wl~W2 ) 
(2d)  If  Q  ~  V ~W,  wl,  w  2  c W,  t  E T,  and  r  e RQ(At.Wl)  then: 

(r[w2])  e  R 

Q(Wll~ 2) 

(2e)  If  Q  s  V ~W,  w  ~ W,  t  e T,  r  e RQw,  and  t  does  not  occur  free 

in  Q(x)  for  any  x  which  occurs  free  in  r,  then: 

(At.  r)  s  RQ(&t.w ) 

(Again  we  have  specified  complete  parenthesization,  but  will  omit  parentheses 
according  to  common  usage.)  By  structural  induction  on  r,  it  is  easy  to  show 

that  r  ~ RQw  and  r  c RQ  implies  w  = w' W  v 

The  restriction  on  t  in  (2e)  reflects  the  fact  that  the  meaning  of  t  in 
At.  r  is  distinct  from  its  meaning  in  the  surrounding  context.  For  example, 
Q(x)  =  t does  not  imply  At.x  ~  RQ(At.t ). 

414 
Semantics 

We  will  interpret  our  language  in  terms  of  the  lattice-theoretic  approach 
of  D.  Scott~9-12~ntuitively  the  effect  of  a  type  expression  is  to  produce  a 

Scott  domain  given  an  assignment  of  a  domain  to  each  free  type  variable  occurring 
in  the  type  expression.  Thus  we  expect  the  meaning  of  type  expressions  to  be 
given  by  a  function 

B  s W==~J0T~Jo 

where~denotes  the  class  of  all  domains. 

To  specify  B  we  consider  each  of  the  cases-in  the  syntactic  definition  of W: 

(la)  Obviously, 

B[t](D)  = D(t) 
(We will  use  barred  variables  to  denote  functions  of  T,  and  square 
brackets  to  denote  application  to  syntactic  arguments.) 

(ib)  We  intend  w  I  /  w  2 to  denote  the  domain  of  continuous  functions 

from  the  domain  denoted  by  w  I to  the  domain  denoted  by  w 2.  Thus 

B[w I  ~ w2](D)  =  arrow(B[Wl](D),  B[w2](D)) 
where  arrow  e  (~xJO)~O  satisfies 

arrow(D I,  D 2)  =  D  1  /  D 2. 
(ic)  We  intend  At.  w  to  denote  a  set  of  functions  over  the  class  of 

domains  which,  when  appl~ed  to  a  domain  D  will  produce  some  element 
of  the  domain  denoted  by  w  under  the  assignment  of  D  to  t.  Thus 

B[At.  w](~)  =  delta(%D  ~.  B[w][DItID]) 
where  delta  s  (J~D)=7~)satisfies 

delta(e)  ~  ~ e(D) 

DsJO 

We  leave  open  the  possibility  that  delta(e)  may  be  a  proper  subset 

of  the  above  expression.  (Indeed,  if  we  are  going  to  avoid  the 
paradoxes  of  set  theory  and  consider  delta(@)  to  be  a  domain,  it  had 
better  be  a very  proper  subset.) 

By  structural  induction,  one  can  show  that  w  = w'  implies  B[w]  =  B[w'],  and 
that  B[w  I I~2](~) =  B[Wl][~  I  t  i B[w2](~)] 

415 
The  effect  of  a normal  expression  is  to produce  a value,  given  an 
assignment  of domains  to its  free  type variables  and an assignment  of values 

to  its  free normal variables.(We  will  call  the  latter  assignment  an environment.) 
However,  this  effect must  conform  to the type  structure.  When  given  a  type 

assignment D,  a normal  expression  r  s RQw must  only  accept  environments  which 
map  each variable  x into  a member  of  the domain B[Q(x)](D),  and r must  produce 

a member  of  the domain B[w](D).  Thus we  expect  that,  for all Q  c V~W  and 
w  ~ W,  the meaning  of  the normal  expressions  in RQw will be given by a function 

MQw  e R~  ==k  H m(Env~(D)  +  B[w](D)) 
where 

EnVQ(D)  =  ~  B[Q(x)](D)  . 

xgV 

To  specify  the MQw we  consider  each of  the  cases  in  the syntactic 
definition  of RQw.  Essentially  the  specification  is  an immediate  consequence 

of  the  intuitive meaning  of  the language,  guided by  the necessity  of making  the 
functionalities  come out  right: 

(2a) MQQ(x)[X](D)(e)  =  e(x) 

(2b) MQw2[r I r2] (D) (e) =  (MQ(wl_>W2) [r I] (D) (e)) (MQwi[r2] (D) (e)) 
(2c) MQ(wl+w2) [Xx c w I.  r] (D) (e) 

=  Xac  B[Wl](D).  M[QiXlWl]W2[r](~)[elxla ] 
(2d) M  = Q(Wl i~2) [r [w2 ] ] (~) (e)  (MQ(~t.Wl) [r ] (D) (e)) (B [w2 ](~)) 

(2e) MQ(At.w)[At.  r](D)(e)  =  XD  ~.  MQw[r][DItlD](e) 

416 
Representations 

Before  we  can  formulate  the  representation  theorem,  we  must  specify  what 
we  mean  by  representation. 

For  D,  D'  e 4/), the  set  of  representations  between  D  and  D',  written 
rep(D,  D'),  is  the  set  of  continuous  function  pairs 

rep(D,  D')  =  {  <~,  9>  I @  ~ D  /  D',  4  ~ D'  /  D,  4"~  ~  I D,  @'4  ~  I D,  } 
where  I D  denotes  the  identity  function  on  D.  For  x  E D,  x'  # D',  and 

p  =  <~,  4>  e  rep(D,  D'),  we  write 

p:  X ~  X ~ 
and  say  that  x  represents  x'  according  to  p  if  and  only  if 

x  ~  ~( x' )  
or  equivalently, 

c(x) ~  x' 

A  pragmatic  justification  of  this  rather  ad  hoc  definition  is  that  it  will 
ultimately  make  the  representation  theorem  correct.  (Although  this  would  still 
be  true  if  we  took  rep(D,  D')  to  be  the  set  of  projection  pairs  between  D  and  D', 

i.e.,  if  we  replaced  the  requirement  ~.~  ~I D  by  4"~  =  I D  .)  However,  some 
intuition  is  provided  by  the  following  connection  with  the  notion  of  representation 
between  sets.  Conventionally,  we  might  say  that  a  representation  between  a  set  S 

and  a  set  S'  is  simply  a  function  ~  e  S ~-2S ',  and  that  x  e  S  represents  x'  e  S' 
according  to  ~  iff  ~(x)  =  x'.  But  if  we  take  D  and  D'  to  be  the  powerset  domains 
2 S  and  2 S'  (with  ~as~),  and  ~  and  ~  to  be  the  pointwise  extensions  of  ~  and 
its  converse  (as  a  relation),  then  p  =  <~,4>  is  a  representation  between  D  and  D', 
and  p:  sJ+  s'  iff  every  x  ~  s  conventionally  represents  some  x'  e  s'  according 

to  ~. 

The  following  is  an  obvious  and  useful  extension  of  our  definition. 
For  D,  D'  g j~T,  we  define 

rap(D,  D')=  ~  rep(D(t),  D'(t))  . 

teT 

417 
The  Representation  Theorem 

At  this  point,  we  can  formulate  a preliminary  version  of  the  representation 
theorem.  Consider  the  set  of  normal  expressions  RQw,and  suppose  that  D,  D'  E  ~T 
and ~  ~  rep(D,  D'),  so  that  for  each  type  variable  t,  p(t)  is  a  representation 
between  the  domains  D(t)  and D'(t) o  Moreover,  suppose  that  e  and  e'  are 

environments  such  that,for  each  normalvariable  x,  e(x)  represents  e'(x) 

according  to  the  relevant  representation,  i.e.,  ~(Q(x)).  Then  we  expect  that 

the  value  of  any  r  s RQw when  evaluated  with  respect  to D  and  e  should 
represent  the  value  of  the  same  normal  expression  when  evaluated  with  respect  to 
D'  and  e',  according  to  the  relevant  representation,  i.e.,  ~(w). 

More  formally: 

Let  Q  ~ V ---'FW, w  ~ W,  D,  D'  eJO~ 7  E  rep(D,  D'),  e  ~ ENVQ  (D), 
and  e'  ~ EnVQ  (D').  If 

(Vx  ~ V)  7(Q(x)):  e(x)  ~+ e'(x) 
then 

(~r  c RQw)  7(w):  MQw[r] (D) (e) ~  MQw[r](D')(e') 

However,  this  formulation  has  a  serious  flaw.  In  choosing  ~,  we  assign 
a  representation  to  every  type  variable,  but  not  to  every  type  expression~ 

so  that  the  representations  ~(Q(x))  and ~(w)  are  not  fully  defined.  Moreover, 
we  can  hardly  expect  to  assign  an  arbitary  representation  to  every  type  expression. 

For  example,  once  we  have  chosen  a representation  for  integer  and  a  representation 

for  real,  we  would  expect  that  this  choice  would  determine  a  representation  for 
integer  +  real  and  for  any  other  type  expression  constructed  from  integer  and  real. 

In brief,  we  have  underestimated  the meaning  of  type  expressions.  Not  only 
must  B[w]  map  an  assignment  of  domains  to  type  variables  into  a domain,  but  it must 

also  map  an  assignment  of  representations  into  a  representation.  If we  can  extend 

the  meaning  of  B  to  do  so,  then  a  correct  formulation  of  the  representation 

theorem  is: 

Let  Q  ~ V ~W,  w  ~ W,  D,  D'  E~)T, 7  ~ rep(D,  D'),  e  E EnvQ  (D), 
and  e'  s EnVQ  (D').  If 

(~x  e V)  B[Q(x)](~):  e(x) ~+ e'(x) 
then 

(Vr  ~ RQw ) B[w](p):  MQw[r] (D) (e) ~+ MQw[r](D')(e') 

418 
The Full  Semantics  of  Type  Expressions 

In order  to  extend  the  semantic  function  B,  we  first  note  that  the 
combination  of  domains  and  representations  forms  a  category.  We write  C  to 
denote  the  category,  called  the  category of  types,  in which  the  set  of  objects 
is J~,  the  set  of morphisms  from D  to D'  is  rep(D,  D'),  composition  is  given  by 

<c', ~'> * <0,  4 > =  <c"0,  ~'~'> 
and  the  identity  for D  is 

~D  =  <ID'  ID> 
From  the  category  of  types,  we  can  form  two  further  categories  by  standard !13   c T 
constructions  of  category  theory  e write  to denote  the  category  in which 
the  set  of  objects  is~ T,  the  set  of morphisms  from ~  to D'  is rep(D,  D'), 

composition  is  given by 

(p "p) (t) = 7' (t)"7(0 
and  the  identity  for D  is  given by 

&g(t)  =4g(t ) 
We write  Funct(C,  C)  to denote  the  category  in which  the  objects  are  the 
functors  from C  to  C  and  the morphisms  from  8  to  O'  are  the natural  transformations 

from  8  to  8',  i.e.,  the  functions  n  s  ~  rep(e(D),8'(D))  such  that,  for  all D~ 

D,  D'  e J0and  p  s rep(D,  D'), 

8' (p)'N(D)  =  h(D') "@(p) 
Composition  is  given  by 

(~''o)(n)  =  n'(D)'N(D) 
and  the  identity  for  e is  given by 

~e (D)  = ~e(D) 

419 
We  have  seen  that  the  meaning  B[w]  of  a  type  expression  w  must  map  the 
objects  of  C T  into  the  objects  of  C  and  the  morphisms  of  C T  into  the  morphisms 
of  C.  Moreover,  if  our  formulation  of  the  representation  theorem  is  to be 
meaningful,  we  must  have 

7  e rep(D,  D')  implies  B[w](~)  e rep(B[w](D),  B[w](D')) 
Thus,  at  least  if we  can  satisfy  the  appropriate  laws,  we  expect  to  extend 
B[w]  from  a  function  from'~ T  to j~ into  a  functor  from  C T  to  C. 

Indeed,  by  pursuing  the  analogy  of  categories  with  sets  and  functors 
with  functions,  we  can  induce  the  main  structure  of  the  definition  of  B[w]. 

For  each  of  the  cases  in  the  syntactic  definition  of W: 

(la)  B[t](D)  = D(t) 

B [t] (7)  = ~(t) 

(ib)  B[w I /  w2](D)  =  arrow(B[Wl](D),  B[w2](D)) 

B[w I *  w 2](7)  =  arrow(B[w I](7),  B[w 2](7)) 
where  arrow  is  a bifunctor  from  C  x  C  into  C. 
(ic)  B[At.  w]  =  delta  * abstract 

where  abstract  is  the  functor  from  C T  into  Funct(C,  C)  such  that 

abstract(D)(D)  =  B[w][~I~ID ] 

abstract(D)(p)  =  B[w][~Itlp  ] 
abstract(7)(D)  =  B[w][71t]#D] 
and  delta  is  a  functor  from  Funct(C,  C)  into  C. 
Even  before  defining  the  functors  arrow  and  delta,  it  can  be  shown  that 
B  maps  every  type  expression  into  a  functor  from  C T  into  C,  that  w  = w'  implies 
B[w]  =  B[w'],  and  that 

B[WlI: 2](~)  =  B[Wl][  D  I t  I B[w2](D)  ] 
B[WlI~2](7)  =  B[Wl][  ~  I t  I B[w2](~)  ] 

420 
The Functors  arrow  and  delta 

The definition  of  the  functor  arrow  is  fairly  obvious.  Essentially, 
its  action  on representations  is  to produce  the  only  reasonable  composition 
which matches  domains  correctly.  For  all DI,  D  2 el9, 

arrow(D I,  D  2)  =  D  I  /  D  2 
For  all  <~i'  41>  s rep(Dl'  Di)  and  <~2'  42>  E rep(D2,  D~), 

arrow(<~l,41 >,  <~2,42 >)  = 

<  ~f  E DI/D 2.  ~2"f'41,  ~f  e  D  1  D  2. 42"f'~i  > 
(The action  of  arrow  on representations  is  similar  to  the method  used by 
Scott  to  construct  retraction  or projection  pairs  for  function  spaces.) 

The  definition  of  arrow  and  the properties  of  representations  give 
the  following  lepta: 

,  '  / D~  Pl  ~ rep(Dl  Di)'  and  P2  E rep(D 2,  D~). Let  f  ~  D  1  +  D  2 f'  g  D  1 
Then 

arrow(p I,  P2 ):  f,/ f' 

if and  only  if,  for  all x  ~  D  1 and  x'  s D i, 

PI:  x'/ x'  implies  P2:  f(x),/  f'(x')  . 

which,  with  the definition  of B~gives  the  following  lemma: 

Let Wl,  w  2  s W, ~  e rep(D,  D'),  f  e B[w I  / w2](D) , and  f'  s B[w I  + w2](D'). 
Then 

B[w I  + w2](~):  f,/ f' 

if  and  only  if,  for  all x  ~ B[Wl](D)  and x'  e B[Wl](D'), 

B[Wl](~):  xJ+ x'  implies  B[w2](~):  f(x)i+  f'(x') 

(As  an aside,  we  note  that  the  definition  of  arrow  establishes  a  connection 
between  our notion  of  representation  and  the  concept  of simulation~14~ypically, 

one  says  that  a  function  ~  s  S =7S'  is  a  simulation  of  a  relation  r  ~  S  *  S by  a 
relation  r'E  S'  x  S' iff  ~'r C__r'.~  (where  * denotes  relational  composition). 
But  if  f,  f',  ~,  and  4  are  the pointwise  extensions  of r,  r',  ~,  and  the  converse 

of  ~,  then  ~.r ~  r'.~  iff  arrow(p,  p):  fl~  f', where  p  = <@,  4>.) 

421 
The  definition  of  the  functor  delta  is  less  obvious.  For  all  functors 
e  from C  to  C,  delta(8)  is  the  complete  lattice with  elements 

{  f  I  f  s  H 8(D)  and  (VD,  D'  c~)(Vp  s rep(D,D'))8(p):  f(D) ~  f(D') Ds~ 

with  the partial  ordering  f  ~  g iff  (~D  s~0)  f(D) ~e(D)  g(D).  For  all natural 

transformations  q  from  e  to  e', 

delta(n)  = 

<  %f  e delta(e).  %D  sD.  [q(D)]i(f(D)) , 

kf  e delta(e').  %D  g~.  [~(D)]2(f(D))  > 

At  this  point,  we must  admit  a  serious  lacuna  in  our  chain  of  argument. 
Although  delta(e)  is  a  complete  lattice  (with  (-~F)(D)  = US(D)  {f(D)  I  f  s  F  } ), 

it  is not  known  to be  a  domain,  i.e.,  the question  of whether  it  is  continuous 

and  countably  based  has  not  been  resolved.  Nevertheless  there  is  reasonable 
hope  of  evading  the  set-theoretic  paradoxes.  Even  though  n  e(D)  is  immense 

DcJ~ 

(since JO  is  a  class),  the stringent  restrictions  on membership  in delta(e) 
seem  to make  its  size  tractable.  For  example,  if  f  s delta(0),  then  the value 
of  f(D)  determines  its value  for  any  domain  isomorphic  to D. 

The  definition  of delta  and  the properties  of  representations  give 
the  lemma: 

Let  q be  a natural  transformation  from  8 to  e',  f  s delta(e)  and 

f'  g delta(e').  Then 

delta(q):  f~+ f' 

if  and  only  if,  for  all D,  D'  s J0, and  p  E rep(D,  D'), 

n(D')'e(p):  f(D) ,+ f'(D') 
which,  with  the  definition  of B,  gives: 

Let  t  ~ T, w  ~ W, ~  e rep(D,  D'),  f  E B[At.  w](D),  and  f'  c B[At.  w](D'). 
Then 

B[At.  w](~):  f~+  f' 

if  and  only  if,  for  all  D,  Des  J9,  and  p  e rep(D,  D'), 

B[w][~Itlp]:  f(D),/  f'(D') 
From  the  final  lemmas  obtained  about  arrow  and  delta,  the  representation 
theorem  can be proved  by  structural  induction  on r. 

422 
Some  Syntactic  Manipulations 

We  have  explore d  our  illustrative  language  semantically  rather  than 
syntactically,  i.e.,  we  have  provided  it  with  a  mathematical  meaning  instead 
of  investigating  the  syntactic  consequences  of  reducibility.  However,  an 
obvious  question  is  raised  by  the  fact  that  every  expression  in  the  typed 
lambda  calculus,  but  not  the  untyped  lambda  calculus,  has  a  normal  form. (8) 

We  have  been  unable  to  resolve  this  question  for  our  language. 
Nevertheless,  the  language  permits  some  interesting  constructions  which  are 

not  possible  in  the  typed  lambda  calculus. 

For  example,  consider  the  following  normal  expressions: 

O  n  ~ At.  If  ~  t  / t.  lx  ~  t. ~----~f( ...  f(x)  ...  ) 

n  times of  type  ~  ~ At.  (t  /  t)  + (t  +  t), 

e  5 %h  s  ~. At.  %f  e  t  /  t. lx  s  t.  f(h[t]  f  x) 
of  type  ~  /  ~ (We  assume  application  is  left-associative.), 

~  lg  s  ~  / ~.  Xh  ~  ~. g(h[~]  g  pl ) 
of  type  (~ /  ~)  ~ (~  /  ~),  and 

of  type  ~  / (w +  w).  Then  the  following  expressions  are  intereonvertible: 

8  Pn  =  Pn+l 

B  Pm+l  =  ~ (B  Pm ) 
B  PO  Pn  =  Pn+l 

Pm+l  PO  =  B Pm Pl 
B  Pm+l  Pn+l  ~  B Pm  (B  Pm+l  Pn ) 

From  the  last  three  equations  it  follows  that  B  Pm  Pn  =  P~(n,m)'  where  ~(n,m) 

is  Ackermann's  function. 

423 
Further  Remarks 

Since  the  writing  of  the  preliminary  version  of  this  paper,  considerable 
attention  has  been  given  to  the  "serious  lacuna"  mentioned  above.  We  have 
managed  to  show  that  delta(e)  is  a  continuous  lattice,  but  not  that  it  is 

countably  based.  Conceivably,  our  notion  of  representation  is  too  restrictive, 
which  would  tend  to  make  delta(8)  unnecessarily  large. 

ACKNOWLEDGEMENT 
The  author  would  like  to  thank  Dr.  Lockwood  Morris  for  numerous  helpful 
suggestions  and  considerable  encouragement. 

424 
REFERENCES 

i.  Van  Wijngaarden,  A.,  Mailloux,  B.  J.,  Peck,  J.  E.  L.,  and Koster,  C.  H. A.,  Report  on  the  Al@orithmic  Language 

ALGOL  68.  MR  i01  Mathematisch  Centrum,  Amsterdam, October  1969.  Also  Numerische  Mathematik  14  (1969)  79-218. 

2.  Cheatham,  T.  E.,  Jr*,  Fischer,  A.,  and  Jorrand,  P.,  On the Basis  for  ELF-An  Extensible  Language  Facility.  Proc.  AFIPS 

1968  Fall  Joint  Comput.  Conf.,  Vol.  33  Pt.  2,  MDI  Publications, 
Wayne,  Pa.,  pp.  937-948. 

3.  Reynolds,  J.  C.,  A  Set-theoretic  Approach  to  the  Concept of  Type.  Working  paper,  NATO  Conf.  on  Techniques  in 

Software  Engineering,  Rome,  October  1969. 
4.  Morris,  J.  H.,  "Protection  in  Programming  Languages," 

Comm.  ACM,  16  (i), January  1973. 

5.  Morris,  J.  H.,  Types  are  not  Sets.  Proc.  ACM  Symposium  on 

Principle  of  Programming  Languages,  Boston  1973,  pp.  120-124. 

6.  Fischer,  A.  E.,  and  Fischer,  ~.  J.,  Mode  Modules  as Representations  of  Domains.  Proc.  ACM  Symposium  on  Principles 

of  Programming  Languages,  Boston  1973,  pp.  139-143. 
7.  Liskov,  B.,  and  Zilles,  S.,  An  Approach  to  Abstraction. Computation  Structures  Group  Memo  88,  Project  MAC,  MIT, 

September  1973. 
8.  Morris,  J.  H.,  Lambda-calculus  Models  of  Programming 

Languages.  MAC-TR-57,  Project  MAC,  MIT,  Cambridge, 
Mass.,  December  1968. 

9.  Scott,  D.,  "Outline  of  a Mathematical  Theory  of  Computation," Proc.  Fourth  Annual  Princeton  Conf.  on  Information  Sciences 

and  Systems ' (1970),  pp.  169-176.  Also,  Tech.  Monograph PRG-2,  Programming  Research  Group,  Oxford  University  Computing 
Laboratory,  November  1970. 
i0.  *  "Continuous  Lattices,"  Proc.  1971  Dalhousie  Conf., Springer  Lecture  Note  Series,  Springer-Verlag,  Heidelberg. 

Also,  Tech.  Monograph  PRG-7,  Programming  Research  Group, Oxford  University  Computing  Laboratory,  August  1971. 

ii.  *  "Mathematical  Concepts  in  Programming  Language Semantics,"  AFIPS  Conference  Proc.,  Vol.  40,  AFIPS  Press, 

Montvale,  New  Jersey  (1972),  pp.  225-234. 
12.  "Data  Types  as  Lattices",  Notes,  Amsterdam, 

June  i972. 

13.  MacLane,  S.,  Categories  for  the  Working  Mathematician, Springer-Verlag,  New  York  1971. 

425 
14.  Morris,  F.  L.,  Correctness  of  Translations  of  Programming Languages  --  An  Algebraic  Approach,  Stanford  Computer 

Science  Department  Report  STAN-CS-72-303,  August  1972. 