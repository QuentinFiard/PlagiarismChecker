

Type Inference for First-Class Messageswith Feature Constraints

Martin M"uller1 and Susumu Nishimura2
1 Universit"at des Saarlandes, 66041 Saarbr"ucken, Germany

mmueller@ps.uni-sb.de2
RIMS, Kyoto University, Sakyo-ku, Kyoto 606-8502, Japan

nisimura@kurims.kyoto-u.ac.jp

Abstract. We present a constraint system OF of feature trees that is appropriate to specify and implement type inference for first-class messages. OF extends
traditional systems of feature constraints by a selection constraint xhyiz "by firstclass feature tree" y, in contrast to the standard selection constraint x[ f ]y "by fixed
feature" f . We investigate the satisfiability problem of OF and show that it can
be solved in polynomial time, and even in quadratic time in an important special
case. We compare OF with Treinen's constraint system EF of feature constraints
with first-class features, which has an NP-complete satisfiability problem. This
comparison yields that the satisfiability problem for OF with negation is NP-hard.
Based on OF we give a simple account of type inference for first-class messages
in the spirit of Nishimura's recent proposal, and we show that it has polynomial
time complexity: We also highlight an immediate extension that is desirable but
makes type inference NP-hard.Keywords:

object-oriented programming; first-class messages; constraint-based
type inference; complexity; feature constraints

1 Introduction
First-class messages add extra expressiveness to object-oriented programming. First-class messages are analogous to first-class functions in functional programming languages; a message refers to the computation triggered by the corresponding methodcall, while a functional argument represents the computation executed on application.
For example, a map method can be defined by means of first-class messages as follows

method map(o,l) = for each message m in l: o  m
where o is an object, l is a list of first-class messages, and om sends message m to o.First-class messages are more common and crucial in distributed object-oriented

programming. A typical use of first-class messages is the delegation of messages toother objects for execution. Such delegate objects are ubiquitous in distributed systems:
for example, proxy servers enable access to external services (e. g., ftp) beyond a fire-wall. The following delegate object defines simple proxy server:

let ProxyServer = f new(o) = f send(m) = o  mg g;
cfl Springer-Verlag, to appear in Proc. of Asian Computing Science Conferences (ASIAN98)

This creates an object ProxyServer with a method new that receives an object o. Themethod returns a second object that, on receipt of a message labeled

send and carryinga message
m, forwards m to o. To create a proxy to an FTP server, we can execute

let FtpProxy = ProxyServer  new(ftp);
where ftp refers to an FTP object. A typical use of this new proxy is the following one:

FtpProxy  send(get('paper.ps.gz'))
Delegation cannot be easily expressed without first-class messages, since the requestedmessages are not known statically and must be abstracted over by a variable

m.In a programming language with records, abstraction over messages corresponds

to abstraction over field names: For example, one might want to use a function
let fn x = y.x; to select the field x from record y. Neither first-class messages norfirst-class record fields can be type checked in languages from the ML family such

as SML [14] or the objective ML dialect O'Caml [24].Recently, the second author has proposed an extension to the ML type system that
can deal with first-class messages [18]. He defines a type inference procedure in termsof kinded unification [20] and proves it correct. This procedure is, however, formally
involved and not easily understandable or suitable for further analysis.In this paper, we give a constraint-based formulation of type inference for firstclass messages in the spirit of [18] that considerably simplifies the original formulation,and we settle its complexity. For this purpose, we define a new constraint system over
feature trees [3] that we call OF (objects and features). This constraint system extendsknown systems of feature constraints [4, 5, 27, 30] by a new tailor-made constraint: this
new constraint is motivated by the type inference of a message sending statement o 
m, and pinpoints the key design idea underlying Nishimura's system.We investigate the (incremental) satisfiability problem for OF and show that it can

be solved in polynomial time, and in time O(n2) for an important special case. We alsoshow that the satisfiability problem for positive and negative OF constraints is NP-hard,
by comparing OF with Treinen's feature constraint system EF [30].Based on OF, we define monomorphic type inference for first-class messages. Our
formulation considerably simplifies the original one based on kinded unification. A keydifference between both is that we strictly separate the types (semantics) from the type
descriptions (syntax), whereas the original system confused syntax and semantics byallowing variables in the types themselves.

From our complexity analysis of OF we obtain that monomorphic type infer-ence for first-class messages can be done in polynomial time. Incrementality is important for modular program analysis without loss of efficiency in comparison toglobal program analysis. Our constraint-based setup of type inference allows us to
explain ML-style polymorphic type inference [10, 13] as an instance HM(OF) of theHM(X) scheme [29]: Given a monomorphic type system based on constraint system X,
the authors give a generic construction of HM(X), i. e., type inference for ML-stylepolymorphic constrained types. Type inference for the polymorphic system remains
DEXPTIME-complete, of course [11].In the remainder of the introduction we summarize the main idea of the type system
for first-class messages and of the constraint system OF.

1.1 The Type System
The type system contains types for objects and messages and explains what type ofmessages can be sent to a given object type. An object type is a labeled collection of

method types (i. e., a product of function types distinguished by labels) marked by obj.
E. g., the object

let o = f pos(x) = x?0, neg(p) = : pg
implements two methods pos and neg that behave like functions from integerand boolean to boolean, respectively. Hence, it has an object type

obj(pos:int !
bool;neg:bool ! bool).1 When a message f (M) is sent to an object, the correspondingmethod is selected according to the message label

f and then applied to the messageargument
M. Since a message parameter may refer to a variety of specific messages atrun-time, it has a message type marked by

msg that collects the corresponding types (asa sum of types distinguished by labels). For example, the expression

m = if b then pos(42) else neg(true);
defines, depending on b, a message m of message type msg(pos:int;neg:bool). Theexpression

o  m is well-typed since two conditions hold:

1. For both labels that are possible for m, pos and neg, the object o implements amethod that accepts the corresponding message arguments of type

int or bool.2. Both methods
pos and neg have the same return type, here bool. Thus the type of
o  m is unique even though the message type is underspecified.

These are the crucial intuitions underlying Nishimura's type system [18]. Our typeinferences captures these intuitions fully. Formally, however, our type inference implements a type system that does not exactly match the original one: Ours is slightlyweaker and hence accepts more programs than Nishimura's. This weakness is crucial
in order to achieve polynomial time complexity of type inference. However, type infer-ence for a stronger system that fills this gap would require both positive and negative
OF constraints and thus make type inference NP-hard.

1.2 Constraint-based Type Inference
It is well-known that many type inference problems have a natural and simple formu-lation as the satisfiability problem of an appropriate constraint system (e. g. [21, 32]).

Constraints were also instrumental in generalizing the ML-type system towards recordpolymorphism [20, 23, 33], overloading [6, 19] and subtyping [1, 8] (see also [29]).

Along this line, we adopt feature trees [3] as the semantic domain of theconstraint system underlying our type system. A feature tree is a possibly infinite tree with unordered marked edges (called features) and with marked nodes(called

labels), where the features at the same node must be pairwise different.

1 Notice that the colons in the type obj(pos:int ! bool;neg:bool ! bool) do not separate items

from the annotation of their types, but rather the field names from the associated type components. This notation is common in the literature on feature trees and record typing.

1998asian

yearconf
paper

@@

@
\Gamma \Gamma 
\Gamma 

For example, the picture on the right shows a feature treewith two features

conf and year that is labeled with paperat the root and
asian resp. 1998 at the leaves.Feature trees can naturally model objects, records,

and messages as compound data types with labeled com-ponents. A base type like

int is a feature tree with label
int and no features. A message type msg( f1:t1; ::: ; fn:tn) is a feature tree with label
msg, features f f1; :: : ; fng, and corresponding subtrees ft1;: :: ;tng, and an object type
obj( f1:t1 ! t01;: :: ; fn:tn ! t0n) is a feature tree with label obj, features f f1;: :: ; fng,and corresponding subtrees t

1 ! t01 through tn ! t0n; the arrow notation t ! t0 in turnis a notational convention for a feature tree with label

! and subtrees t;t0 at fixed anddistinct features d and r, the names of which should remind of "domain" and "range".

Feature trees are the interpretation domain for a class of constraint languages calledfeature constraints [4, 5, 16, 27, 30]. These are a class of feature description logics, and,
as such, have a long tradition in knowledge representation and in computational lin-guistics and

constraint-based grammars [22, 25]. More recently, they have been used tomodel record structures in constraint programming languages [2, 26, 27].

The constraint language of our system OF is this one:

j ::= j ^ j0 j x = y j a(x) j x[ f ]y j F(x) j xhyiz
The first three constraints are the usual ones: The symbol = denotes equality on featuretrees,

a(x) holds if x denotes a feature tree that is labeled with a at the root, and x[ f ]yholds if the subtree of (the denotation of) x at feature f is defined and equal to y. For

a set of features F, the constraint F(x) holds if x has at most the features in F at theroot; in contrast, the arity constraint of CFT [27] forces

x to have exactly the features inF. The constraint x
hyiz is new. It holds for three feature trees tx, ty, and tz if (i) tx hasmore features at the root than t

y, and if (ii) for all root features f at ty, the subtree of txat f equals t
y: f ! tz (where ty: f is the subtree of ty at f ).It is not difficult to see that x

hyiz is tailored to type inference of message sending.For example the

ProxyServer above gets the following polymorphic constrained type:

8abg :obj(a) ^ msg(b) ^ ahbig ) fnew:a ! fsend:b ! ggg
Using notation from [29], this describes an object that accepts a message labeled newwith argument type a, returning an object that accepts a message labeled

send withargument type b and has return type g; the type expresses the additional constraint that

a be an object type, b be a message type appropriate for a, and the correspondingmethod type in a has return type g.

Plan. Section 2 defines the constraint system OF, considers the complexity of its sat-isfiability problem, and compares OF with the feature constraint systems from the literature. Section 3 applies OF to recast the type inference for first-class messages andcompares it with the original system [18]. Section 4 concludes the paper.

Some of the proofs in this paper are only sketched for lack of space. The completeproofs are found in an appendix of the full paper [17].

2 The Constraint System OF
2.1 Syntax and Semantics
The constraint system OF is defined as a class of constraints along with their interpre-tation over feature trees. We assume two infinite sets V of variables x

; y; z;: ::, and Fof
features f ; :::, where F contains at least d and r, and a set L of labels a;b; :: : thatcontains at least

!: The meaning of constraints depends on this label. We write x for asequence x

1; ::: ;xn of variables whose length n does not matter, and x:y for a sequenceof pairs x
1:y1; :: : ; xn:yn. We use similar notation for other syntactic categories.

Feature Trees. A path p is a word over features. The empty path is denoted by e andthe free-monoid concatenation of paths p and p

0 as pp0; we have ep = pe = p. Given

paths p and p0, p0 is called a prefix of p if p = p0p00 for some path p00. A tree domain isa non-empty prefix closed set of paths. A feature tree t is a pair

(D; L) consisting of atree domain
D and a labeling function L : D ! L. Given a feature tree t, we write Dtfor its tree domain and

Lt for its labeling function. The arity ar(t) of a feature tree t isdefined by
ar(t) = Dt " F . If p 2 Dt, we write as t:p the subtree of t at path p: formally
Dt:p = fp0 j pp0 2 Dtg and Lt:p = f(p0;a) j (pp0; a) 2 Ltg. A feature tree is finite ifits tree domain is finite, and

infinite otherwise. The cardinality of a set S is denotedby #S. Given feature trees t

1; ::: ;tn, distinct features f1;: :: ; fn, and a label a, we writeas a
( f1:t1;: :: ; fn:tn) the feature tree whose domain is Sni=1f fip j p 2 Dtig and whoselabeling is

f(e;a)g [ Sni=1f( fip;b) j (p;b) 2 Ltig. We use t1 ! t2 to denote the featuretree t with

Lt = (e;!), ar(t) = fd;rg, t:d = t1, and t:r = t2.

Syntax. An OF constraint j is defined as a conjunction of the following primitiveconstraints:

x = y (Equality)a

(x) (Labeling)
x[ f ]y (Selection)F

(x) (Arity Bound)
xhyiz (Object Selection)

Conjunction is denoted by ^. We write j0 ` j if all primitive constraints in j0 are alsocontained in j, and we write

x = y 2 j [etc.] if x = y is a primitive constraint in j [etc.].We denote with F
(j), L(j), and V (j) the set of features, labels, and variables occurringin a constraint j. The

size S(j) of a constraint j is the number of variable, feature, andlabel symbols in j.

Semantics. We interpret OF constraints in the structure F T of feature trees. The sig-nature of F T contains the symbol

=, the ternary relation symbol \Delta h\Delta i\Delta , for every a 2 La unary relation symbol
a(\Delta ), and for every f 2 F a binary relation symbol \Delta [ f ]\Delta . Weinterpret
= as equality on feature trees and the other relation symbols as follows.

a(t) if (e; a) 2 Ltt

[ f ]t0 if t: f = t0F

(t) if ar(t) ` Ft
ht0it00 if 8 f 2 ar(t0) : f 2 ar(t) and t: f = t0: f ! t00

Let \Phi  and \Phi 0 be first-order formulas built from OF constraints with the usual first-order connectives

., ^, :, !, etc., and quantifiers. We call \Phi  satisfiable (valid) if \Phi is satisfiable (valid) in F T . We say that \Phi 

entails \Phi 0, written \Phi  j=OF \Phi 0, if \Phi  ! \Phi 0 isvalid, and that \Phi  is equivalent to \Phi 
0 if \Phi  $ \Phi 0 is valid.

A key difference between the selection constraints x[ f ]y and xhyiz is that "selectionby (fixed) feature" is functional, while "selection by (first-class) feature tree" is not:

x[ f ]y ^ x[ f ]y0 ! y = y0 (1)
xhyiz ^ xhyiz0 6! z = z0 (2)

The reason for the second equation not to hold is that y may have no subtrees: In thiscase, the constraint

xhyiz does not constrain z at all. I. e., this implication holds:

fg(y) ! 8z xhyiz (3)
If, however, y is known to have at least one feature at the root, then selecting both z and
z0 by y from x implies equality of z and z0:

y[ f ]y0 ^ xhyiz ^ xhyiz0 ! z = z0 (4)
OF cannot express that y has a non-empty arity; rather, to express that y has somefeature it must provide a concrete witness. Using negation, this can be expressed as

:fg(x). However, while satisfiability for OF is polynomial, it becomes NP-hard if it isextended such that

:fg(x) can be expressed (see Section 2.3).

Feature Terms. For convenience, we will occasionally use feature terms [3] as ageneralization of first-order terms: Feature terms t are built from variables by feature tree construction like a( f1:t1; ::: ; fn:tn), where again the features f1; :: : fn are re-quired to be pairwise distinct. Equations between feature terms can be straightforwardly
expressed as a conjunction of OF constraints x = y, a(x), F(x), x[ f ]y, and existen-tial quantification. For example, the equation

x = a( f :b) corresponds to the formula
9y (a(x) ^ f f g(x) ^ x[ f ]y ^ b(y) ^ fg(y)). In analogy to the notation t1 ! t2, we use theabbreviation x

= y ! z for the equation x = !(d:y;r:z).

2.2 Constraint Solving
Theorem 1. The satisfiability problem of OF constraints is decidable in incremental
polynomial space and time.

For the proof, we define constraint simplification as a rewriting system on constraints inFigure 1. The theorem follows from Propositions 1, 2 and 3 below. Rules (Substitution),

(Selection), (Label Clash), and (Arity Clash) are standard. Rules (Arity PropagationI/II) reflect the fact that a constraint

xhyiz implies the arity bound on x to subsume theone on y. (Arity Intersection) normalizes a constraint to contain at most one arity bound

per variable. (Object Selection I) reflects that xhyiz implies all features necessary for yto be also necessary for

x, and (Object Selection II) establishes the relation of x, y, and zat a joint feature f .

j ^ x = y
j[y=x] ^ x = y if x

2 f v(j) (Substitution)

j ^ x[ f ]y ^ x[ f ]z
j ^ x[ f ]z ^ y = z (Selection)

j ^ xhyiz ^ F(x)
j ^ xhyiz ^ F(x) ^ F(y) if not exists F

0 : F0(y) 2 j (Arity Propagation I)

j ^ xhyiz ^ F(x) ^ F0(y)
j ^ xhyiz ^ F(x) ^ F " F0(y) if F

" F0 6= F0 (Arity Propagation II)

j ^ F(x) ^ F0(x)

j ^ F " F0(x) (Arity Intersection)

j
j ^ x[ f ]x0 if x

hyiz ^ y[ f ]y0 2 j and
not exists z : x[ f ]z 2 j; x0 fresh

(Object Selection I)

j
j ^ x0 = y0 ! z if x

hyiz ^ y[ f ]y0 ^ x[ f ]x0 2 j and
x0 = y0 ! z 62 j

(Object Selection II)

j ^ a(x) ^ b(x)

fail if a

6= b (Label Clash)

j ^ F(x) ^ x[ f ]x0

fail if f

62 F (Arity Clash)

Fig. 1. Constraint Solving Rules
Notice that the number of fresh variables introduced in rule (Object Selection I) isbounded: This rule adds at most one fresh variable per constraint x

hyiz and feature fand the number of both is constant during constraint simplification. For the subsequent

analysis, it is convenient to think of the fresh variables as fixed in advance. Hence, wedefine the finite set : V

0(j) =def V (j) [ fvx

; f 2 V j x 2 V (j); f 2 F(j);vx; f freshg.

Remark 1. In addition to the rules in Figure 1, there are two additional rules justifiedby implications (3) and (4):

j ^ xhyiz

j if

fg(y) 2 j (Empty Message)

j ^ xhyiz ^ xhyiz0

j ^ xhyiz ^ z = z0 if y

[ f ]y0 2 j (Non-empty Message)

The first one is just a simplification rule that does not have an impact on the satisfiabilitycheck. It helps reducing the size of a solved constraint and therefore saves space and
time. Secondly, compact presentation of a solved constraint can be crucial in the typeinference application where solved constraints must be understood by programmers.
The second one is a derived rule that should be given priority over rule (Object SelectionII).

Proposition 1. The rewrite system in Figure 1 terminates on all OF constraints j.
Proof. Let j be an arbitrary constraint. Obviously, F(j) is a finite set and the numberof occurring features is fixed since no rule adds new feature symbols. Secondly, recall

that the number of fresh variables introduced in rule (Object Selection I) is bounded.Call a variable

x eliminated in a constraint x = y ^ j if x 62 V (j). We use the constraintmeasure
(O1; O2;A; E; S) defined by

(O1) number of sextuples (x;y;z;x0;y0; f ) of non-eliminated variables x; y; z;x0; y0 2

V 0(j) and features f 2 F(j) such that xhyiz^x[ f ]x0 ^y[ f ]y0 2 j but x0 = y0 ! z 62 j.(O
2) number of tuples (x; f ) of non-eliminated variables x 2 V 0(j) and features f 2F

(j) such that there exists y;y0 and z with xhyiz ^ y[ f ]y0 2 j but x[ f ]x0 62 j forany

x0.(A) number of non-eliminated variables x

2 V 0(j) for which no arity bound F(x) 2 jexists.

(E) number of non-eliminated variables.(S) size of constraint as defined above.

The measure of j is bounded and strictly decreased by every rule application as thefollowing table shows. this proves our claim.

O1 O2 A E S
(Arity Propagation II) = = = = !(Arity Intersection)

= = = = !(Selection)
= = = = !(Substitution)
^ ^ ^ ! =(Arity Propagation I)
= = ! = ?(Object Selection I)
= ! ? ? ?(Object Selection II)
! = = = ? 2

Proposition 2. We can implement the rewrite system in Figure 1 such that it uses spaceO

(n3) and incremental time O(n5), or, if the number of features is bounded, such that it
uses linear space and incremental time O(n2).

Proof. We implement the constraint solver as a rewriting on pairs (P;S) where S isthe store that flags failure or represents a satisfiable constraint in a solved form, and

where P is the pool (multiset) of primitive constraints that still must be added to S. Todecide satisfiability of j we start the rewriting on the pool of primitive constraints in j
and the empty store and check the failure flag on termination.For lack of space, we defer some involved parts of the proof to the full paper [17].

Define ni = #V (j), nv = ni \Delta  n f = #V 0(j), nl = #L(j), n f = #F(j). In the full paper,we define a data structure for the store that consists of a union-find data structure [12] for

equations, tables for the constraints a(x), F(x), and x[ f ]z, a list for constraints xhyiz, andtwo adjacency list representations of the graphs whose nodes are the initial variables,
and whose edges (x;y) are given by the constraints xhyiz for the first one and yhxiz forthe second one. (See appendix of the full paper [17] for details). This data structure has
size O

(ni \Delta  n f + ni + nv \Delta  n f + ni \Delta  n f + n) = O(nv \Delta  n f + n)

which is O(n) if the number of features is assumed constant and O(n3) otherwise. Italso allows to check in time

O(1) whether it contains a given primitive constraint; andto add it in quasi-constant time.2 This is clear in the non-incremental (off-line) case

where nv, ni, n f ,and ns are fixed. In the incremental (on-line) case, where nv, ni, n f ,and

ns may grow, we can use dynamically extensible hash tables [7] to retain constanttime check and update for primitive constraints.

Each step of the algorithm removes a primitive constraint from the pool P, adds itto the store

S, and then derives all its immediate consequences under the simplificationrules: Amongst them, equations x

= y and selections x[ f ]y are put back into the pool,while selections
xhyiz and arity bounds F(x) are directly added to the store.We show that every step can be implemented such that it costs time O

(n + ni \Delta  n f ).3(The complete analysis of this time bound can be found in appendix of the full paper [17]). We also show that every step may at most add O(n) equations and O(nv) se-lection constraints of the form x

[ f ]y. It remains to estimate the number of steps: Thereare at least
O(n) steps needed for touching all primitive constraints in j.

- Amongst the new equations, there are at most O(nv) relevant ones, in the sense thatone can at most execute

nv equations before all variables are equated. That is, allbut O
(nv) equations cost constant time.- Amongst the new selection constraint, there are at most O

(nv \Delta  n f ) relevant onessince adding a selection constraint
x[ f ]y induces immediate work only if x has noselection constraint on
f yet. The others will generate a new equation and terminatethen. Hence, all but O
(nv \Delta  n f ) selection constraints cost constant time.

In summary, there are O(n + nv \Delta  n f ) steps that cost O(n + ni \Delta  n f ). Each of these stepsmay add

O(n) equations and O(nv) selections each of which may add a new equationitself. Hence we have O

((n + nv \Delta  n f ) \Delta  (n + nv)) steps that cost O(1). Overall, the algo-rithm has the complexity

O((n + nv \Delta  n f ) \Delta  (n + ni \Delta  n f ) + (n + nv \Delta  n f ) \Delta  (n + nv) \Delta  1) = O((n + nv \Delta  n f ) \Delta  (n + ni \Delta  n f ))
Since O(n f ) = O(n) and O(nv) = O(ni \Delta n f ) = O(n2), this bound is O(n5). If the numberof features is bounded,

O(nv) = O(ni) = O(n), so the bound is rather O(n2). 2

Notice that a constraint system of records with first-class record labels is obtainedas an obvious restriction of OF and the above result implies the same time complexity
bound as OF.

2 All constraints except equations can be added in time O(1), but addition of an equation costs

amortized time O(a(nv)) where a(nv) is the inverse of Ackermann's function. For all practical
purposes, a(nv) can be considered as constant.3
To be precise, each step costs O(n+ni \Delta n f +a(nv)) which we sloppily simplify to O(n+ni \Delta n f ).

Proposition 3. Every OF constraint j which is closed under the rules in Figure 1 (and
hence is different from fail) is satisfiable.

Proof. For the proof, we need to define a notion of path reachability similar to the oneused in earlier work, such as [15, 16]. For all paths p and constraints j, we define a

binary relation j;p, where x j;p y reads as "y is reachable from x over path p in j":

x j;e x for every x
x j;e y if y = x 2 j or x = y 2 j
x j; f y if x[ f ]y 2 j
x j;pp0 y if x j;p z and z j;p0 y:

Define relations x j;p a meaning that "label a can be reached from x over path p in j":

x j;p a if x j;p y and a(y) 2 j
Fix an arbitrary label unit. For every closed constraint j we define the mapping a fromvariables into feature trees defined as follows.

Da(x) = fp j exists y : x j;p yg
La(x) = f(p;a) j x j;p ag [ f(p;unit) j p 2 Da(x) but 6 9a : x j;p ag

It remains to be shown that a defines a mapping into feature trees for closed con-straints j, and that a indeed satisfies j. This can be done by a straightforward induction

over paths p. 2

2.3 Relation to Feature Constraint Systems
We compare OF with feature constraint systems in the literature: Given a two-sortedsignature with variables

x;y; z; ::: and u; v;w;: :: ranging over feature trees and features,
resp., collections of feature constraints from the following list have, amongst others,been considered [3, 27, 30]:

j ::= x = y j a(x) j x[ f ]y j Fx j u = f j x[u]y j j ^ j0
The constraints x = y, a(x), and x[ f ]y are the ones of OF. The arity bound Fx (where Fis a finite set of features) states that

x has exactly the features in F at the root.

Ft if ar(t) = F
Apparently, both arity constraints are interreducible by means of disjunctions:F

(x) $ WF0`F F0x. The constraints of FT [3] contain x = y, a(x), and x[ f ]y, CFT [27]extends FT by

Fx, and EF [30] contains the constraints x=y, a(x), x = f , Fx, and x[u]y.The satisfiability problems for FT and CFT are quasi-linear [27]. In contrast, the

satisfiability problem for EF is NP-hard, as Treinen shows by reducing the minimalcover problem to it [9, 30]. Crucial in this proof is the following implication

f f1;: :: ; fngx ^ x[u]y !

n.

i=1u

= fi

In order to express a corresponding disjunction in OF, we need existential quantificationand constraints of the form

:fg(y)

f f1; :: : ; fng(x) ^ xhyiz ^ :fg(y) !

n.

i=1

9zi y[ fi]zi

With this new constraint we reduce the satisfiability check for EF to the one for OF.
Proposition 4. There is an embedding [[\Delta ]] from EF constraints into OF with negative
constraints of the form :fg(x) such that every EF constraint j is satisfiable iff [[j]] is.

Proof. Labeling a(x) and equality x = y translate trivially. Now assume two speciallabels

unit and lab; we use these to represent labels f in EF by feature trees lab( f :unit).

[[u = f ]] = 9x (lab(u) ^ f f g(u) ^ u[ f ]x ^ unit(x) ^ fg(x))

[[x[u]y]] = xhuiy ^ :fg(u)
[[f f1;: :: ; fngx]] = f f1; :: : ; fng(x) ^ Vni=1 9y x[ fi]y

To show that satisfiability of an EF constraint j implies satisfiability of the OF con-straint

[[j]] we map every EF solution of j to an OF solution of [[j]] by replac-ing every feature f by

lab( f :unit) and every feature tree of the form a( f :t : ::) by
a( f :unit ! t :::).For the inverse, we take a satisfiable OF constraint

[[j]] and construct an OF solutionof
[[j]] which maps all variables u in selector position in xhuiy to a feature tree withexactly one feature. From this solution we derive an EF solution of j by replacing these

singleton-feature trees by their unique feature. Notice that the solution constructed inthe proof of Proposition 3 does not suffice since it may map

u to a feature tree withoutany feature.

Formally, we extend the definition of path reachability by x j;p F meaning that"arity bound

F can be reached from x over path p in j":

x j;p F if x j;p y and F(y) 2 j
We assume an order on F(j), and, for non-empty F, let min(F) denote the smallestfeature in F wrt. this order. We define a as follows:

Da(x) = fp j exists y : x j;p yg [ fp f j x j;p F; f = min(F)g
La(x) = f(p;a) j x j;p ag [ f(p;unit) j p 2 Da(x);6 9a : x j;p ag

By the constraint :fg(u) in the translation of xhuiy we know that, for closed and non-failed j, the set

F must be non-empty in the first line. Hence, a is a well-defined map-ping into feature trees. It is easy to show that a satisfies j and that a corresponds to an

EF solution as sketched above. 2
Corollary 1. The satisfiability problem of every extension of OF that can express
:fg(x) is NP-hard.

For example, the satisfiability problem of positive and negative OF constraints is NP-hard.

x : t 2 \Gamma j

;\Gamma  ` x : t VAR j;\Gamma  ` b : typeof(b) CONST

j;\Gamma  ` M : t0 j j=OF t :: msg( f : t0)

j;\Gamma  ` f (M) : t MSG

j;\Gamma ;xi : ti ` Mi : t0i for every i = 1;:::;n
j;\Gamma  ` f f1(x1) = M1;:::; fn(xn) = Mng : obj( f1:t1!t0n;:::; fn:tn!t0n) OBJ

j;\Gamma  ` M : t1 j;\Gamma  ` N : t2 j j=OF obj(t1) ^ msg(t2) ^t1ht2it3

j;\Gamma  ` M  N : t3 MSGPASS

j;\Gamma ;y : t1 ` M : t1 j;\Gamma ;y : t1 ` N : t2

j;\Gamma  ` let y = M in N : t2 LET (monomorphic)

Fig. 2. The Monomorphic Type System

3 Type Inference
We reformulate the type inference of [18] in terms of OF constraints. As in that paper,we consider a tiny object-oriented programming language with this abstract syntax.4

M ::= b (Constant)

j x (Variable)
j f (M) (Message)
j f f1(x1) = M1; :: : ; fn(xn) = Mng (Object)
j M  N (Message Passing)
j let y = M in N (Let Binding)

The operational semantics contains no surprise (see [18]). For the types, we assumeadditional distinct labels

msg and obj to mark message and object types, and a set ofdistinct labels such as
int, bool, etc., to mark base types. Monomorphic types are allfeature trees over this signature; monomorphic

type terms are feature terms:

t ::= a (Type variable)

j int j bool j : :: (Base type)
j msg( f1:t1;:: :; fn:tn) (Message type)
j obj( f1:t1!t01;:: :; fn:tn!t0n) (Object type)

Somewhat sloppily, we allow for infinite (regular) feature terms such as to incorporaterecursive types without an explicit

u notation. Recursive types are necessary for theanalysis of recursive objects. We assume a mapping

typeof from constants of base typeto their corresponding types. We also use the kinding notation x :: a

( f1:t1; :: : ; fn:tn) toconstrain
x to a feature tree whose arity is underspecified, e. g., a(x) ^ Vni=1 x[ fi]ti.

Monomorphic Type Inference. The monomorphic type system is given in Figure 2.As usual, \Gamma  is a finite mapping from variables to type terms and \Gamma ;

x : t extends \Gamma  so

4 In contrast to [18], we drop letobj and allow let to introduce recursively defined expressions.

I (x;b) = a(x) ^ fg(x) if a = typeof(b)
I (x;y) = x = y
I (x; f (M)) = 9y (msg(x) ^ x[ f ]y ^ I (y;M))
I (x;f f1(x1) = M1;:::; fn(xn) = Mng) = obj(x) ^ f f1;:::; fng(x)^

Vn

i=1 9xi 9x

0 9z (x[ fi]x0 ^ x0 = xi ! z ^ I (z;Mi))

I (x;M  N) = 9y 9z (yhzix ^ obj(y) ^ I (y;M) ^ msg(z) ^ I (z;N))
I (x;let y = M in N) = 9y (I (y;M) ^ I (x;N))

Fig. 3. Monomorphic Type Inference for First-Class Messages with OF Constraints
that it maps variable x to t. The type system defines judgments j;\Gamma  ` M : t which readsas "under the type assumptions in \Gamma  subject to the constraint j, the expression

M hastype t";5 the constraint j in well-formed judgements is required to be satisfiable. We

do not comment further on the type system here but refer to [18] for intuitions andto [28, 29] for notation. The corresponding type inference is given in Figure 3 as a
mapping I from a variable x and a program expressions M to an OF constraint suchthat every solution of

x in I (x; M) is a type of M. For ease of reading, we use the boundvariables in program expressions as their corresponding type variables. Correctness of

the type inference with respect to the type system is obvious, and it should be clear thatsoundness of the type system (with respect to the assumed operational semantics) can
be shown along the lines given in [18]. The type inference generates a constraint whosesize is proportional to the size of the given program expression. Hence, we know from
Proposition 2 that type inference can be done in polynomial time and space.6Let us give some examples. To reduce the verbosity of OF constraints, we shall
freely use feature term equations as introduced above. First, the statement

let o1 = fsucc(x)=x+1, pos(x)=x?0g;
defines an object with two methods succ : int!int and pos : int!bool. Type inferencegives the type of this object as an OF constraint on the type variable o

1 equivalent to

j1 j o1 = obj(succ : int!int; pos : int!bool):
A delegate object for the object o1 is defined as follows:

let o2 = fredirect(m)= o1  mg;
where m is a parameter that binds messages to be redirected to o1. Assuming the vari-able

o1 to be constrained by j1, the constraint j2 restricts o2 to the type of o2:

5 This terminology is slightly sloppy but common: Since t may contain type variables it is rather

a type term than a type and it would be accurate to say that M has "some type matching t".6
To be precise, we have to show that every satisfiable OF constraint derived by type inference
is satisfiable in the smaller domain of types; this is easy.

j2 j 9m 9z (o2 = obj(redirect : m!z) ^ o1hmiz ^ msg(m)):
The return type of a message passing to this object, e. g.,

let w = o2 redirect(succ(1));
is described as the solution of j1 ^ j2 ^ j3 for the type variable w, where

j3 j 9z0 (o2hz0iw ^ z0 :: msg(redirect : msg(succ : int)));
The solved form of j1 ^ j2 ^ j3 contains the primitive constraint int(w), which tells theintended result type

int.If
o1 does not respond to the message argument of redirect, for instance as in

let v = o2 redirect(pred(1));
a type error is detected as inconsistency in the derived constraint. Here, the constraint

j4 j 9z0 (o2hz0iw0 ^ z0 :: msg(redirect : msg(pred : int)))
implies 9z0 (o1hz0iw0 ^ z0 :: msg(pred : int)), and hence that o1 has a feature pred whichcontradicts j

1 by an arity clash.Now recall that in OF the implication x

hyiz ^ xhyiz0 ! z = z0 does not hold. Thefollowing example demonstrates how this weakness affects typing and type inference.

let o1 = fa(x)=x+1, b(x)=x?0g in o2 = fb(x)=x=0,c(x)=x*2g
in o3 = ffoo(m)= begin o1 m; o2m endg;

It is easy to see that the foo method always returns bool, since the argument messageof

foo must be accepted by both the objects o1 and o2, which share only the methodname

b. However, type inference for this program derives (essentially) the constraint

o1 = obj(a : int!int; b : int!bool) ^ o2 = obj(b : int!bool; c : int!int)^o

3 = obj(foo : m!z) ^ o1hmiz1 ^ o2hmiz2
Herein, the result type z of the method foo is neither entailed to equal z1 nor z2. This isreasonable since the message

m in this program is not sent and hence may safely returnanything. By a similar argument, the following program can be considered acceptable:

let o1 = fa(x)=x+1g in o2 = fc(x)=x*2g
in o3 = ffoo(m)= begin if b then o1m else o2m endg

One may complain that this kind of methods should be detected as a type error. Ma-nipulating the type system and the type inference to do this is easy: One just needs to

exclude types msg(), i. e., message types without any feature. However, recall that thepolynomial time complexity of the analysis depends on this weakness: The corresponding clause in the type inference

I (x; f (M)) = 9y (:fg(x) ^ msg(x) ^ x[ f ]y ^ I (y; M))
generates OF constraints with negation such that constraint solving (and hence, typeinference) would become NP-hard.7

7 The altered type inference does still not exactly correspond to the original. For example, we

would not accept message sending to an empty object as in fg  m, while the original one
does.

Polymorphic Type Inference. We can obtain the polymorphic type inference by ap-plying the scheme HM(X) [29]. The constraint system OF is a viable parameter for
HM(X) since it satisfies the two required properties, called coherence and soundness.Both rely on a notion of monomorphic types, in our case, given by feature trees; it does
no harm that these may be infinite. The coherence property requires that the consideredorder on types is semantically well-behaved; this is trivial in our case since we only
consider a trivial order on feature trees. The soundness property that a solved constraintindeed has a solution follows from Proposition 3.

Comparison with Nishimura. In Nishimura's original type system [18], abbreviatedas D in the following, constraints are modeled as kinded type variables. The kindings
have a straightforward syntactic correspondence with OF constraints: the message kind-ing

x :: hh f1:t1;: :: ; fn:tniiF corresponds to x :: msg( f1:t1; :: : ; fn:tn) ^ F(x) and the objectkinding x ::

fjy1!t1; :: : ; yn!tnjgF corresponds to obj(x) ^ Vni=1 xhyiiti ^ F(x).Our reformulation HM(OF) of D is in the same spirit as the reformulation

HM(REC) [29] of Ohori's type system for the polymorphic record calculus: Both re-cast the kinding system as a constraint system. One might thus expect the relation of D
and HM(OF) to be as close as that between Ohori's system and HM(REC) which typeexactly the same programs ("full and faithful"); this is, however, not the case.

There is a significant difference between the the kind system in D and OF. In D,kinded types may contain variables,

e. g., an object returning integers as a response tomessages of type y receives the kind

fjy!intjgF . On unifying two types with kindings
fjy!intjgF and fjy!zjgF, the type inference for D unifies z and int since it is syntacticallyknown that both

z and int denote the type of the response of the same object to the samemessage. Thus in D, the name of type variables is crucial. In this paper, variables only

occur as part of type descriptions (i. e., syntax) while the (semantic) domain of typesdoes not contain variables. E. g., we understand

fjy!intjg not as a type but as part of a
type description which can be expressed by a constraint like obj(x) ^ xhyiint.As a consequence, well-typedness in our system does not depend on the choice of

variable names but only on the type of variables. This is usual for ML-style type systemsbut does not hold for D. Consider the following example:

ffoo(m) = (om) + 1; (om) & trueg
This program is accepted by the OF-based type system, since the constraint ohmiint ^o

hmibool is satisfiable. The type system D, however, rejects it after trying to unify intand

bool during type inference. To insist that this is a syntactic argument notice that Daccepts the following program, where

o is replaced by the object constant fg:

fbaz(m) = (fgm) + 1; (fgm) & trueg

4 Conclusion
We have presented a new constraint system OF over feature trees and investigated thecomplexity of its satisfiability problem. OF is designed for specification and implementation of type inference for first-class messages in the spirit of Nishimura's system [18].

We have given a type system for which monomorphic type inference with OF con-straints can be done in polynomial time; this system is weaker than the original one,
but the additional expressiveness would render monomorphic type inference NP-hardas we have shown. Given OF, we can add ML-style polymorphism by instantiating the
recent HM(X) scheme to the constraint system OF.
Acknowledgements. We would like to thank the members of RIMS, Andreas Rossbergand Joachim Walser for careful proofreading and feedback, as well as Martin Sulzmann
for extensive discussion on HM(X). We also acknowledge helpful remarks of the refer-ees.

References

1. A. Aiken and E. Wimmers. Type inclusion constraints and type inference. In Proceedings

of the 6th ACM Conference on Functional Programming and Computer Architecture, pp.
31-41. ACM Press, New York, June 1993.
2. H. A"fft-Kaci and A. Podelski. Towards a meaning of life. The Journal of Logic Programming,

16(3 - 4):195-234, July, Aug. 1993.
3. H. A"fft-Kaci, A. Podelski, and G. Smolka. A feature-based constraint system for logic programming with entailment. Theoretical Computer Science, 122(1-2):263-283, Jan. 1994.
4. R. Backofen. A complete axiomatization of a theory with feature and arity constraints.

The Journal of Logic Programming, 24(1 - 2):37-71, 1995. Special Issue onComputational
Linguistics and Logic Programming.
5. R. Backofen and G. Smolka. A complete and recursive feature theory. Theoretical Computer

Science, 146(1-2):243-268, July 1995.
6. F. Bourdoncle and S. Merz. Type checking higher-order polymorphic multi-methods. In

Proceedings of the 24th ACM Symposium on Principles of Programming Languages, pp.
302-315. ACM Press, New York, Jan. 1997.
7. M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer Auf Der Heide, H. Rohnert, and R. E.

Tarjan. Dynamic perfect hashing: Upper and lower bounds. SIAM Journal of Computing,
23(4):738-761, Aug. 1994.
8. J. Eifrig, S. Smith, and V. Trifonow. Type inference for recursively constrained types and

its application to object-oriented programming. Electronic Notes in Theoretical Computer
Science, 1, 1995.
9. M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to the Theory of

NP-Completeness. W.H. Freeman and Company, New York, 1979.
10. R. Hindley. The principal type scheme of an object in combinatory logic. Transactions of

the American Mathematical Society, 146:29-60, Dec. 1969.
11. H. G. Mairson. Deciding ML typebility is complete for deterministic exponential time. In

Proceedings of the 17th ACM Symposium on Principles of Programming Languages, pp.
382-401. ACM Press, New York, Jan. 1990.
12. K. Mehlhorn and P. Tsakalides. Data structures. In van Leeuwen [31], chapter 6, pp. 301-

342.
13. R. Milner. A theory of type polymorphism in programming. Journal of Computer and System

Science, 17(3):348-375, 1978.
14. R. Milner, M. Tofte, R. Harper, and D. MacQueen. The Definition of Standard ML (Revised).

The MIT Press, Cambridge, MA, 1997.

15. M. M"uller, J. Niehren, and A. Podelski. Inclusion constraints over non-empty sets of trees.

In M. Bidoit and M. Dauchet, eds., Proceedings of the Theory and Practice of Software Development, vol. 1214 of Lecture Notes in Computer Science, pp. 345-356. Springer-Verlag,
Berlin, Apr. 1997.16. M. M"uller, J. Niehren, and A. Podelski. Ordering constraints over feature trees. In

G. Smolka, ed., Proceedings of the 3rd International Conference on Principles and Practice
of Constraint Programming, vol. 1330 of Lecture Notes in Computer Science, pp. 297-311.
Springer-Verlag, Berlin, 1997. Full version submitted to special journal issue of CP'97.17. M. M"uller and S. Nishimura. Type inference for first-class messages with feature constraints.

Technical report, Programming Systems Lab, Universit"at des Saarlandes, 1998. http:
//www.ps.uni-sb.de/Papers/abstracts/FirstClass98.html.18. S. Nishimura. Static typing for dynamic messages. In Proceedings of the 25th ACM Symposium on Principles of Programming Languages, pp. 266-278. ACM Press, New York, 1998.19. M. Odersky, P. Wadler, and M. Wehr. A second look at overloading. In Proceedings of the
7th ACM Conference on Functional Programming and Computer Architecture. ACM Press,
New York, 1995.20. A. Ohori. A polymorphic record calculus and its compilation. ACM Transactions on Programming Languages and Systems, 17(6):844-895, 1995.21. J. Palsberg. Efficient inference of object types. In Proceedings of the 9th IEEE Symposium
on Logic in Computer Science, pp. 186-185. IEEE Computer Society Press, 1994.22. C. Pollard and I. Sag. Head-Driven Phrase Structure Grammar. Studies in Contemporary
Linguistics. Cambridge University Press, Cambridge, England, 1994.23. D. R'emy. Type checking records and variants in a natural extension of ML. In Proceedings
of the 16th ACM Symposium on Principles of Programming Languages, pp. 77-87. ACM
Press, New York, 1989.24. D. R'emy and J. Vouillon. Objective ML: A simple object-oriented extension of ML. In

Proceedings of the 24th ACM Symposium on Principles of Programming Languages, pp.
40-53. ACM Press, New York, 1997.25. W. C. Rounds. Feature logics. In J. v. Benthem and A. ter Meulen, eds., Handbook of Logic

and Language, pp. 475-533. Elsevier Science Publishers B.V. (North Holland), 1997. Part
2: General Topics.26. G. Smolka. The Oz Programming Model. In J. van Leeuwen, ed., Computer Science Today,

vol. 1000 of Lecture Notes in Computer Science, pp. 324-343. Springer-Verlag, Berlin, 1995.27. G. Smolka and R. Treinen. Records for logic programming. The Journal of Logic Programming, 18(3):229-258, Apr. 1994.28. M. Sulzmann. Proofs of properties about HM(X). Technical Report YALEU/DCS/RR-1102,
Yale University, 1998.29. M. Sulzmann, M. Odersky, and M. Wehr. Type inference with constrained types (extended
abstract). In B. Pierce, ed., Proceedings of the 4th International Workshop on Foundations
of Object-oriented Programming, Jan. 1997. Full version to appear in TAPOS, 1998.30. R. Treinen. Feature constraints with first-class features. In A. M. Borzyszkowski and

S. Sokol/owski, eds., International Symposium on Mathematical Foundations of Computer
Science, vol. 711 of Lecture Notes in Computer Science, pp. 734-743. Springer-Verlag,
Berlin, 30 August-3 September 1993.31. J. van Leeuwen, ed. Handbook of Theoretical Computer Science, vol. A (Algorithms and

Complexity). The MIT Press, Cambridge, MA, 1990.32. M. Wand. Complete type inference for simple objects. In Proceedings of the IEEE Symposium on Logic in Computer Science, pp. 37-44. IEEE Computer Society Press, 1987.
Corrigendum in LICS '88, p. 132.33. M. Wand. Type inference for record concatenation and multiple inheritance. Information

and Computation, 93:1-15, 1991.