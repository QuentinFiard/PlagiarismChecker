

Defunctionalized Interpreters

for Call-by-Need Evaluation

Olivier Danvy1, Kevin Millikin2, Johan Munk3, and Ian Zerny1

1 Department of Computer Science, Aarhus University
Aabogade 34, 8200 Aarhus N, Denmark -- {danvy,zerny}@cs.au.dk

2 Google

Aabogade 15, 8200 Aarhus N, Denmark -- kmillikin@google.com

3 Arctic Lake Systems

Aabogade 15, 8200 Aarhus N, Denmark -- johanmunk@gmail.com

Abstract. Starting from the standard call-by-need reduction for the
*-calculus that is common to Ariola, Felleisen, Maraist, Odersky, and
Wadler, we inter-derive a series of hygienic semantic artifacts: a reductionfree stateless abstract machine, a continuation-passing evaluation function, and what appears to be the first heapless natural semantics for
call-by-need evaluation. Furthermore we observe that a data structure
and a judgment in this natural semantics are in defunctionalized form.
The refunctionalized counterpart of this evaluation function is an extended direct semantics in the sense of Cartwright and Felleisen.
Overall, the semantic artifacts presented here are simpler than many
other such artifacts that have been independently worked out, and which
require ingenuity, skill, and independent soundness proofs on a caseby-case basis. They are also simpler to inter-derive because the interderivational tools (e.g., refocusing and defunctionalization) already exist.

1 Introduction
A famous functional programmer once was asked to give an overview talk. He be-gan with "This talk is about lazy functional programming and call by need." and

paused. Then, quizzically looking at the audience, he quipped: "Are there anyquestions?" There were some, and so he continued: "Now listen very carefully, I
shall say this only once."This apocryphal story illustrates demand-driven computation and memoization of intermediate results, two key features that have elicited a fascinat-ing variety of semantic specifications and implementation techniques over the
years, ranging from purely syntactic treatments to mutable state, and featuringsmall-step operational semantics [2,26], a range of abstract machines [17,19,33],
big-step operational semantics [1, 24], as well as evaluation functions [20, 22].In this article, we extract the computational content of the standard call-byneed reduction for the *-calculus that is common to both Ariola and Felleisen [2]and Maraist, Odersky, and Wadler [26]. This computational content takes the
forms of a one-step reduction function, an abstract machine, and a natural se-mantics that are mutually compatible and all abide by Barendregt's variable

convention [4, page 26]. Rather than handcrafting each of these semantic ar-tifacts from scratch and then proving a series of soundness theorems, we successively inter-derive them from small steps to big steps using a series of fullycorrect transformations. To this end, we follow the programme outlined in the
first author's invited talk at ICFP 2008 [9]. To this programme we add one newrefunctionalization step that is specific to call by need:

0. we modify one axiom in the standard call-by-need reduction to make the asso-ciated one-step reduction function preserve Barendregt's variable convention;
1. iterating this hygienic one-step reduction function yields a reduction-basedevaluation function, which we refocus to obtain a reduction-free evaluation

function with the same built-in hygiene; this evaluation function takes theform of an abstract machine and is correct by construction;
2. we simplify this hygienic abstract machine by compressing its corridor transi-tions, and we refunctionalize this simplified hygienic abstract machine into a

continuation-passing evaluation function, which we write back to direct style,obtaining a functional program that is correct by construction and that implements a heapless natural semantics with the same built-in hygiene;3. in addition, we observe that a data structure and a judgment in this hygienic natural semantics are in defunctionalized form, and we present thecorresponding higher-order evaluation function.

The ML code of the entire derivation is available from the authors.
Prerequisites: We assume the reader to know the formats of a reduction seman-tics, an abstract machine, and a natural semantics as can be gathered, e.g., in

the first author's lecture notes at AFP 2008 [10].

2 The standard call-by-name reduction for the *-calculus
The standard call-by-name reduction for the *let-calculus is a simplification ofAriola et al.'s call-by-need formulation presented in Section 3. This call-by-name

formulation reads as follows:
Definition 1 (call-by-name *let-calculus).
Syntax: Terms 3 T ::= x | *x.T | T T | let x be T in T

Values 3 V ::= *x.T
Answers 3 A ::= V | let x be T in A
Evaluation Contexts 3 E ::= [ ] | E T | let x be T in E

Axioms (i.e., contraction rules):1

(I) (*x.T ) T1 ! let x be T1 in T(

N ) let x be T in E[x] ! let x be T in E[T ](
C) (let x be T1 in A) T2 ! let x be T1 in A T2

1 The unusual notation "E[x]" in Rule (N) stands for a term that uniquely decomposes

into an evaluation context E and a variable x. Naturally, there may be more than
one occurrence of x in the term E[x].

2

In words: Terms are pure *-terms with let expressions. Values are *-abstractions.Answers are let expressions nested around a value. Evaluation contexts are terms
with a hole and are constructed according to the call-by-name reduction strategy.As for the axioms, Rule (

I) introduces a let binding from an application; Rule(
N ) hygienically substitutes a term for the occurrence of a let-bound variablearising in an evaluation context; and Rule (

C) allows let bindings to commutewith applications, hygienically, i.e., renaming what needs to be renamed so that

no free variable is captured.The following reduction sequence illustrates the demand-driven aspect of call
by name as well as the duplication of work it entails, noting one-step reductionwith 7!

name and annotating each reduction step with the corresponding axiom:

(*z.z z) ((*y.y) (*x.x)) 7!name (I)
let z be (*y.y) (*x.x) in z z 7!name (N )
let z be (*y.y) (*x.x) in ((*y.y) (*x.x)) z 7!name (I)
let z be (*y.y) (*x.x) in (let y be *x.x in y) z 7!name (C)
let z be (*y.y) (*x.x) in let y be *x.x in y z 7!name (N )
let z be (*y.y) (*x.x) in let y be *x.x in (*x.x) z 7!name (I)
let z be (*y.y) (*x.x) in let y be *x.x in let x be z in x 7!name (N )
let z be (*y.y) (*x.x) in let y be *x.x in let x be z in z 7!name (N )
let z be (*y.y) (*x.x) in let y be *x.x in let x be z in (*y.y) (*x.x) 7!name (I)
. . .

We have shaded the occurrences of the variables whose value is needed in thecourse of the reduction. Each of the two shaded occurrences of

z triggers thereduction of (
*y.y) (*x.x). The result of this demand-driven reduction is notmemoized.

3 The standard call-by-need reduction for the *-calculus
Our starting point is the standard call-by-need reduction for the *let-calculusthat is common to Ariola, Felleisen, Maraist, Odersky, and Wadler's articles [2,

26], renaming non-terminals for notational uniformity, and assuming that initialterms are closed:

Definition 2 (call-by-need *let-calculus).
Syntax: Terms 3 T ::= x | *x.T | T T | let x be T in T

Values 3 V ::= *x.T
Answers 3 A ::= V | let x be T in A
Evaluation Contexts 3 E ::= [ ] | E T | let x be T in E | let x be E in E[x]

Axioms (i.e., contraction rules):

(I) (*x.T ) T1 ! let x be T1 in T(

V ) let x be V in E[x] ! let x be V in E[V ](
C) (let x be T1 in A) T2 ! let x be T1 in A T2(
A) let x be let y be T1

in A
in E[x]

! let y be T1

in let x be A

in E[x]

3

In words: Terms are pure *-terms with let expressions. Values are *-abstractions.Answers are let expressions nested around a value. Evaluation contexts are terms
with a hole and are constructed according to the call-by-need reduction strategy.As for the axioms, Rule (

I) introduces a let binding from an application; Rule(
V ) substitutes a value for the occurrence of a let-bound variable arising in anevaluation context; Rule (

C) allows let bindings to commute with applications;and Rule (
A) re-associates let bindings.
Where call by name uses Axiom (N ), call by need uses (V ), ensuring thatonly values are duplicated. The reduction strategy thus also differs, so that the

definiens of a needed variable is first reduced and this variable is henceforthdeclared to denote this reduct.

The following reduction sequence illustrates the demand-driven aspect ofcall by need as well as the memoization of intermediate results it enables, noting
one-step reduction with 7!need (and specifying it precisely in Section 4.7):

(*z.z z) ((*y.y) (*x.x)) 7!need (I)
let z be (*y.y) (*x.x) in z z 7!need (I)
let z be (let y be *x.x in y) in z z 7!need (V )
let z be (let y be *x.x in *x.x) in z z 7!need (A)
let y be *x.x in let z be *x.x in z z 7!need (V )
let y be *x.x in let z be *x.x in (*x.x) z 7!need (I)
let y be *x.x in let z be *x.x in let x be z in x 7!need (V )
let y be *x.x in let z be *x.x in let x be *x.x in x 7!need (V )
let y be *x.x in let z be *x.x in let x be *x.x in *x.x

As in Section 2, we have annotated each reduction step with the name of thecorresponding axiom and we have shaded the occurrences of the variables whose
values are needed in the course of the reduction. Only the first shaded occurrenceof

z triggers the reduction of (*y.y) (*x.x). The result of this demand-drivenreduction is memoized in the let expression that declares

z and thus the twoother shaded occurrences of
z trigger the (V ) rule. This let expression is neededas long as
z occurs free in its body; thereafter it can be garbage-collected [6].

4 Some exegesis
Definition 2 packs a lot of information. Let us methodically spell it out:

- The axioms are a mouthful, and so in Section 4.1, we identify their underlyingstructure by stating a grammar for potential redexes.
- In reduction semantics, evaluation is defined as iterated one-step reduction.However, one-step reduction assumes Barendregt's variable convention, i.e.,

that all bound variables are distinct, but not all the axioms preserve this con-vention: naive iteration is thus unsound. Rather than subsequently ensuring
hygiene as in Garcia et al.'s construction of a lazy abstract machine [19], werestate one axiom in Section 4.2 to make naive iteration hygienic upfront.

4

- The evaluation contexts are unusual in that they involve terms that areuniquely decomposable into a delimited evaluation context and an identifier. In Section 4.3, we restate their definition to clearly distinguish betweenordinary evaluation contexts and delimited evaluation contexts.
- The one-step reduction of a reduction semantics is implicitly structured inthree parts: given a non-answer term, (1, decomposition): locate the next

potential redex according to the reduction strategy; (2, contraction): if thepotential redex is an actual one, i.e., if the non-answer term is not stuck,
contract this actual redex as specified by the axioms; and (3, recomposition):fill the surrounding context with the contractum to construct the next term
in the reduction sequence.
Based on Sections 4.1, 4.2, and 4.3, we specify decomposition, contraction, andrecomposition in Sections 4.4, 4.5, and 4.6. We then formalize one-step reduction

in Section 4.7 and evaluation as iterated one-step reduction in Section 4.8.

4.1 Potential redexes
To bring out the underlying structure of the axioms, let us state a grammar forpotential redexes:

Pot Redexes 3 R ::= A T | let x be A in E[x]
where E[x] stands for a non-answer term.The two forms of answers - value and let expression - give rise to an axiom

for each production in the grammar of potential redexes: (I) arises from theapplication of a value to a term; (

C) arises from the application of a let expressionto a term; and likewise, (
V ) and (A) arise from the binding of an answer to avariable whose value is needed.

In the present case of the pure *let-calculus, all potential redexes are actualones.

4.2 Barendregt's variable convention
The definition of evaluation as iterated one-step reduction assumes Barendregt'svariable convention, i.e., that all bound variables are distinct. Indeed the rules

(V ), (C) and (A) assume the variable convention when they move a term in thescope of a binding. A reduction step involving (

V ), however, yields a term wherethe variable convention does not hold, since
V is duplicated and it may contain
*-abstractions and therefore bound variables.There are many ways to ensure hygiene, if not the variable convention, at

all times. We choose to allow *-bound (not let-bound) variables to overlap, andsince no reduction can take place inside a

*-abstraction prior to its application,in Rule (
I), we lazily rename *-bound variables as the need arises, using anauxiliary function to rename the formal parameter of a

*-abstraction with aglobally fresh name:

(I) (*x.T ) T1 ! let x0 be T1 in T [x0/x] where x0 is fresh

5

This modification preserves Barendregt's variable convention for let-bound vari-ables. We thus assume that any initial term satisfies the convention for let-bound
variables (otherwise we appropriately rename it).Other alternatives exist for ensuring hygiene. We have explored several of
them, and in our experience they lead to semantic artifacts that are about assimple and understandable as the ones presented here. The alternative we chose
here, i.e., the modification of Rule (I), corresponds to, and is derived into thesame renaming side condition as in Maraist, Odersky, and Wadler's natural
semantics [26, Figure 11].
4.3 The evaluation contexts
The grammar of contexts for call by need, given in Definition 2, is unusual com-pared to the one for call by name given in Definition 1. Call-by-need evaluation

contexts have an additional constructor involving the term "E[x]" for whichthere exists an identifier

x in the eye of a delimited context E. Spelling out thedecomposition function (see Section 4.5 and Figure 3) shows that these delimited contexts are constructed outside in whereas all the others are constructedinside out. Let us make it explicit which are which by adopting an isomorphic
representation of contexts as a list of frames:

Context Frames 3 F ::= \Lambda  T | let x be \Lambda  in Eoi [x] | let x be T in \Lambda 
Outside-in Contexts 3 Eoi ::= " | F ffi Eoi

Inside-out Contexts 3 Eio ::= " | F ffi Eio

Here " is the empty list, ffi is the list constructor, and \Lambda  is the hole in a contextframe. For example, the context

E = ([ ] T1) T2 is isomorphic to Eio = (\Lambda  T1) ffi(\Lambda 
T2) ffi " which is equivalent to Eoi = (\Lambda  T2) ffi (\Lambda  T1) ffi " in the sense that, asdefined in Section 4.4, h

Eio, T iio *rec T 0 and hEoi , T ioi *rec T 0 for all T .NB. As pointed out in Footnote 1 page 2, in this BNF of context frames,

the notation "Eoi [x]" is meant to represent a term that uniquely decomposesinto an outside-in evaluation context

Eoi and a variable x. From Section 5.1onwards, we take notational advantage of this paired representation to short-cut

the subsequent decomposition of this term into Eoi and x towards the potentialredex contracted in Rule (

V ) in Section 4.6.

4.4 Recomposition
Outside-in contexts and inside-out contexts are recomposed (or again are `plugged'or `filled') as follows:

Definition 3 (recomposition of outside-in contexts). An outside-in con-text

Eoi is recomposed around a term T into a term T 0 whenever hEoi , T ioi *rec T 0holds. (See Figure 1.)

Definition 4 (recomposition of inside-out contexts). An inside-out con-text

Eio is recomposed around a term T into a term T 0 whenever hEio, T iio *rec T 0holds. (See Figure 2.)

6

h", T ioi *rec T h

Eoi , T ioi *rec T1 hE0oi, xioi *rec T2h
(let x be \Lambda  in E0oi [x]) ffi Eoi, T ioi *rec let x be T1 in T2

hEoi, T ioi *rec T0h
(\Lambda  T1) ffi Eoi, T ioi *rec T0 T1 h

Eoi, T ioi *rec T2h
(let x be T1 in \Lambda ) ffi Eoi, T ioi *rec let x be T1 in T2

Fig. 1. Recomposition of outside-in contexts

h", T iio *rec T h

Eoi, xioi *rec T hEio, let x be T1 in T iio *rec T2h

(let x be \Lambda  in Eoi[x]) ffi Eio, T1iio *rec T2

hEio, T0 T1iio *rec T2h
(\Lambda  T1) ffi Eio, T0iio *rec T2 h

Eio, let x be T1 in T iio *rec T2h
(let x be T1 in \Lambda ) ffi Eio, T iio *rec T2

Fig. 2. Recomposition of inside-out contexts

hx, Eioiterm #dec hEio, (", x)irerooth
*x.T , Eioiterm #dec hEio, *x.T icontexth
T0 T1, Eioiterm #dec hT0, (\Lambda  T1) ffi Eioitermh
let x be T1 in T , Eioiterm #dec hT, (let x be T1 in \Lambda ) ffi Eioiterm

h", Aicontext #dec hAianswerh
(\Lambda  T1) ffi Eio, Aicontext #dec hA T1, Eioidecompositionh
(let x be \Lambda  in Eoi [x]) ffi Eio, Aicontext #dec hlet x be A in Eoi [x], Eioidecompositionh

(let x be T1 in \Lambda ) ffi Eio, Aicontext #dec hEio, let x be T1 in Aicontext

h(let x be T1 in \Lambda ) ffi Eio, (Eoi, x)ireroot #dec hT1, (let x be \Lambda  in Eoi [x]) ffi Eioitermh

F ffi Eio, (Eoi, x)ireroot #dec hEio, (F ffi Eoi, x)ireroot

where F 6= let x be T in \Lambda 

Fig. 3. Decomposition of an answer term into itself

and of a non-answer term into a potential redex and its context

The alert reader will have noticed that each of these recomposition functions,together with the data type of contexts, is in defunctionalized form [13,14,30,31],
indicating a large and friendly degree of freedom for implementing a one-stepreduction function in a functional programming language.

4.5 Decomposition
Decomposing a non-answer term into a potential redex and its evaluation contextis at the heart of a reduction semantics, but outside of the authors' publications,

it seems never to be spelled out. Let us do so.There are many ways to specify decomposition. In our experience, the simplest one is the abstract machine displayed in Figure 3. This machine startsin the configuration h

T, "iterm , for a given term T . It halts in an answer state

7

if the given term contains no potential redex, and in a decomposition stateh

R, Eioidecomposition otherwise, where R denotes the first potential redex in Tand

Eio its evaluation context according to the reduction strategy specified bythe grammar of evaluation contexts.

The term and context transitions are traditional: one dispatches on a termand the other on the top context frame. The reroot transitions locate the letbinder for a variable while maintaining the outside-in context from the binderto its occurrence, zipper-style [21].

4 In effect, the transitions reverse the prefix

of an inside-out context into an outside-in context.

4.6 The axioms
In accordance with the new BNF of contexts, the hygienic axioms of Definition 2are restated as follows:

(I) (*x.T ) T1 ! let x0 be T1 in T [x0/x] where x0 is fresh(

V ) let x be V in Eoi[x] ! let x be V in T where hEoi , V ioi *rec T(
C) (let x be T1 in A) T2 ! let x be T1 in A T2(
A) let x be let y be T1

in A
in Eoi [x]

! let y be T1

in let x be A

in Eoi [x]

4.7 One-step reduction
The partial function of performing one contraction in a non-answer term is de-fined as (1) locating a redex and its context through a number of decomposition

steps, (2) contracting this redex, and (3) recomposing the resulting contractuminto the context:

Definition 5 (one-step reduction). For any T ,

T 7!need T 00 if 8?!?: h

T, "iterm #*dec hR, Eioidecomposition

(R, T 0) 2 (I) [ (V ) [ (C) [ (A)h
Eio, T 0iio *rec T 00

One-step reduction is a partial function because the given term may already bean answer.

4.8 Reduction-based evaluation
Reduction-based evaluation is defined as the iteration of the one-step reductionfunction. It thus proceeds by enumerating the reduction sequence of any given

term:
Definition 6 (reduction-based evaluation). For any T , T 7!*need A
Evaluation is a partial function because it may diverge.

4 Decomposition could be stuck if the initial term contained free variables, but we

assume it to be closed.

8

4.9 Conclusion and perspectives
As illustrated here, there is substantially more than meets the eye in a reductionsemantics.

In addition, extensional properties such as unique decomposition, standard-ization, and hygiene do not only ensure the existence of a deterministic evaluator extensionally, but it is our thesis that they also provide precious intensionalguidelines. Indeed, after exegetically spelling out what does not readily meet the
eye, things become compellingly simple: refocusing the reduction-based evalu-ation function immediately gives a reduction-free small-step abstract machine
(Section 5.1); fusing its iteration function with its transition functions yields abig-step abstract machine (Section 5.2); compressing the corridor transitions of
this abstract machine improves the efficiency of its execution (Section 5.3); re-functionalizing this improved abstract machine with respect to the contexts gives
a reduction-free evaluation function in continuation-passing style (Section 5.4);and mapping this evaluation function back to direct style gives a functional implementation of a natural semantics (Section 5.5). All of these semantic artifactsare correct by construction, and their operational behaviors rigorously mirror
each other. And should one be tempted to fine-tune one of these semantic arti-facts, one is in position to adjust the others to keep their operational behaviors
in line, or to understand why this alignment is not possible and where coherencegot lost in the fine-tuning [10].

5 Derivation: from small-step reduction semantics

to big-step evaluation function

This section implements the programme outlined in Section 4.9.

5.1 Refocusing: from reduction semantics

to small-step abstract machine

By recomposing and then immediately decomposing, a reduction-based evaluatortakes a detour from a redex site, up to the top of the term, and back down

again to the next redex site. Many of the steps that make up this detour can beeliminated by refocusing [15]. Refocusing the reduction-based evaluation function
of a reduction semantics yields a reduction-free evaluation function in the formof an abstract machine that directly navigates in a term from redex site to redex
site without any detour via the top of the term.Refocusing replaces successive recompositions and decompositions by a call
to a `refocus' function that maps a contractum and its associated (inside-out)evaluation context into a value or a decomposition consisting of the next potential redex and associated evaluation context. Surprisingly, optimal refocusingconsists of simply continuing with decomposition from the contractum and its
associated evaluation context. This is another reason why we place such store inthe decomposition function of a reduction semantics.

9

The hygienic reduction semantics of Section 4 satisfies the requirements forrefocusing [15] and so its reduction-based evaluation function can be mechanically replaced by a reduction-free evaluation function that short-cuts the succes-sive terms in the reduction sequence.

5.2 Lightweight fusion: from small-step abstract machineto big-step abstract machine
The refocused specification of a reduction semantics implements a small-stepabstract machine. Small-step abstract machines are characterized by a singlestep state-transition function which maps a machine configuration to the nextand is iterated toward a final state if any. In contrast, big-step abstract machines
are characterized by a collection of mutually tail-recursive transition functionsmapping a configuration to a final state, if any.

Fusing the composition of a small-step abstract machine's iteration functionwith its transition functions yields a big-step abstract machine [12]. To this end,
we use Ohori and Sasano's lightweight fusion by fixed-point promotion [28].

The difference between the two styles of abstract machines is not typicallyapparent in the abstract-machine specifications found in programming-language

semantics. A machine specification is normally presented as a small-step abstractmachine given by reading the transition arrow as the definition of a single-step
transition function to be iterated and with the configuration labels as passivecomponents of the configurations. However, the same specification can equally
be seen as a big-step abstract machine if the transition labels are interpreted astail recursive functions, with the transition arrow connecting left- and right-hand
sides of their definitions. Ohori and Sasano's correctness-preserving fusion of thesmall-step machine's transition and iteration functions justifies this dual view.

The difference between the two styles is relevant when we consider the trans-formation of an abstract machine semantics into an evaluator implementing a
natural semantics. Such evaluators are big-step ones, and it is for this reasonthat we transform small-step machines into big-step machines.

5.3 Transition compression: from big-step abstract machineto big-step abstract machine
Some of the transitions of the abstract machine of Section 5.2 are to intermediateconfigurations such that the next transition is statically known. These so-called
"corridor transitions" can be hereditarily compressed so that the original config-uration transitions directly to the final one, skipping all intermediate ones. The
resulting abstract machine is displayed in Figure 4.
Proposition 1 (full correctness). For any T ,

T 7!*need A , hT, "iterm !*run hAianswer .

10

hx, Eioiterm !run hEio, (", x)irerooth
*x.T , Eioiterm !run hEio, *x.T icontexth
T0 T1, Eioiterm !run hT0, (\Lambda  T1) ffi Eioitermh
let x be T1 in T , Eioiterm !run hT, (let x be T1 in \Lambda ) ffi Eioiterm

h", Aicontext !run hAianswerh
(\Lambda  T1) ffi Eio, *x.T icontext !run hT [x0/x], (let x0 be T1 in \Lambda ) ffi Eioiterm

where x0 is freshh
(\Lambda  T2) ffi Eio, let x be T1 in Aicontext !run h(\Lambda  T2) ffi (let x be T1 in \Lambda ) ffi Eio, Aicontexth
(let x be \Lambda  in Eoi [x]) ffi Eio, V icontext !run hT, (let x be V in \Lambda ) ffi Eioiterm

where hEoi, V ioi *rec T

h"let x be \Lambda in E

oi[x] << ffi Eio, "

let y be T1
in A <<icontext !run h"

let x be \Lambda 
in Eoi[x] << ffi "

let y be T1
in \Lambda  << ffi Eio, Aicontexth
(let x be T1 in \Lambda ) ffi Eio, Aicontext !run hEio, let x be T1 in Aicontext

h(let x be T1 in \Lambda ) ffi Eio, (Eoi, x)ireroot !run hT1, (let x be \Lambda  in Eoi [x]) ffi Eioitermh

F ffi Eio, (Eoi, x)ireroot !run hEio, (F ffi Eoi, x)ireroot

where F 6= let x be T in \Lambda 

Fig. 4. Abstract machine after transition compression
5.4 Refunctionalization: from abstract machineto continuation-passing interpreter

Reynolds introduced defunctionalization [14, 30] to derive first-order evaluatorsfrom higher-order ones. Defunctionalization turns a function type into a sum
type, and function application into the application of an apply function dis-patching on the sum type. Its left inverse, refunctionalization [13], can transform
first-order abstract machines into higher-order evaluators. It specifically workson programs that are in defunctionalized form, i.e., in the image of Reynolds's
defunctionalization.

The big-step abstract machine of Section 5.3 is not in defunctionalized formwith respect to the inside-out reduction contexts. Indeed these contexts are

consumed by the two transition functions corresponding to hEio, Aicontext andh

Eio, (Eoi , x)ireroot rather than by the single apply function demanded for re-functionalization. This mismatch can be fixed by introducing a sum type discriminating between the (non-context) arguments to the two transition functions andcombining them into a single transition function [13]. The left summand (tagged
"ans") contains an answer, and the right summand (tagged "ide") contains apair of an identifier whose value is needed and an incrementally-constructed
outside-in context used to get back to the place in the term where the value wasneeded.

Three of the context constructors occur on the right-hand sides of their ownapply function clauses. When refunctionalized, these correspond to recursive
functions and therefore show up as named functions.

The refunctionalized abstract machine is an interpreter for lazy evaluation incontinuation-passing style, with the functional representation of the inside-out

contexts serving as continuations.

11

x +eval ide(", x) *x.T +eval ans(*x.T )

T0 +eval r r T1 +apply r0

T0 T1 +eval r0

T +eval r (x, T1, r) +bind r0

let x be T1 in T +eval r0

(ans(A)) T2 +apply r (x, T1, r) +bind r0

(ans(let x be T1 in A)) T2 +apply r0

T [x0/x] +eval r (x0, T1, r) +bind r0

(ans(*x.T )) T1 +apply r0 where x0 is fresh

(ide(Eoi , x)) T1 +apply ide((\Lambda  T1) ffi Eoi, x)

(x, T1, ans(A)) +bind ans(let x be T1 in A)

T1 +eval r (x, Eoi, r) +force r0

(x, T1, ide(Eoi, x)) +bind r0

(x, T1, ide(Eoi, y)) +bind ide((let x be T1 in \Lambda ) ffi Eoi, y) where x 6= y

hEoi , V ioi *rec T T +eval r (x, V, r) +bind r0

(x, Eoi, ans(V )) +force r0

(x, Eoi , ans(A)) +force r (y, T1, r) +bind r0

(x, Eoi , ans(let y be T1 in A)) +force r0

(x, Eoi, ide(E0oi , y)) +force ide((let x be \Lambda  in Eoi[x]) ffi E0oi, y)

Fig. 5. Natural semantics

5.5 Back to direct style: from continuation-passing interpreterto natural semantics

It is a simple matter to transform the continuation-passing interpreter describedin Section 5.4 into direct style [8]. The continuations do not represent any control
effect other than non-tail calls, so the resulting direct-style interpreter does notrequire first-class control operators [11].

This interpreter implements a natural semantics (i.e., a big-step operationalsemantics) for lazy evaluation. This semantics is displayed in Figure 5.

Proposition 2 (full correctness). For any T ,

hT, "iterm !*run hAianswer , T +eval ans(A).

5.6 Refunctionalization: from natural semanticsto higher-order evaluation function

The natural semantics implementation of Section 5.5 is already in defunctional-ized form with respect to the first-order outside-in contexts. Indeed, as already
mentioned in Section 4.4, the recomposition function of Definition 3 and Figure 1is the corresponding apply function.

An outside-in context acts as an accumulator recording the path from avariable whose value is needed to its binding site. The recomposition function

12

eval(x) = ide(*r.r, x)
eval(*x.T ) = ans(*x.T )
eval(T0 T1) = apply(eval(T0), T1)
eval(let x be T1 in T ) = bind(x, T1, eval(T ))

apply(ans(*x.T ), T1) = bind(x0, T1, eval(T [x0/x])) where x0 is fresh
apply(ans(let x be T1 in A), T2) = bind(x, T1, apply(ans(A), T2))

apply(ide(h, x), T1) = ide(*r.apply(h @ r, T1), x)

bind(x, T1, ans(A)) = ans(let x be T1 in A)
bind(x, T1, ide(h, x)) = force(x, h, eval(T1))

bind(x, T1, ide(h, y)) = ide(*r.bind(x, T1, h @ r), y) where x 6= y

force(x, h, ans(V )) = bind(x, V, h @ (ans(V )))
force(x, h, ans(let y be T1 in A)) = bind(y, T1, force(x, h, ans(A)))

force(x, h, ide(h0, y)) = ide(*r.force(x, h, h0 @ r), y)

Fig. 6. Higher-order evaluation function
turns this accumulator inside-out again when the variable's value is found. Therefunctionalized outside-in contexts are functional representations of these accumulators.The resulting refunctionalized evaluation function is displayed in Figure 6.
Notationally, higher-order functions are introduced with * and eliminated with@, which is infix.

Proposition 3 (full correctness). For any T ,

T +eval ans(A) , eval(T ) = ans(A).
This higher-order evaluation function exhibits a computational pattern thatwe find striking because it also occurs in Cartwright and Felleisen's work on

extensible denotational language specifications [7]: each valuation function yieldseither a (left-injected with "ans") value or a (right-injected with "ide") higherorder function. For each call, this higher-order function may yield another right-injected higher-order function that, when applied, restores this current call. This
computational pattern is typical of delimited control: the left inject stands foran expected result, while the right inject acts as an exceptional return that
incrementally captures the current continuation. At any rate, this pattern wassubsequently re-invented by F"unfrocken to implement process migration [18, 32,
34], and then put to use to implement first-class continuations [25, 29]. In thepresent case, this pattern embodies two distinct computational aspects--one
intensional and the other extensional:

How: The computational pattern is one of delimited control, from the point ofuse of a let-bound identifier to its point of declaration.

What: The computational effect is one of a write-once state since once thedelimited context is captured, it is restored with the value of the let-bound

identifier.

13

These two aspects were instrumental in Cartwright and Felleisen's design of ex-tensible denotational semantics for (undelimited) Control Scheme and for State
Scheme [7]. For call by need, this control aspect was recently re-discovered byGarcia, Lumsdaine and Sabry [19], and this store aspect was originally envisioned by Landin [23]. These observations put us in position to write the evalua-tion function in direct style, either with delimited control operators (one control
delimiter for each let declaration, and one control abstraction for each occurrenceof a let-declared identifier whose value is needed [3]), or with a state monad. We
elaborate this point further in the extended version of this article.

6 Conclusion Semantics should be call by need.

- Rod Burstall
Over the years, the two key features of lazy evaluation - demand-driven com-putation and memoization of intermediate results - have elicited a fascinating

variety of semantic artifacts, each with its own originality and elegance. It isour overarching thesis that spelling out the methodical search for the next potential redex that is implicit in a reduction semantics paves the way towardsother semantic artifacts that not only are uniformly inter-derivable and sound
by construction but also correspond to what one crafts by hand. Elsewhere, wehave already shown that refocusing, etc. do not merely apply to purely syntactic
theories such as, e.g., Felleisen and Hieb's syntactic theories of sequential controland state [16,27]: the methodology also applies to call by need with a global heap
of memo-thunks [1, 5], and to graph reduction, connecting term graph rewritingsystems `a la Barendregt et al. and graph reduction machines `a la Turner [35].
Here, we have shown that the methodology also applies to Ariola et al.'s purelysyntactic account of call-by-need.

Acknowledgments: Thanks are due to the anonymous reviewers. We are alsograteful to Zena Ariola, Kenichi Asai, Ronald Garcia, Oleg Kiselyov, Kristoffer
Rose and Chung-chieh Shan for discussions and comments.

References

1. Mads Sig Ager, Olivier Danvy, and Jan Midtgaard. A functional correspondence

between call-by-need evaluators and lazy abstract machines. Information Processing Letters, 90(5):223-232, 2004.
2. Zena M. Ariola and Matthias Felleisen. The call-by-need lambda calculus. Journal

of Functional Programming, 7(3):265-301, 1997.
3. Vincent Balat, Roberto Di Cosmo, and Marcelo P. Fiore. Extensional normalisation

and type-directed partial evaluation for typed lambda calculus with sums. In
Xavier Leroy, editor, Proceedings of the Thirty-First Annual ACM Symposium on
Principles of Programming Languages, pages 64-76, Venice, Italy, January 2004.
ACM Press.
4. Henk Barendregt. The Lambda Calculus: Its Syntax and Semantics, volume 103

of Studies in Logic and the Foundation of Mathematics. North-Holland, revised
edition, 1984.

14

5. Malgorzata Biernacka and Olivier Danvy. A syntactic correspondence between

context-sensitive calculi and abstract machines. Theoretical Computer Science,
375(1-3):76-108, 2007.
6. Roel Bloo and Kristoffer Ho/gsbro Rose. Preservation of strong normalisation in

named lambda calculi with explicit substitution and garbage collection. In CSN-95:
Computer Science in the Netherlands, pages 62-72, 1995.
7. Robert Cartwright and Matthias Felleisen. Extensible denotational language specifications. In Masami Hagiya and John C. Mitchell, editors, Proceedings of the 1994
International Symposium on Theoretical Aspects of Computer Software, number
789 in Lecture Notes in Computer Science, pages 244-272, Sendai, Japan, April
1994. Springer.
8. Olivier Danvy. Back to direct style. Science of Computer Programming, 22(3):183-

195, 1994.
9. Olivier Danvy. Defunctionalized interpreters for programming languages. In Peter

Thiemann, editor, Proceedings of the 2008 ACM SIGPLAN International Conference on Functional Programming (ICFP'08), pages 131-142, Victoria, British
Columbia, September 2008. ACM Press. Invited talk.
10. Olivier Danvy. From reduction-based to reduction-free normalization. In Pieter

Koopman, Rinus Plasmeijer, and Doaitse Swierstra, editors, Advanced Functional
Programming, Sixth International School, number 5382 in Lecture Notes in Computer Science, pages 66-164, Nijmegen, The Netherlands, May 2008. Springer.
Lecture notes including 70+ exercises.
11. Olivier Danvy and Julia L. Lawall. Back to direct style II: First-class continuations.

In William Clinger, editor, Proceedings of the 1992 ACM Conference on Lisp and
Functional Programming, pages 299-310, San Francisco, California, June 1992.
ACM Press.
12. Olivier Danvy and Kevin Millikin. On the equivalence between small-step and

big-step abstract machines: a simple application of lightweight fusion. Information
Processing Letters, 106(3):100-109, 2008.
13. Olivier Danvy and Kevin Millikin. Refunctionalization at work. Science of Computer Programming, 74(8):534-549, 2009.
14. Olivier Danvy and Lasse R. Nielsen. Defunctionalization at work. In Harald

So/ndergaard, editor, Proceedings of the Third International ACM SIGPLAN Conference on Principles and Practice of Declarative Programming (PPDP'01), pages
162-174, Firenze, Italy, September 2001. ACM Press.
15. Olivier Danvy and Lasse R. Nielsen. Refocusing in reduction semantics. Research

Report BRICS RS-04-26, Department of Computer Science, Aarhus University,
Aarhus, Denmark, November 2004.
16. Matthias Felleisen and Robert Hieb. The revised report on the syntactic theories of

sequential control and state. Theoretical Computer Science, 103(2):235-271, 1992.
17. Daniel P. Friedman, Abdulaziz Ghuloum, Jeremy G. Siek, and Lynn Winebarger.

Improving the lazy Krivine machine. Higher-Order and Symbolic Computation,
20(3):271-293, 2007.
18. Stefan F"unfrocken. Transparent migration of Java-based mobile agents. In Kurt

Rothermel and Fritz Hohl, editors, Mobile Agents, Second International Workshop,
MA'98, Proceedings, volume 1477 of Lecture Notes in Computer Science, pages 26-
37, Stuttgart, Germany, September 1998. Springer.
19. Ronald Garcia, Andrew Lumsdaine, and Amr Sabry. Lazy evaluation and delimited control. In Benjamin C. Pierce, editor, Proceedings of the Thirty-Sixth Annual
ACM Symposium on Principles of Programming Languages, pages 153-164, Savannah, GA, January 2009. ACM Press.

15

20. Peter Henderson and James H. Morris Jr. A lazy evaluator. In Susan L. Graham, editor, Proceedings of the Third Annual ACM Symposium on Principles of
Programming Languages, pages 95-103. ACM Press, January 1976.
21. G'erard Huet. The zipper. Journal of Functional Programming, 7(5):549-554, 1997.
22. Mark B. Josephs. The semantics of lazy functional languages. Theoretical Computer Science, 68:105-111, 1989.
23. Peter J. Landin. The mechanical evaluation of expressions. The Computer Journal,

6(4):308-320, 1964.
24. John Launchbury. A natural semantics for lazy evaluation. In Susan L. Graham, editor, Proceedings of the Twentieth Annual ACM Symposium on Principles
of Programming Languages, pages 144-154, Charleston, South Carolina, January
1993. ACM Press.
25. Florian Loitsch. Scheme to JavaScript Compilation. PhD thesis, Universit'e de

Nice, Nice, France, March 2009.
26. John Maraist, Martin Odersky, and Philip Wadler. The call-by-need lambda calculus. Journal of Functional Programming, 8(3):275-317, 1998.
27. Johan Munk. A study of syntactic and semantic artifacts and its application to

lambda definability, strong normalization, and weak normalization in the presence
of state. Master's thesis, Department of Computer Science, Aarhus University,
Aarhus, Denmark, May 2007. BRICS research report RS-08-3.
28. Atsushi Ohori and Isao Sasano. Lightweight fusion by fixed point promotion. In

Matthias Felleisen, editor, Proceedings of the Thirty-Fourth Annual ACM Symposium on Principles of Programming Languages, pages 143-154, Nice, France,
January 2007. ACM Press.
29. Greg Pettyjohn, John Clements, Joe Marshall, Shriram Krishnamurthi, and

Matthias Felleisen. Continuations from generalized stack inspection. In Benjamin
Pierce, editor, Proceedings of the 2005 ACM SIGPLAN International Conference
on Functional Programming (ICFP'05), pages 216-227, Tallinn, Estonia, September 2005. ACM Press.
30. John C. Reynolds. Definitional interpreters for higher-order programming languages. In Proceedings of 25th ACM National Conference, pages 717-740, Boston,
Massachusetts, 1972. Reprinted in Higher-Order and Symbolic Computation
11(4):363-397, 1998, with a foreword [31].
31. John C. Reynolds. Definitional interpreters revisited. Higher-Order and Symbolic

Computation, 11(4):355-361, 1998.
32. Tatsurou Sekiguchi, Hidehiko Masuhara, and Akinori Yonezawa. A simple extension of Java language for controllable transparent migration and its portable
implementation. In Paolo Ciancarini and Alexander L. Wolf, editors, Coordination
Languages and Models, Third International Conference, COORDINATION '99,
Proceedings, volume 1594 of Lecture Notes in Computer Science, pages 211-226,
Amsterdam, The Netherlands, April 1999. Springer.
33. Peter Sestoft. Deriving a lazy abstract machine. Journal of Functional Programming, 7(3):231-264, May 1997.
34. Wei Tao. A portable mechanism for thread persistence and migration. PhD thesis,

University of Utah, Salt Lake City, Utah, 2001.
35. Ian Zerny. On graph rewriting, reduction and evaluation. In Zolt'an Horv'ath,

Vikt'oria Zs'ok, Peter Achten, and Pieter Koopman, editors, Trends in Functional
Programming Volume 10, Kom'arno, Slovakia, June 2009. Intellect Books. To appear.

To be presented at FLOPS 2010.

16