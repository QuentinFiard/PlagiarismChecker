

10 The Essence of ML Type Inference

Franc,ois Pottier and Didier Re'my

10.1 What Is ML?

The name ML appeared during the late seventies. It then referred to a general-
purpose programming language that was used as a meta-language (whence its
name) within the theorem prover LCF (Gordon, Milner, and Wadsworth, 1979).
Since then, several new programming languages, each of which offers several
different implementations, have drawn inspiration from it. So, what does ML
stand for today?

For a semanticist, ML might stand for a programming language featuring
first-class functions, data structures built out of products and sums, muta-
ble memory cells called references, exception handling, automatic memory
management, and a call-by-value semantics. This view encompasses the Stan-
dard ML (Milner, Tofte, and Harper, 1990) and Caml (Leroy, 2000) families of
programming languages. We refer to it as ML-the-programming-language.

For a type theorist, ML might stand for a particular breed of type systems,
based on the simply-typed *-calculus, but extended with a simple form of
polymorphism introduced by let declarations. These type systems have de-
cidable type inference; their type inference algorithms strongly rely on first-
order unification and can be made efficient in practice. Besides Standard ML
and Caml, this view encompasses programming languages such as Haskell
(Peyton Jones, 2003) and Clean (Brus, van Eekelen, van Leer, and Plasmeijer,
1987), whose semantics is rather different--indeed, it is nonstrict and pure
(Sabry, 1998)--but whose type system fits this description. We refer to it as
ML-the-type-system. It is also referred to as the Hindley-Milner type discipline
in the literature.

Code for this chapter may be found on the book's web site.

390 10 The Essence of ML Type Inference

For us, ML might also stand for the particular programming language whose
formal definition is given and studied in this chapter. It is a core calculus fea-
turing first-class functions, local definitions, and constants. It is equipped
with a call-by-value semantics. By customizing constants and their seman-
tics, one may recover data structures, references, and more. We refer to this
particular calculus as ML-the-calculus.

Why study ML-the-type-system today, such a long time after its initial dis-
covery? One may think of at least two reasons.

First, its treatment in the literature is often cursory, because it is consid-
ered either as a simple extension of the simply-typed *-calculus (TAPL, Chap-
ter 9) or as a subset of Girard and Reynolds' System F (TAPL, Chapter 23).
The former view is supported by the claim that local (let) definitions, which
distinguish ML-the-type-system from the simply-typed *-calculus, may be un-
derstood as a simple textual expansion facility. However, this view tells only
part of the story, because it fails to give an account of the principal types
property enjoyed by ML-the-type-system, leads to a naive type inference al-
gorithm whose time complexity is exponential not only in the worst case
but in the common case, and breaks down when the language is extended
with side effects, such as state or exceptions. The latter view is supported by
the fact that every type derivation within ML-the-type-system is also a valid
type derivation within an implicitly-typed variant of System F. Such a view is
correct but again fails to give an account of type inference for ML-the-type-
system, since type inference for System F is undecidable (Wells, 1999).

Second, existing accounts of type inference for ML-the-type-system (Milner,
1978; Damas and Milner, 1982; Tofte, 1988; Leroy, 1992; Lee and Yi, 1998;
Jones, 1999) often involve heavy manipulations of type substitutions. Such
a ubiquitous use of type substitutions is often quite obscure. Furthermore,
actual implementations of the type inference algorithm do not explicitly ma-
nipulate substitutions; instead, they extend a standard first-order unification
algorithm, where terms are updated in place as new equations are discovered
(Huet, 1976; Martelli and Montanari, 1982). Thus, it is hard to tell, from these
accounts, how to write an efficient type inference algorithm for ML-the-type-
system. Yet, in spite of the increasing speed of computers, efficiency remains
crucial when ML-the-type-system is extended with expensive features, such
as Objective Caml's object types (Re'my and Vouillon, 1998), variant types
(Garrigue, 1998), or polymorphic methods (Garrigue and Re'my, 1999).

Our emphasis on efficiency might come as a surprise, since type inference
for ML-the-type-system is known to be dexptime-complete (Kfoury, Tiuryn,
and Urzyczyn, 1990; Mairson, Kanellakis, and Mitchell, 1991). In practice,
however, most implementations of it behave well. This apparent contradic-
tion may be explained by observing that types usually remain small and

10.1 What Is ML? 391
that let constructs are never deeply nested towards the left. Indeed, un-
der the assumption that types have bounded size and that programs have
bounded "scheme depth," type inference may be performed in quasi-linear
time (McAllester, 2003). In ML-the-programming-language, algebraic data type
definitions allow complex data structures to be described by concise expres-
sions, such as "list X," which helps achieve the bounded-type-size property.

In fact, in such favorable circumstances, even an inefficient algorithm may
behave well. For instance, some deployed implementations of type inference
for ML-the-type-system contain sources of inefficiency (see remark 10.1.21
on page 404) and do not operate in quasi-linear time under the bounded-
type-size assumption. However, such implementations are put under greater
stress when types become larger, a situation that occurs in some programs
(Saha, Heintze, and Oliva, 1998) and also arises when large, transparent type
expressions are used instead of algebraic data types, as in Objective Caml's
object-oriented fragment (Re'my and Vouillon, 1998).

For these reasons, we believe it is worth giving an account of ML-the-type-
system that focuses on type inference and strives to be at once elegant and
faithful to an efficient implementation, such as Re'my's (1992a). In this presen-
tation, we forego type substitutions and instead put emphasis on constraints,
which offer a number of advantages.

First, constraints allow a modular presentation of type inference as the
combination of a constraint generator and a constraint solver, allowing sep-
arate reasoning about when a program is correct and how to check whether
it is correct. This perspective has long been standard in the setting of the
simply-typed *-calculus: see, for example, Wand (1987b) and TAPL, Chap-
ter 22. In the setting of ML-the-type-system, such a decomposition is pro-
vided by the reduction of typability problems to acyclic semi-unification prob-
lems (Henglein, 1993; Kfoury, Tiuryn, and Urzyczyn, 1994). This approach,
however, was apparently never used in production implementations of ML-
the-programming-language. An experimental extension of SML/NJ with poly-
morphic recursion (Emms and LeiSS, 1996) did reduce type inference to a
semi-unification problem. Semi-unification found applications in the closely
related area of program analysis; see, for example, Fa"hndrich, Rehof, and Das
(2000) and Birkedal and Tofte (2001). In this chapter, we give a constraint-
based description of a "classic" implementation of ML-the-type-system, which
is based on first-order unification and a mechanism for creating and instan-
tiating principal type schemes.

Second, it is often natural to define and implement the solver as a con-
straint rewriting system. The constraint language allows reasoning not only
about correctness--is every rewriting step meaning-preserving?--but also
about low-level implementation details, since constraints are the data struc-

392 10 The Essence of ML Type Inference

x, y ::= Identifiers:

z Variable
m Memory location
c Constant
t ::= Expressions:

x Identifier
*z.t Function
t t Application
let z = t in t Local definition
v, w ::= Values:

z Variable

m Memory location
*z.t Function
c v1 . . . vk Data

c 2 Q+ ^ k <= a(c)
c v1 . . . vk Partial application

c 2 Q- ^ k < a(c)
E ::= Evaluation Contexts:

[] Empty context
E t Left side of an application
v E Right side of an application
let z = E in t Local definition

Figure 10-1: Syntax of ML-the-calculus

tures manipulated throughout the type inference process. For instance, de-
scribing unification in terms of multi-equations allows reasoning about the
sharing of nodes in memory, which a substitution-based approach cannot
account for. Last, constraints are more general than type substitutions, and
allow smooth extensions of ML-the-type-system with recursive types, rows,
subtyping, and more. These arguments are developed, for example, in Jouan-
naud and Kirchner (1991).

Before delving into the details of this new presentation of ML-the-type-
system, it is worth recalling its standard definition. Thus, in what follows,
we first define the syntax and operational semantics of ML-the-calculus, and
equip it with a type system, known as Damas and Milner's type system.

ML-the-Calculus
The syntax of ML-the-calculus is defined in Figure 10-1. It is made up of sev-
eral syntactic categories.

Identifiers group several kinds of names that may be referenced in a pro-
gram: variables, memory locations, and constants. We let x and y range over
identifiers. Variables--also called program variables, to avoid ambiguity--are
names that may be bound to values using * or let binding forms; in other
words, they are names for function parameters or local definitions. We let
z and f range over program variables. We sometimes write for a program
variable that does not occur free within its scope: for instance, * .t stands for
*z.t, provided z is fresh for t. (We say that z is fresh for t when z does not oc-

10.1 What Is ML? 393
cur free in t.) Memory locations are names that represent memory addresses.
They are used to model references (see Example 10.1.9 below). Memory loca-
tions never appear in source programs, that is, programs that are submitted
to a compiler. They only appear during execution, when new memory blocks
are allocated. Constants are fixed names for primitive values and operations,
such as integer literals and integer arithmetic operations. Constants are el-
ements of a finite or infinite set Q. They are never subject to ff-conversion,
in contrast to variables and memory locations. Program variables, memory
locations, and constants belong to distinct syntactic classes and may never
be confused.

The set of constants Q is kept abstract, so most of our development is
independent of its concrete definition. We assume that every constant c has
a nonnegative integer arity a(c). We further assume that Q is partitioned into
subsets of constructors Q+ and destructors Q-. Constructors and destructors
differ in that the former are used to form values, while the latter are used to
operate on values.

10.1.1 Example [Integers]: For every integer n, one may introduce a nullary con-

structor ^n. In addition, one may introduce a binary destructor ^+, whose ap-
plications are written infix, so t1 ^+ t2 stands for the double application ^+ t1
t2 of the destructor ^+ to the expressions t1 and t2. 2

Expressions--also known as terms or programs--are the main syntactic cat-
egory. Indeed, unlike procedural languages such as C and Java, functional
languages, including ML-the-programming-language, suppress the distinction
between expressions and statements. Expressions consist of identifiers, *-
abstractions, applications, and local definitions. The *-abstraction *z.t repre-
sents the function of one parameter named z whose result is the expression t,
or, in other words, the function that maps z to t. Note that the variable z is
bound within the term t, so (for instance) the notations *z1.z1 and *z2.z2
denote the same entity. The application t1 t2 represents the result of calling
the function t1 with actual parameter t2, or, in other words, the result of
applying t1 to t2. Application is left-associative, that is, t1 t2 t3 stands for
(t1 t2) t3. The construct let z = t1 in t2 represents the result of evaluating
t2 after binding the variable z to t1. Note that the variable z is bound within
t2, but not within t1, so for instance let z1 = z1 in z1 and let z2 = z1 in z2
are the same object. The construct let z = t1 in t2 has the same meaning as
(*z.t2) t1, but is dealt with in a more flexible way by ML-the-type-system. To
sum up, the syntax of ML-the-calculus is that of the pure *-calculus, extended
with memory locations, constants, and the let construct.

Values form a subset of expressions. They are expressions whose evalua-
tion is completed. Values include identifiers, *-abstractions, and applications

394 10 The Essence of ML Type Inference

of constants, of the form c v1 . . . vk, where k does not exceed c's arity if c
is a constructor, and k is smaller than c's arity if c is a destructor. In what
follows, we are often interested in closed values--ones that do not contain
any free program variables. We use the meta-variables v and w for values.

10.1.2 Example: The integer literals . . . , d-1, ^0, ^1, . . . are nullary constructors, so they

are values. Integer addition ^+ is a binary destructor, so it is a value, and
so is every partial application ^+ v. Thus, both ^+ ^1 and ^+ ^+ are values. An
application of ^+ to two values, such as ^2^+^2, is not a value. 2

10.1.3 Example [Pairs]: Let (*, *) be a binary constructor. If t1 are t2 are expres-

sions, then the double application (*, *) t1 t2 may be called the pair of t1
and t2, and may be written (t1, t2). By the definition above, (t1, t2) is a value
if and only if t1 and t2 are both values. 2

Stores are finite mappings from memory locations to closed values. A store
u represents what is usually called a heap, that is, a collection of values,
each of which is allocated at a particular address in memory and may contain
pointers to other elements of the heap. ML-the-programming-language allows
overwriting the contents of an existing memory block--an operation some-
times referred to as a side effect. In the operational semantics, this effect is
achieved by mapping an existing memory location to a new value. We write IJ
for the empty store. We write u[m , v] for the store that maps m to v and
otherwise coincides with u. When u and u0 have disjoint domains, we write
uu0 for their union. We write dom(u) for the domain of u and range(u) for
the set of memory locations that appear in its codomain.

The operational semantics of a pure language like the *-calculus may be
defined as a rewriting system on expressions. Because ML-the-calculus has
side effects, however, we define its operational semantics as a rewriting sys-
tem on configurations. A configuration t/u is a pair of an expression t and a
store u. The memory locations in the domain of u are not considered bound
within t/u, so, for instance, m1/(m1 , ^0) and m2/(m2 , ^0) denote distinct
entities. (In the literature, memory locations are often considered bound in-
side configurations. This offers the advantage of making memory allocation a
deterministic operation. However, there is still a need for non-ff-convertible
configurations: rules R-Extend and R-Context in Figure 10-2 cannot other-
wise be correctly stated! Quite a few papers run into this pitfall.)

A configuration t/u is closed if and only if t has no free program variables
and every memory location that appears within t or within the range of u is in
the domain of u. If t is a closed source program, its evaluation begins within
an empty store--that is, with the configuration t/IJ. Because source programs
do not contain memory locations, this configuration is closed. Furthermore,
we shall see that closed configurations are preserved by reduction.

10.1 What Is ML? 395
(*z.t) v -! [z , v]t (R-Beta)
let z = v in t -! [z , v]t (R-Let)

t/u ffi-! t0/u0

t/u -! t0/u0 (R-Delta)

t/u -! t0/u0
dom(u00) # dom(u0)
range(u00) # dom(u0 \ u)

t/uu00 -! t0/u0u00 (R-Extend)

t/u -! t0/u0
E[t]/u --n~ E[t0]/u0 (R-Context)

Figure 10-2: Semantics of ML-the-calculus

Note that, instead of separating expressions and stores, it is possible to
make store fragments part of the syntax of expressions; this idea, proposed in
Crank and Felleisen (1991), has also been used for the encoding of reference
cells in process calculi.

A context is an expression where a single subexpression has been replaced
with a hole, written []. Evaluation contexts form a strict subset of contexts. In
an evaluation context, the hole is meant to highlight a point in the program
where it is valid to apply a reduction rule. Thus, the definition of evaluation
contexts determines a reduction strategy: it tells where and in what order
reduction steps may occur. For instance, the fact that *z.[] is not an evalu-
ation context means that the body of a function is never evaluated--that is,
not until the function is applied. The fact that t E is an evaluation context
only if t is a value means that, to evaluate an application t1 t2, one should
fully evaluate t1 before attempting to evaluate t2. More generally, in the case
of a multiple application, it means that arguments should be evaluated from
left to right. Of course, other choices could be made: for instance, defining
E ::= . . . | t E | E v | . . . would enforce a right-to-left evaluation order, while
defining E ::= . . . | t E | E t | . . . would leave the evaluation order unspeci-
fied, effectively allowing reduction to alternate between both subexpressions,
and making evaluation nondeterministic (because side effects could occur in
different order). The fact that let z = v in E is not an evaluation context
means that the body of a local definition is never evaluated--that is, not until
the definition itself is reduced. We write E[t] for the expression obtained by
replacing the hole in E with the expression t.

Figure 10-2 defines first a relation -! between arbitrary configurations,
then a relation --n~ between closed configurations. If t/u -! t0/u holds for
every store u, then we write t -! t0 and say that the reduction is pure.

The semantics need not be deterministic. That is, a configuration may re-
duce to two different configurations. In fact, our semantics is deterministic

396 10 The Essence of ML Type Inference

only if the relation ffi-!, which is a parameter to our semantics, is itself de-
terministic. In practice, ffi-! is usually deterministic, up to ff-conversion of
memory locations. As explained above, the semantics could also be made
nondeterministic by a different choice in the definition of evaluation contexts.

The key reduction rule is R-Beta, which states that a function application
(*z.t) v reduces to the function body, namely t, where every occurrence of
the formal argument z has been replaced with the actual argument v. The *
construct, which prevented the function body t from being evaluated, disap-
pears, so the new term may (in general) be further reduced. Because ML-the-
calculus adopts a call-by-value strategy, rule R-Beta is applicable only if the
actual argument is a value v. In other words, a function cannot be invoked un-
til its actual argument has been fully evaluated. Rule R-Let is very similar to
R-Beta. Indeed, it specifies that let z = v in t has the same behavior, with re-
spect to reduction, as (*z.t) v. Substitution of a value for a program variable
throughout a term is expensive, so R-Beta and R-Let are never implemented
literally: they are only a simple specification. Actual implementations usually
employ runtime environments, which may be understood as a form of explicit
substitutions (Abadi, Cardelli, Curien, and Le'vy, 1991; Hardin, Maranget, and
Pagano, 1998). Note that our choice of a call-by-value reduction strategy has
essentially no impact on the type system; the programming language Haskell,
whose reduction strategy is known as lazy or call-by-need, also relies on the
Hindley-Milner type discipline.

Rule R-Delta describes the semantics of constants. It states that a certain
relation ffi-! is a subset of -!. Of course, since the set of constants is un-

specified, the relation ffi-! must be kept abstract as well. We require that, if
t/u ffi-! t0/u0 holds, then

(i) t is of the form c v1 . . . vn, where c is a destructor of arity n; and
(ii) dom(u) is a subset of dom(u0).
Condition (i) ensures that ffi-reduction concerns full applications of destruc-
tors only, and that these are evaluated in accordance with the call-by-value
strategy. Condition (ii) ensures that ffi-reduction may allocate new memory
locations, but not deallocate existing locations. In particular, a "garbage col-
lection" operator, which destroys unreachable memory cells, cannot be made
available as a constant. Doing so would not make much sense anyway in the
presence of R-Extend. Condition (ii) allows proving that, if t/u reduces (by

-!) to t0/u0, then dom(u) is also a subset of dom(u0); checking this is left as
an exercise to the reader.

Rule R-Extend states that any valid reduction is also valid in a larger store.
The initial and final stores u and u0 in the original reduction are both ex-

10.1 What Is ML? 397
tended with a new store fragment u00. The rule's second premise requires that
the domain of u00 be disjoint with that of u0 (and consequently, also with that
of u), so that the new memory locations are indeed undefined in the original
reduction. (They may, however, appear in the image of u.) The last premise
ensures that the new memory locations in u00 do not accidentally carry the
same names as the locations allocated during the original reduction step, that
is, the locations in dom(u0 \ u). The notation A # B stands for A " B = IJ.

Rule R-Context completes the definition of the operational semantics by
defining --n~, a relation between closed configurations, in terms of -!. The
rule states that reduction may take place not only at the term's root, but also
deep inside it, provided the path from the root to the point where reduction
occurs forms an evaluation context. This is how evaluation contexts deter-
mine an evaluation strategy. As a purely technical point, because --n~ relates
closed configurations only, we do not need to require that the memory lo-
cations in dom(u0 \ u) be fresh for E; indeed, every memory location that
appears within E must be a member of dom(u).

10.1.4 Example [Integers, continued]: The operational semantics of integer addi-

tion may be defined as follows:

^k1 ^+ ^k2 ffi-! "k1 + k2 (R-Add)

The left-hand term is the double application ^+ ^k1 ^k2, while the right-hand
term is the integer literal ^k, where k is the sum of k1 and k2. The distinction
between object level and meta level (that is, between ^k and k) is needed here
to avoid ambiguity. 2

10.1.5 Example [Pairs, continued]: In addition to the pair constructor defined in

Example 10.1.3, we may introduce two destructors ss1 and ss2 of arity 1. We
may define their operational semantics as follows, for i 2 {1, 2}:

ssi (v1, v2) ffi-! vi (R-Proj)
Thus, our treatment of constants is general enough to account for pair con-
struction and destruction; we need not build these features explicitly into the
language. 2

10.1.6 Exercise [Booleans, Recommended, n'n', 3]: Let true and false be nullary

constructors. Let if be a ternary destructor. Extend the semantics with

if true v1 v2 ffi-! v1 (R-True)

if false v1 v2 ffi-! v2 (R-False)
Let us use the syntactic sugar if t0 then t1 else t2 for the triple applica-
tion of if t0 t1 t2. Explain why these definitions do not quite provide the
expected behavior. Without modifying the semantics of if, suggest a new

398 10 The Essence of ML Type Inference

definition of the syntactic sugar if t0 then t1 else t2 that corrects the
problem. 2

10.1.7 Example [Sums]: Booleans may in fact be viewed as a special case of the more

general concept of sum. Let inj1 and inj2 be unary constructors, called re-
spectively left and right injections. Let case be a ternary destructor, whose
semantics is defined as follows, for i 2 {1, 2}:

case (inji v) v1 v2 ffi-! vi v (R-Case)
Here, the value inji v is being scrutinized, while the values v1 and v2, which
are typically functions, represent the two arms of a standard case construct.
The rule selects an appropriate arm (here, vi) based on whether the value un-
der scrutiny was formed using a left or right injection. The arm vi is executed
and given access to the data carried by the injection (here, v). 2

10.1.8 Exercise [n', 3]: Explain how to encode true, false, and the if construct

in terms of sums. Check that the behavior of R-True and R-False is properly
emulated. 2

10.1.9 Example [References]: Let ref and ! be unary destructors. Let := be a binary

destructor. We write t1 := t2 for the double application := t1 t2. Define the
operational semantics of these three destructors as follows:

ref v/IJ ffi-! m/(m , v) if m is fresh for v (R-Ref)

!m/(m , v) ffi-! v/(m , v) (R-Deref)
m := v/(m , v0) ffi-! v/(m , v) (R-Assign)
According to R-Ref, evaluating ref v allocates a fresh memory location m and
binds v to it. The name m must be chosen fresh for v to prevent inadvertent
capture of the memory locations that appear free within v. By R-Deref, evalu-
ating !m returns the value bound to the memory location m within the current
store. By R-Assign, evaluating m := v discards the value v0 currently bound to
m and produces a new store where m is bound to v. Here, the value returned
by the assignment m := v is v itself; in ML-the-programming-language, it is
usually a nullary constructor (), pronounced unit. 2

10.1.10 Example [Recursion]: Let fix be a binary destructor, whose operational se-

mantics is:

fix v1 v2 ffi-! v1 (fix v1) v2 (R-Fix)
fix is a fixpoint combinator: it effectively allows recursive definitions of
functions. Indeed, the construct letrec f = *z.t1 in t2 provided by ML-
the-programming-language may be viewed as syntactic sugar for let f =
fix (*f.*z.t1) in t2. 2

10.1 What Is ML? 399
10.1.11 Exercise [Recommended, n'n', 3]: Assuming the availability of Booleans and

conditionals, integer literals, subtraction, multiplication, integer comparison,
and a fixpoint combinator, most of which were defined in previous exam-
ples, define a function that computes the factorial of its integer argument,
and apply it to ^3. Determine, step by step, how this expression reduces to a
value. 2

It is straightforward to check that, if t/u reduces to t0/u0, then t is not a
value. In other words, values are irreducible: they represent completed com-
putations. The proof is left as an exercise to the reader. The converse, how-
ever, does not hold: if the closed configuration t/u is irreducible with respect
to --n~, then t is not necessarily a value. In that case, the configuration t/u is
said to be stuck. It represents a runtime error, that is, a situation that does not
allow computation to proceed, yet is not considered a valid outcome. A closed
source program t is said to go wrong if and only if the initial configuration
t/IJ reduces to a stuck configuration.

10.1.12 Example: Runtime errors typically arise when destructors are applied to ar-

guments of an unexpected nature. For instance, the expressions ^+ ^1 m and
ss1 ^2 and !^3 are stuck, regardless of the current store. The program let z =

^+ ^+ in z 1 is not stuck, because ^+ ^+ is a value. However, its reduct through
R-Let is ^+ ^+ 1, which is stuck, so this program goes wrong. The primary
purpose of type systems is to prevent such situations from arising. 2

10.1.13 Remark: The configuration !m/u is stuck if m is not in the domain of u. In

that case, however, !m/u is not closed. Because we consider --n~ as a rela-
tion between closed configurations only, this situation cannot arise. In other
words, the semantics of ML-the-calculus never allows the creation of dan-
gling pointers. As a result, no particular precautions need be taken to guard
against them. Several strongly typed programming languages do neverthe-
less allow dangling pointers in a controlled fashion (Tofte and Talpin, 1997;
Walker, Crary, and Morrisett, 2000; DeLine and Fa"hndrich, 2001; Grossman,
Morrisett, Jim, Hicks, Wang, and Cheney, 2002). 2

Damas and Milner's Type System
ML-the-type-system was originally defined by Milner (1978). Here, we repro-
duce the definition given a few years later by Damas and Milner (1982), which
is written in a more standard style: typing judgments are defined inductively
by a collection of typing rules. We refer to this type system as DM.

We must first define types. In DM, types are terms built out of type con-
structors and type variables. Furthermore, they are first-order terms: that is,

400 10 The Essence of ML Type Inference

in the grammar of types, none of the productions binds a type variable. This
situation is identical to that of the simply-typed *-calculus.

We begin with several considerations concerning the specification of type
constructors.

First, we do not wish to fix the set of type constructors. Certainly, since
ML-the-calculus has functions, we need to be able to form an arrow type
T ! T0 out of arbitrary types T and T0; that is, we need a binary type con-
structor !. However, because ML-the-calculus includes an unspecified set of
constants, we cannot say much else in general. If constants include integer
literals and integer operations, as in Example 10.1.1, then a nullary type con-
structor int is needed; if they include pair construction and destruction, as in
Examples 10.1.3 and 10.1.5, then a binary type constructor * is needed; etc.

Second, it is common to refer to the parameters of a type constructor by
position, that is, by numeric index. For instance, when one writes T ! T0, it
is understood that the type constructor ! has arity 2, that T is its first pa-
rameter, known as its domain, and that T0 is its second parameter, known as
its codomain. Here, however, we refer to parameters by names, known as di-
rections. For instance, we define two directions domain and codomain and let
the type constructor ! have arity {domain, codomain}. The extra generality
afforded by directions is exploited in the definition of nonstructural subtyp-
ing (Example 10.2.9) and in the definition of rows ($10.8).

Last, we allow types to be classified using kinds. As a result, every type
constructor must come not only with an arity, but with a richer signature,
which describes the kinds of the types to which it is applicable and the
kind of the type that it produces. A distinguished kind ? is associated with
"normal" types, that is, types that are directly ascribed to expressions and
values. For instance, the signature of the type constructor ! is {domain ,
?, codomain , ?} ) ?, because it is applicable to two normal types and
produces a normal type. Introducing kinds other than ? allows viewing some
types as ill-formed: this is illustrated, for instance, in $10.8. In the simplest
case, however, ? is really the only kind, so the signature of a type constructor
is nothing but its arity (a set of directions), and every term is a well-formed
type, provided every application of a type constructor respects its arity.

10.1.14 Definition: Let d range over a finite or denumerable set of directions and ^

over a finite or denumerable set of kinds. Let ? be a distinguished kind. Let K
range over partial mappings from directions to kinds. Let F range over a finite
or denumerable set of type constructors, each of which has a signature of the
form K ) ^. The domain of K is called the arity of F, while ^ is referred to
as its image kind. We write ^ instead of K ) ^ when K is empty. Let ! be a
type constructor of signature {domain , ?, codomain , ?} ) ?. 2

10.1 What Is ML? 401

The type constructors and their signatures collectively form a signature S.
In the following, we assume that a fixed signature S is given and that every
type constructor in it has finite arity, so as to ensure that types are machine
representable. However, in $10.8, we shall explicitly work with several distinct
signatures, one of which involves type constructors of denumerable arity.

A type variable is a name that is used to stand for a type. For simplicity,
we assume that every type variable is branded with a kind, or in other words,
that type variables of distinct kinds are drawn from disjoint sets. Each of
these sets of type variables is individually subject to ff-conversion: that is,
renamings must preserve kinds. Attaching kinds to type variables is only a
technical convenience; in practice, every operation performed during type
inference preserves the property that every type is well-kinded, so it is not
necessary to keep track of the kind of every type variable. It is only necessary
to check that all types supplied by the programmer, within type declarations,
type annotations, or module interfaces, are well-kinded.

10.1.15 Definition: For every kind ^, let V^ be a disjoint, denumerable set of type

variables. Let X, Y, and Z range over the set V of all type variables. Let _X and
_Y range over finite sets of type variables. We write _X_Y for the set _X [ _Y and

often write X for the singleton set {X}. We write ftv(o) for the set of free type
variables of an object o. 2

The set of types, ranged over by T, is the free many-kinded term algebra
that arises out of the type constructors and type variables. Types are given
by the following inductive definition:

10.1.16 Definition: A type of kind ^ is either a member of V^, or a term of the form

F {d1 , T1, . . . , dn , Tn}, where F has signature {d1 , ^1, . . . , dn , ^n} ) ^
and T1, . . . , Tn are types of kind ^1, . . . , ^n, respectively. 2

As a notational convention, we assume that, for every type constructor F,
the directions that form the arity of F are implicitly ordered, so that we may
say that F has signature ^1 \Omega  . . . \Omega  ^n ) ^ and employ the syntax F T1 . . . Tn
for applications of F. Applications of the type constructor ! are written infix
and associate to the right, so T ! T0 ! T00 stands for T ! (T0 ! T00).

In order to give meaning to the free type variables of a type, or more gen-
erally, of a typing judgment, traditional presentations of ML-the-type-system,
including Damas and Milner's, employ type substitutions. Most of our pre-
sentation avoids substitutions and uses constraints instead. However, we do
need substitutions on a few occasions, especially when relating our presenta-
tion to Damas and Milner's.

10.1.17 Definition: A type substitution ` is a total, kind-preserving mapping of type

variables to types that is the identity everywhere but on a finite subset of V ,

402 10 The Essence of ML Type Inference

which we call the domain of ` and write dom(`). The range of `, which we
write range(`), is the set ftv(`(dom(`))). A type substitution may naturally
be viewed as a total, kind-preserving mapping of types to types. 2

If ~X and ~T are respectively a vector of distinct type variables and a vector
of types of the same (finite) length such that, for every index i, Xi and Ti
have the same kind, then [~X , ~T] denotes the substitution that maps Xi to
Ti for every index i and is the identity elsewhere. The domain of [~X , ~T] is
a subset of _X, the set underlying the vector ~X. Its range is a subset of ftv(_T),
where _T is the set underlying the vector ~T. (These may be strict subsets; for
instance, the domain of [X , X] is the empty set, since this substitution is the
identity.) Every substitution ` may be written under the form [~X , ~T], where
_X = dom(`). Then, ` is idempotent if and only if _X # ftv(_T) holds.

As pointed out earlier, types are first-order terms. As a result, every type
variable that appears within a type T appears free within T. Things become
more interesting when we introduce type schemes. As its name implies, a
type scheme may describe an entire family of types; this effect is achieved via
universal quantification over a set of type variables.

10.1.18 Definition: A type scheme S is an object of the form 8_X.T, where T is a type

of kind ? and the type variables _X are considered bound within T. Any type
of the form [~X , ~T]T is called an instance of the type scheme 8_X.T. 2

One may view the type T as the trivial type scheme 8IJ.T, where no type vari-
ables are universally quantified, so types of kind ? may be viewed as a subset
of type schemes. The type scheme 8_X.T may be viewed as a finite way of
describing the possibly infinite family of its instances. Note that, throughout
most of this chapter, we work with constrained type schemes, a generalization
of DM type schemes (Definition 10.2.2).

Typing environments, or environments for short, are used to collect as-
sumptions about an expression's free identifiers.

10.1.19 Definition: An environment \Gamma  is a finite ordered sequence of pairs of a pro-

gram identifier and a type scheme. We write IJ for the empty environment and
";" for the concatenation of environments. An environment may be viewed as
a finite mapping from program identifiers to type schemes by letting \Gamma  (x) = S
if and only if \Gamma  is of the form \Gamma 1; x : S; \Gamma 2, where \Gamma 2 contains no assumption
about x. The set of defined program identifiers of an environment \Gamma  , written
dpi(\Gamma  ), is defined by dpi(IJ) = IJ and dpi(\Gamma  ; x : S) = dpi(\Gamma  ) [ {x}. 2

To complete the definition of Damas and Milner's type system, there re-
mains to define typing judgments. A typing judgment takes the form \Gamma  ` t : S,
where t is an expression of interest, \Gamma  is an environment, which typically con-
tains assumptions about t's free program identifiers, and S is a type scheme.

10.1 What Is ML? 403
\Gamma  (x) = S

\Gamma  ` x : S (dm-Var)
\Gamma  ; z : T ` t : T0
\Gamma  ` *z.t : T ! T0 (dm-Abs)
\Gamma  ` t1 : T ! T0 \Gamma  ` t2 : T

\Gamma  ` t1 t2 : T0 (dm-App)

\Gamma  ` t1 : S \Gamma  ; z : S ` t2 : T

\Gamma  ` let z = t1 in t2 : T (dm-Let)

\Gamma  ` t : T _X # ftv(\Gamma  )

\Gamma  ` t : 8_X.T (dm-Gen)
\Gamma  ` t : 8_X.T
\Gamma  ` t : [~X , ~T]T (dm-Inst)

Figure 10-3: Typing rules for DM

Such a judgment may be read: under assumptions \Gamma  , the expression t has the
type scheme S. By abuse of language, it is sometimes said that t has type S.
A typing judgment is valid (or holds) if and only if it may be derived using
the rules that appear in Figure 10-3. An expression t is well-typed within the
environment \Gamma  if and only if there exists some type scheme S such that the
judgment \Gamma  ` t : S holds; it is ill-typed within \Gamma  otherwise.

Rule dm-Var allows fetching a type scheme for an identifier x from the
environment. It is equally applicable to program variables, memory locations,
and constants. If no assumption concerning x appears in the environment
\Gamma  , then the rule isn't applicable. In that case, the expression x is ill-typed
within \Gamma  . Assumptions about constants are usually collected in a so-called ini-
tial environment \Gamma 0. It is the environment under which closed programs are
typechecked, so every subexpression is typechecked under some extension \Gamma 
of \Gamma 0. Of course, the type schemes assigned by \Gamma 0 to constants must be con-
sistent with their operational semantics; we say more about this later ($10.5).
Rule dm-Abs specifies how to typecheck a *-abstraction *z.t. Its premise re-
quires the body of the function, t, to be well-typed under an extra assumption
that causes all free occurrences of z within t to receive a common type T. Its
conclusion forms the arrow type T ! T0 out of the types of the function's
formal parameter, T, and result, T0. It is worth noting that this rule always
augments the environment with a type T--recall that, by convention, types
form a subset of type schemes--but never with a nontrivial type scheme.
Rule dm-App states that the type of a function application is the codomain
of the function's type, provided that the domain of the function's type is a
valid type for the actual argument. Rule dm-Let closely mirrors the opera-
tional semantics: whereas the semantics of the local definition let z = t1
in t2 is to augment the runtime environment by binding z to the value of
t1 prior to evaluating t2, the effect of dm-Let is to augment the typing envi-

404 10 The Essence of ML Type Inference

ronment by binding z to a type scheme for t1 prior to typechecking t2. Rule
dm-Gen turns a type into a type scheme by universally quantifying over a set
of type variables that do not appear free in the environment; this restriction
is discussed in Example 10.1.20 below. Rule dm-Inst, on the contrary, turns a
type scheme into one of its instances, which may be chosen arbitrarily. These
two operations are referred to as generalization and instantiation. The no-
tion of type scheme and the rules dm-Gen and dm-Inst are characteristic of
ML-the-type-system: they distinguish it from the simply-typed *-calculus.

10.1.20 Example: It is unsound to allow generalizing type variables that appear free

in the environment. For instance, consider the typing judgment z : X ` z :
X (1), which, according to dm-Var, is valid. Applying an unrestricted version
of dm-Gen to it, we obtain z : X ` z : 8X.X (2), whence, by dm-Inst, z : X `
z : Y (3). By dm-Abs and dm-Gen, we then have IJ ` *z.z : 8XY.X ! Y. In
other words, the identity function has unrelated argument and result types!
Then, the expression (*z.z) ^0 ^0, which reduces to the stuck expression ^0 ^0,
has type scheme 8Z.Z. So, well-typed programs may cause runtime errors:
the type system is unsound.

What happened? It is clear that the judgment (1) is correct only because
the type assigned to z is the same in its assumption and in its right-hand
side. For the same reason, the judgments (2) and (3)--the former of which
may be written z : X ` z : 8Y.Y--are incorrect. Indeed, such judgments defeat
the very purpose of environments, since they disregard their assumption.
By universally quantifying over X in the right-hand side only, we break the
connection between occurrences of X in the assumption, which remain free,
and occurrences in the right-hand side, which become bound. This is correct
only if there are in fact no free occurrences of X in the assumption. 2

10.1.21 Remark: A naive implementation of dm-Gen would traverse the environment

\Gamma  in order to compute the set of its free type variables. However, the num-
ber of entries in \Gamma  may be linear in the program size, so, even if types have
bounded size, the time required by this computation may be linear in the
program size. Since it is performed at every let node, this naive approach
gives type inference quadratic time complexity. To avoid this pitfall, our con-
straint solver annotates every type variable with an integer rank, which allows
telling, in constant time, whether it appears free in \Gamma  (page 444). 2

It is a key feature of ML-the-type-system that dm-Abs may only introduce a
type T, rather than a type scheme, into the environment. Indeed, this allows
the rule's conclusion to form the arrow type T ! T0. If instead the rule were
to introduce the assumption z : S into the environment, then its conclusion
would have to form S ! T0, which is not a well-formed type. In other words,

10.1 What Is ML? 405
this restriction is necessary to preserve the stratification between types and
type schemes. If we were to remove this stratification, thus allowing univer-
sal quantifiers to appear deep inside types, we would obtain an implicitly-
typed version of System F (TAPL, Chapter 23). Type inference for System F
is undecidable (Wells, 1999), while type inference for ML-the-type-system is
decidable, as we show later, so this design choice has a rather drastic impact.

10.1.22 Exercise [Recommended, n']: Build a type derivation for the expression *z1.

let z2 = z1 in z2. 2

10.1.23 Exercise [Recommended, n']: Let int be a nullary type constructor of signa-

ture ?. Let \Gamma 0 consist of the bindings ^+ : int ! int ! int and ^k : int, for every
integer k. Can you find derivations of the following valid typing judgments?
Which of these judgments are valid in the simply-typed *-calculus, where
let z = t1 in t2 is syntactic sugar for (*z.t2) t1?

\Gamma 0 ` *z.z : int ! int
\Gamma 0 ` *z.z : 8X.X ! X
\Gamma 0 ` let f = *z.z^+^1 in f ^2 : int

\Gamma 0 ` let f = *z.z in f f ^2 : int

Show that the expressions ^1 ^2 and *f.(f f) are ill-typed within \Gamma 0. Could these
expressions be well-typed in a more powerful type system? 2

DM enjoys a number of nice theoretical properties, which have practical
implications.

First, it is sound: that is, well-typed programs do not go wrong. This essen-
tial property ensures that programs that are accepted by the typechecker may
be compiled without runtime checks. Establishing this property requires (i)
suitable hypotheses about the semantics of constants and the type schemes
assigned to constants in the initial environment, and (ii) in the presence of
side effects, a slight restriction of the syntax of let constructs, known as the
value restriction.

Furthermore, there exists an algorithm that, given a (closed) environment \Gamma 
and a program t, tells whether t is well-typed with respect to \Gamma  , and if so, pro-
duces a principal type scheme S. A principal type scheme is such that (i) it is
valid, that is, \Gamma  ` t : S holds, and (ii) it is most general, that is, every judgment
of the form \Gamma  ` t : S0 follows from \Gamma  ` t : S by dm-Inst and dm-Gen. (For the
sake of simplicity, we have stated the properties of the type inference algo-
rithm only in the case of a closed environment \Gamma  ; the specification is slightly
heavier in the general case.) This implies that type inference is decidable: the
compiler need not require expressions to be annotated with types. The fact
that, under a fixed environment \Gamma  , all of the type information associated with

406 10 The Essence of ML Type Inference

an expression t may be summarized in the form of a single, principal type
scheme is also key to modular programming. Indeed, exporting a value out
of a module requires explicitly assigning a type scheme to it as part of the
module's signature. If the chosen type scheme is not principal, then part of
the value's (hence, of the module's) potential for reuse is lost.

Road Map
Before proving the above claims, we first generalize our presentation by mov-
ing to a constraint-based setting. The necessary tools--the constraint lan-
guage, its interpretation, and a number of constraint equivalence laws--are
introduced in $10.2. In $10.3, we describe the standard constraint-based type
system HM(X) (Odersky, Sulzmann, and Wehr, 1999). We prove that, when
constraints are made up of equations between free, finite terms, HM(X) is
a reformulation of DM. In the presence of a more powerful constraint lan-
guage, HM(X) is an extension of DM. In $10.4, we show that type inference
may be viewed as a combination of constraint generation and constraint solv-
ing, as promised earlier. Then, in $10.5, we give a type soundness theorem. It
is stated purely in terms of constraints, but--thanks to the results developed
in the previous sections--applies equally to HM(X) and DM.

Throughout this core material, the syntax and interpretation of constraints
are left partly unspecified. Thus, the development is parameterized with re-
spect to them--hence the unknown X in the name HM(X). We really describe
a family of constraint-based type systems, all of which share a common con-
straint generator and a common type soundness proof. Constraint solving,
however, cannot be independent of X: on the contrary, the design of an ef-
ficient solver is heavily dependent on the syntax and interpretation of con-
straints. In $10.6, we consider constraint solving in the particular case where
constraints are made up of equations interpreted in a free tree model, and
define a constraint solver on top of a standard first-order unification algo-
rithm.

The remainder of this chapter deals with extensions of the framework. In

$10.7, we explain how to extend ML-the-calculus with a number of features,
including products, sums, references, recursion, algebraic data types, and re-
cursive types. Last, in $10.8, we extend the type language with rows and use
them to assign polymorphic type schemes to operations on records and vari-
ants.

10.2 Constraints 407
oe ::= type scheme:

8_X[C].T
C, D ::= constraint:

true truth
false falsity
P T1 . . . Tn predicate application
C ^ C conjunction
9_X.C existential quantification
def x : oe in C type scheme introduction
x _ T type scheme instantiation

C, D ::= Syntactic sugar for constraints:

. . . As before
oe _ T Definition 10.2.3
let x : oe in C Definition 10.2.3
9oe Definition 10.2.3
def \Gamma  in C Definition 10.2.4
let \Gamma  in C Definition 10.2.4
9\Gamma  Definition 10.2.4

Figure 10-4: Syntax of type schemes and constraints

10.2 Constraints

In this section, we define the syntax and logical meaning of constraints. Both
are partly unspecified. Indeed, the set of type constructors (Definition 10.1.14)
must contain at least the binary type constructor !, but might contain more.
Similarly, the syntax of constraints involves a set of so-called predicates on
types, which we require to contain at least a binary subtyping predicate <=, but
might contain more. (The introduction of subtyping, which is absent in DM,
has little impact on the complexity of our proofs, yet increases the frame-
work's expressive power. When subtyping is not desired, we interpret the
predicate <= as equality.) The logical interpretation of type constructors and
of predicates is left almost entirely unspecified. This freedom allows reason-
ing not only about Damas and Milner's type system, but also about a family
of constraint-based extensions of it.

Syntax of Constraints
We now define the syntax of constrained type schemes and of constraints and
introduce some extra constraint forms as syntactic sugar.

10.2.1 Definition: Let P range over a finite or denumerable set of predicates, each

of which has a signature of the form ^1 \Omega  . . . \Omega  ^n ) *, where n >= 0. For every
kind ^, let =^ and <=^ be distinguished predicates of signature ^ \Omega  ^ ) *. 2

10.2.2 Definition: The syntax of type schemes and constraints is given in Figure 10-4.

It is further restricted by the following requirements. In the type scheme
8_X[C].T and in the constraint x _ T, the type T must have kind ?. In the con-

408 10 The Essence of ML Type Inference

straint P T1 . . . Tn, the types T1, . . . , Tn must have kind ^1, . . . , ^n, respectively,
if P has signature ^1 \Omega . . .\Omega ^n ) *. We write 8_X.T for 8_X[true].T, which allows
viewing DM type schemes as a subset of constrained type schemes. 2

We write T1 =^ T2 and T1 <=^ T2 for the binary predicate applications =^ T1 T2
and <=^ T1 T2, and refer to them as equality and subtyping constraints, respec-
tively. We often omit the subscript ^, so T1 = T2 and T1 <= T2 are well-formed
constraints whenever T1 and T2 have the same kind. By convention, 9 and def
bind tighter than ^; that is, 9_X.C ^ D is (9_X.C) ^ D and def x : oe in C ^ D
is (def x : oe in C) ^ D. In 8_X[C].T, the type variables _X are bound within
C and T. In 9_X.C, the type variables _X are bound within C. The sets of free
type variables of a type scheme oe and of a constraint C, written ftv(oe ) and
ftv(C), respectively, are defined accordingly. In def x : oe in C, the identifier
x is bound within C. The sets of free program identifiers of a type scheme
oe and of a constraint C, written fpi(oe ) and fpi(C), respectively, are defined
accordingly. Note that x occurs free in the constraint x _ T.

The constraint true, which is always satisfied, mainly serves to indicate
the absence of a nontrivial constraint, while false, which has no solution,
may be understood as the indication of a type error. Composite constraints
include conjunction and existential quantification, which have their standard
meaning, as well as type scheme introduction and type scheme instantiation
constraints, which are similar to Gustavsson and Svenningsson's constraint
abstractions (2001). In order to be able to explain these last two forms, we
must first introduce a number of derived constraint forms:

10.2.3 Definition: Let oe be 8_X[D].T. If _X # ftv(T0) holds, then oe _ T0 (read: T0 is an

instance of oe ) stands for the constraint 9_X.(D ^ T <= T0). We write 9oe (read: oe
has an instance) for 9_X.D and let x : oe in C for 9oe ^ def x : oe in C. 2

Constrained type schemes generalize Damas and Milner's type schemes, while
this definition of instantiation constraints generalizes Damas and Milner's no-
tion of instance (Definition 10.1.18). Let us draw a comparison. First, Damas
and Milner's instance relation is binary (given a type scheme S and a type T,
either T is an instance of S, or it isn't), and is purely syntactic. For instance,
the type Y ! Z is not an instance of 8X.X ! X in Damas and Milner's sense,
because Y and Z are distinct type variables. In our presentation, on the other
hand, 8X.X ! X _ Y ! Z is not an assertion; rather, it is a constraint, which
by definition is 9X.(true ^ X ! X <= Y ! Z). We later prove that it is equivalent
to 9X.(Y <= X ^X <= Z) and to Y <= Z, and, if subtyping is interpreted as equality,
to Y = Z. That is, oe _ T0 represents a condition on (the ground types denoted
by) the type variables in ftv(oe , T0) for T0 to be an instance of oe , in a logical,
rather than purely syntactic, sense. Second, the definition of instantiation

10.2 Constraints 409
constraints involves subtyping, to ensure that any supertype of an instance
of oe is again an instance of oe (see rule C-ExTrans on page 418). This is con-
sistent with the purpose of subtyping: to allow a subtype where a supertype
is expected (TAPL, Chapter 15). Third and last, every type scheme oe is now
of the form 8_X[C].T. The constraint C, whose free type variables may or may
not be members of _X, is meant to restrict the set of instances of the type
scheme 8_X[C].T. This is evident in the instantiation constraint 8_X[C].T _ T0,
which by Definition 10.2.3 stands for 9_X.(C ^ T <= T0): the values that _X may
assume are restricted by the demand that C be satisfied. This requirement
vanishes in the case of DM type schemes, where C is true. Our notions of con-
strained type scheme and of instantiation constraint are standard, coinciding
with those of HM(X) (Odersky, Sulzmann, and Wehr, 1999).

Let us now come back to an explanation of type scheme introduction and
instantiation constraints. In brief, the construct def x : oe in C binds the name
x to the type scheme oe within the constraint C. If C contains a subconstraint
of the form x _ T, where this occurrence of x is free in C, then this subcon-
straint acquires the meaning oe _ T. Thus, the constraint x _ T is indeed an
instantiation constraint, where the type scheme that is being instantiated is
referred to by name. The constraint def x : oe in C may be viewed as an ex-
plicit substitution of the type scheme oe for the name x within C. Later ($10.4),
we use such explicit substitutions to supplant typing environments. That is,
where Damas and Milner's type system augments the current typing envi-
ronment (dm-Abs, dm-Let), we introduce a new def binding in the current
constraint; where it looks up the current typing environment (dm-Var), we
employ an instantiation constraint. (The reader may wish to look ahead at Fig-
ure 10-9 on page 431.) The point is that it is then up to a constraint solver to
choose a strategy for reducing explicit substitutions--for instance, one might
wish to simplify oe before substituting it for x within C--whereas the use of
environments in standard type systems such as DM and HM(X) imposes an
eager substitution strategy, which is inefficient and thus never literally imple-
mented. The use of type scheme introduction and instantiation constraints
allows separating constraint generation and constraint solving without com-
promising efficiency, or, in other words, without introducing a gap between
the description of the type inference algorithm and its actual implementation.
Although the algorithm that we plan to describe is not new (Re'my, 1992a), its
description in terms of constraints is: to the best of our knowledge, the only
close relative of our def constraints is to be found in Gustavsson and Sven-
ningsson (2001). An earlier work that contains similar ideas is Mu"ller (1994).
Approaches based on semi-unification (Henglein, 1989, 1993) achieve a simi-
lar separation between constraint generation and constraint solving, but are
based on a rather different constraint language.

410 10 The Essence of ML Type Inference

In the type system of Damas and Milner, every type scheme S has a fixed,
nonempty set of instances. In a constraint-based setting, things are more
complex: given a type scheme oe and a type T, whether T is an instance
of oe (that is, whether the constraint oe _ T is satisfied) depends on the
meaning assigned to the type variables in ftv(oe , T). Similarly, given a type
scheme, whether some type is an instance of oe (that is, whether the con-
straint 9Z.oe _ Z, where Z is fresh for oe , is satisfied) depends on the meaning
assigned to the type variables in ftv(oe ). Because we do not wish to allow
forming type schemes that have no instances, we often use the constraint
9Z.oe _ Z. In fact, we later prove that it is equivalent to 9oe , as defined above.
We also use the constraint form let x : oe in C, which requires oe to have an
instance and at the same time associates it with the name x. Because the def
form is more primitive, it is easier to work with at a low level, but it is no
longer explicitly used after $10.2; we always use let instead.

10.2.4 Definition: Environments \Gamma  remain as in Definition 10.1.19, except DM type

schemes S are replaced with constrained type schemes oe . The set of free
program identifiers of an environment \Gamma  , written fpi(\Gamma  ), is defined by fpi(IJ) =
IJ and fpi(\Gamma  ; x : oe ) = fpi(\Gamma  ) [ fpi(oe ). We write dfpi(\Gamma  ) for dpi(\Gamma  ) [ fpi(\Gamma  ). We
define def IJ in C as C and def \Gamma  ; x : oe in C as def \Gamma  in def x : oe in C. Similarly,
we define let IJ in C as C and let \Gamma  ; x : oe in C as let \Gamma  in let x : oe in C. We define
9IJ as true and 9(\Gamma  ; x : oe ) as 9\Gamma  ^ def \Gamma  in 9oe . 2

In order to establish or express certain laws of equivalence between con-
straints, we need constraint contexts. A constraint context is a constraint with
zero, one, or several holes, written []. The syntax of contexts is as follows:

C ::= [] | C | C ^ C | 9_X.C | def x : oe in C | def x : 8_X[C].T in C
The application of a constraint context C to a constraint C, written C[C], is
defined in the usual way. Because a constraint context may have any number
of holes, C may disappear or be duplicated in the process. Because a hole
may appear in the scope of a binder, some of C's free type variables and free
program identifiers may become bound in C[C]. We write dtv(C) and dpi(C)
for the sets of type variables and program identifiers, respectively, that C may
thus capture. We write let x : 8_X[C].T in C for 9_X.C ^ def x : 8_X[C].T in C.
(Being able to state such a definition is why we require multi-hole contexts.)
We let X range over existential constraint contexts, defined by X ::= 9_X.[].

Meaning of Constraints
We have defined the syntax of constraints and given an informal description
of their meaning. We now give a formal definition of the interpretation of
constraints. We begin with the definition of a model:

10.2 Constraints 411
10.2.5 Definition: For every kind ^, let M^ be a nonempty set, whose elements

are called the ground types of kind ^. In the following, t ranges over M^, for
some ^ that may be determined from the context. For every type constructor
F of signature K ) ^, let F denote a total function from MK into M^, where
the indexed product MK is the set of all mappings T of domain dom(K) that
map every d 2 dom(K) to an element of MK(d). For every predicate symbol
P of signature ^1 \Omega  . . . \Omega  ^n ) *, let P denote a predicate on M^1 * . . . * M^n .
For every kind ^, we require the predicate =^ to be equality on M^ and the
predicate <=^ to be a partial order on M^. 2

For the sake of convenience, we abuse notation and write F for both the
type constructor and its interpretation, and similarly for predicates.

By varying the set of type constructors, the set of predicates, the set of
ground types, and the interpretation of type constructors and predicates, one
may define an entire family of related type systems. We refer to the collection
of these choices as X. Thus, the type system HM(X), described in $10.3, is
parameterized by X.

The following examples give standard ways of defining the set of ground
types and the interpretation of type constructors.

10.2.6 Example [Syntactic models]: For every kind ^, let M^ consist of the closed

types of kind ^. Then, ground types are types that do not have any free type
variables, and form the so-called Herbrand universe. Let every type construc-
tor F be interpreted as itself. Models that define ground types and interpret
type constructors in this manner are referred to as syntactic. 2

10.2.7 Example [Tree models]: Let a path ss be a finite sequence of directions. The

empty path is written ffl and the concatenation of the paths ss and ss0 is written
ss * ss0. Let a tree be a partial function t from paths to type constructors
whose domain is nonempty and prefix-closed and such that, for every path
ss in the domain of t, if the type constructor t(ss) has signature K ) ^, then
ss * d 2 dom(t) is equivalent to d 2 dom(K) and, furthermore, for every
d 2 dom(K), the type constructor t(ss * d) has image kind K(d). If ss is in
the domain of t, then the subtree of t rooted at ss, written t/ss, is the partial
function ss0 , t(ss * ss0). A tree is finite if and only if it has finite domain. A
tree is regular if and only if it has a finite number of distinct subtrees. Every
finite tree is thus regular. Let M^ consist of the finite (respectively regular)
trees t such that t(ffl) has image kind ^: then, we have a finite (respectively
regular) tree model.

If F has signature K ) ^, one may interpret F as the function that maps
T 2 MK to the ground type t 2 M^ defined by t(ffl) = F and t/d = T (d) for
d 2 dom(T ), that is, the unique ground type whose head symbol is F and

412 10 The Essence of ML Type Inference

whose subtree rooted at d is T (d). Then, we have a free tree model. Note
that free finite tree models coincide with syntactic models, as defined in the
previous example. 2

Rows ($10.8) are interpreted in a tree model, albeit not a free one. The fol-
lowing examples suggest different ways of interpreting the subtyping predi-
cate.

10.2.8 Example [Equality models]: The simplest way of interpreting the subtyp-

ing predicate is to let <= denote equality on every M^. Models that do so
are referred to as equality models. When no predicate other than equality is
available, we say that the model is equality-only. 2

10.2.9 Example [Structural, nonstructural subtyping]: Let a variance * be a

nonempty subset of {-, +}, written - (contravariant), + (covariant), or +- (in-
variant) for short. Define the composition of two variances as an associative,
commutative operation with + as neutral element, +- as absorbing element
(that is, +-- = +-+ = +-+- = +-), and such that -- = +. Now, consider a free
(finite or regular) tree model, where every direction d comes with a fixed vari-
ance *(d). Define the variance *(ss) of a path ss as the composition of the
variances of its elements. Let a` be a partial order on type constructors such
that (i) if F1 a` F2 holds and F1 and F2 have signature K1 ) ^1 and K2 ) ^2, re-
spectively, then K1 and K2 agree on the intersection of their domains and ^1
and ^2 coincide; and (ii) F0 a` F1 a` F2 implies dom(F0) " dom(F2) ` dom(F1).
Let a`+, a`-, and a`+- stand for a`, a', and =, respectively. Then, define the inter-
pretation of subtyping as follows: if t1, t2 2 M^, let t1 <= t2 hold if and only if,
for every path ss 2 dom(t1) " dom(t2), t1(ss) a`*(ss) t2(ss) holds. It is not diffi-
cult to check that <= is a partial order on every M^. The reader is referred to
Amadio and Cardelli (1993), Kozen, Palsberg, and Schwartzbach (1995), and
Brandt and Henglein (1997) for more details about this construction. Models
that define subtyping in this manner are referred to as nonstructural subtyp-
ing models.

A simple nonstructural subtyping model is obtained by: letting the direc-
tions domain and codomain be contra- and covariant, respectively; introduc-
ing, in addition to the type constructor !, two type constructors ? and ? of
signature ?; and letting ? a` ! a` ?. This gives rise to a model where ? is the
least ground type, ? is the greatest ground type, and the arrow type construc-
tor is, as usual, contravariant in its domain and covariant in its codomain.
This form of subtyping is called nonstructural because comparable ground
types may have different shapes: consider, for instance, ? and ? ! ?.

A typical use of nonstructural subtyping is in type systems for records. One
may, for instance, introduce a covariant direction content of kind ?, a kind

10.2 Constraints 413
ffi, a type constructor abs of signature ffi, a type constructor pre of signature
{content , ?} ) ffi, and let pre a` abs. This gives rise to a model where
pre t <= abs holds for every t 2 M?. Again, comparable ground types may
have different shapes: consider, for instance, pre ? and abs. $10.8 says more
about typechecking operations on records.

Nonstructural subtyping has been studied, for example, in Kozen, Palsberg,
and Schwartzbach (1995), Palsberg, Wand, and O'Keefe (1997), Jim and Pals-
berg (1999), Pottier (2001b), Su et al. (2002), and Niehren and Priesnitz (2003).

An important particular case arises when any two type constructors related
by a` have the same arity (and thus also the same signatures). In that case, it
is not difficult to show that any two ground types related by subtyping must
have the same shape, that is, if t1 <= t2 holds, then dom(t1) and dom(t2) must
coincide. For this reason, such an interpretation of subtyping is usually re-
ferred to as atomic or structural subtyping. It has been studied in the finite
(Mitchell, 1984, 1991b; Tiuryn, 1992; Pratt and Tiuryn, 1996; Frey, 1997; Re-
hof, 1997; Kuncak and Rinard, 2003; Simonet, 2003) and regular (Tiuryn and
Wand, 1993) cases. Structural subtyping is often used in automated program
analyses that enrich standard types with atomic annotations without altering
their shape. 2

Many other kinds of constraints exist, which we lack space to list; see
Comon (1994) for a short survey.

Throughout this chapter, we assume (unless otherwise stated) that the set
of type constructors, the set of predicates, and the model--which, together,
form the parameter X--are arbitrary, but fixed.

As usual, the meaning of a constraint is a function of the meaning of its
free type variables and of its free program identifiers, which are respectively
given by a ground assignment and a ground environment.

10.2.10 Definition: A ground assignment OE is a total, kind-preserving mapping from

V into M. Ground assignments are extended to types by OE(F T1 . . . Tn) =
F(OE(T1), . . . , OE(Tn)). Then, for every type T of kind ^, OE(T) is a ground type
of kind ^.

A ground type scheme s is a set of ground types, which we require to be
upward-closed with respect to subtyping: that is, t 2 s and t <= t0 must im-
ply t0 2 s. A ground environment  is a partial mapping from identifiers to
ground type schemes.

Because the syntax of type schemes and constraints is mutually recursive,
so is their interpretation. The interpretation of a type scheme oe under a
ground assignment OE and a ground environment  is a ground type scheme,
written (OE, )oe . It is defined in Figure 10-5. The " is the upward closure

414 10 The Essence of ML Type Inference

Interpretation of type schemes:

(OE, )(8_X[C].T) =

"{OE[~X , ~t](T) ; OE[~X , ~t],  |= C}

Interpretation of constraints:

OE,  |= true (CM-True)
P (OE(T1), . . . , OE(Tn))

OE,  |= P T1 . . . Tn (CM-Predicate)

OE,  |= C1
OE,  |= C2

OE,  |= C1 ^ C2 (CM-And)
OE[~X , ~t],  |= C

OE,  |= 9_X.C (CM-Exists)
OE, [x , (OE, )oe ] |= C

OE,  |= def x : oe in C (CM-Def)

OE(T) 2 (x)
OE,  |= x _ T (CM-Instance)

Figure 10-5: Meaning of constraints

operator and |= is the constraint satisfaction predicate, defined next. The in-
terpretation of a constraint C under a ground assignment OE and a ground
environment  is a truth value, written OE,  |= C (read: OE and  satisfy C).
The three-place predicate |= is defined by the rules in Figure 10-5. A con-
straint C is satisfiable if and only if OE,  |= C holds for some OE and . It is
false (or unsatisfiable) otherwise. 2

Let us now explain these definitions. The interpretation of the type scheme
8_X[C].T is a set of ground types, which we may refer to as the type scheme's
ground instances. It contains the images of T under extensions of OE with
new values for the universally quantified variables _X; these values may be
arbitrary, but must be such that the constraint C is satisfied. We implicitly
require ~X and ~t to have matching kinds, so that OE[~X , ~t] remains a kind-
preserving ground assignment. This set is upward closed, so any ground type
that lies above a ground instance of oe is also a ground instance of oe . This
interpretation is standard; see, for example, Pottier (2001a).

The rules that define |= (Figure 10-5) are syntax-directed. CM-True states
that the constraint true is a tautology, that is, holds in every context. No rule
matches the constraint false, which means that it holds in no context. CM-
Predicate states that the meaning of a predicate application is given by the
predicate's interpretation within the model. More specifically, if P's signature
is ^1 \Omega  . . . \Omega  ^n ) *, then, by well-formedness of the constraint, every Ti is of
kind ^i, so OE(Ti) is a ground type in M^i . By Definition 10.2.5, P denotes a
predicate on M^1 * . . . * M^n , so the rule's premise is mathematically well-
formed. It is independent of , which is natural, since a predicate application
has no free program identifiers. CM-And requires each of the conjuncts to be

10.2 Constraints 415
valid in isolation. CM-Exists allows the type variables ~X to denote arbitrary
ground types ~t within C, independently of their image through OE. CM-Def
deals with type scheme introduction constraints, of the form def x : oe in C.
It binds x, within C, to the ground type scheme currently denoted by oe . Last,
CM-Instance concerns type scheme instantiation constraints of the form x _
T. Such a constraint is valid if and only if the ground type denoted by T is a
member of the ground type scheme denoted by x.

It is possible to prove that the constraints def x : oe in C and [x , oe ]C have
the same meaning, where the latter denotes the capture-avoiding substitution
of oe for x throughout C. As a matter of fact, it would have been possible to
use this equivalence as a definition of the meaning of def constraints, but the
present style is pleasant as well. This confirms our claim that the def form is
an explicit substitution form.

Because constraints lie at the heart of our treatment of ML-the-type-system,
most of our proofs involve establishing logical properties of constraints.
These properties are usually not stated in terms of the satisfaction predi-
cate |=, which is too low-level. Instead, we reason in terms of entailment or
equivalence assertions. Let us first define these notions.

10.2.11 Definition: We write C1 dh C2, and say that C1 entails C2, if and only if,

for every ground assignment OE and for every ground environment , the
assertion OE,  |= C1 implies OE,  |= C2. We write C1 j C2, and say that C1
and C2 are equivalent, if and only if C1 dh C2 and C2 dh C1 hold. 2

In other words, C1 entails C2 when C1 imposes stricter requirements on
its free type variables and program identifiers than C2 does. Note that C is
unsatisfiable if and only if C j false holds. It is straightforward to check
that entailment is reflexive and transitive and that j is indeed an equivalence
relation.

We immediately exploit the notion of constraint equivalence to define what
it means for a type constructor to be covariant, contravariant, or invariant
with respect to one of its parameters. Let F be a type constructor of signature
^1 \Omega  . . . \Omega  ^n ) ^. Let i 2 {1, . . . , n}. F is covariant (respectively contravariant,
invariant) with respect to its ith parameter if and only if, for all types T1, . . . , Tn
and T0i of appropriate kinds, the constraint F T1 . . . Ti . . . Tn <= F T1 . . . T0i . . . Tn
is equivalent to Ti <= T0i (respectively T0i <= Ti, Ti = T0i).

10.2.12 Exercise [n', 3]: Check the following facts: (i) in an equality model, covari-

ance, contravariance, and invariance coincide; (ii) in an equality free tree
model, every type constructor is invariant with respect to each of its parame-
ters; and (iii) in a nonstructural subtyping model, if the direction d has been
declared covariant (respectively contravariant, invariant), then every type con-

416 10 The Essence of ML Type Inference

structor whose arity includes d is covariant (respectively contravariant, in-
variant) with respect to d. 2

In the following, we require the type constructor ! to be contravariant
with respect to its domain and covariant with respect to its codomain--a
standard requirement in type systems with subtyping (TAPL, Chapter 15).
This requirement is summed up by the following equivalence law:

T1 ! T2 <= T01 ! T02 j T01 <= T1 ^ T2 <= T02 (C-Arrow)
Note that this requirement bears on the interpretation of types and of the
subtyping predicate. In an equality free tree model, by (i) and (ii) in the exer-
cise above, it is always satisfied. In a nonstructural subtyping model, it boils
down to requiring that the directions domain and codomain be declared con-
travariant and covariant, respectively. In the general case, we do not have any
knowledge of the model and cannot formulate a more precise requirement.
Thus, it is up to the designer of the model to ensure that C-Arrow holds.

We also exploit the notion of constraint equivalence to define what it means
for two type constructors to be incompatible. Two type constructors F1 and
F2 with the same image kind are incompatible if and only if all constraints
of the form F1 ~T1 <= F2 ~T2 and F2 ~T2 <= F1 ~T1 are false. Note that in an equality
free tree model, any two distinct type constructors are incompatible. In the
following, we often indicate that a newly introduced type constructor must
be isolated. We implicitly require that, whenever both F1 and F2 are isolated,
F1 and F2 be incompatible. Thus, the notion of isolation provides a concise
and modular way of stating a collection of incompatibility requirements. We
require the type constructor ! to be isolated.

Reasoning with Constraints
In this section, we give a number of equivalence laws that are often useful and
help understand the meaning of constraints. To begin, we note that entail-
ment is preserved by arbitrary constraint contexts, as stated by the theorem
below. As a result, constraint equivalence is a congruence. Throughout this
chapter, these facts are often used implicitly.

10.2.13 Theorem [Congruence]: C1 dh C2 implies C[C1] dh C[C2]. 2

Next, we define what it means for a constraint to determine a set of type
variables. In brief, C determines _Y if and only if, given a ground assignment
for ftv(C) \ _Y and given that C holds, it is possible to reconstruct, in a unique
way, a ground assignment for _Y. Determinacy appears in the equivalence law
C-LetAll on page 418 and is exploited by the constraint solver in $10.6.

10.2 Constraints 417
10.2.14 Definition: C determines _Y if and only if, for every environment \Gamma  , two

ground assignments that satisfy def \Gamma  in C and that coincide outside _Y must
coincide on _Y as well. 2

We now give a toolbox of constraint equivalence laws. It is worth noting
that they do not form a complete axiomatization of constraint equivalence;
in fact, they cannot, since the syntax and meaning of constraints is partly
unspecified.

10.2.15 Theorem: All equivalence laws in Figure 10-6 hold. 2

Let us explain. C-And and C-AndAnd state that conjunction is commuta-
tive and associative. C-Dup states that redundant conjuncts may be freely
added or removed, where a conjunct is redundant if and only if it is entailed
by another conjunct. Throughout this chapter, these three laws are often used
implicitly. C-ExEx and C-Ex* allow grouping consecutive existential quanti-
fiers and suppressing redundant ones, where a quantifier is redundant if and
only if the variables bound by it do not occur free within its scope. C-ExAnd
allows conjunction and existential quantification to commute, provided no
capture occurs; it is known as a scope extrusion law. When the rule is ori-
ented from left to right, its side-condition may always be satisfied by suitable
ff-conversion. C-ExTrans states that it is equivalent for a type T to be an
instance of oe or to be a supertype of some instance of oe . We note that the in-
stances of a monotype are its supertypes, that is, by Definition 10.2.3, T0 _ T
and T0 <= T are equivalent. As a result, specializing C-ExTrans to the case
where oe is a monotype, we find that T0 <= T is equivalent to 9Z.(T0 <= Z^Z <= T),
for fresh Z, a standard equivalence law. When oriented from left to right, it
becomes an interesting simplification law: in a chain of subtyping constraints,
an intermediate variable such as Z may be suppressed, provided it is local, as
witnessed by the existential quantifier 9Z. C-InId states that, within the scope
of the binding x : oe , every free occurrence of x may be safely replaced with oe .
The restriction to free occurrences stems from the side-condition x 62 dpi(C).
When the rule is oriented from left to right, its other side-conditions, which
require the context let x : oe in C not to capture oe 's free type variables or
free program identifiers, may always be satisfied by suitable ff-conversion.
C-In* complements the previous rule by allowing redundant let bindings to
be simplified. We note that C-InId and C-In* provide a simple procedure for
eliminating let forms. C-InAnd states that the let form commutes with con-
junction; C-InAnd* spells out a common particular case. C-InEx states that it
commutes with existential quantification. When the rule is oriented from left
to right, its side-condition may always be satisfied by suitable ff-conversion.
C-LetLet states that let forms may commute, provided they bind distinct

418 10 The Essence of ML Type Inference

C1 ^ C2 j C2 ^ C1 (C-And)
(C1 ^ C2) ^ C3 j C1 ^ (C2 ^ C3) (C-AndAnd)

C1 ^ C2 j C1 if C1 dh C2 (C-Dup)

9_X.9_Y.C j 9_X_Y.C (C-ExEx)

9_X.C j C if _X # ftv(C) (C-Ex*)

(9_X.C1) ^ C2 j 9_X.(C1 ^ C2) if _X # ftv(C2) (C-ExAnd)
9Z.(oe _ Z ^ Z <= T) j oe _ T if Z 62 ftv(oe , T) (C-ExTrans)
let x : oe in C[x _ T] j let x : oe in C[oe _ T] (C-InId)

if x 62 dpi(C) and dtv(C) # ftv(oe ) and {x} [ dpi(C) # fpi(oe )

let \Gamma  in C j 9\Gamma  ^ C if dpi(\Gamma ) # fpi(C) (C-In*)

let \Gamma  in (C1 ^ C2) j (let \Gamma  in C1) ^ (let \Gamma  in C2) (C-InAnd)
let \Gamma  in (C1 ^ C2) j (let \Gamma  in C1) ^ C2 if dpi(\Gamma ) # fpi(C2) (C-InAnd*)

let \Gamma  in 9_X.C j 9_X.let \Gamma  in C if _X # ftv(\Gamma ) (C-InEx)
let \Gamma 1; \Gamma 2 in C j let \Gamma 2; \Gamma 1 in C (C-LetLet)

if dpi(\Gamma 1) # dpi(\Gamma 2) and dpi(\Gamma 2) # fpi(\Gamma 1) and dpi(\Gamma 1) # fpi(\Gamma 2)

let x : 8_X[C1 ^ C2].T in C3 j C1 ^ let x : 8_X[C2].T in C3 if _X # ftv(C1) (C-LetAnd)

let \Gamma  ; x : 8_X[C1].T in C2 j let \Gamma  ; x : 8_X[let \Gamma  in C1].T in C2 (C-LetDup)

if _X # ftv(\Gamma  ) and dpi(\Gamma  ) # fpi(\Gamma )

let x : 8_X[9_Y.C1].T in C2 j let x : 8_X_Y[C1].T in C2 if _Y # ftv(T) (C-LetEx)

let x : 8_X_Y[C1].T in C2 j 9_Y.let x : 8_X[C1].T in C2 (C-LetAll)

if _Y # ftv(C2) and 9_X.C1 determines _Y

9X.(T <= X ^ let x : X in C) j let x : T in C if X 62 ftv(T, C) (C-LetSub)

~X = ~T ^ [~X , ~T]C j ~X = ~T ^ C (C-Eq)

true j 9_X.(~X = ~T) if _X # ftv(_T) (C-Name)
[~X , ~T]C j 9_X.(~X = ~T ^ C) if _X # ftv(_T) (C-NameEq)

Figure 10-6: Constraint equivalence laws

10.2 Constraints 419
program identifiers and provided no free program identifiers are captured
in the process. C-LetAnd allows the conjunct C1 to be moved outside of the
constrained type scheme 8_X[C1 ^ C2].T, provided it does not involve any of
the universally quantified type variables _X. When oriented from left to right,
the rule yields an important simplification law: indeed, taking an instance of
8_X[C2].T is less expensive than taking an instance of 8_X[C1 ^C2].T, since the
latter involves creating a copy of C1, while the former does not. C-LetDup al-
lows pushing a series of let bindings into a constrained type scheme, provided
no capture occurs in the process. It is not used as a simplification law but as a
tool in some proofs. C-LetEx states that it does not make any difference for a
set of type variables _Y to be existentially quantified inside a constrained type
scheme or part of the type scheme's universal quantifiers. Indeed, in either
case, taking an instance of the type scheme means producing a constraint
where _Y is existentially quantified. C-LetAll states that it is equivalent for
a set of type variables _Y to be part of a type scheme's universal quantifiers
or existentially bound outside the let form, provided these type variables are
determined. In other words, when a type variable is sufficiently constrained,
it does not matter whether it is polymorphic or monomorphic. Together, C-
LetEx and C-LetAll allow, in some situations, hoisting existential quantifiers
out of the left-hand side of a let form.

10.2.16 Example: C-LetAll would be invalid without the condition that 9_X.C1 de-

termines _Y. Consider, for instance, the constraint let x : 8Y.Y ! Y in (x _
int ! int ^ x _ bool ! bool) (1), where int and bool are incompatible nullary
type constructors. By C-InId and C-In*, it is equivalent to 8Y.Y ! Y <= int !
int ^ 8Y.Y ! Y <= bool ! bool which, by Definition 10.2.3, means 9Y.(Y !
Y <= int ! int) ^ 9Y.(Y ! Y <= bool ! bool), that is, true. Now, if C-LetAll
was valid without its side-condition, then (1) would also be equivalent to
9Y.let x : Y ! Y in (x _ int ! int^x _ bool ! bool), which by C-InId and C-In*
is 9Y.(Y ! Y <= int ! int ^ Y ! Y <= bool ! bool). By C-Arrow and C-ExTrans,
this is int = bool, that is, false. Thus, the law is invalid in this case. It is easy to
see why: when the type scheme oe contains a 8Y quantifier, every instance of
oe receives its own 9Y quantifier, making Y a distinct (local) type variable; but
when Y is not universally quantified, all instances of oe share references to a
single (global) type variable Y. This corresponds to the intuition that, in the
former case, oe is polymorphic in Y, while in the latter case, it is monomorphic
in Y. It is possible to prove that, when deprived of its side-condition, C-LetAll
is only an entailment law, that is, its right-hand side entails its left-hand side.
Similarly, it is in general invalid to hoist an existential quantifier out of the
left-hand side of a let form. To see this, one may study the (equivalent) con-
straint let x : 8X[9Y.X = Y ! Y].X in (x _ int ! int ^ x _ bool ! bool).
Naturally, in the above examples, the side-condition "true determines Y" does

420 10 The Essence of ML Type Inference

not hold: by Definition 10.2.14, it is equivalent to "two ground assignments
that coincide outside Y must coincide on Y as well," which is false when M?
contains two distinct elements, such as int and bool here.

There are cases, however, where the side-condition does hold. For instance,
we later prove that 9X.Y = int determines Y; see Lemma 10.6.7. As a result,
C-LetAll states that let x : 8XY[Y = int].Y ! X in C (1) is equivalent to
9Y.let x : 8X[Y = int].Y ! X in C (2), provided Y 62 ftv(C). The intuition is
simple: because Y is forced to assume the value int by the equation Y = int, it
makes no difference whether Y is or isn't universally quantified. By C-LetAnd,
(2) is equivalent to 9Y.(Y = int ^ let x : 8X.Y ! X in C) (3). In an efficient
constraint solver, simplifying (1) into (3) before using C-InId to eliminate the
let form is worthwhile, since doing so obviates the need for copying the type
variable Y and the equation Y = int at every free occurrence of x inside C. 2

C-LetSub is the analog of an environment strengthening lemma: roughly
speaking, it states that, if a constraint holds under the assumption that x has
type X, where X is some supertype of T, then it also holds under the assump-
tion that x has type T. The last three rules deal with the equality predicate.
C-Eq states that it is valid to replace equals with equals; note the absence of a
side-condition. When oriented from left to right, C-Name allows introducing
fresh names ~X for the types ~T. As always, ~X stands for a vector of distinct
type variables; ~T stands for a vector of the same length of types of appropri-
ate kind. Of course, this makes sense only if the definition is not circular, that
is, if the type variables _X do not occur free within the terms _T. When oriented
from right to left, C-Name may be viewed as a simplification law: it allows
eliminating type variables whose value has been determined. C-NameEq is
a combination of C-Eq and C-Name. It shows that applying an idempotent
substitution to a constraint C amounts to placing C within a certain context.

So far, we have considered def a primitive constraint form and defined
the let form in terms of def, conjunction, and existential quantification. The
motivation for this approach was to simplify the (omitted) proofs of several
constraint equivalence laws. However, in the remainder of this chapter, we
work with let forms exclusively and never employ the def construct. This of-
fers us an extra property: every constraint that contains a false subconstraint
must be false.

10.2.17 Lemma: C[false] j false. 2

Reasoning with Constraints in an Equality-Only Syntactic Model
We have given a number of equivalence laws that are valid with respect to
any interpretation of constraints, that is, within any model. However, an im-

10.2 Constraints 421
portant special case is that of equality-only syntactic models. Indeed, in that
specific setting, our constraint-based type systems are in close correspon-
dence with DM. In brief, we aim to prove that every satisfiable constraint C
such that fpi(C) = IJ admits a canonical solved form and to show that this
notion corresponds to the standard concept of a most general unifier. These
results are exploited when we relate HM(X) with Damas and Milner's system
(p. 428).

Thus, let us now assume that constraints are interpreted in an equality-
only syntactic model. Let us further assume that, for every kind ^, (i) there
are at least two type constructors of image kind ^ and (ii) for every type con-
structor F of image kind ^, there exists t 2 M^ such that t(ffl) = F. We refer to
models that violate (i) or (ii) as degenerate; one may argue that such models
are of little interest. The assumption that the model is nondegenerate is used
in the proof of Theorem 10.3.7. Last, throughout the present subsection we
manipulate only constraints that have no free program identifiers.

A solved form is a conjunction of equations, where the left-hand sides are
distinct type variables that do not appear in the right-hand sides, possibly
surrounded by a number of existential quantifiers. Our definition is identi-
cal to Lassez, Maher, and Marriott's solved forms (1988) and to Jouannaud
and Kirchner's tree solved forms (1991), except we allow for prenex existen-
tial quantifiers, which are made necessary by our richer constraint language.
Jouannaud and Kirchner also define dag solved forms, which may be expo-
nentially smaller. Because we define solved forms only for proof purposes,
we need not take performance into account at this point. The efficient con-
straint solver presented in $10.6 does manipulate graphs, rather than trees.
Type scheme introduction and instantiation constructs cannot appear within
solved forms; indeed, provided the constraint at hand has no free program
identifiers, they can be expanded away. For this reason, their presence in the
constraint language has no impact on the results contained in this section.

10.2.18 Definition: A solved form is of the form 9_Y.(~X = ~T), where _X # ftv(_T). 2

Solved forms offer a convenient way of reasoning about constraints be-
cause every satisfiable constraint is equivalent to one. This property is estab-
lished by the following lemma.

10.2.19 Lemma: Every constraint is equivalent to either a solved form or false. 2

It is possible to impose further restrictions on solved forms. A solved form
9_Y.(~X = ~T) is canonical if and only if its free type variables are exactly _X. This
is stated, in an equivalent way, by the following definition.

10.2.20 Definition: A canonical solved form is a constraint of the form 9_Y.(~X = ~T),

where ftv(_T) ` _Y and _X # _Y. 2

422 10 The Essence of ML Type Inference

10.2.21 Lemma: Every solved form is equivalent to a canonical solved form. 2

It is easy to describe the solutions of a canonical solved form: they are the
ground refinements of the substitution [~X , ~T]. Hence, every canonical
solved form is satisfiable.

The following definition allows entertaining a dual view of canonical solved
forms, either as constraints or as idempotent type substitutions. The latter
view is commonly found in standard treatments of unification (Lassez, Maher,
and Marriott, 1988; Jouannaud and Kirchner, 1991) and in classic presenta-
tions of ML-the-type-system.

10.2.22 Definition: If [~X , ~T] is an idempotent substitution of domain _X, let 9[~X ,

~T] denote the canonical solved form 9_Y.(~X = ~T), where _Y = ftv(_T). An idem-

potent substitution ` is a most general unifier of the constraint C if and only
if 9` and C are equivalent. 2

By definition, equivalent constraints admit the same most general unifiers.
Many properties of canonical solved forms may be reformulated in terms
of most general unifiers. By Lemmas 10.2.19 and 10.2.21, every satisfiable
constraint admits a most general unifier.

10.3 HM(X)

Constraint-based type systems appeared during the 1980s (Mitchell, 1984;
Fuh and Mishra, 1988) and were widely studied during the following decade
(Curtis, 1990; Aiken and Wimmers, 1993; Jones, 1994; Smith, 1994; Palsberg,
1995; Trifonov and Smith, 1996; Fa"hndrich, 1999; Pottier, 2001b). We now
present one such system, baptized HM(X) because it is a parameterized ex-
tension of Hindley and Milner's type discipline; the meaning of the parameter
X was explained on page 411. Its original description is due to Odersky, Sulz-
mann, and Wehr (1999). Since then, it has been completed in a number of
works including Mu"ller (1998), Sulzmann, Mu"ller, and Zenger (1999), Sulz-
mann (2000), Pottier (2001a), and Skalka and Pottier (2002). Each of these
presentations introduces minor variations. Here, we follow Pottier (2001a),
which is itself inspired by Sulzmann, Mu"ller, and Zenger (1999).

Definition
Our presentation of HM(X) relies on the constraint language introduced in

$10.2. Technically, our approach to constraints is less abstract than that
of Odersky, Sulzmann, and Wehr (1999). We interpret constraints within a
model, give conjunction and existential quantification their standard mean-

10.3 HM(X) 423
\Gamma  (x) = oe C dh 9oe

C, \Gamma  ` x : oe (hmx-Var)
C, (\Gamma  ; z : T) ` t : T0
C, \Gamma  ` *z.t : T ! T0 (hmx-Abs)
C, \Gamma  ` t1 : T ! T0 C, \Gamma  ` t2 : T

C, \Gamma  ` t1 t2 : T0 (hmx-App)
C, \Gamma  ` t1 : oe C, (\Gamma  ; z : oe ) ` t2 : T

C, \Gamma  ` let z = t1 in t2 : T (hmx-Let)

C ^ D, \Gamma  ` t : T _X # ftv(C, \Gamma  )

C ^ 9_X.D, \Gamma  ` t : 8_X[D].T (hmx-Gen)

C, \Gamma  ` t : 8_X[D].T

C ^ D, \Gamma  ` t : T (hmx-Inst)
C, \Gamma  ` t : T C dh T <= T0

C, \Gamma  ` t : T0 (hmx-Sub)
C, \Gamma  ` t : oe _X # ftv(\Gamma  , oe )

9_X.C, \Gamma  ` t : oe (hmx-Exists)

Figure 10-7: Typing rules for HM(X)

ing, and derive a number of equivalence laws ($10.2). Odersky et al., on the
other hand, do not explicitly rely on a logical interpretation; instead, they
axiomatize constraint equivalence, that is, they consider a number of equiva-
lence laws as axioms. Thus, they ensure that their high-level proofs, such as
type soundness and correctness and completeness of type inference, are in-
dependent of the low-level details of the logical interpretation of constraints.
Their approach is also more general, since it allows dealing with other logi-
cal interpretations, such as "open-world" interpretations, where constraints
are interpreted not within a fixed model, but within a family of extensions
of a "current" model. In this chapter, we have avoided this extra layer of ab-
straction and given fixed meaning to constraints, making things somewhat
simpler. However, the changes required to adopt Odersky et al.'s approach
would not be extensive, since the forthcoming proofs do indeed rely mostly
on constraint equivalence laws, rather than on low-level details of the logical
interpretation of constraints.

Another slight departure from Odersky et al.'s work lies in the fact that
we have enriched the constraint language with type scheme introduction and
instantiation forms, which were absent in the original presentation of HM(X).
To prevent this addition from affecting HM(X), we require the constraints
that appear in HM(X) typing judgments to have no free program identifiers.
Note that this does not prevent them from containing let forms.

The type system HM(X) consists of a four-place judgment whose parame-
ters are a constraint C, an environment \Gamma  , an expression t, and a type scheme
oe . A judgment is written C, \Gamma  ` t : oe and is read: under the assumptions C
and \Gamma  , the expression t has type oe . One may view C as an assumption about

424 10 The Essence of ML Type Inference

the judgment's free type variables and \Gamma  as an assumption about t's free pro-
gram identifiers. Recall that \Gamma  now contains constrained type schemes, and
that oe is a constrained type scheme.

We would like the validity of a typing judgment to depend not on the syn-
tax, but only on the meaning of its constraint assumption. We enforce this
point of view by considering judgments equal modulo equivalence of their
constraint assumptions. In other words, the typing judgments C, \Gamma  ` t : oe
and D, \Gamma  ` t : oe are considered identical when C j D holds. A judgment is
valid, or holds, if and only if it is derivable via the rules given in Figure 10-7.
Note that a valid judgment may involve an arbitrary constraint. A (closed)
program t is well-typed within the (closed) environment \Gamma  if and only if a
judgment of the form C, \Gamma  ` t : oe holds for some satisfiable constraint C. One
might wonder why we do not make the apparently stronger requirement that
C ^ 9oe be satisfiable; however, by inspection of the typing rules, the reader
may check that, if the above judgment is derivable, then C dh 9oe holds, hence
the two requirements are equivalent.

Let us now explain the rules. Like dm-Var, hmx-Var looks up the environ-
ment to determine the type scheme associated with the program identifier x.
Its second premise plays a minor technical role: as noted in the previous para-
graph, its presence helps simplify the definition of well-typedness. hmx-Abs,
hmx-App, and hmx-Let are identical to dm-Abs, dm-App, and dm-Let, respec-
tively, except that the assumption C is made available to every subderivation.
We recall that the type T may be viewed as the type scheme 8IJ[true].T (Defi-
nitions 10.1.18 and 10.2.2). As a result, types form a subset of type schemes,
which implies that \Gamma  ; z : T is a well-formed environment and C, \Gamma  ` t : T a
well-formed typing judgment. To understand hmx-Gen, it is best to first con-
sider the particular case where C is true. This yields the following, simpler
rule:

D, \Gamma  ` t : T _X # ftv(\Gamma  )

9_X.D, \Gamma  ` t : 8_X[D].T (hmx-Gen')

The second premise is identical to that of dm-Gen: the type variables that
are generalized must not occur free within the environment. The conclusion
forms the type scheme 8_X[D].T, where the type variables _X have become uni-
versally quantified, but are still subject to the constraint D. Note that the
type variables that occur free in D may include not only _X, but also other
type variables, typically free in \Gamma  . hmx-Gen may be viewed as a more liberal
version of hmx-Gen', whereby part of the current constraint, namely C, need
not be copied if it does not concern the type variables that are being gener-
alized, namely _X. This optimization is important in practice, because C may
be very large. An intuitive explanation for its correctness is given by the con-

10.3 HM(X) 425
straint equivalence law C-LetAnd, which expresses the same optimization in
terms of let constraints. Because HM(X) does not use let constraints, the op-
timization is hard-wired into the typing rule. As a last technical remark, let
us point out that replacing C ^ 9_X.D with C ^ D in hmx-Gen's conclusion
would not affect the set of derivable judgments; this fact may be established
using hmx-Exists and Lemma 10.3.1. hmx-Inst allows taking an instance of
a type scheme. The reader may be surprised to find that, contrary to dm-
Inst, it does not involve a type substitution. Instead, the rule merely drops
the universal quantifier, which amounts to applying the identity substitu-
tion ~X , ~X. One should recall, however, that type schemes are considered
equal modulo ff-conversion, so it is possible to rename the type scheme's
universal quantifiers prior to using hmx-Inst. The reason why this provides
sufficient expressive power appears in Exercise 10.3.2 below. The constraint
D carried by the type scheme is recorded as part of the current constraint
in hmx-Inst's conclusion. The subsumption rule hmx-Sub allows a type T to
be replaced at any time with an arbitrary supertype T0. Because both T and
T0 may have free type variables, whether T <= T0 holds depends on the cur-
rent assumption C, which is why the rule's second premise is an entailment
assertion. An operational explanation of hmx-Sub is that it requires all uses
of subsumption to be explicitly recorded in the current constraint. Note that
hmx-Sub remains a useful and necessary rule even when subtyping is inter-
preted as equality: then, it allows exploiting the type equations found in C.
Last, hmx-Exists allows the type variables that occur only within the current
constraint to become existentially quantified. As a result, these type variables
no longer occur free in the rule's conclusion; in other words, they have be-
come local to the subderivation rooted at the premise. One may prove that
the presence of hmx-Exists in the type system does not augment the set of
well-typed programs, but does augment the set of valid typing judgments; it
is a pleasant technical convenience. Indeed, because judgments are consid-
ered equal modulo constraint equivalence, constraints may be transparently
simplified at any time. (By simplifying a constraint, we mean replacing it with
an equivalent constraint whose syntactic representation is considered sim-
pler.) Bearing this fact in mind, one finds that an effect of rule hmx-Exists
is to enable more simplifications: because constraint equivalence is a con-
gruence, C j D implies 9_X.C j 9_X.D, but the converse does not hold in
general. For instance, there is in general no way of simplifying the judgment
X <= Y <= Z, \Gamma  ` t : oe , but if it is known that Y does not appear free in \Gamma  or
oe , then hmx-Exists allows deriving 9Y.(X <= Y <= Z), \Gamma  ` t : oe , which is the
same judgment as X <= Z, \Gamma  ` t : oe . Thus, an interesting simplification has
been enabled. Note that X <= Y <= Z j X <= Z does not hold, while, according to
C-ExTrans, 9Y.(X <= Y <= Z) j X <= Z does.

426 10 The Essence of ML Type Inference

A pleasant property of HM(X) is that strengthening a judgment's con-
straint assumption (that is, weakening the judgment itself) preserves its va-
lidity. It is worth noting that in traditional presentations, which rely more
heavily on type substitutions, the analog of this result is a type substitu-
tion lemma; see for instance Tofte (1988), Lemma 2.7; Re'my (1992a), Lemma
1; Leroy (1992), Proposition 1.2; and Skalka and Pottier (2002), Lemma 3.4.
Here, the lemma further states that weakening a judgment does not alter the
shape of its derivation, a useful property when reasoning by induction on
type derivations.

10.3.1 Lemma [Weakening]: If C0 dh C, then every derivation of C, \Gamma  ` t : oe may be

turned into a derivation of C0, \Gamma  ` t : oe with the same shape. 2

10.3.2 Exercise [Recommended, n'n']: In some presentations of HM(X), hmx-Inst

is replaced with the following variant:

C, \Gamma  ` t : 8_X[D].T C dh [~X , ~T]D

C, \Gamma  ` t : [~X , ~T]T (hmx-Inst')
Show that hmx-Inst' is admissible in our presentation of HM(X)--that is, if its
premise is derivable according to the rules of Figure 10-7, then so is its con-
clusion. Thus, the choice between hmx-Inst and hmx-Inst' is only stylistic: it
makes no difference in the system's expressive power. Because hmx-Inst is
more elementary, choosing it simplifies some proofs. 2

10.3.3 Exercise [n']: Give a derivation of true, IJ ` *z.z : int ! int. Give a derivation

of true, IJ ` *z.z : 8X.X ! X. Check that the former judgment also follows
from the latter via hmx-Inst' (Exercise 10.3.2), and determine which deriva-
tion of true, IJ ` *z.z : int ! int this path gives rise to. 2

We do not give a direct type soundness proof for HM(X). Instead, in the
forthcoming sections, we prove that well-typedness in HM(X) is equivalent
to the satisfiability of a certain constraint and use that characterization as
a basis for our type soundness proof. A direct type soundness result, based
on a denotational semantics, may be found in Odersky, Sulzmann, and Wehr
(1999). Another type soundness proof, which follows Wright and Felleisen's
syntactic approach (1994), appears in Skalka and Pottier (2002). Last, a hybrid
approach, which combines some of the advantages of the previous two, is
given in Pottier (2001a).

An Alternate Presentation of HM(X)
The presentation of HM(X) given in Figure 10-7 has only four syntax-directed
rules out of eight. It is a good specification of the type system, but it is far

10.3 HM(X) 427
\Gamma  (x) = 8_X[D].T

C ^ D, \Gamma  ` x : T (hmd-VarInst)

C, (\Gamma  ; z : T) ` t : T0
C, \Gamma  ` *z.t : T ! T0 (hmd-Abs)

C, \Gamma  ` t1 : T ! T0 C, \Gamma  ` t2 : T

C, \Gamma  ` t1 t2 : T0 (hmd-App)

C ^ D, \Gamma  ` t1 : T1 _X # ftv(C, \Gamma  )
C ^ 9_X.D, (\Gamma  ; z : 8_X[D].T1) ` t2 : T2

C ^ 9_X.D, \Gamma  ` let z = t1 in t2 : T2

(hmd-LetGen)
C, \Gamma  ` t : T C dh T <= T0

C, \Gamma  ` t : T0 (hmd-Sub)
C, \Gamma  ` t : T _X # ftv(\Gamma  , T)

9_X.C, \Gamma  ` t : T (hmd-Exists)

Figure 10-8: An alternate presentation of HM(X)

from an algorithmic description. As a first step towards such a description,
we provide an alternate presentation of HM(X), where generalization is per-
formed only at let expressions and instantiation takes place only at refer-
ences to program identifiers (Figure 10-8). This presentation only has two
non-syntax-directed rules, making it sometimes easier to reason about. It has
the property that all judgments are of the form C, \Gamma  ` t : T, rather than
C, \Gamma  ` t : oe . The following theorem states that the two presentations are
indeed equivalent.

10.3.4 Theorem: C, \Gamma  ` t : T is derivable via the rules of Figure 10-8 if and only if it

is a valid HM(X) judgment. 2

This theorem shows that the rule sets of Figures 10-7 and 10-8 derive
the same monomorphic judgments, that is, the same judgments of the form
C, \Gamma  ` t : T. The fact that judgments of the form C, \Gamma  ` t : oe , where oe is
a not a monotype, cannot be derived using the new rule set is a technical
simplification, without deep significance.

10.3.5 Exercise [n'n'n', 3]: Show that it is possible to simplify the presentation of

Damas and Milner's type system in an analogous manner. That is, define an
alternate set of typing rules for DM, which allows deriving judgments of the
form \Gamma  ` t : T; then, show that this new rule set is equivalent to the previous
one, in the same sense as above. Which auxiliary properties of DM does your
proof require? A solution is given by Clement, Despeyroux, Despeyroux, and
Kahn (1986). 2

428 10 The Essence of ML Type Inference

Relating HM(X) with Damas and Milner's Type System
In order to explain our interest in HM(X), we wish to show that it is more gen-
eral than Damas and Milner's type system. Since HM(X) really is a family of
type systems, we must make this statement more precise. First, every mem-
ber of the HM(X) family contains DM. Conversely, DM contains HM(=), the
constraint-based type system obtained by specializing HM(X) to the setting
of an equality-only syntactic model.

The first of these assertions is easy to prove because the mapping from
DM judgments to HM(X) judgments is essentially the identity: every valid
DM judgment may be viewed as a valid HM(X) judgment under the trivial
assumption true. This statement relies on the fact that the DM type scheme
8_X.T is identified with the constrained type scheme 8_X[true].T, so DM type
schemes (respectively environments) form a subset of HM(X) type schemes
(respectively environments). Its proof is easy and relies on Exercise 10.3.2.

10.3.6 Theorem: If \Gamma  ` t : S holds in DM, then true, \Gamma  ` t : S holds in HM(X). 2

We are now interested in proving that HM(=), as defined above, is con-
tained within DM. To this end, we must translate every HM(=) judgment to
a DM judgment. It turns out that this is possible if the original judgment's
constraint assumption is satisfiable. The translation relies on the fact that
the definition of HM(=) assumes an equality-only syntactic model. Indeed, in
that setting, every satisfiable constraint admits a most general unifier (Defi-
nition 10.2.22), whose properties we make essential use of.

Unfortunately, due to lack of space, we cannot give the details of this trans-
lation, which are fairly involved. Let us merely say that, given a type scheme
oe and an idempotent type substitution ` such that ftv(oe ) ` dom(`) and
9` dh 9oe hold, the translation of oe under ` is a DM type scheme, written
Joe K`. Its meaning is intended to be the same as that of the HM(X) type
scheme `(oe ). For instance, under the identity substitution, the translation of
the HM(X) type scheme 8XY[X = Y ! Y].X is the DM type scheme 8Z.Z ! Z.
The translation is extended to environments in such a way that J\Gamma  K` is defined
when ftv(\Gamma  ) ` dom(`) holds. We are now ready to state the main theorem.

10.3.7 Theorem: Let C, \Gamma  ` t : oe hold in HM(=). Let ` be a most general unifier of

C such that ftv(\Gamma  , oe ) ` dom(`). Then, J\Gamma  K` ` t : Joe K` holds in DM. 2

Note that, by requiring ` to be a most general unifier of C, we also require C
to be satisfiable. Judgments that carry an unsatisfiable constraint cannot be
translated.

Together, Theorems 10.3.6 and 10.3.7 yield a precise correspondence be-
tween DM and HM(=): there exists a compositional translation from each to

10.4 Constraint Generation 429
the other. In other words, they may be viewed as two equivalent formulations
of a single type system. One might also say that HM(=) is a constraint-based
formulation of DM. Furthermore, Theorem 10.3.6 states that every member of
the HM(X) family is an extension of DM. This explains our double interest in
HM(X), as an alternate formulation of DM, which we believe is more pleasant
for reasons already discussed, and as a more expressive framework.

10.4 Constraint Generation

We now explain how to reduce type inference problems for HM(X) to con-
straint solving problems. A type inference problem consists of a type environ-
ment \Gamma  , an expression t, and a type T of kind ?. The problem is to determine
whether there exists a satisfiable constraint C such that C, \Gamma  ` t : T holds. A
constraint solving problem consists of a constraint C. The problem is to de-
termine whether C is satisfiable. To reduce a type inference problem (\Gamma  , t, T)
to a constraint solving problem, we must produce a constraint C that is both
sufficient and necessary for C, \Gamma  ` t : T to hold. Below, we explain how to
compute such a constraint, which we write J\Gamma  ` t : TK. We check that it is
indeed sufficient by proving J\Gamma  ` t : TK, \Gamma  ` t : T. That is, the constraint
J\Gamma  ` t : TK is specific enough to guarantee that t has type T under environ-
ment \Gamma  . We say that constraint generation is sound. We check that it is indeed
necessary by proving that, for every constraint C, the validity of C, \Gamma  ` t : T
implies C dh J\Gamma  ` t : TK. That is, every constraint that guarantees that t has
type T under environment \Gamma  is at least as specific as J\Gamma  ` t : TK. We say
that constraint generation is complete. Together, these properties mean that
J\Gamma  ` t : TK is the least specific constraint that guarantees that t has type T
under environment \Gamma  .

We now see how to reduce a type inference problem to a constraint solving
problem. Indeed, if there exists a satisfiable constraint C such that C, \Gamma  `
t : T holds, then, by the completeness property, C dh J\Gamma  ` t : TK holds, so
J\Gamma  ` t : TK is satisfiable. Conversely, by the soundness property, if J\Gamma  ` t : TK
is satisfiable, then we have a satisfiable constraint C such that C, \Gamma  ` t : T
holds. In other words, t is well-typed with type T under environment \Gamma  if and
only if J\Gamma  ` t : TK is satisfiable.

The reader may be somewhat puzzled by the fact that our formulation
of the type inference problem requires an appropriate type T to be known
in advance, whereas the very purpose of type inference seems to consist in
discovering the type of t! In other words, we have made T an input of the con-
straint generation algorithm, instead of an output. Fortunately, this causes
no loss of generality, because it is possible to let T be a type variable X, cho-

430 10 The Essence of ML Type Inference

sen fresh for \Gamma  . Then, the constraint produced by the algorithm will contain
information about X. This is the point of the following exercise.

10.4.1 Exercise [Recommended, n']: Let X 62 ftv(\Gamma  ). Show that, if there exist a sat-

isfiable constraint C and a type T such that C, \Gamma  ` t : T holds, then there
exists a satisfiable constraint C0 such that C0, \Gamma  ` t : X holds. Conclude that,
given a closed environment \Gamma  and an arbitrary type variable X, the term t is
well-typed within \Gamma  if and only if J\Gamma  ` t : XK is satisfiable. 2

This shows that providing T as an input to the constraint generation proce-
dure is not essential. We adopt this style because it is convenient. A somewhat
naive alternative would be to provide \Gamma  and t only, and to have the procedure
return both a constraint C and a type T (Sulzmann, Mu"ller, and Zenger, 1999).
It turns out that this does not quite work, because C and T may mention
"fresh" variables, which we must be able to quantify over, if we are to avoid
an informal treatment of "freshness." Thus, the true alternative is to provide
\Gamma  and t only and to have the procedure return a type scheme oe (Bourdoncle
and Merz, 1997; Bonniot, 2002).

The existence of a sound and complete constraint generation procedure
is the analog of the existence of principal type schemes in classic presenta-
tions of ML-the-type-system (Damas and Milner, 1982). Indeed, a principal
type scheme is least specific in the sense that all valid types are substitution
instances of it. Here, the constraint J\Gamma  ` t : TK is least specific in the sense
that all valid constraints entail it. More about principal types and principal
typings may be found in Jim (1996) and Wells (2002).

How do we perform constraint generation? A standard approach (Sulz-
mann, Mu"ller, and Zenger, 1999; Bonniot, 2002) is to define J\Gamma  ` t : TK by
induction on the structure of t. At every let node, following hmd-LetGen,
part of the current constraint, namely D, is turned into a type scheme, namely
8_X[D].T, which is used to extend the environment. Then, at every occurrence
of the program variable that was bound at this let node, following hmd-
VarInst, this type scheme is retrieved from the environment, and a copy of
D is added back to the current constraint. If such an approach is adopted, it is
important to simplify the type scheme 8_X[D].T before it is stored in the en-
vironment, because it would be inefficient to copy an unsimplified constraint.
In other words, in an efficient implementation of this standard approach,
constraint generation and constraint simplification cannot be separated.

Type scheme introduction and elimination constraints, which we intro-
duced in $10.2 but did not use in the specification of HM(X), are intended
as a means of solving this problem. By extending our vocabulary, we are able
to achieve the desired separation between constraint generation, on the one
hand, and constraint solving and simplification, on the other hand, without

10.4 Constraint Generation 431

Jx : TK = x _ T
J*z.t : TK = 9X1X2.(let z : X1 in Jt : X2K ^ X1 ! X2 <= T)
Jt1 t2 : TK = 9X2.(Jt1 : X2 ! TK ^ Jt2 : X2K)
Jlet z = t1 in t2 : TK = let z : 8X[Jt1 : XK].X in Jt2 : TK

Figure 10-9: Constraint generation

compromising efficiency. Indeed, by exploiting these new constraint forms,
we may define a constraint generation procedure whose time and space com-
plexity is linear, because it no longer involves copying subconstraints back
and forth between the environment and the constraint that is being gener-
ated. (It is then up to the constraint solver to perform simplification and
copying, if and when necessary.) In fact, the environment is suppressed al-
together: we define Jt : TK by induction on the structure of t--notice the
absence of the parameter \Gamma  . Then, the constraint J\Gamma  ` t : TK discussed above
becomes syntactic sugar for let \Gamma  in Jt : TK. We now employ the full constraint
language: the program identifiers that appear free in t may also appear free in
Jt : TK, as part of instantiation constraints. They become bound when Jt : TK
is placed within the context let \Gamma  in []. A similar approach to constraint gen-
eration appears in Mu"ller (1994).

The defining equations for Jt : TK appear in Figure 10-9. We refer to them
as the constraint generation rules. The definition is quite terse and certainly
simpler than the declarative specification of HM(X) given in Figure 10-7; yet,
we prove below that the two are equivalent.

Before explaining the definition, we state the requirements that bear on
the type variables X1, X2, and X, which appear bound in the right-hand sides
of the second, third, and fourth equations. These type variables must have
kind ?. They must be chosen distinct (that is, X1 6= X2 in the second equa-
tion) and fresh for the objects that appear on the left-hand side--that is, the
type variables that appear bound in an equation's right-hand side must not
occur free in the term and type that appear in the equation's left-hand side.
Provided this restriction is obeyed, different choices of X1, X2, and X lead
to ff-equivalent constraints--that is, to the same constraint, since we iden-
tify objects up to ff-conversion--which guarantees that the above equations
make sense. Since expressions do not have free type variables, the freshness
requirement may be simplified to: type variables that appear bound in an
equation's right-hand side must not appear free in T. However, this simplifica-
tion would be rendered invalid by the introduction of open type annotations

432 10 The Essence of ML Type Inference

within expressions. Note that we are able to state a precise (as opposed to in-
formal) freshness requirement. This is made possible by the fact that Jt : TK
has no free type variables other than those of T, which in turn depends on
our explicit use of existential quantification to limit the scope of auxiliary
variables.

Let us now review the four equations. The first equation may be read: x
has type T if and only if T is an instance of the type scheme associated with
x. Note that we no longer consult the type scheme associated with x in the
environment--indeed, there is no environment. Instead, we merely generate
an instantiation constraint, where x appears free. (For this reason, every pro-
gram identifier that occurs free within t typically also occurs free within
Jt : TK.) This constraint acquires its full meaning when it is later placed within
a context of the form let x : oe in []. This equation roughly corresponds to
hmd-VarInst. The second equation may be read: *z.t has type T if and only
if, for some X1 and X2, (i) under the assumption that z has type X1, t has type
X2, and (ii) T is a supertype of X1 ! X2. Here, the types associated with z
and t must be fresh type variables, namely X1 and X2, because we cannot in
general guess them. These type variables are bound so as to guarantee that
the generated constraint is unique up to ff-conversion. They are existentially
bound because we intend the constraint solver to discover their value. Con-
dition (i) is expressed by the subconstraint let z : X1 in Jt : X2K. This makes
sense as follows. The constraint Jt : X2K typically contains a number of in-
stantiation constraints bearing on z, of the form z _ Ti. By wrapping it within
the context let z : X1 in [], we effectively require every Ti to be a supertype
of X1. Note that z does not occur free in the constraint let z : X1 in Jt : X2K,
which is necessary for well-formedness of the definition, since it does not
occur free in *z.t. This equation roughly corresponds to hmd-Exists, hmd-
Abs, and hmd-Sub. The third equation may be read: t1 t2 has type T if and
only if, for some X2, t1 has type X2 ! T and t2 has type X2. Here, the fresh
type variable X2 stands for the unknown type of t2. This equation roughly
corresponds to hmd-App. The last equation, which roughly corresponds to
hmd-LetGen, may be read: let z = t1 in t2 has type T if and only if, under
the assumption that z has every type X such that Jt1 : XK holds, t2 has type
T. As in the case of *-abstractions, the instantiation constraints bearing on z
that appear within Jt2 : TK are given a meaning via a let prefix. The difference
is that z may now be assigned a type scheme, as opposed to a monotype.
An appropriate type scheme is built as follows. The constraint Jt1 : XK is the
least specific constraint that must be imposed on the fresh type variable X
so as to make it a valid type for t1. In other words, t1 has every type X such
that Jt1 : XK holds, and none other. That is, the type scheme 8X[Jt1 : XK].X,
abbreviated oe in the following, is a principal type scheme for t1. It is inter-

10.4 Constraint Generation 433
esting to note that there is no question of which type variables to generalize.
Indeed, by construction, no type variables other than X may appear free in
Jt1 : XK, so we cannot generalize more variables. On the other hand, it is valid
to generalize X, since it does not appear free anywhere else. This interesting
simplification is inspired by Sulzmann, Mu"ller, and Zenger (1999), where a
similar technique is used. Now, what happens when Jt2 : TK is placed inside
the context let z : oe in []? When placed inside this context, an instantiation
constraint of the form z _ T0 acquires the meaning oe _ T0, which by defini-
tion of oe and by Lemma 10.4.6 (see below) is equivalent to Jt1 : T0K. Thus, the
constraint produced by the fourth equation simulates a textual expansion of
the let construct, where every occurrence of z would be replaced with t1.
Thanks to type scheme introduction and instantiation constraints, however,
this effect is achieved without duplication of source code or constraints. In
other words, constraint generation has linear time and space complexity.

10.4.2 Exercise [n', 3]: Define the size of an expression, of a type, and of a con-

straint, viewed as abstract syntax trees. Check that the size of Jt : TK is linear
in the sum of the sizes of t and T. 2

10.4.3 Exercise [Recommended, n', 3]: Compute and simplify, as best as you can,

the constraint Jlet f = *z.z in f f : TK. 2

We now state several properties of constraint generation. We begin with
soundness, whose statement was explained above.

10.4.4 Theorem [Soundness]: let \Gamma  in Jt : TK, \Gamma  ` t : T. 2

The following lemmas are used in the proof of the completeness property
and in a number of other occasions. The first two state that Jt : TK is covari-
ant with respect to T. Roughly speaking, this means that enough subtyping
constraints are generated to achieve completeness with respect to hmd-Sub.

10.4.5 Lemma: Jt : TK ^ T <= T0 dh Jt : T0K. 2
10.4.6 Lemma: X 62 ftv(T) implies 9X.(Jt : XK ^ X <= T) j Jt : TK. 2

The next lemma gives a simplified version of the second constraint genera-
tion rule, in the specific case where the expected type is an arrow type. Thus,
fresh type variables need not be generated; one may directly use the arrow's
domain and codomain instead.

10.4.7 Lemma: J*z.t : T1 ! T2K is equivalent to let z : T1 in Jt : T2K. 2

We conclude with the completeness property. The theorem states that if,
within HM(X), t has type T under assumptions C and \Gamma  , then C must be at

434 10 The Essence of ML Type Inference

least as specific as let \Gamma  in Jt : TK. The statement requires C and \Gamma  to have
no free program identifiers, which is natural, since they are part of an HM(X)
judgment. The hypothesis C dh 9\Gamma  excludes the somewhat pathological situa-
tion where \Gamma  contains constraints not apparent in C. This hypothesis vanishes
when \Gamma  is the initial environment; see Definition 10.5.2.

10.4.8 Theorem [Completeness]: Let C dh 9\Gamma  . Assume fpi(C, \Gamma  ) = IJ. If C, \Gamma  ` t : T

holds in HM(X), then C entails let \Gamma  in Jt : TK. 2

10.5 Type Soundness

We are now ready to establish type soundness for our type system. The
statement that we wish to prove is sometimes known as Milner's slogan:
"Well-typed programs do not go wrong" (Milner, 1978). Below, we define well-
typedness in terms of our constraint generation rules, for the sake of con-
venience, and establish type soundness with respect to that particular def-
inition. Theorems 10.3.6 and 10.4.8 imply that type soundness also holds
when well-typedness is defined with respect to the typing judgments of DM
or HM(X). We establish type soundness by following Wright and Felleisen's
so-called syntactic approach (1994). The approach consists of isolating two in-
dependent properties. Subject reduction, whose exact statement will be given
below, implies that well-typedness is preserved by reduction. Progress states
that no stuck configuration is well-typed. It is immediate to check that, if both
properties hold, then no well-typed program can reduce to a stuck configu-
ration. Subject reduction itself depends on a key lemma, usually known as a
(term) substitution lemma. Here is a version of this lemma, stated in terms of
the constraint generation rules.

10.5.1 Lemma: let z : 8_X[Jt2 : T2K].T2 in Jt1 : T1K entails J[z , t2]t1 : T1K. 2

Before going on, let us give a few definitions and formulate several re-
quirements. First, we must define an initial environment \Gamma 0, which assigns a
type scheme to every constant. A couple of requirements must be established
to ensure that \Gamma 0 is consistent with the semantics of constants, as specified

by ffi-!. Second, we must extend constraint generation and well-typedness to
configurations, as opposed to programs, since reduction operates on configu-
rations. Last, we must formulate a restriction to tame the interaction between
side effects and let-polymorphism, which is unsound if unrestricted.

10.5.2 Definition: Let \Gamma 0 be an environment whose domain is the set of constants

Q. We require ftv(\Gamma 0) = IJ, fpi(\Gamma 0) = IJ, and 9\Gamma 0 j true. We refer to \Gamma 0 as the
initial typing environment. 2

10.5 Type Soundness 435
10.5.3 Definition: Let ref be an isolated, invariant type constructor of signature

? ) ?. A store type M is a finite mapping from memory locations to types. We
write ref M for the environment that maps every m 2 dom(M) to ref M(m).
Assuming dom(u) and dom(M) coincide, the constraint Ju : MK is defined
as the conjunction of the constraints Ju(m) : M(m)K, where m ranges over
dom(u). Under the same assumption, the constraint Jt/u : T/MK is defined
as Jt : TK ^ Ju : MK. A closed configuration t/u is well-typed if and only if
there exist a type T and a store type M such that dom(u) = dom(M) and the
constraint let \Gamma 0; ref M in Jt/u : T/MK is satisfiable. 2

The type ref T is the type of references (that is, memory locations) that
store data of type T (TAPL, Chapter 13). It must be invariant in its parameter,
reflecting the fact that references may be both read and written.

A store is a complex object: it may contain values that indirectly refer to
each other via memory locations. In fact, it is a representation of the graph
formed by objects and pointers in memory, which may contain cycles. We rely
on store types to deal with such cycles. In the definition of well-typedness,
the store type M imposes a constraint on the contents of the store--the value
u(m) must have type M(m)--but also plays the role of a hypothesis: by plac-
ing the constraint Jt/u : T/MK within the context let ref M in [], we give
meaning to free occurrences of memory locations within Jt/u : T/MK, and
stipulate that it is valid to assume that m has type M(m). In other words, we
essentially view the store as a large, mutually recursive binding of locations
to values. The context let \Gamma 0 in [] gives meaning to occurrences of constants
within Jt/u : T/MK.

We now define a relation between configurations that plays a key role in the
statement of the subject reduction property. The point of subject reduction is
to guarantee that well-typedness is preserved by reduction. However, such a
simple statement is too weak to be amenable to inductive proof. Thus, for the
purposes of the proof, we must be more specific. To begin, let us consider the
simpler case of a pure semantics, that is, a semantics without stores. Then,
we must state that if an expression t has type T under a certain constraint,
then its reduct t0 has type T under the same constraint. In terms of generated
constraints, this statement becomes: let \Gamma 0 in Jt : TK entails let \Gamma 0 in Jt0 : TK.
Let us now return to the general case, where a store is present. The state-
ment of well-typedness for a configuration t/u now involves a store type
M whose domain is that of u. So, the statement of well-typedness for its
reduct t0/u0 must involve a store type M0 whose domain is that of u0, which
is larger if allocation occurred. The types of existing memory locations must
not change: we must request that M and M0 agree on dom(M), that is, M0
must extend M. Furthermore, the types assigned to new memory locations in

436 10 The Essence of ML Type Inference

dom(M0)\dom(M) might involve new type variables, that is, variables that do
not appear free in M or T. We must allow these variables to be hidden--that
is, existentially quantified--otherwise the entailment assertion cannot hold.
These considerations lead us to the following definition:

10.5.4 Definition: t/u v t0/u0 holds if and only if, for every type T and for every

store type M such that dom(u) = dom(M), there exist a set of type variables
_Y and a store type M0 such that _Y # ftv(T, M) and ftv(M0) ` _Y [ ftv(M) and

dom(M0) = dom(u0) and M0 extends M and

let \Gamma 0; ref M in Jt /u : T/M K
dh 9_Y.let \Gamma 0; ref M0 in Jt0/u0 : T/M0K.

The relation v is intended to express a connection between a configuration
and its reduct. Thus, subject reduction may be stated as: (--n~) ` (v), that
is, v is indeed a conservative description of reduction. 2

We have introduced an initial environment \Gamma 0 and used it in the definition
of well-typedness, but we haven't yet ensured that the type schemes assigned
to constants are an adequate description of their semantics. We now for-

mulate two requirements that relate \Gamma 0 with ffi-!. They are specializations of
the subject reduction and progress properties to configurations that involve
an application of a constant. They represent proof obligations that must be

discharged when concrete definitions of Q, ffi-!, and \Gamma 0 are given.

10.5.5 Definition: We require (i) ( ffi-!) ` (v); and (ii) if the configuration c v1 . . .

vk/u (where k >= 0) is well-typed, then either it is reducible, or c v1 . . . vk is a
value. 2

The last point that remains to be settled before proving type soundness
is the interaction between side effects and let-polymorphism. The following
example illustrates the problem:

let r = ref *z.z in let = (r := *z.(z ^+ ^1)) in !r true
This expression reduces to true ^+ ^1, so it must not be well-typed. Yet, if
natural type schemes are assigned to ref, !, and := (see Example 10.7.5), then
it is well-typed with respect to the rules given so far, because r receives the
polymorphic type scheme 8X.ref (X ! X), which allows writing a function of
type int ! int into r and reading it back with type bool ! bool. The problem
is that let-polymorphism simulates a textual duplication of the let-bound
expression ref *z.z, while the semantics first reduces it to a value m, causing
a new binding m , *z.z to appear in the store, then duplicates the address m.

10.5 Type Soundness 437
The new store binding is not duplicated: both copies of m refer to the same
memory cell. For this reason, generalization is unsound in this case, and must
be restricted. Many authors have attempted to come up with a sound type
system that accepts all pure programs and remains flexible enough in the
presence of side effects (Tofte, 1988; Leroy, 1992). These proposals are often
complex, which is why they have been abandoned in favor of an extremely
simple syntactic restriction, known as the value restriction (Wright, 1995).

10.5.6 Definition: A program satisfies the value restriction if and only if all subex-

pressions of the form let z = t1 in t2 are in fact of the form let z = v1 in
t2. In the following, we assume that either all constants have pure semantics,
or all programs satisfy the value restriction. 2

Put slightly differently, the value restriction states that only values may be
generalized. This eliminates the problem altogether, since duplicating values
does not affect a program's semantics. Note that any program that does not
satisfy the value restriction can be turned into one that does and has the
same semantics: it suffices to change let z = t1 in t2 into (*z.t2) t1 when
t1 is not a value. Of course, such a transformation may cause the program to
become ill-typed. In other words, the value restriction causes some perfectly
safe programs to be rejected. In particular, in its above form, it prevents gen-
eralizing applications of the form c v1 . . . vk, where c is a destructor of arity
k. This is excessive, because many destructors have pure semantics; only a
few, such as ref, allocate new mutable storage. Furthermore, we use pure
destructors to encode numerous language features ($10.7). Fortunately, it is
easy to relax the restriction to allow generalizing not only values, but also
a more general class of nonexpansive expressions, whose syntax guarantees
that such expressions cannot allocate new mutable storage (that is, expand
the domain of the store). The term nonexpansive was coined by Tofte (1988).
Nonexpansive expressions may include applications of the form c t1 . . . tk,
where c is a pure destructor of arity k and t1, . . . , tk are nonexpansive. Ex-
perience shows that this slightly relaxed restriction is acceptable in practice.
Some limitations remain: for instance, constructor functions (that is, func-
tions that do not allocate mutable storage and build a value) are regarded
as ordinary functions, so their applications are considered potentially expan-
sive, even though a naked constructor application would be a value and thus
considered nonexpansive. For instance, in the expression let f = c v in
let z = f w in t, where c is a constructor of arity 2, the partial application
c v, to which the name f is bound, is a constructor function (of arity 1). The
program variable z cannot receive a polymorphic type scheme, because f w
is not a value, even though it has the same semantic meaning as c v w, which
is a value. A recent improvement to the value restriction (Garrigue, 2004)

438 10 The Essence of ML Type Inference

provides a partial remedy. Technically, the effect of the value restriction (as
stated in Definition 10.5.6) is summarized by the following result.

10.5.7 Lemma: Under the value restriction, the production E ::= let z = E in t

may be suppressed from the grammar of evaluation contexts (Figure 10-1)
without altering the operational semantics. 2

We are finished with definitions and requirements. Let us now turn to the
type soundness results.

10.5.8 Theorem [Subject reduction]: (--n~) ` (v). 2

Subject reduction ensures that well-typedness is preserved by reduction.
10.5.9 Corollary: Let t/u --n~ t0/u0. If t/u is well-typed, then so is t0/u0. 2

Let us now state the progress property.
10.5.10 Theorem [Progress]: If t/u is well-typed, then either it is reducible, or t is

a value. 2

We may now conclude:
10.5.11 Theorem [Type Soundness]: Well-typed source programs do not go wrong. 2

Recall that this result holds only if the requirements of Definition 10.5.5 are
met. In other words, some proof obligations remain to be discharged when

concrete definitions of Q, ffi-!, and \Gamma 0 are given. This is illustrated by several
examples in $10.7 and $10.8.

10.6 Constraint Solving

We have introduced a parameterized constraint language, given equivalence
laws describing the interaction between its logical connectives, and exploited
them to prove theorems about type inference and type soundness, which
are valid independently of the nature of primitive constraints--the so-called
predicate applications. However, there would be little point in proposing a
parameterized constraint solver, because much of the difficulty of design-
ing an efficient constraint solver lies precisely in the treatment of primitive
constraints and in its interaction with let-polymorphism. In this section, we
focus on constraint solving in the setting of an equality-only free tree model.
Thus, the constraint solver developed here allows performing type inference
for HM(=) (that is, for Damas and Milner's type system) and for its extension
with recursive types. Of course, some of its mechanisms may be useful in
other settings. The program analysis and type inference literature abounds

10.6 Constraint Solving 439
with constraint-based systems of all kinds; a short list of papers that put par-
ticular emphasis on constraint solving is Aiken and Wimmers (1992), Hen-
glein (1993), Niehren, Mu"ller, and Podelski (1997), Fa"hndrich (1999), Melski
and Reps (2000), Mu"ller, Niehren, and Treinen (2001), Pottier (2001b), Niel-
son, Nielson, and Seidl (2002), McAllester (2002; 2003), and Simonet (2003).

We begin with a rule-based presentation of a standard, efficient first-order
unification algorithm. This yields a constraint solver for a subset of the con-
straint language, except for the type scheme introduction and instantiation
forms. On top of it, we build a full constraint solver, which corresponds to
the code that accompanies this chapter.

Unification
Unification is the process of solving equations between terms. It was first
introduced by Robinson (1971), but his original algorithm could be very in-
efficient. Efficient algorithms, which perform unification in quasi-linear time,
were independently proposed by Martelli and Montanari (1976; 1982) and by
Huet (1976, Chapter 5). Both algorithms rely on a data structure that effi-
ciently solves the union-find problem (Tarjan, 1975). Martelli and Montanari's
algorithm performs unification in topological (top-down) order, and is thus
restricted to the acyclic case, that is, to the case where equations are inter-
preted in a syntactic model. In this specific case, unification may actually be
performed in truly linear time (Paterson and Wegman, 1978). On the other
hand, Huet's algorithm is able to deal with cyclic structures. The acyclicity
check is postponed until the very end of the solving process if equations are
interpreted within a syntactic model, or omitted altogether if working within
a regular tree model. Except for the final acyclicity check, Huet's algorithm is
incremental. Furthermore, it is simple; we present a version of it here. Knight
(1989) and Baader and Siekmann (1994) also describe Huet's algorithm, and
provide further historical background and references.

Following Jouannaud and Kirchner (1991), we specify the algorithm as a
(nondeterministic) system of constraint rewriting rules. As suggested above,
it is almost the same for finite and regular tree models; only one rule, which
implements the occurs check, must be removed in the latter case. In other
words, the algorithm works with possibly cyclic data structures and does
not rely in an essential way on the occurs check. In order to more closely
reflect the behavior of the actual algorithm, and in particular the union-find
data structure, we modify the syntax of constraints by replacing equations
with multi-equations--equations involving an arbitrary number of types, as
opposed to exactly two.

440 10 The Essence of ML Type Inference

10.6.1 Definition: Let there be, for every kind ^ and for every n >= 1, a predicate

=n^, of signature ^n ) *, whose interpretation is (n-ary) equality. The predicate
constraint =n^ T1 . . . Tn is written T1 = . . . = Tn, and called a multi-equation.
We consider the constraint true as a multi-equation of length 0 and let ffl
range over all multi-equations. In the following, we identify multi-equations
up to permutations of their members, so a multi-equation ffl of kind ^ may
be viewed as a finite multiset of types of kind ^. We write ffl = ffl0 for the
multi-equation obtained by concatenating ffl and ffl0. 2

Thus, we are interested in the following subset of the constraint language:

U ::= true | false | ffl | U ^ U | 9_X.U
Equations are replaced with multi-equations; no other predicates are avail-
able. Type scheme introduction and instantiation forms are absent.

10.6.2 Definition: A multi-equation is standard if and only if its variable mem-

bers are distinct and it has at most one nonvariable member. A constraint
U is standard if and only if every multi-equation inside U is standard and
every variable that occurs (free or bound) in U is a member of at most one
multi-equation inside U. (Note that to be a member of ffl implies, but is not
equivalent to, to occur free in ffl.) 2

A union-find algorithm maintains equivalence classes (that is, disjoint sets)
of variables, and associates with each class a descriptor, which in our case is
either absent or a nonvariable term. Thus, a standard constraint represents
a state of the union-find algorithm. A constraint that is not standard may be
viewed as a superposition of a state of the union-find algorithm, on the one
hand, and of control information, on the other hand. For instance, a multi-
equation of the form ffl = T1 = T2, where ffl is made up of distinct variables
and T1 and T2 are nonvariable terms, may be viewed, roughly speaking, as the
equivalence class ffl = T1, together with a pending request to solve T1 = T2 and
to update the class's descriptor accordingly. Because multi-equations encode
both state and control, our specification of the unification algorithm remains
rather abstract. It would be possible to give a lower-level description, where
state (standard conjunctions of multi-equations) and control (pending binary
equations) are distinguished.

10.6.3 Definition: Let U be a conjunction of multi-equations. Y is dominated by X

with respect to U (written: Y OEU X) if and only if U contains a conjunct of the
form X = F ~T = ffl, where Y 2 ftv(_T). U is cyclic if and only if the graph of OEU
exhibits a cycle. 2

10.6 Constraint Solving 441
(9_X.U1) ^ U2 ! 9_X.(U1 ^ U2) (S-ExAnd)

if _X # ftv(U2)

X = ffl ^ X = ffl0 ! X = ffl = ffl0 (S-Fuse)

X = X = ffl ! X = ffl (S-Stutter)
F ~X = F ~T = ffl ! ~X = ~T ^ F ~X = ffl (S-Decompose)
F T1 . . . Ti . . . Tn = ffl ! 9X.(X = Ti ^ F T1 . . . X . . . Tn = ffl) (S-Name-1)

if Ti 62 V ^ X 62 ftv(T1, . . . , Tn, ffl)

F ~T = F0 ~T0 = ffl ! false (S-Clash)

if F 6= F0

T ! true (S-Single)
U ^ true ! U (S-True)

U ! false (S-Cycle)

if the model is syntactic and U is cyclic

U[false] ! false (S-Fail)

if U 6= []

Figure 10-10: Unification

The specification of the unification algorithm consists of a set of constraint
rewriting rules, given in Figure 10-10. Rewriting is performed modulo ff-
conversion, modulo permutations of the members of a multi-equation, mod-
ulo commutativity and associativity of conjunction, and under an arbitrary
context. The specification is nondeterministic: several rule instances may be
simultaneously applicable.

S-ExAnd is a directed version of C-ExAnd, whose effect is to float up all
existential quantifiers. In the process, all multi-equations become part of a
single conjunction, possibly causing rules whose left-hand side is a conjunc-
tion of multi-equations, namely S-Fuse and S-Cycle, to become applicable.
S-Fuse identifies two multi-equations that share a common variable X, and
fuses them. The new multi-equation is not necessarily standard, even if the
two original multi-equations were. Indeed, it may have repeated variables or
contain two nonvariable terms. The purpose of the next few rules, whose
left-hand side consists of a single multi-equation, is to deal with these sit-
uations. S-Stutter eliminates redundant variables. It only deals with vari-

442 10 The Essence of ML Type Inference

ables, as opposed to terms of arbitrary size, so as to have constant time cost.
The comparison of nonvariable terms is implemented by S-Decompose and
S-Clash. S-Decompose decomposes an equation between two terms whose
head symbols match. It produces a conjunction of equations between their
subterms, namely ~X = ~T. Only one of the two terms remains in the original
multi-equation, which may thus become standard. The terms ~X are copied:
there are two occurrences of ~X on the right-hand side. For this reason, we
require them to be type variables, as opposed to terms of arbitrary size. (We
slightly abuse notation by using ~X to denote a vector of type variables whose
elements are not necessarily distinct.) By doing so, we allow explicit reasoning
about sharing: since a variable represents a pointer to an equivalence class,
we explicitly specify that only pointers, not whole terms, are copied. As a
result of this decision, S-Decompose is not applicable when both terms at
hand have a nonvariable subterm. S-Name-1 remedies this problem by intro-
ducing a fresh variable that stands for one such subterm. When repeatedly
applied, S-Name-1 yields a unification problem composed of so-called small
terms only--that is, where sharing has been made fully explicit. S-Clash com-
plements S-Decompose by dealing with the case where two terms with differ-
ent head symbols are equated; in a free tree model, such an equation is false,
so failure is signaled. S-Single and S-True suppress multi-equations of size
1 and 0, respectively, which are tautologies. S-Cycle is the occurs check: it
signals failure if the constraint is cyclic. It is applicable only in the case of
syntactic unification, that is, when ground types are finite trees. It is a global
check: its left-hand side is an entire conjunction of multi-equations. S-Fail
propagates failure; U ranges over unification constraint contexts.

The constraint rewriting system in Figure 10-10 enjoys the following prop-
erties. First, rewriting is strongly normalizing, so the rules define a (nonde-
terministic) algorithm. Second, rewriting is meaning-preserving. Third, every
normal form is either false or of the form 9_X.U, where U is satisfiable. The
latter two properties indicate that the algorithm is indeed a constraint solver.

10.6.4 Lemma: The rewriting system ! is strongly normalizing. 2
10.6.5 Lemma: U1 ! U2 implies U1 j U2. 2
10.6.6 Lemma: Every normal form is either false or of the form X[U], where X is an

existential constraint context, U is a standard conjunction of multi-equations
and, if the model is syntactic, U is acyclic. These conditions imply that U is
satisfiable. 2

10.6 Constraint Solving 443
A Constraint Solver
On top of the unification algorithm, we now define a constraint solver. Its
specification is independent of the rules and strategy employed by the uni-
fication algorithm. However, the structure of the unification algorithm's nor-
mal forms as well as the logical properties of multi-equations are exploited
when performing generalization, that is, when creating and simplifying type
schemes. Like the unification algorithm, the constraint solver is specified in
terms of a reduction system. However, the objects that are subject to rewrit-
ing are not just constraints: they have more complex structure. Working
with such richer states allows distinguishing the solver's external language--
namely, the full constraint language, which is used to express the problem
that one wishes to solve--and an internal language, introduced below, which
is used to describe the solver's private data structures. In the following, C
and D range over external constraints, that is, constraints that were part of
the solver's input. External constraints are to be viewed as abstract syntax
trees, subject to no implicit laws other than ff-conversion. As a simplifying
assumption, we require external constraints not to contain any occurrence of
false--otherwise the problem at hand is clearly false. Internal data structures
include unification constraints U, as previously studied, and stacks, whose
syntax is as follows:

S ::= [] | S[[] ^ C] | S[9_X.[]] | S[let x : 8_X[[]].T in C] | S[let x : oe in []]
In the second and fourth productions, C is an external constraint. In the last
production, we require oe to be of the form 8_X[U].X, and we demand 9oe j
true. Every stack may be viewed as a one-hole constraint context (page 410);
indeed, one may interpret [] as the empty context and *[*] as context com-
position, which replaces the hole of its first context argument with its second
context argument. A stack may also be viewed, literally, as a list of frames.
Frames may be added and deleted at the inner end of a stack, that is, near the
hole of the constraint context that it represents. We refer to the four kinds of
frames as conjunction, existential, let, and environment frames, respectively.
A state of the constraint solver is a triple S; U; C where S is a stack, U is a
unification constraint, and C is an external constraint. The state S; U; C is to
be understood as a representation of the constraint S[U ^ C], that is, the
constraint obtained by placing both U and C within the hole of the constraint
context S. The notion of ff-equivalence between states is defined accordingly.
In particular, one may rename type variables in dtv(S), provided U and C are
renamed as well. In brief, the three components of a state play the following
roles. C is an external constraint that the solver intends to examine next. U

444 10 The Essence of ML Type Inference

is the internal state of the underlying unification algorithm; one might think
of it as the knowledge that has been obtained so far. S tells where the type
variables that occur free in U and C are bound, associates type schemes with
the program variables that occur free in C, and records what should be done
after C is solved. The solver's initial state is usually of the form []; true; C,
where C is the external constraint that one wishes to solve, that is, whose
satisfiability one wishes to determine. If the constraint to be solved is of the
form let \Gamma 0 in C, and if the type schemes that appear within \Gamma 0 meet the
requirements that bear on environment frames, as defined above, then it is
possible to pick let \Gamma 0 in []; true; C as an initial state. For simplicity, we make
the (unessential) assumption that states have no free type variables.

The solver consists of a (nondeterministic) state rewriting system, given in
Figure 10-11. Rewriting is performed modulo ff-conversion. S-Unify makes
the unification algorithm a component of the constraint solver, and allows the
current unification problem U to be solved at any time. Rules S-Ex-1 to S-Ex-4
float existential quantifiers out of the unification problem into the stack and
through the stack up to the nearest enclosing let frame, if there is any, or to
the outermost level, otherwise. Their side-conditions prevent capture of type
variables, and can always be satisfied by suitable ff-conversion of the left-
hand state. If S; U; C is a normal form with respect to these five rules, then U
must be either false or a conjunction of standard multi-equations, and every
type variable in dtv(S) must be either universally quantified at a let frame or
existentially bound at the outermost level. (Recall that, by assumption, states
have no free type variables.) In other words, provided these rules are applied
in an eager fashion, there is no need for existential frames to appear in the
machine representation of stacks. Instead, it suffices to maintain, at every let
frame and at the outermost level, a list of the type variables that are bound
at this point and, conversely, to annotate every type variable in dtv(S) with
an integer rank, which allows telling, in constant time, where the variable is
bound: type variables of rank 0 are bound at the outermost level, and type
variables of rank k >= 1 are bound at the kth let frame down in the stack S.
The code that accompanies this chapter adopts this convention. Ranks were
initially described in Re'my (1992a) and have also been studied by McAllester
(2003).

Rules S-Solve-Eq to S-Solve-Let encode an analysis of the structure of the
third component of the current state. There is one rule for each possible case,
except false, which by assumption cannot arise, and true, which is dealt with
further on. S-Solve-Eq discovers an equation and makes it available to the
unification algorithm. S-Solve-Id discovers an instantiation constraint x _ T
and replaces it with oe _ T, where the type scheme oe = S(x) is the type

10.6 Constraint Solving 445

S; U; C ! S; U0; C (S-Unify)

if U ! U0

S; 9_X.U; C ! S[9_X.[]]; U; C (S-Ex-1)

if _X # ftv(C)

S[(9_X.S0) ^ D]; U; C ! S[9_X.(S0 ^ D)]; U; C (S-Ex-2)

if _X # ftv(D)

S[let x : 8_X[9_Y.S0].T in D]; U; C ! S[let x : 8_X_Y[S].0T in D]; U; C (S-Ex-3)

if _Y # ftv(T)

S[let x : oe in 9_X.S0]; U; C ! S[9_X.let x : oe in S0]; U; C (S-Ex-4)

if _X # ftv(oe )

S; U; T1 = T2 ! S; U ^ T1 = T2; true (S-Solve-Eq)

S; U; x _ T ! S; U; S(x) _ T (S-Solve-Id)
S; U; C1 ^ C2 ! S[[] ^ C2]; U; C1 (S-Solve-And)

S; U; 9_X.C ! S[9_X.[]]; U; C (S-Solve-Ex)

if _X # ftv(U)

S; U; let x : 8_X[D].T in C ! S[let x : 8_X[[]].T in C]; U; D (S-Solve-Let)

if _X # ftv(U)

S[[] ^ C]; U; true ! S; U; C (S-Pop-And)
S[let x : 8_X[[]].T in C]; U; true ! S[let x : 8_XX[[]].X in C];

U ^ X = T; true (S-Name-2)
if X 62 ftv(U, T) ^ T 62 V

S[let x : 8_XY[[]].X in C]; Y = Z = ffl ^ U; true ! S[let x : 8_XY[[]].`(X) in C];

Y ^ Z = `(ffl) ^ `(U); true (S-Compress)
if Y 6= Z ^ ` = [Y , Z]

S[let x : 8_XY[[]].X in C]; Y = ffl ^ U; true ! S[let x : 8_X[[]].X in C]; ffl ^ U; true (S-UnName)

if Y 62 X [ ftv(ffl, U)

S[let x : 8_X_Y[[]].X in C]; U; true ! S[9_Y.let x : 8_X[[]].X in C]; U; true (S-LetAll)

if _Y # ftv(C) ^ 9_X.U determines _Y

S[let x : 8_X[[]].X in C]; U1 ^ U2; true ! S[let x : 8_X[U2].X in []]; U1; C (S-Pop-Let)

if _X # ftv(U1) ^ 9_X.U2 j true

S[let x : oe in []]; U; true ! S; U; true (S-Pop-Env)

Figure 10-11: A constraint solver

446 10 The Essence of ML Type Inference

scheme carried by the nearest environment frame that defines x in the stack
S. It is defined as follows:

S[[] ^ C](x) = S(x)

S[9_X.[]](x) = S(x) if _X # ftv(S(x))
S[let y : 8_X[[]].T in C](x) = S(x) if _X # ftv(S(x))

S[let y : oe in []](x) = S(x) if x 6= y
S[let x : oe in []](x) = oe

If x 2 dpi(S) does not hold, then S(x) is undefined and the rule is not appli-
cable. If it does hold, then the rule may always be made applicable by suitable
ff-conversion of the left-hand state. Recall that, if oe is of the form 8_X[U].X,
where _X # ftv(T), then oe _ T stands for 9_X.(U ^ X = T). The process of
constructing this constraint is informally referred to as "taking an instance
of oe ." In the worst case, it is just as inefficient as textually expanding the
corresponding let construct in the program's source code, and leads to ex-
ponential time complexity. In practice, however, the unification constraint
U is often compact because it was simplified before the environment frame
let x : oe in [] was created, which explains why the solver usually performs
well. (The creation of environment frames, performed by S-Pop-Let, is dis-
cussed below.) S-Solve-And discovers a conjunction. It arbitrarily chooses to
explore the left branch first, and pushes a conjunction frame onto the stack,
so as to record that the right branch should be explored afterwards. S-Solve-
Ex discovers an existential quantifier and enters it, creating a new existential
frame to record its existence. Similarly, S-Solve-Let discovers a let form and
enters its left-hand side, creating a new let frame to record its existence. The
choice of examining the left-hand side first is not arbitrary. Indeed, examin-
ing the right-hand side first would require creating an environment frame--
but environment frames must contain simplified type schemes of the form
8_X[U].X, whereas the type scheme 8_X[D].T is arbitrary. In other words, our
strategy is to simplify type schemes prior to allowing them to be copied by
S-Solve-Id, so as to avoid any duplication of effort. The side-conditions of S-
Solve-Ex and S-Solve-Let may always be satisfied by suitable ff-conversion
of the left-hand state.

Rules S-Solve-Eq to S-Solve-Let may be referred to as forward rules, be-
cause they "move down into" the external constraint, causing the stack to
grow. This process stops when the external constraint at hand becomes true.
Then part of the work has been finished, and the solver must examine the
stack in order to determine what to do next. This task is performed by the
last series of rules, which may be referred to as backward rules, because they
"move back out," causing the stack to shrink and possibly scheduling new
external constraints for examination. These rules encode an analysis of the

10.6 Constraint Solving 447
structure of the innermost stack frame. There are three cases, correspond-
ing to conjunction, let, and environment frames. The case of existential stack
frames need not be considered, because rules S-Ex-2 to S-Ex-4 allow either
fusing them with let frames or floating them up to the outermost level, where
they shall remain inert. S-Pop-And deals with conjunction frames. The frame
is popped, and the external constraint that it carries is scheduled for exam-
ination. S-Pop-Env deals with environment frames. Because the right-hand
side of the let construct at hand has been solved--that is, turned into a uni-
fication constraint U--it cannot contain an occurrence of x. Furthermore, by
assumption, 9oe is true. Thus, this environment frame is no longer useful: it
is destroyed. The remaining rules deal with let frames. Roughly speaking,
their purpose is to change the state S[let x : 8_X[[]].T in C]; U; true into
S[let x : 8_X[U].T in []]; true; C, that is, to turn the current unification con-
straint U into a type scheme, turn the let frame into an environment frame,
and schedule the right-hand side of the let construct (that is, the external
constraint C) for examination. In fact, the process is more complex, because
the type scheme 8_X[U].T must be simplified before becoming part of an en-
vironment frame. The simplification process is described by rules S-Name-2
to S-Pop-Let. In the following, we refer to type variables in _X as young and
to type variables in dtv(S) \ _X as old. The former are the universal quanti-
fiers of the type scheme that is being created; the latter contain its free type
variables.

S-Name-2 ensures that the body T of the type scheme that is being created
is a type variable, as opposed to an arbitrary term. If it isn't, then it is re-
placed with a fresh variable X, and the equation X = T is added so as to recall
that X stands for T. Thus, the rule moves the term T into the current unifica-
tion problem, where it potentially becomes subject to S-Name-1. This ensures
that sharing is made explicit everywhere. S-Compress determines that the
(young) type variable Y is an alias for the type variable Z. Then, every free
occurrence of Y other than its defining occurrence is replaced with Z. In an
actual implementation, this occurs transparently when the union-find algo-
rithm performs path compression (Tarjan, 1975, 1979). We note that the rule
does not allow substituting a younger type variable for an older one; indeed,
that would make no sense, since the younger variable could then possibly
escape its scope. In other words, in implementation terms, the union-find al-
gorithm must be slightly modified so that, in each equivalence class, the rep-
resentative element is always a type variable with minimum rank. S-UnName
determines that the (young) type variable Y has no occurrences other than its
defining occurrence in the current type scheme. (This occurs, in particular,
when S-Compress has just been applied.) Then, Y is suppressed altogether.
In the particular case where the remaining multi-equation ffl has cardinal 1,

448 10 The Essence of ML Type Inference

it may then be suppressed by S-Single. In other words, the combination of
S-UnName and S-Single is able to suppress young unused type variables as
well as the term that they stand for. This may, in turn, cause new type vari-
ables to become eligible for elimination by S-UnName. In fact, assuming the
current unification constraint is acyclic, an inductive argument shows that
every young type variable may be suppressed unless it is dominated either
by X or by an old type variable. (In the setting of a regular tree model, it is
possible to extend the rule so that young cycles that are not dominated either
by X or by an old type variable are suppressed as well.) S-LetAll is a directed
version of C-LetAll. It turns the young type variables _Y into old variables.
How to tell whether 9_X.U determines _Y is discussed later (see Lemma 10.6.7).
Why S-LetAll is an interesting and important rule will be explained shortly.
S-Pop-Let is meant to be applied when the current state has become a nor-
mal form with respect to S-Unify, S-Name-2, S-Compress, S-UnName, and
S-LetAll, that is, when the type scheme that is about to be created is fully
simplified. It splits the current unification constraint into two components
U1 and U2, where U1 is made up entirely of old variables, as expressed by
the side-condition _X # ftv(U1), and U2 constrains young variables only, as
expressed by the side-condition 9_X.U2 j true. Note that U2 may still con-
tain free occurrences of old type variables, so the type scheme 8_X[U2].X that
appears on the right-hand side is not necessarily closed. It is not obvious
why such a decomposition must exist; Lemma 10.6.10 proves that it does.
Let us say for now that S-LetAll plays a role in guaranteeing its existence,
whence comes part of its importance. Once the decomposition U1 ^ U2 is
obtained, the behavior of S-Pop-Let is simple. The unification constraint U1
concerns old variables only, that is, variables that are not quantified in the
current let frame; thus, it need not become part of the new type scheme and
may instead remain part of the current unification constraint. This is justi-
fied by C-LetAnd and C-InAnd* and corresponds to the difference between
hmx-Gen' and hmx-Gen discussed in $10.3. The unification constraint U2, on
the other hand, becomes part of the newly built type scheme 8_X[U2].X. The
property 9_X.U2 j true guarantees that the newly created environment frame
meets the requirements imposed on such frames. Note that the more type
variables are considered old, the larger U1 may become, and the smaller U2.
This is another reason why S-LetAll is interesting: by allowing more vari-
ables to be considered old, it decreases the size of the type scheme 8_X[U2].X,
making it cheaper to instantiate.

To complete our description of the constraint solver, there remains to ex-
plain how to decide when 9_X.U determines _Y, since this predicate occurs in
the side-condition of S-LetAll. The following lemma describes two important
situations where, by examining the structure of an equation, it is possible to

10.6 Constraint Solving 449
discover that a constraint C determines some of its free type variables _Y (Def-
inition 10.2.14). In the first situation, the type variables _Y are equated with or
dominated by a distinct type variable X that occurs free in C. In that case,
because the model is a free tree model, the values of the type variables _Y
are determined by the value of X: they are subtrees of it at specific positions.
For instance, X = Y1 ! Y2 determines Y1Y2, while 9Y1.(X = Y1 ! Y2) deter-
mines Y2. In the second situation, the type variables _Y are equated with a
term T, all of whose type variables are free in C. Again, the value of the type
variables _Y is then determined by the values of the type variables ftv(T). For
instance, X = Y1 ! Y2 determines X, while 9Y1.(X = Y1 ! Y2) does not. In the
second situation, no assumption is in fact made about the model. (Note that
X = Y1 ! Y2 determines Y1Y2 and determines X, but does not simultaneously
determine XY1Y2.)

10.6.7 Lemma: Let _X # _Y. Assume either ffl is X = ffl0, where X 62 _X_Y and _Y ` ftv(ffl0), or

ffl is _Y = T = ffl0, where ftv(T) # _X_Y. Then, 9_X.(C ^ ffl) determines _Y. 2

Thanks to Lemma 10.6.7, an efficient implementation of S-LetAll comes
to mind. The problem is, given a constraint 9_X.U, where U is a standard con-
junction of multi-equations, to determine the greatest subset _Y of _X such that
9(_X \ _Y).U determines _Y. By the first part of the lemma, it is safe for _Y to in-
clude all members of _X that are directly or indirectly dominated (with respect
to U) by some free variable of 9_X.U. Those can be found, in time linear in
the size of U, by a top-down traversal of the graph of OEU . By the second part
of the lemma, it is safe to close _Y under the closure law X 2 _X ^ (8Y Y OEU
X ) Y 2 _Y) ) X 2 _Y. That is, it is safe to also include all members of _X
whose descendants (with respect to U) have already been found to be mem-
bers of _Y. This closure computation may be performed, again in linear time,
by a bottom-up traversal of the graph of OEU . When U is acyclic, it is possible
to show that this procedure is complete, that is, does compute the greatest
subset _Y that meets our requirement.

The above discussion has shown that when Y and Z are equated, if Y is
young and Z is old, then S-LetAll allows making Y old as well. If binding
information is encoded in terms of integer ranks, as suggested earlier, then
this remark may be formulated as follows: when Y and Z are equated, if the
rank of Y exceeds that of Z, then it may be decreased so that both ranks
match. As a result, it is possible to attach ranks with multi-equations, rather
than with variables. When two multi-equations are fused, the smaller rank is
kept. This treatment of ranks is inspired by Re'my (1992a); see the resolution
rule Fuse, as well as the simplification rules Propagate and Realize, in that
paper.

450 10 The Essence of ML Type Inference

Let us now state the properties of the constraint solver. First, the reduction
system is terminating, so it defines an algorithm.

10.6.8 Lemma: The reduction system ! is strongly normalizing. 2

Second, every rewriting step preserves the meaning of the constraint that
the current state represents. We recall that the state S; U; C is meant to rep-
resent the constraint S[U ^ C].

10.6.9 Lemma: S; U; C ! S0; U0; C0 implies S[U ^ C] j S0[U0 ^ C0]. 2

Last, we classify the normal forms of the reduction system:
10.6.10 Lemma: A normal form for the reduction system ! is one of (i) S; U; x _ T,

where x 62 dpi(S); (ii) S; false; true; or (iii) X; U; true, where X is an existential
constraint context and U a satisfiable conjunction of multi-equations. 2

In case (i), the constraint S[U ^ C] has a free program identifier x. In other
words, the source program contains an unbound program identifier. Such an
error could of course be detected prior to constraint solving, if desired. In
case (ii), the unification algorithm failed. By Lemma 10.2.17, the constraint
S[U ^ C] is then false. In case (iii), the constraint S[U ^ C] is equivalent to
X[U], where U is satisfiable, so it is satisfiable as well. If the initial constraint
is closed, case (i) cannot arise, while cases (ii) and (iii) respectively denote
failure and success. Thus, Lemmas 10.6.9 and 10.6.10 indeed prove that the
algorithm is a constraint solver.

10.6.11 Remark: Type inference for ML-the-calculus is dexptime-complete (Kfoury,

Tiuryn, and Urzyczyn, 1990; Mairson, Kanellakis, and Mitchell, 1991). Thus,
our constraint solver cannot run any faster, asymptotically. This cost is es-
sentially due to let-polymorphism, which requires a constraint to be du-
plicated at every occurrence of a let-bound variable (S-Solve-Id). In order
to limit the amount of duplication to a bare minimum, it is important that
rule S-LetAll be applied before S-Pop-Let, allowing variables and constraints
that need not be duplicated to be shared. We have observed that algorithms
based on this strategy behave remarkably well in practice (Re'my, 1992a). In
fact, McAllester (2003) has proved that they have linear time complexity, pro-
vided the size of type schemes and the (left-) nesting depth of let constructs
are bounded. Unfortunately, many implementations of type inference for ML-
the-programming-language do not behave as efficiently as the algorithm pre-
sented here. Some spend an excessive amount of time in computing the set
of nongeneralizable type variables; some do not treat types as dags, thus los-
ing precious sharing information; others perform the expensive occurs check
after every unification step, rather than only once at every let construct, as
suggested here (S-Pop-Let). 2

10.7 From ML-the-Calculus to ML-the-Language 451
10.7 From ML-the-Calculus to ML-the-Language

In this section, we explain how to extend the framework developed so far
to accommodate operations on values of base type (such as integers), pairs,
sums, references, and recursive function definitions. Then, we describe alge-
braic data type definitions. Last, the issues associated with recursive types
are briefly discussed. For space reasons, exceptions are not discussed; the
reader is referred to (TAPL, Chapter 14).

Simple Extensions
Introducing new constants and extending ffi-! and \Gamma 0 appropriately allows
adding many features of ML-the-programming-language to ML-the-calculus. In
each case, it is necessary to check that the requirements of Definition 10.5.5
are met, that is, to ensure that the new initial environment faithfully reflects
the nature of the new constants as well as the behavior of the new reduc-
tion rules. Below, we describe several such extensions in isolation. The first
exercise establishes a technical result that is useful in the next exercises.

10.7.1 Exercise [Recommended, n']: Let \Gamma 0 contain the binding c : 8_X.T1 ! . . . !

Tn ! T. Prove let \Gamma 0 in Jc t1 . . . tn : T0K equivalent to let \Gamma 0 in 9_X.(Vni=1Jti :
TiK ^ T <= T0). 2

10.7.2 Exercise [Integers, Recommended, n'n']: Integer literals and integer addition

have been introduced and given an operational semantics in Examples 10.1.1,
10.1.2, and 10.1.4. Let us now introduce an isolated type constructor int of
signature ? and extend the initial environment \Gamma 0 with the bindings ^n : int,
for every integer n, and ^+ : int ! int ! int. Check that these definitions meet
the requirements of Definition 10.5.5. 2

10.7.3 Exercise [Pairs, n'n', 3]: Pairs and pair projections have been introduced and

given an operational semantics in Examples 10.1.3 and 10.1.5. Let us now in-
troduce an isolated type constructor * of signature ? \Omega  ? ) ?, covariant in
both of its parameters, and extend the initial environment \Gamma 0 with the follow-
ing bindings:

(*, *) : 8XY.X ! Y ! X * Y

ss1 : 8XY.X * Y ! X
ss2 : 8XY.X * Y ! Y

Check that these definitions meet the requirements of Definition 10.5.5. 2

10.7.4 Exercise [Sums, n'n', 3]: Sums have been introduced and given an operational

semantics in Example 10.1.7. Let us now introduce an isolated type construc-
tor + of signature ? \Omega  ? ) ?, covariant in both of its parameters, and extend

452 10 The Essence of ML Type Inference

the initial environment \Gamma 0 with the following bindings:

inj1 : 8XY.X ! X + Y
inj2 : 8XY.Y ! X + Y

case : 8XYZ.(X + Y) ! (X ! Z) ! (Y ! Z) ! Z

Check that these definitions meet the requirements of Definition 10.5.5. 2
10.7.5 Exercise [References, n'n'n']: References have been introduced and given an

operational semantics in Example 10.1.9. The type constructor ref has been
introduced in Definition 10.5.3. Let us now extend the initial environment \Gamma 0
with the following bindings:

ref : 8X.X ! ref X

! : 8X.ref X ! X
:= : 8X.ref X ! X ! X

Check that these definitions meet the requirements of Definition 10.5.5. 2
10.7.6 Exercise [Recursion, Recommended, n'n'n', 3]: The fixpoint combinator fix

has been introduced and given an operational semantics in Example 10.1.10.
Let us now extend the initial environment \Gamma 0 with the following binding:

fix : 8XY.((X ! Y) ! (X ! Y)) ! X ! Y
Check that these definitions meet the requirements of Definition 10.5.5. Re-
call how the letrec syntactic sugar was defined in Example 10.1.10, and
check that this gives rise to the following constraint generation rule:

let \Gamma 0 in Jletrec f = *z.t1 in t2 : TK
j let \Gamma 0 in let f : 8XY[let f : X ! Y; z : X in Jt1 : YK].X ! Y in Jt2 : TK

Note the somewhat peculiar structure of this constraint: the program variable
f is bound twice in it, with different type schemes. The constraint requires
all occurrences of f within t1 to be assigned the monomorphic type X ! Y.
This type is generalized and turned into a type scheme before inspecting t2,
however, so every occurrence of f within t2 may receive a different type, as
usual with let-polymorphism. A more powerful way of typechecking recur-
sive function definitions, proposed by (Mycroft, 1984) and known as polymor-
phic recursion, allows the types of occurrences of f within t1 to be possibly
distinct instances of a single type scheme. However, type inference for this
extension is equivalent to semi-unification (Henglein, 1993), which has been
proved undecidable (Kfoury, Tiuryn, and Urzyczyn, 1993). Hence, type infer-
ence must either require type annotations or rely on a semi-algorithm. 2

10.7 From ML-the-Calculus to ML-the-Language 453

In the exercises above, we have considered a number of extensions (inte-
gers, booleans, pairs, etc.) in isolation. We have checked that each of them
preserves type soundness. Unfortunately, this does not in general imply that
their combination preserves type soundness. In fact, it is possible to prove
that these extensions are independent in a suitable sense and that indepen-
dent extensions may be safely combined. Unfortunately, we lack space to
further explain these notions.

Algebraic Data Types
Exercises 10.7.3 and 10.7.4 have shown how to extend the language with bi-
nary, anonymous products and sums. These constructs are quite general but
still have several shortcomings. First, they are only binary, while we would
like to have k-ary products and sums, for arbitrary k >= 0. Such a general-
ization is of course straightforward. Second, more interestingly, their compo-
nents must be referred to by numeric index (as in "extract the second com-
ponent of the pair"), rather than by name ("extract the component named y").
In practice, it is crucial to use names, because they make programs more
readable and more robust in the face of changes. One could introduce a
mechanism that allows defining names as syntactic sugar for numeric in-
dices. That would help a little, but not much, because these names would
not appear in types, which would still be made of anonymous products and
sums. Third, in the absence of recursive types, products and sums do not
have sufficient expressiveness to allow defining unbounded data structures,
such as lists. Indeed, it is easy to see that every value whose type T is com-
posed of base types (int, bool, etc.), products, and sums must have bounded
size, where the bound | T | is a function of T. More precisely, up to a con-
stant factor, we have | int | = | bool | = 1, | T1 * T2 | = 1 + | T1 | + | T2 |, and
| T1 + T2 | = 1 + max(| T1 |, | T2 |). The following example describes another
facet of the same problem.

10.7.7 Example: A list is either empty, or a pair of an element and another list. So,

it seems natural to try and encode the type of lists as a sum of some arbitrary
type (say, unit) on the one hand, and of a product of some element type and of
the type of lists itself on the other hand. With this encoding in mind, we can
go ahead and write code--for instance, a function that computes the length
of a list:

letrec length = *l.case l (* .^0) (*z.^1 ^+ length (ss2 z))
We have used integers, pairs, sums, and the letrec construct introduced in
the previous section. The code analyzes the list l using a case construct.

454 10 The Essence of ML Type Inference

If the left branch is taken, the list is empty, so 0 is returned. If the right
branch is taken, then z becomes bound to a pair of some element and the
tail of the list. The latter is obtained using the projection operator ss2. Its
length is computed using a recursive call to length and incremented by 1.
This code makes perfect sense. However, applying the constraint generation
and constraint solving algorithms eventually leads to an equation of the form
X = Y + (Z * X), where X stands for the type of l. This equation accurately re-
flects our encoding of the type of lists. However, in a syntactic model, it has
no solution, so our definition of length is ill-typed. It is possible to adopt
a free regular tree model, thus introducing equirecursive types into the sys-
tem (TAPL, Chapter 20); however, there are good reasons not to do so (see
the section on Recursive Types on p. 459). 2

To work around this problem, ML-the-programming-language offers alge-
braic data type definitions, whose elegance lies in the fact that, while repre-
senting only a modest theoretical extension, they do solve the three problems
mentioned above. An algebraic data type may be viewed as an abstract type
that is declared to be isomorphic to a (k-ary) product or sum type with named
components. The type of each component is declared, as well, and may refer
to the algebraic data type that is being defined: thus, algebraic data types are
isorecursive (TAPL, Chapter 20). In order to allow sufficient flexibility when
declaring the type of each component, algebraic data type definitions may be
parameterized by a number of type variables. Last, in order to allow the de-
scription of complex data structures, it is necessary to allow several algebraic
data types to be defined at once; the definitions may then be mutually recur-
sive. In fact, in order to simplify this formal presentation, we assume that
all algebraic data types are defined at once at the beginning of the program.
This decision is, of course, at odds with modular programming but will not
otherwise be a problem.

In the following, D ranges over a set of data types. We assume that data
types form a subset of type constructors. We require each of them to be iso-
lated and to have image kind ?. Furthermore, ` ranges over a set L of labels,
which we use both as data constructors and as record labels. An algebraic
data type definition is either a variant type definition or a record type defini-
tion, whose respective forms are

D ~X ss

kX

i=1

`i : Ti and D ~X ss

kY

i=1

`i : Ti.

In either case, k must be nonnegative. If D has signature ~^ ) ?, then the type
variables ~X must have kind ~^. Every Ti must have kind ?. We refer to _X as
the parameters and to ~T (the vector formed by T1, . . . , Tk) as the components

10.7 From ML-the-Calculus to ML-the-Language 455
of the definition. The parameters are bound within the components, and the
definition must be closed, that is, ftv(~T) ` _X must hold. Last, for an algebraic
data type definition to be valid, the behavior of the type constructor D with
respect to subtyping must match its definition. This requirement is clarified
below.

10.7.8 Definition: Consider an algebraic data type definition whose parameters

and components are respectively ~X and ~T. Let ~X0 and ~T0 be their images under
an arbitrary renaming. Then, D ~X <= D ~X0 dh ~T <= ~T0 must hold. 2

Because it is stated in terms of an entailment assertion, the above require-
ment bears on the interpretation of subtyping. The idea is, since D ~X is de-
clared to be isomorphic to (a sum or a product of) ~T, whenever two types
built with D are comparable, their unfoldings should be comparable as well.
The reverse entailment assertion is not required for type soundness, and it
is sometimes useful to declare algebraic data types that do not validate it--
so-called phantom types (Fluet and Pucella, 2002). Note that the requirement
may always be satisfied by making the type constructor D invariant in all of
its parameters. Indeed, in that case, D ~X <= D ~X0 entails ~X = ~X0, which must en-
tail ~T = ~T0 since ~T0 is precisely [~X , ~X0]~T. In an equality free tree model, every
type constructor is naturally invariant, so the requirement is trivially satis-
fied. In other settings, however, it is often possible to satisfy the requirement
of Definition 10.7.8 while assigning D a less restrictive variance. The following
example illustrates such a case.

10.7.9 Example: Let list be a data type of signature ? ) ?. Let Nil and Cons be data

constructors. Then, the following is a definition of list as a variant type:

list X ss \Sigma  (Nil : unit; Cons : X * list X)
Because data types form a subset of type constructors, it is valid to form the
type list X in the right-hand side of the definition, even though we are still in
the process of defining the meaning of list. In other words, data type defini-
tions may be recursive. However, because ss is not interpreted as equality, the
type list X is not a recursive type: it is nothing but an application of the unary
type constructor list to the type variable X. To check that the definition of list
satisfies the requirement of Definition 10.7.8, we must ensure that

list X <= list X0 dh unit <= unit ^ X * list X <= X0 * list X0
holds. This assertion is equivalent to list X <= list X0 dh X <= X0. To satisfy the
requirement, it is sufficient to make list a covariant type constructor, that is,
to define subtyping in the model so that list X <= list X0 j X <= X0 holds.

456 10 The Essence of ML Type Inference

Let tree be a data type of signature ? ) ?. Let root and sons be record
labels. Then, the following is a definition of tree as a record type:

tree X ss \Pi  (root : X; sons : list (tree X))
This definition is again recursive, and relies on the previous definition. Be-
cause list is covariant, it is straightforward to check that the definition of tree
is valid if tree is made a covariant type constructor as well. 2

A prologue is a set of algebraic data type definitions, where each data type
is defined at most once and where each data constructor or record label ap-
pears at most once. A program is a pair of a prologue and an expression.
The effect of a prologue is to enrich the programming language with new
constants. That is, a variant type definition extends the operational seman-
tics with several injections and a case construct, as in Example 10.1.7. A
record type definition extends it with a record formation construct and sev-
eral projections, as in Examples 10.1.3 and 10.1.5. In either case, the initial
typing environment \Gamma 0 is extended with information about these new con-
stants. Thus, algebraic data type definitions might be viewed as a simple
configuration language that allows specifying in which instance of ML-the-
calculus the expression that follows the prologue should be typechecked and
interpreted. Let us now give a precise account of this phenomenon.

To begin, suppose the prologue contains the definition D ~X ss Pki=1 `i : Ti.
Then, for each i 2 {1, . . . , k}, a constructor of arity 1, named `i, is introduced.
Furthermore, a destructor of arity k + 1, named caseD, is introduced. When
k > 0, it is common to write case t [`i : ti]ki=1 for the application caseD t t1
. . . tn. The operational semantics is extended with the following reduction
rules, for i 2 {1, . . . , k}:

case (`i v) [`j : vj ]kj=1 ffi-! vi v (R-Alg-Case)
For each i 2 {1, . . . , k}, the initial environment is extended with the binding
`i : 8_X.Ti ! D ~X. It is further extended with the binding caseD : 8_XZ.D ~X !
(T1 ! Z) ! . . . (Tk ! Z) ! Z.

Now, suppose the prologue contains the definition D ~X ss Qki=1 `i : Ti. Then,
for each i 2 {1, . . . , k}, a destructor of arity 1, named `i, is introduced. Fur-
thermore, a constructor of arity k, named makeD, is introduced. It is common
to write t.` for the application ` t and, when k > 0, to write {`i = ti}ki=1 for
the application makeD t1 . . . tk. The operational semantics is extended with
the following reduction rules, for i 2 {1, . . . , k}:

({`j = vj }kj=1).`i ffi-! vi (R-Alg-Proj)
For each i 2 {1, . . . , k}, the initial environment is extended with the binding
`i : 8_X.D ~X ! Ti. It is further extended with the binding makeD : 8_X.T1 ! . . . !
Tk ! D ~X.

10.7 From ML-the-Calculus to ML-the-Language 457
10.7.10 Example: The effect of defining list (Example 10.7.9) is to make Nil and Cons

data constructors of arity 1 and to introduce a binary destructor caselist. The
definition also extends the initial environment as follows:

Nil : 8X.unit ! list X
Cons : 8X.X * list X ! list X
caselist : 8XZ.list X ! (unit ! Z) ! (X * list X ! Z) ! Z

Thus, the value Cons(^0, Nil()), an integer list of length 1, has type list int. A
function that computes the length of a list may now be written as follows:

letrec length = *l.case l [ Nil : * .^0 | Cons : *z.^1 ^+ length (ss2 z) ]
Recall that this notation is syntactic sugar for

letrec length = *l.caselist l (* .^0) (*z.^1 ^+ length (ss2 z))
The difference with the code in Example 10.7.7 appears minimal: the case
construct is now annotated with the data type list. As a result, the type infer-
ence algorithm employs the type scheme assigned to caselist, which is derived
from the definition of list, instead of the type scheme assigned to the anony-
mous case construct, given in Exercise 10.7.4. This is good for a couple of
reasons. First, the former is more informative than the latter, because it con-
tains the type Ti associated with the data constructor `i. Here, for instance,
the generated constraint requires the type of z to be X * list X for some X, so
a good error message would be given if a mistake was made in the second
branch, such as omitting the use of ss2. Second, and more fundamentally,
the code is now well-typed, even in the absence of recursive types. In Exam-
ple 10.7.7, a cyclic equation was produced because case required the type of
l to be a sum type and because a sum type carries the types of its left and
right branches as subterms. Here, caselist requires l to have type list X for
some X. This is an abstract type: it does not explicitly contain the types of
the branches. As a result, the generated constraint no longer involves a cyclic
equation. It is, in fact, satisfiable; the reader may check that length has type
8X.list X ! int, as expected. 2

Example 10.7.10 stresses the importance of using declared, abstract types,
as opposed to anonymous, concrete sum or product types, in order to obviate
the need for recursive types. The essence of the trick lies in the fact that the
type schemes associated with operations on algebraic data types implicitly
fold and unfold the data type's definition. More precisely, let us recall the type
scheme assigned to the ith injection in the setting of (k-ary) anonymous sums:
it is 8X1 . . . Xk.Xi ! X1 + . . . + Xk, or, more concisely, 8X1 . . . Xk.Xi ! Pki=1 Xi.

458 10 The Essence of ML Type Inference

By instantiating each Xi with Ti and generalizing again, we find that a more
specific type scheme is 8_X.Ti ! Pki=1 Ti. Perhaps this could have been the
type scheme assigned to `i? Instead, however, it is 8_X.Ti ! D ~X. We now re-
alize that the latter type scheme not only reflects the operational behavior
of the ith injection but also folds the definition of the algebraic data type D
by turning the anonymous sum Pki=1 Ti--which forms the definition's right-
hand side--into the parameterized abstract type D ~X--which is the definition's
left-hand side. Conversely, the type scheme assigned to caseD unfolds the
definition. The situation is identical in the case of record types: in either case,
constructors fold, destructors unfold. In other words, occurrences of data
constructors and record labels in the code may be viewed as explicit instruc-
tions for the typechecker to fold or unfold an algebraic data type definition.
This mechanism is characteristic of isorecursive types.

10.7.11 Exercise [n', 3]: For a fixed k, check that all of the machinery associated

with k-ary anonymous products--that is, constructors, destructors, reduction
rules, and extensions to the initial typing environment--may be viewed as the
result of a single algebraic data type definition. Conduct a similar check in the
case of k-ary anonymous sums. 2

10.7.12 Exercise [n'n'n', 3]: Check that the above definitions meet the requirements

of Definition 10.5.5. 2

10.7.13 Exercise [n'n'n', 3]: For the sake of simplicity, we have assumed that all data

constructors have arity one. If desired, it is possible to accept variant data
type definitions of the form D ~X ss Pki=1 `i : ~Ti, where the arity of the data con-
structor `i is the length of the vector ~Ti, and may be an arbitrary nonnegative
integer. This allows, for instance, altering the definition of list so that the
data constructors Nil and Cons are respectively nullary and binary. Make the
necessary changes in the above definitions and check that the requirements
of Definition 10.5.5 are still met. 2

One significant drawback of algebraic data type definitions resides in the
fact that a label ` cannot be shared by two distinct variant or record type
definitions. Indeed, every algebraic data type definition extends the calculus
with new constants. Strictly speaking, our presentation does not allow a sin-
gle constant c to be associated with two distinct definitions. Even if we did
allow such a collision, the initial environment would contain two bindings
for c, one of which would then hide the other. This phenomenon arises in
actual implementations of ML-the-programming-language, where a new alge-
braic data type definition may hide some of the data constructors or record
labels introduced by a previous definition. An elegant solution to this lack of
expressiveness is discussed in $10.8.

10.7 From ML-the-Calculus to ML-the-Language 459
Recursive Types
We have shown that specializing HM(X) with an equality-only syntactic model
yields HM(=), a constraint-based formulation of Damas and Milner's type
system. Similarly, it is possible to specialize HM(X) with an equality-only
free regular tree model, yielding a constraint-based type system that may be
viewed as an extension of Damas and Milner's type discipline with recursive
types. This flavor of recursive types is sometimes known as equirecursive,
since cyclic equations, such as X = X ! X, are then satisfiable. Our theo-
rems about type inference and type soundness, which are independent of the
model, remain valid. The constraint solver described in $10.6 may be used
in the setting of an equality-only free regular tree model; the only difference
with the syntactic case is that the occurs check is no longer performed.

Note that, although ground types are regular, types remain finite objects:
their syntax is unchanged. The u notation commonly employed to describe
recursive types may be emulated using type equations: for instance, the no-
tation uX.X ! X corresponds, in our constraint-based approach, to the type
scheme 8X[X = X ! X].X.

Although recursive types come for free, as explained above, they have not
been adopted in mainstream programming languages based on ML-the-type-
system. The reason is pragmatic: experience shows that many nonsensical
expressions are well-typed in the presence of recursive types, whereas they
are not in their absence. Thus, the gain in expressiveness is offset by the fact
that many programming mistakes are detected later than otherwise possible.
Consider, for instance, the following OCaml session:

ocaml -rectypes
# let rec map f = function

| [] ! []
| x :: l ! (map f x) :: (map f l);;
val map : 'a ! ('b list as 'b) ! ('c list as 'c) = <fun>

This nonsensical version of map is essentially useless, yet well-typed. Its prin-
cipal type scheme, in our notation, is 8XYZ[Y = list Y ^ Z = list Z].X ! Y ! Z.
In the absence of recursive types, it is ill-typed, since the constraint Y =
list Y ^ Z = list Z is then false.

The need for equirecursive types is usually suppressed by the presence of
algebraic data types, which offer isorecursive types, in the language. Yet, they
are still necessary in some situations, such as in Objective Caml's extensions
with objects (Re'my and Vouillon, 1998) or polymorphic variants (Garrigue,
1998, 2000, 2002), where recursive object or variant types are commonly in-
ferred. In order to allow recursive object or variant types while still rejecting
the above version of map, Objective Caml's constraint solver implements a

460 10 The Essence of ML Type Inference

selective occurs check, which forbids cycles unless they involve the type con-
structors h*i or [*] respectively associated with objects and variants. The
corresponding model is a tree model where every infinite path down a tree
must encounter the type constructor h*i or [*] infinitely often.

10.8 Rows

In $10.7, we have shown how to extend ML-the-programming-language with
algebraic data types, that is, variant and record type definitions, which we
now refer to as simple. This mechanism has a severe limitation: two distinct
definitions must define incompatible types. As a result, one cannot hope
to write code that uniformly operates over variants or records of different
shapes, because the type of such code is not even expressible.

For instance, it is impossible to express the type of the polymorphic record
access operation, which retrieves the value stored at a particular field ` inside
a record, regardless of which other fields are present. Indeed, if the label
` appears with type T in the definition of the simple record type D ~X, then
the associated record access operation has type 8_X.D ~X ! T. If ` appears
with type T0 in the definition of another simple record type, say D0 ~X0, then
the associated record access operation has type 8_X0.D0 ~X0 ! T0; and so on.
The most precise type scheme that subsumes all of these incomparable type
schemes is 8XY.X ! Y. It is, however, not a sound type scheme for the record
access operation. Another powerful operation whose type is currently not
expressible is polymorphic record extension, which copies a record and stores
a value at field ` in the copy, possibly creating the field if it did not previously
exist, again regardless of which other fields are present. (If ` was known to
previously exist, the operation is known as polymorphic record update.)

In order to assign types to polymorphic record operations, we must do
away with record type definitions: we must replace named record types, such
as D ~X, with structural record types that provide a direct description of the
record's domain and contents. (Following the analogy between a record and
a partial function from labels to values, we use the word domain to refer to
the set of fields that are defined in a record.) For instance, a product type is
structural: the type T1 * T2 is the (undeclared) type of pairs whose first com-
ponent has type T1 and whose second component has type T2. Thus, we wish
to design record types that behave very much like product types. In doing so,
we face two orthogonal difficulties. First, as opposed to pairs, records may
have different domains. Because the type system must statically ensure that
no undefined field is accessed, information about a record's domain must be
made part of its type. Second, because we suppress record type definitions,

10.8 Rows 461
labels must now be predefined. However, for efficiency and modularity rea-
sons, it is impossible to explicitly list every label in existence in every record
type.

In what follows, we explain how to address the first difficulty in the simple
setting of a finite set of labels. Then we introduce rows, which allow dealing
with an infinite set of labels, and address the second difficulty. We define the
syntax and logical interpretation of rows, study the new constraint equiva-
lence laws that arise in their presence, and extend the first-order unification
algorithm with support for rows. Then we review several applications of rows,
including polymorphic operations on records, variants, and objects, and dis-
cuss alternatives to rows.

Because our interest is in typechecking and type inference issues, we do
not address the compilation issue: how does one efficiently compile poly-
morphic records or polymorphic variants? A few relevant papers are Pugh
and Weddell (1990), Ohori (1995), and Garrigue (1998). The problem of op-
timizing message dispatch in object-oriented languages, which has received
considerable attention in the literature, is related.

Records with Finite Carrier
Let us temporarily assume that L is finite. In fact, for the sake of definiteness,
let us assume that L is the three-element set {`a, `b, `c}.

To begin, let us consider only full records, whose domain is exactly L--in
other words, tuples indexed by L. To describe them, it is natural to introduce
a type constructor \Pi  of signature ? \Omega  ? \Omega  ? ) ?. The type \Pi  Ta Tb Tc rep-
resents all records where the field `a (respectively `b, `c) contains a value
of type Ta (respectively Tb, Tc ). Note that \Pi  is nothing but a product type
constructor of arity 3. The basic operations on records, namely creation of
a record out of a default value, which is stored into every field, update of
a particular field (say, `b), and access to a particular field (say, `b), may be
assigned the following type schemes:

{*} : 8X.X ! \Pi  X X X
{* with `b = *} : 8XaXbX0bXc.\Pi  Xa Xb Xc ! X0b ! \Pi  Xa X0b Xc

*.{`b} : 8XaXbXc.\Pi  Xa Xb Xc ! Xb

Here, polymorphism allows updating or accessing a field without knowledge
of the types of the other fields. This flexibility stems from the key property
that all record types are formed using a single \Pi  type constructor.

This is fine, but in general, the domain of a record is not necessarily L: it
may be a subset of L. How may we deal with this fact while maintaining the
above key property? A naive approach consists of encoding arbitrary records

462 10 The Essence of ML Type Inference

in terms of full records, using the standard algebraic data type option, whose
definition is option X ss pre X+abs. We use pre for present and abs for absent:
indeed, a field that is defined with value v is encoded as a field with value pre
v, while an undefined field is encoded as a field with value abs. Thus, an arbi-
trary record whose fields, if present, have types Ta, Tb, and Tc, respectively,
may be encoded as a full record of type \Pi  (option Ta) (option Tb) (option
Tc). This naive approach suffers from a serious drawback: record types still
contain no domain information. As a result, field access must involve a dy-
namic check, so as to determine whether the desired field is present; in our
encoding, this corresponds to the use of caseoption.

To avoid this overhead and increase programming safety, we must move
this check from runtime to compile time. In other words, we must make the
type system aware of the difference between pre and abs. To do so, we re-
place the definition of option by two separate algebraic data type definitions,
namely pre X ss pre X and abs ss abs. In other words, we introduce a unary
type constructor pre, whose only associated data constructor is pre, and a
nullary type constructor abs, whose only associated data constructor is abs.
Record types now contain domain information; for instance, a record of type
\Pi  abs (pre Tb) (pre Tc) must have domain {`b, `c}. Thus, the type of a field
tells whether it is defined. Since the type pre has no data constructors other
than pre, the accessor pre-1, whose type is 8X.pre X ! X, and which allows
retrieving the value stored in a field, cannot fail. Thus, the dynamic check has
been eliminated.

To complete the definition of our encoding, we now define operations on
arbitrary records in terms of operations on full records. To distinguish be-
tween the two, we write the former with angle braces, instead of curly braces.
The empty record hi, where all fields are undefined, may be defined as {abs}.
Extension at a particular field (say, `b) h* with `b = *i is defined as *r.*z.
{r with `b = pre z}. Access at a particular field (say, `b) *.h`bi is defined as
*z.pre-1z.{`b}. It is straightforward to check that these operations have the
following principal type schemes:

hi : \Pi  abs abs abs
h* with `b = *i : 8XaXbX0bXc.\Pi  Xa Xb Xc ! X0b ! \Pi  Xa (pre X0b) Xc

*.h`bi : 8XaXbXc.\Pi  Xa (pre Xb) Xc ! Xb

It is important to notice that the type schemes associated with extension
and access at `b are polymorphic in Xa and Xc, which now means that these
operations are insensitive, not only to the type, but also to the presence or
absence of the fields `a and `c. Furthermore, extension is polymorphic in Xb,
which means that it is insensitive to the presence or absence of the field `b
in its argument. The subterm pre X0b in its result type reflects the fact that

10.8 Rows 463
`b is defined in the extended record. Conversely, the subterm pre Xb in the
type of the access operation reflects the requirement that `b be defined in its
argument.

Our encoding of arbitrary records in terms of full records was carried out
for pedagogical purposes. In practice, no such encoding is necessary: the data
constructors pre and abs have no machine representation, and the compiler
is free to lay out records in memory in an efficient manner. The encoding
is interesting, however, because it provides a natural way of introducing the
type constructors pre and abs, which play an important role in our treatment
of polymorphic record operations.

Once we forget about the encoding, the arguments of the type constructor
\Pi  are expected to be either type variables or formed with pre or abs, while,
conversely, the type constructors pre and abs are not intended to appear
anywhere else. It is possible to enforce this invariant using kinds. In addition
to ?, let us introduce the kind ffi of field types. Then, let us adopt the following
signatures: pre: ? ) ffi, abs : ffi, and \Pi  : ffi \Omega  ffi \Omega  ffi ) ?.

10.8.1 Exercise [Recommended, n', 3]: Check that the three type schemes given

above are well-kinded. What is the kind of each type variable? 2

10.8.2 Exercise [Recommended, n'n']: Our \Pi  types contain information about every

field, regardless of whether it is defined: we encode definedness informa-
tion within the type of each field, using the type constructors pre and abs.
A perhaps more natural approach would be to introduce a family of record
type constructors, indexed by the subsets of L, so that the types of records
with different domains are formed with different constructors. For instance,
the empty record would have type {}; a record that defines the field `a only
would have a type of the form {`a : Ta}; a record that defines the fields
`b and `c only would have a type of the form {`b : Tb; `c : Tc}; and so on.
Assuming that the type discipline is Damas and Milner's (that is, assuming
an equality-only syntactic model), would it be possible to assign satisfactory
type schemes to polymorphic record access and extension? Would it help to
equip record types with a nontrivial subtyping relation? 2

Records with Infinite Carrier
The treatment of records described above is not quite satisfactory, from prac-
tical and theoretical points of view. First, in practice, the set L of all record
labels that appear within a program could be very large. Because every record
type is just as large as L itself, even if the record that it describes only has a
few fields, this is unpleasant. Furthermore, in a modular setting, the set of all
record labels that appear within a program cannot be determined until link

464 10 The Essence of ML Type Inference

time, so it is still unknown at compile time, when each compilation unit is
separately typechecked. As a result, it may only be assumed to be a subset of
the infinite set of all syntactically valid record labels. Resolving these issues
requires coming up with a treatment of records that does not become more
costly as L grows and that, in fact, allows L to be infinite. Thus, from here
on, let us assume that L is infinite.

As in the previous section, we first concentrate on full records, whose do-
main is exactly L. The case of arbitrary records, whose domain is a subset of
L, will then follow in the same manner, by using the type constructors pre
and abs to encode domain information.

Of course, even though we have assumed that L is infinite, we must ensure
that every record has a finite representation. We choose to restrict our atten-
tion to records that are almost constant, that is, records where all fields but
a finite number contain the same value. Every such record may be defined in
terms of two primitive operations, namely (i) creation of a constant record
out of a value; for instance, {false} is the record where every field contains
the value false; and (ii) update of a record at a particular field; for instance,
{{false} with ` = 1} carries the value 1 at field ` and the value false at
every other field. As usual, an access operation allows retrieving the contents
of a field. Thus, the three primitive operations are the same as in the previous
subsection, only in the setting of an infinite number of fields.

If we were to continue as before, we would now introduce a type construc-
tor \Pi , equipped with an infinite family of type parameters. Because types
must remain finite objects, we cannot do so. Instead, we must find a finite
(and economical) representation of such an infinite family of types. This is
precisely the role played by rows.

A row is a type that denotes a function from labels to types or, equiva-
lently, a family of types indexed by labels. Its domain is L--the row is then
complete--or a cofinite subset of L--the row is then incomplete. (A subset of
L is cofinite if and only if its complement is finite. Incomplete rows are used
only as building blocks for complete rows.) Because rows must admit a finite
representation, we build them out of two syntactic constructions, namely (i)
construction of a constant row out of a type; for instance, the notation @bool
denotes a row that maps every label in its domain to bool; and (ii) strict ex-
tension of an incomplete row; for instance, (` : int ; @bool) denotes a row
that maps ` to int and every other field in its domain to bool. Formally, @ is
a unary type constructor, while, for every label `, (` : * ; *) is a binary type
constructor. These two constructions are reminiscent of the two operations
used above to build records. There are, however, a couple of subtle but im-
portant differences. First, @T may be a complete or incomplete row. Second,
(` : T ; T0) is defined only if ` is not in the domain of the row T0, so this

10.8 Rows 465
construction is strict extension, not update. These aspects are made clear by
a kinding discipline, to be introduced later on.

It is possible for two syntactically distinct rows to denote the same func-
tion from labels to types. For instance, according to the intuitive interpreta-
tion of rows given above, the three complete rows (` : int ; @bool), (` : int ;
(`0 : bool ; @bool)), and (`0 :bool ; (` : int ; @bool)) denote the same total func-
tion from labels to types. In the following, we define the logical interpretation
of types in such a way that the interpretations of these three rows in the
model are indeed equal.

We may now make the record type constructor \Pi  a unary type constructor,
whose parameter is a row. Then, (say) \Pi  (` : int ; @bool) is a record type, and
we intend it to be a valid type for the record {{false} with ` = 1}. The basic
operations on records may be assigned the following type schemes:

{*} : 8X.X ! \Pi  (@X)
{* with ` = *} : 8XX0Y.\Pi  (` : X ; Y) ! X0 ! \Pi  (` : X0 ; Y)

*.{`} : 8XY.\Pi  (` : X ; Y) ! X

These type schemes are reminiscent of those given above. However, in the
previous section, the size of the type schemes was linear in the cardinal of L,
whereas here it is constant, even though L is infinite. This is made possible
by the fact that record types no longer list all labels in existence; instead, they
use rows. In the type scheme assigned to record creation, the constant row
@X is used to indicate that all fields have the same type in the newly created
record. In the next two type schemes, the row (` : X` ; X) is used to separate
the type X`, which describes the contents of the field `, and the row X, which
collectively describes the contents of all other fields. Here, the type variable X
stands for an arbitrary row; it is often referred to as a row variable. The ability
of quantifying over row and type variables alike confers great expressiveness
to the type system.

We have explained, in an informal manner, how rows allow typechecking
operations on full records, in the setting of an infinite set of labels. We return
to this issue in Example 10.8.25. To deal with the case of arbitrary records,
whose domain is finite, we rely on the field type constructors pre and abs, as
explained previously. We return to this point in Example 10.8.30. In the fol-
lowing, we give a formal exposition of rows. We begin with their syntax and
logical interpretation. Then we give some new constraint equivalence laws,
which characterize rows, and allow extending our first-order unification al-
gorithm with support for rows. We conclude with several illustrations of the
use of rows and some pointers to related work.

466 10 The Essence of ML Type Inference

Syntax of Rows
In the following, the set of labels L is considered denumerable. We let L range
over finite subsets of L. When ` AE L holds, we write `.L for {`} ] L. Before
explaining how the syntax of types is enriched with rows, we introduce row
kinds, whose grammar is as follows:

s ::= Type | Row(L)
Row kinds help distinguish between three kinds of types, namely ordinary
types, complete rows, and incomplete rows. While ordinary types are used to
describe expressions, complete or incomplete rows are used only as building
blocks for ordinary types. For instance, the record type \Pi  (` : int ; @bool),
which was informally introduced above, is intended to be an ordinary type,
that is, a type of row kind Type. Its subterm (` : int ; @bool) is a complete row,
that is, a type of row kind Row(IJ). Its subterm @bool is an incomplete row,
whose row kind is Row({`}). Intuitively, a row of kind Row(L) denotes a fam-
ily of types whose domain is L\L. In other words, L is the set of labels that the
row does not define. The purpose of row kinds is to outlaw meaningless types,
such as \Pi  (int), which makes no sense because the argument to the record
type constructor \Pi  should be a (complete) row, or (` :T1 ; ` : T2 ; @bool), which
makes no sense because no label may occur twice within a row.

Let us now define the syntax of types in the presence of rows. As usual, it
is given by a signature S (Definition 10.1.14), which lists all type constructors
together with their signatures. Here, for the sake of generality, we do not wish
to give a fixed signature S. Instead, we give a procedure that builds S out of
two simpler signatures, referred to as S0 and S1. The input signature S0 lists
the type constructors that have nothing to do with rows, such as !, *, int,
etc. The input signature S1 lists the type constructors that allow a row to be a
subterm of an ordinary type, such as the record type constructor \Pi . In a type
system equipped with extensible variant types or with object types, there
might be several such type constructors; see the sections on Polymorphic
Variants (p. 483) and Other Applications of Rows (p. 486). Without loss of
generality, we assume that all type constructors in S1 are unary. The point of
parameterizing the definition of S over S0 and S1 is to make the construction
more general: instead of defining a fixed type grammar featuring rows, we
wish to explain how to enrich an arbitrary type grammar with rows.

In the following, we let G (respectively H) range over the type constructors
in S0 (respectively S1). We let ^ range over the kinds involved in the defini-
tion of S0 and S1, and refer to them as basic kinds. We let F range over the
type constructors in S. The kinds involved in the definition of S are com-
posite kinds, that is, pairs of a basic kind ^ and a row kind s, written ^.s.

10.8 Rows 467
This allows the kind discipline enforced by S to reflect that enforced by S0
and S1 and also to impose restrictions on the structure and use of rows,
as suggested above. For the sake of conciseness, we write K.s for the map-
ping (d , K(d).s)d2dom(K) and (K ) ^).s for the (composite) kind signature
K.s ) ^.s. (In other words, we let .s distribute over basic signatures.) We use
symmetric notations to build a composite kind signature out of a basic kind
and a row kind signature.

10.8.3 Definition: The signature S is defined as follows:

F 2 dom(S) Signature Conditions

Gs (K ) ^).s (G : K ) ^) 2 S0

H K.Row(IJ) ) ^.Type (H : K ) ^) 2 S1
@^,L ^.(Type ) Row(L))
`^,L ^.(Type \Omega  Row(`.L) ) Row(L)) ` AE L

We sometimes refer to S as the row extension of S0 with S1. 2
Examples 10.8.7 and 10.8.8 suggest common choices of S0 and S1 and give a
perhaps more concrete-looking definition of the grammar of types that they
determine. First, however, let us explain the definition. The type constructors
that populate S come in four varieties: they may be (i) taken from S0, (ii)
taken from S1, (iii) a unary row constructor @, or (iv) a binary row constructor
(` : * ; *). Let us review and explain each case.

Let us first consider case (i) and assume, for the time being, that s is Type.
Then, for every type constructor G in S0, there is a corresponding type con-
structor GType in S. For instance, S0 must contain an arrow type constructor
!, whose signature is {domain , ?, codomain , ?} ) ?. Then, S contains
a type constructor !Type, whose signature is {domain , ?.Type, codomain ,
?.Type} ) ?.Type. Thus, !Type is a binary type constructor whose parame-
ters and result must have basic kind ? and must have row kind Type; in other
words, they must be ordinary types, as opposed to complete or incomplete
rows. The family of all type constructors of the form GType, where G ranges
over S0, forms a copy of S0 at row kind Type: one might say, roughly speak-
ing, that S contains S0. This is not surprising, since our purpose is to enrich
the existing signature S0 with syntax for rows.

Perhaps more surprising is the existence of the type constructor Gs, for
every G in S0, and for every row kind s. For instance, for every L, S contains a
type constructor !Row(L), whose signature is {domain , ?.Row(L), codomain
, ?.Row(L)} ) ?.Row(L). Thus, !Row(L) is a binary type constructor whose
parameters and result must have basic kind ? and must have row kind Row(L).
In other words, this type constructor maps a pair of rows that have a common
domain to a row with the same domain. Recall that a row is to be interpreted

468 10 The Essence of ML Type Inference

as a family of types. Our intention is that !Row(L) maps two families of types
to a family of arrow types. This is made precise in the next subsection. One
should point out that the type constructors Gs , with s 6= Type, are required
only in some advanced applications of rows; Examples 10.8.28 and 10.8.39
provide illustrations. They are not used when assigning types to the usual
primitive operations on records, namely creation, update, and access (Exam-
ples 10.8.25 and 10.8.30).

Case (ii) is simple: it simply means that S contains S1. It is only worth
noting that every type constructor H maps a parameter of row kind Row(IJ)
to a result of row kind Type, that is, a complete row to an ordinary type.
Thanks to this design choice, the type \Pi  (intType) is invalid: indeed, intType
has row kind Type, while \Pi  expects a parameter of row kind Row(IJ).

Cases (iii) and (iv) introduce new type constructors that were not present
in S0 or S1 and allow forming rows. They were informally described in the
previous subsection. First, for every ^ and L, there is a constant row construc-
tor @^,L. Its parameter must have row kind Type, while its result has row kind
Row(L); in other words, this type constructor maps an ordinary type to a row.
It is worth noting that the row thus built may be complete or incomplete; for
instance, @?,IJ bool is a complete row, and may be used, for example, to build
the type \Pi  (@?,IJ bool), while @?,{`} bool is an incomplete row, and may be
used, for example, to build the type \Pi  (` : int ; @?,{`} bool). Second, for every
^, L, and ` AE L, there is a row extension constructor `^,L. We usually write
`^,L : T1 ; T2 for `^,L T1 T2 and let this symbol be right associative so as to
recover the familiar list notation for rows. According to the definition of S,
if T2 has row kind Row(`.L), then `^,L : T1 ; T2 has row kind Row(L). Thanks
to this design choice, the type (`?,L : T1 ; `?,L : T2 ; @?,`.L bool) is invalid; in-
deed, the outer ` expects a parameter of row kind Row(`.L), while the inner
` produces a type of row kind Row(L).

The superscripts carried by the type constructors G, `, and @ in the signa-
ture S make all kind information explicit, obviating the need for assigning
several kinds to a single type constructor. In practice, however, we often
drop the superscripts and use unannotated types. No ambiguity arises be-
cause, given a type expression T of known kind, it is possible to reconstruct
all superscripts in a unique manner. This is the topic of the next example and
exercises.

10.8.4 Example [Ill-kinded types]: Assume that S0 contains type constructors int

and !, whose signatures are respectively ? and ? \Omega  ? ) ?, and that S1
contains a type constructor \Pi , whose signature is ? ) ?.

The unannotated type X ! \Pi (X) is invalid. Indeed, because \Pi 's image row
kind is Type, the arrow must be !Type. Thus, the leftmost occurrence of X

10.8 Rows 469
must have row kind Type. On the other hand, because \Pi  expects a parameter
of row kind Row(IJ), its rightmost occurrence must have row kind Row(IJ)--a
contradiction. The unannotated type X ! \Pi (@X) is, however, valid, provided
X has kind ?.Type. In fact, it is the type of the primitive record creation oper-
ation.

The unannotated type (` : T ; ` : T ; T00) is also invalid: there is no way
of reconstructing the missing superscripts so as to make it valid. Indeed,
the row (` : T0 ; T00) must have row kind Row(L) for some L that does not
contain `. However, the context where it occurs requires it to also have row
kind Row(L) for some L that does contain `. This makes it impossible to
reconstruct consistent superscripts.

Any type of the form \Pi (\Pi (T)) is invalid, because the outer \Pi  expects a pa-
rameter of row kind Row(IJ), while the inner \Pi  constructs a type of row kind
Type. This is an intentional limitation: unlike those of S0, the type construc-
tors of S1 are not lifted to every row kind s. (If they were, we would be led to
work not only with rows of ordinary types, but also with rows of rows, rows
of rows of rows, and so on. Re'my (1990) explores this avenue.) 2

10.8.5 Exercise [Recommended, n']: Consider the unannotated type

X ! \Pi (` : int ; (Y ! @X)).
Can you guess the kind of the type variables X and Y, as well as the missing
superscripts, so as to ensure that this type has kind ?.Type? 2

10.8.6 Exercise [n'n'n', 3]: Propose a kind checking algorithm that, given an unan-

notated type T, given the kind of T, and given the kind of all type variables that
appear within T, ensures that T is well-kinded, and reconstructs the missing
superscripts within T. Next, propose a kind inference algorithm that, given an
unannotated type T, discovers the kind of T and the kind of all type variables
that appear within T so as to ensure that T is well-kinded. 2

We have given a very general definition of the syntax of types. In this view,
types, ranged over by the meta-variable T, encompass both "ordinary" types
and rows: the distinction between the two is established only via the kind
system. In the literature, however, it is common to establish this distinction
by letting distinct meta-variables, say T and R, range over ordinary types and
rows, respectively, so as to give the syntax a more concrete aspect. The next
two examples illustrate this style and suggest common choices for S0 and S1.

10.8.7 Example: Assume that there is a single basic kind ?, that S0 consists of the

arrow type constructor !, whose signature is ? \Omega  ? ) ?, and that S1 consists

470 10 The Essence of ML Type Inference

of the record type constructor \Pi , whose signature is ? ) ?. Then, the com-
posite kinds are ?.Type and ?.Row(L), where L ranges over the finite subsets
of L. Let us employ T (respectively R) to range over types of the former (re-
spectively latter) kind, and refer to them as ordinary types (respectively rows).
Then, the syntax of types, as defined by the signature S, may be presented
under the following form:

T ::= X | T ! T | \Pi  R
R ::= X | R ! R | (` : T ; R) | @T

Ordinary types T include ordinary type variables (that is, type variables of
kind ?.Type), arrow types (where the type constructor ! is really !Type), and
record types, which are formed by applying the record type constructor \Pi  to
a row. Rows R include row variables (that is, type variables of kind ?.Row(L)
for some L), arrow rows (where the row constructor ! is really !Row(L) for
some L), row extension (whereby a row R is extended with an ordinary type T
at a certain label `), and constant rows (formed out of an ordinary type T). It
would be possible to also introduce a syntactic distinction between ordinary
type variables and row variables, if desired.

Such a presentation is rather pleasant, because the syntactic segregation
between ordinary types and rows makes the syntax less ambiguous. It does
not allow getting rid of the kind system, however: (row) kinds are still neces-
sary to keep track of the domain of every row. 2

10.8.8 Example: Assume that there are two basic kinds ? and ffi, that S0 consists

of the type constructors !, abs, and pre, whose respective signatures are
?\Omega ? ) ?, ffi, and ? ) ffi, and that S1 consists of the record type constructor \Pi ,
whose signature is ffi ) ?. Then, the composite kinds are ?.Type, ?.Row(L),
ffi.Type, and ffi.Row(L), where L ranges over the finite subsets of L. Let us em-
ploy T?, R?, Tffi, and Rffi, respectively, to range over types of these four kinds.
Then, the syntax of types, as defined by the signature S, may be presented
under the following form:

T? ::= X | T? ! T? | \Pi  Rffi
R? ::= X | R? ! R? | (` : T? ; R?) | @T?

Tffi ::= X | abs | pre T?
Rffi ::= X | abs | pre R? | (` : Tffi ; Rffi) | @Tffi

Ordinary types T? are as in the previous example, except the record type
constructor \Pi  must now be applied to a row of field types Rffi. Rows R? are
unchanged. Field types Tffi include field type variables (that is, type variables
of kind ffi.Type) and applications of the type constructors abs and pre (which
are really absType and preType). Field rows Rffi include field row variables (that

10.8 Rows 471
is, type variables of kind ffi.Row(L) for some L), applications of the row con-
structors abs and pre (which are really absRow(L) and preRow(L) for some L),
row extension, and constant rows, where row components are field types Tffi.

In many basic applications of rows, absRow(L) and preRow(L) are never re-
quired: that is, they do not appear in the type schemes that populate the
initial environment. (Applications where they are required appear in Pot-
tier [2000].) In that case, they may be removed from the syntax. Then, the
nonterminal R? becomes unreachable from the nonterminal T?, which is the
grammar's natural entry point, so it may be removed as well. In that simpli-
fied setting, the syntax of types and rows becomes:

T? ::= X | T? ! T? | \Pi  Rffi

Tffi ::= X | abs | pre T?
Rffi ::= X | (` : Tffi ; Rffi) | @Tffi

This is the syntax found in some introductory accounts of rows (Re'my, 1989;
Pottier, 2000). 2

Meaning of Rows
We now give meaning to the type grammar defined in the previous section
by interpreting it within a model. We choose to define a regular tree model,
but alternatives exist; see Remark 10.8.12 below. In this model, every type
constructor whose image row kind is Type (that is, every type constructor of
the form GType or H) is interpreted as itself, as in a free tree model. However,
every application of a type constructor whose image row kind is Row(L) for
some L receives special treatment: it is interpreted as a family of types in-
dexed by L \ L, which we encode as an infinitely branching tree. To serve as
the root label of this tree, we introduce, for every ^ and for every L, a symbol
L^, whose arity is L \ L. More precisely,

10.8.9 Definition: The model, which consists of a set M^.s for every ^ and s, is the

regular tree algebra that arises out the following signature:

Symbol Signature Conditions
G (K ) ^).Type (G : K ) ^) 2 S0
H K.Row(IJ) ) ^.Type (H : K ) ^) 2 S1
L^ ^.(TypeL\L ) Row(L))

The first two lines in this signature coincide with the definitions of GType
and H in the signature S. Indeed, as stated above, we intend to interpret

472 10 The Essence of ML Type Inference

these type constructors in a syntactic manner, so each of them must have a
counterpart in the model. The third line introduces the symbols L^ hinted at
above.

According to this signature, if t is a ground type of kind ^.Type (that is, an
element of M^.Type), then its head symbol t(ffl) must be of the form G or H.
If t is a ground type of kind ^.Row(L), then its head symbol must be L^, and
its immediate subtrees, which are indexed by L \ L, are ground types of kind
^.Type; in other words, the ground row t is effectively a family of ordinary
ground types indexed by L \ L. Thus, our intuition that rows denote infinite
families of types is made literally true.

We have defined the model; there remains to explain how types are mapped
to elements of the model.

10.8.10 Definition: The interpretation of the type constructors that populate S is

defined as follows.

1. Let (G : K ) ^) 2 S0. Then, GType is interpreted as the function that maps

T 2 MK.Type to the ground type t 2 M^.Type defined by t(ffl) = G and
t/d = T (d) for every d 2 dom(K). This is a syntactic interpretation.

2. Let (H : K ) ^) 2 S1. Then, H is interpreted as the function that maps

T 2 MK.Row(IJ) to the ground type t 2 M^.Type defined by t(ffl) = H and
t/d = T (d) for every d 2 dom(K). (Because H is unary, there is exactly
one such d.) This is also a syntactic interpretation.

3. Let (G : K ) ^) 2 S0. Then, GRow(L) is interpreted as the function that

maps T 2 MK.Row(L) to the ground type t 2 M^.Row(L) defined by t(ffl) =
L^ and t(`) = G and t/(` * d) = T (d)/` for every ` 2 L \ L and d 2
dom(K). Thus, when applied to a family of rows, the type constructor
GRow(L) produces a row where every component has head symbol G. This
definition may sound quite technical; its effect is summed up in a simpler
fashion by the equations C-Row-GD and C-Row-GL in the next section.

4. Interpret @^,L as the function that maps t1 2 M^.Type to the ground type

t 2 M^.Row(L) defined by t(ffl) = L^ and t/` = t1 for every ` 2 L \ L. Note
that t/` does not depend on `: t is a constant ground row.

5. Let ` AE L. Then, `^,L is interpreted as the function that maps (t1, t2) 2

M^.Type *M^.Row(`.L) to the ground type t 2 M^.Row(L) defined by t(ffl) = L^
and t/` = t1 and t/`0 = t2(`0) for every `0 2 L \ `.L. This definition
is precisely row extension; indeed, the ground row t maps ` to t1 and
coincides with the ground row t2 at every other label `0. 2

10.8 Rows 473
Defining a model and an interpretation allows our presentation of rows to fit
within the formalism proposed earlier in this chapter ($10.2). It also provides
a basis for the intuition that rows denote infinite families of types. From a
formal point of view, the model and its interpretation allow proving several
constraint equivalence laws concerning rows, which are given and discussed
in the next subsection. Of course, it is also possible to accept these equiv-
alence laws as axioms and give a purely syntactic account of rows without
relying on a model; this is how rows were historically dealt with (Re'my, 1993).

10.8.11 Remark: We have not defined the interpretation of the subtyping predicate,

because much of the material that follows is independent of it. One common
approach is to adopt a nonstructural definition of subtyping (Example 10.2.9),
where every L^ is considered covariant in every direction, and where the vari-
ances and relative ordering of all other symbols (G and H) are chosen at will,
subject to the restrictions associated with nonstructural subtyping and to the
conditions necessary to ensure type soundness.

Recall that the arrow type constructor ! is contravariant in its domain and
covariant in its codomain. The record type constructor \Pi  is usually covariant.
These properties are exploited in proofs of the subject reduction theorem.
The type constructors ! and \Pi  are usually incompatible. This property is
exploited in proofs of the progress theorem. In the case of Example 10.8.7,
because no type constructors other than ! and \Pi  are present, these condi-
tions imply that there is no sensible way of interpreting subtyping other than
equality. In the case of Example 10.8.8, two sensible interpretations of sub-
typing exist: one is equality, while the other is the nonstructural subtyping
order obtained by letting pre a` abs. In the former interpretation, abs means
"definitely absent," while in the latter, it means "possibly absent." 2

10.8.12 Remark: The model proposed above is a regular tree model. Of course, it

is possible to adopt a finite tree model instead. Furthermore, other interpre-
tations of rows are possible: for instance, Fa"hndrich (1999) extends the set
constraints formalism with rows. In his model, an ordinary type is interpreted
as a set of values, while a row is interpreted as a set of functions from labels
to values. While the definition of the model may vary, the key point is that
the characteristic laws of rows, which we discuss next, hold in the model. 2

Reasoning with Rows
The interpretation presented in the previous section was designed to support
the intuition that a row denotes an infinite family of types, indexed by labels,
that the row constructor ` : * ; * denotes row extension, and that the row
constructor @ denotes the creation of a constant row. From a formal point of

474 10 The Essence of ML Type Inference

(`1 : T1 ; `2 : T2 ; T3) = (`2 : T2 ; `1 : T1 ; T3) (C-Row-LL)

@T = (` : T ; @T) (C-Row-DL)
G @T1 . . . @Tn = @(G T1 . . . Tn) (C-Row-GD)
G (` : T1 ; T01) . . . (` : Tn ; T0n) = (` : G T1 . . . Tn ; G T01 . . . T0n) (C-Row-GL)

Figure 10-12: Equational reasoning with rows

view, the definition of the model and interpretation may be exploited to es-
tablish some reasoning principles concerning rows. These principles take the
form of equations between types (Figure 10-12) and constraint equivalence
laws (Figure 10-13), which we now explain and prove.

10.8.13 Remark: As stated earlier, we omit the superscripts of row constructors. We

also omit the side conditions that concern the kind of the type variables (X)
and type meta-variables (T) involved. Thus, each equation in Figure 10-12
really stands for the (infinite) family of equations obtained by reconstructing
the missing kind information in a consistent way. For instance, the second
equation may be read @`.LT = (`^,L : T ; @LT), where ` AE L and T has kind
^.Type. 2

10.8.14 Exercise [Recommended, n', 3]: Reconstruct all of the missing kind infor-

mation in the equations of Figure 10-12. 2

10.8.15 Remark: There is a slight catch with the unannotated version of the second

equation in Figure 10-12: its left-hand side admits strictly more kinds than its
right-hand side, because the former has row kind Row(L) for every L, while
the latter has row kind Row(L) for every L such that ` AE L holds. As a result,
while replacing the unannotated term (` : T ; @T) with @T is always valid, the
converse is not: replacing the unannotated term @T with (` : T ; @T) is valid
only if it does not result in an ill-kinded term. 2

The first equation in Figure 10-12 states that rows are equal up to commu-
tation of labels. For the equation to be well-kinded, the labels `1 and `2 must
be distinct. The equation holds under our interpretation because extension
of a ground row at `1 and extension of a ground row at `2 commute. The
second equation states that @T maps every label within its domain to T, that
is, @LT maps every label ` 62 L to T. This equation holds because @T is inter-
preted as a constant row. The last two equations deal with the relationship
between the row constructors G and the ordinary type constructor G. Indeed,
notice that their left-hand sides involve GRow(L) for some L, while their right-
hand sides involve GType. Both equations state that it is equivalent to apply

10.8 Rows 475
(`1 : T1 ; T01) = (`2 : T2 ; T02) j 9X.(T01 = (`2 : T2 ; X) ^ T02 = (`1 : T1 ; X)) (C-Mutate-LL)

if X # ftv(T1, T01, T2, T02) ^ `1 6= `2

@T = (` : T0 ; T00) j T = T0 ^ @T = T00 (C-Mutate-DL)
G T1 . . . Tn = @T j 9X1 . . . Xn.(G X1 . . . Xn = T ^ Vni=1(Ti = @Xi)) (C-Mutate-GD)

if X1 . . . Xn # ftv(T1, . . . , Tn, T)

G T1 . . . Tn = (` : T ; T0) j 9X1 . . . Xn, X01 . . . X0n.(G X1 . . . Xn = T ^

G X01 . . . X0n = T0 ^V

ni=

1(Ti = (` : Xi ; X0i)))

if X1 . . . Xn, X01 . . . X0n # ftv(T1, . . . , Tn, T, T0) (C-Mutate-GL)

Figure 10-13: Constraint equivalence laws involving rows

GRow(L) at the level of rows or to apply GType at the level of types. Our inter-
pretation of GRow(L) was designed to give rise to these equations; indeed, the
application of GRow(L) to n ground rows (where n is the arity of G) is inter-
preted as a pointwise application of GType to the rows' components (item 3 of
Definition 10.8.10). Their use is illustrated in Examples 10.8.28 and 10.8.39.

10.8.16 Lemma: Each of the equations in Figure 10-12 is equivalent to true. 2

The four equations in Figure 10-12 show that two types with distinct head
symbols may denote the same element of the model. In other words, in the
presence of rows, the interpretation of types is no longer free: an equation of
the form T1 = T2, where T1 and T2 have distinct head symbols, is not necessar-
ily equivalent to false. In Figure 10-13, we give several constraint equivalence
laws, known as mutation laws, that concern such "heterogeneous" equations,
and, when viewed as rewriting rules, allow solving them. To each equation
in Figure 10-12 corresponds a mutation law. The soundness of the mutation
law, that is, the fact that its right-hand side entails its left-hand side, follows
from the corresponding equation. The completeness of the mutation law, that
is, the fact that its left-hand side entails its right-hand side, holds by design
of the model.

10.8.17 Exercise [Recommended, n', 3]: Reconstruct all of the missing kind infor-

mation in the laws of Figure 10-13. 2

Let us now review the four mutation laws. For the sake of brevity, in the
following informal explanation, we assume that a ground assignment OE that

476 10 The Essence of ML Type Inference

satisfies the left-hand equation is fixed, and write "the ground type T" for "the
ground type OE(T)." C-Mutate-LL concerns an equation between two rows,
which are both given by extension but exhibit distinct head labels `1 and `2.
When this equation is satisfied, both of its members must denote the same
ground row. Thus, the ground row T01 must map `2 to the ground type T2,
while, symmetrically, the ground row T02 must map `1 to the ground type
T1. This may be expressed by two equations of the form T01 = (`2 : T2 ; . . .)
and T02 = (`1 : T1 ; . . .). Furthermore, because the ground rows T01 and T02
must agree on their common labels, the ellipses in these two equations must
denote the same ground row. This is expressed by letting the two equations
share a fresh, existentially quantified row variable X. C-Mutate-DL concerns
an equation between two rows, one of which is given as a constant row, the
other of which is given by extension. Then, because the ground row @T maps
every label to the ground type T, the ground type T0 must coincide with the
ground type T, while the ground row T00 must map every label in its domain
to the ground type T. This is expressed by the equations T = T0 and @T = T00.
C-Mutate-GD and C-Mutate-GL concern an equation between two rows, one
of which is given as an application of a row constructor G, the other of which
is given either as a constant row or by extension. Again, the laws exploit
the fact that the ground row G T1 . . . Tn is obtained by applying the type
constructor G, pointwise, to the ground rows T1, . . . , Tn. If, as in C-Mutate-
GD, it coincides with the constant ground row @T, then every Ti must itself be
a constant ground row, of the form @Xi, and T must coincide with G X1 . . . Xn.
C-Mutate-GL is obtained in a similar manner.

10.8.18 Lemma: Each of the equivalence laws in Figure 10-13 holds. 2

Solving Equality Constraints in the Presence of Rows
We now extend the unification algorithm given in $10.6 with support for rows.
The extended algorithm is intended to solve unification problems where the
syntax and interpretation of types are as defined in the discussions above of
the syntax (p. 466) and meaning (p. 471) of rows. Its specification consists
of the original rewriting rules of Figure 10-10, minus S-Clash, which is re-
moved and replaced with the rules given in Figure 10-14. Indeed, S-Clash is
no longer valid in the presence of rows: not all distinct type constructors are
incompatible.

The extended algorithm features four mutation rules, which are in direct
correspondence with the mutation laws of Figure 10-13, as well as a weak-
ened version of S-Clash, dubbed S-Clash', which applies when neither S-
Decompose nor the mutation rules are applicable. (Let us point out that, in

10.8 Rows 477
(`1 : X1 ; X01) = (`2 : T2 ; T02) = ffl ! 9X.(X01 = (`2 : T2 ; X) ^ T02 = (`1 : X1 ; X))

^ (`1 : X1 ; X01) = ffl (S-Mutate-LL)
if `1 6= `2

@X = (` : T ; T0) = ffl ! X = T ^ @X = T0 ^ @X = ffl (S-Mutate-DL)
G T1 . . . Tn = @X = ffl ! 9X1 . . . Xn.(G X1 . . . Xn = X ^ Vni=1(Ti = @Xi))

^ @X = ffl (S-Mutate-GD)

G T1 . . . Tn = (` : X ; X0) = ffl ! 9X1 . . . Xn, X01 . . . X0n.(G X1 . . . Xn = X ^

G X01 . . . X0n = X0 ^V

ni=

1(Ti = (` : Xi ; X0i )))

^ (` : X ; X0) = ffl (S-Mutate-GL)

F ~T = F0 ~T0 = ffl ! false (S-Clash')

if F 6= F0 and none of the four rules above applies

Figure 10-14: Row unification (changes to Figure 10-10)

S-Decompose, the meta-variable F ranges over all type constructors in the sig-
nature S, so that S-Decompose is applicable to multi-equations of the form
@X = @T = ffl or (` : X ; X0) = (` : T ; T0) = ffl.) Three of the mutation rules
may allocate fresh type variables, which must be chosen fresh for the rule's
left-hand side. The four mutation rules paraphrase the four mutation laws
very closely. Two minor differences are (i) the mutation rules deal with multi-
equations, as opposed to equations; and (ii) any subterm that appears more
than once on the right-hand side of a rule is required to be a type variable,
as opposed to an arbitrary type. Neither of these features is specific to rows:
both may be found in the definition of the standard unification algorithm
(Figure 10-10), where they help reason about sharing.

10.8.19 Exercise [n', 3]: Check that the rewriting rules in Figure 10-14 preserve well-

kindedness. Conclude that, provided its input constraint is well-kinded, the
unification algorithm needs not keep track of kinds. 2

The properties of the unification algorithm are preserved by this extension,
as witnessed by the next three lemmas. Note that the termination of reduction
is ensured only when the initial unification problem is well-kinded. The ill-
kinded unification problem X = (`1 : T ; Y) ^ X = (`2 : T ; Y), where `1 and `2
are distinct, illustrates this point.

10.8.20 Lemma: The rewriting system ! is strongly normalizing. 2

478 10 The Essence of ML Type Inference

10.8.21 Lemma: U1 ! U2 implies U1 j U2. 2
10.8.22 Lemma: Every normal form is either false or of the form X[U], where X is an

existential constraint context, U is a standard conjunction of multi-equations
and, if the model is syntactic, U is acyclic. These conditions imply that U is
satisfiable. 2

The time complexity of standard first-order unification is quasi-linear. What
is, then, the time complexity of row unification? Only a partial answer is
known. In practice, the algorithm given in this chapter is extremely efficient
and appears to behave just as well as standard unification. In theory, the com-
plexity of row unification remains unexplored and forms an interesting open
issue.

10.8.23 Exercise [n'n'n', 3]: The unification algorithm presented above, although very

efficient in practice, does not have linear or quasi-linear time complexity. Find
a family of unification problems Un such that the size of Un is linear with re-
spect to n and the number of steps required to reach its normal form is
quadratic with respect to n. 2

10.8.24 Remark: Mutation is a common technique for solving equations in a large

class of non-free algebras that are described by syntactic theories (Kirchner
and Klay, 1990). The equations of Figure 10-12 happen to form a syntactic
presentation of an equational theory. Thus, it is possible to derive a unifica-
tion algorithm out of these equations in a systematic way (Re'my, 1993). Here,
we have presented the same algorithm in a direct manner, without relying on
the apparatus of syntactic theories. 2

Operations on Records
We now illustrate the use of rows for typechecking operations on records. We
begin with full records; our treatment follows Re'my (1992b).

10.8.25 Example [Full records]: As before, let us begin with full records, whose do-

main is exactly L. The primitive operations are record creation {*}, update
{* with ` = *}, and access *.{`}.

Let < denote a fixed strict total order on row labels. For every set of labels
L of cardinal n, let us introduce a (n + 1)-ary constructor {}L. We use the fol-
lowing syntactic sugar: we write {`1 = t1; . . . ; `n = tn; t} for the application
{}L ti1 . . . tin t, where L = {`1, . . . , `n} = {`i1, . . . , `in} and `i1 < . . . < `in
holds. The use of the total order < makes the meaning of record expressions
independent of the order in which fields are defined; in particular, it allows
fixing the order in which t1, . . . , tn are evaluated. We abbreviate the record

10.8 Rows 479
value {`1 = v1; . . . ; `n = vn; v} as {V; v}, where V is the finite function that
maps `i to vi for every i 2 {1, . . . , n}.

The operational semantics of the above three operations may now be de-
fined in the following straightforward manner. First, record creation {*} is
precisely the unary constructor {}IJ. Second, for every ` 2 L, let update
{* with ` = *} and access *.{`} be destructors of arity 1 and 2, respectively,
equipped with the following reduction rules:

{{V; v} with ` = v0} ffi-! {V[` , v0]; v} (R-Update)

{V; v}.{`} ffi-! V(`) (` 2 dom(V)) (R-Access-1)
{V; v}.{`} ffi-! v (` AE dom(V)) (R-Access-2)

In these rules, V[` , v] stands for the function that maps ` to v and coincides
with V at every other label, while V(`) stands for the image of ` through V.
Because these rules make use of the syntactic sugar defined above, they are,
strictly speaking, rule schemes: each of them really stands for the infinite
family of rules that would be obtained if the syntactic sugar was eliminated.

Let us now define the syntax of types as in Example 10.8.7. Let the initial
environment \Gamma 0 contain the following bindings:

{}{`1,...,`n} : 8X1 . . . XnX.X1 ! . . . ! Xn ! X ! \Pi  (`1 : X1; . . . ; `n : Xn; @X)

where `1 < . . . < `n
{* with ` = *} : 8XX0Y.\Pi  (` : X ; Y) ! X0 ! \Pi  (` : X0 ; Y)

*.{`} : 8XY.\Pi  (` : X ; Y) ! X

Note that, in particular, the type scheme assigned to record creation {*} is
8X.X ! \Pi  (@X). As a result, these bindings are exactly as stated in the discus-
sion of records with infinite carrier (p. 463).

To illustrate how these definitions work together, let us consider the pro-
gram {{0} with `1 = true}.{`2}, which builds a record, extends it at `1, then
accesses it at `2. Can we build an HM(X) type derivation for it, under the
constraint true and the initial environment \Gamma 0? To begin, by looking up \Gamma 0
and using hmx-Inst, we find that {*} has type int ! \Pi  (@int). Thus, assum-
ing that 0 has type int, the expression {0} has type \Pi  (@int). Indeed, this
expression denotes a record all of whose fields hold an integer value. Then,
by looking up \Gamma 0 and using hmx-Inst, we find that {* with `1 = *} has type
\Pi  (`1 : int ; @int) ! bool ! \Pi  (`1 : bool ; @int). May we immediately use hmx-
App to typecheck the application of {* with `1 = *} to {0}? Unfortunately,
no, because there is an apparent mismatch between the expected type \Pi 
(`1 :int ; @int) and the effective type \Pi  (@int). To work around this problem, let
us recall that, by C-Row-DL, the equation \Pi  (@int) = \Pi  (`1 : int ; @int) is equiv-
alent to true. Thus, hmx-Sub allows proving that {0} has type \Pi  (`1 :int ; @int).

480 10 The Essence of ML Type Inference

Assuming that true has type bool, we may now apply hmx-App and deduce

true, \Gamma 0 ` {{0} with `1 = true} : \Pi  (`1 : bool ; @int).
We let the reader check that, in a similar manner involving C-Row-DL, C-Row-
LL, and hmx-Sub, one may prove that {{0} with `1 = true}.{`2} has type int,
provided `1 and `2 are distinct. 2

10.8.26 Exercise [n'n', 3]: Unfold the definition of the constraint let \Gamma 0 in J{{0} with

`1 = true}.{`2} : XK, which states that X is a valid type for the above program.
Assuming that subtyping is interpreted as equality, simulate a run of the
constraint solver ($10.6), extended with support for rows, so as to solve this
constraint. Check that the solved form is equivalent to X = int. 2

10.8.27 Exercise [n'n'n']: Check that the definitions of Example 10.8.25 meet the re-

quirements of Definition 10.5.5. 2

10.8.28 Example [Record application]: Let us now introduce a more unusual prim-

itive operation on full records. This operation accepts two records, the first of
which is expected to hold a function in every field and produces a new record,
whose contents are obtained by applying, pointwise, the functions in the first
record to the values in the second record. In other words, this new primitive
operation lifts the standard application combinator (which may be defined as
*f.*z.f z), pointwise, to the level of records. For this reason, we refer to it as
rapply. Its operational semantics is defined by making it a binary destructor
and equipping it with the following reduction rules:

rapply {V; v} {V0; v0} ffi-! {V V0; v v0} (R-Apply-1)
rapply {V; v} {V0; v0} ffi-! rapply {V; v} {V0[` , v0]; v0} (R-Apply-2)

if ` 2 dom(V) \ dom(V0)

rapply {V; v} {V0; v0} ffi-! rapply {V[`0 , v]; v} {V0; v0} (R-Apply-3)

if `0 2 dom(V0) \ dom(V)

In the first rule, V V0 is defined only if V and V0 have a common domain; it is
then defined as the function that maps ` to the expression V(`) V0(`). The
second and third rules, which are symmetric, deal with the case where some
field is explicitly defined in one input record but not in the other; in that case,
the field is made explicit by creating a copy of the record's default value.

The syntax of types remains as in Example 10.8.25. We extend the initial
environment \Gamma 0 with the following binding:

rapply : 8XY.\Pi  (X ! Y) ! \Pi  X ! \Pi  Y

10.8 Rows 481
To understand this type scheme, recall that the principal type scheme of
the standard application combinator (which may be defined as *f.*z.f z) is
8XY.(X ! Y) ! X ! Y. The type scheme assigned to rapply is very similar; the
most visible difference is that both arguments, as well as the result, are now
wrapped within the record type constructor \Pi . A more subtle, yet essential
change is that X and Y are now row variables: their kind is ?.Row(IJ). As
a result, the leftmost occurrence of the arrow constructor is really !Row(IJ).
Thus, we are exploiting the presence of type constructors of the form Gs,
with s 6= Type, in the signature S.

To illustrate how these definitions work together, let us consider the pro-
gram rapply {` = not; succ} {` = true; 0}, where the terms not and succ
are assumed to have types bool ! bool and int ! int, respectively. Can
we build an HM(X) type derivation for it, under the constraint true and
the initial environment \Gamma 0? To begin, it is straightforward to derive that the
record {` = not; succ} has type \Pi  (` : bool ! bool ; @(int ! int)) (1). In or-
der to use rapply, however, we must prove that this record has a type of
the form \Pi  (R1 ! R2), where R1 and R2 are rows. This is where C-Row-GD
and C-Row-GL (Figure 10-12) come into play. Indeed, by C-Row-GD, the type
@(int ! int) may be written @int ! @int. So, (1) may be written \Pi  (` : bool !
bool ; @int ! @int) (2), which by C-Row-GL may be written \Pi  ((` : bool ;
@int) ! (` : bool ; @int)) (3). Thus, hmx-Sub allows deriving that the record
{` = not; succ} has type (3). We let the reader continue and conclude that the
program has type \Pi  (` : bool ; @int) under the constraint true and the initial
environment \Gamma 0.

This example illustrates a very important use of rows, namely to lift an
operation on ordinary values so as to turn it into a pointwise operation on
records. Here, we have chosen to lift the standard application combinator,
giving rise to rapply on records. The point is that, thanks to the expres-
sive power of rows, we were also able to lift the standard combinator's type
scheme in the most straightforward manner, giving rise to a suitable type
scheme for rapply. 2

10.8.29 Exercise [n'n'n', 3]: Check that the definitions of Example 10.8.28 meet the

requirements of Definition 10.5.5. 2

The previous examples have illustrated the use of rows to typecheck op-
erations on full records. Let us now move to records with finite domain. As
explained in the discussion above of records with finite carrier (p. 461), they
may be either encoded in terms of full records, or given a direct definition.
The latter approach is illustrated below.

10.8.30 Example [Finite records]: For every set of labels L of cardinal n, let us in-

troduce a n-ary constructor hiL. We define the notations h`1 = t1; . . . ; `n = tni

482 10 The Essence of ML Type Inference

and hVi, where V is a finite mapping of labels to values, in a manner similar
to that of Example 10.8.25.

The three primitive operations on finite records, namely the empty record
hi, extension h* with ` = *i, and access *.h`i, may be defined as follows. First,
the empty record hi is precisely the nullary constructor hiIJ. Second, for every
` 2 L, let extension h* with ` = *i and access *.h`i be destructors of arity 1
and 2, respectively, equipped with the following reduction rules:

hhVi with ` = vi ffi-! hV[` , v]i (R-Extend)

hVi.h`i ffi-! V(`) (` 2 dom(V)) (R-Access)

Let us now define the syntax of types as in Example 10.8.8. Let the initial
environment \Gamma 0 contain the following bindings:

hi{`1,...,`n} : 8X1 . . . Xn.X1 ! . . . ! Xn ! \Pi  (`1 : pre X1; . . . ; `n : pre Xn; @abs)

where `1 < . . . < `n
h* with ` = *i : 8XX0Y.\Pi  (` : X ; Y) ! X0 ! \Pi  (` : pre X0 ; Y)

*.h`i : 8XY.\Pi (` : pre X ; Y) ! X

Note that, in particular, the type scheme assigned to the empty record hi is
\Pi  (@abs). 2

10.8.31 Exercise [Recommended, n', 3]: Reconstruct all of the missing kind infor-

mation in the type schemes given in Example 10.8.30. 2

10.8.32 Exercise [Recommended, n'n', 3]: Give an encoding of finite records in terms

of full records, along the lines of the discussion of records with finite carrier
(p. 461). Check that the principal type schemes associated, via the encod-
ing, with the three operations on finite records are precisely those given in
Example 10.8.30. 2

10.8.33 Exercise [Recommended, n']: The extension operation, as defined above, may

either change the value of an existing field or create a new field, depending
on whether the field ` is or isn't present in the input record. This flavor is
known as free extension. Can you define a strict flavor of extension that is
not applicable when the field ` already exists? Can you define (free and strict
flavors of) a restriction operation that removes a field from a record? 2

10.8.34 Exercise [Recommended, n']: Explain why, when pre a` abs holds, subsump-

tion allows a record with more fields to be supplied in a context where a
record with fewer fields is expected. This phenomenon is often known as
width subtyping. Explain why such is not the case when subtyping is inter-
preted as equality. 2

10.8.35 Exercise [n'n'n', 3]: Check that the definitions of Example 10.8.30 meet the

requirements of Definition 10.5.5. 2

10.8 Rows 483
Polymorphic Variants
So far, we have emphasized the use of rows for flexible typechecking of opera-
tions on records. The record type constructor \Pi  expects one parameter, which
is a row; informally speaking, one might say that it is a product constructor of
infinite arity. It appears natural to also define sums of infinite arity. This may
be done by introducing a new unary type constructor \Sigma , whose parameter is
a row.

As in the case of records, we use a nullary type constructor abs and a
unary type constructor pre in order to associate information with every row
label. Thus, for instance, the type \Sigma  (`1 : pre T1 ; `2 : pre T2 ; @abs) is intended
to contain values of the form `1 v1, where v1 has type T1, or of the form
`2 v2, where v2 has type T2. The type constructors abs and pre are not the
same type constructors as in the case of records. In particular, their subtyping
relationship, if there is one, is reversed. Indeed, the type \Sigma  (`1 : pre T1 ;
`2 : abs ; @abs) is intended to contain only values of the form `1 v1, where
v1 has type T1, so it is safe to make it a subtype of the above type; in other
words, it is safe to allow abs <= pre T2. In spite of this, we keep the names abs
and pre by tradition.

The advantages of this approach over algebraic data types are the same as
in the case of records. The namespace of data constructors becomes global,
so it becomes possible for two distinct sum types to share data constructors.
Also, the expressiveness afforded by rows allows assigning types to new op-
erations, such as filtering (see below), which allows functions that perform
case analysis to be incrementally extended with new cases. One disadvantage
is that it becomes more difficult to understand what it means for a function
defined by pattern matching to be exhaustive; this issue is, however, out of
the scope of this chapter.

10.8.36 Example [Polymorphic variants]: For every label ` 2 L, let us introduce a

unary constructor ` and a ternary destructor [ ` : * | * ] *. We refer to the for-
mer as a data constructor, and to the latter as a filter. Let us also introduce a
unary destructor []. We equip these destructors with the following reduction
rules:

[ ` : v | v0 ] (` w) ffi-! v w (R-Filter-1)
[ ` : v | v0 ] (`0 w) ffi-! v0 (`0 w) if ` 6= `0 (R-Filter-2)

Let us define the syntax of types as follows. Let there be two basic kinds ?
and *. Let S0 consist of the type constructors !, abs, and pre, whose respec-
tive signatures are ? \Omega  ? ) ?, *, and ? ) *. Let S1 consist of the record type
constructor \Sigma , whose signature is * ) ?. Note the similarity with the case of
records (Example 10.8.8).

484 10 The Essence of ML Type Inference

Subtyping is typically interpreted in one of two ways. One is equality. The
other is the nonstructural subtyping order obtained by letting ! be con-
travariant in its domain and covariant in its codomain, \Sigma  be covariant, !
and \Sigma  be incompatible, and letting abs a` pre. Compare this definition with
the case of records (Remark 10.8.11).

To complete the setup, let the initial environment \Gamma 0 contain the following
bindings:

` * : 8XY.X ! \Sigma  (` : pre X ; Y)
[ ` : * | * ] * : 8XX0YY0.(X ! Y) ! (\Sigma  (` : X0 ; Y0) ! Y) ! \Sigma  (` : pre X ; Y0) ! Y

[] : 8X.\Sigma  (@abs) ! X

The first binding means, in particular, that if v has type T, then a value of the
form ` v has type \Sigma  (` : pre T ; @abs). This is a sum type with only one branch
labeled `, hence a very precise type for this value. However, it is possible to
instantiate the row variable Y with rows other than @abs. For instance, the
value ` v also has type \Sigma  (` : pre T ; `0 : pre T0 ; @abs). This is a sum type with
two branches, hence a somewhat less precise type, but still a valid one for
this value. It is clear that, through this mechanism, the value ` v admits an
infinite number of types. The point is that, if v has type T and v0 has type T0,
then both ` v and `0 v0 have type \Sigma  (` : pre T ; `0 : pre T0 ; @abs), so they may
be stored together in a homogeneous data structure, such as a list.

Filters are used to perform case analysis on variants, that is, on values of
a sum type. According to R-Filter-1 and R-Filter-2, a filter [ ` : v | v0 ] is a
function that expects an argument of the form `0 w and reduces to v w if `0 is
` and to v0 (`0 w) otherwise. Thus, a filter defines a two-way branch, where the
label of the data constructor at hand determines which branch is taken. The
expressive power of filters stems from the fact that they may be organized
in a sequence, so as to define a multi-way branch. The inert filter [], which
does not have a reduction rule, serves as a terminator for such sequences. For
instance, the composite filter [ ` : v | [ `0 : v0 | [] ] ], which may be abbreviated
as [ ` : v | `0 : v0 ], may be applied either to a value of the form ` w, yielding
v w, or to a value of the form `0 w0, yielding v0 w0. Applying it to a value w
whose head symbol is not ` or `0 would lead to the term [] w, which is stuck,
since [] does not have a reduction rule.

For the type system to be sound, we must ensure that every application
of the form [] w is ill-typed. This is achieved by the third binding above: the
domain type of [] is \Sigma  (@abs), a sum type with zero branches, which contains
no values. The return type of [] may be chosen at will, which is fine; since it
can never be invoked, it can never return. The second binding above means
that, if v accepts values of type T and v0 accepts values of type \Sigma  (` : T00 ; T0),
then the filter [ ` : v | v0 ] accepts values of type \Sigma  (` : pre T ; T0). Note that

10.8 Rows 485
any choice of T00 will do, including, in particular, abs. In other words, it is
okay if v0 does not accept values of the form ` w. Indeed, by definition of the
semantics of filters, it will never be passed such a value. 2

10.8.37 Exercise [n'n'n', 3]: Check that the definitions of Example 10.8.36 meet the

requirements of Definition 10.5.5. 2

10.8.38 Remark: It is interesting to study the similarity between the type schemes

assigned to the primitive operations on polymorphic variants and those as-
signed to the primitive operations on records (Example 10.8.30). The type of
[] involves the complete row @abs, just like the empty record hi. The type
of [ ` : * | * ] * is pretty much identical to the type of record extension
h* with ` = *i, provided the three continuation arrows ! Y are dropped.
Last, the type of the data constructor ` is strongly reminiscent of the type
of record access *.h`i. With some thought, this is hardly a surprise. Indeed,
records and variants are dual: it is possible to encode the latter in terms of
the former and vice-versa. For instance, in the encoding of variants in terms
of records, a function defined by cases is encoded as a record of ordinary
functions, in continuation-passing style. Thus, the encoding of [] is *f.f hi,
the encoding of [ ` : v | v0 ] is *f.f hv0 with ` = vi, and the encoding of
` v is *r.r.h`i v. The reader is encouraged to study the type schemes that
arise out of this encoding and how they relate to the type schemes given in
Example 10.8.36. 2

10.8.39 Example [First-class messages]: In a programming language equipped with

both records and variants, it is possible to make the duality between these
two forms of data explicit by extending the language with a primitive opera-
tion # that turns a record of ordinary functions into a single function, defined
by cases. More precisely, # may be introduced as a binary destructor, whose
reduction rule is

# v (` w) ffi-! v.h`i w (R-Send)
What type may we assign to such an operation? In order to simplify the an-
swer, let us assume that we are dealing with full records (Example 10.8.25)
and full variants; that is, we have a single basic kind ?, and do not employ
abs and pre. Then, a suitable type scheme would be

8XY.\Pi  (X ! @Y) ! \Sigma  X ! Y
In other words, this operation accepts a record of functions, all of which have
the same return type Y, but may have arbitrary domain types, which are given
by the row X. It produces a function that accepts a parameter of sum type \Sigma  X

486 10 The Essence of ML Type Inference

and returns a result of type Y. The fact that the row X appears both in the \Sigma 
type and in the \Pi  type reflects the operational semantics. Indeed, according
to R-Send, the label ` carried by the value ` w is used to extract, out of the
record v, a function, which is then applied to w. Thus, the domain type of
the function stored at ` within the record v should match the type of w. In
other words, at every label, the domain of the contents of the record and the
contents of the sum should be type compatible. This is encoded by letting
a single row variable X stand for both of these rows. Note that the arrow in
X ! @Y is really !Row(IJ); once again, we are exploiting the presence of type
constructors of the form Gs, with s 6= Type, in the signature S.

If the record of functions v is viewed as an object, and if the variant ` w
is viewed as a message ` carrying a parameter w, then R-Send may be under-
stood as (first-class) message dispatch, a common feature of object-oriented
languages. (The first-class qualifier refers to the fact that the message name
` is not statically fixed, but is discovered at runtime.) The issue of type infer-
ence in the presence of such a feature has been studied by Nishimura (1998),
Mu"ller and Nishimura (1998), and Pottier (2000). These papers address two is-
sues that are not dealt with in the above example, namely (i) accommodating
finite (as opposed to full) record and variants and (ii) allowing distinct meth-
ods to have distinct result types. This is achieved via the use of subtyping
and of some form of conditional constraints. 2

10.8.40 Exercise [n'n'n', 3]: Check that the definitions of Example 10.8.39 meet the

requirements of Definition 10.5.5. 2

The name polymorphic variants stems from the highly polymorphic type
schemes assigned to the operations on variants (Example 10.8.36). A row-
based type system for polymorphic variants was first proposed by Re'my
(1989). A somewhat similar, constraint-based type system for polymorphic
variants was then studied by Garrigue (1998; 2000; 2002) and implemented
by him as part of the programming language Objective Caml.

Other Applications of Rows
Typechecking records and variants is the best-known application of rows.
Many variations of it are conceivable, some of which we have illustrated, such
as the choice between full and finite records and variants. However, rows may
also be put to other uses, of which we now list a few.

First, since objects may be viewed as records of functions, at least from a
typechecking point of view, rows may be used to typecheck object-oriented
languages in a structural style (Wand, 1994; Re'my, 1994). This is, in particu-
lar, the route followed in Objective Caml (Re'my and Vouillon, 1998). There,

10.8 Rows 487
an object type consists of a row of method types, and gives the object's inter-
face. Such a style is considered structural, as opposed to the style adopted by
many popular object-oriented languages, such as C++, Java, and C#, where an
object type consists of the name of its class. Thanks to rows, method invo-
cation may be assigned a polymorphic type scheme, similar to that of record
access (Example 10.8.30), making it possible to invoke a specific method (say,
`) without knowing which class the receiver object belongs to.

Rows may also be used to encode sets of properties within types or to
encode type refinements, with applications in type-based program analysis.
Some instances worth mentioning are soft typing (Cartwright and Fagan,
1991; Wright and Cartwright, 1994), exception analysis (Leroy and Pessaux,
2000; Pottier and Simonet, 2003), and static enforcement of an access control
policy (Pottier, Skalka, and Smith, 2001). BANE (Fa"hndrich, 1999), a versatile
program analysis toolkit, also implements a form of rows.

Variations on Rows
A type system may be said to have rows, in a broad sense, if mappings from
labels to types may be (i) defined incrementally, via some syntax for extending
an existing mapping with information about a new label and (ii) abstracted by
a type variable. In this chapter, which follows Re'my's ideas (1993; 1992a;
1992b), the former feature is provided by the row constructors (` : * ; *),
while the latter is provided by the existence of row variables, that is, type
variables of row kind Row(L) for some L. There are, however, type systems
that provide (i) and (ii) while departing significantly from the one presented
here. These systems differ mainly in how they settle some important design
choices:

1. Does a row denote a finite or an infinite mapping from labels to types?
2. Is a row with duplicate labels considered well-formed? If not, by which

mechanism is it ruled out?

In Re'my's approach, every row denotes an infinite (in fact, cofinite) mapping
from labels to types. The type constructors abs and pre are used to encode
domain information within field types. A row with duplicate labels, such as
(` : T1 ; ` : T2 ; T3), is ruled out by the kind system. Below, we mention a
number of type systems that make different design choices.

The first use of rows for typechecking operations on records, including
record extension, is due to Wand (1987a; 1988). In Wand's approach, rows de-
note finite mappings. Furthermore, rows with duplicate labels are considered
legal; row extension is interpreted as function extension, so that, if a label oc-
curs twice, the later occurrence takes precedence. This leads to a difficulty in

488 10 The Essence of ML Type Inference

the constraint solving process: the constraint (` : T1 ; R1) = (` : T2 ; R2) entails
T1 = T2, but does not entail R1 = R2, because R1 and R2 may have different
domains--indeed, their domains may differ at `. Wand's proposed solution
(1988) introduces a four-way disjunction, because each of R1 and R2 may or
may not define `. This gives type inference exponential time complexity.

Later work (Berthomieu, 1993; Berthomieu and le Monie`s de Sagazan, 1995)
interprets rows as infinite mappings but sticks with Wand's interpretation of
row extension as function extension, so that duplicate labels are allowed. The
constraint solving algorithm rewrites the problematic constraint (` :T1 ; R1) =
(` : T2 ; R2) to (T1 = T2) ^ (R1 ={`} R2), where the new predicate =L is inter-
preted as row equality outside L. Of course, the entire constraint solver must
then be extended to deal with constraints of the form T1 =L T2. The advan-
tage of this approach over Wand's lies in the fact that no disjunctions are
ever introduced, so that the time complexity of constraint solving apparently
remains polynomial.

Several other works make opposite choices, sticking with Wand's interpre-
tation of rows as finite mappings but forbidding duplicate labels. No kind
discipline is imposed: some other mechanism is used to ensure that dupli-
cate labels do not arise. In Jategaonkar and Mitchell (1988) and Jategaonkar
(1989), somewhat ad hoc steps are taken to ensure that, if the row (` : T ; X)
appears anywhere within a type derivation, then X is never instantiated with
a row that defines `. In Gaster and Jones (1996), Gaster (1998), and Jones
and Peyton Jones (1999), explicit constraints prevent duplicate labels from
arising. This line of work uses qualified types (Jones, 1994), a constraint-
based type system that bears strong similarity with HM(X). For every label
`, a unary predicate * lacks ` is introduced; roughly speaking, the constraint
R lacks ` is considered to hold if the (finite) row R does not define the label `.
The constrained type scheme assigned to record access is

*.h`i : 8XY[Y lacks `].\Pi  (` : X ; Y) ! X.
The constraint Y lacks ` ensures that the row (` : X ; Y) is well-formed. Al-
though interesting, this approach is not as expressive as that described in
this chapter. For instance, although it accommodates record update (where
the field being modified is known to exist in the initial record) and strict
record extension (where the field is known not to initially exist), it cannot ex-
press a suitable type scheme for free record extension, where it is not known
whether the field initially exists. This approach has been implemented as the
"Trex" extension to Hugs (Jones and Peterson, 1999).

It is worth mentioning a line of type systems (Ohori and Buneman, 1988,
1989; Ohori, 1995) that do not have rows, because they lack feature (i) above,
but are still able to assign a polymorphic type scheme to record access. One

10.8 Rows 489
might explain their approach as follows. First, these systems are equipped
with ordinary, structural record types, of the form {`1 : T1; . . . ; `n : Tn}. Sec-
ond, for every label `, a binary predicate * has ` : * is available. The idea is
that the constraint T has ` : T0 holds if and only if T is a record type that
contains the field ` : T0. Then, record access may be assigned the constrained
type scheme

*.h`i : 8XY[X has ` : Y].X ! Y.

This technique also accommodates a restricted form of record update, where
the field being written must initially exist and must keep its initial type; it
does not, however, accommodate any form of record extension, because of
the absence of row extension in the syntax of types. Although the papers
cited above employ different terminology, we believe it is fair to view them as
constraint-based type systems. In fact, Odersky, Sulzmann, and Wehr (1999)
prove that Ohori's system (1995) may be viewed as an instance of HM(X).
Sulzmann (2000) proposes several extensions of it, also presented as in-
stances of HM(X), which accommodate record extension and concatenation
using new, ad hoc constraint forms in addition to * has `.

In the label-selective *-calculus (Garrigue and Ai"t-Kaci, 1994; Furuse and
Garrigue, 1995), the arrow type constructor carries a label, and arrows that
carry distinct labels may commute, so as to allow labeled function arguments
to be supplied in any order. Some of the ideas that underlie this type system
are closely related to rows.

Pottier (2003) describes an instance of HM(X) where rows are not part of
the syntax of types: equivalent expressive power is obtained via an exten-
sion of the constraint language. The idea is to work with constraints of the
form R1 <=L R2, where L may be finite or cofinite, and to interpret such a
constraint as row subtyping inside L. In this approach, no new type variables
need be allocated during constraint solving; contrast this with S-Mutate-LL,
S-Mutate-GD, and S-Mutate-GL in Figure 10-14. One benefit is to simplify
the complexity analysis; another is to yield insights that lead to generaliza-
tions of rows.

Even though rows were originally invented with type inference in mind,
they are useful in explicitly typed languages as well; indeed, other approaches
to typechecking operations on records appear quite complex (Cardelli and
Mitchell, 1991).

A Solutions to Selected Exercises 523

2. Adding a conditional module expression destroys the phase distinction,

because the types in a conditional module, e.g.

if ... then LNat::*M else LUnit::*M,
depends on the run-time value of the test.
10.1.22 Solution: Within Damas and Milner's type system, we have:

dm-Let
dm-Var z

1 : X ` z1 : X z1 : X; z2 : X ` z2 : X

dm-Var

dm-Abs z1 : X ` let z2 = z1 in z2 : XIJ ` *z

1.let z2 = z1 in z2 : X ! X

Note that, because X occurs free within the environment z1 : X, it is impossible
to apply dm-Gen to the judgment z1 : X ` z1 : X in a nontrivial way. For this
reason, z2 cannot receive the type scheme 8X.X, and the whole expression
cannot receive type X ! Y, where X and Y are distinct.

10.1.23 Solution: It is straightforward to prove that the identity function has type

int ! int:

\Gamma 0; z : int ` z : int dm-Var
\Gamma 0 ` *z.z : int ! int dm-Abs
In fact, nothing in this type derivation depends on the choice of int as the type
of z. Thus, we may just as well use a type variable X instead. Furthermore,
after forming the arrow type X ! X, we may employ dm-Gen to quantify
universally over X, since X no longer appears in the environment.

dm-Gen

dm-Abs

dm-Var

\Gamma 0; z : X ` z : X

\Gamma 0 ` *z.z : X ! X X 62 ftv(\Gamma 0)

\Gamma 0 ` *z.z : 8X.X ! X

It is worth noting that, although the type derivation employs an arbitrary
type variable X, the final typing judgment has no free type variables. It is thus
independent of the choice of X. In the following, we refer to the above type
derivation as \Delta 0.

Next, we prove that the successor function has type int ! int under the
initial environment \Gamma 0. We write \Gamma 1 for \Gamma 0; z : int, and make uses of dm-Var
implicit.

dm-App
dm-App

\Gamma 1 ` ^+ : int ! int ! int \Gamma 1 ` z : int

\Gamma 1 ` ^+ z : int ! int \Gamma 1 ` ^1 : int

dm-Abs

\Gamma 1 ` z ^+ ^1 : int

\Gamma 0 ` *z.z ^+ ^1 : int ! int

524 A Solutions to Selected Exercises

In the following, we refer to the above type derivation as \Delta 1. We may now
build a derivation for the third typing judgment. We write \Gamma 2 for \Gamma 0; f : int !
int.

\Delta 1

\Gamma 2 ` f : int ! int \Gamma 2 ` ^2 : int

\Gamma 2 ` f ^2 : int dm-App
\Gamma 0 ` let f = *z.z ^+ ^1 in f ^2 : int dm-Let

To derive the fourth typing judgment, we re-use \Delta 0, which proves that the
identity function has polymorphic type 8X.X ! X. We write \Gamma 3 for \Gamma 0; f :
8X.X ! X. By dm-Var and dm-Inst, we have both \Gamma 3 ` f : (int ! int) !
(int ! int) and \Gamma 3 ` f : int ! int. Thus, we may build the following derivation:

\Delta 0 dm-App

dm-App

\Gamma 3 ` f : (int ! int) ! (int ! int)

\Gamma 3 ` f : int ! int

\Gamma 3 ` f f : int ! int \Gamma 3 ` ^2 : int

\Gamma 3 ` f f ^2 : int
\Gamma 0 ` let f = *z.z in f f ^2 : int dm-Let

The first and third judgments are valid in the simply-typed *-calculus, be-
cause they use neither dm-Gen nor dm-Inst, and use dm-Let only to introduce
the monomorphic binding f : int ! int into the environment. The second judg-
ment, of course, is not: because it involves a nontrivial type scheme, it is not
even a well-formed judgment in the simply-typed *-calculus. The fourth judg-
ment is well-formed, but not derivable, in the simply-typed *-calculus. This is
because f is used at two incompatible types, namely (int ! int) ! (int ! int)
and int ! int, inside the expression f f ^2. Both of these types are instances of
8X.X ! X, the type scheme assigned to f in the environment \Gamma 3.

By inspection of the rules, a derivation of \Gamma 0 ` ^1 : T must begin with an
instance of dm-Var, of the form \Gamma 0 ` ^1 : int. It may be followed by an arbitrary
number of instances of the sequence (dm-Gen; dm-Inst), turning int into a
type scheme of the form 8_X.int, then back to int. Thus, T must be int. Because
int is not an arrow type, there follows that the application ^1 ^2 cannot be
well-typed under \Gamma 0. In fact, because this expression is stuck, it cannot be
well-typed in a sound type system.

The expression *f.(f f) is ill-typed in the simply-typed *-calculus, because
no type T may coincide with a type of the form T ! T0: indeed, T would be
a subterm of itself. In DM, this expression is ill-typed as well, but the proof
of this fact is slightly more complex. One must point out that, because f
is *-bound, it must be assigned a type T (as opposed to a type scheme) in
the environment. Furthermore, one must note that dm-Gen is not applicable
(except in a trivial way) to the judgment \Gamma 0; f : T ` f : T, because all of the

A Solutions to Selected Exercises 525
type variables in the type T appear free in the environment \Gamma 0; f : T. Once these
points are made, the proof is the same as in the simply-typed *-calculus.

It is important to note that the above argument crucially relies on the fact
that f is *-bound and must be assigned a type, as opposed to a type scheme.
Indeed, we have proved earlier in this exercise that the self-application f f is
well-typed when f is let-bound and is assigned the type scheme 8X.X ! X.
For the same reason, *f.(f f) is well-typed in an implicitly-typed variant of
System F. It also relies on the fact that types are finite: indeed, *f.(f f) is well-
typed in an extension of the simply-typed *-calculus with recursive types,
where the equation T = T ! T0 has a solution.

Later, we will develop a type inference algorithm for ML-the-type-system
and prove that it is correct and complete. Then, to prove that a term is ill-
typed, it will be sufficient to simulate a run of the algorithm and to check
that it reports a failure.

10.3.2 Solution: Our hypotheses are C, \Gamma  ` t : 8_X[D].T (1) and C dh [~X , ~T]D (2).

We may also assume, w.l.o.g., _X # ftv(C, \Gamma  , ~T) (3). By hmx-Inst and (1), we have
C ^D, \Gamma  ` t : T, which by Lemma 10.3.1 yields C ^D ^~X = ~T, \Gamma  ` t : T (4). Now,
we claim that ~X = ~T dh T <= [~X , ~T]T (5) holds; the proof appears in the next
paragraph. Applying hmx-Sub to (4) and to (5), we obtain C ^ D ^ ~X = ~T, \Gamma  `
t : [~X , ~T]T (6). By C-Eq and by (2), we have C ^ ~X = ~T dh D, so (6) may be
written C ^ ~X = ~T, \Gamma  ` t : [~X , ~T]T (7). Last, (3) implies _X # ftv(\Gamma  , [~X , ~T]T) (8).
Applying rule hmx-Exists to (7) and (8), we get 9_X.(C ^ ~X = ~T), \Gamma  ` t : [~X ,
~T]T (9). By C-NameEq and by (3), 9_X.(C ^ ~X = ~T) is equivalent to C, hence (9)

is the goal C, \Gamma  ` t : [~X , ~T]T.

There now remains to establish (5). One possible proof method is to unfold
the definition of dh and reason by structural induction on T. Here is another,
axiomatic approach. Let Z be fresh for T, ~X, and ~T. By reflexivity of subtyping
and by C-ExTrans, we have true j T <= T j 9Z.(T <= Z ^ Z <= T), which by
congruence of j and by C-ExAnd implies ~X = ~T j 9Z.(T <= Z ^ ~X = ~T ^ Z <=
T) (10). Furthermore, by C-Eq, we have (~X = ~T ^ Z <= T) j (~X = ~T ^ Z <= [~X ,
~T]T) dh (Z <= [~X , ~T]T) (11). Combining (10) and (11) yields ~X = ~T dh 9Z.(T <=

Z ^ Z <= [~X , ~T]T), which by C-ExTrans may be read ~X = ~T dh T <= [~X , ~T]T.

10.3.3 Solution: The simplest possible derivation of true, IJ ` *z.z : int ! int is

syntax-directed. It closely resembles the Damas-Milner derivation given in
Exercise 10.1.23.

true, z : int ` z : int hmx-Var
true, IJ ` *z.z : int ! int hmx-Abs

As in Exercise 10.1.23, we may use a type variable X instead of the type int,

526 A Solutions to Selected Exercises

then employ hmx-Gen to quantify universally over X.

true, z : X ` z : X hmx-Var
true, IJ ` *z.z : X ! X hmx-Abs X # ftv(true, IJ)

true, IJ ` *z.z : 8X[true].X ! X hmx-Gen

The validity of this instance of hmx-Gen relies on the equivalence true^true j
true and on the fact that judgments are identified up to equivalence of their
constraint assumptions.

If we now wish to instantiate X with int, we may use hmx-Inst' as follows:

true, IJ ` *z.z : 8X[true].X ! X true dh [X , int]true

true, IJ ` *z.z : int ! int hmx-Inst'

This is not, strictly speaking, an HM(X) derivation, since hmx-Inst' is not
part of the rules of Figure 10-7. However, since the proof of Lemma 10.3.1
and the solution of Exercise 10.3.2 are constructive, it is possible to exhibit
the HM(X) derivation that underlies it. We find:

Y = int, z : X ` z : X hmx-Var
Y = int, IJ ` *z.z : X ! X hmx-Abs
Y = int, IJ ` *z.z : 8X.X ! X hmx-Gen

Y = int, IJ ` *z.z : Y ! Y hmx-Inst
Y = int dh Y ! Y <= int ! int

Y = int, IJ ` *z.z : int ! int hmx-Sub
9Y.(Y = int), IJ ` *z.z : int ! int hmx-Exists

Since 9Y.(Y = int) is equivalent to true, the conclusion is indeed the desired
judgment.

10.4.1 Solution: Let X 62 ftv(\Gamma  ) (1). Assume that there exist a satisfiable constraint

C and a type T such that C, \Gamma  ` t : T (2) holds. Thanks to (1), we find that,
up to a renaming of C and T, we may further assume X 62 ftv(C, T) (3). Then,
applying Lemma 10.3.1 to (2), we obtain C ^ T = X, \Gamma  ` t : T, which by hmx-
Sub yields C ^ T = X, \Gamma  ` t : X (4). Furthermore, by (3) and C-NameEq, we have
9X.(C ^ T = X) j C. Because C is satisfiable, this implies that C ^ T = X is
satisfiable as well. As a result, we have found a satisfiable constraint C0 such
that C0, \Gamma  ` t : X holds.

Now, assume \Gamma  is closed and X is arbitrary. Then, (1) holds, so the previous
paragraph proves that, if t is well-typed within \Gamma  , then there exists a satisfi-
able constraint C0 such that C0, \Gamma  ` t : X holds. By the completeness property,

A Solutions to Selected Exercises 527
we must then have C0 dh J\Gamma  ` t : XK. Since C0 is satisfiable, this implies that
J\Gamma  ` t : XK is satisfiable as well. Conversely, if J\Gamma  ` t : XK is satisfiable, then,
by the soundness property, t is well-typed within \Gamma  .

10.7.1 Solution: We have

let \Gamma 0 in Jc t1 . . . tn : T0K
j let \Gamma 0 in 9Z1 . . . Zn.(Vni=1Jti : ZiK ^ c _ Z1 ! . . . ! Zn ! T0) (1)
j let \Gamma 0 in 9Z1 . . . Zn_X.(Vni=1Jti : ZiK

^ T1 ! . . . ! Tn ! T <= Z1 ! . . . ! Zn ! T0)

(2)

j let \Gamma 0 in 9_X.(Vni=1Jti : TiK ^ T <= T0) (3)
where (1) is by definition of constraint generation; (2) is by C-InId; (3) is by
C-Arrow, C-ExAnd, and by Lemma 10.4.6.

10.7.2 Solution: We must first ensure that R-Add respects v (Definition 10.5.4).

Since the rule is pure, it is sufficient to establish that let \Gamma 0 in J^n1 ^+ ^n2 : TK
entails let \Gamma 0 in J "n1 + n2 : TK. In fact, we have

let \Gamma 0 in J^n1 ^+ ^n2 : TK
j let \Gamma 0 in (J^n1 : intK ^ J^n2 : intK ^ int <= T) (1)
j let \Gamma 0 in (int <= int ^ int <= int ^ int <= T) (2)
j int <= T (3)
j let \Gamma 0 in J "n1 + n2 : TK (4)

where (1) and (2) are by Exercise 10.7.1; (3) is by C-In* and by reflexivity of
subtyping; (4) is by Exercise 10.7.1 again.

Second, we must check that if the configuration c v1 . . . vk/u (where k >= 0)
is well-typed, then either it is reducible, or c v1 . . . vk is a value.

We begin by checking that every value that is well-typed with type int is of
the form ^n. Indeed, suppose that let \Gamma 0; ref M in Jv : intK is satisfiable. Then, v
cannot be a program variable, for a well-typed value must be closed. v cannot
be a memory location m, for otherwise ref M(m) <= int would be satisfiable--
but the type constructors ref and int are incompatible. v cannot be ^+ or ^+ v0,
for otherwise int ! int ! int <= int or int ! int <= int would be satisfiable--but
the type constructors ! and int are incompatible. Similarly, v cannot be a
*-abstraction. Thus, v must be of the form ^n, for it is the only case left.

Next, we note that, according to the constraint generation rules, if the
configuration c v1 . . . vk/u is well-typed, then a constraint of the form
let \Gamma 0; ref M in (c _ X1 ! . . . ! Xk ! T ^ Jv1 : X1K ^ . . . ^ Jvk : XkK) is satisfiable.
We now reason by cases on c.

ffi Case c is ^n. Then, \Gamma 0(c) is int. Because the type constructors int and !
are incompatible with each other, this implies k = 0. Since ^n is a constructor,
the expression is a value.

528 A Solutions to Selected Exercises

ffi Case c is ^+. We may assume k >= 2, because otherwise the expression is
a value. Then, \Gamma 0(c) is int ! int ! int, so, by C-Arrow, the above constraint
entails let \Gamma 0; ref M in (X1 <= int ^ X2 <= int ^ Jv1 : X1K ^ Jv2 : X2K), which, by
Lemma 10.4.5, entails let \Gamma 0; ref M in (Jv1 : intK ^ Jv2 : intK). Thus, v1 and
v2 are well-typed with type int. By the remark above, they must be integer
literals ^n1 and ^n2. As a result, the configuration is reducible by R-Add.

10.7.5 Solution: We must first ensure that R-Ref, R-Deref and R-Assign respect v

(Definition 10.5.4).

ffi Case R-Ref. The reduction is ref v/IJ -! m/(m , v), where m 62 fpi(v) (1).
Let T be an arbitrary type. According to Definition 10.5.4, the goal is to show
that there exist a set of type variables _Y and a store type M0 such that
_Y # ftv(T) and ftv(M0) ` _Y and dom(M0) = {m} and let \Gamma 0 in Jref v : TK

entails 9_Y.let \Gamma 0; ref M0 in Jm/(m , v) : T/M0K. Now, we have

let \Gamma 0 in Jref v : TK
j 9Y.let \Gamma 0 in (ref Y <= T ^ Jv : YK) (2)
j 9Y.let \Gamma 0; ref M0 in (m _ T ^ Jv : M0(m)K) (3)
j 9Y.let \Gamma 0; ref M0 in Jm/(m , v) : T/M0K (4)

where (2) is by Exercise 10.7.1 and by C-InEx; (3) assumes M0 is defined as
m , Y, and follows from (1), C-InId and C-In*; and (4) is by definition of
constraint generation.

ffi Case R-Deref. The reduction is !m/(m , v) -! v/(m , v). Let T be an
arbitrary type and let M be a store type of domain {m}. We have

let \Gamma 0; ref M in J!m/(m , v) : T/MK
j let \Gamma 0; ref M in 9Y.(ref M(m) <= ref Y ^ Y <= T ^ Jv : M(m)K) (1)
j let \Gamma 0; ref M in 9Y.(M(m) = Y ^ Y <= T ^ Jv : M(m)K) (2)
j let \Gamma 0; ref M in (M(m) <= T ^ Jv : M(m)K) (3)
dh let \Gamma 0; ref M in (Jv : TK ^ Jv : M(m)K) (4)
j let \Gamma 0; ref M in Jv/(m , v) : T/MK (5)

where (1) is by Exercise 10.7.1 and by C-InId; (2) follows from C-ExTrans and
from the fact that ref is an invariant type constructor; (3) is by C-NameEq;
(4) is by Lemma 10.4.5 and C-Dup; and (5) is again by definition of constraint
generation.

ffi Case R-Assign. The reduction is m := v/(m , v0) -! v/(m , v). Let T

A Solutions to Selected Exercises 529
be an arbitrary type and let M be a store type of domain {m}. We have

let \Gamma 0; ref M in Jm := v/(m , v0) : T/MK
dh let \Gamma 0; ref M in Jm := v : TK (1)
j let \Gamma 0; ref M in 9Z.(ref M(m) <= ref Z ^ Jv : ZK ^ Z <= T) (2)
j let \Gamma 0; ref M in 9Z.(M(m) = Z ^ Z <= T ^ Jv : ZK) (3)
j let \Gamma 0; ref M in (M(m) <= T ^ Jv : M(m)K) (4)
dh let \Gamma 0; ref M in Jv/(m , v) : T/MK (5)

where (1) is by definition of constraint generation; (2) is by Exercise 10.7.1
and C-InId; (3) follows from the fact that ref is an invariant type constructor;
(4) is by C-NameEq; and (5) is obtained as in the previous case.

Second, we must check that if the configuration c v1 . . . vk/u (where k >= 0)
is well-typed, then either it is reducible, or c v1 . . . vk is a value. We only
give a sketch of this proof; see the solution to Exercise 10.7.2 for details of a
similar proof.

We begin by checking that every value that is well-typed with a type of the
form ref T is a memory location. This assertion relies on the fact that the type
constructor ref is isolated.

Next, we note that, according to the constraint generation rules, if the
configuration c v1 . . . vk/u is well-typed, then a constraint of the form
let \Gamma 0; ref M in (c _ X1 ! . . . ! Xk ! T ^ Jv1 : X1K ^ . . . ^ Jvk : XkK) is satisfiable.
We now reason by cases on c.

ffi Case c is ref. If k = 0, then the expression is a value; otherwise, it is
reducible by R-Ref.

ffi Case c is !. We may assume k >= 1; otherwise the expression is a value.
By definition of \Gamma 0(!), the above constraint entails let \Gamma 0; ref M in 9Y.(ref Y !
Y <= X1 ! . . . ! Xk ! T ^ Jv1 : X1K), which, by C-Arrow, Lemma 10.4.5, and
C-InEx, entails 9Y.let \Gamma 0; ref M in Jv1 : ref YK. Thus, v1 is well-typed with a
type of the form ref Y. By the remark above, v1 must be a memory location
m. Furthermore, because every well-typed configuration is closed, m must
be a member of dom(u). As a result, the configuration ref v1 . . . vk/u is
reducible by R-Deref.

ffi Case c is :=. We may assume k >= 2, because otherwise the expression is a
value. As above, we check that v1 must be a memory location and a member
of dom(u). Thus, the configuration is reducible by R-Assign.

10.8.2 Solution: The record access operation *.h`bi may be given the type scheme

8Xb.{`b : Xb} ! Xb. However, this type scheme isn't satisfactory, because it
allows accessing `b only in records where `a and `c are undefined. The type
scheme 8XaXb.{`a : Xa; `b : Xb} ! Xb is also a valid type scheme for *.h`bi,

530 A Solutions to Selected Exercises

but allows accessing `b only in records where `a is defined and `c is not. To
sum up, a satisfactory description of *.h`bi requires a whole family of type
schemes, none of which is principal (more general than the others). A similar
problem arises with record extension h* with `b = *i.

A potential solution is to equip record types with a subtyping relationship,
so that (say) both {`a : Ta; `b : Tb} and {`a : Ta; `b : Tb; `c : Tc} are subtypes
of {`b : Tb}. Then, 8Xb.{`b : Xb} ! Xb becomes a satisfactory type scheme for
the record access operation *.h`bi. Indeed, the operation is now applicable
to any record that admits a type of the form {`b : Tb}, that is, thanks to
subtyping, to any record where `b is defined, regardless of which other fields
are defined.

However, this is only half a solution, because there still is a problem with
record extension. The type scheme 8Xb.{`b : Xb} ! {`b : Xb} is valid, and
makes record extension applicable to any record where `b is defined, which
is good. The trouble is with its return type: it states that only `b may be
safely assumed to be defined in the new record. In other words, it causes
static information about all fields other than `b to be lost. Addressing this
dramatic loss of precision is one of the key motivations for introducing rows.

10.8.5 Solution: We let the reader check that X must have kind ?.Type and Y must

have kind ?.Row({`}). The type with all superscripts made explicit is

X !Type \Pi  (`?,Row(IJ) : intType ; (Y !Row({`}) @?,Row({`})X)).
In this case, because the type constructor \Pi  occurs on the right-hand side
of the toplevel arrow, it is possible to guess that the type must have kind
?.Type. There are cases where it is not possible to guess the kind of a type,
because it may have several kinds; consider, for instance, @int.

10.8.27 Solution: For the sake of generality, we perform the proof in the presence of

subtyping, that is, we do not assume that subtyping is interpreted as equality.
We formulate some hypotheses about the interpretation of subtyping: the
type constructors (` : * ; *), @, and \Pi  must be covariant; the type constructors
! and \Pi  must be isolated.

We begin with a preliminary fact: if the domain of V is {`1, . . . , `n}, where
`1 < . . . < `n, then the constraint let \Gamma 0 in J{V; v} : TK is equivalent to
let \Gamma 0 in 9Z1 . . . ZnZ.(Vni=1JV(`i) : ZiK ^ Jv : ZK ^ \Pi  (`1 : Z1; . . . ; `n : Zn; @Z) <= T).
We let the reader check this fact using the constraint generation rules, the
definition of \Gamma 0 and rule C-InId, and the above covariance hypotheses. We
note that, by C-Row-LL, the above constraint is invariant under a permuta-
tion of the labels `1, . . . , `n, so the above fact still holds when the hypothesis
`1 < . . . < `n is removed.

A Solutions to Selected Exercises 531

We now prove that rules R-Update, R-Access-1, and R-Access-2 enjoy sub-
ject reduction (Definition 10.5.4). Because the store is not involved, the goal
is to establish that let \Gamma 0 in Jt : TK entails let \Gamma 0 in Jt0 : TK, where t is the redex
and t0 is the reduct.

ffi Case R-Update. We have:

let \Gamma 0 in J{{V; v} with ` = v0} : TK
j let \Gamma 0 in 9XX0Y.(J{V; v} : \Pi  (` : X ; Y)K ^ Jv0 : X0K ^ \Pi  (` : X0 ; Y) <= T) (1)
j let \Gamma 0 in 9XX0YZ1 . . . ZnZ.(Vni=1JV(`i) : ZiK ^ Jv : ZK

^ \Pi  (`1 : Z1; . . . ; `n : Zn; @Z) <= \Pi  (` : X ; Y)
^ Jv0 : X0K ^ \Pi  (` : X0 ; Y) <= T)

(2)

where (1) is by Exercise 10.7.1, and (2) follows from the preliminary fact and
from C-ExAnd, provided {`1, . . . , `n} is the domain of V. We now distinguish
two subcases:

Subcase ` 2 dom(V). We may assume, w.l.o.g., that ` is `1. Then, by our
covariance hypotheses, the subconstraint in the second line of (2) entails
(`2 : Z2; . . . ; `n : Zn; @Z) <= Y, which in turn entails \Pi  (`1 : X0; `2 : Z2; . . . ; `n :
Zn; @Z) <= \Pi  (` : X0 ; Y). By transitivity of subtyping, the subconstraint in the
second and third lines of (2) entails \Pi  (`1 : X0; `2 : Z2; . . . ; `n : Zn; @Z) <= T. By
this remark and by C-Ex*, (2) entails

let \Gamma 0 in 9X0Z2 . . . ZnZ.(Jv0 : X0K ^ Vni=2JV(`i) : ZiK ^ Jv : ZK

^ \Pi  (`1 : X0; `2 : Z2; . . . ; `n : Zn; @Z) <= T)

(3)

which by our preliminary fact is precisely let \Gamma 0 in J{V[` , v0]; v} : TK.

Subcase ` AE dom(V). By C-Row-DL and C-Row-LL, the term (`1 : Z1; . . . ; `n :
Zn; @Z) may be replaced with (` : Z; `1 : Z1; . . . ; `n : Zn; @Z). Thus, reasoning as
in the previous subcase, we find that (2) entails

let \Gamma 0 in 9X0Z1 . . . ZnZ.(Jv0 : X0K ^ Vni=1JV(`i) : ZiK ^ Jv : ZK

^ \Pi  (`1 : X0; `1 : Z1; . . . ; `n : Zn; @Z) <= T)

(4)

which by our preliminary fact is precisely let \Gamma 0 in J{V[` , v0]; v} : TK.

ffi Cases R-Access-1, R-Access-2. We have:

let \Gamma 0 in J{V; v}.{`} : TK
j let \Gamma 0 in 9XY.(J{V; v} : \Pi  (` : X ; Y)K ^ X <= T) (1)
j let \Gamma 0 in 9XYZ1 . . . ZnZ.(Vni=1JV(`i) : ZiK ^ Jv : ZK

^ \Pi  (`1 : Z1; . . . ; `n : Zn; @Z) <= \Pi  (` : X ; Y)
^ X <= T)

(2)

where (1) is by Exercise 10.7.1, and (2) follows from the preliminary fact and
from C-ExAnd, provided {`1, . . . , `n} is the domain of V. We now distinguish
two subcases:

532 A Solutions to Selected Exercises

Subcase ` 2 dom(V), i.e., (R-Access-1). We may assume, w.l.o.g., that ` is
`1. Then, by our covariance hypotheses, the subconstraint in the second line
of (2) entails Z1 <= X. By transitivity of subtyping, by Lemma 10.4.5, and by
C-Ex*, we find that (2) entails let \Gamma 0 in JV(`) : TK.

Subcase ` AE dom(V), i.e., (R-Access-2). By C-Row-DL and C-Row-LL, the
term (`1 : Z1; . . . ; `n : Zn; @Z) may be replaced with (` : Z; `1 : Z1; . . . ; `n :
Zn; @Z). Thus, reasoning as in the previous subcase, we find that (2) entails
let \Gamma 0 in Jv : TK.

Before attacking the proof of the progress property, let us briefly check that
every value v that is well-typed with type \Pi  T must be a record value, that is,
must be of the form {V; w}. Indeed, assume that let \Gamma 0; ref M in Jv : \Pi  TK
is satisfiable. Then, v cannot be a program variable, for a well-typed value
must be closed. Furthermore, v cannot be a memory location m, because
ref M(m) <= \Pi  T is unsatisfiable: indeed, the type constructors ref and \Pi 
are incompatible (recall that \Pi  is isolated). Similarly, v cannot be a partially
applied constant or a *-abstraction, because T0 ! T00 <= \Pi  T is unsatisfiable.
Thus, v must be a fully applied constructor. Since the only constructors in
the language are the record constructors {}L, v must be a record value. (If
there were other constructors in the language, they could be ruled out as
well, provided their return types are incompatible with \Pi .)

We must now prove that if the configuration c v1 . . . vk/u is is well-typed,
then either it is reducible, or c v1 . . . vk is a value. By the well-typedness hy-
pothesis, a constraint of the form let \Gamma 0; ref M in Jc v1 . . . vk : TK is satisfiable.

ffi Case c is {}L. If k is less than or equal to n + 1, where n is the cardinal
of L, then c v1 . . . vk is a value. Otherwise, unfolding the above constraint,
we find that it cannot be satisfiable, because \Pi  and ! are incompatible; this
yields a contradiction.

ffi Case c is {* with ` = *}. Analogous to the next case.
ffi Case c is *.{`}. If k = 0, then c v1 . . . vk is a value. Assume k >= 1. Then,
the constraint let \Gamma 0; ref M in Jc v1 : TK is satisfiable. By Exercise 10.7.1, this
implies that let \Gamma 0; ref M in Jv1 : \Pi  (` : X ; Y)K is satisfiable. Thus, v1 must be a
record value, and the configuration is reducible by R-Access-1 or R-Access-2.

10.8.33 Solution: To make extension strict, it suffices to restrict its binding in the

initial environment \Gamma 0, as follows:

h* with ` = *i : 8XY.\Pi  (` : abs ; Y) ! X ! \Pi  (` : pre X ; Y).
The new binding, which is less general than the former, requires the field `
to be absent in the input record. The operational semantics need not be mod-
ified, since strict extension coincides with free extension when it is defined.

A Solutions to Selected Exercises 533

Defining the operational semantics of (free) restriction is left to the reader.
Its binding in the initial environment should be:

* \ h`i : 8XY.\Pi  (` : X ; Y) ! \Pi  (` : abs ; Y)
In principle, there is no need to guess this binding: it may be discovered
through the encoding of finite records in terms of full records (10.8.32). Strict
restriction, which requires the field to be present in the input record, may be
assigned the following type scheme:

* \ h`i : 8XY.\Pi  (` : pre X ; Y) ! \Pi  (` : abs ; Y)
10.8.34 Solution: The informal sentence "supplying a record with more fields in a

context where a record with fewer fields is expected" may be understood as
"providing an argument of type \Pi  (` : pre T ; T0) to a function whose domain
type is \Pi  (` : abs ; T0)," or, more generally, as "writing a program whose
well-typedness requires some constraint of the form \Pi  (` : pre T ; T0) <= \Pi 
(` : abs ; T0) to be satisfiable." Now, in a nonstructural subtyping order where
pre a` abs holds, such a constraint is equivalent to true. On the opposite, if
subtyping is interpreted as equality, then such a constraint is equivalent to
false. In other words, it is the law pre T <= abs j true that gives rise to width
subtyping.

It is worth drawing a comparison with the way width subtyping is defined in
type systems that do not have rows. In such type systems, a record type is of
the form {`1 : T1; . . . ; `n : Tn}. Let us forget about the types T1, . . . , Tn, because
they describe the contents of fields, not their presence, and are thus orthog-
onal to the issue at hand. Then, a record type is a set {`1, . . . , `n}, and width
subtyping is obtained by letting subtyping coincide with (the reverse of) set
containment. In a type system that exploits rows, on the other hand, a record
type is a total mapping from row labels to either pre or abs. (Because we are
ignoring T1, . . . , Tn, let us temporarily imagine that pre is a nullary type con-
structor.) The above record type is then written {`1 : pre; . . . ; `n : pre; @abs}.
In other words, a set is now encoded as its characteristic function. Width sub-
typing is obtained by letting pre a` abs and by lifting this ordering, pointwise,
to rows (which corresponds to our convention that rows are covariant).

References
Abadi, Marti'n, Luca Cardelli, Pierre-Louis Curien, and Jean-Jacques Le'vy. Explicit sub-

stitutions. Journal of Functional Programming, 1(4):375-416, 1991. Summary in

ACM Symposium on Principles of Programming Languages (POPL), San Francisco,
California, 1990.

Adams, Rolf, Walter Tichy, and Annette Weinert. The cost of selective recompila-

tion and environment processing. ACM Transactions on Software Engineering and

Methodology, 3(1):3-28, January 1994.

Ahmed, Amal, Limin Jia, and David Walker. Reasoning about hierarchical storage.

In IEEE Symposium on Logic in Computer Science (LICS), Ottawa, Canada, pages
33-44, June 2003.

Ahmed, Amal and David Walker. The logical approach to stack typing. In ACM SIG-

PLAN Workshop on Types in Language Design and Implementation (TLDI), New
Orleans, Louisiana, pages 74-85, January 2003.

Aho, Alfred V., Ravi Sethi, and Jeffrey D. Ullman. Compilers: Principles, Techniques,

and Tools. Addison-Wesley, Reading, Massachusetts, 1986.

Aiken, Alexander, Manuel Fa"hndrich, and Raph Levien. Better static memory man-

agement: Improving region-based analysis of higher-order languages. In ACM SIG-
PLAN Conference on Programming Language Design and Implementation (PLDI),
La Jolla, California, pages 174-185, June 1995.

Aiken, Alexander, Jeffrey S. Foster, John Kodumal, and Tachio Terauchi. Checking

and inferring local non-aliasing. In ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI), San Diego, California, pages 129-140,
June 2003.

Aiken, Alexander and Edward L. Wimmers. Solving systems of set constraints. In

IEEE Symposium on Logic in Computer Science (LICS), Santa Cruz, California, pages
329-340, June 1992.

536 References

Aiken, Alexander and Edward L. Wimmers. Type inclusion constraints and type infer-

ence. In ACM Symposium on Functional Programming Languages and Computer
Architecture (FPCA), Copenhagen, Denmark, pages 31-41, June 1993.

Altenkirch, Thorsten. Constructions, Inductive Types and Strong Normalization. PhD

thesis, Laboratory for Foundations of Computer Science, University of Edinburgh,
Edinburgh, Scotland, 1993.

Amadio, Roberto M. and Luca Cardelli. Subtyping recursive types. ACM Transac-

tions on Programming Languages and Systems, 15(4):575-631, 1993. Summary
in ACM Symposium on Principles of Programming Languages (POPL), Orlando,
Florida, pp. 104-118; also DEC/Compaq Systems Research Center Research Report
number 62, August 1990.

Amtoft, Torben, Flemming Nielson, and Hanne Riis Nielson. Type and Effect Systems:

Behaviours for Concurrency. Imperial College Press, 1999.

Ancona, Davide and Elena Zucca. A theory of mixin modules: Basic and derived op-

erators. Mathematical Structures in Computer Science, 8(4):401-446, August 1998.

Ancona, Davide and Elena Zucca. A calculus of module systems. Journal of Functional

Programming, 12(2):91-132, March 2002.

Appel, Andrew W. Foundational proof-carrying code. In IEEE Symposium on Logic in

Computer Science (LICS), Boston, Massachusetts, pages 247-258, June 2001.

Appel, Andrew W. and Amy P. Felty. A semantic model of types and machine instruc-

tions for proof-carrying code. In ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages (POPL), Boston, Massachusetts, pages 243-253, January
2000.

Aspinall, David. Subtyping with singleton types. In International Workshop on Com-

puter Science Logic (CSL), Kazimierz, Poland, volume 933 of Lecture Notes in Com-
puter Science, pages 1-15. Springer-Verlag, September 1994.

Aspinall, David and Martin Hofmann. Another type system for in-place update. In

European Symposium on Programming (ESOP), Grenoble, France, volume 2305 of
Lecture Notes in Computer Science, pages 36-52. Springer-Verlag, April 2002.

Augustsson, Lennart. Cayenne--A language with dependent types. In ACM SIGPLAN

International Conference on Functional Programming (ICFP), Baltimore, Maryland,
pages 239-250, 1998.

Baader, Franz and Jo"rg Siekmann. Unification theory. In D. M. Gabbay, C. J. Hogger,

and J. A. Robinson, editors, Handbook of Logic in Artificial Intelligence and Logic
Programming, volume 2, Deduction Methodologies, pages 41-125. Oxford Univer-
sity Press, 1994.

Baker, Henry G. Lively linear Lisp--look ma, no garbage! ACM SIGPLAN Notices, 27

(8):89-98, 1992.

Barendregt, Henk P. The Lambda Calculus. North Holland, revised edition, 1984.
Barendregt, Henk P. Introduction to generalized type systems. Journal of Functional

Programming, 1(2):125-154, 1991.

References 537
Barendregt, Henk P. Lambda calculi with types. In S. Abramsky, D. M. Gabbay, and

T. Maibaum, editors, Handbook of Logic in Computer Science, volume 2, Computa-
tional Structures. Oxford University Press, 1992.

Barendsen, Erik and Sjaak Smetsers. Conventional and uniqueness typing in graph

rewrite systems. In Foundations of Software Technology and Theoretical Computer
Science (FSTTCS), Bombay, India, volume 761 of Lecture Notes in Computer Science,
pages 41-51. Springer-Verlag, December 1993.

Barras, Bruno, Samuel Boutin, Cristina Cornes, Judicael Courant, Jean-Christophe

Filliatre, Eduardo Gimenez, Hugo Herbelin, Gerard Huet, Cesar Munoz, Chetan
Murthy, Catherine Parent, Christine Paulin-Mohring, Amokrane Saibi, and Benjamin
Werner. The Coq proof assistant reference manual: Version 6.1. Technical Report
RT-0203, INRIA, 1997.

Bauer, Lujo, Andrew W. Appel, and Edward W. Felten. Mechanisms for secure modular

programming in Java. Technical Report TR-603-99, Princeton University, 1999.

Bellantoni, Stephan and Stephan Cook. A new recursion-theoretic characterization of

polytime functions. Computational Complexity, 2(2):97-110, 1992.

Bellantoni, Stephan, K.-H. Niggl, and H. Schwichtenberg. Higher type recursion, rami-

fication and polynomial time. Annals of Pure and Applied Logic, 104:17-30, 2000.

Berardi, Stefano. Towards a mathematical analysis of the Coquand-Huet calculus

of constructions and the other systems in Barendregt's cube. Technical report,
Department of Computer Science, CMU, and Dipartimento Matematica, Universita
di Torino, 1988.

Berthomieu, Bernard. Tagged types: A theory of order sorted types for tagged expres-

sions. Research Report 93083, LAAS, 7, avenue du Colonel Roche, 31077 Toulouse,
France, March 1993.

Berthomieu, Bernard and Camille le Monie`s de Sagazan. A calculus of tagged types,

with applications to process languages. In Workshop on Types for Program Analysis
(TPA), informal proceedings, pages 1-15, May 1995.

Biagioni, Edoardo, Nicholas Haines, Robert Harper, Peter Lee, Brian G. Milnes, and

Eliot B. Moss. Signatures for a protocol stack: A systems application of Stan-
dard ML. In ACM Symposium on Lisp and Functional Programming (LFP), Orlando,
Florida, pages 55-64, June 1994.

Bierman, G. M., A. M. Pitts, and C. V. Russo. Operational properties of Lily, a polymor-

phic linear lambda calculus with recursion. In Workshop on Higher Order Opera-
tional Techniques in Semantics (HOOTS), Montre'al, Que'bec, volume 41 of Electronic
Notes in Theoretical Computer Science. Elsevier, September 2000.

Birkedal, Lars and Robert W. Harper. Constructing interpretations of recursive types

in an operational setting. Information and Computation, 155:3-63, 1999.

Birkedal, Lars and Mads Tofte. A constraint-based region inference algorithm. Theo-

retical Computer Science, 258:299-392, 2001.

538 References

Birkedal, Lars, Mads Tofte, and Magnus Vejlstrup. From region inference to von Neu-

mann machines via region representation inference. In ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages (POPL), St. Petersburg Beach,
Florida, pages 171-183, 1996.

Blume, Matthias. The SML/NJ Compilation and Library Manager, May 2002. Available

from http://www.smlnj.org/doc/CM/index.html.

Blume, Matthias and Andrew W. Appel. Hierarchical modularity. ACM Transactions

on Programming Languages and Systems, 21(4):813-847, 1999.

Bonniot, Daniel. Type-checking multi-methods in ML (a modular approach). In Inter-

national Workshop on Foundations of Object-Oriented Languages (FOOL), informal
proceedings, January 2002.

Bourdoncle, Franc,ois and Stephan Merz. Type-checking higher-order polymorphic

multi-methods. In ACM SIGPLAN-SIGACT Symposium on Principles of Program-
ming Languages (POPL), Paris, France, pages 302-315, January 1997.

Bracha, Gilad and William R. Cook. Mixin-based inheritance. In ACM SIGPLAN Confer-

ence on Object Oriented Programming: Systems, Languages, and Applications (OOP-
SLA)/European Conference on Object-Oriented Programming (ECOOP), Ottawa, On-
tario, pages 303-311, October 1990.

Brandt, Michael and Fritz Henglein. Coinductive axiomatization of recursive type

equality and subtyping. In International Conference on Typed Lambda Calculi and
Applications (TLCA), Nancy, France, volume 1210 of Lecture Notes in Computer
Science, pages 63-81. Springer-Verlag, April 1997. Full version in Fundamenta
Informaticae, 33:309-338, 1998.

Breazu-Tannen, Val, Thierry Coquand, Carl Gunter, and Andre Scedrov. Inheritance

as implicit coercion. Information and Computation, 93(1):172-221, July 1991. Also
in C. A. Gunter and J. C. Mitchell, editors, Theoretical Aspects of Object-Oriented
Programming: Types, Semantics, and Language Design, MIT Press, 1994.

Bruce, Kim B. Typing in object-oriented languages: Achieving expressibility and

safety, 1995. Available through http://www.cs.williams.edu/~kim.

Bruce, Kim B. Foundations of Object-Oriented Languages: Types and Semantics. MIT

Press, 2002.

Bruce, Kim B., Luca Cardelli, Giuseppe Castagna, the Hopkins Objects Group

(Jonathan Eifrig, Scott Smith, Valery Trifonov), Gary T. Leavens, and Benjamin
Pierce. On binary methods. Theory and Practice of Object Systems, 1(3):221-242,
1996.

Bruce, Kim B., Luca Cardelli, and Benjamin C. Pierce. Comparing object encodings.

In International Symposium on Theoretical Aspects of Computer Software (TACS),
September 1997. An earlier version was presented as an invited lecture at the Third
International Workshop on Foundations of Object Oriented Languages (FOOL 3),
July 1996; full version in Information and Computation, 155(1-2):108-133, 1999.

References 539
de Bruijn, Nicolas G. A survey of the project AUTOMATH. In J. P. Seldin and J. R.

Hindley, editors, To H. B. Curry: Essays in Combinatory Logic, Lambda Calculus,
and Formalism, pages 589-606. Academic Press, 1980.

Brus, Tom, Marko van Eekelen, Maarten van Leer, and Marinus Plasmeijer. Clean: A

language for functional graph rewriting. In ACM Symposium on Functional Pro-
gramming Languages and Computer Architecture (FPCA), Portland, Oregon, vol-
ume 274 of Lecture Notes in Computer Science, pages 364-384. Springer-Verlag,
September 1987.

Burstall, Rod and Butler Lampson. A kernel language for abstract data types and

modules. In International Symposium on Semantics of Data Types, Sophia-Antipolis,
France, volume 173 of Lecture Notes in Computer Science, pages 1-50. Springer-
Verlag, June 1984.

Burstall, Rod, David MacQueen, and Donald Sannella. HOPE: an experimental ap-

plicative language. In ACM Symposium on Lisp and Functional Programming (LFP),
Stanford, California, pages 136-143, August 1980.

Calcagno, Cristiano. Stratified operational semantics for safety and correctness of re-

gion calculus. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL), London, England, pages 155-165, 2001.

Calcagno, Cristiano, Simon Helsen, and Peter Thiemann. Syntactic type soundness

results for the region calculus. Information and Computation, 173(2):199-221,
2002.

Cardelli, Luca. A polymorphic *-calculus with Type:Type. Research report 10,

DEC/Compaq Systems Research Center, May 1986.

Cardelli, Luca. Phase distinctions in type theory, 1988a. Manuscript, available from

http://www.luca.demon.co.uk.

Cardelli, Luca. Typechecking dependent types and subtypes. In Foundations of Logic

and Functional Programming, Trento, Italy, (December, 1986), volume 306 of Lec-
ture Notes in Computer Science, pages 45-57. Springer-Verlag, 1988b.

Cardelli, Luca. Program fragments, linking, and modularization. In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), Paris, France,

pages 266-277, January 1997.

Cardelli, Luca, James Donahue, Mick Jordan, Bill Kalsow, and Greg Nelson. The

Modula-3 type system. In Proceedings of the Sixteenth Annual ACM Symposium

on Principles of Programming Languages, pages 202-212, January 1989.

Cardelli, Luca and Xavier Leroy. Abstract types and the dot notation. In IFIP TC2

Working Conference on Programming Concepts and Methods. North Holland, 1990.
Also appeared as DEC/Compaq SRC technical report 56.

Cardelli, Luca and Giuseppe Longo. A semantic basis for Quest. Journal of Functional

Programming, 1(4):417-458, October 1991. Summary in ACM Conference on Lisp
and Functional Programming, pp. 30-43, 1990. Also available as DEC/Compaq SRC
Research Report 55, Feb. 1990.

540 References

Cardelli, Luca and John Mitchell. Operations on records. Mathematical Structures

in Computer Science, 1:3-48, 1991. Also in C. A. Gunter and J. C. Mitchell, edi-
tors, Theoretical Aspects of Object-Oriented Programming: Types, Semantics, and
Language Design, MIT Press, 1994; available as DEC/Compaq Systems Research
Center Research Report #48, August, 1989; and in the Proceedings of Workshop
on the Mathematical Foundations of Programming Semantics (MFPS), New Orleans,
Louisiana, Springer LNCS, volume 442, pp. 22-52, 1989.

Cartmell, John. Generalised algebraic theories and contextual categories. Annals of

Pure and Applied Logic, 32:209-243, 1986.

Cartwright, Robert and Mike Fagan. Soft typing. In ACM SIGPLAN Conference on Pro-

gramming Language Design and Implementation (PLDI), Toronto, Ontario, pages
278-292, June 1991.

Cervesato, Iliano, Joshua S. Hodas, and Frank Pfenning. Efficient resource manage-

ment for linear logic proof search. Theoretical Computer Science, 232(1-2):133-
163, February 2000.

Cervesato, Iliano and Frank Pfenning. A linear logical framework. Information and

Computation, 179(1):19-75, November 2002.

Chaki, Sagar, Sriram K. Rajamani, and Jakob Rehof. Types as models: Model checking

message-passing programs. In ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages (POPL), Portland, Oregon, pages 45-57, 2002.

Chirimar, Jawahar, Carl A. Gunter, and Jon G. Riecke. Reference counting as a com-

putational interpretation of linear logic. Journal of Functional Programming, 6(2):
195-244, March 1996.

Christiansen, Morten Voetmann and Per Velschow. Region-based memory manage-

ment in Java. Master's thesis, University of Copenhagen, Department of Computer
Science, 1998.

Church, Alonzo. The Calculi of Lambda Conversion. Princeton University Press, 1941.
Church, Alonzo. The weak theory of implication. Kontroliertes Denken: Untersuchun-

gen zum Logikkalk ul und zur Logik der Einzelwissenschaften, pages 22-37, 1951.

Clement, Dominique, Joelle Despeyroux, Thierry Despeyroux, and Gilles Kahn. A

simple applicative language: Mini-ML. In ACM Symposium on Lisp and Functional
Programming (LFP), Cambridge, Massachusetts, pages 13-27, August 1986.

Colby, Christopher, Peter Lee, George C. Necula, Fred Blau, Mark Plesko, and Kenneth

Cline. A certifying compiler for Java. ACM SIGPLAN Notices, 35(5):95-107, May
2000.

Comon, Hubert. Constraints in term algebras (short survey). In Conference on Alge-

braic Methodology and Software Technology (AMAST), June, 1993, Workshops in
Computing, pages 97-108. Springer-Verlag, 1994.

Constable, Robert L., Stuart F. Allen, Mark Bromley, Rance Cleaveland, James F. Cre-

mer, Robert W. Harper, Douglas J. Howe, Todd B. Knoblock, Paul Mendler, Prakash
Panangaden, James T. Sasaki, and Scott F. Smith. Implementing Mathematics with
the NuPRL Proof Development System. Prentice-Hall, Englewood Cliffs, NJ, 1986.

References 541
Coquand, Catarina. The AGDA proof system homepage, 1998. http://www.cs.

chalmers.se/~catarina/agda/.

Coquand, Thierry. An analysis of Girard's paradox. In IEEE Symposium on Logic in

Computer Science (LICS), Cambridge, Massachusetts, pages 227-236, June 1986.

Coquand, Thierry. An algorithm for testing conversion in type theory. In G. Huet

and G. Plotkin, editors, Logical Frameworks, pages 255-279. Cambridge University
Press, 1991.

Coquand, Thierry. Pattern matching with dependent types. In Workshop on

Types for Proofs and Programs (TYPES), Ba*stad, Sweden, informal proceed-
ings. Available from ftp://ftp.cs.chalmers.se/pub/cs-reports/baastad.
92/proc.ps.Z, June 1992.

Coquand, Thierry and Ge'rard Huet. The calculus of constructions. Information and

Computation, 76(2-3):95-120, February/March 1988.

Coquand, Thierry, Randy Pollack, and Makoto Takeyama. A logical framework with

dependently typed records. In International Conference on Typed Lambda Calculi
and Applications (TLCA), Valencia, Spain, volume 2701 of Lecture Notes in Com-
puter Science, pages 105-119. Springer-Verlag, June 2003.

Courant, Judicae"l. Strong normalization with singleton types. In Workshop on In-

tersection Types and Related Systems (ITRS), Copenhagen, Denmark, volume 70 of
Electronic Notes in Theoretical Computer Science. Elsevier, July 2002.

Crank, Erik and Matthias Felleisen. Parameter-passing and the lambda calculus.

In ACM Symposium on Principles of Programming Languages (POPL), Orlando,
Florida, pages 233-244, January 1991.

Crary, Karl. A simple proof technique for certain parametricity results. In ACM SIG-

PLAN International Conference on Functional Programming (ICFP), Paris, France,
pages 82-89, September 1999.

Crary, Karl. Toward a foundational typed assembly language. In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), New Orleans,
Louisiana, pages 198-212, January 2003.

Crary, Karl, Robert Harper, and Sidd Puri. What is a recursive module? In ACM SIG-

PLAN Conference on Programming Language Design and Implementation (PLDI),
pages 50-63, May 1999.

Crary, Karl, Stephanie Weirich, and Greg Morrisett. Intensional polymorphism in

type-erasure semantics. In ACM SIGPLAN International Conference on Functional
Programming (ICFP), Baltimore, Maryland, pages 301-312, 1998. Full version in
Journal of Functional Programming, 12(6), Nov. 2002, pp. 567-600.

Curtis, Pavel. Constrained Quantification in Polymorphic Type Analysis. PhD thesis,

Cornell University, Ithaca, New York, February 1990.

van Daalen, Diederik T. The Language Theory of Automath. PhD thesis, Technische

Hogeschool Eindhoven, Eindhoven, The Netherlands, 1980.

542 References

Damas, Luis and Robin Milner. Principal type schemes for functional programs. In

ACM Symposium on Principles of Programming Languages (POPL), Albuquerque,
New Mexico, pages 207-212, 1982.

Danvy, Olivier. Functional unparsing. Journal of Functional Programming, 8(6):621-

625, 1998.

DeLine, Rob and Manuel Fa"hndrich. Enforcing high-level protocols in low-level soft-

ware. In ACM SIGPLAN Conference on Programming Language Design and Imple-
mentation (PLDI), Snowbird, Utah, pages 59-69, June 2001.

Donahue, James and Alan Demers. Data types are values. ACM Transactions on

Programming Languages and Systems, 7(3):426-445, July 1985.

Dos^en, Kosta. A historical introduction to substructural logics. In K. Dos^en and

P. Schroeder-Heister, editors, Substructural Logics, pages 1-30. Oxford University
Press, 1993.

Dreyer, Derek, Karl Crary, and Robert Harper. A type system for higher-order mod-

ules. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan-
guages (POPL), New Orleans, Louisiana, pages 236-249, New Orleans, January
2003.

Dussart, Dirk, Fritz Henglein, and Christian Mossin. Polymorphic recursion and sub-

type qualifications: Polymorphic binding-time analysis in polynomial time. In Inter-
national Symposium on Static Analysis (SAS) , Paris, France, volume 983 of Lecture
Notes in Computer Science, pages 118-135. Springer-Verlag, July 1995.

Emms, Martin and Hans LeiSS. Extending the type checker for SML by polymor-

phic recursion--A correctness proof. Technical Report 96-101, Centrum fu"r
Informations- und Sprachverarbeitung, Universita"t Mu"nchen, 1996.

Erhard, Thomas. A categorical semantics of constructions. In IEEE Symposium on

Logic in Computer Science (LICS), Edinburgh, Scotland, pages 264-273, July 1988.

Fa"hndrich, Manuel. Bane: A Library for Scalable Constraint-Based Program Analysis.

PhD thesis, University of California at Berkeley, Berkeley, California, 1999.

Fa"hndrich, Manuel and Rob DeLine. Adoption and focus: Practical linear types for

imperative programming. In ACM SIGPLAN Conference on Programming Language
Design and Implementation (PLDI), Berlin, Germany, pages 13-24, June 2002.

Fa"hndrich, Manuel, Jakob Rehof, and Manuvir Das. Scalable context-sensitive flow

analysis using instantiation constraints. In ACM SIGPLAN Conference on Program-
ming Language Design and Implementation (PLDI), Vancouver, British Columbia,
Canada, pages 253-263, June 2000.

Felleisen, Matthias and Robert Hieb. A revised report on the syntactic theories of

sequential control and state. Theoretical Computer Science, 103(2):235-271, 1992.

Fisher, Kathleen and John H. Reppy. The design of a class mechanism for Moby. In

ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI), Atlanta, Georgia, pages 37-49, May 1999.

References 543
Flanagan, Cormac and Shaz Qadeer. A type and effect system for atomicity. In

ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI), San Diego, California, pages 338-349, June 2003.

Flatt, Matthew and Matthias Felleisen. Units: Cool modules for HOT languages. In

ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI), Montre'al, Que'bec, pages 236-248, 1998.

Fluet, Matthew. Monadic regions. In Workshop on Semantics, Program Analysis and

Computing Environments for Memory Management (SPACE), informal proceedings,
January 2004.

Fluet, Matthew and Riccardo Pucella. Phantom types and subtyping. In IFIP Interna-

tional Conference on Theoretical Computer Science (TCS), pages 448-460, August
2002.

Foster, Jeffrey S., Tachio Terauchi, and Alex Aiken. Flow-sensitive type qualifiers. In

ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI), Berlin, Germany, pages 1-12, June 2002.

Frey, Alexandre. Satisfying subtype inequalities in polynomial space. In International

Symposium on Static Analysis (SAS) , Paris, France, volume 1302 of Lecture Notes
in Computer Science, pages 265-277. Springer-Verlag, September 1997.

Fuh, You-Chin and Prateek Mishra. Type inference with subtypes. In European Sym-

posium on Programming (ESOP), Nancy, France, volume 300 of Lecture Notes in
Computer Science, pages 94-114. Springer-Verlag, March 1988.

Furuse, Jun P. and Jacques Garrigue. A label-selective lambda-calculus with optional

arguments and its compilation method. RIMS Preprint 1041, Kyoto University,

October 1995.

Garcia, Ronald, Jaakko Jarvi, Andrew Lumsdaine, Jeremy Siek, and Jeremia h Will-

cock. A comparative study of language support for generic programming. In ACM
SIGPLAN Conference on Object Oriented Programming: Systems, Languages, and
Applications (OOPSLA), Anaheim, California, pages 115-134, October 2003.

Garrigue, Jacques. Programming with polymorphic variants. In ACM SIGPLAN Work-

shop on ML, informal proceedings, September 1998.

Garrigue, Jacques. Code reuse through polymorphic variants. In Workshop on Foun-

dations of Software Engineering (FOSE), November 2000.

Garrigue, Jacques. Simple type inference for structural polymorphism. In Interna-

tional Workshop on Foundations of Object-Oriented Languages (FOOL), informal
proceedings, January 2002.

Garrigue, Jacques. Relaxing the value restriction. In International Symposium on

Functional and Logic Programming (FLOPS), Nara, Japan, volume 2998 of Lecture

Notes in Computer Science, pages 196-213. Springer-Verlag, April 2004.

Garrigue, Jacques and Hassan Ai"t-Kaci. The typed polymorphic label-selective

lambda-calculus. In ACM SIGPLAN-SIGACT Symposium on Principles of Program-
ming Languages (POPL), Portland, Oregon, pages 35-47, 1994.

544 References

Garrigue, Jacques and Didier Re'my. Extending ML with semi-explicit higher-order

polymorphism. Information and Computation, 155(1):134-169, 1999.

Gaster, Benedict R. Records, variants and qualified types. PhD thesis, University of

Nottingham, Nottingham, England, July 1998.

Gaster, Benedict R. and Mark P. Jones. A polymorphic type system for extensible

records and variants. Technical Report NOTTCS-TR-96-3, Department of Computer
Science, University of Nottingham, November 1996.

Gay, David and Alexander Aiken. Language support for regions. In ACM SIGPLAN

Conference on Programming Language Design and Implementation (PLDI), Snow-
bird, Utah, pages 70-80, June 2001.

Ghelli, Giorgio and Benjamin Pierce. Bounded existentials and minimal typing,

1992. Circulated in manuscript form. Full version in Theoretical Computer Science,
193(1-2):75-96, February 1998.

Gifford, David K. and John M. Lucassen. Integrating functional and imperative pro-

gramming. In ACM Symposium on Lisp and Functional Programming (LFP), Cam-
bridge, Massachusetts, pages 28-38, August 1986.

Girard, Jean-Yves. Interpre'tation fonctionnelle et e'limination des coupures de l'arith-

me'tique d'ordre supe'rieur. The`se d'e'tat, University of Paris VII, 1972. Summary
in J. E. Fenstad, editor, Scandinavian Logic Symposium, pp. 63-92, North-Holland,
1971.

Girard, Jean-Yves. Linear logic. Theoretical Computer Science, 50:1-102, 1987.
Girard, Jean-Yves. Light linear logic. Information and Computation, 143:175-204,

1998.

Girard, Jean-Yves, Yves Lafont, and Paul Taylor. Proofs and Types, volume 7 of Cam-

bridge Tracts in Theoretical Computer Science. Cambridge University Press, 1989.

Glew, Neal. Type dispatch for named hierarchical types. In ACM SIGPLAN Interna-

tional Conference on Functional Programming (ICFP), Paris, France, pages 172-182,
1999.

GNU. GNU C library, version 2.2.5, 2001. Available from http://www.gnu.org/

manual/glibc-2.2.5/html_mono/libc.html.

Goguen, Healfdene. A Typed Operational Semantics for Type Theory. PhD thesis,

LFCS, University of Edinburgh, Edinburgh, Scotland, 1994. Report ESC-LFCS-94-
304.

Gordon, Andrew D. Bisimilarity as a theory of functional programming. In Workshop

on the Mathematical Foundations of Programming Semantics (MFPS), New Orleans,
Louisiana, volume 1 of Electronic Notes in Theoretical Computer Science. Elsevier,
April 1995.

Gordon, Andrew D. Operational equivalences for untyped and polymorphic object

calculi. In A. D. Gordon and A. M. Pitts, editors, Higher-Order Operational Tech-
niques in Semantics, Publications of the Newton Institute, pages 9-54. Cambridge
University Press, 1998.

References 545
Gordon, Andrew D. and Alan Jeffrey. Authenticity by typing for security protocols. In

IEEE Computer Security Foundations Workshop (CSFW), Cape Breton, Nova Scotia,

pages 145-159, 2001a.

Gordon, Andrew D. and Alan Jeffrey. Typing correspondence assertions for commu-

niation protocols. In Workshop on the Mathematical Foundations of Programming
Semantics (MFPS), Aarhus, Denmark, volume 45 of Electronic Notes in Theoretical
Computer Science, pages 379-409. Elsevier, May 2001b.

Gordon, Andrew D. and Alan Jeffrey. Types and effects for asymmetric cryptographic

protocols. In IEE Computer Security Foundations Workshop (CSFW) , Cape Breton,
Nova Scotia, pages 77-91, 2002.

Gordon, Andrew D. and Don Syme. Typing a multi-language intermediate code.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), London, England, pages 248-260, January 2001.

Gordon, Michael J., Robin Milner, and Christopher P. Wadsworth. Edinburgh LCF,

volume 78 of Lecture Notes in Computer Science. Springer-Verlag, 1979.

Gough, John. Compiling for the .NET Common Language Runtime. .NET series. Pren-

tice Hall, 2002.

Grossman, Dan, Greg Morrisett, Trevor Jim, Michael Hicks, Yanling Wang, and James

Cheney. Region-based memory management in Cyclone. In ACM SIGPLAN Con-
ference on Programming Language Design and Implementation (PLDI), Berlin, Ger-
many, pages 282-293, 2002.

Gustavsson, Jo"rgen and Josef Svenningsson. Constraint abstractions. In Symposium

on Programs as Data Objects (PADO), Aarhus, Denmark, volume 2053 of Lecture
Notes in Computer Science, pages 63-83. Springer-Verlag, May 2001.

Hallenberg, Niels, Martin Elsman, and Mads Tofte. Combining region inference and

garbage collection. In ACM SIGPLAN Conference on Programming Language De-
sign and Implementation (PLDI), Berlin, Germany, pages 141-152, June 2002.

Hallgren, Thomas and Aarne Ranta. An extensible proof text editor (abstract). In

International Conference on Logic for Programming and Automated Reasoning
(LPAR), Reunion Island, volume 1955 of Lecture Notes in Computer Science, pages
70-84. Springer-Verlag, 2000.

Hamid, Nadeem, Zhong Shao, Valery Trifonov, Stefan Monnier, and Zhaozhong Ni.

A syntactic approach to foundational proof-carrying code. In IEEE Symposium on
Logic in Computer Science (LICS), pages 89-100, July 2002.

Hanson, David R. Fast allocation and deallocation of memory based on object life-

times. Software--Practice and Experience, 20(1):5-12, 1990.

Hardin, The're`se, Luc Maranget, and Bruno Pagano. Functional runtimes within the

lambda-sigma calculus. Journal of Functional Programming, 8(2):131-172, March
1998.

Harper, Robert, Furio Honsell, and Gordon Plotkin. A framework for defining logics.

Journal of the ACM, 40(1):143-184, 1993. Summary in IEEE Symposium on Logic in
Computer Science (LICS), Ithaca, New York, 1987.

546 References

Harper, Robert and Mark Lillibridge. A type-theoretic approach to higher-order mod-

ules with sharing. In ACM SIGPLAN-SIGACT Symposium on Principles of Program-
ming Languages (POPL), Portland, Oregon, pages 123-137, January 1994.

Harper, Robert and John C. Mitchell. On the type structure of Standard ML. ACM

Transactions on Programming Languages and Systems, 15(2):211-252, April 1993.
An earlier version appeared in ACM Symposium on Principles of Programming Lan-
guages (POPL), San Diego, California, under the title "The Essence of ML" (Mitchell
and Harper), 1988.

Harper, Robert, John C. Mitchell, and Eugenio Moggi. Higher-order modules and the

phase distinction. In ACM Symposium on Principles of Programming Languages
(POPL), San Francisco, California, pages 341-354, January 1990.

Harper, Robert and Frank Pfenning. On equivalence and canonical forms in the LF

type theory. ACM Transactions on Computational Logic, 2004. To appear. An ear-
lier version is available as Technical Report CMU-CS-00-148, School of Computer
Science, Carnegie Mellon University.

Harper, Robert and Robert Pollack. Type checking with universes. Theoretical Com-

puter Science, 89:107-136, 1991.

Harper, Robert and Christopher Stone. A type-theoretic interpretation of Standard

ML. In G. Plotkin, C. Stirling, and M. Tofte, editors, Proof, Language and Interaction:
Essays in Honour of Robin Milner. MIT Press, 2000.

Heintze, Nevin. Set based analysis of ML programs. In ACM Symposium on Lisp and

Functional Programming (LFP), Orlando, Florida, pages 306-317, June 1994.

Heintze, Nevin. Control-flow analysis and type systems. In International Sympo-

sium on Static Analysis (SAS) , Glasgow, Scotland, volume 983 of Lecture Notes in
Computer Science, pages 189-206. Springer-Verlag, 1995.

Helsen, Simon and Peter Thiemann. Syntactic type soundness for the region calculus.

In Workshop on Higher Order Operational Techniques in Semantics (HOOTS), Mon-
tre'al, Que'bec, volume 41(3) of Electronic Notes in Theoretical Computer Science,
pages 1-20. Elsevier, September 2000.

Helsen, Simon and Peter Thiemann. Polymorphic specialization for ML. ACM Trans-

actions on Programming Languages and Systems, 26(4):652-701, July 2004.

Henglein, Fritz. Polymorphic Type Inference and Semi-Unification. PhD thesis, Rutgers

University, April 1989. Available as NYU Technical Report 443, May 1989, from
New York University, Courant Institute of Mathematical Sciences, Department of
Computer Science, 251 Mercer St., New York, NY 10012, USA.

Henglein, Fritz. Type inference with polymorphic recursion. ACM Transactions on

Programming Languages and Systems, 15(2):253-289, 1993.

Henglein, Fritz, Henning Makholm, and Henning Niss. A direct approach to control-

flow sensitive region-based memory management. In ACM SIGPLAN International
Conference on Principles and Practice of Declarative Programming (PPDP), Firenze,
Italy, pages 175-186, September 2001.

References 547
Henglein, Fritz and Christian Mossin. Polymorphic binding-time analysis. In European

Symposium on Programming (ESOP), Edinburgh, Scotland, volume 788 of Lecture

Notes in Computer Science, pages 287-301. Springer-Verlag, April 1994.

Hirschowitz, Tom and Xavier Leroy. Mixin modules in a call-by-value setting. In

European Symposium on Programming (ESOP), Grenoble, France, pages 6-20, April
2002.

Hoare, C. A. R. Proof of correctness of data representation. Acta Informatica, 1:

271-281, 1972.

Hofmann, Martin. A mixed modal/linear lambda calculus with applications to

bellantoni-cook safe recursion. In International Workshop on Computer Science
Logic (CSL), Aarhus, Denmark, pages 275-294, August 1997a.

Hofmann, Martin. Syntax and semantics of dependent types. In A. M. Pitts and

P. Dybjer, editors, Semantics and Logic of Computation, pages 79-130. Cambridge
University Press, 1997b.

Hofmann, Martin. Linear types and non-size-increasing polynomial time computa-

tion. In IEEE Symposium on Logic in Computer Science (LICS), Trento, Italy, pages
464-473, June 1999.

Hofmann, Martin. Safe recursion with higher types and BCK-algebra. Annals of Pure

and Applied Logic, 104(1-3):113-166, 2000.

Honsell, Furio, Ian A. Mason, Scott F. Smith, and Carolyn L. Talcott. A variable typed

logic of effects. Information and Computation, 119(1):55-90, 1995.

Howard, William A. Hereditarily majorizable functionals of finite type. In A. S. Troel-

stra, editor, Metamathematical Investigation of Intuitionistic Arithmetic and Analy-
sis, volume 344 of Lecture Notes in Mathematics, pages 454-461. Springer-Verlag,
Berlin, 1973.

Howard, William A. The formulas-as-types notion of construction. In J. P. Seldin

and J. R. Hindley, editors, To H. B. Curry: Essays on Combinatory Logic, Lambda
Calculus, and Formalism, pages 479-490. Academic Press, 1980. Reprint of 1969
article.

Howe, Douglas J. Proving congruence of bisimulation in functional programming

languages. Information and Computation, 124(2):103-112, 1996.

Huet, Ge'rard. Re'solution d'equations dans les langages d'ordre 1,2, ...,!. The`se de

Doctorat d'Etat, Universite' de Paris 7, Paris, France, 1976.

Igarashi, Atsushi and Naoki Kobayashi. A generic type system for the Pi-calculus.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), London, England, pages 128-141, January 2001.

Igarashi, Atsushi and Naoki Kobayashi. Resource usage analysis. In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), Portland,
Oregon, pages 331-342, January 2002.

548 References

Igarashi, Atsushi and Benjamin C. Pierce. Foundations for virtual types. In European

Conference on Object-Oriented Programming (ECOOP), Lisbon, Portugal, June 1999.
Also in informal proceedings of the Workshop on Foundations of Object-Oriented
Languages (FOOL), January 1999. Full version in Information and Computation,
175(1): 34-49, May 2002.

Ishtiaq, Samin and Peter O'Hearn. BI as an assertion language for mutable data

structures. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL), London, England, pages 14-26, January 2001.

Jacobs, Bart. Categorical Logic and Type Theory. Studies in Logic and the Foundations

of Mathematics 141. Elsevier, 1999.

Jategaonkar, Lalita A. ML with extended pattern matching and subtypes. Master's

thesis, Massachusetts Institute of Technology, August 1989.

Jategaonkar, Lalita A. and John C. Mitchell. ML with extended pattern matching and

subtypes (preliminary version). In ACM Symposium on Lisp and Functional Pro-
gramming (LFP), Snowbird, Utah, pages 198-211, Snowbird, Utah, July 1988.

Jensen, Kathleen and Niklaus Wirth. Pascal User Manual and Report. Springer-Verlag,

second edition, 1975.

Jim, Trevor. What are principal typings and what are they good for? In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), St. Petersburg
Beach, Florida, pages 42-53, 1996.

Jim, Trevor, J. Greg Morrisett, Dan Grossman, Michael W. Hicks, James Cheney, and

Yanling Wang. Cyclone: A safe dialect of C. In General Track: USENIX Annual
Technical Conference, pages 275-288, June 2002.

Jim, Trevor and Jens Palsberg. Type inference in systems of recursive types with sub-

typing, 1999. Manuscript, available from http://www.cs.purdue.edu/homes/
palsberg/draft/jim-palsberg99.pdf.

Johann, Patricia. A generalization of short-cut fusion and its correctness proof.

Higher-Order and Symbolic Computation, 15(4):273-300, 2002.

Jones, Mark P. Qualified Types: Theory and Practice. Cambridge University Press,

1994.

Jones, Mark P. Using parameterized signatures to express modular structure. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL),
St. Petersburg Beach, Florida, January 21-24, 1996.

Jones, Mark P. Typing Haskell in Haskell. In ACM Haskell Workshop, informal pro-

ceedings, October 1999.

Jones, Mark P. and John C. Peterson. The Hugs 98 user manual, 1999. Available from

http://www.haskell.org/hugs/.

Jones, Mark P. and Simon Peyton Jones. Lightweight extensible records for Haskell.

In ACM Haskell Workshop, informal proceedings, October 1999.

References 549
Jouannaud, Jean-Pierre and Claude Kirchner. Solving equations in abstract algebras:

a rule-based survey of unification. In J.-L. Lassez and G. Plotkin, editors, Computa-
tional Logic: Essays in honor of Alan Robinson, pages 257-321. MIT Press, 1991.

Jouvelot, Pierre and David Gifford. Algebraic reconstruction of types and effects.

In ACM Symposium on Principles of Programming Languages (POPL), Orlando,
Florida, pages 303-310, January 1991.

Jouvelot, Pierre and David K. Gifford. Reasoning about continuations with control

effects. In ACM SIGPLAN Conference on Programming Language Design and Im-
plementation (PLDI), Portland, Oregon, pages 218-226, June 1989.

Jung, Achim and Allen Stoughton. Studying the fully abstract model of PCF within its

continuous function model. In International Conference on Typed Lambda Calculi
and Applications (TLCA), Utrecht, The Netherlands, volume 664 of Lecture Notes in
Computer Science, pages 230-244. Springer-Verlag, March 1993.

Jutting, L.S. van Benthem, James McKinna, and Robert Pollack. Checking algorithms

for Pure Type Systems. In International Workshop on Types for Proofs and Pro-
grams (TYPES), Nijmegen, The Netherlands, May 1993, volume 806 of Lecture Notes
in Computer Science, pages 19-61. Springer-Verlag, 1994.

Kfoury, Assaf J., Jerzy Tiuryn, and Pawel Urzyczyn. ML typability is dexptime-

complete. In Colloquium on Trees in Algebra and Programming (CAAP), Copen-
hagen, Denmark, volume 431 of Lecture Notes in Computer Science, pages 206-
220. Springer-Verlag, May 1990.

Kfoury, Assaf J., Jerzy Tiuryn, and Pawel Urzyczyn. The undecidability of the semi-

unification problem. Information and Computation, 102(1):83-101, January 1993.

Kfoury, Assaf J., Jerzy Tiuryn, and Pawel Urzyczyn. An analysis of ML typability.

Journal of the ACM, 41(2):368-398, March 1994.

Kirchner, Claude and Francis Klay. Syntactic theories and unification. In IEEE Sympo-

sium on Logic in Computer Science (LICS), Philadelphia, Pennsylvania, pages 270-
277, June 1990.

Knight, Kevin. Unification: a multidisciplinary survey. ACM Computing Surveys, 21

(1):93-124, March 1989.

Kobayashi, Naoki. Quasi-linear types. In ACM SIGPLAN-SIGACT Symposium on Princi-

ples of Programming Languages (POPL), San Antonio, Texas, pages 29-42, January
1999.

Kozen, Dexter, Jens Palsberg, and Michael I. Schwartzbach. Efficient recursive sub-

typing. Mathematical Structures in Computer Science, 5(1):113-125, 1995.

Kuncak, Viktor and Martin Rinard. Structural subtyping of non-recursive types is

decidable. In IEEE Symposium on Logic in Computer Science (LICS), Ottawa, Canada,
pages 96-107, June 2003.

Lafont, Yves. The linear abstract machine. Theoretical Computer Science, 59:157-180,

1988.

550 References

Lambek, Joachim. The mathematics of sentence structure. American Mathematical

Monthly, 65:154-170, 1958.

Lampson, Butler and Rod Burstall. Pebble, a kernel language for modules and abstract

data types. Information and Computation, 76:278-346, February/March 1988.

Lassen, So/ren Bo/gh. Relational Reasoning about Functions and Nondeterminism. PhD

thesis, Department of Computer Science, University of Aarhus, Aarhus, Denmark,
1998.

Lassez, Jean-Louis, Michael J. Maher, and Kim G. Marriott. Unification revisited. In

J. Minker, editor, Foundations of Deductive Databases and Logic Programming,
pages 587-625. Morgan Kaufmann, 1988.

Lee, Oukseh and Kwangkeun Yi. Proofs about a folklore let-polymorphic type infer-

ence algorithm. ACM Transactions on Programming Languages and Systems, 20
(4):707-723, July 1998.

Leivant, Daniel. Stratified functional programs and computational complexity.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), Charleston, South Carolina, pages 325-333, January 1993.

Leroy, Xavier. Polymorphic typing of an algorithmic language. Research Report 1778,

INRIA, October 1992.

Leroy, Xavier. Manifest types, modules and separate compilation. In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), Portland,
Oregon, pages 109-122, January 1994.

Leroy, Xavier. Applicative functors and fully transparent higher-order modules.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), San Francisco, California, pages 142-153, January 1995.

Leroy, Xavier. A syntactic theory of type generativity and sharing. Journal of Func-

tional Programming, 6(5):667-698, September 1996.

Leroy, Xavier. The Objective Caml system: Documentation and user's manual, 2000.

With Damien Doligez, Jacques Garrigue, Didier Re'my, and Je'ro^me Vouillon. Avail-
able from http://caml.inria.fr.

Leroy, Xavier and Franc,ois Pessaux. Type-based analysis of uncaught exceptions.

ACM Transactions on Programming Languages and Systems, 22(2):340-377, March
2000. Summary in ACM SIGPLAN-SIGACT Symposium on Principles of Program-
ming Languages (POPL), San Antonio, Texas, 1999.

Lillibridge, Mark. Translucent Sums: A Foundation for Higher-Order Module Systems.

PhD thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh,
Pennsylvania, May 1997.

Lindholm, Tim and Frank Yellin. The Java Virtual Machine Specification. The Java

Series. Addison-Wesley, Reading, MA, January 1997.

Liskov, Barbara. A history of CLU. ACM SIGPLAN Notices, 28(3):133-147, 1993.

References 551
Loader, Ralph. Finitary PCF is not decidable. Theoretical Computer Science, 266(1-2):

341-364, September 2001.

Lucassen, John M. Types and Effects towards the Integration of Functional and Impera-

tive Programming. PhD thesis, Massachusetts Institute of Technology, Cambridge,
Massachusetts, August 1987. Technical Report MIT-LCS-TR-408.

Lucassen, John M. and David K. Gifford. Polymorphic effect systems. In ACM Sympo-

sium on Principles of Programming Languages (POPL), San Diego, California, pages
47-57, 1988.

Luo, Zhaohui. Computation and Reasoning: A Type Theory for Computer Science.

Number 11 in International Series of Monographs on Computer Science. Oxford
University Press, 1994.

Luo, Zhaohui and Robert Pollack. The LEGO proof development system: A user's

manual. Technical Report ECS-LFCS-92-211, University of Edinburgh, May 1992.

MacQueen, David. Modules for Standard ML. In ACM Symposium on Lisp and Func-

tional Programming (LFP), Austin, Texas, pages 198-207, 1984.

MacQueen, David. Using dependent types to express modular structure. In ACM

Symposium on Principles of Programming Languages (POPL), St. Petersburg Beach,

Florida, pages 277-286, January 1986.

MacQueen, David B. and Mads Tofte. A semantics for higher-order functors. In Eu-

ropean Symposium on Programming (ESOP), Edinburgh, Scotland, volume 788 of
Lecture Notes in Computer Science, pages 409-423. Springer-Verlag, April 1994.

Magnusson, Lena and Bengt Nordstro"m. The ALF proof editor and its proof engine. In

International Workshop on Types for Proofs and Programs (TYPES), Nijmegen, The
Netherlands, May, 1993, volume 806 of Lecture Notes in Computer Science, pages
213-237. Springer-Verlag, 1994.

Mairson, Harry G., Paris C. Kanellakis, and John C. Mitchell. Unification and ML type

reconstruction. In J.-L. Lassez and G. Plotkin, editors, Computational Logic: Essays
in Honor of Alan Robinson, pages 444-478. MIT Press, 1991.

Makholm, Henning. Region-based memory management in Prolog. Master's thesis,

University of Copenhagen, Department of Computer Science, March 2000. Techni-
cal Report DIKU-TR-00/09.

Makholm, Henning. A Language-Independend Framework for Region Inference. PhD

thesis, University of Copenhagen, Department of Computer Science, Copenhagen,
Denmark, 2003.

Makholm, Henning and Kostis Sagonas. On enabling the WAM with region support.

In International Conference on Logic Programming (ICLP), volume 2401 of Lecture
Notes in Computer Science, pages 163-178. Springer-Verlag, July 2002.

Martelli, Alberto and Ugo Montanari. Unification in linear time and space: A struc-

tured presentation. Internal Report B76-16, Istituto di Elaborazione delle Infor-
mazione, Consiglio Nazionale delle Ricerche, Pisa, July 1976.

552 References

Martelli, Alberto and Ugo Montanari. An efficient unification algorithm. ACM Trans-

actions on Programming Languages and Systems, 4(2):258-282, 1982.

Martin-Lo"f, Per. Intuitionistic Type Theory. Bibliopolis, 1984.
Mason, Ian A., Scott F. Smith, and Carolyn L. Talcott. From operational semantics to

domain theory. Information and Computation, 128(1):26-47, 1996.

Mason, Ian A. and Carolyn L. Talcott. Equivalence in functional languages with effects.

Journal of Functional Programming, 1:287-327, 1991.

McAllester, David. On the complexity analysis of static analyses. Journal of the ACM,

49(4):512-537, July 2002.

McAllester, David. A logical algorithm for ML type inference. In International Con-

ference on Rewriting Techniques and Applications (RTA), Valencia, Spain, volume
2706 of Lecture Notes in Computer Science, pages 436-451. Springer-Verlag, June
2003.

McBride, Conor. Dependently Typed Functional Programs and their Proofs. PhD thesis,

LFCS, University of Edinburgh, Edinburgh, Scotland, 2000.

McBride, Conor and James McKinna. The view from the left. Journal of Functional

Programming, 14(1):69-111, 2004.

McKinna, James and Robert Pollack. Pure Type Sytems formalized. In International

Conference on Typed Lambda Calculi and Applications (TLCA), Utrecht, The Nether-
lands, volume 664 of Lecture Notes in Computer Science, pages 289-305. Springer-
Verlag, March 1993.

Melski, David and Thomas Reps. Interconvertibility of a class of set constraints

and context-free language reachability. Theoretical Computer Science, 248(1-2),
November 2000.

Milner, Robin. A theory of type polymorphism in programming. Journal of Computer

and System Sciences, 17:348-375, August 1978.

Milner, Robin, Mads Tofte, and Robert Harper. The Definition of Standard ML. MIT

Press, 1990.

Milner, Robin, Mads Tofte, Robert Harper, and David MacQueen. The Definition of

Standard ML, Revised edition. MIT Press, 1997.

Minamide, Yasuhiko. A functional representation of data structures with a hole.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), San Diego, California, pages 75-84, January 1998.

Minamide, Yasuhiko, Greg Morrisett, and Robert Harper. Typed closure conversion.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), St. Petersburg Beach, Florida, pages 271-283, January 1996.

Miquel, Alexandre. Le calcul des constructions implicite: syntaxe et se'mantique. PhD

thesis, University Paris 7, Paris, France, 2001.

Mitchell, John C. Coercion and type inference. In ACM Symposium on Principles

of Programming Languages (POPL), Salt Lake City, Utah, pages 175-185, January
1984.

References 553
Mitchell, John C. Representation independence and data abstraction. In ACM Sympo-

sium on Principles of Programming Languages (POPL), St. Petersburg Beach, Florida,

pages 263-276, January 1986.

Mitchell, John C. On the equivalence of data representations. In V. Lifschitz, editor,

Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of

John McCarthy, pages 305-330. Academic Press, 1991a.

Mitchell, John C. Type inference with simple subtypes. Journal of Functional Pro-

gramming, 1(3):245-286, July 1991b.

Mitchell, John C. Foundations for Programming Languages. MIT Press, 1996.
Mitchell, John C. and Gordon D. Plotkin. Abstract types have existential types. ACM

Transactions on Programming Languages and Systems, 10(3):470-502, 1988. Sum-
mary in ACM Symposium on Principles of Programming Languages (POPL), New
Orleans, Louisiana, 1985.

Moggi, Eugenio. Computational lambda-calculus and monads. In IEEE Symposium

on Logic in Computer Science (LICS), Asilomar, California, pages 14-23, June 1989.
Full version, titled Notions of Computation and Monads, in Information and Com-
putation, 93(1), pp. 55-92, 1991.

Moh, Shaw-Kwei. The deduction theorems and two new logical systems. Methodos, 2:

56-75, 1950.

Mohring, Christine. Algorithm development in the calculus of constructions. In IEEE

Symposium on Logic in Computer Science (LICS), Cambridge, Massachusetts, pages
84-91, June 1986.

Monnier, Stefan, Bratin Saha, and Zhong Shao. Principled scavenging. In ACM SIG-

PLAN Conference on Programming Language Design and Implementation (PLDI),
Snowbird, Utah, pages 81-91, June 2001.

Morrisett, Greg, Karl Crary, Neal Glew, and David Walker. Stack-based typed assembly

language. Journal of Functional Programming, 12(1):43-88, January 2002.

Morrisett, Greg, David Walker, Karl Crary, and Neal Glew. From System-F to typed

assembly language. ACM Transactions on Programming Languages and Systems,
21(3):527-568, May 1999.

Mossin, Christian. Flow Analysis of Typed Higher-Order Programs. PhD thesis, Uni-

versity of Copenhagen, Department of Computer Science, Copenhagen, Denmark,
1997. Also available as Technical Report DIKU-TR-97/1.

Mu"ller, Martin. A constraint-based recast of ML-polymorphism. In International Work-

shop on Unification, June 1994. Also available as Technical Report 94-R-243, CRIN,
Nancy, France.

Mu"ller, Martin. Notes on HM(X), August 1998. Available from http://www.ps.

uni-sb.de/~mmueller/papers/HMX.ps.gz.

Mu"ller, Martin, Joachim Niehren, and Ralf Treinen. The first-order theory of ordering

constraints over feature trees. Discrete Mathematics and Theoretical Computer
Science, 4(2):193-234, 2001.

554 References

Mu"ller, Martin and Susumu Nishimura. Type inference for first-class messages with

feature constraints. In Asian Computer Science Conference (ASIAN), Manila, The
Philippines, volume 1538 of Lecture Notes in Computer Science, pages 169-187.
Springer-Verlag, December 1998.

Mycroft, Alan. Polymorphic type schemes and recursive definitions. In International

Symposium on Programming, Toulouse, France, volume 167 of Lecture Notes in
Computer Science, pages 217-228, Toulouse, France, April 1984. Springer-Verlag.

Necula, George C. Proof-carrying code. In ACM SIGPLAN-SIGACT Symposium on Prin-

ciples of Programming Languages (POPL), Paris, France, pages 106-119, January
1997.

Necula, George C. Compiling with Proofs. PhD thesis, Carnegie Mellon University,

Pittsburgh, Pennsylvania, September 1998. Technical report CMU-CS-98-154.

Necula, George C. Translation validation for an optimizing compiler. In ACM SIG-

PLAN Conference on Programming Language Design and Implementation (PLDI),
Vancouver, British Columbia, Canada, pages 83-94, June 2000.

Necula, George C. and Peter Lee. Safe kernel extensions without run-time checking.

In USENIX Symposium on Operating Systems Design and Implementation (OSDI),
Seattle, Washington, pages 229-243, October 1996.

Necula, George C. and Peter Lee. The design and implementation of a certifying

compiler. In ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI), Montre'al, Que'bec, pages 333-344, June 1998a.

Necula, George C. and Peter Lee. Efficient representation and validation of logical

proofs. In IEEE Symposium on Logic in Computer Science (LICS), Indianapolis, Indi-
ana, pages 93-104, June 1998b.

Niehren, Joachim, Martin Mu"ller, and Andreas Podelski. Inclusion constraints over

non-empty sets of trees. In Theory and Practice of Software Development (TAP-
SOFT), Lille, France, volume 1214 of Lecture Notes in Computer Science, pages
217-231. Springer-Verlag, April 1997.

Niehren, Joachim and Tim Priesnitz. Non-structural subtype entailment in automata

theory. Information and Computation, 186(2):319-354, November 2003.

Nielson, Flemming and Hanne Riis Nielson. From CML to its process algebra. Theo-

retical Computer Science, 155:179-219, 1996.

Nielson, Flemming, Hanne Riis Nielson, and Christopher L. Hankin. Principles of Pro-

gram Analysis. Springer-Verlag, 1999.

Nielson, Flemming, Hanne Riis Nielson, and Helmut Seidl. A succinct solver for ALFP.

Nordic Journal of Computing, 9(4):335-372, 2002.

Nielson, Hanne Riis and Flemming Nielson. Higher-order concurrent programs with

finite communication topology. In ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages (POPL), Portland, Oregon, pages 84-97, January 1994.

References 555
Nishimura, Susumu. Static typing for dynamic messages. In ACM SIGPLAN-SIGACT

Symposium on Principles of Programming Languages (POPL), San Diego, California,
pages 266-278, 1998.

Niss, Henning. Regions are Imperative: Unscoped Regions and Control-Flow Sensi-

tive Memory Management. PhD thesis, University of Copenhagen, Department of
Computer Science, Copenhagen, Denmark, 2002.

No"cker, Erick and Sjaak Smetsers. Partially strict non-recursive data types. Journal

of Functional Programming, 3(2):191-215, 1993.

No"cker, Erick G. M. H., Sjaak E. W. Smetsers, Marko C. J. D. van Eekelen, and Mari-

nus J. Plasmeijer. Concurrent clean. In Symposium on Parallel Architectures and
Languages Europe, Volume I: Parallel Architectures and Algorithms (PARLE), Eind-
hoven, The Netherlands, volume 505 of Lecture Notes in Computer Science, pages
202-219. Springer-Verlag, June 1991.

Odersky, Martin. Observers for linear types. In European Symposium on Program-

ming (ESOP), Rennes, France, volume 582 of Lecture Notes in Computer Science,
pages 390-407. Springer-Verlag, February 1992.

Odersky, Martin, Vincent Cremet, Christine Rockl, and Matthias Zenger. A nominal

theory of objects with dependent types. In International Workshop on Foundations
of Object-Oriented Languages (FOOL), informal proceedings, 2003.

Odersky, Martin, Martin Sulzmann, and Martin Wehr. Type inference with constrained

types. Theory and Practice of Object Systems, 5(1):35-55, 1999. Summary in Inter-
national Workshop on Foundations of Object-Oriented Languages (FOOL), informal
proceedings, 1997.

O'Hearn, Peter. On bunched typing. Journal of Functional Programming, 13(4):747-

796, 2003.

O'Hearn, Peter and David Pym. The logic of bunched implications. Bulletin of Symbolic

Logic, 5(2):215-244, 1999.

Ohori, Atsushi. A polymorphic record calculus and its compilation. ACM Transac-

tions on Programming Languages and Systems, 17(6):844-895, November 1995.

Ohori, Atsushi and Peter Buneman. Type inference in a database programming lan-

guage. In ACM Symposium on Lisp and Functional Programming (LFP), Snowbird,
Utah, pages 174-183, July 1988.

Ohori, Atsushi and Peter Buneman. Static type inference for parametric classes. In

Conference on Object Oriented Programming: Systems, Languages, and Applica-
tions (OOPSLA), New Orleans, Louisiana, pages 445-456, October 1989. Also in C.
A. Gunter and J. C. Mitchell, editors, Theoretical Aspects of Object-Oriented Pro-
gramming: Types, Semantics, and Language Design, MIT Press, 1994.

Orlov, Ivan E. The calculus of compatibility of propositions (in Russian). Matematich-

eskii Sbornik, 35:263-286, 1928.

556 References

Owre, Sam, Sreeranga Rajan, John M. Rushby, Natarajan Shankar, and Mandayam K.

Srivas. PVS: Combining specification, proof checking, and model checking. In
International Conference on Computer Aided Verification (CAV), New Brunswick,
New Jersey, volume 1102 of Lecture Notes in Computer Science, pages 411-414.
Springer-Verlag, July 1996.

Palsberg, Jens. Efficient inference of object types. Information and Computation, 123

(2):198-209, 1995.

Palsberg, Jens. Type-based analysis and applications. In ACM SIGPLAN-SIGSOFT

Workshop on Program Analysis for Software Tools and Engineering (PASTE), Snow-
bird, Utah, pages 20-27, June 2001.

Palsberg, Jens and Patrick O'Keefe. A type system equivalent to flow analysis. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL), San
Francisco, California, pages 367-378, 1995.

Palsberg, Jens and Michael Schwartzbach. Type substitution for object-oriented

programming. In ACM SIGPLAN Conference on Object Oriented Programming:
Systems, Languages, and Applications (OOPSLA)/European Conference on Object-
Oriented Programming (ECOOP), Ottawa, Ontario, volume 25(10) of ACM SIGPLAN
Notices, pages 151-160, October 1990.

Palsberg, Jens and Michael I. Schwartzbach. Object-Oriented Type Systems. Wiley,

1994.

Palsberg, Jens, Mitchell Wand, and Patrick M. O'Keefe. Type inference with non-

structural subtyping. Formal Aspects of Computing, 9:49-67, 1997.

Parnas, David. The criteria to be used in decomposing systems into modules. Com-

munications of the ACM, 14(1):221-227, 1972.

Paterson, Michael S. and Mark N. Wegman. Linear unification. Journal of Computer

and System Sciences, 16:158-167, 1978.

Paulin-Mohring, Christine. Extracting F!'s programs from proofs in the calculus

of constructions. In ACM Symposium on Principles of Programming Languages
(POPL), Austin, Texas, pages 89-104, January 1989.

Petersen, Leaf, Perry Cheng, Robert Harper, and Chris Stone. Implementing the TILT

internal language. Technical Report CMU-CS-00-180, Department of Computer Sci-
ence, Carnegie Mellon University, 2000.

Petersen, Leaf, Robert Harper, Karl Crary, and Frank Pfenning. A type theory for

memory allocation and data layout. In ACM SIGPLAN-SIGACT Symposium on Prin-
ciples of Programming Languages (POPL), New Orleans, Louisiana, pages 172-184,
January 2003.

Peyton Jones, Simon. Special issue: Haskell 98 language and libraries. Journal of

Functional Programming, 13, January 2003.

Pfenning, Frank and Rowan Davies. A judgmental reconstruction of modal logic.

Mathematical Structures in Computer Science, 11(4):511-540, 2001.

References 557
Pfenning, Frank and Carsten Schu"rmann. Algorithms for equality and unification

in the presence of notational definitions. In T. Altenkirch, W. Naraschewski,
and B. Reus, editors, International Workshop on Types for Proofs and Programs

(TYPES), Kloster Irsee, Germany, volume 1657 of Lecture Notes in Computer Sci-
ence. Springer-Verlag, 1998.

Pierce, Benjamin C. Types and Programming Languages. MIT Press, 2002.
Pierce, Benjamin C. and David N. Turner. Object-oriented programming without re-

cursive types. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL), Charleston, South Carolina, pages 299-312, January 1993.

Pitts, Andrew M. Relational properties of domains. Information and Computation,

127:66-90, 1996.

Pitts, Andrew M. Existential types: Logical relations and operational equivalence.

In International Colloquium on Automata, Languages and Programming (ICALP),
Aalborg, Denmark, volume 1443 of Lecture Notes in Computer Science, pages 309-
326. Springer-Verlag, 1998.

Pitts, Andrew M. Parametric polymorphism and operational equivalence. Mathemat-

ical Structures in Computer Science, 10:321-359, 2000.

Pitts, Andrew M. Operational semantics and program equivalence. In G. Barthe, P. Dy-

bjer, and J. Saraiva, editors, Applied Semantics, Advanced Lectures, volume 2395 of
Lecture Notes in Computer Science, Tutorial, pages 378-412. Springer-Verlag, 2002.

Pitts, Andrew M. and Ian D. B. Stark. Observable properties of higher order functions

that dynamically create local names, or: What's new? In International Symposium
on Mathematical Foundations of Computer Science, Gda'nsk, Poland, volume 711 of
Lecture Notes in Computer Science, pages 122-141. Springer-Verlag, 1993.

Pitts, Andrew M. and Ian D. B. Stark. Operational reasoning for functions with local

state. In A. D. Gordon and A. M. Pitts, editors, Higher-Order Operational Techniques
in Semantics, Publications of the Newton Institute, pages 227-273. Cambridge Uni-
versity Press, 1998.

Plotkin, Gordon D. Lambda-definability and logical relations. Memorandum SAI-RM-

4, University of Edinburgh, Edinburgh, Scotland, October 1973.

Plotkin, Gordon D. LCF considered as a programming language. Theoretical Computer

Science, 5:223-255, 1977.

Plotkin, Gordon D. Lambda-definability in the full type hierarchy. In J. P. Seldin

and J. R. Hindley, editors, To H. B. Curry: Essays on Combinatory Logic, Lambda
Calculus and Formalism, pages 363-373. Academic Press, 1980.

Plotkin, Gordon D. and Marti'n Abadi. A logic for parametric polymorphism. In In-

ternational Conference on Typed Lambda Calculi and Applications (TLCA), Utrecht,
The Netherlands, volume 664 of Lecture Notes in Computer Science, pages 361-375.
Springer-Verlag, March 1993.

558 References

Polakow, Jeff and Frank Pfenning. Natural deduction for intuitionistic non-

commutative linear logic. In International Conference on Typed Lambda Calculi
and Applications (TLCA), L'Aquila, Italy, volume 1581 of Lecture Notes in Computer
Science, pages 295-309. Springer-Verlag, April 1999.

Poll, Erik. Expansion Postponement for Normalising Pure Type Systems. Journal of

Functional Programming, 8(1):89-96, 1998.

Pollack, Robert. The Theory of LEGO: A Proof Checker for the Extended Calculus of

Constructions. PhD thesis, University of Edinburgh, Edinburgh, Scotland, 1994.

Popkorn, Sally. First Steps in Modal Logic. Cambridge University Press, 1994.
Pottier, Franc,ois. A versatile constraint-based type inference system. Nordic Journal

of Computing, 7(4):312-347, November 2000.

Pottier, Franc,ois. A semi-syntactic soundness proof for HM(X). Research Report

4150, INRIA, March 2001a.

Pottier, Franc,ois. Simplifying subtyping constraints: a theory. Information and Com-

putation, 170(2):153-183, November 2001b.

Pottier, Franc,ois. A constraint-based presentation and generalization of rows. In IEEE

Symposium on Logic in Computer Science (LICS), Ottawa, Canada, pages 331-340,
June 2003.

Pottier, Franc,ois and Vincent Simonet. Information flow inference for ML. ACM Trans-

actions on Programming Languages and Systems, 25(1):117-158, January 2003.

Pottier, Franc,ois, Christian Skalka, and Scott Smith. A systematic approach to static

access control. In European Symposium on Programming (ESOP), Genova, Italy,
volume 2028 of Lecture Notes in Computer Science, pages 30-45. Springer-Verlag,
April 2001.

Pratt, Vaughan and Jerzy Tiuryn. Satisfiability of inequalities in a poset. Fundamenta

Informaticae, 28(1-2):165-182, 1996.

Pugh, William and Grant Weddell. Two-directional record layout for multiple in-

heritance. In ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI), White Plains, New York, pages 85-91, June 1990.

Rajamani, Sriram K. and Jakob Rehof. A behavioral module system for the pi-calculus.

In International Symposium on Static Analysis (SAS) , Paris, France, volume 2126 of
Lecture Notes in Computer Science, pages 375-394. Springer-Verlag, July 2001.

Rajamani, Sriram K. and Jakob Rehof. Conformance checking for models of asyn-

chronous message passing software. In International Conference on Computer
Aided Verification (CAV), Copenhagen, Denmark, pages 166-179, July 2002.

Rehof, Jakob. Minimal typings in atomic subtyping. In ACM SIGPLAN-SIGACT Sym-

posium on Principles of Programming Languages (POPL), Paris, France, pages 278-
291, January 1997.

Rehof, Jakob and Manuel Fa"hndrich. Type-based flow analysis: From polymorphic

subtyping to CFL reachability. In ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages (POPL), London, England, pages 54-66, 2001.

References 559
Reid, Alastair, Matthew Flatt, Leigh Stoller, Jay Lepreau, and Eric Eide. Knit: Com-

ponent composition for systems software. In USENIX Symposium on Operating
Systems Design and Implementation (OSDI), San Diego, California, pages 347-360,
October 2000.

Re'my, Didier. Typechecking records and variants in a natural extension of ML. In

ACM Symposium on Principles of Programming Languages (POPL), Austin, Texas,
pages 242-249, January 1989. Long version in C. A. Gunter and J. C. Mitchell, ed-
itors, Theoretical Aspects of Object-Oriented Programming: Types, Semantics, and
Language Design, MIT Press, 1994.

Re'my, Didier. Alge`bres Touffues. Application au Typage Polymorphe des Objets Enreg-

istrements dans les Langages Fonctionnels. PhD thesis, Universite' Paris VII, 1990.

Re'my, Didier. Extending ML type system with a sorted equational theory. Research

Report 1766, Institut National de Recherche en Informatique et Automatisme, Roc-
quencourt, BP 105, 78 153 Le Chesnay Cedex, France, 1992a.

Re'my, Didier. Projective ML. In ACM Symposium on Lisp and Functional Programming

(LFP), San Francisco, California, pages 66-75, June 1992b.

Re'my, Didier. Syntactic theories and the algebra of record terms. Research Report

1869, Institut National de Recherche en Informatique et Automatisme, Rocquen-
court, BP 105, 78 153 Le Chesnay Cedex, France, 1993.

Re'my, Didier. Programming objects with ML-ART: An extension to ML with abstract

and record types. In International Symposium on Theoretical Aspects of Computer
Software (TACS), Sendai, Japan, volume 789 of Lecture Notes in Computer Science,
pages 321-346. Springer-Verlag, April 1994.

Re'my, Didier and Je'ro^me Vouillon. Objective ML: An effective object-oriented exten-

sion to ML. Theory And Practice of Object Systems, 4(1):27-50, 1998. Summary
in ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), Paris, France, 1997.

van Renesse, Robbert, Kenneth P. Birman, Mark Hayden, Alexey Vaysburd, and David

Karr. Building adaptive systems using Ensemble. Software: Practice and Experience,
28(9):963-979, August 1998.

Restall, Greg. An Introduction to Substructural Logics. Routledge, February 2000.
Restall, Greg. Relevant and substructural logics. In D. Gabbay and J. Woods, editors,

Handbook of the History and Philosophy of Logic, volume 6, Logic and the Modalities
in the Twentieth Century. Elsevier, 2005. To appear.

Reynolds, John C. Automatic computation of data set definitions. In Information

Processing 68, Edinburgh, Scotland, volume 1, pages 456-461. North Holland, 1969.

Reynolds, John C. Towards a theory of type structure. In Colloque sur la Programma-

tion, Paris, France, volume 19 of Lecture Notes in Computer Science, pages 408-425.
Springer-Verlag, 1974.

560 References

Reynolds, John C. Syntactic control of interference. In ACM Symposium on Principles

of Programming Languages (POPL), Tucson, Arizona, pages 39-46, January 1978.
Reprinted in O'Hearn and Tennent, ALGOL-like Languages, vol. 1, pages 273-286,
Birkha"user, 1997.

Reynolds, John C. Types, abstraction, and parametric polymorphism. In R. E. A.

Mason, editor, Information Processing 83, Paris, France, pages 513-523. Elsevier,
1983.

Reynolds, John C. Syntactic control of interference, part 2. Report CMU-CS-89-130,

Carnegie Mellon University, April 1989.

Reynolds, John C. Intuitionistic reasoning about shared mutable data structure. In

J. Davies, A. W. Roscoe, and J. Woodcock, editors, Millennial Perspectives in Com-
puter Science: Proceedings of the 1999 Oxford-Microsoft Symposium in honour of
Sir Tony Hoare. Palgrave Macmillan, 2000.

Robinson, J. Alan. Computational logic: The unification computation. Machine Intel-

ligence, 6:63-72, 1971.

Ross, Douglas T. The AED free storage package. Communications of the ACM, 10(8):

481-492, 1967.

Russo, Claudio V. Types for Modules. PhD thesis, Edinburgh University, Edinburgh,

Scotland, 1998. LFCS Thesis ECS-LFCS-98-389.

Russo, Claudio V. Non-dependent types for standard ML modules. In ACM SIGPLAN

International Conference on Principles and Practice of Declarative Programming
(PPDP), Paris France, pages 80-97, September 1999.

Russo, Claudio V. Recursive structures for Standard ML. In ACM SIGPLAN Interna-

tional Conference on Functional Programming (ICFP), Firenze, Italy, pages 50-61,
September 2001.

Sabry, Amr. What is a purely functional language? Journal of Functional Program-

ming, 8(1):1-22, January 1998.

Saha, Bratin, Nevin Heintze, and Dino Oliva. Subtransitive CFA using types. Technical

Report YALEU/DCS/TR-1166, Yale University, Department of Computer Science,
October 1998.

Sangiorgi, Davide and David. The ss-Calculus: a Theory of Mobile Processes. Cam-

bridge University Press, 2001.

Sannella, Donald, Stefan Sokolowski, and Andrzej Tarlecki. Toward formal develop-

ment of programs from algebraic specifications: Parameterisation revisited. Acta
Informatica, 29(8):689-736, 1992.

Schneider, Fred B. Enforceable security policies. ACM Transactions on Information

and System Security, 3(1):30-50, February 2000.

Schwartz, Jacob T. Optimization of very high level languages (parts I and II). Com-

puter Languages, 1(2-3):161-194, 197-218, 1975.

References 561
Seldin, Jonathan. Curry's anticipation of the types used in programming languages.

In Proceedings of the Annual Meeting of the Canadian Society for History and Phi-
losophy of Mathematics, Toronto, Ontario, pages 143-163, May 2002.

Semmelroth, Miley and Amr Sabry. Monadic encapsulation in ML. In ACM SIGPLAN

International Conference on Functional Programming (ICFP), Paris, France, pages
8-17, September 1999.

Sestoft, Peter. Replacing function parameters by global variables. In ACM Sympo-

sium on Functional Programming Languages and Computer Architecture (FPCA),
London, England, pages 39-53, September 1989. Also available as University of
Copenhagen, Department of Computer Science Technical Report 88-7-2.

Sestoft, Peter. Moscow ML homepage, 2003. http://www.dina.dk/~sestoft/

mosml.html.

Severi, Paula and Erik Poll. Pure type systems with definitions. In International Sym-

posium on Logical Foundations of Computer Science (LFCS), St. Petersburg, Russia,
volume 813 of Lecture Notes in Computer Science, pages 316-328. Springer-Verlag,
September 1994.

Shao, Zhong. An overview of the FLINT/ML compiler. In ACM SIGPLAN Workshop on

Types in Compilation (TIC), Amsterdam, The Netherlands, June 1997.

Shao, Zhong. Typed cross-module compilation. In ACM SIGPLAN International Con-

ference on Functional Programming (ICFP), Baltimore, Maryland, pages 141-152,
September 1998.

Shao, Zhong. Transparent modules with fully syntactic signatures. In ACM SIGPLAN

International Conference on Functional Programming (ICFP), Paris, France, pages
220-232, September 1999.

Shao, Zhong, Christopher League, and Stefan Monnier. Implementing typed inter-

mediate languages. In ACM SIGPLAN International Conference on Functional Pro-
gramming (ICFP), Baltimore, Maryland, pages 313-323, September 1998.

Shivers, Olin. Control flow analysis in Scheme. In ACM SIGPLAN Conference on Pro-

gramming Language Design and Implementation (PLDI), Atlanta, Georgia, pages
164-174, June 1988.

Shivers, Olin. Control-Flow Analysis of Higher-Order Languages or Taming Lambda.

PhD thesis, Carnegie Mellon University, Pittsburgh, Pennsylvania, May 1991.

Simonet, Vincent. Type inference with structural subtyping: a faithful formalization

of an efficient constraint solver. In Asian Symposium on Programming Languages
and Systems (APLAS), Beijing, China, pages 283-302, November 2003.

Skalka, Christian and Franc,ois Pottier. Syntactic type soundness for HM(X). In Work-

shop on Types in Programming (TIP), Dagstuhl, Germany, volume 75 of Electronic
Notes in Theoretical Computer Science. Elsevier, July 2002.

Smith, Frederick, David Walker, and Greg Morrisett. Alias types. In European Sym-

posium on Programming (ESOP), Berlin, Germany, volume 1782 of Lecture Notes in
Computer Science, pages 366-381. Springer-Verlag, April 2000.

562 References

Smith, Geoffrey S. Principal type schemes for functional programs with overloading

and subtyping. Science of Computer Programming, 23(2-3):197-226, December
1994.

Smith, Jan, Bengt Nordstro"m, and Kent Petersson. Programming in Martin-Lo"f's Type

Theory: An Introduction. Oxford University Press, 1990.

Statman, Richard. Logical relations and the typed *-calculus. Information and Con-

trol, 65(2-3):85-97, May-June 1985.

Steele, Guy L., Jr. Common Lisp: The Language. Digital Press, 1990.
Stone, Christopher A. Singleton Kinds and Singleton Types. PhD thesis, Carnegie

Mellon University, Pittsburgh, Pennsylvania, August 2000.

Stone, Christopher A. and Robert Harper. Deciding type equivalence in a language

with singleton kinds. In ACM SIGPLAN-SIGACT Symposium on Principles of Pro-
gramming Languages (POPL), Boston, Massachusetts, pages 214-227, January 2000.

Stone, Christopher A. and Robert Harper. Extensional equivalence and singleton

types. 2005. To appear.

Streicher, Thomas. Semantics of Type Theory. Springer-Verlag, 1991.
Su, Zhendong, Alexander Aiken, Joachim Niehren, Tim Priesnitz, and Ralf Treinen.

The first-order theory of subtyping constraints. In ACM SIGPLAN-SIGACT Sym-
posium on Principles of Programming Languages (POPL), Portland, Oregon, pages
203-216, January 2002.

Sulzmann, Martin. A General Framework for Hindley/Milner Type Systems with Con-

straints. PhD thesis, Yale University, Department of Computer Science, New Haven,
Connecticut, May 2000.

Sulzmann, Martin, Martin Mu"ller, and Christoph Zenger. Hindley/Milner style type

systems in constraint form. Research Report ACRC-99-009, University of South
Australia, School of Computer and Information Science, July 1999.

Sumii, Eijiro and Benjamin C. Pierce. A bisimulation for type abstraction and re-

cursion. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan-
guages (POPL), Long Beach, California, 2005.

Sun. JavaTM 2 Platform Micro Edition (J2METM) Technology for Creating Mobile

Devices--White Paper. Sun Microsystems, May 2000. Available from http://java.
sun.com/products/kvm/wp/KVMwp.pdf.

Tait, William W. Intensional interpretations of functionals of finite type I. Journal of

Symbolic Logic, 32(2):198-212, June 1967.

Talcott, C. Reasoning about functions with effects. In A. D. Gordon and A. M. Pitts,

editors, Higher Order Operational Techniques in Semantics, Publications of the
Newton Institute, pages 347-390. Cambridge University Press, 1998.

Talpin, Jean-Pierre and Pierre Jouvelot. Polymorphic type, region and effect inference.

Journal of Functional Programming, 2(2):245-271, 1992.

References 563
Talpin, Jean-Pierre and Pierre Jouvelot. The type and effect discipline. Information

and Computation, 111:245-296, 1994.

Tarditi, David, Greg Morrisett, Perry Cheng, Christopher Stone, Robert Harper, and

Peter Lee. TIL: A type-directed optimizing compiler for ML. In ACM SIGPLAN Con-
ference on Programming Language Design and Implementation (PLDI), Philadephia,
Pennsylvania, pages 181-192, May 1996.

Tarjan, Robert Endre. Efficiency of a good but not linear set union algorithm. Journal

of the ACM, 22(2):215-225, April 1975.

Tarjan, Robert Endre. Applications of path compression on balanced trees. Journal

of the ACM, 26(4):690-715, October 1979.

Terlouw, J. Een nadere bewijstheoretische analyse van GSTTs. Manuscript, University

of Nijmegen, Netherlands, 1989.

Thorup, Kresten Krab. Genericity in Java with virtual types. In European Confer-

ence on Object-Oriented Programming (ECOOP), Jyva"skyla", Finland, volume 1241
of Lecture Notes in Computer Science, pages 444-471. Springer-Verlag, June 1997.

Tiuryn, Jerzy. Subtype inequalities. In IEEE Symposium on Logic in Computer Science

(LICS), Santa Cruz, California, pages 308-317, June 1992.

Tiuryn, Jerzy and Mitchell Wand. Type reconstruction with recursive types and

atomic subtyping. In Theory and Practice of Software Development (TAPSOFT),
Orsay, France, volume 668 of Lecture Notes in Computer Science, pages 686-701.
Springer-Verlag, April 1993.

Tofte, Mads. Operational Semantics and Polymorphic Type Inference. PhD thesis,

Computer Science Department, Edinburgh University, Edinburgh, Scotland, 1988.

Tofte, Mads and Lars Birkedal. A region inference algorithm. ACM Transactions on

Programming Languages and Systems, 20(4):724-767, 1998.

Tofte, Mads, Lars Birkedal, Martin Elsman, and Niels Hallenberg. Region-based mem-

ory management in perspective. In ACM SIGPLAN International Conference on
Principles and Practice of Declarative Programming (PPDP), Firenze, Italy, pages
175-186, September 2001a.

Tofte, Mads, Lars Birkedal, Martin Elsman, Niels Hallenberg, Tommy Ho/jfeld Olesen,

and Peter Sestoft. Programming with regions in the ML Kit (for version 4). Technical
report, IT University of Copenhagen, October 2001b.

Tofte, Mads and Jean-Pierre Talpin. Implementing the call-by-value lambda-calculus

using a stack of regions. In ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages (POPL), Portland, Oregon, January 1994.

Tofte, Mads and Jean-Pierre Talpin. Region-based memory management. Information

and Computation, 132(2):109-176, February 1997.

Torgersen, Mads. Virtual types are statically safe. In International Workshop on Foun-

dations of Object-Oriented Languages (FOOL), informal proceedings, January 1998.

564 References

Trifonov, Valery and Scott Smith. Subtyping constrained types. In International Sym-

posium on Static Analysis (SAS) , Aachen, Germany, volume 1145 of Lecture Notes
in Computer Science, pages 349-365. Springer-Verlag, September 1996.

Turner, David N. and Philip Wadler. Operational interpretations of linear logic. The-

oretical Computer Science, 227:231-248, 1999. Special issue on linear logic.

Turner, David N., Philip Wadler, and Christian Mossin. Once upon a type. In ACM

Symposium on Functional Programming Languages and Computer Architecture
(FPCA)San Diego, California, pages 1-11, June 1995.

Vouillon, Jerome and Paul-Andre' Mellie`s. Semantic types: A fresh look at the ideal

model for types. In ACM SIGPLAN-SIGACT Symposium on Principles of Program-
ming Languages (POPL), Venice, Italy, pages 52-63, 2004.

Wadler, Philip. Theorems for free! In ACM Symposium on Functional Programming

Languages and Computer Architecture (FPCA), London, England, pages 347-359,
September 1989.

Wadler, Philip. Linear types can change the world. In IFIP TC 2 Working Conference

on Programming Concepts and Methods, Sea of Galilee, Israel, pages 546-566, April
1990.

Wadler, Philip. The marriage of effects and monads. ACM Transactions on Computa-

tional Logic, 4(1):1-32, 2003.

Wahbe, Robert, Steven Lucco, Thomas E. Anderson, and Susan L. Graham. Efficient

software-based fault isolation. In ACM Symposium on Operating Systems Principles
(SOSP), Asheville, North Carolina, pages 203-216, December 1993.

Walker, David, Karl Crary, and Greg Morrisett. Typed memory management via static

capabilities. ACM Transactions on Programming Languages and Systems, 22(4):
701-771, July 2000.

Walker, David and Greg Morrisett. Alias types for recursive data structures. In ACM

SIGPLAN Workshop on Types in Compilation (TIC), Montre'al, Que'bec, September,
2000, volume 2071, pages 177-206. Springer-Verlag, 2001.

Walker, David and Kevin Watkins. On regions and linear types. In ACM SIGPLAN

International Conference on Functional Programming (ICFP), Firenze, Italy, pages
181-192, September 2001.

Wand, Mitchell. Complete type inference for simple objects. In IEEE Symposium on

Logic in Computer Science (LICS), Ithaca, New York, pages 37-44, June 1987a.

Wand, Mitchell. A simple algorithm and proof for type inference. Fundamenta Infor-

maticae, 10:115-122, 1987b.

Wand, Mitchell. Corrigendum: Complete type inference for simple objects. In IEEE

Symposium on Logic in Computer Science (LICS), Edinburgh, Scotland, page 132,
1988.

Wand, Mitchell. Type inference for objects with instance variables and inheritance.

In C. A. Gunter and J. C. Mitchell, editors, Theoretical Aspects of Object-Oriented

References 565

Programming: Types, Semantics, and Language Design, pages 97-120. MIT Press,
1994.

Wang, Daniel C. and Andrew W. Appel. Type-preserving garbage collectors. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL),

London, England, pages 166-178, January 2001.

Wansbrough, Keith and Simon Peyton Jones. Once upon a polymorphic type. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL), San
Antonio, Texas, pages 15-28, January 1999.

Wells, Joe B. Typability and type checking in system F are equivalent and undecidable.

Annals of Pure and Applied Logic, 98(1-3):111-156, 1999.

Wells, Joe B. The essence of principal typings. In International Colloquium on Au-

tomata, Languages and Programming (ICALP), volume 2380 of Lecture Notes in
Computer Science, pages 913-925. Springer-Verlag, 2002.

Werner, Benjamin. Une The'orie des Constructions Inductives. PhD thesis, Universite'

Paris 7, Paris, France, May 1994.

Wirth, Niklaus. Systematic Programming: An Introduction. Prentice Hall, 1973.
Wirth, Niklaus. Programming in Modula-2. Texts and Monographs in Computer Sci-

ence. Springer-Verlag, 1983.

Wright, Andrew K. Simple imperative polymorphism. Lisp and Symbolic Computation,

8(4):343-355, 1995.

Wright, Andrew K. and Robert Cartwright. A practical soft type system for Scheme.

In ACM Symposium on Lisp and Functional Programming (LFP), Orlando, Florida,
pages 250-262, June 1994. Full version available in ACM Transactions on Program-
ming Languages and Systems, 19(1):87-52, January 1997.

Wright, Andrew K. and Matthias Felleisen. A syntactic approach to type soundness.

Information and Computation, 115(1):38-94, November 1994.

Xi, Hongwei. Dependent Types in Practical Programming. PhD thesis, Carnegie Mellon

University, Pittsburgh, Pennsylvania, 1998.

Xi, Hongwei and Robert Harper. A dependently typed assembly language. In ACM SIG-

PLAN International Conference on Functional Programming (ICFP), Firenze, Italy,
pages 169-180, September 2001.

Xi, Hongwei and Frank Pfenning. Dependent types in practical programming. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL), San
Antonio, Texas, pages 214-227, January 1999.

Zenger, Christoph. Indexed types. Theoretical Computer Science, 187:147-165, 1997.
Zwanenburg, Jan. Pure type systems with subtyping. In International Conference

on Typed Lambda Calculi and Applications (TLCA), L'Aquila, Italy, volume 1581 of
Lecture Notes in Computer Science, pages 381-396. Springer-Verlag, April 1999.