

ORSAYNo d'ordre : 1448

UNIVERSIT'E DE PARIS-SUD 11

CENTRE D'ORSAY

TH `ESE

pr'esent'eepour obtenir

L'HABILITATION `A DIRIGER DES RECHERCHESDE L'UNIVERSIT'E PARIS-SUD 11

PAR
Jean-Christophe Filli^atre--*--

SUJET : Deductive Program Verification

soutenue le 2 d'ecembre 2011 devant la commission d'examen

MM. Gilles Barthe rapporteursYves Bertot

K. Rustan M. LeinoMme Christine Paulin examinateurs
MM. Olivier DanvyRoberto di Cosmo

G'erard HuetXavier Leroy

Deductive Program Verification

Jean-Christophe Filli^atre

`a Anne, Marion,'Emilie et Juliette
Contents

Contents vii
Preface ix
1 Deductive Program Verification 11.1 Program Verification is Challenging . . . . . . . . . . . . . . . . . . . 3

1.2 Specifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61.3 Methodologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
1.4 Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2 A Tool for Program Verification: Why3 132.1 History . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

2.2 Overview of Why3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162.3 Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
2.4 Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222.5 Programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

3 Case Studies in Program Verification 373.1 Termination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

3.2 Mathematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 423.3 Data Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.4 Using Why3 as an Intermediate Language . . . . . . . . . . . . . . . 52
4 Perspectives 594.1 Deductive Program Verification . . . . . . . . . . . . . . . . . . . . . 59

4.2 Why3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Bibliography 67
Index 77

vii

Preface
This memoir purposely focuses on my main research activity, that is deductiveprogram verification. Even more specifically, it presents research I'm doing these
days and that I'm considering for the forthcoming years. For completeness, I'mbriefly listing here the works I've made that are ignored in this document.

The Coq Proof Assistant. I did my Ph.D. in the Coq team, where the Coq proofassistant had been developing for more than 10 years already at that time. The
outcome of my Ph.D. was a tactic to perform verification of imperative programs inCoq [36, 37]. I used it to verify several non-trivial programs [45, 39]. Though I then
gradually moved to a mere Coq user, I gained from that period a deep knowledge ofthat tool -- not mentioning my contribution to its programming architecture. For
instance, I could use Coq in 2004 to verify implementations of finite sets as AVLsand red-black trees, in a joint work with Pierre Letouzey [44]. Today, I use Coq on
a daily basis to handle verification conditions that are not discharged by automatedtheorem provers.

Verification of C Programs. It was a wonderful experience to develop the Caduceustool for the verification of C programs with Claude March'e in 2004 [46]. We learned
a lot from that experience. In particular, the specification language we designedfor Caduceus served as a basis for the design of the more ambitious specification
language for Frama-C [50], namely ACSL [8]. Recently, I supervised the Ph.D. ofFran,cois Bobot whose purpose was to introduce concepts of separation logic within
the framework of traditional deductive verification of pointer programs [13].

Verification of Floating-Point Programs. When Sylvie Boldo joined the ProVal teama few years ago, we naturally considered extending our expertise in deductive verification to floating-point programs. She is indeed an expert in the domain. ThoughI'm rather ignorant with respect to floating-point arithmetic, I could provide the
other ingredient to get a nice framework for deductive verification of floating-point programs [19]. Later, another specialist of floating-point arithmetic, Guilix

x CONTENTS
laume Melquiond, joined ProVal and we could go another step forward [20, 18]using his shiny tool Gappa.

Functional Programming. Those who know me can attest that I'm an enthusiastic,even fanatic, OCaml programmer. I have been lucky to be introduced to this
language by Guy Cousineau, Xavier Leroy, and Damien Doligez when I was doingmy undergraduate studies at 'Ecole Normale Sup'erieure. It was difficult not to fell
in love with the creation of such a dream team. Since then, I have experienced somany joyful moments of programming with OCaml that I can't remember all of
them.It explains why, since my Ph.D., I've been continuously publishing papers related
to functional programming. Most of them are describing OCaml libraries [25, 26,28, 3, 43] or neat functional programs [48, 38, 41]. A more profound paper describes
a joint work with Sylvain Conchon and introduces the notion of semi-persistent datastructures [27]. It is somewhat unfortunate that it is not covered in this memoir, as
it is probably the piece of work I'm most proud of.Obviously, OCaml had a great influence on my work related to program verification. In designing the language of Why, I mostly reused syntax, typing, andsemantics of OCaml as much as possible. It appeared to be a successful inspiration.
Concepts such as polymorphism, algebraic data types, pattern matching, recordswith mutable fields, etc., are all of genuine interest in program verification, as we
show later in this document.Finally, two of the three Ph.D. theses I supervised are related to functional
programming, namely those of Julien Signoles [93] and Johannes Kanig [56, 57].

Acknowledgments

I'm greatly honored to defend this thesis in front of such a committee, for itis exclusively composed of people I admire. If only Natarajan Shankar could have

joined it, it would have been the perfect committee.Gilles Barthe, Yves Bertot, and Rustan Leino accepted to serve as examiners,
despite the extra workload it represents. I sincerely thank them. The contribution ofRustan to the domain of deductive verification is truly impressive and has influenced
my work more than once. I remember when I read his PASTE 2005 paper forthe first time and how many new insights on weakest preconditions I got from
these eight pages. Program verification has always been central in Yves's work, asdemonstrated in the Coq'Art, the book he co-authored with Pierre Cast'eran. This
book was immensely useful for me when I taught program verification with Coqat the MPRI a few years ago. In 2010, Gilles kindly accepted to be our invited
speaker at PLPV, a workshop I was co-organizing. It was an opportunity for me

CONTENTS xi
to appreciate his impressive contribution to the domain of cryptographic softwareverification.

Roberto di Cosmo was my adviser at 'Ecole Normale Sup'erieure when I wasdoing my undergraduate studies. I remember when I met him for the first time:
he was enthusiastic about Perl at that time and even tried to convince me! Moreimportantly, he gave me the advice I needed regarding my first internship, which
led me to the Coq team and to my first meeting with G'erard Huet. It was in 1993at INRIA Rocquencourt. What a souvenir! My first immersion into a research lab
was great: computers piled in the so-called "buffers", researchers giving a tour oftheir work on the blackboard, hardware and software hacking all over the place,
etc. I did not stay there for long, however, since I soon left to Lyon to perform myinternship under the supervision of Christine Paulin. The lab was not as attractive,
with its hospital-like look, but the team was great. At the monthly meetings ofthe Coq group, I was repeatedly impressed by stratospheric discussions related to
type theory always involving Christine and G'erard. It was at one of these meetingsthat I picked up the PhD proposal on imperative program verification suggested by
G'erard. I clearly remember this event and the way I was literally attracted by thesubject. May be I was missing the very first days of my programmer's life, when
I was doing imperative programming only. I am immensely grateful to Roberto,Christine, and G'erard for having guided my first steps into research.

I am a programmer, since the age of thirteen. As I explained above, I was luckyto be introduced to functional programming at some point, which changed my life
as a programmer, but also influenced my research activity. That's why it makesa lot of sense for me to count two eminent members of the ML community on my
committee. Xavier Leroy's contribution to the domain is beyond words, but I mustconfess that I'm even more impressed by his recent move to the domain of program
verification with the CompCert project. I wish my own contribution to programverification will eventually be able to contribute to a similar project. Surprisingly, I
met Olivier Danvy for the first time only recently. He visited me in Orsay two yearsago and, almost immediately, challenged me with a programming exercise! If only
all computer scientists could be in that state of mind, it would change our disciplinefor the better. At last, I can contribute to Nature's statistical result: thanks Olivier.

Remerciements

<< Tout vient `a point `a qui sait attendre OE dit le proverbe. Je ne sais pas sicette habilitation vient `a point mais il est clair que j'ai su attendre. Je remercie

tr`es chaleureusement toutes les personnes qui m'ont encourag'e dans cette voie cesderni`eres ann'ees, sans jamais d'esesp'erer. Cela inclut les membres de l''equipe ProVal,
pass'es et pr'esents, et en particulier Christine, qui a su me remotiver plusieurs fois.J'ai 'egalement re,cu le chaleureux soutien de nombreux enseignants de l' 'Ecole Polyxii CONTENTS
technique, notamment Olivier Bournez, Benjamin Werner, St'ephane Lengrand etThomas Clausen.

Je remercie le d'el'egu'e aux th`eses de l''ecole doctorale d'informatique de Paris-Sud, Dominique Gouyou-Beauchamps, pour ses conseils relatifs `a l''ecriture de ce
m'emoire, en particulier l'id'ee d''ecrire un document que l'on puisse donner `a lire `aun 'etudiant de M2 qui souhaite comprendre notre domaine.

Un grand merci `a Xavier Urbain pour son aide pr'ecieuse dans la pr'eparation dupot ; je n'ai toutefois aucun espoir de parvenir `a faire aussi bien que lui.
Enfin, je d'edie ce m'emoire `a Anne, Marion, 'Emilie et Juliette qui ont support'esans jamais se plaindre le surcro^it de travail que cette habilitation a pu me donner
certains week-ends, sans parler de quelques r^aleries suppl'ementaires.

1
Deductive Program Verification

I will start with a definition:

Deductive program verification is the art of turning the correctness of aprogram into a mathematical statement and then proving it.

The words are carefully chosen. The word "deductive" makes a clear distinctionwith other verification methods such as model checking, abstract interpretation,
typing, or testing. It also emphasizes the use of a logic, to specify and to prove.I favor "program" to "software" since I am mostly interested in the verification
of small and challenging programs, rather than million line long software systems.Providing methods and tools to verify textbook programs as easily as possible is
one of my goals. Yet I intend to verify code that is executable and thus I favor"program" to "algorithm". Deductive program verification is an "art", exactly as
programming is. It requires experience, imagination, tricks, but also taste, to figureout specifications and proof steps in the most elegant way. There is a long way to
go before it becomes a technique routinely used in software production. The word"correctness" is purposely vague. It may refer to the safe execution of the program
only, but it may also characterize the precise meaning of what the program is do-ing. We will show that deductive verification can be a challenging task whatever
the notion of correctness might be. Having the correctness expressed as a "math-ematical statement" has the obvious advantage that a wide range of existing tools
and techniques can be used. This includes proof assistants and automated theoremprovers, which were not necessarily developed with program verification in mind.
Finally, it is important to embed the task of "proving" the correctness statementinto the definition. This is indeed a part of the game, and a successful verification
should include a proof as elegant as possible.

This chapter intends to be a survey on deductive program verification, alongthe lines of the definition above. My own contribution to this domain is described
in the next two chapters.

1

2 CHAPTER 1. DEDUCTIVE PROGRAM VERIFICATION

The idea of deductive program verification is not new. It is actually as old asprogramming. One of the very first proof of program was performed by Alan Turing
in 1949. His three page paper Checking a Large Routine [101, 79] contains a rigorousproof a of program computing the factorial by repeated additions. The program is
given as the following flowchart:

STOP

r0 = 1
u0 = 1 v0 = u TEST r - n s0 = 1 u0 = u + v s0 = s + 1

r0 = r + 1 TEST s - r
Assigned variables are primed: a statement such as r0 = r + 1 must be read as
r  r + 1. Variable n contains the input parameter and is not modified. When theprogram exits, variable

u contains n!, the factorial of n. There are two nested loops.In the outer loop, variable

u contains r! and its contents is copied into variable v.Then the inner loop computes (

r + 1)! in u, using repeated additions of v. Sincevariables
r and s are only used for iteration, this program can profitably be writtenusing "for" loops, in a more modern way. With a benign modification of its control

flow 1, it reads as follows:

u  1for

r = 0 to n - 1 do
v  ufor

s = 1 to r do
u  u + v

The idea defended by Turing at the very beginning of his article is that "the pro-grammer should make a number of definite assertions which can be checked individually, and from which the correctness of the whole programme easily follows".He does so on the program above, associating mathematical assertions about variables to the various points of the code flowchart. For instance, one assertion statesthat, prior to the execution of

u0 = u + v, variable v contains r! and variable ucontains
s * r!. The paper even includes a proof of termination. Turing gives anordinal that decreases whenever a transition in the flowchart is taken. The ordinal

is (n - r)!2 + (r - s)! + k, where k is assigned a value from 0 to 6 according to thestatement under consideration. In modern terminology, we recognize the variant
n - r for the outer loop and the variant r - s for the inner loop. As an alternativeto the ordinal, Turing proposes the natural number (

n - r)280 + (r - s)240 + k, sincehe is assuming 40-bit integers.

1. The finding of which is left as an exercise.

1.1. PROGRAM VERIFICATION IS CHALLENGING 3

Another example of early proof is Tony Hoare's proof of FIND [53]. In this 1971paper, Hoare shows the correctness of a program that rearranges the elements of an
array as follows: given an index f , elements are swapped in such a way that we endup with a value

v at position f , elements smaller than v to the left, and elementsgreater than
v to the right. Hoare builds the program by successive refinementsteps and exhibits the loop invariants in the process. He carefully states and proves

the eighteen lemmas that entail their validity. For instance, one of the loops iswhile

A[i] < r do i := i + 1 and has the following invariant:

m <= i & 8p(1 <= p < i oe A[p] <= r):
The preservation of this invariant is stated as the following lemma:

A[i] <= r & m <= i & 8p(1 <= p < i oe A[p] <= r)oe
m <= i + 1 & 8p(1 <= p < i + 1 oe A[p] <= r):

(The loop test is purposely strict, while this not necessary from the invariant andthe lemma.) Hoare's proof also includes termination and preservation of the array
elements. There is even a footnote commenting on the possibility of arithmeticoverflows, in statements such as

i = i + 1 above, and on possible workarounds.Remarkably, a subsequent mechanization of this proof in 1999 [39] showed that it

did not contain a single error.From a theoretical point of view, a manual proof such as in the examples above
can be carried out for any code and any specification, the only limit being themathematical skills of the user. In practice, however, this is not that simple. Proving
a program requires to check the validity of many conditions, most of them beingtedious and error-prone statements. Fortunately, the situation has evolved a lot
in the past two decades. Languages, techniques, and tools have flourished, whichallow the mechanization of the verification process. Still, before we describe them
in detail, let us take some time to examine other examples. Our purpose is to showwhy deductive software verification can be truly difficult.

1.1 Program Verification is Challenging

A program specification can be limited to the mere safety: the program willexecute without ever running into a fatal error, such as dividing by zero or accessing
an invalid memory location. Proving safety can already be quite challenging. A fewyears ago, a bug was found in the Java standard library which was related to the
computation of the average of two integers in some binary search [12]. Witharray indices l and u large enough, the computation of (l + u) / 2 may return a
negative value if the addition overflows, resulting in some fatal access out of array

4 CHAPTER 1. DEDUCTIVE PROGRAM VERIFICATION
bounds 2. On a 32-bit machine with enough memory, it is indeed possible to havearrays with more than a billion elements, and thus to trigger this bug. A possible
fix is to compute the mean value using l + (u-l)/2 instead. This sole exampleshows that proving safety may require to prove the absence of arithmetic overflows,
which in turn may require a lot of other properties to be checked. This can be evenmore difficult. Consider another fix using a logical shift right instead of a division,
that is (l + u) >>> 2 in Java. Then there is an overflow in some cases, but it is aharmless one. Thus proving this code correct would require an even more complex
model of machine arithmetic.Another example is termination. Most of the time, termination is a desired
property and should naturally be associated to safety. It is worth pointing out thatearly papers on program verification, in particular the ones cited above [101, 53],
already included proving termination as part of the proof process. In principle,proving termination has an easy rule of thumb: each loop or recursive function
is associated with some entity, called a variant, which decreases at each step andcannot decrease indefinitely [49]. Typically, a natural number will do. But exactly
as for safety above, proving termination can be challenging anyway. A historicalexample is John McCarthy's "91 function" [71]. It is a function over integers defined
as follows:

f (n) = ( f (f (n + 11)) if n <= 100,n - 10 otherwise:

Figuring out a variant for this function is not that difficult: it is as simple as 101-n.But proving that it is indeed a variant, that is proving that it is non-negative and
decreases for each recursive call, is another story. Indeed, it requires to establisha postcondition for the function, relating its output value to its parameter

n --namely, that
f (n) returns 91 whenever n <= 100, and n - 10 otherwise. As forbinary search above, proving a property as simple as termination actually requires

us to prove much more about the program.Another example of program the sole termination of which is difficult to establish
is Robert Floyd's cycle detection algorithm, also known as "tortoise and hare"algorithm [61, ex. 6 p. 7]. To check whether a singly linked list contains a cycle, this
algorithm traverses it at speeds 1 and 2 at the same time, using only two pointers.Whenever a pointer reaches the end of the list, the outcome is negative. Whenever
the two pointers are equal, the outcome is positive. The beauty of this algorithmis that it necessarily terminates, the hare not being able to overtake the tortoise
within the cycle, if any. Turning that into a proof is non-trivial. One has to statethe finiteness of the memory cells of the list, to introduce the inductive notion of

2. Interestingly, binary search was precisely taken as an example of program verification inJon Bentley's Programming Pearls [10] more than 25 years ago. Unfortunately, his proof does not
consider the possibility of an arithmetic overflow.

1.1. PROGRAM VERIFICATION IS CHALLENGING 5
path from one list cell to another, and finally to come up with a variant which isquite involved.

Here is yet another example where proving safety is truly difficult. Let usconsider computing the first

M prime numbers, along the lines of Don Knuth'sMIX program from The Art of Computer Programming [60, p. 147]. We are going

to fill a table with the first M primes, in increasing order. We store 2 in the firstslot and then we consider odd numbers starting from 3, performing divisibility tests
using the prime numbers computed so far 3. Say we have already found the first mprime numbers, for

m >= 2. They are stored in p[1], : : : , p[m]. Then we look for thenext prime, examining odd numbers starting from

p[m] + 2. If n is our candidate,the loop checking for the primality of
n can be sketched as follows:

while p[i]2 < n ^ n mod p[i] 6= 0 do

i  i + 1

In practice, it is written differently, as we need to distinguish between the twopossible reasons for a loop exit. However, the loop above suffices to illustrate the

idea. Indeed, proving the safety of this code requires to prove that variable i willnot exceed the bounds of array

p. More precisely, we are going to prove that i willnot exceed
m, that is, we will not run out of prime numbers. Additionally, it ensuresthat dividing by

p[i] is safe, since p[i] >= 2 for i <= m. Last, it ensures the terminationof the loop in an obvious way. To prove that

i does not exceed m, it suffices to provethat
p[m] is large enough for the test p[m]2 < n to fail. Fortunately, this is ensuredby Bertrand's postulate: for

k > 1, there is always a prime p such that k < p < 2k.Therefore, we have
n < 2p[m] <= p[m]2. Said otherwise, verifying the safety of thisprogram requires not less than Bertrand's postulate. In 2003, Laurent Th'ery proved

Knuth's program for prime numbers using Why and Coq [99]. Truly a tour de force,this proof includes the full proof of Bertrand's postulate in Coq.

As a last example, let us consider the verification of a sorting algorithm. Thealgorithmic literature contains so many sorting algorithms that it is natural to
consider proving them as well, at least as an exercise. Expressing that a routinesorting an array ends up with the array being sorted is quite easy. It amounts to
providing a postcondition such as

8ij, 0 <= i <= j < n ) a[i] <= a[j]:
But this is only half of the specification, and this is the easy one. We also need tostate that the final contents of the array is a rearrangement of its initial contents.
Otherwise, a code that simply fills the array with a constant value would obviouslyfulfill the specification above. When it comes to specify the rearrangement property,

3. There are more efficient ways to compute prime numbers, but that is not the point here: thepurpose of this program is to illustrate the MIX assembly language.

6 CHAPTER 1. DEDUCTIVE PROGRAM VERIFICATION
there are several solutions but none is easy to define. In a higher-order logic, onecan state the existence of a bijection. Though elegant, it is not amenable to proof
automation. Another solution is to introduce the notion of multiset, to turn thecontents of an array into a multiset, and then to state the equality of the multisets for
the initial and final contents of the array. A third possibility is to define the notionof permutation as the smallest equivalence relation containing transpositions, which
is adapted to sorting algorithms that swap elements [45]. Whatever the solution,it will be quite difficult to get a fully automated proof, even for simple sorting
algorithms such as insertion sort or selection sort.All these verification examples show the necessity of expressive specification
languages, even to prove simple properties such as safety. In particular, we cannotexpect deductive program verification to be conducted within a decidable logic.

1.2 Specifications

Roughly speaking, a specification language is made of two parts: first, a mathe-matical language in which components of the specification (pre- and postconditions,

invariants, etc.) are written, as well as verification conditions in fine; second, itsintegration with a programming language. Obviously, the choice of a specification
language is tied to both the methodology used to generate the verification condi-tions and the technique used to prove them. These two aspects will be discussed in
the next two sections.As far as the mathematical language is concerned, first-order predicate calculus with equality is a natural choice, immediately picked up without discus-sion in pioneer work [49, p. 21]. Today, many systems use a flavor of first-order
logic [9, 5, 30, 16, 65, 8]. Beside equality, a handful of built-in theories are typi-cally considered. Linear arithmetic, purely applicative arrays, and bit vectors are
the common ones; non-linear or real arithmetic may be available as well. Otherextensions to first-order logic include recursive functions and algebraic data types
-- in Dafny [65] and Why3 [16] for instance -- as well as polymorphism [17] andinductive predicates [16]. Set theory is an alternative, considered for instance in the
B method [1].An alternate route is to consider using the logic of an existing, general-purpose
proof assistant. Examples of such systems successfully used in program verificationinclude Coq [98], PVS [83], Isabelle [85], and ACL2 [58]. This approach has obvious benefits. First, it provides a powerful specification language, as these proofassistants typically provide a rich and higher-order logic. Second, the logic is already implemented and, in particular, interactive proof tools are ready to be used.Finally, proof assistants come with libraries developed over years, which eases the
specification process. Anyhow, this approach has drawbacks as well. One is that aricher logic comes at a cost: proof automation is typically more difficult to achieve.

1.2. SPECIFICATIONS 7
This is discussed later in Section 1.4.One can also introduce a new logic, dedicated for program verification. Undoubtedly the best example is separation logic [89]. Among other things, it allowslocal reasoning on heap fragments, being a tool of choice for proving programs involving pointer data structures. Similar proofs with traditional first-order predicatecalculus require cumbersome and explicit manipulations of sets of pointers.

Once the mathematical language for specification and verification conditions isset, we are left with its integration into a programming language. Pioneer work
intends to bind logical assertions to the program flowchart [101, 49]. A key step wasthen Hoare's axiomatic basis [52] introducing the concept known nowadays as Hoare
triple. In modern notation, such a triple {P }s{Q} binds together a precondition P ,a program statement

s, and a postcondition Q. Its validity means that executionof
s in any state satisfying P must result, on completion, in a state satisfying
Q. Requiring s to be terminating defines total correctness, as opposed to partialcorrectness otherwise. The beauty of Hoare logic is not really that it proposes

a methodology to derive the correctness of a program -- weakest preconditionsare more efficient, as we will see in next section -- but that it opens the way
to a modular reasoning framework about programs. Software components can beenclosed in Hoare triples, with preconditions that are proof requirements for the
caller and, conversely, postconditions that are ensured to be valid by the callee. Insome hypothetical language, such a triple for a function

f could look like

requires Pensures

Qfunction

f (x1, : : : , xn)

where P may refer to the current state and to function parameters xi, and Q mayrefer to the state prior to the call, to the final state, to function parameters, and
to the returned value, if any. This idea has been popularized by Meyer's designby contract, a key feature of the Eiffel programming language [76], and later by
specification languages such as JML [63] and its derivatives [47, 8, 5]. Modernspecification languages include some variations, such as the ability to have several
contracts for a given function, to distinguish side effects from the postcondition, toallows exceptional behaviors, etc. Anyway, they all clearly derive from Hoare logic.

This is not the only way to go, though. A specification language can be tied toa programming language within a dedicated program logic, which mixes programs
and logical statements in a more intricate way. The aforementioned B method isbuilt on top of a notion of generalized substitution, which infuses programming
constructs among logical ones within a single language. Similarly, when programverification is conducted within a general-purpose proof assistant, there is only one
language, that is the logic language. A program f is simply a purely applicative

8 CHAPTER 1. DEDUCTIVE PROGRAM VERIFICATION
and terminating function, already part of the logic. Proving it correct amounts toestablishing a statement like

8x, P (x) ) Q(x, f (x)): (1.1)
The user is then left with a traditional proof, or is assisted with some "tactic"dedicated to program verification.

So far we have discussed the specification language and its integration withthe programming language. We now turn to methodologies to extract verification
conditions from a program and its associated specification.

1.3 Methodologies

Hoare logic is undoubtedly the most famous of all techniques, Hoare's paper [52]being the most cited among pioneer work. It proposes rules to establish the validity

of Hoare triples. The rule for assignment, for instance, reads

{P [x  E]} x := E {P }:
It assumes E to be an expression without side effect, thus safely shared betweenprogram and logic, and also

x not to be aliased with another program variable.More generally, each program construct is given a deductive rule. Some additional

rule allows to strengthen a precondition and to weaken a postcondition. It is a neatsystem, from which you can derive the validity of arbitrarily complex programs.
In practice, however, one quickly finds it painful to figure out intermediate asser-tions for Hoare rules to compose nicely. The natural approach is rather to assign
meaningful assertions at key places in the code, and to let the system figure outthe intermediate assertions. This is exactly what Dijkstra's calculus of weakest precondition [35] is doing. Given a program statement s and a postcondition Q, itcomputes a precondition

wp(s, Q), recursively over the structure of s, that preciselycaptures the weakest requirement over the initial state such that the execution of

swill end up in a final state satisfying
Q. As a consequence, the validity of the Hoaretriple {
P }s{Q} is equivalent to

P ) wp(s, Q):
Computing weakest preconditions is the approach taken in most modern verificationcondition generators. Recent work has even improved over Dijkstra's calculus to

provide greater efficiency [64]. There is still the limitation of programs being free ofaliasing, though. As a consequence, the semantics of the program under consideration must be encoded as a set of types, symbols, and axioms, known as the memorymodel, together with an alias-free version of this program performing actions on

1.3. METHODOLOGIES 9
this memory model. Within the last decade, two intermediate languages appeared,the sole purpose of which is to perform the computation of weakest preconditions,
independently of the memory model: Why [47, 15] and Boogie [4]. Many tools nowemploy this route which consists in building a memory model and then reusing an
existing intermediate language (Krakatoa [74], SPEC# [6], VCC [30], Frama-C [50],Dafny, among others).

Building memory models is an activity in itself. Some key ideas come fromthe 70s [23]. They could be successfully applied at the turn of the century when
practice finally caught up with theory [21], and then even improved [54]. Othermodels include ideas from state-of-the-art recent research. A nice example is the
model used in the L4verified project [59]. This model [100] combines low-level detailsallowing the verification of high-performance C code with higher-level concepts of
separation logic.

We already explained that proof assistants such as Coq, PVS, Isabelle, or ACL2,are tools of choice to write program specifications, and even to write programs when

they happen to be purely applicative. Then, proving a program f to be correct,that is establishing a statement such as (1.1), is a matter of following the definition
of f , splitting the goal into smaller verification conditions. This may be automated,using a dedicated tactic (either built-in or developed for the purpose of program
verification). The user may have to provide some intermediate assertions, such asa generalized specification for a recursive function. This can be compared to the
computation of weakest preconditions. When done, the user is left with a bunch ofpurely logical statements and all the power of the proof assistant can be exploited
to discharge them. An impressive example of such a program verification is theverified C compiler CompCert [69], developed and proved correct within the Coq
proof assistant by Xavier Leroy and his team.But the use of general-purpose proof assistants is not limited to the verification of purely applicative programs. One can use the logic of a proof assistantto define an imperative programming language and its semantics. Then a proof
methodology can be carried out within the proof assistant and particular programscan be verified. This is called deep embedding. A successful example is Schirmer's
work in Isabelle/HOL [90]. It provides a Hoare logic-like language with procedures,operating over a polymorphic state space. It was used in the L4verified project.
An additional benefit of deep embedding is that it allows meta-theoretical proofs,such as soundness of the proof method w.r.t. the semantics of the language. An
alternative to deep embedding is shallow embedding. Concepts related to programsare mere notations for semantic definitions, which can be tackled by unfolding or,
better, by relevant axioms and theorems. An example is Ynot [80], a Coq-embeddedsystem to verify higher-order and effectful programs using a combination of monads, separation logic, and Hoare triples. Another example is Arthur Chargu'eraud'scharacteristic formulae [24].

10 CHAPTER 1. DEDUCTIVE PROGRAM VERIFICATION

When a program is given a specification, and is processed through a suitabledeductive verification method, one is left with a set of mathematical statements,
the so-called verification conditions. The last step is to prove them.

1.4 Proofs

The L4verified and CompCert projects are two examples of large program verifi-cation conducted within a proof assistant (Isabelle/HOL and Coq, respectively). At

least they show the relevance of using a general-purpose proof assistant to dischargeverification conditions. Even when those are computed completely independently,
for instance using a weakest precondition calculus, it is still possible to translatethem to the native format of a proof assistant. This is always possible, as the logic
of the proof assistant is typically richer than the one used to express the verificationconditions.

However, there are several reasons why we may want to avoid this path, atleast in a first step. One reason is that deductive verification typically generates
numerous, yet simple, goals. These include array bounds checking, variant decrease,absence of arithmetic overflows, non-nullity of pointers, etc. They are better handled
directly by automated theorem provers, as discussed below. Processing them withina proof assistant would incur an extra cost, such as one manipulation at least per
verification condition, if not more. Another reason to avoid interactive proof in thefirst step is proof maintenance. In the process of figuring out the right specification,
or even the right code, it is likely that verification conditions will change a lot beforestabilizing. Any manipulation within the proof assistant, as small as it is, will slow
the whole specify/prove cycle.It is better to turn to automated theorem provers when it comes to the task of
discharging verification conditions. Automated theorem provers have a long history,as demonstrated by the CASC competition [94] and the huge corresponding library
of problems TPTP [95]. However, all the automated theorem provers taking part inthis competition were never really involved in deductive program verification. The
main reason must be the lack of support for arithmetic, a must-have in programverification 4. Independently, another line of automated theorem provers emerged,
called SMT solvers 5. Initiated by Shostak's and Nelson-Oppen's decision proce-dures [92, 81] in the early 80s, it focuses on the combination of first-order logic,
congruence closure, and built-in theories. The latter typically involve linear arith-metic, at least. One of the earliest provers in that line was Nelson's Simplify [34].
Developed in the 90s, in the context of program verification, it still performs im-pressively. Other SMT solvers followed, such as CVC3 [7], Yices [33], Z3 [32], and

4. Things may change, as there are rumors that next versions of Vampire, the state-of-the-artTPTP prover, will have support for arithmetic.
5. We only consider here SMT solvers with support for quantifiers.

1.4. PROOFS 11
Alt-Ergo [14]. Today, they have reached such a level of efficiency that a programimplementing binary search can be proved correct fully automatically within a second. This includes proving safety, termination, absence of arithmetic overflow andfull behavioral correctness.

Obviously, we are also left from time to time with verification conditions thatcannot be proved automatically. A possibility is then to insert more intermediate
assertions in the code, to reduce the cost of each individual deduction. In otherwords, the user inserts logical cuts to ease the proof. If this is unsuccessful, or if
this is not even an option, then there is no other choice than turning to a proofassistant and starting an interactive proof. A definitive improvement in this process
is the recent introduction of automated theorem provers within proof assistants.Isabelle/HOL is leading the way with its Sledgehammer tool [75].

Finally, another approach is to use a dedicated prover. It can be motivated bya need for a close connection between verification conditions as displayed during an
interactive proof process and the input code and specification. Examples includethe system KeY [9] and the B method, for instance. Regarding the latter, it may
also be motivated by the poor support for set theory in existing automated theoremprovers. One obvious drawback of a dedicated prover is that it will hardly benefit
from state-of-the-art results in automated or interactive theorem proving, at leastnot for free.

2A Tool for Program Verification: Why3
Since my PhD, I have been continuously developing a tool for program verifi-cation, with other members of ProVal. This chapter describes this tool. It does
not intend to be exhaustive -- more details about Why3 are available in papersrelated to Why3 [16, 17], in its manual [15], and from its website why3.lri.fr.
This chapter rather discusses design choices and technical solutions.

2.1 History

I started the development of a tool for deductive program verification duringmy PhD [36, 37]. At the time, it was a tactic for the Coq proof assistant, called
Correctness. Given a Hoare triple {P }e{Q}, this tactic was building a proof of

8~x, P ) 9~y, 9r, Q (2.1)
where ~x is the set of all variables occurring in the triple, ~y the set of variablespossibly modified by expression

e, and r is the result of e. Actually, only the com-putational part of this proof was built, as a purely applicative interpretation of

e ina monadic style. When fed to Coq's refine tactic, it resulted in proof obligations,

exactly as if Hoare logic rules had been applied. Programs included a standardwhile language with local variables and (possibly recursive) functions. It was using a shallow embedding of the logic: data types were those of Coq, as were formulasin annotations. Using that tactic, I could prove a few non-trivial programs such
as Hoare's FIND [39], sorting algorithms quicksort and heapsort [45], and Knuth-Morris-Pratt string searching algorithm. All proofs were conducted in Coq, with no
proof automation beside the omega tactic for Presburger arithmetic. A few othersused the Correctness tactic. Nicolas Magaud contributed the verification of insertion sort as an undergraduate internship [45]. Worth mentioning is Laurent Th'ery'sproof of Knuth's algorithm for prime numbers [99], which includes the full proof of
Bertrand's postulate in Coq (see Section 3.2).

13

14 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3

In 2001, while visiting Cesar Mu~noz at NASA Langley, I turned my implementa-tion into a standalone tool, for Cesar to perform proofs using PVS instead of Coq.
I called this tool Why, for it is a way to tell the machine why a computation issound, instead of simply telling it how to compute. The technology was still based
on a purely applicative translation of imperative programs, but proof obligationswere now extracted from it by Why itself, no more by Coq's refine tactic. Yet it
was still possible to build the Coq proof for (2.1) when the proof obligations weredischarged using Coq. The tool Why was first released in July 2002.

The idea of translating imperative programs into purely applicative ones toderive proof obligations is elegant. In particular, it provides strong guarantees since,
once proof obligations are discharged, a proof of (2.1) can be built automaticallyand checked by Coq 1. Unfortunately, it also has the drawback of traditional Hoare
logic: the user has to provide adequate intermediate assertions. At some point, itbecomes a bottleneck, as we figured out when we started using Why for deductive
verification of Java programs. It was in 2002 and Christine Paulin, Claude March'e,and Xavier Urbain were developing the tool Krakatoa [74], which translates Java
programs into Why programs. The problem of intermediate assertions being ashowstopper, we had to go for the obvious solution: the computation of weakest
preconditions. We quickly modified the Why tool accordingly, weakest preconditionsbeing straightforward to implement. There was one big side effect, though: we lost
the Coq proof of (2.1) in the process, our weakest precondition calculus not beingproof-producing.

The divorce from Coq was on its way, anyhow. At the same period, we werealready experimenting with automated theorem provers, the first ones being haRVey [87] and Simplify [34]. Corresponding back-ends were added to Why. As aconsequence, proof obligations were not all discharged with Coq anymore, ruling
out the possibility of a complete Coq proof of (2.1). Other back-ends followed,for other automated theorem provers (CVC Lite in 2004, SMT-lib syntax in 2005,
Zenon in 2006, Alt-Ergo in 2008) as well as other proof assistants (HOL Light andMizar in 2003, Isabelle/HOL and HOL4 in 2005). All these back-ends were added
"on demand", from our own experiments or from user requests. They were main-tained to various degrees, depending on their actual use. Some of the back-ends
have been used for no more than a single program verification.Supporting many theorem provers is challenging. This is definitely more subtle
than writing several pretty-printers for the corresponding input languages. Themain reason is that theorem provers implement different type systems: some are
untyped, some have simple types, and others have richer type systems with polymor-phic types, dependent types, etc. The logic of Why happens to be a compromise:
it is a first-order logic with polymorphic types. There is no difficulty to embed it

1. Note that there is still space for unsoundness, such as a buggy translation which would notpreserve the semantics of the imperative program.

2.1. HISTORY 15
into richer type systems 2. On the other way round, however, a careful translationmust be carried out, since a mere removal of types would be unsound. A solution
was worked out by Jean-Fran,cois Couchot and St'ephane Lescuyer in 2007 [29] andrecently improved by Andrei Paskevich and Fran,cois Bobot [17].

In 2004, Claude March'e and myself started a tool for the verification of C pro-grams, Caduceus [46]. Following the methodology of Krakatoa, it translated C programs into Why programs, on top of a memory model `a la Burstall-Bornat [23, 21].Why was clearly appearing as a suitable intermediate language. It is worth mentioning that another such intermediate language, Boogie, was developed independentlyat Microsoft Research [4]. Later, Claude March'e identified another intermediate
language to stick between C/Java and Why, to factor out common concepts relatedto memory models [54, 73]. Yet the role of Why was unchanged: computing weakest
preconditions and feeding them to theorem provers. This is not incompatible withthe direct use of Why to prove programs, which I kept doing all these years.

In 2007, a conference was organized in Bordeaux to celebrate Don Knuth whowas receiving an Honoris Causa degree from University Bordeaux 1. In an attempt
to honor the man and his work, I implemented a small tool to verify MIX programsusing Why. MIX is the hypothetical machine introduced by Knuth in The Art of
Computer Programming [60], as well as the name of its assembly language. Sothe point was to verify assembly programs and to use Why as an intermediate
language one more time. The tool is a front-end to Why. It takes an annotatedMIX program as input and turns it into a set of sequential Why programs. Since
assembly programs have arbitrary control flow graphs, the notion of loop invariant isreplaced by a more general notion of invariant. Invariants can be placed anywhere
in programs. The only requirement is that any cycle in the control flow graphshould contain at least one invariant. Then the control flow graph is traversed and
any path from one invariant to another results in a separate Why program. Thememory model of MIX is simple, with a bunch of references for the registers and
status flags and a single array for the whole memory. More details are available inthe conference paper [40].

In 2009, B'arbara Vieira (University do Minho, Portugal) visited ProVal andstarted the development of a tool to verify CAO programs. CAO is a domainspecific language for cryptography, developed within the CACE European Project.This tool translates CAO to Jessie, which is then translated to Why. More details
are available from the related publication [2]. After Java, C, and MIX, this is yetanother example of the use of Why as a verification condition generator.

After several years of development, the code of Why was becoming messy. Inparticular, the back-end of the code offering support for the various theorem provers

2. This is typically the case of proof assistants, with the notable exception of PVS, which doesnot provide declaration-level polymorphism. PVS supports type-parametric theories only, which
turns the Why output into a nightmare of small theories.

16 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3

file.why

file.mlw

WhyML
VCgen

Why
transform/translate

print/run

Coq Alt-Ergo Gappa Z3 etc.
Figure 2.1: Overview of Why3's architecture.

was getting so complex 3 that it was almost impossible to add new features, such assupport for algebraic data types for instance. Beside, we all know from The Mythical
Man-Month [22] that "we have to throw one away". So on February 2010 we starteda brand new implementation, from scratch, with Andrei Paskevich, Claude March'e,
and Fran,cois Bobot. It is called Why3 and was first released on December 2010.

2.2 Overview of Why3

Figure 2.1 gives an overview of Why3's architecture. It clearly distinguishes twoparts: a purely logical back-end and a programs front-end.

Logical files include declaration or definition of types and symbols, axioms, andgoals. Such declarations are organized in small components called theories, which
are grouped in files with suffix .why. The purpose of Why3 is to extract goals fromtheories and to pass them to provers using suitable series of transformations and
printers, as sketched in Fig. 2.1. For instance, the command line

why3 -P alt-ergo -t 10 -T EuclideanDivision int.why
extracts all goals from theory EuclideanDivision in file int.why and passes themto the SMT solver Alt-Ergo with a timeout of 10 seconds. This includes transforming

3. At the very beginning, the front-end for type checking programs and computing weakestpreconditions was clearly the main part of the code; today, it is the opposite: the support for many
provers is definitely dominating.

2.3. LOGIC 17
goals to remove logical features that are not known from Alt-Ergo, such as recursiveand inductive definitions. Conversely, it makes use of Alt-Ergo's built-in theories,
such as linear integer arithmetic or AC symbols.Why3 provides a programming language, called WhyML. As depicted in Fig. 2.1
page 16, it is a mere front-end to what we have described so far. A WhyMLinput text is a file with suffix .mlw. It contains a list of theories and/or modules.
Modules extend theories with programs. This front-end simply turns modules intotheories, replacing programs by goals corresponding to the verification conditions
-- as computed by a weakest precondition calculus. WhyML files are handled bythe tool why3ml, which has a command line similar to why3. For instance,

why3ml -P alt-ergo turing.mlw
will run the SMT solver Alt-Ergo on all verification conditions for the programscontained in file turing.mlw.

2.3 Logic

Why3 implements a polymorphic first-order logic. There are four kinds of dec-larations in this logic: types, function and predicate symbols, axioms, and goals.

Non Interpreted and Alias Types. Types can be either non interpreted, aliases fortype expressions, or (possibly recursive) algebraic data types. Types can be mutually defined. A non interpreted type t is simply declared as

type t
A type alias introduces a shortcut for a type definition, e.g.,

type length = int
Technically, type aliases are expanded in a systematic manner. Built-in types in-clude type int of integers, type real of real numbers, and tuple types.

Algebraic Data Types. An algebraic data type is defined with one or more construc-tors. For instance, the type of polymorphic lists is declared as

type list ff = Nil | Cons ff (list ff)
Each constructor introduces a new function symbol. Values of algebraic data typescan be examined using pattern matching, in both terms and formulas (see below).

Records are particular cases of algebraic data types, with a specific syntax:

type polar = {| radius: real; angle: real |}

18 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3
A record introduces projection functions for its fields. The constructor of a recordtype is not accessible; syntax {|...|} must be used instead, both for construction
and destruction.
Type Expressions. A type expression is either a type variable or the application ofa type symbol.

o/ ::= ff type variable|

s o/ : : : o/ type symbol application

Functions and Predicates. Function and predicate symbols can be non interpretedor (mutually and/or recursively) defined. For instance, a non interpreted relation
rel over type t can declared as

predicate rel t t
and a recursive function length over lists is defined as follows:

function length (l: list ff): int =match l with

| Nil ! 0| Cons _ r ! 1 + length r
end
Why3 automatically verifies that recursive definitions are terminating. To do so, itlooks for an appropriate lexicographic order of arguments that guarantees a structural descent.
Inductive Predicates. A predicate can also be defined inductively. For instance, thereflexive and transitive closure of rel is defined as follows:

inductive rstar t t =| Refl: 8 x: t. rstar x x

| Trans: 8 x y z: t. rstar x y ! rel y z ! rstar x z
Standard positivity restrictions apply to ensure the existence of a least fixed point.

Terms, Formulas, and Patterns. As usual in first-order logic, Why3 distinguishesterms and formulas. Terms are built as follows:

t ::= x variable|

c constant|
s t : : : t function symbol application| if

f then t else t conditional expression| match

t with p ! t, : : : , p ! t end pattern matching

2.3. LOGIC 19
Constants include integer and real literals. Note the intrusion of formulas into termsin conditional expressions. Formulas are built as follows:

f ::= s t : : : t predicate symbol application| 8

x : o/:f universal quantification| 9
x : o/:f existential quantification|
f ^ f conjunction|
f . f disjunction|
f ! f implication|
f $ f equivalence| not

f negation| true

| false| if

f then f else f conditional expression| match

t with p ! f, : : : , p ! f end pattern matching

Formulas enrich the usual connectives of first-order logic with conditional and pat-tern matching expressions. Finally, patterns are built as follows:

p ::= x variable|

s t : : : t constructor application| catch all

| p|p or pattern|

p as x binding

Axioms and Goals. Axioms can be introduced to enrich the logical context of sub-sequent declarations. The syntax is immediate:

axiom rel sym: 8 x y: t. rel x y ! rel y x
A goal is declared with an equally obvious syntax:

goal test length: length (Cons 2 (Cons 3 (Cons 5 Nil))) = 3
The context of a goal consists of all preceding declarations. Finally, a lemma decla-ration combines both notions of goal and axiom: it is a goal at the place where it

appears and an axiom for subsequent declarations. A typical lemma is the following:

lemma length nonnegative: 8 l: list ff. length l >= 0
In the case of this lemma, a proof by induction is needed and we may use Coq toprove it. As an axiom, it will be used in subsequent proofs by automated theorem

provers that may not be powerful enough to prove it, such as SMT solvers.

20 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3
Semantics. First-order logic is standard. For instance, a definition of many-sortedfirst-order logic can be found in Manzano's Extensions of first-order logic [72]. But
polymorphic first-order logic is not standard. Informally speaking, polymorphism inWhy3 is a declaration-level polymorphism, `a la Hindley-Milner [77]. It means that
each polymorphic declaration is a schema for the (possibly infinite) set of all itsmonomorphic instances. For instance, the following declaration of a polymorphic
function symbol length over lists

function length: list ff : int
can be understood as the declaration of an infinite set of function symbols:

function length int: list int : intfunction length bool: list bool : int

function length list int: list (list int) : int...

Similarly, a polymorphic axiom such as

axiom length nonneg: 8 l: list ff. length l >= 0
is also to be understood as an infinite set of axioms

axiom length nonneg1: 8 l: list int. length l >= 0axiom length nonneg2: 8 l: list bool. length l >= 0

axiom length nonneg3: 8 l: list (list int). length l >= 0...

A polymorphic goal, on the contrary, can always be turned into a monomorphicgoal, by instantiating all its type variables with fresh, uninterpreted types. A precise definition of polymorphic first-order logic is given by Fran,cois Bobot and An-drei Paskevich [17].

In practice, polymorphic first-order logic cannot be reduced to many-sortedfirst-order logic using an infinite number of instantiations. Thus Why3 implements
various methods for encoding polymorphism, that are proved to be sound and com-plete. This is described in the paper just mentioned.

Theories

Declarations are organized in small components called theories, which are groupedin files with suffix .why. For instance, a file list.why may contain a first theory

List defining the data type of polymorphic lists

theory Listtype list

ff = Nil | Cons ff (list ff)end

2.3. LOGIC 21
and then another theory Length where the length of a list is defined:

theory Lengthuse import int.Int

use import Listfunction length (l: list

ff) : int =match l with

| Nil ! 0| Cons _ r ! 1 + length r
endlemma length nonnegative: 8 l: list

ff. length l >= 0end

The declaration use import is used to import symbols from an existing theory.Here, integer arithmetic symbols are imported from the standard library int.Int,
as well as the previously defined theory List. Imported symbols are shared: twoimports of the same theory will result into a single addition of the corresponding
symbols to the context. The purpose of theories is to control the logical context,which is an important matter when one uses automated theorem provers. If there is
no need to import theory Length, we will avoid cluttering the logical context withunnecessary definitions and axioms.

The other way to use a theory is to clone it. Cloning a theory is making acopy of all its declarations, together with a possible instantiations of some of its
non interpreted symbols. Here is an example. Let us introduce the following theorywhich defines the reflexive transitive closure of an abstract relation rel over an
abstract type t.

theory RTClosuretype t

predicate rel t tinductive rstar t t =

| Refl: 8 x:t. rstar x x| Trans: 8 x y z:t. rstar x y ! rel y z ! rstar x z
end
Given a particular relation next over integers, we can clone this theory to get thereflexive transitive closure of next:

clone import RTClosure with type t = int, predicate rel = next
It is exactly as if we had typed in a fresh copy of the inductive definition above,with int and next respectively substituted for t and rel. It saves us the trouble

-- and the possibility of a mistake. Cloning theories is a powerful concept. Forinstance, we can clone the whole theory

clone import RTClosure

22 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3
to get a fresh type symbol t, a fresh predicate symbol rel, and its reflexive transitiveclosure star. More subtly, we can clone it twice to get two relations and their
reflexive transitive closures over a single type elt:

type eltclone import RTClosure as R1 with type t = elt
clone import RTClosure as R2 with type t = elt
Equivalently, and more elegantly, we can reuse the type provided by the first cloningto instantiate the second one:

clone import RTClosure as R1clone import RTClosure as R2 with type t = R1.t
The cloned theories are renamed using as X declarations to avoid name clashes.Generally speaking, a theory with

n uninterpreted symbols can be cloned in upto 2
n different ways (not mentioning the substitution itself). As illustrated above,

different cloning of a single theory can be meaningful. Why3's standard library ismaking a great use of theory cloning to avoid duplicated axioms; it is worth having

a look at it to understand how useful this simple idea can be.Though they were developed independently, the concept of theory cloning is
similar to that of theory interpretation in PVS [84].

2.4 Proofs

Generally speaking, all information related to a given prover is gathered into atext file called a driver . Such a file contains the list of transformations to apply,
the pretty-printer to use, the list of built-in symbols and corresponding axioms toignore, etc. The purpose of drivers is to ease the addition or modification of a
prover support, without changing Why3's code. It also eases experiments such asremoving the use of a prover's built-in theory.

Beside its command line tool, Why3 comes with an IDE 4. It displays goals andallows the user to perform proofs by repeated applications of provers and simple
transformations such as splitting. A screenshot of the IDE is given in Fig. 2.2. Thewhole proof session can be saved into a file, to be reloaded from the IDE or to be
replayed in a batch mode. The IDE is not limited to automated theorem provers.Interactive proofs using Coq can be edited, and then checked. Coq proofs are saved
as part of the proof session.

4. Why3's IDE is mostly contributed by Claude March'e.

2.5. PROGRAMS 23

Figure 2.2: Screenshot of Why3's IDE.
2.5 Programs

As depicted in Fig. 2.1, Why3 is a verification condition generator for a pro-gramming language called WhyML. The main features of this language can be
summarized as follows:- it borrows many features from ML (syntax, polymorphism, algebraic data

types, immutable variables, local and anonymous functions);- yet it is mostly a first-order language i.e. there is currently no support for
higher-order programs;- it keeps to the main ideas of Hoare logic: (1) any term from the logic can be
used in programs; and (2) aliasing is not allowed.In the remaining of this section, we detail the most distinguishable aspects of
WhyML.

24 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3
Mutable State

There is only one kind of mutable data structures in WhyML: records withmutable fields. The concept of mutable variable, or reference in ML-like terminology,

is defined as a particular case of record type 5:

type ref ff = {| mutable contents: ff |}
Then functions to create, access, and update references are easily defined, usingrespectively record creation, field access, and field update. For instance, function

:= to update a reference is defined as follows:

let (:=) (r:ref ff) (v:ff) = {} r.contents  v { !r = v }
Note the empty precondition and the postcondition stating that, in the final state,the value of !r is equal to v. Here is for instance Turing's early proof of program [101] written in WhyML using for loops and a reference u:

let routine (n: int) ={ n >= 0 }

let u = ref 1 infor r = 0 to n-1 do invariant { !u = fact r }

let v = !u infor s = 1 to r do invariant { !u = s * fact r }

u := !u + vdone
done;!u
{ result = fact n }
(Annotations make use of a function symbol fact imported from Why3's standardlibrary.) Note that for loop indexes (r and s here) are not mutable, as in OCaml.

Mutable states mean that we may need to refer to previous values of states inannotations. Two constructs are provided for that purpose. First, a postcondition
may refer to the value of term t in the pre-state with old t. Second, labels can beintroduced within code and the value of a term

t at a program point labeled with
L is denoted at t L. From the parsing and type checking point of view, old and atare nothing else than polymorphic identity functions. They are interpreted later, in

the weakest precondition calculus.

Model Types

Let us consider modeling arrays in WhyML. As usual in Hoare logic, an array ismodeled as a map from integers to values, which is mutated as a whole. Assuming

5. This is exactly how references are defined in OCaml.

2.5. PROGRAMS 25
we have maps available from Why3's standard library, an array can be defined asa reference containing a map or, equivalently, as a new record type with a mutable
field:

use import map.Maptype array

ff = {| mutable elts: map int ff |}

Although it is fine for many purposes, this model of arrays has a drawback: it doesnot prevent us from copying the entire contents of one array into another. This can

indeed be achieved as simply as

a1.elts  a2.elts
We would like to provide operations such as array access or array assignment, butcertainly not the ability to make such an atomic copy. Actually, we intend the

record type above to be a model of an array, not the array data type itself. For thispurpose, WhyML introduces the notion of model type. It consists in replacing, in
the type definition above, the equality sign by the model keyword:

type array ff model {| mutable elts: map int ff |}
This way, the type array ff is no more a record type in programs, but rather anabstract type. In the logic, however, that is in annotations, it is still defined as a

record type. It means that we can refer to the field elts when specifying operationsover arrays and when annotating programs using arrays. The other way round, we
cannot refer to field elts in programs anymore, which means that we cannot defineoperations such as array access or array assignment. We can only declare them.
Here is for instance how array access is introduced:

val ([]) (a: array ff) (i: int) :{ 0 <= i

< length a } ff reads a { result = a[i] }

As a consequence, what we end up with is not an implementation of the arraydata structure, but rather a signature or model of this data type. This is perfectly

fine; after all, an array in not implemented as a purely applicative map. The sametechnique can be used for other mutable data structures that cannot be implemented
in WhyML. For instance, a mutable queue implemented as a singly linked list andtwo pointers to its extremities cannot be implemented in WhyML. But such a data
structure can easily be modeled using purely applicative lists. It would start asfollows:

type t ff model {| mutable elts: list ff |}val push: x:

ff ! q: t ff !{} unit writes q { q.elts = old q.elts ++ Cons x Nil }

...

26 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3
Regions

We are not done with our model of arrays: the notion of array length is stillmissing (it is used in the precondition for function [] above). A simple solution

is to have a notion of length associated to purely applicative maps, as a func-tion from map int

ff to int. Then the length of array a is simply the length ofa.elts. Equivalently, we could replace type map int

ff above with a product type(int, map int
ff).This is not a good solution, however. Having the length tied to the map means

that each modification to the array contents possibly modifies the length as well.Of course, axioms over maps or suitable postconditions for array operations could
ensure that this is not the case. Unfortunately, it would also require the user tostate the invariance of an array length in annotations. For instance, a loop over an
array of size 10 would look like

for i = 0 to 9 do invariant { length a = 10 ^ ... }a[i]  0

done
to account for the array length not being modified. Without this annotation, it isno more possible to prove that a[i] is a legal array access. Similarly, postconditions

for function mutating arrays would have to ensure length invariance as well. Addingsuch annotations automatically would be an ugly hack, with no way to figure out
the proper generalization. Finally, all these annotations will result in more complexverification conditions.

Instead, we turn to a much more elegant solution. We store the array lengthinto another, immutable, field:

type array ff model {| length: int; mutable elts: map int ff |}
This way, any array operation which mutates the array contents results in a mod-ification of field elts, while field length is left unchanged, with no need to say

anything about it.Clearly, record types with possibly mutable fields allow us to model arrays in a
way that traditional Hoare logic cannot 6. To do so, WhyML makes a slight shiftfrom traditional Hoare logic. The primitive notion is not that of mutable variable,
but rather that of a region. Regions are introduced by mutable record fields.From a technical point of view, effects are now sets of regions and no more
sets of variables as they used to be in Why2. Accordingly, weakest preconditionsmust now quantify over fresh values for regions. They must also reconstruct the
values of all variables involving the corresponding regions. For instance, the weakest

6. Of course, we could model an array with two variables, one for its length and another onefor its contents. But this would already be a translation from a language with arrays to another

language without. What we seek here is a proper modeling of arrays directly in WhyML.

2.5. PROGRAMS 27
precondition for the loop above scanning a 10-element array will look like

8a0, : : : 8m1, let a1 = {length = a0:length; elts = m1} in : : :
The modification of the array within the loop body is interpreted as a new map
m1 and a new value a1 for array a is built from its old value a0 and m1. As aconsequence, any assumption over the length of

a0 will hold for a1 as well. Thisnew way of computing weakest preconditions is explained later in this section, on

page 31.

Abstract Syntax

The abstract syntax of WhyML expressions is given in Fig. 2.3. On top ofthat, several constructs are defined as syntactic sugar. We briefly describe these

constructs here for the reader to be able to go through all the exemples from thenext chapter. The sequence is the simplest one:

e1; e2 def= let = e1 in e2
Access to a record field f can be reduced to a logical term using a let binding:

e1:f def= let x1 = e1 in x1:f
Indeed, any logical term can be used in programs. Additionally, predicate symbolscan be used in programs as well, according to the following sugar:

s e1 : : : en def= let x1 = e1 in : : : let x1 = e1 inif

s x1 : : : xn then True else False

This includes equality and integer comparisons for instance.A function call

e1 e2, with e1 of type x2 : o/2 ! ^1, is translated using thenon-deterministic construct any:

e1 e2 def= let x1 = e1 in let x2 = e2 in any ^1
The expression any ^1 stands for any computation with type, effect, and specificationas specified by

^1; in a context of modular verification, this is exactly what thefunction call means. Similarly, assignment of record field

f can be interpreted usingthe any construct, as if it would be a function call:

e1:f  e2 def= let x1 = e1 in let x2 = e2 in any {}unit writes x1:f {x1:f = x2}

28 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3

e ::= x variable|

t term| let

x = e in e local binding| let rec

d, : : : , d in e local binding| fun
d anonymous function

| if e then e else e conditional| loop

e invariant f infinite loop| for
x = x to x do e invariant f for loop| match

x with p ! e, : : : , p ! e end pattern matching

| raise (E e) exception throwing| try

e with E x ! e, : : : , E x ! e exception handling

| L : e label| assert

f assertion (cut)| check
f assertion| assume

f assumption| absurd absurdity

| any ^ non-determinism
d ::= x : o/, : : : , x : o/ = {f } e {q} function body
o/ ::= ff type variable|

s r, : : : , r o/, : : : , o/ type application|
x : o/ ! ^ function type
^ ::= {f } o/ ffl {q} specification

ffl ::= reads r, : : : , r writes r, : : : , rraises

E, : : : , E effect
q ::= f, E ! f, : : : , E ! f postcondition

Figure 2.3: Abstract syntax of WhyML.

2.5. PROGRAMS 29

A while loop is syntactic sugar for an infinite loop where the predefined exceptionExit is used to exit:

while e1 do e2 invariant I variant t def=try loop if

e1 then e2 else raise Exit invariant I variant twith Exit ! ()

Within an infinite loop, the variant is some syntactic sugar for an assertion placedat the end of the loop body:

loop e invariant f variant t def= loop L : e; assert t OE at t L invariant f
A fresh label L is used to denote the starting point of the loop body, in order tostate that the variant is decreasing (OE is the order relation associated to the variant

t). Variants for recursive functions is also syntactic sugar. We use the function
preconditions to insert the corresponding assertions. We proceed in two steps. First,we save the value of the variants at the function entry points, in local variables

vi:

let rec f1 ~x1 variant t1 = e1and

f2 ~x2 variant t2 = e2
:::and

fn ~xn variant tn = enin
e

def=

let rec f1 ~x1 = let v1 = t1 in e1and

f2 ~x2 = let v2 = t2 in e2
:::and

fn ~xn = let vn = tn in enin
e

Then we type each function body ei within an environment where function fj hastype

fj : ~xj ! {tj( ~xj) OE vi ^ pj}o/jfflj{qj}
where OE is the order relation associated to all variants ti (it must be unique).Finally, lazy operators && and || are syntactic sugar for conditional constructs.

e1 && e2 def= ( let x1 = e1 in andb x1 e2 if e2 is pure,if e1 then e2 else false otherwise.
We make a particular case when e2 is pure (that is, without any effect other thanread effects) to limit the number of conditional constructs. This helps in getting
smaller and more intuitive verification conditions. Operator || is interpreted in asimilar way.

Type Checking

The purpose of Why3 type checking is three-fold:
1. to perform traditional ML-like type checking;

30 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3

2. to infer effects;
3. to exclude aliases.
Regarding point 1, we use a standard W algorithm [77]. We avoid the issue ofpolymorphic references as follows: types are not generalized at local binders and

global binders only bind values, hence the value restriction applies [102]. Point 2is also standard: it amounts to compute the sets of regions possibly accessed and
possibly modified for each program sub-expression, as well as the set of possiblyraised exceptions. It follows Talpin and Jouvelot's type and effect discipline [96,
97] in a straightforward way. The resulting effects are used to compute weakestpreconditions.

Point 3 is the detection, and then rejection, of possible region aliases. Thisis a requirement for the weakest precondition calculus to be sound, as it assumes
distinct regions to denote distinct memory cells. There are two different ideas.First, functions are polymorphic w.r.t. regions, exactly as they are polymorphic
w.r.t. types. For instance, a function that swaps the contents of two references hasa type such as

swap : 8r1, r2: 8ff: ref r1 ff ! ref r2 ff ! unit
(where we omit annotations for clarity). When we implement and prove correct afunction with such a type, we assume regions

r1 and r2 to be distinct. Therefore,when we apply this function to two references, we check that the corresponding

references are indeed distinct. As a consequence, an expression such as

let r = ref 0 in swap r r
is ill-typed. A function taking twice the same reference as argument should ratherhave a type such as

swap' : 8r: 8ff: ref r ff ! ref r ff ! unit:
However, to keep the system as simple as possible (but no simpler), regions arehidden from the user. To make this possible, a compromise is made. First, regions
provided by function arguments must all be distinct. This rules out functions suchas swap' above, but they are of poor interest anyway. Second, regions returned
as part of the function result must be freshly allocated, i.e., allocated during thefunction call. This rules out functions such as the identity over references:

id : 8r: 8ff: ref r ff ! ref r ff:
Again, such functions are seldom useful. These two conditions are ensured by theWhy3 type checker.

2.5. PROGRAMS 31
Weakest Preconditions

Given a program expression e, a postcondition f , and ~q a set of exceptionalpostconditions

E1 ! f1, : : : , En ! fn, we define the weakest precondition wp(e, f, ~q)recursively over the structure of

e.

Purely Applicative Constructs. The case of a program variable is immediate:

wp(x, f, ) def= f [result  dxe],
and so is the case of a logical term:

wp(t, f, ) def= f [result  t]:
The weakest precondition of a pattern matching is a mere swapping of the twoconstructs:

wp(match x with p1 ! e1, : : : , pn ! en end, f, ~q) def=match

x with p1 ! wp(e1, f, ~q), : : : , pn ! wp(en, f, ~q) end:

Of course, this is that simple since we have pattern matching in the logic as well.Getting rid of it is left to Why3's back end (see Section 2.4).

Sequence and Conditional. Sequence and conditional follow the standard rules. Thesequence is here generalized into a let binding:

wp(let x = e1 in e2, f, ~q) def= wp(e1, wp(e2, f, ~q)[dxe  result], ~q):
In the particular case of a true sequence e1; e2, that is when x does not appear in
e2, it simplifies as expected:

wp(e1; e2, f, ~q) def= wp(e1, wp(e2, f, ~q), ~q):
When e1 and e2 cannot raise an exception, it simplifies even further, to the tradi-tional rule

wp(e1; e2, f ) def= wp(e1, wp(e2, f )):
The conditional rule is also standard:

wp(if e1 then e2 else e3, f, ~q) def= wp(e1, if result then wp(e2, f, ~q) else wp(e3, f, ~q), ~q):
However, in the particular case where e2 and e3 are both logical terms or variables,we avoid the duplication of

f using a conditional term:

wp(if e1 then e2 else e3, f, ~q) def= wp(e1, f [result  if result then e2 else e3], ~q):

32 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3
Assertions. Rules for assertions are straightforward to derive. An assertion intro-duced with assert accumulates to the postcondition:

wp(assert f1, f2, ) def= f1 ^ f2:
In practice, such a conjunction is tagged so that a later split of this formula willproduce

f1 and f1 ) f2, instead of merely f1 and f2. This way, f1 acts as a logicalcut, which is the purpose of assert. A variant of assert, called check, results into

a symmetric conjunction. An assertion introduced with assume is turned into anhypothesis:

wp(assume f1, f2, ) def= f1 ) f2:
Finally, the absurd statement turns the whole weakest precondition into falsity:

wp(absurd, , ) def= false:

Labels. When a label is crossed, we simply erase the corresponding label withinannotations. Thus we set

wp(L : e, f, ~q) def= wp(e, f, ~q)[at t L  t]
where the substitution ranges over all occurrences of terms at t L in the weakestprecondition.

Exceptions. Let ~q = E1 ! f1, : : : , En ! fn be the set of exceptional postcondi-tions. When considering the statement raise (

Ei e), we can always assume that Eibelongs to
~q -- otherwise we extend ~q with a true postcondition for Ei. Then wehave

wp(raise (Ei e), , ~q) def= wp(e, fi, ~q):
For a try with construct, we can assume that handled exceptions are E1, : : : , Em,with

m <= n, without loss of generality. Then we have

wp(try e with E1 x1 ! e1, : : : , Em xm ! em, f, ~q) def=wp(

e, f, (E1 ! wp(e1, f1, ~q), : : : , Em ! wp(em, fm, ~q), ~qm+1::n)):

A New Quantification. Before we go any further, we need to introduce a new op-eration. In traditional Hoare logic, anytime we need to generalize the weakest
precondition w.r.t. the state, we simply quantify over all the corresponding pro-gram variables. In our case, however, it is a slightly more complex operation. The
reason is that we allow sub-parts of data structures to be mutated. Therefore weneed to introduce new values for these sub-parts and then to reconstruct all the
values they belong to, as we informally explained earlier on page 26.

2.5. PROGRAMS 33

Let f be a formula (typically the weakest precondition computed so far) and
~r = r1, : : : , rn be a set of regions (typically the writes effect of some program sub-expression). We define the formula r

~r: f as follows. Let v1, : : : , vm be the set offree variables of
f whose types contain at least one region from ~r. Then we set

r~r: f def= 8~r: let v1 = update v1 ~r in

: : :let

vn = update vn ~r in
f

The value for each variable vi is rebuilt using function update. This function de-composes the old value and rebuilds its fields one by one:

update v ~r def= match v with

C y1 : : : ym ! C (update1 y1 ~r) : : : (updatem ym ~r):

C is the constructor for the type of v, which exists since v contains some regions inits type. Function update

i rebuilds the value yi for field i, as follows:

updatei yi ~r def= 8?!?:

rj if rj is the region for field i,
yi if ~r = ;,update

yi (~r " reg(yi)) otherwise.

Here reg(yi) stands for the set of regions occurring in the type of yi. Here is anexample. Let us assume the declaration of two record types array and state as

follows:

type array r ff = {mutable elts : map int ff}type state

r1 r2 = {a : array r1 bool; b : array r2 real}

Let s be a variable of type state r1 r2 and f a formula. We assume that s is theonly variable from

f whose type contains r1. Then

rr1: f = 8r1 : map int bool:let

s = match s with

C y1 y2 ! C (match y1 with C0 ! C0 r1) b in
f:

Loops. The rule for the infinite loop is defined as follows:

wp(loop e invariant I, , ~q) def= I ^ rwrites(e): I ) wp(e, I, ~q):
Note that the normal postcondition -- second argument of wp -- is of no use heresince the loop cannot terminate normally. On the contrary, one can exit the loop

34 CHAPTER 2. A TOOL FOR PROGRAM VERIFICATION: WHY3
using an exception, hence the use of ~q. The case of a for loop is rather tricky. Thatis the main reason why this construct is not defined as syntactic sugar.

wp(for x = x1 to x2 do e invariant I(x), f, ~q) def=

x1 > x2 ) f^
x1 <= x2 ) I(x1)^ rwrites(

e): 8i:x1 <= i <= x2 ) I(i) ) wp(e, I(i + 1), ~q)^

I(x2 + 1) ) f

First, it distinguishes the case where the for loop is not even entered, that is when
x1 > x2. Otherwise, I must hold initially (that is, I(x1)), must be preserved by e(that is,

I(i) must imply I(i + 1), informally speaking), and must imply f on loopexit. The last two conditions must hold within a fresh state, hence the r operator.

Note that the latter condition mentions I(x2 + 1), not I(x2). Indeed, there are
x2 - x1 + 1 different states in a for loop and we chose the convention that I(x) refersto the beginning of the loop body, as in other loops.

Function Call. A function call is interpreted using the non-determinism constructany. The expression any {

p} o/ ffl {q} stands for any computation with precondition
p, result of type o/ , effect ffl, and postcondition q. When computing the weakestprecondition, we may assume that both postconditions are referring to the same set

of exceptions, since we may always extend them using true postconditions. Thenwe have

wp(any {f0} o/ ffl {f1, ~q1}, f2, ~q2) def=

f0 ^ rwrites(ffl): (8r : o/: f1 ) f2) ^ ^

i (8

r : o/i: q1,i ) q2,i)

where o/i is the type of the value carried by exception Ei. There is only one quantifi-cation rwrites(

ffl), for both normal and exceptional postconditions. We do not makea distinction between effects for normal output and effects for exceptional output.

Function Definition. The weakest precondition for an anonymous function onlyamounts to verifying that the definition is correct:

wp(fun d, , ) def= correct(d)
Indeed, the result of this expression being a function, it cannot appear in the post-condition. Predicate correct is defined below. On the contrary, recursive functions

are necessarily bound into an expression. Thus the weakest precondition containstwo parts:

wp(letrec d1, : : : , dn in e, f, ~q) def= wp(e, f, ~q) ^ ^

i correct(

di)

2.5. PROGRAMS 35
The predicate correct expresses than a function definition satisfies all its annotations.It is defined using predicate wp:

correct(x1 : o/1, : : : xn : o/n = {p} e {f, ~q}) def=8

x1, : : : , xn: rwrites(e) [ reads(e): p ) wp(e, f, ~q)

There is a subtle point here: contrary to what we have done so far for loop, for, andany, we also quantify over reads(

e). It expresses that such a function may be usedin states that are possibly different from the one where it is declared.

Top-level Declarations. In Why3, top-level declarations are limited to declarationsand function definitions. A declaration induces no verification condition. A function
definition is either let d or letrec d1, : : : , dn and is translated into a verificationcondition using predicate correct, as we did above for local definitions. Finally,
it is turned into a closed formula using universal quantification over all programvariables.

3
Case Studies in Program Verification
Over the past years, I have used the Why tool to verify several dozens of pro-grams. All these proofs can be obtained from Why3's on-line "gallery of verified
program", at why3.lri.fr. There are also part of Why3's source distribution. Thisincludes, though not exhaustively:

- historical examples, such as proofs from Turing's, Floyd's, and Hoare's pa-pers [101, 49, 53] and McCarthy's 91 function [71];
- examples from books: binary search from Bentley's Programming Pearls [10],Knuth's prime numbers algorithm from The Art of Computer Programming [60],

all program proofs from Software Foundations [86];- challenges in program verification: all problems from VSTTE'10 competition [91], some problems from VACID-0 [66];- several algorithms: Bresenham line drawing, Knuth-Morris-Pratt string searching, Floyd's "tortoise and hare", Levenshtein distance, Dijkstra's Dutch na-tional flag, Dijkstra's shortest path;
- several sorting algorithms: mergesort, selection sort, insertion sort, and quick-sort;
- mathematically oriented programs: Fibonacci numbers (in linear and loga-rithmic time), fast exponentiation (recursive and iterative), greatest common

divisor (with Bezout coefficients), N -queens puzzle (counting the number ofsolutions [42]);
- data structures: sparse arrays, same fringe problem;This chapter presents a selection of these proofs. It intends to strengthen the
discussion of the previous chapters. Additionally, it can serve as a companion toWhy3's manual, which already contains a detailed description of the solutions for
the five VSTTE'10 verification problems, and to some of my publications [39, 45].

37

38 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION
3.1 Termination

We focus here on some program verification which involve tricky terminationproofs.

McCarthy's 91 Function

This famous function was precisely introduced as a challenge for terminationproofs. It is defined over integers by

f (n) = ( n - 10 if n > 100,f (f (n + 11)) otherwise.
We can show that it returns 91 as soon as n <= 101, hence its name. In Why3, wedefine it recursively, as above. To prove it terminates, we have to provide a variant.
Here, it is as simple as

101 - n

but proving that it decreases for each function call is tricky. Indeed, it actuallyrequires us to also prove a postcondition which states how the return value relates
to n. Thus we prove both termination and behavior at the same time.

let rec f91 (n:int) : int variant { 101-n } ={ }

if n <= 100 thenf91 (f91 (n + 11))
elsen - 10
{ (n <= 100 and result = 91) or (n >= 101 and result = n - 10) }
The resulting weakest precondition is discharged in no time by any SMT solver --which means, in our case, either Alt-Ergo, CVC3, or Z3.

Let us now consider a non-recursive implementation of McCarthy's 91 function 1.We do not need to make a full stack explicit. We can simply remember how many
calls to f are still to be performed. Let e be that number, which is initially set to 1.If

n > 100 we simply subtract 10 from n and decrement e by 1, since we have justperformed one call to

f . Otherwise, we add 11 to n and increment e by 1, whichprecisely mean two more calls to

f since we just did one. The pseudocode reads asfollows:

1. The following code was suggested by Judica"el Courant.

3.1. TERMINATION 39

e  1while

e > 0 doif
n > 100 then

n  n - 10
e  e - 1else

n  n + 11
e  e + 1return n

Proving the termination of this loop is at the same time simpler and more difficultthan proving the termination of the recursive function. It is simpler because we
do not need to say anything about the behavior of the code. But it is also moredifficult since the variant is now a pair, namely

(101 - n + 10e, e):
It is ordered lexicographically, where the first and second components are bothcompared using the usual order relation over natural integers. This order relation
over pairs of integers is defined in Why3's standard library and we import it:

use import int.Lex2
We could stop here. But exactly as the recursive implementation above was achallenge for termination, this non-recursive implementation looks appealing for a

proof of correctness. It is not completely trivial why it indeed computes f (n). Theloop invariant is

f e(n) = f (n0)
where n0 stands for the initial value of n. Therefore, when we exit with e = 0, wehave

n = f (n0) and we return it. To express this invariant, we first introduce thelogic function

f .

function f (x: int) : int = if x >= 101 then x-10 else 91
It is not recursive but instead captures the extensional meaning of McCarthy's91 function. Then we define

f k(x). Such a logical function cannot be definedrecursively over
k, since it is not structural (see page 18). So we axiomatize it.

function iter int int : intaxiom iter 0: 8 x: int. iter 0 x = x

axiom iter s: 8 k x: int. 0 < k ! iter k x = iter (k-1) (f x)
More generally, the standard library contains a theory int.Iter that axiomatizesthe iteration of any function. So we can replace the three declarations above with

a theory cloning:

40 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION
use import module ref.Refuse import int.Lex2
function f (x: int) : int = if x >= 101 then x-10 else 91
clone import int.Iter with type t = int, function f = f
let f91 nonrec (n0: int) ={ }

let e = ref 1 inlet n = ref n0 in
while !e > 0 doinvariant { e >= 0 and iter e n = f n0 }

variant { (101 - n + 10 * e, e) } with lexif !n

> 100 then beginn := !n - 10;

e := !e - 1end else begin
n := !n + 11;e := !e + 1
enddone;
!n{ result = f n0 }

Figure 3.1: Non-recursive implementation of McCarthy's 91 function.

clone import int.Iter with type t = int, function f = f
The code and its specification are given in Fig. 3.1. As for the recursive version,the weakest precondition is easily discharged by all SMT solvers.

Tortoise and Hare Algorithm

The tortoise and hare algorithm is a cycle detection algorithm. It appears involume 2 of The Art of Computer Programming [61, ex. 6 p. 7] and is credited to
Robert Floyd. Let f be a function over a type T and x0 a value of type T . Wecan define an infinite sequence with

xn+1 = f (xn). Clearly, the sequence (xn) hasfinitely many distinct values if and only if it becomes cyclic at some point. The

purpose of Floyd's algorithm is precisely to detect such a cycle. It is extraordinarily

3.1. TERMINATION 41

type tfunction f t : t
function x0: tclone import int.Iter with type t = t, function f = f
function x (i: int): t = iter i x0
function mu : intfunction lambda : int

axiom mu range: 0 <= muaxiom lambda range: 1 <= lambda
axiom distinct:8 i j: int. 0 <= i

< mu+lambda ! 0 <= j < mu+lambda !i 6= j ! x i 6= x j

axiom cycle: 8 n: int. mu <= n ! x (n + lambda) = x n

Figure 3.2: Tortoise and Hare Algorithm: Assumptions.

simple:

T, H  f (x0), f (f (x0))while

T 6= H do
T, H  f (T ), f (f (H))

That is, tortoise T advances at speed 1, while hare H advances at speed 2, andwe stop whenever they are equal. If so, we have detected a cycle. Otherwise, the

algorithm loops forever and there is no cycle. The beauty of this algorithm is thatit runs in constant space. Besides, it has several meaningful applications. For
instance, it can be used to check whether a singly linked list is cyclic -- is that case,it will even stop in both cases, since either it detects a cycle or reaches the null
pointer.Let us assume that there is a cycle and let us prove that Floyd's algorithm terminates. We start with a bunch of assumptions, gathered in Fig. 3.2. We introducefunction

f and the infinite sequence (xn), reusing library int.Iter for that purpose.The existence of a cycle means that there exist smallest integers

u >= 0 and * >= 1such that
xu = xu+*. It is convenient to introduce u and * as constants -- this isnothing more than skolemization. The properties of

u and * are decomposed intofour axioms. Instead of the characterization above, we adopt Knuth's one, which is

equivalent: values x0, x1, : : : , xu+*-1 are all distinct, and xn+* = xn for n >= u.The challenge is obviously to prove the termination, i.e., to figure out a variant
for the while loop. Actually, we are even going to prove that it runs in time O(u+*).The code is given in Fig. 3.3. The obvious part of the loop invariant states that

42 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION
the tortoise is some xt while the hare is x2t. Moreover, we have checked so far that
xi 6= x2i for 1 <= i < t. Finally, we add t <= u + * to the invariant, which bounds therunning time.

The termination argument is the following: once it is inside the cycle, the tortoisecannot be overtaken by the hare. Thus the distance between the hare and the
tortoise decreases. We have to turn that into a variant, which requires some care.First, we introduce dist

i j, the distance between xi and xj. Since this it is a partialfunction, we only define it for

u <= i, j. Second, we define a custom order relation,rel. It compares two "tortoises" and requires them to be consecutive values

xi and
xi+1 with i <= u + *. Additionally, it requires the distance between x2i+2 and xi+1to be smaller than the distance between

x2i and xi, whenever the two tortoises arewithin the cycle, that is
i >= u. Then the variant is simply the tortoise, tortoisesbeing compared with rel.

The proof decomposes into four goals: one lemma to prove that xn+k* = xnwhenever

n >= u, and three verification conditions (the loop invariant is initialized,the loop invariant is preserved, and the variant decreases). Apart from the loop

invariant initialization, which is discharged automatically, the remaining goals aredischarged interactively using Coq. Slightly more than 80 lines of tactics are needed.

It is worth pointing out that, beside termination, we have also proved that thereis no more than

u + * + 1 loop steps.

3.2 Mathematics
Fibonacci Numbers

The sequence of Fibonacci numbers is the well-known integer sequence definedas follows: 8?!

?:

F0 = 0
F1 = 1
Fn = Fn-1 + Fn-2 for n >= 2:

In Why3, we cannot define a logical function recursively over integers. Thus it isaxiomatized.

theory Fibonacci "Fibonacci numbers"use export int.Int

function fib int : intaxiom fib0: fib 0 = 0
axiom fib1: fib 1 = 1axiom fibn: 8 n:int. n >= 2 ! fib n = fib (n-1) + fib (n-2)
end

3.2. MATHEMATICS 43

(* the minimal distance between x i and x j *)function dist int int : int
(* it is defined as soon as i,j >= mu *)axiom dist def: 8 i j: int. mu <= i ! mu <= j !

dist i j >= 0 ^x (i + dist i j) = x j ^
8 k: int. 0 <= k ! x (i + k) = x j ! dist i j <= k
predicate rel (t2 t1: t) =9 i: int. t1 = x i ^ t2 = x (i+1) ^ 1 <= i <= mu + lambda ^

(i >= mu ! dist (2*i+2) (i+1) < dist (2*i) i)
let tortoise hare () =let tortoise = ref (f x0) in

let hare = ref (f (f x0)) inwhile !tortoise 6= !hare do

invariant {9 t: int. 1 <= t <= mu+lambda ^

!tortoise = x t ^ !hare = x (2*t) ^8 i: int. 1 <= i

< t ! x i 6= x (2*i) }variant { !tortoise } with rel

tortoise := f !tortoise;hare := f (f !hare)
done

Figure 3.3: Tortoise and Hare Algorithm: Code.

Let us consider now the computation of Fn. A naive computation of Fn followingthe recursive scheme above would have time complexity

O(OEn) where OE = 1+p52 isthe golden ratio. A better solution is obviously to compute it iteratively, storing

two consecutive values Fk and Fk+1 in two variables a and b and repeating theassignment

a, b  b, a + b
which leads to a O(n) algorithm. There is actually an even better way to compute
Fn. It is based on the identity

1 11 0 !n =  Fn+1 Fn

Fn Fn-1 ! (3.1)

which holds for all n >= 0 if we set F-1 = 1. It is easily proved by induction over
n. Using a fast exponentiation algorithm, it is thus possible to compute Fn in time
O(log n). Let us prove the correctness of a program computing Fn along this idea.

44 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION

We do not need to compute the four coefficients of the matrix. Computing only
Fn and Fn-1 is enough since we have Fn+1 = Fn + Fn-1. Thus we define a recursivefunction logfib which takes

n as argument and returns the pair (Fn-1, Fn). Thepseudocode reads as follows:

logfib n =if

n = 0 then(1, 0)

elselet (

a, b) = logfib (n/2) inif
n mod 2 = 0 then(

a2 + b2, b(2a + b))else

(b(2a + b), (a + b)2 + b2)

We could specify this code with a postcondition which simply states that it returns(

Fn-1, Fn). But proving it correct would require proving identities relating F2k and
F2k-1 to Fk-1 and Fk. Instead we keep to equation (3.1), which only requires atrivial induction, and thus we choose the specification

let (a, b) = logfib n in  1 11 0 !

n =  a + b b

b a ! :

This is a natural cut, which makes the proof easier. We introduce a custom theoryfor 2 * 2 integer matrices in Fig. 3.4. It uses a record type for matrices. It only
contains the identity matrix and two operations: multiplication and exponentia-tion. The latter is obtained from a generic theory Exponentiation. This theory
includes the lemma xn+m = xn * xm, from which we can deduce the patterns for fastexponentiation, namely

x2n = xn * xn and x2n+1 = xn * xn * x.Fig. 3.5 gives the annotated code for logfib and the subsequent fibo function

which returns Fn as the second component of logfib n. In the middle, we insertthe lemma corresponding to equation (3.1). It is limited to the first column of the
matrix. It is indeed enough for the induction to be carried out, since

1 11 0 ! *  Fn+1 ?

Fn ? ! = 

Fn+2 ?
Fn+1 ? ! :

Therefore we avoid specifying F-1 = 1.Coq is needed to prove the postcondition of logfib (in the non-trivial case), as
well as the lemma fib m. The remaining goals are discharged automatically.

3.2. MATHEMATICS 45
theory Mat22 "2x2 integer matrices"use import int.Int

type t = {| a11: int; a12: int; a21: int; a22: int |}
function id : t = {| a11 = 1; a12 = 0; a21 = 0; a22 = 1 |}
function mult (x: t) (y: t) : t ={| a11 = x.a11 * y.a11 + x.a12 * y.a21;

a12 = x.a11 * y.a12 + x.a12 * y.a22;a21 = x.a21 * y.a11 + x.a22 * y.a21;
a22 = x.a21 * y.a12 + x.a22 * y.a22; |}
clone export int.Exponentiationwith type t = t, function one = id, function (*) = mult
end

Figure 3.4: A theory for 2 * 2 integer matrices.
Knuth's Program for Prime Numbers

Knuth's program for prime numbers [60, p. 147] was discussed in the introduc-tion (see page 5) as an example of a program whose safety proof is difficult. Knuth's

code is given in left of Fig. 3.6. It fills the array p with the first 500 primes. Notethat

p is indexed from 1, not 0. Variables are used as follows: j counts the numberof primes found so far;

n stands for the candidate for next prime; k scans p to usepreviously computer primes.

We make a few changes with respect to Knuth's code. First, the array is indexedfrom 0. Second, we compute the first

m prime numbers, for some arbitrary m >= 2.Last, we make a slight change in the code flowchart. Knuth's flowchart is well suited

for assembly language, but not for a structured language. Thus we turn the codeinto a for loop on

j and a local recursive function test. The resulting pseudocodeis given in right of Fig. 3.6.

The notions of divisibility (predicate divides) and of prime number (predicateprime) are imported from Why3's standard library. Fig. 3.7 contains additional
material for the specification. Predicate first primes p u states that p[0], : : : , p[u-1] contains the first

u prime numbers. It makes use of predicate no primes in l u,which states that there is no prime number between

l and u; it will be convenientlyreused in the code's annotation. Bertrand's postulate is introduced as an axiom --

we do not intend to prove it.The annotated code is given in Fig. 3.8. Most of the specification is obvious.
The termination of the recursive function test is ensured using a pair of integers

46 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION
module FibonacciLogarithmicuse import Fibonacci

use import int.EuclideanDivisionuse import Mat22

function m1110 : t = {| a11 = 1; a12 = 1;a21 = 1; a22 = 0 |}
let rec logfib n variant { n } ={ n >= 0 }

if n = 0 then(1, 0)
else beginlet a, b = logfib (div n 2) in

let c = a + b inif mod n 2 = 0 then

(a*a + b*b, b*(a + c))else
(b*(a + c), c*c + b*b)end
{ let a, b = result inpower m1110 n = {|a11=a+b; a12=b; a21=b; a22=a|} }

lemma fib m :8 n: int. n >= 0 !

let p = power m1110 n in fib (n+1) = p.a11 and fib n = p.a21
let fibo n ={ n >= 0 }

let _, b = logfib n in b{ result = fib n }
end

Figure 3.5: A program computing Fn in time O(log n).

3.2. MATHEMATICS 47

p[1]  2; j  1; n  3

j  j + 1; p[j]  n

test j = 500
n  n + 2; k  2

test p[k]|n
test n=p[k] <= p[k]

k  k + 1

stop

p[0]  2; p[1]  3; n  5for

j = 2 to m - 1 dolet rec test

k =if
n mod p[k] = 0 then

n  n + 2; test 1else if

n/p[k] > p[k] thentest (

k + 1)in

test 1; p[j]  n; n  n + 2

Figure 3.6: Knuth's program for prime numbers: original assembly code (left) andequivalent structured code (right).

predicate no prime in (l u: int) =8 x: int. l

< x < u ! not (prime x)

(* p[0]...p[u-1] are the first u prime numbers *)predicate first primes (p: array int) (u: int) =

p[0] = 2 ^(* sorted *)
(8 i j: int. 0 <= i < j < u ! p[i] < p[j]) ^(* only primes *)
(8 i: int. 0 <= i < u ! prime p[i]) ^(* all primes *)
(8 i: int. 0 <= i < u-1 ! no prime in p[i] p[i+1])
axiom Bertrand postulate:8 p: int. prime p ! not (no prime in p (2*p))

Figure 3.7: Knuth's program for prime numbers: specification.

48 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION

let prime numbers (m: int) ={ m >= 2 }

let p = make m 0 inp[0]  2;
p[1]  3;let n = ref 5 in (* candidate for next prime *)
for j = 2 to m - 1 doinvariant { first primes p j ^

p[j-1] < !n < 2*p[j-1] ^ odd !n ^ no prime in p[j-1] !n }let rec test (k: int) variant { (2*p[j-1] - !n, j - k) } with lex =
{ 1 <= k < j ^ first primes p j ^p[j-1]

< !n < 2*p[j-1] ^ odd !n ^ no prime in p[j-1] !n ^8 i: int. 0 <= i

< k ! not (divides p[i] !n) }if mod !n p[k] = 0 then begin

assert { not (prime !n) }; n += 2; test 1end else if div !n p[k]

> p[k] thentest (k + 1)

elseassert { prime !n }
{ p[j-1] < !n ^ prime !n ^ no prime in p[j-1] !n }in
test 1;p[j]  !n;
n += 2done;
p{ first primes result m }

Figure 3.8: Knuth's program for prime numbers: code.
ordered lexicographically. Indeed, either n is increased and k is reset to 1, or k isincreased and

n is not modified. A key annotation to establish the validity of thisvariant is

p[j-1] < !n < 2*p[j-1].
That is where Bertrand's postulate is needed: when n is increased, the right in-equality still holds, since it would otherwise contradict Bertrand's postulate. Thus
we can use 2*p[j-1] - !n as first component in the variant.Five goals require interactive proof using Coq (one lemma and four verification conditions). The remaining goals (30 verification conditions) are dischargedautomatically.

3.3. DATA STRUCTURES 49
3.3 Data Structures
Same Fringe

"Same fringe" is a famous problem among functional programmers. There is noreference for this problem; it's simply part of folklore. The problem can be stated

as follows:

Given two binary trees,do they contain the same elements when traversed in order?

Here we assume binary trees with elements stored at inner nodes. (The problemwould be equally interesting with elements stored at leaves.) Here is an example of
two trees with different shapes but the same list of elements, namely 1,3,4,5,8.

8
3
1 5

4

4
1

3

8
5

The nature of the elements is of no importance here. We make no assumption aboutit 2, using an uninterpreted type elt for elements:

type elttype tree =

| Empty| Node tree elt tree

On way to specify the problem is to turn the two trees into lists and then comparethem. Turning a tree into a list is defined recursively over the structure of the tree,
with the help of list concatenation:

function elements (t : tree) : list elt = match t with| Empty ! Nil

| Node l x r ! elements l ++ Cons x (elements r)end

Solving the same fringe problem is another matter. If we naively build the two listsand then compare them, it is likely to be inefficient, from both space and time point
of view. Ideally, we would like to come up with a O(min(n, m)) solution, where nand

m are the sizes of the two trees. Though it can be done, we are slightly less

2. Though, it can be pointed out that when elements are equipped with a total order andsorted from left to right, such trees are binary search trees. Thus the same fringe problem is that of
deciding whether two binary search trees contain the same elements, a problem of genuine interest.

50 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION
ambitious here and we propose a O(max(n, m)) solution. The idea is to considerthe leftmost branch of each tree, as a list ordered from bottom up (its head is the
leftmost element). Each element on this branch comes with its associated rightsubtree, which may be empty. This can be depicted as follows:

x1

x2

...

xn

t1

t2

tn

We call such a list an enumerator. Building it is easy: we simply descend the leftbranch until we reach the empty tree. On the example above, the two enumerators
are the following:

1

3

8

5
4

1

4

3

8
5

The purpose of enumerators is to propose an easy and lazy comparison of the trees: iftheir heads differ, we are done; otherwise, we remove it and prepend the enumerator
for its right subtree. Enumerators correspond to the following data type:

type enum =| Done

| Next elt tree enum
Such a data structure is a degenerated form of Huet's zipper [55]. (There is no wayto descend to the right.)

Fig. 3.9 gives the full specification and annotated code for the same fringe prob-lem. This includes a function enum elements to turn an enumerator into a list, for
the purpose of specification, and three functions to solve the problem: enum to turn atree into an enumerator; eq enum to compare enumerators; and finally same fringe

3.3. DATA STRUCTURES 51

type elttype tree =

| Empty| Node tree elt tree
function elements (t : tree) : list elt = match t with| Empty ! Nil

| Node l x r ! elements l ++ Cons x (elements r)end
type enum =| Done

| Next elt tree enumfunction enum elements (e : enum) : list elt = match e with
| Done ! Nil| Next x r e ! Cons x (elements r ++ enum elements e)
endlet rec enum t e variant { length (elements t) } =

{ }match t with
| Empty ! e| Node l x r ! enum l (Next x r e)
end{ enum elements result = elements t ++ enum elements e }
let rec eq enum e1 e2 variant { length (enum elements e1) } ={ }

match e1, e2 with| Done, Done !

True| Next x1 r1 e1, Next x2 r2 e2 !
x1 = x2 && eq enum (enum r1 e1) (enum r2 e2)| _ !
Falseend
{ result=True $ enum elements e1 = enum elements e2 }let same fringe t1 t2 =
{ }eq enum (enum t1 Done) (enum t2 Done)
{ result=True $ elements t1 = elements t2 }

Figure 3.9: Solution to the same fringe problem.

52 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION
int binary search(int* t, int n, int v) {int l = 0, u = n-1;

while (l <= u) {int m = (l + u) / 2;

if (t[m] < v)l = m + 1;
else if (t[m] > v)u = m - 1;
elsereturn m;
}return -1;
}

Figure 3.10: Binary search within a sorted array (C code).

to solve the problem. Thanks to functions elements and enum elements, the spec-ification is obvious. Note the use of list lengths to ensure termination.

The very nice thing about this proof is that it is entirely automated: Alt-Ergosucceeds in discharging all verification conditions, in no time. Though it looks like
such a proof requires induction, it is here performed implicitly, hidden within theverification of both recursive functions enum and eq enum. This is induction without
induction, somehow.

3.4 Using Why3 as an Intermediate Language

As explained in Section 2.1, Why has been used for years at ProVal as anintermediate language to verify C and Java programs. This section sketches the
main ideas of this process.Following Jon Bentley, we use the challenge of binary search as an example [10].
Let us consider a C function, binary search, which looks for a given integer valuewithin a sorted array. Its code is given in Fig. 3.10. The three arguments are t, the
array in which the search is performed, n, the size of this array, and v, the valuewhich is searched for.

This C program contains two elements which are not part of the Why3 language:
1. the pointer type int* and the associated operation t[m];
2. the presence of a return inside a while loop.
Since the code is actually not performing any pointer arithmetic, one could modelthe type int* directly as an array. However, we choose to keep to a low-level model

3.4. USING WHY3 AS AN INTERMEDIATE LANGUAGE 53
type pointertype memory
function get memory pointer int : intval mem : memory ref

Figure 3.11: A minimal memory model.
of pointers, with more complex programs in mind. Thus we introduce a Why3 typefor C pointers of type int*:

type pointer
We introduce another type, memory, for the state of the memory:

type memory
Then we can introduce a get operation to access memory with a given pointer:

function get memory pointer int : int
If m is some given memory state, p a pointer and i an integer, then get m p iaccesses m at address p+i. We assume here that the memory is only word-addressed,

i.e. we only have pointers of type int*. A global reference mem contains the currentstate of memory:

val mem : ref memory
It completes our first memory model, which is summarized in Fig. 3.11.Translating function binary search in this memory model is straightforward:

t becomes an argument of type pointer and expression t[m] is translated intoget !mem t m. Of course, the memory model could be simplified even further. One
could simply declare a function function t int : int, suppress argument t andtranslate t[m] into t m. Though, as explained above, we want to keep to a realistic
memory model. If the memory was to be mutated (which is not the case in thisprogram), we would introduce another operation

function set memory pointer int int : memory
and we would translate a C assignment into a mutation of reference mem.The second obstacle is the presence of a return statement inside the while loop.

To translate it, we introduce a Why3 exception carrying an integer value:

exception Return int
Then we translate return m into raise (Return int m). The whole while loop issurrounded with a try with, as follows:

54 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION

let binary search (t:pointer) (n:int) (v:int) =try

...with Return r !
rend

The remaining of the translation is straightforward. Local variables l, u and m aretranslated into Why3 local references, since the C operator & is not used to obtain
their addresses. For variable m, we can even use a non-mutable variable since it isnot mutated in the C code.

We still need to give the function its specification. The precondition requiresthe array to be sorted.

{ 8 k1 k2:int.0 <= k1 <= k2 <= n-1 ! get mem t k1 <= get mem t k2 }
The loop invariant maintains inequalities over l and u and the crucial property thatv, if it occurs in t[0..n-1], then necessarily occurs in t[l..u].
{ invariant 0 <= l and u <= n-1 and8 k:int. 0 <= k

< n ! get(mem,t,k) = v ! l <= k <= u }

To prove termination, we simply add the variant u-l. Finally, the postconditionstates soundness and completeness properties, that is, either the result is nonnegative and v occurs in t at this position, or the result is -1 and v does notoccur in t.

{ (result >= 0 and get mem t result = v) or(result = -1 and 8 k:int. 0<=k

<n ! get mem t k 6= v) }

Function binary search is given Fig. 3.12. It is proved correct automatically.Let us make this proof slightly more realistic by adding array bound checking.

To do this, we first introduce the notion of block size in our memory model:

function block size memory pointer : int
In this new model, each pointer points to the beginning of a block, whose size isgiven by function block size. Now, instead of accessing memory with function

get inside the program, we will use instead a function with a precondition:

val get : p:pointer ! ofs:int !{ 0 <= ofs

< block size mem p }int reads mem

{ result = get mem p ofs }
In the Why3 code for function binary search, we replace the two occurrences ofget !mem t m with get t m, getting a a new verification condition for each. Both

3.4. USING WHY3 AS AN INTERMEDIATE LANGUAGE 55
exception Return int
let binary search (t : pointer) (n : int) (v : int) ={ 8 k1 k2:int.

0 <= k1 <= k2 <= n-1 ! get mem t k1 <= get mem t k2 }try
let l = ref 0 inlet u = ref (n-1) in
while !l <= !u doinvariant { 0 <= l and u <= n-1 and

8 k:int. 0 <= k < n ! get mem t k = v ! l <= k <= u }variant { u-l }
let m = div (!l + !u) 2 inif get !mem t m

< v then l := m + 1else if get !mem t m

> v then u := m - 1else raise (Return m)

done;raise (Return (-1))
with Return r !r
end{ (result >= 0 and get mem t result = v) or

(result = -1 and 8 k:int. 0<=k<n ! get mem t k 6= v) }

Figure 3.12: Function binary search translated to Why3.

amount to showing

0 <= (l + u) / 2 < block size mem t:
To be able to discharge them, we need to add an extra precondition to functionbinary search, which states that n is no larger than the block size:

let binary search (t : pointer) (n : int) (v : int) ={ n <= block size mem t and ... }

...
All VCs are discharged automatically.Finally, let us make this proof even more realistic by showing the absence of

arithmetic overflow in this C code. For simplicity, we consider here that C type intstands for 32 bit integers. We introduce a new Why3 type to model this C type.

type int32
The key idea for reasoning about fixed size integers is the following:

56 CHAPTER 3. CASE STUDIES IN PROGRAM VERIFICATION

Specifications, and thus verification conditions, should only use mathe-matical integers, that is Why3's type int.
There are two reasons for this. First, we do not want to loose the ATPs capabilitiesregarding arithmetic, and this is the only arithmetic they are aware of. Second,
we cannot introduce partial function symbols in the logic, such as an addition over32 bit integers. If an addition is to appear within a specification, it should be the
usual addition over mathematical integers. Thus we introduce a function whichmaps values of types int32 to the corresponding value in type int.

function to int int32 : int
If the value of a C variable x is referred to within an annotation, we will writeto int x instead. More generally, we do so for any expression of type int32 occurring within an annotation. For instance, the loop invariant used to be

0 <= l and u <= n-1 and8 k:int. 0 <= k

< n ! get mem t k = v ! l <= k <= u

and now it is cluttered with to ints:

0 <= to int l and to int u <= to int n - 1 and8 k:int. 0 <= k

< to int n !to int (get mem t k) = to int v ! to int l <= k <= to int u

Note that the universal quantification 8 k is still over type int. To axiomatizeint32 and to int, we first introduce an axiom which defines the range of 32 bit
integers.

axiom int32 domain :8 x:int32. -2147483648 <= to int x <= 2147483647

Then we introduce an operation to build a value in type int32 from a value in typeint, provided it lies in the appropriate range.

val of int : x:int !{ -2147483648 <= x <= 2147483647 }

int32{ to int result = x }

To translate a C operation over 32 bit integers, say an addition such as

e1 +32 e2
we convert both operands to type int with to int, apply the corresponding oper-ation over type int, and then convert back to type int32 with of int:

of int (to int e1 + to int e2)

3.4. USING WHY3 AS AN INTERMEDIATE LANGUAGE 57
Of course, we perform this recursively in both e1 and e2, up to variables and con-stants. For instance, the initialization of u used to be

let u = ref (n - 1) in
and now reads as follows:

let u = ref (of int (to int n - to int (of int 1))) in
It is worth pointing out that writing to int (of int 1) instead of 1 enforces usto prove that constant 1 fits in the range of 32 bit integers. Even if obvious in this

case, absence of arithmetic overflows in constants are to be checked as well 3. It isclear from the two excerpts above that translating both specifications and programs
to this new model is quickly intractable in a manual process. Fortunately, this canbe easily automated during a translation from C to Why3, since the compiler has
access to abstract syntax trees fully decorated with types.When we try to prove this third model of the C program, we are left with one
unproved verification condition. It is related to the C statement

int m = (l + u) / 2;
and more precisely with the absence of arithmetic overflow in the computation of l+ u. Proving that it is greater or equal to -231 is easy (we know that both l and

u are non-negative at this point) but we cannot prove that it is smaller or equal to231 - 1. And indeed this is not provable: for a large enough array, we could have
for instance l = u = 230 and the addition would overflow. We already discussedthis famous bug and its possible fixes in the first chapter. For the fix

int m = l + (u - l) / 2;
all VCs are easily discharged automatically. Proving the other fix proposed byJoshua Bloch [12], namely int m = (l + u) >>> 2 in Java, is another matter.

Indeed, the addition may still overflow but the shift will restore a zero sign bit,ending up with the expected value. To prove such a fix correct, we can no longer
use the model above, since it does not allow overflows. A more elaborated modelwould be needed, for instance one that is faithful to the machine's 32-bit signed
arithmetic.
Realistic Memory Models. Tools such as Krakatoa or the Jessie plug-in of Frama-Care using even more complex memory models, to account for pointer arithmetic,
heap-allocated data, dynamic memory allocation, and so on. The basic idea is tomodel memory according to structure (or objects) fields, following an old idea by
Burstall [23]. At ProVal, this was first experimented in Krakatoa and Caduceus,and later refined using a static separation analysis of pointers [54], leading to the
intermediate language Jessie [73].

3. Most compilers report arithmetic overflows in constants.

4Perspectives
My research perspectives are split into general perspectives for deductive pro-gram verification (Sec. 4.1) and perspectives specific to the Why3 tool (Sec. 4.2).
4.1 Deductive Program Verification
Verification of Algorithms
Among many others, a legitimate goal for deductive program verification is thefollowing:

We should be able to pick up any algorithm from a standard textbookand prove it to be correct in time and space no larger than the textbook
proof.
Let us clarify what me mean in the statement above. First, writing the code itselfin a formal language suitable for program verification should be easy, at least no

more difficult than writing pseudo-code or code in some mainstream programminglanguage. It means that high-level programming constructs should be available,
as well as suitable libraries. Second, performing the proof should be of a similardifficulty to a pen-and-paper proof. Of course, we assume here that the proof
is done for the first time on both sides. Both kinds of proof require to exhibitinvariants. Then the proof process itself differs, but the time spent in writing down
a pen-and-paper proof should be comparable to the time spent in elaborating aformal proof, provided a reasonable amount of proof automation. The latter means
suitable decision procedures, e.g. for lists, finite sets, or reflexive transitive closure.With such tools being available, teachers and scientists should be able to ensure the
correctness of algorithms presented in lectures and research papers in a reasonableamount of time. As far as I am concerned, I have this perspective in mind. This
document has explained what I have done so far in that direction and I definitelyintend to make further progress in the future.

59

60 CHAPTER 4. PERSPECTIVES
Verification of Static Analysis Tools
Textbook algorithms are legitimate targets for deductive verification but they arenot real programs. This is somehow frustrating. Among all real programs, relevant

candidates for formal verification are static analysis tools: compilers, abstract in-terpretors, model checkers, slicers, etc. They are often used on critical code, and
thus are critical programs themselves. We already mentioned Leroy's verified com-piler CompCert, but most static analyzers are still waiting to be proved sound. I
think Why3 can be seriously considered to tackle such challenges: indeed, it fea-tures algebraic data types (for abstract syntax trees), inductive predicates (to define
semantics), relevant libraries (e.g. finite sets), and a nice combination of proof au-tomation and interactive proof.

Bootstrapping Verification Tools
Among static analysis tools are the verification tools themselves. They are obviouscandidate for being verified, as we want them to be sound in the first place. There

had been already several steps in that direction. For instance, Nipkow formalized thefirst 100 pages of Winskel's book using Isabelle/HOL [82]. This includes soundness
and relative completeness of Hoare logic, the latter using a weakest precondition cal-culus. Later, Yves Bertot conducted a similar experience in Coq, though introducing
new ingredients such as computational reflection and abstract interpretation [11].Along these lines, the undergoing Ph.D. thesis of Paolo Herms [51] at ProVal aims
at certifying the whole chain from C programs to verification conditions used inFrama-C.

However, formally verifying a tool such as Why3 is a lot of work and it is not thatobvious that we should do it right now. We should probably focus first on improving
the capacity of our tools before considering proving them. Who cares about asound, but useless tool? I remember a discussion with Natarajan Shankar during
my postdoc on a related topic: I was (very naively) comparing the relative soundnessof Coq and PVS and Shankar was replying that providing new, useful features to
PVS was more important than increasing the trust in PVS's own soundness. Today,I definitely agree with him.

4.2 Why3

We can already do a lot of program verification with Why3, as demonstratedin the previous chapter. Yet we have a lot of possible improvements in mind. We
discuss them here.

4.2. WHY3 61
Ghost Code. It is sometimes useful to insert additional code into a program for thesole purpose of writing its specification. Such a code is called ghost code. Ghost code
is similar to regular code: it is parsed, type checked, and turned into verificationconditions in the same way. The only constraint is that it does not interfere with
regular code, in the sense that we can remove ghost code without affecting thebehavior of the regular code. This does not prevent ghost code from performing side
effects, but it limits those side effects to ghost data. We have already demonstratedthe usefulness of ghost code in a paper describing the proof of a two line C program
computing the number of solutions to the N -queens problem [42].Somehow, ghost code is reminiscent of program extraction in Coq [78, 70]: sort
Set is used for programs and sort Prop for annotations, and the latter can be safelyremoved thanks to non-interference ensured by type checking. However, separating
regular and ghost code using types is not the only way to go. One can instead tagsome variables and functions as ghost. This is the way followed in Dafny [65] for
instance.

Program Execution. Currently, there is no way to execute Why3 code. We planto provide a translator from Why3 to OCaml, so that Why3 programs can be
executed interactively in the OCaml interpreter or compiled and linked into stan-dalone OCaml programs. OCaml is the target of choice since it provides almost
all WhyML features (exceptions, polymorphism, algebraic data types, records withmutable fields, etc.). Getting executable code from Why3 raises some interesting
issues:- First, there are several possible reasons for a Why3 code not to be executable:

it may refer to a program function which is declared but not defined (val);equivalently, it may use the non-deterministic program construct (any); finally, it may involve some logical term which is not executable. Thus theuser must be able to provide some OCaml implementation to fill the gaps.
An example is type int, which should be mapped to some implementation ofarbitrary-precision arithmetic. Such mapping could be done using a configuration file along the lines of prover drivers. But this could also be done byturning the whole code into an OCaml functor whose parameters correspond
to the missing implementations.- Second, since WhyML programs may involve arbitrary logic expressions, we
need to be able to translate them to OCaml as well. This is not alwayspossible. An obvious case is when a logic symbol is declared but not defined.
Even when a logic symbol is defined, it may not be possible to translate itto OCaml code. For instance, its definition may involve quantifiers or non
deterministic inductive predicates, which are not executable in most cases. Itmay also involve the equality predicate. If it is used on some algebraic data
type, we can use OCaml's polymorphic and structural equality. If it is used

62 CHAPTER 4. PERSPECTIVES

on some uninterpreted type, we cannot.- Finally, one can imagine turning annotations into code as well, to perform
run-time assertion checking. This implies turning logic expressions into code,which we just discussed. But this also implies saving state values in order
to interpret constructs old and at within annotations. This is a well-knownissue in the run-time assertion checking community (see for instance [62]).
Even if it is likely to be simpler in the case of Why3, due to the absence ofaliases, it remains a nontrivial problem.

Invariants. Currently, there is no easy way to associate an invariant to a givenWhy3 data type. For instance, we showed earlier how arrays are modeled in Why3
(see page 26), namely

type array ff model {| length: int; mutable elts: map int ff |}
but we have no way to state and prove that the length of any array is non-negative.We should be able to do that, however, since array is an abstract data type and

since the only operations returning arrays (make, append, etc.) all ensure that thereturned array has a non-negative length. Currently, the user has to insert suitable
preconditions regarding array lengths, when necessary. Said otherwise, we alreadyhave a mechanism for data abstraction so we should be able to give it a suitable
mechanism for data invariant.
Encapsulation. Our model of arrays is elegant and genuinely useful. However, ar-rays belong to the category of data structures that we do not implement in Why3;
we only give them a signature. On the contrary, there are many data structuresthat we can implement in Why3, such as hash tables, binary search trees, priority
queues, etc. For such data structures, we want to define a signature and an imple-mentation, separately, and then to confront them. For instance, the signature for
imperative sets of integers would look like

type t model {| mutable elts: set int |}val create: unit ! {} t { result.elts = empty }

val add: x: int ! s: t !{} unit writes s { s.elts = add x (old s.elts) }
...
and a possible implementation using hash tables would look like

type t = array (list int)let create () = Array.make 17 Nil

...
As usual in data abstraction, verifying the implementation against the signaturewill typically require invariants. In the example above, the invariant will relate the

4.2. WHY3 63
abstract set to the set of all elements appearing in the hash table. Currently, thereis no way to do that in Why3: we can define the signature, we can use it in some
client code, and, independently, we can implement a data structure, but we cannotverify the implementation against the signature -- unless we manually insert the
specifications from the signature into the implementation.
Module Cloning. As we showed earlier, theory cloning is a powerful concept toreuse specifications. It is natural to consider doing the same for modules. Module
cloning would be a way to get a new module by partially instantiating some unin-terpreted symbols from another module (types, constants, functions), reusing code,
specification, and proof in a single step. Somehow, module cloning is no differentfrom ML functors [68]; it is only easier to use and more flexible. As an example,
let us consider priority queues. A signature module can be designed as follows. Anabstract type for elements is declared

module Qtype elt
and is equipped with a total order

clone export relations.TotalOrder with type t = elt
The priority queue itself can be modeled as a list of elements, though it is not ofimportance here:

type pqueue model {| mutable elts: list elt |}
Then operations can be declared, such as create, push, pop, and so on. Once thesignature module Q is complete, module cloning would allow us to instantiate type

elt, and possible relation rel as well, to get priority queues specialized for thistype. For instance, priority queues containing integers could be used as easily as

clone import module Q with type elt = int, predicate rel = (<=)
A nice idea by Andrei Paskevich is that data encapsulation, as discussed in the previ-ous paragraph, could be implemented using module cloning: cloning the signature

module and instantiating its parameters with functions from the implementationmodule should generate the expected verification conditions.

Higher-Order Programs. WhyML is already so close to OCaml that it is natural toconsider going one step further and tackle higher-order programs. Actually, there is
already some limited support for higher-order functions in Why3. Indeed, the typechecker already allows function arguments with arbitrary types. Since function
types include specifications, one can perfectly write some code like

let f (g: n:int ! {} unit writes x { !x = old !x + n }) = ...

64 CHAPTER 4. PERSPECTIVES
(assuming some global reference x). After all, this is no different from having a globalfunction g in the context and then prove function f. However, it is already limited
when it comes to applying function f to some particular function: the argumentfunction must have exactly the type of g. Thus the following is legal

f (fun n:int ! {} x := !x + n { !x = old !x + n })
but applying f to a function with a different specification or effect is not. Obviously,we could relax this a little bit to allow a function with a weaker precondition,

a stronger postcondition, or a smaller effect. Yet we would be far from idiomatichigher-order programs. Indeed, higher-order is particularly powerful when combined
with polymorphism. A typical example is an iterator. Iterators are the idiomaticway to traverse the elements of a collection in functional programming, either to
perform some action on each (iter), to build a value from them (fold), or to rebuilda new collection (map). Here is for instance the type of the iter function over lists
from OCaml standard library:

List.iter: (ff ! unit) ! ff list ! unit
Specifying, proving, and using such a function in a verification context is quite achallenge. Indeed, the function argument of type

ff ! unit may have some arbi-trary effect and specification, thus we need some kind of effect polymorphism and

higher-order logic. A huge step in that direction was made in Johannes Kanig'sPhD thesis [56], which extended previous work by Regis-Gianas on purely applicative programs [88] to programs with effects. We still need to find a way to integrateKanig's work smoothly into Why3. (Incidentally, it is Johannes's work that inspired
the use of regions in Why3.)Obviously, specifying and proving higher-order programs quickly requires higherorder logic, as demonstrated in Kanig's thesis for instance. Since automated theo-rem provers are limited to first-order logic, higher-order logic must be encoded into
first-order logic in some way or another. A simple, yet limited, solution is to spothigher-order schemes and to translate all their instantiations into first-order logic,
as done by Leino and Monahan [67]. Otherwise a systematic translation can beconsidered, as done for instance by Meng and Paulon in Isabelle/HOL [75] or by
Regis-Gianas and Kanig in the aforementioned work [88, 56].

Interactive Proof. When a verification condition is not discharged by any automatedtheorem prover, we turn to a proof assistant, typically Coq. There we apply tactics
to discharge the goal interactively. This includes high-level reasoning steps, suchas applying an induction principle or inverting some inductive predicate definition.
Once these are performed, we are left with simpler goals, most of them could bedischarged by automated theorem provers. Unfortunately, there is currently no way
to use these provers from Coq. We consider implementing a Coq plug-in to do this.

4.2. WHY3 65
This is not a new idea, as such a technology already exists in Isabelle/HOL -- thisis the Sledgehammer tool [75] we already mentioned in the first chapter.

However, we consider doing it slightly differently. First, we do not really careabout reconstructing a proof in Coq, since we are already assuming the soundness
of automated theorem provers. (Of course, checking such proofs when they existcannot harm, but the point here is that we are perfectly fine with calling provers
that do not produce any proof.) Second, we will use Why3 and its OCaml APIto implement this Coq plug-in, thus performing a round trip from Why3 to Coq
and back. Hopefully, this round trip should not have any impact on the terms andformulas coming from the original Why3 goal. Of course, there is no reason why
such a plug-in could not be used for other kinds of Coq proofs, at least when they usethe first-order fragment of Coq's logic. Somehow, it would provide a first (modest)
step towards a Sledgehammer-like tactic for Coq. This Coq plug-in is already workin progress.

Bibliography
[1] Jean-Raymond Abrial. The B-Book, assigning programs to meaning. Cam-bridge University Press, 1996.
[2] M. Barbosa, Jean-Christophe Filli^atre, J. Sousa Pinto, and B. Vieira. A De-ductive Verification Platform for Cryptographic Software. In 4th International

Workshop on Foundations and Techniques for Open Source Software Certifi-cation (OpenCert 2010), volume 33, Pisa, Italy, September 2010. Electronic
Communications of the EASST.
[3] Romain Bardou, Jean-Christophe Filli^atre, Johannes Kanig, and St'ephaneLescuyer. Faire bonne figure avec Mlpost. In Vingti`emes Journ'ees Francophones des Langages Applicatifs, Saint-Quentin sur Is`ere, January 2009.INRIA.

[4] Mike Barnett, Robert DeLine, Bart Jacobs, Bor-Yuh Evan Chang, andK. Rustan M. Leino. Boogie: A Modular Reusable Verifier for Object-Oriented

Programs. In Frank S. de Boer, Marcello M. Bonsangue, Susanne Graf, andWillem-Paul de Roever, editors, Formal Methods for Components and Objects:
4th International Symposium, volume 4111 of Lecture Notes in Computer Sci-ence, pages 364-387, 2005.

[5] Mike Barnett, K. Rustan M. Leino, K. Rustan, M. Leino, and WolframSchulte. The Spec# Programming System: An Overview. pages 49-69.

Springer, 2004.
[6] Mike Barnett, K. Rustan M. Leino, and Wolfram Schulte. The Spec# Pro-gramming System: An Overview. In Construction and Analysis of Safe, Secure, and Interoperable Smart Devices (CASSIS'04), volume 3362 of LectureNotes in Computer Science, pages 49-69. Springer, 2004.

[7] Clark Barrett and Cesare Tinelli. CVC3. In Damm and Hermanns [31], pages298-302.

67

68 BIBLIOGRAPHY
[8] Patrick Baudin, Jean-Christophe Filli^atre, Claude March'e, Benjamin Monate,Yannick Moy, and Virgile Prevosto. ACSL: ANSI/ISO C Specification Language, version 1.4, 2009. http://frama-c.cea.fr/acsl.html.
[9] Bernhard Beckert, Reiner H"ahnle, and Peter H. Schmitt, editors. Verifica-tion of Object-Oriented Software: The KeY Approach, volume 4334 of Lecture

Notes in Computer Science. Springer, 2007.
[10] J.L. Bentley. Programming Pearls. Addison-Wesley, 1986.
[11] Yves Bertot. From Semantics to Computer Science, essays in Honour of GillesKahn, chapter Theorem proving support in programming language semantics,

pages 337-361. Cambridge University Press, 2009.
[12] Joshua Bloch. Nearly all binary searches and mergesorts arebroken, 2006. http://googleresearch.blogspot.com/2006/06/

extra-extra-read-all-about-it-nearly.html.
[13] Fran,cois Bobot. Logique de s'eparation et v'erification d'eductive. Th`ese dedoctorat, Universit'e Paris-Sud, 2011.

[14] Fran,cois Bobot, Sylvain Conchon, 'Evelyne Contejean, Mohamed Iguernelala,St'ephane Lescuyer, and Alain Mebsout. The Alt-Ergo automated theorem

prover, 2008. http://alt-ergo.lri.fr/.
[15] Fran,cois Bobot, Jean-Christophe Filli^atre, Claude March'e, and Andrei Paske-vich. The Why3 platform. LRI, CNRS & Univ. Paris-Sud & INRIA Saclay,

version 0.64 edition, February 2011. http://why3.lri.fr/.
[16] Fran,cois Bobot, Jean-Christophe Filli^atre, Claude March'e, and Andrei Paske-vich. Why3: Shepherd your herd of provers. In Boogie 2011: First International Workshop on Intermediate Verification Languages, Wroclaw, Poland,August 2011.

[17] Fran,cois Bobot and Andrei Paskevich. Expressing Polymorphic Types in aMany-Sorted Language, 2011. Preliminary report. http://hal.inria.fr/

inria-00591414/.
[18] Sylvie Boldo, Fran,cois Cl'ement, Jean-Christophe Filli^atre, Micaela Mayero,Guillaume Melquiond, and Pierre Weis. Formal Proof of a Wave Equation

Resolution Scheme: the Method Error. In Matt Kaufmann and Lawrence C.Paulson, editors, Proceedings of the first Interactive Theorem Proving Conference, volume 6172 of LNCS, pages 147-162, Edinburgh, Scotland, July 2010.Springer. (merge of TPHOLs and ACL2).

[19] Sylvie Boldo and Jean-Christophe Filli^atre. Formal Verification of Floating-Point Programs. In 18th IEEE International Symposium on Computer Arithmetic, pages 187-194, Montpellier, France, June 2007.

BIBLIOGRAPHY 69
[20] Sylvie Boldo, Jean-Christophe Filli^atre, and Guillaume Melquiond. Combin-ing Coq and Gappa for Certifying Floating-Point Programs. In 16th Symposium on the Integration of Symbolic Computation and Mechanised Reasoning,volume 5625 of Lecture Notes in Artificial Intelligence, pages 59-74, Grand
Bend, Canada, July 2009. Springer.
[21] Richard Bornat. Proving pointer programs in Hoare logic. In Mathematics ofProgram Construction, pages 102-126, 2000.

[22] Frederick P. Brooks, Jr. The mythical man-month (anniversary ed.). Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA, 1995.
[23] Rod Burstall. Some techniques for proving correctness of programs whichalter data structures. Machine Intelligence, 7:23-50, 1972.
[24] Arthur Chargu'eraud. Characteristic formulae for the verification of imperativeprograms. In Manuel M. T. Chakravarty, Zhenjiang Hu, and Olivier Danvy,

editors, Proceeding of the 16th ACM SIGPLAN international conference onFunctional Programming (ICFP), pages 418-430, Tokyo, Japan, September
2011. ACM.
[25] Sylvain Conchon and Jean-Christophe Filli^atre. Type-Safe Modular Hash-Consing. In ACM SIGPLAN Workshop on ML, Portland, Oregon, September

2006.
[26] Sylvain Conchon and Jean-Christophe Filli^atre. A Persistent Union-Find DataStructure. In ACM SIGPLAN Workshop on ML, pages 37-45, Freiburg, Germany, October 2007. ACM.
[27] Sylvain Conchon and Jean-Christophe Filli^atre. Semi-Persistent Data Struc-tures. In 17th European Symposium on Programming (ESOP'08), Budapest,

Hungary, April 2008.
[28] Sylvain Conchon, Jean-Christophe Filli^atre, and Julien Signoles. Designinga Generic Graph Library using ML Functors. In Marco T. Moraz'an, editor,

Trends in Functional Programming Volume 8: Selected Papers of the 8th In-ternational Symposium on Trends in Functional Programming (TFP'07), New
York, USA, volume 8. Intellect, 2008.
[29] Jean-Fran,cois Couchot and St'ephane Lescuyer. Handling polymorphism inautomated deduction. In 21th International Conference on Automated Deduction (CADE-21), volume 4603 of LNCS (LNAI), pages 263-278, Bremen,Germany, July 2007.

[30] Markus Dahlweid, Michal Moskal, Thomas Santen, Stephan Tobies, and Wol-fram Schulte. VCC: Contract-based modular verification of concurrent C.

In 31st International Conference on Software Engineering, ICSE 2009, May

70 BIBLIOGRAPHY

16-24, 2009, Vancouver, Canada, Companion Volume, pages 429-430. IEEEComp. Soc. Press, 2009.
[31] Werner Damm and Holger Hermanns, editors. Computer Aided Verification,volume 4590 of Lecture Notes in Computer Science, Berlin, Germany, July

2007. Springer.
[32] Leonardo de Moura and Nikolaj Bjo/rner. Z3, an efficient SMT solver. http://research.microsoft.com/projects/z3/.

[33] Leonardo de Moura and Bruno Dutertre. Yices: An SMT Solver. http://yices.csl.sri.com/.
[34] David Detlefs, Greg Nelson, and James B. Saxe. Simplify: a theorem proverfor program checking. J. ACM, 52(3):365-473, 2005.
[35] Edsger W. Dijkstra. Guarded commands, nondeterminacy and formal deriva-tion of programs. Commun. ACM, 18:453-457, August 1975.
[36] Jean-Christophe Filli^atre. Preuve de programmes imp'eratifs en th'eorie destypes. PhD thesis, Universit'e Paris-Sud, July 1999.
[37] Jean-Christophe Filli^atre. Verification of non-functional programs using inter-pretations in type theory. Journal of Functional Programming, 13(4):709-745,

July 2003.
[38] Jean-Christophe Filli^atre. Backtracking iterators. In ACM SIGPLAN Work-shop on ML, Portland, Oregon, September 2006.

[39] Jean-Christophe Filli^atre. Formal Proof of a Program: Find. Science ofComputer Programming, 64:332-240, 2006.
[40] Jean-Christophe Filli^atre. Formal Verification of MIX Programs. In Journ'eesen l'honneur de Donald E. Knuth, Bordeaux, France, October 2007. http:

//knuth07.labri.fr/exposes.php.
[41] Jean-Christophe Filli^atre. A Functional Implementation of the Garsia-WachsAlgorithm. In ACM SIGPLAN Workshop on ML, Victoria, British Columbia,

Canada, September 2008. ACM.
[42] Jean-Christophe Filli^atre. Verifying two lines of C with Why3: an exercise inprogram verification. In Verified Software: Theories, Tools and Experiments

(VSTTE), Philadelphia, USA, January 2012.
[43] Jean-Christophe Filli^atre and K. Kalyanasundaram. Functory: A distributedcomputing library for Objective Caml. In Trends in Functional Programming,

Madrid, Spain, May 2011.

BIBLIOGRAPHY 71
[44] Jean-Christophe Filli^atre and Pierre Letouzey. Functors for Proofs and Pro-grams. In Proceedings of The European Symposium on Programming, volume

2986 of Lecture Notes in Computer Science, pages 370-384, Barcelona, Spain,April 2004.

[45] Jean-Christophe Filli^atre and Nicolas Magaud. Certification of Sorting Al-gorithms in the System Coq. In Theorem Proving in Higher Order Logics:

Emerging Trends, Nice, France, 1999.
[46] Jean-Christophe Filli^atre and Claude March'e. Multi-Prover Verification of CPrograms. In Sixth International Conference on Formal Engineering Methods,

pages 15-29. Springer, 2004.
[47] Jean-Christophe Filli^atre and Claude March'e. The Why/Krakatoa/Caduceusplatform for deductive program verification. In Damm and Hermanns [31],

pages 173-177.
[48] Jean-Christophe Filli^atre and F. Pottier. Producing All Ideals of a Forest,Functionally. Journal of Functional Programming, 13(5):945-956, September

2003.
[49] Robert W. Floyd. Assigning meanings to programs. In J. T. Schwartz, editor,Mathematical Aspects of Computer Science, volume 19 of Proceedings of Symposia in Applied Mathematics, pages 19-32, Providence, Rhode Island, 1967.American Mathematical Society.

[50] The Frama-C platform for static analysis of C programs, 2008. http://www.frama-c.cea.fr/.
[51] Paolo Herms, Claude March'e, and Benjamin Monate. A certified multi-proververification condition generator. In Rajeev Joshi, Peter M"uller, and Andreas

Podelski, editors, VSTTE, Lecture Notes in Computer Science. Springer, 2012.
[52] C. A. R. Hoare. An axiomatic basis for computer programming. Communi-cations of the ACM, 12(10):576-580 and 583, October 1969.

[53] C. A. R. Hoare. Proof of a program: Find. Commun. ACM, 14:39-45, January1971.
[54] Thierry Hubert and Claude March'e. Separation analysis for deductive ver-ification. In Heap Analysis and Verification (HAV'07), pages 81-93, Braga,

Portugal, March 2007.
[55] G'erard Huet. The Zipper. Journal of Functional Programming, 7(5):549-554,Septembre 1997.

[56] Johannes Kanig. Sp'ecification et preuve de programmes d'ordre sup'erieur.Th`ese de doctorat, Universit'e Paris-Sud, 2010.

72 BIBLIOGRAPHY
[57] Johannes Kanig and Jean-Christophe Filli^atre. Who: A Verifier for EffectfulHigher-order Programs. In ACM SIGPLAN Workshop on ML, Edinburgh,

Scotland, UK, August 2009.
[58] Matt Kaufmann, J. Strother Moore, and Panagiotis Manolios. Computer-Aided Reasoning: An Approach. Kluwer Academic Publishers, Norwell, MA,

USA, 2000.
[59] Gerwin Klein, June Andronick, Kevin Elphinstone, Gernot Heiser, DavidCock, Philip Derrin, Dhammika Elkaduwe, Kai Engelhardt, Rafal Kolanski,

Michael Norrish, Thomas Sewell, Harvey Tuch, and Simon Winwood. seL4:Formal verification of an OS kernel. Communications of the ACM, 53(6):107-
115, June 2010.
[60] Donald E. Knuth. The Art of Computer Programming, volume 1 (3rd ed.):Fundamental Algorithms. Addison Wesley Longman Publishing Co., Inc.,

1997.
[61] Donald E. Knuth. The Art of Computer Programming, volume 2 (3rd ed.):Seminumerical Algorithms. Addison-Wesley Longman Publishing Co., Inc.,

1997.
[62] Piotr Kosiuczenko. An abstract machine for the old value retrieval. In ClaudeBolduc, Jules Desharnais, and B'echir Ktari, editors, MPC, volume 6120 of

Lecture Notes in Computer Science, pages 229-247. Springer, 2010.
[63] Gary T. Leavens, K. Rustan M. Leino, Erik Poll, Clyde Ruby, and BartJacobs. JML: notations and tools supporting detailed design in Java. In

OOPSLA 2000 Companion, Minneapolis, Minnesota, pages 105-106, 2000.
[64] K. Rustan M. Leino. Efficient weakest preconditions. Information ProcessingLetters, 93(6):281-288, 2005.

[65] K. Rustan M. Leino. Dafny: An Automatic Program Verifier for FunctionalCorrectness. In Springer, editor, LPAR-16, volume 6355, pages 348-370, 2010.
[66] K. Rustan M. Leino and Michal Moskal. VACID-0: Verification of amplecorrectness of invariants of data-structures, edition 0. In Proceedings of Tools

and Experiments Workshop at VSTTE, 2010.
[67] Rustan Leino and Rosemary Monahan. Automatic verification of textbookprograms that use comprehensions. In Formal Techniques for Java-like Programs (FTfJP 2007), Berlin, Germany, July 2007.
[68] Xavier Leroy. A modular module system. Journal of Functional Programming,10(3):269-303, 2000.

BIBLIOGRAPHY 73
[69] Xavier Leroy. A formally verified compiler back-end. Journal of AutomatedReasoning, 43(4):363-446, 2009.
[70] Pierre Letouzey. Programmation fonctionnelle certifi'ee: l'extraction de pro-grammes dans l'assistant Coq. Th`ese de doctorat, Universit'e Paris-Sud, July

2004.
[71] Z. Manna and J. Mccarthy. Properties of programs and partial function logic.In Machine Intelligence, volume 5, 1970.

[72] Mar'ia Manzano. Extensions of first order logic. Cambridge University Press,New York, NY, USA, 1996.
[73] Claude March'e. Jessie: an intermediate language for Java and C verification.In Programming Languages meets Program Verification (PLPV), pages 1-2,

Freiburg, Germany, 2007. ACM.
[74] Claude March'e, Christine Paulin-Mohring, and Xavier Urbain. The Kraka-toa tool for certification of Java/JavaCard programs annotated in JML.

Journal of Logic and Algebraic Programming, 58(1-2):89-106, 2004. http://krakatoa.lri.fr.

[75] Jia Meng and Lawrence C. Paulson. Translating higher-order clauses to first-order clauses. Journal of Automated Reasoning, 40:35-60, 2008.
[76] Bertrand Meyer. Eiffel: The Language. Prentice Hall, Hemel Hempstead,1992.
[77] R. Milner. A theory of type polymorphismn in programming. Journal ofComputer and System Sciences, 17, 1978.
[78] Christine Paulin Mohring and Benjamin Werner. Synthesis of ml programsin the system coq. Journal of Symbolic Computation, 15:607-640, 1993.
[79] F. L. Morris and C. B. Jones. An early program proof by Alan Turing. IEEEAnnals of the History of Computing, 6(2):139-143, April 1984.
[80] Aleksandar Nanevski, Greg Morrisett, Avi Shinnar, Paul Govereau, and LarsBirkedal. Ynot: Reasoning with the awkward squad. In Proceedings of

ICFP'08, 2008.
[81] Greg Nelson and Derek C. Oppen. Fast decision procedures based on congru-ence closure. J. ACM, 27(2):356-364, 1980.

[82] Tobias Nipkow. Winskel is (almost) right: Towards a mechanized semanticstextbook. Formal Aspects of Computing, 10:171-186, 1998.
[83] S. Owre, N. Shankar, J. M. Rushby, and D. W. J. Stringer-Calvert. PVSLanguage Reference. Computer Science Laboratory, SRI International, Menlo

Park, CA, September 1999.

74 BIBLIOGRAPHY
[84] Sam Owre and N. Shankar. Theory interpretations in PVS. Technical ReportSRI-CSL-01-01, SRI International, 2001.
[85] Lawrence C. Paulson. Introduction to isabelle. Technical report, Universityof Cambridge, 1993.
[86] Benjamin C. Pierce, Chris Casinghino, Michael Greenberg, Vilhelm Sjoberg,and Brent Yorgey. Software Foundations. Distributed electronically, 2011.
[87] Silvio Ranise and David Deharbe. Light-weight theorem proving for debuggingand verifying units of code. In Proc. SEFM'03, Canberra, Australia, September 2003. IEEE Computer Society Press. http://www.loria.fr/equipes/cassis/softwares/haRVey/.

[88] Yann R'egis-Gianas and Fran,cois Pottier. A Hoare logic for call-by-value func-tional programs. In Proceedings of the Ninth International Conference on

Mathematics of Program Construction (MPC'08), pages 305-335, 2008.
[89] J. C. Reynolds. Separation logic: a logic for shared mutable data structures.In 17h Annual IEEE Symposium on Logic in Computer Science. IEEE Comp.

Soc. Press, 2002.
[90] Norbert Schirmer. Verification of Sequential Imperative Programs in Is-abelle/HOL. PhD thesis, Technische Universit"at M"unchen, 2006.

[91] Natarajan Shankar and Peter Mueller. Verified Software: Theories, Tools andExperiments (VSTTE'10). Software Verification Competition, August 2010.

http://www.macs.hw.ac.uk/vstte10/Competition.html.
[92] R. E. Shostak. Deciding combinations of theories. Journal of the ACM, 31:1-12, 1984.

[93] Julien Signoles. Extension de ML avec raffinement : syntaxe, s'emantiques etsyst`eme de types. Th`ese de doctorat, Universit'e Paris-Sud, July 2006.
[94] G. Sutcliffe and C. Suttner. The State of CASC. AI Communications,19(1):35-48, 2006.
[95] G. Sutcliffe and C.B. Suttner. The TPTP Problem Library: CNF Releasev1.2.1. Journal of Automated Reasoning, 21(2):177-203, 1998.
[96] Jean-Pierre Talpin and Pierre Jouvelot. Polymorphic type, region and effectinference. Journal of Functional Programming, 2(3):245-271, 1992.
[97] Jean-Pierre Talpin and Pierre Jouvelot. The type and effect discipline. Infor-mation and computation, 111(4):245-298, June 1994.
[98] The Coq Development Team. The Coq Proof Assistant Reference Manual -Version V8.2, 2008. http://coq.inria.fr.

BIBLIOGRAPHY 75
[99] Laurent Th'ery. Proving pearl: Knuth's algorithm for prime numbers. InDavid Basin and Burkhart Wolff, editors, Proceedings of the 16th International

Conference on Theorem Proving in Higher Order Logics (TPHOLs 2003),volume 2758 of LNCS. Springer-Verlag, 2003.

[100] Harvey Tuch, Gerwin Klein, and Michael Norrish. Types, bytes, and separa-tion logic. In Martin Hofmann and Matthias Felleisen, editors, Proc. 34th

ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan-guages (POPL'07), pages 97-108, Nice, France, January 2007.

[101] Alan Mathison Turing. Checking a large routine. In Report of a Conferenceon High Speed Automatic Calculing Machines, pages 67-69, Cambridge, 1949.

Mathematical Laboratory.
[102] Andrew K. Wright. Simple imperative polymorphism. LISP and symboliccomputation, 8:343-355, 1995.

Index
r, 3242, 42
91 function, 4, 38
alias, 30Alt-Ergo, 11, 14, 16, 17, 38, 52

arithmeticoverflow, 3, 55

Presburger, 13array, 24

Barthe, Gilles, xBentley, Jon, 4, 52
Bertot, Yves, x, 60Bertrand's postulate, 5
binary search, 3, 52Bobot, Fran,cois, ix, 15, 16, 20
Boldo, Sylvie, ix
Caduceus, ix, 15, 57Cast'eran, Pierre, x

Chargu'eraud, Arthur, 9cloning

modules, 63theories, 21
CompCert, xi, 9, 10, 60Conchon, Sylvain, x
consistance, see cr`eme de marronsCoq, ix, 5, 13, 14, 60, 64, 65
Couchot, Jean-Fran,cois, 15Courant, Judica"el, 38
Cousineau, Guy, x

cr`eme de marrons, see consistanceCVC Lite, 14
CVC3, 10, 38cycle detection, 4, 40

Dafny, 6, 9, 61Danvy, Olivier, xi
di Cosmo, Roberto, xiDoligez, Damien, x
driver, 22
exponentiationfast, 44

Fibonacci, 42FIND (program), 3
Floyd, Robert, 4, 40Frama-C, 57, 60
fringe, see same fringe
Gappa, xghost code, 61

haRVey, 14Herms, Paolo, 60
higher-order, 63Hoare, Tony, 3
HOL Light, 14HOL4, 14
Huet, G'erard, 50Huet, G'erard, xi

IDE
77

78 INDEX

of Why3, 22induction, 52
invariant, 15Isabelle/HOL, 14

Jessie, 15, 57Jouvelot, Pierre, 30
Kanig, Johannes, 64Knuth, Donald E., 5, 15, 45
Krakatoa, 14, 15, 57
Leino, K. Rustan M., x, 64Leroy, Xavier, x, xi, 9

Lescuyer, St'ephane, 15Letouzey, Pierre, ix
lexicographic order, 18, 39, 48
Magaud, Nicolas, 13March'e, Claude, ix, 14-16, 22

McCarthy, John, 4, 38Melquiond, Guillaume, x
memory model, 53MIX, 5, 15
Mizar, 14model type, 24, 25

N -queens, 37
OCaml, x, 24, 61, 63-65overflow, 3

Paskevich, Andrei, 15, 16, 20, 63Paulin, Christine, xi, 14
prime number, 45procrastination, 1-78
programsof Why3, see WhyML
ProVal, ix, x, 13, 15, 52, 57, 60PVS, 14, 15, 22, 60

reference, 24region, 26

run-time assertion checking, 62
same fringe, 49Shankar, Natarajan, x, 60

Signoles, Julien, xSimplify, 14

Talpin, Jean-Pierre, 30termination, 4, 38
Th'ery, Laurent, 5, 13theory, 20
tortoise and hare (algorithm), 4, 40Turing, Alan, 2

Urbain, Xavier, 14
variant, 4, 29, 38, 41Vieira, B'arbara, 15

W, algorithm, 30weakest precondition, 31
Why, x, 5, 13, 14, 15, 37, 52Why3, 13, 13, 16-18, 20, 22-25, 29-

31, 35, 37-39, 42, 45, 52-57,59-65
WhyML, 17, 23, 23, 24-28, 61, 63, 78
Yices, 10Ynot, 9

Z3, 10, 38Zenon, 14
zipper, 50