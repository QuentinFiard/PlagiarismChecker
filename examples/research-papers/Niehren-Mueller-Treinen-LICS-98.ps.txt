

Draft12/2/1998

The First-Order Theory of
Ordering Constraints over Feature Trees

Martin M"uller and Joachim NiehrenProgramming Systems Lab,
Univ. des Saarlandes, Saarbr"ucken, Germany

Ralf TreinenLRI, Universit'e de Paris-Sud, Orsay, France

February 12, 1998

Abstract
The system FT^ of ordering constraints over feature trees has been introduced asan extension of the system FT of equality constraints over feature trees. We investigate the first-order theory of FT^ and its fragments in detail, both over finitetrees and over possibly infinite trees. We prove that the first-order theory of

FT^is undecidable, in contrast to the first-order theory of FT which is well-known

to be decidable. We show that the entailment problem of FT^ with existentialquantification is PSPACE-complete. So far, this problem has been shown decidable, coNP-hard in case of finite trees, PSPACE-hard in case of arbitrary trees,and cubic time when restricted to quantifier-free entailment judgments. To show
PSPACE-completeness, we show that the entailment problem of FT^ with exis-tential quantification is equivalent to the inclusion problem of non-deterministic
finite automata.

1 Introduction
Feature constraints have been used for describing records in constraint programming
[1, 26, 25] and record like structures in computational linguistics [11, 9, 18, 21]. Following [2, 4, 3], we consider feature constraints as predicate logic formulas interpreted
in the structure of feature trees.

A feature tree is a tree with unordered edges labeled by features and with possibly
labeled nodes. Features are functional in that the features labeling the edges departing
from the same node must be pairwise different. The structure of feature trees gives rise
to an ordering in a very natural way which is
called weak subsumption ordering in [6]: A
feature tree t1 is smaller than another feature

wine

red
color ^

wine

red 1998
color year

tree t2 if t1 has fewer edges and node labels than t2. In this case we write t1 ^ t2. An
example is given in the picture.

1

Draft12/2/1998 We consider the system FT^ of ordering constraints over feature trees [16, 13, 15]. Its

constraints j are given by the following abstract syntax:

j ::= x^x0 j x[ f ]x0 j a(x) j j ^ j0
The constraints of FT^ are interpreted in the structure of feature trees with the weak
subsumption ordering. We distinguish two cases, the structure of finite feature trees
and the structure of possibly infinite feature trees. A constraint x^x0 holds if the denotation of x weakly subsumes the denotation of x0, x[ f ]x0 is valid if the denotation of x
has an edge at the root that is labeled with the feature f and leads to the denotation of
x0, and a(x) means that the root of x is labeled with a.

The constraint system FT^ is an extension of FT , which provides for equality constraints y over feature trees [2]:

y ::= x=x0 j x[ f ]x0 j a(x) j y ^ y0
The first-order theory of FT and its fragments are well-understood. The full first-order
theory of FT is decidable [4] but has non-elementary complexity [31]. The satisfiability problem of FT , its entailment problem y j= y0, and its entailment problem with
existential quantifiers y j= 9x1 : : :9xn y0 can be solved in quasi-linear1 time [26].

Much less is known about the first-order theory of FT^ and its fragments. Its investigation has been initiated with the O(n5)-algorithm of [6] for deciding satisfiability of
FT^-constraints. This result was improved to O(n3) in [16], where also the entailment
problem of FT^ concerning quantifier-free judgments j j= j0 was shown decidable in
cubic time. The next step towards larger fragments of the theory of FT^ was to consider the judgments with existential quantification j j= 9x1 : : :9xn j0 which are equivalent to unsatisfiability judgments j ^ :9x1 : : :9xn j0 with quantification below negation. As shown in [15], this problem is decidable, coNP-hard in case of finite trees,
and PSPACE-hard in case of arbitrary trees. Decidability is proved by reduction to the
entailment problem with existential quantifiers in the related structure of so-called sufficiently labeled feature trees. Since the full first-order theory of ordering constraints
over sufficiently labeled (finite) feature trees can easily be encoded in (weak) second
order monadic logic, decidability of entailment follows from the classical results on
(W)S2S [27, 20].

In this paper we answer three intriguing open questions on FT^:
What is exact complexity of the entailment problem of FT^ with existential quantification? We prove that the entailment problem of FT^ with existentials is PSPACEcomplete, both in the case of finite trees and for possibly infinite trees. This is done
by reducing the entailment problem of FT^ with existentials to the inclusion problem
of non-deterministic finite automata (NFA), and vice versa. A reduction of NFA inclusion to entailment with existentials is presented in [15] in the case of possibly infinite
trees. Surprisingly, we can adapt this reduction to the case of finite trees by inverting
all ordering constraints used there. The reduction of the entailment problem of FT^
with existentials to NFA inclusion is obtained by extending a technique developed by
D"orre [6]. Given an existential formula 9xj we construct an automaton that accepts all
consequences of 9xj. D"orre's automata accept only simple consequences that suffice
to characterize satisfiability.

2

Draft12/2/1998 Is the first order theory of FT^ decidable? We show that the first-order theory of FT^is undecidable. We prove this result by encoding the Post Correspondence Problem

following a technique of [29]. Our result holds over possibly infinite feature trees and,
more surprisingly, even over finite feature trees.

What is the relationship between the first-order theory of FT^ and S2S? We show
that S2S can be encoded into FT^ (over possibly infinite feature trees) and that WS2S
can be encoded into FT^ over finite feature trees. The undecidability of the firstorder theory of FT^ yields that there can be no reduction of the first-order theory of
FT^ to S2S. This result is in contrast to the fact that the first-order theory of ordering
constraints over sufficiently labeled feature trees can be encoded into S2S [15].

Applications and Related Work. The application domains of ordering constraints
over feature trees are quite diverse. They have been used to describe so-called coordination phenomena in natural language [6] but also for the analysis of concurrent
constraint programming languages [14]. The less general equality constraints over
feature trees are central to constraint based grammars, and they provide record constraints for logic programming [26] or concurrent constraint programming [22, 12].
In concurrent constraint programming, entailment with existential quantification is
needed for deciding the satisfaction of conditional guards. Our results are also relevant
for constraint-based inference of record types (see, e.g., [17]). When modeling record
types by feature trees, ordering constraints over feature trees correspond to subtyping
constraints, and the entailment test is useful to justify constraint simplification [19].

Originally, weak subsumption has been introduced as a weakening of subsumption.
The subsumption ordering between feature structures [10, 23, 5] is omnipresent in linguistic theories like HPSG (head-driven phrase structure grammar) [18]. According to
the more general view of [24, 6], the subsumption ordering and the weak subsumption
ordering are definable between elements of an arbitrary feature algebra (not only between feature structures). This logical perspective enables the definition of subsumption (resp. weak subsumption) constraints [7] which are interpreted with respect the
subsumption (resp. weak subsumption) ordering of arbitrary feature algebras. Syntactically, subsumption constraints, weak subsumption constraints, and FT^ constraints
coincide but semantically they differ. As proved in [7] the satisfiability problem of
subsumption constraints is undecidable. The satisfiability problem of weak subsumption constraints is equivalent to the satisfiability problem of FT^ constraints [6, 16]
and hence decidable in cubic time.

2 Ordering Constraints
The constraint system FT^ is defined by a set of constraints, the structure of feature
trees, and an interpretation of constraints over feature trees. We assume an infinite
set V of variables ranged over by x; y; z, a set F of at least two features ranged over
by f ; g and a set L of labels ranged over by a; b.

Feature Trees A path p is a word over features. The empty path is denoted by e and
the free-monoid concatenation of paths p and p0 as pp0. We have ep = pe = p. Given

3

Draft12/2/1998 a path p, we write p

\Gamma 1 for the reverse of p. A path p0 is called a prefix of p if p = p0p00

for some path p00. A tree domain is a non-empty prefix closed set of paths.
A feature tree t is a pair (D; L) consisting of a tree domain D and a partial functionL : D

* L that we call labeling function of t. Given a feature tree t, we write Dt

for its tree domain and Lt for its labeling function. For instance, t0 =
(fe; f g; f( f ; a)g) is a feature tree with domain Dt0 = fe; f g and Lt0 =
f( f ; a)g. A feature tree is finite if its tree domain is finite, and infinite

t0= \Delta a f

otherwise. A node of t is an element of Dt. A node p of t is labeled with a if (p; a) 2
Lt. A node of t is unlabeled if it is not labeled by any a. The root of t is the nodee

. Given a tree t with p 2 Dt, we write as t[p] the subtree of t at path p; formally
Dt

:p = fp0 j pp0 2 Dtg and Lt:p = f(p0; a) j (pp0; a) 2 Ltg.

Syntax and Semantics An FT^ constraint j is defined by the abstract syntax

j ::= x^y j a(x) j x[ f ]y j j1 ^ j2
An FT^ constraint is a conjunction of basic constraints which are either inclusion
constraints x^y, labeling constraints a(x), or selection constraints x[ f ]y.

We define the structure FT^ over feature trees in which we interpret FT^ constraints.
Its universe consists of the set of all feature trees. Its substructure consisting of all
finite trees is denoted by FTfin^ . The constraints are interpreted as follows:

t1^t2 iff Dt1 ` Dt2 and Lt1 ` Lt2
t1[ f ]t2 iff Dt2 = fp j f p 2 Dt1g and

Lt2 = f(p; a) j ( f p; a) 2 Lt1g

a(t) iff (e; a) 2 Lt

First-Order Formulas Let \Phi  and \Phi 0 be first-order formulas built from FT^ constraints with the usual first-order connectives. We call \Phi  satisfiable (valid) if \Phi  is
satisfiable (valid) in the structure FT^. We say that \Phi  entails \Phi 0, written \Phi  j= \Phi 0,
if \Phi  ! \Phi 0 is valid, and that \Phi  is equivalent to \Phi 0 if \Phi  $ \Phi 0 is valid. We denote
with V (\Phi ) the set of variables occurring free in \Phi , and with F (\Phi ) and L(\Phi ) the set
of features and labels occurring in \Phi . We also write x!y to abbreviate the formula
x^y ^ x 6= y.

3 Expressiveness
3.1 Minima and Maxima
We define

ux j :, j ^ 8y (j[y=x] ! x^y)
nx j :, j ^ 8y (j[y=x] ! y^x)

Here, j is an arbitrary formula, y is a fresh variable not occurring in j, and j[y=x]
denotes the formula where every free occurrence of x is replaced by y. Typically, x

4

Draft12/2/1998 occurs free in j but this is not required. Note that, in contrast to 8 and 9, ux and nxare not variable binders that restrict the scope of the variable

x; hence x is free in ux j
if it is free in j.

The formula ux j (nx j) reads x is minimal (maximal) with the property j. Since ^ is
a partial order, these formulas define uniquely the value of x once the values of their
other free variables are fixed (provided there is a solution at all).

Example 1 The formula

j1(x) = 9x (ux (x[0]x ^ x[1]x))
is satisfied in FT^ by the full binary, everywhere unlabeled tree, and is not satisfiable
in FTfin^ since FTfin^ contains no infinite trees.

Example 2 The sentence

9x (nx x^x)

is not valid in any of the models considered since none of them contains a greatest tree.

3.2 Arity and Label Restrictions
We use the following abbreviations:

x f # :, 9y (x[ f ]y)
x f " :, :9y (x[ f ]y)

The following formula expresses that x has exactly the features f1; : : : ; fn:

xf f1; : : : ; fng :, 9x1; : : : ; xn (ux(x[ f1]x1 ^ : : : x[ fn]xn))
These so-called arity constraints have been introduced in [26].
To express label restrictions we define the following abbreviation:

x , y := 9z (x^z ^ y^z)
The formula x , y reads x and y are consistent. The following formula expresses that
the root of a tree is unlabeled:

unlabeled(x) := 9y (x , y ^ a(y)) ^ 9y (x , y ^ b(y))
We write x , a to express that x is either unlabeled or labeled with a:

x , a := 9y (a(y) ^ x^y)

5

Draft12/2/1998 3.3 Quantification over Labels and Features

We can simulate a first-class status of label and feature symbols by representing a label
a by the tree (feg; f(e; a)g), and a feature f by the tree (fe; f g; /0). More precisely:

one-dist(x; y) := (x ! y ^ :9z (x ! z ! y))

atom(x) := 9y ((uy true) ^ one-dist(y; x))

Hence atom(t) expresses that t is an atom in the lattice-theoretic sense. The labeled
atoms represent labels and the unlabeled ones represent features:

feature-atom(x) := atom(x) ^ unlabeled(x)

label-atom(x) := atom(x) ^ :unlabeled(x)

We can now express that x and y have the same label by

(unlabeled(x) ^ unlabeled(y)) . 9z (label-atom(z) ^ z^x ^ z^y)
and that y has at least all the features of x by

8z (feature-atom(z) ^ z^x ! z^y)
Hence, we get the expressivity of the feature constraint system considered in [30].

3.4 Inductive Properties
In the case of infinite trees it is in fact quite simple to express "inductive properties" of
a tree. For instance, we can express that the domain of x contains f0; 1g\Lambda  by

9y (y[0]y ^ y[1]y ^ y^x)
The following formula says that x has domain f0; 1g\Lambda , one node of x is labeled with a
and all other nodes are unlabeled:

a-singleton(x) := 9y; z (y[0]y ^ y[1]y ^ unlabeled(y) ^

z[0]z ^ z[1]z ^ a(z) ^
y ! x ! z ^ one-dist(y; x))

The formula b-singleton is defined analogously. We can now express that x has domain
f0; 1g\Lambda  and that all its nodes are labeled with either a or b by:

ux i8y; z (a-singleton(y) ^ b-singleton(z) ^ y 6, z !

(y 6, x ^ z , x) . (y , x ^ z 6, x))j

The idea behind this formula is the following: an a-singleton and a b-singleton are
inconsistent iff they have their label at the same position. Hence, the formula says that
every node of x which is reachable via a f0; 1g\Lambda -path is either labeled with a or with b.
The minimality of x guarantees that F (x) ` f0; 1g. In case of finite trees we have to

6

Draft12/2/1998 use another trick (these techniques work also in case of infinite trees). The followingformula expresses that all nodes of x which are reachable via a path from

f f g\Lambda  are

unlabeled or labeled with a:

9y (x[ f ]y ^ x , a ^ y^x)
The next formula is crucial for our undecidability proof. It expresses that the domain
of x is of the form fe; c; c2; : : : ; cng:

string-c(x) := (xfcg ^ 9y (x[c]y ^ y^x))
In general, we have that
Lemma 3.1 The formula 9y (x[ f ]y ^ y^x) is satisfied by t iff the following holds: Let
n be maximal such that f n 2 Dt, and let ti be the tree with t[ f n]ti. Then

tn^tn\Gamma 1^ : : : ^t1^t

3.5 Expressing Second-Order Monadic Logic
We can easily show that the theory of S2S (WS2S) can be reduced to the theory of FT^
(FTfin^ ). To show this reduction, we consider a modified version of (W)S2S containing
as only sort sets, and as predicates the subset relationship and the predicates 0(x; y)
resp. 1(x; y), where 0[M; N] holds if N = fw0 j w 2 Mg (and analogously for 1[M; N]).
A similar reduction is employed when proving the decidability of the theory of S2S
by a reduction to the emptiness problem of Rabin tree automata (see, e.g., [28]). To
encode S2S into FT^we proceed as follows: We encode a set M as a full binary tree
where the node w is labeled with a if wR 2 M (wR is the mirrored image of w). Then,
weak subsumption corresponds to the subset relationship, and 0(x; y) is encoded by
x[0]y (analogously for 1(x; y). The encoding is not surjective, so when translating a
quantifier of S2S to the theory of FT^ we have to restrict the quantifier to the set of all
full binary trees where nodes can only be labeled with a. That the value of x belongs
to this subset can be expressed by

is-set(x) = 9y; z (uy (y[0]y ^ y[0]y) ^ uz (z[0]z ^ z[1]z ^ a(z)) ^ y^x^z )
The following formula expresses that the denotation of x is a tree t such that Dt `
f0; 1g\Lambda , L(t) ` fag and if a node is labeled with a then all its ancestors are labeled
with a:

prefix-closed(x) := 9x0; x1(x[0]x0 ^ x[1]x1 ^ x0^x ^ x1^x ^ xf0; 1g ^ x , a)
Hence, an arbitrary set is any tree smaller then a tree with the property defined above:

is-set(x) := 9y (prefix-closed(y) ^ x^y)
We can now take the formula is-set(x) to denote all encodings of subsets of f0; 1g\Lambda .
Note that all finite sets can be encoded by finite trees. The encoding, however, is not
injective, that is we have to define the equality of sets by a formula:

equal-set(x; y) = 8z((x , z) $ (y , z))

7

Draft12/2/1998 4 Undecidability

Theorem 1 The first-order theory of FTfin^ is undecidable.

The result holds for arbitrary (even empty) L and for F of cardinality * 2, we use
however, different feature and label symbols for the sake of clarity.

An instance of the Post Correspondence Problem (PCP) is a finite sequence P =
f(pi; qi) j 1 ^ i ^ mg of pairs of words from fa; bg\Lambda . This instance P induces in a natural way two homomorphisms lP and rP from f1; : : : ; mg\Lambda  to fa; bg\Lambda , where lP(i) = pi
and rP(i) = qi. The instance P is said to be solvable if there is a non-empty word
v 2 f1; : : : ; mg+ such that lP(v) = rP(v). According to a classical result due to Post, it
is undecidable whether an instance of the PCP is solvable.

We reduce the solvability of an instance of PCP to the theory of FTfin^ . Let P =
f(pi; qi) j 1 ^ i ^ mg be a fixed instance of PCP.

We define a mapping _g from feature trees to words over fa; bg as follows. If t does not
have the feature s, or if it has no label, or if it has a label different from a and from b
then _g(t) = e. Otherwise let t0 be such that t[s]t0. We define _g(t) = a \Delta  _g(t0) if t has
the label a, and _g(t) = b \Delta  _g(t0) if t has the label b.

We define for any p 2 fa; bg\Lambda  a formula x = p \Delta  y by induction on p:

x = e \Delta  y :, x = y
x = ap \Delta  y :, a(x) ^ 9z (x[s]z ^ z = p \Delta  y)
x = bp \Delta  y :, b(x) ^ 9z (x[s]z ^ z = p \Delta  y))

Furthermore, we define

empty(x) :, :9y x[s]y . :a(x) . :b(x)
Hence we get that empty(t) holds iff _g(t) = e, and t = p \Delta  t0 holds iff _g(t) = p \Delta  _g(t0).
We can now give the proof of the first direction of the proof of the theorem. Here, in is
some formula, the definition does not matter for this direction of the proof.

solvP := 9x (9z (in(z; z; x) ^ :empty(z)

^8y; y0 (in(y; y0; x) ! (empty(y) ^ empty(y0)

.9z; z0 (in(z; z0; x) ^ .

j=1:::m

(y = p j \Delta  z ^ y0 = q j \Delta  z0)))))

The above formula can be read as: There is a set containing a pair (z; z), where z is
a non-empty word, and every pair of words in the set is either the pair of two empty
words, or it can be constructed from another pair in the set by one construction step
of P.

Lemma 4.1 If solvP holds in FTfin^ than the instance P of the Post Correspondence
Problem is solvable.

Proof. We show by induction that if in(t; t0; s) is satisfied, then (_g(t); _g(t0)) is finitely
constructible according to the instance P of the Post Correspondence Problem. 2

8

Draft12/2/1998 ffl

\Gamma \Gamma 

\Gamma p

ffl

\Delta \Delta 

\Delta AA

A
l r

g(v1) g(w1)

PPPP

PPPP

P

c

ffl

\Gamma \Gamma 

\Gamma p

ffl

\Delta \Delta 

\Delta AA

A
l r

g(v2) g(w2)

PPPP

Pc

PPPP

Pc ffl

\Gamma \Gamma 

\Gamma p

ffl

\Delta \Delta 

\Delta AA

A
l r

g(vn) g(wn)

Figure 1: Representation of a solution sequence (vi; wi)i

In order to prove the other direction of the proof of the theorem, we first chose a
representation function g from fa; bg\Lambda  to feature trees: g(e) = e, g(aw) is the smallest
tree t such that a(t) and t[s]g(w), and g(bw) is the smallest tree t such that b(t) andt

[s]g(w). In particular, the function g is injective, and _g(g(w)) = w.

The representation of a sequence (vi; wi)i is given in Figure 1. For the definition of the
in-predicate we first need

one-branch(x; x0) := 9xc (nxc (string-c(xc) ^ xc^x)

^nx0 (xc ! x0 ! x ^ 9z 8y (xc ! y ! x0 ! z^y)))

Lemma 4.2 Let t be tree according to Figure 1. Then one-p(t; t0) holds iff t0^t is as
depicted in Figure 2.

in(yl; yr; x) :, 9x 0(one-branch(x; x0) ^

(9x1; x2 (ux1 (x0^x1 ^ x1[c]x2 ^ x2^x1)

9z (x1[p]z ^ z[l]yl ^ z[r]yr))))

The idea behind this formula is as follows: In order to express that a pair (yl ; yr)
is contained in x, we construct first a tree x0 consisting of a c-spine with just one pair
(yl; yr), say, at position n. From this we get the tree x1 containing at all nodes reachable
by a fcg\Lambda -path which are ancestors of n a pair (zl; zr) such that yl^zl and yr^zr (by
Lemma 3.1). By the minimality of x1 we get that yl = zl and yr = zr.

Lemma 4.3 If the instance P of the Post Correspondence Problem is solvable then
solvP holds in FTfin^ .

Theorem 2 The first-order theory of FT^ is undecidable.

9

Draft12/2/1998 ffl

PPPP

PPPP

P

c

ffl

\Gamma \Gamma 

\Gamma p

ffl

\Delta \Delta 

\Delta AA

A
l r

g(v2) g(w2)

PPPP

Pc

PPPP

Pc

Figure 2: A possible value for t such that one-branch(s; t), where s is as in Figure 1

.

The formula finite(x) states that x does not contain an infinite branch labeled with s.

finite(x) = 9y (uy(y[s]y ^ y 6! x)
The formula used for the reduction of the instance of the PCP to the validity problem
in FT^ is now:

solvP := 9x (9z (in(z; z; x) ^ :empty(z) ^ finite(z)

^8y; y0 (in(y; y0; x) ! (empty(y) ^ empty(y0)

.9z; z0 (in(z; z0; x) ^ .

j=1:::m

(y = p j \Delta  z ^ y0 = q j \Delta  z0)))))

Besides, the proof is exactly as before.
5 Complexity of Entailment j j= 9xj0
Theorem 3 Entailment j j= 9xj0 is PSPACE-complete, independent of whether j andj

0 are interpreted over finite or infinite trees.

In [15] we have shown PSPACE-hardness for the case of infinite trees and coNPhardness for the case of finite trees. In Section 5.2 we modify the proof of [15] such
that it proves PSPACE-hardness for both cases (Proposition 5.3). In particular, we
show that we can encode the Kleene-star operator without need for infinite trees.

Containment in PSPACE is shown (Prop. 5.8) by reducing in polynomial time the
entailment problem to an inclusion problem between the languages accepted by nondeterministic finite state automata (NFA). Language equivalence (and hence inclusion,
because A ` B $ B = A [ B) for NFA is known to be PSPACE-complete if the alphabet
contains at least two distinct symbols [8].

10

Draft12/2/1998 5.1 Path Constraints

We characterize existential FT^ formulas 9xj by means of a new class of path constraints y. The abstract syntax of path constraints y is defined as follows:

y ::= x[p] * y j x[p] * a j x[p] #

j x?[p],y?[p0] j x?[p],a j x?[p] ^ y?[p0]

The semantics of path constraints is given by extension of the structure FT^ through
the following predicates.

t[p] * t0 iff p 2 Dt and t:p * t0t

[p] * a iff p 2 Dt and (p; a) 2 Ltt
[p] # iff p 2 Dtt
?[p],a iff p 2 Dt implies t:p,at
?[p],t0?[p0] iff p 2 Dt and p0 2 Dt0 imply t:p,t0:p0t
?[p] ^ t0?[p0] iff p 2 Dt and p0 2 Dt0 imply t:p^t0:p0

In Section 5.3 we will construct an automaton that accepts all y entailed by 9xj.1

Proposition 5.1 For all x; y; z, p; p0, and a; b; c the following judgments hold:

1) x[p] * y j= x[p0] # if p0 is a prefix of p
2) x[p] * a j= x[p0] # if p0 is a prefix of p
3) x[p] * y j= x?[p],y?[e]
4) x[p] * a j= x?[p],a
5) x?[p] ^ y?[p0] j= x?[p],y?[p0]
6) x?[p],y?[p0] j=j y?[p0],x?[p]
7) x?[p],a ^ x?[p],b j= x?[p],c if a 6= b
8) z[p] * x ^ z[p] * y j= x?[e],y?[e]

Lemma 5.2 For every path constraint y there exists an ordering constraint j and
variables x1; : : : ; xn such that y j=j 9x1 : : :9xn j.

Example 3 Both x^y ^ z^y ^ a(z) and x^y ^ a(y) entail x?[e],a.
Example 4 If a 6= b then for all c:

x[ f ]x0 ^ x0^x00 ^ x00[g]x000 ^ b(x000)
x^y ^ y[ f ]y0 ^ y0,z0 ^ z0[g]z00 ^ a(z00) oe j= x?[ f g],c

In other words, if a is a solution of the left-hand side and f g 2 Da(x) then f g is unlabeled in a(x).

Example 5 Both of the following formulas are equivalent to x?[ f g],a:

9y9y09z9z0 (x^y ^ y[ f ]y0 ^ z^y0 ^ z[g]z0 ^ a(z0))
9x09x009y9y0 (x^x0 ^ x0[ f ]x00 ^ x00^y ^ y[g]y0 ^ a(y0))

Example 6 y ^ u0 ^ u[ f ]u0 ^ u ^ x ^ x ^ v ^ v[ f ]v0 ^ v0 ^ y j= x[ f ]y

1Notice that D"orre's automaton only recognized constraints of the form x[p] * a [6].

11

Draft12/2/1998 5.2 Entailment is PSPACE-hard

We next show that entailment is PSPACE-complete for both the finite and the infinite
tree case. PSPACE-hardness follows from Proposition 5.3, which claims a polynomial
reduction of the inclusion problem between regular languages over the alphabet F to
an entailment problem between two existential FT^ formulas. Notice that we have
assumed F to contain at least two features.

Our PSPACE-hardness proof is based on the fact that a satisfiable ordering constraintsj

may entail an infinite conjunction of path constraints, even in case of finite trees:

Example 7 8p 2 f \Lambda  : x[ f ]y ^ y^x j= x?[p] ^ x?[e].
For this reason the entailment problem for FTfin^ does not necessarily reduce to an
inclusion problem between finite regular languages (which is decidable in coNP [8]).
We consider regular expressions of the following form

R ::= e j f j R\Lambda  j R1 [ R2 j R1R2 if f 2 F
Define, for all regular expressions R and variables x; y the existential formula \Theta (x; R; y)
recursively as follows.

\Theta (x; e; y) = x^y\Theta 

(x; f ; y) = 9z(x^z ^ z[ f ]y)\Theta 
(x; S1 [ S2; y) = \Theta (x; S1; y) ^ \Theta (x; S2; y)\Theta 
(x; S\Lambda ; y) = 9z(x^z ^ \Theta (z; S; z) ^ z^y)\Theta 
(x; S1S2; y) = 9z(\Theta (x; S1; z) ^ \Theta (z; S2; y))

Apparently, \Theta (x; R; y) has size linear in the size of R.
Proposition 5.3 For all variables x; y and for every pair of regular expressions R1 and
R2: \Theta (x; R1; y) j= \Theta (x; R2; y) is equivalent to L(R2) ` L(R1).

Proof. It is sufficient to prove for every R that \Theta (x; R; y) is equivalent to Vfx?[p] ^
y?[e] j p 2 L(R)g. This is done by structural induction over R, closely along the lines
of the corresponding proof in [15]. 2

In comparison to [15], the surprising insight here is that it needs only a minor modification to adapt the PSPACE-hardness proof for the case of infinite trees given there
to the case of finite trees as given here. The encoding in [15] uses formulas \Theta 0(x; R; y)
that characterizes regular expressions R by upper bounds on x instead of lower bounds
in that \Theta 0(x; R; y) j=j Vfx[p] * y j p 2 L(R)g for all R.2 Hence, every solution of\Theta 

0(x; R; y) maps x to an infinite tree if R is an infinite language.

2In comparison to [15], all ordering symbols have been turned around, and in the clause \Theta (x

; f ;y) we

have exchanged the ordering and the selection constraint.

12

Draft12/2/1998 5.3 Automata for Path ConstraintsWe define an automaton that accepts words w over the alphabet F [ V [ L [

f^; ,; *; Rg that correspond to path constraints y:

w ::= xpy* j xpa* j xp*

j xpa, j xpRp0y, j xpRp0y^

Every word w corresponds to a unique path constraint hwi and vice versa.

hxpy*i = x[p] * y
hxpa*i = x[p] * a

hxp*i = x[p] #
hxpa,i = x?[p],a
hxpRp0y,i = x?[p],y?[p0\Gamma 1]
hxpRp0y^i = x?[p] ^ y?[p0\Gamma 1]

We associate with every constraint j and set of variables V a non-deterministic finite
automaton AVj = (Q ; \Delta  \Delta \Gamma !\Delta ; qs; q f ), where the set Q contains the initial state qs, the
final state q f , and the following states where x; y; z; x0; y0 range over V (j):

ffl x, x, xy, xy, and xy, where we identify xy and yx, as well as xy and

yx.

ffl x0y0[x,y] and x0y0[x,y]; we identify the states yy0[x,x0], yy0[x0,x] and

y0y[x,x0], as well as yy0[x,x0], yy0[x0,x] and y0y[x,x0].

ffl x, x, z[x,y] and z[x,y] , where we identify states z[x,y] and z[y,x],

as well as z[x,y] and z[y,x].

ffl x, z[x,y], x, where we identify z[x,y] and z[y,x].

The naming convention of the states indicates which variables have been reached and
into which direction we will proceed. The orientation of the arrowhead tells whether
we traverse the ordering upward (!) or downward (), and whether we traverse feature selection upward (") or downward (#). The bends in the arrows tell where we
came from. The compatibility constraints in brackets mean conditions to be checked
before proceeding in the state indicated by the prefix.

The ternary transition relation \Delta  \Delta \Gamma !\Delta  is now defined. For xpy*, xpa* and xp* we
need these transitions:

8x 2 V (j)nV : qs x\Gamma ! x
8x ^ y 2 j : y e\Gamma ! x

8x[ f ]y 2 j : x f\Gamma ! y
8x 2 V (j)nV : x x*\Gamma ! q f
8x 2 V (j)nV : x *\Gamma ! q f
8a(x) 2 j : x a*\Gamma ! q f

13

Draft12/2/1998 For words xpa

, we follow two paths through the constraint in parallel. To see why,

see clause 7 in Proposition 5.1. For the upward part of xpa, we need the following
transitions:

8x 2 V (j)nV : qs x\Gamma ! xx

8x ^ z 2 j : xy e\Gamma ! zy

8x[ f ]x0 ^ y[ f ]y0 2 j : xy f\Gamma ! x0y0
We extend the automaton such that it accepts xpa,. In states xy and xy we may,
for each of the variables at a downward right slope, guess another variable with compatible denotation and proceed downward left ( ). Before turning, compatibility must
be checked; this check is successful when a trivial pair x,x has been found.

8x; y; z 2 V (j) : xy e\Gamma ! zy[x,z]
8x; y; z 2 V (j) : yz[x,x] e\Gamma ! yz
8x; y; z 2 V (j) : xy e\Gamma ! xz[y,z]
8x; y; z 2 V (j) : yz[x,x] e\Gamma ! yz

In order to check compatibility we need:

8z[ f ]x ^ z0[ f ]x0 2 j : yy0[x,x0] e\Gamma ! yy0[z,z0]
8z[ f ]x ^ z0[ f ]x0 2 j : yy0[x,x0] e\Gamma ! yy0[z,z0]
8x^z 2 j : yy0[x,x0] e\Gamma ! yy0[z,x0]
8x^z 2 j : yy0[x,x0] e\Gamma ! yy0[z,x0]

For the downward part we need:

8x ^ y 2 j : zx e\Gamma ! zy
8x ^ y 2 j : yz e\Gamma ! xz
8x ^ y 2 j : yz e\Gamma ! xz

8x[ f ]x0 ^ y[ f ]y0 2 j : xy f\Gamma ! x0y0
8x[ f ]x0 ^ y[ f ]y0 2 j : xy f\Gamma ! x0y0

We may stop everywhere reading a label:

8a(x) 2 j : xy a,\Gamma ! q f
8a(x) 2 j : xy a,\Gamma ! q f
8a(x) 2 j : yx a,\Gamma ! q f
8a(x) 2 j : xy a,\Gamma ! q f

In particular, if we reach two different labels, we derive compatibility with any label.

8a(x); b(y) 2 j; a 6= b; c 2 L(j) : xy c,\Gamma ! q f
8a(x); b(y) 2 j; a 6= b; c 2 L(j) : xy c,\Gamma ! q f
8a(x); b(y) 2 j; a 6= b; c 2 L(j) : xy c,\Gamma ! q f

14

Draft12/2/1998 Now let us consider words of the form xpRp

0y^.

8x 2 V (j)nV : qs x\Gamma ! x
8x ^ y 2 j : x e\Gamma ! y

8x[ f ]x0 2 j : x f\Gamma ! x0
8x 2 V (j) : x R\Gamma ! x
8x^y 2 j : x e\Gamma ! y

8y[ f ]x 2 j : x f\Gamma ! y
8x 2 V (j) : x x^\Gamma ! q f

In order to accept xpRp0y,, we need the following transitions:

8x; y 2 V (j) : x e\Gamma ! y[x,y]
8x0[ f ]x ^ y0[ f ]y 2 j : z[x,y] e\Gamma ! z[x0,y0]
8x^x0 2 j : z[x,y] e\Gamma ! z[x0,y]
8x 2 V (j) : x[x,x] e\Gamma ! x
8y^x 2 j : x e\Gamma ! y
8y[ f ]x 2 j : x e\Gamma ! y
8x 2 V (j) : x x,\Gamma ! q f

Clause 6 of Proposition 5.1 implies that we must accept the word yp0RRpRx, whenever
we accept the word xpRp0y,. The necessary transitions through states qs, x, x[y,z],

x, x, and q f are easily defined: they must describe a path through the constraint j
inverse to the one given in the last two blocks of transitions.

Write L(A) for the language accepted by automaton A.

Proposition 5.4 (Correctness) If w 2 L(Afxgj ) then 9xj j= hwi.
Lemma 5.5 (Key) For all paths u; p1; p2; n0, variables x; y; z, and constraints j:

1. If yu0Rp2p1x^ 2 L(A /0j) and zn0Rp1x^ 2 L(A /0j) then yu0Rp2n0\Gamma 1z, 2 L(A /0j).
2. If yu0Ru\Gamma 1x^ 2 L(A /0j) and xuu00a* 2 L(A /0j) then yu0u00a, 2 L(A /0j)

Lemma 5.6 Let hw1i j= hw2i be an entailment judgement justified by Proposition 5.1,j

a constraint and x a sequence of variables. If w1 2 L(Axj) then w2 2 L(Axj).

5.4 Deciding Entailment
We call a constraint j F-closed if it satisfies the following properties (reflexivity, transitivity, decomposition):

F1:1 x^x 2 j if x 2 V (j)
F1:2 x^z 2 j if x^y 2 j and y^z 2 j
F2 x0^y0 2 j if y[ f ]y0 2 j

15

Draft12/2/1998 In order to decide j j= 9xj

0, we test satisfiability of j and j ^ 9xj0. This can be

done in time O(n3) where n is the size of the entailment problem [16]. If one of the
tests fails, entailment is trivial. Otherwise, we compute the F-closures of j and of j0
and define the associated automata A /0j and Afxgj0 in time O(n3). By Proposition 5.8,j

j= 9xj0 if and only if L(Afxgj0 ) ` L(A /0j). This inclusion is decidable in PSPACE [8].

Proposition 5.7 (Characterization) If j is an F-closed FT^ constraint, then

9xj j=j ^ L(Afxgj ) :
Proof. The direction from left to right (correctness) is clear. For the direction from
right to left let V = V (9xj), and assume a solution a of V L(Afxgj ). Define an extension a0 of a by setting, for all x 2 V (9xj): a0(x) = a(x), and for all x 2 x: a0(x) = t
where

Da0(x) = fp j xp* 2 L(A /0j0)g [

fpp00 j z 2 V; zp0Rp\Gamma 1x^ 2 L(A /0j0 ); p0p00 2 Da(z)g
La0(x) = f(p; a) j xpa* 2 L(A /0j0 )g [

f(pp00; a) j z 2 V; zp0Rp\Gamma 1x^ 2 L(A /0j0); (p0p00; a) 2 Da(z)g

It is obvious that D0a(x) is prefix closed. The Key Lemma 5.5 implies that L0a(x)
is a partial function. It can be shown by a case distinction that a0 satisfies all basic
constraints in j0. 2

The situation considered in the set comprehension of the second clauses is crucial (the
"mountain chains" of [15]). It should become clear when the reader draws a picture of
the situation.

Proposition 5.8 (Reduction) Let j and j0 be closed FT^ constraints and x a sequence of variables such that all labels and free variables in 9xj0 occur in j. Further
assume that j ^ 9xj0 is satisfiable. Then

j j= 9xj0 if and only if L(Afxgj0 ) ` L(A /0j) :
Proof. The direction from right to left follows directly from Proposition 5.7. For the
inverse direction, we show by case distinction over y that j 6j= y if y 62 L(A /0j). 2

Acknowledgments. The research reported in this paper has been supported by the
BMBF (FKZ ITW 9601), the Esprit Working Group CCL II (EP 22457), and the DFG
(SFB 378). Special thanks are due to Denys Duchier for providing the initial zigzag
macros.

References

[1] H. A"it-Kaci and A. Podelski. Towards a meaning of life. The Journal of Logic

Programming, 16(3 and 4):195-234, July, Aug. 1993.

16

Draft12/2/1998 [2] H. A"it-Kaci, A. Podelski, and G. Smolka. A feature-based constraint systemfor logic programming with entailment. Theoretical Computer Science, 122(1-

2):263-283, Jan. 1994.
[3] R. Backofen. A complete axiomatization of a theory with feature and arity constraints. The Journal of Logic Programming, 24(1&2):37-71, 1995. Special
Issue on Computational Linguistics and Logic Programming.

[4] R. Backofen and G. Smolka. A complete and recursive feature theory. Theoretical Computer Science, 146(1-2):243-268, July 1995.

[5] B. Carpenter. The Logic of Typed Feature Structures - with Applications to Unification Grammars, Logic Programs and Constraint Resolution. Number 32 in
Cambridge Tracts in Theoretical Computer Science. Cambridge University Press,
Cambridge, England, 1992.

[6] J. D"orre. Feature logics with weak subsumption constraints. In Annual Meeting

of the Association of Computational Linguistics, pages 256-263, 1991.

[7] J. D"orre and W. C. Rounds. On subsumption and semiunification in feature algebras. In 5th IEEE Symposium on Logic in Computer Science, pages 300-310.
IEEE Computer Society Press, 1990.

[8] M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to the

Theory of NP-Completeness. W.H. Freeman and Company, New York, 1979.

[9] R. M. Kaplan and J. Bresnan. Lexical-functional grammar: A formal system for

grammatical representation. In J. Bresnan, editor, The Mental Representation of
Grammatical Relations, pages 173-281. The MIT Press, Cambridge, MA, 1982.

[10] R. T. Kasper and W. C. Rounds. A logical semantics for feature structures. In

Annual Meeting of the Association of Computational Linguistics, pages 257-265,
1986.

[11] M. Kay. Functional grammar. In C. Chiarello et al., editor, Proceedings of the

5th Annual Meeting of the Berkeley Linguistics Society, pages 142-158, 1979.

[12] M. J. Maher. Logic semantics for a class of committed-choice programs. In J.-L.

Lassez, editor, International Conference on Logic Programming, pages 858-876.
The MIT Press, Cambridge, MA, 1987.

[13] M. M"uller. Ordering constraints over feature trees with ordered sorts. In P. Lopez,

S. Manandhar, and W. Nutt, editors, Computational Logic and Natural Language
Understanding, Lecture Notes in Artificial Intelligence, to appear. SpringerVerlag, Berlin, Germany, 1997.

[14] M. M"uller. Set-based Failure Diagnosis for Concurrent Constraint Programming. Doctoral Dissertation. Universit"at des Saarlandes, Technische Fakult"at,
66041 Saarbr"ucken, Germany, 1998. In preparation.

17

Draft12/2/1998 [15] M. M"uller and J. Niehren. Ordering constraints over feature trees expressed insecond-order monadic logic. In T. Nipkow, editor, International Conference on

Rewriting Techniques and Applications, Tsukuba, Japan, 1998. Preprint available
at http://www.ps.uni-sb.de/Papers/abstracts/SWS97.html.

[16] M. M"uller, J. Niehren, and A. Podelski. Ordering constraints over feature trees.

In G. Smolka, editor, 3rd International Conference on Principles and Practice of
Constraint Programming, volume 1330 of Lecture Notes in Computer Science,
pages 297-311, Schloss Hagenberg, Linz, Austria, 1997. Springer-Verlag, Berlin,
Germany.

[17] J. Palsberg. Efficient inference of object types. In 9th IEEE Symposium on Logic

in Computer Science, pages 186-185. IEEE Computer Society Press, 1994.

[18] C. Pollard and I. Sag. Head-Driven Phrase Structure Grammar. Studies in Contemporary Linguistics. Cambridge University Press, Cambridge, England, 1994.

[19] F. Pottier. Simplifying subtyping constraints. In ACM SIGPLAN International

Conference on Functional Programming, pages 122-133. ACM Press, New
York, May 1996.

[20] M. O. Rabin. Decidability of second-order theories and automata on infinite

trees. Transactions of the American Mathematical Society, 141:1-35, 1969.

[21] W. C. Rounds. Feature logics. In J. v. Benthem and A. ter Meulen, editors, Handbook of Logic and Language. Elsevier Science Publishers B.V. (North Holland),
1997.

[22] V. A. Saraswat. Concurrent Constraint Programming. The MIT Press, Cambridge, MA, 1993.

[23] S. Shieber. An Introduction to Unification-based Approaches to Grammar. CSLI

Lecture Notes No. 4. Center for the Study of Language and Information, 1986.

[24] G. Smolka. Feature constraint logics for unification grammars. The Journal of

Logic Programming, 12:51-87, 1992.

[25] G. Smolka. The Oz Programming Model. In J. van Leeuwen, editor, Computer

Science Today, Lecture Notes in Computer Science, vol. 1000, pages 324-343.
Springer-Verlag, Berlin, Germany, 1995.

[26] G. Smolka and R. Treinen. Records for logic programming. The Journal of Logic

Programming, 18(3):229-258, Apr. 1994.

[27] J. W. Thatcher and J. B. Wright. Generalized finite automata theory with an

application to a decision problem of second-order logic. Mathematical Systems
Theory, 2(1):57-81, August 1968. Published by Springer-Verlag NY Inc.

[28] W. Thomas. Automata on infinite objects. In J. van Leeuwen, editor, Handbook

of Theoretical Computer Science, volume B (Formal Models and Semantics),
chapter 4, pages 133-191. The MIT Press, Cambridge, MA, 1990.

18

Draft12/2/1998 [29] R. Treinen. A new method for undecidability proofs of first order theories. Jour-nal of Symbolic Computation, 14:437-457, 1992.

[30] R. Treinen. Feature trees over arbitrary structures. In P. Blackburn and M. de Rijke, editors, Specifying Syntactic Structures, chapter 7, pages 185-211. CSLI
Publications and FoLLI, 1997.

[31] S. Vorobyov. An improved lower bound for the elementary theories of trees. In

Procedings of the International Conference on Automated Deduction (CADE),
volume 1104 of Lecture Notes in Computer Science, pages 275-287, Rutgers,
NJ, 1996. Springer-Verlag, Berlin, Germany.

19

Draft12/2/1998A Proof of the Charaterization

Lemma 5.5 (Key) For all paths u; p1; p2; n0, variables x; y; z, and constraints j:

1. If yu0Rp2p1x^ 2 L(A /0j) and zn0Rp1x^ 2 L(A /0j) then yu0Rp2n0\Gamma 1z, 2 L(A /0j).
2. If yu0Ru\Gamma 1x^ 2 L(A /0j) and xuu00a* 2 L(A /0j) then yu0u00a, 2 L(A /0j)
Proof. to be done 2

Proposition 5.7 (Characterization) If j is a F-closed FT^ constraint, then

9xj j=j ^ L(Afxgj ) :
Proof. The direction from left to right (correctness) is clear. For the direction from
right to left let V = V (9xj), and assume a solution a of V L(Afxgj ). Define an extension a0 of a by setting, for all x 2 V (9xj): a0(x) = a(x), and for all x 2 x: a0(x) = t
where

Da0(x) = fp j xp* 2 L(A /0j0)g [

fpp00 j z 2 V; zp0Rp\Gamma 1x^ 2 L(A /0j0 ); p0p00 2 Da(z)g
La0(x) = f(p; a) j xpa* 2 L(A /0j0 )g [

f(pp00; a) j z 2 V; zp0Rp\Gamma 1x^ 2 L(A /0j0); (p0p00; a) 2 Da(z)g

It is obvious that Da0(x) is prefix closed. Lemma A.1 (which relies on the Key
Lemma 5.5) yields that La0(x) is a partial function such that a0(x) is a feature tree.
Lemma A.2 proves that a0 is indeed a solution of j0. 2

Lemma A.1 La0(x) is a partial function.
Proof. It is sufficient to prove the lemma for x 2 fxg. Suppose that there exists a pathp

and labels a and b such that (p; a) 2 Lt and (p; b) 2 Lt. We have to prove that a = b.

1. Suppose that both pairs have been contributed by the second clause of the definition of Lt. There exist paths u; u0; u00; n; n0; n00 and variables y; z 2 V such thatp

= uu00 = nn00 and

(a) yu0Ru\Gamma 1x^ 2 L(A /0j0); (u0u00; a) 2 Da(y)
(b) zn0Rn\Gamma 1x^ 2 L(A /0j0); (n0n00; b) 2 Da(z)

Without loss of generality, we can assume that n is a prefix of u, i.e. u = np1 for
some p1. The key Lemma 5.5 implies yu0Rp\Gamma 11 n0\Gamma 1z, 2 L(A /0j0 ). Since y; z 2 V ,

we also have yu0Rp\Gamma 11 n0\Gamma 1z, 2 L(Afxgj0 ) such that the Correctness Proposition
5.4 yields:

V L(Afxg

j0 ) j= y?[u0],z?[n0p1] j= y[u0u00],z[n0p1u00]

It remains to show that p1u00 = n00 which then implies a = b since a is a solution
of V L(Afxgj0 ). This can be seen as follows. Since u = np1 we know uu00 = np1u00.
In combination with uu00 = nn00 this implies nn00 = np1u00 and hence n00 = p1u00
as required.

20

Draft12/2/1998 2. Suppose that (p; a) and (p; b) are both contributed by the first clause. Thenj0

j= ^ L(A /0j0) j= x[p] * a ^ x[p] * b

such that the satisfiability of j0 implies a = b.
3. Suppose that (p; a) is contributed by the first clause of the definition of Lt and

(p; b) by the second clause. There exist paths u; u0; u00 and a variables y 2 V such
that p = uu00 and

(a) yu0Ru\Gamma 1x^ 2 L(A /0j0); (u0u00; b) 2 Da(y)
(b) xpa* ` L(A /0j0 )

Lemma 5.5 implies yu0u00a, 2 L(A /0j0 ). Since y 2 V the correctness Proposition
5.4 implies: V

L(Afxgj0 ) j= y?[u0u00],a

Since a is a solution of V L(Afxgj0 ) and (u0u00; b) 2 La(y) we conclude b = a.

2

Lemma A.2 The variable assignment a0 is a solution of j0.
Proof. We have to show that all basic constraints in j0 are validated by a0.

1. Case x[ f ]y 2 j0, x 2 V , y =2 V .

(a) For p 2 Da0(y) we show that f p 2 Da0(x).

i. p is contributed by a mountain chain. There exists u; u0; u00 and a variable z 2 V such that p = uu00, zu0Ru\Gamma 1y^ 2 L(A /0j0 ) and u0u00 2 Da(z).

Since x[ f ]y 2 j this yields zu0Ru\Gamma 1 f x^ 2 L(A /0j0) such that z 2 V implies: ^

L(Afxgj0 ) j= z?[u0] ^ x?[ f u]

Since u0u00 2 Da(z) we know that f uu00 2 Da(x).
ii. p is contributed to Da(y) by a local path, i.e. yp* 2 L(A /0j0). In this

case x f p* 2 L(Afxgj0 ) such that 9xj j= x[ f p] #, i.e. f p 2 Da(x).
(b) For f p 2 Da0(x) we show that p 2 Da0(y). Let f p 2 Da(x). There is a

mountain chain with global variable x since x f y* and yeRey,. Henceep

2 Da0(y) by the second clause.

(c) For (p; a) 2 Da0(y) we show that ( f p; a) 2 Da0(x).

i. (p; a) is contributed by a mountain chain. There exists u; u0; u00 and

variables z; z0 such that p = uu00 and

z 2 V; yuz0* 2 L(A /0j0); zeRu0\Gamma 1z0, 2 L(A /0j0); (u0u00; a) 2 La(z)

Since z; x 2 V we we have zu0Ru\Gamma 1 f x^ 2 L(Afxgj0 ) such that

^ L(Afxg

j0 ) j= z?[u0] ^ x?[ f u]

Since (u0u00; a) 2 La(z) we know that ( f uu00; a) 2 La(x).

21

Draft12/2/1998 ii. (p; a) is contributed to Da(y) by a local path, i.e. ypa* 2 L(A /0j0). In

this case x f pa* 2 L(Afxgj0 ) such that ( f p; a) 2 Da(x).

(d) For ( f p; a) 2 La0(x) we show that (p; a) 2 Da0(y). Let ( f p; a) 2 La(x).

The assumption x[ f ]y 2 j implies x f Re\Gamma 1y^ 2 L(A /0j) such that (ep; a) 2
La0(y).

2. Case x[ f ]y 2 j0, x =2 V , y 2 V . to be done
3. Case x[ f ]y 2 j0, x; y 2 V . This case is trivial since a(x) = a0(x) and a(y) = a0(y)

and a is a solution of x f y* and x f Re\Gamma 1y^.

4. Case x[ f ]y 2 j0, x; y =2 V . to be done
5. Case x^y 2 j0 and x; y 2 V . This case is trivial since a is a solution of xeRe\Gamma 1y^.
6. Case x^y 2 j0 and x 2 V , y =2 V .
7. Case x^y 2 j0 and x =2 V , y 2 V . to be done
8. Case x^y 2 j0 and x; y =2 V . to be done

(a) For p 2 Da0(x) show p 2 Da0(y)

i. If xp* 2 L(A /0j0) thus yp* 2 L(A /0j0) such that p 2 Da0(y).
ii. If p is contributed by a mountain chain to Da0(x) then pe is contributed

by a longer mountain chain to Da0(y).

(b) For (p; a) 2 La0(x) show (p; a) 2 La0(y)

i. If xpa* 2 L(A /0j0) thus ypa* 2 L(A /0j0 ) such that (p; a) 2 La0(y).
ii. If (p; a) is contributed by a mountain chain to La0(x) then (pe; a) is

contributed by a longer mountain chain to La0(y).

2

B Satisfiability and Entailment of F T^
For sake of completeness, we restate results on satisfiability and entailment of FT^
without existential quantifiers that are proved in [16, 15]. They will be used in Appendix C for proving the reduction of entailment of FT^ with existential quantifiers as
stated in Proposition 5.8.

Proposition B.1 (Satisfiablity Test [16, 15]) There exists a cubic time algorithm that
given a constraint j either detects the unsatisfiability of j, or proves its satisfiability
and returns an F-closed constraint equivalent to j.

Proof. The same statement can be found as Lemma 21 in [15]. There a proof is given
which is based on the completeness of the satisfiablity test of FT^ presented in [16].
2

22

Draft12/2/1998 Proposition B.2 (Least Solutions [15]) Let j be satisfiable and F-closed. For everyvariable x 2 V (j) and all a; p the following two equivalences hold:

j j= x[p] # iff xp* 2 L(A /0j)j
j= x[p] * a iff xpa* 2 L(A /0j)

Proof. As in [15] we define syntactic entailment judgements of the form j ` x[p]*y
and j ` x[p]*a as follows.

j ` xey* if y^x 2 jj

` x f y* if x[ f ]y 2 jj
` xp1p2y* if exists z such that j ` xp1z* and j ` zp2y*j

` xpa* if exists z such that j ` xpz* and z(a) 2 j

Next note that j ` xpz0* for some z0 if and only if xp* 2 L(A /0j), and that j ` xpa*
if and only if xpa* 2 L(A /0j). Hence Proposition B.2 follows from Propositon 22
in [15]. 2

Proposition B.3 (Entailment of Inequations [16]) If j is F-closed then j j= x^y if
and only if x = y or x^y 2 j.

Proof. The proposition is equivalent to Proposition 13 in [16]. 2

C Proof of the Reduction
Proposition 5.8 (Reduction). Let j and j0 be F-closed FT^ constraints and x a sequence of variables such that all labels and free variables in 9xj0 occur in j. Further
assume that j ^ 9xj0 is satisfiable. Then

j j= 9xj0 if and only if L(Afxgj0 ) ` L(A /0j) :

Proof. The direction from right to left follows directly from Proposition 5.7. The
inverse follows from Lemma C.3. 2

For all constraints j and features f fix a fresh variable x f and define the following
extension jxf of j:

jxf = j ^ x[ f ]x f ^ Vfx f ^y j x 2 V (j); x f Ry^ 2 L(Aj)gV

fy^x f j x 2 V (j); yR f x^ 2 L(Aj)g

For the induction proofs to come we need the following syntatic and semantic properties of extensions jxf .

Lemma C.1 (Syntactic Properties of Extensions) For all x; f ;V :

1. If j is satisfiable and F-closed, then jxf also is satisfiable and F-closed.

23

Draft12/2/1998 2. If x f * 2 L(AVj ) then L(AVj ) = L(AV[fxf gjx

f ).

Proof. to be done. 2

Lemma C.2 (Semantic Properties of Extensions) Let j be satisfiable. Then, for all
x; p; p0; a:

1. If j j= x[ f ] #, then: j j= x[ f p] * y iff jxf j= x f [p] * y
2. j j= x?[ f p],a iff jxf j= x f ?[p],a
3. j j= x?[ f p] ^ y?[p0] iff jxf j= x f ?[p] ^ y?[p0]
4. j j= x?[p] ^ y?[ f p0] iff jyf j= x?[p] ^ y f ?[p0]
5. j j= x?[ f p],y?[p0] iff jxf j= x f ?[p],y?[p0]

Proof. For illustration, we check the first two cases.

1. j j= x[ f p] * y iff j j= x[ f ] # ^8x f (x[ f ]x f ! x f [p] * y)

iff j j= 8x f (x[ f ]x f ! x f [p] * y) (since j j= x[ f ] #)
iff j ^ x[ f ]x f j= x f [p] * y
iff jxf j= x f [p] * y

Notice that we need the assumption j j= x[ f ] # only for the upward implication.

2. j j= x?[ f p],a iff j j= 8x f (x[ f ]x f ! x f ?[p],a)

iff j ^ x[ f ]x f j= x f ?[p],a
iff jxf j= x f ?[p],a

The proofs of the remaining three cases are analogue. 2

Lemma C.3 For all w; j;V : If w 62 L(AVj ), then j 6j= hwi.
Proof. The proof is by case distinction over w.
xp*: If xp* 62 L(A /0j) then j 6j= x[p] * by Proposition B.2, first statement.
xpa*: If xpa* 62 L(A /0j) then j 6j= x[p] * a by Proposition B.2, second statement.
xpy*: Assume xpy* 62 L(A /0j). We show j 6j= x[p] * y by induction over p.

p = e: Then x[p] * y is equivalent to y^x. On inequations, syntactic containment and entailment coincide according to Proposition B.3. So j 6j= y^x
since otherwise y^x 2 j such that xey* 2 L(A /0j) in contradiction to our
assumption.

p = f p0: We can assume x f * 2 L(A /0j) since otherwise j 6j= x[ f ] * by the case

on xpy* considered above. If x f * 2 L(A /0j), it suffices to show x f p0y* 62
L(A /0jxf ) since in this case, jxf 6j= x f [p0] * y by induction assumption such
that j 6j= x[ f p0] * y by Lemma C.2, clause 1.

24

Draft12/2/1998 Thus, we show x f p0y* 62 L(A /0j) by contradiction. If x f p0y* 2 L(A /0jxf ),

then by definition of the automaton x f p0y* 2 L(A /0jxf ) and hence, by

Lemma C.1, xpy* 2 L(Afxf gjxf ) = L(A /0j).

xpa,: Assume xpa, 62 L(A /0j). We show j 6j= x?[p],a by induction over p.

p = e: We distinguish three cases, depending on the number n of distinct labels c such that xec, 2 L(A /0j).

n = 0: Let b be an arbitrary label distinct from a. Then clearly j ^ b(x) isF

-closed and satisfiable and entails :x?[e],a. Hence j 6j= x?[e],a.

n = 1: Let b be the unique label such that xeb, 2 L(A /0j). The assumption

xpa, 62 L(A /0j) implies a 6= b. Clearly, j ^ b(x) is satisfiable and entails :x?[e],a. Hence j 6j= x?[e],a.

n * 2: This is impossible since Lemma 5.6 together with clause 7 of Proposition 5.1 would imply xea, 2 L(A /0j), in contradition to our assumption.

p = f p0: By Lemma C.1, x f p0a, 62 L(A /0jxf ). By Lemma C.2, clause 2, this

implies j 6j= x?[p],a.

xpRp0y^: Assume xpRp0y^ 62 L(A /0j). We show j 6j= x?[p] ^ y?[p0\Gamma 1] by simultaneous induction over p and p0.

p = p0 = e: Then xRy^ is equivalent to the basic constraint x^y, and j 6j= x^y

follows directly from [16].

p = f p00: By Lemma C.1, x f p00Rp0y^ 62 L(A /0jxf ). By Lemma C.2, clause 3, this

implies j 6j= x?[p] ^ y?[p0\Gamma 1].
p0 = p00 f : By Lemma C.1, xpRp00y f ^ 62 L(A /0jyf ). By Lemma C.2, clause 4, this

implies j 6j= x?[p] ^ y?[(p00 f )\Gamma 1].

xpRp0y,: Assume xpRp0y, 62 L(A /0j). We show j 6j= x?[p],y?[p0] by simultaneous

induction over p and p0.

p = p0 = e: From Proposition 5.1, clause 8, and Lemma 5.6 we know that for

all z and p, zpx* 62 L(A /0j) or zpx* 62 L(A /0j). Hence, for all z and p,j

6j= z[p] * x or j 6j= z[p] * y by the third case above, and therefore j 6j= x,y
by definition of x,y.

p = f p00: By Lemma C.1, x f p00Rp0y, 62 L(A /0jxf ). By Lemma C.2, clause 5, this

implies j 6j= x?[p],y?[p0].
p0 = p00 f : Follows from the previous case since xpRp0y, 2 L(A /0j) iff

yp0RRpRy, 2 L(A /0j).

2

25