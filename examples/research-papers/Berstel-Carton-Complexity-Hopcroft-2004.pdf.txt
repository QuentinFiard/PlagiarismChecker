

On the Complexity of Hopcroft's State

Minimization Algorithm

Jean Berstel1 and Olivier Carton2

1 Institut Gaspard Monge,
Universitt^e de Marne-la-Vallt^ee
http://www-igm.univ-mlv.fr/~berstel2

LIAFA, Universitt^e Paris 7
http://www.liafa.jussieu.fr/~carton

Abstract. Hopcroft's algorithm for minimizing a deterministic automa-ton has complexity

O(n log n). We show that this complexity bound is
tight. More precisely, we provide a family of automata of size n = 2k
on which the algorithm runs in time k2k. These automata have a verysimple structure and are built over a one-letter alphabet. Their sets of

final states are defined by de Bruijn words.

1 Introduction
E\Delta cient state minimization algorithms are an important issue for tools involvingfinite state automata, as they arise e.g. in computational linguistics. The elementary minimization algorithm usually credited to Moore (see also [1]) has beenimproved by Hopcroft [2]. In the special case of finite sets, minimal automata
can be constructed and maintained even more e\Delta ciently (see [3, 4] and [5] fora recent survey). Extensions to more general situations of Hopcroft's algorithm
are considered in [6, 7, 8].Hopcroft's algorithm is known to run in time

O(n log n) for an automatonwith
n states. We show here that this bound is tight, that is that this runningtime is reached for an infinite family of automata. For that purpose we define

a class of automata over a unary alphabet. These automata have a very simplestructure since they are just made of a single cycle. The final states of these
automata are defined by a pattern given by de Bruijn words. The simple structureof the automaton and the special layout of the final states allows us to control
precisely how some particular execution of the algorithm runs.We should point out that Hopcroft's algorithm has a degree of freedom because, in each step of its main loop, it allows a free choice of a set of states to beprocessed. Hopcroft has proved that any sequence of choices can be processed
in time O(n log n). Our family of examples results in showing that there existssome "unlucky" sequence of choices that slows down the computation to achieve
the lower bound \Omega (n log n). Partial results on another family of examples havebeen obtained in [9].

M. Domaratzki et al. (Eds.): CIAA 2004, LNCS 3317, pp. 35E^44, 2005.c\Delta  Springer-Verlag Berlin Heidelberg 2005

36 J. Berstel and O. Carton

The paper is organized as follows. After some general definitions we outlineHopcroft's algorithm. We next present de Bruijn words, and then introduce our
family of automata. These are simply one letter automata with n = 2k statesorganized as a cycle. The key property is the choice of final states. Exactly one
half of the states are final, and they are chosen according to the occurrence ofthe symbol 1 in a de Bruijn word of order

k.Given such a cyclic automaton, we next present the strategy used to choose

the sets in Hopcroft's algorithm. We then prove that this choice indeed leads toa running time in

O(n log n). It should be observed that minization of one-letterautomata can be performed in linear time by another algorithm [7].

2 Minimal Automaton
In this section, we fix some notation and we give some basic definitions.We only use deterministic and complete automata. An automaton A over
a finite alphabet A is composed of a finite state set Q, a distinguished statecalled the initial state, a set

F \Delta  Q of final states, and of a next-state function
Q * A \Theta  Q that maps (q, a) to a state denoted by q * a.A partition of a set

Q is a family {Q1, . . . , Qn} of nonempty subsets of Qthat are pairwise disjoint (that is

Qi \Lambda  Qj = \Xi  for i \Pi = j) and cover Q, (that is
Q = Q1 \Sigma  * * * \Sigma  Qn). The subsets Qi are called the classes of the partition.If

Q is the state set of an automaton A, a congruence of A is a partitionwhich is compatible with the transitions of A. This means that if

q and q\Theta  arein the same class, then
q * a and q\Theta  * a are also in the same class for any q, q\Theta  \Upsilon  Qand any
a \Upsilon  A.A partition of

Q saturates a subset F of Q if F is the union of some of itsclasses. This also means that in a class either all elements or none belong to

F . Apartition {
Q1, . . . , Qn} is coarser than a partition {Q\Theta 1, . . . , Q\Theta m} if the partition{
Q\Theta 1, . . . , Q\Theta m} saturates each class Qi. This relation defines a partial order onpartitions.

It is well known that any regular set L of finite words is accepted by a uniqueminimal deterministic automaton.
It should be noticed that the minimal automaton of A does not depend onthe initial state of A as long as any state is reachable from it. In what follows,
we often omit to specify the initial state since it does not matter.

3 Hopcroft's Algorithm
Hopcroft [2] has given an algorithm that computes the minimal automaton ofa given deterministic automaton. The running time of the algorithm is

O(|A| *
n log n) where |A| is the cardinality of the alphabet and n is the number of statesof the given automaton. The algorithm has been described and re-described

several times [2, 10, 11, 12, 13, 14].The algorithm is outlined below, and it is explained then in some more detail.

On the Complexity of Hopcroft's State Minimization Algorithm 37
It is convenient to use the shorthand T c = Q \ T when T is a subset of theset

Q of states. We denote by min(B, C) the set of smaller size of the two sets
B and C, and any one of them if they have the same size.

1: P \Delta  {F, F c}
2: for all a \Theta  A do3: Add((min(

F, F c), a), S)
4: while S \Lambda = \Xi  do5: (

C, a) \Delta  Some(S) \Delta  takes some element in S
6: for each B \Theta  P split by (C, a) do
7: B\Delta , B\Delta \Delta  \Delta  Split(B, C, a)8: Replace

B by B\Delta  and B\Delta \Delta  in P
9: for all b \Theta  A do10:

if (B, b) \Theta  S then
11: Replace (B, b) by (B\Delta , b) and (B\Delta \Delta , b) in S
12: else13: Add((min(

B\Delta , B\Delta \Delta ), b), S)

Algorithm 1. HopcroftMinimization

Given a deterministic automaton A, Hopcroft's algorithm computes thecoarsest congruence which saturates the set

F of final states. It starts fromthe partition {
F, F c} which obviously saturates F and refines it until it gets acongruence. These refinements of the partition are always obtained by splitting

some class into two classes.Before explaining the algorithm in more detail, some notation is needed. For
a set B of states, we note by B * a the set {q * a | q \Upsilon  B}. Let B and C be twosets of states and let

a be a letter. We say that the pair (C, a) splits the set B ifboth sets (
B *a)\Lambda  C and (B *a)\Lambda  Cc are nonempty. In that case, the set B is splitinto the two sets

B\Theta  = {q \Upsilon  B | q * a \Upsilon  C} and B\Theta \Theta  = {q \Upsilon  B | q * a /\Upsilon  C} that wecall the resulting sets. Note that a partition {

Q1, . . . , Qn} is a congruence if andonly if for any 1 <=
i, j <= n and any a \Upsilon  A, the pair (Qi, a) does not split Qj.The algorithm proceeds as follows. It maintains a current partition P =

{B1, . . . , Bn} and a current set S of pairs (C, a) where C is a class of P and
a is a letter that remain to be processed. The set S is called the waiting set.The algorithm stops when the waiting set S becomes empty. When it stops, the

partition P is the coarsest congruence that saturates F . The starting partitionis the partition {

F, F c} and the starting set S contains all pairs (min(F, F c), a)for
a \Upsilon  A.The main loop of the algorithm takes one pair (

C, a) out of the waitingset S and performs the following actions. Each class
B of the current partition(including the class
C) is checked whether it is split by the pair (C, a). If (C, a)does not split
B, then nothing is done. Otherwise, the class B is replaced in thepartition P by the two resulting sets

B\Theta  and B\Theta \Theta  of the split. For each letter b,if the pair (
B, b) is in S, it is replaced in S by the two pairs (B\Theta , b) and (B\Theta \Theta , b),otherwise only the pair (min(

B\Theta , B\Theta \Theta ), b) is added to S.

38 J. Berstel and O. Carton

The main ingredient in the analysis of the running time of the algorithm isthat the splitting of all classes of the current partition according to a pair (

C, a)takes a time proportional to the size of
C. Therefore, the global running timeof the algorithm is proportional to the sum of the sizes of the classes processed

in the main loop. Note that a pair which is added to the waiting set S is notnecessarily processed later because it can be split by the processing of another
pair before it is considered.It should be noted that the algorithm is not really deterministic because
it has not been specified which pair (C, a) is taken from S to be processed ateach iteration of the main loop. This means that for a given automaton, there
are many executions of the algorithm. It turns out that all of them producethe right partition of the states. However, different executions may give rise to
different sequences of splitting and also to different running time. Hopcroft hasproved that the running time of any execution is bounded by

O(|A| * n log n).In this paper, we show that this bound is tight. More precisely, we show that

there exist automata over a one-letter alphabet and of size n and there existexecutions on these automata that give a running time of magnitude

O(n log n).Actually, we will not give automata for all integers
n but those of the form 2k.

4 De Bruijn Words
The family of automata that we use to show the lower bound on the running timeof Hopcroft's algorithm are based of de Bruijn words. We recall their definition.

Let w = w1 . . . wm a word of length m. By a slight abuse, we use the notation
wi even if the integer i is greater than m. We denote by wi the letter wi\Delta  where
i\Theta  is the unique integer such that 1 <= i\Theta  <= m and i\Theta  = i mod m. A circularoccurrence of a word

u = u1 . . . up of length p in w is an integer k in the interval[1;
m] such that wk+i-1 = ui for each i in [1; p].A de Bruijn word of order

n over the alphabet B is a word w such that eachword of length
n over B has exactly one circular occurrence in w. Since thereare |
B|n words of length n, the length of a de Bruijn word of order n is |B|n.Set for instance the alphabet

B = {0, 1}. The word w = 1100 is a de Bruijnword of order 2 since each of the words {00

, 01, 10, 11} has a circular occurrencein
w. The word w = 11101000 is a de Bruijn word of order 3.De Bruijn words are widely investigated (see for instance [15]). It is well

known that for any alphabet, there are de Bruijn words for all orders. We recallhere a short proof of this fact. Let

B be a fixed alphabet and let n be a fixedinteger. We recall the definition of the de Bruijn graph B

n of order n. Its vertexset is the set
Bn-1 of all words of length n - 1. The edges of Bn are the pairsof the form (

bu, ua) for u \Upsilon  Bn-2 and a, b \Upsilon  B. This graph is often presentedas a labeled graph where each edge (

bu, ua) is labeled by the letter a. Note thatthe function which maps each word
w = bua of length n to the edge (bu, ua) isone to one. Therefore, a de Bruijn word of order

n corresponds to an Euleriancircuit in B

n. Since there are exactly |B| edges entering and leaving each vertexof B
n, the graph Bn has Eulerian circuits [15] and there are de Bruijn words

On the Complexity of Hopcroft's State Minimization Algorithm 39
of order n. In Fig. 1 below we show the de Bruijn graph of order 4. Taking anEulerian circuit from it, one obtains the de Bruijn word

w = 0000100110101111of order 4.

Fig. 1. The de Bruijn graph of order 4 over the alphabet {0, 1}
5 Cyclic Automata
In what follows, we only consider de Bruijn words over the binary alphabetB = {0

, 1}. Let w be a de Bruijn word of order n. Recall that the length of wis 2
n. We define an automaton Aw over the unary alphabet {a} as follows. The

state set of Aw is {1, . . . , 2n} and the next state function is defined by i*a = i+1for

i < 2n and 2n * a = 1. Note that the underlying labeled graph of Aw is justa cycle of length 2

n. The final states really depend on w. The set of final states

of Aw is F = {1 <= i <= 2n | wi = 1}.For a word

u over B, we define a subset Qu of states of Aw. By definition theset
Qu is the set of positions of circular occurrences of u in w. If the length of uis
n, the set Qu is a singleton since the de Bruijn word w has exactly one circularoccurrence of

u. More generally, if the length of u is less than n, the cardinalityof
Qu is 2n-|u| since there are as many circular occurrences of u as there arewords

v such that |uv| = n. If u is the empty word, then Qu is by conventionthe set

Q of all states of Aw. By definition, the set F of final states of Aw is Q1while its complement

F c is Q0.

Fig. 2. Cyclic automaton Aw for w = 11101000

40 J. Berstel and O. Carton

Let w be the de Bruijn word 11101000. The automaton Aw is pictured inFig. 2. The sets

Q1, Q01 and Q011 of states are respectively {1, 2, 3, 5}, {4, 8}and {8}.

Since any circular occurrence of u in w is followed by either 0 or 1, the equality
Qu = Qu0 \Sigma  Qu1 holds. If a word u = bu\Theta  has a circular occurrence k in w, itssu\Delta x

u\Theta  has a circular occurrence k + 1 in w. If follows that if u is factorized
u = bu\Theta  where b \Upsilon  B, then Qu * a \Psi  Qu\Delta .

6 Hopcroft's Algorithm on Cyclic Automata
We claim that the running time of Hopcroft's algorithm on a cyclic automa-ton A

w may be of order n2n. Before giving the proof of this claim, we give anexample of an execution on the automaton pictured in Fig. 2. Since cyclic automata are over the unary alphabet A = {a}, we merely say that a class C splitsa class

B to mean that the pair (C, a) splits the class B.

E^ The starting partition is P = {F, F c} = {Q0, Q1} and S = {Q1}.
E^ The class Q1 is processed.*

The class Q0 is split into Q00 and Q01, and Q01 is added to S.*
The class Q1 is split into Q10 and Q11, and Q11 is added to S.
Then P = {Q00, Q01, Q10, Q11} and S = {Q01, Q11}.
E^ The class Q01 is processed.*

The class Q00 is split into Q000 and Q001, and Q001 is added to S.*
The class Q10 is split into Q100 and Q101, and Q101 is added to S.
Then P = {Q000, Q001, Q01, Q100, Q101, Q11} and S = {Q11, Q001, Q101}.
E^ The class Q11 is processed.*

The class Q01 is split into Q010 and Q011, and Q011 is added to S.*
The class Q11 is split into Q110 and Q111, and Q111 is added to S.
Then P = {Q000, Q001, Q010, Q011, Q100, Q101, Q110, Q111} andS = {

Q001, Q011, Q101, Q111}.
E^ Classes Q001, Q011, Q101, Q111 are processed but this gives no further split-ting since the partition is made of singletons.

Let us point out some properties of this particular execution of the algorithm.The classes that appear during the the execution are all of the form

Qu for someword
u. Every time a class Qu is split, it is split into the classes Qu0 and Qu1.Since these two classes have the same cardinality, the algorithm may either add

one or another one to S. In this execution we have always assumed that itchooses

Qu1.When the algorithm processes

Q01, it could have chosen to process Q11 in-stead. The algorithm would have run differently because the class

Q01 wouldhave been split by
Q11.We now describe the worst case strategy which we use to prove that the

O(n log n) bound of Hopcroft's algorithm is tight. Given n and the automaton

On the Complexity of Hopcroft's State Minimization Algorithm 41
Aw, we construct a sequence (Pk, Sk) for k = 1, . . . , n where Pk and Sk are thepartition and the waiting set given by

Pk = {Qu | u \Upsilon  Bk} and Sk = {Qv | v \Upsilon  Bk-11}.
In particular, P1 = {Q0, Q1} is the starting partition of Hopcroft's algorithmand S

1 = {Q1} is the starting content of the waiting set. The pair (Pk+1, Sk+1)is obtained from the pair (P

k, Sk) by obeying to the following strategy: choosethe sets
Qv of Sk in such an order that Qv does not split any set in the currentwaiting set S.

More precisely, a linear order < on Sk is said to be non-splitting if whenever
Qv\Delta  splits Qv then Qv < Qv\Delta . In other terms the strategy we choose is to processsets in S

k in some order which avoids splitting. We call such a strategy a non-splitting strategy. We will see in Proposition 1 that during this process, each

removal of an element of Sk contributes to two elements in Sk+1. It happens,as we will prove, that the new sets are not split by the currently processed set
either. We will see in Proposition 2 that non-splitting orders do exist.The transition from (P

k, Sk) to (Pk+1, Sk+1) involves 2k-1 iterations of themain loop of the algorithm. Each iteration removes one set from the waiting set,

and as we will show splits exactly two sets in the current partition and addsexactly two sets to the waiting set. These latter sets are of the form

Qv for
v \Upsilon  Bk1.

Proposition 1. If Hopcroft's algorithm starts from (Pk, Sk) and processes thesets in S

k in a non-splitting order, it yields the pair (Pk+1, Sk+1).

Proposition 2. Each Sk admits non-splitting orders.

We start with several lemmas. Some properties of the splitting of the sets ofthe form

Qu are needed. They are stated in the following lemma.

Lemma 1. Let u and v be two words of length smaller than n. The pair (Qv, a)splits

Qu if and only if there are b \Upsilon  B and s \Upsilon  B+ such that us = bv. If (Qv, a)splits
Qu, the resulting sets are Qus and Qu \ Qus. In particular if |u| > |v|, then
Qv does not split Qu.

Proof. Assume that u = bu\Theta  where b \Upsilon  B. Then the inclusion Qu * a \Psi  Qu\Delta  holds.Therefore if

v is not equal to u\Theta s for some s \Upsilon  B*, the intersection (Qu * a) \Lambda  Qvis empty and (

Qv, a) does not split Qu. Assume now that v = u\Theta s for some s.If
s is the empty word, the intersection (Qu * a) \Lambda  Qcv is empty and (Qv, a) doesnot split

Qu. It follows that s is not empty and that us = bv. \Omega ff

Corollary 1. If u and v are two words of the same length, the pair (Qv, a) splits
Qu if and only if there are b, b\Theta  \Upsilon  B such that ub\Theta  = bv. If (Qv, a) splits Qu, theresulting sets are

Qu0 and Qu1.

In other terms, if u and v are two words of the same length k, then Qv splits
Qu iff there is an edge (u, v) in the de Bruijn graph Bk+1.We are now ready for the proof of Proposition 1.

42 J. Berstel and O. Carton
Proof. (of Proposition 1) We consider how the execution goes according to ournon-splitting strategy from the pair (P

k, Sk) to the pair (Pk+1, Sk+1). We denoteby P and S the current values of the partition and of the waiting set when we

process the classes in Sk in a fixed non-splitting order. At the beginning of theexecution, P = P

k and S = Sk and at the end P = Pk+1 and S = Sk+1. ByCorollary 1, each class

Qu of Pk is split by exactly one class Qv in Sk and eachclass

Qv splits two classes Qu and Qu\Delta  in Pk. Moreover, Qv does not split anyother class in the current partition. By the choice of the ordering, both classes

Qu and Qu\Delta  do not belong to S when Qv is processed. The class Qu is splitinto the classes

Qu0 and Qu1. Since these two classes have the same cardinality,either
Qu0 or Qu1 may be added to S. Similarly the class Qu\Delta  is split into theclasses

Qu\Delta 0 and Qu\Delta 1. The execution of our strategy adds the classes Qu1 and
Qu\Delta 1 to the set S. The execution continues until all classes in Sk have beenprocessed. While this is done, classes

Qu1 for u \Upsilon  Bk are added to S. When allclasses
Qu from Sk have been processed, the partition P and the set S are Pk+1and S

k+1. \Omega ff

We now proceed to proof of the existence of non-splitting orders on Sk.
Proof. (of Proposition 2) Let Gk = (Vk, Ek) be the graph where the vertex set is
Vk = Bk-11 and the set of edges is Ek = {(u, v) | Qv splits Qu}. By Corollary 1,the graph

Gk is actually the subgraph of the de Bruijn Bk+1 defined by the set
Vk of vertices. The main property of that graph Gk is to be almost acyclic: Foreach

k >= 0, the only cycle in Gk is the edge (1k, 1k).It is easy to see that if there is a path of length

\Theta  from some node to vin
G, then the word v belongs to Bk-\Delta -11\Delta +1. It follows from the claim that thevertex 1

k is the only vertex which can appear in a cycle.

Since this graph is acyclic, the words of Bk-11 can be topologically ordered.Thus a non-splitting order on S

k is defined by Qu < Qv iff u < v in the previoustopological order. \Omega ff

The graph G3 of the previous proof is pictured in Fig. 3.

Fig. 3. The graph G3
Let us come back to the execution given at the beginning of that section. After
Q1 is processed, the partition P and the set S are P = {Q00, Q01, Q10, Q11} andS = {

Q01, Q11}. The class Q11 splits the class Q01 while the class Q01 does notsplit the class

Q11. A non-splitting order on S2 is given by Q01 < Q11. The class

On the Complexity of Hopcroft's State Minimization Algorithm 43
Q01 is therefore processed before the class Q11. The partition P and the set Sbecome P = {

Qu | u \Upsilon  B3} and S = {Qu1 | u \Upsilon  B2}.We finally analyze the running time of the algorithm. The following result

shows that the O(n log n) upper bound of the running time of Hopcroft's algo-rithm is tight.

Theorem 1. The non-splitting strategy requires n2n operations for the mini-mization of the automaton A

w of size 2n for any de Bruijn word w of order n.

Proof. The time needed to process a class C is proportional to the size of C. Inthe execution that we give the algorithm processes all classes

Qu1 for |u| < n.Summing all the sizes, we get that the running time of the algorithm is

n2nwhereas the size of the automaton A

w is 2n. \Omega ff

7 Conclusion
We have shown that Hopcroft's algorithm may have executions running in time
O(n log n). These executions run on the cyclic automata that we have defined. Itis not very di\Delta cult to see that there are also executions that run in linear time

for the same automata. It is still open whether there are automata on which allexecutions of Hopcroft's algorithm do not run in linear time.

These different executions depend on the choice of the class which is processedat each iteration of the main loop of the algorithm. Defining strategies which
specify which class is processed might be of interest from a theoretical andpractical point of view.

Acknowledgment. We would like to thank Luc Boasson and Isabelle Fagnot forfruitful discussions and the anonymous referees for their helpful comments.

References

1. Hopcroft, J.E., Ullman, J.D.: Formal Languages and their Relation to Automata.

Addison-Wesley (1969)2. Hopcroft, J.E.: An

n log n algorithm for minimizing states in a finite automaton.In Kohavi, Z., Paz, A., eds.: Theory of Machines and Computations, Academic

Press (1971) 189-1963. Krivol, S.L.: Algorithms for minimization of finite acyclic automata and pattern
matching in terms. Cybernetics 27 (1991) 324- 331 translated from Kibernetika,No 3, May-June 1991, pp. 11-16.
4. Revuz, D.: Minimisation of acyclic deterministic automata in linear time. Theoret.

Comput. Sci. 92 (1992) 181-1895. Daciuk, J.: Comparison of construction algorithms for minimal, acyclic, deterministic finite-state automata from sets of strings. In Champarnaud, J.M., Maurel,
D., eds.: 7th Implementation and Application of Automata (CIAA 2002). Volume
2608 of Lect. Notes in Comput. Sci., Springer Verlag (2002) 255-2616. Cardon, A., Crochemore, M.: Partitioning a graph in

O(|A| log2 |V |). Theoret.Comput. Sci.
19 (1982) 85-98

44 J. Berstel and O. Carton

7. Paige, R., Tarjan, R.E., Bonic, R.: A linear time solution for the single function

coarsest partition problem. Theoret. Comput. Sci. 40 (1985) 67-848. Paige, R., Tarjan, R.E.: Three partition refinement algorithms. SIAM J. Comput.

18 (1987) 973-9899. Gai, A.T.: Algorithmes de partionnement : minimisation d'automates et applications aux graphes. Mt^emoire de DEA, Universitt^e Montpellier II (2003)
10. Gries, D.: Describing an algorithm by Hopcroft. Acta Inform. 2 (1973) 97-10911. Aho, A., Hopcroft, J., Ullman, J.: The Design and Analysis of Computer Algorithms. Addison-Wesley (1974)12. Beauquier, D., Berstel, J., Chrt^etienne, P.: t^Elt^ements d'algorithmique. Masson
(1992)
13. Blum, N.: A O(n log n) implementation of the standard method for minimizing

n-state finite automata. Inform. Proc. Letters 57 (1996) 65-69
14. Knuutila, T.: Re-describing an algorithm by Hopcroft. Theoret. Comput. Sci. 250(2001) 333-363

15. Tutte, W.T.: Graph Theory. Volume 21 of Encyclopedia of Mathematics and itsApplications. Addison-Wesley (1984)