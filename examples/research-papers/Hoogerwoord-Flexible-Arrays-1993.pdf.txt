

A  L og arithmic  I m p l e m e n t a t i o n   o f  Flexible  Arrays 

Rob  R.  Hoogerwoord 
Eindhoven  University of Technology, department  of Mathematics and  Computing  Science, postbus  513,  5600  MB  Eindhoven,  The  Netherlands 

A b s t r a c t .   In  this  paper  we  derive  an  implementation  of so-called flexible arrays;  a flexible array is  an  array  whose size can  be  changed  by  adding  or 

removing elements at  either end.  By representing flexible arrays by so-called Braun  trees, we are  able to  implement  all array operations with  logarithmic 
---in the size of the  array-- time complexity. Braun  trees  can  be  conveniently  defined  in  a  recursive  way.  Therefore,  we 
use functional programming to derive (recursive) definitions for the functions representing  the  array operations.  Subsequently,  we  use  these  definitions to 
derive (iterative) sequentiM implementations. 

0  I n t r o d u c t i o n  
A  flexible array  is  an  array  the  size of which  can  be  changed  by  adding  or  removing 
elements  at  either  end.  In  1983  W. Braun  and  M. Rem  designed  an  implementation 
of flexible arrays by means of balanced binary trees, which are used in such  a way that 

all  array  operations  can  be  performed  in  logarithmic  time.  Examples  of programs  in 
which  flexible  arrays  are  used  can  be  found  in  [1]. 

The  original  presentation  of this  design  by  Braun  and  Rem  is,  however,  rather 
complicated  [0].  In  this  paper  we  use  functional  programming  to  derive  this  im- 
plementation  in  a  more  straightforward  way.  We  do  so  in  three  steps.  First,  the 
binary  trees  used  to  represent  arrays  are  defined  as  a  recursive  data  type.  Second, 
we  derive recursive  definitions  for  the  functions  implementing the  array  operations; 
this  is  relatively easy.  Finally, we  use  these  definitions to  derive iterative sequential 
implementations  of the  array  operations,  where  the  Braun  trees  are  represented  by 
means  of nodes  linked  together  by  pointers. 

1  F u n c t i o n a l   P r o g r a m s  
1.0  S p e c i f i c a t i o n s  
For the  sake of simplicity of presentation,  we assume  that  all (flexible) arrays have  0 
as their  lower bound.  Then,  an  array of size  d, 0 <  d,  is a  function of type  [0, d)  --~ A, 
where  A  denotes  the  element  type of the  array. As  usual for functions,  we call  [0, d) 
the  domain  of the  array  and  we call values of type  A  elements.  The  size  of an  array 
is  an  attribute  of that  array's  value,  not  of its  type  - - a s   in  P a s c a l - - .   Arrays  being 
flexible means  that  different  arrays  may  have  different  sizes;  yet,  they  are  all  of the 
same  type. 

We denote  the  size of array  x  by  # x .   The  function  #  is one of the operations to 
be  implemented.  Another  important  operation  on  arrays is  element  selection,  which 

192 
is the  same  as function  application:  for array  x  and  i, 0 _< i < # x ,   element  z-i  is the 
value  of  z  in  point  i  of its  domain.  Notice  that  an  array  is  completely  determined 
by  its  size  and  its  elements.  In  what  follows we  use  this  without  explicit  reference. 

By  means  of  element  replacement,  an  array  can  be  modified  in  a  single  point 
of its  domain.  For  array  z,  natural  i, 0 <  i <  # z ,   and  element  b,  we  use  z : i, b  to 

denote  the  array  y  that  satisfies: 

# y = # x   A  y . i = b   A  (Vj  :  0 < j < # x   A  j # i   :  y . j = x . j )  
Notice  that  element  selection  and  replacement  are  only  meaningful  for  nonempty 
arrays. 

The  functions  le  and  he  represent  the  operations  to  extend  an  array  with  an additional  element  at  the  lower or  higher  end  of its  domain;  that  is,  for  element  b 

and  array  z,   arrays  ie.b.x  and  he.b.z  are  the  arrays  y  and  z  that  satisfy: 

# y = # x + l   A  y . O= b  A  ( V j : O < j < # x : y . ( j + l ) = x . j )   ,  and 
# z = # x + l   A  z . ( # x ) = b   A  ( V j : O < j < # x : z . j = x . j )  

Finally,  the  (partial)  inverses of  le  and  he  are  the functions  lr  and  hr ; they  can 
be  used  to  remove  the  extreme  elements  of an  array.  For  array  x  satisfying  # x   >__ 1, 
arrays  lr.x  and  hr.x  are  the  arrays  y  and  z  satisfying: 

# y = # x - 1   A  ( V j : O < _ j < # y : y . j = x . ( j + l ) )   ,  and 
# z = # x - 1   A  ( V j : O < _ j < # z : z . j = z . j )  

/.From  these  specifications  it  follows,  for  instance,  that  lr.(le.b.x)  =  x  and  that 

hr.(he.b.x)  =  x. 

1.1  B r a u n   Tr ees 
For  the  sake  of  the  required  (logarithmic)  efficiency,  we  use  a  divide-and-conquer 
approach.  The  unique  array  of size  0  can  be  represented  by  the  unique  element  of a 
unit  type.  An array  z  of size  d + l ,   0 < d,  can be represented  as follows. One element, 
namely  x.0,  is  kept  separate;  the  remaining  elements  x . ( j + l ) ,   0 < j   < d,  are  parti- 
tioned  according to  the  parity  of j .   Th at  is,  we distinguish  the  elements  x . ( 2 * i+ l) ,  

0 < 2 . i  < d,  and  the  elements  x- ( 2 . i+2 ) ,  0 <  2 , i+ 1   < d.  The  ranges  0 _< 2 . i   <  d  and 
0 < 2 . i +1   <  d  can  be  rewritten  into  0_< i < ddiv2+dmod2  and  0 _< i < ddiv2  respec- 
tively.  Hence,  the  two  collections  of  elements  thus  obtained  can  be  considered  as 

arrays  again,  of sizes  ddiv2+dmod2  and  ddiv2. 

So,  an  array  of size  d + l  can  be  represented  by  a  triple  consisting  of an  element 
and  two  arrays  of  sizes  ddiv2+dmod2  and  ddiv2.  By  applying  the  same  trick  to 
these  two  subarrays,  we  obtain  a  recursive  data-type  the  elements  of which  we  call Braun  trees. 

We  represent  them  by  tuples,  using  the  empty  tuple  ()  to  represent 
the  empty  array  and  using  the  triple  (a, s, t)  to  represent  the  array  consisting  of element  a  and  subarrays  s  and  t. 

We devote  the  remainder  of this  section  to  a  formal  definition  of Braun  trees  and 
of how  they  represent  flexible  arrays.  Trees  are  defined  recursively  by: 

193 
()  is a  tree  ,  and 
(a , s , t )   is  a  t r e e ,   for  element  a  and  tree  s, t  

The  fact  that  the  two subtrees of  (a, s, t)  represent arrays of almost  equal sizes gives 
rise  to  trees  that  are  balanced,  which  can  be  formalised  as  follows.  We  introduce  a 
predicate  bal  on  the  set  of trees  and  we  define  the  Braun ~ trees  as  those  trees  that 
satisfy  bal.  This  predicate is  defined  in  terms  of the  sizes of the  subtrees;  therefore, 

we  denote  the  size  of tree  s  by  # s :  

hal-()  =_  true 
bal.(a,s,t)  =  #t   <_ # s  A  #s   <_ #t + l   A  bal.s  A  bal.t #() 

=  o 
# ( a , s , t )   =  l + # s + # t  

Throughout  the  rest  of this  paper  we only consider  Braun  trees  and  we use  the  term 

"tree"  for  "Braun  tree". 

We  now  define  how  trees  represent  arrays,  by  defining  how  the  size  and  the 
elements  of the  array  depend  on  the  tree  representing  it.  First,  we have: 

the  size  of the  array  represented  by  tree  s  equals  # s  
Second,  we  denote  element  i  of the  array  represented  by  tree  s  by  s!i ; for  element 
a  and  tree  s , t ,   the  elements  of  the  array  represented  by  (a, s,t)  are  defined  as 
follows: 

(a , s , t ) !O   =  a 

( a, s , t )!( 2* i + l )   =  s!i  ,  for  i : O< i < # s 
( a, s , t )!( 2* i + 2)   =  t!i  ,  for  i :O < i < #t  

Notice that  the  domain  of the  array thus  represented is  [0, d + l ) ,   where  d  =  #s + #t   ; 
the  tripartitioning  {0)  L)  { i : 0 < i < # s : 2 . i + 1 )   L)  { i : 0 < i < # t : 2 * i + 2 )   exactly 
characterizes  this  domain.  T h at   trees  are  balanced  plays  a  crucial  role  here,  as  is 
reflected  by  the  following property. 

P r o p e r t y   O: bal.(a,s,t)  A  # ( a , s , t ) =  

d + l  
D 

=~  # s   =  ddiv2+drnod2  A  #t   =  ddiv2 

The  size  of a  tree  equals  the  size  of  the  array  represented  by  it;  computing  the 
size  of the  array  in  this  way  requires  a  linear  amount  of time,  though.  It  is possible 

and  sufficient  to  record  the  size  of  the  whole  array  separately. As  a  consequence  of 
Prop erty  0,  it  is not  necessary  to  record  the  size of  each  subtree  together  with  that 
subtree. 

As  a  consequence  of its  balance,  the  height  of a  tree  is  proportional  to  the  loga- 
rithm  of its  size.  This  is  the  reason  why  all  operations  on  trees  require  an  amount 
of time  that  is  at  most  logarithmic  in  the  size of the  tree. 

0 We  use  the  term  "Braun  tree"  because  "balanced"  is  too  general  a  notion  here:  Braun trees  are  trees  that  are  so  neatly  balanced  that  they  admit  the  operation  of  element 

selection,  as defined in  the  next  paragraph. 

194 
1.2  E l e m e n t   S election   a n d   R e p l a c e m e n t  
In the  previous section we have defined  element  selection.  This  definition  is  recursive 

and  it  can  be  considered  as  a  (functional)  program  right  away. We  repeat  it  here: 

(a,s,t)  !O  =  a (a, s, t)!(2 , i+ l)  =  s!i  ,  for  i:0<i< #s 

( a , s , t ) ! ( 2 , i + 2 )   =  t!i  ,  for  i : O < i < # t  
Element  replacement  is  so  similar  to  element  selection  that  there  is  hardly  any- 
thing  to  derive;  the  difference  lies  only  in  the  value  produced: 

(~,s,t)  :0,b  =  (b,s,t) 
(a,s,t)  : ( 2 , i + l ) , b   =  ( a , ( s : i , b ) , t )   ,  for  i : O < i < # s  
( a , s , t ) : ( 2 , i + 2 ) , b   =  ( a , s , ( t : i , b ) )   ,  for  i : O < _ i < # t  

1.3  I n t e r m e z z o   o n   B a g   I n s e r t i o n s  
Arrays  as  well  as  trees  can  be  considered  as  (representations  of)  bags  of elements. In  terms  of bags,  the  two  array  extension  operations,  le  and 

he,  both  boil  down  to 
insertion  of an  element  into  a  bag.  To separate  our  concerns,  we first  investigate  bag 
insertion  in  isolation. 

We  denote  the  bag  represented  by  tree  s  by  [[s~;  a  recursive  definition  for 
function  ~-~  is -- wh er e  { }  denotes the  empty  bag and  +  denotes  bag summation--: 

We  now  derive  definitions  for  a  function  ins,  where  for  element  b  and  tree  s  the 
tree  ius.b.s  is  a  solution  of the  equation 1 (with  unknown  u ) : 

We  use  the  first  conjunct  of this  equation  to  guide  our  derivation,  whereas  the 
second  conjunct  remains  as  an  a  posteriori  proof obligation.  By  induction  over  the 
size  of the  trees  we derive,  starting  with  the  case  that  s  is  the  empty  tree: 

=_  { 
=_  { 
~= 

1 The  word 

{ }  is  the  identity  of  +  ; definition  of  ~. ]]  } 
=  { b} +~ ()]]+~ ()~ 
definition  of  [.~  } 

=  ~  (b, (),()) 
{  Leibniz  } 
=  (b , (), ())  . 

"equation"  is  used  here for arbitrary  predicates,  not  just  equalities. 

195 
The  first  step  of this  derivation  may  look  like  a  rabbit,  but  it  is  not:  the  only  way 

to  solve  an  equation  of the  form  u  :  ~ u~ - -E  is  to  transform  E  into  an  expression 
of the  form  I F ] ]   and  then  to  apply  "Leibniz",  as  we  did  in  the  last  step.  In  view 
of the  definition  of  [[.]]  and  the  occurrence  of  {b},  the  only  thing  we  can  do  is  to 
work  towards  a  formula of the  shape  ff (b, ?, ?) ]] . 

Notice  that  in  the  above derivation  in all  steps  except  the  last  one,  only the right- 
hand  side  of the  equality  is  manipulated.  In  order  to  avoid  the  continued  rewriting 
of the  constant  left-hand  side,  we shall  carry out  the  calculation  with  the  right-hand 

expression  only.  That  is,  in  order  to  solve  an  equation  of the  form  u  :  f.u  = E,   we 
transform  E  into an  equivalent  expression  f . F   in isolation,  after  which we conclude 

that  F  is  a  solution  of the  equation. 

For  the  composite  tree  (a, s,t)  we  derive,  in  the  same  "goal-driven"  way: 

{b} +  (a, s, t) ]] 
=  {  definition  of  [.]]  } 

{b}+  {a} 

=  { specification  of  ins,  by  induction  hypothesis  (see  below)  } 

{b} +  ~ ins.a.s ]] + I t ]] 
=  {  definition  of  [[.]]  } 

[[  (b,  ins.a.s,  t)  . 

The  second  step  of  this  derivation  represents  a  choice  out  of  many  possibilities; 
because  bag  summation  is  symmetric  and  associative,  we have  8  possibilities  here: 
a  and  b  may  be  interchanged,  s  and  t  may  be  interchanged,  and  the  recursive 
application  of  ins  may be taken  as the  "right"  or as the  "left" subtree  in the resulting 

tree.  Thus,  we  obtain  8  different  definitions  for  a  function  ins  satisfying  the  first 
conjunct  of the  above  specification. 

Regarding  the  remaining  proof obligation  we  observe  that,  by  the  definition  of hal,  bal.(b,  (),()) 

holds.  For  the  8  alternatives  a  simple  calculation  reveals  that, 
generally,  bal. (a, s, t)  ==~ bal.u  only holds when  s  and  t  satisfy  an  additional  precon- 

dition,  as  follows  --notice  that  we  need  write  down  4  cases  only,  since  the  relative 
positions  of  a  and  b  are  irrelevant--: 

bal.(a,s,t)  ~  bal.(b,  ins.a.s,t)  ,  if  # s = # t  bal.(a,s,t)  =r  bal.(b,  ins.a.t,s) 

,  if  true bal.(a,s,t)  ~  bat.(b,  s,  ins.a.t) 
,  if  # s = # t + l  bal.(a,s,t)  ~  ba l . ( b, t ,   ins.a.s) 
,  if  false 

Apparently,  the  last  alternative  is  never  useful;  thus,  only  6  out  of the  8  alter- 
natives  can  be  used  when  the  trees  are  to  remain  balanced.  As  for  the  sizes  of the 

trees,  ins  has  the  following property. 

P r o p e r t y   1:  for  all  b  and  s  we have  #(ins.b.s)  =  # s + l  Q 

196 
The  definitions  we  shall  derive  for  the  array  extension  operations  turn  out  to correspond to some of the  recursive schemes discussed here.  That  is, these operations 
are  refinements  of the  above functions  ins.  As  a  consequence,  we  have  done  away with  the  proof obligations  regarding  the  size  and  the  balance  of the  trees. 

1.4  Low  E xtens ion  and  P~emoval 
We  recall  the  specification  of functon  ie,  but  now  reformulated  in  terms  of trees. 
For element  b  and  tree  s,  the  value  le.b.s  is  the  tree  u  satisfying: 

# u = # s + l   A  u! O= b   A  ( V j: O< j < #s : u !( j + l) = s ! j ) 
According t ot h e   analysis in the previous section, we have only one option for  le.b. ( )  ; 
fortunately,  it  satisfies all  requirements.  So,  we define: 

te.b.<)  =  (b,(),()) 
For the  composite  tree  (a,s ,t)  of size  d + l ,   the  value  le.b.(a,s,t)  is the  tree  u 
satisfying: 

# u  

The  term analysis  in 

# u  

(Vi 

= d + 2   A  U! 0 =b  A  ( V j : 0 _ < j < d + l : u ! ( j + l ) = ( a , s , t ) ! j )  

(a,s ,t) !j  and  the  definition  of  element  selection  suggest  a  3-way  case the  range  0 <_j < d + l ;   so,  using  the  definition  of  !,  we  rewrite  this  as: 

= d + 2   A  u!O  =  b  A  u!l  =  a  A : 0 _ < i < # s : u ! ( 2 * i + 2 ) = s ! i )   A  ( V i : 0 < i < # t : u ! ( 2 * i + 3 ) = t ! i )  
This  provides  an  explicit  definition  of  the  elements  of  u  in  terms  of  a  ,b,s ,  t.  In view, again,  of the  definition of  !, and observing that  u  will be a  composite tree,  we 

are  forced  to  distinguish  between  u!0,  u ! ( 2 , i +l ) ,   and  u!(2,i+2).  By  comparing this with the above requirement we conclude that  we must choose  u  =  (b, v, s),  where 
v  is  the  tree  satisfying: 

# v = # t + l   A  v !O = a  A  ( V i :O < _i < #t : v! (i + l )= t ! i)  
This  specification of  v  is precisely the  specification of the  tree  le.a4  ; because is smaller than  (a, s, t)  we may use  this  recursive application  of  le.  Thus  we obtain 
the  following definition  for  /e: 

le.b-<)  =  <b,</, (/) 
Z~.b.<a,s,t>  =  {b,  Z~.a.t,  s> 

This  definition  corresponds  to  one  of  the  alternatives  for  bag  insertion  discussed in  the  previous  section;  as  already  stated  there,  this  definition  also  satisfies  the 

requirements  regarding the  size  and  the  balance  of the  resulting  tree. 

Finally,  we  recall  the  specification  of the  function  It,  reformulated  in  terms  of trees.  For  composite tree  s  the  value 

lr.s  is the  tree  u  that  satisfies: 

# u = # s - 1   A  ( V j : 0 _ _ j < # u : u ! j = s ! ( j + l ) )  

197 
Using  that  lr.(le.b.s)  =  s,  we obtain  from  the  above  definition  for  le  the  following 
definition  for  lr,  by means  of "program  inversion".  The  verification  that  this  defini- 
tion  indeed  satisfies  the  specification  requires  a  calculation  very much  like  the  above 
derivation  for  le. 

=  () =  (s!O,t, 

t  .s)  ,  for  s:sr 

1.5  H i g h   E x t e n s i o n   a n d   R e m o v a l  
We  recall  the  specification  of function  he,  now  reformulated  in  terms  of trees.  For 
element  b  and  tree  s,  the  value  he.b.s  is  the  tree  u  satisfying: 

# u = # s + l   A  u!(#s)  = b   A  ( V j : O < _ j < # s : u ! j = s ! j )  
As  in  the  previous  section,  the  only  possible  definition  for  he.b.()  is: 

he.b.()  =  (b,() ,()) 
For  the  composite  tree  (a, s, t)  we observe --calculation  om itted- -  that  the  first 
and  the  third  conjuncts  of the  above specification  can  be  met  both  by: 

he.b.(a,s,t)  =  (a,  he.b.s,  t)  ,  and  by: he.b.(a,s,t)  =  (a ,  s,  he.b.t) 

To  investigate  which  one  we  need,  we  try  to  prove  the  second  conjunct  of the  spec- 
ification,  where  we  assume  #(a,  s,t)  =  d + l ;   recall  that  then  # s   =  ddiv2+dmod2 

and  # t   =  ddiv2.  For  the  first  alternative  to  satisfy  the  second  conjunct,  we need: 

(a,  he+s,  t)!(d+a) 

{ assume  d  to  be  even,  set  d = 2 , e ;   definition  of  !  } 
he.b.s!e 

{  d = 2 * e ,   so  # s = e ;   specification  of  he,  by  ind.hyp.  } 
b .  

So,  the  expression  ( a,   he.b.s,  t)  satisfies  the  specification  if  d  is  even,  provided 

that  we  also  have  bal.  (a,   he.b.s,  t)  ;  the  condition  for  this  is  # s   =  # t ,   which  is 
equivalent  to  d  being  even. 

Similarly,  we  can  derive  that  the  other  expression,  (a,  s,  he.b.t),  satisfies  the 
specification  if  d  is  odd;  in  that  case  we  have  # s = # t + l ,   which  is  exactly  the 

condition  for  bal.  ( a ,  s,  he.b.t )  . 

Thus,  we obtain  the  following definition  for  he: 

he.b-() he.b. (a, s, t)  =  (b,(),()) =  if  d m o d 2 = 0   --+  ( a , h e . b . s , t )  

dmod2  ~  0  --*  ( a , s,  he.b.t ) fi  where  d = # ( a , s , t ) - I   end 

198 
To  allow  for  logarithmic  computation  times,  the  value  #( a ,s,t )  occurring  in  this 

definition  must  not  be  computed  but  must  be  supplied  as  an  additional  parameter 
instead.  By  Property  0  this  is  possible. 

Finally,  we  recall  the  specification  of the  function  hr,  reformulated  in  terms  of 
trees.  For  composite  tree  s  the  value  hr.s  is  the  tree  u  that  satisfies: 

# u = # s - 1   A  ( V j : 0 _ < j < # u : u ; j = s ! j )  
Using  that  hr.(he.b.s)  =  s,  we  can  derive  the  following  definition  for  hr  from  the 
above  one  for  he,  again  by program  inversion: 

hr.(a,(),<))  =  () hr.(a,s,t) 

=  if  dmod2  =  0  --~  (a,  hr.s,  t) 

B  d m o d 2 # O   --*  ( a , s , h r . t )  
fi  where  d = # ( a , s , t ) - 2   end  ,  for  s : s # ( )  

1.6  S u m m a r y   o f  t h e   F u n c t i o n a l   P r o g r a m s  

(a,s,t)  !O  =  a ( a , s , t ) ! ( 2 , i + l )  

=  s!i  ,  for  i : O < i < # s  (a ,s,t )!( 2, i+ 2 )  =  t!i  ,  for  i:O<__i<#t 

(a,s,t)  :O,b  =  (b,s,t) (a,s,t)  :(2*i+l),b  =  ( a , ( s : i , b ) , t )  
( a , s , t ) : ( 2 , i + 2 ) ,b   =  ( a,   s,  (t:i,b)) 

,  for  i : O< _ i < # s  
,  for  i : O < i < # t  

lr  =  (b,(),()) 
lr  =  <b,  Z~.~.~,  s) 

t,,(a,(),())  =  () 
lr.(~,s,t>  =  ( s ! 0 , t , b - ~ >   ,  for  ~ : s r  

h~.b.<)  =  (b,(),()) 
he.b.(a,s,t)  =  if  d m o d 2 = O   --+  (a,  he .b .s,t) 

D  draod2  #  0  --+  (a ,  s,  he.b.t) 
fi  where  d =   # ( a , s , t ) - i   end 

hr.{a,{>,{>>  =  () hr.(a,s,t) 

=  if  d m o d 2 = 0   --~  (a ,  h v . s , t )  

0  d m o d 2 # 0   --~  ( a , s , h r . t )  
fi  where  d = # ( a , s , t ) - 2   end  ,  for  s : s r  

199 
2  S e q u e n t i a   !  I m p l e m e n t a t i o n s  
In  this  section  we  derive  sequential  implementations  from  the  recursive  function 
definitions  in  the  previous  section.  We  represent  trees  by  data  structures  built  from 
smaller  units  called  nodes,  which  are  linked  together  by  means  of pointers.  For  this 

purpose  we  use  a  program  notation  that  is  a  mixture  of  guarded  commands  and 

Pascal. Before  doing  so,  however, we  explain  the  techniques  used  for  this  transformation 

by means  of a  simple  example.  Readers  who are  sufficiently familiar  with  techniques 
for  pointer  manipulation  and  recursion  elimination  may  wish  to  skip  the  next  sub- 
section  at  first  reading. 

2.0  A  Few  Simple  Transformation  Techniques 
This  subsection  consists  of two  parts.  First,  we  present  two  (well-known)  instances 
of  how  tail-recursive  definitions  can  be  transformed  into  equivalent  non-recursive 
programs.  Second, we illustrate  how a simple function on  lists,  namely list  catenation, 

can  be  implemented  as  a  sequential  program. 

We  consider  the  following tail-recursive  definition  of a  function  F  : 

F . x   =  if  -~b.x  ~  f . x  b.x  -~  F. (g . x)  

fi 
/.From  this  definition  we  obtain  the  following  iterative,  sequential  program  for  the computation  of,  say, 

F . X .   The  correctness  of this  program  follows from  the  invari- 
ance  of  F . X   =  F.x  : 

:-~-X 
;  do  b.x  --~  x : = g . x   od 
;  r : = f . x  { r = F . X   } 

Next,  we  consider  the  following  tail-recursive  procedure  P ,   in  which  x  is  as- 
sumed  to  be  a  value  parameter: 

procedure P ( x )  =1[ 

if  ~b.x  ~  & 

b.x  --*  $1  ;  P(g. x) fi 

]J 
This  procedure  can  be  transformed  into  the  following equivalent  non-recursive  one: 

procedure P( x) 

=  I[  do  b.x  ~  5'1  ;  x : = g . x  od ;So 

200 
If we  wish  to  get  rid  of the  procedure  altogether,  each  call  P( X )   may  be  replaced by the  following program  fragment;  we call  this  unfolding  P ( X )   : 

I[  vat  x  ; ~ : ~ X  

;  do  b.z  ---*  S z ;   z : = g. z   od ;5"0 
]J 

We  consider  the  function  f  that  maps  two  lists  onto  their  catenation,  defined  re- 
cursively  as  follows: 

f .z .y  =  if  z = [ ]   --*  y 

z # [ l   ---*  hd.x  cons  f .( t l. x) . y 
fi 

The  first  step  towards  a  sequential  implementation  is  to  recode  this  definition  as  a 
procedure  definition;  the  reason  for  using  a  result  parameter  for  the  function  result will  become  clear  later: 

procedure  P0(x,  y;  result z )  

=  J[  {  post:  z  =  f.x.y} 

var  h  ; 

if  z = [ ]   --*  z : =   y 

D  x # [ ]   - - ~ P 0 ( t l . x , y , h )  ;  z  :=  hd.x  cons  h 

fi ]1 

In the  second step  we introduce  the  representation  of lists  by means  of nodes  and 
pointers.  A  list  is  represented  by  a  pointer;  a  pointer  is  either  nil,  or  a  reference  to 
a  node  --Pascal:  a  record--  consisting  of an  element  and  a  pointer.  The  value  nil 
has  as  its  only  property  that  it  differs from all  pointer  values  referring  to  nodes.  By 
means  of  a  call  of the  standard  procedure  new(p)  ,  pointer  variable  p  is  assigned 
a  value  that  differs  from  nil  and  that  differs  from  all  pointer  values  "currently  in 
use":  we  call  such  a  pointer  value,  and  the  node  referred  to  by  it,  fresh. 

The  type  definitions  needed  to  define  this  data  structure  formally  are: 

type  listp  =  pointer  to  node  ; 

node  =  ( hd  : element  ;  tl : lislp  ) 

For  p  a  pointer  of type  listp  and  p C   nil,  we use  p~  to  denote  the  node  to which  p 
refers.  We  denote  the  two  components  of this  node  by  p~.hd  and  pT.tl;  that  is,  we 

use  the  Pascal  convention  of field  selectors  to  identify  the  components  of a  pair.  As 
in  Pascal,  we  admit  and  shall  use  assignments  to  individual  components  of nodes. 

A  pointer  p  represents  a  list  lip]I,  say,  as  follows: 

lI nil ~  =  [] 
~p~  =  pT.hd  cons  [[p~.tl~  ,  for  p : p r   nil 

201 
(The  use of  nil  to represent  the  (one and  only) empty list  is somewhat  opportunistic, but  it  simplifies  things  a  little.) 

By  incorporation  of this  list  representation  we  obtain  from  the  above  procedure 
P0  our  next  version;  notice  that  [~p]]= []  =  p =   nil  : 

procedure  PI (P, q;  resultr) 

=  I[  {  post:  IIr]]  =  f.~p~.~q~  } vat  h  ; 

if  p =n il  - - + r : = q  

p #   nil  --*  Pl(pT.tl,  q,  h) ;n ew(r) 

;  rT  :=  (pf.hd,  h) fi 
]1 
Procedure  P1  entails  an  important  design  decision.  In  this  procedure  the  only 
assignment  to  values  of type  node  is  the  assigment  to  r]"  , which is  a  fresh  node.  As 
a  result,  existing  nodes  are  not  modified.  Generally,  if the  value  of a node, once it has 

been  created  and  initialised,  is  never  changed,  then  this  node  may  be freely  shared 
among  different  data  structures.  If  such  a  node  contains  pointers  to  other  nodes, then  the  "never  change"  condition  must  also  hold  for  all  nodes  that  are  reachable 

from  this  node.  By  building  data  structures  in  this  way,  the  use  of  sharing  saves 
both  storage  space  and  computation  time.  For  example,  a  list  assignment  can  now 
be  implemented  by  copying  a  pointer  only,  which  is  an  O(1)  operation,  instead  of 
by  copying the  whole  list.  As  a  result,  the  two  lists  are  represented  in  storage  by the 
same  data  structure  as  long  as  they  remain  equal.  In  procedure  P1,  for  instance, we have  used  the  pointer  assignment  r  :=  q  to  implement  the  list  assignment  z :=  y 

from  procedure  P0.  The  price  to  be  paid  for  this  flexibility  is  that  efficient  storage 
management  involves  some  form of garbage  collection. 
A side:  As  a  matter  of fact,  sharing  is possible  when,  for every pointer  p  represent- 

ing  a  list,  the  value  ~p~  is  never  changed.  This  requirement  is  weaker  than 

the  requirement  that  PI  is never  changed.  That  is,  nodes  may be  overwritten 
as long they still  represent  the  same  abstract  values - -in   our  case: lists--.  For 
example,  node  overwriting  is frequently  used  in graph-reduction  machines.  In 

this  paper,  we  can  live  with  the  stricter  regime. 1:3 

In  the  third  step  we  employ  the  possibility  to  use  assignments  to  individual 
components  of nodes,  to  rearrange  the  order  of the  assignments  in  such  a  way  that 
the  procedure  becomes  tail-recursive.  Thus,  we obtain: 

procedure  P2 (P, q ;  result r) 

=  I[  {  post:  [[r]]  =  f.~p~.~q~  } if  p =n il  ~ r : = q  

p:~ nil  ~  new(,') ;  r[.hd 

:= p~.hd ;  P~(p~.tl,  q,  r~.tl) 

fi ]1 

202 
Procedure  P2  is  tail-recursive  but  it  still  contains  a  result  parameter;  the  trans- formation  into  iterative  form  discussed  in  the  beginning  of  this  subsection  is  only 
applicable  to  procedures  with  value  parameters  only.  Result  parameter  r  may  be 
turned  into  a  value  parameter,  provided  that  we  remove  all  assignments  to  r  from 
the  procedure.  (Notice that  assignments to  rT  are not  assignments to  r  .) The  assign- 
ment  r  : -   q  can be  removed by the  introduction  of an  additional  procedure  P3  that 

is identical  to  P2  but  with  its  precondition  strengthened  with  p ~   nil  . This  requires, 
of course,  that  the  case  p =   nil  be  dealt  with  separately.  Similarly,  the  assignment 

new(r)  can  be  eliminated  by  strengthening  the  precondition  of  P3  even  further, 
namely  with  "r  is fresh"  . Thus,  we obtain: 

procedure  P2(P, q;  resultr) 

=  I[  {  post:  [[r]]  =  f.[[p]]'l[q]]  } if  p=nil  - - * r : = q  

p:~ nil  ~  new(r) 

{ p # n i l   A  "r isfresh"  } ;  P3(p,q,r) 

fi ]1 

procedure P3(P, q, r) =  I[  {  pre:  pC  nil  ^  "r  is  fresh"  } 

{  post:  fir]]  =  f.~p]].[[q~  ) rT.hd  := pT.hd 
;  if  pT.ti =  nil  --~ r~.tl  :=  q []  pT.tl r 

nil  --~  new(rT.tl) ;  P3(pT.tl,  q,  rT.tl) 

fi ]1 

Finally,  if we  now  distribute  the  assignment  rT.hd  :=  p'[.hd  over  the  alternatives  of 
the  succeeding  selection  statement,  procedure  Pz  can  be  transformed  into  iterative 
form; by unfolding its one and  only call,  P3  can be  eliminated  altogether.  This  yields 

our  final,  iterative  implementation  of list  catenation: 

procedure P4(P, q;  resultr) 

=  l[  {  post:  [~r]]  =  f.[[p]].[[q]]  ) var  h  ; 

if  p=  nil  --~ v :=   q 

D  p #nil  --~  new(r)  ;  h : = r  

{ invariant:  p # nil  A  "h  is  fresh"  } ;  dopT'tl#nil  ~  hT.hd 

:=  pT.hd ;  new(hT.tl) 

;  p, h  :=  pT.tl,  hT.il od 
;  hT  :=  (pT.hd,  q) fi 
]1 

203 
2.1  S e l e c t i o n   a n d   R e p l a c e m e n t  
We  represent  trees  by  means  of data  structures  composed  from  nodes  and  pointers. 
A  tree  is  represented  by  a  pointer;  a  pointer  is  either  nil  or  a  pointer  to  a  node 
consisting of an  element  and  2  pointers.  The  value  nil  has  as  its  only property  that 
it differs from  all pointer values referring to nodes.  By means  of a  call of the  standard 
procedure  new(p),  pointer  variable  p  is  assigned  a  value  that  differs  from  nil  and 

that  differs  from  all  pointer  values  "currently  in  use":  we  call  such  a  pointer  value, 
and  the  node  referred  to  by  it,  fresh. 

Assignments  to  nodes  will  be  restricted  to  fresh  nodes;  as  a  result,  the  values 
of existing  nodes  will never  be  changed  and  we  may  employ  node  sharing.  (See  the 
previous  subsection,  for  a  slightly more  elaborate  discussion of node  sharing.) 

The  type  definitions  needed  to  define  the  d at a  structure  formally  are: 

type  lreep =  pointer  to  node; 

node  =  (  a : element  ;  s,t:listp) 

For  p  a  pointer  of type  treep  and  PC  nil,  we use  p]"  to  denote  the  node  to  which  p 
refers.  We  denote  the  three  components  of this  node  by  pT'a  ,  pT's  ,  and  pT.t  .  We 
admit  and  shall  use  assignments  to  individual components  of nodes. 

A  pointer  p  represents  a  tree  lip]I,  say,  as  follows: 

[I.il~  =  () 
~p~  =  (pl.a,  ~pr.s~,  ~pT.t~)  ,  forp:penil 

The  definition of element selection is tail-recursive. Such a  definition can be trans- 
formed  into an  iterative program  in  a  straightforward  way.  Next,  the  tree operations 

in  terms  of  tuples  are  recoded  in  terms  of node  and  pointer  operations.  Thus,  we 
obtain  the  following program;  to  make  verification of this  transformation  somewhat 
easier,  we  repeat  the  definition  of element  selection  here  with  some  of the  syntactic 
sugar  - - t h e   parameter  p a t t e r n s - -   removed: 

u!i  =  if  i = 0   --*u.a 

i > 0   --*if  j m o d 2 = O   -~  u.s !(jdiv2) 

j m o d 2 ~ O   --~ u.t!(jdiv2) 
fi  where  j = i- 1   end 
fi 

procedure EL (p,  i ; result e) 

=  I[  {  pre:  O< i< # [ [ p~   } 

{  post:  e  =  ~p]]!i  (initial  values  ofp, i)  } 
do  i r   --* i : = i - 1  

; i f   i m o d 2 = 0   --+  p,i  :=  pT.s,  idly2 

0  i m o d 2 = l   --~  p , i : =   pT.t,idiv2 
fi 
od 
;  e  :=pI.a ]1 

204 
For  the  implementation  of element  replacement,  we  introduce  a  procedure  REP with  the  following  specification: 

procedure  REP(p, i, b;  resultr) =1[  {  pre: 

{  post:  ~Ir]]  =  liP]l:  i,b  } ]1 

As  a  first  approximation,  we  construct  the  following  (recursive)  code  from  the  (re- cursive)  definiton  of element  replacement: 

procedure  REP(p, i, b ; resultr) =  ][  var  h; 

if  i= O   -*  new(v)  ;  rT:=  (b,pT.s,pT.t) 

r]  i # o   --.,  i : = i - 1  ;  if  imod2=O  ~  REP(p~.s,  idiv2,  b,  h) 

;  new(r)  ;  rT  :=  (pT.a,  h,  pl-t) 
I1  im od 2=   1  --*  REP(pT.t, idiv2,  b,  h) ;  new(r)  ;  rT 

:=  (pT.a,  pT.s,  h) fi 

fi ]1 

By  means  of  the  techniques  from  the  previous  section,  this  procedure  can  be transformed  into  the  following  iterative  one: 

procedure  REP1 (p, i, b;  resultr) =  I[  var  h; 

new(r)  ;  h:=  r 
;  d o i ~ 0   --*  i : = i - 1  

;  if  i m o d 2 = 0   ~  hT.a  :=p~.a  ;  hT.t  :=pT4 ;  new(hT.s)  ;  p,i,h  :=  p~.s,  idiv2,  hT.s 

0  i m o d 2 = l   --~  h~.a  := pT.a  ;  h~.s  := p~.s ;  new(hT4)  ;  p,i,h  :=  pT4,  idiv2,  h~.t 
fi od 
;  hT  :=  ( b,  PT's,  PT't ) ]1 

Procedure  REP1  constructs  a  new  tree  that  shares  the  majority  of its nodes  with the  old  tree.  As  a  result,  this  operation  requires  at  most  logarithmic  computation 
time. 

2.2  E x t e n s i o n   a n d   R e m o v a l  
The  techniques  used  in  the  previous  subsections  can  be  used  to  derive  iterative implementations  of the  extension  and  removal  operations  as  well.  Although  these 

cases  are  slightly  more  complicated,  this  transformation  offers  no  further  surprises; 

205 
therefore,  we  only  present  the  resulting  programs.  As  is  the  case  with  element  re- 
placement,  the  following  procedures  construct,  in  logarithmic  time,  new  trees  t ha t  
share  the  m a j or i t y  of  their  nodes  with  the  old  ones. 

procedure  LE(p,  b ; result r) =  I[  var  h; 

new(r)  ;  h:=  r 
;  d op# ni l   ~  h'[.a:=b  ;  h'flt:=p'f.s ;  new(h~.s)  ;  p,b,h 

:=  pT.t,p'f.a,  hT.s 
od 
;  hl"  :=  (b, nil, nil) 

JI 

procedure  HE@,  d, b ; result r) 

=  I[  {  pre:  d  =  #lip]/} var  h; 

new(r)  ;  h:=  r 
;  d od #0  ~  d : = d - 1  

;  if  dm od 2=0   --,  h T . a : = p l . a ;   h~.t  : =p~ -t  ;  new(hT.s)  ;  p, d, h 

:=  pT.s,  ddiv2,  h'f.s 
dm od 2= l   ---*  h[.a  :=  pT.a  ;  h~.s  :=  pT.s ;  new(hT.t)  ;  p,d,h  

:=  pT.t,  ddiv2,  hT.t 
fi 
od 
;  hT  :=  (b, nil, nil) 

]1 

procedure  HR(p,  d;  resultr) 

=  I[  {  pre:  d  =  #~v~ vat  h  ; 

if  d =l   --*  r: =ni l  d>  l  --*  new(r)  ;  d,h  :=  d - 2 ,   r 

;  do d>2   A  dmod2=O  --*  hT.a  :=pT.a  ;  hT.t  :=pT.t ;  new(h~.~) 

;  p , d, h   :=  pT.s,  dd i v2 -1,   h~.s 
d >2  A  dm o d2= l   ---*  hT.a:=pT.a  ;  hT.s:=pT.s 

od 
; i f   d= O  --+ 

D  d =l   --. fi 

;  new(hT.t) 
;  p, d, h  :=  pT't,  d d i v 2 -1 ,   hT.t 

n+  :-_- (pT.~,  .il,  .il) hT :=  (pI.a,  pT.s,  nil) 

fi 
]1 

206 
procedure LR(p;  resultr) 

=  l[  var  h; if  p~.s=nil  --*  r : = n i l  

pT.s  r  nil  --*  new(r)  ;  h  :=  r 

;  do pT.s'f.s  ~  nil 

fi ]1 

--~  hT.a  := pT.sT.a  ;  hT.s  := pT.t ;  new(hT.t )  ;  p,h 

:=  pT.s,  h~.t 
od 
;  hT :=  (pT.s~.a,  pT4,  nil) 

3  C o n c l u d i n g   R e m a r k s  
The  introduction  of Braun  trees  to represent  flexible  arrays  constitutes  a  major  de- 
sign  decision.  Once  this  decision  has  been  taken,  functional  programs  for  the  array 

operations  can  be  derived  smoothly.  These  functional  programs  are  compact  and provide a  good starting  point  for  the  construction of a  sequential,  nonrecursive  im- 

plementation of the  array operations. Although the resulting programs are  nontrivial 
they  can be  obtained  by systematic  transformation of the  functional programs; this 
requires  great  care  but  little  ingenuity. 

The  exercise  in  this  paper  also  shows  that  recursive  data  types,  such  as  Braun 
trees,  can  be  implemented  by means  of nodes  and  pointers  in  a  simple  and  system- atic  way.  Notice  that  we  have  not  employed  an  (elaborate)  formal  theory  on  the 

semantics  of pointer  operations;  nevertheless,  we  are  convinced of the  correctness 
of the  programs  thus  obtained.  The  programs  derived  in  this  paper  employ sharing 

of nodes by adhering  to the  "never-change-an-existing-node"  discipline;  it  is equally well  possible  to  derive  programs  that,  instead  of building  a  new  tree,  modify  the 

existing  tree  by modifying nodes. 

Braun  trees  admit  several  variations  and  embellishments.  To  mention  a  few: 
instead  of binary trees,  k-ary  trees,  for some fixed  k,  can  be  used.  Operations  like 

mod2  and  div2  then  become  modk  and  divk.  Larger values of  k  give rise  to  trees 
of smaller  height --when  the  size  remains  the  same---. The  price  to  be  paid  is  that 

storage  utilisation  decreases:  each node  now contains  k  pointers  per  array  element 
instead  of  2. To compensate for this,  it  is possible to store several consecutive array 

elements,  instead  of a single one, per node of the  tree.  This reduces  the height of the 
tree  even  further  and  improves  storage  utilisation  (,  except  for  very  small  arrays). 

Note,  however, that  in  a  setting  where  nodes  are  shared,  large  nodes  are  awkward, 
because  of the  time needed  to  make  copies of nodes; this  places  an  upper  bound  on 
what  can  be  considered  as  a  reasonable  node  size. 

Acknowledgement 

To  Anne  Kaldewaij  and  the  members  of  the  Kleine  Club,  for  their  constructive 
comments on  an  earlier  version of this  paper. 

207 
R e f e re n c e s  
[0]  Braun,  W.,  Rem,  M.:  A logarithmic implementation of flexible arrays.  Memorandum MR83/4,  Eindhoven University  of Technology (1983). 
[1]  Dijkstra,  Edsger  W.:  A  discipline  of  programming.  Prentice-Hall,  Englewood  Cliffs (1976), 