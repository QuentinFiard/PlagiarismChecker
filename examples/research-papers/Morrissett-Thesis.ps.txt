

Compiling with Types

Greg Morrisett
December, 1995
CMU-CS-95-226

School of Computer Science

Carnegie Mellon University

Pittsburgh, PA 15213

Submitted in partial fulfillment of the requirements

for the degree of Doctor of Philosophy.

Thesis Committee:
Robert Harper, Co-Chair
Jeannette Wing, Co-Chair

Peter Lee
Andrew Appel, Princeton University

This research was sponsored in part by the Defense Advanced Research Projects Agency, CSTO,
under the title "The Fox Project: Advanced Development of Systems Software", ARPA Order No. 8313,
issued by ESD/AVS under Contract No. F19628-91-C-0168. Support also was sponsored by the Wright
Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF, and the Advanced
Research Projects Agency ([ARPA]) under grant F33615-93-1-1330. The US Government is authorized
to reproduce and distribute reprints for Government purposes, notwithstanding any copyright notation
thereon.

Views and conclusions contained in this document are those of the author and should not be
interpreted as representing the official policies, either expressed or implied, of Wright Laboratory or the
United States Government.

Copyright cfl1995 Greg Morrisett

1
Abstract
Compilers for monomorphic languages, such as C and Pascal, take advantage of types
to determine data representations, alignment, calling conventions, and register selection. However, these languages lack important features including polymorphism, abstract
datatypes, and garbage collection. In contrast, modern programming languages such as
Standard ML (SML), provide all of these features, but existing implementations fail to
take full advantage of types. The result is that performance of SML code is quite bad
when compared to C.

In this thesis, I provide a general framework, called type-directed compilation,
that allows compiler writers to take advantage of types at all stages in compilation. In
the framework, types are used not only to determine efficient representations and calling
conventions, but also to prove the correctness of the compiler. A key property of typedirected compilation is that all but the lowest levels of the compiler use typed intermediate
languages. An advantage of this approach is that it provides a means for automatically
checking the integrity of the resulting code.

An important contribution of this work is the development of a new, staticallytyped intermediate language, called *MLi . This language supports dynamic type dispatch,
providing a means to select operations based on types at run time. I show how to
use dynamic type dispatch to support polymorphism, ad-hoc operators, and garbage
collection without having to box or tag values. This allows compilers for SML to take
advantage of techniques used in C compilers, without sacrificing language features or
separate compilation.

To demonstrate the applicability of my approach, I, along with others, have
constructed a new compiler for SML called TIL that eliminates most restrictions on the
representations of values. The code produced by TIL is roughly twice as fast as code
produced by the SML/NJ compiler. This is due at least partially to the use of natural
representations, but primarily to the conventional optimizer which manipulates typed,
*MLi code. TIL demonstrates that combining type-directed compilation with dynamic
type dispatch yields a superior architecture for compilers of modern languages.

1
Acknowledgements

I owe a great deal of thanks to a great number of people. My wife Tanya (also known as
Jack), went well beyond the reasonable call of duty in her help and support. Not only did
she take care of day-to-day tasks (such as making dinner), but she also helped proofread this
document.

This thesis and my work in general are direct reflections of Bob Harper's teaching and
mentoring. Jeannette Wing also deserves a great deal of credit: Not only did she suffer through
early drafts of this document, but she supported me in many other ways throughout my stay
at CMU. Peter Lee, Andrew Appel, and Matthias Felleisen also deserve a great deal of credit
for passing on their knowledge, wisdom, and experience. I am deeply honored to have studied
under all of these people.

The TIL compiler wouldn't be here without David Tarditi, Perry Cheng, or Chris Stone. I
truly enjoyed working with all of these guys and hope to do so again. Andrzej Filinski has been
the ultimate officemate throughout my graduate career. Many other folks have been especially
good to me over the years and deserve special recognition including Nick Barnes, Lars Birkedal,
Sharon Burks, Prasad Chalasani, Art Charlesworth, Julie Clark, Olivier Danvy, Rich Goodwin, Gary Greenfield, Jonathan Hardwick, Maurice Herlihy, Susan Hinrichs, Puneet Kumar,
Mark Leone, Mark Lillibridge, Kevin Lynch, David MacQueen, Yasuhiko Minamide, Scott Nettles, Brian Noble, Chris Okasaki, Sue Older, Scott Reilly, Norman Sobel, David Steere, Andrew Tolmach, and Mark Wheeler.

Of course, my mother and father deserve the most thanks and credit (especially for the
ZX81!). Thanks everyone!

Greg Morrisett
December, 1995

Contents
1 Introduction 8

1.1 Type Directed Translation : : : : : : : : : : : : : : : : : : : : : : : : : : 11
1.2 The Issue of Variable Types : : : : : : : : : : : : : : : : : : : : : : : : : 12

1.2.1 Previous Approach: Eliminate Variable Types : : : : : : : : : : : 15
1.2.2 Previous Approach: Restrict Representations : : : : : : : : : : : : 16
1.2.3 Previous Approach: Coercions : : : : : : : : : : : : : : : : : : : : 19
1.3 Dynamic Type Dispatch : : : : : : : : : : : : : : : : : : : : : : : : : : : 21
1.4 Typing Dynamic Type Dispatch : : : : : : : : : : : : : : : : : : : : : : 23
1.5 Overview of the Thesis : : : : : : : : : : : : : : : : : : : : : : : : : : : 25

2 A Source Language: Mini-ML 27

2.1 Dynamic Semantics of Mini-ML : : : : : : : : : : : : : : : : : : : : : : : 28
2.2 Static Semantics of Mini-ML : : : : : : : : : : : : : : : : : : : : : : : : : 30

3 A Calculus of Dynamic Type Dispatch 36

3.1 Syntax of *MLi : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 36
3.2 Dynamic Semantics of *MLi : : : : : : : : : : : : : : : : : : : : : : : : : : 38
3.3 Static Semantics of *MLi : : : : : : : : : : : : : : : : : : : : : : : : : : : 41
3.4 Related Work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 42

4 Typing Properties of *MLi 46

4.1 Decidability of Type Checking for *MLi : : : : : : : : : : : : : : : : : : : 46

4.1.1 Reduction of Constructors : : : : : : : : : : : : : : : : : : : : : : 47
4.1.2 Local Confluence for Constructor Reduction : : : : : : : : : : : : 51
4.1.3 Strong Normalization for Constructor Reduction : : : : : : : : : : 55
4.1.4 Decidability of Type Checking : : : : : : : : : : : : : : : : : : : : 59
4.2 *MLi Type Soundness : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 63

5 Compiling with Dynamic Type Dispatch 70

5.1 The Target Language: *MLi -Rep : : : : : : : : : : : : : : : : : : : : : : : 71

2

CONTENTS 3

5.2 Compiling Mini-ML to *MLi -Rep : : : : : : : : : : : : : : : : : : : : : : : 73

5.2.1 Translation of Types : : : : : : : : : : : : : : : : : : : : : : : : : 73
5.2.2 Translation of Terms : : : : : : : : : : : : : : : : : : : : : : : : : 76
5.2.3 Translation of Equality : : : : : : : : : : : : : : : : : : : : : : : : 76
5.2.4 Translation of Functions : : : : : : : : : : : : : : : : : : : : : : : 78
5.2.5 Translation of Applications : : : : : : : : : : : : : : : : : : : : : 81
5.2.6 Translation of Type Abstraction and Application : : : : : : : : : 83
5.3 Correctness of the Translation : : : : : : : : : : : : : : : : : : : : : : : : 83
5.4 Compiling Other Constructs : : : : : : : : : : : : : : : : : : : : : : : : : 87

5.4.1 C-style Structs : : : : : : : : : : : : : : : : : : : : : : : : : : : : 87
5.4.2 Type Classes : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 95
5.4.3 Communication Primitives : : : : : : : : : : : : : : : : : : : : : : 98
5.5 Related Work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 100

6 Typed Closure Conversion 102

6.1 An Overview of Closure Conversion : : : : : : : : : : : : : : : : : : : : : 103
6.2 The Target Language: *MLi -Close : : : : : : : : : : : : : : : : : : : : : : 105
6.3 The Closure Conversion Translation : : : : : : : : : : : : : : : : : : : : : 109

6.3.1 The Constructor and Type Translations : : : : : : : : : : : : : : 109
6.3.2 The Term Translation : : : : : : : : : : : : : : : : : : : : : : : : 111
6.4 Correctness of the Translation : : : : : : : : : : : : : : : : : : : : : : : : 113

6.4.1 Correctness of the Constructor Translation : : : : : : : : : : : : : 113
6.4.2 Type Correctness of the Term Translation : : : : : : : : : : : : : 116
6.4.3 Correctness of the Term Translation : : : : : : : : : : : : : : : : 118
6.5 Related Work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 121

7 Types and Garbage Collection 122

7.1 Mono-GC : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 124

7.1.1 Dynamic Semantics of Mono-GC : : : : : : : : : : : : : : : : : : 125
7.1.2 Static Semantics of Mono-GC : : : : : : : : : : : : : : : : : : : : 127
7.2 Abstract Garbage Collection : : : : : : : : : : : : : : : : : : : : : : : : : 132
7.3 Type-Directed Garbage Collection : : : : : : : : : : : : : : : : : : : : : : 135
7.4 Generational Collection : : : : : : : : : : : : : : : : : : : : : : : : : : : : 141
7.5 Polymorphic Tag-Free Garbage Collection : : : : : : : : : : : : : : : : : 143

7.5.1 *MLi -GC : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 144
7.5.2 Static Semantics of *MLi -GC : : : : : : : : : : : : : : : : : : : : : 146
7.5.3 Garbage Collection and *MLi -GC : : : : : : : : : : : : : : : : : : : 151
7.6 Related Work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 158

CONTENTS 4
8 The TIL/ML Compiler 161

8.1 Design Goals of TIL : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 161
8.2 Overview of TIL : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 163
8.3 SML and Lambda : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 166
8.4 Lmli : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 168

8.4.1 Kinds, Constructors, and Types of Lmli : : : : : : : : : : : : : : 168
8.4.2 Terms of Lmli : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 172
8.5 Lambda to Lmli : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 179

8.5.1 Translating Datatypes : : : : : : : : : : : : : : : : : : : : : : : : 179
8.5.2 Specializing Arrays and Boxing Floats : : : : : : : : : : : : : : : 181
8.5.3 Flattening Datatypes : : : : : : : : : : : : : : : : : : : : : : : : : 182
8.5.4 Flattening Arguments : : : : : : : : : : : : : : : : : : : : : : : : 184
8.6 Bform and Optimization : : : : : : : : : : : : : : : : : : : : : : : : : : : 184
8.7 Closure Conversion : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 187
8.8 Ubform, Rtl, and Alpha : : : : : : : : : : : : : : : : : : : : : : : : : : : 188
8.9 Garbage Collection : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 189
8.10 Performance Analysis of TIL : : : : : : : : : : : : : : : : : : : : : : : : : 190

8.10.1 The Benchmarks : : : : : : : : : : : : : : : : : : : : : : : : : : : 191
8.10.2 Comparison against SML/NJ : : : : : : : : : : : : : : : : : : : : 191
8.10.3 The Effect of Separate Compilation : : : : : : : : : : : : : : : : : 197
8.10.4 The Effect of Flattening : : : : : : : : : : : : : : : : : : : : : : : 198

9 Summary, Future Work, and Conclusions 212

9.1 Summary of Contributions : : : : : : : : : : : : : : : : : : : : : : : : : : 212
9.2 Future Work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 213

9.2.1 Theory : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 213
9.2.2 Practice : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 214
9.3 Conclusions : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 216

List of Figures

1.1 A Polymorphic Merge Sort Function : : : : : : : : : : : : : : : : : : : : 13
1.2 Natural Representation of a Floating Point Array : : : : : : : : : : : : : 18
1.3 Boxed Representation of a Floating Point Array : : : : : : : : : : : : : : 18

2.1 Syntax of Mini-ML : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 28
2.2 Contexts and Instructions of Mini-ML : : : : : : : : : : : : : : : : : : : 29
2.3 Contextual Dynamic Semantics for Mini-ML : : : : : : : : : : : : : : : : 30
2.4 Static Semantics for Mini-ML : : : : : : : : : : : : : : : : : : : : : : : : 32

3.1 Syntax of *MLi : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 38
3.2 Values, Contexts, and Instructions of Constructors : : : : : : : : : : : : : 38
3.3 Rewriting Rules for Constructors : : : : : : : : : : : : : : : : : : : : : : 39
3.4 Values, Contexts, and Instructions of Expressions : : : : : : : : : : : : : 40
3.5 Rewriting Rules for Expressions : : : : : : : : : : : : : : : : : : : : : : : 40
3.6 Constructor Formation : : : : : : : : : : : : : : : : : : : : : : : : : : : : 41
3.7 Constructor Equivalence : : : : : : : : : : : : : : : : : : : : : : : : : : : 43
3.8 Type Formation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 44
3.9 Type Equivalence : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 44
3.10 Term Formation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 45

5.1 Syntax of *MLi -Rep : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 71
5.2 Added Constructor Formation Rules for *MLi -Rep : : : : : : : : : : : : : 73
5.3 Added Term Formation Rules for *MLi -Rep : : : : : : : : : : : : : : : : : 74
5.4 Translation from Mini-ML to *MLi -Rep : : : : : : : : : : : : : : : : : : : 77
5.5 Relating Mini-ML to *MLi -Rep : : : : : : : : : : : : : : : : : : : : : : : : 85

6.1 Syntax of *MLi -Close : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 107
6.2 Closure Conversion of Constructors : : : : : : : : : : : : : : : : : : : : : 110
6.3 Closure Conversion of Terms : : : : : : : : : : : : : : : : : : : : : : : : : 112

7.1 Syntax of Mono-GC Expressions : : : : : : : : : : : : : : : : : : : : : : : 124
7.2 Syntax of Mono-GC Programs : : : : : : : : : : : : : : : : : : : : : : : : 126

5

LIST OF FIGURES 6

7.3 Rewriting Rules for Mono-GC : : : : : : : : : : : : : : : : : : : : : : : : 128
7.4 Static Semantics of Mono-GC Expressions : : : : : : : : : : : : : : : : : 130
7.5 Static Semantics of Mono-GC Programs : : : : : : : : : : : : : : : : : : 131
7.6 Postponement and Diamond Properties : : : : : : : : : : : : : : : : : : : 134
7.7 Syntax of *MLi -GC : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 144
7.8 *MLi -GC Evaluation Contexts and Instructions : : : : : : : : : : : : : : : 146
7.9 *MLi -GC Constructor and Type Rewriting Rules : : : : : : : : : : : : : : 147
7.10 *MLi -GC Expression Rewriting Rules : : : : : : : : : : : : : : : : : : : : 148

8.1 Stages in the TIL Compiler : : : : : : : : : : : : : : : : : : : : : : : : : 164
8.2 Kinds and Constructors of Lmli : : : : : : : : : : : : : : : : : : : : : : : 169
8.3 Terms of Lmli : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 173
8.4 TIL Execution Time Relative to SML/NJ : : : : : : : : : : : : : : : : : 193
8.5 TIL Heap Allocation Relative to SML/NJ (excluding fmult and imult) : 194
8.6 TIL Physical Memory Used Relative to SML/NJ : : : : : : : : : : : : : : 194
8.7 TIL Executable Size Relative to SML/NJ (without runtimes) : : : : : : : 195
8.8 Til Compilation Time Relative to SML/NJ : : : : : : : : : : : : : : : : : 195
8.9 TIL Execution Time Relative to SML/NJ for Separately Compiled Programs199
8.10 Execution Time of Separately Compiled Programs Relative to Globally

Compiled Programs : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 199

List of Tables

8.1 Benchmark Programs : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 192
8.2 Comparison of TIL Running Times to SML/NJ : : : : : : : : : : : : : : 204
8.3 Comparison of TIL Heap Allocation to SML/NJ : : : : : : : : : : : : : : 205
8.4 Comparison of TIL Maximum Physical Memory Used to SML/NJ : : : : 206
8.5 Comparison of TIL Stand-Alone Executable Sizes to SML/NJ (excluding

runtimes) : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 207
8.6 Comparison of TIL Compilation Times to SML/NJ : : : : : : : : : : : : 208
8.7 Separately Compiled Benchmark Programs : : : : : : : : : : : : : : : : : 209
8.8 Comparison of TIL Execution Times Relative to SML/NJ for Separately

Compiled Programs : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 210
8.9 Effects of Flattening on Running Times : : : : : : : : : : : : : : : : : : : 210
8.10 Effects of Flattening on Allocation : : : : : : : : : : : : : : : : : : : : : 211

7

Chapter 1
Introduction
The goal of my thesis is to show that types can and should be used throughout implementations of modern programming languages. More specifically, I claim that, through
the use of type-directed translation and dynamic type dispatch (explained below), we can
compile polymorphic, garbage-collected languages, such as Standard ML [90], without
sacrificing natural data representations, efficient calling conventions, or separate compilation. Furthermore, I claim that a principled language implementation based on types
lends itself to proofs of correctness, as well as tools that automatically verify the integrity of the implementation. In short, compiling with types yields both safety and
performance.

Traditionally, compilers for low-level, monomorphic languages, such as C and Pascal,
have taken advantage of the invariants guaranteed by types to determine data representations, alignment, calling conventions, register selection and so on. For example, when
allocating space for a record, a C compiler can determine the size of the record from its
type. When allocating a register for a variable of type double, a C compiler will use a
floating point register instead of a general purpose register. Some implementations take
advantage of types to support tag-free garbage collection [23, 119, 6] and so-called "conservative" garbage collection [21]. Types are also used to support debugging, printing
and parsing, marshaling, and other means of traversing a data structure.

In addition to directing implementation, types are useful for proving formal properties
of programs. For instance, it is possible to prove that every term in the simply-typed
*-calculus terminates. Similarly, it is possible to show that there is no closed value in
the Girard-Reynolds polymorphic *-calculus with the type 8ff:ff. Compilers can take
advantage of these properties to produce better code. For instance, a compiler can
determine that a function, which takes an argument of type 8ff:ff, will never be called
simply because there are no values of the argument type. Therefore, the compiler can
safely eliminate the function.

Types are also useful for proving relations between programs. In particular, types

8

CHAPTER 1. INTRODUCTION 9
are useful for showing that two programs are equivalent, in the sense that they compute
equivalent values. This provides a powerful mechanism for proving that a compiler is
correct: Establish a set of simulation relations based on types, and then show that every
source program and its translation are in the relation given by the source program's type.

Unfortunately, two obstacles have prevented language implementors from taking full
advantage of types. The first obstacle is that implementors have lacked a sufficiently
powerful, yet convenient framework for formally expressing their uses of types. Instead,
implementors rely upon informal, ad hoc specifications of typing properties. This in turn
prevents the implementor from proving formal properties based on types, and from recognizing opportunities for better implementation techniques within a compiler or runtime
system.

A good example of this issue comes from the literature on type-based, tag-free garbage
collection, where we find many descriptions of clever schemes for maintaining type information at run time to support memory management. Many of the approaches are
surprisingly difficult to implement and rely upon very subtle typing properties. Yet, few
if any of these descriptions are formal in any sort of mathematical sense. Indeed, the
basic definitions of program evaluation and what it means for a value to be garbage
are at best described informally, and at worst left unstated. Consequently, we have no
guarantee that the algorithms are in any way correct. Practically speaking, this keeps
us from modifying or adapting the algorithms with any assurance, simply because the
necessary invariants are left implicit.

The second obstacle keeping implementors from fully taking advantage of types is
that types have become complex, relative to the simple monomorphic type systems of
C and Pascal. To support better static type checking, abstraction, code reuse, separate
compilation, and other software engineering practices, we have evolved from using simple
monomorphic types, to using the complex, modern types of Standard ML (SML), Haskell,
and Quest. These modern types include polymorphic types, abstract types, object types,
module types, qualified types, and even dependent types. These kinds of types have one
thing in common: They include component types that are unknown at compile time. In
fact, many of these types contain components that are variable at run time.

Most of the type-based implementation techniques used in compilers for C and Pascal
rely critically upon knowing the type of every object at compile time. Implementors have
lacked a sufficiently general approach for extending these techniques to cover unknown
or variable types. Because of this, compilers for languages like SML, which have variable
types, have traditionally ignored type information, and treated the language as if it
was uni-typed. Consequently and ironically, implementations of modern languages suffer
performance problems because they provide advanced types, but fail to take advantage
of simple types.

The purpose of this thesis is to remove these two obstacles and open the path for
language implementors to take full advantage of types. To address the first obstacle,

CHAPTER 1. INTRODUCTION 10
lack of formalism, I demonstrate how to formalize key compilation phases and a run-time
system using a methodology called type-directed translation. This methodology provides
a unifying framework for specifying and proving the correctness of a compiler that takes
full advantage of types. However, to compile languages like SML, the methodology of
type-directed translation requires some formal mechanism for dealing with the second
obstacle -- variable types.

To address variable types, I provide a new compilation technique, dynamic type dispatch, that extends traditional approaches for compiling monomorphic languages to handle modern types. In principle, dynamic type dispatch has none of the drawbacks of
previous approaches, but it introduces some issues of its own. In particular, to take
full advantage of dynamic type dispatch, we must propagate type information through
each phase of a compiler. Fortunately, type-directed translation provides a road map for
achieving this goal.

In short, the two contributions of this thesis, type-directed translation and dynamic
type dispatch, are equally important because they rely critically upon each other. To
demonstrate the practicality of these two techniques, I (with others) have constructed a
compiler for SML called TIL. TIL, which stands for Typed Intermediate Languages, takes
advantage of both type-directed translation and dynamic type dispatch to provide natural
representations and calling conventions. The type-directed transformations performed by
TIL reduce running times by roughly 40% and heap allocation by 50%.

In addition to type-directed translation and dynamic type dispatch, TIL employs a
set of conventional functional language optimizations. These optimizations account for
much of the good performance of TIL, in spite of the fact that they operate on staticallytyped intermediate languages. Indeed, TIL produces code that is roughly twice as fast as
code produced by the SML/NJ compiler [12], which is one of the best existing compilers
for Standard ML.

The rest of this chapter serves as an overview of the thesis. In Section 1.1, I give an
overview of type-directed translation. In Section 1.2, I discuss the problem of compiling
in the presence of variable types, discuss previous approaches to this problem, and show
why these solutions are inadequate. In Section 1.3, I give an overview of dynamic type
dispatch and discuss why it is a superior to previous approaches of compiling in the
presence of variable types. In Section 1.4, I discuss the key issue of using dynamic type
dispatch in conjunction with type-directed translation -- how to type check a language
that provides dynamic type dispatch. Finally, in Section 1.5, I give a comprehensive
overview of the rest of the thesis.

CHAPTER 1. INTRODUCTION 11
1.1 Type Directed Translation
A compiler transforms a program in a source language into a program in a target language.
Usually, we think of the target language as more "primitive" than the source language
according to functionality. As an example, consider the compilation of SML programs
to a lower-level language such as C. We consider C "lower-level" because SML provides
features that C does not directly provide, such as closures, exceptions, automatic memory
management, algebraic data types, and so forth. These high-level constructs must be
encoded into constructs that C does support. For instance, closures can be encoded in C
as a struct containing both a pointer to a C function and a pointer to another struct
that contains values of the free variables in the closure.

It is a daunting task to compile a high-level language, such as SML, to a relatively lowlevel language, such as C, and even more daunting to compile to an extremely low-level
language, such as machine code. The only feasible approach to overcome the complexity
is to break the task into a series of simpler compilers that successively map their source
language to closely related, but slightly simpler target languages. Taking the sequential
composition of these simpler compilers yields a compiler from the original source language
to the final target language. Decomposing a compiler into a series of simpler compilers
has an added benefit: Correctness of the entire compiler can be established by proving
the correctness of each of the simpler compilers.

The initial task a compiler writer faces is deciding how to break her compiler into
smaller, more manageable compilation steps. She must decide what language feature(s)
to eliminate in each step of compilation and she must develop a strategy for how this is
to be accomplished. Next, for each stage of compilation she must design and specify the
intermediate target languages. This includes formally specifying a dynamic semantics so
that we know precisely what each target language construct means. Then, the compiler
writer must formulate a precise, but sufficiently high-level description of an algorithm
that maps the source language to the target language for each stage. Finally, the compiler
writer must prove each of the translation algorithms correct. A translation is correct if
when we run the source program (using the source language dynamic semantics) and we
run the translation of the program (using the target language dynamic semantics), then
we get "equivalent" answers. For simple answers, such as strings or integers, "equivalent"
usually means syntactic equality. However, weaker, semantic notions of equivalence are
needed to relate more complex objects such as functions.

In this thesis, I demonstrate this methodology by deriving key parts of a compiler
from a simple ML-like functional language to a relatively low-level language that makes
representations, calling conventions, closures, allocation, and garbage collection explicit.
I formulate the translation as a series of type-directed and type-preserving maps. By typedirected, I mean that the source language of each stage is statically typed and source
types are used to guide the compilation at every step. For instance, given a generic

CHAPTER 1. INTRODUCTION 12
structural equality operation at the source level, we can select the code that implements
the operation according to the type assigned to the arguments of the operation. If that
type is int, we use integer equality, and if the type is float, we use floating point equality,
and so on.

By a type-preserving translation, I mean the following: first, both the source and
the target languages are typed. Second, a type-preserving translation specifies a type
translation in addition to a term translation. Third, if a source expression e has type o/ ,
the term translation of e is e0, and the type translation of o/ is o/ 0, then e0 has type o/ 0.
Therefore, assuming the input is well-typed, so is the output.

By using a typed target language in addition to a typed source language, we ensure
that any later translations in the compiler can continue to take advantage of types for their
own purpose. For example, in Chapter 7, I take advantage of these types to implement
garbage collection.

In type-directed translation, we not only use types to guide the translation, but we
also use types to argue that the translation is correct. Indeed, it is the presence of
types that allows us to define what it means for the translation to be correct! Thus, the
contribution of types to the compilation process is many fold: We use types to select
appropriate representations, calling conventions, and primitive operations, and we use
types to prove that the compiler is correct.

1.2 The Issue of Variable Types
Modern programming languages, such as C++, CLU, Modula-3, Ada, Standard ML, Eiffel, and Haskell all provide type systems that are much more expressive than the simple,
monomorphic systems of C and Pascal. In particular, each of these languages supports
at least one notion of unknown or variable type. Variable types arise in conjunction
with two key language advances: abstract data types and polymorphism. These features
are the building blocks of relatively new language features including modules, generics,
objects, and classes.

The SML code in Figure 1.1 provides an example use of an unknown type. The code
implements a merge sort on a list of values of uniform, but unknown type, denoted by
ff. The function sort takes a predicate lt (less-than) of type ff * ff -? bool, a list of
ff values, and produces a list of ff values. We can apply the sort function to a list of
integers, passing integer less-than as the comparison operator:

sort (op ! : int*int-?bool) [5,7,2,1,3,9,10]
Alternatively, we can apply the sort function to a list of floating point values, passing
floating point less-than as the comparison operator:

sort (op ! : real*real-?bool) [138.0,3.1415,4.79]

CHAPTER 1. INTRODUCTION 13

fun sort (lt:ff*ff-?bool) (l:ff list) : ff list =

let fun merge (nil,l) = l

-- merge (l,nil) = l
-- merge (x::tx,y::ty) =

if lt(x,y) then x :: merge(tx,y::ty)
else y :: merge(x::tx,ty)
fun split ([],one,two) = (sort lt one,sort lt two)

-- split (x::tl,one,two) = split (tl,two,x::one)
in

case l of

:: :: =? merge (split(l,[],[]))
-- =? l
end

Figure 1.1: A Polymorphic Merge Sort Function

In fact, we can pass a list of any type to the sort routine provided we have an appropriate
comparison operation for that type. By abstracting the component type of the list as a
type variable, we can write the sort code once and use it at as many types as we like. For
monomorphic languages like Pascal, which strictly enforce types, a sort implementation
must be copied for each instantiation of ff. This can waste code space and make program
maintenance more difficult. For instance, if we find a bug in the sort implementation,
then we must make sure to eliminate the bug in all copies.

The ability to use code at different types, as in the preceding sort example, is usually
called polymorphism, meaning "many changing". Polymorphism is closely related to the
notion of abstract data types (ADTs). ADTs are objects that implement some data
type and its corresponding operations, but hold the representation of the data type and
the implementation of the operations abstract. For example, the following SML code
implements a stack of integers as an ADT via the abstype mechanism:

abstype stack = Stack of int list
with

val empty = Stack nil
fun push (x, Stack s) = Stack (x :: s)
exception Empty
fun pop (Stack nil) = raise Empty

-- pop (Stack (x :: s)) = (x, Stack s)
end

CHAPTER 1. INTRODUCTION 14
The type system of SML prevents the client of an abstype from examining the representation of the abstracted type. Hence, if we try to use a stack as if it is an integer list, we
will get a type error. A key advantage of abstracting the type is that, in principal, we
can separately compile the definition of the ADT from its uses. Furthermore, we should
be able to change the representation of the abstracted type without having to recompile
clients of the abstraction. For example, we could use a vector to represent the stack of
integers instead of a list.

But how do we compile in the presence of variable types? Consider, for example, the
following issues:

1. Functions can have arguments of unknown type:

fun id (x:ff) : ff = x
Since ff can be instantiated to any type, what register should we use to pass the
argument to id? Should we use a floating point or general purpose register?

2. The following function creates a record of values whose types are unknown:

fun foo (x:ff,y:fi) = (x,y,x,y)
How much space should we allocate for the data structure? How do we align the
components of the record to support efficient access? Should we add padding?
Should we pack the fields of the record?

3. In languages such as SML, n-argument functions are represented by functions taking

a single n-tuple as an argument. This makes the language uniform and simplifies the
semantics. But for efficiency, we want to "flatten" a tuple argument into multiple
arguments. If the argument to a function has a variable type, then how do we know
if we should flatten the argument?

4. When compiling an ad-hoc polymorphic operation such as structural equality (e.g.,

eq(e1; e2)) and the type of the arguments is a variable, what code should we generate? Should we generate an integer comparison, floating point comparison, or code
that extracts components and recursively compares them for equality?

5. How do we determine the size and pointers of a value of unknown type so that we

can perform tracing garbage collection?

In this section, I explore existing solutions to these issues and discuss their relative
strengths and weaknesses. As I will show, none of the existing approaches preserves all
of the following desirable implementation properties:

ffl separate compilation

CHAPTER 1. INTRODUCTION 15

ffl natural representations and calling conventions
ffl fully polymorphic definitions or fully abstract data types

1.2.1 Previous Approach: Eliminate Variable Types
The easiest way to implement a language with variable types is to contrive either the
language or the implementation so that all of the variable types are eliminated before
compilation begins. This allows us to use a standard, monomorphic compiler.

The "elimination" approach has been used in various guises by implementations of
C++ [114], Ada [121], NESL [20], and Gofer [74] to support ADTs and polymorphism.

ffl When defining a new class in C++, the definition is placed in a ".h" file. The

definition is #included by any client code that wishes to use the abstraction.
Hence, the compiler can always determine the representation of an abstract data
type. The type system enforces the abstracted type within the client, but the first
stage of compilation eliminates the abstracted type variable, and replaces it with
its implementation definition.

ffl When defining an ADT via the package mechanism of Ada, it is sometimes necessary to expose the representation of the ADT in the interface of the package. This
representation is "hidden" in a private part of the interface. Again, the type system
of the language enforces the abstraction, but the first stage of compilation replaces
the abstract type variable with the implementation representation.

ffl NESL is a programming language for parallel computations that allows programmers to define polymorphic functions [20]. However, the NESL implementation
delays compiling any polymorphic definitions. Instead, whenever a polymorphic
function is instantiated with a particular type, the type is substituted for the occurrences of the type variable within the polymorphic code. The resulting monomorphic code is compiled. A caching scheme is used to minimize code duplication.

ffl Gofer, a dialect of Haskell, provides both polymorphism and type classes. Mark

Jones constructed an implementation that, like the NESL implementation, performs
all polymorphic instantiation at compile time [73].

Unfortunately, the "eliminate variable types" approach has many drawbacks. One
drawback is that polymorphic code is never shared. Instead, each polymorphic definition
is copied at least once for each unique instantiation. This can have a serious effect on both
compile times and instruction cache locality. For C++, the definitions in the ".h" file
must be processed each time a client is compiled. Newer compilers attempt to cache the
results of this processing in a separate file precisely to avoid this compilation overhead.

CHAPTER 1. INTRODUCTION 16
The caching scheme used by NESL ensures that exactly one copy is made for a given
type, but no code is actually shared across different instantiations. Both caching schemes
introduce a coherence problem: When the polymorphic definition is updated, the cached
definitions must be discarded. For languages like Gofer, Haskell, and SML, which provide
nested polymorphic definitions, it is possible that the number of copies of a polymorphic
definition could grow exponentially with the number of type variables in the definition.
(However, Jones reports that this does not occur in practice [73].)

Even if code size, compile times, and instruction cache locality were not an issue, the
"eliminate" approach sacrifices separate compilation of an ADT or polymorphic definition
from its uses. For example, if we change the implementation of an ADT implemented
using an Ada package, then we must also change the private portion of the package
specification. Since all clients depend upon this specification, changing the ADT implementation requires that all clients be recompiled. Similarly, a simple change to a class
definition in C++ can require the entire program to be recompiled.

Increasingly, we are moving away from a world where we have access to all of the source
files of a program, and where we can "batch" process the compilation, linking, and loading
of a program. For example, vendor-supplied, dynamically-linked libraries (e.g., Xlib, Tk)
are now the norm instead of the exception. Often, it is impossible to get the source
code for such libraries and it is prohibitively time-consuming to recompile them for each
application, especially during development. We now have languages such as Java [51] and
Obliq [27, 28] where objects and code are dynamically transmitted from one machine to
another via a network, compiled to a native representation, and then dynamically linked
into a running program. Hence, the ability to compile program components separately is
becoming increasingly important and any compilation methodology must provide some
level of support for separate compilation.

Finally, for many newer programming languages, it is simply impossible to eliminate
all polymorphism or all ADTs at compile time. Consider, for example, a language that
supports first-class polymorphic definitions. Such objects can be placed in data structures, passed as arguments to functions, and so forth. Thus, determining all of the types
that instantiate a given definition becomes in general undecidable.

1.2.2 Previous Approach: Restrict Representations
A different approach to compiling in the presence of variable types is to restrict the
types that can instantiate a type variable. This approach, known as boxing, restricts
type variables so that, no matter what the actual type is, the representation of the value
has the same size. As an example, Modula-3 allows only pointer types (e.g., ptr[o/ ]) to
be used as the implementation of an abstract type. Assuming all pointers are the same

CHAPTER 1. INTRODUCTION 17
size1, we can always allocate a data structure containing values of type ptr[t], even if t
is unknown. Similarly, we know that such values will be passed in general purpose as
opposed to floating point registers.

Languages like SML do not make a restriction on polymorphism or variable types at
the source level, but almost all implementations use such a restriction in compilation. In
essence, they perform a type-directed translation that maps variable types (t) to pointer
types (ptr[t]). Unfortunately, a naive translation that always maps type variables to
pointer types is not type-preserving. Consider for example the polymorphic identity
function and its use at some type:

let fun id (x:ff) : ff = x
in

(id : float-?float) 3.1415
end

The naive translation yields:

let fun id (x:ptr[ff]) : ptr[ff] = x
in

(id : ptr[float]-?ptr[float]) 3.1415
end

However, this translation is ill-typed because id takes a pointer as an argument, but the
literal 3.1415 is a floating point value. Since the translation is ill-typed, the rest of the
compiler will produce erroneous code. For example, the translation of the application
of id to the floating point value may place the argument into a floating point register,
whereas the code of the function will be translated with the expectation that the argument
is in a general purpose register.

The problem is that in general, it is impossible to tell whether or not a value will be
passed to a polymorphic function. If a value is passed as an argument of unknown type
to some routine, then the value must be boxed (i.e., represented as a pointer.) Because
it is impossible to tell whether or not a value will be passed to a polymorphic function,
most ML compilers, including Poly/ML [88], Bigloo [107], Caml [126], and older versions
of SML/NJ [9], box all objects.

Boxing supports separate compilation and dynamic linking, but unfortunately, it consumes space and time because of the extra indirection that is introduced. For example,
to support polymorphic array operations, an array of floating point values must be represented by an array of pointers to singleton records that contain the actual floating point
values (see Figures 1.2 and 1.3). An extra word is used as the pointer for each array

1Even this is a dangerous assumption in many environments, including MS-DOS versions of Borland
C, where distinctions are made between "near" and "far" pointers.

CHAPTER 1. INTRODUCTION 18

3.141592653587931 2.718281828459045 42.00000000000000
Figure 1.2: Natural Representation of a Floating Point Array

3.141592653587931

2.718281828459045

42.00000000000000
Figure 1.3: Boxed Representation of a Floating Point Array

element. For systems such as SML/NJ that use tagging garbage collection, an additional
tag word is required for each element. Hence, the polymorphic array can consume twice
as much space as its monomorphic counterpart. Furthermore, accessing an array element
requires an additional memory operation. As memory speeds become slower relative to
processor speeds, this extra memory operation per access becomes more costly. Finally,
in the presence of a copying garbage collector, the elements of the array could be scattered across memory. This could destroy the spatial locality of the array, resulting in
increased data cache misses and even longer access times.

In addition to causing performance problems, boxing also interferes with interoperability. As with tags to support garbage collection, adding extra indirection can impede
communication with systems that do not use boxing. In particular, it becomes difficult
to communicate with libraries, runtime services, and operating system services, because
they tend to be written in low-level languages such as C or Fortran that do not provide
variable types. Extra code must be written to "marshal" a data structure from its boxed
representation to the representation used by the library, runtime, or operating system.

Finally, although boxing addresses many of the issues of compiling in the presence
of variable types, it does not help us eliminate overloaded operators (such as structural
equality) or perform garbage collection. Hence, standard implementations of SML both
box and tag all values to support their advanced language features. As a direct result,

CHAPTER 1. INTRODUCTION 19
the quality of the code emitted by most SML compilers, even when these features are
not used, is far below the quality of compilers for languages like C or Fortran.

1.2.3 Previous Approach: Coercions
Because boxing and tagging are so expensive, a great deal of research has gone into
minimizing these costs [75, 81, 64, 65, 102, 110]. A particularly clever approach was
suggested by Xavier Leroy for call-by-value languages based on the ML type system [81].
The fundamental idea is to compile monomorphic code in exactly the same way that it
is compiled in the absence of variable types, and to compile polymorphic code assuming
that variables of unknown type are boxed and tagged. As we showed in Section 1.2.2, this
results in a type mismatch when a polymorphic object is instantiated. Leroy's solution is
to apply a coercion to the polymorphic object to mitigate this mismatch. The coercion
is based on the type of the object and the type at which it is being instantiated. A
fascinating property of Leroy's solution is that, for languages based on the ML type
system, the appropriate coercion to apply in a given situation can always be determined
at compile time.

As an example, the naive boxing translation of the identity function produced the
following incorrect code:

let fun id (x:ptr[ff]) : ptr[ff] = x
in

(id : ptr[float]-?ptr[float]) 3.1415
end

Leroy's translation fixes the mismatch by applying a boxing coercion to the argument of
the polymorphic function and an unboxing coercion to the result:

let fun id (x:ptr[ff]) : ptr[ff] = x
in

unbox[float]

(id : ptr[float]-?ptr[float]) (box[float](3.1415))
end

Assuming box and unbox convert a value to and from a pointer representation and add
any necessary tags, the resulting code is operationally correct. In general, a polymorphic
object of type 8ff:o/ [ff] is compiled with the type 8ff:o/ [ptr[ff]]. When instantiated with
some type o/ 0, the object has the type o/ [ptr[o/ 0]], but the object is expected to have the
type o/ [o/ 0]. A coercion is applied to the instantiated object to correct the mismatch.
The coercion is calculated via a function S that maps the type scheme o/ [ff] and the

CHAPTER 1. INTRODUCTION 20
instantiating type o/ 0 to a term as follows:

S[ff; o/ 0] = *x: unbox[o/ 0](x)
S[int; o/ 0] = *x: x
S[float; o/ 0] = *x: x
S[ho/1 \Theta  \Delta  \Delta  \Delta  \Theta  o/ni; o/ 0] = *x: let x1=ss1 x; \Delta  \Delta  \Delta  ; xn=ssn x

in hS[o/1; o/ 0](x1); \Delta  \Delta  \Delta  ; S[o/n; o/ 0](xn)i
S[o/1 ! o/2; o/ 0] = *f: *x: S[o/2; o/ 0](f (G[o/1; o/ 0]x))

The definition of S at arrow types uses the dual coercion function G:

G[ff; o/ 0] = *x: box[o/ 0](x)
G[int; o/ 0] = *x: x
G[float; o/ 0] = *x: x
G[ho/1 \Theta  \Delta  \Delta  \Delta  \Theta  o/ni; o/ 0] = *x: let x1=ss1 x; \Delta  \Delta  \Delta  ; xn=ssn x

in hG[o/1; o/ 0](x1); \Delta  \Delta  \Delta  ; G[o/n; o/ 0](xn)i
G[o/1 ! o/2; o/ 0] = *f: *x: G[o/2; o/ 0](f (S[o/1; o/ 0]x))

The coercions generated by S and G deconstruct a value into its components until we
reach a base type or a type variable. The coercion at a base type is the identity but the
coercion at a variable type requires either boxing or unboxing that component. Once the
components have been coerced, the aggregate value is reassembled. Hence, it is fairly
easy to show that:

S[o/ [ff]; o/ 0] : o/ [ptr[o/ 0]] ! o/ [o/ 0]
G[o/ [ff]; o/ 0] : o/ [o/ 0] ! o/ [ptr[o/ 0]]

and thus S and G appropriately mitigate the type mismatch that occurs at polymorphic
instantiation.

The coercion approach offers the best mix of features from the set of solutions presented thus far. In particular, as with full boxing, it supports separate compilation and
code sharing. Unlike full boxing, monomorphic code does not have to pay the penalties of
boxing and tagging. Leroy found that his coercion approach cut execution time by up to
a factor of two for some benchmarks run through his Gallium compiler, notably numeric
codes that manipulate many integer or floating point values. However, for at least one
contrived program with a great deal of polymorphism, the coercion approach slowed the
program by more than a factor of two [81]. Nevertheless, his coercion approach has an
attractive property: You pay only for the polymorphism you use.

Other researchers have also found that eliminating boxing and tagging through coercions can cut execution times and allocation considerably. For instance, Shao and Appel
were able to improve execution time by about 19% and decrease heap allocation by 36%
via Leroy-style coercions for their SML/NJ compiler [110]. However, much of their improvement (11% execution time, 30% of allocation) comes by performing a type-directed
flattening of function arguments as part of the coercion process.

CHAPTER 1. INTRODUCTION 21

Unfortunately, the coercion approach has some practical drawbacks: First, the coercions operate by deconstructing a value, boxing or unboxing some components, and then
building a copy of the value out of the coerced components. Building a copy of a large
data structure, such as a list, array, or vector, requires mapping a coercion across the
whole data structure. Such coercions can be prohibitively expensive and applying them
may well outweigh the benefits of leaving the data structure unboxed. Second, in the
presence of recursive types (ML data types), refs, or arrays, not only must the components corresponding to type variables be boxed, but their components must be recursively
boxed [81]. Third, and perhaps most troublesome, it is difficult if not impossible to make
a copy of a mutable data structure such as an array. The problem is that updates to
the copy must be reflected in the original data structure and vice versa. Hence, it is
impossible to apply a coercion to refs or arrays and consequently, the components of
such data structures must always be boxed.

It is possible to represent refs and arrays as a pair of "get" and "set" functions
whose shared closure contains the actual ref cell or array. Then the standard functional
coercions can be applied to the get and set operations to yield a coerced mutable data
structure. However, having to perform a function call to access a component of an array
can easily offset any benefits from leaving the array unboxed.

Finally, the coercion approach to variable types is simply a stop-gap measure. It takes
advantage of certain properties of the ML type system - notably the lack of first-class
polymorphic objects - to ensure that the appropriate coercion can always be calculated
at compile time. This approach breaks down when we move to a language with first-class
polymorphism.

1.3 Dynamic Type Dispatch
There is an approach for compiling in the presence of variable types, first suggested by
the Napier '88 implementation [97], which avoids the drawbacks of boxing or coercions
without sacrificing separate compilation. The idea is to delay deciding what code to
select until types are known. This is accomplished by passing types that are unknown
at compile-time to primitive operations. Then, the operations can analyze the type in
order to select and dispatch to the appropriate code needed to manipulate the natural
representation of an object. I call such an approach dynamic type dispatch.

For example, a polymorphic subscript function on arrays might be compiled into the
following pseudo-code:

sub = \Lambda ff. typecase ff of

int =? intsub
-- float =? floatsub
-- ptr[oe] =? ptrsub[oe]

CHAPTER 1. INTRODUCTION 22
assuming the following operations, where we elide the "ptr[\Gamma ]" around arrow and array
types for clarity:

intsub : [intarray; int] ! int
floatsub : [floatarray; int] ! float
ptrsub[ptr[oe]] : [ptrarray[ptr[oe]]; int] ! ptr[oe]

Here, sub is a function that takes a type argument (ff), and then performs a case analysis
to determine the appropriate specialized subscript function that should be returned. For
example, sub[int] returns the integer subscript function that expects an array of integers,
whereas sub[float] returns the floating point subscript function that expects a doubleword aligned array of floating point values. All other types are pointers, so we assume
the array has boxed components and thus sub returns the boxed subscript function at
the appropriate large type.

If the sub operation is instantiated with a type that is known at compile-time (or
link-time), then the overhead of the case analysis can be eliminated by duplicating and
specializing the definition of sub at the appropriate type. For example, the source expression

sub(x,4) + 3.14,
will be compiled to the target expression

sub[float](x,4) + 3.14,
since the result of the sub operation is constrained to be a float. If the definition of sub is
inlined into the target expression and some simple reductions are performed, this yields
the optimized expression:

floatsub(x,4) + 3.14.
Like the coercion approach to compiling with variable types, dynamic type dispatch
supports separate compilation and allows us to pay only for the polymorphism that we
use. In particular, monomorphic code can be compiled as if there are no variable types.
Furthermore, unlike coercions, dynamic type dispatch supports natural representations
for large data structures (such as lists, arrays, or vectors) and for mutable data structures
(such as arrays). Instead of coercing the values of the data structures, we coerce the
behavior of the operations. Hence, we do not have to worry about keeping copies of a
mutable data structure coherent. As a result, dynamic type dispatch provides better
interoperability than any of the previously tried solutions, without sacrificing separate
compilation.

As I will show, dynamic type dispatch also supports tag-free overloaded operations.
For example, we can code an ML-style polymorphic equality routine by dispatching on
a type:

CHAPTER 1. INTRODUCTION 23

typerec eq[int] = *(x,y).= int(x,y)

-- eq[float] = *(x,y).= float(x,y)
-- eq[ptr[ho/1 \Theta  o/2i]] =

*(x,y). eq[o/1](ss1 x,ss1 y) andalso eq[o/2](ss2 x,ss2 y)
-- eq[ptr[o/1 ! o/2]] = *(x,y). false

The same approach can be used to dynamically flatten arguments into registers, dynamically flatten structs and align their components, and so on. Finally, by passing
unknown types to the garbage collector at run-time, dynamic type dispatch supports
tag-free garbage collection.

In short, dynamic type dispatch provides a smooth transition from compilers for
monomorphic languages to compilers for modern languages with variable types.

1.4 Typing Dynamic Type Dispatch
If we are to use types to support register allocation, calling conventions, data structure
layout, and garbage collection, we must propagate types through compilation to the stages
where these decisions are made. Many of these decisions are made after optimization or
code transformations, so it is important that we can propagate type information to as
low a level as possible.

An intermediate language that supports run-time type dispatch allows us to express
source primitives, such as array subscript or polymorphic equality, as terms in the language. This exposes the low-level operations of the source primitive to optimization and
transformations that may not be expressible at the source level.

If we are to use an intermediate language that supports run-time type dispatch, we
must be able to assign a type to terms that use typecase. But what type should we
give a term such as sub, shown previously? We cannot use a parametric type such as
8ff:[array[ff]; int] ! ff, because instantiating sub with int for instance, yields the intsub
operation of type [intarray; int] ! int which is not an instantiation of the parametric type.

My approach to this problem is to consider a type system that provides type dispatch
at the type level via a "Typecase" construct. For example, the sub definition can be
assigned a type of the form:

8ff:[SpclArray[ff]; int] ! ff
where the specialized array constructor SpclArray is defined using Typecase as follows:

SpclArray[ff] = Typecase ff of

int =? intarray
-- float =? floatarray
-- ptr[oe] =? ptrarray[ptr[oe]]

CHAPTER 1. INTRODUCTION 24
The definition of the constructor parallels the definition of the term: If the parameter
ff is instantiated to int, the resulting type is intarray; if the parameter is instantiated to
float, the resulting type is floatarray.

In this thesis, I present a formal calculus called *MLi that provides run-time type
passing and type dispatch operations. The calculus is intended to provide the formal
underpinnings of a target language for compiling in the presence of variable types. I prove
two important properties regarding *MLi : The type system is sound and type checking is
decidable.

In its full generality, *MLi allows types to be analyzed not just by case analysis (i.e.,
typecase), but also via primitive recursion. This allows more sophisticated transformations to be coded within the target language, yet type checking for the target language
remains decidable.

An example of a more sophisticated translation made possible by primitive recursion
is one where arrays of pointers to pairs are represented as a pointer to a pair of arrays.
For example, an array of ptr[hint\Theta floati] is represented as a pointer to a pair of an intarray
and a floatarray. This representation allows the integer components of the array to be
packed and allows the floating point components to be naturally aligned. It also saves
n \Gamma  1 words of indirection for an array of size n, since pairs are normally boxed. The
subscript operation for this representation is defined using a recursive typecase construct
called typerec in the following manner:

typerec sub[int] = intsub

-- sub[float] = floatsub
-- sub[ptr[ho/1 \Theta  o/2i]] = *[hx,yi,i].hsub[o/1]x,sub[o/2]yi
-- sub[ptr[oe]] = ptrsub[ptr[oe]]

If sub is given a product type, ptr[ho/1 \Theta  o/2i], it returns a function that takes a pair of
arrays (hx,yi) and an index (i), and returns the pair of values from both arrays at that
index, recursively calling the sub operation at the types o/1 and o/2.

The type of this sub operation is:

8ff:[RecArray[ff]; int] ! ff
where the recursive, specialized array constructor RecArray is defined using a type-level
"Typerec":

Typerec RecArray [int] = intarray

j RecArray [float] = floatarray
j RecArray [ptr[ho/1 \Theta  o/2i]] = ptr[hRecArray[o/1] \Theta  RecArray[o/2]i]
j RecArray[ptr[oe]] = ptrarray[ptr[oe]]

Again, the definition of the constructor parallels the definition of the sub operation. If
the parameter is instantiated with int, then the resulting type is ptr[intarray]. If the

CHAPTER 1. INTRODUCTION 25
parameter is instantiated with ptr[ho/1 \Theta  o/2i], then the resulting type is the product of
RecArray[o/1] and RecArray[o/2].

1.5 Overview of the Thesis
In this thesis, I show that we can take advantage of types to compile languages with variable types, without losing control over data representations or performance. In particular,
I show that dynamic type dispatch can be used to support efficient calling conventions
and native representations of data without sacrificing efficient monomorphic code, separate compilation, or tag-free garbage collection. I also show how key pieces of a standard
functional language implementation must be extended to accommodate dynamic type dispatch. For instance, I show that representation analysis, closure conversion, and garbage
collection can all be extended to work with and take advantage of dynamic type dispatch.

A significant contribution of my thesis is that I formulate these aspects of language
implementation at a fairly abstract level. This allows me to present concise proofs of
correctness. Even if we ignore dynamic type dispatch, exhibiting compact formulations
and correctness arguments for representation analysis, closure conversion, and garbage
collection is a significant contribution.

The TIL compiler demonstrates not only that dynamic type dispatch is a viable
technique for compiling in the presence of variable types, but also that type-directed
compilation does not interfere with standard optimization, such as inlining (fi-reduction),
common sub-expression elimination, and loop invariant removal. Also, TIL demonstrates
that these standard optimizations are, for the most part, sufficient to eliminate the
overheads of dynamic type dispatch for an SML-like language.

I now briefly outline the remainder of the thesis: In Chapter 2, I present a simple, core
polymorphic source language called Mini-ML. I define the syntax, dynamic semantics,
and static semantics of the language. I also state the key properties of the static semantics
for the language. Readers familiar with ML-style polymorphism may want to skip this
chapter, but compiler writers unfamiliar with formal semantic specifications may find
this chapter illuminating.

In Chapter 3, I present a core intermediate language called *MLi . This language
provides the formal underpinnings of a calculus with dynamic type dispatch that is
used in the subsequent chapters. I define the syntax, dynamic semantics, and static
semantics of the language. In Chapter 4, I summarize the key semantic properties of
the formal calculus, including decidability of type checking and soundness of the static
semantics. Proofs of these properties follow for those interested in the underlying type
theory. Compiler writers may want to skip these details.

In Chapter 5, I define a variant of *MLi , called *MLi -Rep, that makes calling conventions
explicit. I show how to map Mini-ML to *MLi -Rep. In the compilation, I show how to

CHAPTER 1. INTRODUCTION 26
eliminate polymorphic equality and flatten function arguments, in order to demonstrate
the power and utility of dynamic type dispatch. I establish a suitable set of logical simulation relations between Mini-ML and *MLi -Rep and use them to prove the correctness
of the translation. I then demonstrate how other language features can be implemented
using dynamic type dispatch, including flattened data structures with aligned components, unboxed floating point arguments, Haskell-style type classes, and communication
primitives.

In Chapter 6, I show how to map *MLi to a language with closed code, explicit environments, and explicit closures. This translation, known as closure conversion, is important
because it eliminates functions with free variables. The key difficulty is that I must
account for free type variables as well as free term variables when producing the code
of a closure and thus, environments must contain bindings for both value variables and
type variables. Unlike most accounts of closure conversion, the target language of my
translation is still typed. This allows me to propagate type information through closure conversion. In turn, this supports other type-directed transformations after closure
conversion, as well as run-time type dispatch and tag-free garbage collection.

In Chapter 7, I provide an operational semantics for a monomorphic subset of closure
converted *MLi code. The semantics makes the heap and the stack explicit. I formalize
garbage collection as any rewriting rule that drops portions of the heap without affecting
evaluation. I specify and prove correct an abstract formulation of copying garbage collection based on the abstract syntax of terms (i.e., tags). I then show how types can be
used to support tag-free garbage collection and prove that this approach is sound. Then
I show how to extend the tag-free approach to a type-passing, polymorphic language like
*MLi .

In Chapter 8, I give an overview of TIL and the practical issues involved in compiling
a real programming language to machine code in the presence of dynamic type dispatch.
I also examine some aspects of the performance of TIL code: I compare the running times
and space of TIL code against the code produced by SML/NJ. I also measure the impact
that various type-directed translations have on both the running time and amount of
data allocated.

Finally, in Chapter 9, I present a summary of the thesis, and discuss future directions.

Chapter 2
A Source Language: Mini-ML
In this chapter, I specify a starting source language, called Mini-ML, that is based on the
core language of Standard ML [90, 31]. Although Mini-ML is a fairly limited language,
it has many of the constructs that one might find in a conventional functional programming language, including integers and floating point values; first-class, lexically-scoped
functions; tuples (records); and polymorphism. Indeed, I have designed Mini-ML so that
it brings out the key issues one must address when compiling a modern language like
SML.

The syntax of Mini-ML is given in Figure 2.1. There are four basic syntactic classes:
monotypes, polytypes, values, and expressions. The monotypes of Mini-ML describe
expressions and consist of type variables (t), base types including int, float and unit,
and constructed types including ho/1 \Theta  o/2i and o/1 ! o/2. The monotypes are distinct
from types that contain a quantifier (8). Polytypes, also referred to as type schemes,
are either monotypes or prenex, universally-quantified monotypes. Type variables range
over monotypes. Thus, polytypes are forbidden from instantiating a type variable.

Values consist of variables (x), integer and floating point literals (i and f ), unit (hi),
pairs of values, term functions (*x:o/:e), and type functions (\Lambda t1; \Delta  \Delta  \Delta  ; tn:e). Term and type
functions are sometimes referred to as term or type abstractions, respectively. Expressions contain variables, literals, unit, pairs of expressions, term functions, a structural
equality operation (eq(e1; e2)), a test for zero, projections (ssi e), and term applications
(e1 e2).

Expressions also include a def construct, which binds a variable to a value. Since
values include type abstractions, this provides a means for binding a type abstraction to
a variable, much like the let construct of SML. Finally, expressions include applications
of values to monotypes (v[o/1; \Delta  \Delta  \Delta  ; o/n]). The typing rules, explained in Section 2.2 restrict
v to be either a def-bound variable or a \Lambda -abstraction. Hence, the only thing that can
be done with a \Lambda -abstraction is either bind it to a variable via def or apply it to some
monotypes. This means that, as in SML, type abstractions are "second-class" because

27

CHAPTER 2. A SOURCE LANGUAGE: MINI-ML 28

(types) o/ ::= t j int j float j unit j ho/1 \Theta  o/2i j o/1 ! o/2
(schemes) oe ::= o/ j 8t1; \Delta  \Delta  \Delta  ; tn:o/
(values) v ::= x j i j f j hi j hv1; v2i j *x:o/: e j \Lambda t1; \Delta  \Delta  \Delta  ; tn:e
(expressions) e ::= x j i j f j *x:o/: e j e1 e2 j hi j he1; e2i j ss1 e j ss2 e j

eq(e1; e2) j if0 e1 then e2 else e3 j def x:oe = v in e2 j
v[o/1; \Delta  \Delta  \Delta  ; o/n]

Figure 2.1: Syntax of Mini-ML

they cannot be placed in data structures, passed as arguments to functions, or returned
as the result of a function.

I use def instead of let because I reserve let as an abbreviation. In particular, I use
let x:o/ = e1 in e2 as an abbreviation for (*x:o/: e2) e1.

Following conventional formulations of *-calculus based languages [15], I consider the
variable x in *x:o/: e to be bound within the body of the function e. Likewise, I consider x
to be bound within e in the expression def x:oe = v in e, and the type variables t1; \Delta  \Delta  \Delta  ; tn
to be bound within the body of the expression \Lambda t1; \Delta  \Delta  \Delta  ; tn:e. Likewise, t1; \Delta  \Delta  \Delta  ; tn are bound
within o/ for the polytype 8t1; \Delta  \Delta  \Delta  ; tn:o/ . If a variable is not bound in an expression/type,
it is said to be free. I consider expressions/types to be equivalent modulo ff-conversion
(i.e., systematic renaming) of the bound variables.

Finally, I write fe0=xge to denote capture avoiding substitution of the closed expression e0 for the variable x in the expression e. Likewise, I write fo/ =tgoe to denote
capture-avoiding substitution of the monotype o/ for t within the polytype oe.

2.1 Dynamic Semantics of Mini-ML
I describe evaluation of Mini-ML programs using a contextual rewriting semantics in the
style of Felleisen and Hieb [41]. This kind of semantics describes evaluation as an abstract
machine whose states are expressions and whose steps are functions, or more generally,
relations between expressions. The final state of this abstract machine is a closed value.
Each step of the abstract machine proceeds according to a simple algorithm: We break
the current expression into an evaluation context, E, and an instruction expression, I.
The evaluation context is an expression with a "hole" ([ ]) in the place of some subexpression. The original expression, e, is formed by replacing the hole in the context with

CHAPTER 2. A SOURCE LANGUAGE: MINI-ML 29

(contexts) E ::= [ ] j E1 e2 j v1 E2 j hE1; e2i j hv1; E2i j ssi E j

eq(E1; e2) j eq(v1; E2) j if0 E1 then e2 else e3

(instructions) I ::= eq(v1; v2) j ssi hv1; v2i j if0 i then e2 else e3 j (*x:o/: e) v j

def x:oe = v in e j (\Lambda t1; \Delta  \Delta  \Delta  ; tn:e) [o/1; \Delta  \Delta  \Delta  ; o/n]

Figure 2.2: Contexts and Instructions of Mini-ML

the instruction expression, denoted e = E[I]. Roughly speaking, the evaluation context
corresponds to the control state (or "stack") of a conventional computer whereas the
instruction corresponds to the registers and program counter1. We replace the instruction
expression with a result expression R within the hole of the context to form a new
expression e0 = E[R]. This new expression serves as the next expression to process in
the evaluation sequence.

The expression contexts and instructions of Mini-ML are given in Figure 2.2 and
the rewriting rules are given in Figure 2.3. The form of the evaluation contexts reflects
the fact that Mini-ML evaluates expressions in a left-to-right, inner-most to outer-most
order. Furthermore, the context v1 E2 shows that Mini-ML is an eager (as opposed to
lazy) language with respect to function application, because evaluation proceeds on the
argument before applying the function to it. Similarly, the contexts for data structures,
namely pairs, show that these data structures are eager with respect to their components.

A def instruction is evaluated by substituting the value v for all occurrences of the
variable x within the scope of the def, e. Application of a \Lambda -expression to a set of
monotypes is evaluated by substituting the monotypes for the bound type variables
within the body of the abstraction.

Rewriting a primitive instruction is fairly straightforward with the exception of the
equality operation. In particular, the rewriting rule for equality must select the appropriate function (e.g., =int versus =float) according to the syntactic class of the values
given to the operation as arguments.

Evaluation does not proceed into the branches of an if0 construct. Instead, the first
component is evaluated and then one of the arms is selected according to the resulting
value. When rewriting an application, (*x:o/: e) v, we first substitute the value v for the
free occurrences of the variable x within the body of the function e. Likewise, when
rewriting a def construct, we substitute the value v for the variable x within the body
of the def.

1The relationship between contexts and instructions, and a stack and registers is made explicit in
Chapter 7.

CHAPTER 2. A SOURCE LANGUAGE: MINI-ML 30

E[eq(i1; i2)] 7\Gamma ! E[1] (i1 =int i2)
E[eq(i1; i2)] 7\Gamma ! E[0] (i1 6=int i2)
E[eq(f1; f2)] 7\Gamma ! E[1] (f1 =float f2)
E[eq(f1; f2)] 7\Gamma ! E[0] (f1 6=float f2)
E[eq(hv1; v2i; hv01; v02i)] 7\Gamma ! E[if0 eq(v1; v01) then 0 else eq(v2; v02)]
E[eq(*x1:o/1: e1; *x2:o/2: e2)] 7\Gamma ! E[0]
E[if0 0 then e2 else e3] 7\Gamma ! E[e2]
E[if0 i then e2 else e3] 7\Gamma ! E[e3] (i 6= 0)
E[ssi hv1; v2i] 7\Gamma ! E[vi] (i = 1; 2)
E[(*x : o/: e) v] 7\Gamma ! E[fv=xge]
E[def x:oe = v in e] 7\Gamma ! E[fv=xge]
E[(\Lambda t1; \Delta  \Delta  \Delta  ; tn:e) [o/1; \Delta  \Delta  \Delta  ; o/n]] 7\Gamma ! E[fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tnge]

Figure 2.3: Contextual Dynamic Semantics for Mini-ML

Formally, I consider the rewriting rules to be relations between programs. I consider
evaluation to be the least relation formed by taking the reflexive, transitive closure of
these rules, denoted by 7\Gamma !\Lambda . I define e + v to mean that e 7\Gamma !\Lambda  v, and e * to mean that
there exists an infinite sequence, e 7\Gamma ! e1 7\Gamma ! e2 7\Gamma ! \Delta  \Delta  \Delta .

2.2 Static Semantics of Mini-ML
I formulate the static semantics for Mini-ML as a deductive system allowing us to derive
judgments of the form \Delta ; \Gamma  ` e : o/ and \Delta ; \Gamma  ` v : oe. The first judgment means that
under the assumptions of \Delta  and \Gamma , the expression e can be assigned the monotype o/ .
Similarly, the second judgment asserts that the value v can be assigned the type scheme
oe under the assumptions of \Delta  and \Gamma . Both judgments' assumptions include a set of type
variables (\Delta ) and a type assignment (\Gamma ). The type assignment maps term variables to
type schemes, written fx1:oe1; \Delta  \Delta  \Delta  ; xn:oeng. At most one type scheme is assigned to any
variable in an assignment. Therefore, we can think of \Gamma  as a partial function that maps
variables to types. I use the notation \Gamma  ] fx:o/ g to denote the type assignment obtained
by extending \Gamma  so that it maps x to o/ , under the requirement that x does not already
occur in the domain of \Gamma .

I assume that the free type variables of the range of \Gamma , the free type variables of e
and v, and the free type variables of o/ are contained in \Delta . Hence, \Delta  tracks the set of
type variables that are in scope for the expression, value, or type. Similarly, the domain
of \Gamma  contains the set of free variables of e and v and thus tracks the set of term variables

CHAPTER 2. A SOURCE LANGUAGE: MINI-ML 31
that are in scope for the expression or value. I write \Delta  ` oe and \Delta  ` \Gamma  to assert that oe
and \Gamma  are well-formed with respect to \Delta .

The axioms and inference rules that allow us to derive these judgments are given in
Figure 2.4. Most of the rules are standard, but a few deserve some explanation: If the
assumptions map x to the scheme oe, then we can conclude that x has the type oe. Note
that x can be viewed as a value or an expression and oe could be a monotype (o/ ).

The eq rule requires that both arguments have the same type. For now, I make
no restriction to "equality types" (i.e., types not containing an arrow) as in SML2. The
dynamic semantics simply maps equality of two functional values to 0.

The most interesting rules are def, tapp, and tabs. The def rule allows us to
bind a polymorphic value v to some variable within a closed scope e. If we assign the
value a quantified type, then we can only use the variable in another def binding or type
application. Consequently polymorphic objects are "second-class". The tapp rule allows
us to instantiate a polymorphic value of type 8t1; \Delta  \Delta  \Delta  ; tn:o/ , with types o/1; \Delta  \Delta  \Delta  ; o/n. The
resulting expression has the monotype formed by replacing ti with o/i in o/ . Finally, the
tabs rule assigns the scheme 8t1; \Delta  \Delta  \Delta  ; tn:o/ to the type abstraction \Lambda t1; \Delta  \Delta  \Delta  ; tn:e if, adding
t1; \Delta  \Delta  \Delta  ; tn to the assumptions in \Delta , we can conclude that e has type o/ . Note that the
notation \Delta  ] ft1; \Delta  \Delta  \Delta  ; tng precludes the ti from occurring in \Delta .

I write ` e : oe if ;; ; ` e : oe is derivable from these axioms and inference rules. The
following lemmas summarize the key properties of the static semantics for Mini-ML.

Lemma 2.2.1 (Type Substitution) If \Delta  ] ftg; \Gamma  ` e : oe and \Delta  ` o/ , then
\Delta ; fo/ =tg(\Gamma ) ` fo/ =tg(e) : fo/ =tg(oe).

Proof (sketch): By induction on the derivation of \Delta  ] ftg; \Gamma  ` e : oe. 2

Lemma 2.2.2 (Term Substitution) If \Delta ; \Gamma  ] fx:oe0g ` e : oe and \Delta ; \Gamma  ` e0 : oe0, then
\Delta ; \Gamma  ` fe0=xge : oe.

Proof (sketch): By induction on \Delta ; \Gamma  ] fx:oe0g ` e : oe. Simply replace all occurrences
of the var rule used to assign x the type oe0 with the derivation of \Delta ; \Gamma  ` e0 : oe0. 2

Lemma 2.2.3 (Canonical Forms) Suppose ` e : oe. Then if oe is:

ffl int, then v is some integer i.
ffl float, then v is some floating-point value f .
ffl unit, then v is hi.
2I address the issue of equality types in Section 5.4.2.

CHAPTER 2. A SOURCE LANGUAGE: MINI-ML 32

(var) \Delta ; \Gamma  ] fx:oeg ` x : oe (int) \Delta ; \Gamma  ` i : int (float) \Delta ; \Gamma  ` f : float

(eq) \Delta ; \Gamma  ` e1 : o/ \Delta ; \Gamma  ` e2 : o/\Delta ; \Gamma  ` eq(e

1; e2) : int

(if0) \Delta ; \Gamma  ` e1 : int \Delta ; \Gamma  ` e2 : o/ \Delta ; \Gamma  ` e3 : o/\Delta ; \Gamma  ` if0 e

1 then e2 else e3 : o/

(unit) \Delta ; \Gamma  ` hi : unit (pair) \Delta ; \Gamma  ` e1 : o/1 \Delta ; \Gamma  ` e2 : o/2\Delta ; \Gamma  ` he

1; e2i : ho/1 \Theta  o/2i

(proj) \Delta ; \Gamma  ` e : ho/1 \Theta  o/2i\Delta ; \Gamma  ` ss

i e : o/i (i = 1; 2)

(abs) \Delta ; \Gamma  ] fx:o/1g ` e : o/2\Delta ; \Gamma  ` *x:o/

1: e : o/1 ! o/2 (app)

\Delta ; \Gamma  ` e1 : o/1 ! o/2 \Delta ; \Gamma  ` e2 : o/1

\Delta ; \Gamma  ` e1 e2 : o/2

(def) \Delta ; \Gamma  ` v : oe \Delta ; \Gamma  ] fx:oeg ` e : o/\Delta ; \Gamma  ` def x:oe = v in e : o/

(tapp)

\Delta  ` o/1 \Delta  \Delta  \Delta  \Delta  ` o/n
\Delta ; \Gamma  ` v : 8t1; \Delta  \Delta  \Delta  ; tn:o/

\Delta  ` v[o/1; \Delta  \Delta  \Delta  ; o/n] : fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tngo/

(tabs) \Delta  ] ft1; \Delta  \Delta  \Delta  ; tng; \Gamma  ` e : o/\Delta ; \Gamma  ` \Lambda t

1; \Delta  \Delta  \Delta  ; tn:e : 8t1; \Delta  \Delta  \Delta  ; tn:o/

Figure 2.4: Static Semantics for Mini-ML

CHAPTER 2. A SOURCE LANGUAGE: MINI-ML 33

ffl ho/1 \Theta  o/2i, then v is hv1; v2i, for some v1 and v2.
ffl o/1 ! o/2, then v is *x:o/1: e, for some x and e.
ffl 8t1; \Delta  \Delta  \Delta  ; tn:o/ , then v is \Lambda t1; \Delta  \Delta  \Delta  ; tn:e, for some e.

Proof: By an examination of the typing rules. 2

Lemma 2.2.4 (Unique Decomposition) If ` e : oe, then either e is a value v or else
there exists a unique E, e0, and oe0 such that e = E[e0] and ` e0 : oe0. Furthermore, for all
e00 such that ` e00 : oe0, ` E[e00] : oe.

Proof (sketch): By induction on the derivation of ` e : oe. Suppose e is not a value.
There are seven cases to consider. I give one of the cases here. The other cases follow in
a similar fashion.

case: e is e1 e2 for some e1 and e2. Then a derivation of ` e : oe must end with a use
of the app rule. Hence, there exists o/1 and o/2 such that ` e1 : o/1 ! o/2, ` e2 : o/1 and
oe = o/2. By induction, either e1 is a value or else there exists unique E1, e01, and oe01 such
that e1 = E1[e01] and ` e01 : oe01. If e1 is not a value, then we take E = E1 e2, e0 = e01, and
oe0 = oe01. Otherwise, e1 = v1 for some v1. By induction, either e2 is a value or else there
exists unique E2, e02 and oe02 such that e2 = E2[e02] and ` e02 : oe02. If e2 is not a value, then
E = v1 E2, e0 = e02, and oe0 = oe02. Otherwise, e2 = v2 for some v2. Thus, E = [ ], e0 = v1 v2
and oe0 = oe. 2

Lemma 2.2.5 (Preservation) If ` e : oe and e 7\Gamma ! e0, then ` e0 : oe.
Proof: By Unique Decomposition and the fact that e 7\Gamma ! e0, there exists a unique E,
I, and e00 such that e = E[I], I 7\Gamma ! e00, and e0 = E[e00]. Furthermore, there exists a oe0
such that ` I : oe0 and for all e000 such that ` e000 : oe0, ` E[e000] : oe. Hence, it suffices to
show that regardless of I and e00, ` e00 : oe0. There are six cases to consider:

case: If I = eq(v1; v2) then a derivation of ` I : oe0 must end with an application of the
eq rule. Hence, oe0 = int and there exists a o/ such that ` v1 : o/ and ` v2 : o/ . If v1 and
v2 are integers, floats, or *-abstractions, then I 7\Gamma ! i for some i and ` i : oe0. If v1 and
v2 are pairs, hva; vbi and hv0a; v0bi, then I 7\Gamma ! if0 eq(va; v0a) then 0 else eq(vb; v0b). By
examination of the typing rules, o/ must be of the form ho/a \Theta  o/bi. Since ` v1 : ho/a \Theta  o/bi
and ` v2 : ho/a \Theta  o/bi, derivations of these facts must end with a use of the pair rule.
Hence, ` va : o/a, ` vb : o/b, ` v0a : o/a, and ` v0b : o/b. By the eq rule, ` eq(va; v0a) : int
and ` eq(vb; v0b) : int. Thus, by the if0 rule, ` if0 eq(va; v0a) then 0 else eq(vb; v0b) : int.
Hence, ` e00 : oe0.

CHAPTER 2. A SOURCE LANGUAGE: MINI-ML 34
case: If I = if0 i then e1 else e2, then a derivation of ` I : oe0 must end with an
application of the if0 rule. Hence, there exists a o/ such that ` e1 : o/ and ` e2 : o/ and
oe0 = o/ . If i is 0, then I 7\Gamma ! e1 else I 7\Gamma ! e2. Regardless, the resulting expression has
type oe0.

case: If I = ssi v for i = 1; 2, then a derivation of ` I : oe0 must end with an application
of the proj rule. Hence, there exists o/1 and o/2 such that ` v : ho/1 \Theta  o/2i and oe0 = o/i.
By Canonical Forms, v must be of the form hv1; v2i and I 7\Gamma ! vi. A derivation of
` hv1; v2i : ho/1 \Theta  o/2i must end with the pair rule, hence ` vi : o/i and ` e00 : oe0.

case: If I = (*x:o/1: e1) v then e00 = fv=xge1. A derivation of ` I : oe0 must end with a
use of the app rule. Hence, oe0 = o/2 for some o/2 and ` *x:o/1: e1 : o/1 ! o/2 and ` v : o/1.
By Term Substitution, ` fv=xge1 : o/2. Hence, ` e00 : oe0.

case: If I = (\Lambda t1; \Delta  \Delta  \Delta  ; tn:e1) [o/1; \Delta  \Delta  \Delta  ; o/n] then e00 = fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tnge1. A derivation of
` I : oe0 must end with a use of the tapp rule. Hence, oe0 = fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tngo/ for some o/
such that ` \Lambda t1; \Delta  \Delta  \Delta  ; tn:e1 : 8t1; \Delta  \Delta  \Delta  ; tn:o/ . By Type Substitution, ` fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tnge1 :
fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tngo/ . Thus, ` e00 : oe0. 2

Lemma 2.2.6 (Progress) If ` e : oe, then either e is a value or else there exists some
e0 such that e 7\Gamma ! e0.

Proof: If e is not a value, then by Unique Decomposition, there exists an E, e1, and oe0
such that e = E[e1] and ` e1 : oe0. I argue that e1 must be an instruction and hence, there
is an e2 such that e1 7\Gamma ! e2 and thus E[e1] 7\Gamma ! E[e2]. There are five cases to consider,
where e1 could possibly be stuck.

case: If e1 is of the form ea eb, then ea and eb must both be values, else by Unique
Decomposition, e1 can be broken into a nested evaluation context and expression. Thus,
e1 = v1 v2 for some v1 and v2. Since ` v1 v2 : oe0, the derivation must end in an application
of the app rule. Thus, there exists a o/ 0 and o/ such that ` v1 : o/ 0 ! o/ and ` v2 : o/ 0 and
oe0 = o/ . Since ` v1 : o/ 0 ! o/ , v1 is closed, by Canonical Forms, v1 must be of the form
*x:o/ 0: e00 for some x and e00. Thus, e1 7\Gamma ! fv2=xge00.

case: If e1 is of the form ssi e1 for i = 1; 2, then e1 must be a value v1, else by Unique
Decomposition, e1 can be broken into a nested evaluation context and expression. Thus,
e1 = v for some v. Since ` ssi v : oe0, by an examination of the typing rules, a derivation
of this fact must end with a use of the proj rule. Hence, ` v : o/1 \Theta  o/2 for some o/1 and
o/2 such that o/i = oe0. By Canonical Forms, there exists two values v1 and v2 such that
v = hv1; v2i. Hence, e1 7\Gamma ! vi.

case: If e1 is of the form eq(ea; eb) then ea and eb must be values, v1 and v2. Since
` e1 : oe0, a derivation of this fact must end with the eq rule. Hence, oe0 is int and there
exists a o/ such that ` v1 : o/ and ` v2 : o/ . By Canonical Forms, v1 and v2 are both either
integers, floats, pairs, or functions. Hence, e1 7\Gamma ! i for some i.

CHAPTER 2. A SOURCE LANGUAGE: MINI-ML 35
case: If e1 is of the form if0 ea then eb else ec, then ea must be a value v. Since
` e1 : oe0, a derivation of this fact must end with a use of the if0 rule. Hence, ` v : int.
By canonical forms, v is some integer i. If i is 0, then e1 7\Gamma ! eb else e1 7\Gamma ! ec.
case: If e1 is of the form v [o/1; \Delta  \Delta  \Delta  ; o/n], then since ` e1 : oe0, a derivation of this fact
must end with a use of the tapp rule. Hence, there exists some 8t1; \Delta  \Delta  \Delta  ; tn:o/ such that
` v : 8t1; \Delta  \Delta  \Delta  ; tn:o/ , where oe0 = fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tngo/ . By Canonical Forms, v must be
\Lambda t1; \Delta  \Delta  \Delta  ; tn:e00 for some e00. Hence, e1 7\Gamma ! fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tnge00. 2

This last lemma implies that well-typed Mini-ML expressions cannot "get stuck"
during evaluation. From a practical standpoint, this means that it is impossible to have
a well-typed program that attempts to apply a non-function to some arguments, or to
project a component from a non-tuple. Therefore, any implementation that accurately
reflects the dynamic semantics will never "dump core" when given a well-typed program.

Corollary 2.2.7 (Soundness) If ` e : oe, then either e * or else there exists some v
such that e + v and ` v : oe.

Proof: By induction on the number of rewriting steps, if e 7\Gamma !\Lambda  e0, then by Preservation, ` e0 : oe and by Progress, either e0 is a value or else there exists an e00 such that
e0 7\Gamma ! e00. Therefore, either there exists an infinite sequence, e 7\Gamma !\Lambda  e0 7\Gamma ! e1 7\Gamma ! e2 7\Gamma !
\Delta  \Delta  \Delta , or else e + v and ` v : oe. 2

Chapter 3
A Calculus of Dynamic Type
Dispatch

I argued in Chapter 1 that compiling a polymorphic language without sacrificing control over data representations or the ability to compile modules separately requires an
intermediate language that supports dynamic type dispatch. In this chapter, I present
a core calculus called *MLi that provides a formal foundation for dynamic type dispatch.
In subsequent chapters, I derive intermediate languages based on this formal calculus
and show how to compile Mini-ML to these lower-level languages, taking advantage of
dynamic type dispatch to implement various language features.

3.1 Syntax of *

MLi

*MLi is based on *ML [94], a predicative variant of the Girard-Reynolds polymorphic calculus, F! [47, 46, 106]. The essential departure from the impredicative systems of Girard
and Reynolds is that, as in Mini-ML, there is a distinction made between monotypes
(types without a quantifier) and polytypes, and type variables are only allowed to range
over monotypes. Such a calculus is more than sufficient for the interpretation of ML-style
polymorphism1 and makes arguments based on logical relations easier than an impredicative calculus. The language *MLi extends *ML with intensional (or structural [52])
polymorphism, which allows non-parametric functions to be defined via intensional analysis of types.

The four syntactic classes of *MLi are given in Figure 3.1. The expressions of the
language are described by types. Types include int, function types, explicitly injected
constructors (T (_)) and polymorphic types (8t::^:oe). Types that do not include a quantifier are called monotypes, whereas types that do include a quantifier are called polytypes.

1See Harper and Mitchell [94] for further discussion of this point.

36

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 37
The language easily extends to float, products, and inductively generated types like lists;
I omit these here to simplify the formal treatment of the calculus.

The constructors of *MLi form a language that is isomorphic to a simply-typed *-
calculus extended with a single, inductively defined base type (such as lists or trees) and
an induction elimination form (such as fold). In this case, the inductively defined base
type is given by the set of constructor values which are generated as follows:

o/ ::= Int j Arrow(o/1; o/2):
Each constructor value o/ names a monotype oe. In particular, Int is a constructor value
that names the type int. If o/1 names the type oe1 and o/2 names the type oe2, then
Arrow(o/1; o/2) names the type oe1 ! oe2.

To distinguish expression-level types from constructor-level types, I call the latter
kinds (^). Closed constructors of kind \Omega  compute constructor values. If _ computes the
constructor value o/ , and o/ names the monotype oe, then I use the explicit injection T (_)
to denote the monotype oe. The precise relationship between constructors and monotypes
is axiomatized in Section 3.3.

As in standard polymorphic calculi, constructor abstractions (\Lambda t::^:e) let us define
functions from constructors to terms. Unlike languages based on the Hindley-Milner type
system including Mini-ML, SML, and Haskell, I do not restrict constructor abstractions
to a "second-class" status. This is reflected in the types of the language, because there
is no prenex-quantifier restriction. Hence, constructor abstractions can be placed in data
structures, passed as arguments, or returned from functions.

The Typerec and typerec forms give us the ability to define both constructors and
terms by structural induction on monotypes. The Typerec and typerec forms may be
thought of as eliminatory forms for the kind \Omega  at the constructor and term level respectively. The introductory forms are the constructors of kind \Omega ; there are no introductory
forms at the term level in order to preserve the phase distinction [25, 60]. In effect, Typerec
and typerec let us fold some computation over a monotype. Limiting the computation
to a fold, instead of some general recursion, ensures that the computation terminates --
a crucial property at the constructor level. However, many useful operations, including
pattern matching, iterators, maps, and reductions can be coded using folds.

I consider * to bind the type variable t within a constructor function, *t::^: e. I also
consider 8t::^:oe to bind t within the scope of oe. I consider * to bind the expression
variable x within an expression function, *x:oe: e. I consider \Lambda  to bind the type variable
t within a constructor abstraction \Lambda t::^:e. Finally, I consider t to be bound in oe for the
"[t:oe]" portion of a typerec expression. This type scheme on typerecs is needed to make
the language explicitly typed. As usual, I consider constructors, types, and expressions
to be equivalent modulo ff-conversion of bound variables.

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 38

(kinds) ^ ::= \Omega  j ^1 ! ^2
(constructors) _ ::= t j Int j Arrow(_1; _2) j *t::^: _ j _1 _2 j

Typerec _ of (_int; _arrow)

(types) oe ::= T (_) j int j oe1 ! oe2 j 8t::^:oe
(expressions) e ::= x j i j *x:oe: e j \Lambda t::^:e j e1 e2 j e[_] j

typerec _ of [t:oe](eint; earrow)

Figure 3.1: Syntax of *MLi

(values) u ::= Int j Arrow(u; u) j *t::^: _
(contexts) U ::= [ ] j U _ j u U j Typerec U of (_int; _arrow)
(instructions) J ::= (*t::^: _1) u j Typerec Int of (_int; _arrow) j

Typerec Arrow(u1; u2) of (_int; _arrow)

Figure 3.2: Values, Contexts, and Instructions of Constructors

3.2 Dynamic Semantics of *MLi
The dynamic semantics for *MLi consists of a set of rewriting rules for both constructors
and expressions. I use a contextual semantics to describe evaluation at both levels.

The values, evaluation contexts, and instructions for constructors are given in Figure 3.2. I choose to evaluate constructors in a call-by-value fashion, though either callby-name or call-by-need would also be appropriate. Therefore, the values of constructors
consist of variables, functions, Int, or Arrow constructors with value components. The
evaluation contexts of constructors consist of a hole, an application with a hole somewhere in the function position, an application of a value to constructor with a hole in the
argument position, or a Typerec with a hole somewhere in the argument. The instructions
consist of an application of a function to a value, or a Typerec where the the argument
constructor is either Int or Arrow.

The rewriting rules for constructors are given in Figure 3.3. The rule for function

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 39

U [(*t::^: _1) u2] 7\Gamma ! U [fu2=tg_1]
U [Typerec Int of (_int; _arrow)] 7\Gamma ! U [_int]
U [Typerec Arrow(u1; u2) of (_int; _arrow)] 7\Gamma !

U [_arrow u1 u2 (Typerec u1 of (_int; _arrow)) (Typerec u2 of (_int; _arrow))]

Figure 3.3: Rewriting Rules for Constructors

application is straightforward. The rules for Typerec select the appropriate clause according to the head component of the argument constructor. Thus, _int is chosen if the
argument is Int, while _arrow is chosen if the argument is Arrow(u1; u2). If the argument
constructor has components, then we pass these components as arguments to the clause.
We also pass the the "unrolling" of the Typerec on these components. For instance, if
the argument constructor is Arrow(u1; u2), then we pass u1, u2, and the same Typerec
applied to u1 and u2 to the _arrow clause. In this fashion, the Typerec is folded across the
components of a constructor.

The values, evaluation contexts, and instructions for the expressions of *MLi are given
in Figure 3.4. The evaluation contexts and values show that *MLi expressions are evaluated
in a standard call-by-value fashion. As at the constructor level, I choose to evaluate constructor application eagerly. Hence, a constructor is reduced to a constructor value before
it is substituted for the \Lambda -bound type variable of a constructor abstraction. Evaluation
of an expression-level typerec is similar to the evaluation of a constructor-level Typerec.
First, the argument is evaluated and then, the appropriate clause, either eint or earrow is
chosen according to this component. Any nested constructor components are passed as
constructor arguments to the clause as well as the "unrolling" of the typerec on these
components. Hence, evaluation of a typerec applied to the constructor Arrow(u1; u2)
selects the earrow clause, passes it u1 and u2 as constructor arguments and the same
typerec applied to u1 and u2 as value arguments.

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 40

(values) v ::= i j *x:oe: e j \Lambda t::^:e
(contexts) E ::= [] j E1 e2 j v1 E2 j E[_]
(instructions) I ::= (*x:oe: e) v j (\Lambda t::^:e)[U [J ]] j (\Lambda t::^:e)[u] j

typerec U [J ] of [t:oe](eint; earrow) j
typerec Int of [t:oe](eint; earrow) j
typerec Arrow(u1; u2) of [t:oe](eint; ; earrow)

Figure 3.4: Values, Contexts, and Instructions of Expressions

E[(*x:oe: e) v] 7\Gamma ! E[fv=xge]
E[(\Lambda t::^:e)[U [J ]]] 7\Gamma ! E[(\Lambda t::^:e)[U [_]]] when U [J ] 7\Gamma ! U [_]
E[(\Lambda t::^:e)[u]] 7\Gamma ! E[fu=tge]
E[typerec U [J ] of [t:oe](eint; earrow)] 7\Gamma !

E[typerec U [_] of [t:oe](eint; earrow)] when U [J ] 7\Gamma ! U [_]

E[typerec Int of [t:oe](eint; earrow)] 7\Gamma ! E[eint]
E[typerec Arrow(u1; u2) of [t:oe](eint; earrow)] 7\Gamma !

E[earrow [u1] [u2] (typerec u1 of [t:oe](eint; earrow))

(typerec u2 of [t:oe](eint; earrow))]

Figure 3.5: Rewriting Rules for Expressions

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 41

(var) \Delta  ] ft::^g ` t :: ^ (int) \Delta  ` Int :: \Omega 

(arrow) \Delta  ` _1 :: \Omega  \Delta  ` _2 :: \Omega \Delta  ` Arrow(_

1; _2) :: \Omega 

(fn) \Delta  ] ft::^1g ` _ :: ^2\Delta  ` *t::^

1: _ :: ^1 ! ^2 (app)

\Delta  ` _1 : ^1 ! ^2 \Delta  ` _2 : ^1

\Delta  ` _1 _2 : ^2

(trec)

\Delta  ` _ :: \Omega  \Delta  ` _int :: ^
\Delta  ` _arrow :: \Omega  ! \Omega  ! ^ ! ^ ! ^

\Delta  ` Typerec _ of (_int; _arrow) :: ^

Figure 3.6: Constructor Formation

3.3 Static Semantics of *MLi
The static semantics of *MLi consists of a collection of rules for deriving judgments of the
form \Delta  ` _ :: ^ _ is a constructor of kind ^

\Delta  ` _1 j _2 :: ^ _1 and _2 are equivalent constructors
\Delta  ` oe oe is a valid type
\Delta  ` oe1 j oe2 oe1 and oe2 are equivalent types
\Delta ; \Gamma  ` e : oe e is a term of type oe;

where \Delta  is a kind assignment, mapping type variables (t) to kinds (^), and \Gamma  is a type
assignment, mapping term variables (x) to types (oe). These judgments may be derived
from the axioms and inference rules of Figures 3.6, 3.7, 3.8, 3.9, and 3.10, respectively.

Constructor formation (see Figure 3.6) is standard with the exception of Typerec.
Here, I require that the argument of the Typerec be of kind \Omega . When evaluating a Typerec,
one of the clauses is chosen according to the value of the argument. Any components
are passed as arguments to the clause as well as the unrolling of the Typerec on these
components. Therefore, the whole constructor is assigned the kind ^ only if _int has kind ^
(since the Int constructor has no components) and _arrow has kind \Omega  ! \Omega  ! ^ ! ^ ! ^,
(since it has two components).

To type check an expression, we need to be able to tell when two types are equivalent.
Since constructors can be injected into types, we need an appropriate notion of constructor equivalence. Therefore, I define definitional equivalence [113, 87] via the judgment
\Delta  ` _1 j _2 :: ^. Figure 3.7 gives the axioms and inference rules that allows us to derive

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 42
definitional equivalence. The rules consist of fi- and j-conversion, recursion equations
governing the Typerec form, and standard rules of equivalence and congruence. In the
following chapter, I show that every well-formed constructor _ has a unique normal form,
with respect to the obvious notion of reduction derived by orienting these equivalence
rules to the right. Furthermore, I show that this reduction relation is confluent, from
which it follows that constructor equivalence is decidable [113].

The type formation and equivalence rules can be found in Figures 3.8 and 3.9 respectively. The rules of type equivalence define the interpretation T (_) of the constructor
_ as a type. For example, T (Int) j int and T (Arrow(_1; _2)) j T (_1) ! T (_2). Thus,
T takes us from a constructor that names a type to the actual type. The other type
equivalence rules make the relation an equivalence and congruence with respect to the
type constructs.

The term formation rules may be found in Figure 3.10. Term formation judgments
are of the form \Delta ; \Gamma  ` e : oe. I make the implicit assumption that all free type variables
in oe, e, and the range of \Gamma  can be found in the domain of \Delta . Hence, \Delta  provides the set
of type variables that are in scope.

The term formation rules resemble the typing rules of Mini-ML (see Figure 2.4)
with the exception of the constructor abstraction, application, typerec and equivalence
rules. Similar to value abstraction, constructor abstraction adds a new type variable
of the appropriate kind to the current kind assignment to give a type to the body of
the abstraction. Again, the "]" notation ensures that the added variable does not
already occur in \Delta . For a constructor application, e [_], if e is given a polymorphic
type 8t::^:oe, and _ has kind ^ under the current type and kind assignments, then the
resulting expression has the type obtained by substituting _ for the free occurrences of t
within oe. The equivalence rule ascribes the type oe to an expression of type oe0 if oe and
oe0 are definitionally equivalent.

A typerec expression of the form typerec _ of [t:oe](eint; earrow) is given the type
obtained by substituting the argument constructor _ for t in the type oe if the following
conditions hold: First, _ must be a constructor of kind \Omega , since only these constructors
can be examined via typerec. Second, each of the clauses must have a type obtained by
replacing the appropriate constructor for t within oe. Furthermore, earrow must abstract
the components of the Arrow constructor as well as the result of unwinding the typerec
on these components.

3.4 Related Work
There are two traditional interpretations of polymorphism, the explicit style (due to Girard [47, 46] and Reynolds [106]), in which types are passed to polymorphic operations,
and the implicit style (due to Milner [89]), in which types are erased prior to execution.

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 43

(fi) \Delta  ] ft :: ^

0g ` _1 :: ^ \Delta  ` _2 :: ^0

\Delta  ` (*t::^0: _1) _2 j f_2=tg_1 :: ^

(j) \Delta  ` _ :: ^1 ! ^2\Delta  ` *t::^

1: (_ t) j _ :: ^1 ! ^2 (t 62 Dom(\Delta ))

(trec-int)

\Delta  ` _int :: ^
\Delta  ` _arrow :: \Omega  ! \Omega  ! ^ ! ^ ! ^

\Delta  ` Typerec Int of (_int; _arrow) j _int :: ^

(trec-arrow)

\Delta  ` _1 :: \Omega  \Delta  ` _2 :: \Omega  \Delta  ` _int :: ^

\Delta  ` _arrow :: \Omega  ! \Omega  ! ^ ! ^ ! ^

\Delta  ` Typerec Arrow(_1; _2) of (_int; _arrow) j

_arrow _1 _2 (Typerec _1 of (_int; _arrow))

(Typerec _2 of (_int; _arrow)) :: ^

(refl) \Delta  ` _ :: ^\Delta  ` _ j _ :: ^ (tran) \Delta  ` _1 j _2 :: ^ \Delta  ` _2 j _3 :: ^\Delta  ` _

1 j _3 :: ^

(symm) \Delta  ` _1 j _2 :: ^\Delta  ` _

2 j _1 :: ^ (arrow)

\Delta  ` _1 j _01 :: \Omega  \Delta  ` _2 j _02 :: \Omega 
\Delta  ` Arrow(_1; _2) j Arrow(_01; _02) :: \Omega 

(fn) \Delta  ] ft::^1g ` _1 j _2 :: ^2\Delta  ` *t::^

1: _1 j *t::^1: _2 :: ^1 ! ^2

(app) \Delta  ` _1 j _

01 :: ^1 ! ^2 \Delta  ` _2 j _02 :: ^1

\Delta  ` _1 _2 j _01 _02 :: ^2

(trec)

\Delta  ` _ j _0 :: \Omega  \Delta  ` _int j _0int :: ^
\Delta  ` _arrow j _0arrow :: \Omega  ! \Omega  ! ^ ! ^ ! ^
\Delta  ` Typerec _ of (_int; _arrow) j Typerec _0 of (_0int; _0arrow) :: ^

Figure 3.7: Constructor Equivalence

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 44

\Delta  ` int \Delta  ` _ :: \Omega \Delta  ` T (_) \Delta  ` oe1 \Delta  ` oe2\Delta  ` oe

1 ! oe2

\Delta  ] ft::^g ` oe

\Delta  ` 8t::^: oe

Figure 3.8: Type Formation

\Delta  ` T (Int) j int \Delta  ` T (Arrow(_1; _2)) j T (_1) ! T (_2)

\Delta  ` _ j _0 :: \Omega 
\Delta  ` T (_) j T (_0)

\Delta  ` oe j oe \Delta  ` oe j oe

0

\Delta  ` oe0 j oe

\Delta  ` oe1 j oe2 \Delta  ` oe2 j oe3

\Delta  ` oe1 j oe3

\Delta  ` oe1 j oe01 \Delta  ` oe2 j oe02

\Delta  ` hoe1 \Theta  oe2i j hoe01 \Theta  oe02i

\Delta  ` oe1 j oe01 \Delta  ` oe2 j oe02

\Delta  ` oe1 ! oe2 j oe01 ! oe02

\Delta  ] ft::^g ` oe j oe0
\Delta  ` 8t::^:oe j 8t::^:oe0

Figure 3.9: Type Equivalence

CHAPTER 3. A CALCULUS OF DYNAMIC TYPE DISPATCH 45

(var) \Delta ; \Gamma  ] fx:oeg ` x : oe (int) \Delta ; \Gamma  ` i : int
(fn) \Delta ; \Gamma  ] fx:oe1g ` e : oe2\Delta ; \Gamma  ` *x:oe

1: e : oe1 ! oe2 (app)

\Delta ; \Gamma  ` e1 : oe1 ! oe2 \Delta ; \Gamma  ` e2 : oe1

\Delta ; \Gamma  ` e1 e2 : oe2

(tfn) \Delta  ] ft::^g; \Gamma  ` e : oe\Delta ; \Gamma  ` \Lambda t::^: e : 8t::^:oe (tapp) \Delta ; \Gamma  ` e : 8t::^:oe \Delta  ` _ :: kappa\Delta ; \Gamma  ` e[_] : f_=tgoe

(trec)

\Delta  ` _ : \Omega 
\Delta ; \Gamma  ` eint : fInt=tgoe
\Delta ; \Gamma  ` earrow : 8t1::\Omega :8t2::\Omega :ft1=tgoe ! ft2=tgoe ! fArrow(t1; t2)=tgoe

\Delta ; \Gamma  ` typerec _ of [t:oe](eint; earrow) : f_=tgoe

(equiv) \Delta ; \Gamma  ` e : oe

0 \Delta  ` oe0 j oe :: \Omega 

\Delta ; \Gamma  ` e : oe

Figure 3.10: Term Formation

In their study of the type theory of Standard ML [93, 59], Harper and Mitchell argued
that an explicitly-typed interpretation of ML polymorphism has better semantic properties and scales more easily to cover a full programming language. Harper and Mitchell
formulated a predicative type theory, XML, a theory of dependent types augmented with
a universe of small types, adequate for capturing many aspects of SML. This type theory
was later refined by Harper, Mitchell, and Moggi [60], and provides the fundamental basis
for the type theory of *MLi .

The idea of adding an inductively generated ground type (the natural numbers) with
an elimination rule like Typerec, to the typed *-calculus is implicit in G"odel's original
"functionals of finite type"[48]. Thus, the constructor language of *MLi is fundamentally
based on this work. According to Lambek and Scott [79], Marie-France Thibault [117]
studied the correspondence between such calculi and cartesian closed categories equipped
with "strong" natural number objects. However, the notion of constructor equivalence
in *MLi corresponds to what Lambek and Scott term a "weak" natural number object.

The idea of adding an inductively generated universe, with a term-level elimination
rule such as typerec, was derived from the universe elimination rules found in NuPrl [32],
though the idea was only described in unpublished work of Robert Constable. Harper
and I devised the original formulation of *MLi [62, 61].

Chapter 4
Typing Properties of *MLi

In this chapter, I present proofs of two important properties of *MLi : Type checking
*MLi terms is decidable, and the type system is sound with respect to the operational
semantics. Hence, *MLi enjoys many of the same semantic properties as more conventional
typed calculi.

Readers anxious to see how dynamic type dispatch can be used may wish to skip this
chapter and come back to it later.

4.1 Decidability of Type Checking for *MLi
If we remove the equivalence rule from the term formation rules, then type checking *MLi
terms would be entirely syntax-directed. This is due to the type label on *-abstractions
at the expression level, the kind label on *-abstractions at the constructor level, and the
type scheme [t:oe] labelling typerec expressions. But in the presence of the equivalence
rule, we need an alternative method for determining whether an expression may be
assigned a type, and if so, what types it may be given.

In this section, I show that every well-formed constructor has a unique normal form
with respect to a certain notion of reduction, and that two constructors are definitionally equivalent if and only if they have syntactically identical normal forms, modulo
ff-conversion. From this notion of normal forms for constructors, it is straightforward
to generalize to a normal form for types: Normalize any constructor components of the
type, and recursively replace T (Int) with int and T (Arrow(_1; _2)) with T (_1) ! T (_2).
From this, it is easy to see that two types are definitionally equivalent iff their normal
forms are syntactically equivalent, modulo ff-conversion.

With normal forms for types, we can formulate a different proof system for the wellformedness of *MLi terms that is entirely syntax directed: At each step in the derivation,
we replace the type on the right-hand side of the ":" with its normal form. Given a

46

CHAPTER 4. TYPING PROPERTIES OF *MLI 47
procedure for determining normal forms, since the rest of the rules are syntax directed,
type checking in the new proof system is entirely syntax directed. Furthermore, it is
easy to see that the resulting proof system is equivalent to the original system. Any
proof in the new system can be transformed into a proof in the old system simply by
adding applications of the equivalence rule at each step, asserting that the type ascribed
by the old system and its normal form are equivalent. Any proof in the old system can
be transformed into a proof in the new system since normal forms are unique.

Consequently, if I can establish normal forms for constructors, show that two constructors are definitionally equivalent iff they have the same normal form, and give a
procedure for finding normal forms, then we can use this procedure to formulate an
entirely syntax-directed type checking system.

4.1.1 Reduction of Constructors
I begin by defining a reduction relation, _ \Gamma ! _0, on "raw" constructors that (potentially)
contain free variables. This primitive notion of reduction is generated from four rules:
one rule each for fi- and j-reduction of functionals, and two rules for reducing Typerecs:

(fi) (*t::^: _) _0 \Gamma ! f_0=tg_
(j) (*t::^: (_ t)) \Gamma ! _ (t 62 F V (_))
(t1) Typerec Int of (_int; _arrow) \Gamma ! _int
(t2) Typerec Arrow(_1; _2) of (_int; _arrow) \Gamma !

_arrow _1 _2 (Typerec _1 of (_int; _arrow))(Typerec _2 of (_int; _arrow))

I use T to abbreviate the union of these four relations:

T = fi [ j [ t1 [ t2
I extend the relation to form a congruence by defining term contexts which are arbitrary
raw constructors with a single hole in them, much like constructor evaluation contexts,
but with no restrictions governing where the hole can occur:

C ::= [ ] j Arrow(C; _) j Arrow(_; C) j *t::^: C j C _ j _ C j

Typerec C of (_int; _arrow) j Typerec _ of (C; _arrow) j Typerec _ of (_int; C)

The constructor C[_] represents the result of replacing the hole in C with the constructor
_, possibly binding free variables of _.

Definition 4.1.1 _1 \Gamma ! _2 iff there exists _01, _02, and C such that _1 = C[_01], _2 =
C[_02], and (_01; _02) 2 T.

CHAPTER 4. TYPING PROPERTIES OF *MLI 48

I write _1 \Gamma !\Lambda  _2 for the reflexive, transitive closure of _1 \Gamma ! _2, _1 ! _2 for
the symmetric closure of _1 \Gamma ! _2, and _1 !\Lambda  _2 for the least equivalence relation
generated by _1 \Gamma !\Lambda  _2. The constructor _ is in normal form if there is no _0 such that
_ \Gamma ! _0. I say that a constructor _ is strongly normalizing (SN ) if there is no infinite
reduction sequence _ \Gamma ! _1 \Gamma ! _2 \Gamma ! \Delta  \Delta  \Delta .

Lemma 4.1.2

1. If _1 \Gamma ! _2, then f_3=tg_1 \Gamma ! f_3=tg_2.
2. If _1 \Gamma ! _2, then f_1=tg_3 \Gamma ! f_2=tg_3.

Proof (sketch): Straightforward induction on terms and case analysis of the reduction
relation. 2

The following lemmas relate the reduction relation to definitional equivalence. In
particular, two well-formed constructors _1 and _2 are definitionally equivalent iff we can
convert from _1 to _2 via the !\Lambda  equivalence relation.

Lemma 4.1.3 (Substitution) If \Delta  ] ft::^0g ` _ :: ^ and \Delta  ` _0 :: ^0, then \Delta  `
f_0=tg_ :: ^.

Lemma 4.1.4 If \Delta  ` C[_] :: ^, then there exists some \Delta 0 and ^0 such that \Delta 0 ` _ :: ^0
and if \Delta 0 ` _0 :: ^0, then \Delta  ` C[_0] :: ^.

Proof (sketch): By induction on C. 2

Lemma 4.1.5 (Kind Preservation) If \Delta  ` _ :: ^ and _ \Gamma ! _0, then \Delta  ` _0 :: ^.
Proof: Suppose \Delta  ` C[_] :: ^. By the previous lemma, there exists some \Delta 0 and ^0
such that \Delta 0 ` _ :: ^0. Hence, it suffices to show that (_; _0) 2 T implies \Delta 0 ` _0 :: ^0.

fi : _ = (*t::^1: _1) _2 and _0 = f_2=tg_1. Follows from the typing rule for functions

and the Substitution Lemma.

j : _ = *t::^1: (_1 t) (t 62 F V (_1)) and _0 = _1. By the typing rule for functions,

\Delta 0 ] ft::^1g ` _1 t :: ^2 for some ^2 and ^0 = ^1 ! ^2. By the application rule,
\Delta 0 ] ft::^1g ` _1 :: ^0. Since t does not occur free in _1, \Delta 0 ` _1 :: ^0.

t1 : _ = Typerec Int of (_i; _a) and _0 = _i. By the typing rule for Typerec, \Delta 0 ` _ :: ^0

and \Delta  ` _i :: ^0.

CHAPTER 4. TYPING PROPERTIES OF *MLI 49

t2 : _ = Typerec Arrow(_1; _2) of (_i; _a) and

_0 = _a _1 _2 Typerec _1 of (_i; _a) Typerec _2 of (_i; _a):
By the typing rule for Typerec, \Delta 0 ` _ :: ^0 and \Delta  ` _i :: ^0, \Delta 0 ` _a :: \Omega  !
\Omega  ! ^0 ! ^0 ! ^0. By the rule for Arrow, \Delta 0 ` _1 :: \Omega  and \Delta 0 ` _2 :: \Omega . By the
application rule, _a _1 _2 has type ^0 ! ^0 ! ^0. By the typing rule for Typerec,
\Delta 0 ` Typerec _1 of (_i; _a) :: ^0 and likewise for _2. Thus, by the application rule,
\Delta 0 ` _0 :: ^0.

2

Lemma 4.1.6 If \Delta  ` _ :: ^ and _ \Gamma ! _0, then \Delta  ` _ j _0 :: ^.
Proof (sketch): Suppose \Delta  ` C[_] :: ^ and (_; _0) 2 T. Then there exists some
\Delta 0, ^0 such that \Delta 0 ` _ :: ^0 and by preservation, \Delta 0 ` _0 :: ^0. Argue by cases that
\Delta 0 ` _ j _0 :: ^0. Then show by induction on C that \Delta 0 ` _ j _0 :: ^0 implies
\Delta  ` C[_] j C[_0] :: ^. 2

Lemma 4.1.7 If \Delta  ` _1 :: ^, \Delta  ` _2 :: ^, and there exists a _ such that _1 \Gamma !\Lambda  _ and
_2 \Gamma !\Lambda  _, then \Delta  ` _1 j _2 : ^.

Proof: By the previous lemma, \Delta  ` _1 j _ :: ^ and \Delta  ` _2 j _ :: ^ and by symmetry
and transitivity, \Delta  ` _1 j _2 :: ^. 2

Lemma 4.1.8 \Delta  ` _1 j _2 :: ^ iff _1 !\Lambda  _2.
Proof: The "only-if" is apparent from the previous lemma. Hence, I must show
that \Delta  ` _1 j _2 :: ^ implies _1 !\Lambda  _2. I argue by induction on the derivation of
\Delta  ` _1 j _2 :: ^. Reflexivity, symmetry, and transitivity follow from the definition of
!\Lambda . The arrow, fn, app, and trec rules follow by building an appropriate context C
for each of the component constructors _, using the induction hypothesis to argue that
_ j _0 implies _ !\Lambda  _0 and thus C[_] j C[_0]. The subcases are glued together via
transitivity. The fi, j, trec-int, and trec-arrow rules all follow from their counterparts in
T. 2

The main results of this chapter are that the reduction relation "\Gamma !\Lambda " is confluent
and strongly normalizing for well-formed constructors. That is, every reduction sequence
terminates and the reduction sequences have the diamond property: If a constructor
reduces to two different constructors, then those two constructors reduce to a common
constructor.

CHAPTER 4. TYPING PROPERTIES OF *MLI 50
Proposition 4.1.9 (Strong Normalization) If \Delta  ` _ :: ^, then _ is strongly normalizing.

Proposition 4.1.10 (Confluence) If _ \Gamma !\Lambda  _1 and _ \Gamma !\Lambda  _2, then there exists a
constructor _0 such that _1 \Gamma !\Lambda  _0 and _2 \Gamma !\Lambda  _0.

Confluence for "\Gamma !\Lambda " is important because of the following immediate corollaries:
First, normal forms are unique up to ff-conversion:

Corollary 4.1.11 If _ \Gamma !\Lambda  _1 and _ \Gamma !\Lambda  _2 and _1 and _2 are normal forms, then
_1 = _2.

Second, the reduction system has the "Church-Rosser" property, which tells us that
finding and comparing normal forms is a complete procedure for determining equivalence
of constructors.

Corollary 4.1.12 (Church-Rosser) _ !\Lambda  _0 iff there exists a _00 such that _ \Gamma !\Lambda  _00
and _0 \Gamma !\Lambda  _00.

Proof: The "if" part is obvious. For the "only if", I argue by induction on the length
of the sequence _ ! _1 ! \Delta  \Delta  \Delta  ! _n ! _0. For n = 0, _ ! _0 and thus either
_ \Gamma ! _0 or else _0 \Gamma ! _. Without loss of generality, assume _ \Gamma ! _0. Then choose
_00 = _0 and we are done. Assume the theorem holds for all values up through n. We
have _ ! _1 ! \Delta  \Delta  \Delta  ! _n and _n ! _0. I must show that there is a _00 such that
_n \Gamma !\Lambda  _00 and _0 \Gamma !\Lambda  _00. By the induction hypothesis, there exists _a and _b such
that _ \Gamma !\Lambda  _a, _n \Gamma !\Lambda  _a, _n \Gamma !\Lambda  _b, and _0 \Gamma !\Lambda  _b. Since _n reduces to both _a and
_b, we have via confluence that there exists a _00 such that _a \Gamma !\Lambda  _00 and _b \Gamma !\Lambda  _00
and hence _ \Gamma !\Lambda  _00 and _0 \Gamma !\Lambda  _00. 2

Since for well-formed constructors, convertibility is the same as definitional equivalence, the Church-Rosser property implies that two well-formed constructors are definitionally equivalent iff there is some common reduct. If I can show that all well-formed
constructors are strongly normalizing, then we have a decision procedure for determining
constructor equivalence: Choose any reduction sequence for the two constructors and
eventually, we will reach normal forms, since the two constructors are strongly normalizing. Then, the Church-Rosser theorem together with unique normal forms, tells us
that the two constructors are equivalent iff the two normal forms are equivalent modulo
ff-conversion.

In the presence of strong normalization, confluence is equivalent to local confluence:
If _ \Gamma ! _1 and _ \Gamma ! _2, then there exists a _0 such that _1 \Gamma !\Lambda  _0 and _2 \Gamma !\Lambda  _0.

Lemma 4.1.13 If _ is strongly normalizing and locally confluent, then _ is confluent.

CHAPTER 4. TYPING PROPERTIES OF *MLI 51
Proof: Suppose _ \Gamma !\Lambda  _1 in m steps and _ \Gamma !\Lambda  _2 in n steps. Since _ is strongly
normalizing, there exists some bound b on the number of steps any reduction sequence
can take. I argue by induction on b and reduce the problem to m ^ 1, n ^ 1. If m = 0
or n = 0 then there is nothing to prove. The case m = 1, n = 1 is handled by local
confluence.

Suppose m ? 1 or else n ? 1. Then, we have _ \Gamma ! _01 \Gamma !m\Gamma 1 _1 and _ \Gamma !
_02 \Gamma !n\Gamma 1 _2 where m \Gamma  1 ? 0 or n \Gamma  1 ? 0. By local confluence, we know there is a _00
such that _01 \Gamma !\Lambda  _00 and _02 \Gamma !\Lambda  _00.

Now _01 and _02 have smaller bounds than _, so by the induction hypothesis, there
exists _001 and _002 such that _1 \Gamma !\Lambda  _001, _00 \Gamma !\Lambda  _001, _2 \Gamma !\Lambda  _002, and _00 \Gamma !\Lambda  _002.

Again, _00 has a bound less than b, so applying the induction hypothesis, we know that
there exists a _0 such that _001 \Gamma !\Lambda  _0 and _002 \Gamma !\Lambda  _0. Thus, _1 \Gamma !\Lambda  _0 and _2 \Gamma !\Lambda  _0.

The result is summarized by the following diagram, where assuming the solid arrows,
we have shown that the dotted arrows exist:

_

_01 _02
_1 _00 _2

_001 _002

_0

jj
jj
jj+

1

QQ

QQ

QQs

1

jj
jj
jj+

m \Gamma  1 QQ

QQ

QQs

n \Gamma  1. . . .
. . .

. .s

\Lambda 

...
...
...+

\Lambda 

...
...
...+

\Lambda 

. . .

. . .

. . .s
\Lambda 

. . .

. . .

. . .s
\Lambda 

...
...
...+

\Lambda 

. . .

. . .

. . .s
\Lambda 

...
...
...+

\Lambda 

2
All that remains is to establish local confluence and strong normalization, which I
address in Sections 4.1.2 and 4.1.3, respectively.

4.1.2 Local Confluence for Constructor Reduction
To show that the reduction system for constructors is locally confluent, I must show
that whenever _ \Gamma ! _1 and _ \Gamma ! _2, then there exists a _0 such that _1 \Gamma !\Lambda  _0 and
_2 \Gamma !\Lambda  _0.

CHAPTER 4. TYPING PROPERTIES OF *MLI 52

Let D range over the set of expressions with exactly two holes in them. This set can
be described by the following grammar:

D ::= Arrow(C1; C2) j C1C2 j Typerec C1 of (C2; _arrow) j

Typerec C1 of (_int; C2) j Typerec _ of (C1; C2) j C[D]

where I use C[D] to denote the two-holed constructor formed by replacing the hole in C
with D and I use D[_1; _2] to denote the constructor obtained by replacing the left-most
hole in D with _1 and the right-most hole in D with _2.

Suppose _ = Ca[_a], (_a; _0a) 2 T, and _ = Cb[_b] and (_b; _0b) 2 T. The two
constructors, _a and _b are said to overlap in _ if one constructor is only found as a
subterm of the other (i.e., _a = C[_b] or _b = C[_a] for some C). If _a and _b do not
overlap, then it is clear that there exists some D such that _ = D[_a; _b] and thus:

_ = D[_a; _b] \Gamma ! D[_0a; _b] \Gamma ! D[_0a; _0b]
and

_ = D[_a; _b] \Gamma ! D[_a; _0b] \Gamma ! D[_0a; _0b]:

Therefore, we need only consider overlapping constructors to show local confluence.

Let _a and _b be overlapping constructors in _, such that _ = Ca[_a], _a = Cb[_b],
and suppose (_a; _0a) 2 T and (_b; _0b) 2 T. Without loss of generality, we may ignore the
outer context, Ca. There are four cases for the reduction from _a to _0a. I consider each
case below and show that, for each rule taking _b to _0b, there exists a _0 and sequence of
reductions which takes _0a to _0 and Cb[_0b] to _0. Each argument is made by presenting
a diagram where the left-arrow represents the reduction from _a to _0a, and the right
arrow represents the reduction from _a = Cb[_b] to Cb[_0b]. The solid arrows represent
assumptions, whereas the dotted arrows represent the relations I claim exist. I use t to
represent some arbitrary reduction from T, ff to represent ff conversion, = to represent
zero reductions, and t\Lambda  to represent zero or more applications of a t reduction.

case fi: Both sub-cases follow from lemma 4.1.2, part 1 and 2 respectively.

(*t::^: _1) _2

f_2=tg_1 (*t::^: _01) _2

f_2=tg_01

jj
jj
j+

fi QQ

QQ

Qs

t

. . .

. . .

.st

...
...
.+ fi

(*t::^: _1) _2
f_2=tg_1 (*t::^: _1) _02

f_02=tg_1

jj
jj
j+

fi QQ

QQ

Qs

t

. . .

. . .

.st\Lambda 

...
...
.+ fi

CHAPTER 4. TYPING PROPERTIES OF *MLI 53
case j: The constructor is an j-redex *t::^: (_1 t). If the inner reduction occurs within
_1, then the result is obvious, since t cannot occur freely within _1. If the inner reduction
is an application of fi because _1 is a function, then the results of the outer reduction
and inner reduction yield terms that are equal, modulo ff-conversion.

*t::^: (_1 t)

_1 *t::^: (_01 t)

_01

jj
jj
jj+

j QQ

QQ

Qs

t

. . .

. . .

. . .st

...
...
..+ j

*t::^: ((*t0::^0: _1) t)
*t0::^0: _1 *t::^: ft=t0g_1

*t0::^0: _1

jj
jj
j+

j QQ

QQ

Qs

fi

. . .

. . .

.s=

...
...
.+ ff

case t1: The constructor is a Typerec applied to Int. The inner reduction either modifies _i or _a. If _i is reduced, then after performing the Typerec reduction, the same
reduction can be applied. If _a is reduced, then after performing the Typerec reduction,
_a disappears, and the terms are equal.

Typerec Int of (_i; _a)

_i Typerec Int of (_0i; _a)

_0i

jj
jj
jj+

t1 QQ

QQ

Qs

t

. . .

. . .

. . .st

...
...
..+ t1

Typerec Int of (_i; _a)

_i Typerec Int of (_i; _0a)

_i

jj
jj
jj+

t1 QQ

QQ

Qs

t

. . .

. . .

. . .s=

...
...
..+ t1

case t2: The constructor is a Typerec applied to Arrow(_1; _2). There are four subcases: _1, _2, _i, or _a is reduced. In any of these cases, we can apply the same reduction,

CHAPTER 4. TYPING PROPERTIES OF *MLI 54
possibly multiple times to yield the same term.

Typerec Arrow(_1; _2) of (_i; _a)

_a _1 _2 (Typerec _1 of (_i; _a))

(Typerec _2 of (_i; _a)) Typerec Arrow(_

01; _2) of (_i; _a)

_a _01 _2 (Typerec _01 of (_i; _a)) (Typerec _2 of (_i; _a))

aeae
aeae
aeaeae=

t2

ZZ

ZZ

ZZ

ZZ~

t

. . .

. . .

. . .

.~
t\Lambda 

...
...
...
...= t2

Typerec Arrow(_1; _2) of (_i; _a)

_a _1 _2 (Typerec _1 of (_i; _a))

(Typerec _2 of (_i; _a)) Typerec Arrow(_1; _

02) of (_i; _a)

_a _1 _02 (Typerec _1 of (_i; _a)) (Typerec _02 of (_i; _a))

aeae
aeae
aeaeae=

t2

ZZ

ZZ

ZZ

ZZ~

t

. . .

. . .

. . .

.~
t\Lambda 

...
...
...
...= t2

Typerec Arrow(_1; _2) of (_i; _a)

_a _1 _2 (Typerec _1 of (_i; _a))

(Typerec _2 of (_i; _a)) Typerec Arrow(_1; _2) of (_

0i; _a)

_a _1 _2 (Typerec _1 of (_0i; _a)) (Typerec _2 of (_0i; _a))

aeae
aeae
aeaeae=

t2

ZZ

ZZ

ZZ

ZZ~

t

. . .

. . .

. . .

.~
t\Lambda 

...
...
...
...
=

t2

CHAPTER 4. TYPING PROPERTIES OF *MLI 55

Typerec Arrow(_1; _2) of (_i; _a)

_a _1 _2 (Typerec _1 of (_i; _a))

(Typerec _2 of (_i; _a)) Typerec Arrow(_1; _2) of (_i; _

0a)

_0a _1 _2 (Typerec _1 of (_i; _0a)) (Typerec _2 of (_i; _0a))

aeae
aeae
aeaeae=

t2

ZZ

ZZ

ZZ

ZZ~

t

. . .

. . .

. . .

.~
t\Lambda 

...
...
...
...= t2

Finally, from the diagrams above, we have the desired property.
Theorem 4.1.14 (Local Confluence) If _ \Gamma ! _1 and _ \Gamma ! _2, then there exists a
_0 such that _1 \Gamma !\Lambda  _0 and _2 \Gamma !\Lambda  _2.

All that remains is to show that well-formed constructors are strongly normalizing.

4.1.3 Strong Normalization for Constructor Reduction
Our proof of strong normalization for the constructor reduction relation uses unary logical
relations (predicates), but in a setting where we can have open terms. The ideas follow
closely those of Harper [55] and Lambek and Scott [79].

The predicates are indexed by both a kind (^) and a kind assignment (\Delta ) and are
defined as follows:

jj\Omega jj\Delta  = f_ j \Delta  ` _ :: ^; _ SN g
jj^1 ! ^2jj\Delta  = f_ j \Delta  ` _ :: ^1 ! ^2; 8\Delta 0 ' \Delta : 8_1 2 jj^1jj\Delta 0 : _ _1 2 jj^2jj\Delta 0g

The idea is to include only those constructors that are strongly normalizing and then
show that every well-formed constructor is in the appropriate set. From the definitions,
it is clear that if _ 2 jj^jj\Delta  then \Delta  ` _ :: ^ and for all \Delta 0 ' \Delta , jj^jj\Delta 0.

Lemma 4.1.15 t _1 _2 \Delta  \Delta  \Delta  _n is SN iff each _i is SN .

The following lemma shows that every constructor in one of the sets is strongly
normalizing and that a variable t is always in jj^jj\Delta , whenever \Delta (t) = ^.

Lemma 4.1.16 1. If _ 2 jj^jj\Delta , then _ is SN .

CHAPTER 4. TYPING PROPERTIES OF *MLI 56

2. If \Delta  ` t :: ^1 ! \Delta  \Delta  \Delta  ! ^n ! ^, \Delta 0 ` _i :: ^i and _i is SN (1 ^ i ^ n) for some

\Delta 0 ' \Delta , then t _1 \Delta  \Delta  \Delta  _n 2 jj^jj\Delta 0.

Proof: Simultaneously by induction on ^. If ^ = \Omega , then part 1 is built in to the
definition and part 2 follows since t _1 \Delta  \Delta  \Delta  _n is SN whenever each of the _i are SN .

Suppose ^ = ^0 ! ^00 and _ 2 jj^jj\Delta . Take \Delta 0 = \Delta  ] ft::^0g. By induction hypothesis
2, t 2 jj^0jj\Delta 0 and _ t 2 jj^00jj\Delta 0 from which it follows via induction hypothesis 1 that _ t
is SN . This in turn implies that _ is SN .

Suppose ^ = ^0 ! ^00, \Delta  ` t :: ^1 ! \Delta  \Delta  \Delta  ! ^n ! ^, and \Delta 0 ` _i :: ^i is SN for some
\Delta 0 ' \Delta . Let _ 2 jj^0jj\Delta 0. I must show that t _1 \Delta  \Delta  \Delta  _n _ 2 jj^00jj\Delta 0. But by induction
hypothesis 1, _ is SN . Hence, by induction hypothesis 2, the result holds. 2

Corollary 4.1.17 If \Delta  ` t :: ^, then t 2 jj^jj\Delta .

The following lemma shows that the predicates are closed under a suitable notion of
fi-expansion. This lemma is crucial for showing that well-formed *-terms are in the sets
and therefore are strongly normalizing.

Lemma 4.1.18 Suppose \Delta  ] ft::^0g ` _ :: ^1 ! \Delta  \Delta  \Delta  ! ^n ! ^ and _i 2 jj^ijj\Delta 
(0 ^ i ^ n). If (f_0=tg_) _1 \Delta  \Delta  \Delta  _n 2 jj^jj\Delta , then (*t::^0: _) _0 _1 \Delta  \Delta  \Delta  _n 2 jj^jj\Delta .

Proof:

By induction on ^. Assume ^ = \Omega . I must show _a = (*t::^0: _) _0 _1 \Delta  \Delta  \Delta  _n is in
jj\Omega jj\Delta . It suffices to show that this term is SN . Suppose not. Then there exists some
infinite reduction sequence starting with _a. Since (f_0=tg_) _1 \Delta  \Delta  \Delta  _n 2 jj\Omega jj\Delta , this
term is SN and hence all of its components are. Moreover, since _0 2 jj^0jj\Delta , _0 is SN .
Hence, no infinite reduction sequence can take place only within _; _0; _1; \Delta  \Delta  \Delta  ; _n. Thus,
any infinite reduction sequence has the form:

(*t::^0: _) _0 _1 \Delta  \Delta  \Delta  _n \Gamma !\Lambda 

(*t::^0: _0) _00 _01 \Delta  \Delta  \Delta  _0n \Gamma !

(f_00=tg_0); _01; \Delta  \Delta  \Delta  ; _0n \Gamma ! _00 \Gamma ! \Delta  \Delta  \Delta 

Consequently, _ \Gamma !\Lambda  _0, _0 \Gamma !\Lambda  _00, and f_0=tg_ \Gamma !\Lambda  f_00=tg_0. Thus, we can construct
an infinite reduction sequence:

(f_0=tg_ _1 \Delta  \Delta  \Delta  _n \Gamma !\Lambda 

(f_00=tg_0 _01 \Delta  \Delta  \Delta  _0n \Gamma ! _00 \Gamma ! \Delta  \Delta  \Delta 

contradicting the assumption. Therefore, _a 2 jj\Omega jj\Delta .

CHAPTER 4. TYPING PROPERTIES OF *MLI 57

Assume ^ = ^0 ! ^00, and let _0 2 jj^0jj\Delta 0 for \Delta 0 ' \Delta . I must show that

(*t::^0: _) _0 _1 \Delta  \Delta  \Delta  _n _0
is in jj^00jj\Delta 0. By the induction hypothesis, this holds if

(f_0=tg_) _1 \Delta  \Delta  \Delta  _n _0
is in jj^00jj\Delta 0. But this follows from the assumption that

(f_0=tg_) _1 \Delta  \Delta  \Delta  _n
is in jj^0 ! ^00jj\Delta . 2

Corollary 4.1.19 If \Delta  ] ft::^0g ` _ :: ^, _0 2 jj^0jj\Delta , and f_0=tg_ 2 jj^jj\Delta , then
(*t::^0: _) _0 2 jj^jj\Delta .

The following lemma shows that the predicates are closed under a suitable notion
of Typerec-expansion. This lemma is crucial for showing that well-formed Typerecconstructors are in the sets and hence are strongly normalizing.

Lemma 4.1.20 Let ^0 = ^1 ! \Delta  \Delta  \Delta  ! ^n ! ^ and suppose \Delta  ` Typerec _ of (_i; _a) ::
^0, _j 2 jj^jjj\Delta  (1 ^ j ^ n), _ 2 jj\Omega jj\Delta , _i 2 jj^0jj\Delta , and _a 2 jj\Omega  ! \Omega  ! ^0 ! ^0 !
^0jj\Delta . Then Typerec _ of (_i; _a) 2 jj^0jj\Delta .

Proof:

By induction on ^. If ^ = \Omega , then it suffices to show that

Typerec _ of (_i; _a) _1 \Delta  \Delta  \Delta  _n
is SN . I argue by induction on the height (h) of the normal form of _. Suppose h = 0.
Then the normal form of _ is either a variable or Int. Since _ 2 jj\Omega jj\Delta , _i 2 jj^0jj\Delta , _a is
in

jj\Omega  ! \Omega  ! ^0 ! ^0 ! ^0jj\Delta ;

and _j 2 jj^jjj\Delta  (1 ^ j ^ n), _, _i, _a, and _1; \Delta  \Delta  \Delta  ; _n are all SN . Hence, any infinite
reduction sequence cannot occur only within these terms. Thus, any such sequence
must perform a Typerec reduction and the normal form of _ must be Int, so the infinite
reduction sequence has the form:

Typerec _ of (_i; _a) _1 \Delta  \Delta  \Delta  _n \Gamma !\Lambda 

Typerec Int of (_0i; _0a) _01 \Delta  \Delta  \Delta  _0n \Gamma ! _0i _01 \Delta  \Delta  \Delta  _0n \Gamma ! \Delta  \Delta  \Delta 

CHAPTER 4. TYPING PROPERTIES OF *MLI 58
But since _i 2 jj^0jj\Delta , and _j 2 jj^jjj\Delta  (1 ^ j ^ n), _0i _01 \Delta  \Delta  \Delta  _0n is SN . Therefore,
Typerec _ of (_i; _a) 2 jj^0jj\Delta  when h = 0.

Suppose the theorem holds for all terms with normal forms of height less than h and
suppose the normal form of _ has height h + 1. By the same previous argument, any
infinite reduction sequence must perform a Typerec reduction. Furthermore, since the
normal form of _ has height h + 1, such a sequence must have the form:

Typerec _ of (_i; _a) _1 \Delta  \Delta  \Delta  _n \Gamma !\Lambda 

Typerec Arrow(_1; _2) of (_0i; _0a) _01 \Delta  \Delta  \Delta  _0n \Gamma !
((_0a _1 _2 (Typerec _1 of (_0i; _0a)) (Typerec _2 of (_0i; _0a))) _01 \Delta  \Delta  \Delta  _0n) \Gamma ! \Delta  \Delta  \Delta 

Since _ is SN , it must be the case that _1 and _2 are SN , and hence _1; _2 2 jj\Omega jj\Delta .
Furthermore, the heights of the normal forms of _1 and _2 must be less than or equal
to h. Hence, via the inner induction hypothesis, Typerec _1 of (_0i; _0a) 2 jj\Omega jj\Delta  and
Typerec _1 of (_0i; _0a) 2 jj\Omega jj\Delta . Since by assumption _a 2 jj\Omega  ! \Omega  ! ^0 ! ^0 ! ^0jj\Delta ,

(_0a _1 _2 (Typerec _1 of (_0i; _0a)) (Typerec _2 of (_0i; _0a))) _01 \Delta  \Delta  \Delta  _0n
is SN and in jj\Omega jj\Delta .

Now suppose ^ = ^0 ! ^00 and let _0 2 jj^0jj\Delta 0 for some \Delta  ' \Delta . I must show that
(Typerec _ of (_i; _a)) _1 \Delta  \Delta  \Delta  _n _0 2 jj^00jj\Delta 0. But this follows from the outer induction
hypothesis. 2

Corollary 4.1.21 If \Delta  ` Typerec _ of (_i; _a) :: ^, _ 2 jj\Omega jj\Delta , _i 2 jj^jj\Delta , and _a 2
jj\Omega  ! \Omega  ! ^ ! ^ ! ^jj\Delta , then Typerec _ of (_i; _a) 2 jj^jj\Delta .

Let ffi range over substitutions of constructors for constructor variables.
Definition 4.1.22

1. \Delta 0j ` _ :: ^[ffi] iff ffi(_) 2 jj^jj\Delta 0.
2. \Delta 0j ` ffi :: \Delta  iff Dom(ffi) = Dom(\Delta ) and for each t in Dom(ffi), ffi(t) 2 jj\Delta (t)jj\Delta 0.
3. j ` \Delta  ` _ :: ^ iff for every \Delta 0 and every ffi such that \Delta 0j ` ffi :: \Delta , \Delta 0j ` _ :: ^[ffi].

Theorem 4.1.23 If \Delta  ` _ :: ^, then j ` \Delta  ` _ :: ^.
Proof: By induction on the derivation of \Delta  ` _ :: ^. Suppose \Delta 0j ` ffi :: \Delta .
var: Holds by the assumption \Delta 0j ` ffi.
int: Holds, since ffi(Int) = Int is trivially SN and thus Int 2 jj\Omega jj\Delta 0.

CHAPTER 4. TYPING PROPERTIES OF *MLI 59
arrow: Must show \Delta 0j ` Arrow(_1; _2) :: \Omega [ffi]. By the induction hypothesis, ffi(_1) 2
jj\Omega jj\Delta 0 and ffi(_2) 2 jj\Omega jj\Delta 0. Hence, _1 and _2 are SN and Arrow(_1; _2) is SN . Thus,
Arrow(_1; _2) 2 jj\Omega jj\Delta 0 .
fn: Must show ffi(*t::^1: _) 2 jj^1 ! ^2jj\Delta 0 . Let _1 2 jj^1jj\Delta 00 for some \Delta 00 = \Delta 0 ] ft::^1g.
I must show that f_1=tgffi(_) 2 jj^2jj\Delta 00 . By the induction hypothesis, ffi_ 2 jj^2jj\Delta 00 so
the result follows from lemma 4.1.19
app: Must show ffi(_1 _2) 2 jj^2jj\Delta 0 . By the induction hypotheses, ffi(_1) 2 jj^1 ! ^2jj\Delta 0
and ffi(_2) 2 jj^1jj\Delta 0, so the result follows from the definition of jj^1 ! ^2jj\Delta 0.
trec: Must show ffi(Typerec _ of (_i; _a)) 2 jj^jj\Delta 0. By the induction hypotheses, ffi(_) 2
jj\Omega jj\Delta 0, ffi(_i) 2 jj^jj\Delta 0, and ffi(_a) 2 jj\Omega  ! \Omega  ! ^ ! ^ ! ^jj\Delta 0 , so the result follows from
lemma 4.1.21. 2

Corollary 4.1.24 (Strong Normalization) If \Delta  ` _ :: ^, then _ is strongly normalizing.

Proof: Pick ffi to be the identity substitution for \Delta . That is, ffi = ft=t j t 2 Dom(\Delta )g.
Then it is easy to see that \Delta j ` ffi :: \Delta . Moreover, ffi(_) = _ 2 jj^jj\Delta  and thus _ is SN .

2

Corollary 4.1.25

1. Every constructor _ has a unique normal form, N F (_).

2. If _ is well-formed, there is an algorithm to calculate N F (_).
3. Conversion of well-formed constructors is decidable.

4.1.4 Decidability of Type Checking
In the following definitions, I establish a suitable notion of a normalized derivation for
typing judgments. I then show that a term is well typed iff there is a normal derivation
of the judgment. The proof is constructive, and thus provides an algorithm for type
checking *MLi .

Definition 4.1.26 (Normal Types, Judgments) A type oe is in normal form iff it is
int, T (_) where _ is normal, oe1 ! oe2 where oe1 and oe2 are normal, or 8t::^:oe0 where oe0
is normal. A judgment \Delta ; \Gamma  ` e : oe is normal iff oe is normal.

From the properties of constructors, it is clear that every well-formed type oe, has
a unique normal form N F (oe), and that finding this form is decidable -- we simply
normalize all of the constructor components and replace all occurrences of T (Int) with
int and all occurrences of T (Arrow(_1; _2)) with T (_1) ! T (_2). Furthermore, this
normalization process preserves type equivalence.

CHAPTER 4. TYPING PROPERTIES OF *MLI 60
Lemma 4.1.27 If \Delta  ` oe, then \Delta  ` oe j N F (oe).
Proof (sketch): Follows from confluence and strong normalization of constructors.
2

In the absence of typerec, a normal typing derivation is simply a derivation where
we interleave uses of the non-equiv rules and a single use of the equiv rule to normalize
the resulting type. However, for uses of typerec, we need additional uses of equiv to
"undo" the normalization for the inductive cases.

Definition 4.1.28 (Normal Derivations) A typing derivation D of the normal judgment \Delta ; \Gamma  ` e : N F (oe) is in normal form iff D ends in an application of the equiv
rule,

(equiv)

(R) D1 \Delta  \Delta  \Delta  Dn\Delta ; \Gamma  ` e : oe \Delta  ` oe j N F (oe)

\Delta ; \Gamma  ` e : N F (oe)
and:

1. the rule R is an axiom, or
2. R is neither equiv nor trec, and D1; \Delta  \Delta  \Delta  ; Dn are normal, or
3. R is a use of trec where the sub-derivations D1 and D2 are of the form:

(equiv) D

01 \Delta  ` N F (fInt=tgoe) j fInt=tgoe

\Delta  ` ei : fInt=tgoe
and

(equiv) D

02 \Delta  ` N F (8t

1; t2::\Omega :ft1=tgoe ! ft2=tgoe ! fArrow(t1; t2)=tgoe) j

8t1; t2 :: \Omega :ft1=tgoe ! ft2=tgoe ! fArrow(t1; t2)=tgoe

\Delta  ` ea : t1; t2:ft1=tgoe ! ft2=tgoe ! fArrow(t1; t2)=tgoe

and D01 and D02 are normal.
Theorem 4.1.29 \Delta ; \Gamma  ` e : oe iff there exists a normal derivation of \Delta ; \Gamma  ` e : N F (oe).
Proof: The "if" part is immediate: The normal derivation ends in \Delta ; \Gamma  ` e : N F (oe).
Since a type and its normal form are equivalent, a single additional application of the
equiv rule yields a derivation of \Delta ; \Gamma  ` e : oe.

For the "only if" part, we use the following algorithm to transform the derivation of
\Delta ; \Gamma  ` e : oe into a normal derivation of \Delta ; \Gamma  ` e : N F (oe). The algorithm is given by
induction on the derivation D of \Delta ; \Gamma  ` e : oe.

CHAPTER 4. TYPING PROPERTIES OF *MLI 61

If D is an axiom, then we add an additional equiv rule, using the fact that \Delta  `
N F (oe) j oe. The resulting derivation is in normal form.

If D ends with an application of equiv,

(equiv)

(R) D1 \Delta  \Delta  \Delta  Dn\Delta ; \Gamma  ` e : oe0 \Delta  ` oe0 j oe

\Delta ; \Gamma  ` e : oe
then the normal form of oe0 must also be N F (oe). Hence if D01 and D0n are the normal
derivations of D1 through Dn respectively, the derivation

(equiv)

(R) D

01 \Delta  \Delta  \Delta  D0

n

\Delta ; \Gamma  ` e : oe00 \Delta  ` oe

00 j N F (oe)

\Delta ; \Gamma  ` e : N F (oe)
is normal.

If D ends in

(R) D1 \Delta  \Delta  \Delta  Dn\Delta ; \Gamma  ` e : oe

where R is not equiv, we first transform D1 through Dn to normal derivations D01
through D0n. I must now show that the rule R applies, followed by an application of
equiv, yielding the normal judgment \Delta ; \Gamma  ` e : N F (oe). There are five cases to consider:

case fn: D1 ends in \Delta ; \Gamma  ] fx:oe1g ` e : oe2. The normal derivation D01 allows us to
conclude that \Delta ; \Gamma  ] x:oe1 ` e : N F (oe2) Applying the fn rule, we can conclude that
\Delta ; \Gamma  ` *x:oe1:e : oe1 ! N F (oe2). Since \Delta  ` oe2 j N F (oe2), \Delta  ` oe1 ! N F (oe2) j oe j
N F (oe). Hence, following fn with equiv, we can conclude that \Delta ; \Gamma  ` *x:oe1:e : N F (oe).

case app: D1 ends in \Delta ; \Gamma  ` e1 : oe1 ! oe2 and D2 ends in \Delta ; \Gamma  ` e2 : oe1. The normal
derivation D01 ends in \Delta ; \Gamma  ` e1 : N F (oe1 ! oe2). Now, \Delta  ` N F (oe1 ! oe2) j N F (oe1) !
N F (oe2). Hence, D02 ends in \Delta ; \Gamma  ` e2 : N F (oe1), and applying the app rule, we can
conclude that \Delta ; \Gamma  ` e1 e2 : N F (oe2). Since \Delta  ` N F (oe2) j oe2, and oe2 = oe, we can apply
the equiv rule yielding \Delta ; \Gamma  ` e1 e2 : N F (oe).

case tfn: D1 ends in \Delta  ] ft::^g; \Gamma  ` e1 : oe1. The normal derivation D01 ends in
\Delta  ] ft::^g; \Gamma  ` e1 : N F (oe1) Applying the tfn rule, we can conclude that \Delta ; \Gamma  ` \Lambda t::^:e1 :
8t::^:N F (oe1). Since \Delta  ] ft::^g ` oe1 j N F (oe1), \Delta  ` 8t::^:oe1 j 8t::^:N F (oe1) j
N F (8t::^:oe1). Thus, applying the equiv rule, we can conclude that \Delta ; \Gamma  ` 8t::^:e1 :
N F (oe).

case tapp: D1 ends in \Delta ; \Gamma  ` e1 : 8t::^:oe1, whereas the normal derivation D01 ends
in \Delta ; \Gamma  ` e1 : N F (8t::^:oe1). Now, \Delta  ` N F (8t::^:oe1) j 8t::^:N F (oe1). Applying the
tapp rule, we can conclude that \Delta ; \Gamma  ` e1 [_] : f_=tgN F (oe1). By equivalence of types

CHAPTER 4. TYPING PROPERTIES OF *MLI 62
under substitution of a well-formed constructor, we can conclude that \Delta  ` f_=tgoe1 j
f_=tgN F (oe1). Furthermore, \Delta  ` f_=tgN F (oe1) j N F (f_=tgoe1). Thus, \Delta  ` oe j N F (oe)
and by an application of the equiv rule, we can conclude that \Delta ; \Gamma  ` e1 [_] : N F (oe).

case trec: D1 ends in \Delta ; \Gamma  ` ei : fInt=tgoe1 and D2 ends in \Delta ; \Gamma  ` ea :
8t1; t2::\Omega :ft1=tgoe1 ! ft2=tgoe1 ! fArrow(t1; t2)=tgoe1. By induction, the normal
derivations corresponding to these two derivations are D01 which ends in \Delta ; \Gamma  `
ei : N F (fInt=tgoe1) and D02 which ends in \Delta ; \Gamma  ` ea : N F (8t1; t2::\Omega :ft1=tgoe1 !
ft2=tgoe1 ! fArrow(t1; t2)=tgoe1. Now \Delta  ` N F (fInt=tgoe1) j ft=oe1g and \Delta  `
N F (8t1; t2::\Omega :ft1=tgoe1 ! ft2=tgoe1 ! fArrow(t1; t2)=tgoe1) j 8t1; t2::\Omega :ft1=tgoe1 !
ft2=tgoe1 ! fArrow(t1; t2)=tgoe1. So, applying equiv to D01 and D02, followed by an application of trec, we can conclude that

\Delta ; \Gamma  ` typerec _ of [t:oe1](ei; ea) : f_=tgoe1
Since \Delta  ` f_=tgoe1 j N F (f_=tgoe1), we can apply equiv to this derivation yielding
\Delta ; \Gamma  ` typerec _ of [t:oe1](ei; ea) : N F (oe). 2

Theorem 4.1.30 Given \Delta , \Gamma , and e, where \Gamma  is well-formed with respect to \Delta , there is
an algorithm to determine whether there exists a oe such that \Delta ; \Gamma  ` e : oe.

Proof: By the previous theorem, the judgment \Delta ; \Gamma  ` e : oe is derivable iff there is a
normal derivation D of \Delta ; \Gamma  ` e : N F (oe). I proceed by induction on e to calculate such a
derivation if it exists, and to signal an error otherwise. By an examination of the typing
rules, it is clear that for each case, at most one rule other than equiv applies.

case var: If e is a variable x, then the normal derivation is \Delta ; \Gamma  ` x : \Gamma (x) followed by
\Delta ; \Gamma  ` x : N F (\Gamma (x)). If x does not occur in \Gamma , then e is not well-typed.

case int: If e is an integer i, then the normal derivation is \Delta ; \Gamma  ` x : int, followed by a
reflexive use of equivalence (i.e., int j int).

case fn: If e is a function *x:oe1:e0, then the bound variable can always be chosen via
ff-conversion so that it does not occur in the domain of \Gamma . If the free type variables of
oe1 are in \Delta , then \Gamma  ] fx:oe1g is well-formed with respect to \Delta , else there is no derivation.
By induction, there is an algorithm to calculate a normal derivation of \Delta ; \Gamma  ] fx:oe1g `
e0 : N F (oe2), if one exists. Given this derivation, by an application of the fn rule and a
reflexive use of equiv, we can construct a normal derivation \Delta ; \Gamma  ` *x:oe1:e0 : N F (oe1 !
oe2).

case tfn: If e is \Lambda t::^:e0, then the bound type variable can always be chosen via ffconversion so that it does not occur in the domain of \Delta . Hence, the context \Delta  ] ft::^g; \Gamma 
is well-formed. By induction, there is an algorithm to calculate a normal derivation of
\Delta  ] ft::^g; \Gamma  ` e0 : N F (oe), if it exists. If so, applying tfn followed by a reflexive use of
equiv, we can construct a normal derivation of \Delta ; \Gamma  ` \Lambda t::^:e0 : N F (8t::^:oe).

CHAPTER 4. TYPING PROPERTIES OF *MLI 63
case app: If e is an application e1 e2, then by induction, we can calculate normal derivations of \Delta ; \Gamma  ` e1 : N F (oea) and \Delta ; \Gamma  ` e2 : N F (oeb). If such derivations exist, then either
N F (oea) is of the form oe1 ! oe2 or else not. If not, then no other rule applies, so the term
is ill-formed. If so, then for app to apply, oe1 must be the same as N F (oeb). If this holds,
then applying the app rule, yields N F (oe2). Applying the equiv rule yields a normal
derivation of \Delta ; \Gamma  ` e1 e2 : N F (oe2).

case tapp: If e is e0 [_], then by induction, we can calculate a normal derivation of
\Delta ; \Gamma  ` e0 : N F (8t::^:oe) if it exists and signal an error otherwise. If it exists, applying
tapp yields a derivation of \Delta ; \Gamma  ` e0 [_] : f_=tgoe. Following this derivation with a use of
equiv yields a normal derivation of \Delta ; \Gamma  ` e0 [_] : N F (f_=tgoe).

case trec: If e is typerec _ of [t:oe](ei; ea) then by induction, we can calculate normal
derivations of \Delta ; \Gamma  ` ei : N F (oei) and \Delta ; \Gamma  ` ea : N F (oea) if such derivations exist. Since
type equivalence is decidable, we can also determine if \Delta  ` N F (oei) j fInt=tgoe and
\Delta  ] ft1::\Omega ; t2::\Omega g ` N F (oea) j fArrow(t1; t2)=tgoe. If so, then we can apply the equiv
rule, followed by the trec rule to yield a derivation of \Delta ; \Gamma  ` typerec _ of [t:oe](ei; ea) :
f_=tgoe. Then, with another application of the equiv rule, we can build a normal derivation of \Delta ; \Gamma  ` typerec _ of [t:oe](ei; ea) : N F (f_=tgoe). 2

Corollary 4.1.31 (Type Checking Decidable) There is an algorithm to determine
whether there exists a oe such that ` e : oe.

Proof: The type assignment ; is trivially well-formed with respect to the kind assignment ;. Hence, by the previous theorem, we can calculate whether ;; ; ` e : oe is
derivable or not. 2

4.2 *MLi Type Soundness
In this section I prove that the type system for *MLi is sound. My proof is a syntactic
one in the style of Wright and Felleisen [130]. The basic idea is to show that every wellformed program e of type oe is a value of type oe, or else there exists a unique e0 (modulo
ff-conversion), such that e steps to e0 and e0 has type oe. Consequently, no well-formed
*MLi program ever becomes "stuck". The notion of stuck computations is captured by
the following definition.

Definition 4.2.1 (Stuck Constructors and Expressions) A constructor is stuck if
it is of one of the following forms:

1. u _ (u is not a *-constructor).

CHAPTER 4. TYPING PROPERTIES OF *MLI 64

2. Typerec u of (_int; _arrow) (u is not of the form Int or Arrow(u1; u2)).
An expression is stuck if it is of one of the following forms:

1. v1 v2 (v1 is not a *-expression).
2. v [_] (v is not a \Lambda -expression).
3. typerec U [_] of [t:oe](ui; ua) (_ is stuck).
4. typerec u of [t:oe](ui; ua) (u is not of the form Int or Arrow(u1; u2)).

Lemma 4.2.2 (Unique Decomposition of Constructors) A closed constructor _ is
either a constructor value u, or else _ can be decomposed into a unique U and _0 such
that _ = U [_0] where _0 is either an instruction or is stuck.

Proof: By induction on the structure of constructors. If _ is Int, Arrow(u1; u2), or
*t::^: _0, then _ is a value. Hence, there are only two cases to consider.

case: Suppose _ is _1 _2. There are three sub-cases to consider. First, if _1 and _2 are
values u1 and u2, then the only decomposition of _ is an empty context U = [ ] filled with
u1 u2. If u1 is a *-constructor, then _ is an instruction, else _ is stuck.

Second, if _1 is u1, but _2 is not a value, then by induction, there is a unique U2 and
_02 such that _2 = U2[_02] and _02 is either stuck or else _02 is an instruction. Hence, the
only decomposition of _ is u1 U2[_02].

Third, if _1 is not a value, then by induction, there exists a unique U1 and _01 such
that _1 = U1[_01] and _01 is either an instruction or stuck. Hence, the only decomposition
of e is E1[e01] e2.

case: Suppose _ is Typerec _1 of (_i; _a). If _1 is a value u, then the only decomposition
of _ is an empty context U = [ ] filled with _. If u is either Int or Arrow(u1; u2), the u is
an instruction, else u is stuck.

If _1 is not a value, then by induction, there is a unique U1 and _01 such that _1 =
U1[_01] and _01 is either an instruction or stuck. Hence, the only decomposition of e is
Typerec U1[_01] of (_i; _a). 2

Lemma 4.2.3 (Unique Decomposition of Expressions) A closed expression e is
either a value v, or else e can be decomposed into a unique E and e0 such that e = E[e0]
where e0 is either an instruction or is stuck.

Proof: By induction on the structure of expressions. The argument is similar to the
one for constructors. 2

CHAPTER 4. TYPING PROPERTIES OF *MLI 65
Lemma 4.2.4 (Determinacy) For any closed expression e, there is at most one value
v such that e + v.

Proof: By unique decomposition, if e is not a value, there is at most one E and I
such that e = E[e1] where e1 is an instruction. Since each instruction has at most one
rewriting rule, there is at most one e0 such that e 7\Gamma ! e0. 2

The following lemma allows us to take advantage of some of the properties I proved
about constructor rewriting in the context of constructor evaluation.

Lemma 4.2.5 If _ 7\Gamma ! _0, then _ \Gamma ! _0.
Proof: By the fact that U contexts are a subset of C contexts (see Section 4.1.1),
and the three evaluation rules of constructors correspond precisely to fi, t1, and t2,
respectively. 2

Corollary 4.2.6

1. If ` _ :: ^ and _ 7\Gamma ! _0, then ` _0 :: ^.
2. If ` _ :: ^ and _ 7\Gamma ! _0, then ` _ j _0 :: ^.
3. If \Delta  ] ft::^g ` oe and \Delta  ` _ :: ^, then \Delta  ` f_=tgoe.
4. If \Delta  ] ft::^g ` oe and \Delta  ` _ j _0 :: ^, then \Delta  ` f_=tgoe j f_0=tgoe.
Lemma 4.2.7 (Constructor Substitution) If \Delta  ] ft::^g; \Gamma  ` e : oe, and \Delta  ` _ :: ^,
then \Delta ; f_=tg\Gamma  ` f_=tge : f_=tgoe.

Proof: By induction on the normal derivation of \Delta  ] ft::^g; \Gamma  ` e : N F (oe). In each
case, we back up the derivation one step to the application of the non-equiv rule.

case var: We have \Delta  ] ft::^g; \Gamma  ` x : \Gamma (x). Thus, \Delta ; f_=tg\Gamma  ` x : f_=tg(\Gamma (x)).
case int: We have \Delta  ] ft::^g; \Gamma  ` i : int. Thus, \Delta ; f_=tg\Gamma  ` i : f_=tgint.
case fn: We have \Delta ]ft::^g; \Gamma  ` *x:oe1:e : oe1 ! oe2. By induction, \Delta ; f_=tg(\Gamma ]fx:oe1g) `
f_=tge : f_=tgoe2. Thus, \Delta ; f_=tg\Gamma  ] fx:f_=tgoe1g ` f_=tge : f_=tgoe2. By the fn rule,
\Delta ; f_=tg\Gamma  ` f_=tg(*x:oe1:e) : f_=tg(oe1 ! oe2).

case tfn: We have \Delta ]ft::^g; \Gamma  ` \Lambda t0::^0:e : 8t0::^0:oe. By induction, \Delta ]ft0::^0g; f_=tg\Gamma  `
f_=tge : f_=tgoe, since t0 can always be chosen distinct from t. By the tfn rule,
\Delta ; f_=tg\Gamma  ` f_=tg\Lambda t0::^0:e : f_=tg8t0::^:oe.

case app: We have \Delta  ] ft::^g; \Gamma  ` e1 e2 : oe. By induction, \Delta ; f_=tg\Gamma  ` f_=tge1 :
f_=tg(oe1 ! oe) and \Delta ; f_=tg\Gamma  ` f_=tge2 : f_=tgoe1. By the app rule, \Delta ; f_=tg\Gamma  `
f_=tg(e1 e2) : f_=tgoe.

CHAPTER 4. TYPING PROPERTIES OF *MLI 66
case tapp: We have \Delta  ] ft::^g; \Gamma  ` e1 [_0] : f_0=t0goe. By induction, \Delta ; f_=tg\Gamma  `
f_=tge1 : f_=tg(8t0::^0:oe), where t0 is chosen distinct from t via ff-conversion. By the
tapp rule, \Delta ; f_=tg\Gamma  ` f_=tg(e1 [_0]) : f_0=t0g(f_=tgoe).

case trec: We have

\Delta  ] ft::^g; \Gamma  ` typerec _0 of [t0:oe](ei; ea) : f_0=t0goe:
By induction,

\Delta ; f_=tg\Gamma  ` ei : fInt=t0g(f_=tgoe)

and \Delta ; f_=tg\Gamma  ` e

a : 8t1; t2::\Omega :ft1=t0g(f_=tgoe) !

ft2=t0g(f_=tgoe) ! fArrow(t1; t2)=t0g(f_=tgoe):

By the trec rule, since t0 and t can always be chosen to be distinct via ff-conversion,

\Delta ; f_=tg\Gamma  ` f_=tg(typerec _0 of [t0:oe](ei; ea)) : f(f_=tg_0)=t0g(f_=tgoe):
Thus,

\Delta ; f_=tg\Gamma  ` e : f_=tg(f_0=t0goe):

2

Lemma 4.2.8 (Expression Substitution) If \Delta ; \Gamma ]fx:oe1g ` e : oe, and \Delta ; \Gamma  ` e1 : oe1,
then \Delta ; \Gamma  ` fe1=xge : oe.

Proof: By induction on the normal derivation of \Delta ; \Gamma ]fx:oe1g ` e : N F (oe). We simply
replace all derivations of \Delta ; \Gamma  ` x : oe1 with a copy of the derivation of \Delta ; \Gamma  ` e1 : oe1. The
proof relies upon weakening the context \Delta ; \Gamma  at these points to include the free variables
that are in scope. 2

Lemma 4.2.9 If ` E[e] : oe, then there exists a oe0 such that ` e : oe0, and for all e0 such
that ` e0 : oe0, ` E[e0] : oe.

Proof: By induction on the normal derivation of ` E[e] : oe, In each case, we back up
the derivation one step to the application of the non-equiv rule.

If E is empty, the result holds trivially with oe = oe0. Otherwise, there are three cases
to consider:

case app1: E[e] is of the form E1[e] e2. By the typing rules, the normal derivation ends
in a use of app. Hence, ` E1[e] : oe1 ! oe and ` e2 : oe1. By induction, there exists a oe0
such that ` e : oe0 and for all ` e0 : oe0, ` E1[e0] : oe1 ! oe. Hence, by the app rule, there
are derivations of ` E1[e] e2 : oe and ` E1[e0] e2 : oe.

CHAPTER 4. TYPING PROPERTIES OF *MLI 67
case app2: E[e] is of the form v1 E2[e]. By the typing rules, the normal derivation ends
in a use of app. Hence, ` v1 : oe1 ! oe and ` E2[e] : oe1. By induction, there exists a oe0
such that ` e : oe0 and for all ` e0 : oe0, ` E2[e0] : oe1. Hence, by the app rule, there are
derivations of ` v E2[e] : oe and ` v E2[e0] : oe.

case tapp: E[e] is of the form E1[e] [_]. By the typing rules, the normal derivation ends
in a use of tapp. Hence, ` E1[e] : 8t::^:oe1, where oe is f_=tgoe1. By induction, there
exists a oe0 such that ` e : oe0 and for all ` e0 : oe0, ` E1[e0] : 8t::^:oe1. Hence, by the tapp
rule, there are derivations of ` E1[e] [_] and ` E1[e0] [_]. 2

Lemma 4.2.10 (Type Preservation) If ` e1 : oe and e1 7\Gamma ! e2, then ` e2 : oe.
Proof: By unique decomposition, there is a unique E and I such that e1 = E[I].
Thus, E[I] 7\Gamma ! E[e0] where e2 = E[e0]. By the previous lemma, there exists a oe0 such
that ` I : oe0, and it suffices to show that ` e0 : oe0. There are six basic cases to consider,
depending upon I. In each case, we use the normal derivation of ` I : oe0, backing up to
the last use of a non-equiv rule.

case: I is (*x:oe1:e00) v and thus e0 is fv=xge00. The only way that ` I : oe0 can be
derived is by the app rule. Thus, ` *x:oe1:e00 : oe1 ! oe0 and ` v : oe1. Any normal
derivation of ` *x:oe1:e00 : oe1 ! oe0 must end with a use of abs followed by an equiv.
Hence, ;; fx:oe1g ` e00 : N F (oe0). Therefore, by the Expression Substitution Lemma,
` fv=xge00 : N F (oe0), and since each type is equivalent to its normal form, ` e0 : oe0.

case: I is (\Lambda t::^:e00)[U [J ]] and e0 is (\Lambda t::^:e00)[U [_]], where U [J ] 7\Gamma ! U [_]. Any derivation
of ` I : oe0 must end with the tapp rule. Hence, ` \Lambda t::^:e00 : 8t::^:oe1, ` U [J ] :: ^,
and oe0 = fU [J ]=tgoe1. By Kind Preservation (lemma 4.1.5), ` U [_] :: ^. Thus, by
the tapp rule, ` (\Lambda t::^:e00)[U [_]] : fU [_]=tgoe1. By equivalence of constructors under
reduction, ` U [J ] j U [_]. Therefore, by equivalence of types under substitution of
equivalent constructors, ` fU [J ]=tgoe1 j fU [_]=tgoe1. Thus, by the equiv typing rule,
` (\Lambda t::^:e00)[U [_]] : fU [J ]=tgoe1.

case: I is (\Lambda t::^:e00)[u] and e0 is fu=tge00. The last step in the normal derivation of ` I : oe0
must be a use of tapp. Thus, ` \Lambda t::^:e00 : 8t::^:oe1 and oe0 = fu=tgoe1. Therefore, by the
Constructor Substitution Lemma, ` fu=tge00 : fu=tgN F (oe1). By equivalence of types
under substitution of equivalent constructors, ` fu=tgN F (oe1) j fu=tgoe1 = oe. Thus, by
the equiv typing rule, ` fu=tge00 : oe.

case: I is typerec U [J ] of [t:oe1](ei; ea) and e0 is typerec U [_] of [t:oe1](ei; ea). The last
step in the normal derivation of ` I : oe0 must be a use of trec. Thus, ` U [J ] :: \Omega  and by
kind preservation, ` U [_] :: \Omega . Therefore, by trec, ` typerec U [_] of [t:oe1](ei; ea) : oe

case: I is typerec Int of [t:oe1](ei; ea) and e0 is ei. The last step in the normal derivation
of ` I : oe0 must be a use of trec. Thus, oe0 is equivalent to fInt=tgoe1. By the ei typing
hypothesis, ` ei : fInt=tgoe1. Thus, ` e0 : oe.

CHAPTER 4. TYPING PROPERTIES OF *MLI 68
case: I is typerec Arrow(u1; u2) of [t:oe1](ei; ea) and e0 is

ea[u1][u2](typerec u1 of [t:oe1](ei; ea))(typerec u2 of [t:oe1](ei; ea)):
The last step in the normal derivation of ` I : oe0 must be a use of trec. Thus, oe0 is
equivalent to fArrow(u1; u2)=tgoe1. By the ea typing hypothesis,

` ea : 8t1; t2::\Omega :ft1=tgoe1 ! ft2=tgoe1 ! fArrow(t1; t2)=tgoe1:
Thus,

` ea[u1][u2] : fu1=tgoe1 ! fu2=tgoe1 ! fArrow(u1; u2)=tgoe1:

Therefore, ` e0 : fArrow(u1; u2)=tgoe1, and ` e0 : oe0. 2

Lemma 4.2.11 (Canonical Forms) If ` v : oe then:

ffl If ` oe j int, then v = i for some integer i.
ffl If ` oe j oe1 ! oe2, then v is of the form *x:oe1:e, for some x and e.
ffl If ` oe j 8t::^:oe0, then v is of the form \Lambda t::^:e, for some e.

Proof: If ` v : oe, then there is a normal derivation of ` v : N F (oe). Backing up this
derivation by one rule, it is easy to see by the definition of values that only one rule
applies. 2

Lemma 4.2.12 (Constructor Progress) If ` _1 :: ^, then either _1 is a constructor
value u or else there exists a _2 such that _1 7\Gamma ! _2.

Proof: If _1 is not a value, then there is a unique decomposition into U [_] for some
context U and closed constructor _. I argue that _ must be an instruction. Since
` U [_] :: ^, there exists a ^0 such that ` _ :: ^0.

If _ is of the form _1 _2, then _1 and _2 must be values u1 and u2 respectively. Since
` u1 u2 :: ^0, this must be derived using the app rule. Thus, there exists a ^1 such that
` u1 :: ^1 ! ^0, and this must be derived via the fn rule. Therefore, u1 must have the
form *t::^1:_0 and thus u1 u2 7\Gamma ! fu2=tgu0.

If _ is of the form Typerec _0 of (_i; _a), then _0 must be a value u. Since ` _ ::
^, a derivation of this fact must end in a use of trec. Hence, ` u :: \Omega , and u is
either Int or Arrow(u1; u2). In the former case, _ 7\Gamma ! _i and in the latter case, _ 7\Gamma !
_a[u1][u2](Typerec u1 of (_i; _a))(Typerec u2 of (_i; _a)). 2

CHAPTER 4. TYPING PROPERTIES OF *MLI 69
Lemma 4.2.13 (Expression Progress) If ` e1 : oe, then either e1 is a value or else
there exists an e2 such that e1 7\Gamma ! e2.

Proof: If e1 is not a value, then by Unique Decomposition, there exists an E and e
such that e1 = E[e] and e is either stuck or else e is an instruction. I argue that e must
be an instruction and thus there exists an e0 such that e 7\Gamma ! e0 and thus E[e] 7\Gamma ! e2
where e2 = E[e0]. Since ` E[e] : oe, there exists a oe0 such that ` e : oe0.

case: If e is of the form e1 e2 then both e1 and e2 must be values, v1 and v2. Since
` v1 v2 : oe0, there is a normal derivation of ` v1 v2 : N F (oe0) where the second to the last
step uses the app rule. Hence, there is a oe1 such that ` v1 : oe1 ! oe0 and ` v2 : oe2. A
normal derivation of ` v1 : oe1 ! oe0 must have a second to last step that uses the fn rule.
By Canonical Forms, v1 must be of the form *x:oe1:e00. Therefore, v1 v2 7\Gamma ! fv2=xgv1.

case: If e is of the form e1 [_] then e1 must be a value v1. The second to the last
step of a normal derivation of ` v1 [_] : oe0 must use the tapp rule. Thus, there exists
some ^ such that ` _ :: ^ and ` v1 : 8t::^:oe1 where f_=tgoe1 is equivalent to oe0. Any
normal derivation of ` v1 : 8t::^:oe1 must have a second to last step that uses the tfn
rule. By Canonical Forms, v1 must be of the form \Lambda t::^:e00. If _ is a constructor value u,
then v1 [u] 7\Gamma ! fu=tge00. Otherwise, by constructor progress, there exists a _00 such that
_ 7\Gamma ! _00. Therefore, v1 [_] 7\Gamma ! v1 [U [_00]].

case: If e is of the form typerec _ of [t:oe1](ei; ea), then by constructor progress _ is
either a constructor value u or else there exists a _0 such that _ 7\Gamma ! _0 and thus e 7\Gamma !
typerec _0 of [t:oe1](ei; ea). If _ is a constructor value u, then any normal derivation of
` e : oe0 must end with the second to last step an application of trec. Hence, ` u :: \Omega .
Therefore, u is either Int or Arrow(u1; u2) for some u1 and u2. In the former case, e 7\Gamma ! ei
and in the latter case,

e 7\Gamma ! ea[u1][u2](typerec u1 of [t:oe1](ei; ea))(typerec u2 of [t:oe1](ei; ea)):

2

Corollary 4.2.14 (Stuck Programs Untypeable) If ` e : oe, then e is not stuck.
Proof: If ` e : oe, then by progress, either e is a value or else e 7\Gamma ! e0 for some e0. If
e 7\Gamma ! e0, then by preservation, ` e0 : oe0. 2

Corollary 4.2.15 (Soundness) If ` e : oe then e cannot become stuck.
Proof: I argue by induction on n that if e 7\Gamma !n e0, then e0 is not stuck. For n = 0, the
result holds by the previous corollary. Suppose e 7\Gamma !n e0. By the induction hypothesis,
e0 is not stuck. Hence, e0 is either a value or else e0 7\Gamma ! e00. By Preservation, ` e00 : oe.
Thus, by the previous lemma, e00 is not stuck. 2

Chapter 5
Compiling with Dynamic Type
Dispatch

In this chapter, I show how to compile Mini-ML to a variant of *MLi , called *MLi -Rep.
The primary purpose of the translation is to give a simple, but compelling demonstration
of the power of dynamic type dispatch. A secondary purpose is to demonstrate the
methodology of type-directed compilation and present a proof of translation correctness.

I also address two real implementation issues with the translation: first, I show how to
eliminate structural, polymorphic equality by using a combination of primitive equality
operations and dynamic type dispatch. As a result, the target language does not need
specialized support for dispatching on values. This implies that *MLi -Rep does not need
tags on values to support polymorphic equality.

Second, I flatten 1-argument functions into multiple argument functions when possible. Recall that Mini-ML, like SML, provides only 1-argument functions. We can
simulate multiple arguments by passing a tuple to a function, but it is best to pass multiple arguments directly in registers since access to registers is typically faster than access
to an allocated object. Therefore, if a source function takes a tuple as an argument, I
translate it so that the components of the tuple are passed directly as multiple, unallocated arguments. I use dynamic type dispatch to determine whether to flatten a function
that takes an argument of unknown type.

In practice, flattening function arguments yields a substantial speedup for SML code
and significantly reduces allocation. Much of the improvement claimed by Shao and
Appel for their implementation of Leroy-style representation analysis is due to argument
flattening [110]. In particular, they reduced total execution time by 11% on average and
allocation by 30% on average. I found similar performance advantages with argument
flattening in the context of the TIL compiler (see Chapter 8).

After demonstrating how multi-argument functions and polymorphic equality may
be implemented in *MLi , I sketch how other language constructs, notably C-style structs,

70

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 71

(kinds) ^ ::= \Omega  j ^1 ! ^2
(constructors) _ ::= t j Int j Float j Unit j Prod(_1; _2) j Arrow([_1; \Delta  \Delta  \Delta  ; _k]; _) j

*t::^: _ j _1 _2 j Typerec _ of (_i; _f ; _u; _p; _a)

(types) oe ::= T (_) j int j float j unit j hoe1 \Theta  oe2i j [oe1; \Delta  \Delta  \Delta  ; oek] ! oe2 j 8t::^:oe
(expressions) e ::= x j i j f j hi j he1; e2i j ss1 e j ss2 e j *[x:oe1; \Delta  \Delta  \Delta  ; xk:oek]: e j

e [e1; \Delta  \Delta  \Delta  ; ek] j \Lambda t::^:e j e[_] j
eqint(e1; e2) j eqfloat(e1; e2) j if0 e1 then e2 else e3 j
typerec _ of [t:oe](ei; ef ; eu; ep; ea)

Figure 5.1: Syntax of *MLi -Rep

Haskell-style type classes, and polymorphic communication primitives, can be coded
using dynamic type dispatch. The rest of this chapter proceeds as follows: In Section
5.1, I define the target language, *MLi -Rep. In Section 5.2, I define a type-directed
translation from Mini-ML to *MLi -Rep that eliminates equality and flattens function
arguments. In Section 5.3 I prove the correctness of this translation. Finally, In Section
5.4, I demonstrate how other constructs may be implemented through dynamic type
dispatch.

5.1 The Target Language: *MLi -Rep
The syntactic classes of the target language, *MLi -Rep, are given in Figure 5.1. *MLi -Rep
extends *MLi by adding floats, products, and k-argument functions (for some fixed, but
arbitrary k.) The constructor level reflects these changes by the addition of Float, Unit,
Prod(_1; _2), and Arrow([_1; \Delta  \Delta  \Delta  ; _k]; _) constructors, and by the addition of arms within
Typerec and typerec corresponding to these constructors. In addition, *MLi -Rep provides
primitive equality functions for integer and floating point values (eqint and eqfloat)
as well as an if0 construct. However, *MLi -Rep does not provide a polymorphic equality
operator.

The values, evaluation contexts, and rewriting rules of *MLi -Rep are essentially the
same as for *MLi (see Section 3.3), with the addition of the product operations, the
equality operations, and if0, so I omit these details. The added constructor and term
formation rules for *MLi -Rep are given in Figures 5.2 and 5.3 respectively.

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 72

Technically, all *MLi -Rep functions have k arguments, but I use *[x1:oe1; \Delta  \Delta  \Delta  ; xn:oen]: e
where n ^ k to represent the term:

*[x1:oe1; \Delta  \Delta  \Delta  ; xn:oen; xn+1:unit; \Delta  \Delta  \Delta  ; xk:unit]: e
when xn+1; \Delta  \Delta  \Delta  ; xk do not occur free in e. Similarly, I write e [e1; \Delta  \Delta  \Delta  ; en] where n ^ k
to represent the term e [e1; \Delta  \Delta  \Delta  ; en; hin+1; \Delta  \Delta  \Delta  ; hik]. In the degenerate case where n = 1, I
drop the brackets entirely and simply write *x1:oe1: e and e e1. I use similar abbreviations
for arrow constructors and types.

When convenient, I use ML-style pattern matching to define a constructor involving
Typerec or a term involving typerec. For instance, instead of writing

F = *t::^:Typerec t of

(_i; _f ; _u;

*t1::\Omega :*t2::\Omega :*t01::^:t02::^:_p
*t1::\Omega : \Delta  \Delta  \Delta  :*tk:*t::\Omega :*t01::^: \Delta  \Delta  \Delta  :*t0k::^; t::^:_a)

I write: F[Int] = _

i
F[Float] = _f

F[Unit] = _u
F[Prod(t1; t2)] = fF[t1]=t01; F[t2]=t02g_p
F[Arrow([t1; \Delta  \Delta  \Delta  ; tk]; t)] = fF[t1]=t01; \Delta  \Delta  \Delta  ; F[tk]=t0k; F[t]=t0g_a

As in SML, I use an underscore (" ") to represent a wildcard match.

I also use the derived form Typecase for an application of Typerec where the inductive
cases are unused. Hence, the pattern matching constructor

F[Int] = _i
F[Float] = _f

F[Unit] = _u
F[Prod(t1; t2)] = fF[t1]=t01; F[t2]=t02g_p
F[Arrow([t1; \Delta  \Delta  \Delta  ; tk]; t)] = fF[t1]=t01; \Delta  \Delta  \Delta  ; F[tk]=t0k; F[t]=t0g_a

where t01 and t02 do not occur free in _p and t01; \Delta  \Delta  \Delta  ; t0k; t0 do not occur free in _a may be
written using Typecase as follows:

Typecase _ of

Int =? _i
j Float =? _f
j Unit =? _u
j Prod(t1; t2) =? _p
j Arrow([t1; \Delta  \Delta  \Delta  ; tk]; t2) =? _a

Similarly, I use a derived typecase expression form for instances of typerec where the
inductive cases cases are unused.

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 73

(unit) \Delta  ` Unit :: \Omega  (prod) \Delta  ` _1 :: \Omega  \Delta  ` _2 :: \Omega \Delta  ` Prod(_

1; _2) :: \Omega 

(arrow)

\Delta  ` _1 :: \Omega  \Delta  \Delta  \Delta  \Delta  ` _k :: \Omega 

\Delta  ` _ :: \Omega 

\Delta  ` Arrow([_1; \Delta  \Delta  \Delta  ; _k]; _) :: \Omega 

(trec)

\Delta  ` _ :: \Omega  \Delta  ` _i :: ^
\Delta  ` _f :: ^ \Delta  ` _u :: ^
\Delta  ` _p :: \Omega  ! \Omega  ! ^ ! ^ ! ^
\Delta  ` _arrow :: \Omega 1 ! \Delta  \Delta  \Delta  ! \Omega k ! \Omega  ! ^1 ! \Delta  \Delta  \Delta  ! ^k ! ^ ! ^

\Delta  ` Typerec _ of (_i; _f ; _u; _p; _a) :: ^ (^1; \Delta  \Delta  \Delta  ; ^k = ^)

Figure 5.2: Added Constructor Formation Rules for *MLi -Rep

5.2 Compiling Mini-ML to *MLi -Rep
With the definitions of the source and target languages in place, I can define a translation from Mini-ML to *MLi -Rep. In this section, I carefully develop such a translation,
concentrating first on a translation from Mini-ML types to *MLi -Rep constructors. Next,
I develop a term translation and show that it respects the type translation. Finally, I
prove that the translation is correct by establishing a suitable family of simulation relations and by showing that a well-formed Mini-ML expression is appropriately simulated
by its *MLi -Rep translation.

5.2.1 Translation of Types
I translate Mini-ML monotypes to *MLi -Rep constructors via the function jo/ j, which is
defined by induction on o/ as follows:

jtj = t
jintj = Int
jfloatj = Float

junitj = Unit
jho/1 \Theta  o/2ij = hjo/1j \Theta  jo/2ji

jo/1 ! o/2j = Vararg jo/1j jo/2j

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 74

(prod) \Delta ; \Gamma  ` e1 : oe1 \Gamma ; \Delta  ` e2\Delta ; \Gamma  ` he

1; e2i : hoe1 \Theta  oe2i

(proj) \Delta ; \Gamma  ` e : hoe1 \Theta  oe2i\Delta ; \Gamma  ` ss

i e : oei (n = 1; 2)

(eqi) \Delta ; \Gamma  ` e1 : int \Delta ; \Gamma  ` e2 : int\Delta ; \Gamma  ` eqint(e

1; e2) : int (eqf)

\Delta ; \Gamma  ` e1 : float \Delta ; \Gamma  ` e2 : float

\Delta ; \Gamma  ` eqfloat(e1; e2) : int

(if0) \Delta ; \Gamma  ` e1 : int \Delta ; \Gamma  ` e2 : oe \Delta ; \Gamma  ` e3 : oe\Delta ; \Gamma  ` if0 e

1 then e2 else e3 : oe

(abs) \Delta ; \Gamma  ] fx1:oe1; \Delta  \Delta  \Delta  ; xk:oekg ` e : oe\Delta ; \Gamma  ` *[x

1:oe1; \Delta  \Delta  \Delta  ; xk:oek]: e : [oe1; \Delta  \Delta  \Delta  ; oek] ! oe

(app)

\Delta ; \Gamma  ` e : [oe1; \Delta  \Delta  \Delta  ; oek] ! oe
\Delta ; \Gamma  ` e1 : oe1 \Delta  \Delta  \Delta  \Delta ; \Gamma  ` ek : oek

\Delta ; \Gamma  ` e [e1; \Delta  \Delta  \Delta  ; ek] : oek

(trec)

\Delta  ` _ :: \Omega  \Delta ; \Gamma  ` ei : fInt=tgoe
\Delta ; \Gamma  ` ef : fFloat=tgoe \Delta ; \Gamma  ` eu : fUnit=tgoe
\Delta ; \Gamma  ` ep : 8t1::\Omega :8t2::\Omega :[ft1=tgoe] ! [ft2=tgoe] ! fProd(t1; t2)=tgoe

\Delta ; \Gamma  ` ea : 8t1::\Omega : \Delta  \Delta  \Delta  :8tk::\Omega :8t0::\Omega :

[ft1=tgoe] ! \Delta  \Delta  \Delta  ! [ftk=tgoe] ! [ft0=tgoe] !

fArrow([t1; \Delta  \Delta  \Delta  ; tk]; t0)=tgoe

\Delta ; \Gamma  ` typerec _ of [t:oe](ei; ef ; eu; ep; ea) : f_=tgoe

Figure 5.3: Added Term Formation Rules for *MLi -Rep

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 75
The translation maps each type to its corresponding constructor except for arrow types:
An arrow type whose domain is a tuple is flattened into an arrow constructor with
multiple arguments by the Vararg constructor function. Vararg is defined using Typecase
as follows: Vararg = *t::\Omega :*t0::\Omega :

Typecase t of

Prod(t1; t2) =? Arrow([t1; t2]; t0)
j =? Arrow(t; t0);

and has the property that, if o/ = ho/1 \Theta  o/2i, then

Vararg jo/ j jo/ 0j j Arrow([jo/1j; jo/2j]; jo/ 0j):
Alternatively, if o/ is not a product (and not a variable), then Vararg does not flatten the
domain. For instance,

Vararg Int jo/ 0j j Arrow(Int; jo/ 0j):

In effect, Vararg reifies the type translation for arrow types as a function at the constructor
level.

The type translation is extended to map source type schemes to target types, source
type assignments to target type assignments, and source kind assignments to target kind
assignments as follows:

j8t1; \Delta  \Delta  \Delta  ; tn:o/ j = 8t1::\Omega : \Delta  \Delta  \Delta  :8tn::\Omega :T (jo/ j)

j\Gamma j = fx:j\Gamma (x)j j x 2 Dom(\Gamma )g
j\Delta j = ft::\Omega  j t 2 Dom(\Delta )g
This type translation has the very important property that it commutes with substitution. This is in stark contrast to any of the coercion-based approaches to polymorphism,
where this property does not hold and a term-level coercion must be used to mitigate
the mismatch. In some sense, my type translation is "self-correcting" when I perform
substitution, because the computation of an arrow type, whose domain is unknown, is
delayed until the type is apparent.

Lemma 5.2.1 jfo/ 0=tgo/ j j fjo/ 0j=tgjo/ j.
Proof: By induction on o/ . 2

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 76
5.2.2 Translation of Terms
I specify the translation of Mini-ML expressions as a deductive system using judgments
of the form \Delta ; \Gamma  ` e : oe ) e0 where \Delta ; \Gamma  ` e : oe is a Mini-ML typing judgment and e0 is
the *MLi -Rep translation of e. The axioms and inference rules that allow us to conclude
this judgment are given in Figure 5.4.

Much of the translation is straightforward: The translation of variables, integers, and
floating point values is the identity; the translation of if0 and ss expressions is obtained
by simply translating the component expressions. In the following subsections, I present
the translation of equality, functions, application, type abstractions, and type application
in detail.

5.2.3 Translation of Equality
An equality operation is translated according to the following rule:

\Delta ; \Gamma  ` e1 : o/ ) e01 \Delta ; \Gamma  ` e2 : o/ ) e02

\Delta ; \Gamma  ` eq(e1; e2) : int ) peq[jo/ j][e01; e02]

The translation uses an auxiliary function, peq, that can be coded in the target language
using typerec. Here, I use the pattern-matching syntax to define such a function:

peq[Int] = *[x1:int; x2:int]: eqint(x1; x2)
peq[Float] = *[x1:float; x2:float]: eqfloat(x1; x2)
peq[Unit] = *[x1:unit; x2:unit]: 1
peq[Prod(ta; tb)] = * [x1:T (Prod(ta; tb)); x2:T (Prod(ta; tb))]:

if0 peq[ta][ss1 x1; ss1 x2] then 0 else peq[tb][ss2 x1; ss2 x2]
peq[t] = * [x1:T (t); x2:T (t)]: 0

Operationally, peq takes a constructor as an argument and selects the appropriate comparison function according to that constructor. For a product Prod(ta; tb), the appropriate
function is constructed by using the inductive arguments peq[ta] and peq[tb] to compare
the components of the product.

Expanding the pattern matching abbreviation to a typerec yields:

\Lambda t::\Omega :typerec t of [t:oe](ei; ef ; eu; ep; ea)

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 77

(var) \Delta ; \Gamma  ] fx:oeg ` x : oe ) x (unit) \Delta ; \Gamma  ` hi : unit ) hi

(int) \Delta ; \Gamma  ` i : int ) i (float) \Delta ; \Gamma  ` f : float ) f

(eq) \Delta ; \Gamma  ` e1 : o/ ) e

01 \Delta ; \Gamma  ` e2 : o/ ) e02

\Delta ; \Gamma  ` eq(e1; e2) : int ) peq[jo/ j][e01; e02]

(if0) \Delta ; \Gamma  ` e1 : int ) e

01 \Delta ; \Gamma  ` e2 : o/ ) e02 \Delta ; \Gamma  ` e3 : o/ ) e03

\Delta ; \Gamma  ` if0 e1 then e2 else e3 : o/ ) if0 e01 then e02 else e03

(pair) \Delta ; \Gamma  ` e1 : o/1 ) e

01 \Delta ; \Gamma  ` e2 : o/2 ) e0n

\Delta ; \Gamma  ` he1; e2i : ho/1 \Theta  o/2i ) he01; e02i

(proj) \Delta ; \Gamma  ` e : ho/1 \Theta  o/2i ) e

0

\Delta ; \Gamma  ` ssi e : o/i ) ssi e0 (i = 1; 2)

(abs) \Delta ; \Gamma  ] fx:o/1g ` e : o/2 ) e

0

\Delta ; \Gamma  ` *x:o/1: e : o/1 ! o/2 ) vararg[jo/1j][jo/2j](*x:T (jo/1j): e0)

(app) \Delta ; \Gamma  ` e1 : o/1 ! o/2 ) e

01 \Delta ; \Gamma  ` e2 : o/1 ) e02

\Delta ; \Gamma  ` e1 e2 : o/2 ) (onearg[jo/1j][jo/2j] e01) e02

(def) \Delta ; \Gamma  ` v : oe ) v

0 \Delta ; \Gamma  ] fx:oeg ` e : o/ ) e0

\Delta ; \Gamma  ` def x:oe = v in e : o/ ) let x:joej = v0 in e0

(tapp)

\Delta  ` o/1 \Delta  \Delta  \Delta  \Delta  ` o/n
\Delta ; \Gamma  ` v : 8t1; \Delta  \Delta  \Delta  ; tn:o/ ) v0
\Delta ; \Gamma  ` v[o/1; \Delta  \Delta  \Delta  ; o/n] : fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tngo/ ) v0[jo/1j] \Delta  \Delta  \Delta  [jo/nj]

(tabs) \Delta  ] ft1; \Delta  \Delta  \Delta  ; tng; \Gamma  ` e : o/ ) e

0

\Delta ; \Gamma  ` \Lambda t1; \Delta  \Delta  \Delta  ; tn:e : 8t1; \Delta  \Delta  \Delta  ; tn:o/ ) \Lambda t1::\Omega : \Delta  \Delta  \Delta  :\Lambda tn::\Omega :e0

Figure 5.4: Translation from Mini-ML to *MLi -Rep

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 78
where (eliding some kind and type information)

oe = [T (t); T (t)] ! int
ei = *[x1:int; x2:int]: eqint(x1; x2)
ef = *[x1:float; x2:float]: eqfloat(x1; x2)
eu = *[x1:unit; x2:unit]: 1
ep = \Lambda ta:\Lambda tb:*peqa:*peqb:*[x1:T (Prod(ta; tb)); x2:T (Prod(ta; tb))]:

if0 peqa[ss1 x1; ss1 x2] then 0 else peqb[ss2 x1; ss2 x2]
ea = \Lambda t1: \Delta  \Delta  \Delta  \Lambda tk:\Lambda t0:*peq1: \Delta  \Delta  \Delta  *peq2:*peq0:

*[x1:T (Arrow([t1; \Delta  \Delta  \Delta  ; tk]; t0)); x2:T (Arrow([t1; \Delta  \Delta  \Delta  ; tk]; t0))]:0

From this definition, it is easy to verify that

` peq : 8t::\Omega :[T (t); T (t)] ! int:
The derivation proceeds as follows: By the tabs rule (see Figure 5.4), it suffices to show

ft::\Omega g; ; ` typerec t of [t:oe](ei; ef ; eu; ep; ea) : oe:
This follows if I can derive the preconditions of the trec rule for *MLi -Rep (see Figure 5.3).
For instance, I must show that

ft::\Omega g; ; ` ei : fInt=tgoe;
which follows from the derivation below:

ft::\Omega g; fx1:int; x2:intg ` x1 : int ft::\Omega g; fx1:int; x2:intg ` x2 : int

ft::\Omega g; fx1:int; x2:intg ` eqint(x1; x2) : int
ft::\Omega g; ; ` *[x1:int; x2:int]:eqint(x1; x2) : fInt=tg([T (t); T (t)] ! int)

The other cases follow in a similar manner.

Intuitively, peq implements the first five rewriting rules of the dynamic semantics
of Mini-ML (see Figure 2.3), but it does so by dispatching on its constructor argument
instead of the shape of its value arguments.

5.2.4 Translation of Functions
There are three cases to consider when translating a *-expression:

1. the argument type is known to be a tuple;
2. the argument type is int, float, unit, or an arrow type;

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 79

3. the argument type is a type variable.

In the first case, the argument is a tuple. I need to produce a function that takes
the components of the tuple directly as arguments. I translate the body of the function
under the assumption that the argument was passed as a tuple. Then, I abstract the
arguments appropriately. However, before executing the body of the function, I allocate
a tuple and bind it to the original parameter, x.

\Delta ; \Gamma  ] fx:ho/1 \Theta  o/2ig ` e : o/ 0 ) e0
\Delta ; \Gamma  ` *x:ho/1 \Theta  o/2i: e : ho/1 \Theta  o/2i ! o/ 0 )
*[x1:T (jo/1j); x2:T (jo/2j)]: let x:T (jho/1 \Theta  o/2ij) = hx1; x2i in e0

(x1; x2 62 Dom(\Gamma ))

It is easy for an optimizer to replace projections ssi x within the translated body of the
function with the appropriate argument, xi. When the tuple is used only to simulate
multiple arguments, the variable x will occur only within such projections. Hence, all
occurrences of x will be eliminated by the optimizer, and the binding of the tuple to x
will become "dead" and can be eliminated altogether.

I leave these optimizations out of the translation for two reasons: first, such optimizations make reasoning about the underlying translation more difficult. Second, the
optimizations (projection elimination and dead code elimination) are generally useful and
could be applied after other passes in the compiler. Hence, for the sake of modularity it
is best to leave these transformations as separate passes over the target code.

In the second case, the argument is a non-tuple and a non-variable. No flattening
need occur and the translation is straightforward:

\Delta ; \Gamma  ] fx:o/ g ` e : o/ 0 ) e0
\Gamma  ` *x:o/: e : o/ ! o/ 0 ) *x:T (jo/ j): e0

In the third case, the argument type of the function is a type variable (t). If this
variable is instantiated with a tuple type, then the function should be flattened; otherwise,
the function should not be flattened. I use a term-level typecase to decide which calling
convention to use. To avoid duplicating the function body for each case, I borrow an idea
from the coercion-based approaches: Pick one calling convention, compile the function
using this convention, and for each case, calculate a coercion from the expected to the
actual calling convention. For instance, I might compile the function as if there was one
argument of type t and then use typecase to calculate the proper coercion to multiple
arguments, depending on the instantiation of t. This leads to the following translation:

\Delta ; \Gamma  ] fx:tg ` e : o/2 ) e0
\Delta ; \Gamma  ` *x:t: e : t ! o/2 ) vararg[t][jo/2j](*x:T (t): e0)

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 80
where the term vararg is defined as follows:

vararg = \Lambda t::\Omega :t0::\Omega :

typecase t of

Prod(t1; t2) =?

*[x:[T (Prod(t1; t2))] ! T (t0)]:*[x1:T (t1); x2:T (t2)]:x [hx1; x2i]
j =? *[x:[T (t)] ! T (t0)]:x

Expanding the pattern matching typecase to a formal typerec yields

typerec t of [t:oe](e0[Int]; e0[Float]; e0[Unit]; ep; ea);
where (eliding some kind and type annotations)

oe = [[T (t)] ! T (t0)] ! T (Vararg t t0)
e0 = \Lambda t00::\Omega :*[[x:T (t00)] ! T (t0)]:x
ea = \Lambda t1: \Delta  \Delta  \Delta  :\Lambda tk:\Lambda t00:*[x1]: \Delta  \Delta  \Delta  :*[xk]:*[x00]:*[x:[T (Arrow([t1; \Delta  \Delta  \Delta  ; tk]; t00))] ! T (t0)]:x

ep = \Lambda t1:\Lambda t2:*[x01]:*[x02]:*[x:[T (Prod(t1; t2))] ! T (t0)]:*[x1:T (t1); x2:T (t2)]:x [hx1; x2i]:

Notice that the inductive arguments for ea (x1; \Delta  \Delta  \Delta  ; xk and x00) and ep (x01 and x02) are
unused. It is straightforward to show that the expansion of vararg yields a well-formed
term with type 8t::\Omega :8t0::\Omega :oe.

Lemma 5.2.2 ` vararg : 8t::\Omega :8t0::\Omega :(T (t) ! T (t0)) ! (T (Vararg t t0))

As a direct result, the translation of functions using vararg preserves the type translation.

Lemma 5.2.3 If

j\Delta j; j\Gamma  ] fx:o/1gj ` e0 : jo/2j;

then

j\Delta j; j\Gamma j ` vararg[jo/1j][jo/2j](*x:T (jo/1j): e0) : jo/1 ! o/2j:

In Chapter 8, I show that for most SML code (and I conjecture code in other similar
languages), it is rarely the case that we do not know enough information about the
argument type at compile time that we must use vararg to choose a calling convention
at link- or even run-time. Therefore, most functions will be translated using one of the
first two translation rules.

Furthermore, standard optimizations, such as compile-time fi-reduction for constructor abstractions, can eliminate variable types at compile time and hence eliminate the
need for vararg. Indeed, it is entirely reasonable to translate every function using vararg
and allow an optimizer "fix-up" the inefficiencies. In this fashion, vararg reifies the

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 81
monomorphic term translation of functions in the same way that Vararg reifies the type
translation.

Since the source language does not have first-class polymorphism and the scope of
a polymorphic value is constrained, we could eliminate all polymorphism at compile
time and thus, all occurrences of vararg. However, I argued earlier that eliminating all
polymorphism at compile time is not reasonable since it duplicates code and does not scale
to languages with first-class polymorphism, modules, or separate compilation. I therefore
leave the decision to inline a polymorphic function to an optimizer. If polymorphic
functions tend to be small or the number of uses is relatively small, then a reasonable
strategy is to inline them within their defining compilation unit.

While I borrow the idea of a coercion to mitigate the mismatch in calling conventions,
there are still significant differences between my approach and the approach suggested by
Leroy (see Section 1.2.3). First, Leroy's coercions can always be calculated at compiletime without the need to examine types at run-time. In contrast, vararg may need to
examine constructors at run-time. However, I argued that Leroy's approach does not
scale to languages like *MLi that have first-class polymorphic values, while clearly, my
approach can. Second, Leroy's S and G coercions recursively pull apart any polymorphic
object to coerce its components and make a "deep" copy of a data structure. For instance,
if we have a vector of polymorphic functions, Leroy's coercions will traverse and create a
new vector when the unknown types are instantiated. In contrast, my "shallow" coercion
only affects a closure as it is constructed. In particular, I delay the construction of a
vector of polymorphic functions until the unknown types are apparent, at which point
the appropriate coercion is selected. Hence, no copy is ever generated and there is no
coherency issue when state is involved. Finally, while I use a coercion to mitigate a
mismatch with calling conventions, I do not use coercions to implement all language
features (see for instance Section 5.4). Thus, typerec,Typerec and the ideas of dynamic
type dispatch support coercions, but are a much more general mechanism.

5.2.5 Translation of Applications
As with functions, there are three cases to consider when translating an application: the
argument type is either a tuple, a non-tuple, or a variable.

If the term is e1 e2 and the argument e2 has a tuple type, I need to extract the
components of the tuple and pass them directly to the function. I translate e1 and e2,
binding the resulting expressions to x1 and x2 via let. Then, I project the components
of x2 and pass them to x1.

\Delta ; \Gamma  ` e1 : ho/1 \Theta  o/2i ! o/ ) e01 \Delta ; \Gamma  ` e2 : ho/1 \Theta  o/2i ) e02

\Delta ; \Gamma  ` e1 e2 : o/ )
let x1:T (jho/1 \Theta  o/2i ! o/ j) = e01 in let x2:T (jho/1 \Theta  o/2ij) = e02 in x1 [ss1 x2; ss2 x2]

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 82
Again, an optimizer should eliminate unnecessary projections. In particular, if e01 is a
tuple hea; ebi that is constructed solely to pass multiple arguments, then optimization
will yield the simple expression e01 [ea; eb].

If the argument has a non-tuple, non-variable type, then the translation is straightforward: \Delta ; \Gamma  ` e

1 : o/ 0 ! o/ ) e01

\Delta ; \Gamma  ` e2 : o/ 0 ) e02

\Delta ; \Gamma  ` e1 e2 : o/ ) e01 e02

If the argument type is a type variable (t), then I must decide whether or not to
flatten the argument into multiple arguments using typecase. The following onearg
function calculates a coercion for a function, deciding whether or not to pass the argument
flattened, based on t:

onearg = \Lambda t::\Omega :t0::\Omega :

typecase t of

Prod(t1; t2) =?

*[f :[T (t1); T (t2)] ! T (t0)]:*[x:T (Prod(t1; t2))]:f [ss1 x; ss2 x]
j =? *[f :[T (t)] ! T (t0)]:f

It is easy to verify that onearg translates functions from their Vararg calling convention
so that they take one argument.

Lemma 5.2.4 ` onearg : 8t::\Omega :8t0::\Omega :[T (Vararg t t0)] ! [T (t)] ! T (t0)

Hence, a simple translation of application is as follows:

\Delta ; \Gamma  ` e1 : o/1 ! o/2 ) e01 \Delta ; \Gamma  ` e2 : o/1 ) e02

\Delta ; \Gamma  ` e1 e2 : o/2 ) (onearg[jo/1j][jo/2j] e01) e02

The following lemma shows that this translation of application obeys the type translation.
Lemma 5.2.5 If j\Delta j; j\Gamma j ` e01 : jo/1 ! o/2j and j\Delta j; j\Gamma j ` e02 : jo/1j, then j\Delta j; j\Gamma j `
(onearg[jo/1j][jo/2j] e01) e02 : jo/2j.

Again, an optimizer can inline and eliminate the call to onearg when jo/1j is known
and can then decide whether or not to flatten e02. Furthermore, the following lemma
shows that onearg is a left-inverse of vararg. This gives an optimizer the opportunity
to replace

onearg[_1][_2] (vararg[_1][_2] v)

with simply v even when the argument type of the function v is unknown. Henglein and
J"orgensen suggest a similar approach to eliminate excessive Leroy-style coercions [65].

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 83
Lemma 5.2.6 If ` v : T (_0) ! T (_), ` v0 : T (_0), then

(onearg[_0][_](vararg[_0][_] v)) v0 + v00
iff v v0 + v00.
Proof: By induction on the normal form of _0. 2

5.2.6 Translation of Type Abstraction and Application
When translating a def, I translate the polymorphic value v yielding v0 and bind this
using let. I translate an instantiation v[o/1; \Delta  \Delta  \Delta  ; o/n] by applying the translation of v to the
constructors generated by jo/1j; \Delta  \Delta  \Delta  ; jo/nj. I translate polymorphic variables to themselves
and I translate type-abstractions to constructor abstractions.

This part of the term translation may appear innocuous at first, but it is significant:
Traditional compilers ignore type applications and type abstractions since they do not
use dynamic type dispatch. Hence, they pass no arguments to polymorphic values when
they are instantiated.

In my translation, I turn a type-abstraction into a function that takes constructors
as arguments and pass the appropriate constructor arguments to the abstraction at runtime. In some sense, building the constructor arguments and passing them at runtime is the "overhead" of dynamic type dispatch because I must do this whether or not
the abstraction examines the constructors via typerec. Within a compilation unit, an
optimizer may determine that some constructor arguments are not used by a polymorphic
function and modify local call sites so that they do not build or pass these constructors
at run time. In at least some cases, however, type application will require building and
passing constructors at run time.

5.3 Correctness of the Translation
From the lemmas regarding peq, vararg, and onearg, and the commutivity of type
translation with substitution, it is easy to show by induction on the derivation of \Delta ; \Gamma  `
e : o/ ) e0 that the term translation preserves types modulo the type translation.

Lemma 5.3.1 If \Delta ; \Gamma  ` e : oe ) e0, then j\Delta j; j\Gamma j ` e0 : joej.

To prove the correctness of the translation, I want to assert that a Mini-ML expression
terminates with a value iff its translation terminates with an "equivalent" value. Equivalence of values is easy to define at base types - syntactic equality will do nicely. But

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 84
what should be the definition of equivalence for arrow types? I need a notion of semantic equivalence that captures the idea that functions are equivalent when they compute
equivalent answers, given equivalent arguments.

It seems as though I am stuck: To determine whether a Mini-ML expression and its
translation compute equivalently, I must define what it means for Mini-ML and *MLi -Rep
values to be equivalent. But to define what it means for two values to be equivalent,
in particular what it means for two functions to be equivalent, I need to define what
it means for two expressions to compute equivalently. How can I formulate these two
relations that are defined in terms of one another?

The answer to this dilemma is to simultaneously define these simulation relations,
but index the relations by types. I will start by defining value equivalence and expression
equivalence at closed, base types and then logically extend the notions of equivalence for
higher types in terms of the equivalence relations indexed by the component types. In
the end, I will generate a family of inductively defined relations which will allow us to
argue by induction on the type of an expression that its translation is correct.

I begin by defining an auxiliary relation between closed, Mini-ML monotypes and
closed *MLi -Rep constructors that respects constructor equivalence:

9_0:jo/ j = _0 and ` _0 j _ :: \Omega 

o/ ss _

In Figure 5.5, I give suitable relations between closed Mini-ML and *MLi -Rep terms. The
relations are indexed by closed, Mini-ML type schemes. Two computations are related
if, whenever one evaluates to a value, then the other evaluates to a related value. Two
values are related at base type if they are syntactically equal. Two values are related at
a product type if projecting the corresponding components yields related computations
at the component type. Two values of arrow type are related if, whenever we have
values related at the domain type, applying the functions to the values yields related
computations. In the case of the *MLi -Rep function, we must first coerce the function
to take one argument via the onearg function. Finally, values are related at the type
scheme 8t1; \Delta  \Delta  \Delta  ; tn:o/ , if, whenever applied to closed, related monotypes and constructors,
they yield related computations at the type obtained by substituting the monotypes for
the type variables.

The relations e ,o/ e0, v sso/ v0, and v ssoe v0 are well founded even though their
definitions refer to one another, because either the size of the type index decreases, or
else the number of quantifiers in the type index decreases. This is ensured because
Mini-ML is predicative, (i.e., only monotypes can instantiate type variables).

The monotype/constructor relation is extended to substitutions ffi and ffi0, indexed by
a set of type variables, \Delta , where ffi maps type variables to closed, Mini-ML monotypes

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 85
Expression Relations:

e + v iff e0 + v0 and v sso/ v0

e ,o/ e0

Value Relations:

i ssint i f ssfloat f hi ssunit hi

ss1 v ,o/1 ss1 v0 ss2 v ,o/2 ss2 v0

v ssho/1\Theta o/2i v0

8v1; v01:v1 sso/0 v01 implies v v1 ,o/ (onearg[jo/ 0j][jo/ j] v0) (v01)

v sso/0!o/ v0

8o/1; _1; \Delta  \Delta  \Delta  ; o/n; _n:o/1 ss _1; \Delta  \Delta  \Delta  ; o/n ss _n implies

v[o/1; \Delta  \Delta  \Delta  ; o/n] ,fo/1=t1;\Delta \Delta \Delta ;o/n=tngo/ v0[_1] \Delta  \Delta  \Delta  [_n]

v ss8t1;\Delta \Delta \Delta ;tn:o/ v0

Figure 5.5: Relating Mini-ML to *MLi -Rep

and ffi0 maps type variables to closed, *MLi -Rep constructors as follows:

Dom(ffi) = Dom(ffi0) = Dom(\Delta )

8t 2 \Delta :ffi(t) ss ffi0(t)

ffi ss\Delta  ffi0

The term relation is extended to pairs of substitutions, ffi; fl and ffi0; fl0, indexed by \Delta ; \Gamma ,
where ffi and ffi0 are as above and fl and fl0 are substitutions from term variables to values.
I assume that all free type variables occurring in the range of \Gamma  are in \Delta .

ffi ss\Delta  ffi0 \Delta  ` \Gamma  Dom(fl) = Dom(fl0) = Dom(\Gamma )

8x 2 Dom(\Gamma ):ffi(fl(x)) ss\Gamma (x) fl0(x)

ffi; fl ss\Delta ;\Gamma  ffi0; fl

With these definitions, I can begin to establish the correctness of the term translation.
The first step is to show that peq has the appropriate behavior.

Lemma 5.3.2 If v1 sso/ v01 and v2 sso/ v02, then eq(v1; v2) ,int peq[jo/ j][v01; v02].
Proof: By induction on o/ . 2
Next, I argue that, under appropriate circumstances, abstracting related values with
respect to related expressions yields related functions. This follows almost directly from
the definitions of the relations and the fact that onearg and vararg are left-inverses.

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 86
Lemma 5.3.3 Suppose \Delta ; \Gamma  ] fx:o/ 0g ` e : o/ ) e0, and for all ffi; fl ] fx=vg ss\Delta ;\Gamma ]fx:o/0g
ffi0; fl0 ] fx=v0g, ffi(fl ] fx=vg(e)) ,ffi(o/) ffi0(fl0 ] fx=v0g(e0)). Then for all ffi; fl ss\Delta ;\Gamma  ffi0; fl0,
ffi(fl(*x:o/ 0:e)) ssffi(o/0!o/) ffi0(fl0(vararg[jo/ 0j][jo/ j](*x:T (jo/ 0j):e0)))

Proof: Let ffi; fl ss\Delta ;\Gamma  ffi0; fl0 and let v ssffi(o/0) v0. I must show:
(ffi(fl(*x:o/ 0:e))) v ,ffi(o/) (onearg[ffi0(jo/ 0j)][ffi0(jo/ j)](ffi0(fl0(vararg[jo/ 0j][jo/ j](*x:T (jo/ 0j):e0))))) v0:
This holds iff:

(*x:ffi(o/ 0):ffi(fl(e))) v ,ffi(o/) (onearg[ffi0(jo/ 0j)][ffi0(jo/ j)]

(vararg[ffi0(jo/ 0j)][ffi0(jo/ j)](*x:T (ffi0(jo/ 0j)):ffi0(fl0(e0))))) v0:

Since onearg is a left-inverse of vararg (see lemma 5.2.6), this holds iff:

(*x:ffi(o/ 0):ffi(fl(e))) v ,ffi(o/) (*x:T (ffi0(jo/ 0j)):ffi0(fl0(e0))) v0
which holds iff:

ffi(fl ] fx=vg(e)) ,ffi(o/) ffi0(fl0 ] fx=v0g(e0))

which follows by assumption. 2

Finally, I establish the correctness of the translation by showing that applying related
substitutions to an expression and its translation yields related computations.

Theorem 5.3.4 If \Delta ; \Gamma  ` e : oe ) e0 and ffi; fl ss\Delta ;\Gamma  ffi0; fl0, then ffi(fl(e)) ,ffi(oe) ffi0(fl0(e0)).
Proof: By induction on the derivation of \Delta ; \Gamma  ` e : o/ ) e0. Let ffi; fl ss\Delta ;\Gamma  ffi0; fl0. The
int, float, and unit cases follow trivially. The var case follows from the assumptions
regarding ffi; fl and ffi0; fl0. The equality case follows from lemma 5.3.2. The if0 case
follows since related values at int must be the same integer. The pair case follows from
the inductive assumptions and the proj case follows from the definition of the relations
at product types. The abs case follows from lemma 5.3.3 and the app case follows from
the definition of the relations at arrow types. The tapp case follows from the definition
of the relations at type schemes, and the fact that ffi(o/ ) ss ffi0(jo/ij) by lemma 5.2.1. 2

Corollary 5.3.5 (Translation Correctness) If ` e : oe ) e0, then e ,oe e0.
Proof: Suppose ;; ; ` e : oe ) e0. Taking ffi = ffi0 = ; and fl = fl0 = ;, we have
ffi; fl ss;;; ffi0; fl0. By the previous theorem, then ffi(fl(e)) ,ffi(oe) ffi0(fl0(e0)), thus e ,oe e0.
2

To summarize, I have defined a translation from Mini-ML to *MLi -Rep that eliminates
polymorphic equality and flattens function arguments. The type translation uses Typerec

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 87
to define Vararg, which determines calling conventions for functions. The term translation
uses typerec to define peq, vararg, and onearg. The vararg term converts a function
from taking one argument so that it has the proper calling convention according to Vararg.
Conversely, the onearg term converts a function from its Vararg calling convention to one
argument.

A real source language like SML provides n-tuples (for arbitrary n) instead of only
binary tuples. Extending the flattening translation so that it flattens argument tuples of
less than k components is straightforward - we simply use k + 1 cases in the definitions
of Vararg to determine the proper calling convention:

Vararg = *t::\Omega :*t0::\Omega :

Typecase t of

Prod(t1) =? Arrow(t1; t0)
j Prod(t1; t2) =? Arrow([t1; t2]; t0)
j Prod(t1; t2; t3) =? Arrow([t1; t2; t3]; t0)

\Delta  \Delta  \Delta 
j Prod(t1; \Delta  \Delta  \Delta  ; tk) =? Arrow([t1; \Delta  \Delta  \Delta  ; tk]; t0)
j =? Arrow(t; t0)

Similarly, the definitions of vararg and onearg will require k + 1 cases.

5.4 Compiling Other Constructs
Dynamic type dispatch can be used to support a variety of language mechanisms in
the presence of unknown types. In this section, I show how the dynamic type dispatch
facilities of *MLi can be used to support flattened data structures (such as C-style structs
and arrays), Haskell-style type classes [53], and polymorphic communication primitives.

5.4.1 C-style Structs
Languages like C provide flattened data structures by default. Programmers explicitly
specify when they want to use pointers. This gives programmers control over both sharing
and data layout. For example, a C struct (i.e., record) with nested struct components
such as

struct f

struct fint x; double y;g a;
int b;
struct fdouble f; double g;g c;
g,

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 88
is typically represented in the same way as a flattened struct made out of the primitive
components (ignoring alignment constraints):

struct f

int x;
double y;
int b;
double f;
double g;
g.

In effect, a C compiler performs a type-directed translation that eliminates nested structs.
To perform this flattening, a C compiler relies upon there being no unknown types at
compile time. In this section, I show how to use dynamic type analysis to flatten structs
in the presence of unknown types.

I begin by extending *MLi -Rep to support records with an arbitrary number of primitive components. To this end, I add list kinds (^\Lambda ) with introductory constructors Nil^
and Cons(_1; _2), and an eliminatory constructor Listrec _ of (_n; _c). Similar to Typerec,
the Listrec constructor provides a means for folding a computation across a list of constructors. I then replace Unit and Prod(_1; _2) with a single constructor Struct(_), where
_ is a constructor of kind \Omega \Lambda  (i.e., a list of monotypes). As before, we can generate the
monotypes by induction; but for Structs, we require a dual induction to generate lists of
monotypes. Therefore, I extend the Typerec constructor to provide a means for folding
a computation across the list of \Omega  components of a Struct constructor. The resulting
grammars for kinds and constructors are as follows:

(kinds) ^ ::= \Delta  \Delta  \Delta  j ^\Lambda 

(constructors) _ ::= \Delta  \Delta  \Delta  j Nil^ j Cons(_1; _2) j Struct(_) j

Listrec _ of (_n; _c) j
Typerec _ of (_i; _f ; _s; _a)(_n; _c)

The formation rules for the constructors are straightforward except for Listrec and Typerec. A Listrec is well-formed with kind ^, provided its argument is a list, and it maps
an empty list to a constructor of kind ^1 and a non-empty list to a constructor of kind
^1, given the head and tail of the list as arguments, as well as the result of folding the
Listcase across the tail of the list.

\Delta  ` _ :: ^1\Lambda 
\Delta  ` _n :: ^ \Delta  ` _c :: ^1 ! ^1\Lambda  ! ^ ! ^

\Delta  ` Listrec _ of (_n; _c) :: ^

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 89
The formation rule for Typerec is as before, but we require extra constructors _n and
_c in order to fold the Typerec across the list components of a Struct. In effect, we
simultaneously define a Typerec with a Listrec. Therefore, the formation rule for Typerec
is as follows1: \Delta  ` _ :: \Omega  \Delta  ` _

i :: ^ \Delta  ` _f :: ^

\Delta  ` _a :: \Omega  ! \Omega  ! ^ ! ^ ! ^ \Delta  ` _s :: ^0 ! ^

\Delta  ` _n \Delta  ` _c :: \Omega  ! \Omega \Lambda  ! ^ ! ^0 ! ^0

\Delta  ` Typerec _ of (_i; _a; _s)(_n; _c) :: ^
The _n and _c clauses determine how the Typerec computation is folded across the
components of a Struct, resulting in a constructor of kind ^0. The _s clause simply
converts this ^0 constructor to a constructor of kind ^.

The equivalences that govern Listrec and Typerec are as before: We choose the appropriate clause according to the head of the normal form of the argument, and unroll the
computation on the component constructors. For a Struct, we unroll as follows:

Typerec Struct(_) of (_i; _f ; _a; _s)(_n; _c) j

_s (Listrec _ of (_n; (*ta::\Omega :*tb::\Omega \Lambda :*t0b::^0:

_c ta tb (Typerec ta of (_i; _f ; _a; _s)(_n; _c)) t0b)))

To the types, I add structfoe1; \Delta  \Delta  \Delta  ; oeng for n * 0, as well as the following equivalence
relating Struct constructors and struct types:

\Delta  ` _1 :: \Omega  \Delta  \Delta  \Delta  \Delta  ` _n :: \Omega 
\Delta  ` T (Struct(Cons(_1; \Delta  \Delta  \Delta  Cons(_n; Nil\Omega )))) j structfT (_1); \Delta  \Delta  \Delta  ; T (_n)g

To the terms, I first add listrec so that we may fold a term-level computation across
a list of constructors:

(lrec)

\Delta  ` _ :: ^\Lambda  \Delta ; \Gamma  ` en : fNil^=tgoe
\Delta ; \Gamma  ` ec : 8t1::^:8t2::^\Lambda :ft2=tgoe ! fCons(t1; t2)=tgoe

\Delta ; \Gamma  ` listrec _ of [t::^\Lambda :oe](en; ec) : f_=tgoe

As I did at the constructor-level, I extend typerec so that we simultaneously define how
to fold a term-level computation across types and across lists of type:

(trec)

\Delta  ` _ :: \Omega  \Delta ; \Gamma  ` ei : fInt=tgoe \Delta ; \Gamma  ` ef : fFloat=tgoe
\Delta ; \Gamma  ` ea : 8t1::\Omega :8t2::\Omega :ft1=tgoe ! ft2=tgoe ! fArrow(t1; t2)=tgoe

\Delta ; \Gamma  ` es : 8t1::\Omega \Lambda :ft1=t0goe0 ! fStruct(t1)=tgoe
\Delta ; \Gamma  ` typerec _ of [t::\Omega :oe](ei; ef ; ea; es)[t0::\Omega \Lambda :oe0](en; ec) : f_=tgoe
1To simplify the presentation, I only consider single argument functions at the term level, and hence
Arrow takes one domain constructor instead of k. It is straightforward to extend Arrow to take and
return an arbitrary number of arguments and results by giving it kind \Omega 

\Lambda  ! \Omega \Lambda  ! \Omega .

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 90
I also add two sorts of intro and elim forms for structs. The first sort provides both an
efficient mechanism for constructing structs (structfe1; \Delta  \Delta  \Delta  ; eng) and an efficient mechanism for projecting a component from a struct (#i e). The typing rules for these terms
are standard:

(struct) \Delta ; \Gamma  ` e1 : oe1 \Delta  \Delta  \Delta  \Delta ; \Gamma  ` en : oen\Delta ; \Gamma  ` structfe

1; \Delta  \Delta  \Delta  ; eng : structfoe1; \Delta  \Delta  \Delta  ; oeng (n * 0)

(select) \Delta ; \Gamma  ` e : structfoe1; \Delta  \Delta  \Delta  ; oeng\Delta ; \Gamma  ` #i e : oe

i (1 ^ i ^ n)

However, these terms do not provide a means for constructing or deconstructing a struct
by induction on the list of component types. Consider, for example, extending the
polymorphic equality term of the previous section to compare arbitrary structs:

peq[Int] = *[x1:int; x2:int]: eqint(x1; x2)
peq[Float] = *[x1:float; x2:float]: eqfloat(x1; x2)
peq[Struct(t)] = *[x1:T (Struct(t)); x2:T (Struct(t))]: ???

I need to project the components of the structure and compare them at their respective
types. I cannot use select since both i and n must be determined at compile time, and
the length of the list of constructors t is unknown. I therefore add a second sort of intro
and elim forms that allows us to construct (cons(e1; e2)) and deconstruct structs (head e
and tail e) by induction on the list of components. These terms have the following
formation rules:

(cons) \Delta ; \Gamma  ` e1 : T (_1) \Delta ; \Gamma  ` e2 : T (Struct(_2))\Delta ; \Gamma  ` cons(e

1; e2) : T (Struct(Cons(_1; _2)))

(hd) \Delta ; \Gamma  ` e : T (Struct(Cons(_1; _2)))\Delta ; \Gamma  ` head e : T (_

1)

(tl) \Delta ; \Gamma  ` e : T (Struct(Cons(_1; _2)))\Delta ; \Gamma  ` tail e : T (Struct(_

2))

Operationally, cons takes values v and structfv1; \Delta  \Delta  \Delta  ; vng, and constructs the
new value structfv; v1; \Delta  \Delta  \Delta  ; vng. Correspondingly, head and tail take a value
structfv1; v2; \Delta  \Delta  \Delta  ; vng and return values v1 and structfv2; \Delta  \Delta  \Delta  ; vng, respectively.

It is possible to effectively define the other struct primitives with cons, head, and
tail2. For example, structfe1; e2; \Delta  \Delta  \Delta  ; eng can be defined as

structfe1; e2; \Delta  \Delta  \Delta  ; eng = cons(e1; cons(e2; \Delta  \Delta  \Delta  cons(en; structfg) \Delta  \Delta  \Delta ));
2The encoding is not quite complete, because cons, head, and tail only operate on structs of
monotypes, whereas the other operations can operate on structs of polytypes.

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 91
whereas #i e can be defined as

#1 e = head e
#i e = #(i-1) (tail e)

However, these encodings generate many intermediate structs that are simply discarded.
Some implementation strategies may avoid creating most if not all of these structs. For
instance, in C, the tail operation can be implemented by returning the address of the
second component of a struct. Unfortunately, many memory management strategies
forbid pointers into the middle of objects. TIL implements tail by returning a logical
pointer or cursor instead of an actual pointer (see Chapter 8). The logical pointer is
implemented as a pair, which consists of a pointer to the beginning of the original struct
and an integer offset. Adding the offset to the pointer yields the logical pointer. This
approach is compatible with most memory management strategies and provides an O(1)
tail. Unfortunately, this still makes projecting the ith component an O(i) operation.
Therefore, I use the select operation (#i e) for O(1) access whenever possible, and only
use head and tail when iterating across a struct. Likewise, I use structfe1; \Delta  \Delta  \Delta  ; eng
whenever possible to avoid creating any intermediate structs, and only use cons when
necessary.

With these additions to the target language, I can now define a translation that
maps Mini-ML tuples to flattened structs. Of course, flattening all tuples is not a good
strategy, but the source language can provide two sorts of tuple types -- those that should
be flattened and those that should not -- and hence leave the choice of representation
to the programmer (as in C). Alternatively, a compiler may perform some analysis to
determine a representation that is likely to be beneficial. To demonstrate the key ideas,
I will simply assume that all products are to be flattened.

The type translation is as before (see Section 5.2.1), except for unit and products.
The translation of unit is simply an empty structure. In the translation of a tuple type,
I use two auxiliary constructor functions, Flat and Append:

junitj = Struct(Nil\Omega )
jho/1 \Theta  o/2ij = Struct(Append[Flat[jo/1j]][Flat[jo/2j]])

These two functions are defined using the pattern matching notation for Typecase and
Listrec as follows: Flat takes a monotype and, if it is a Struct, returns the list of components of the Struct. Otherwise, Flat conses the given monotype onto nil to create a
singleton list:

Flat :: \Omega  ! \Omega \Lambda 

Flat = *t::\Omega :Typecase t of Struct(t) =? t

j =? Cons(t; Nil\Omega ))

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 92
Append takes two lists of monotypes and returns their concatenation:

Append :: \Omega \Lambda  ! \Omega \Lambda  ! \Omega \Lambda 

Append[Nil\Omega ][t] = t
Append[Cons(t1; t2)][t] = Cons(t1; Append[t2][t])

Therefore, the type translation of a product results in a struct where the structs resulting
from nested product components have been flattened and appended together.

The term translation is as before except for tuple creation and projection. Unit simply
maps to an empty struct. Binary tuples are translated according to the following rule:

\Delta ; \Gamma  ` e1 : o/1 ) e01 \Delta ; \Gamma  ` e2 : o/1 ) e02
\Delta ; \Gamma  ` he1; e2i : ho/1 \Theta  o/2i ) append[Flatjo/1j][Flatjo/2j](flat[o/1] e1) (flat[o/2] e2)

The translation uses auxiliary term functions flat and append, which are defined using
typecase and listrec as follows: The flat function takes a constructor t and a value
of type T (t). If the value is a structure, it simply returns that value. If the value is not
a structure, then flat places it in a structure.

flat : 8t::\Omega :T (t) ! T (Flat[t])

flat = \Lambda t::\Omega :typecase t of

Struct(t)=?*x:T (Struct(t)):x
j =?*x:T (t):structfxg

The append function takes two structs and concatenates their contents, yielding a flattened struct:

append : 8t1::\Omega \Lambda :8t2::\Omega \Lambda :T (Struct(t1)) ! T (Struct(t2)) ! T (Struct(Append[t1][t2]))

append[Nil\Omega ][t] = *x:structfg:*y:T (Struct(t)):y
append[Cons(t1; t2)][t] = *x:T (Struct(Cons(t1; t2))):*y:T (Struct(t)):

cons(head x; append[t2][t] (tail x) y)

We can easily verify from the types of flat and append that the term translation for
products respects the type translation.

The term translation of first and second tuple projections is given by the following
two inference rules:

\Delta ; \Gamma  ` e : ho/1 \Theta  o/2i ) e0
\Delta ; \Gamma  ` ss1 e : o/1 ) unflat jo/1j(proj1[Flatjo/1j] [Flatjo/2j] e0)

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 93

\Delta ; \Gamma  ` e : ho/1 \Theta  o/2i ) e0
\Delta ; \Gamma  ` ss2 e : o/1 ) unflat jo/2j(proj2[Flatjo/1j] [Flatjo/2j] e0)

These translations use the auxiliary term functions unflat, proj1 and proj2, which are
defined as follows: The unflat function is the inverse of flat. It has type

unflat : 8t::\Omega :T (Flat[t]) ! T (t);
and is defined as:

unflat = \Lambda t::\Omega :typecase t of

Struct(t) =? *x:T (Struct(t)):x
j =? *x:T (Struct(t)):head x

The proj1 function extracts the first components of a struct, corresponding to its first
argument list of constructors. Similar to append, proj1 is defined using the term-level
listrec:

proj1 : 8t1::\Omega \Lambda :8t2::\Omega \Lambda :T (Struct(Append[t1][t2])) ! T (Struct(t1))

proj1[Nil\Omega ][t] = *x:T (Struct(t)):structfg
proj1[Cons(t1; t2)][t] = *x:T (Struct(Append[Cons(t1; t2)][t])):

cons(head x; proj1[t2][t](tail x))

The proj2 function extracts the latter components of a struct, corresponding to its
second argument list of constructors.

proj2 : 8t1::\Omega \Lambda :8t2::\Omega \Lambda :T (Struct(Append[t1][t2])) ! T (Struct(t2))

proj2[Nil\Omega ][t] = *x:T (Struct(t)):x
proj2[Cons(t1; t2)][t] = *x:T (Struct(Append[Cons(t1; t2)][t])):

proj2[t2][t](tail x)

The crucial step in showing that the term translations of projections respect the type
translation, is showing that

Append[Cons(_1; _2)][_] j Cons(_1; Append[_2][_]);
which follows directly from the definition of Append. This allows us to argue that the
inductive cases are well-formed.

One advantage of explicitly flattening structs in the target language is that we can
export a type-safe form of casting to the source level. I call such a case a view. Let
us define two Mini-ML types o/1 and o/2 to be similar, o/1 , o/2, iff they have the same

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 94
representations -- that is, iff jo/1j is definitionally equivalent to jo/2j. If o/1 , o/2 in the
source language, then it is possible to safely view any source o/1 expression as having
type o/2 and vice versa. In particular, given the flattening translation above, any two
source tuple types that are equivalent modulo associativity of the tuple constructor,
have translations that are definitionally equivalent. Thus, if v : o/1 \Theta  (o/2 \Theta  o/3), we can
safely view v as having type (o/1 \Theta  o/2) \Theta  o/3.

Because I represent equivalent source types using equivalent target types, no coercion
needs to take place when viewing a value with a different, but similar type. Hence, this
approach to views, unlike coercion-based approaches, is compatible with mutable types
(i.e., arrays and refs) in the sense that array[o/1] , array[o/2] whenever o/1 , o/2. This means
we may freely intermingle updates with views of complex data structures, capturing some
of the expressiveness of C casts without sacrificing type-safety.

It is possible to define more sophisticated translations that, for instance, insert
padding to ensure that each element of a struct lies on a multiple-of-eight (i.e., quadword) boundary, assuming the struct is allocated on an aligned boundary. For example,
we can modify Append to insert padding (a pointer to an empty struct) between non-Float
components:

Append0[Nil\Omega ][_] = _
Append0[Cons(Float; _2)][_] = Cons(Float; Append0[_2][_])
Append0[Cons(t1; t2)][_] = Cons(t1; Cons(Struct(Nil\Omega ); Append0[_2][_]))

Alternatively, we might split the float and non-float components of a struct to avoid
padding altogether. This yields the following alternative type translation:

jho/1 \Theta  o/2ij = Struct(Append[Split[Flat[jo/1j][Split[Flat[jo/2j]]])
where Split is defined as

Split[t] = Split0[t][Nil\Omega ][Nil\Omega ]

Split0[Nil\Omega ][tf ][t] = Append[Rev[tf ]][Rev[t]]
Split0[Cons(Float; t2)][tf ][t] = Split0[t2][Cons(Float; tf )][t]
Split0[Cons(t1; t2)][tf ][t] = Split0[t2][tf ][Cons(t1; t)]

Rev[t] = Rev0[t][Nil\Omega ]
Rev0[Nil\Omega ][t] = t
Rev0[Cons(t1; t2)][t] = Rev0[t2][Cons(t1; t)]

This translation maps the Mini-ML type

int \Theta  (float \Theta  (int \Theta  (float \Theta  int)))

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 95
to the target type structffloat; float; int; int; intg. Assuming that such values are allocated
on quad-word boundaries, the floating-point components will always be aligned.

There is, of course, a limit to the transformations that can be coded, since definitional
equivalence of constructors must be decidable so that in turn, type-checking remains
decidable. Nevertheless, the range of transformations that *MLi -like languages can support
seems to cover a wide variety of the interesting cases.

5.4.2 Type Classes
The programming language Haskell [68] gives the programmer the ability to define a
class of types with associated operations called methods. The canonical example is the
class of types that admit equality (also known as equality types in SML [90]). The class
of equality types includes primitive types, such as int and float, that have a primitive
notion of equality. Equality types also include data structures, such as tuples, when the
component types are equality types. However, equality types exclude arrow types since
determining whether two functions are extensionally equivalent is generally undecidable.

The peq operation of Section 5.2.3 effectively defines an equality method for equality
types. However, the definition includes a case for arrow types, because the type of peq
is:

8t::\Omega :[T (t); T (t)] ! int

and t ranges over all monotypes, not just the class of equality types. We would like to
restrict peq so that only equality types can be passed to it.

SML accomplishes such a restriction for its polymorphic equality operation by having
two classes of type variables: Normal type variables (e.g., ff) may be instantiated with any
monotype, and equality type variables (e.g., "ff) may only be instantiated with equality
types. The polymorphic equality operation is assigned the SML type:

8 "ff:"ff \Theta  "ff ! bool
Hence, only equality types may instantiate the polymorphic equality primitive. In particular, an SML type checker will reject the following expression:

fn (x:ff ! fi,y:ff ! fi) =? x = y.
Haskell generalizes this sort of restriction by qualifying bound type variables with a
user-defined predicate or predicates (e.g., is eqty(ff))3. Another approach, suggested
by Duggan [38], is to refine the kind of the bound type variable, much as Freeman and
Pfenning suggest refinements of SML datatypes [44].

3See Jones [72, 71] for a general formulation of qualified types.

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 96

However, it is possible to encode type classes to a limited degree using Typerec. In this
section, I demonstrate the encoding by sketching how the equality types of SML can be
simulated in *MLi . The basic idea is to represent the type class as a constructor function
that maps equality types to themselves, and non-equality types to the distinguished
constructor Void. This Void constructor corresponds to the void type, which is empty.
That is, there are no closed values of type void.

As an example, the class of equality types is encoded by the following constructor
function Eq, which is defined in terms of an auxiliary function, Eq':

Eq :: \Omega  ! \Omega 

Eq[t] = (Eq0[t])[t]
Eq0 :: \Omega  ! (\Omega  ! \Omega )

Eq0[Int] = *t::\Omega :t
Eq0[Float] = *t::\Omega :t
Eq0[Unit] = *t::\Omega :t
Eq0[Prod(t1; t2)] = *t::\Omega :Eq0[t2](Eq0[t1] t)
Eq0[Arrow(t1; \Delta  \Delta  \Delta  ; tk; t0)] = *t::\Omega :Void
Eq0[Void] = *t::\Omega :Void

The Eq' function returns the identity function on \Omega  if its argument is an equality type.
Otherwise, Eq' returns the function that maps every monotype to Void. Therefore,
(Eq[_])[_] returns _ whenever _ is an equality type, and Void otherwise. In essence,
Eq' serves as an "if-then-else" construct that checks to see if _ is an equality type, and
if so returns _.

Now we can write the polymorphic equality function as follows:

peq[Int] = *[x1:int; x2:int]: eqint(x1; x2)
peq[Float] = *[x1:float; x2:float]: eqfloat(x1; x2)
peq[Unit] = *[x1:unit; x2:unit]: 1
peq[Prod(ta; tb)] = * [x1:T (Prod(ta; tb)); x2:T (Prod(ta; tb))]:

if0 peq[ta][ss1 x1; ss1 x2] then 0 else

peq[tb][ss2 x1; ss2 x2]
peq[Arrow(t1; \Delta  \Delta  \Delta  ; tk; t)] = * [x1:void; x2:void]:0

and the term can be assigned the following type:

8t::\Omega :[T (Eq[t]); T (Eq[t])] ! int

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 97
Consequently, peq[_][e1; e2] is well-formed only if e1 and e2 have type T (_) and _ is an
equality type. In particular, the expression

peq[Arrow([Int]; Int)][*x:int:x; *x:int]
is ill-typed because peq applied to an Arrow constructor has type [void; void] ! Int and
thus cannot be applied to the two functions of type int ! int. The encoding is not entirely
satisfactory because peq can be applied to an Arrow constructor. However, the resulting
expression can only be applied to arguments of type void. Since there are no closed values
of type void, the resulting expression can never be invoked. Thus, an optimizer can safely
replace the Arrow-clause of peq with some polymorphic constant (e.g., error).

This encoding suggests the following type translation for SML: Wrap each occurrence
of an equality type variable with the Eq constructor function.

jtj = t
j"tj = Eq["t]

\Delta  \Delta  \Delta 
j8t1; \Delta  \Delta  \Delta  ; tn; "t1; \Delta  \Delta  \Delta  ; "tm:o/ j = 8t1; \Delta  \Delta  \Delta  ; tn; "t1; \Delta  \Delta  \Delta  ; "tm:T (jo/ j)

However, when instantiating a polymorphic function we must use an auxiliary translation
that does not wrap the equality variables with Eq:

jjtjj = t
jj"tjj = "t

\Delta  \Delta  \Delta 

This auxiliary translation is needed because the translation above does not commute with
substitution of equality types for equality type variables (i.e., an extra "Eq" gets wrapped
around each equality type variable). Hence, the translation of polymorphic instantiation
becomes:

(tapp)

\Delta  ` o/1 \Delta  \Delta  \Delta  \Delta  ` o/n \Delta  ` "o/1 \Delta  \Delta  \Delta  \Delta  ` "o/m

\Delta ; \Gamma  ` v : 8t1; \Delta  \Delta  \Delta  ; tn; "t1; \Delta  \Delta  \Delta  ; "tm:o/

\Delta ; \Gamma  ` v[o/1; \Delta  \Delta  \Delta  ; o/n; "o/1; \Delta  \Delta  \Delta  ; "o/m] : fo/1=t1; \Delta  \Delta  \Delta  ; o/n=tn; "o/1="t1; \Delta  \Delta  \Delta  ; "o/m="tmg )v : [jjo/

1jj; \Delta  \Delta  \Delta  ; jjo/njj; jj"o/1jj; \Delta  \Delta  \Delta  ; jj"o/mjj]

It is easy to verify that the type translation commutes with type substitution,

fjjo/ jj="tgjo/ 0j j jfo/ 0="tgo/ 0j;
and thus the resulting term has the appropriate type.

In this fashion, Typerec can be used to encode equality types and other type classes,
whereas typerec can be used to implement the methods (i.e., peq) of the class. The
information encoded in the type class can be used by a compiler to eliminate unneeded
cases within methods.

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 98
5.4.3 Communication Primitives
Ohori and Kato give an extension of ML with primitives for communication in a distributed, heterogeneous environment [100]. Their extension has two essential features:
one is a mechanism for generating globally unique names ("handles" or "capabilities")
that are used as proxies for functions provided by servers. The other is a method for representing arbitrary values in a form suitable for transmission through a network. Integers
are considered transmissible, as are pairs of transmissible values, but functions cannot be
transmitted (due to the heterogeneous environment) and are thus represented by proxy.
These proxies are associated with their functions by a name server that may be contacted
through a primitive addressing scheme. In this section I sketch how a variant of Ohori
and Kato's representation scheme can be implemented using dynamic type dispatch.

To accommodate Ohori and Kato's primitives, I extend *MLi -Rep with a primitive
constructor Proxy of kind \Omega  ! \Omega  and a corresponding type constructor proxy(oe), linked
by the equation T (Proxy(_)) j proxy(T (_)). The Typerec and typerec primitives are
extended in the obvious way to account for constructors of the form Proxy(_).

Next, I add primitives proxy and rpc with the following types:

proxy : 8t1; t2::\Omega :(T (Tran[t1]) ! T (Tran[t2])) ! T (Tran[Arrow(t1; t2)])

rpc : 8t1; t2::\Omega :(T (Tran[Arrow(t1; t2)])) ! T (Tran[t1]) ! T (Tran[t2])
where Tran is a constructor coded using Typerec as follows:

Tran :: \Omega  ! \Omega 

Tran[Int] = Int
Tran[Float] = Float
Tran[Unit] = Unit
Tran[Prod(t1; t2)] = Prod(Tran[t1]; Tran[t2])
Tran[Arrow(t1; t2)] = Proxy(Arrow(t1; t2))
Tran[Proxy(t)] = Proxy(t)

The constructor Tran[_] maps _ to a constructor where each arrow is wrapped by a Proxy
constructor. Thus, values of type T (Tran[_]) do not contain functions and are therefore
transmissible.

The proxy primitive takes a function between transmissible values, generates a new,
globally unique proxy and tells the name server to associate that proxy with the function.
For example, the proxy might consist of the machine's name paired with the address of
the function. Conversely, the rpc operation takes a proxy of a function and a transmissible argument value. Then, the operation contacts the name sever to find the function
corresponding to the proxy. When the function is found, the argument value is sent to

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 99
the appropriate machine. Then, the function associated with the proxy is applied to
the argument, and the result of the function is transmitted back as the result of the
operation. Thus, proxy maps a function on transmissible representations to a transmissible representation of the function, whereas rpc maps a transmissible representation of
a function to a function on transmissible representations.

The goal of Ohori and Kato's compilation was to provide transparent communication.
That is, given any function f of type T (_) ! T (_0), their goal was to be able to transmit
a representation of f to a remote site. We cannot obtain a proxy for f directly, because
proxies require functions that take and return transmissible representations. Therefore,
the key to transparent communication is a function marshal that coerces f to take and
return transmissible values. In general, we want marshal to take any value and convert
it to a transmissible representation.

I can write marshal using typerec. The definition requires a dual function,
unmarshal, to accommodate function arguments4.

marshal : 8t::\Omega :T (t) ! T (Tran[t])

marshal[Int] = *x:int:x
marshal[Float] = *x:float:x
marshal[Unit] = *x:unit:x
marshal[Prod(t1; t2)] = *x:T (Prod(t1; t2)):

hmarshal[t1](ss1 x); marshal[t2](ss2 x)i
marshal[Arrow(t1; t2)] = *f :T (Arrow(t1; t2)):

proxy[t1][t2]

(*x:T (Tran[t1]):marshal[t2](f (unmarshal[t1] x)))
marshal[Proxy(t)] = *x:T (Proxy(t)):x

unmarshal : 8t::\Omega :T (Tran[t]) ! T (t)

unmarshal[Int] = *x:int:x
unmarshal[Float] = *x:float:x
unmarshal[Unit] = *x:unit:x
unmarshal[Prod(t1; t2)] = *x:T (Tran[Prod(t1; t2)]):

hunmarshal[t1](ss1 x); unmarshal[t2](ss2 x)i
unmarshal[Arrow(t1; t2)] = *f :T (Proxy(Arrow(Tran[t1]; Tran[t2]))):*x:T (t1):

unmarshal[t2](rpc[t1][t2] f (marshal[t1] x))
unmarshal[Proxy(t)] = *x:T (Proxy(t)):x

4Technically, I must calculate marshal and unmarshal with one typerec and return a tuple containing
the two functions.

CHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 100
At arrow types, marshal converts the given function to one that takes and returns transmissible types, and then allocates a new proxy for the resulting function. Conversely,
unmarshal takes a proxy and a marshaled argument, performs an rpc on the proxy, and
then unmarshals the result.

With marshal and unmarshal, I can dynamically convert a value to and from its
transmissible representation. In effect, these terms reify the stub compilers of traditional
RPC systems (e.g., the Mach Interface Generator for Mach RPC [70, 123]). Similarly,
we can code general-purpose print and read routines within *MLi , in order to achieve
the easy input/output of languages like Lisp and Scheme.

5.5 Related Work
Peyton Jones and Launchbury suggested an approach to unboxed integers and reals
in the context of a lazy language [75]. However, they restricted unboxed types from
instantiating type variables. A similar idea was recently proposed by Ohori [101] to
compile polymorphic languages such as SML.

Leroy suggested the coercion based approach to allow unrestricted instantiation of
type variables [81], and later, Poulsen extended his work to accommodate unboxed
datatypes that do not "escape" [102]. Henglein and Jo/rgensen examined techniques for
eliminating coercions at compile-time. Shao and Appel [110, 108] took the ideas of Leroy
and extended them to the full Standard ML language. Thiemann extended the work
of Leroy to keep some values unboxed even within polymorphic functions [118]. None
of these approaches supports unboxed mutable data, or generally unboxed datatypes.
Furthermore, they do not address type classes, marshaling, or garbage collection.

Of a broadly similar nature is the work on "soft" type systems [64, 7, 29, 132].
Here, ML-style type inference or set constraints are used to eliminate type-tag checks in
dynamically typed languages such as Scheme.

Morrison, et al. [97] described an implementation of Napier that passed types at
run time to determine the behavior of polymorphic operations. However, the actual
transformations performed were not described and there was little or no analysis of the
typing properties or performance of the resulting code. The work of Ohori on compiling
record operations [99] is similarly based on a type-passing interpretation and provided
much of the inspiration of this work. Type passing was also used by Aditya and Caro in an
implementation of Id, so that instantiations of polymorphic types could be reconstructed
for debugging purposes [5].

Jones [72, 71] has proposed a general framework for passing data derived from types
to "qualified" polymorphic operations, called evidence passing. He shows how evidence
passing can be used to implement Haskell-style type classes, generalizing the earlier work
of Wadler and Blott [122]. He also shows how Ohori-style record calculi can be impleCHAPTER 5. COMPILING WITH DYNAMIC TYPE DISPATCH 101
mented with evidence passing. Jones's approach subsumes type passing in that functions
or types or any evidence derived from qualified types could, in principle, be passed to
polymorphic operations. However, qualified types represent predicates on types, whereas
the type system of *MLi supports computations that transform types. For example, it is
not possible to express the transmissible representation or a flattened representation of
a type in Jones's framework.

Recently, Duggan and Ophel [38] and Thatte [116] have independently suggested
semantics for type classes that are similar in spirit to my proposal. In one sense, these
proposals do a better job of enforcing type classes, since they restrict the kinds of type
variables. However, like Jones's qualified types, neither of these approaches can express
transformations on types.

Dubois, Rouaix, and Weis formulated an approach to polymorphism dubbed "extensional polymorphism" [37]5. The goal was to provide a framework to type check ad
hoc operators like polymorphic equality. As with *MLi , their formulation requires that
some types be passed at runtime and be examined using what amounts to a structural
induction elimination form. Their approach is fairly general since it is not restricted to
primitive recursion over monotypes. However, type checking for the language is in general undecidable and type errors can occur at run time. Furthermore, like the approaches
to type classes, there is no facility for transforming types.

Marshalling in languages with abstract or polymorphic types has been the subject
of much research [85, 86, 84, 66, 27, 4, 100, 77]. The solution I propose does not easily
extend to user-defined abstract types (as with Herlihy and Liskov [66]). However, none
of these previous approaches are able to express the relationship between a value's type
and its transmissible representation, whereas I am able to express this relationship as a
constructor function (i.e., Tran).

5Originally, Harper and I termed the type analysis of *ML

i "intensional polymorphism".

Chapter 6
Typed Closure Conversion
In the previous chapters, I argued that types and dynamic type dispatch are important
for compiling programming languages like Mini-ML. I showed that types can be used to
direct compilation in choosing primitive operations, data structure layout, and calling
conventions, and that types can direct a proof that a compiler is correct.

If we are to use types at run time for dynamic type dispatch, we must propagate
type information all the way through the lowest levels of a compiler. This is one reason
why type-preserving transformations, such as the translation from Mini-ML to *MLi -Rep
of Chapter 5, are so important.

In this chapter, I present a particularly important stage of compilation for functional
programming languages known as closure conversion. To my knowledge, no one (besides
Yasuhiko Minamide, Robert Harper and myself [92, 91]) has presented a type-preserving
closure conversion phase, especially for type-passing polymorphic languages. Therefore,
it is important to show that such a translation exists if I am to claim that my type-based
implementation approach is viable. In this chapter, I show how to closure convert *MLi Rep using abstract closures. Minamide, Harper, and Morrisett provide further details on
environment representations and how to represent closures [92, 91].

I begin by giving an overview of closure conversion and why it is an important part
of functional language implementation. I then define a target language called *MLi -Close,
which is a variant of *MLi -Rep that provides explicit facilities for constructing closures and
their environments. Next, I give a type-directed and type-preserving closure transform
from *MLi -Rep to *MLi -Close and prove that it is correct using the same methodology I
used to compile Mini-ML to *MLi -Rep.

102

CHAPTER 6. TYPED CLOSURE CONVERSION 103
6.1 An Overview of Closure Conversion
Standard operational models of programming languages based on the *-calculus, such
as the contextual semantics of Mini-ML and *MLi -Rep, compute by substituting terms
for variables in other terms. Substitution is expensive because it requires traversing and
copying a term in order to find and replace all occurrences of the given variable. A wellknown technique for mitigating these costs is to delay substitution until the binding of
the variable is required during evaluation [80, 2, 1]. This is accomplished by pairing an
open term with an environment that provides values for the free variables in the term.
The open term may be thought of as immutable code that acts on the environment.
Since the code is immutable, it can be generated once and shared among all instances of
a function.

Closure conversion [105, 111, 33, 78, 76, 9, 124, 54] is a program transformation that
achieves such a separation between code and data. Functions with free variables are replaced by code abstracting an extra environment parameter. Free variables in the body
of the function are replaced by references to the environment. The abstracted code is
"partially applied" to an explicitly constructed environment providing the bindings for
these variables. This "partial application" of the code to its environment is, in fact, suspended until the function is actually applied to its argument; the suspended application
is called a "closure", a data structure containing pure code and a representation of its
environment.

The main ideas of closure conversion are illustrated by considering the following
monomorphic ML program:

let val x = 1

val y = 2
val z = 3
val f = *w. x + y + w
in

f 100
end

The function f contains free variables x and y, but not z. We may eliminate the references
to these variables from the body of f by abstracting an environment env, and by replacing
x and y by references to the environment. In compensation, a suitable environment
containing the bindings for x and y must be passed to f before it is applied. This leads
to the following translation:

CHAPTER 6. TYPED CLOSURE CONVERSION 104

let val x = 1

val y = 2
val z = 3
val f = (*env. *w. (ss1 env) + (ss2 env) + w) hx,yi
in f 100
end

References to x and y in the body of f are replaced by projections (field selections) ss1
and ss2 that access the corresponding component of the environment. Since the code for f
is closed, it may be hoisted out of the enclosing definition and defined at the top-level. I
ignore this "hoisting" phase and instead concentrate on the process of closure conversion.

In the preceding example, the environment contains bindings only for x and y, and is
thus as small as possible. Since the body of f could contain an occurrence of z, it is also
sensible to include z in the environment, resulting in the following code:

let val x = 1

val y = 2
val z = 3
val f = (*env. *w. (ss1 env) + (ss2 env) + w) hx,y,zi
in

f 100
end

In the above example I chose a "flat" (FAM-like [26]) representation of the environment as a record with one field for each variable. Alternatively, I could choose a
"linked" (CAM-like [33]) representation where, for example, each binding is a separate
"frame" attached to the front of the remaining bindings. This idea leads to the following
translation:

let val x = 1

val y = 2
val z = 3
val f = (*env. *w. (ss1(ss2(ss2 env))) + (ss1(ss2 env)) + w)

hz,hy,hx,hiii
in

f 100
end

The linked representation facilitates sharing of environments, but at the expense of introducing link traversals proportional to the nesting depth of the variable in the environment.
The linked representation can also support constant-time closure creation, but this requires reusing the current environment and can result in bindings in the environment for

CHAPTER 6. TYPED CLOSURE CONVERSION 105
variables that do not occur free in the function (such as z above), leading to space leaks
[109].

Closure conversion for a language like *MLi where constructors are passed at run time
is complicated by the fact that we must account for free type variables as well as free value
variables within code. Furthermore, both value abstractions (*-terms) and constructor
abstractions (\Lambda -terms) induce the creation of closures.

As an example, consider the expression:

*x:t1. (x:t1, y:t2, z:int)
of type t1 ! (t1 \Theta  t2 \Theta  int) where t1 and t2 are free type variables and y and z are free
value variables of type t2 and int respectively. After closure conversion, this expression
is translated to the partial application

let val code =

\Lambda tenv :: \Omega  \Theta  \Omega .

*venv : T (ss1 tenv)\Theta int.

*x : T (ss1 tenv).(x, ss1 venv, ss2 venv)
in

code (t1,t2) hy,zi
end

The code abstracts type environment (tenv) and value environment (venv) arguments.
The actual type environment, (t1,t2), is a constructor tuple with kind \Omega  \Theta  \Omega . The
actual value environment, hy,zi, is a tuple with type T (t2)\Theta int. However, to keep the
code closed so that it may be hoisted and shared, all references to free type variables in
the type of venv must come from tenv. Thus, we give venv the type T (ss1 tenv)\Theta int.
Similarly, the code's argument x is given the type T (ss1 tenv). Consequently, the code
part of the closure is a closed expression of closed type oe, where

oe = 8tenv::\Omega  \Theta  \Omega .

T (ss1 tenv)\Theta int!T (ss1 tenv)!(T (ss1 tenv)\Theta T (ss2 tenv)\Theta int)

It is easy to check that the entire expression has type t1 ! (t1 \Theta  t2 \Theta  int), and thus the
type of the original function is preserved.

6.2 The Target Language: *MLi -Close
The target language of the closure conversion translation is called *MLi -Close. The syntax
of this language is given in Figure 6.1. The constructors of the language are similar to
those of *MLi -Rep, except that I have added unit, products, and projections for building

CHAPTER 6. TYPED CLOSURE CONVERSION 106
constructor environments. To the types, I have added a code type, code(t::^; oe1; oe2),
corresponding to both value-abstraction code (vcode) and type-abstraction code (tcode),
where t is the abstracted type environment and oe1 is the abstracted value environment.
If oe2 is an arrow-type, then the code type describes code for a value abstraction, and if
oe2 is a 8-type, then the code type describes code for a type abstraction.

The best way to understand these new constructs is to relate them informally to
standard *MLi -Rep constructs as follows:

code(t::^; oe; oe0) ss 8t::^:oe ! oe0

vcode[t::^; x:oe; x1:oe1; \Delta  \Delta  \Delta  ; xk:oek]:e ss \Lambda t::^:*x:oe:*[x1:oe1; \Delta  \Delta  \Delta  ; xk:oek]:e

tcode[t::^; x:oe; t0::^0]:e ss \Lambda t::^:*x:oe:\Lambda t0::^0:e

hhe1; _; e2ii ss (e1 [_]) e2

Code terms abstract a type environment and a value environment. In the case of value
code, I also abstract a set of k value arguments; for type code, I abstract an additional
type argument. I have added a special closure form to terms, hhe1; _; e2ii, where e1 is the
code of the closure, _ is the type environment, and e2 is the value environment. Closure
terms represent the delayed partial application of code to its environments.

Technically, I need to provide code and closure forms at the constructor level as
well as the term level. However, doing so requires redefining an appropriate notion of
constructor equivalence and reduction in the presence of constructor code and closures.
This in turn requires reproving properties, such as strong-normalization and confluence
for reduction of constructors. To avoid this complexity and to simplify the presentation,
I will use standard *-abstractions and partial applications to represent code and closures
at the constructor level.

The constructor formation and equivalence rules are essentially the same as in *MLREP (See Figure 5.2) except for the addition of rules pertaining to constructor-level
products. I add formation rules for products as follows:

\Delta  ` () :: 1 \Delta  ` _1 :: ^1 \Delta  ` _2 :: ^2\Delta  ` h_

1; _2i :: ^1 \Theta  ^2

\Delta  ` _ :: ^1 \Theta  ^2

\Delta  ` ssi _ :: ^i

I add both fi and j-like rules governing equivalences of products as follows:

\Delta  ` _ :: 1
\Delta  ` _ j ()

\Delta  ` _1 :: ^1 \Delta  ` _2 :: ^2

\Delta  ` ssi h_1; _2i j _i :: ^i

\Delta  ` _ :: ^1 \Theta  ^2
\Delta  ` hss1 _; ss2 _i j _ :: ^1 \Theta  ^2

CHAPTER 6. TYPED CLOSURE CONVERSION 107

(kinds) ^ ::= \Omega  j 1 j ^1 \Theta  ^2 j ^1 ! ^2
(constructors) _ ::= t j Int j Float j Unit j Prod(_1; _2) j Arrow([_1; \Delta  \Delta  \Delta  ; _k]; _) j

() j (_1; _n) j ss1 _ j ss2 _ j *t::^: _ j _1 _2 j
Typerec _ of (_i; _f ; _u; _p; _a)

(types) oe ::= T (_) j int j float j unit j hoe1 \Theta  oe2i j [oe1; \Delta  \Delta  \Delta  ; oek] ! oe j

8t::^:oe j code(t::^; oe1; oe2)

(expressions) e ::= x j i j f j hi j he1; e2i j ss1 e j ss2 e j

vcode[t::^; x:oe; x1:oe1; \Delta  \Delta  \Delta  ; xk:oek]:e j tcode[t1::^; x:oe; t2::^2]:e j
hhe1; _; e2ii j e [e1; \Delta  \Delta  \Delta  ; en] j e[_] j
eqint(e1; e2) j eqfloat(e1; e2) j if0 e1 then e2 else e3 j
typerec _ of [t:oe](ei; ef ; eu; ep; ea)

Figure 6.1: Syntax of *MLi -Close

I also add appropriate congruences for both product and projection formation (not shown
here).

The type formation and equivalence rules are the same as in *MLi -Rep, with the
addition of rules governing code types. The code type formation rule is similar to the
one governing 8:

\Delta  ] ft::^g ` oe1 \Delta  ] ft::^g ` oe2

\Delta  ` code(t::^; oe1; oe2)

The interesting term formation rules pertain to code and closures and are as follows:

\Delta  ] ft::^g ` oe
\Delta  ] ft::^g ` oe1 \Delta  \Delta  \Delta  \Delta  ] ft::^g ` oek
\Delta  ] ft::^g; \Gamma  ] fx:oe; x1:oe1; \Delta  \Delta  \Delta  ; xk:oekg ` e : oe0
\Delta ; \Gamma  ` vcode[t::^; x:oe; x1:oe1; \Delta  \Delta  \Delta  ; xk:oek]:e : code(t::^; oe; [oe1; \Delta  \Delta  \Delta  ; oek] ! oe0)

\Delta  ] ft::^g ` oe \Delta  ] ft::^; t0::^0g ` oe0

\Delta  ] ft::^; t0::^0g; \Gamma  ] fx:oeg ` e : oe0
\Delta ; \Gamma  ` tcode[t::^; x:oe; t0::^0]:e : code(t::^; oe; 8t0::^0:oe0)

\Delta ; \Gamma  ` e1 : code(t::^; oe; oe0) \Delta  ` _ :: ^ \Delta ; \Gamma  ` e2 :: f_=tgoe

\Delta ; \Gamma  ` hhe1; _; e2ii :: f_=tgoe0

CHAPTER 6. TYPED CLOSURE CONVERSION 108

The values, contexts, instructions, and rewriting rules for constructors are standard,
except for the addition of products (which is straightforward). If, at the constructor level,
I introduced code and closures instead of *-abstractions, then we would consider these
constructs to be values (assuming the components of the closures are values). Application
of a closure to a constructor value would proceed by substituting both the environment
of the closure and the argument for the abstracted constructor variables in the code.
These issues are demonstrated at the term level.

The values, contexts, and instructions for terms are standard except for the following
changes: first, I consider both vcode and tcode terms to be values, as well as closures
containing value components:

(values) v ::= \Delta  \Delta  \Delta  j vcode[t::^; x:oe; x1:oe1; \Delta  \Delta  \Delta  ; xk:oek]:e j

tcode[t::^; x:oe; t0::^0]: j hhv; u; v0ii

I extend evaluation contexts so that closure components are evaluated in a left-to-right
fashion as follows:

(contexts) E ::= \Delta  \Delta  \Delta  j hhE; _; eii j hhv; u; Eii
In the instructions, I replace application of abstractions to values with applications of
closures to values. I also add an instruction to evaluate the constructor component of a
closure. This yields instructions of the form

(instructions) I ::= \Delta  \Delta  \Delta  j hhv; U [J ]; eii j hhv0; u; vii [v1; \Delta  \Delta  \Delta  ; vk] j

hhv0; u; vii[u0]

with the restriction that the first component of a closure must be an appropriate code
term, according to the application (see below).

Finally, the rewriting rules for both value and constructor application are as follows:

E[hhvcode[t::^; x:oe; x1:oe1; \Delta  \Delta  \Delta  ; xk:oek]:e; u; vii [v1; \Delta  \Delta  \Delta  ; vk]] 7\Gamma !

E[fu=t; v=x; v1=x1; \Delta  \Delta  \Delta  ; vk=xkge]

E[hhtcode[t::^; x:oe; t0::^0]:e; u; vii [u0]] 7\Gamma ! E[fu=t; v=x; u0=t0ge]
In each case, we open the closure and extract the code, type environment, and value environment. We then substitute the environments and the argument(s) for the appropriate
variables in the code.

It is straightforward to show that the static semantics of *MLi -Close, as with *MLi
and *MLi -Rep, is sound with respect to the operational semantics and that type-checking
*MLi -Close terms is decidable.

CHAPTER 6. TYPED CLOSURE CONVERSION 109
6.3 The Closure Conversion Translation
The closure conversion translation is broken into a constructor translation, a type translation, and a term translation. I use the source kind and type judgments to define these
translations, but I augment the judgments with additional structure to determine certain
details in the translation.

Throughout the translation, I use n-tuples at both the constructor and term levels
as abbreviations for right-associated binary products, terminated with a unit. For instance, I use (^1 \Theta  ^2 \Theta  \Delta  \Delta  \Delta  \Theta  ^n) to abbreviate the kind ^1 \Theta  (^2 \Theta  (\Delta  \Delta  \Delta  \Theta  (^n \Theta  1) \Delta  \Delta  \Delta ))
and (_1; _2; \Delta  \Delta  \Delta  ; _n) to abbreviate the constructor (_1; (_2; (\Delta  \Delta  \Delta  (_n; ()) \Delta  \Delta  \Delta ))). Correspondingly, I use #1(_) as an abbreviation for ss1 _ and #i(_) as an abbreviation for
#(i \Gamma  1)(ss2 _) when i ? 1.

6.3.1 The Constructor and Type Translations
I begin the translation by considering closure conversion of *MLi -Rep constructors. Constructor translation judgments are of the form

\Delta env; \Delta arg ` _ :: ^ ) _0;
where \Delta env ] \Delta arg ` _ :: ^ is derivable from the constructor formation rules of *MLi -Rep,
and _0 is a *MLi -Close constructor. The axioms and inference rules that allow us to derive
this judgment are given in Figure 6.2.

In the constructor translation judgment, I split the kind assignment into two pieces:
\Delta env and \Delta arg. The \Delta arg component contains a kind assignment for the type variable
bound by the nearest enclosing *-abstraction (if any). The \Delta env component contains
a kind assignment for the other type variables in scope. The translation maps a type
variable found in \Delta arg to itself, but maps type variables in \Delta env to a projection from
a type environment data structure. This data structure is assumed to be bound to the
distinguished target variable tenv. Hence, I assume that tenv does not occur in the domain
of \Delta arg. The projections assume that the order of bindings in the kind assignment does
not change, so I consider \Delta env to be an ordered sequence, binding variables to kinds.

The rest of the translation is straightforward with the exception of *-abstractions,
which we must closure-convert. In this case, I generate a piece of code of the form
*tenv::^env: *t::^1: _0, which abstracts both a type environment (tenv) and an argument
(t). I also generate an environment, _env (discussed below). The code is obtained by
choosing a new kind assignment, \Delta 0env, to replace \Delta env, and by replacing \Delta arg with ft::^1g
in the translation of the body of the abstraction. Choosing the new kind assignment
\Delta 0env corresponds to deciding which variables will be preserved in the environment of the
closure. Therefore, \Delta 0env must be a subset of the bindings contained in \Delta env ] \Delta arg, and
\Delta 0env must contain bindings for all of the free type variables in the abstraction.

CHAPTER 6. TYPED CLOSURE CONVERSION 110

(var-arg) \Delta env; ft::^g ` t :: ^ ) t (unit) \Delta env; \Delta arg ` Unit :: \Omega  ) Unit

(var-env) ft1::^1; \Delta  \Delta  \Delta  ; tn::^ng; \Delta arg ` ti :: ^i ) #i(tenv)
(int) \Delta env; \Delta arg ` Int :: \Omega  ) Int (float) \Delta env; \Delta arg ` Float :: \Omega  ) Float

(prod) \Delta env; \Delta arg ` _1 :: \Omega  ) _

01 \Delta env; \Delta arg ` _2 :: \Omega  ) _02

\Delta env; \Delta arg ` Prod(_1; _2) :: \Omega  ) Prod(_01; _02)

(arrow)

\Delta env; \Delta arg ` _1 :: \Omega  ) _01 \Delta  \Delta  \Delta  \Delta env; \Delta arg ` _k :: \Omega  ) _0k

\Delta env; \Delta arg ` _ :: \Omega  ) _0
\Delta env; \Delta arg ` Arrow([_1; \Delta  \Delta  \Delta  ; _k]; _) :: \Omega  ) Arrow([_01; \Delta  \Delta  \Delta  ; _0k]; _0)

(fn) \Delta 

0env; ft::^1g ` _ :: ^2 ) _0 \Delta env; \Delta arg `env \Delta 0env ) _env

\Delta env; \Delta arg ` *t::^1: _ :: ^1 ! ^2 ) (*tenv::j\Delta 0envj: *t::^1: _0) _env

(app) \Delta env; \Delta arg ` _1 :: ^1 ! ^2 ) _

01 \Delta env; \Delta arg ` _2 :: ^1 ) _02

\Delta env; \Delta arg ` _1 _2 :: ^2 ) _1 _02

(trec)

\Delta env; \Delta arg ` _ :: \Omega  ) _0 \Delta env; \Delta arg ` _i; _f ; _u :: ^ ) _0i; _0f ; _0u

\Delta env; \Delta arg ` _p :: \Omega  ! \Omega  ! ^ ! ^ ! ^ ) _0p
\Delta env; \Delta arg ` _a :: \Omega 1 ! \Delta  \Delta  \Delta  ! \Omega k ! \Omega  ! ^1 ! \Delta  \Delta  \Delta  ! ^k ! ^ ! ^ ) _0a

\Delta env; \Delta arg ` Typerec _ of (_i; _f ; _u; _p; _a) :: ^ )

Typerec _0 of (_0i; _0f ; _0u; _0p; _0a)

(env) \Delta env; \Delta arg ` t1 :: ^1 ) _1 \Delta  \Delta  \Delta  \Delta env; \Delta arg ` tn :: ^n ) _n\Delta 

env; \Delta arg `env ft1::^1; \Delta  \Delta  \Delta  ; tn::^ng ) (_1; \Delta  \Delta  \Delta  ; _n)

Figure 6.2: Closure Conversion of Constructors

CHAPTER 6. TYPED CLOSURE CONVERSION 111

I construct the environment of the closure using the auxiliary judgment

\Delta env; \Delta arg `env \Delta 0env ) _:
With the env rule, I create an environment corresponding to \Delta 0env by extracting the
value corresponding to each variable in the domain of \Delta 0env, and then packing these
values in order into a tuple. If \Delta 0env = ft1::^1; \Delta  \Delta  \Delta  ; tn::^ng, then the kind of the resulting
environment is (^1 \Theta  \Delta  \Delta  \Delta  \Theta  ^n), which I abbreviate as j\Delta 0envj.

To translate types, I use judgments of the form \Delta env; \Delta arg ` oe ) oe0. The translation
maps *MLi -Rep types to the same *MLi -Close types, except that the injected constructors
are converted via the constructor translation:

\Delta env; \Delta arg ` _ :: \Omega  ) _0
\Delta env; \Delta arg ` T (_) ) T (_0)

The type translation of a polytype extends the current argument assignment, \Delta arg, with
the bound type variable during the translation of the body of the polytype:

\Delta env; \Delta arg ] ft::^g ` oe ) oe0
\Delta env; \Delta arg ` 8t::^:oe ) 8t::^:oe0

6.3.2 The Term Translation
The term translation for closure conversion mirrors the constructor translation, except
that I must account for both free type variables and free value variables. Judgments in
the translation are of the form

\Delta env; \Delta arg; \Gamma env; \Gamma arg ` e : oe ) e0
where \Delta env ] \Delta arg; \Gamma env ] \Gamma arg ` e : oe is a *MLi -Rep term formation judgment and e0 is a
*MLi -Close expression. The important axioms and inference rules that let us derive this
judgment are given in Figure 6.3. The rest of the rules simply map *MLi -Rep terms to
their corresponding *MLi -Close terms.

Like the constructor translation, the kind assignment and the type assignment are
split into environment and argument components. The argument component assigns
kinds/types to the variables of the nearest enclosing \Lambda  or *-expression (if any); the
environment component assigns kinds/types to the other free variables in scope. As in
the constructor case, I translate a variable occurring in \Gamma arg to itself, whereas I translate
a variable occurring in \Gamma env to a projection from a distinguished variable, xenv. Again,
the order of bindings in \Gamma env is relevant to the translation.

The abs and tabs rules translate abstractions to closures consisting of code, a constructor environment (_env), and a value environment (eenv). The code components are

CHAPTER 6. TYPED CLOSURE CONVERSION 112

(var-arg) \Delta env; \Delta arg; \Gamma env; fx1:oe1; \Delta  \Delta  \Delta  ; xk:oekg ` xi : oei ) xi
(var-env) \Delta env; \Delta arg; fx1:oe1; \Delta  \Delta  \Delta  ; xn:oeng; \Gamma arg ` xi : oei ) #i(xenv)

(tapp) \Delta env; \Delta arg ` _ :: ^ ) _

0 \Delta env; \Delta arg; \Gamma env; \Gamma arg ` e : 8t::^:oe ) e0

\Delta env; \Delta arg; \Gamma env; \Gamma arg ` e [_] : f_=tgoe ) e0 [_0]

(abs)

\Delta env; \Delta arg `env \Delta 0env ) _env \Delta env; \Delta arg; \Gamma env; \Gamma arg `env \Gamma 0env ) eenv

\Delta 0env; ; `env\Gamma type \Gamma 0env ) \Gamma 00env
\Delta 0env; ; ` oe1 ) oe01 \Delta  \Delta  \Delta  \Delta 0env; ; ` oek ) oe0k

\Delta 0env; ;; \Gamma 0env; fx1:oe1; \Delta  \Delta  \Delta  ; xk:oekg ` e : oe ) e0
\Delta env; \Delta arg; \Gamma env; \Gamma arg ` *[x1:oe1; \Delta  \Delta  \Delta  ; xk:oek]: e : [oe1; \Delta  \Delta  \Delta  ; oek] ! oe )

hhvcode[tenv :: j\Delta 0envj; xenv:j\Gamma 00envj; x1:oe01; \Delta  \Delta  \Delta  ; xk:oe0k]:e0; _env; eenvii

(tabs)

\Delta env; \Delta arg `env \Delta 0env ) _env \Delta env; \Delta arg; \Gamma env; \Gamma arg `env \Gamma 0env ) eenv

\Delta 0env; ; `env\Gamma type \Gamma 0env ) \Gamma 00env
\Delta 0env; ft::^g; \Gamma 0env; ; ` e : oe ) e0
\Delta env; \Delta arg; \Gamma env; \Gamma arg ` \Lambda t::^:e : 8t::^:oe )
hhtcode[tenv :: j\Delta 0envj; xenv:j\Gamma 00envj; t::^]:e0; _env; eenvii

Figure 6.3: Closure Conversion of Terms

CHAPTER 6. TYPED CLOSURE CONVERSION 113
constructed by choosing new kind and type assignments to cover the free variables of the
abstraction.

The environment components are constructed using the auxiliary judgments

\Delta env; \Delta arg ` \Delta 0env ) _env
and

\Delta env; \Delta arg; \Gamma env; \Gamma arg `env \Gamma 0env ) eenv:

The former judgment is obtained via the env constructor translation rule, whereas the
latter judgment is obtained via the following term translation rule:

(env)

\Delta env; \Delta arg; \Gamma env; \Gamma arg ` x1:oe1 ) e1

\Delta  \Delta  \Delta 
\Delta env; \Delta arg; \Gamma env; \Gamma arg ` xn:oen ) en

\Delta env; \Delta arg; \Gamma env; \Gamma arg ` fx1:oe1; \Delta  \Delta  \Delta  ; xn:oeng ) he1; \Delta  \Delta  \Delta  ; eni

This rule translates a new type assignment, \Gamma 0env, by extracting the values corresponding
to each variable in the domain of the assignment and placing the resulting values in a
tuple. To obtain the type of the resulting environment data structure, I first translate
all of the types in the range of \Gamma 0env:

(env-type) \Delta env; \Delta arg ` oe1 ) oe

01 \Delta  \Delta  \Delta  \Delta env; \Delta arg ` oen ) oe0n

\Delta env; \Delta arg `env\Gamma type fx1:oe1; \Delta  \Delta  \Delta  ; xn:oeng ) fx1:oe01; \Delta  \Delta  \Delta  ; xn:oe0ng

This process results in a *MLi -Close type assignment \Gamma 00env = fx1:oe01; \Delta  \Delta  \Delta  ; xn:oe0ng. The tuple
environment data structure has the type hoe01 \Theta  \Delta  \Delta  \Delta  \Theta  oe0ni, which I abbreviate as j\Gamma 00envj.

6.4 Correctness of the Translation
To prove the correctness of the closure conversion translation, I will establish suitable
relations between source and target constructors and terms, and then show that a source
construct is always related to its translation. I first examine the correctness of constructor
translation and, then consider term translation.

6.4.1 Correctness of the Constructor Translation
It is clear that if \Delta env; \Delta arg ` _ :: ^ ) _0, then \Delta env ] \Delta arg ` _ :: ^. It is also fairly
easy to show that we can always construct some translation of a well-formed constructor.
I only need to show that we can always delay any reordering or strengthening of the
kind assignment until we reach a use of an abs rule. Finally, it is also easy to show via
induction on the translation that constructor closure conversion preserves kinds directly.

CHAPTER 6. TYPED CLOSURE CONVERSION 114
Lemma 6.4.1 (Kind Correctness) If \Delta env; \Delta arg ` _ :: ^ ) _0, then ftenv::j\Delta envjg ]
\Delta arg ` _0 :: ^.

I want to show that a constructor and its translation are suitably equivalent. I begin
by establishing a set of kind-indexed simulation relations relating closed source and target
constructors. At base-kind, the relation is given as follows:

; ` _ j u :: \Omega  ; ` _0 j u :: \Omega 

_ ss\Omega  _0

Two closed constructors of kind \Omega  are related if they are definitionally equivalent to the
same constructor value. That is, to determine whether a source and target constructor
are related, we simply normalize the constructors and then syntactically compare them.
(Recall that constructors of the source language are a subset of the constructors in the
target language and the two languages coincide at the base kind \Omega .) I logically extend
the base relation to arrow kinds:

_1 ss^1 _01 implies _ _1 ss^2 _0 _01

_ ss^1!^2 _0

Let ffi and ffi0 range over substitutions of type variables for closed, source and target constructors respectively. I extend the relation to substitutions indexed by kind assignments:

Dom(ffi) = ft1; \Delta  \Delta  \Delta  ; tng 81 ^ i ^ n:ffi(ti) ss^i #i(_)

ffi ssft1::^1;\Delta \Delta \Delta ;tn::^ng ftenv=_g

Note that the distinguished type variable tenv is used in the target substitution. Finally,
I relate pairs of substitutions ffienv; ffiarg and ffi0env; ffi0arg as follows:

ffienv ss\Delta env ffi0env
Dom(ffiarg) = Dom(\Delta arg) = Dom(ffi0arg)

8t 2 Dom(\Delta arg):ffiarg(t) ss\Delta arg(t) ffi0arg(t)

ffienv; ffiarg ss\Delta env;\Delta arg ffi0env; ffi0arg

The pairs of substitutions are related iff ffienv and ffi0env are related under \Delta env, and for any
argument variable t, ffiarg(t) and ffi0arg(t) are related at \Delta arg(t).

With these definitions in place, I can state and prove the correctness of the constructor
translation. The first step is to show that constructing new environments from related
constructors yields related environments.

Lemma 6.4.2 If ffienv; ffiarg ss\Delta env;\Delta arg ffi0env; ffi0arg, \Delta env; \Delta arg `env \Delta 0env ) (_1; \Delta  \Delta  \Delta  ; _n),
where \Delta 0env = ft1::^1; \Delta  \Delta  \Delta  ; tn::^ng, then ft1=ffienv ] ffiarg(t1); \Delta  \Delta  \Delta  ; tn=ffienv ] ffiarg(tn)g ss\Delta 0env
ftenv=ffi0env ] ffi0arg(_1; \Delta  \Delta  \Delta  ; _n)g.

CHAPTER 6. TYPED CLOSURE CONVERSION 115
Proof: I must show that ffienv ] ffiarg(ti) ss^i #i(ffi0env ] ffi0arg(_1; \Delta  \Delta  \Delta  ; _n)) for 1 ^ i ^ n.
Hence, it suffices to show ffienv ] ffiarg(ti) ss^i ffi0env ] ffi0arg(_i). By an examination of the env
rule, \Delta env; \Delta arg ` ti::^i_i. There are two cases to consider, depending on the rule used to
produce _i: either ti is translated under the var-arg rule or else ti is translated under the
var-env rule. In the former case, _i = ti. By assumption, ffienv; ffiarg ss\Delta env;\Delta arg ffi0env; ffi0arg,
thus ffiarg(ti) ss^i ffi0arg(ti). In the latter case, we have _i = #j(tenv), ti = t0j, and \Delta env is
of the form ft01::^01; \Delta  \Delta  \Delta  ; t0j::^i; \Delta  \Delta  \Delta  ; t0m::^0mg. By assumption, ffienv ss\Delta env ffiarg. Therefore, by
the definition of the relation, for all 1 ^ k ^ m, ffienvt0k ss^k ffi0env#k(tenv). In particular,
since t0j = ti, ffienv(ti) ss^i #j(ffi0env(tenv)). Consequently, in either case we know that
ffienv ] ffiarg(ti) ss^i ffi0env ] ffi0arg(_i). 2

Next, by induction on the derivation of a translation, I show that a constructor and its
translation are related when we apply related substitutions. In particular, the translation
of a constructor of base kind yields a constructor that is definitionally equivalent to that
constructor.

Theorem 6.4.3 (Constructor Correctness) If \Delta env; \Delta arg ` _ :: ^ ) _0 and
ffienv; ffiarg ss\Delta env;\Delta arg ffi0env; ffi0arg, then ffienv ] ffiarg(_) ss^ ffi0env ] ffi0arg(_0).

Proof: By induction on the derivation of \Delta env; \Delta arg ` _ :: ^ ) _0. The interesting
cases, var-arg, var-env, fn, and trec are given below.

var-arg: \Delta env; ft::^g ` t :: ^ ) t. By assumption, ffiarg(t) ss^ ffi0arg(t).
var-env: ft1::^1; \Delta  \Delta  \Delta  ; tn::^ng ` ti :: ^i ) #i(tenv). By assumption, ffienv(ti) ss^
#i((ffi0env(ti))).

fn: \Delta env; \Delta arg ` *t::^1: _ :: ^1 ! ^2 ) (*tenv::j\Delta 0envj: *t::^1: _0)_env. Let _1 ss^1 _01.
I must show (*t::^1: ffienv ] ffiarg(_)) _1 ss^2 (ffi0env ] ffi0arg(*tenv::j\Delta 0envj: *t::^1: _0) _env) _01.
Since the code of the closure is closed, it suffices to show (ffienv ] ffiarg ] ft=_1g)(_) ss^2
(ftenv=ffi0env ] ffi0arg(_env); t=_01g(_0)). Since \Delta 0env; ft::^1g ` _ :: ^2, I can drop the bindings
of variables in ffienv ] ffiarg that do not occur in \Delta 0env. Let ffi00env = ft=ffienv ] ffiarg(t) j t 2
Dom(\Delta 0env)g. I must now show (ffi00env]ft=_1g)(_) ss^2 (ftenv=ffi0env]ffi0arg(_env); t=_01g(_0)).
By the inductive hypothesis, this holds if I can show that ffi00env ] ft=_1g ss\Delta env;ft::^1g
ftenv=ffi0env ] ffi0arg(_env)g ] ft=_01g. By assumption, _1 ss^1 _01 so I only need to show that

ffi00env ss\Delta env ftenv=ffi0env ] ffi0arg(_env)g:
But, this holds directly from lemma 6.4.2.

CHAPTER 6. TYPED CLOSURE CONVERSION 116
trec: We have

\Delta env; \Delta arg ` Typerec _ of (_i; _f ; _u; _p; _a) :: ^ ) Typerec _0 of (_0i; _0f ; _0u; _0p; _0a):
By assumption, ffienv ] ffiarg(_) ss\Omega  ffi0env ] ffi0arg(_0). Therefore, these two constructors have
the same normal forms when their respective substitutions are applied. Let _0 be this
normal form. I argue by induction on the structure of _0 that

ffienv ] ffiarg(Typerec _ of (_i; _f ; _u; _p; _a)) ss^ ffi0env ] ffi0arg(Typerec _0 of (_0i; _0f ; _0u; _0p; _0a)):

If _0 is Int, then

ffienv ] ffiarg(Typerec _ of (_i; _f ; _u; _p; _a)) j ffienv ] ffiarg(_i)
and

ffi0env ] ffi0arg(Typerec _0 of (_0i; _0f ; _0u; _0p; _0a)) j ffienv ] ffiarg(_0i):

By the outer inductive hypothesis, these two constructors are related at ^. Similar
reasoning shows that the result holds for _0 = Float and _0 = Unit.

If _0 is Prod(_1; _2), then

ffienv ] ffiarg(Typerec _ of (_i; _f ; _u; _p; _a)) j ffienv ] ffiarg(_p _1 _2 _a _b)
where _a = Typerec _1 of (_i; _f ; _u; _p; _a) and _b = Typerec _2 of (_i; _f ; _u; _p; _a).
Likewise,

ffi0env ] ffi0arg(Typerec _0 of (_0i; _0f ; _0u; _0p; _0a)) j ffi0env ] ffi0arg(_0p _1 _2 _0a _0b)
where _0a = Typerec _1 of (_0i; _0f ; _0u; _0p; _0a) and _0b = Typerec _2 of (_0i; _0f ; _0u; _0p; _0a).
By the inner induction hypothesis, ffienv ] ffiarg(_a) ss^ ffi0env ] ffi0arg(_0a) and ffienv ] ffiarg(_b) ss^
ffi0env ] ffi0arg(_0b). By the outer induction hypothesis, ffienv ] ffiarg(_p) ss^0 ffi0env ] ffi0arg(_0p) where
^0 = \Omega  ! \Omega  ! ^ ! ^ ! ^. Hence, by the definition of the relations at arrow types, we
know that

ffienv ] ffiarg(_p _1 _2 _a _b) ss^ ffi0env ] ffi0arg(_0p _1 _2 _0a _0b):

Similar reasoning shows that the result holds for _0 = Arrow([_1; \Delta  \Delta  \Delta  ; _k]; _).

2

6.4.2 Type Correctness of the Term Translation
The next step in proving the correctness of closure conversion is to show that each
translated term has the translated type. I begin by showing that the type translation
commutes with substitution.

CHAPTER 6. TYPED CLOSURE CONVERSION 117
Lemma 6.4.4 If \Delta env; \Delta arg ] ft::^g ` oe ) oe0 and \Delta env; \Delta arg ` _ :: ^ ) _0, then
\Delta env; \Delta arg ` f_=tgoe ) f_0=tgoe0.

Proof: By induction on the derivation of \Delta env; \Delta arg ] ft::^g ` oe ) oe0. The base case,
T (_) relies upon the correctness of the constructor translation. 2

The following lemma is critical for showing that closures are well-formed. Roughly
speaking, it shows that a type obtained from the "current" constructor context
(\Delta env; \Delta arg) is equivalent to the type obtained from the closure's context, as long as
we substitute the closure's environment for the abstracted environment variable.

Lemma 6.4.5 If \Delta env; \Delta arg ` oe ) oe1 and \Delta env; \Delta arg `env \Delta 0env ) _, then \Delta 0env; ; ` oe )
oe2 and ftenv::j\Delta envjg ] \Delta arg ` oe1 j f_=tenvgoe2.

Theorem 6.4.6 (Type Correctness) If \Delta env; \Delta arg; \Gamma env; \Gamma arg ` e : oe ) e0, then
\Delta env; \Delta arg `env\Gamma type \Gamma env ) \Gamma 0env, \Delta env; \Delta arg `env\Gamma type \Gamma arg ) \Gamma 0arg, and \Delta env; \Delta arg `
oe ) oe0, then ftenv::j\Delta envjg ] \Delta arg; fxenv:j\Gamma 0envjg ] \Gamma 0arg ` e0 : oe0.

Proof: By induction on the derivation of \Delta env; \Delta arg; \Gamma env; \Gamma arg ` e : oe ) e0. The
most interesting cases are the translations of variables and *-abstractions (shown below).
The other cases follow in a straightforward fashion. In particular, the treatment of \Lambda -
abstractions almost directly follows the treatment of *-abstractions.

var-arg: We have \Delta env; \Delta arg; \Gamma env; fx1:oe1; \Delta  \Delta  \Delta  ; xn:oeng ` xi : oei ) e0. By the typeenv translation rule, \Gamma 0arg = fx1:oe01; \Delta  \Delta  \Delta  ; xn:oe0ng where \Delta env; \Delta arg ` oei ) oe0i. Thus,
ftenv::j\Delta envjg; \Delta arg; fxenv:j\Gamma 0envjg; \Gamma 0arg ` xi : oe0i.

var-env: We have \Delta env; \Delta arg; fx1:oe1; \Delta  \Delta  \Delta  ; xn:oeng; \Gamma arg ` xi : oei ) #i(xenv). By the
type-env translation rule, \Gamma 0env = fx1:oe01; \Delta  \Delta  \Delta  ; xn:oe0ng where \Delta env; \Delta arg ` oei ) oe0i. Thus,
j\Gamma 0envj = hoe01 \Theta  \Delta  \Delta  \Delta  \Theta  oe0ni. Hence, ftenv::j\Delta envjg; \Delta arg; fxenv:j\Gamma 0envjg; \Gamma 0arg ` #i(xenv) : oe0i.

abs: To simplify the proof, I only show the case for 1-argument functions. We have

\Delta env; \Delta arg; \Gamma env; \Gamma arg ` *x:oea: e : oea ! oeb ) hhec; _env; eenvii
where ec is vcode[tenv::j\Delta 0envj; xenv:j\Gamma 00envj; x:oe00a]:e0. By the inductive hypothesis, we know
that

ftenv::j\Delta 0envjg; fxenv:j\Gamma 00envjg ] fx:oe00ag ` e0 : oe00b ;

where \Delta 0env; ; ` \Gamma 0env ) \Gamma 00env, \Delta 0env; ; ` oea ) oe00a, and \Delta 0env; ; ` oeb ) oe00b . From this and
the typing rule for vcode, we can conclude that

;; ; ` ec : code(tenv::j\Delta 0envj; j\Gamma 00envj; oe00a ! oe00b ):

CHAPTER 6. TYPED CLOSURE CONVERSION 118

From kind-preservation of the constructor translation, we know that ftenv::j\Delta envjg ]
\Delta arg ` _env :: j\Delta 0envj. Thus, the code and the type environment agree on kinds. I only
need to show that the code and the value environment agree on types.

Suppose \Gamma 0env = fx1:oe1; \Delta  \Delta  \Delta  ; xn:oeng. Then eenv = he1; \Delta  \Delta  \Delta  ; eni where

\Delta env; \Delta arg; \Gamma env; \Gamma arg ` xi : oei ) ei
for 1 ^ i ^ n. By the induction hypothesis,

ftenv::j\Delta envjg ] \Delta arg; fxenv:j\Gamma 0jg ] \Gamma 0arg ` ei : oe0i
where \Delta env; \Delta arg ` \Gamma env ) \Gamma 0, \Delta env; \Delta arg ` \Gamma arg ) \Gamma 0arg, and \Delta env; \Delta arg ` oei ) oe0i. From
lemma 6.4.5, we know that ftenv::j\Delta 0envjg ` oe0i j f_env=tenvg\Gamma 00env(xi). Therefore,

ftenv::j\Delta 0envjg ` hoe01 \Theta  \Delta  \Delta  \Delta  \Theta  oe0ni j f_env=tenvgj\Gamma 00envj:
Thus, from the formation rule for closures, we can conclude that

ftenv::j\Delta envjg ] \Delta arg; fx:j\Gamma 0jg ] \Gamma 0arg ` hhec; _env; eenvii : f_env=tenvg(oe0a ! oe0b):
Suppose \Delta env; \Delta arg ` oea ) oe0a and \Delta env; \Delta arg ` oeb ) oe0b. Then by the type translation,

\Delta env; \Delta arg ` oea ! oeb ) oe0a ! oe0b:

By lemma 6.4.5, we can conclude that

ftenv::j\Delta envjg ] \Delta arg ` oe0a ! oe0b j f_env=tenvg(oe00a ! oe00b ):
Hence,

ftenv::j\Delta envjg ] \Delta arg; fx:j\Gamma 0jg ] \Gamma 0arg ` hhec; _env; eenvii : oe0a ! oe0b:

2

6.4.3 Correctness of the Term Translation
Correctness of the term translation follows a similar pattern to that of the constructor
translation. I begin by establishing a set of relations for closed term values, indexed by
closed source types.

;; ; ` e : oe ; ` oe ) oe0 ;; ; ` e0 : oe0

e + v iff e0 + v0 and v ssoe v0

e ,oe e0

i ssint i f ssfloat f hi ssunit hi

CHAPTER 6. TYPED CLOSURE CONVERSION 119

ss1 v ,oe1 ss1 v0 ss2 v ,oe2 ss1 v0

v ssoe1\Theta oe2 v0

v1 ssoe1 v01 \Delta  \Delta  \Delta  vk ssoek v0k implies v [v1; \Delta  \Delta  \Delta  ; vk] ,oe v0 [v01; \Delta  \Delta  \Delta  ; v0k]

v ss[oe1;\Delta \Delta \Delta ;oek]!oe v0

_ ss^ _0 implies v [_] ,f_=tgoe v0 [_0]

v ss8t::^:oe v0

Two expressions e and e0 are related at source type oe iff e has type oe, e0 has a type oe0
obtained by translating oe, and e evaluates to a value iff e0 evaluates to a related value
at oe. Values at base type are related iff they are syntactically equal. Values at product
type are related if projecting their components yields related computations. Values at
arrow types are related when they yield related computations, given related arguments.
Finally, two polymorphic values are related if they yield related computations given
related constructors.

For open expressions, I extend the relations to substitutions fl and fl0, mapping variables to values, where the relations are indexed by a source type assignment \Gamma  as follows:

v1 ssoe1 v01 \Delta  \Delta  \Delta  vn ssoen v0n
fx1=v1; \Delta  \Delta  \Delta  ; xn=vng ssfx1:oe1;\Delta \Delta \Delta ;xn:oeng fxenv=hv01; \Delta  \Delta  \Delta  ; v0nig

I relate pairs of substitutions, flenv; flarg and fl0env; fl0arg as follows:

flenv ss\Gamma env fl0env
Dom(\Gamma arg) = Dom(flarg) = Dom(fl0arg) 8x 2 Dom(\Gamma arg):flarg(x) ss\Gamma arg(x) fl0arg(x)

flenv; flarg ss\Gamma env;\Gamma arg fl0env; fl0arg

The following lemma shows that the translation of variables is correct, and thus so is
the translation of environments.

Lemma 6.4.7 Let ffienv; ffiarg ss\Delta env;\Delta arg ffi0env; ffi0arg and flenv; flarg ssffienv]ffiarg(\Gamma env;\Gamma arg) fl0env; fl0arg.

1. If \Delta env; \Delta arg; \Gamma env; \Gamma arg ` x : oe ) e, then flenv ] flarg(x) ,ffienv]ffiarg(oe) fl0env ] fl0arg(e).
2. If \Delta env; \Delta arg; \Gamma env; \Gamma arg `env \Gamma 0env ) eenv, then fl0env ] fl0arg(eenv) + venv for some venv

and, fx=flenv ] flarg(x) j x 2 Dom(\Gamma 0env)g ssffienv]ffiarg(\Gamma 0env) fxenv=venvg.

With this lemma in hand, I can establish the correctness of the translation by showing
that a *MLi -Rep expression is always related to its *MLi -Close translation, given appropriately related substitutions.

CHAPTER 6. TYPED CLOSURE CONVERSION 120
Theorem 6.4.8 (Correctness) Let ffienv; ffiarg ss\Delta env;\Delta arg ffi0env; ffi0arg,
and let flenv; flarg ssffienv]ffiarg(\Gamma env;\Gamma arg) fl0env; fl0arg. If \Delta env; \Delta arg; \Gamma env; \Gamma arg ` e : oe ) e0, then
ffienv ] ffiarg(flenv ] flarg(e)) ,ffienv]ffiarg(oe) ffi0env ] ffi0arg(fl0env ] fl0arg(e0)):

Proof: By induction on the derivation of \Delta env; \Delta arg; \Gamma env; \Gamma arg ` e : oe ) e0 (see
Figure 6.3). The var-arg and var-env cases follow directly from lemma 6.4.7. The
int, float, and unit rules follow trivially. The elimination rules proj, app, and tapp
follow directly from the inductive hypotheses as well as the definitions of the relations.
The typerec rule follows directly from constructor translation correctness, the inductive
hypotheses, and the definition of the relations. Arguments for the abs and tabs rules
follow.

abs: Let v1 ssffienv]ffiarg(oe1) v01, \Delta  \Delta  \Delta , vk ssffienv]ffiarg(oek) v0k, and let fl00env = fx=flenv]flarg(x) j x 2
Dom(\Gamma 0)g. By lemma 6.4.7, fl0env ] fl0arg(eenv) + venv for some venv and fl00env ssffienv]ffiarg(\Gamma 0env)
fxenv=venvg.

Let ffi00env = ft=ffienv ] ffiarg(t) j t 2 Dom(\Delta 0)g and let _0env = ffi0env ] ffi0arg(_env). By lemma
6.4.2, we know that ffi00env ss\Delta 0env ftenv=_0envg. Hence, ffi00env; ; ss\Delta 0env;; ftenv=_0envg; ;. By the
induction hypothesis and type preservation, we can conclude that

ffi00env(fl00env ] fx1=v1; \Delta  \Delta  \Delta  ; xk=vkg(e)) ssffienv]ffiarg(oe)

ftenv=_0envg(fxenv=venv; x1=v01; \Delta  \Delta  \Delta  ; xk=v0kg(e0)):

Thus,

ffienv ] ffiarg(flenv ] flarg(*[x1:oe1; \Delta  \Delta  \Delta  ; xk:oek]: e)) ssffienv]ffiarg([oe1;\Delta \Delta \Delta ;oek]!oe)

ffi0env ] ffi0arg(fl0env ] fl0arg(hhec; _env; eenvii))

where ec is vcode[tenv::j\Delta 0envj; xenv:j\Gamma 00envj; x1:oe01; \Delta  \Delta  \Delta  ; xk:oe0k]:e0.

tabs: Let _ ss^ _0 and let fl00env = fx=flenv ] flarg(x) j x 2 Dom(\Gamma 0)g. By lemma 6.4.7,
fl0env ] fl0arg(eenv) + venv for some venv and fl00env ssffienv]ffiarg(\Gamma 0env) fxenv=venvg.

Let ffi00env = ft=ffienv ] ffiarg(t) j t 2 Dom(\Delta 0)g and let _0env = ffi0env ] ffi0arg(_env). By lemma
6.4.2, we know that ffi00env ss\Delta 0env ftenv=_0envg. Hence, by the assumption regarding _ and
_0, ffi00env; ft=_g ss\Delta 0env;ft::^g ftenv=_0envg; ft=_0g. By the induction hypothesis, and type
preservation, we can conclude that

ffi00env ] ft=_g(fl00env(e)) ssffienv]ffiarg]ft=_g(oe) ftenv=_0env; t=_0g(fxenv=venvg(e0)):
Thus,

ffienv ] ffiarg(flenv ] flarg(\Lambda t::^:e)) ssffienv]ffiarg(8t::^:oe) ffi0env ] ffi0arg(fl0env ] fl0arg(hhec; _env; eenvii))
where ec is tcode[tenv::j\Delta 0envj; xenv:j\Gamma 00envj; t::^]:e0. 2

CHAPTER 6. TYPED CLOSURE CONVERSION 121
6.5 Related Work
Closure conversion is discussed in descriptions of various functional language compilers [111, 78, 11, 9, 109]. It is closely related to *-lifting [69] in that it eliminates free
variables in the bodies of *-abstractions. However, closure conversion differs by making
the representation of the environment explicit as a data structure. Making the environment explicit is important because it exposes environment construction and variable
lookup to an optimizer. Furthermore, Shao and Appel show that not all environment
representations are "safe for space" [109], and thus choosing a good environment representation is an important part of compilation.

Wand and Steckler [124] have considered two optimizations of the basic closure conversion strategy -- selective and lightweight closure conversion -- and provide a correctness
proof for each of these in an untyped setting. Hannan [54] recasts Wand's work into a
typed setting, and provides correctness proofs for Wand's optimizations. As with my
translation, Hannan's translation is formulated as a deductive system. However, Hannan does not consider the important issue of environment representation (preferring an
abstract account), nor does he consider the typing properties of the closure-converted
code.

Minamide, Morrisett, and Harper give a comprehensive treatment of type-directed
closure conversion for the simply-typed *-calculus and a predicative, type-passing polymorphic *-calculus [92, 91]. This chapter extends the initial treatment by showing how
to closure convert a language like *MLi with higher-kinds (i.e., functions at both the
constructor and term levels).

Chapter 7
Types and Garbage Collection
In the previous chapters, I argued that one should use types at compile time to direct
the translation of a high-level language to a low-level language. In this chapter, I will
show that types can be used at run time to implement a key facility, namely automatic
storage reclamation or garbage collection. As in the previous chapters, types will guide
us in the process of garbage collection as well as a proof of correctness.

In most accounts of language implementation, garbage collection is either ignored or
at best discussed without regard to the rest of the implementation. Most descriptions of
garbage collectors are extremely low-level and concentrate on manipulating "mark bits",
"forwarding pointers", "tags", "reference counts", and the like. This focus on the lowlevel details makes it extremely difficult to determine what effect a garbage collector has
on a program's evaluation. As a result, there are very few proofs that a garbage collector
does not interfere with evaluation and only collects true garbage.

The primary culprit is that traditional models of evaluation based on the *-calculus,
such as the contextual semantics of Mini-ML and *MLi , use substitution as the mechanism
of computation. Unfortunately, substitution hides all memory management issues: during
evaluation we simply ff-convert terms so that we can always find an unused variable.
Since ff-conversion is defined in terms of substitution, it is substitution that implicitly
"allocates" fresh variable names for us. Furthermore, when we substitute a value for
a variable, if there are no occurrences of that variable, the value disappears. Thus,
substitution also takes care of "collecting" unneeded terms.

In this chapter, I develop an alternative style of semantics where allocation is explicit.
The basic idea is to represent a program's memory or heap as a global set of syntactic
declarations. The evaluation rules allocate large objects in the global heap and automatically dereference pointers to such objects when needed. Since the heap is explicit, the
process of garbage collection is made explicit as any relation that removes portions of a
program's heap without affecting the program's evaluation.

I specify a particular garbage collection strategy which characterizes the family of

122

CHAPTER 7. TYPES AND GARBAGE COLLECTION 123
tracing garbage collectors including mark/sweep and copying collectors. By employing
standard syntactic techniques, I prove that the specification is correct with respect to
the definition of garbage.

Next, I develop an algorithm that implements the tracing garbage collection strategy.
Standard tracing collectors use tags on values in the heap to determine their shape --
the size of the object and any pointers contained in the object. Instead of using tags, I
show that for monomorphic languages, if enough type information is recorded on terms
at compile time, types can be used to determine the shape of objects in the heap. Consequently, no tags are required on the values in the heap to support garbage collection.
This approach to tag-free garbage collection is not new [23], but my formulation is at a
sufficiently high level that it is easy to prove its correctness.

I then show how to extend the tag-free collection algorithm to accommodate generational garbage collection. Generational collection is an important technique that collects
most of the garbage in a program but examines a smaller set of objects than the standard
tracing collection algorithm. Thus, generational collection tends to improve the latency
or response time of garbage collection without sacrificing too much space.

After showing how a monomorphic language can be garbage collected in a tag-free
fashion, I show how a type-passing, polymorphic language such as *MLi can be garbage
collected. The key idea is to use constructors that are passed dynamically as arguments
to procedures during the garbage collection process. With type information recorded
at compile time, this allows us to reconstruct the shape of all objects. Hence, tag-free
garbage collection is another mechanism that can use dynamic type dispatch to account
for variable types. As for monomorphic languages, this approach to tag-free garbage
collection for polymorphic languages is not new [119, 6, 96, 95], but my formulation is
sufficiently abstract that we can easily prove its correctness.

Tag-free garbage collection is important for two very practical reasons: first, a clever
tag-free implementation can avoid manipulating any type information in monomorphic
code at run time, except during garbage collection. In contrast, a tagging implementation must tag values as they are created and possibly untag the values when they are
examined. The overheads of manipulating these tags during the computation can be
considerable [112] and implementors go to great lengths and use many clever encodings
to minimize these overheads [128]. Second, tag-free garbage collection supports language
and system interoperability. In particular, many ubiquitous languages, such as Fortran,
C, and C++, do not provide automatic memory management and, thus, do not tag values.
A language that uses tags for collection must strip tags off values before passing them
to library routines written in Fortran or C. Similarly, communicating with the operating
system, windowing system, or hardware requires matching the representations dictated
by these systems. Since tag-free collection places no constraints on the representation of
values, communicating with these systems is easier and more efficient.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 124

(types) o/ ::= int j float j unit j ho/1 \Theta  o/2i j code(o/1; o/2) j o/1 ! o/2
(expressions) e ::= return x j if0 x then e1 else e2 j let x:o/ = d in e
(declarations) d ::= x j i j f j hi j hx1; x2i j ss1 x j ss2 x j

vcode[xenv:o/env; x:o/ ]:e j hhx1; x2ii j x x0 j
eqint(x1; x2) j eqfloat(x1; x2)

Figure 7.1: Syntax of Mono-GC Expressions

7.1 Mono-GC
In this Section, I define a language called Mono-GC, which is derived from the monomorphic subset of the *MLi -Close language (see Chapter 6). The expressions of the language
are limited in the style of Flanagan et al.[42]. In particular, the language forbids nested
expressions and requires that all values and computations be bound to variables. These
restrictions simplify the presentation of the semantics, but they provide many of the
practical benefits of CPS [9].

The syntax of Mono-GC is defined in Figure 7.1. Types are monomorphic and include
base types, products, code, and arrow types. To simplify the language, I only consider
functions of one argument. Expressions (e) return a variable, branch on a variable, or
bind a declaration (d) to a variable and continue with some expression. Declarations
can either be immediate constants, a primitive operation (e.g., eqint) applied to some
variables, a tuple whose components are variables, a piece of code, a closure, a projection
from a variable, or an application of a variable to a variable. As in Mono-CLOSE, I
require that code always be closed.

The declaration let x:o/ = d in e binds the variable x within the scope of the expression e. Similarly, the declaration vcode[xenv:o/env; x:o/ ]:e binds the variables xenv and x in
the scope of the expression e. I consider expressions to be equivalent up to ff-conversion
of the bound variables.

From an implementor's perspective, the variables of Mono-GC correspond to abstract
machine registers. In contrast to a semantics based on substitution, I bind values to
registers and then compute with the registers, instead of substituting the contents of a
register within a term. By restricting declarations so that there are no nested expressions,
I greatly simplify the process of breaking an expression into an evaluation context and
instruction. Indeed, the evaluation contexts are explicitly tracked via a program stack
(see below).

CHAPTER 7. TYPES AND GARBAGE COLLECTION 125

The other syntactic classes of Mono-GC are given in Figure 7.2. Mono-GC programs
have four components: a heap (H), a stack (S), a typed environment (ae), and an expression (e). Informally, the heap holds values too large to fit into registers. The stack holds
a list of delayed computations, essentially as closures, that are waiting for a function
invocation to return. The environment serves as the "registers" of the abstract machine
and maps variables to small values. Finally, the expression corresponds to the code that
the machine is currently executing.

Formally, a heap is an unordered set of bindings that maps locations (l) to heap values.
A heap value (h) is a tuple of small values, a piece of code, or a closure. Heap values are
too large to fit into registers and are thus bound to locations in memory. Small values (v)
are values that can fit into registers and consist of integer and floating point constants,
unit, and locations. A typed environment (ae) is an environment that maps variables to
both a type and a small value. I use ae(x) and aetype(x) to denote the value and type to
which ae maps x, respectively. A stack (S) is a list of pairs of the form [ae; *x:o/: e]. Each
pair represents a delayed computation where ae is the environment of the computation
and *x:o/: e is the "continuation" of the delayed computation. I require that all the free
variables in *x:o/: e be bound in the environment ae. The stack could also be represented as
a list of closures, but this approach models a system where stack frames are not allocated
in the heap. Composing the "closures" of the stack results in the "continuation" of the
program. Finally, I distinguish programs with an empty stack and return x expression
as answer programs.

Like the expression level, I consider code-expressions to bind their variable arguments
within the scope of their expression components. For a stack frame [ae; *x:o/: e], I consider
the domain of ae and x to be bound within e. Finally, I consider the domain of the
heap to bind the locations within the scope of the range of the heap, the stack, and the
environment of a program. Thus, I consider programs to be equivalent up to ff-conversion
and reordering of the locations bound in the heap.

Considering programs equivalent modulo ff-conversion and the treatment of heaps
and environments as sets instead of sequences hides many of the complexities of memory
management. In particular, programs are automatically considered equivalent if the
heap or environment is rearranged and locations or variables are renamed as long as the
"graph" of the program is preserved. This abstraction allows us to focus on the issues of
determining what bindings in the heap are garbage without specifying how such bindings
are represented in a real machine.

7.1.1 Dynamic Semantics of Mono-GC
Figure 7.3 defines the rewriting rules for Mono-GC programs. I briefly describe each rule
below:

CHAPTER 7. TYPES AND GARBAGE COLLECTION 126

(locations) l
(small values) v ::= i j f j l j hi
(heap values) h ::= hv1; v2i j vcode[xenv:o/env; x:o/ ]:e j hhvcode; venvii
(heaps) H ::= fl1=h1; \Delta  \Delta  \Delta  ; ln=hng
(environments) ae ::= fx1:o/1=v1; \Delta  \Delta  \Delta  ; xn:o/n=vng
(stacks) S ::= [] j S[ae; *x:o/: e]
(programs) P ::= (H; S; ae; e)
(answers) A ::= (H; []; ae; return x)

Figure 7.2: Syntax of Mono-GC Programs

(1,2) An if0 is applied to some variable x. We find the value of x in the current environment and select the appropriate expression according to whether this value is 0
or some other integer.

(3) A variable x is bound to another variable x0 in a let expression. We lookup the

small value v to which x0 is bound in the current environment, ae. We extend ae to
map x to v and continue with the body of the let.

(4,5) The integer equality primitive is applied to two variables. We find the value of the

variables in the environment and return 1 or 0 as appropriate. This new value is
bound to the let-bound variable in the new environment. The rules for floatingpoint equality (not shown) are similar.

(6) The expression binds a variable to an immediate small value. We add that binding

to the current environment and continue.

(7,8,9) The expression allocates a tuple, code, or a closure binding the result to x. We

first replace all of the free variables in the object with their bindings from the
environment. Code objects are always closed, so they are not effected. Then, we
allocate a new location on the heap l and bind the heap value to this location.
Next, we map x to l in the current environment and continue.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 127

(10) The expression projects the ith component of y, binding the result to x. We lookup

y in the environment, find that it is bound to the location l. We dereference l in
the heap and find that it is bound to a heap value hv1; v2i. We bind vi to x in the
environment and continue.

(11) The expression applies x1 to some argument x2, binding the result to x. We lookup

x1 and x2 in the environment, finding that x1 is bound to some location l and x2
is bound to v. We dereference l in the heap and find that it is bound to a closure,
hhlcode; venvii, where lcode is bound to the code vcode[xenv:o/env; y:o/ 0]:e. We form a
new stack frame by pairing the current environment (ae0) and the current expression,
abstracting the result of the function *x:o/: e0. This frame is pushed on the stack.
Then, we install the environment which maps xenv to venv and y to v. We then
continue with the body of the closure as the current expression.

(12) The current expression is return x0 and the stack is non-empty. We lookup the

value of x0 in the current environment (ae0), pop off a stack frame, install its environment (ae) as the current environment, bind the small value ae0(x0) to the argument
of the continuation (x), and continue with the body of the continuation.

In this formulation, each time a let-expression is evaluated, the type ascribed to the
bound variable is entered into the current environment ae, as well as the value. In essence,
the environment contains a type assignment \Gamma  that is constructed on the fly. It is possible
to avoid constructing these type assignments at run time by labelling let-expressions not
only with the type of the bound variable, but also with the types of all variables in scope.
This allows evaluation to simply discard the current type assignment and proceed with
the assignment labelling the expression. Since these assignments can be calculated at
compile time, no assignment construction need occur at run time.

Of course, labelling each expression with the types of all variables in scope could
take a great deal of space. But, as I will show, this type information is only used
during garbage collection. Most language implementations restrict garbage collection
from occuring except at certain points during evaluation. For example, the garbage
collector of SML/NJ is only invoked at the point when a function is called, or at the point
when an array or vector is allocated. Hence, we only need to record type assignments for
those let-expressions that perform a function call or array allocation. This guarantees
that when we invoke garbage collection, enough type information is present to do the
job.

7.1.2 Static Semantics of Mono-GC
The static semantics of Mono-GC is described via a family of judgments. The first two
judgments, \Gamma  `exp e : o/ and \Gamma  `dec d : o/ , give types to expressions and declarations,

CHAPTER 7. TYPES AND GARBAGE COLLECTION 128

1: (H; S; ae; if0 x then e1 else e2) 7\Gamma ! (H; S; ae; e1) (ae(x) = 0)
2: (H; S; ae; if0 x then e1 else e2) 7\Gamma ! (H; S; ae; e2)(ae(x) = i and i 6= 0)
3: (H; S; ae; let x:o/ = x0 in e) 7\Gamma ! (H; S; ae ] fx:o/ =ae(x0)g; e)
4: (H; S; ae; let x:o/ = eqint(x1; x2) in e) 7\Gamma !

(H; S; ae ] fx:o/ =1g; e) (ae(x1) =int ae(x2))

5: (H; S; ae; let x:o/ = eqint(x1; x2) in e) 7\Gamma !

(H; S; ae ] fx:o/ =0g; e) (ae(x1) 6=int ae(x2))

6: (H; S; ae; let x:o/ = v in e) 7\Gamma ! (H; S; ae ] fx:o/ =vg; e)
7: (H; S; ae; let x:o/ = hx1; x2i in e) 7\Gamma !

(H ] fl = hae(x1); ae(x2)ig; S; ae ] fx:o/ =lg; e)

8: (H; S; ae; let x:o/ = vcode[xenv:o/env; x:o/ 0]:e0 in e) 7\Gamma !

(H ] fl = vcode[xenv:o/env; x:o/ 0]:e0g; S; ae ] fx:o/ =lg; e)

9: (H; S; ae; let x:o/ = hhxcode; xenvii in e) 7\Gamma !

(H ] fl = hhae(xcode); ae(xenv)iig; S; ae ] fx:o/ =lg; e)

10: (H; S; ae; let x:o/ = ssi y in e) 7\Gamma ! (H; S; ae ] fx:o/ =vig; e)

where ae(y) = l and H(l) = hv1; v2i (1 ^ i ^ 2)

11: (H; S; ae; let x:o/ = x1 x2 in e0) 7\Gamma !

(H; S[ae; *x:o/: e0]; fxenv:o/env=venv; y:o/ 0=ae(x2)g; e)
where ae(x1) = l and H(l) = hhlcode; venvii and

H(lcode) = vcode[xenv:o/env; y:o/ 0]:e

12: (H; S[ae; *x:o/: e]; ae0; return x0) 7\Gamma ! (H; S; ae ] fx:o/ =ae0(x0)g; e)

Figure 7.3: Rewriting Rules for Mono-GC

CHAPTER 7. TYPES AND GARBAGE COLLECTION 129
respectively, in the context of a variable type assignment \Gamma . These judgments are derived via the conventional axioms and inference rules of Figure 7.4, ignoring the equality
primitives.

The static semantics for Mono-GC programs requires six more judgments that are
characterized as follows. I use \Psi  to range over location type assignments which map
locations to types.

\Psi  `val v : o/ v is a well-formed small value of type o/
\Psi  `hval h : o/ h is a well-formed heap value of type o/
\Psi  `heap H : \Psi  H is a well-formed heap described by \Psi 
\Psi  `env ae : \Gamma  ae is a well-formed environment described by \Gamma 
\Psi  `stack S : o/1 ! o/2 S is a well-formed stack of type o/1 ! o/2
`prog P : o/ P is a well-formed program of type o/

These judgments are defined by the inference rules and axioms of Figure 7.5. A program
has type o/ if the following requirements are met: The program's heap can be described by
\Psi  under no assumptions and is thus closed. The program's stack maps o/ 0 to o/ under the
assumptions of \Psi . The program's environment is described by \Gamma  under the assumptions
of \Psi . Finally, the program's expression has the type o/ 0 under the assumptions of \Gamma .

A heap H is described by \Psi  under the assumptions \Psi 0 if for all locations l in \Psi ,
H(l) has the type \Psi (l) under the assumptions of both \Psi  and \Psi 0. This circularity in the
definition allows cycles in the heap, in much the same way that a typing rule for fix allows
a circular definition of a recursive function. A stack has type o/1 ! o/2 if the composition
of its closure components yields a function from o/1 values to o/2 values. A closure has
type o/ 0 ! o/ if its environment has type o/env and its code has type code(o/env; o/ 0 ! o/ ).

Lemma 7.1.1 (Extension) If (H; S; ae; e) 7\Gamma ! (H0; S0; ae0; e0), then:

1. H0 = H ] H00 for some H00
2. if S = S0, then ae0 = ae ] ae00 for some ae00.

Theorem 7.1.2 (Preservation) If `prog P : o/ and P 7\Gamma ! P 0, then `prog P 0 : o/ .
Theorem 7.1.3 (Canonical Forms) Suppose `prog (H; []; ae; return x) : o/ . Then if o/
is:

ffl int, then ae(x) = i for some i.
ffl float, then ae(x) = f for some f .
ffl unit, then ae(x) = hi.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 130
Expressions:

(var) \Gamma  ] fx:o/ g `var x : o/ (var-e) \Gamma  `var x : o/\Gamma  `

exp return x : o/

(if0-e) \Gamma  `var x : int \Gamma  `exp e1 : o/ \Gamma  `exp e2 : o/\Gamma  `

exp if0 x then e1 else e2 : o/

(let-e) \Gamma  `dec d : o/

0 \Gamma  ] fx:o/ 0g `exp e : o/

\Gamma  `exp let x:o/ 0 = d in e : o/
Declarations:

(var-d) \Gamma  ] fx:o/ g `dec x : o/ (int-d) \Gamma  `dec i : int
(float-d) \Gamma  `dec f : float (unit-d) \Gamma  `dec hi : unit

(tuple-d) \Gamma  `var x1 : o/1 \Gamma  `var x2 : o/2\Gamma  `

dec hx2; x2i : ho/1 \Theta  o/2i (proj-d)

\Gamma  `var x : ho/1 \Theta  o/2i

\Gamma  `dec ssi x : o/i (1 ^ i ^ 2)

(vcode-d) fxenv:o/env; x:o/

0g `exp e : o/

\Gamma  `dec vcode[xenv:o/env; x:o/ 0]:e : code(o/env; o/ 0 ! o/ )

(close-d) \Gamma  `var xcode : code(o/env; o/ ) \Gamma  `var xenv : o/env\Gamma  `

dec hhxcode; xenvii : o/

(app-d) \Gamma  `var x1 : o/

0 ! o/ \Gamma  `var x2 : o/ 0

\Gamma  `dec x1 x2 : o/

Figure 7.4: Static Semantics of Mono-GC Expressions

CHAPTER 7. TYPES AND GARBAGE COLLECTION 131
Values:

(loc-v) \Psi  ] fl:o/ g `val l : o/ (int-v) \Psi  `val i : int

(float-v) \Psi  `val f : float (unit-v) \Psi  `val hi : unit
Heap Values:

(tuple-h) \Psi  `val v1 : o/1 \Psi  `val v2 : o/2\Psi  `

hval hv1; v2i : ho/1 \Theta  o/2i

(code-h) `dec vcode[xenv:o/env; x:o/

0]:e : code(o/env; o/ 0 ! o/ )

\Psi  `hval vcode[xenv:o/env; x:o/ 0]:e : code(o/env; o/ 0 ! o/ )

(close-h) \Psi  `val vcode : code(o/env; o/ ) \Psi  `val venv : o/env\Psi  `

hval hhvcode; venvii : o/

Heaps:

(heap) 8l 2 Dom(\Psi ):\Psi 

0 ] \Psi  `hval H(l) : \Psi (l)

\Psi 0 `heap H : \Psi 
Environments:

(env) \Psi  `val v1 : o/1 \Delta  \Delta  \Delta  \Psi  `val vn : o/n\Psi  `

env fx1:o/1=v1; \Delta  \Delta  \Delta  ; xn:o/n=vng : fx1:o/1; \Delta  \Delta  \Delta  ; xn:o/ng (x

1; \Delta  \Delta  \Delta  ; xn unique)

Stacks:

(empty-stack) \Psi  `stack [] : o/ ! o/

(push-stack) \Psi  `stack S : o/2 ! o/3 \Psi  `env ae : \Gamma  \Gamma  ] fx:o/1g ` e : o/2\Psi  `

stack S[ae; *x:o/1: e] : o/1 ! o/3

Programs:

(prog)

; `heap H : \Psi  \Psi  ` S : o/ 0 ! o/

\Psi  `env ae : \Gamma  \Gamma  ` e : o/ 0

`prog (H; S; ae; e) : o/

Figure 7.5: Static Semantics of Mono-GC Programs

CHAPTER 7. TYPES AND GARBAGE COLLECTION 132

ffl ho/1 \Theta  o/2i, then ae(x) = l and H(l) = hv1; v2i for some l, v1, and v2.
ffl code(o/env; o/1 ! o/2), then ae(x) = l and H(l) = vcode[xenv:o/env; x:o/1]:e for some l,

xenv, x, and e.

ffl o/1 ! o/2, then ae(x) = l, H(l) = hhlcode; lenvii, and

H(lcode) = vcode[xenv:o/env; x:o/1]:e;
for some l, lcode, lenv, xenv, o/env, x, and e.
Theorem 7.1.4 (Progress) If ` P : o/ , then either P = A for some answer A or else
there exists some P 0 such that P 7\Gamma ! P 0.

7.2 Abstract Garbage Collection
Since the semantics of Mono-GC makes the allocation of values explicit, I can define
what it means to "garbage collect" a value in the heap. A binding l = h in the heap
of a program is garbage if removing the binding produces an "equivalent" program. To
simplify the presentation, I will focus on programs that return an integer (i.e., are of type
int) and use Kleene equivalence to compare programs.

Definition 7.2.1 (Kleene Equivalence) P1 ' P1 means P1 + (H1; []; ae1; return x1)
iff P2 + (H2; []; ae2; return x2) and ae1(x1) = ae2(x2) = i for some integer i.

Definition 7.2.2 (Heap Garbage) If P = (H ] fl=hg; S; ae; e), and `prog P : int, then
the binding l=h is garbage in P iff P ' (H; S; ae; e) and `prog (H; S; ae; e) : int.

A collection of a well-typed program P is obtained by dropping a (possibly empty)
set of garbage bindings from the heap of P , resulting in a well-typed program P 0. This
definition is very weak in that it only allows us to drop bindings in the heap and precludes
other program transformations including modifications to the stack, environment, or
current expression. It even precludes changing a heap value to some other heap value. A
garbage collector is a rewriting rule that computes a collection of a program.

Many garbage collectors attempt to collect more garbage than is allowed by this definition by modifying the stack, the environment, or values in the heap in some simple
manner. For example, many collectors drop unneeded bindings in the current environment or environments on the stack. This technique is known as "black-holing." Some
very few collectors reclaim bindings by remapping locations from one heap value to an
already existing, equivalent heap value. This is known as hash-consing in the garbage
collection literature.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 133

However, the definition I have given accurately models what conventional garbage
collectors try to do. In fact, as I will show, the family of tracing garbage collectors,
typified by mark/sweep and copying collectors, have the nice property that they always
collect as much as this definition of garbage allows, but no more1. Consequently, tracing
collectors are optimal with respect to this definition of garbage.

Abstractly, tracing collectors simply drop bindings in the heap that are not "reachable" from the stack or the current environment. I define reachability in terms of the
free locations of program components, denoted F L(\Gamma ):

F Lval(l) = flg
F Lval(v) = ; (v = i, f , or hi)

F Lhval(hv1; v2i) = F Lval(v1) [ F Lval(v2)
F Lhval(vcode[xenv:o/env; x:o/ ]:e) = ;

F Lhval(hhvcode; venvii) = F Lval(vcode) [ F Lval(venv)

F Lheap(fl1 = h1; \Delta  \Delta  \Delta  ; ln = hng) = ([ni=1(F Lhval(hi))) n fl1; \Delta  \Delta  \Delta  ; lng

F Lenv(fx1=v1; \Delta  \Delta  \Delta  ; xn=vng) = [ni=1F Lval(vi)

F Lstack([]) = ;
F Lstack(S[ae; *x:o/: e]) = F Lstack(S) [ F Lenv(ae)

F Lprog(H; S; ae; e) = (F Lheap(H) [ F Lstack(S) [ F Lenv(ae)) n Dom(H)
A tracing collector is any collector that drops bindings in the heap but does not leave
any free locations. I represent this specification as a new rewriting rule as follows:

Definition 7.2.3 (Tracing Collector) (H ] H0; S; ae; e) trace7\Gamma ! (H; S; ae; e) if and only if
F Lprog(H; S; ae; e) = ;.

I must show that tracing garbage collection is indeed a garbage collector in that, when
given a program, it always produces a Kleene-equivalent program. The keys to a simple,
syntactic proof of correctness are Postponement and Diamond Lemmas. The statements
of these lemmas can be summarized by the diagrams of Figure 7.6, respectively, where
solid arrows denote relations that are assumed to exist and dashed arrows denote relations
that can be derived from the assumed relations.

1In an untyped setting where collections are not required to be closed programs, it is undecidable
whether or not a given binding in an arbitrary program is garbage [96, 95]. This more general notion of
garbage can be recovered in the typed setting by allowing locations to be rebound in the heap.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 134

P1 P2

P 02 P3

-trace
-trace
?

R

?

R

P1 P2

P 02 P3

-trace
-trace
?

R

?

R

Figure 7.6: Postponement and Diamond Properties
Lemma 7.2.4 (Postponement) If P1 trace7\Gamma ! P2 7\Gamma ! P3, then there exists a P 02 such that
P1 7\Gamma ! P 02 trace7\Gamma ! P3.

Lemma 7.2.5 (Diamond) If P1 trace7\Gamma ! P2 and P1 7\Gamma ! P 02, then there exists a P3 such
that P2 7\Gamma ! P3 and P 02 trace7\Gamma ! P3.

With the Postponement and Diamond Lemmas, it is straightforward to show that
tracing garbage collection does not affect evaluation.

Theorem 7.2.6 (Correctness of Tracing Collection) If P trace7\Gamma ! P 0, then P 0 is a
collection of P .

Proof: Let P = (H1 ] H2; S; ae; e) and let P 0 = (H1; S; ae; e) such that P trace7\Gamma ! P 0. I
must show P evaluates to an integer answer iff P 0 evaluates to the same integer. Suppose
P 0 + (H; []; ae0; return x) and ae0(x) = i. By induction on the number of rewriting steps
using the Postponement Lemma, I can show that P + (H ] H2; []; ae0; return x), and
clearly ae0(x) = i.

Now suppose P + (H; []; ae0; x) and ae0(x) = i. By induction on the number of rewriting
steps using the Diamond Lemma, we know that there exists a P 00 such that P 0 + P 00 and

and P 00 trace7\Gamma ! (H; []; ae0; return x). Thus, P 00 = (H ] H0; []; ae0; return x) and ae0(x) = i and
both P and P 0 compute the same answer. 2

This theorem shows that a single application of tracing collection results in a Kleeneequivalent program. A real implementation interleaves garbage collection with evaluation. Let R stand for the standard set of rewriting rules (see Figure 7.3) and let T stand
for this set with the tracing garbage collection rule. The following theorem shows that
evaluation under R and T is equivalent.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 135
Theorem 7.2.7 For all P , P +R (H; []; ae; return x) iff P +T (H0; []; ae; return x).
Proof: Clearly any evaluation under the R rules can be simulated by the T rules
simply by not performing any collection steps. Now suppose P +T (H1; []; ae1; return x1)
and ae1(x1) = i. Then there exists a finite rewriting sequence using T as follows:

P T7\Gamma ! P1 T7\Gamma ! P2 T7\Gamma ! \Delta  \Delta  \Delta  T7\Gamma ! (H1; []; ae1; return x1)
I can show by induction on the number of rewriting steps in this sequence, using the
Postponement Lemma, that all garbage collection steps can be performed at the end of
the evaluation sequence. This provides us with an alternative evaluation sequence where
all the R steps are performed at the beginning:

P R7\Gamma ! P 01 R7\Gamma ! P 02 R7\Gamma ! \Delta  \Delta  \Delta  R7\Gamma ! P 0n trace7\Gamma !

Pn+1 trace7\Gamma ! Pn+2 trace7\Gamma ! \Delta  \Delta  \Delta  trace7\Gamma ! (H1; []; ae1; return x1)

Since collection does not affect the expression part of a program and only removes bindings from the heap, P 0n = (H1 ] H2; []; ae1; return x1) for some H2. Therefore, P +R P 0n.
Thus, any evaluation under T can be simulated by an evaluation under R. 2

Finally, I can prove that tracing garbage collection is optimal with respect to my
definition of garbage in the sense that it can collect as much garbage as any other collector
can.

Theorem 7.2.8 (Tracing Collection Optimal) If P 0 is a collection of a well-typed
program P , then P trace7\Gamma ! P 0.

Proof: Let P = (H ] H0; S; ae; e) and suppose P 0 = (H; S; ae; e) is a collection of P . By
the definition of heap garbage, P 0 is well-typed. Hence, P 0 is closed and F Lprog(P 0) = ;.

Thus P trace7\Gamma ! P 0. 2

7.3 Type-Directed Garbage Collection
In the previous section, I gave a specification for tracing garbage collection as a rewriting
rule and showed that this new rewriting rule did not effect a program's evaluation. However, the rewriting rule is simply a specification and not an algorithm for computing a
collection of a program. It assumes some mechanism for partitioning the set of bindings
in the heap into two disjoint pieces, such that one set of bindings is unreachable from the
second set of bindings and the rest of the program. Real garbage collection algorithms

CHAPTER 7. TYPES AND GARBAGE COLLECTION 136
need a deterministic mechanism for generating this partitioning. In this section I formulate an abstract version of such a mechanism, the tracing garbage collection algorithm,
by lifting the ideas of mark/sweep and copying collectors to the level of program syntax.

The basic idea behind an algorithm for tracing garbage collectors is to calculate the
set of locations accessible from the current context (i.e., the environment and stack).
These locations must be preserved to keep the program closed. Next, for each location
that has been preserved, we examine the heap value to which this location is bound.
Each location within this heap value must also be preserved. We iterate this process
until all locations in the heap have been classified as accessible or inaccessible.

How do we calculate the set of locations within an environment or stack or heap
value? One approach is to deconstruct the object in question based on its abstract
syntax and simply find all of the "l" objects. However, this requires that the distinctions
between syntactic classes remain apparent at runtime. That is, we must be able to tell
l objects from f and i and hi objects and we must be able to break tuples and closures
into their components, determine which components are l objects, etc. Fundamentally,
this is a parsing problem: To deconstruct an object to find its location components, we
must leave enough markers or tags in the representation of objects to determine what
the components of the object are.

Tagging objects directly is unattractive because it can cost both space and time during computation. For example, if we tag integer and floating point values so that we
can tell them from locations, then we can no longer directly use the machine's primitive
operations, such as addition, to implement our primitive integer and floating point operations. Instead, we must strip the tag(s) from the value, apply the machine operation,
and then tag the result.

An alternative approach to tagging values is to use types to guide the process of
finding the locations in an object. In particular, by the Canonical Forms Lemma, we
know that if we have an answer of the form (H; S; ae; return x) of type ho/1 \Theta  o/2i, then x
is bound to some location l in ae. Furthermore, we know that H(l) is defined and is of
the form hv1; v2i. If o/i is a tuple type, code type, or arrow type, then we know that vi
is a location. In this fashion, given the type of an object in the heap, we can extract all
the locations in that object.

Extracting locations from closures requires a bit more cooperation from the implementation. In particular, we must assume that all closures provide sufficient information
for finding their environment components and the type of the environment. However,
once this information is in hand, we can use the type of the environment argument of
the code to determine all of the locations that are in the closure's environment.

I formalize the process of extracting locations based on types as follows. First, I define
a subset of types corresponding to heap values:

(pointer types) OE ::= ho/1 \Theta  o/2i j code(o/env; o/ ) j o/1 ! o/2

CHAPTER 7. TYPES AND GARBAGE COLLECTION 137
Next, I construct a partial function, T Lhval, that maps a location, a pointer type, and a
heap to a location type assignment. I use T L to remind the reader that we are extracting
a set of T yped Locations. Since code heap values never have free locations, the definition
of T Lhval at code types is simply the empty type assignment:

T Lhval[l:code(o/env; o/ ); H] = ;
The free locations of a tuple are those components whose types are pointer types.

T Lhval[l:hOE1 \Theta  OE2i; H ] fl=hv1; v2ig] = fv1:OE1g [ fv2:OE2g
T Lhval[l:hOE1 \Theta  o/2i; H ] fl=hv1; v2ig] = fv1:OE1g
T Lhval[l:ho/1 \Theta  OE2i; H ] fl=hv1; v2ig] = fv2:OE2g
T Lhval[l:ho/1 \Theta  o/2i; H ] fl=hv1; v2ig] = ;

The free locations of a closure include the location bound to the code and possibly the
environment value. To determine if the environment is a location and to determine its
type, we must look at the type ascribed to the environment argument of the code. If
this type is a pointer type OE, then the environment component of the closure must be a
location whose contents are described by OE.

T Lhval[l:o/1 ! o/2; H] = flcode:code(OE; o/1 ! o/2); venv:OEg

when H(l) = hhlcode; venvii
and H(lcode) = vcode[xenv:OE; x:o/1]:e:

Otherwise, if the type of the environment argument is not a pointer type, then the
environment of the closure is not a location and thus only the code pointer is in the
resulting type assignment:

T Lhval[l:o/1 ! o/2; H] = flcode:code(o/env; o/1 ! o/2)g

when H(l) = hhlcode; venvii
and H(lcode) = vcode[xenv:o/env; x:o/1]:e

The following lemma shows that T Lhval[l:\Psi (l); H] is always defined and consistent
with \Psi  whenever \Psi  describes the contents of the heap H. Thus, if we know the type
of some location, then we can always extract the pointers contained in the heap value
bound to that location.

Lemma 7.3.1 (Canonical Heap Values) If `heap H : \Psi ]fl:o/ g, then T Lhval[l:o/; H] =
\Psi h for some \Psi h and \Psi h ` \Psi  ] fl:o/ g.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 138
Proof (sketch): By examination of the heap, heap value, and small value typing rules.

2

The T Lhval function provides the functionality that we need to keep a garbage collector
running. All that remains is to extract the locations and their types from the stack and
environment of a program.

T Lenvfx1:o/1=v1; \Delta  \Delta  \Delta  ; xn:o/n=vng] = [ni=1fvi:o/i j 9OE:o/i = OEg

T Lstack([]) = ;
T Lstack(S[ae; *x:o/: e]) = T Lstack(S) [ T Lenv(ae)

With these functions in hand, I can now construct an algorithm that finds all of the
locations that must be preserved in a program. The algorithm is formulated as a rewriting
system between triples consisting of a heap, a location type assignment, and another heap,
(Hf ; \Psi ; Ht). In traditional garbage collection terminology, the first heap is termed the
"from-heap" or "from-space", the location type assignment is called the "scan-set" or
"frontier", and the second heap is called the "to-heap" or "to-space".

Initially, the from-space contains all of the bindings from the program's heap; when
the algorithm terminates, it contains those bindings that do not need to be preserved.
Correspondingly, the to-space is initially empty; when the algorithm terminates, it contains all of the bindings that must be preserved. During each step of the algorithm,
the scan-set contains the locations and their types that are bound in the from-space but
are immediately reachable from the to-space. The scan-set is initialized by finding the
locations in the current environment and stack.

The body of the algorithm proceeds as follows: a location l of type OE is removed from
\Psi . If l is bound in the from-space to a heap value, then we use T Lhval[l:OE; H] to extract
the locations contained in H(l), where H is the union of the from- and to-spaces. For
each such location l0, we check to see if l0 has already been forwarded to the to-set Ht.
Only if l0 is not bound in Ht do we add the location and its type to the scan-set \Psi .
This ensures that a variable moves at most once from the from-space to the scan-set. I
formalize this process via the following rewriting rule:

(Hf ] fl=hg; \Psi s ] fl:OEg; Ht) ) (Hf ; \Psi s [ \Psi 0s; Ht ] fl=hg)

where \Psi 0s = fl0:OE0 2 T Lhval[l:OE; Hf ] fl=hg ] Ht] j l0 62 Dom(Ht) ] flgg
Once the scan-set becomes empty, the algorithm terminates and the to-space is taken as
the new, garbage-collected heap of the program, while the from-space is discarded. The
initialization and finalization steps are captured by the following inference rule:

(H; T Lenv(ae) [ T Lstack(S); ;) )\Lambda  (Hf ; ;; Ht)

(H; S; ae; e) tr-alg7\Gamma ! (Ht; S; ae; e)

CHAPTER 7. TYPES AND GARBAGE COLLECTION 139

To prove the correctness of this garbage collection algorithm, it suffices to show that,
whenever P tr-alg7\Gamma ! P 0, then P trace7\Gamma ! P 0, since I have already shown that the tracing garbage
collection specification is correct. However, to ensure that we have a proper algorithm, I

must also show that there always exists some P 0 such that P tr-alg7\Gamma ! P 0. That is, I must
show that the algorithm does not get stuck.

I begin by establishing a set of invariants, with respect to the original program, that
are to be maintained by the algorithm. I note that if a program P = (H; S; ae; e) is welltyped, then there is a unique location type assignment \Psi P , variable type assignment \Gamma P ,
and unique types o/P and o/ 0P such that: ; `heap H : \Psi P , \Psi P `stack o/ 0P ! o/P , \Psi P `env ae : \Gamma P
and \Gamma P `exp e : o/ 0P . Hence, for a well-typed P , I write \Psi P , \Gamma P , o/P , and o/ 0P to represent
these respective objects.

Definition 7.3.2 (Well-Formedness) Let P = (H; S; ae; e) be a well-typed program.
The tuple (Hf ; \Psi s; Ht) is well-formed with respect to P iff, taking \Psi t = fl:\Psi P (l) j l 2
Dom(Ht)g and \Psi f = fl:\Psi P (l) j l 2 Dom(Hf )g:

1. Hf ] Ht = H
2. \Psi s ` \Psi f
3. \Psi s ] \Psi t `stack S : o/ 0P ! o/P
4. \Psi s ] \Psi t `env ae : \Gamma P
5. \Psi s `heap Ht : \Psi t.

Roughly speaking, the invariants ensure that: (1) all of the heap bindings are accounted for in either the from-space or the to-space and these two spaces are disjoint, (2)
the scan-set types some of the locations in the from-space and these types are consistent
with the rest of the program, (3) the scan-set coupled with the types of locations in the
to-space allow us to type the stack appropriately, (4) the scan-set coupled with the types
of locations in the to-space allow us to type the environment appropriately, and (5) the
scan-set allows us to type the to-space appropriately. The following lemma shows that
these invariants are preserved by the algorithm.

Lemma 7.3.3 (Preservation) If `prog P : o/P , (Hf ; \Psi s; Ht) is well-formed with respect
to P and (Hf ; \Psi s; Ht) ) (H0f ; \Psi 0s; H0t), then (H0f ; \Psi 0s; H0t) is well-formed with respect to
P .

Proof: Suppose (Hf ] fl=hg; \Psi s ] fl:o/ g; Ht) is well-formed with respect to P =
(H; S; ae; e) and suppose (Hf ] fl=hg; \Psi s ] fl:o/ g; Ht) ) (Hf ; \Psi s ] \Psi 0s; Ht ] fl=hg) where
\Psi 0s = fl0:o/ 0 2 T Lhval[l:o/; Hf ] fl=hg ] Ht] j l0 62 Dom(Ht)g.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 140

By condition (1), H = (Hf ] fl=hg) ] Ht thus, H = Hf ] (Ht ] fl=hg).
By condition (2), we know that l:o/ 2 \Psi P and \Psi s ` \Psi P . By the Canonical Heap
Values Lemma, T Lhval[o/ ](h) ` \Psi P . Hence, \Psi 0s ` \Psi s ] \Psi 0s ` \Psi P .

By conditions (3) and (4), taking \Psi  = (\Psi s ] fl:o/ g) ] \Psi t, we know that \Psi  `stack S :
o/ 0P ! o/P and \Psi  `env ae : \Gamma P . By condition (2) we know that l:o/ 2 \Psi P . Thus, \Psi t ] fl:o/ g
is well-formed and taking \Psi 0 = (\Psi s [ \Psi 0s) ] (\Psi t ] fl:o/ g), we have \Psi 0 `stack S : o/ 0P ! o/P
and \Psi 0 `env ae : \Gamma P .

By condition (5), \Psi s ]fl:o/ g `heap Ht : \Psi t. I must show (\Psi s [\Psi 0s) `heap Ht ]fl=hg : \Psi 0t
where \Psi t ] fl:o/ g. By the Canonical Heap Values Lemma, T Lhval[l:o/; H] `hval h : o/ , where
H = Hf ] fl=hg ] Ht. Hence, (\Psi s [ \Psi 0s) ] \Psi t `hval h : o/ . Thus, by the heap typing rule,
(\Psi s [ \Psi 0s) `heap Ht ] fl=hg : \Psi t ] fl:o/ g. 2

The following lemma shows that at each step in the algorithm, either the scan-set is
empty -- in which case the algorithm is finished -- or else the algorithm can step to a
new state.

Lemma 7.3.4 (Progress) If `prog P : o/P and (Hf ; \Psi s; Ht) is well-formed with respect
to P , then either \Psi s is empty or else (Hf ; \Psi s; Ht) ) (H0f ; \Psi 0s; H0t) for some (H0f ; \Psi 0s; H0t).

Proof: Suppose \Psi s contains the binding l:o/ and let H = Hf ] Ht. First, I must show
that l is bound to some heap value in Hf and that heap value has a shape described by
o/ . By the second requirement of well-formedness and the definition of \Psi f , we know that
\Psi f (l) = \Psi P (l) = o/ . Since `heap H : \Psi P , by the Canonical Heap Values Lemma, we know
that H(l) = h for some h, T Lhval[l:o/; H] = \Psi h, and \Psi h ` \Psi P . By the definition of \Psi f
and the first requirement of well-formedness, the binding l=h must be in Hf .

Taking \Psi 00s = fl0:o/ 0 2 \Psi h j l0 62 Dom(Ht)g, I must now show that (\Psi s n fl:o/ g) [ \Psi 00s
is a valid location type assignment. But since \Psi h ` \Psi P , then \Psi 00s ` \Psi P . By the second
requirement of well-formedness, \Psi s ` \Psi f ` \Psi P , so (\Psi s n fl:o/ g) [ \Psi 00s is well formed as a
subset of \Psi P .

Finally, since Hf and Ht are disjoint but cover H, l cannot be bound in Ht and hence
Ht ] fl=hg is well-formed. Thus, taking H0f = Hf n fl=hg, \Psi 0s = \Psi s n fl:o/ g [ \Psi 00s , and
H0t = Ht ] fl=hg, we know that (Hf ; \Psi s; Ht) ) (H0f ; \Psi 0s; H0t). 2

With the Preservation and Progress Lemmas in hand, I can establish the correctness
of the algorithm.

Theorem 7.3.5 (Tracing Algorithm Correctness) If P is well-typed, then there exists a P 0 such that P tr-alg7\Gamma ! P 0 and P ' P 0.

Proof: Let P = (H; S; ae; e). First, I must show that (H; T Lenv(ae) [ T Lstack(S); ;)
exists and is well-formed with respect to P . Since the to-space is empty, conditions one

CHAPTER 7. TYPES AND GARBAGE COLLECTION 141
and five of well-formedness are trivially satisfied. By the env typing rule, it is clear that
T Lenv(ae) exists and is a subset of \Psi P . By the stack typing rules and the env typing rule,
it is clear that T Lstack(S) exists and is a subset of \Psi P . Hence, T Lenv(ae) [ T Lstack(S) is
a well-formed location type assignment that is a subset of \Psi P . Furthermore, it is clear
that all of the free locations in both the stack and environment are contained in this
location type assignment. Hence, conditions two, three, and four are satisfied and the
initial tuple is well-formed with respect to P .

Since (H; T Lenv(ae) [ T Lstack(S); ;) is well-formed, by progress, the algorithm will
continue to run until the scan-set is empty, at which point the algorithm terminates
in the state (Hf ; ;; Ht). By preservation, we know that this tuple is well-formed with
respect to P . Hence, we know that, taking \Psi t = fl:o/ j l 2 \Psi P g, \Psi t `stack S : [o/ 0P ] ! o/P ,
\Psi t `env ae : \Gamma P , and `heap Ht : \Psi t. Consequently, the program P 0 = (Ht; S; ae; e) is

closed and thus P trace7\Gamma ! P 0. By the correctness of the tracing specification, we know that
P ' P 0. Thus, P 0 is a collection of P . 2

Finally, the tracing algorithm that I have presented is optimal with respect to my
definition of garbage.

Theorem 7.3.6 Let P tr-alg7\Gamma ! (H1; S; ae; e). If (H2; S; ae; e) is a collection of P then H1 `
H2.

Proof: By theorem 7.2.8, it suffices to show that if P trace7\Gamma ! P 0 where P 0 = (H2; S; ae; e),
then H1 ` H2. Let l=h be a binding in H1. I must show that this binding is also in
H2. I do so by analyzing how l is placed in the scan set and hence forwarded from the
from-space to the to-space during the execution of the tracing algorithm.

If l is placed in the initial scan-set, then l occurs free in either the range of ae or else
the range of the environment of some closure on the stack. Hence, l must be bound in
H2 to keep P 0 closed.

Suppose l is is placed in the scan-set because it is found via T Lhval[o/ 0](h) for some
l0:o/ 0 already in the scan-set. The binding, l0=h0 is forwarded to the to-space. Therefore,
h0 is in the range of H2. But then F Lhval(h0) contains l. Thus, for P 0 to be closed, H2
must contain the binding for l. 2

7.4 Generational Collection
The tracing garbage collection algorithm I presented in the previous section examines
all of the reachable bindings in the heap to determine that the rest of the bindings may
be removed. By carefully partitioning the heap into smaller heaps, a garbage collector
can scan less than the whole heap and still free significant amounts of memory. A

CHAPTER 7. TYPES AND GARBAGE COLLECTION 142
generational partition of a program's heap is a sequence of sub-heaps ordered in such a
way that "older" generations never have pointers to "younger" generations.

Definition 7.4.1 (Generational Partition) A generational partition of a heap H is
a sequence of heaps H1; H2; : : : ; Hn such that H = H1 ] H2 ] \Delta  \Delta  \Delta  ] Hn and for all i such
that 1 ^ i ! n, F Lheap(Hi) " Dom(Hi+1 ] Hi+2 ] \Delta  \Delta  \Delta  ] Hn) = ;. The Hi are referred to
as generations and Hi is said to be an older generation than Hj if i ! j.

Given a generational partition of a program's heap, a tracing garbage collector can
eliminate a set of bindings in younger generations without looking at any older generations.

Theorem 7.4.2 (Generational Collection) Let H1; : : : ; Hi; : : : ; Hn be a generational
partition of the heap of P = (H; S; ae; e). Suppose Hi = (H1i ] H2i ) and Dom(H2i ) "

F Lprog(H1i ] Hi+1 ] \Delta  \Delta  \Delta  ] Hn; S; ae:\Gamma ; e) = ;. Then P trace7\Gamma ! (H n H2i ; S; ae; e).

Proof: I must show that Dom(H2i ) " F Lprog(H n H2i ; S; ae; e) = ;. Since H1; \Delta  \Delta  \Delta  ; Hn is a
generational partition of H, for all j, 1 ^ j ! i, F Lheap(Hj ) " Dom(Hj+1 ] \Delta  \Delta  \Delta  ] Hn) = ;.
Hence, F Lheap(H1 ] \Delta  \Delta  \Delta  ] Hi\Gamma 1) " Dom(H2i ) = ;. Now,

F Lprog(H n H2i ; S; ae; e) " Dom(H2i )
= (F Lheap(H n H2i ) [ F Lstack(S) [ F Lenv(ae) [ F Lexp(e)) " Dom(H2i )
= (F Lheap(H1 ] \Delta  \Delta  \Delta  ] Hi\Gamma 1) [ F Lheap(H1i ] \Delta  \Delta  \Delta  ] Hn)[

F Lstack(S) [ F Lenv(ae) [ F Lexp(e)) " Dom(H2i )
= (F Lheap(H1 ] \Delta  \Delta  \Delta  ] Hi\Gamma 1) " Dom(H2i ))[

((F Lheap(H1i ] \Delta  \Delta  \Delta  ] Hn) [ F Lstack(S) [ F Lenv(ae) [ F Lexp(e)) " Dom(H2i ))
= ; [ ((F Lheap(H1i ] \Delta  \Delta  \Delta  ] Hn) [ F Lstack(S) [ F Lenv(ae) [ F Lexp(e)) " Dom(H2i ))
= F Lprog(H1i ] \Delta  \Delta  \Delta  ] Hn; S; ae; e) " Dom(H2i )
= ;

2
Generational collection is important for three practical reasons: first, evaluation of
programs makes it easy to maintain generational partitions.

Theorem 7.4.3 (Generational Preservation) Let P = (H; S; ae; e) be a well-typed
program. If H1; : : : ; Hn is a generational partition of H and P 7\Gamma ! (H ] H0; S; ae; e), then
H1; : : : ; Hn; H0 is a generational partition of H ] H0.

Proof: The only evaluation rules that modify the heap are the rules that allocate tuples
and closures. The other rules leave the heap intact and hence preserve the partition
trivially. Since the allocation rules only add a binding to the heap and do not modify the

CHAPTER 7. TYPES AND GARBAGE COLLECTION 143
rest of the heap, all I must show is that there are no references in the older generations to
this new location. But this must be true since a new location is chosen for the allocated
heap value. 2

Clearly, the addition of certain language features such as assignment or memoization
breaks the Generational Preservation Theorem. The problem with these features is that
bindings in the heap can be updated so that a heap value in an older generation contains
a reference to a location in a younger generation. It is possible to maintain a generational
partition for such languages by keeping track of all older bindings that are updated and
by moving them from the older generation to a younger generation. The mechanism that
tracks updates to older generations is called a write barrier. Wilson's overview provides
many examples of techniques used to implement write barriers [128].

The second reason generational collection is important is that, given a generational
partition, we can directly use the tracing collection algorithm to generate a generational
collection of a program.

The following generational collection rule starts simply forwards the entire older generation at the beginning of the algorithm and then processes the younger generation.

H1; H2 a generational partition
(H2; fl:o/ 2 T Lstack(S) [ T Lenv(ae) j l 62 Dom(H1)g; H1) ) (Hf ; ;; H1 ] H02)

(H1 ] H2; S; ae; e) gen-alg7\Gamma ! (H1 ] H02; S; ae; e)
The rule's soundness follows directly from the Generational Collection Theorem, as well
as the soundness of the tracing collection algorithm.

The third reason generational collection is important is that empirical evidence shows
that "objects tend to die young" [120]. That is, recently allocated bindings are more likely
to become garbage in a small number of evaluation steps. Thus, if we place recently
allocated bindings in younger generations, we can concentrate our collection efforts on
these generations, ignoring older generations, and still eliminate most of the garbage.

7.5 Polymorphic Tag-Free Garbage Collection
In this section, I show how to apply type-based, tag-free garbage collection to a *MLi -based
language called *MLi -GC. It is possible to give a low-level operational semantics for *MLi
in the style of Mono-GC, where environments and the stack are made explicit. However,
the type structure of *MLi is considerably more complex than for Mono-GC, and as a
result, proving even relatively basic properties, such as type preservation, is considerably
more difficult than in the simply-typed setting. Consequently, I use a somewhat higherlevel semantics to describe evaluation of *MLi -GC programs. This semantics is a cross
between the contextual rewriting semantics used in earlier chapters and the allocation

CHAPTER 7. TYPES AND GARBAGE COLLECTION 144

(kinds) ^ ::= \Omega  j ^1 ! ^2
(con) _ ::= (* :: ^)
(raw con) * ::= t j u j Arrow(_1; _2) j *t::^:_ j _1 _2 j Typerec _ of (_i; _a)
(small con) u ::= l j Int
(heap con) q ::= Arrow(u1; u2) j *t::^:_
(con heap) Q ::= fl1=q1; \Delta  \Delta  \Delta  ; ln=qng

(types) oe ::= T (_) j int j oe1 ! oe2 j 8t::^:oe
(norm types) & ::= int j oe1 ! oe2 j 8t::^:oe

(exp) e ::= x j (v : &) j (r : oe)
(raw exp) r ::= *x:oe:e j e1 e2 j \Lambda t::^:e j e [_] j typerec _ of [t:oe](ei; ea)
(small val) v ::= i j l
(heap val) h ::= *x:oe:e j \Lambda t::^:e
(val heap) H ::= fl1=h1; \Delta  \Delta  \Delta  ; ln=hng

(program) P ::= (Q; H; e)
(answer) P ::= (Q; H; v:&)

Figure 7.7: Syntax of *MLi -GC

semantics of Mono-GC. Heaps are left explicit, but the stack and environments are
implicitly represented by evaluation contexts and meta-level substitution of small values
for variables. The resulting system abstracts enough details that proofs are tractable,
yet exposes the key issues of tag-free collection.

7.5.1 *MLi -GC
The syntax of *MLi -GC is given in Figure 7.7. Programs consist of two heaps and an
expression. The Q heap maps locations to constructor heap values, whereas the H
heap maps locations to expression heap values. In practice, one heap suffices for both
constructors and expressions, but making a distinction simplifies the static semantics for
the language. I assume that the constructor heap of a program contains no cycles (this
is reflected in the static semantics below), but make no such assumption regarding the
expression heap. The expression of the program can refer directly to locations bound in
the heaps, instead of indirecting through an environment. As with Mono-GC, I consider

CHAPTER 7. TYPES AND GARBAGE COLLECTION 145
programs to be equivalent up to reordering and ff-conversion of locations bound in the
heap and variables bound in constructors and expressions.

Each raw constructor * is labelled with its kind, and almost all raw expressions
are labelled with types. This information corresponds to the kind or type information
that would be present on bound variables of a let-expression in an A-normal form.
By labelling nested computations with kind or type information at compile time, we
effectively assign kinds/types to any intermediate values allocated during computation.
Constructor values and expression values in the heaps are not paired with summary kind
or type information; this information is recovered during garbage collection from the
information labelling computations.

During garbage collection, we need to determine shape information concerning values
found in computations from the kinds and types labelling these values. Unfortunately,
it is not always possible to determine an expression value's shape from its type. In
particular, if the type is of the form T (_) where _ is some constructor computation,
then we must "run" the computation to reach at least a head-normal form, either Int or
Arrow(_1; _2), in order to determine the shape of the object2. But running this constructor computation during garbage collection is problematic because the computation may
need to allocate values. It seems as though to free storage, we must garbage collect, but
to garbage collect, we might need to allocate more storage.

The solution to this problem is to "run" the necessary constructors within types
during evaluation and ensure that all needed types are always in head-normal form when
garbage collection is invoked. This constraint is reflected in the syntax of *MLi -GC by the
fact that only & types (types in head-normal form) can label small values. The evaluation
rules for *MLi -GC (see below) ensure that this constraint is maintained at all times. In
particular, small values and their normalized type labels are substituted for free variables
during evaluation. In the TIL compiler (see Chapter 8), this constraint is maintained by
explicitly reifying type computations and by labelling variables of unknown shape with
a reified type. If *MLi did not have a phase distinction between types and terms (i.e., if
types were dependent upon terms in some fashion), then we could not guarantee that all
needed types would be computed before garbage collection was invoked.

Figure 7.8 gives the evaluation contexts and instructions for the constructors, types,
and terms of *MLi -GC, and Figures 7.9, and 7.10 give the rewriting rules for the language.
As in Mono-GC, large values are allocated on the heap and replaced with a reference to
the appropriate location. Unlike Mono-GC, I use evaluation contexts to determine the
next instruction instead of relying upon an A-normal form to provide explicit sequencing
and a stack to represent the continuation. Furthermore, I use meta-level substitution
of small values for variables at function application, instead of installing these values in

2Head-normal forms are not always sufficient to determine shape. For example, components of pair
types must also be normalized so that we can determine which components of the pair are locations.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 146

(con ctxt) U ::= [] j (N :: ^)
(raw ctxt) N ::= Arrow(U; _) j Arrow(u::^; U ) j U _ j (u::^) U j

Typerec U of (_i; _a)
(con instr) J ::= Arrow(u1::^1; u2::^2) j *t::^:_ j (l::^1) (u2::^2) j

Typerec (u::^) of (_i; _a)

(type instr) K ::= T (u::^) j T (U [J ::^])
(exp ctxt) E ::= [] j (R : oe)
(raw ctxt) R ::= E e j (l:&) E j E [_]
(exp instr) I ::= (*x:oe:e) : K j (*x:oe:e) : & j (\Lambda t::^:e) : & j ((l:&) (v:& 0)) : oe j

((l:&) U [J ::^]) : oe j ((l:&) [u::^]) : oe j
(typerec U [J ::^] of [t:oe0](ei; ea)) : oe j
(typerec (u::^) of [t:oe0](ei; ea)) : oe j

Figure 7.8: *MLi -GC Evaluation Contexts and Instructions

an environment. This avoids the need to assume closure conversion, greatly simplifying
both the dynamic and static semantics for the language.

Note that evaluation of *-expressions at the term level proceeds in two stages: first,
the type labelling the expression is evaluated. Second, the *-expression is bound to a
new location on the heap and is replaced with this location within the expression. There
is no need to evaluate the type labelling a \Lambda -expression, since this type must always
begin with 8 and hence is already in head-normal form. The rest of the rewriting rules
are fairly standard and reflect the left-to-right, call-by-value evaluation strategy of the
language.

It is fairly easy to see that evaluation of *MLi -GC programs preserves the cycle-freedom
of the constructor heap and that, given a cycle-free expression heap, evaluation preserves
cycle-freedom.

7.5.2 Static Semantics of *MLi -GC
In the description of the static semantics for *MLi -GC, I use the following meta-variables
to range over various sorts of assignments, mapping variables or locations to kinds and

CHAPTER 7. TYPES AND GARBAGE COLLECTION 147

1: (Q; Arrow(u1::^1; u2::^2) :: ^) 7\Gamma ! (Q ] fl=Arrow(u1; u2)g; l::^)
2: (Q; (*t::^1:_) :: ^) 7\Gamma ! (Q ] fl=*t::^1:_g; l::^)
3: (Q; (l::^1) (u::^2)) 7\Gamma ! (Q; fu=tg_) (Q(l) = *t::^:_)
4: (Q; (Typerec (Int::^0) of (_i; _a)) :: ^) 7\Gamma ! (Q; _i)
5: (Q; (Typerec (l::^0) of (_i; _a)) :: ^) 7\Gamma !

(Q; ((((_a (u1::\Omega ) :: \Omega  ! ^ ! ^ ! ^)

(u2::\Omega ) :: ^ ! ^ ! ^)
(Typerec (u1::\Omega ) of (_i; _a) :: ^) :: ^ ! ^)
(Typerec (u2::\Omega ) of (_i; _a) :: ^)) :: ^) (Q(l) = Arrow(u1; u2))

6: (Q; J ::^) 7\Gamma ! (Q

0; _)

(Q; U [J ::^]) 7\Gamma ! (Q0; U [_])

7: (Q; T (Int::^)) 7\Gamma ! (Q; int)
8: (Q; T (l::\Omega )) 7\Gamma ! (Q; T (u1::^1) ! T (u2::^2)) (Q(l) = Arrow(u1; u2))

9: (Q; J ::^) 7\Gamma ! (Q

0; _)

(Q; S[T (U [J ::^])]) 7\Gamma ! (Q0; S[T (U [_])])

Figure 7.9: *MLi -GC Constructor and Type Rewriting Rules

CHAPTER 7. TYPES AND GARBAGE COLLECTION 148

10: (Q; K) 7\Gamma ! (Q

0; oe)

(Q; H; (*x:oe0:e) : K) 7\Gamma ! (Q; H; (*x:oe0:e) : oe)

11: (Q; H; (*x:oe:e) : &) 7\Gamma ! (Q; H ] fl=*x:oe:eg; l:&)
12: (Q; H; (\Lambda t::^:e) : &) 7\Gamma ! (Q; H ] fl=\Lambda t::^:eg; l:&)
13: (Q; H; ((l:&1) (v:&)) : oe) 7\Gamma ! (Q; H; f(v:&)=xge) (H(l) = *x:oe0:e)

14: (Q; U [J ::^]) 7\Gamma ! (Q

0; U [_])

(Q; H; ((l:&) U [J ::^]) : oe) 7\Gamma ! (Q0; H; ((l:&) U [_]) : oe)

15: (Q; H; ((l:&1) (u::^)) : oe) 7\Gamma ! (Q; H; fu=tge) (H(l) = \Lambda t::^:e)

16: (Q; U [J ::^]) 7\Gamma ! (Q

0; U [_])

(Q; H; (typerec U [J ::^] of [t:oe0](ei; ea)) : oe) 7\Gamma !

(Q0; H; (typerec U [_] of [t:oe0](ei; ea)) : oe)

17: (Q; H; (typerec (Int::^] of [t:oe0](ei; ea)) : oe) 7\Gamma ! (Q; H; ei)
18: (Q; H; (typerec (l::^) of [t:oe0](ei; ea)) : oe) 7\Gamma !

(Q; H; ((((((ea (u1::\Omega )) : 8t2::\Omega :fu1=tgoe0 ! ft2=tgoe0 ! oe)

(u2::\Omega )) : fu1=tgoe0 ! fu2=tgoe0 ! oe
((typerec (u1::\Omega ) of [t:oe0](ei; ea)) : fu1=tgoe0) : fu2=tgoe0 ! oe))
((typerec (u2::\Omega ) of [t:oe0](ei; ea)) : fu2=tgoe0)) : oe) (Q(l) = Arrow(u1; u2))

19: (Q; H; I : oe) 7\Gamma ! (Q

0; H0; e)

(Q; H; E[I : oe]) 7\Gamma ! (Q0; H0; E[e])

Figure 7.10: *MLi -GC Expression Rewriting Rules

CHAPTER 7. TYPES AND GARBAGE COLLECTION 149
types:

(variable kind assignment) \Delta  ::= ft1::^1; \Delta  \Delta  \Delta  ; tn::^ng
(variable type assignment) \Gamma  ::= fx1:oe1; \Delta  \Delta  \Delta  ; xn:oeng
(location kind assignment) \Pi  ::= fl1::^1; \Delta  \Delta  \Delta  ; ln::^ng
(location type assignment) \Psi  ::= fl1:&1; \Delta  \Delta  \Delta  ; ln:&ng

In addition I use \Phi  to range over maps from locations to both kinds and heap constructor
values:

\Phi  ::= fl1::^1=q1; \Delta  \Delta  \Delta  ; ln::^n=qng

Given an assignment \Phi , I use Q\Phi  and \Pi \Phi  to represent the heap and location kind assignment implicit in \Phi .

The formation judgments for *MLi -GC are as follows:

1: \Pi ; \Delta  ` * :: ^ constructor formation
2: \Pi  ` q :: ^ constructor heap value formation
3: \Pi  ` Q :: \Pi 0 constructor heap formation
4: \Pi  ` \Phi  kind and constructor assignment formation

5: \Pi ; \Delta  ` oe type formation
6: \Pi  ` \Psi  location type assignment formation
7: \Pi ; \Delta  ` \Gamma  variable type assignment formation

8: \Phi ; \Psi ; \Delta ; \Gamma  ` e : oe expression formation
9: \Phi ; \Psi  ` h : oe heap value formation
10: \Phi ; \Psi 0 ` H : \Psi  heap formation
11: ` (Q; H; e) : oe program formation

The axioms and inference rules that allow us to derive these judgments are largely standard, so I will only provide a high-level overview. For judgments 1-7, \Pi  tracks the kind of
all free locations in the given constructor, constructor heap value, constructor heap, type,
or assignment. For constructors and types, \Delta  tracks the kind of free type variables. The
lack of \Delta  in the judgments 3-4 indicates that there can be no free type variables, only
free locations within constructor heaps. Constructor heap formation consists of an axiom
and an inference rule that allow us to construct heaps inductively, thereby ensuring the
heap has no cycles:

\Pi  ` ; : ; \Pi 

0 ` Q :: \Pi  \Pi 0 ] \Pi  ` q :: ^

\Pi 0 ` Q ] fl=qg :: \Pi  ] fl::^g
A kind and constructor assignment \Phi  is well-formed with respect to \Pi  if \Pi  ` Q\Phi  :: \Pi \Phi .

Judgments 8-9 require more information than simply the kinds of free locations. This
is because we must treat constructor locations as transparent type variables in order to

CHAPTER 7. TYPES AND GARBAGE COLLECTION 150
recover the same definitional equivalence that we have in a totally substitution-based
semantics. For example, if l1 is bound to Arrow(u1; u2), then we must consider l1 to
be equivalent to Arrow(u1; u2). Therefore, equivalence of both constructors and types is
given with respect to a kind and constructor assignment \Phi :

12: \Phi ; \Delta  ` _ j _0 :: ^ constructor equivalence
13: \Phi ; \Delta  ` oe j oe0 type equivalence

The axioms and inference rules that allow us to conclude two constructors or types are
equivalent are standard (see Chapter 3) with the addition of two axioms governing the
transparency of locations:

\Phi  ] fl::\Omega =Arrow(u1; u2)g; \Delta  ` l::\Omega  j (Arrow(u1::\Omega ; u2::\Omega )::\Omega ) :: \Omega 

\Phi  ] fl::^=*t::^0:_g; \Delta  ` l::^ j ((*t::^0:_)::^) :: ^
I claim that orienting these equivalences to the right yields a reduction system for constructors (and hence types) that is both locally confluent and strongly normalizing if \Phi 
has no cycles, which is true when \Phi  is well-formed. It should be fairly straightforward to
extend the proofs of Chapter 4 to show that this claim is true.

Judgment 11, program formation, is determined by the following rule:

; ` \Phi  \Phi ; ; ` H : \Psi 

\Phi ; \Psi ; ;; ; ` e : oe

` (Q\Phi ; H; e) : oe

The rule requires that the constructor heap be well-formed and described by \Phi , that the
expression heap be well-formed and described by \Psi  under the assumptions of \Phi , and that
the expression be well-formed with type oe under the assumptions \Phi  and \Psi . Note that
all components must be closed with respect to type and value variables.

Given unique normal forms for types, it is straightforward to define a suitable notion of
normal derivation for *MLi -GC programs and hence show that type checking is decidable.
With the normal derivations in hand, it should be fairly straightforward to prove both
preservation and progress, as in Chapter 4.

Proposition 7.5.1 (Preservation) If ` (Q; H; e) : oe and (Q; H; e) 7\Gamma ! (Q0; H0; e0),
then ` (Q0; H0; e0) : oe.

Proposition 7.5.2 (Progress) If ` P : oe, then either P is an answer or else there
exists a P 0 such that P 7\Gamma ! P 0.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 151
7.5.3 Garbage Collection and *MLi -GC
The definitions of garbage and garbage collection for *MLi -GC are essentially the same as
for Mono-GC, except that I want to eliminate garbage bindings in both the constructor
and the expression heaps. Assuming F L calculates all of the free locations of a program,
then the tracing collection specification for *MLi -GC is simply:

F L(Q1; H1; e) = ;
(Q1 ] Q2; H1 ] H2; e) trace7\Gamma ! (Q1; H1; e)

It is easy to prove the diamond and postponement lemmas hold with respect to this
trace step and any other rewriting rule of *MLi -GC. From this, we can conclude that the
tracing collection specification is a sound garbage collection rule.

In the rest of this section, I will present a type-based, tag-free collection algorithm
and give a proof sketch that it is sound by showing that any garbage it collects can also
be collected by the tracing specification.

Before giving the collection algorithm, I need to define some auxiliary functions that
extract the range of the constructor and value environments of an abstraction. Since
*MLi -GC uses meta-level substitution, these environments are not immediately apparent.
Therefore, these auxiliary functions must deconstruct terms based on abstract syntax
to find these values. In a lower-level model, as with Mono-GC, where environments are
explicit, no such processing of terms is required.

The ConEnv function maps a constructor _ to a location kind assignment \Pi , by
extracting all of the locations (and their kinds) within the constructor:

ConEnv(t :: ^) = ;
ConEnv(Int :: ^) = ;
ConEnv(l :: ^) = fl::^g
ConEnv(Arrow(_1; _2) :: ^) = ConEnv(_1) [ ConEnv(_2)
ConEnv((*t::^1:_) :: ^) = ConEnv(_)
ConEnv((Typerec _1 of (_i; _a)) :: ^) = ConEnv(_) [ ConEnv(_i) [ ConEnv(_a)

The TypeEnv function maps a type oe to a location kind assignment \Pi :

TypeEnv(T (_)) = ConEnv(_)
TypeEnv(int) = ;
TypeEnv(oe1 ! oe2) = TypeEnv(oe1) [ TypeEnv(oe2)
TypeEnv(8t::^:oe) = TypeEnv(oe)

Finally, the ExpEnv function maps an expression e to both a location kind assignment
\Pi  and a location type assignment \Psi . In the definition of the function, I use h\Pi 1; \Psi 1i [

CHAPTER 7. TYPES AND GARBAGE COLLECTION 152
h\Pi 2; \Psi 2i to abbreviate h\Pi 1 [ \Pi 2; \Psi 1 [ \Psi 2i.

ExpEnv(x) = h;; ;i
ExpEnv(v:int) = h;; ;i
ExpEnv(l:oe1 ! oe2) = hTypeEnv(oe1 ! oe2); fl:oe1 ! oe2gi
ExpEnv(l:8t::^:oe) = hTypeEnv(oe); fl:8t::^:oegi
ExpEnv((*x:oe0:e) : oe) = hTypeEnv(oe) [ TypeEnv(oe0); ;i [ ExpEnv(e)
ExpEnv((e1 e2) : oe) = hTypeEnv(oe); ;i [ ExpEnv(e1) [ ExpEnv(e2)
ExpEnv((\Lambda t::^:e) : oe) = hTypeEnv(oe); ;i [ ExpEnv(e)
ExpEnv((e1 [_]) : oe) = hTypeEnv(oe) [ ConEnv(_); ;i [ ExpEnv(e)

ExpEnv((typerec _ of [t:oe0](ei; ea)) : oe) =

hTypeEnv(oe) [ TypeEnv(oe0) [ ConEnv(_); ;i [ ExpEnv(ei) [ ExpEnv(ea)

Note that, once a small value is reached, we can use type information to determine the
shape of the value. For instance, when processing a small value v labelled with int,
we know that v must be an integer i. Hence, we continue to use type information to
determine the shape of small values and heap values, just as I did in the tag-free collection
of Mono-GC.

The following lemma shows that the ConEnv and TypeEnv functions extract appropriate kind assignments from well-formed constructors and types.

Lemma 7.5.3

1. If \Pi ; \Delta  ` (* :: ^), then ConEnv(* :: ^) = \Pi 0 for some \Pi 0 and \Pi 0 ` \Pi  and \Pi 0; \Delta  `

(* :: ^).

2. If \Pi ; \Delta  ` oe, then TypeEnv(oe) = \Pi 0 for some \Pi 0 and \Pi 0 ` \Pi  and \Pi 0; \Delta  ` oe.
Proof (sketch): Simple induction on * and oe, using the syntax-directedness of the
formation rules. The fact that \Pi 0 ` \Pi  ensures that the inductive hypotheses can be
unioned to form a consistent kind assignment. 2

The next lemma shows that we can strengthen the assumptions regarding the equivalence of two constructors or two types, as long as the strengthened assumptions are
closed and cover the free locations of the constructors or types.

Lemma 7.5.4

1. If \Phi ; \Delta  ` _1 j _2 :: ^, \Phi 0 ` \Phi , ; ` \Phi 0, \Pi \Phi 0 ; \Delta  ` _1, and \Pi \Phi 0 ; \Delta  ` _2, then

\Phi 0; \Delta  ` _1 j _2 :: ^.

2. If \Phi ; \Delta  ` oe1 j oe2, \Phi 0 ` \Phi , ; ` \Phi 0, \Pi \Phi 0; \Delta  ` oe1, and \Pi \Phi 0; \Delta  ` oe2, then \Phi 0; \Delta  ` oe1 j

oe2 :: ^.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 153
Proof (sketch): By induction on the derivation of \Phi ; \Delta  ` _1 j _2 :: ^ and \Phi ; \Delta  ` oe1 j
oe2. 2

Next, I argue that if e has type oe under \Phi ; \Psi ; \Delta ; \Gamma , then ExpEnv(e) exists and is some
h\Pi 0; \Psi 0i "consistent" with \Phi  and \Psi . Here, consistent means that, if we start with a subset
of \Phi  containing all of the locations bound in \Pi 0, extend this subset so that it is closed
and covers all of the free locations in \Gamma  and oe yielding \Phi 0, then \Phi 0; \Psi 0; \Delta ; \Gamma  is sufficient
to show that e has type oe.

Lemma 7.5.5 If \Phi ; \Psi ; \Delta ; \Gamma  ` e : oe, then ExpEnv(e) = h\Pi 0; \Psi 0i and:

1. \Pi 0 ` \Pi \Phi ,
2. \Psi 0 ` \Psi ,
3. If \Phi 0 ` \Phi , such that Dom(\Pi 0) ` Dom(\Phi 0), \Pi \Phi  ` \Psi 0, \Pi \Phi ; \Delta  ` \Gamma , \Pi \Phi ; \Delta  ` oe, and

` \Phi 0, then \Phi 0; \Psi 0; \Delta ; \Gamma  ` e : oe.

Proof (sketch): The proof proceeds by induction on e and relies upon the fact that each
typing derivation has a normal form that interleaves non-equiv rules with equiv rules.
The preconditions of part 3 coupled with the previous lemma are sufficient to show that,
for every application of the equiv step, the two types in question are equivalent under
the strengthened assumptions. Parts 1 and 2 are needed to show that the union of the
assumptions for the inductive hypotheses are well-formed contexts. 2

Using ConEnv, TypeEnv, and ExpEnv, I can now define functions to extract the locations and their types or kinds from heap values based on kinds or types. The definitions
of these functions are similar to the various T L functions of Mono-GC, given in Section
7.3. The function KL is a partial function that takes a kind ^ and a constructor heap
value q and returns the set of free locations in q as well as their kinds.

KL[\Omega ](Arrow(u1; u2)) = ConEnv(u1::\Omega ) [ ConEnv(u2::\Omega )
KL[^1 ! ^2](*t::^1:_) = ConEnv(*t::^1:_)

Similarly, the function T L is a partial function that takes a head-normal type & and a
heap value h and returns the set of free locations in h as well as their kinds or types.

T L[oe1 ! oe2](*x:oe0:e) = ExpEnv((*x:oe0:e) : oe1 ! oe2)
T L[8t::^:oe](\Lambda t::^:e) = ExpEnv((\Lambda t::^:e) : 8t::^:oe)

As for Mono-GC, I express garbage collection as a set of rewriting rules between tuples.
I begin by defining a rewriting system that only operates on constructor heaps. For this
system, tuples are of the form (Qf ; \Pi s; Qt) where Qf is the constructor from-space, \Pi s

CHAPTER 7. TYPES AND GARBAGE COLLECTION 154
is the scan-set describing the kinds of all constructors in the from-space reachable from
the to-space, and Qt is the to-space. The rewriting rule for constructors is simply:

(Qf ] fl=qg; \Pi s ] fl::^g; Qt) ) (Qf ; \Pi s [ \Pi 0s; Qt ] fl=qg)

where \Pi 0s = fl0::^0 2 KL[^](q) j l0 62 Dom(Qt) ] flgg
If a location l, described by ^ is in the scan-set and l is bound to the heap value q in the
from-space, then we forward the binding l=q to the to-space and add any free location
in q and its kind to the scan-set, unless the location has already been forwarded to the
to-space.

The following definition gives the essential invariants of the constructor garbage collection rewriting system:

Definition 7.5.6 (Constructor GC Well-Formedness) (Qf ; \Pi s; Qt) is well-formed
with respect to \Phi  iff:

1. ; ` Qf ] Qt :: \Phi ,
2. \Pi s ` \Pi \Phi ,
3. Dom(\Pi s) ` Dom(Qf ),
4. \Pi s ` Qt :: \Pi t, where \Pi t = fl::^ 2 \Pi \Phi  j l 2 Dom(Qt)g.
It is straightforward to prove that constructor well-formedness is preserved by the rewriting system and that progress is always possible for well-formed tuples.

Lemma 7.5.7 (Constructor GC Preservation) If T is well-formed with respect to
\Phi  and T ) T 0, then T 0 is well-formed with respect to \Phi .

Proof (sketch): Follows from the invariants and lemma 7.5.3 (1). The argument is
similar to the preservation argument for Mono-GC (see lemma 7.3.3). 2

Lemma 7.5.8 (Constructor GC Progress) If T = (Qf ; \Pi s; Qt) is well-formed with
respect to \Phi , then either \Pi s is empty or else there exists a T 0 such that T ) T 0.

Proof: Suppose \Pi s = \Pi 0s ] fl::^g. By the second condition of well-formedness, we
know that \Pi \Phi (l) = ^. By the third condition, we know that Qf = Q0f ] fl=qg for
some Q0f and q. By the first condition, we know that \Pi \Phi  ` q::^. Hence, KL[^](q)
is defined and by lemma 7.5.3, KL[^](q) ` \Pi \Phi . Thus, \Pi 0s [ \Pi 00s is well-formed where
\Pi 00s = fl0::^0 2 KL[^](q) j l0 62 Dom(Qt) ] flgg. Therefore, T ) (Qf ; \Pi 0s [ \Pi 00s ; Qt ] fl=qg).

2

CHAPTER 7. TYPES AND GARBAGE COLLECTION 155

Since the size of the from-space always decreases with each step, it is easy to see that
constructor garbage collection always terminates. The progress lemma tells us that the
collection never gets stuck and the preservation lemma tells us that at every step, the
resulting tuple is well-formed with respect to the given \Phi .

The following lemma shows that constructor garbage collection is locally confluent.
With the fact that constructor garbage collection always terminates, this implies that
constructor collection is confluent. This tells us that, no matter what order we process
the constructors, we always get the same to-space at the end of a collection.

Lemma 7.5.9 (Constructor GC Local Confluence) If T is well-formed with respect to \Phi , T ) T1 and T ) T2, then there exists a T 0 such that T1 ) T 0 and T2 ) T 0.

Proof: Suppose T = (Qf ] fl1=q1; l2=q2g; \Pi s ] fl1::^1; l2::^2g; Qt), T1 = (Qf ]
fl2=q2g; \Pi s ]fl2::^2g[\Pi 1; Qt]fl2=q2g) where \Pi 1 = fl0::^0 2 KL[^1](q1) j l0 62 Dom(Qt)]
fl1gg, and T2 = (Qf ] fl1=q1g; \Pi s ] fl1::^1g [ \Pi 2; Qt ] fl2=q2g) where \Pi 2 = fl0::^0 2
KL[^2](q2) j l0 62 Dom(Qt) ] fl2gg. Let T 0 = (Qf ; \Pi s [ \Pi 01 [ \Pi 02; Qt ] fl1= 1q1; l2=q2g),
where \Pi 01 = fl0::^0 2 \Pi 1 j l0 6= l2g and \Pi 02 = fl0::^0 2 \Pi 2 j l0 6= l1g. Then it is easy to see
that both T1 ) T 0 and T2 ) T 0. 2

Lemma 7.5.10 If (Qf ; \Pi s; Qt) and (Qf ; \Pi s [ \Pi 0s; Qt) are well-formed with respect to \Phi ,
then (Qf ; \Pi s; Qt) )\Lambda  (Q0f ; ;; Q0t), (Qf ; \Pi s [ \Pi 0s; Qt) )\Lambda  (Q00f ; ;; Q00t ), and Q0t ` Q00t .

For expressions, the garbage collection rewriting rules operate on 6-tuples of the
form (Qf ; Hf ; \Pi s; \Psi s; Qt; Ht), where Qf and Hf are the constructor and expression fromspaces, \Pi s describes the constructors immediately reachable from Qt, Ht, and \Psi s, and
\Psi s describes the heap values immediately reachable from Ht. There are two rewriting
rules at this level. The first rule simply uses the constructor rewriting rule to process a
constructor binding:

(Qf ; \Pi s; Qt) ) (Q0f ; \Pi 0s; Q0t)
(Qf ; Hf ; \Pi s; \Psi s; Qt; Ht) ) (Q0f ; Hf ; \Pi 0s; \Psi s; Q0t; Ht)

The second rule processes a binding in the expression heap:

(Qf ; Hf ] fl=hg; \Pi s; \Psi s ] fl:&g; Qt; Ht) ) (Qf ; Hf ; \Pi s [ \Pi 0s; \Psi s [ \Psi 0s; Qt; Ht ] fl=hg)

where h\Pi 00s ; \Psi 00s i = T L[&](h)

\Pi 0s = fl0::^0 2 \Pi 00s j l0 62 Dom(Qt)g
\Psi 0s = fl0:&0 2 \Psi 00s j l0 62 Dom(Ht) ] flgg

Note that both of the scan sets are updated when an expression heap value is processed.

CHAPTER 7. TYPES AND GARBAGE COLLECTION 156

The initialization and finalization steps for the full garbage collection are captured
by the following inference rule:

ExpEnv(e) = h\Pi ; \Psi i
(Q; H; \Pi ; \Psi ; ;; ;) )\Lambda  (Qf ; Hf ; ;; ;; Qt; Ht)

(Q; H; e) tr-alg7\Gamma ! (Qt; Ht; e)
We initialize the system by extracting the locations and their kinds or types from the
range of the environment of the current expression. This corresponds to extracting the
root locations from the stack and registers of a real implementation. Then, we continue
choosing locations in one of the scan sets, forward this location from the appropriate
from-space to the appropriate to-space, potentially adding new locations to the scansets. Once the scan-sets become empty, the algorithm is finished, and the to-spaces are
taken as the new, garbage collected heaps of the program.

To prove the correctness of the algorithm, I must establish a suitable set of invariants that guarantees that (a) the algorithm does not become stuck and (b) the resulting
program is closed. The key difficulty in establishing the invariants is that we must conceptually complete the constructor garbage collection to ensure that enough constructors are
present that we can derive all needed equivalences to type-check the heap and expression
of the program.

Definition 7.5.11 (Well-Formedness) Suppose P = (Q; H; e) where ; ` \Phi , \Phi ; ; `
H : \Psi , and \Phi ; \Psi ; ;; ; ` e : oe. The tuple T = (Qf ; Hf ; \Pi s; \Psi s; Qt; Ht) is well-formed with
respect to P , \Phi , \Psi , and oe iff:

1. (Qf ; \Pi s; Qt) is well-formed with respect to \Phi  and thus, for some \Phi 0 ` \Phi ,

(Qf ; \Pi s; Qt) )\Lambda  (Q0f ; ;; Q\Phi 0),

2. H = Hf ] Ht,
3. \Psi s ` \Psi  and Dom(\Psi s) ` Dom(Hf ),
4. \Phi 0; \Psi s ` Ht : \Psi t where \Psi t = fl:& 2 \Psi  j l 2 Dom(Ht)g, and
5. \Phi 0; \Psi s ] \Psi t; ;; ; ` e : oe.

Roughly speaking, the invariants guarantee that (1) constructor garbage collection can
proceed to some appropriate final state, (2) all of the values in the expression heap are
accounted for, (3) the scan-set is consistent with the global location type assignment
\Psi  and describes a frontier of locations bound in the from-space, (4) after constructor
collection is complete, the resulting constructor to-space and expression scan-set cover

CHAPTER 7. TYPES AND GARBAGE COLLECTION 157
the free locations in the to-space and (5) all of the free locations in e and oe are covered
by the to-spaces or scan-sets.

The following lemma shows that the invariants are strong enough to guarantee that,
at the end of rewriting, the resulting program is a collection of the original program.

Lemma 7.5.12 Let P = (Q; H; e) where ; ` \Phi , \Phi ; ; ` H : \Psi , and \Phi ; \Psi ; ;; ; ` e : oe, and
suppose T = (Qf ; Hf ; ;; ;; Qt; Ht) is well-formed with respect to P , \Phi , \Psi , and oe. Then
(Qt; Ht; e) is a collection of P .

Proof: From the correctness of the tracing collection specification, it suffices to show
that (Qt; Ht; e) is closed. Since T is well-formed, we know from the first invariant that
(Qf ; ;; Qt) is well-formed with respect to \Phi . Thus, taking \Phi 0 ` \Phi  such that Dom(\Phi 0) =
Dom(Qt), we know that ; ` Qt::\Pi \Phi 0 and thus ; ` \Phi 0. From the fourth invariant, we know
that \Phi 0; ; ` Ht:\Psi t where \Psi t = fl:& 2 \Psi  j l 2 Dom(Ht)g and from the fifth invariant,
\Phi 0; \Psi t; ;; ; ` e : oe. Consequently, ` (Qt; Ht; e) : oe and (Qt; Ht; e) is closed. Therefore,

P trace7\Gamma ! (Qt; Ht; e) and thus P ' (Qt; Ht; e). 2

Since either the size of the constructor from-space or the expression from-space strictly
decreases at each step, it is clear that the rewriting system either terminates or gets stuck.

Lemma 7.5.13 (Preservation) If T is well-formed with respect to P , \Phi , \Psi , and oe,
and T ) T 0, then T 0 is well-formed with respect to P , \Phi , \Psi , and oe.

Proof: In the first case, T ) T 0 via the constructor garbage collection rule. Wellformedness of T 0 is guaranteed by preservation of the constructor GC invariants, with
confluence of constructor GC.

In the second case, T = (Qf ; Hf ]fl=hg; \Pi s; \Psi s ]fl:&g; Qt; Ht) and T 0 = (Qf ; Hf ; \Pi s [
\Pi 0s; \Psi s [ \Psi 0s; Qt; Ht ] fl=hg), where T L[&](h) = h\Pi 00s ; \Psi 00s i, \Pi 0s = fl0::^0 2 \Pi 00s j l0 62
Dom(Qt)g, and \Psi 0s = fl0:&0 2 \Psi 00s j l0 62 Dom(Ht) ] flgg. Lemma 7.5.5 and the definition
of T L tells us that \Pi 00s ` \Pi s and \Psi 00s ` \Psi s. Thus \Pi s [ \Pi 0s is a well-formed location
kind assignment that is a subset of \Pi . Thus, invariant (1), (Qf ; \Pi s [ \Pi 0s; Qt) is satisfied.
Invariant (2) is trivially satisfied, since, by assumption, H = Hf ] Ht ] fl=hg. Invariant
(3) is satisfied if \Psi 0s ` \Psi  and Dom(\Psi 0) ` Dom(Hf ). The former condition holds since
\Psi 00s ` \Psi  and the latter condition holds by construction of \Psi 0.

By invariant (1), (Qf ; \Pi s; Qt) )\Lambda  (Q0f ; ;; Q0t) for some Q0f and Q0t, where \Phi 0 ` \Phi 
and Q\Phi 0 = Q0t. Furthermore, (Qf ; \Pi s [ \Pi 0s; Qt) )\Lambda  (Q00f ; ;; Q00t ) and taking \Phi 00 ` \Phi 
such that Q\Phi 00 = Q00t , and by lemma 7.5.10, we know that \Phi 0 ` \Phi 00. By invariant (3),
\Phi 0; \Psi s ] fl:&g ` Ht : \Psi t. Since \Phi 0 ` \Phi 00, \Phi 00; \Psi s ] fl:&g ` Ht : \Psi t. By lemma 7.5.5, we
know that \Phi 00; (\Psi s ] \Psi t) [ \Psi 0s; ;; ; ` h : &. Thus, \Phi 00; \Psi s [ \Psi 0s ` Ht ] fl=hg : \Psi t ] fl:&g
and invariant (4) is satisfied.

Finally, by invariant (5), \Phi 0; \Psi s ] \Psi t ] fl:&g; ;; ; ` e : oe. Thus, \Phi 00; (\Psi s ] \Psi t ] fl:&g) [
\Pi 0s; ;; ; ` e : oe and invariant (5) is satisfied. 2

CHAPTER 7. TYPES AND GARBAGE COLLECTION 158
Lemma 7.5.14 (Progress) If T = (Qf ; Hf ; \Pi s; \Psi s; Qt; Ht) is well-formed with respect
to P , \Phi , \Psi , and oe, then either \Pi s and \Psi s are empty or else there exists a T 0 such that
T ) T 0.

Proof: If \Pi s is non-empty, then progress is guaranteed by constructor GC progress.
If the expression scan-set is non empty, then it is of the form \Psi s ] fl:&g. By invariant
(3), fl:&g 2 \Psi  and l must be bound in the from space. Thus, assume the from-space is
of the form Hf ] fl=hg for some Hf and h. By lemma 7.5.5 and the definition of T L,
we know that T L[&](h) is defined and is some h\Pi 00s ; \Psi 00s i such that \Pi 00s ` \Pi  and \Psi 00s ` \Psi .
Therefore, taking \Pi 0s = fl0::^0 2 \Pi 00s j l0 62 Dom(Qt)g and \Psi 0s = fl0:&0 2 \Psi 00s j l0 62
Dom(Ht) ] flgg, we know that \Pi s [ \Pi 0s is well-formed and \Psi s [ \Psi 0s is well-formed. Thus,
T ) (Qf ; Hf ; \Pi s [ \Pi 0s; \Psi s [ \Psi 0s; Qt; Ht ] fl=hg). 2

Corollary 7.5.15 (Tracing Algorithm Correctness) If P is well-typed, then there
exists a P 0 such that P tr-alg7\Gamma ! P 0 and P ' P 0.

Proof: Follows immediately from lemma 7.5.12, Preservation, and Progress. 2

7.6 Related Work
The literature on garbage collection in sequential programming languages per se contains
few papers that attempt to provide a compact characterization of algorithms or correctness proofs. Demers et al. [34] give a model of memory parameterized by an abstract
notion of a "points-to" relation. As a result, they can characterize reachability-based
algorithms including mark-sweep, copying, generational, "conservative," and other sophisticated forms of garbage collection. However, their model is intentionally divorced
from the programming language and cannot take advantage of any semantic properties
of evaluation, such as type preservation. Consequently, their framework cannot model
the type-based collectors I describe here. Nettles [98] provides a concrete specification
of a copying garbage collection algorithm using the Larch specification language. My
specification of the free-variable tracing algorithm is essentially a high-level, one-line
description of his specification.

Hudak gives a denotational model that tracks reference counts for a first-order language [67]. He presents an abstraction of the model and gives an algorithm for computing
approximations of reference counts statically. Chirimar, Gunter, and Riecke give a framework for proving invariants regarding memory management for a language with a linear
type system [30]. Their low-level semantics specifies explicit memory management based
on reference counting. Both Hudak and Chirimar et al. assume a weak approximation
of garbage (reference counts). Barendsen and Smetsers give a Curry-like type system for

CHAPTER 7. TYPES AND GARBAGE COLLECTION 159
functional languages extended with uniqueness information that guarantees an object is
only "locally accessible" [16]. This provides a compiler enough information to determine
when certain objects may be garbage collected or over-written.

Tolmach [119] built a type-recovery collector for a variant of SML that passes type
information to polymorphic routines during execution. Aditya and Caro gave a typerecovery algorithm for an implementation of Id that is equivalent to type passing [5] and
Aditya, Flood, and Hicks extended this work to garbage collection for Id [6]. In both
collectors, bindings for type variables are accumulated in type environments as I propose
here.

However, the type systems of these languages are considerably simpler that *MLi . In
particular, they only support instantiation of polytypes and not general forms of computation (e.g., function call and Typerec). Furthermore, neither of these implementations
allowed terms to examine types for operations, such as polymorphic equality or dynamic argument flattening. Tolmach took advantage of these properties by delaying the
computation of a type instantiation until this instantiation was needed during garbage
collection. In essence, he represented types as closures - a pair consisting of a type
environment and a term with free variables whose bindings could be found in the environment. His "lazy" strategy for type instantiation avoided constructing types that are
unneeded outside garbage collection.

In contrast, for languages like *MLi , I propose computing type information eagerly to
ensure that no computation, and thus no allocation occurs during garbage collection. The
TIL compiler uses a hybrid tag-free scheme to avoid constructing types for all values. TIL
also performs various optimizations to share as many type computations as is possible.
These and other "real-world" implementation issues are discussed in Chapter 8.

Over the past few years, a number of papers on inference-based collection in monomorphic [22, 129, 23] and polymorphic [8, 49, 50, 43] languages appeared in the literature.
Appel [8] argued informally that "tag-free" collection is possible for polymorphic languages such as SML by a combination of recording information statically and performing
what amounts to type inference during the collection process, though the connections
between inference and collection were not made clear. Baker [14] recognized that Milnerstyle type inference can be used to prove that reachable objects can be safely collected,
but did not give a formal account of this result. Goldberg and Gloger [50] recognized
that it is not possible to reconstruct the concrete types of all reachable values in an implementation of an ML-style language that does not pass types to polymorphic routines.
They gave an informal argument based on traversal of stack frames to show that such
values are semantically garbage. Fradet [43] gave another argument based on Reynolds's
abstraction/parametricity theorem [104].

The style of semantics I use here is closely related to the allocation semantics used in
my previous work on garbage collection [96, 95], but is slightly lower-level. In particular,
I use closures and environments to implement substitution. In this respect, the semantics

CHAPTER 7. TYPES AND GARBAGE COLLECTION 160
is quite similar to the SECD [80] and CEK machines [40]. The primary difference between
my approach and these machines is that I make the heap explicit, which enables me to
define a suitable notion of garbage and garbage collection.

Chapter 8
The TIL/ML Compiler

TIL, which stands for Typed Intermediate Languages, is a batch compiler that translates
a subset of Standard ML to DEC Alpha assembly language. Together with David Tarditi,
Perry Cheng, and Chris Stone, I have constructed TIL to explore some of the practical
issues of type-directed translation and dynamic type dispatch. In this chapter, I give an
overview of the design and implementation of TIL, catalog its features and drawbacks,
and compare it to Standard ML of New Jersey -- one of the best SML compilers currently
available.

Throughout this chapter, I use the plural (e.g., "we") when referring to Tarditi,
Cheng, Stone, and me. I reserve the singular (e.g., "I") when referring only to myself.

8.1 Design Goals of TIL
In designing TIL, our primary goal was to make the common case fast, possibly at the
expense of a less common case. For example, all functions in SML take one argument;
multiple arguments are simulated by using a tuple as the argument. From previous studies
[81, 110], we determined that most functions do not use the tuple argument except to
extract the components of the tuple. Consequently, we wanted TIL to translate functions
so that they take tuple components in registers as multiple arguments, thereby avoiding
constructing the argument tuple.

Our secondary goal was to use type-directed translation to propagate type information
through as many stages of compilation as was possible. The idea was to try to discover
new ways that types could be used in the lower-levels of a compiler. Some uses of types
came at a surprisingly low level. For instance, we used type information to orient switch
arms to maximize correctly predicted branches for list and tree-processing code. To
support tag-free garbage collection, we knew that it was necessary to hang on to as much
type information for as long as was possible. To accomplish this, we needed a suitably

161

CHAPTER 8. THE TIL/ML COMPILER 162
expressive, typed intermediate form.

Another design goal was to leverage existing tools as much as possible. For instance,
we decided to emit Alpha assembly language and let the native assembler handle instruction scheduling and opcode emission. We were careful to use standard Unix tools, such
as ld so that we could take advantage of profilers, debuggers, and other widely used
tools. Also, to avoid constructing a parser, type-checker, and pattern match compiler,
we decided to use the front end of the ML Kit Compiler [19].

Finally, we wanted TIL to be as interoperable with other languages (notably C, C++,
and Fortran) as possible, without compromising the efficiency of conventional SML code.
The goal was to support efficient access to library routines, system calls, and hardware,
which is needed for "systems" programming in SML as proposed by the Fox project [56].
To this end, we decided to use tag-free garbage collection to support untagged, unboxed
integers and pointers, since most arguments to libraries or system calls involve these two
representations. Also, we made the register allocator aware of the standard C calling
convention so that C functions could be directly called from SML code.

We decided not to use a fully tag-free collector, but instead to place tag words before
heap-allocated objects (i.e., records and arrays). For records, we decided to use a bit map
to describe which components are pointers. Arrays are uniform, so we planned to use a
single bit in the length tag to tell whether or not the contents of the array are pointers.

Most allocators for languages like C and C++ also use header words for heap-allocated
objects, so the proposed scheme would not sacrifice interoperability. Furthermore, we
suspected that most tags could be computed at compile time, so the cost of constructing
these tags would not be prohibitive. We also felt that tagging heap objects would simplify
the garbage collector since we could use standard breadth-first copying collection once
the "roots" (i.e., registers and stack) had been scanned. Fully tag-free collectors cannot
use the standard breadth-first scan, because there is not always space for a forwarding
pointer in a tag-free object1. Furthermore, we were worried that the sizes of tables
that contain full type information might be excessively large [35]. Taking all of these
factors into account, we felt that leaving integers and pointers untagged, but tagging
heap-allocated objects, had the most virtues.

We decided not to unbox double-precision floating point values except within functions
and within arrays. We felt that unboxing doubles in arrays would be important for
scientific code (e.g., matrix operations). Unboxing double function arguments requires a
more complicated approach to calling conventions and register allocation in the presence
of polymorphism. (I discuss this issue in Section 8.8). Similarly, unboxed floating point
values in records require a more complicated mechanism for calculating the sizes and tags
of records, as well as the offsets of fields within records. We were unsure whether the run

1Yasuhiko Minamide pointed this out to me and showed that Tolmach failed to properly correct for
this in his tag-free collector [119].

CHAPTER 8. THE TIL/ML COMPILER 163
time costs of the more complicated mechanisms would outweigh the benefits of unboxed
doubles, especially for conventional SML code which typically manipulates many records
and few doubles.

We did design the compiler so that unboxed doubles could either be passed as function
arguments or placed in records for monomorphic code. We hope to use TIL in the
future to explore the tradeoffs of various mechanisms that support unboxed doubles for
polymorphic code.

8.2 Overview of TIL
Figure 8.1 gives a block-diagram of the stages of the TIL compiler. All of the transformations are written in Standard ML. In this section, I give a brief overview of each stage
and in the following sections, I provide more detailed information.

The first phase of TIL uses the front end of the ML Kit compiler [19] to parse, type
check, and elaborate SML source code. The Kit produces annotated abstract syntax
for the full SML language and then compiles a subset of this abstract syntax to an
explicitly-typed core language called Lambda. The compilation to Lambda eliminates
pattern matching and various derived forms.

I extended Lambda to support signatures, structures (modules), and separate compilation. Each source module is compiled to a Lambda module with an explicit list of
imported modules and their signatures. Imported signatures may include transparent
definitions of types defined in other modules. Hence, TIL supports a limited form of
translucent [58] or manifest types [83].

I extended the mapping from SML abstract syntax to Lambda so that SML structures are mapped to Lambda structures with transparent imported types. Currently,
the mapping to Lambda does not handle source-level signatures, nested structures, or
functors. In principle, however, all of these constructs are supported by the intermediate
languages of TIL.

The next phase of TIL uses an intermediate language called Lmli. Lmli is a "real
world" version of *MLi , providing constructs for dynamic type dispatch, efficient data
representations, recursive functions, arrays, and so forth. In the translation of Lambda
to Lmli, we use these constructs to provide tag-free polymorphic equality, specialized
arrays, efficient data representations, and multi-argument functions. The argument flattening and implementation of polymorphic equality are based on the formal type-directed
translation of Chapter 5.

Like *MLi , type checking Lmli terms is decidable. I provide a kind checker, constructor
normalizer, and type checker for Lmli. We also provide support for pretty-printing Lmli
terms. Currently, the type checker is quite slow because I normalize all types before
comparing them. A much better approach is to compare types directly and normalize

CHAPTER 8. THE TIL/ML COMPILER 164

SML
Lambda

Lmli
Lmli-Bform
Lmli-Closure

Ubform

Rtl
Alpha

choose data representations,
flatten arguments

name computations,linearize control

close code,calculate environments

choose abstractmachine instructions
allocate registers,map to Alpha assembly

calculate gc infofor variables

parse, elaborate,elim. pattern matching

Optimization:
alpha-conversionelim. dead code
elim. primopselim. common sub-exps
elim. redundant switchesinline functions used once
loop invariant removalhoisting

inline switch contextsink expressions
uncurry functionselim. redundant comparisons
minimize fixinline small functions

Figure 8.1: Stages in the TIL Compiler

CHAPTER 8. THE TIL/ML COMPILER 165
components only if they do not match.

Lmli-Bform (or simply Bform) is a subset of Lmli similar to A-normal form [42]. It
provides a more regular intermediate language than Lmli to facilitate optimization. Because Bform is a subset of Lmli, we can use all of the Lmli tools, including the type
checker and pretty printer on the Bform representation2. We perform a wide variety of
optimizations on the Bform representation of a program including dead code elimination; uncurrying; constant folding; constant typecase and switch elimination; inlining of
constructor functions, term functions, type functions and switch continuations; common
sub-expression elimination; redundant switch elimination; and invariant removal. Because the optimization phases use Bform for both the source and target language, the
output of each phase can be checked for type correctness.

Most of the design and implementation of the optimizer is not my work, and is
described fully by Tarditi's thesis [115]. It is interesting to note that working with a
typed intermediate form did not constrain the set of optimizations that Tarditi wished
to perform, and that types could be used to perform some optimizations that were not
possible in an untyped setting. However, working with a typed intermediate form did
have some drawbacks. In particular, our typed intermediate form needs more constructs
(e.g., typecase) than a comparable untyped form. This makes the optimizer code bigger
since there are more cases to process. In turn, this increases the likelihood of introducing
bugs in compilation. However, we found that the ability to type-check the output of the
optimizer often mitigated this drawback.

After Bform optimization, we perform closure conversion, mapping the Bform representation to a language called Lmli-Close. In fact, all of the constructs of Lmli-Close
are present in Bform but are unused until the closure phase of the compiler. Hence,
Lmli-Close is a refinement of Lmli-Bform, much the same as Lmli-Bform is a refinement
of Lmli. The conversion is based on the type-directed closure translation described in
Chapter 6. However, following Kranz [78], we calculate the set of functions that do not
"escape" and avoid constructing closures for such functions. Because Lmli-Close is a
subset of Bform, we can use both the optimizer and the type checker on the closure
converted code.

After closure conversion, we translate the resulting code to an untyped Bform, called
Ubform. Instead of annotating variables with types, Ubform requires that we annotate
variables with representation information. The translation to Ubform erases the distinction between computations at the constructor and term levels. For example, a constructor
function call looks the same as a term function call.

The next phase of TIL maps Ubform programs to the Rtl intermediate form. Rtl,

2The actual ML datatypes used for Lmli and Bform differ, but we provide a simple map from Bform
to Lmli. If SML provided refinement types [44], then we could have defined Bform as a refinement of
Lmli and avoided this extra piece of code.

CHAPTER 8. THE TIL/ML COMPILER 166
which stands for register transfer language, provides an idealized RISC instruction set,
with a few heavy-weight instructions and an infinite number of registers. After Rtl, we
perform register allocation and map the resulting code to DEC Alpha assembly language.

We use the system assembler to translate Alpha assembly language to binaries and
the system linker to link these binaries with the runtime system. The runtime is written
in C and provides code for initialization, memory management, and multi-threading. The
garbage collector uses table information generated at the Rtl level to determine which
registers and stack slots contain pointer values. The rest of the garbage collector is a
standard, two-space copying collector.

8.3 SML and Lambda
Currently, we do not support the signatures, nested structures, or functors of Standard
ML. There are also some parts of core SML that we do not support. In order to assign
a quantified, polymorphic type to an expression, we require that that expression be
syntactically equivalent to a value. By value, we mean that the expression must be
a constant, a record of values, a data constructor (besides ref) applied to values, or
a function. This so-called "value restriction" is necessary to support a type-passing
interpretation of SML, since polymorphic computations are represented as functions. The
value restriction has been proposed by others [63, 57, 82] as a way to avoid the well-known
problems of polymorphism and refs, exceptions, continuations, and other constructs that
have computational effects. Furthermore, according to a study performed by Wright
[131], most SML code naturally obeys the value restriction. The few cases he found that
do not, are easily transformed so that they do meet this restriction.

The other restriction on core SML code involves datatypes. We do not support
recursive datatypes of the form:

datatype ff foo = D1 of (ff * ff) foo -? int
where a type constructor foo abstracts a type argument ff, and is defined in terms of
itself applied to a different type containing the abstracted variable (e.g., (ff * ff) foo).
Representing such a datatype as a predicative constructor is impossible because the type
variable ff must be abstracted inside the recursion equation governing the definition.
Hence, the recursion equation defines a fixed-point over polytypes instead of monotypes.
Such datatypes are very rare. A cursory study showed that no datatypes of this form
existed in either the Edinburgh or the SML/NJ library. In many respects, the ability to
define such datatypes violates the type-theoretic "essence of SML" [94], and thus I view
them more as a bug in the Definition [90] than a feature. In principle, TIL supports
the rest of the Standard ML Definition, though of course there may be bugs in the
implementation.

CHAPTER 8. THE TIL/ML COMPILER 167

We use the ML Kit Compiler [19] to parse, type-check, and elaborate SML expressions.
The Kit translates SML to annotated abstract syntax. The annotations include position
information for error reporting as well as type information. Next, the annotated abstract
syntax is translated to the Lambda intermediate form. This intermediate form is quite
similar to the language described by Birkedal et. al. [19], but I added support for type
abbreviations, structures, and signatures. Also, we added various primitive operations
to the language to support, for instance, unsigned integer operations, logical operations,
and so forth.

The Kit compiler translates core SML, annotated abstract syntax to Lambda declarations. During the translation, all type definitions are hoisted to the top-level and almost
all pattern matching is eliminated. Datatype definitions are represented in almost exactly
the same fashion as they are at the source level.

I modified the translation to Lambda to support structures and a standard "prelude"
environment. This environment contains bindings for commonly used functions such as
map and fold, as well as definitions of the built in types, including arrays, bools, and
strings. The prelude environment is conceptually prepended onto every structure. This
allows the optimizer to easily inline functions such as map.

Some primitive types, notably strings, are defined in terms of other datatypes in the
prelude. For example, the string type is represented as a standard datatype of the form:

datatype string rep =

C000 -- C001 -- C002 -- ... -- C255 --
stringrep str of int * (int array)

The data constructors C000--C255 correspond to 8-bit, ASCII characters whereas the
data constructor stringrep str corresponds to strings of length 0 or of length greater
than 1. We found that distinguishing characters from other strings was important since
characters could always be represented unboxed and character comparison could be implemented efficiently3. Strings of more than one character are represented as integer
arrays. Since integers are untagged, each integer in the array holds 4 characters on a
32-bit machine4. The extra int paired with the integer array indicates the length of
the string in characters. All of the string primitives -- including implode, explode, and
append -- are implemented by a combination of pattern matching and array operations.
The ability to manipulate strings a word-at-a-time using the standard integer array operations simplified the implementation greatly without sacrificing performance.

The translation does provide support for separate compilation. In particular, each
SML structure is compiled to a Lambda module containing a list of all imported modules

3Earlier versions of SML/NJ used a similar representation, but newer versions expose the character
datatype to the programmer. Our string representation is compatible with either approach.

4Although the Alpha is a 64-bit processor, we represent integers and pointers as 32-bit values.

CHAPTER 8. THE TIL/ML COMPILER 168
and their Lambda signatures. These signatures can, but need not, contain transparent
or manifest type definitions. Since we account for all external references in the list of
imported modules, each module can be compiled separately from other modules in the
program. This scheme relies upon unique module names at link-time to resolve intermodule references.

8.4 Lmli
The Lmli intermediate form is based on the formal *MLi calculus of Chapter 3, but provides
a suitably rich set of constructs to support efficient compilation of Lambda datatypes
and terms. In this section, I present various details regarding Lmli, including the SML
datatype used to represent the kinds, constructors, types, and terms of Lmli.

8.4.1 Kinds, Constructors, and Types of Lmli
The SML datatype definitions for a subset of the kinds and constructors of Lmli are given
in Figure 8.2. To simplify the presentation, I have eliminated all of the constructs that
are used only for closure conversion. These constructs are discussed in Section 8.7.

All constructors are labelled with a kind. This simplifies kind checking and constructor manipulation, since we can always determine a constructor's kind with no additional
context. A more sophisticated implementation might elide much of this information and
reconstruct it as needed. The kind Mono k is the ASCII representation of \Omega  and thus
represents all constructors corresponding to monotypes. Kinds include Mono k, n-ary
products (Tuple k), arrow kinds (Arrow k), and list kinds (List k). In TIL, we elide the
distinction between a constructor _ of kind Mono k and the type T (_). Instead, we use
the special kind Poly k to distinguish types from constructors5.

Constructors include variables, projections from modules (Dot c), primitive constructors of zero or one argument, tuple intro and elim forms, list intro and elim forms, function
intro and elim forms, recursive constructors (Mu c), and monotype elim forms. I briefly
discuss each of these constructs here, and then provide more details regarding primitive
constructors.

The list intro forms include Nil c and Cons c. The list elim forms include both a
fold for lists (Fold c) and a simple case mechanism (Listcase c). The formation rule

5TIL actually provides more kind structure than is shown here, in order to check well-formedness of
types.

CHAPTER 8. THE TIL/ML COMPILER 169

datatype kind = Mono k -- Tuple k of kind list

-- Arrow k of kind * kind -- List k of kind -- Poly k

datatype primcon = Primcon0 of primcon0 -- Primcon1 of primcon1
datatype con = Con of (raw con * kind)
and raw con =

Var c of var
-- Dot c of strid * int * label
-- Prim0 c of primcon0
-- Prim1 c of primcon1 * con
-- Tuple c of con list
-- Proj c of int * con
-- Nil c of kind
-- Cons c of con * con
-- Listcase c of farg : con, nil c : con, cons c : confng
-- Fold c of farg : con, nil c : con, cons c : confng
-- Fn c of confn
-- App c of con * con
-- Mu c of ((var * con) list) * con
-- Typecase c of farg : con,

arms : (primcon * confn) list,
default: con,
kind : kindg
-- Typerec c of farg : con,

arms : (primcon * confn) list,
default : con,
kind : kindg
-- Let c of (var * kind * con * con)
-- All c of (var * kind) list * con
and confn = CF of (var * kind * con)

Figure 8.2: Kinds and Constructors of Lmli

CHAPTER 8. THE TIL/ML COMPILER 170
for the fold construct is roughly

\Delta  ` _ :: List k(^0) \Delta  ` _1 :: ^
\Delta  ` _2 :: Tuple k[^0; List k(^0); ^] ! ^
\Delta  ` Fold cfarg=_,nil c=_1,cons c=_2g :: ^

The arg component must be of list kind and thus evaluates to either a Nil c or else a
Cons c constructor. The nil c component is selected for the base case and the arg c
component is selected for the inductive case. The head and tail of a Cons c cell are
passed to the cons c component as arguments, with the unrolling of the fold on the tail
of the list. The formation rule for listcase is similar, but the nil c component only takes
the head and tail as arguments.

The monotype elim forms include both Typerec c and Typecase c forms. The clauses
are indexed by a primcon, and each primcon can occur in at most one clause. Clauses
corresponding to primcon1 values are functions that take appropriate arguments of the
appropriate kind, whereas clauses corresponding to primcon0 values are constructor functions that take an empty tuple as an argument. The default case is used to match constructors that do not appear in the arms list. Note that although recursive types are
considered to be monotypes, there is no way to deconstruct them in Lmli; the default
clause of a Typecase c or Typerec c is always selected when one of these constructs is
applied to a Mu c constructor.

The function intro (Fn c) and elim (App c) forms are standard. The Let c form
can be abbreviated with these constructs as usual. However, this is not possible in the
restricted Lmli-Bform that is used in the optimizer. We retain Let c here to support
pretty-printing, and both kind and type-checking of Lmli-Bform. The All c constructor
is not really a constructor, but rather a type. It is always labelled with the kind Poly k.

The Mu c constructor is a generalized recursive type constructor. Informally, Mu c
corresponds to a "letrec" at the constructor level, simultaneously binding the variables
to the constructors, within the scope of the exported constructor. Each of the variables
is constrained to have the kind Mono k. We require that the constructors bound to the
variables be expansive. That is, if one of the variables bound in the Mu c occurs in a
constructor bound to a variable, then that variable must occur within an argument to a
primcon1.

The type that a recursive constructor represents is isomorphic to the type obtained by
simultaneously replacing each variable in the exported constructor with the "unrolling" of
the recursive type. For instance, the recursive constructor Mu c([(x1,c1),(x2,c2)],c)
is isomorphic to fc1'/x1,c2'/x2gc where

c1' = Con(Mu c([(x1,c1),(x2,c2)],Var c(x1,Mono k)),Mono k)
and

CHAPTER 8. THE TIL/ML COMPILER 171

c2' = Con(Mu c([(x1,c1),(x2,c2)],Var c(x2,Mono k)),Mono k).
This isomorphism is not implicit as in some calculi. At the term level, we must use
explicit "roll" and "unroll" operations on terms to affect the isomorphism.

The addition of recursive types to *MLi is not straightforward since we have destroyed
the key property that the monotypes can be generated by induction. However, the elim
forms that we provide at the constructor level treat recursive types as pseudo-base cases.
In particular, we cannot examine the contents of a Mu c constructor with Typecase c
or Typerec c. I therefore speculate that both confluence and strong-normalization of
constructor reduction are preserved, though I have yet to prove this.

The primcon0 and primcon1 datatypes are defined as follows:

datatype primcon0 = Int c -- Real c -- String c -- Intarray c

-- Realarray c -- Exn c -- Enum c of int

datatype primcon1 = Ptrarray c -- Arrow c -- Sum c -- Sumcursor c

-- Record c -- Recordcursor c -- Excon c -- Deexcon c
-- Enumorrec c of int -- Enumorsum c of int

Most of the primcon0 data constructors are self explanatory. We provide a string constructor even though string values are represented in terms of other constructs (integer
arrays). This distinction is necessary to support the proper semantics of polymorphic
equality, since strings are compared by value whereas arrays are compared by reference.
The Exn c constructor is used to type exception packets, and the Enum c constructor is
used in the translation of datatypes. Enum values are used to represent data constructors with no argument (e.g., nil). Enum values are also used to tag variant records.
We assume that enum values are always distinguishable from pointers to heap-allocated
objects. Currently, we represent enum values as small integers between 0 and 255. We
could represent enum values as odd integers, assuming pointers are always evenly aligned.

The primcon1 data constructors are primitive constructors of one argument. Multiple
arguments are simulated by a constructor tuple or a list of constructors. The Ptrarray c
(pointer array) constructor corresponds to arrays that contain any value except for integers or reals. The Arrow c (arrow) constructor corresponds to functions at the term level.
Functions in Lmli take multiple arguments and yield one result. Therefore, the arrow constructor takes two arguments (as a constructor tuple), and these arguments correspond
to the domain types and the range type. The domain types are represented as a list of
constructors. Thus, arrow has the kind Tuple k[List k(Mono k); Mono k] ! Mono k.

The Record c (record) constructor corresponds to n-tuples at the term level and has
the kind List k(Mono k) ! Mono k. Recordcursor c values are used to iterate over the
components of a Record c value. Roughly speaking, a record cursor is a pair consisting
of a pointer to a record and an integer offset.

CHAPTER 8. THE TIL/ML COMPILER 172

The Sum c (sum) constructor represents immutable, Pascal-style variant record
types. Sum values are in fact records where the first component of the record contains an Enum c value indicating the variant. Thus, the sum constructor has kind
List k(List k(Mono k)) ! Mono k. For instance, values with a type described by the
constructor

Sum c[[Int c,Real c],[String c]]
are either records with a type described by

Record c[Enum c 2,Int c,Real c]
or else records with a type described by

Record c[Enum c 2,String c].
Similar to record cursors, Sumcursor c values provide a means for folding a computation
across a sum.

Values described by Excon c and Deexcon c are used to represent SML exceptions.
In particular, each creation of an SML exception carrying type o/ is translated to a single
operation that creates a pair consisting of an Excon c(o/ ) value and a Deexcon c(o/ )
value. A value of type Excon c(o/ ) can be applied to a value of type o/ to yield a value
of type Exn c, thereby hiding the type o/ . A value of type Deexcon c(o/ ) can be applied
to a value of type Exn c. The result is essentially a o/ option: a variant record where the
first variant is empty (None) and the second variant contains a value of type o/ (Some).

Finally, the Enumorrec c and Enumorsum c constructors are special cases of variant
records used to optimize the representation of SML datatypes. In particular, enum-or-rec
values are either an enum value or a record value, whereas enum-or-sum values are either
an enum value or a variant record (i.e., sum) value. Since records and sums are always
allocated (i.e., pointers), we can always distinguish enum values from records and sums.

8.4.2 Terms of Lmli
The terms of Lmli are described by the SML datatype given in Figure 8.3. Similar to
constructors, each term is labelled with its type, where the type is represented as an
Lmli con. Labelling each term with its type simplifies type checking and type-directed
translation. The space overheads of this fully typed representation are not quite as great
as we might first expect. This is because we can bind types to variables (via Let e)
and use the variable in place of the type representation. Then, we can use standard
optimization techniques, such as common sub-expression elimination and hoisting, to
eliminate redundant type definitions.

CHAPTER 8. THE TIL/ML COMPILER 173

datatype exp = Exp of (raw exp * con)
and raw exp =

Var e of var
-- Dot e of strid * int * label
-- Record e of exp list
-- Inject e of int * (exp list)
-- Int e of word
-- Real e of string
-- Enum e of int
-- String e of string
-- Let e of decl * exp
-- Fn e of function
-- Tfn e of tfunction
-- App e of exp * (exp list)
-- Tapp e of exp * (con list)
-- Coerce e of coerceop * exp
-- Op1 e of op1 * exp
-- Op2 e of op2 * exp * exp
-- Misc e of miscop
-- Switch e of switch exp
-- Typecase e of typecase exp
-- Tlistcase e of tlistcase exp
-- Raise e of exp
-- Handle e of exp * function
-- Export e of

ftypes : (label * con) list, values: (label * exp) listg
and decl =

Var d of (var * con * exp)
-- Con d of (var * kind * con)
-- Fix d of (var * con * function) list
-- Fixtype d of (var * con * tfunction) list
and function = Func of (var * con) list * exp
and tfunction = Tfunc of (var * kind) list * exp

Figure 8.3: Terms of Lmli

CHAPTER 8. THE TIL/ML COMPILER 174

The raw expressions include variables, projections from imported modules, literal
values, various primitive operations, various switch operations, (recursive) value and
constructor abstractions, value and constructor applications, exception primitives, letexpressions, and a mechanism for exporting type definitions and values. In the rest of
this section, I briefly describe some of these constructs.

The Inject e expression is used to calculate a sum value (i.e., variant record). The
integer component must be an enum value (i.e., between 0 and 255). Operationally,
Inject e just allocates a record of size n + 1, places the enum component in the first
position and then places the other values in positions 2 through n + 1.

Let e expressions provide a means of declaring variables within a scope. Variables in
a declaration are either bound to expressions (Var d), constructors (Con d), or mutually
recursive functions. The Fix d declaration provides fixed-points for value abstractions
whereas the Fixtype d declaration provides fixed-points for constructor abstractions.
Both value and constructor abstractions can take multiple arguments.

Coercions are primitive operations that have no operational effect, but are needed for
type checking. The set of coercion operations is given by

datatype coerceop =

proll -- punroll -- penum enumorrec -- prec enumorrec
-- penum enumorsum -- psum enumorsum -- penum2int -- pfromstring
-- ptostring -- pchr.

The proll and punroll coercions affect the isomorphism between a recursive type and
its unrolling. The penum enumorrec, and penum enumorsum coercions inject an enum
value into an enum-or-record or enum-or-sum type, whereas the prec enumorrec and
psum enumorrec inject a record or sum into an enum-or-record or enum-or-sum type.
The penum2int coercion coerces an enum to an integer value. The pfromstring and
ptostring coerce a string to and from its underlying representation. Finally, the pchr
operation coerces an integer to an enum value6.

The op1 primitive operations are given by the datatype

datatype op1 =

preal i -- pnot i -- pfloor r -- psqrt r -- psin r -- pcos r
-- parctan r -- pexp r -- pln r -- psize a of spclarray
-- pselect of int -- prec cursor -- prec head -- prec tail
-- psum cursor,

where

6Technically, the pchr operation should ensure that the integer value meets the representation constraints of enum values. In practice, the front-end ensures this by checking to see if the integer lies
between 0 and 255.

CHAPTER 8. THE TIL/ML COMPILER 175

datatype spclarray = Intarray -- Realarray -- Ptrarray.
Most of the rest of the operations perform some computation on real values, such as
calculating the square root (psqrt r) or natural log (pln r). The psize a operation
calculates the size of an array.

The prec cursor operation takes a record of type Record c[c1,...,cn] and pairs
it with the integer 0 to form a record cursor of type Recordcursor c[c1,...,cn]. Similarly, the psum cursor operation takes a sum value of type Sum c[c1,...,cn] and pairs it
with the enum 0 to form a sum cursor of type Sumcursor c[c1,...,cn]. The prec head
operation takes a record cursor of type Recordcursor c[c1,...,cn] and returns a value
of type c1. This value is obtained by taking the current offset of the record cursor and
selecting this component from the record of the record cursor. The prec tail operation
takes a record cursor of type Recordcursor c[c1,c2,...,cn] and returns a new record
cursor of type Recordcursor c[c2,...,cn]. This new cursor is obtained by taking the
offset of the old cursor, incrementing it, and then pairing it with the record of the old
cursor to form a new cursor. When combined with the term-level listcase operations on
constructors, record cursors can be used to fold an operation across the components of a
record. We use this facility, for example, to compute polymorphic equality on records of
arbitrary arity.

The op2 primitive operations take two arguments and are defined as follows:

datatype op2 =

pdiv i -- pmul i -- pplus i -- pminus i -- pmod i
-- peq i -- plst i -- pgtt i -- plte i -- pgte i
-- pdiv ui -- pmul ui -- pplus ui -- pminus ui
-- plst ui -- pgtt ui -- plte ui -- pgte ui
-- por i -- pand i -- pxor i -- plshift i -- prshift i
-- pdiv r -- pmul r -- pplus r -- pminus r -- peq r
-- plst r -- pgtt r -- plte r -- pgte r
-- palloc a of spclarray -- psub a of spclarray
-- pexcon -- pde excon -- peqptr

Operations ending in " i" are signed, checked integer operations, whereas operations
ending in " ui" are unsigned, unchecked operations. (The checks are for overflow and
divide by zero.) The operations ending in " r" are double-precision (i.e., 64-bit) IEEE
floating point operations.

The palloc a operations allocate arrays of the appropriate type, where the size is
determined by the first argument and the array is initialized with the second argument.
The psub a operation extracts a value from an array (the first argument) at the given
offset (the second argument). The pexcon operation takes a value of type Excon c(o/ )
and a value of type o/ and returns a value of type Exn c. The pde excon operation takes a

CHAPTER 8. THE TIL/ML COMPILER 176
value of type Exn c and a value of type Deexcon c(o/ ) and returns a Enumorrec c(1,[o/ ])
value. The resulting value is either an enum or else a record containing a o/ value.

The miscop operations are given by the following datatype:

datatype miscop =

pupdate a of spclarray * exp * exp * exp
-- pextern of string * con
-- pnew exn of con
-- peq of con
-- vararg of con * exp
-- onearg of con * exp * exp

The pupdate a operation is used to update an array. The front-end ensures that the index
is within range. The pextern operation is used to reference external labels, exported by
the runtime or a foreign language (e.g., C). The pnew exn operation takes a constructor
o/ and returns a pair of a Excon c(o/ ) value and a Deexcon c(o/ ) value.

The peq operation corresponds to polymorphic equality at the monotype denoted by
the given constructor. This operation can be coded using various other operations in the
language (see Section 5.2.3). In fact, a later stage in the compiler replaces all occurrences
of peq with a call to such a function defined in a separate, globally shared module. We
leave the operation as a primitive so that the optimizer can easily recognize and specially
treat the operation.

The vararg(o/ ,e) and onearg(o/ ,e,e') operations are used to implement dynamic
argument flattening and roughly correspond to the vararg and onearg terms of Chapter
5 (see Sections 5.2.4 and 5.2.5).

The vararg operation takes a constructor o/ and a function e. The typing rules
constrain e to take a single argument of type o/ . The operation calculates a coercion,
based on o/ , that turns e into a multi-argument function. In particular, if o/ is a record
constructor of the form Record c[c1,...,cn], then the coercion is a function that takes
n arguments of type c1,\Delta  \Delta  \Delta ,cn, respectively. These arguments are placed into a record
and passed to the original function e. If o/ is not a record, then the coercion is the identity.

The onearg operation takes a constructor o/ , a function e, and an argument e'.
If o/ is not a record constructor, then the operation simply applies e to e'. If o/ is a
record constructor of the form Record c[c1,...,cn], then the e is constrained by the
typing rules to be a multi-argument function that takes arguments of type c1,\Delta  \Delta  \Delta ,cn,
respectively, and e' is constrained to be a record of type o/ . In this case, onearg extracts
the components of the record e' and passes them directly as arguments to e.

The typing constraints on vararg and onearg are expressed using Typecase c (see
Section 5.2.1). For a fixed number of arguments, both vararg and onearg can be implemented directly in Lmli by a combination of term-level Typecase e and Listcase e

CHAPTER 8. THE TIL/ML COMPILER 177
expressions that deconstruct the argument constructor and calculate the appropriate coercion. Like peq, a later phase in the compiler replaces all occurrences of vararg and
onearg with references to these terms, which are placed in a globally shared module. We
leave both forms as primitive operations to facilitate optimization.

The Switch e expression provides a combination of a control flow operator and a
primitive deconstructor for integer, enum, sum, enum-or-record, enum-or-sum, and sum
cursor values. The switch exp argument to Switch e is defined by the SML type abbreviation

type switch exp =

fswitch type : switch type,

arg : exp,
arms : (word * function) list,
default : exp Optiong,

where switch type is given by

datatype switch type =

Int sw -- Enum sw -- Sum sw -- Enumorrec sw -- Enumorsum sw
-- Sumcursor sw

Each clause or arm of the switch is indexed by a 32-bit word. For integer and enum
switches, the value of the argument is used to select the appropriate arm according to
this index. In these cases, the arms are functions that take no arguments. For sum
switches, the enum in the first position of the sum is used to select the appropriate arm.
The arm function must take a record type corresponding to the appropriate variant. For
instance, if e has type Sum c[[Int c,String c],[Int c]], then the 0-arm must be a
function that takes a record of type Record c[Enum c 2,Int c,String c] whereas the
1-arm must be a function that takes a record of type Record c[Enum c 2,Int c]. If the
switch is for an enum-or-record or enum-or-sum value, then the 0-arm corresponds to the
enum case whereas the 1-arm corresponds to either a record or sum. In all cases, if an
arm is missing, then the default expression is chosen. Defaults are required unless the
arms are exhaustive.

Recall that sum cursor values are implemented as pairs consisting of an enum and a
sum value. Switch expressions for sum cursor values are evaluated as follows: if the enum
value of the cursor matches the enum value of the sum value, then the 0-arm is selected
and the sum value is passed as an argument. If the enum value of the cursor does not
match, then the 1-arm is selected and a new cursor value is constructed from the old.
The new cursor has the same sum value, but increases the index by one. If the original
sum cursor has type Sumcursor c[c1,c2,...,cn], then the new sum cursor value has
type Sumcursor c[c2,...,cn]. Therefore, switch on sum cursors provides a means for
eliminating one of the possible cases in a sum.

CHAPTER 8. THE TIL/ML COMPILER 178

The Tlistcase e and Typecase e forms provide a simple eliminatory form for constructors at the term level. We do not provide Fold e or Typerec e at the term level,
because these may be simulated with Fixtype d. The argument to a Tlistcase e is
described by

type tlistcase exp =

farg : con,

scheme: var * kind * con,
nil c : exp,
cons c: tfunctiong.

The arg component is the argument constructor, which must be of a list kind. The
scheme component is a type scheme used to describe the type of the clauses as well
as the type of the entire expression. The type of the entire expression is obtained by
substituting arg for the type variables of the scheme within the constructor of the scheme.
The nil c clause must have a type described by substituting Nil c (at the appropriate
kind) for the variable in the constructor. The cons c clause must be a function that
abstracts two constructor arguments, corresponding to the head and tail of the list of
constructors.

The argument to a Typecase e is described by

type typecase exp =

farg : con,

scheme : var * kind * con,
arms : (primcon * tfunction) list,
mu arm : tfunction Option,
default : tfunction Optiong

Here, the arg component must be of kind Mono k. Again, the entire type is obtained
by substituting arg for the variable within the constructor of the scheme. Each arm is
indexed by a primitive constructor. The mu arm matches any Mu c values. The "unrolling"
of the recursive constructor is passed as an argument to this clause when it is selected.
The default component is selected if the argument does not match any of the arms.

Raise e raises an exception packet of type Exn c, whereas Handle e(e,f) evaluates
e and if an exception is raised, the exception packet is passed to the function f. The
function can use a combination of the de excon primitive and a Switch e to determine
what exception was raised and extract a value from the packet.

Finally, the Export e form is not an expression, but rather an anonymous module.
Each compilation unit in TIL is constrained to be an expression consisting of a series of
declarations that terminate with an Export e. This form specifies a list of constructors
and values that are to be exported by the module. Each module is given a globally unique
strid M . The module is described by a signature

CHAPTER 8. THE TIL/ML COMPILER 179

datatype signat =

Signat of ftypes : (label * kind * (con Option)) list,

values : (label * con) listg

that describes the kinds and types of the constructors and values exported by the module.
Each exported constructor can optionally include the definition of the constructor in the
signature. In this respect, Lmli signatures resemble the translucent sums of the Harper
and Lillibridge module calculus [58]. The types of the values can contain references to
the constructors exported by the module -- using the Dot c notation -- relative to the
module strid M . The module itself is represented with a datatype of the form

datatype module =

Module of fname: strid,

imports : (strid * signat) list,
signat : signat,
body : expg.

The imports component specifies the set of modules (and their signatures) upon which
this module depends.

8.5 Lambda to Lmli
In the translation from Lambda to Lmli, I eliminate datatype definitions and perform
a series of type-directed transformations that specialize arrays and refs, flatten function
arguments, box floating point values, and flatten certain representations of datatypes.
All of these type-directed translations make use of dynamic type analysis when they encounter unknown types. I also provide Lmli terms that implement polymorphic equality,
and the vararg and onearg primitives as suggested in Chapter 5.

In this section, I show how I compile datatypes to Lmli constructors, and discuss the
various type-directed translations. I also contrast my approach to datatype representations with that of SML/NJ and show that, unlike SML/NJ, I am able to flatten data
constructors without restricting abstraction.

8.5.1 Translating Datatypes
I translate a simple datatype definition of the form

datatype (ff1,\Delta  \Delta  \Delta ,ffn) T = D1 -- D2 -- \Delta  \Delta  \Delta  -- Dm,
to a constructor function that abstracts the type variables (ff1 through ffn). The body of
the function is a Mu c constructor where T is bound to a representation of its definition
(discussed below). For example, the SML datatype

CHAPTER 8. THE TIL/ML COMPILER 180

datatype ff tree = Leaf of ff -- Node of ff tree * ff tree
is compiled to a constructor function of the form

tree = *ff::Mono k.Mu c([(t,Sum c[[ff],[[Var c t,Var c t]]])],Var c t).
(I have elided some kind information and used * to represent the constructor function.)
Within the definition of the datatype, I replace recursive references with the Mu c-bound
variable. For instance, in the previous tree definition, I replaced ff tree with the variable
t. This replacement is possible because I always verify that a datatype is applied to the
same type variables that it abstracts (see Section 8.3). The resulting constructor has
kind Mono k ! Mono k.

The translation of a datatype applied to some type argument is straightforward: I
simply apply the constructor function corresponding to the datatype to the translation
of the type arguments.

This approach to datatypes was originally suggested by Harper [59], though he also
suggests the use of an existential to hide the representation of the datatype. Hiding the
representation of the datatype is important at the source level, since this distinguishes
user types that happen to have the same representation. However, within the back-end
of a compiler, there is no advantage to such abstraction. Therefore, I do not abstract the
representations of datatypes.

The general form of an SML datatype definition is a series of mutually recursive
definitions of the form

datatype (ff1;1,\Delta  \Delta  \Delta ,ff1;n1) T1 = D1;1 -- D1;2 -- \Delta  \Delta  \Delta  -- D1;m1
and (ff2;1,\Delta  \Delta  \Delta ,ff2;n2) T2 = D2;1 -- D2;2 -- \Delta  \Delta  \Delta  -- D2;m2

...
and (ffp;1,\Delta  \Delta  \Delta ,ffp;np) Tp = Dp;1 -- Dp;2 -- \Delta  \Delta  \Delta  -- Dp;mp

In this general case, I generate one constructor function that abstracts all of the unique
type arguments. The function uses a single Mu c constructor to define the constructors
simultaneously. I then export the set of constructors corresponding to the datatype as a
constructor tuple. Individual types are obtained by instantiating the type variables and
projecting the appropriate component from the tuple.

The representation that I choose for a datatype

datatype (ff1,\Delta  \Delta  \Delta ,ffn) T = D1 -- D2 -- \Delta  \Delta  \Delta  -- Dm
depends on the form of the data constructors, D1, D2, \Delta  \Delta  \Delta , Dm. In SML, data constructors
can have zero or one argument. I choose the representation of the datatype according to
the following cases:

CHAPTER 8. THE TIL/ML COMPILER 181

ffl If all of the data constructors take zero arguments, then we use an Enum c as

the translation of the datatype. For example, datatype bool = true -- false is
represented as an (Enum c 2) constructor.

ffl If there is only one data constructor and this data constructor takes an argument

of type o/ , then we use the translation of o/ as the representation of the datatype.

ffl If all of the data constructors take one argument, and there is more than one data

constructor, we use a Sum c (variant record) as the translation of the datatype.
For example, datatype foo = Bar of int -- Baz of real is translated to the
constructor Sum c[[Int c],[Real c]].

ffl If all but one of the data constructors takes zero arguments, then we use an

Enumorrec c to represent the datatype. For example, the datatype ff list = nil
-- :: of ff * (ff list) is translated to an Enumorrec c(1,[Record c[ff,Var c
t]) constructor (where t is recursively bound to the definition). The data constructor that takes an argument (e.g., cons) is always represented as a record so
that it can be distinguished from Enum c values. However, this introduces extra
indirection when the argument to the data constructor is already a record (e.g., ff
* (ff list)). A later phase eliminates this extra indirection when possible (see
Section 8.5.3).

ffl If there is more than one data constructor that takes an argument and there are data

constructors that take no arguments, the datatype is translated to an Enumorsum c
constructor. Enum c values are used for the data constructors that take no arguments whereas Sum c values are used for the data constructors that take arguments.

A naive representation of datatypes might map each datatype to a variant record. However, this approach would cause values such as true, false, and nil to be allocated. By
mapping datatypes to the various efficient representation types, we avoid a great deal of
allocation.

8.5.2 Specializing Arrays and Boxing Floats
During the translation from Lambda to Lmli, I translate polymorphic array operations
such as sub and update to constructor abstractions that perform a typecase on the
unknown type. The typecase selects the appropriate primitive operation (e.g., psub
Realarray, psub Intarray, or psub Ptrarray) according to the instantiation of this
type.

We chose to distinguish integer and floating point arrays from other kinds of arrays
for a variety of reasons: first, in the presence of a generational collector, the update

CHAPTER 8. THE TIL/ML COMPILER 182
operation on these arrays does not require a write barrier, because the value placed in
the array can never point across generational boundaries. Second, by leaving integer
arrays untagged and unboxed, we are able to use them to represent both raw strings
and byte arrays. Third, by distinguishing floating point arrays, we are able to align
such arrays on 64-bit boundaries, providing efficient access to the elements of the array.
SML/NJ provides specialized monomorphic strings, bytearrays, and floating point arrays
for these same reasons. However, any array library function -- such as an iterator --
must be coded for each of these array types.

After translating Lambda to Lmli, I perform a series of type-directed translations
on the resulting Lmli code. The first translation ensures that all float values are boxed
(i.e., placed in a record), except when they are placed in floating point arrays. The
translation simply boxes floating point literals, unboxes floats as they are passed to
primitive operations (e.g., pplus r), and boxes float results of primitive operations. Much
of the boxing and unboxing is eliminated within a function by conventional optimization.

8.5.3 Flattening Datatypes
After boxing floats, I perform a type-directed translation to flatten Enumorrec c values.
Consider the list datatype:

datatype ff list = nil -- :: of ff * (ff list)
This datatype is initially translated to the Lmli constructor

list = *ff::Mono k.

Mu c([t,Enumorrec c(1,[Record c[ff,Var c t]])],Var c t).

At this stage, list values will either be an (Enum c 1) value corresponding to nil or a
Record c[Record c[ff,list(ff)]] value corresponding to cons. Because the contents
of a cons cell is always a record (Record c[ff,list(ff)]), we can always determine
such values from nil and thus eliminate the extra Record c[-] in cons cells. After the
constructor flattening phase, the list datatype is represented by the constructor

list = *ff::Mono k.Mu c([t,Enumorrec c(1,[ff,Var c t])],Var c t).
This optimization eliminates an extra level of indirection in every cons cell, and is thus
very important for typical SML code, which does a fair amount of list-processing.

However, we cannot always determine at compile time whether or not we can flatten
an Enumorrec c constructor. In particular, consider the option datatype:

datatype ff option = NONE -- SOME of ff
The initial translation of this datatype yields the constructor

CHAPTER 8. THE TIL/ML COMPILER 183

option = *ff::Mono k.Enumorrec c(1,[ff]).
Since the data constructor SOME has an argument of unknown type (ff), we cannot determine whether SOME will always be applied to a record and thus cannot determine whether
we can flatten the representation. In particular, the SML type int option should not
be flattened because we cannot always tell integer values from Enum c values.

Therefore, when we encounter an Enumorrec c(n,ff) constructor, we use Typecase c
on ff to determine whether or not the constructor should be flattened. Therefore, after
constructor flattening, the option datatype is represented by the constructor

option = *ff::Mono k.Typecase c ff of

Record c [o/1; \Delta  \Delta  \Delta  ; o/n] =? Enumorrec c(1,[o/1; \Delta  \Delta  \Delta  ; o/n])
-- =? Enumorrec c(1,[ff])

When constructing an option value or deconstructing an option value, we must use
Typecase e at the term level to determine the proper code sequence.

My approach generalizes the constructor flattening performed in the SML/NJ compiler. In SML/NJ, cons cells are flattened but SOME cells are not, precisely because the
compiler cannot determine at compile time whether it can safely flatten option datatypes.
Even to support flattened cons cells, SML/NJ restricts the programmer from writing
certain legal SML programs [10]. In particular, SML/NJ will not let the programmer
abstract the contents of a cons cell in a signature as follows

signature LIST =

sig

type ff Abstract Cons
datatype ff list = nil -- :: of ff Abstract Cons
end

structure List : LIST =

struct

datatype ff list = nil -- :: of ff Abstract Cons
withtype ff Abstract Cons = ff * ff list
end.

Typing this code into the SML/NJ (version 1.08) interactive system yields the following
message:

std in:0.0-23.5 Error: The constructor :: of datatype list
has different representations in the signature and the structure.
Change the definition of the types carried by the constructors in
the functor formal parameter and the functor actual parameter so
that they are both abstract, or so that neither is abstract.

CHAPTER 8. THE TIL/ML COMPILER 184
The problem is that a functor parameterized by the LIST signature cannot determine
whether the contents of cons cells can be flattened; any such functor will be compiled
assuming that cons cells are not flat, whereas the structure List will be compiled so that
cons cells are flattened. My approach makes no such restriction because I dynamically
determine the representation of abstract data structures when necessary.

8.5.4 Flattening Arguments
After flattening Enumorrec c values, I flatten function arguments in the same manner as
suggested in Chapter 5. If a function takes a record as an argument and the number of
elements in the record does not exceed a constant k, then the function is transformed to
take the elements of the record as multiple arguments. If a function takes an argument
of known type that is not a record (or else the function takes a record with greater than
k components7), then the function is not transformed. If a function takes an argument of
unknown type, then the function is compiled expecting a single argument. The vararg
primitive is used to calculate a coercion dynamically, based on the instantiation of the
unknown type.

Likewise, an application is transformed so that, if the argument is a record and the
number of elements in the record does not exceed k, then the components of the record
are passed directly as multiple arguments. If the argument has known type, but is either
not a record or else is a record of greater than k components, then the application is not
transformed. If an application has an argument of unknown type, then I use the onearg
primitive to calculate a coercion dynamically, based on the instantiation.

8.6 Bform and Optimization
After the translation to Lmli, and after the series of type-directed transformations, we
translate Lmli to Bform. Bform is a subset of Lmli that makes an explicit distinction between small values and constructors that fit into registers, large values and constructors
that must be allocated on the heap, and computations that produce values or constructors.

At the term level, small values are either variables, projections from a module, unit
(an empty record), integers, floats, enums, external labels, or coercions applied to a
small value. Large values include strings, records of small values, and functions. At the
constructor level, small values are either variables, projections from modules, an empty
tuple of constructors, or a 0-ary primitive constructor (e.g., Int c). Large values include
tuples and lists of constructors as well as primitive constructors that take arguments
(e.g., Record c).

7In the current prototype, k is arbitrarily set to eight arguments.

CHAPTER 8. THE TIL/ML COMPILER 185

All large values and all computations are bound to variables in a declaration and
we use the variable in place of the large value or computation. Thus, expressions always
manipulate small values. These constraints ensure that we avoid duplicating large objects
(such as strings) and preserve as much sharing as possible. These constraints also have
the effect of linearizing nested computations and naming intermediate results. All of
these constraints simplify standard optimization.

Numerous transformations and optimizations are applied in the Bform phase to programs. (See Tarditi [115] for a more complete description of these optimizations.) The
optimizations include the following conventional transformations:

ffl alpha-conversion: We assign unique names to all bound variables.
ffl minimizing fix: We break functions into minimal sets of mutually recursive functions. This improves inlining, by separating non-recursive and recursive functions.

ffl dead-code elimination: We eliminate unreferenced, pure expressions, and functions.

ffl uncurrying: We transform curried functions to multi-argument functions whenever all of the call sites of the curried function can be determined.

ffl constant folding: We reduce arithmetic operations, switches, and typecases on

constant values, as well as projections from known records.

ffl sinking: We push pure expressions used in only one branch of a switch into that

branch.

ffl inlining: We always inline functions that are applied only once. We never inline

recursive functions. We inline non-recursive, "small" functions in a bottom-up pass.

ffl inlining switch continuations: We inline the continuation of a switch, when all

but one clause raises an exception. For example, the expression

let x = if y then e2 else raise e3
in e4
end

is transformed to

if y then let x = e2 in e4 end else raise e3.
This makes expressions in e2 available within e4 for optimizations such as common
sub-expression elimination.

CHAPTER 8. THE TIL/ML COMPILER 186

ffl common subexpression elimination (CSE): Given an expression

let x = e1
in e2
end

if e1 is pure, then we replace all occurrences of e1 in e2 with x. Pure expressions include operations such as record projection that are guaranteed to terminate
without effect, but exclude signed arithmetic (due to the possibility of overflow and
divide-by-zero exceptions) and function calls.

ffl eliminating redundant switches: Given an expression

let x = if z then

let val y = if z then e1 else e2
in ...

we replace the nested if statement by e1, since z is always true at that point.
ffl hoisting invariant computations: Using the call graph, we calculate the nesting

depth of each function. We assign a let-bound variable and the expression it binds
a nesting depth equal to that of the nearest enclosing function. For every pure
expression e, if all free variables of e have a nesting depth less than e, we move the
definition of e right after the definition of the free variable with the highest lexical
nesting depth.

ffl eliminating redundant comparisons: We propagate a set of simple arithmetic

relations of the form x ! y top-down through the program and a "rule-of-signs"
abstract interpretation is used to determine signs of variables. We use this information to eliminate array-bounds checks and other tests.

In addition to these standard optimizations, I perform a set of type-specific optimizations:

ffl eliminating peq: If the polymorphic equality primitive is applied to a known type,

and the number of syntax nodes in the type is smaller than some parameter, then I
generate special equality code for that type. I delay performing this specialization
until after hoisting and common subexpression elimination to avoid duplication.

ffl eliminating vararg and onearg: As suggested in Section 5.2.5, the onearg and

vararg primitives cancel. I use this to eliminate applications of onearg and vararg.
Also, as types become known, I specialize the onearg and vararg primitives to the
appropriate coercion. As with peq, I delay performing this specialization until after
hoisting and common subexpression elimination to avoid duplication.

CHAPTER 8. THE TIL/ML COMPILER 187

ffl hoisting type applications: Because we make the restriction at the source level

that all expressions assigned a 8-type must be values (i.e., effect-free), we are assured that a type application is effect-free. Furthermore, the back-end does not
introduce any polymorphic functions with computational effects, and thus all type
applications are effect free. Therefore, like other pure operations, we hoist type
applications.

Currently, we apply the optimization as follows. First, we perform a round of reduction optimizations, including dead-code elimination, constant folding, inlining functions
called once, CSE, eliminating redundant switches, and invariant removal. These optimizations do not increase program size and should always result in better code. We
iterate these optimizations until no further reductions occur. Then we perform switchcontinuation inlining, sinking, uncurrying, comparison elimination, fix minimizing, and
general inlining. The entire optimization process is then iterated for some adjustable
number of times (currently three).

8.7 Closure Conversion
The closure conversion phase of TIL is based on the formal treatment of closure conversion
given in Chapter 6, but following Kranz [78] and Appel [9], I extended the translation to
avoid creating closures and environments unless functions "escape". A function escapes
if it is placed in a data structure, passed as an argument to another function, or is
returned as the result of a function. If a function does not escape, then all of its call sites
can be determined and all of the free variables of the function are available at the call
sites. Therefore, we transform non-escaping functions to code that takes all of their free
variables as additional arguments, but we avoid creating an environment and closure for
the function. Instead, we modify the call sites of each function to pass these extra values
directly to the code.

A transformed call site may mention variables that occur free in the function being
called, but not the original calling function. Therefore, we must take the set of applications to non-escaping functions into account when calculating the free variables of a
function.

We use a flat constructor tuple to represent constructor environments, and a flat
record to represent value environments. These environments are always allocated on the
heap. To support recursion, we simultaneously define the environments and closures of
a set of mutually recursive function using a Scheme-style "letrec" declaration.

TIL does not close over variables bound at the top level (i.e., outside of any function).
Such variables are mapped to labels (machine addresses) by lower levels of the compiler
and thus can be directly addressed. In practice, this results in a two-level environment,
where a data pointer is used to access top-level values and a closure pointer is used to

CHAPTER 8. THE TIL/ML COMPILER 188
access values defined within a function. The advantage of this approach is that heapallocated environments can be substantially smaller. The disadvantage is that values
bound at the top-level cannot easily be garbage collected, since these values are bound
to labels.

After closure conversion, we perform another round of optimization in an effort to
clean up any inefficiencies introduced by closure conversion. Some optimizations, notably
invariant removal and inlining, are turned off since they do not preserve the invariants of
closure conversion.

8.8 Ubform, Rtl, and Alpha
After closure conversion and closure optimization, we translate the resulting code to
Ubform. The Ubform intermediate language is an untyped Bform, but each variable is
labelled with representation information. We erase the distinction between computations
at the constructor and term levels in the translation to Ubform. Hence, constructor variables become term variables, constructor values become term values, and constructor
computations become term computations. Mono k constructors, such as Int c, are represented as an enumeration, whereas Mono k constructors that take an argument, such
as Record c are represented as tagged, variant records. Thus, the entire kind of Mono k
constructors is represented in the same fashion as an SML datatype.

The representation information on Ubform variables indicates whether each variable
is an integer, float, pointer to a heap-allocated value, or of unknown representation
at compile-time. Enum c, Enumorrec c, and Enumorsum c values are considered to be
pointers since the garbage collector can always determine whether they are in fact pointers
at run time. Variables with unknown representation are annotated with other variables
(corresponding to Bform type variables) that will contain the representation at runtime. An earlier stage boxes floating point values, thereby guaranteeing that variables of
unknown representation are never floats. This invariant allows the register allocator to
always assign a general purpose register to variables of unknown representation. Without
the invariant, the register allocator would have to assign both a general purpose machine
register and a floating point register to the variable and use dynamic type analysis to
decide which of the two registers to use.

The Ubform representation is quite similar to a direct-style version of the CPS intermediate form used by Shao and Appel in the SML/NJ compiler [110]. While Shao
and Appel claim that their compiler is type-based, they only use representation-based,
untyped intermediate forms. Hence, it is not possible, in general, to verify automatically
that any of their intermediate representations are type-safe. In contrast, only the last
stages of TIL are untyped and a type checker can be used to verify automatically the
type integrity of the code, even after optimization and closure conversion. Furthermore,

CHAPTER 8. THE TIL/ML COMPILER 189
the representation information we use at the Ubform level is more general than the representation information used by Shao and Appel, since we allow dynamic instantiation
of representation information.

Currently, no optimization or other transformations occur at the Ubform level. We
simply use the translation to Ubform as a convenient way to stage the compilation of the
closure-converted code to the next intermediate form. This next form is called Rtl, which
stands for Register Transfer Language. Rtl is similar to Alpha, MIPS, and other RISCstyle assembly languages. However, it provides heavy-weight function call and return
mechanisms, and a form of interprocedural goto for implementing exceptions. Rtl also
provides an infinite number of pseudo-registers. In the conversion from Ubform to Rtl,
we decide whether Ubform variables will be represented as constants, labels, or pseudoregisters. During the conversion, we also eliminate exceptions, insert tagging operations
for records and arrays, and insert garbage collection checks.

The Rtl level would be suitable for a conventional, low-level imperative optimizer,
similar to the ones found in C and Fortran compilers. We perform a few small optimizations, notably collapsing garbage collection checks and eliminating redundant loads of
small constants.

Finally, the Rtl representation is translated to Alpha. Alpha is DEC Alpha assembly
language, with extensions similar to those for Rtl. In the translation from Rtl to Alpha,
we use conventional graph-coloring register allocation to allocate physical registers for
the Rtl pseudo-registers. We also construct tables describing the layout and garbage
collection information for each stack frame.

8.9 Garbage Collection
The translation from Ubform to Rtl and the translation from Rtl to Alpha, maintain
the representation information that annotates variables. This representation information
is used to construct tables for garbage collection. These tables tell the collector which
registers and which stack slots contain pointers to heap-allocated objects.

Abstractly, we record enough information to determine which registers and which
stack slots are live at every call site, and whether or not to trace these values, based on
the representation information. We use the return address of call sites as an index to
find the information and ensure that the return address is always saved in the first slot
of a stack frame. In these respects, our collector closely resembles Britton's collector for
Pascal [23] and the formal development of Chapter 7.

However, our collector is complicated by two details: the first complication is that
some values have unknown representation at compile time. At the Ubform level, these
values are labelled with another variable (corresponding to a type variable) that, at run
time, indicates the representation of the value. Hence, for values of unknown represenCHAPTER 8. THE TIL/ML COMPILER 190
tation, we must record where this other variable can be found so that the collector can
determine whether or not to trace the original value. In this respect, our collector resembles Tolmach's tag-free collector for SML [119]. However, Tolmach calculates unknown
representations lazily during garbage collection, because he does not have a general programming language at the type level. In particular, he only supports substitution at the
constructor level and not, for instance, Typerec. In contrast, our constructor computations can perform type analysis, function call, and allocation. Therefore, we calculate
unknown representations eagerly, during program evaluation so that all representations
are already calculated before garbage collection is invoked.

The second complication is that we split the registers into a set of caller-saves and
a set of callee-saves registers. Callee-saves registers are used to hold values needed after
a procedure call. To use a callee-saves register as a temporary, a procedure must save
the contents of the register on the stack and restore the contents before returning to the
caller.

In effect, callee-saves registers are like extra arguments to a procedure that are simply returned with the result of the procedure. Unfortunately, the types and thus the
representations of these extra arguments are unknown to the called procedure. We solve
this issue by recording when callee-saves registers are saved into stack slots and when
variables are placed into callee-saves registers. During garbage collection, we process the
stack from oldest frame to youngest frame. Initially, the callee-saves registers are not
live. If the first procedure places values into the callee-saves registers, then it knows the
representations of these values. We propagate this information to the next stack frame.
If the next procedure spills a callee-saves register to the stack, then we can determine the
representation of the stack slot from the propagated representation information. Otherwise, we simply forward the representation information to the next stack frame, and
so on. This approach to reconstructing type information is similar to the approach suggested by Appel [8] and Goldberg and Gloger [49, 50]. Once we determine which registers
and which stack slots must be traced, we perform a standard copying garbage collection
on the resulting roots. Currently, we use a simple two-generation collector.

8.10 Performance Analysis of TIL
In this section, I compare the performance of code produced by TIL against code produced
by the SML/NJ compiler [12]. I also examine other aspects, including heap allocation,
physical memory requirements, executable size, and compile time. The goal is to show
that, for a reasonable set of benchmarks, TIL produces code that is comparable (or
better) than the code produced by SML/NJ, at least for the subset of SML that TIL
currently supports.

However, I make no attempt to compare TIL and SML/NJ except for these end-toCHAPTER 8. THE TIL/ML COMPILER 191
end measurements. There are many differences between these two systems, so we cannot
directly compare particular implementation choices (such as whether or not to use tagfree collection), simply because we cannot fix all of the other variables. By showing that
TIL code is comparable to SML/NJ, I hope to persuade the reader that a type-based
implementation of SML that uses novel technologies, such as dynamic type dispatch and
tag-free collection, can compete with one of the best existing ML compilers.

8.10.1 The Benchmarks
I chose a set of small to medium-sized benchmarks ranging from a few lines up to 2000
lines of code to measure the performance of TIL. Larger programs would be desirable, but
there are few large SML programs that do not use nested modules or functors. Table 8.1
describes these programs. The benchmarks cover a range of application areas including
scientific computing, list processing, systems programming, and compilers. Some of these
programs have been used previously for measuring ML performance [9, 36]. Others were
adapted from the Caml-Light distribution [24].

For this set of comparisons, I compiled all of the programs as single closed modules.
For lexgen and simple, which are standard benchmarks [9], I eliminated functors by
hand, since TIL does not yet support functors.

For TIL, I compiled programs with all optimizations enabled. For SML/NJ, I compiled programs using the default optimization settings. I used a recent internal release
of SML/NJ (a variant of version 108.3), since it produces code that is about 35% faster
than the standard 0.93 release of SML/NJ [110].

For both compilers, we extended the built-in types with safe 2-dimensional arrays.
The 2-d array operations perform bounds checking on each dimension and then use unsafe
1-d array operations. Arrays are stored in column-major order.

TIL automatically prefixes a set of operations onto each module that it compiles. This
"inline" prelude is about 280 lines in length. It contains 2-d array operations, commonlyused list functions, and so forth. By prefixing the module with these definitions, we
ensure that they are exposed to the optimizer. To avoid handicapping SML/NJ, I created
separate copies of the benchmark programs for SML/NJ, and carefully placed equivalent
"prelude" code at the beginning of each program.

Since TIL creates stand-alone executables, I used the exportFn facility of SML/NJ
to create stand-alone programs. The exportFn function of SML/NJ dumps part of the
heap to disk and throws away the interactive system.

8.10.2 Comparison against SML/NJ
I compared the performance of TIL against SML/NJ in several dimensions: execution
time, total heap allocation, physical memory footprint, the size of the executable, and

CHAPTER 8. THE TIL/ML COMPILER 192

Program lines Description
cksum 241 Checksum fragment from the Foxnet [18], doing 5000 checksums

on a 4096-byte array, using a stream interface [17].
dict 166 Insert 10,000 strings, indexed by integers into a balanced binary tree, lookup each string and replace it with another. The
balanced binary trees are taken from the SML/NJ library.
fft 246 Fast-Fourier transform.

fmult 63 Matrix multiply of two 100x100 floating point matrices.
imult 63 Matrix multiply of two 200x200 integer matrices.
kb 618 The Knuth-Bendix completion algorithm.
lexgen 1123 A lexical-analyzer generator [13], processing the lexical description of SML/NJ.
life 146 A simulation of cells implemented using lists [103].
logic 459 A simple Prolog-like interpreter, with unification and backtracking.
msort 45 List merge sort of 5,120 integers, 40 times.

pia 2065 A Perspective Inversion Algorithm [125] deciding the location of

an object in a perspective video image.
qsort 141 Integer array quicksort of 50,000 pseudo-random integers, 2

times.sieve 27 Sieve of Eratosthenes, filtering primes up to 30000.

simple 870 A spherical fluid-dynamics program [39], run for 4 iterations

with grid size of 100.
soli 131 A solver for a peg-board game.

Table 8.1: Benchmark Programs

CHAPTER 8. THE TIL/ML COMPILER 193

25%
50%
75%
100%
125%
150%

cksum dict fft fmult imult kb lexgen life logic msort pia qsort sieve simple soli

Figure 8.4: TIL Execution Time Relative to SML/NJ

compilation time.

I measured execution time on a DEC Alpha AXP 250-4/266 workstation, running
OSF/1, version V3.2, using the UNIX getrusage function. For SML/NJ, I started
timing after the heap had been reloaded. For TIL, I measured the entire execution time
of the process, including load-time. I made 5 runs of each program on an unloaded
workstation and chose the lowest execution time. The workstation had 96 Mbytes of
physical memory, so paging was not a factor in the measurements.

I measured total heap allocation by instrumenting the TIL runtime to count the bytes
allocated. I used existing instrumentation in the SML/NJ run-time system. I measured
the maximum amount of physical memory during execution using getrusage.

To compare program sizes, I first compiled empty programs under TIL and under
SML/NJ. The empty program for TIL generates a stripped executable that is around
250 Kbytes, whereas the empty program for SML/NJ consists of roughly 425 Kbytes
from the runtime, and 170 Kbytes from the heap, for a total of 595 Kbytes. Next, I
stripped all executables produced by TIL, and then subtracted the size of the empty
program (250 Kbytes) from the size of each program. For SML/NJ, I measured the size
of the heap generated by exportFn for each program and subtracted the size of the heap
generated by the empty program (170 Kbytes).

Finally, I measured end-to-end compilation time, including time to assemble files
produced by TIL and time to export a heap image for SML/NJ.

Figures 8.4 through 8.8 present the measurements. The raw numbers appear in Tables
8.2 through 8.6. For each benchmark, measurements for TIL were normalized to those
for SML/NJ and then graphed. SML/NJ represents the 100% mark on all the graphs,

CHAPTER 8. THE TIL/ML COMPILER 194

25%
50%
75%
100%
125%

cksum dict fft kb lexgen life logic msort pia qsort sieve simple soli
Figure 8.5: TIL Heap Allocation Relative to SML/NJ (excluding fmult and imult)

25%
50%
75%
100%
125%
150%
175%
200%
225%

cksum dict fft fmult imult kb lexgen life logic msort pia qsort sieve simple soli

Figure 8.6: TIL Physical Memory Used Relative to SML/NJ

CHAPTER 8. THE TIL/ML COMPILER 195

25%
50%
75%
100%
125%
150%
175%
200%

cksum dict fft fmult imult kb lexgen life logic msort pia qsort sieve simple soli
Figure 8.7: TIL Executable Size Relative to SML/NJ (without runtimes)

100%
500%

1000%
1500%
2000%

cksum dict fft fmult imult kb lexgen life logic msort pia qsort sieve simple soli

Figure 8.8: Til Compilation Time Relative to SML/NJ

CHAPTER 8. THE TIL/ML COMPILER 196
indicated by a solid horizontal line.

Figure 8.4 presents relative running times. On average, programs compiled by TIL
run about two times faster than programs compiled by SML/NJ. All programs but kb
and msort run faster under TIL than under SML/NJ. Furthermore, the TIL versions
of the largest programs, lexgen, pia, and simple, are more than twice as fast as their
SML/NJ counterparts. Finally, the slowest program, msort, is no more than 50% slower
than the SML/NJ version.

The kb benchmark uses exceptions and exception handlers quite frequently. TIL does
a relatively poor job of register saving and restoring around exception handlers and I
suspect that this is the reason for its poor performance on this benchmark. The poor
performance of msort is most likely due to the difference in garbage collectors for the two
systems, since roughly two-thirds of the running time for TIL is spent in the collector. I
speculate that the multi-generational collector of SML/NJ does a better job of memory
management for this benchmark.

Since SML/NJ flattens arguments using Leroy-style coercions, and also flattens some
constructors (see Section 8.5.3), the primary difference in performance for most benchmarks is not due to my type-directed translations. Most likely, the primary difference in
performance is due to the conventional optimizations that TIL employs [115]. What is
remarkable is that, even though TIL employs more optimizations than SML/NJ, the use
of types and dynamic type dispatch does not interfere with optimization. Furthermore,
for some benchmarks (notably fft and simple) much, if not all, of the performance improvement is due to the type-directed array flattening (see Section 8.10.4). Regardless, a
reasonable conclusion to draw from these measurements is that type-directed compilation
and dynamic type dispatch does not interfere with optimization and, when coupled with
a good optimizer, yields code that competes quite well with existing compilers.

Figure 8.5 compares the relative amounts of heap allocation between TIL and
SML/NJ, except for the fmult and imult benchmarks. The TIL version of fmult allocates over 16 Mbytes of data, whereas the SML/NJ version allocates less around 1
Kbyte. This is entirely because TIL does not flatten floating point values into registers
across function calls. During the dot product loop of the TIL version, floating point
values are pulled out of the arrays, multiplied, and added to an accumulator, and the
accumulator is boxed as it is passed around the loop. Under SML/NJ, the accumulator
remains unboxed. In contrast, the TIL version of imult does not allocate at all at run
time, whereas the SML/NJ version allocates about 1 Kbyte. Even including fmult but
excluding imult, the geometric mean of the ratios of heap-allocated data shows that TIL
programs allocate about 34% of the amount of data that SML/NJ allocates. This low
percentage is not surprising, because TIL uses a stack for activation records, whereas
SML/NJ allocates activation records on the heap.

Figure 8.6 presents the relative maximum amounts of physical memory used. TIL

CHAPTER 8. THE TIL/ML COMPILER 197
programs tend to use either much less or much more memory than SML/NJ programs.
I speculate that some variability is due to the different strategies used to size the heaps.
SML/NJ uses a multi-generational collector with a heap-size-to-live-data ratio of 3 to 1
for older generations, whereas TIL uses a two-generation collector that has a heap-sizeto-live-data ratio of up to 10 to 1 (the ratio varies). Also, since TIL does not yet properly
implement tail-recursion (tail calls within exception handlers are not implemented properly) the stack may be larger than it needs to be.

Figure 8.7 compares executable sizes, excluding runtimes and any pervasives. On
average, TIL programs are about 80% of the size of SML/NJ programs, and no program
is more than twice as big as the SML/NJ version. These sizes confirm that generating
tables for nearly tag-free garbage collection consumes a modest amount of space. The
numbers also establish that the inlining strategy used by TIL produces code of reasonable
size.

Figure 8.8 compares compilation times for TIL and SML/NJ. SML/NJ does quite
a lot better than TIL when it comes to compilation time, compiling about six times
faster. However, we have yet to tune TIL for compilation speed. Most of the compile
time is spent in the optimizer and the register allocator. We assume that much of the
time in the register allocator can be eliminated by using an intelligent form of coalescing
as suggested by George and Appel [45]. We assume that much of the time spent in the
optimizer can be eliminated by simply tuning and inlining key routines.

Another reason the optimizer is slow is that we always fully normalize a type whenever we want to determine some property (e.g., the domain or range of an arrow type).
Normalizing is an expensive process that destroys a great deal of sharing. By lazily
normalizing, we hope to improve many optimization phases that depend upon type information.

Finally, I speculate that a great deal of time and allocation during compilation is
due to our naive approach of maintaining type information. In particular, we label each
bound value variable with its type, and we label each bound type variable with its kind.
In the B-form representation, this means that almost every construct has associated type
information and this type information contains a great deal of kind information. Much
of the type/kind information is unneeded or can easily be recovered. Many primitive
transformations, such as ff-conversion, must process this unneeded information and are
thus slowed by the inefficient representation.

8.10.3 The Effect of Separate Compilation
In this section, I explore the effect that separate compilation has on the performance
of some of the benchmarks. When programs are separately compiled, the optimizer
cannot perform as many reductions and transformations. Hence, the likelihood that
the resulting program will use dynamic dispatch increases when compared to the same

CHAPTER 8. THE TIL/ML COMPILER 198
program compiled all together.

I took two of the larger programs, logic and lexgen, and broke them into modules at
natural boundaries, resulting in the benchmark programs logic s and lexgen s. These
benchmarks should give an indication of how TIL performs with realistic, separately
compiled programs.

I also took the dict, fmult, imult, and msort benchmarks, placed the core routines
into separate modules, and abstracted the types and primitive operations of the routines.
Thus, these modules provide a set of generic library routines and abstract datatypes
(balanced binary trees, matrix multiply, list sort) that can be used at any type. During
development, programmers are likely to use such modules. I wanted to determine what
the costs are of holding the types abstract and separately compiling the modules from
their uses.

Table 8.7 describes the resulting benchmarks. The running times of these benchmarks
relative to SML/NJ are graphed in Figure 8.9, and the raw numbers are given in Table
8.8. On the whole, the TIL programs run roughly as well or better than their SML/NJ
counterparts. Only logic s, msort0 and msort1 are slower, and by no more than 20%.

Figure 8.10 compares the running times of each of the separately compiled programs to
the comparable, globally compiled benchmark of the previous section. For the non-matrix
benchmarks, we see about a 10-20% overhead in separate compilation. For the matrix
benchmarks, we see over a 350% overhead. The difference between the fmult0/imult0
and fmult1/imult1 bars is because fmult0 and imult0 must perform dynamic type
dispatch to select an array operation, whereas fmult1 and imult1 do not. Hence, we
see that most of the overhead of separate compilation is not due to type abstraction, but
rather to the fact that the primitive operations (multiplication and addition) are held
abstract.

These figures indicate that TIL provides a tradeoff between separate compilation
and performance. During development, programmers can use separate compilation and
expect that their code will perform reasonably well. Towards the end of development,
as key routines are identified through profiling, programmers can specialize the types of
generic routines and expect a modest gain in performance, without sacrificing full separate
compilation. Clients of a specialized generic abstraction need only be re-compiled if the
type exported by that abstraction changes. At the very end of development, when the
most important abstractions and routines are identified, programmers can inline these
modules to get the best performance, but at the cost of separate compilation.

8.10.4 The Effect of Flattening
In this section, I explore the performance effect of the various type-directed flattening
translations in TIL. Of course, we cannot easily determine the entire impact of types on
the system. For instance, it is impossible to determine what effect the tag-free garbage

CHAPTER 8. THE TIL/ML COMPILER 199

25%
50%
75%
100%
125%

dict0 dict1 fmult0 fmult1 imult0 imult1 lexgen s logic s msort0 msort1
Figure 8.9: TIL Execution Time Relative to SML/NJ for Separately Compiled Programs

50%
100%
150%
200%
250%
300%
350%

dict0 dict1 fmult0 fmult1 imult0 imult1 lexgen s logic s msort0 msort1
Figure 8.10: Execution Time of Separately Compiled Programs Relative to Globally
Compiled Programs

CHAPTER 8. THE TIL/ML COMPILER 200
collector has without building a corresponding tagging collector. Therefore, I have only
examined those uses of types that I can easily turn off and on.

For each of the benchmarks described in the previous section, I measured the running
time and amount of heap allocation of the program when compiled in the following ways:

ffl B (Baseline): We do not flatten arguments, constructors, or arrays.
ffl FC (Flattened Constructors) : We flatten all Enumorrec c constructors that contain records. This effectively flattens lists and option datatypes. Dynamic type
dispatch is used when the component type is unknown.

ffl CAF (Conventional Argument Flattening): In addition to FC, We examine the

call sites of each non-escaping function. If each call-site applies the function to a
known record, then we flatten the function and pass the components of the record
directly as arguments.

ffl TDAF (Type-Directed Argument Flattening): In addition to FC, we flatten all

functions that take records as arguments, and flatten all applications of functions
to records. We use dynamic type dispatch when the argument type is unknown.

ffl FRA (Flattened Real-Arrays): In addition to TDAF, we flatten all polymorphic

arrays of floating point values. We use dynamic type dispatch for array operations,
when the component type is unknown.

Tables 8.9 and 8.10 record the running times (in seconds) and amounts of heap allocation
(in megabytes) for each program compiled in each configuration. The numbers in parenthesis indicate the ratio to the corresponding baseline. Figure 8.10.4 plots the running
times, normalized to the baseline; Figure 8.10.4 plots the allocation, normalized to the
baseline.

From the data, we can conclude that flattening both constructors and arguments is
almost always worthwhile, both in terms of running times and allocation. All together,
the flattening phases provide an average speedup of 42% and decrease allocation by 50%.
The biggest improvements for most benchmarks comes from argument flattening. Furthermore, type-directed argument flattening does as well if not better than conventional
argument flattening in almost all cases, providing an addition speedup of 7% and an
additional decrease in allocation of 9%, on average. This is in part because type-directed
flattening is able to flatten higher-order functions, whereas conventional argument flattening cannot.

The increase in running time for imult, when constructors are flattened, appears to
be an anomaly in the measurements. Separate and longer runs (10 times each) indicate
that constructor flattening has no measurable effect at all on running times or allocation,
but the original data shows a 19% increase in running times.

CHAPTER 8. THE TIL/ML COMPILER 201

Eff
ect
s o
f Fl
atte

nin
g o
n R
unn

ing
 Tim

es

020406080100120140

cksum

dict
fft

fmult
imult
kb

lexgen
life

logic

msort
pia

qsort

sieve

simple
soli

Pro
gra
m

Percentage Execution Time Relative to Baseline

FC CAFTD

AF

FRA

CHAPTER 8. THE TIL/ML COMPILER 202

Effects of Flattening on Allocation

0102030405060708090100

cksum

dict
fft

fmult
imult
kb

lexgen
life

logic

msort
pia

qsort

sieve

simple
soli

Pro
gra
m

Percentage Allocation Relative to Baseline

FC CAFTD

AF

FRA

CHAPTER 8. THE TIL/ML COMPILER 203

Flattening real arrays has mixed results on most benchmarks, causing allocation or
running times to vary up or down slightly. This is not surprising since most of the
benchmarks do not manipulate floating point arrays; when floating point arrays are
flattened, these benchmarks must perform dynamic type dispatch when working with
other array types. However, some benchmarks that do manipulate floating point arrays,
notably fft and simple, show dramatic speedups: fft shows an 84% improvement in
running time and an 88% reduction in allocation. Surprisingly, the amount of allocation
for simple increases, but running times decrease. I speculate that, since we box floating
point values passed to other functions, this accounts for the increased allocation, since
values pulled out of a flattened array must be boxed before being passed to a function. A
similar effect happens for fmult. Furthermore, these boxes are short-lived -- lasting only
a function call -- and are thus not preserved by the garbage collector. In contrast, when
values are boxed before being placed in an array, the boxes may tend to live longer. Also,
as boxed arrays are updated, the generational collector must be informed of any potential
generational conflicts. This may account for the fact that simple allocates more, but runs
faster when floating point arrays are flattened. Regardless, since flattening real arrays
has a negligible negative effect on the other benchmarks, it is a worthwhile optimization.

All of these results are consistent with results seen by Shao and Appel [110]. The
advantages of my approach are that (a) we can flatten data constructors without making
restrictions at the source level, (b) we can flatten arrays, (c) we need not tag values for
garbage collection or polymorphic equality.

CHAPTER 8. THE TIL/ML COMPILER 204

Program Exec. time (s) TIL/NJ

TIL NJ

cksum 2.36 11.68 0.20
dict 0.40 0.57 0.70
fft 1.39 15.67 0.09
fmult 0.33 0.50 0.66
imult 1.46 4.93 0.30
kb 1.93 1.74 1.11
lexgen 0.65 2.76 0.24
life 1.29 1.44 0.90
logic 7.98 9.42 0.85
msort 2.72 1.82 1.49
pia 0.38 1.11 0.34
qsort 0.44 1.31 0.34
sieve 0.39 0.30 1.30
simple 8.51 24.02 0.35
soli 0.31 0.56 0.55
Geo. mean 0.50

Table 8.2: Comparison of TIL Running Times to SML/NJ

CHAPTER 8. THE TIL/ML COMPILER 205

Program Heap alloc. (Kbytes) TIL/NJ

TIL NJ

cksum 143.897 984.775 0.15
dict 12.445 38.495 0.32
fft 9.108 214.853 0.04
fmult 16.000 0.001 16,000.00
imult 0.000 0.001 0.00
kb 36.941 96.761 0.38
lexgen 8.753 113.405 0.08
life 25.447 45.259 0.56
logic 253.053 525.997 0.48
msort 114.052 121.738 0.94
pia 5.238 55.142 0.09
qsort 1.035 35.332 0.03
sieve 2.525 7.282 0.35
simple 323.394 826.504 0.39
soli 0.328 15.606 0.02

Geo. mean (excluding imult) 0.39

Table 8.3: Comparison of TIL Heap Allocation to SML/NJ

CHAPTER 8. THE TIL/ML COMPILER 206

Program Phys. mem. (Kbytes) TIL/NJ

TIL NJ

cksum 672 1472 0.46
dict 1152 1872 0.62
fft 2672 17592 0.15
fmult 816 936 0.87
imult 504 1208 0.42
kb 2712 3480 0.78
lexgen 1672 2992 0.56
life 816 1208 0.68
logic 6576 4096 1.61
msort 10032 4896 2.05
pia 1376 1592 0.86
qsort 1096 1536 0.71
sieve 2256 2576 0.88
simple 9088 17784 0.51
soli 1000 1120 0.89

Geo. mean 0.69

Table 8.4: Comparison of TIL Maximum Physical Memory Used to SML/NJ

CHAPTER 8. THE TIL/ML COMPILER 207

Program Exec. size (Kbytes) TIL/NJ

TIL NJ

cksum 32.768 73.840 0.44
dict 24.576 30.720 0.80
fft 40.960 85.128 0.48
fmult 163.840 196.632 0.83
imult 327.680 196.632 1.67
kb 90.112 74.880 1.20
lexgen 271.336 153.824 1.76
life 40.960 20.480 2.00
logic 98.304 51.272 1.92
msort 8.192 18.432 0.44
pia 237.568 149.728 1.59
qsort 16.384 38.936 0.42
sieve 8.192 17.408 0.47
simple 188.416 325.808 0.58
soli 16.384 58.424 0.28

Geo. mean 0.81

Table 8.5: Comparison of TIL Stand-Alone Executable Sizes to SML/NJ (excluding
runtimes)

CHAPTER 8. THE TIL/ML COMPILER 208

Program Comp. time (s) TIL/NJ

TIL NJ

cksum 12.89 1.62 7.96
dict 11.44 1.57 7.29
fft 11.24 2.13 5.28
fmult 3.88 0.77 5.04
imult 3.88 0.78 4.97
kb 59.42 7.19 8.26
lexgen 262.52 13.60 19.3
life 21.15 2.48 8.53
logic 85.40 7.01 12.18
msort 3.79 0.73 5.19
pia 205.16 15.93 12.89
qsort 7.27 1.25 5.82
sieve 2.52 0.57 4.42
simple 206.46 18.27 11.30
soli 10.52 1.35 7.79

Geo. mean 5.8

Table 8.6: Comparison of TIL Compilation Times to SML/NJ

CHAPTER 8. THE TIL/ML COMPILER 209

Program Description
dict0 Generic dictionary structure, with key and value types held abstract as well as key comparison function. Instantiated with
integer keys and string values as in the dict benchmark.
dict1 Same as dict0, but with types known. Only the key comparison

is held abstract.fmult0 Generic matrix multiply routine, with element type held abstract as well as primitive multiplication, addition, and zero values. Instantiated with floating point type and values as in the
fmult benchmark.fmult0 Same as fmult0, but with the element type known (real). Only

the primitive multiplication, addition, and zero values are held
abstract.imult0 Generic matrix multiply routine, with element type held abstract as well as primitive multiplication, addition, and zero values. Instantiated with integer type and values as in the imult
benchmark.imult1 Same as imult0, but with the element type known (int). Only

the primitive multiplication, addition, and zero values are held
abstract.lexgen s Same as lexgen benchmark, but broken into separately compiled modules.
logic s Same as logic benchmark, but broken into separately compiled

modules.msort0 Generic list merge sort, with element type held abstract as well

as comparison operator. Instantiated with integer type and comparison as in the msort benchmark.
msort1 Same as msort0, but with the element type known (int). Only

the comparison operator is held abstract.

Table 8.7: Separately Compiled Benchmark Programs

CHAPTER 8. THE TIL/ML COMPILER 210

Program Comp. time (s) TIL/NJ

TIL NJ

dict0 0.47 0.58 0.81
dict1 0.38 0.57 0.67
fmult0 1.19 1.20 0.99
fmult1 1.01 1.15 0.88
imult0 5.19 7.57 0.67
imult1 3.58 7.57 0.47
lexgen s 0.72 2.49 0.29
logic s 9.99 8.74 1.14
msort0 3.24 2.73 1.19
msort1 2.93 2.73 1.07

Table 8.8: Comparison of TIL Execution Times Relative to SML/NJ for Separately
Compiled Programs

Program Execution time in seconds (ratio to baseline)

B FC CAF TDAF FRA

cksum 3.92 3.65 (0.93) 3.15 (0.80) 2.29 (0.58) 2.36 (0.60)
dict 0.68 0.64 (0.94) 0.45 (0.66) 0.41 (0.60) 0.40 (0.59)
fft 12.26 11.41 (0.93) 11.20 (0.91) 11.60 (0.95) 1.39 (0.11)
fmult 0.47 0.46 (0.98) 0.37 (0.79) 0.35 (0.74) 0.33 (0.70)
imult 2.80 3.32 (1.19) 1.54 (0.55) 1.47 (0.53) 1.46 (0.52)
kb 2.58 2.49 (0.97) 2.45 (0.95) 2.01 (0.78) 1.93 (0.75)
lexgen 1.23 0.94 (0.76) 0.80 (0.65) 0.71 (0.58) 0.65 (0.53)
life 1.77 1.37 (0.77) 1.33 (0.75) 1.28 (0.72) 1.29 (0.73)
logic 10.45 10.07 (0.96) 8.87 (0.85) 7.92 (0.76) 7.98 (0.76)
msort 6.45 4.37 (0.68) 2.80 (0.43) 2.75 (0.43) 2.72 (0.42)
pia 0.46 0.41 (0.89) 0.37 (0.80) 0.37 (0.80) 0.38 (0.83)
qsort 0.50 0.50 (1.00) 0.44 (0.88) 0.44 (0.88) 0.44 (0.88)
sieve 0.58 0.43 (0.74) 0.43 (0.74) 0.39 (0.67) 0.39 (0.67)
simple 18.99 17.94 (0.94) 15.75 (0.83) 13.40 (0.71) 8.52 (0.45)
soli 0.32 0.31 (0.97) 0.39 (1.22) 0.31 (0.97) 0.31 (0.97)

Geom. mean (0.90) (0.77) (0.70) (0.58)

Table 8.9: Effects of Flattening on Running Times

CHAPTER 8. THE TIL/ML COMPILER 211

Program Allocation in Mbytes (ratio to baseline)

B FC CAF TDAF FRA

cksum 307.99 267.02 (0.87) 205.35 (0.77) 143.90 (0.47) 143.90 (0.47)
dict 35.66 31.73 (0.89) 17.02 (0.48) 12.45 (0.35) 12.45 (0.35)
fft 51.48 51.48 (1.00) 51.00 (0.99) 51.00 (0.99) 9.11 (0.18)
fmult 24.00 24.00 (1.00) 16.00 (0.67) 16.00 (0.67) 16.00 (0.67)
imult 96.00 96.00 (1.00) 0.00 (0.00) 0.00 (0.00) 0.00 (0.00)
kb 54.96 53.52 (0.97) 53.24 (0.97) 36.94 (0.67) 36.94 (0.67)
lexgen 22.77 20.13 (0.88) 17.87 (0.78) 8.75 (0.38) 8.75 (0.38)
life 37.80 26.98 (0.71) 20.51 (0.54) 25.45 (0.67) 25.45 (0.67)
logic 384.37 345.49 (0.90) 292.07 (0.76) 253.05 (0.66) 253.05 (0.66)
msort 270.93 215.70 (0.80) 114.05 (0.42) 114.05 (0.42) 114.05 (0.42)
pia 7.64 6.80 (0.89) 5.33 (0.70) 5.24 (0.69) 5.24 (0.69)
qsort 6.06 6.06 (1.00) 1.04 (0.17) 1.04 (0.17) 1.04 (0.17)
sieve 4.21 2.53 (0.60) 2.53 (0.60) 2.53 (0.60) 2.53 (0.60)
simple 717.65 627.65 (0.87) 469.02 (0.65) 316.41 (0.44) 323.39 (0.45)
soli 0.33 0.33 (1.00) 0.33 (1.00) 0.33 (1.00) 0.33 (1.00)

Geom. mean
(excluding imult) (0.88) (0.65) (0.56) (0.50)

Table 8.10: Effects of Flattening on Allocation

Chapter 9
Summary, Future Work, and
Conclusions

In this thesis, I have demonstrated that compiler writers can take advantage of types for
everything from enhancing performance to proving correctness. The fundamental idea
behind my approach is to use a combination of type-directed translation and dynamic
type dispatch to build a language implementation. Type-directed translation provides a
formal framework for specifying and proving the correctness of compiler transformations,
whereas dynamic type dispatch provides a means for applying type-directed translation
to languages with unknown or variable types.

9.1 Summary of Contributions
I have presented a core calculus, called *MLi , that provides dynamic type dispatch at both
the term and the constructor levels. I have shown that type-checking *MLi is decidable
and that the type system is sound with respect to the operational semantics.

I gave examples of type-directed translations for SML-like languages to *MLi -like languages. These translations demonstrated how function arguments and data structures
could be flattened, how tag-free ad-hoc operations such as polymorphic equality could
be implemented, how the constraints of Haskell-style type classes could be encoded, and
how communication primitives could be strongly typed, yet dynamically instantiated. I
also demonstrated how to prove correctness of these translations using logical relations.

I showed how a key transformation in functional language implementation, closure
conversion, could be implemented as a type-directed and type-preserving translation,
even for languages like *MLi . I also proved the correctness of this translation.

I developed a formal, yet intuitive framework for expressing program evaluation that
makes the heap, stack, and registers explicit. This model of evaluation allowed me

212

CHAPTER 9. SUMMARY, FUTURE WORK, AND CONCLUSIONS 213
to address memory management issues that higher-level models leave implicit. I gave a
general definition of garbage and a general specification of trace-based garbage collectors.
I proved that such collectors do not interfere with evaluation. I then showed how types
could be used to derive shape information during garbage collection, thereby obviating
the need to place tags on values at run time. I proved the correctness of this tag-free
collection algorithm for monomorphic languages and showed how to extend the technique
to *MLi -like languages. My formulation was at a sufficiently abstract level that the proofs
were tractable, yet the formulation was not so abstract that important details were lost.

Together with others, I constructed a compiler for SML called TIL to explore the
practical issues of type-directed translation and dynamic type dispatch. This compiler
uses typed intermediate languages based on *MLi for almost all optimizations and transformations. TIL uses type-directed translation and dynamic type dispatch to flatten
arguments, to generate efficient representations of datatypes, and to specialize arrays.
TIL also uses dynamic type dispatch to support partially tag-free garbage collection and
tag-free polymorphic equality. Finally, for a wide range of programs, the code emitted
by TIL is as good or better than code produced by Standard ML of New Jersey.

9.2 Future Work
Because this thesis explores so many aspects of types and language implementation, from
proving compiler correctness to implementing tag-free garbage collection, there are many
unresolved issues among each of the topics. In this section, I discuss those issues that I
feel are the most important.

9.2.1 Theory
From both a type-theoretic standpoint, one of the most interesting open issue for *MLi
is extending the language to support dynamic type dispatch on recursive types at the
constructor level. This would allow us to reify a much wider class of type translations
as constructor terms. For instance, the datatype flattening used in TIL can only be
expressed at the meta-level (i.e., in the TIL compiler) and not as a constructor within
the intermediate language Lmli. However, a straightforward extension of Typerec to
generally recursive types is difficult, as this is likely to break constructor normalization,
and hence decidability of type checking.

Of a related nature, the restriction to predicative polymorphism is suitable for interpreting ML-like languages. However, this restriction prevents us from compiling languages based on the original Girard-Reynolds impredicative calculus. Girard has shown
that adding Typerec-like operators to such calculi breaks strong normalization [47], so it
is unlikely that there is a simple calculus that provides both decidable type checking and

CHAPTER 9. SUMMARY, FUTURE WORK, AND CONCLUSIONS 214
impredicative polymorphism. In an impredicative calculus, recursive types (_), 8-types,
and 9-types can all be viewed as primitive constructors of kind (\Omega  ! \Omega ) ! \Omega , so to some
degree, the ability to analyze recursive and polymorphic types requires some intensional
elimination form for functions.

Whereas *MLi provides a convenient intermediate form within a compiler, its use as
a source language is somewhat problematic. The issue is that dynamic type analysis
makes no distinction between user-level abstract types that happen to have the same
representation. From a compiler perspective, the whole purpose of dynamic type dispatch
is to violate the very abstraction that a programmer establishes. There are a variety
of approaches that could be taken to solve this problem. The work of Duggan and
Ophel [38] and Thatte [116] on kind-based definitions of type-classes seems promising
to me. The basic idea is to allow users to define new inductively generated kinds that
could be refinements or extensions of the kind of monotypes and, using a combination of
type dispatch and methods corresponding to the new constructors, allow users to define
appropriate elim forms at both the constructor and term levels.

In our previous work on closure conversion [92], we showed how closures could be
represented using a combination of translucent types and existentials. Using this representation in TIL would allow us to hoist code and environment projections out of
loops, but would greatly complicate the type system. In particular, the target language
of closure conversion would need to be impredicative, and as mentioned earlier, this is
problematic when combined with dynamic type analysis. However, I suspect that there
is a simpler formulation that offers the same performance benefits without requiring full
translucent sums and existentials.

Finally, all of these extensions make the underlying proof theory much more difficult. For instance, in an impredicative setting, we must use some technique like Girard's
method of candidates -- instead of simple, set-based logical relations -- to prove translation correctness. Providing simple formulations of these techniques is imperative.

9.2.2 Practice
From a practical standpoint, we now know that we can generate good code for polymorphic languages if types are readily available at compile time. Furthermore, we know that
for at least the applications studied here, types are either known for the most part, or can
be made to be known. However, I expect that the degree of polymorphism in programs
will only increase as more programmers start to use advanced languages. Hence, the next
logical step is to explore techniques to make polymorphism fast without constraining the
performance of monomorphic code. For example, it would be very profitable in terms of
execution time to hoist typecase expressions out of loops, in an effort to get good code
within the loops. However, hoisting typecase out of a loop requires that we duplicate
the body of the loop for each arm of the typecase. This may be entirely reasonable for

CHAPTER 9. SUMMARY, FUTURE WORK, AND CONCLUSIONS 215
small loops, such as the dot product of matrix multiply, where we have a small number
of cases in the typecase. However, in general, I feel that some sort of profile-driven
feedback mechanism is needed to determine which typecases should be hoisted.

Another practical point that needs to be addressed is the issue of unboxing floating
point values as function arguments and within data structures other than arrays. Unboxing floating point values in function arguments using the vararg/onearg approach is
problematic when there are a large number of argument registers and the underlying machine has split integer and floating point registers. The problem is that for k arguments,
vararg must be able to generate 2k coercions to deal with all of the possible calling
conventions. This approach is impractical if k is greater than a fairly small constant (i.e.,
5 or 6).

Fortunately, there is an alternative approach. When vararg is applied to a function
f that is expecting one argument, we generate a closure that contains a runtime routine
that works as follows: when the routine is called, it spills all of the possible argument
registers to the stack. Then, using the type of f , the routine determines which registers
actually contained arguments. Next, the routine allocates a record on the heap and copies
the argument values into the record. Finally, the routine calls f passing this record to
the function. A primitive corresponding to onearg would have the opposite functionality.
These primitives are likely to be more expensive than the tailored conversions that TIL
currently uses, and for conventional SML code -- which rarely manipulates floating point
values -- it is not clear that the overheads would justify the costs.

There are enough tradeoffs in data representations that it is not clear that, for instance, flattening floating point values in records would be worth the cost. Certainly,
flattening floating point values in arrays has mixed benefits. There are other issues
that should be addressed as well, including alignment, bit fields, "endian-ness", word
size, and so forth. Fortunately, TIL provides an excellent framework to explore these
representation tradeoffs.

Clearly, the compile times of TIL are a current problem, and we have yet to address
this issue. Initial tests confirm that the size of the type information on intermediate
terms is quite large. However, most optimizations, including common sub-expression
elimination, do not optimize types that decorate terms. Rather, the optimizer only
processes constructors that are bound via a let-construct at the term level. By extending
the optimizations to process types, it may be possible to reduce the size significantly, and
hence the compile times of terms. Alternatively, we could use a representation where as
little type and kind information as is possible remains on terms, and reconstruct this
information as needed.

There are a wealth of issues to explore with respect to tag-free garbage collection.
For example, it would be good to implement a fully tagging and fully tag-free implementation of TIL to explore the costs and benefits of our current approach. Fortunately, we
abstracted many details of the garbage collection implementation in the higher levels of

CHAPTER 9. SUMMARY, FUTURE WORK, AND CONCLUSIONS 216
the compiler so that these experiments would someday be possible.
9.3 Conclusions
For compiler writers, types provide a means of encapsulating complex invariants and
analysis information. Type-directed translation shows how we can take this analysis
information from the source-level and transform it, with the program, so that intermediate levels can take advantage of this information. In this respect, the type system of
*MLi is far more powerful than conventional polymorphic calculi because it encapsulates
control-flow information (i.e., Typerec). However, unlike a fully reflective language, *MLi
is sufficiently restricted that we can automatically normalize types and compare them.
These restrictions make proofs of compiler correctness tractable, and tools like the type
checker for TIL's intermediate forms possible.

A key advantage that type-directed translation has over traditional compiler transformations is that, for languages like SML, type information is readily available. Programmers must specify the types of imported values and often these types do not involve
variables. I took advantage of this property in TIL to perform argument, constructor, and
array flattening. These type-based transformations are in no way inhibited by higherorder functions or modules. In contrast, transformations based on data-flow, control-flow,
or set-based analyses often fail to optimize terms due to a lack of information. For example, the conventional argument flattener of TIL fails to flatten many functions that
the type-directed flattener does flatten. Even without programmer-supplied type information, the advances in soft typing [64, 7, 29, 132] provide a means for compiler writers
to take advantage of types.

In general, compilers and other kinds of system software have real issues and problems
that can serve as the clients and driving force behind the development of advanced type
systems. Changing an intermediate language in a compiler to take advantage of recent
advances is much more tractable than changing a ubiquitous source language. As type
systems become more advanced, more information will be available to compilers, enabling
more aggressive transformations. Thus, the real future for both type theory and compilers
is in their marriage.

Bibliography

[1] M. Abadi, L. Cardelli, P.-L. Curien, and J.-J.L'evy. Explicit substitutions. In Sixteenth

ACM Symposium on Principles of Programming Languages, pages 31-46, San Francisco,
Jan. 1990.

[2] M. Abadi, L. Cardelli, P.-L. Curien, and J.-J.L'evy. Explicit substitutions. Journal of

Functional Programming, 1(4):375-416, Oct. 1991.

[3] M. Abadi, L. Cardelli, B. Pierce, and G. Plotkin. Dynamic typing in a statically-typed

language. In Sixteenth ACM Symposium on Principles of Programming Languages, pages
213-227, San Francisco, Jan. 1990.

[4] M. Abadi, L. Cardelli, B. Pierce, and G. Plotkin. Dynamic typing in a statically-typed

language. ACM Transactions on Progamming Languages and Systems, 13(2):237-268,
Apr. 1991. Revised version of [3].

[5] S. Aditya and A. Caro. Compiler-directed type reconstruction for polymorphic languages.

In ACM Conference on Functional Programming and Computer Architecture, pages 74-
82, Copenhagen, June 1993.

[6] S. Aditya, C. Flood, and J. Hicks. Garbage collection for strongly-typed languages using

run-time type reconstruction. In ACM Conference on Lisp and Functional Programming,
pages 12-23, Orlando, June 1994.

[7] A. Aiken, E. L. Wimmers, and T. Lakshman. Soft typing with conditional types. In

Twenty-First ACM Symposium on Principles of Programming Languages, pages 163-173,
Portland, Jan. 1994.

[8] A. W. Appel. Runtime tags aren't necessary. LISP and Symbolic Computation, 2:153-162,

1989.

[9] A. W. Appel. Compiling with Continuations. Cambridge University Press, 1992.
[10] A. W. Appel. A critique of Standard ML. Journal of Functional Programming, 3(4):391-

429, Oct. 1993.

[11] A. W. Appel and T. Jim. Continuation-passing, closure-passing style. In Sixteenth ACM

Symposium on Principles of Programming Languages, pages 293-302, Austin, Jan. 1989.

217

BIBLIOGRAPHY 218

[12] A. W. Appel and D. B. MacQueen. Standard ML of New Jersey. In M. Wirsing, editor,

Third International Symposium on Programming Language Implementation and Logic
Programming, pages 1-13, New York, Aug. 1991. Springer-Verlag. Volume 528 of Lecture
Notes in Computer Science.

[13] A. W. Appel, J. S. Mattson, and D. Tarditi. A lexical analyzer generator for Standard

ML. Distributed with Standard ML of New Jersey, 1989.

[14] H. Baker. Unify and conquer (garbage, updating, aliasing ...) in functional languages. In

ACM Conference on Lisp and Functional Programming, pages 218-226, Nice, 1990.

[15] H. P. Barendregt. The Lambda Calculus: Its Syntax and Semantics, volume 103 of Studies

in Logic and the Foundations of Mathematics. North-Holland, revised edition, 1984.

[16] E. Barendsen and S. Smetsers. Conventional and uniqueness typing in graph rewrite

systems. In Proceedings of the 13th Conference on the Foundations of Software Technology and Theoretical Computer Science 1993, Bombay, New York, 1993. Springer-Verlag.
Extended abstract.

[17] E. Biagioni. Sequence types for functional languages. Technical Report CMU-CS-95-180,

School of Computer Science, Carnegie Mellon University, Aug. 1995. Also published as
Fox Memorandum CMU-CS-FOX-95-06.

[18] E. Biagioni, R. Harper, P. Lee, and B. Milnes. Signatures for a network protocol stack:

A systems application of Standard ML. In ACM Conference on Lisp and Functional
Programming, pages 55-64, Orlando, June 1994.

[19] L. Birkedal, N. Rothwell, M. Tofte, and D. N. Turner. The ML Kit, Version 1. Technical

Report 93/14, Department of Computer Science (DIKU), University of Copenhagen, 1993.

[20] G. E. Blelloch. NESL: A nested data-parallel language (version 2.6). Technical Report

CMU-CS-93-129, School of Computer Science, Carnegie Mellon University, Apr. 1993.

[21] H.-J. Boehm. Space-efficient conservative garbage collection. In ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 197-206, Albuquerque, June 1993.

[22] P. Branquart and J. Lewi. A scheme for storage allocation and garbage collection for

Algol-68. In Algol-68 Implementation. North-Holland Publishing Company, Amsterdam,
1970.

[23] D. E. Britton. Heap storage management for the programming language Pascal. Master's

thesis, University of Arizona, 1975.

[24] Caml light. http://pauillac.inria.fr:80/caml/.
[25] L. Cardelli. Phase distinctions in type theory. Unpublished manuscript.

BIBLIOGRAPHY 219

[26] L. Cardelli. The functional abstract machine. Polymorphism, 1(1), 1983.
[27] L. Cardelli. A language with distributed scope. Computing Systems, 8(1):27-59, Jan.

1995.

[28] L. Cardelli. A language with distributed scope. In Twenty-Second ACM Symposium on

Principles of Programming Languages, pages 286-297, San Francisco, Jan. 1995.

[29] R. Cartwright and M. Fagan. Soft typing. In ACM SIGPLAN Conference on Programming

Language Design and Implementation, pages 278-292, Toronto, June 1991.

[30] J. Chirimar, C. A. Gunter, and J. G. Riecke. Proving memory management invariants for a

language based on linear logic. In ACM Conference on Lisp and Functional Programming,
pages 139-150, San Francisco, June 1992.

[31] D. Cl'ement, J. Despeyroux, T. Despeyroux, and G. Kahn. A simple applicative language:

Mini-ML. In ACM Conference on Lisp and Functional Programming, pages 13-27, 1986.

[32] R. L. Constable, et. al. Implementing Mathematics with the NuPRL Proof Development

System. Prentice-Hall, 1986.

[33] C. Cousineau, P.-L. Curien, and M. Mauny. The categorical abstract machine. In ACM

Conference on Functional Programming and Computer Architecture, volume 201 of Lecture Notes in Computer Science, pages 50-64, Nancy, Sept. 1985. Springer-Verlag.

[34] A. Demers, M. Weiser, B. Hayes, H. Boehm, D. Bobrow, and S. Shenker. Combining

generational and conservative garbage collection: Framework and implementations. In
Seventeenth ACM Symposium on Principles of Programming Languages, pages 261-269,
San Francisco, Jan. 1990.

[35] A. Diwan, E. Moss, and R. Hudson. Compiler support for garbage collection in a statically

typed language. In ACM SIGPLAN Conference on Programming Language Design and
Implementation, pages 273-282, San Francisco, June 1992.

[36] A. Diwan, D. Tarditi, and E. Moss. Memory-system performance of programs with

intensive heap allocation. Transactions on Computer Systems, Aug. 1995.

[37] C. Dubois, F. Rouaix, and P. Weis. Extensional polymorphism. In Twenty-Second ACM

Symposium on Principles of Programming Languages, pages 118-129, San Francisco, Jan.
1995.

[38] D. Duggan and J. Ophel. Kinded parametric overloading. Technical Report CS-94-35,

University of Waterloo, Department of Computer Science, September 1994. Supersedes
CS-94-15 and CS-94-16, March 1994, and CS-93-32, August 1993.

BIBLIOGRAPHY 220

[39] K. Ekanadham and Arvind. SIMPLE: An exercise in future scientific programming.

Technical Report Computation Structures Group Memo 273, MIT, Cambridge, MA, July
1987. Simultaneously published as IBM/T. J. Watson Research Center Research Report
12686, Yorktown Heights, NY.

[40] M. Felleisen and D. P. Friedman. Control operators, the SECD-machine, and the lambdacalculus. In Third Working Conference on the Formal Description of Programming Concepts, pages 193-219, Aug. 1986.

[41] M. Felleisen and R. Hieb. The revised report on the syntactic theories of sequential control

and state. Theoretical Computer Science, 103:235-271, 1992.

[42] C. Flanagan, A. Sabry, B. F. Duba, and M. Felleisen. The essence of compiling with

continuations. In ACM SIGPLAN Conference on Programming Language Design and
Implementation, pages 237-247, Albuquerque, June 1993.

[43] P. Fradet. Collecting more garbage. In ACM Conference on Functional Programming

and Computer Architecture, pages 24-33, Orlando, June 1994.

[44] T. Freeman and F. Pfenning. Refinement types for ML. In ACM SIGPLAN Conference

on Programming Language Design and Implementation, pages 268-277, Toronto, June
1991. ACM.

[45] L. George and A. W. Appel. Iterated register coalescing. In Twenty-Third ACM Symposium on Principles of Programming Languages, Jan. 1996. To appear.

[46] J.-Y. Girard. Une extension de l'interpretation de G"odel `a l'analyse, et son application a

l'elimination des coupures dans l'analyse et la th'eorie des types. In Proceedings of the Second Scandinavian Logic Symposium, edited by J.E. Fenstad. North-Holland, Amsterdam,
pages 63-92, 1971.

[47] J.-Y. Girard. Interpr'etation Fonctionnelle et Elimination des Coupures dans

l'Arithm'etique d'Ordre Sup'erieur. PhD thesis, Universit'e Paris VII, 1972.

[48] K. G"odel. "Uber eine bisher noch nicht ben"utzte Erweiterung des finiten Standpunktes.

Dialectica, 12:280-287, 1958.

[49] B. Goldberg. Tag-free garbage collection for strongly typed programming languages.

In ACM SIGPLAN Conference on Programming Language Design and Implementation,
pages 165-176, Toronto, June 1991.

[50] B. Goldberg and M. Gloger. Polymorphic type reconstruction for garbage collection

without tags. In ACM Conference on Lisp and Functional Programming, pages 53-65,
San Francisco, June 1992.

[51] J. Gosling. Java intermediate bytecodes. In ACM SIGPLAN Workshop on Intermediate

Representations (IR'95), Jan. 1995.

BIBLIOGRAPHY 221

[52] C. A. Gunter, E. L. Gunter, and D. B. MacQueen. Computing ML equality kinds using

abstract interpretation. Information and Computation, 107(2):303-323, Dec. 1993.

[53] C. Hall, K. Hammond, S. Peyton-Jones, and P. Wadler. Type classes in Haskell. In

Fifth European Symposium on Programming, volume 788 of Lecture Notes in Computer
Science, pages 241-256. Springer-Verlag, 1994.

[54] J. Hannan. A type system for closure conversion. In The Workshop on Types for Program

Analysis, Aarhus University, May 1995.

[55] R. Harper. Strong normalization and confluence for predicative, higher-order intensional

polymorphism. Unpublished note.

[56] R. Harper and P. Lee. Advanced languages for systems software: The Fox project in

1994. Technical Report CMU-CS-94-104, School of Computer Science, Carnegie Mellon
University, Jan. 1994.

[57] R. Harper and M. Lillibridge. Explicit polymorphism and CPS conversion. In Twentieth

ACM Symposium on Principles of Programming Languages, pages 206-219, Charleston,
Jan. 1993.

[58] R. Harper and M. Lillibridge. A type-theoretic approach to higher-order modules with

sharing. In Twenty-First ACM Symposium on Principles of Programming Languages,
pages 123-137, Portland, Jan. 1994.

[59] R. Harper and J. C. Mitchell. On the type structure of Standard ML. ACM Transactions

on Progamming Languages and Systems, 15(2):211-252, April 1993. (See also [93].).

[60] R. Harper, J. C. Mitchell, and E. Moggi. Higher-order modules and the phase distinction.

In Seventeenth ACM Symposium on Principles of Programming Languages, pages 341-
354, San Francisco, Jan. 1990.

[61] R. Harper and G. Morrisett. Compiling with non-parametric polymorphism (preliminary

report). Technical Report CMU-CS-94-122, School of Computer Science, Carnegie Mellon
University, Mar. 1994. Also published as Fox Memorandum CMU-CS-FOX-94-03.

[62] R. Harper and G. Morrisett. Compiling polymorphism using intensional type analysis. In

Twenty-Second ACM Symposium on Principles of Programming Languages, pages 130-
141, San Francisco, Jan. 1995.

[63] R. W. Harper and M. Lillibridge. Polymorphic type assignment and CPS conversion.

Lisp and Symbolic Computation, 6:361-379, 1993.

[64] F. Henglein. Global tagging optimization by type inference. In ACM Conference on Lisp

and Functional Programming, pages 205-215, San Francisco, June 1992.

BIBLIOGRAPHY 222

[65] F. Henglein and J. Jo/rgensen. Formally optimal boxing. In Twenty-First ACM Symposium

on Principles of Programming Languages, pages 213-226, Portland, Jan. 1994. ACM.

[66] M. Herlihy and B. Liskov. A value transmission method for abstract data types. ACM

Transactions on Progamming Languages and Systems, 4(4):527-551, Oct. 1982.

[67] P. Hudak. A semantic model of reference counting and its abstraction. In ACM Conference

on Lisp and Functional Programming, pages 351-363, Aug. 1986.

[68] P. Hudak, S. L. P. Jones, and P. Wadler. Report on the programming language Haskell,

version 1.2. ACM SIGPLAN Notices, 27(5), May 1992.

[69] T. Johnsson. Lambda lifting: Transforming programs to recursive equations. In ACM

Conference on Functional Programming and Computer Architecture, volume 201 of Lecture Notes in Computer Science, pages 190-203, Nancy, Sept. 1985. Springer-Verlag.

[70] M. B. Jones, R. F. Rashid, and M. R. Thompson. Matchmaker: An interface specification language for distributed processing. In Twelfth ACM Symposium on Principles of
Programming Languages, pages 225-235, New Orleans, Jan. 1985.

[71] M. P. Jones. Qualified Types: Theory and Practice. PhD thesis, Programming Research

Group, Oxford University Computing Laboratory, July 1992. Currently available as
Technical Monograph PRG-106, Oxford University Computing Laboratory, Programming
Research Group, 11 Keble Road, Oxford OX1 3QD, U.K. email: library@comlab.ox.ac.uk.

[72] M. P. Jones. A theory of qualified types. In ESOP '92: European Symposium on Programming, Rennes, France, New York, February 1992. Springer-Verlag. Lecture Notes in
Computer Science, 582.

[73] M. P. Jones. Partial evaluation for dictionary-free overloading. Research Report

YALEU/DCS/RR-959, Yale University, New Haven, April 1993.

[74] M. P. Jones. The implementation of the Gofer functional programming system. Research

Report YALEU/DCS/RR-1030, Yale University, New Haven, May 1994.

[75] S. P. Jones and J. Launchbury. Unboxed values as first-class citizens. In ACM Conference

on Functional Programming and Computer Architecture, volume 523 of Lecture Notes in
Computer Science, pages 636-666, Cambridge, Sept. 1991. ACM, Springer-Verlag.

[76] R. Kelsey and P. Hudak. Realistic compilation by program translation - detailed summary

-. In Sixteenth ACM Symposium on Principles of Programming Languages, pages 281-
292, Austin, Jan. 1989.

[77] F. Knabe. Language Support for Mobile Agents. PhD thesis, School of Computer Science,

Carnegie Mellon University, 1995.

BIBLIOGRAPHY 223

[78] D. Kranz et al. Orbit: An optimizing compiler for Scheme. In Proceedings of the ACM

SIGPLAN '86 Symposium on Compiler Construction, 1986.

[79] J. Lambek and P. Scott. Introduction to Higher Order Categorical Logic. Cambridge

University Press, 1986.

[80] P. J. Landin. The mechanical evaluation of expressions. The Computer Journal, 6:308-

320, 1966.

[81] X. Leroy. Unboxed objects and polymorphic typing. In Nineteenth ACM Symposium on

Principles of Programming Languages, pages 177-188, Albuquerque, Jan. 1992.

[82] X. Leroy. Polymorphism by name. In Twentieth ACM Symposium on Principles of

Programming Languages, pages 220-231, Charleston, Jan. 1993.

[83] X. Leroy. Manifest types, modules, and separate compilation. In Twenty-First ACM

Symposium on Principles of Programming Languages, pages 109-122, Portland, Jan. 1994.

[84] B. Liskov. Overview of the Argus language and system. Programming Methodology

Group Memo 40, MIT Laboratory for Computer Science, Feb. 1984.

[85] B. Liskov. Distributed Programming in Argus. Communications of the ACM, 31(3):300-

312, Mar. 1988.

[86] B. Liskov, D. Curtis, P. Johnson, and R. Scheifler. Implementation of Argus. In Proceedings of the 11th ACM Symposium on Operating Systems Principles, pages 111-122,
Austin, Nov. 1987. ACM.

[87] P. Martin-L"of. About models for intuitionistic type theories and the notion of definitional

equality. In S. Kanger, editor, Proceedings of the Third Scandinavian Logic Symposium,
Studies in Logic and the Foundations of Mathematics, pages 81-109. North-Holland, 1975.

[88] D. Matthews. Poly manual. ACM SIGPLAN Notices, 20(9):42-76, 1985.
[89] R. Milner. A theory of type polymorphism in programming languages. Journal of Computer and System Sciences, 17:348-375, 1978.

[90] R. Milner, M. Tofte, and R. Harper. The Definition of Standard ML. MIT Press, 1990.
[91] Y. Minamide, G. Morrisett, and R. Harper. Typed closure conversion. Technical Report

CMU-CS-95-171, School of Computer Science, Carnegie Mellon University, July 1995.
Also published as Fox Memorandum CMU-CS-FOX-95-05.

[92] Y. Minamide, G. Morrisett, and R. Harper. Typed closure conversion. In Twenty-Third

ACM Symposium on Principles of Programming Languages. ACM, Jan. 1996. To appear.

[93] J. Mitchell and R. Harper. The essence of ML. In Fifteenth ACM Symposium on Principles

of Programming Languages, pages 28-46, San Diego, Jan. 1988.

BIBLIOGRAPHY 224

[94] J. C. Mitchell and R. Harper. The essence of ML. In Conference Record of the 15th

Annual ACM Symposium on Principles of Programming Languages, pages 28-46, Jan.
1988.

[95] G. Morrisett, M. Felleisen, and R. Harper. Abstract models of memory management.

Technical Report CMU-CS-95-110, School of Computer Science, Carnegie Mellon University, Jan. 1994. Also published as Fox Memorandum CMU-CS-FOX-95-01.

[96] G. Morrisett, M. Felleisen, and R. Harper. Abstract models of memory management. In

ACM Conference on Functional Programming and Computer Architecture, pages 66-77,
La Jolla, June 1995.

[97] R. Morrison, A. Dearle, R. C. H. Connor, and A. L. Brown. An ad hoc approach to the

implementation of polymorphism. ACM Transactions on Progamming Languages and
Systems, 13(3):342-371, July 1991.

[98] S. Nettles. A Larch specification of copying garbage collection. Technical Report CMU-

CS-92-219, School of Computer Science, Carnegie Mellon University, Dec. 1992.

[99] A. Ohori. A compilation method for ML-style polymorphic record calculi. In Nineteenth

ACM Symposium on Principles of Programming Languages, pages 154-165, Albuquerque,
Jan. 1992.

[100] A. Ohori and K. Kato. Semantics for communication primitives in a polymorphic language. In Twentieth ACM Symposium on Principles of Programming Languages, pages
99-112, Charleston, Jan. 1993.

[101] A. Ohori and T. Takamizawa. A polymorphic unboxed calculus as an abstract machine

for polymorphic languages. Technical Report RIMS-1032, RIMS, Kyoto University, May
1995.

[102] E. R. Poulsen. Representation analysis for efficient implementation of polymorphism.

Technical report, Department of Computer Science (DIKU), University of Copenhagen,
Apr. 1993. Master Dissertation.

[103] C. Reade. Elements of Functional Programming. Addison-Wesley, Reading, 1989.
[104] J. Reynolds. Types, abstraction, and parametric polymorphism. In Proceedings of Information Processing '83, pages 513-523, 1983.

[105] J. C. Reynolds. Definitional interpreters for higher-order programming languages. In

Proceedings of the Annual ACM Conference, pages 717-740, 1972.

[106] J. C. Reynolds. Towards a theory of type structure. In Proceedings, Colloque sur la

Programmation. Lecture Notes in Computer Science, volume 19, pages 408-425. SpringerVerlag, Berlin, 1974.

BIBLIOGRAPHY 225
[107] M. Serrano and P. Weis. 1+1 = 1: an optimizing Caml compiler. In Record of the 1994

ACM SIGPLAN Workshop on ML and its Applications, pages 101-111, Orlando, June
1994. INRIA RR 2265.

[108] Z. Shao. Compiling Standard ML for Efficient Execution on Modern Machines. PhD

thesis, Princeton University, 1994.

[109] Z. Shao and A. W. Appel. Space-efficient closure representations. In ACM Conference

on Lisp and Functional Programming, pages 150-161, Orlando, June 1994.

[110] Z. Shao and A. W. Appel. A type-based compiler for Standard ML. In ACM SIGPLAN

Conference on Programming Language Design and Implementation, pages 116-129, La
Jolla, June 1995.

[111] G. L. Steele Jr. Rabbit: A compiler for Scheme. Master's thesis, MIT, 1978.
[112] P. Steenkiste and J. Hennessey. Tags and type checking in LISP: Hardware and software approaches. In Proceedings of the Second International Conference on Architectural
Support for Programming Languages and Operating Systems (ASPLOS-II), pages 50-59,
Oct. 1987.

[113] S. Stenlund. Combinators, *-terms and Proof Theory. D. Reidel, 1972.
[114] B. Stroustrup. The C++ Programming Language, Second Edition. Addison-Wesley, 1991.
[115] D. R. Tarditi. Optimizing ML. PhD thesis, School of Computer Science, Carnegie Mellon

University, 1996. Forthcoming.

[116] S. R. Thatte. Semantics of type classes revisited. In ACM Conference on Lisp and

Functional Programming, pages 208-219, Orlando, June 1994.

[117] M.-F. Thibault. Repr'esentations des Fonctions R'ecursives Dans les Cate'gories. PhD

thesis, McGill University, Montreal, 1977.

[118] P. J. Thiemann. Unboxed values and polymorphic typing revisited. In ACM Conference

on Functional Programming and Computer Architecture, pages 24-35, La Jolla, 1995.

[119] A. Tolmach. Tag-free garbage collection using explicit type parameters. In ACM Conference on Lisp and Functional Programming, pages 1-11, Orlando, June 1994.

[120] D. Ungar. Generational scavenging: A non-disruptive high performance storage management reclamation algorithm. In ACM SIGPLAN Software Engineering Symposium on
Practical Software Development Environments, pages 15-167, Pittsburgh, Apr. 1984.

[121] United States Department of Defense. Reference Manual for the Ada Programming Language, Feb. 1983. U.S. Government Printing Office, ANSI/MIL-STD-1815A-1983.

BIBLIOGRAPHY 226
[122] P. Wadler and S. Blott. How to make ad hoc polymorphism less ad hoc. In Sixteenth

ACM Symposium on Principles of Programming Languages, pages 60-76, Austin, 1989.

[123] L. R. Walmer and M. R. Thompson. A programmer's guide to the Mach user environment.

School of Computer Science, Carnegie Mellon University, Feb. 1988.

[124] M. Wand and P. Steckler. Selective and lightweight closure conversion. In Twenty-First

ACM Symposium on Principles of Programming Languages, pages 435-445, Portland,
Jan. 1994.

[125] K. G. Waugh, P. McAndrew, and G. Michaelson. Parallel implementations from function prototypes: a case study. Technical Report Computer Science 90/4, Heriot-Watt
University, Edinburgh, Aug. 1990.

[126] P. Weis, M.-V. Aponte, A. Laville, M. Mauny, and A. Su'arez. The CAML reference

manual, Version 2.6. Technical report, Projet Formel, INRIA-ENS, 1989.

[127] P. R. Wilson. Uniprocessor garbage collection techniques. In Y. Bekkers and J. Cohen,

editors, International Workshop on Memory Management, number 637 in Lecture Notes
in Computer Science, pages 1-42, St. Malo, Sept. 1992. Springer-Verlag.

[128] P. R. Wilson. Garbage collection. Computing Surveys, 1995. Expanded version of [127]. Draft available via anonymous internet FTP from cs.utexas.edu as
pub/garbage/bigsurv.ps. In revision, to appear.

[129] P. Wodon. Methods of garbage collection for Algol-68. In Algol-68 Implementation.

North-Holland Publishing Company, Amsterdam, 1970.

[130] A. Wright and M. Felleisen. A syntactic approach to type soundness. Technical Report

TR91-160, Department of Computer Science, Rice University, Apr. 1991.

[131] A. K. Wright. Polymorphism for imperative languages without imperative types. Technical Report TR93-200, Department of Computer Science, Rice University, Feb. 1993.

[132] A. K. Wright and R. Cartwright. A practical soft type system for Scheme. In ACM

Conference on Lisp and Functional Programming, pages 250-262, Orlando, June 1994.