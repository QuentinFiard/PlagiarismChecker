

Information Processing Letters 93 (2005) 281-288

www.elsevier.com/locate/ipl

Efficient weakest preconditions

K. Rustan M. Leino
Microsoft Research, Redmond, WA, USA
Received 17 November 2003; received in revised form 3 November 2004

Communicated by F.B. Schneider

In memory of Edsger W. Dijkstra

Abstract

Desired computer-program properties can be described by logical formulas called verification conditions. Different
mathematically-equivalent forms of these verification conditions can have a great impact on the performance of an automatic
theorem prover that tries to discharge them. This paper presents a simple weakest-precondition understanding of the ESC/Java
technique for generating verification conditions. This new understanding of the technique spotlights the program property that
makes the technique work.
(C) 2004 Published by Elsevier B.V.

Keywords: Program correctness; Formal semantics; Automatic theorem proving

0. Introduction

Various computer-program checking tools and verification tools generate verification conditions, logical formu-las whose validity reflect the correctness of the program under analysis. Each verification condition is then passed
to a mechanical theorem prover or some suite of decision procedures. The Extended Static Checkers for Modula-3and for Java are examples of program checkers built around this architecture [5,8,10].

There are many mathematically equivalent ways to formulate a verification condition, and which formulationone uses can have a dramatic impact on the performance of the program-checking system. The ESC/Modula-3
and ESC/Java projects have explored techniques for formulating verification conditions that substantially improve
the way they are handled by the underlying automatic theorem prover. The variation of the technique used inESC/Java is described by Flanagan and Saxe [9]. Their paper compares the ESC/Java technique with the wellknown verification-condition technique of weakest preconditions [6]. In this paper, I show that the ESC/Java

E-mail address: leino@microsoft.com (K.R.M. Leino).
0020-0190/$ - see front matter (C) 2004 Published by Elsevier B.V.
doi:10.1016/j.ipl.2004.10.015

282 K.R.M. Leino / Information Processing Letters 93 (2005) 281-288
technique is in fact the technique of weakest preconditions with the additional use of a certain weakest-preconditionproperty that holds only for a restricted class of programs.

1. Weakest preconditions

Let's start by reviewing weakest preconditions and the problem with their traditional application. We considera simple language like the following, which is representative of the intermediate language used in ESC/Java [11]:

S, T ::= Id := Expr-- assert

Expr-- assume Expr

-- S ; T--

S T

The assignment statement x := E sets program variable x to the value of E. The assert and assume statementsare no-ops if the given expression evaluates to

true. If the expression evaluates to false, the assert statement is anirrevocable error (the execution
goes wrong) and the assume statement is a partial command that does not start(the execution
blocks) [12]. Every execution in our simple language either blocks, goes wrong, or terminates. Thestatement
S ; T is the sequential composition of S and T , where T is executed only if S terminates, and S Tis the arbitrary choice between

S and T . The statements of the simple language are rich enough to encode loopsdeclared with loop invariants and procedure calls declared with procedure specifications (cf. [11,1]). For this paper,

it suffices to know that a common program statement like

if B then S else T end
is encoded as the choice statement

(assume B ; S) (assume ~B ; T )
in the simple language.The

weakest conservative precondition of a statement S with respect to a predicate Q on the post-state of S,denoted

wp(S, Q), is a predicate on the pre-state of S, characterizing all pre-states from which every non-blockingexecution of

S does not go wrong and terminates in a state satisfying Q. Similarly, the weakest liberal preconditionof
S with respect to Q, denoted wlp(S, Q), characterizes the pre-states from which every non-blocking executionof
S either goes wrong or terminates in a state satisfying Q. The connection between wp and wlp is described bythe following equation, which holds for every statement

S [6]:

(\Delta Q * wp(S, Q) \Theta  wp(S, true) \Lambda  wlp(S, Q)). (0)
The semantics of the statements in the simple language are defined by the following weakest preconditions, for anypredicate

Q [6,12]:

Stmt wp(Stmt, Q) wlp(Stmt, Q)
x := E Q[x := E] Q[x := E]assert

E E \Lambda  Q E \Xi  Qassume

E E \Xi  Q E \Xi  Q
S ; T wp(S, wp(T , Q)) wlp(S, wlp(T , Q))
S T wp(S, Q) \Lambda  wp(T , Q) wlp(S, Q) \Lambda  wlp(T , Q)

(1)

where Q[x := E] says about E what Q says about x, that is:

Q[x := E] = let x = E in Q end

K.R.M. Leino / Information Processing Letters 93 (2005) 281-288 283
The verification condition for a given program S--which, recall, is a formula that is valid if and only if S is free oferrors--is therefore the formula

wp(S, true). One way for a program checker to compute this verification conditionfrom a program is to syntactically expand wp

(S, true) as suggested by the shapes of the formulas shown in (1). Thiscomputation is an instance of the general strategy for correctly computing a verification condition: syntactically

transform the formulas according to valid mathematical properties.

2. The problem of redundancy

The problem with the verification conditions computed as suggested by (1) becomes clear when we consideran if statement: in the computation of wp

(S T , Q), which expands to wp(S, Q) \Lambda  wp(T , Q), we duplicate Q.This results in a verification condition whose size is exponential in the size of the program. If size were the only

problem, we could easily provide a fix by naming the common subexpression:

wp(S T , Q) \Theta  let q = Q in wp(S, q) \Lambda  wp(T , q) end (2)
This equation expresses the same mathematical property about wp(S T , Q) as in (1), but computing wp(S T ,
Q) by syntactically expanding it as suggested by equation (2) results in a verification condition that is just linearin the size of the program.0

Unfortunately, size is not all that matters. Depending on its structure, even a syntactically small verificationcondition can push an automatic theorem prover beyond the practical limit of an exponential cliff. What matters is
how the theorem prover will go about processing the given formula.Given a formula whose top-level operator is a conjunction, as in

A \Lambda  B
ESC/Modula-3 and ESC/Java's theorem prover, Simplify [4], first attempts to prove A and then attempts to prove B,and many other theorem provers follow the same strategy.1 Consequently, by syntactically expanding

wp(S T , Q)as suggested by (1), a proof obligation in a program will lead to twice as many copies of the same (or similar) proof

obligations for every preceding if statement, even when which branch is taken in an if statement is inconsequentialto the proof obligation downstream of the if. By introducing a name, like

q in (2), for the common subexpression Q,we do not change the fundamental way in which the theorem prover will attempt to prove the given formula: the

theorem prover would still have to consider q as many times as it had to consider Q. We will have to try somethingelse.

3. Reducing redundancy

Another way to avoid duplicating the second argument in the expansion of wp(S, Q) is to change the formulainto something that replaces the second argument with something that's independent of

Q, like a constant. Weknow a formula for doing just that, namely the connection between
wp and wlp: formula (0) allows us to computewp
(S, true) instead of wp(S, Q), provided we also compute wlp(S, Q). But here we encounter the same prob-lem, because computing wlp

(S T , Q) as suggested by (1) suffers from the same kind of duplication as doeswp
(S T , Q).

0 The formulation with "let q" is correct only if q attains an appropriate higher-level status, so that, for example, q[x := E] still means the
right thing. One way to encode that is to explicate the dependence of q on the program variables, as in q(x, y, z) where x, y, z is the list of
program variables. With this encoding, the let formulation yields a formula that is quadratic in the size of the program.1

Actually, Simplify works by negating the given formula and trying to find a satisfying assignment for the negation. So, instead of attempting
to prove A and then B, Simplify attempts to satisfy ~A and then ~B. But in either case, any common proof obligations in A and B end up
being considered twice.

284 K.R.M. Leino / Information Processing Letters 93 (2005) 281-288

Encouraged by the trick of replacing Q with a constant in wp(S, Q), let's try the same for wlp(S, Q). Theconstant

true will not work, however, because wlp(S, true) is true for every statement S [6]. Instead, consider thefollowing "dream property":

(\Delta Q * wlp(S, Q) \Theta  wlp(S, false) \Pi  Q) (3)
Using this dream property, we would be done, because then, to compute wp(S, Q), we can simply compute

wp(S, true) \Lambda  (wlp(S, false) \Pi  Q)
in which Q is not duplicated. To illustrate further, if the statement is a choice statement, we can compute wp(S T ,
Q) as

wp(S, true) \Lambda  wp(T , true) \Lambda  ((wlp(S, false) \Lambda  wlp(T , false)) \Pi  Q)
But there is a wrinkle: our dream property does not hold for every statement S. To more convincingly describewhich statements

S have the dream property, let us rewrite the dream property into the form

(\Delta Q * Q \Xi  wlp(S, Q)) (4)
which is equivalent to the previous formulation:

Proof ((3) \Delta  (4)). First, we show that (4) follows from (3):

Q\Xi  { logic }
wlp(S, false) \Pi  Q=

{ (3) }
wlp(S, Q)

Next, we show that (3) follows from (4), which we do by assuming (4) and establishing three properties whoseconjunction is equivalent to (3):

wlp(S, false) \Xi  wlp(S, Q) (5)

Q \Xi  wlp(S, Q) (6)
wlp(S, Q) \Xi  wlp(S, false) \Pi  Q (7)

Property (5) follows directly from the monotonicity of wlp(S, u*) (which is a consequence of wlp(S, u*) being con-junctive [6,7]). Property (6) is exactly the assumed (4). Finally, property (7) is equivalent to

wlp(S, Q) \Lambda  ~Q \Xi  wlp(S, false)
which we establish by the following calculation:

wlp(S, Q) \Lambda  ~Q\Xi 

{ (4) with Q := ~Q }
wlp(S, Q) \Lambda  wlp(S, ~Q)=

{ wlp(S, u*) is conjunctive }
wlp(S, Q \Lambda  ~Q)=

{ logic }
wlp(S, false) \Delta 

K.R.M. Leino / Information Processing Letters 93 (2005) 281-288 285
tr(x := E, m) = let x\Sigma  be a fresh variable, E\Sigma  = m(E) in (x\Sigma  := E\Sigma , m(x \Upsilon \Phi  x\Sigma ))
tr(assert E, m) = let E\Sigma  = m(E) in (assert E\Sigma , m)
tr(assume E, m) = let E\Sigma  = m(E) in (assume E\Sigma , m)
tr(S ; T , m) = let (S\Sigma , m\Sigma ) = tr(S, m), (T \Sigma , m\Sigma \Sigma ) = tr(T , m\Sigma ) in (S\Sigma  ; T \Sigma , m\Sigma \Sigma )
tr(S T , m) = let (S\Sigma , m\Sigma ) = tr(S, m), (T \Sigma , m\Sigma \Sigma ) = tr(T , m),

V = -x -- x \Psi  Var \Lambda  m\Sigma (x) \Omega = m\Sigma \Sigma (x)"",
V \Sigma  be a list of fresh variables for the variables in Vin
((S\Sigma  ; V \Sigma  := m\Sigma (V )) (T \Sigma  ; V \Sigma  := m\Sigma \Sigma (V )), m\Sigma (V \Upsilon \Phi  V \Sigma ))

Fig. 0. A translation from the intermediate-language programs in Section 1 into programs that assign to a variable at most once along any
execution path. Input and output of the translation also include a map from program variables to variables that represent the value of the
variable before and after the target program, respectively.

We have now established that the dream property can be expressed as formula (4). This formula lets us think
about what the dream property means in terms of program statements. It says that every non-blocking execution of
S that starts in a state satisfying some predicate Q either goes wrong or terminates in a state that also satisfies Q.
So the dream property apparently characterizes those statements S that terminate only without any net effect on the
program state. These statements are the passive commands, which exclude assignment statements [9].

To summarize, we have now arrived at a technique by which we can compute weakest preconditions of statements with reduced redundancy. To compute wp(S, Q) for a Q that is not the literal true, compute wp(S, true) and
wlp(S, Q) and take the conjunction of the two; to compute wlp(S, Q) for a Q that is not the literal false, compute
wlp(S, false) and take the disjunction of it and Q; and to compute wp(S, true) and wlp(S, false), apply the syntactic
transformations suggested by (1). The resulting formula for wp(S, Q) is quadratic in the size of S: the expansion
will have a wp(u*, true) term for every atomic substatement of S and a wlp(u*, false) term for every substatement
of S, each such wlp(u*, false) term being linear in the size of the substatement.

Since the technique works only for passive commands, one first has to eliminate assignment statements from
the program under consideration, which I explain below. So, instead of translating the source language into the
intermediate language in Section 1 and then computing weakest preconditions as suggested by (1), a program
checker would translate the source language into passive commands (quite possibly by using the language of
Section 1 as an intermediate stepping stone) and then computing weakest preconditions as described in the previous
paragraph.

For reference, I here give a translation from programs into passive commands [9]. I give the translation in two
steps, first introducing new variables and assignments, akin to the technique of static single assignment [0,3], and
then changing the assignment statements into assume statements.

Let Var be the list of program variables. We define a function tr from pairs (S, m) to pairs (T , m\Sigma ), where
S is a program with assignment statements, T is a program where each variable is assigned at most once along
any execution path, and m and m\Sigma  are maps from the variables of Var to variables that represent the values of
Var on entry to and exit from T , respectively. Function tr is defined in Fig. 0, where m(V \Upsilon \Phi  V \Sigma ) denotes the
map that takes any variable in V to the corresponding variable in V \Sigma  and otherwise maps variables like m, m(E)
denotes the expression that results from replacing each variable in E according to the map m, and multiple-variable
assignments stand for a sequential composition of assignments to the respective variables. Let S be a program, m
be any injective map, and (T , m\Sigma ) be the result of computing tr(S, m). Since an assignment x := E along any
execution path of T has the property that x is not used before the assignment and x is not changed after the
assignment, we obtain the passive command corresponding to S by replacing every assignment statement x := E
in T by the statement assume x = E.

For example, the program

if x < 0 then x := -x end; y := y + x; assert 0 \Delta  y

286 K.R.M. Leino / Information Processing Letters 93 (2005) 281-288
can be translated into the intermediate language as

( (assume x < 0; x := -x)

(assume ~(x < 0)) );
y := y + x; assert 0 \Delta  y

which together with the injective map (x \Upsilon \Phi  x0, y \Upsilon \Phi  y0) is transformed by tr into

( (assume x0 < 0; x1 := -x0; x2 := x1)

(assume ~(x0 < 0); x2 := x0) );
y1 := y0 + x2; assert 0 \Delta  y1

which after replacing the assignment statements by assume statements becomes the passive command

( (assume x0 < 0; assume x1 = -x0; assume x2 = x1)

(assume ~(x0 < 0); assume x2 = x0) );assume

y1 = y0 + x2; assert 0 \Delta  y1

4. Programs with exceptions

In some programming languages, statements can terminate not just normally but also exceptionally. To thinkabout such language features, we extend the simple language above as follows:

S, T ::= . . .-- raise

-- S ! T
where raise raises an exception and S ! T prescribes T as the handler for any exception that escapes S. Moreprecisely, statement raise always terminates exceptionally without changing the program state. Sequential composition S ; T executes S and then, if S terminates normally, executes T . Dually, S ! T executes S and then, if Sterminates exceptionally, executes

T .For programs with exceptions, we define

wp and wlp with three arguments, one statement and two predicates onthe post-state [2]: wp
(S, Q, R) characterizes all pre-states from which every non-blocking execution does not gowrong and either terminates normally in

Q or terminates exceptionally in R, and wlp(S, Q, R) characterizes all pre-states from which every non-blocking execution goes wrong, terminates normally in

Q, or terminates exceptionallyin
R. In the presence of exceptions, the connection between wp and wlp reads

(\Delta Q, R * wp(S, Q, R) \Theta  wp(S, true, true) \Lambda  wlp(S, Q, R)) (8)
There is also a dream property for programs with exceptions. To more readily see how it corresponds to dreamproperty (3) of the previous section, note that (3) can also be written as

(\Delta P , Q * wlp(S, P \Pi  Q) \Theta  wlp(S, P ) \Pi  Q) (9)
The equivalence of (3) and (9) is easy to establish by a mutual-implication argument. For programs with exceptions,the dream property is

(\Delta A, B, Q * wlp(S, A \Pi  Q, B \Pi  Q) \Theta  wlp(S, A, B) \Pi  Q) (10)
Using properties (8) and (10), we can compute wp(S, Q, R) by computing the last line in the following calcula-tion:

wp(S, Q, R)=

{ wp-wlp connection (8) }

K.R.M. Leino / Information Processing Letters 93 (2005) 281-288 287
wp(S, true, true) \Lambda  wlp(S, Q, R)=

{ conjunctivity of wlp in its second and third arguments }
wp(S, true, true) \Lambda  wlp(S, Q, true) \Lambda  wlp(S, true, R)=

{ logic }
wp(S, true, true) \Lambda  wlp(S, false \Pi  Q, true \Pi  Q) \Lambda  wlp(S, true \Pi  R, false \Pi  R)=

{ dream property (10) }
wp(S, true, true) \Lambda  (wlp(S, false, true) \Pi  Q) \Lambda  (wlp(S, true, false) \Pi  R)

For programs with exceptions, the dream property again holds for exactly those statements that do not update thestate.

In this rewriting, the resulting verification condition can still be exponential in the size of the program, see [9]for details.

5. Conclusion

Let's compare this weakest-precondition understanding of the ESC/Java technique for generating verificationconditions with its previous description [9]. Flanagan and Saxe define two functions on statements,

N and W . Forany statement
S, N(S) characterizes those initial states from which execution of S may terminate normally, and
W (S) characterizes those initial states from which execution of S may go wrong. That is, ~W (S) characterizesthose states from which

S is guaranteed not to go wrong, and ~N(S) characterizes those states from which S isguaranteed
not to terminate normally. In other words, we have

~W (S) = wp(S, true)~

N(S) = wlp(S, false)

For programs with exceptions, Flanagan and Saxe additionally define a function X such that for any statement S,
X(S) characterizes those initial states from which execution of S may terminate exceptionally. Thus, in terms ofthe

wp and wlp for programs with exceptions, we have

~W (S) = wp(S, true, true)~

N(S) = wlp(S, false, true)~

X(S) = wlp(S, true, false)

There are two key advantages of the weakest-precondition understanding of the ESC/Java technique for gen-erating verification conditions. One advantage is that one can use the standard

wp-wlp semantics of the programstatements, which focuses on what's necessary to
guarantee particular post-states, as opposed to having to definewhat it means that a statement
may have some particular outcome. The other, larger, advantage is that it draws outthe very property that needs to hold of the statements in order to apply the technique. This property, which can be

seen as a wlp distribution property (in formula (9)) or as an invariant-preserving property (in formula (4)), holdsexactly of those statements that do not alter the program state, the passive commands.

Acknowledgements

The ESC/Java technique for generating verification conditions was developed by Jim Saxe, Greg Nelson, andCormac Flanagan as a variation of the technique used in ESC/Modula-3 and invented by Saxe, Nelson, and Dave

288 K.R.M. Leino / Information Processing Letters 93 (2005) 281-288
Detlefs. The general technique, which can also be used with strongest postconditions, as it was in ESC/Modula-3,is described in a patent [13].

I'm grateful to Rajeev Joshi for suggesting that I prove the equivalence between the dream property (3) andproperty (4), which more readily reveals the property as saying "

S has no effect on the program state". Thanks alsoto Cormac Flanagan for providing comments on this paper.

References

[0] B. Alpern, M.N. Wegman, F.K. Zadeck, Detecting equality of variables in programs, in: Conference Record of the 15th Annual ACM

Symposium on Principles of Programming Languages, ACM, January 1988, pp. 1-11.
[1] R.J.R. Back, J. von Wright, Combining angels, demons and miracles in program specifications, Theoret. Comput. Sci. 100 (2) (1992)

365-383.
[2] F. Cristian, Correct and robust programs, IEEE Trans. Software Eng. 10 (1984) 163-174.
[3] R. Cytron, J. Ferrante, B.K. Rosen, M.N. Wegman, F.K. Zadeck, An efficient method of computing static single assignment form, in:

Conference Record of the 16th Annual ACM Symposium on Principles of Programming Languages, ACM, January 1989, pp. 25-35.
[4] D. Detlefs, G. Nelson, J.B. Saxe, Simplify: A theorem prover for program checking, Technical Report HPL-2003-148, HP Labs, July 2003.
[5] D.L. Detlefs, K.R.M. Leino, G. Nelson, J.B. Saxe, Extended static checking, Research Report 159, Compaq Systems Research Center,

December 1998.
[6] E.W. Dijkstra, A Discipline of Programming, Series in Automatic Computation, Prentice-Hall, Englewood Cliffs, NJ, 1976.
[7] E.W. Dijkstra, C.S. Scholten, Predicate Calculus and Program Semantics, Texts and Monographs in Computer Science, Springer-Verlag,

Berlin, 1990.
[8] C. Flanagan, K.R.M. Leino, M. Lillibridge, G. Nelson, J.B. Saxe, R. Stata, Extended static checking for Java, in: Proceedings of the 2002

ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), SIGPLAN Notices 37 (5) (2002) 234-245.
[9] C. Flanagan, J.B. Saxe, Avoiding exponential explosion: Generating compact verification conditions, in: Conference Record of the 28th

Annual ACM Symposium on Principles of Programming Languages, ACM, January 2001, pp. 193-205.
[10] K.R.M. Leino, Extended static checking: A ten-year perspective, in: R. Wilhelm (Ed.), Informatics--10 Years Back, 10 Years Ahead, in:

Lecture Notes in Comput. Sci., vol. 2000, Springer, Berlin, 2001.
[11] K.R.M. Leino, J.B. Saxe, R. Stata, Checking Java programs via guarded commands, in: B. Jacobs, G.T. Leavens, P. Mu"ller, A. PoetzschHeffter (Eds.), Formal Techniques for Java Programs, Technical Report 251, Fernuniversita"t Hagen, May 1999. Also available as Technical
Note 1999-002, Compaq Systems Research Center.
[12] G. Nelson, A generalization of Dijkstra's calculus, ACM Trans. Programm. Lang. Syst. 11 (4) (1989) 517-561.
[13] J.B. Saxe, C.G. Nelson, D.L. Detlefs, Case-reduced verification condition generation system and method using weakest precondition

operator expressed using strongest postcondition operators, United States Patent #6,553,362, filed 16 July 2001, issued 22 April 2003.