

Principality and Type Inference for Intersection Types

Using Expansion Variables*

A. J. Kfoury
Boston University
Boston, MA 02215, U.S.A.

kfoury@cs.bu.edu
http://www.cs.bu.edu/~kfoury

J. B. Wells
Heriot-Watt University
Edinburgh, EH14 4AS, Scotland

jbw@cee.hw.ac.uk
http://www.cee.hw.ac.uk/~jbw

August 20, 2003

Abstract
Principality of typings is the property that for each typable term, there is a typing from which all
other typings are obtained via some set of operations. Type inference is the problem of finding a typing
for a given term, if possible. We define an intersection type system which has principal typings and
types exactly the strongly normalizable *-terms. More interestingly, every finite-rank restriction of this
system (using Leivant's first notion of rank) has principal typings and also has decidable type inference.
This is in contrast to System F where the finite rank restriction for every finite rank at 3 and above has
neither principal typings nor decidable type inference. Furthermore, the notion of principal typings for
our system involves only one operation, substitution, rather than several operations (not all substitutionbased) as in earlier presentations of principality for intersection types (without rank restrictions). In our
system the earlier notion of expansion is integrated in the form of expansion variables, which are subject
to substitution as are ordinary variables. A unification-based type inference algorithm is presented using
a new form of unification, fi-unification.

*This is an expanded version of a report that appeared in the Proceedings of the 1999 ACM Symposium on Principles of Programming Languages, under the title "Principality and Decidable Type Inference for Finite-Rank Intersection Types" [KW99].
This work has been partly supported by EPSRC grants GR/L 36963 and GR/R 41545/01, by NATO grant CRG 971607,
by NSF grants 9417382 (CCR), 9806745 (EIA), 9988529 (CCR), 0113193 (ITR), and by Sun Microsystems equipment grant
EDUD-7826-990410-US.

1

Contents
1 Introduction 31.1 Background and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.2 Contributions of This Paper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41.3 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.4 Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2 Intersection Types with Expansion Variables 52.1 The Type System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

2.2 Substitution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
3 Properties of Substitutions 133.1 On Types in General . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

3.2 On Well-Named Types Only . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153.3 Finite-Support Substitutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

4 Lambda-Compatible Beta-Unification 22
5 Algorithm for Lambda-Compatible Beta-Unification 27
6 Type Inference Algorithm 38
7 Skeletons and Derivations at Finite Ranks 41
8 Termination and Decidability at Finite Ranks 47
A Complete Run of the Type-Inference Procedure 54

2

1 Introduction
1.1 Background and Motivation
The Desire for Polymorphic Type Inference Programming language designers now generally rec-ognize the benefits (as well as the costs!) of strong static typing. Languages such as Haskell [PJHH

+93],

Java [GJS96], and ML [MTHM97] were all designed with strong typing in mind. To avoid imposing an undueburden on the programmer, the compiler is expected to infer as much type information as possible. To avoid

rejecting perfectly safe programs, the type inference algorithm should support as much type polymorphismas possible. The main options for polymorphism are universal types, written 8

ff.o/ , and intersection types,written
oe ^ o/ . (Their duals are the existential types, written 9ff.o/ , and union types, written oe . o/ .)The most popular type inference algorithm is algorithm W by Damas and Milner [DM82] for the type

system commonly called Hindley/Milner which supports polymorphism with a restricted form of universaltypes. In practice this type system is somewhat inflexible, sometimes forcing the programmer into contortions to convince the compiler that their code is well typed. This has motivated a long search for moreexpressive type systems with decidable typability. In this search, there have been a great number of negative
results, e.g., undecidability of System F [Wel94], finite rank restrictions of F above 3 [KW94], F<= [Pie94],F

! [Urz97], F+j [Wel96], and unrestricted intersection types [Pot80]. Along the way, there have been a fewpositive results, some extensions of the Damas/Milner approach, but, perhaps more interestingly, some with

intersection types.

What are Principal Typings? Many systems with intersection types have had a principal typings prop-erty. Jim [Jim96] explains the difference with the principal types property of the Hindley/Milner system as
follows:

Principal TypesGiven: a term

M typable in type environment A.There exists: a type
oe representing all possible types for M in A.

Principal TypingsGiven: a typable term

M .There exists: a judgement
A ` M : o/ representing all possible typings for M .

Wells [Wel02] gives a system-independent abstract definition of principal typings. Specifically, a typing(

A, o/ ) for a program fragment M is principal for M exactly when that typing is at least as strong as all othertypings for

M . A typing (A, o/ ) is at least as strong as a typing (A0, o/ 0) if and only A ` M : o/ being derivableimplies
A0 ` M : o/ 0 is derivable for every M . Jim explains how principal typings support the possibility oftrue separate compilation and Wells discusses how they help with compositional software analysis.

Principal Typings with Intersection Types Intersection types were first introduced by Coppo andDezani [CDC80] and, independently, by Pottinger [Pot80].

1 The first system of intersection types for which

principal typings was proved (as far as we are aware) was presented by Coppo, Dezani, and Venneri [CDCV80](a later version is [CDCV81]). Like many systems of intersection types, it is similar to ours in that "^" can

not appear to the right of "!" and ^-elimination can only occur at *-term variables. Like our system, thissystem is restricted so that the binding type of the bound variable of an abstraction must be an intersection
of exactly the set of types at which it is used. However, this system differs from ours by allowing one of thetypes in the intersection type for a bound variable to be used for multiple occurrences of the bound variable.
It also has a rule to assign the special type ! (representing the intersection of 0 types) to any term.There is a general approach for an algorithm for finding principal typings that was followed by Coppo,
Dezani, and Venneri for their type system as well as by Ronchi della Rocca and Venneri [RDRV84] and vanBakel [vB93] for other systems of intersection types. In this approach, the principal typing algorithm first
finds a normal form (or approximate normal form) and then creates a typing for the normal form. A separateproof shows that any typing for the normal form is also a typing for the original term. The algorithms of this

1Despite appearing earlier, [Sal78] was preceded by the internal report version of [CDC80] and gives credit to Coppo and
Dezani for introducing intersection types.

3

approach are intrinsically impractical, not only due to the expense of normalization but, more importantly,because there is no possibility of a short cut to normalization. The principality of the principal typing is
shown using a technique of several different kinds of operations: expansion (sometimes called duplication),lifting (sometimes called rise), and substitution. The biggest difference with the approach we present in this
paper is that we use expansion variables to formalize expansion in a much simpler way as part of substitution.This allows our approach to be based on both substitution and unification. This opens the possibility of more
efficient algorithms by adding additional (unnecessary) constraints to the unification problem to shortcutthe solution, an adaptation we leave to future work.

Sayag and Mauny [SM97, SM96] continue the earlier work cited above, and succeed in defining a simplernotion of principal typings for a system of intersection types. An important difference with our analysis is the
continued use of an expansion operation, although considerably simplified from earlier formulations, in partbecause they restrict attention to

*-terms in normal form. Moreover, their approach is not substitution-basedand it is not immediately clear how to extend it to arbitrary

*-terms not in normal form.The first unification-based approach to principal typing with intersection types is by Ronchi della

Rocca [RDR88]. Of course, the general method here will diverge for some terms in the full type system, buta decidable restriction is presented which bounds the height of types. Unfortunately, this approach uses the
old, complicated approach to expansion which makes it very difficult to understand. It also appears to havetrouble with commutativity and associativity of "^".

Subsequent unification-based approaches to principal typing with intersection types have focused on therank-2 restriction of intersection types, using Leivant's notion of rank [Lei83]. Van Bakel presents a unification algorithm for principal typing for a rank-2 system [vB93]. Later independent work by Jim also attacksthe same problem, but with more emphasis on handling practical programming language issues such as recursive definitions, separate compilation, and accurate error messages [Jim96]. Successors to Jim's methodinclude Banerjee's [Ban97], which integrates flow analysis, and Jensen's [Jen98], which integrates strictness
analysis. Other approaches to principal typings and type inference with intersection types include [CG92]and [JMZ92].

1.2 Contributions of This Paper
The main contributions of this paper are the following:*

A fully substitution-based notion of principality for a system of intersection types (with or withouta rank restriction on types). Expansion variables abstractly represent the possibility of multiple subderivations for the same term, supporting a substitution-based approach in place of the old notion ofexpansion.

This contribution makes the technology of intersection types significantly more accessible to non-theorists. The notions of expansion in earlier literature are so complicated that few but the authors
could understand them.

* A unification-based type inference algorithm for intersection types using a novel form of unification, fi-unification. The algorithm always returns principal typings when it halts. The algorithm is terminating

when restricted to finite-rank types.
This algorithm is the first understandable type inference algorithm for intersection types beyond therank-2 restriction which does not require that terms first be

fi-reduced to normal form. Although itmay seem that there is quite a bit of material in this report, the vast majority of it exists only to prove

properties of the algorithm. The actual algorithm is largely contained in definitions 2.12, 2.14, 2.15,2.17, 3.8, 3.11, 3.13, 5.1, and 6.1, together with theorem 6.7. This algorithm has been implemented and
can currently be found at http://www.church-project.org/modular/compositional-analysis/.

* Decidability of type inference and principal typings for the restrictions to every finite rank.

Ours is the first system of intersection types for which this has been shown. At rank 3, our systemalready types terms not typable in the very powerful system

F!, e.g., the term

(*x.z(x(*fu.f u))(x(*vg.gv)))(*y.yyy) ,
which was shown untypable in F! by Urzyczyn [Urz97].

4

1.3 Future Work
Using Intersection Types in Practice This work is carried out in the context of the Church Project(

http://www.church-project.org/) an ongoing multi-institutional effort investigating the theory and prac-tice of using advanced types and semantics in the design and implementation of programming language

systems. The Church Project is actively implementing and evaluating intersection-type-based technologyin an ML compiler. A number of practical concerns need to be addressed to finish the task of making the
technology presented in this report usable in the overall project effort. In particular, the following tasks areimportant:

1. Adapt the technology to type systems in which "^" is associative, commutative, and idempotent. Thiswill be vital for reducing the space and time complexity of our algorithm, because it will enable the

expression of the rank restrictions without requiring an essentially linear flow analysis.
2. Add support for sum types, e.g., booleans and conditionals. This seems likely to require the additionof union types or some form of conditional type.

3. Add support for recursive definitions, e.g., a fix-point operator or letrec bindings. This will significantlycomplicate the analysis, because it will interfere with the invariant that

*-compatible constraint sets(definition 4.8) have constraints neatly divided into positive and negative types (definition 4.1). Also,

polymorphic/polyvariant analysis of recursion is notoriously difficult.
4. Take advantage of the new notion of substitution developed in this report to devise efficient represen-tations of polyvariant program analyses. This is particularly promising.

Theoretical Concerns The work presented here inspires the following possible tasks:

* Investigate the relationship between fi-unification and other forms of unification - decidable and unde-cidable. In particular, investigate the relationship with second-order unification and semi-unification.

* Further develop the meta-theory of fi-unification. In particular, investigate conditions under which

fi-unification (1) satisfies a principality property and (2) is decidable. Use this to develop more sophis-ticated type inference algorithms.

* Investigate the complexity of the decidable finite-rank restriction of fi-unification introduced in sec-tion 7. Separately, investigate the complexity of the set of programs typable in the various finite-rank

restrictions.

1.4 Acknowledgements
Torben Amtoft, Gang Chen, and Lyn Turbak carefully read drafts of this paper and found bugs. GangChen went further and suggested specific bug fixes. Bradley Alan implemented the

fi-unification constraintsolver given in the POPL '99 version of this paper [KW99] and pointed out some errors in examples in the

paper. Geoff Washburn completed the implementation by adding the generation of the constraint sets from
*-terms, the use of the results of fi-unification to make principal typings and typing derivations, and a niceweb-based user interface. The web interface can currently be found at

http://www.church-project.org/
modular/compositional-analysis/. S'ebastien Carlier, Geoff Washburn, and Bennett Yates have madehelpful comments and have also helped to carry this research forward by starting to address various items of

future work mentioned in section 1.3. We are also indebted to the anonymous referees, who made numeroussuggestions to clarify our analysis and overall organization of the paper.

2 Intersection Types with Expansion Variables
This section defines a system of intersection types for the *-calculus with the additional feature of expansionvariables. The expansion variables do not affect what is typable; instead they support reasoning about

principal typings via a notion of substitution.

5

Throughout the paper, the notation ~Xn is meta-notation standing for the notation X1, . . . , Xn. Thenotation ~

X stands for ~Xn for some n >= 0 which either does not matter or is clear from the context. Awarning: Some authors use the notation _

X for similar purposes, but in this paper the bar mark on a symbolis not used to stand for a sequence.

2.1 The Type System
The set of natural numbers is denoted N throughout.
Definition 2.1 (*-Terms). Let x and y range over *-Var, the set of *-term variables. We use the usualset of

*-terms

M, N 2 \Lambda  ::= x | *x.M | M N ,
quotiented by ff-conversion as usual, and the usual notion of reduction

(*x.M)N !fi M [x := N ] .
As usual, FV(M ) denotes the set of free variables of M .

The following definition gives a structure to type variable names that will be helpful later when we needto rename them distinctly.

Definition 2.2 (Type Variables and Expansion Variables). The set of basic type variables or basicT-variables is

TVarb = { ai i 2 N }. The set of basic expansion variables or basic E-variables is EVarb ={
Fi i 2 N }. We assume TVarb and EVarb are disjoint sets, and use Varb to denote the union EVarb [ TVarb.Let

b (possibly decorated) be a metavariable ranging over Varb.We use binary strings in {0

, 1}*, called offset labels, to name (and later to rename) variables. If s, t 2{0
, 1}*, we write s * t for their concatenation. The statement s <= t holds iff t = s * s0 for some s0 2 {0, 1}*.Let

p, q, r, s, t (possibly decorated) be metavariables ranging over {0, 1}*.The set of type variables or T-variables and the set of expansion variables or E-variables are, respectively:

TVar = { asi i 2 N , s 2 {0, 1}* } and EVar = { Fsi i 2 N , s 2 {0, 1}* } .
Let TVar and EVar properly extend TVarb and EVarb by taking ai to be a"i and Fi to be F"i , where " denotes theempty string. Let (

asi )t denote as*ti and let (Fsi )t denote Fs*ti . Let ff and fi be metavariables ranging over TVarand let
F (in italics) be a metavariable ranging over EVar. For example, if ff denotes asi , then fft denotes as*ti .We use

v (appropriately decorated) as a metavariable ranging over the disjoint union Var = EVar [ TVar.

Definition 2.3 (Types). Let "!" and "^" be binary type constructors. The set T of types and its subsetT! as well as metavariables over these sets are given as follows:

_o/ 2 T! ::= ff | (o/ ! _o/ )
o/ 2 T ::= _o/ | (o/ ^ o/ 0) | (F o/ )

Note that _o/ is only a metavariable over T!. The letters ae and oe will be used later to range over certainother subsets of T. Observe in the tree representation of any

o/ 2 T that no "^" and no E-variable can occuras the right child of "!". We sometimes omit parentheses according to the rule that "!" and "^" associate

to the right and the application of an expansion variable (e.g., F o/ ) has higher precedence than "^" whichhas higher precedence than "!". For example,

F o/1 ^ o/2 ! o/3 = ((F o/1) ^ o/2) ! o/3.

Definition 2.4 (Type Environments). A type environment is a function A from *-Var to T with a finitedomain of definition. A type environment may be written as a finite list of pairs, as in

x1 : o/1, . . . , xk : o/k
for some distinct x1, . . . , xk 2 *-Var, some o/1, . . . , o/k 2 T and some k >= 0. If A is a type environment, then
A[x 7! o/ ] is the type environment such that

(A[x 7! o/ ])(y) = (A(y) if y 6= x,o/ if y = x,

6

and A\x is the type environment such that

(A\x)(y) = (A(y) if y 6= x,undefined if y = x.
If A and B are type environments, then A ^ B is a new type environment given by:

(A ^ B)(x) = 8??!??:

A(x) ^ B(x) if both A(x) and B(x) defined,
A(x) if only A(x) defined,
B(x) if only B(x) defined,undefined if both

A(x) and B(x) undefined.

If F 2 EVar is an E-variable and A is a type environment, then F A is the type environment such that(

F A)(x) = F (A(x)).

Inference Rules for both Skeletons and Derivations

VAR x : _o/ ` x : _o/ ^ A1 `? M : o/1; A2 `? M : o/2A

1 ^ A2 `e M : o/1 ^ o/2

ABS-I A[x 7! o/] ` M : _o/A ` (*x.M) : (o/ ! _o/ ) ABS-K A ` M : _o/A ` (*x.M) : (_o/ 0 ! _o/ ) if x 62 FV(M)

Inference Rule for Skeletons Only

(S) APP A1 ` M : _o/; A2 `? N : o/A

1 ^ A2 ` M N : _o/ 0

Inference Rule for Derivations Only

(D) APP A1 ` M : o/ ! _o/; A2 `? N : o/A

1 ^ A2 ` M N : _o/

Inference Rule for both Skeletons and Derivations: Introducing Expansion Variable F

F A `? M : o/F A `

e M : F o/

Figure 1: Inference Rules of System I.
Definition 2.5 (Judgements, Rule Names, and Skeletons). The sets of judgements, rule names, andpre-skeletons are determined by the following grammar:

J 2 Judg ::= A ` M : o/ | A `e M : o/
R 2 Rule ::= VAR | ABS-K | ABS-I | APP | ^ | F
Q 2 PSkel ::= hR, J, ~Qi

Judgements formed with the `e symbol will be used to restrict the ^ and F rules so these rules are usedonly for subterms which are the arguments of an application. Observe that a pre-skeleton S is a rule name

R, a final judgement J, and zero or more subskeletons ~Q. The order of the subskeletons is significant. Notethat

F is a rule name for every F 2 EVar.A skeleton S of System I is a pre-skeleton

Q such that, for every sub-pre-skeleton Q0 = hR, J, ~Qi occurring

in Q, it holds that the judgement J is obtained from the end judgements of the pre-skeletons ~Q (whose orderis significant) by rule

R and rule R is one of the rules for skeletons of System I in figure 1. The order of the

pre-skeletons ~Q determines the order in which their end judgements must match the premises of the rule R.A skeleton h

R, J, Q1 . . . Qni may be written instead as:

Q1 . . . Qn R

J
There are two rules named APP in figure 1: Only rule "(S) APP" is used in skeletons. In interpreting therules in figure 1, the pattern

A `? M : o/ can refer to either A ` M : o/ or A `e M : o/. Observe that the

7

rule ABS-K is not a special case of the rule ABS-I. This is because there is no rule or other provision for"weakening" (adding redundant type assumptions to a type environment) in our system and therefore, if
there is a proof for the judgement A ` M : o/ where x 62 FV(M ), then A(x) is not defined.
Definition 2.6 (Derivations and Typings). A derivation D of System I is a skeleton S such that everyuse of the rule named "(S) APP" also qualifies as a use of the more restrictive rule named "(D) APP" in

figure 1. The set Deriv of derivations is therefore a proper subset of the set Skel of skeletons. Henceforth, allskeletons and derivations belong to System I.

Let the statement A `I M : o/ hold iff there exists a derivation D of System I whose final judgement is
A ` M : o/ . When this holds, we say that D is a typing for M. A term M is typable in System I iff A `I M : o/holds for some

A and o/ . Note that every typing is a derivation, but not the other way around.

The following result is merely what anyone would expect from a system of intersection types formulatedwithout a rule for

!.

Theorem 2.7 (Strong Normalization). A *-term M is strongly normalizable (i.e., there is no infinite
fi-reduction sequence starting from M ) if and only if M is typable in System I.

Proof. A *-term M is typable in System I iff M is typable in System *!,^ of [Kfo99], which is shownthere to hold iff

M is fi-SN. System *!,^ of [Kfo99] is in fact a non-essential variation of earlier systems ofintersection types which were shown to type exactly the strongly normalizable

*-terms: The first (correct)proof of the "if" part in the theorem is due to Pottinger [Pot80], and the first (correct) proof of the "only-if"

part, as far as we are aware, is due to Amadio and Curien [AC98].
Corollary 2.8 (Undecidability of Typability). It is undecidable whether an arbitrarily chosen *-term
M is typable in System I.

Later in the paper, we will show certain restrictions of System I to have decidable typability.
Remark 2.9. System I does not have the subject reduction property. For example,

z : ff2 ! ff1 ! ff3, w : ff1 ^ ff2 `I (*x.(*y.zyx)x)w : ff3 ,
but

z : ff2 ! ff1 ! ff3, w : ff1 ^ ff2 0I (*x.zxx)w : ff3 .
By theorem 2.7, typability is preserved, so for example:

z : ff2 ! ff1 ! ff3, w : ff2 ^ ff1 `I (*x.zxx)w : ff3 .
The reason for the lack of subject reduction is that (1) "^" is neither associative, commutative, nor idempo-tent, (2) the implicit ^-elimination done by the VAR rule and the way type environments are built together

fix the component of an intersection type associated with a particular variable, and (3) there is no provisionfor weakening (i.e., introducing unneeded type assumptions). If subject reduction is viewed as a means to
achieve other goals rather than as a goal by itself, then the lack of subject reduction is not a problem, becausederivations of System I can be easily translated into derivations of more permissive systems of intersection
types (see [vB93] for a survey) for which numerous desirable properties have already been verified. Thefeatures of System I which prevent subject reduction make the later analysis of principal typings and type
inference much easier.

2.2 Substitution
The notion of substitution defined here will be used later in unification for type inference and in establishinga principal typing property for System I.

8

Definition 2.10 (Type Contexts). The symbol \Lambda  denotes a "hole". The set T2 of type contexts and itssubset T!

2 as well as metavariables over these sets are given as follows:

_' 2 T!2 ::= \Lambda  | ff | (' ! _')
' 2 T2 ::= _' | (' ^ '0) | (F ')

Note that _' is only a metavariable over T!2 . If ' has n holes, we write #2(') = n and use \Lambda (1), . . . , \Lambda (n)to denote these

n holes in their order of occurrence in ' from left to right. Care must be applied wheninserting
o/1, . . . , o/n 2 T in the holes of ' in order to obtain a type o/ = '[o/1, . . . , o/n] which is valid according
to Definition 2.3. Specifically, if hole \Lambda (i) in ' is to the immediate right of "!", then o/i must be restrictedto the subset T!.

If ' 2 T2, we write EVar(') for the set of E-variables occurring in ', TVar(') for the set of T-variablesoccurring in

', and Var(') for the disjoint union EVar(') [ TVar(').

Definition 2.11 (Expansions). The set E of expansions is a proper subset of T2, defined by the followinggrammar:

e 2 E ::= \Lambda  | (e ^ e0) | (F e)
In words, an expansion is a type context which mentions no T-variable and no "!".
Definition 2.12 (Paths in Type Contexts). We define path as a partial function which determines the
position of \Lambda (i) in ' as a string in {L, R, 0, 1}*. The definition goes as follows, using a "value" of ? to indicatethat the function is undefined on that input:

path(\Lambda (i), \Lambda ) = (" if i = 1,? otherwise.
path(\Lambda (i), ff) = ?

path(\Lambda (i), ' ! _') = 8?!?:

L * p if p = path(\Lambda (i), ') 6=?,
R * q if q = path(\Lambda (i-#2(')), _') 6=?,?

otherwise.

path(\Lambda (i), ' ^ '0) = 8?!?:

0 * p if p = path(\Lambda (i), ') 6=?,
1 * q if q = path(\Lambda (i-#2(')), '0) 6=?,?

otherwise.
path(\Lambda (i), F ') = path(\Lambda (i), ')

Let paths(') = \Gamma path(\Lambda (1), '), . . . , path(\Lambda (n), ')\Delta  where n = #2(').
Remark 2.13. Because an expansion e 2 E is a type context that does not mention "!", a path in e isa string in {0

, 1}* rather than in {L, R, 0, 1}*. We thus use binary strings in {0, 1}* for a dual purpose: aspaths in expansions and as offset labels to rename variables (see definition 2.2). The coincidence between

the two is by design.
Definition 2.14 (Variable Renaming). For every t 2 {0, 1}* (we do not need to consider the larger set{

L, R, 0, 1}), we define a variable renaming h it from T2 to T2, by induction:

1. h\Lambda it = \Lambda .
2. hasi it = as*ti for every asi 2 TVar.
3. h' ! _'it = h'it ! h _'it.
4. h'1 ^ '2it = h'1it ^ h'2it.
5. hFsi 'it = Fs*ti h'it for every Fsi 2 EVar.
In words, h'it is obtained from ' by appending t to every offset that is part of a variable name in '.

9

Definition 2.15 (Substitution on Types and Type Contexts). Because every type is also a type con-text, it suffices to give the definition for the latter. A substitution is a total function

S : Var ! (E [ T!)which respects "sorts", i.e., S
F 2 E for every F 2 EVar and Sff 2 T! for every ff 2 TVar. Note that S(ff)can not have an E-variable or "^" in outermost position. We write

SF instead of S(F ) and Sff instead of
S(ff), as long as no ambiguity is introduced. We lift a substitution S to a function S from T2 to T2, byinduction:

1. S\Lambda  = \Lambda .
2. Sff = Sff.
3. S(' ! _') = (S') ! (S _').
4. S('1 ^ '2) = (S'1) ^ (S'2).
5. S(F ') = e[S(h'is1 ), . . . , S(h'isn )], where SF = e and paths(e) = (s1, . . . , sn).
When no ambiguity is possible, we write S for S and S ' for S(').
Definition 2.16 (Support of Substitutions). Let S : Var ! (E [ T!) be a substitution. The non-trivialE-domain and non-trivial T-domain of

S are

EDom(S) = { F 2 EVar SF 6= F \Lambda  } and TDom(S) = { ff 2 TVar Sff 6= ff },
respectively. The non-trivial domain of S (or the support of S) is

Dom(S) = EDom(S) [ TDom(S).
The notation

{[F1 := e1, . . . , Fm := em, ff1 := _o/1, . . . , ffn := _o/n]}
denotes a substitution S with the indicated mappings where EDom(S) = {F1, . . . , Fm} and TDom(S) ={

ff1, . . . , ffn}. We use the enclosing pair, "{[" and "]}" instead of "{" and "}", as visual help to distinguishS from constraint sets to which it is applied. Consistent with the preceding notation, {[ ]} is the substitution

such that:

{[ ]} (v) = (v\Lambda  if v 2 EVar,v if v 2 TVar.
Definition 2.17 (Operations on Judgements and Skeletons). The notion of renaming from defini-tion 2.14 is lifted to type environments, judgements, rule names, and skeletons in the obvious way.

The ^ operator and the operation of applying an E-variable are lifted to skeletons as follows:
1. S ^ S0 = h^, A1 ^ A2 `e M : o/1 ^ o/2, S S0i if S = hR1, A1 `? M : o/1, ~Si andS0

= hR2, A2 `? M : o/2, ~S0i.

2. F S = hF, F A `e M : F o/ , Si if S = hR, A `? M : o/, ~Si.
Using the preceding, the notation for "expansion filling" is lifted to skeletons as follows:

1. (e ^ e0)[S1, . . . , Sn] = S ^ S0 if #2(e) = j, e[S1, . . . , Sj] = S, and e0[Sj+1, . . . , Sn] = S0.
2. (F e)[S1, . . . , Sn] = F (e[S1, . . . , Sn]).
3. \Lambda [S] = S.

The notion of substitution is lifted to type environments so that S A is the function such that (S A)(x) =
S(A(x)). Substitution is lifted to judgements so that S(A `? M : o/ ) = S(A) `? M : S(o/ ). Substitution islifted to skeletons as follows:

10

1. ShR, J, S1 * * * Sni = hR, S J, (S S1) * * * (S Sn)i if R /2 EVar.
2. ShF, J, Si = e[S(hSis1 ), . . . , S(hSisn )] where SF = e and paths(e) = (s1, . . . , sn).
Lemma 2.18 (Effect of Substitution on Final Judgement). Let S be any substitution. Let S be the
skeleton hR, A `X M : o/, ~Sni where X is either "e" or blank. Then S(S) = hR0, S A `Y M : S o/ , ~S0i for some
R0, ~S0, and Y where Y is blank if X is blank.

Proof. By induction on the number of sub-skeletons in S and then by cases on rule R.
Lemma 2.19 (Substitution Preserves Skeletons and Derivations). Let S be any substitution.

1. If S is a skeleton, then S(S) is a skeleton.
2. If D is a derivation, then S D is a derivation.
Proof. By induction on the number of rules in D, using lemma 2.18.
Definition 2.20 (Principal Typings). A derivation D is a principal typing for *-term M iff D is a typingfor

M and for every other typing D0 for M , there is a substitution S such that D0 = S(D). The principalityproperty for typings is the existence of a principal typing for every typable

*-term.

Subsequent sections will establish that System I has the principality property. We next give two simpleexamples to illustrate how notions introduced so far are used, in particular, the key concepts of "skeleton",

"derivation" and "substitution" in the presence of expansion variables.

The skeleton S1 = Skel(M1) is:

VARx : ff
1 ` x : ff1 ABS-I

` *x.x : ff1 ! ff1

VARy : ff
2 ` y : ff2

VARy : ff
3 ` y : ff3 F

y : F ff3 `e y : F ff3 APP
y : ff2 ^ F ff3 ` yy : fi1 ABS-I
` *y.yy : ff2 ^ F ff3 ! fi1 G
`e *y.yy : G(ff2 ^ F ff3 ! fi1) APP
` (*x.x)(*y.yy) : fi2
Letting \Delta 1 = \Gamma (M1) and S1 = Unify(\Delta 1), the derivation D1 = S1(S1) is:

VARx : o/ ` x : o/

ABS-I` *x.x : o/ ! o/

VARy : F ff ! fi ` y : F ff ! fi

VARy : ff ` y : ff

Fy : F ff `
e y : F ff APP

y : (F ff ! fi) ^ F ff ` yy : fi ABS-I

` *y.yy : o/ APP
` (*x.x)(*y.yy) : o/
where o/ = ((F ff ! fi) ^ F ff) ! fi.

Figure 2: Skeleton S1 and derivation D1 for M1 = (*x.x)(*y.yy).

Example 2.21 (Principal Typing for (*x.x)(*y.yy)). Let M1 denote the *-term (*x.x)(*y.yy). De-picted in figure 2 is a skeleton S

1 for M1. The skeleton S1 is a particular one, produced from M1 by the Skelalgorithm of section 6. It is just a decorated version of the parse tree of

M1 and its size is therefore "small",

11

i.e., proportional to the size of M1:

(*x.x)(*y.yy)
*x.x

x

*y.yy

yy
y y

Applying an arbitrary substitution to S1, we can obtain another skeleton for M1. Thus, S1 is a scheme forinfinitely many skeletons for

M1.Associated with S

1 is a constraint set \Delta 1 = {ff1 ! ff1 .= G(ff2 ^ F ff3 ! fi1) ! fi2, Gff2 .= G(F ff3 ! fi1)},produced from
M1 by the \Gamma  algorithm of section 6. ("Constraint sets" and restrictions on them are definedprecisely in section 4.) Note that there is one constraint in \Delta 

1 for each use of the APP rule in S1. Aparticular substitution S
1, obtained from \Delta 1 using the Unify algorithm of section 5, is given by:

S1 = {[G := \Lambda , ff1 := o/, ff2 := F ff ! fi, fi2 := o/ ]}
where o/ = ((F ff ! fi) ^ F ff) ! fi with ff = ff3 and fi = fi1. Applying substitution S1 to skeleton S1, weobtain another skeleton which is now a derivation D

1 = S1(S1), depicted in figure 2.A consequence of the analysis in sections 5 and 6 is that D

1 is a principal typing for M1, i.e., every typingD0 for
M1 is of the form D0 = S0(D1) for some substitution S0.

The skeleton S2 = Skel(M2) is:

VARx : ff
1 ` x : ff1

VARy : ff
2 ` y : ff2 F

y : F ff2 `e y : F ff2 APP
x : ff1, y : F ff2 ` xy : fi1 ABS-I
x : ff1 ` *y.xy : F ff2 ! fi1 ABS-I
` *x.*y.xy : ff1 ! F ff2 ! fi1

VARz : ff
3 ` z : ff3

VARz : ff
4 ` z : ff4 G

z : Gff4 `e z : Gff4 APP
z : ff3 ^ Gff4 ` zz : fi2 ABS-I
` *z.zz : ff3 ^ Gff4 ! fi2 H
`e *z.zz : H(ff3 ^ Gff4 ! fi2) APP
` (*x.*y.xy)(*z.zz) : fi3
Letting \Delta 2 = \Gamma (M2) and S2 = Unify(\Delta 2), the derivation D2 = S2(S2) is:

VARx : o/
3 ` x : o/3

VARy : o/
1 ` y : o/1

VARy : ff ` y : ff

Gy : Gff `
e y : Gff ^

y : o/2 `e y : o/2 APP
x : o/3, y : o/2 ` xy : fi ABS-I

x : o/3 ` *y.xy : o/3 ABS-I
` *x.*y.xy : o/3 ! o/3

VARz : o/
1 ` z : o/1

VARz : ff ` z : ff

Gz : Gff `
e z : Gff APP

z : o/2 ` zz : fi ABS-I

` *z.zz : o/3 APP
` (*x.*y.xy)(*z.zz) : o/3
where o/1, o/2 and o/3 abbreviate the following types:

o/1 = Gff ! fi, o/2 = o/1 ^ Gff = (Gff ! fi) ^ Gff, o/3 = o/2 ! fi = (Gff ! fi) ^ Gff ! fi.

Figure 3: Skeleton S2 and derivation D2 for M2 = (*x.*y.xy)(*z.zz).
Example 2.22 (A Principal Typing for (*x.*y.xy)(*z.zz)). Let M2 denote the *-term (*x.*y.xy)(*z.zz).Depicted in figure 3 is a skeleton S

2 for M2.

12

As in example 2.21, the skeleton S2 is a particular one, produced from M2 by the Skel algorithm.Associated with S

2 is the following constraint set, produced from M2 by the \Gamma  algorithm of section 6:

\Delta 2 = {ff1 .= F ff2 ! fi1, ff1 ! F ff2 ! fi1 .= H(ff3 ^ Gff4 ! fi2) ! fi3, Hff3 .= H(Gff4 ! fi2)}
A particular substitution S2, obtained from \Delta 2 using the Unify algorithm of section 5, is given by:

S2 = {[F := \Lambda  ^ G\Lambda , H := \Lambda , ff1 := o/3, ff02 := o/1, ff12 := ff, ff3 := o/1, fi1 := fi, fi3 := o/3]}
where we use the abbreviations o/1 = Gff ! fi and o/3 = ((Gff ! fi) ^ Gff) ! fi, with ff = ff4 and fi = fi2.Observe that, in this example,

S2 assigns values to the offsprings ff02 and ff12 of ff2, but does not need toassign any particular value to
ff2 itself. This follows from the way substitutions are applied "outside-in",and becomes clear when we consider the action of S

2 on F ff2:

S2(F ff2) = (\Lambda  ^ G\Lambda )[Shff2i0, Shff2i1] = (\Lambda  ^ G\Lambda )[Sff02, Sff12] = Sff02 ^ G(Sff12) = (Gff ! fi) ^ Gff .
Applying substitution S2 to skeleton S2, we obtain a new skeleton which is also a derivation D2 = S2(S2),as depicted in figure 3.

A consequence of the analysis in sections 5 and 6 is that D2 is a principal typing for M2, i.e., every typingD0 for

M2 is of the form D0 = S0(D2) for some substitution S0.

Remark 2.23. The typings identified as principal in this paper are not identical to the things which wouldbe defined to be principal typings following the general definition of Wells [Wel02]. A minor difference is that

a typing in this paper is an entire derivation of a judgement rather than a pair (A, o/ ) of the type environmentand result type in the final judgement of a derivation. This difference can be bridged by simply using the
(A, o/ ) pair from the final judgement of a typing in this paper. Then every principal typing of this paper isalso a principal typing following the general definition. A slightly larger difference is that the word typing in
this paper is (somewhat arbitrarily) restricted to the case of a derivation where the final type belongs to therestricted set T! rather than the set T of all types. So ({

x : ff}, ff) is in the final judgement of a principaltyping for
x according to this paper's definition, but not ({x : F ff}, F ff). Because each typable term has atleast one principal typing, this difference does not cause a problem.

3 Properties of Substitutions
The mechanism of substitution in this paper is new. It comes with several peculiarities that set it apartfrom other forms of substitution in the literature.

3.1 On Types in General
We start with a very simple but fundamental result about substitutions. If S1 and S2 are substitutions infirst-order unification, then

S1 = S2 iff S1 = S2, where S is the lifting of S (definition 2.15). This is a basicfact, which is completely obvious in first-order unification but requires a little proof in

fi-unification.Proposition 3.1 is nowhere invoked directly. But it is used implicitly throughout, because it allows us to

use the same symbol S to denote both a substitution and its lifting, unambiguously.
Proposition 3.1 (Lifting is Injective). Let S1 : Var ! (E [ T!) and S2 : Var ! (E [ T!) be arbitrarysubstitutions. Then

S1 = S2 iff S1 = S2.

Proof. The implication from left to right is immediate, i.e., lifting S to S is a uniquely defined operation.For the converse ("lifting is injective"), we assume that

S1 = S2 and we prove that S1 = S2.Let
ff be an arbitrary T-variable. We want to show S1ff = S2ff. By definition, Sff = Sff. Hence, if
S1 = S2, then S1ff = S2ff, as desired.Let

F be an arbitrary E-variable. We want to prove that S1F = S2F . Take an arbitrary ff 2 TVar andconsider the action of

S1 and S2 on the type (F ff). By definition 2.15:

S1(F ff) = e1[S1ffs1, . . . , S1ffsm ] = e1[S1ffs1 , . . . , S1ffsm ] ,where

e1 = S1F and (s1, . . . , sm) = paths(e1).

13

S2(F ff) = e2[S2fft1, . . . , S2fftn ] = e2[S2fft1, . . . , S2fftn ] ,where

e2 = S2F and (t1, . . . , tn) = paths(e2).

By hypothesis, S1(F ff) = S2(F ff). Together with the fact that S1ffsi 2 T! for every 1 <= i <= m andS

2fftj 2 T! for every 1 <= j <= n, this implies that e1 = e2, i.e., S1F = S2F as desired.

Much of the difficulty in dealing with substitutions in fi-unification results from the distinctive way inwhich "composition" and "ground composition" of substitutions behave. We next give precise definitions for

these two operations.
Definition 3.2 (Composition of Substitutions). Lifting substitutions to functions from T2 to T2, asin definition 2.15, allows us to compose them (as functions from T

2 to T2) and we use the standard symbol"ffi".2 Specifically, if the substitutions S
1 and S2 are lifted to functions from T2 to T2, then their compositionis defined by:

S2 ffi S1 = { ' 7! S2(S1') | ' 2 T2 } .
If S1, S2 and S3 are arbitrary substitutions, then it is always the case that:

S3 ffi (S2 ffi S1) = (S3 ffi S2) ffi S1 .
This really means S3 ffi (S2 ffi S1) = (S3 ffi S2) ffi S1, which is the usual associativity of function composition.
Definition 3.3 (Ground Composition). If S1 and S2 are arbitrary substitutions, we define a new sub-stitution

S2 \Pi  S1, the ground composition of S2 and S1, by:

S2 \Pi  S1 = { v 7! S2(S1v) v 2 Var } ,
which of course can be lifted to a function S2 \Pi  S1 from T2 to T2 as in definition 2.15.

If S1 and S2 are the functions resulting from lifting S1 and S2, it may be expected as elsewhere inunification theory that

S2 ffi S1 = S2 \Pi  S1, but it is not! This and other subtle issues are illustrated byexamples.

Example 3.4 (Composition 6= Ground Composition). Consider the substitutions S1 = {[ff := fi]},where

ff 6= fi, and S2 = {[F := \Lambda  ^ \Lambda ]}. It is clear that S2 \Pi  S1 = {[F := \Lambda  ^ \Lambda , ff := fi]}. ApplyingS

2 \Pi  S1 to the type F ff, we obtain:

(S2 \Pi  S1)(F ff) = ff0 ^ ff1 .
Applying S2 ffi S1 to the same type F ff, we obtain:

(S2 ffi S1)(F ff) = S2(S1(F ff)) = fi0 ^ fi1 .
Hence, the two operations, "\Pi " and "ffi", are not the same. To be explicit about the lifting operation, thissays that

S2 ffi S1 6= S2 \Pi  S1.

Example 3.5 (Ground Composition Not Associative). Consider the following substitutions:

S1 = {[ F := GH\Lambda  ]}, S2 = {[ H := \Lambda  ^ \Lambda  ]} and S3 = {[ G := \Lambda  ^ \Lambda  ]} .
A straightforward calculation shows that:

S3 \Pi  (S2 \Pi  S1) = {[ F := (\Lambda  ^ \Lambda ) ^ (\Lambda  ^ \Lambda ), G := \Lambda  ^ \Lambda , H := \Lambda  ^ \Lambda  ]} ,
(S3 \Pi  S2) \Pi  S1 = {[ F := H0\Lambda  ^ H1\Lambda , G := \Lambda  ^ \Lambda , H := \Lambda  ^ \Lambda  ]} .

Clearly, S3 \Pi  (S2 \Pi  S1) 6= (S3 \Pi  S2) \Pi  S1.

2The "composition" of substitutions as such, from Var to E[T!, is actually meaningless, because their domain and codomain
are not the same.

14

Example 3.6 (Substitutions Not Closed Under Composition). We give two examples, each illus-trating a different point.

1. Consider the substitutions:

S1 = {[F := \Lambda  ^ \Lambda , ff1 := fi]} and S2 = {[G := \Lambda  ^ \Lambda , ff1 := fl]} ,
where fi 6= fl. While S2 ffi S1 is well-defined as a function from T2 to T2, it is not a substitution, i.e.,the lifting of a substitution. To see this, consider the action of

S2 ffi S1 on the types F ff and Gff:

(S2 ffi S1)(F ff) = S2(S1(F ff)) = ff0 ^ fi and (S2 ffi S1)(Gff) = S2(S1(Gff)) = ff0 ^ fl .
There is no substitution S which maps both F ff to ff0 ^ fi and Gff to ff0 ^ fl. If such a substitution
S existed, it would map two distinct E-variables F and G to the same expansion \Lambda  ^ \Lambda  (which ispossible) and the same T-variable

ff1 to two distinct types fi and fl (which is not possible). It followsalso that there is no substitution which maps the single type

F ff ^ Gff to (ff0 ^ fi) ^ (ff0 ^ fl). Thus,posing
o/ = (F ff ^ Gff), we have So/ 6= (S2 ffi S1)o/ for every substitution S.

2. Let now:

S01 = {[F := \Lambda  ^ (\Lambda  ^ \Lambda ), ff11 := fi]} and S02 = {[G := \Lambda  ^ \Lambda , ff11 := fl]} ,
where fi 6= fl. Consider the action of S02 ffi S01 on the types F ff and Gff1:

(S02 ffi S01)(F ff) = S02(S01(F ff)) = ff0 ^ (ff10 ^ fi) and (S02 ffi S01)(Gff1) = S02(S01(Gff1)) = ff10 ^ fl .
By the reasoning used above, there is no substitution which maps F ff^Gff1 to (ff0^(ff10 ^fi))^(ff10^fl).
Thus, posing o/ 0 = (F ff ^ Gff1), we have So/ 0 6= (S02 ffi S01)o/ 0 for every substitution S.

We have purposely given two types, o/ and o/ 0, over which the composition of two substitutions is not equivalentto a single substitution. Looking ahead,

o/ and o/ 0 violate condition 1 and condition 2, respectively, of "well-named" types (definition 3.9). In lemma 3.18, we show that if

o/ is well-named and S1o/ is well-named, thenthere is indeed a substitution
S such that So/ = (S2 ffi S1)o/ .

Remark 3.7. It is possible to impose restrictions on variable names and the use of substitutions in orderto recover the usual properties encountered in other forms of unification, including the following desirable

property:

1. S2 ffi S1 = S2 \Pi  S1 ,
for all appropriately restricted substitutions S1 and S2, which would imply two other desirable properties:

2. S3 \Pi  (S2 \Pi  S1) = (S3 \Pi  S2) \Pi  S1 , and
3. the function S2 ffi S1 is a substitution, i.e., the lifting of a substitution.
For property 2, the associativity of "\Pi " (not always guaranteed, by example 3.5) would follow from theassociativity of "ffi" (always guaranteed, by definition 3.2). For property 3, as

S2 \Pi  S1 is a substitution (bydefinition 3.3), it would follow that S

2 ffi S1 is (the lifting of) a substitution.However, it does not seem to be worth the effort to guarantee the preceding three properties at some

reasonable level of generality. Instead, we are careful in restricting the use of substitutions in order to achieve,at a minimum, the third property above.

3.2 On Well-Named Types Only
Several properties of substitutions are true provided they are restricted to "well-named" types. The definitionrequires the preliminary notion of "E-path", which also plays an important role in the analysis of later

sections.

15

Definition 3.8 (E-paths). The set EVar* of all finite sequences of E-variables is also called the set ofE-paths. We define a function

E-path from Var * T2 to finite subsets of EVar*. By induction:

1. E-path(v, \Lambda ) = ?.

2. E-path(v, ff) = ({"} if v = ff,? if v 6= ff.
3. E-path(v, ' ! _') = E-path(v, ') [ E-path(v, _').
4. E-path(v, ' ^ '0) = E-path(v, ') [ E-path(v, '0).

5. E-path(v, F ') = ({F ~G | ~G 2 E-path(v, ')} if v 6= F ,{"} [ {F ~G | ~G 2 E-path(v, ')} if v = F .
Let ' be a type context with n >= 1 holes \Lambda (1), . . . , \Lambda (n) and let o/ = '[ff1, . . . , ffn] where ff1, . . . , ffn are n
fresh and distinct T-variables. We define E-path(\Lambda (i), ') = E-path(ffi, o/ ) for every 1 <= i <= n.

Definition 3.9 (Well Named Types and Well Named Type Contexts). As every type is also a typecontext, it suffices to write the definition for the latter. We say that a type context

' 2 T2 is well named iffboth of the following statements hold:

1. For every v 2 Var('), it holds that E-path(v, ') = { ~G} (a singleton set) where v does not occur in ~G.
2. For all vs, vt 2 Var(') with v basic and s, t 2 {0, 1}*, if s <= t then s = t.

Informally, the first condition says that, for every (type or expansion) variable v, the sequence of E-variables encountered as we go from the root of

' (viewed as a tree) to any occurrence of v is always the
same. Furthermore, E-variables do not nest themselves. If E-path(v, ') is the singleton set { ~F }, we can write
E-path(v, ') = ~F without ambiguity.The second condition says that if a variable

v occurs in ', then no proper offspring of v occurs in ', wherea variable
vs*t is called an offspring of vs. Note that types that mention only basic variables automaticallysatisfy the second condition.

Remark 3.10. Condition 1 in definition 3.9 is the important one and will be recalled repeatedly in proofslater. Condition 2 will be automatically satisfied in the way we set up constraints and in the way we apply
substitutions to them, and will play no significant role in the interesting part of our analysis.When we derive a constraint set \Gamma (

M ) from a *-term M in section 6, we will be careful to restrict \Gamma (M )to types over basic variables, thus automatically satisfying condition 2. Types over variables that are not

basic will be introduced only as a result of applying substitutions. In fi-unification, if a substitution S isapplied to a type

o/ , the resulting type So/ may mention several distinct renamings v1, . . . , vn ("offspring")of the same variable

v in o/ . Although we do not do it in this report, it is possible to choose v1, . . . , vn tobe fresh basic variables, obviating the need to impose condition 2. To simplify the bookkeeping, we follow

a different approach, whereby all offsprings in So/ of the same variable v are obtained by attaching distinctand incomparable offset labels to

v, as in definition 2.15. (The offset labels are incomparable as strings in{0
, 1}*.) In this way we guarantee that condition 2 is satisfied again.There are various technical implications of condition 2 in definition 3.9 in relation to variable naming.

These may be ignored without affecting the reader's understanding through most of the analysis. Condition2 in definition 3.9 matters and makes an important difference only in a few places in this section only.

In general, the standard composition of two substitutions using "ffi" does not produce a substitution, i.e.,for substitutions

S1 and S2, there does not necessarily exist a substitution S3 such that S3 = (S2 ffi S1). (Seeexample 3.6). To work around this difficulty, we use "\Omega 

E", a new binary operation on substitutions whichwe call "safe composition relative to E", where E is an environment expressing certain naming constraints.

Lemma 3.18 makes the new notion precise. We need a few preliminary definitions and related facts first.

16

Definition 3.11 (E-Path Environment). Given a well-named type context ', we form its E-path envi-ronment as follows:

(E-env('))(v) = ( ~F if E-path(v, ') = { ~F },undefined if E-path(v, ') = ?.
An E-path environment is a partial function E : Var ! EVar* that is the result of applying the E-env functionto a well-named type context

'. Let E be a metavariable over E-path environments.Let E be an E-path environment, which implies there is a well-named type context

' inducing it, i.e.,E =
E-env('). Let S be a substitution such that S' is a well-named type context. We define SE to beanother E-path environment, by setting

(SE)(v) = ( ~F if E-path(v, S') = { ~F },undefined if E-path(v, S') = ?.
Lemma 3.12 (E-Path Environments Are Prefix-Closed). Let E be an E-path environment and let v 2
Var. If E(v) is defined with E(v) = ~F G, then E(G) is defined with E(G) = ~F .

Proof. Immediate from the definitions.

We give two equivalent definitions of "safe composition", in 3.13 and 3.14. The first is more compactand convenient to use in some proofs. The second is more constructive and makes explicit that

S2 \Omega E S1,the safe composition of substitutions
S1 and S2 relative to E, is well-defined as a function.

Definition 3.13 (Safe Composition). Let S1 and S2 be substitutions, and E an E-path environment.The safe composition of S

1 and S2 relative to E is a new substitution, written S2 \Omega E S1 and defined by:

(S2 \Omega E S1)(v) = 8?!?:

'j if v = _vr, E(_v) = ~F , e = S2(S1( ~F \Lambda )) with #2(e) = n,

r = path(\Lambda (j), e) and e['1, . . . , 'n] = S2(S1( ~F _v)),{
[ ]} (v) otherwise.

which of course can be lifted to a function S2 \Omega E S1 from T2 to T2 as in definition 2.15.
Definition 3.14 (Algorithmic Definition of Safe Composition). First, define auxiliary functions env-offsetand

path-to-hole as follows.

env-offset(E)(b, s) = ((s0, t) if b

s0 in dom(E) and s0 * t = s,

undefined otherwise.

Observe that env-offset(E) is a well defined function, because for each b and s there is at most one s0 <= ssuch that

bs0 2 dom(E), because E is generated from some well-named type context '.

path-to-hole(')(s) = (i if path(\Lambda 

(i), ') = s,

undefined otherwise.

Observe that path-to-hole(') is a well defined function, because for any ' and s there is at most one i such
that path(\Lambda (i), ') = s.

17

Now, define the safe composition operator as follows.

(S1 \Omega E S2)(v) = let bs = vin if

env-offset(E)(b, s) is definedthen let (

s0, t) = env-offset(E)(b, s)
v0 = bs0

~F = E(v0)

e = S2(S1( ~F \Lambda ))
n = #2(e)in if

path-to-hole(e)(t) is definedthen let

i = path-to-hole(e)(t)

e['1, . . . , 'n] = S2(S1( ~F v0))in
'ielse {[ ]} (

v)else {[ ]} (
v)

We next prove three technical results. Lemma 3.15 is used to establish lemmas 3.16 and 3.17, and thelatter two are used in the proof of lemma 3.18 and the proof of lemma 5.11.
Lemma 3.15. Let S be a substitution and let e be an expansion. Then:

1. Se is an expansion.
2. Let #2(e) = k >= 1 and #2(Se) = n >= k. Then there are maps a, b and r solely depending on e and S:

a : {1, . . . , n} ! {1, . . . , k},
b : {1, . . . , n} ! {1, . . . , n}, and
r : {1, . . . , k} * {1, . . . , n} ! {0, 1}*

such that for all '1, . . . , 'k 2 T2 it holds that:

S(e['1, . . . , 'k]) = (Se)[Sh'a(1)ir(a(1),b(1)), . . . , Sh'a(n)ir(a(n),b(n))]
where

* {'a(1), . . . , 'a(n)} = {'1, . . . , 'k}, i.e., a is a total surjective map,

* if E-path(\Lambda (i), e) = ~F for 1 <= i <= k,

then paths(S( ~F \Lambda )) = (r(i, 1), . . . , r(i, ni)) for some ni >= 1,*

n = n1 + * * * + nk,* {

b(j) a(j) = i and 1 <= j <= n } = {1, . . . , ni} for every 1 <= i <= k.

Proof. Both parts are by structural induction on e. Part 1 is easy and left to the reader. Consider part 2only. For the base case

e = \Lambda  of the induction, the result is straightforward.Proceeding inductively, suppose the result is true for expansion

e and for every expansion whose sizedoes not exceed
size(e). Let F 2 EVar and consider the action of S on F e['1, . . . , 'k] for some arbitrary
'1, . . . , 'k 2 T2. We make a record of what we need to push the argument through:

1. Let #2(S F ) = m >= 1 and paths(S F ) = (p1, . . . , pm).
2. For every ` 2 {1, . . . , m}, let #2(Sheip`) = n` >= k.

18

3. By the induction hypothesis, for every ` 2 {1, . . . , m} there are maps a`, b` and r` solely dependingon h

eip` and S:

a` : {1, . . . , n`} ! {1, . . . , k},
b` : {1, . . . , n`} ! {1, . . . , n`}, and
r` : {1, . . . , k} * {1, . . . , n`} ! {0, 1}*

such that for all '01, . . . , '0k 2 T2 it holds that:

S(heip` ['01, . . . , '0k]) = (Sheip` )[Sh'0a`(1)ir`(a`(1),b`(1)), . . . , Sh'0a`(n)ir`(a`(n),b`(n))]
where

* {'0a`(1), . . . , '0a`(n`)} = {'01, . . . , '0k},

* if E-path(\Lambda (i), heip`) = ~F for 1 <= i <= k,

then paths(S( ~F \Lambda )) = (r`(i, 1), . . . , r`(i, n`,i)) for some n`,i >= 1,*

n` = n`,1 + n`,2 + * * * + n`,k,* {

b`(j) a`(j) = i and 1 <= j <= n` } = {1, . . . , n`,i} for every 1 <= i <= k.

4. We also need a general fact about associativity of the operation of placing types in the holes ofexpansions, namely,

e0[e1['1,1, . . . , '1,n1], . . . , em['m,1, . . . , 'm,nm]] =
(e0[e1, . . . , em])['1,1, . . . , '1,n1, . . . , 'm,1, . . . , 'm,nm] .

Based on the preceding observations, it is now straightforward to check the following sequence of equalities,for arbitrary

'1, . . . , 'k 2 T2:

S(F e['1, . . . , 'k]) = (SF )[She['1, . . . , 'k]ip1, . . . , She['1, . . . , 'k]ipm ]

= (SF )[S(heip1[h'1ip1, . . . , h'kip1]), . . . , S(heipm [h'1ipm, . . . , h'kipm ])]

= (SF )[Sheip1 [Sh'a1(1)ip1*r1(a1(1),b1(1)), . . . , Sh'a1(n1)ip1*r1(a1(n1),b1(n1))],

...

Sheipm[Sh'am(1)ipm*rm(am(1),bm(1)), . . . , Sh'am(nm)ipm*rm(am(nm),bm(nm))] ]
= (S(F e))[Sh'a1(1)ip1*r1(a1(1),b1(1)), . . . , Sh'a1(n1)ip1*r1(a1(n1),b1(n1)),

...

Sh'am(1)ipm*rm(am(1),bm(1)), . . . , Sh'am(nm)ipm*rm(am(nm),bm(nm))]
The first and second equalities follow from the definitions, the third equality uses the facts collected in 3above based on the induction hypothesis, and the fourth equality follows from 4. From the right-hand side
of the last equality, it is now easy to extract maps a, b and r that satisfy the conclusion of part 2 for theexpansion

F e.The remaining case of the induction is

e = e1 ^e2, and we assume the conclusion of part 2 is true for everyexpansion whose size is strictly smaller than

size(e). This case is straightforward (easier than the precedingcase
F e) and left to the reader.

Lemma 3.16. Let S be an arbitrary substitution and let ~F 2 EVar*. For all ' 2 T2, it is the case that:

S( ~F ') = (S( ~F \Lambda ))[Sh'ir1 , . . . , Sh'irn]
where paths(S( ~F \Lambda )) = (r1, . . . , rn).

19

Proof. This is a special case of lemma 3.15, obtained by making k = 1, e = ~F \Lambda , and '1 = '.
Lemma 3.17. Let S1 and S2 be arbitrary substitutions and let ~F 2 EVar*. By part 1 of lemma 3.15,
S1( ~F \Lambda ) and S2(S1( ~F \Lambda )) are expansions. Let e1 = S1( ~F \Lambda ) and e2 = S2(S1( ~F \Lambda )), with #2(e1) = k >= 1 and#

2(e2) = n >= k. Then for all ' 2 T2, it holds that:

S2(S1( ~F ')) = e2[S2hS1h'iq1 ir1, . . . , S2hS1h'iqn irn]
for appropriately defined q1, r1, q2, r2, . . . , qn, rn 2 {0, 1}* depending solely on the E-path ~F and the substi-tutions

S1 and S2.

Proof. We have the following sequence of equalities, using the maps a, b and r as defined in part 2 oflemma 3.15:

S2(S1( ~F ')) = S2(e1[S1h'ip1 , . . . , S1h'ipk ])

= e2[S2hS1h'ipa(1) ir(a(1),b(1)), . . . , S2hS1h'ipa(n) ir(a(n),b(n))]

where paths(e1) = (p1, . . . , pk) and, if E-path(\Lambda (i), e1) = ~Fi for every 1 <= i <= k, then paths(S2( ~Fi\Lambda )) =(

r(i, 1), r(i, 2), . . . , r(i, ni)) for some ni >= 1. The first equality above follows from part 2 of lemma 3.15,

posing e = ~F \Lambda ; more directly, it also follows from lemma 3.16. The second equality above follows from part2 of lemma 3.15, posing

e = e1. The desired conclusion now follows.

Lemma 3.18 (Sufficient Condition for Safe Composition). Let S1 and S2 be substitutions, ' a typecontext, and S = S

2 \Omega E S1 for some E-path environment E. If E ' E-env('), then S(') = S2(S1(')).

Note that the condition E ' E-env(') implies that ' is well-named.

Proof. Fix the E-path environment E throughout the proof. The appropriate induction here is on the number
n >= 0 of occurrences of "!" and "^" in well-named type contexts ' such that E ' E-env('). The base caseof the induction on

n involves another nested induction on the length ` >= 0 of E-paths.Base case: Type contexts

' for this case have n = 0 occurrences of "!" and "^", and therefore are of theform \Lambda  or ~
F G\Lambda  or ~F ff, with E(G) = ~F and E(ff) = ~F . If ' = \Lambda , the desired result is immediate. Consider

the case ' = ~F G\Lambda  only, and omit the entirely similar case ' = ~F ff.We proceed by a nested induction, on the length

` >= 0 of ~F . The base case of the nested induction is
` = 0, for which ' = G\Lambda  and E(G) = ". Posing _v = G in definition 3.13, we obtain in the same definition:
e = S2(S1\Lambda ) = \Lambda  and rj = path(\Lambda (j), e) = ", implying that v = _vrj = G and also that

S2(S1G) = S2(S1_v) = (S2 \Omega E S1)(v) = (S2 \Omega E S1)(G) = S(G),
which is the desired result.Consider next the case

' = ~F G\Lambda  where the length of ~F is ` + 1. If E ' E-env('), then E(G) = ~F . Let
e = S2(S1( ~F \Lambda )) with #2(e) = n and paths(e) = (r1, . . . , rn). By lemma 3.17,

S2(S1( ~F G\Lambda )) = e[S2hS1hG\Lambda iq1 ir01 , . . . , S2hS1hG\Lambda iqn ir0n]
for appropriately defined q1, r01, . . . , qn, r0n 2 {0, 1}*. Defining 'j = S2hS1hG\Lambda iqj ir0j for every 1 <= j <= n,
this means that S2(S1( ~F G\Lambda )) = e['1, . . . , 'n]. For a fixed j 2 {1, . . . , n}, if we pose v = Grj and _v = G indefinition 3.13, we get:

S Grj = (S2 \Omega E S1)(Grj ) = 'j.
The preceding observations imply the following sequence of equalities:

S2(S1( ~F G\Lambda )) = e['1, . . . , 'n] as shown above

= e[SGr1, . . . , SGrn] as shown above

= (S( ~F \Lambda ))[SGr1, . . . , SGrn] because S( ~F \Lambda ) = S2(S1( ~F \Lambda )) by induction hypothesis
= S( ~F G\Lambda ) by lemma 3.16

20

which is the desired conclusion.Induction case: Type contexts

' for this case have n + 1 occurrences of "!" and "^", and therefore areof the form ~
F ('1 ! '2) or ~F ('1 ^ '2) where each of '1 and '2 has at most n such occurrences. Consider

the case ~F ('1 ! '2) only, and omit the entirely similar case ~F ('1 ^ '2).

Let S1( ~F \Lambda ) = e1 and S2(S1( ~F \Lambda )) = e2, with paths(e2) = (r1, . . . , rn). By the base case of the induction,
S( ~F \Lambda ) = S2(S1( ~F \Lambda )) = e2. For a 2 {1, 2}, by lemma 3.17, we have:

S2(S1( ~F 'a)) = e2[S2hS1h'aiq1 ir01, . . . , S2hS1h'aiqn ir0n]
for appropriate q1, r01, . . . , qn, r0n 2 {0, 1}* that depend solely on the E-path ~F and the substitutions S1 and
S2. Defining 'a,j = S2hS1h'aiqj ir0j for every 1 <= j <= n, we can write S2(S1( ~F 'a)) = e2['a,1, . . . , 'a,n].Hence, we have the following sequence of equalities:

e2[Sh'air1, . . . , Sh'airn] = S( ~F 'a) by lemma 3.16

= S2(S1( ~F 'a)) by induction hypothesis
= e2['a,1, . . . , 'a,n] as shown above

This implies Sh'airj = 'a,j for a = 1, 2 and j = 1, . . . , n. By lemma 3.17, we have:

S2(S1( ~F ('1 ! '2))) = e2[S2hS1h'1 ! '2iq1ir01, . . . , S2hS1h'1 ! '2iqnir0n]

= e2[S2hS1h'1iq1 ir01 ! S2hS1h'2iq1 ir01 , . . . , S2hS1h'1iqn ir0n ! S2hS1h'2iqnir0n]

Finally, the preceding implies the following sequence of equalities:

S2(S1( ~F ('1 ! '2))) = e2['1,1 ! '2,1, . . . , '1,n ! '2,n] because S2hS1h'aiqj ir0j = 'a,j

= e2[Sh'1ir1 ! Sh'2ir1, . . . , Sh'1irn ! Sh'2irn] because 'a,j = Sh'airj

= (S( ~F \Lambda ))[Sh'1 ! '2ir1, . . . , Sh'1 ! '2irn] because e2 = S( ~F \Lambda )
= S( ~F ('1 ! '2)) by lemma 3.16

which is the desired conclusion.

3.3 Finite-Support Substitutions
When we deal with termination properties of our algorithms in section 5 and 8 we restrict attention tosubstitutions with finite support (definition 2.16). This is justified by the following lemma.

Lemma 3.19 (Finite-Support Substitutions Suffice). Let S be an arbitrary substitution and ' a typecontext. Then, from the given

S and ', we can construct a substitution S0 such that S0' = S' with Dom(S0)finite.

Proof. We first define the set Var(', `) of variables in ' at level `, by induction on ` >= 0:

Var(', 0) = { v 2 Var(') E-path(v, ') = " }

...

Var(', ` + 1) = { v 2 Var(') E-path(v, ') 2 Var(', 0) * * * Var(', `) }
Clearly Var(', `) is finite for every `. Moreover, there is a least m >= 0 such that:

Var(') = Var(', 0) [ Var(', 1) [ * * * [ Var(', m) and Var(', `) 6= ? for every ` <= m.
The desired substitution S0 is defined by:

S0(v) = 8?!?:

S(v) if v = _vp and _v 2 Var(', `)

for some 0 <= ` <= m with p 2 paths(S(E-path(_v, ')\Lambda )),{
[ ]} (v) otherwise.

21

It is clear that Dom(S0) is finite. Moreover, for every v 2 Var(') with E-path(v, ') = ~F , an easy induction
on the length ` >= 0 of ~F shows that:

S( ~F v\Lambda ) = S0( ~F v\Lambda ) if v 2 EVar,
S( ~F v) = S0( ~F v) if v 2 TVar.

This implies that for every type context '0 2 T2 such that '0['1, . . . , 'n] = ' for some '1, . . . , 'n 2 T2where

n = #2('0) >= 0, it is the case that S'0 = S0'0. This last assertion is established by a straightforwardinduction on the size of the "initial fragment"

'0 of ' (details of the induction omitted). A special case of
'0 is '0 = ' with '1 = * * * = 'n = \Lambda , which implies S' = S0'.

4 Lambda-Compatible Beta-Unification
The problem of fi-unification was introduced and shown undecidable by Kfoury in [Kfo99]. This section in-troduces

*-compatible fi-unification, a restriction of fi-unification, in order to develop a principality propertyand in preparation for a unification algorithm presented in section 5.

Definition 4.1 (Positive and Negative Types). We identify two proper subsets R and S of T, whichwe call the "positive types" and the "negative types", respectively. We first define R and S with polarities
inserted, as eR and eS, defined simultaneously with eR! and eS!, together with metavariables over these sets,as follows:

_ae 2 eR! ::= +ff | (oe ! _ae)
ae 2 eR ::= _ae | (+F _ae)

_oe 2 eS! ::= -ff | (+F _ae ! _oe)
oe 2 eS ::= _oe | (oe ^ oe0) | (-F oe)

We obtain R! and R from eR! and eR, respectively, by omitting all polarities. Similarly we obtain S! andS from eS! and eS. Let _

ae, ae, _oe, and oe also range over R!, R, S!, and S, respectively.Note that there is a restriction that exactly one E-variable occurs in each positive position to the left of

"!", and "^" occurs only in negative positions. Note also that the metavariables _ae and _oe are restricted tothe subsets R! and S!, respectively.

If ae 2 R (resp. oe 2 S), there is exactly one way of inserting polarities in ae (resp. oe) so that the resulting
type ae0 (resp. oe0) with polarities is in eR (resp. eS). Let (ae)+ 2 eR (resp. (oe)- 2 eS) be the uniquely definedexpression obtained by inserting polarities in

ae 2 R (resp. oe 2 S). We thus have two well-defined functions:

( )+ from R to eR and ( )- from S to eS.

Definition 4.2 (Well-Named Constraint Sets). A constraint is an equation of the form o/ .= o/ 0 where
o/, o/ 0 2 T. An instance \Delta  of fi-unification is a finite set of constraints, i.e.,

\Delta  = {o/1 .= o/ 01, o/2 .= o/ 02, . . . , o/n .= o/ 0n}
We write EVar(\Delta ) for the set EVar(o/1 ^ * * * ^ o/ 0n), TVar(\Delta ) for the set TVar(o/1 ^ * * * ^ o/ 0n) and Var(\Delta ) for theirdisjoint union

EVar(\Delta ) [ TVar(\Delta ).The above constraint set \Delta  is said to be well named iff the type

o/1 ^ o/ 01 ^ * * * ^ o/n ^ o/ 0n is well named.
Given an arbitrary sequence of E-variables ~F 2 EVar*, we write ~F \Delta  to denote the constraint set:

~F \Delta  = { ~F o/ .= ~F o/ 0 o/ .= o/ 0 is a constraint in \Delta  }.

We write ~F (o/ .= o/ 0) to stand for the constraint ~F o/ .= ~F o/ 0.

22

Definition 4.3 (Good Constraints). From now on, all generated constraints will be in one of 3 forms:

(a) ~F (_ae .= _oe) where Var(_ae) " Var(_oe) = ?.
(b) ~F (G_ae .= oe) where Var(G_ae) " Var(oe) = ?.
(c) ~F (e[_ae1, . . . , _aen] .= e[_oe1, . . . , _oen]) where e = e1 ^ e2 and

Var(_ae1 ^ * * * ^ _aen) " Var(_oe1 ^ * * * ^ _oen) = ?.

In form (c), we impose the restriction e = e1 ^ e2 in order to make (c) disjoint from (a). In this way, the 3forms are mutually exclusive.

We say a constraint is a good constraint if it is in one of the 3 forms above. Observe the polarities oftypes in good constraints: always positive to the left, always negative to the right, of the symbol " .=".
For precise statement of concepts and results later, it is convenient to consider an additional form, ofwhich (

a) and (b), but not (c), are special cases. This additional form is:

(d) ~F (ae .= oe) where there is no G 2 EVar such that ae = G_ae and oe = Goe0.
In form (d), there are constraints which are not good; this happens when Var(ae) " Var(oe) 6= ? and/or when
ae 2 R! and oe 2 S - S!.

Definition 4.4 (Outer and Inner Variable Occurrences). In a constraint in one of the forms specified
in definition 4.3, an E-variable H is said to have an outer occurrence if it occurs in ~F in form (a), in form
(b) and in form (d), or if it occurs in ~F e in form (c). An occurrence of H which is not outer is said to be aninner occurrence. In words, an "outer" occurrence appears on both sides of the constraint and at the top

level. Occurrences of T-variables are always inner; only occurrences of E-variables are differentiated betweenouter and inner.

Let \Delta  be a finite set of such constraints. We say H 2 EVar has an outer (resp. inner ) occurrence in \Delta  if
H has an outer (resp. inner) occurrence in a constraint in \Delta .The definition of "outer" and "inner" occurrences of E-variables carries over, in the obvious way, when

polarities are inserted in constraints. Thus, in each of the forms in definition 4.3:

(a) ~F ((_ae)+ .= (_oe)-).

(b) ~F (+G (_ae)+ .= (oe)-).
(c) ~F (e[(_ae1)+, . . . , (_aen)+] .= e[(_oe1)-, . . . , (_oen)-]).
(d) ~F ((ae)+ .= (oe)-).
No polarities are inserted in the outer ~F . Only inner occurrences are said to be positive or negative.

Applying simplify( ) to constraint sets:

* simplify(?) = ?.*

simplify({o/ .= o/0} [ \Delta ) = simplify(o/ .= o/0) [ simplify(\Delta ).

* simplify(o/ .= o/ 0) =

8??????!

??????:

F simplify(o/1 .= o/01) if o/ = F o/1 and o/0 = F o/ 01,
simplify(o/ 01 .= o/1) [ simplify(o/2 .= o/ 02) if o/ = o/1 ! o/2 and o/ 0 = o/01 ! o/ 02,
simplify(o/1 .= o/ 01) [ simplify(o/2 .= o/ 02) if o/ = o/1 ^ o/2 and o/ 0 = o/ 01 ^ o/02,
? if o/ = o/ 0,{

o/ .= o/0} otherwise.

Figure 4: The function simplify( ).
Lemma 4.5 (Simplification Preserves Good Constraints). Let \Delta  be a finite set of good constraints.

23

1. Applying the function simplify( ) defined in figure 4 to \Delta , we obtain a finite set simplify(\Delta ) of goodconstraints, each of which is in one of the following forms:

(a.1) ~F (ff .= _oe)
(a.2) ~F (_ae .= ff)
(b) ~F (G_ae .= oe)
Form (b) here is identical to form (b) in definition 4.3; forms (a.1) and (a.2) are special cases of form(

a) in definition 4.3.

2. The set of inner (resp. outer) variable occurrences in simplify(\Delta ) is a subset of the set of inner (resp.outer) variable occurrences in \Delta .

It is worth noticing that part 1 of this lemma implies that every constraint in the result of simplifying aset of good constraints matches one of the rewrite rules in algorithm

Unify given in figure 5.

Proof. Define the operation simplify1( ) on constraint sets by:

simplify1(?) = ?,
simplify1({o/ .= o/ 0} [ \Delta ) = simplify1(o/ .= o/ 0) [ simplify1(\Delta ),

simplify1(o/ .= o/ 0) =

8??????!

??????:

F simplify1(o/1 .= o/ 01) if o/ = F o/1 and o/ 0 = F o/ 01,{

o/ 01 .= o/1, o/2 .= o/ 02} if o/ = o/1 ! o/2 and o/ 0 = o/ 01 ! o/ 02,{
o/1 .= o/ 01, o/2 .= o/ 02} if o/ = o/1 ^ o/2 and o/ 0 = o/ 01 ^ o/ 02,
? if o/ = o/ 0 = ff,{

o/ .= o/ 0} otherwise.

In contrast to simplify( ), simplify1( ) takes apart the arguments of a topmost occurrence only of a typeconstructor, ! or ^, appearing symmetrically on both sides of the same constraint. This is why the side

condition in the 4th case above is o/ = o/ 0 = ff rather than o/ = o/ 0. With the side condition o/ = o/ 0 instead,
simplify1( ) would not be well-defined as a function; for example, it would make simplify1(o/1 ! o/2 .= o/1 ! o/2)equal to both {

o/1 .= o/1, o/2 .= o/2} and ?. This is not a problem with the definition of simplify( ).If \Delta  is a finite set of good constraints,

simplify(\Delta ) is obtained by applying simplify1( ) to \Delta  repeatedly.Because \Delta  is a finite set and each of its types has finite size, this process is bound to terminate, producing

a constraint set \Delta 0 such that simplify1(\Delta 0) = \Delta 0.Let \Delta  be a finite set of good constraints. Each constraint in \Delta  is in form (

a) or form (b) or form (c), asdescribed in definition 4.3. We further classify these 3 forms into 5 forms as follows:

(a.1) ~F (ff .= _oe) ,
(a.2) ~F (_ae .= ff) ,
(a.3) ~F (oe ! _ae .= G_ae0 ! _oe) ,
(b) ~F (G_ae .= oe) ,
(c) ~F (e[_ae1, . . . , _aen] .= e[_oe1, . . . , _oen]) , where e = e1 ^ e2.
Forms (a.1), (a.2), and (a.3) completely classifies form (a); forms (a.1) and (a.2) have the special case

~F (ff .= ff0) in common, where ff, ff0 2 TVar. The action of simplify1( ) in the 5 cases is:

(a.1) simplify1( ~F (ff .= _oe)) = { ~F (ff .= _oe)} ,
(a.2) simplify1( ~F (_ae .= ff)) = { ~F (_ae .= ff)} ,
(a.3) simplify1\Gamma  ~F (oe ! _ae .= G_ae0 ! _oe)\Delta  = { ~F (_ae .= _oe), ~F (G_ae0 .= oe)} ,
(b) simplify1\Gamma  ~F (G_ae .= oe)\Delta  = { ~F (G_ae .= oe)} ,
(c) simplify1\Gamma  ~F (e[_ae1, . . . , _aen] .= e[_oe1, . . . , _oen])\Delta  ={

~F (e1[_ae1, . . . , _aem] .= e1[_oe1, . . . , _oem]), ~F (e2[_aem+1, . . . , _aen] .= e2[_oem+1, . . . , _oen])} ,

24

where, in (c), we take e = e1 ^ e2 with 1 <= #2(e1) = m < n and #2(e2) = n -m >= 1. Thus, only forms (a.3)and (

c) are split by simplify1( ) into two other smaller constraints. Hence, the process of applying simplify1( )repeatedly stops when there are no constraints left that are in form (

a.3) or in form (c). Hence, in a goodconstraint set \Delta 0 such that
simplify1(\Delta 0) = \Delta 0, every constraint is in form (a.1) or form (a.2) or form (b).This proves part 1 of the lemma.

For part 2 of the lemma, it suffices to show that, given a finite set \Delta  of good constraints, the set ofinner (resp. outer) variable occurrences in

simplify1(\Delta ) is a subset of the set of inner (resp. outer) variableoccurrences in \Delta . This is a straightforward case analysis, by inspecting each of the forms (

a.1), (a.2), (a.3),(
b), and (c).

Definition 4.6 (Links and Graphs). Let v, w 2 Var. A link (from v to w) is the pair of v and w writtenin the form

v y w. Let \Delta  be a set of good constraints. The graph of \Delta  is a finite set of links.First consider a set \Delta  consisting of a single good constraint ~

F (_ae .= _oe) of form (a) as specified in defini-tion 4.3. In general, _
ae and _oe are of the following forms:

_ae = oe1 ! * * * ! oem ! ff and _oe = ae1 ! * * * ! aen ! fi
for some oe1, . . . , oem 2 S and ae1, . . . , aen 2 R - R!, with m, n >= 0, and some ff, fi 2 TVar. We define:

graph(\Delta ) = 8?!?:{

ff y fi} if m = n,{

ff y w w 2 Var(aem+1 ! * * * ! aen ! fi) and E-path(w, \Delta ) = ~F } if m < n,{
v y fi v 2 Var(oen+1 ! * * * ! oem ! ff) and E-path(v, \Delta ) = ~F } if m > n.

For an arbitrary set \Delta  of good constraints, we define the graph of \Delta  as:

graph(\Delta ) = [{ graph( ~F {_ae .= _oe}) ~F {_ae .= _oe} ` \Delta  }.
If there are no good constraints in \Delta  of form (a), then graph(\Delta ) = ?. (Strictly speaking, if we take Var(\Delta )as the set of nodes in the graph of \Delta , then

graph(\Delta ) = ? means that all the nodes in the graph of \Delta  areisolated, not that there are no nodes in the graph.)

It is important to note that if v y w is a link in graph(\Delta ), then E-path(v, \Delta ) = E-path(w, \Delta ): There are
no links between variables that have different E-paths. For every ~F 2 EVar*, we define graph(\Delta )/ ~F as:

graph(\Delta )/ ~F = { v y w E-path(v, \Delta ) = E-path(w, \Delta ) = ~F and v y\Delta  w } ,
where we write v y\Delta  w as a shorthand for "v y w is a link in graph(\Delta )".
Example 4.7 (y-Chains). Consider the following set \Delta  of good constraints, all of form (a) in definition 4.3:

\Delta  = {ff1 .= F1 _ae1 ! fi1, F1oe1 ! fi1 .= ff2, ff2 .= F2 _ae2 ! fi2, F2oe2 ! fi2 .= ff3},
for some _ae1, _ae2 2 R! and oe1, oe2 2 S. Suppose all the variables in {ff1, ff2, ff3, fi1, fi2, F1, F2} are pairwisedistinct. There are exactly 8 links in

graph(\Delta ), namely (separated by blank space for clarity):

ff1 y F1 ff1 y fi1 F1 y ff2 fi1 y ff2 ff2 y F2 ff2 y fi2 F2 y ff3 fi2 y ff3
A graphic representation of graph(\Delta ) is:

ff1

F1 F2

ff2 ff3
fi1 fi2
For the \Delta  under consideration, graph(\Delta ) is acyclic. Changing, say, ff3 to ff1 introduces cycles, which violatescondition (D) for

*-compatibility below. An instance of a y-chain in graph(\Delta ) (read as "link-chain" or as"chain in
graph(\Delta )", trying to avoid the overloaded word "path" in this paper) is:

ff1 y F1 y ff2 y fi2 y ff3
This is one of 4 possible y-chains in graph(\Delta ) of maximal length. When graph(\Delta ) is acyclic, all the variablesappearing along a y-chain are guaranteed to be pairwise distinct.

25

Definition 4.8 (*-Compatibility). A constraint set \Delta  is *-compatible iff \Delta  is finite of the form:

\Delta  = { ~F1(ae1 .= oe1), . . . , ~Fn(aen .= oen)}
where ~Fi(aei .= oei) is a good constraint of form (a) or form (b) as specified in definition 4.3, for every 1 <= i <= n,and moreover \Delta  satisfies all of the following conditions:

(A) \Delta  is well named.

(B) Every expansion variable F 2 EVar has at most one inner positive occurrence in \Delta , i.e., +F occurs atmost once in +-\Delta , where +-\Delta  is obtained by inserting polarities in \Delta :

+-\Delta  = { ~F1((ae1)+ .= (oe1)-), . . . , ~Fn((aen)+ .= (oen)-)}
(C) Every type variable ff 2 TVar occurs at most twice in \Delta . And if it occurs twice, it occurs once positivelyas +

ff and once negatively as -ff in the constraint set +-\Delta .

(D) graph(\Delta ) is acyclic.
We use the name "*-compatible" because, as shown in lemma 6.2, every constraint set induced by a *-termsatisfies the conditions above.

Remark 4.9. Condition (D) in definition 4.8 is the least transparent and plays a role in the proof oflemma 5.7 only: It imposes a technical restriction on a constraint set \Delta , whose sole purpose is to guarantee
"Var(ae) " Var(oe) = ? for every ~F (ae .= oe) 2 \Delta " is an invariant of algorithm Unify developed in section 5. The
requirement that Var(ae) " Var(oe) = ? for every ~F (ae .= oe) 2 \Delta  is not strong enough by itself to be preservedby every rewrite step of the algorithm.

Example 4.10 (Why Condition (D) Is Included). Consider the following set \Delta  of constraints:

\Delta  = {ff .= F fi ! _oe, F fi ! _ae .= ff},
where _oe 2 S! and _ae 2 R!, with Var(_ae) " Var(_oe) = ? and Var(_ae ^ _oe) " {ff, fi, F } = ?. Then \Delta  is a set ofgood constraints, all of form (

a) as specified in definition 4.3. We can choose _oe and _ae so that conditions (A),(B) and (C) in definition 4.8 are satisfied. However, it is easy to see that no choice of _

oe and _ae will satisfy(D), because
graph(\Delta ) always includes the y-chain ff y F y ff which is a cycle.Algorithm

Unify in section 5 will substitute the type F fi ! _oe for ff in the second constraint, or the type
F fi ! _ae for ff in the first constraint, producing the same constraint set \Delta 0 in both cases, namely:

\Delta 0 = {F fi ! _ae .= F fi ! _oe},
which still satisfies (A), (B) and (C), but not (D) again, as F y F is a cycle (a self-loop in this case). Theresulting constraint in \Delta 0 is not good.

Lemma 4.11 (Simplification Preserves *-Compatibility). If \Delta  is a *-compatible constraint set, thenso is

simplify(\Delta ).

Proof. Because \Delta 0 = \Delta  is *-compatible, every constraint in \Delta 0 is a good constraint of form (a) or form(

b). By lemma 4.5, all the constraints in simplify(\Delta 0) are good constraints of form (a.1) or (a.2) or (b). Wenext show that

simplify(\Delta 0) satisfies conditions (A), (B), (C) and (D), in definition 4.8. It suffices to showthat
simplify1(\Delta 0) satisfies (A), (B), (C) and (D), where simplify1( ) is the function defined in the proof oflemma 4.5.

Following the case analysis in the proof of lemma 4.5, every constraint in \Delta 0 is a good constraint ofform (

a.1), or form (a.2), or form (a.3), or form (b), but not of form (c), because \Delta 0 is a *-compatible(and not only good) constraint set.

3 If \Delta 0 satisfies conditions (A), (B) and (C), then it is immediate that

simplify1(\Delta 0) also satisfies (A), (B) and (C).

3Starting from a *-compatible constraint set \Delta , which does not include good constraints of form (c), algorithm Unify
developed in section 5 applied to \Delta  may generate good constraints of form (c), in addition to form (a) and form (b).

26

It remains to check that simplify1(\Delta 0) satisfies (D). Assume that simplify1(\Delta 0) 6= \Delta 0, otherwise there isnothing to prove. There is exactly one constraint in \Delta 

0, namely, a good constraint of form (a.3), which issplit into two constraints, in order to produce
simplify1(\Delta 0). Suppose simplify1(\Delta 0) = \Delta 1 and:

\Delta 0 = \Delta  [ { ~F (oe ! _ae .= G_ae0 ! _oe)} and \Delta 1 = \Delta  [ { ~F (_ae .= _oe), ~F (G_ae0 .= oe)} ,
for some set \Delta  of good constraints. We need to check that graph(\Delta 1) is acyclic. But this is an immediateconsequence of two facts:

graph(\Delta 1) = graph(\Delta 0) and, by hypothesis, graph(\Delta 0) is acyclic.

Definition 4.12 (Solutions). Let S : Var ! (E[T!) be a substitution and let \Delta  = {o/1 .= o/ 01, . . . , o/n .= o/ 0n}be a

*-compatible constraint set. We say S is a solution for \Delta  iff So/i = So/ 0i for every i 2 {1, . . . , n}.

Definition 4.13 (Principal Solutions). Let S : Var ! (E [ T!) be a substitution and let \Delta  be a *-compatible constraint set. The substitution S is a principal solution for \Delta  iff S is a solution for \Delta  and for

every solution S0 for \Delta , there is a substitution S00 such that S0\Delta  = S00(S\Delta ).4 The principality property isthe existence of a principal solution for every constraint set that has a solution.

5 Algorithm for Lambda-Compatible Beta-Unification
We design a non-deterministic algorithm Unify which takes a *-compatible constraint set \Delta  as input, suchthat if \Delta  has a solution then every evaluation of

Unify(\Delta ) terminates returning a principal solution for \Delta ,and if \Delta  has no solution then every evaluation of

Unify(\Delta ) diverges.

Metavariable conventions:

* _ae 2 R!, ae 2 R, _oe, _oei 2 S!, oe 2 S, o/, o/ 0 2 T, e 2 E, ff 2 TVar, F 2 EVar.
Mode of operation:

* Initial call: Unify(\Delta ) ) Unify(simplify(\Delta ), {[ ]}, E-env(\Delta )).*

Final call: Unify(?, S, E) ) S.*
Unify(\Delta 0, S0, E) ) Unify(\Delta 1, S1, E), provided:

- \Delta 0 = \Delta  [ ~F {ae .= oe} and ae .= oe ) S is an instance of one of the rewrite rules.
- \Delta 1 = simplify(S\Delta 0) and S1 = S \Omega E S0 .

Rewrite rules:

ff .= _oe ) {[ff := _oe]} (rule 1)

_ae .= ff ) {[ff := _ae]} (rule 2)
F _ae .= e[_oe1, . . . , _oen] ) {[F := e]} (rule 3)

Applying substitutions to constraint sets:

* S? = ?.*

S({o/ .= o/0} [ \Delta ) = {So/ .= So/0} [ S\Delta .

Figure 5: Algorithm Unify (the function simplify( ) is defined in figure 4).

Definition 5.1 (Unification Algorithm). The operation of Unify is based on the rewrite rules shown infigure 5. The presentation of

Unify in figure 5 is self-contained -- except for two parts in the "mode ofoperation", namely, the definition of

E-env(\Delta ) and the evaluation of S1 = S \Omega E S0. If \Delta  is the well-named
4We purposely write S0\Delta  = S00(S\Delta ) instead of S0 = S00 ffi S in order to avoid pitfalls associated with the composition of
substitutions in fi-unification. These are carefully examined in section 3.

27

constraint set {o/1 .= o/ 01, . . . , o/n .= o/ 0n}, then the E-path environment of \Delta  is the E-path environment of thetype

o/1 ^ o/ 01 ^ * * * ^ o/n ^ o/ 0n (see definition 3.11), i.e.,

E-env(\Delta ) = E-env(o/1 ^ o/ 01 ^ * * * ^ o/n ^ o/ 0n) .
If E is an E-path environment, the evaluation of S1 = S \Omega E S0 is given in definition 3.13.
Remark 5.2. A rewrite step induced by rule 1 or rule 2 in figure 5 produces, from a given *-compatible\Delta 

0, another *-compatible constraint set simplify(S\Delta 0). In fact, ignoring trivial constraints of the form o/ .= o/(same type

o/ on both sides) and before applying simplify( ) to it, S\Delta 0 is already *-compatible. Theseassertions follow from lemmas 4.11 and 5.7 and their proofs.

By contrast, a rewrite step induced by rule 3 in figure 5 produces a constraint set simplify(S\Delta 0) whichis
*-compatible provided \Delta 0 is, according to lemma 5.7, whereas S\Delta 0 is not in general. That S\Delta 0 isnot necessarily

*-compatible in this case results from the (non-interesting) fact that a constraint of theform {
e[_ae1, . . . , _aen] .= e[_oe1, . . . , _oen]} where n >= 2, which is good of form (c) in definition 4.3, cannot be
*-compatible yet; it must be first broken up into

{ ~F1(_ae1 .= _oe1), . . . , ~Fn(_aen .= _oen)}
using simplify( ), where ~Fi = E-path(\Lambda (i), e) for 1 <= i <= n.

We next prove several lemmas, culminating in the main result of this section (theorem 5.16). On the way,there are 4 key intermediary results:

Unify preserves *-compatibility (lemma 5.7); Unify preserves solvability(lemma 5.11); if there is a solution,
Unify constructs a principal one (lemma 5.12); and if there is a solution,
Unify terminates (lemma 5.15). The remaining lemmas and definitions provide the necessary supportingmaterial.

The next two lemmas, 5.3 and 5.5, are used in the proof of the first key result in lemma 5.7: *-compatibilityis an invariant of algorithm

Unify.

Lemma 5.3 (A Property of Positive and Negative Types). Let R = {ae1, . . . , aem} ae R - R! and let
S = {_oe1, . . . , _oen} ae S!, with m >= 1 and n >= 1. Define the type:

oe = (ae1 ! * * * ! aem ! fi) ^ _oe1 ^ * * * ^ _oen ,
where fi is a fresh T-variable.5 Suppose oe satisfies:

1. oe is well-named.
2. Every F 2 EVar(oe) has at most one positive occurrence in oe.
3. Every ff 2 TVar(oe) has at most one negative occurrence in oe.
Then, for every o/, o/ 0 2 R [ S such that o/ 6= o/ 0, it holds that Var(o/ ) " Var(o/ 0) = ?.

Observe the two first conditions above correspond to (A) and (B) in definition 4.8, while the thirdcondition is a weaker version of (C) in definition 4.8.

Proof. This is a straightforward proof. The details can be found in the technical report [KW02].
Example 5.4 (Links With Polarities). Consider the constraint set \Delta  in example 4.7, now with polari-ties inserted:

+- \Delta  = { +ff1 .= +F1(_ae1)+ -! -fi1 , -F1(oe1)- -! +fi1 .= -ff2 ,

+ff2 .= +F2(_ae2)+ -! -fi2 , -F2(oe2)- -! +fi2 .= -ff3 }.

With polarities inserted, the 8 links of graph(+-\Delta ) are:

+ff1 y +F1 +ff1 y -fi1 -F1 y -ff2 +fi1 y -ff2
+ff2 y +F2 +ff2 y -fi2 -F2 y -ff3 +fi2 y -ff3
5By definition 4.1, the type oe thus defined is indeed a negative type, allowing us to use the letter "oe" to denote it.

28

There is a pattern here, which is proved in general in the next lemma: To the right of "y" it is always eithera positive occurrence of an E-variable or a negative occurrence of a T-variable.

It is possible to specify rules to connect together links with polarities, in order to produce y-chains withpolarities. But this is a little awkward and there is no real need for it.

Lemma 5.5 (A Property of Links). Let \Delta  be a *-compatible constraint set, and +-\Delta  the correspondingset with polarities inserted. Then:

1. Every link in graph(+-\Delta ) is in one of 2 possible forms:

* either "p v y +G" where v 2 Var(\Delta ) with p 2 {+, -} and G 2 EVar(\Delta ),*

or "p v y -fi" where v 2 Var(\Delta ) with p 2 {+, -} and fi 2 TVar(\Delta ).

In words, the right end-point of a link with polarities is either a positive occurrence of an E-variableor a negative occurrence of a T-variable.

2. For every w 2 Var(\Delta ) there is at most one good constraint ~F (_ae .= _oe) of form (a) in \Delta  such that

{ v y w v y\Delta  w } = { v y w v y ~F {_ae .=_oe} w },
i.e., all the links into w are contributed by at most one good constraint of form (a) in \Delta .
Proof. Links are induced by good constraints of form (a) as specified in definition 4.3. Consider such a
constraint ~F (_ae .= _oe). In general, _ae and _oe are of the following forms:

_ae = oe1 ! * * * ! oem ! ff and _oe = G1 _ae1 ! * * * ! Gn _aen ! fi
where oe1, . . . , oem 2 S and _ae1, . . . , _aen 2 R!, with m, n >= 0, and ff, fi 2 TVar and G1, . . . , Gn 2 EVar.Inserting polarities, we obtain:

(_ae)+ = (oe1)- -! * * * -! (oem)- -! +ff and
(_oe)- = +G1(_ae1)+ -! * * * -! +Gn(aen)+ -! -fi.

Following definition 4.6, the conclusion of part 1 of the lemma is now immediate.Part 2 follows from the fact that, in a

*-compatible constraint set \Delta , every G 2 EVar(\Delta ) has at mostone inner positive occurrence, and every
fi 2 TVar(\Delta ) has at most one inner negative occurrence.

Remark 5.6. The dual statement of part 2 in lemma 5.5, namely, for every v 2 Var(\Delta ) all the links out from
v are contributed by at most one good constraint of form (a) in \Delta , is generally false. For a counter-example,consider the constraint set:

\Delta  = { F oe ! ff .= ff0 , F oe0 ! ff0 .= ff00 }
for some appropriate oe, oe0 2 S that make \Delta  *-compatible. The links F y\Delta  ff0 and F y\Delta  ff00, both out from
F , are contributed by two different constraints in \Delta .

Lemma 5.7 (`Unify' Preserves *-Compatibility). Let \Delta 0 and \Delta 1 be constraint sets such that

Unify(\Delta 0, S0, E) ==) Unify(\Delta 1, S1, E)
for some S0, S1 and E (which do not matter here). If \Delta 0 is *-compatible such that simplify(\Delta 0) = \Delta 0, then\Delta 

1 is *-compatible. In words, the properties listed in definition 4.8 are invariant relative to the rewrite rulesof

Unify.

Proof. \Delta 1 is obtained from \Delta 0 according to one of the 3 rules in figure 5. We consider each of the 3 rulesseparately. In each of the 3 cases, a formal proof requires an induction on types, which we avoid because it

is a routine uninteresting induction that obscures the underlying argument.rule 1: The constraint under consideration is ~

F (ff .= _oe). There are two subcases, depending on whether
ff occurs exactly twice or exactly once in \Delta 0. We omit the latter subcase, which is trivial, and assume that

29

ff occurs exactly twice. Thus, given that ff has a single positive occurrence in ~F (ff .= _oe), we assume that
ff has a single negative occurrence in \Delta 0. Let ~G(ae .= oe) be the only constraint other than ~F (ff .= _oe) in \Delta 0that mentions

ff. We thus have:

\Delta 0 = \Delta  [ ~F {ff .= _oe} [ ~G{ae .= oe},
\Delta 1 = simplify(\Delta  [ {[ff := _oe]} { ~G(ae .= oe)})

= simplify(\Delta ) [ simplify({[ff := _oe]} { ~G(ae .= oe)})
= \Delta  [ simplify({[ff := _oe]} { ~G(ae .= oe)}),

where \Delta  is the subset of all constraints of \Delta 0 that do not mention ff. Let ^\Delta 1 = \Delta  [ {[ff := _oe]} { ~G(ae .= oe)},so that \Delta 

1 = simplify( ^\Delta 1). By lemma 4.11, it suffices to show that ^\Delta 1 is *-compatible. This means wehave to show that all the constraints in ^\Delta 

1 are good of form (a) or (b) and that ^\Delta 1 satisfies conditions (A),(B), (C) and (D) in definition 4.8. It is convenient to organize the proof by first showing (1) and (2) below,

simultaneously with the fact that ^\Delta 1 satisfies (D):

(1) If ff 2 TVar(ae), then Var(_oe) " Var(oe) = ?.
(2) If ff 2 TVar(oe), then Var(_oe) " Var(ae) = ?.
Because \Delta 0 satisfies condition (A) in definition 4.8, it must be that ~G is a prefix of ~F . There are two cases,
depending on whether ~G is a proper prefix of ~F or not.Case 1: ~

G is a proper prefix of ~F , i.e., ~F = ~G ~H for some ~H 6= ". If ff 2 TVar(ae), then every E-variable
in ~H has an inner occurrence in ae (because \Delta 0 is well-named), which implies every E-variable in ~H has noinner occurrence in

oe (because Var(ae) " Var(oe) = ?), which implies Var(_oe) " Var(oe) = ?, thus proving (1)above. By a totally similar argument, if

ff 2 TVar(oe) then Var(_oe) " Var(ae) = ?, thus proving (2).We next relate
graph( ^\Delta 1) and graph(\Delta 0). The set of nodes of graph( ^\Delta 1) is Var(\Delta 0) - {ff}, and the setof its links is:

graph( ^\Delta 1) = { v y w v y\Delta 0 w and v 6= ff },
i.e., graph( ^\Delta 1) is a proper subset of graph(\Delta 0). Because graph(\Delta 0) is acyclic, so is graph( ^\Delta 1), thus provingthat ^\Delta 

1 satisfies (D).Case 2: ~

F = ~G. Then ~F {ff .= _oe, ae .= oe} ` \Delta 0. In general, _oe is of the form:

_oe = ae1 ! * * * ! aen ! fi
for some ae1, . . . , aen 2 R - R! and fi 2 TVar with n >= 0. We have ff y v for every v 2 Var(_oe) such that
E-path(v, \Delta 0) = ~F , according to definition 4.6. Because simplify(\Delta 0) = \Delta 0, every constraint in \Delta 0 is a goodconstraint of form (

a.1) or (a.2) or (b), by lemma 4.5. There are three subcases, depending on whether
~F (ae .= oe) is of one of these 3 forms.

Subcase 2.1: ~F (ae .= oe) is of form (a.1), i.e., ae = ff0 2 TVar and oe 2 S!. Because \Delta 0 satisfies (C), it mustbe that

ff 6= ff0, thus proving (1) vacuously, i.e., it cannot be that ff 2 TVar(ae). By definition 4.6, we have
ff0 y v0 for every v0 2 Var(oe) such that E-path(v0, \Delta 0) = ~F . If ff 2 TVar(oe), we have ff0 y ff and, as noted in
the preceding paragraph, ff y v for every v 2 Var(_oe) such that E-path(v, \Delta 0) = ~F . Because \Delta 0 satisfies (D),it must be that

ff0 6= v for every v 2 TVar(_oe), thus proving (2).We relate
graph( ^\Delta 1) and graph(\Delta 0) in this subcase as follows. The set of nodes of graph( ^\Delta 1) are all thevariables in
Var(\Delta 0) - {ff}, and the set of its links is:

graph( ^\Delta 1) = { v y w v y\Delta 0 w and v 6= ff } [ { ff0 y w ff y\Delta 0 w } .
In the second part of this union, we replace a link ff y w in graph(\Delta 0) by the link ff0 y w, for every w 2 Var(_oe)
with E-path(w, \Delta 0) = ~F . Because graph(\Delta 0) is acyclic and ff0 y\Delta 0 ff, it now follows that graph( ^\Delta 1) is acyclic,thus proving that ^\Delta 

1 satisfies (D).Subcase 2.2: ~
F (ae .= oe) is of form (a.2), i.e., oe = ff0 2 TVar and ae 2 R!. Because \Delta 0 satisfies (C), itmust be that
ff0 6= fi (no two negative occurrences of the same T-variable). Because \Delta 0 satisfies (A) and is

30

therefore well-named, it must be that ff0 62 TVar(aei) for every 1 <= i <= n. Hence, ff0 62 TVar(_oe) which is thesame as

Var(oe) " Var(_oe) = ?, thus proving (1). If ff 2 TVar(oe), then necessarily ff = ff0. Hence v0 y ff0 = ff
for every v0 2 Var(ae) such that E-path(v0, \Delta 0) = ~F , by definition 4.6. Because \Delta 0 satisfies (D), together with
the fact that ff y v for every v 2 Var(_oe) such that E-path(v, \Delta 0) = ~F , we have Var(ae) " Var(_oe) = ?, thusproving (2).

We relate graph( ^\Delta 1) and graph(\Delta 0) in this subcase as follows. The set of nodes of graph( ^\Delta 1) are all thevariables in

Var(\Delta 0) - {ff}. If ff 2 TVar(ae) and ff0 6= ff, then

graph( ^\Delta 1) = { v y w v y\Delta 0 w and v 6= ff } [ { w y ff0 ff y\Delta 0 w } .
In the second part of this union, we replace a link ff y w in graph(\Delta 0) by the link w y ff0, for every w 2 Var(_oe)
with E-path(w, \Delta 0) = ~F . By part 2 of lemma 5.5, there are no links of the form v y w where v 6= ff and
w 2 Var(_oe), i.e., deleting the node ff in graph(\Delta 0) turns every such w into an isolated node or a "source" nodein this case. Hence, although the direction of the link

ff y w is reversed to w y ff0, no cycle is introduced asa result. Together with the acyclicity of
graph(\Delta 0), this implies that graph( ^\Delta 1) is acyclic, thus proving that^\Delta 

1 satisfies (D). If ff 62 TVar(ae) and ff0 = ff, then

graph( ^\Delta 1) = { v y w v y\Delta 0 w with v 6= ff and w 6= ff } [ { v y w v y\Delta 0 ff and ff y\Delta 0 w } .
This immediately implies that, if graph(\Delta 0) is acyclic, then so is graph( ^\Delta 1), thus proving that ^\Delta 1 satisfies(D) again.

Subcase 2.3: ~F (ae .= oe) is of form (b), i.e., ae = H _ae0 for some H 2 EVar and _ae0 2 R!, and oe = e[_oe1, . . . , _oen]for some

e 2 E and _oe1, . . . , _oen 2 S! with n = #2(e). Because \Delta 0 is well-named, it must be ff 62 TVar(ae)and, therefore,

ff 2 TVar(oe). By lemma 5.3, it must be Var(ae) " Var(_oe) = ?, thus proving both (1) and (2).We relate
graph( ^\Delta 1) and graph(\Delta 0) as follows. The set of nodes of graph( ^\Delta 1) is Var(\Delta 0) - {ff}, and theset of its links is:

graph( ^\Delta 1) = { v y w v y\Delta 0 w and v 6= ff }.
In words, to obtain graph( ^\Delta 1), we eliminate all links in graph(\Delta 0) of the form ff y w. Because graph(\Delta 0) isacyclic, so is

graph( ^\Delta 1), thus proving that ^\Delta 1 satisfies (D).

We have thus completed the proof that (1) and (2) are true, and that ^\Delta 1 satisfies condition (D), in allcases and subcases.

6

Using the fact that ff occurs either in ae or in oe, we conclude that Var({[ff := _oe]} ae) " Var({[ff := _oe]} oe) = ?,
from (1.1) and (1.2). This in turn implies {[ff := _oe]} { ~G(ae .= oe)} is a good constraint of form (a) or (b),
depending on whether ~G(ae .= oe) is good of form (a) or (b), respectively. It follows that every constraint in^\Delta 

1 is a good constraint of form (a) or (b).We next proceed to show that ^\Delta 

1 satisfies conditions (A), (B), and (C) in definition 4.8. Because
E-path(ff, \Delta 0) = E-path(ff, ^\Delta 1), it is readily checked that if \Delta 0 satisfies conditions (A) and (C), then so does^\Delta 

1. What makes things work as expected is that we substitute a negative type _oe for a negative occurrenceof

ff. If \Delta 0 satisfies condition (B), then so does ^\Delta 1 trivially.rule 2: This is symmetric to rule 1, i.e., the difference between rule 1 and rule 2 are the reversed polarities, and is therefore omitted. (In fact, the proof for rule 2 is somewhat easier, because we can here merge the
counterparts of subcase 2.1 and subcase 2.2 into a single subcase, which occurs when ~F {_ae .= ff, ae .= oe} ` \Delta 0and (

ae .= oe) is of form (a), with no need to deal with forms (a.1) and (a.2) separately. This is because the positive occurrence of ff here always occurs in ae, never in oe; by contrast, for rule 1, when ~F {ff .= _oe, ae .= oe} ` \Delta 0,the negative occurrence of

ff may occur in ae just as in oe. As a result also, in the proof for rule 2, we do notneed to invoke lemma 5.5.)

6In only two places so far, do we need to invoke condition (D), i.e., that graph(\Delta 0) is acyclic, in order to prove (1) and (2),
which are next used to show good constraints are preserved by the rewrite rules; these two places are subcase 2.1 and subcase
2.2. There is one more place, in the part of the proof for rule 2 below corresponding to subcase 2.1 and subcase 2.2, where we
need to invoke (D) again. Nowhere else, in the present proof or elsewhere in this paper, do we need to invoke condition (D)
in an induction to prove a property other than itself. But, of course, we also have to show that (D) itself is initially satisfied,
which is shown in the proof of lemma 6.2, and preserved by all the rewrite rules, which is shown in the present proof.

31

rule 3: Let \Delta 0 = \Delta  [ ~G{F _ae .= e[_oe1, . . . , _oen]}, where the constraint F _ae .= e[_oe1, . . . , _oen] induces a rewritestep according to

rule 3. \Delta 0 is transformed to \Delta 1 = simplify( ^\Delta 1) where

^\Delta 1 = {[F := e]}\Delta  [ ~G{e[h_aeis1, . . . , h_aeisn ] .= e[_oe1, . . . , _oen]}

where si = path(\Lambda (i), e) for every 1 <= i <= n. Note that ^\Delta 1 is not necessarily in the form required bydefinition 4.8, because ^\Delta 

1 may contain good constraints of form (c) as specified in definition 4.3. However,by lemma 4.5, \Delta 
1 = simplify( ^\Delta 1) is in the required form for *-compatibility, i.e., it consists of good constraintsall of form (
a) or form (b).Consider a T-variable or E-variable

v 2 Var(\Delta 0) such that F occurs in E-path(v, \Delta 0). Because \Delta 0 is

well-named, it must be that E-path(v, \Delta 0) = ~GF ~H for some ~H 2 EVar*. Because every constraint in \Delta 0 is
good, it must be that F 62 EVar(e)). It follows that EVar( ~H) " EVar(e) = ?. Hence, substituting e for Fproduces a well-named ^\Delta 

1. Hence, \Delta 1 is also well-named and, thus, satisfies condition (A) in definition 4.8.Because \Delta 
0 satisfies condition (B) and (C) in definition 4.8, then so does ^\Delta 1 trivially, again using thefact that \Delta 
0 is well-named (use, in particular, condition 2 in definition 3.9). Thus, \Delta 1 satisfies conditions(B) and (C) in definition 4.8.

It remains to show that \Delta 1 satisfies condition (D). For every 1 <= i <= n, let E-path(\Lambda (i), e) = ~Hi for some
~Hi 2 EVar*. The following equality follows from the pertinent definitions:

graph(\Delta 1) = { v y w v y\Delta 0 w with F 62 E-path(v, \Delta 0) = E-path(w, \Delta 0) } [{

vs y ws v y\Delta 0 w with F 2 E-path(v, \Delta 0) = E-path(w, \Delta 0) and s 2 {s1, . . . , sn} } [\Gamma [

{ graph( ~G ~Hi{h_aeisi .= _oei}) 1 <= i <= n }\Delta .

We have to show that graph(\Delta 1) is acyclic. Given a y-chain C = v1 y v2 y * * * y vm in graph(\Delta ) for some
*-compatible constraint set \Delta , it is meaningful to write E-path(C, \Delta ) because all the entries in C have thesame E-path in \Delta . Given an offset

s 2 {0, 1}*, we write Cs to denote vs1 y vs2 y * * * y vsm, which may ormay not be a valid y-chain in
graph(\Delta ).

Consider an arbitrary y-chain C in graph(\Delta 1). If E-path(C, \Delta 1) = ~L 62 { ~G ~H1, . . . , ~G ~Hn}, then C is
acyclic, because either C is already a y-chain in graph(\Delta 0) with E-path(C, \Delta 0) = ~L, or C = Cs0 for somey

-chain C0 in graph(\Delta 0) and s 2 {0, 1}*. In the latter situation, we have ~L = ~G ~Hih ~Kis with ~K 6= " and
s = si for some i 2 {1, . . . , n}, and E-path(C0, \Delta 0) = ~GF ~K which is mapped to E-path(C, \Delta 1) = ~G ~Hih ~Kisafter applying the substitution {[

F := e]}.

The non-trivial case occurs when C = w1 y\Delta 1 w2 y\Delta 1 * * * y\Delta 1 wm such that E-path(C, \Delta 1) = ~G ~Hifor some 1 <=

i <= n. There are two cases, n = 1 and n >= 2. Consider the case n = 1 first. In thiscase,
e = ~H\Lambda  for some ~H 2 EVar*. By definition 4.6, X = graph(\Delta 0)/ ~GF and Y = graph(\Delta 0)/ ~G ~H are
disconnected components of graph(\Delta 0), i.e., for every v, w 2 Var(\Delta 0) such that E-path(v, \Delta 0) = ~GF and
E-path(v, \Delta 0) = ~G ~H, we have v 6y w and w 6y v. In the case n = 1, after substituting ~H for F , the new
constraint ~G ~H(_ae .= _oe) introduces links of the form v y w, all directed from component X to Y . Hence, Xand

Y are now part of the same component in graph(\Delta 1), but still acyclic; as all the other components of
graph(\Delta 1) are components of graph(\Delta 0) and therefore acyclic, graph(\Delta 1) is acyclic.Consider the case

n >= 2 next. New links of the form vsi y\Delta 1 w are introduced by every new constraint
~G ~Hi(h_aeisi .= _oei) where si 6= ", and v 2 Var(_ae) and w 2 Var(_oe). In general, there is a fixed i 2 {1, . . . , n}

such that:

C = w1 y\Delta 1 * * * y\Delta 1 wk y\Delta 1 wk+1 y\Delta 1 * * * y\Delta 1 wk+` where

- 0 <= k <= m, 0 <= ` <= m and k + ` = m,
- w1 = vs1, . . . , wk = vsk for some v1, . . . , vk 2 Var(\Delta 0), with s = si 6= ",
- wk+1, . . . , wk+` 2 Var(\Delta 0) " Var(\Delta 1).

If ` = 0, i.e., C = vs1 y\Delta 1 * * * y\Delta 1 vsk, then by stripping the offset s we obtain a y-chain C0 in graph(\Delta 0),namely,

C0 = v1 y\Delta 0 * * * y\Delta 0 vk. Because C0 is acyclic, so is C acyclic.If
k = 0, i.e., C = wk+1 y\Delta 1 * * * y\Delta 1 wk+`, then C is already a y-chain in graph(\Delta 0). Because graph(\Delta 0)is acyclic,

C is also acyclic.

32

Suppose now k 6= 0 6= `. Neither of the two y-chains, vs1 y\Delta 1 * * * y\Delta 1 vsk and wk+1 y\Delta 1 * * * y\Delta 1 wk+`,contains a cycle, for the same reasons given in the case

` = 0 and k = 0, respectively. The two y-chains areconnected by the link
vsk y\Delta 1 wk+1 introduced by the constraint ~G ~Hi(h_aeis .= _oei). Because \Delta 0 is well-named,condition 1 in definition 3.9 implies {

v1, . . . , vk} " {w1, . . . , wk+`} = ?, and condition 2 in definition 3.9implies {
vs1, . . . , vsk} " {w1, . . . , wk+`} = ?. Hence, C is acyclic.

Lemma 5.8 (Progress). Let \Delta 0 be a *-compatible constraint set such that simplify(\Delta 0) = \Delta 0. If \Delta 0 isnot empty, then for every

S and E

1. Unify(\Delta 0, S, E) ) Unify(\Delta 1, ~S \Omega E S, E) ,
for some \Delta 1 and ~S (which do not matter here). Moreover, whenever part 1 holds for some \Delta 1 and ~S, it alsoholds that:

2. If SE ' E-env(\Delta 0) then (~S \Omega E S)E ' E-env(\Delta 1) .
In words, part 1 says that \Delta 0 always contains a constraint that can be processed by one of the rewrite rulesof

Unify. Part 2 is another invariant property of Unify, which says that E-path environments are preservedin the process of rewriting constraint sets (how a substitution S is applied to an E-path environment E to

obtain another E-path environment SE is given in definition 3.11).
Proof. For part 1, we have in fact a stronger result: Every constraint in a *-compatible constraint set \Delta such that

simplify(\Delta ) = \Delta  can be processed by one of the rewrite rules. This is a consequence of lemma 4.5:A good constraint of form (

a.1) is processed by rule 1, a good constraint of form (a.2) is processed by rule
2, and a good constraint of form (b) is processed by rule 3.Part 2 follows from: the fact that \Delta 

1 = simplify(~S\Delta 0) which implies E-env(\Delta 1) ` E-env(~S\Delta 0), the factthat (~S \Omega E S)E = ~S(SE) by lemma 3.18, the hypothesis SE '

E-env(\Delta 0), and the definition of E-pathenvironments (definition 3.11) - producing the following sequence of equalities and containments:

(~S \Omega E S)E = ~S(SE) ' ~S(E-env(\Delta 0)) = E-env(~S\Delta 0) ' E-env(\Delta 1)
which is the desired conclusion.
Lemma 5.9 (`Simplify' Preserves Solvability). Let \Delta  be a *-compatible constraint set and let S be asubstitution. Then:

1. S is a solution for \Delta  iff S is a solution for simplify(\Delta ).
2. S is a principal solution for \Delta  iff S is a principal solution for simplify(\Delta ).
Proof. For part 1 of the lemma, it suffices to consider the case when \Delta  consists of a single constraint o/ .= o/ 0.Moreover, it suffices to show that

S is a solution for \Delta  iff S is a solution for simplify1(\Delta ), where simplify1( )is defined in the proof of lemma 4.5.

There are 5 cases in the definition of simplify1( ). In the 4th case (when o/ = o/ 0) and 5th case (when
simplify1(\Delta ) = \Delta ), the desired conclusion is immediate.In the 2nd case (when

o/ = o/1 ! o/2 and o/ 0 = o/ 01 ! o/ 02) and 3rd case (when o/ = o/1 ^ o/2 and o/ 0 = o/ 01 ^ o/ 02),the desired conclusion follows from the way substitutions are lifted to types (definition 2.15).

For the 1st case, suppose o/ = ~F ae and o/ 0 = ~F oe with ~F 6= " and Var(ae) " Var(oe) = ?. A straightforwardcomputation shows that:

simplify1(o/ .= o/ 0) = simplify1( ~F (ae .= oe)) = ~F simplify1(ae .= oe) .
There are different subcases depending on the forms of ae and oe. We consider only one of these subcases,namely, when

ae = oe1 ! ae1 and oe = ae2 ! oe2; all other subcases are treated similarly. For this sub-case, the desired conclusion follows from the fact that

S is a solution for ~F (ae .= oe) iff S is a solution for{
~F (ae1 .= oe2), ~F (ae2 .= oe1)}. Remaining details omitted.

For part 2 of the lemma, let S be a principal solution for \Delta  which, by part 1, is also a solution for
simplify(\Delta ). It suffices to show that S is principal for simplify1(\Delta ), where simplify1( ) is defined in theproof of lemma 4.5. This is a straightforward consequence of principality (definition 4.13) and the way

substitutions are lifted to types (definition 2.15). This proves the left-to-right implication of part 2. Theconverse implication is readily proved in the same way. Remaining details omitted.

33

The next lemma is used in the proof of lemma 5.11.
Lemma 5.10 (A Property of Substitutions). Let o/ 2 T be well-named, ff 2 TVar(o/ ) and _o/ 2 T!. If
E-path(ff, o/ ) = ~F and S is a substitution such that S( ~F ff) = S( ~F _o/ ), then S({[ff := _o/ ]} o/ ) = So/ .

Proof. By induction on well-named o/ 2 T we prove the stronger conclusion: For every offset p 2 {0, 1}*
we have Sh{[ff := _o/ ]} o/ ip = Sho/ ip. The base case of the induction is o/ = ff, in which case ~F = ". Because{[

ff := _o/ ]} o/ = _o/ here, the desired conclusion follows.Proceeding inductively, the two cases

o/ = o/1 ! o/2 and o/ = o/1 ^o/2, are treated similarly. Consider the firstonly. Suppose
ff 2 TVar(o/ ) with E-path(ff, o/ ) = ~F . With no loss of generality, let ff 2 TVar(o/1) - TVar(o/2).(The two other subcases,

ff 2 TVar(o/2) - TVar(o/1) and ff 2 TVar(o/1) " TVar(o/2), are similar and therefore

omitted.) Then E-path(ff, o/1) = ~F . By the induction hypothesis, Sh{[ff := _o/ ]} o/1ip = Sho/1ip for every p 2{0

, 1}*. Moreover, ff 62 TVar(o/2) implies {[ff := _o/ ]} o/2 = o/2, which implies Sh{[ff := _o/ ]} o/2ip = Sho/2ip for every
p 2 {0, 1}*. Hence, Sh{[ff := _o/ ]} o/ ip = Sho/ ip for every p 2 {0, 1}*, which is the desired conclusion.The last case of the induction is when

o/ = Go/ 0 for some G 2 EVar and o/ 0 2 T. If o/ is well-named, sois
o/ 0, and if ff 2 TVar(o/ ) then ff 2 TVar(o/ 0). Let ~F = E-path(ff, o/ 0), so that G ~F = E-path(ff, o/ ). Consideran arbitrary

p 2 {0, 1}* and let S Gp = e where #2(e) = n and paths(e) = (s1, . . . , sn). We then have thefollowing sequence of equalities:

S h{[ff := _o/ ]} o/ ip = S hG ({[ff := _o/ ]} o/ 0)ip because o/ = G o/ 0,

= e[S h{[ff := _o/ ]} o/ 0ip*s1 , . . . , S h{[ff := _o/ ]} o/ 0ip*sn ] because S Gp = e,
= e[S ho/ 0ip*s1, . . . , S ho/ 0ip*sn ] by the induction hypothesis
= S hG o/ 0ip because S Gp = e,
= S ho/ ip because o/ = G o/ 0,

which is the desired conclusion. This completes the induction and the proof.
Lemma 5.11 (`Unify' Preserves Solvability). Let \Delta 0 be a *-compatible constraint set, let \Delta 1 be a con-straint set, and let:

Unify(\Delta 0, S, E) ) Unify(\Delta 1, ~S \Omega E S, E)
for some S, ~S and E (which do not matter here). Then, from a solution S0 for \Delta 0, we can construct asolution S

1 for \Delta 1.

Proof. \Delta 1 is obtained from \Delta 0 according to one of the 3 rewrite rules in figure 5. In each of the 3 cases,\Delta 

1 = simplify(\Delta 01) where \Delta 01 = ~S\Delta 0 for some appropriately defined substitution ~S. We consider each caseseparately. In all 3 cases, from a solution S

0 for \Delta 0, we show the existence of a solution S1 for \Delta 01 (as wellas \Delta 
1).rule 1: The given constraint set \Delta 

0 = \Delta  [ ~F {ff .= _oe} is transformed to \Delta 01 = {[ff := _oe]}\Delta  [ ~F {_oe .= _oe}.There are two subcases, depending on whether

ff occurs exactly twice or exactly once in \Delta 0. We omit thelatter subcase, which is trivial, and assume that

ff occurs exactly twice. If ff occurs exactly twice in \Delta 0,there is exactly one constraint in \Delta 

0, say ~G(ae .= oe) 2 \Delta , that mentions ff and it mentions ff exactly once.With no loss of generality, assume
ff 2 TVar(ae) and ff 62 TVar(oe); in particular, because \Delta 0 is well-named,

E-path(ff, ~Gae) = ~F . Because S0 is a solution for \Delta 0, we have S0( ~F ff) = S0( ~F _oe). This implies, by lemma 5.10,that S

0 ({[ff := _oe]} ae) = S0 ae. Hence, the desired solution S1 for \Delta 01 is simply the given solution S0 for \Delta 0.rule 2: Identical to rule 1, except for the reversed polarities.

rule 3: Let \Delta 0 = \Delta  [ ~G{F _ae .= e[_oe1, . . . , _oen]}, where the constraint F _ae .= e[_oe1, . . . , _oen] induces a rewritestep according to

rule 3. \Delta 0 is transformed to \Delta 1 = simplify(\Delta 01) where

\Delta 01 = {[F := e]}\Delta  [ ~G{e[h_aeis1, . . . , h_aeisn ] .= e[_oe1, . . . , _oen]}
where paths(e) = (s1, . . . , sn). Because S0 is a solution for \Delta 0, we have that S0( ~GF \Lambda ) = S0( ~Ge). It sufficesto construct a substitution

S1 such that S0 = S1 \Omega E0 {[F := e]} where E0 = E-env(\Delta 0). We keep the actionof S

1 on every variable v (and its offsprings) for which F 62 E-path(v, \Delta 0) identical to the action of S0; in

34

particular, S1( ~Ge) = S0( ~Ge). For every v such that E-path(v, \Delta 0) = ~GF ~H for some ~H 2 EVar*, it thereforesuffices to construct

S1 so that

S0( ~GF ~Hv) = (S1 \Omega E0 {[F := e]})( ~GF ~Hv)

= S1({[F := e]}( ~GF ~Hv))
= S1( ~Ge[h ~Hvis1, . . . , h ~Hvisn])

Note that the action of S1 on ~Ge is already determined, because F 62 EVar( ~Ge), but not on h ~Hvisi and its
offsprings. By part 1 of lemma 3.15, S1( ~Ge) is an expansion, say e0. We then have

e0 = S1( ~Ge) = S0( ~Ge) = S0( ~GF \Lambda )
Let #2(e0) = m >= n and paths(e0) = (p1, . . . , pm). By lemma 3.16,

S0( ~GF ~Hv) = e0[S0h ~Hvip1, . . . , S0h ~Hvipm ]
By part 2 of lemma 3.15,

S1( ~Ge[h ~Hvis1 , . . . , h ~Hvisn ]) = e0[S1h ~Hvisa(1)r(a(1),b(1)), . . . , S1h ~Hvisa(m)r(a(m),b(m))]
for appropriately defined maps:

a : {1, . . . , m} ! {1, . . . , n}

b : {1, . . . , m} ! {1, . . . , m}
r : {1, . . . , n} * {1, . . . , m} ! {0, 1}*

such that

* {a(1), . . . , a(m)} = {1, . . . , n},

* if E-path(\Lambda (i), ~Ge) = ~G ~Gi for 1 <= i <= n,

then paths(S1( ~G ~Gi\Lambda )) = paths(S0( ~G ~Gi\Lambda )) = (r(i, 1), . . . , r(i, mi)) for some mi >= 1,

* m = m1 + * * * + mn,

* { b(j) a(j) = i and 1 <= j <= m } = {1, . . . , mi} for every 1 <= i <= n.
Hence, to complete the definition of S1, we need to satisfy the equality S1h ~Hvisa(i)r(a(i),b(i)) = S0h ~Hvipi for
every 1 <= i <= m. If ~H = H1H2 * * * H` for some ` >= 0 and sa(i)r(a(i), b(i)) = qi, this equality is satisfied bysetting S

1 according to the following values:

S1Hqitj = S0Hpitj and S1vqit = S0vpit
for every 1 <= j <= ` and every t 2 {0, 1}*.
Lemma 5.12 (Principal Solution Constructed). ; Let \Delta 0 and \Delta 1 be *-compatible constraint sets, let
S be a substitution and E an E-path environment such that SE ' E-env(\Delta 0), and let:

Unify(\Delta 0, S, E) ==) Unify(\Delta 1, ~S \Omega E S, E)
for some substitution ~S. If S1 is a principal solution for \Delta 1, then so is S1 \Omega SE ~S for \Delta 0.
Proof. \Delta 1 is obtained from \Delta 0 according to one of the 3 rewrite rules in figure 5. For each of the 3 rules,we have \Delta 

0 = \Delta  [ ~F {ae .= oe} and \Delta 1 = simplify(\Delta 01), where \Delta 01 = ~S\Delta 0 and ~S depends on the form of ae .= oe(see figure 5). Suppose S

1 is a principal solution for \Delta 1.First, we check that S

0 = S1 \Omega SE ~S is a solution for \Delta 0. Consider a constraint ~Gae0 .= ~Goe0 in \Delta 0, whichimplies that ~S( ~
Gae0) .= ~S( ~Goe0) is a constraint in \Delta 01. We have the following sequence of equalities:

S0( ~Gae0) =1 (S1 \Omega SE ~S)( ~Gae0) =2 S1(~S( ~Gae0)) =3 S1(~S( ~Goe0)) =4 (S1 \Omega SE ~S)( ~Goe0) =5 S0( ~Goe0)

35

as desired. Equalities 1 and 5 follow from the definition of S0, equalities 2 and 4 follow from lemma 3.18,and equality 3 follows from the fact that

S1 is a solution for \Delta 1 together with part 1 in lemma 5.9. Theargument works whether or not ~
Gae0 .= ~Goe0 is ~F ae .= ~F oe.Second, we check that
S0 is principal for \Delta 0. Let S00 be an arbitrary solution for \Delta 0. Consider an arbitrary
constraint ~Gae0 .= ~Goe0 in \Delta 0. The corresponding constraint in \Delta 01 is ~S( ~Gae0) .= ~S( ~Goe0). By lemma 5.11, thereexists a solution

S01 for \Delta 1 from S00 such that:

(#) S00( ~Gae0) = S01(~S( ~Gae0)) = S01(~S( ~Goe0)) = S00( ~Goe0) .

By hypothesis, S1 is a principal solution for \Delta 1 and, by part 2 in lemma 5.9, a principal solution for \Delta 01.Hence, there is a substitution ^S such that:

S01(~S( ~Gae0)) = ^S(S1(~S( ~Gae0))) = ^S(S1 \Omega SE ~S( ~Gae0)) = ^S(S0( ~Gae0)) and
S01(~S( ~Goe0)) = ^S(S1(~S( ~Goe0))) = ^S(S1 \Omega SE ~S( ~Goe0)) = ^S(S0( ~Goe0)) .

Together with (#), this implies that S0 is a principal solution for \Delta 0.

To show that Unify(\Delta ) always terminates if \Delta  has a solution, we need to define a strictly decreasingmeasure on solutions S, which we here take as

size(S).

Definition 5.13 (Size). We define the function size : T2 ! N by induction on T2:

1. size(\Lambda ) = size(ff) = 1.
2. size(' ! _') = size(') + size( _') + 1.
3. size(' ^ '0) = size(') + size('0) + 1.
4. size(F ') = size(').
In words, size(') is the number of nodes in the tree representation of '. Occurrences of E-variables are notincluded in the count for

size('). Proper subsets of T2 are T and E; it is therefore meaningful to use size(o/ )and
size(e) for o/ 2 T and e 2 E.We extend the function

size( ) to an arbitrary substitution S : Var ! (E [ T!) with finite Dom(S) asfollows. Let:

S = {[F1 := e1, . . . , Fm := em, ff1 := _o/1, . . . , ffn := _o/n]} ,
where m + n 6= 0. We define size(S) by:

size(S) = size(e1) + * * * + size(em) + size(_o/1) + * * * + size(_o/n)
If Dom(S) = {[ ]}, we define size(S) = 0. If Dom(S) is infinite, we leave size(S) undefined.
Lemma 5.14 (Solutions with Finite Support Suffice). Let \Delta  be a *-compatible constraint set and letS be a substitution. If S is a solution for \Delta , then we can construct a substitution S0 from S such that:

1. Dom(S0) is finite.
2. S0 is a solution for \Delta .
Proof. This is an immediate consequence of lemma 3.19.
Lemma 5.15 (`Unify' Decreases Solution Size). Let \Delta 0 be a *-compatible constraint set, let \Delta 1 be aconstraint set, and let:

Unify(\Delta 0, S, E) ) Unify(\Delta 1, ~S \Omega E S, E)
for some S, ~S and E (which do not matter here). If S0 is a solution for \Delta 0 with finite Dom(S0), then wecan construct a solution S

1 for \Delta 1 with finite Dom(S1) such that size(S1) < size(S0).

36

Proof. This is a slight adjustment of the proof for lemma 5.11. The given solution S0 in the proof forlemma 5.11 can be assumed to have finite

Dom(S0), by lemma 5.14. Call ^S1 the solution constructed for \Delta 1
in lemma 5.11, to distinguish it from the solution S1 constructed here. It is clear that size(S0) = size(^S1).We consider each of the 3 rewrite rules separately.

rule 1: The given constraint set \Delta 0 = \Delta [ ~F {ff .= _oe} is first transformed to \Delta 01 = {[ff := _oe]}\Delta [ ~F {_oe .= _oe}
and then to \Delta 1 = simplify(\Delta 01). Suppose the given solution S0 is such that S0( ~F \Lambda ) = e. Then

S0( ~F ff) = ^S1( ~F ff) = e[ffs1 , . . . , ffsn]
where paths(e) = (s1, . . . , sn). As the variables ffs1, . . . , ffsn do not occur in \Delta 01, we can define S1 by:

S1v = (v if v 2 {ff

s1 , . . . , ffsn },

^S1v otherwise.

Because {ffs1, . . . , ffsn} ` Dom(S0) while {ffs1, . . . , ffsn} " Dom(S1) = ?, we conclude size(S1) < size(S0).

rule 2: Identical to rule 1, except for the reversed polarities.rule 3: Let \Delta 

0 = \Delta  [ ~G{F _ae .= e[_oe1, . . . , _oen]}, where the constraint F _ae .= e[_oe1, . . . , _oen] induces a rewritestep according to rule 3. \Delta 

0 is transformed to \Delta 1 = simplify(\Delta 01) where

\Delta 01 = {[F := e]}\Delta  [ ~G{e[h_aeis1, . . . , h_aeisn ] .= e[_oe1, . . . , _oen]}
where paths(e) = (s1, . . . , sn). Let paths(S0( ~G\Lambda )) = (t1, . . . , tm). Because the variables F t1, . . . , F tm donot occur in \Delta 0

1, we can define S1 by:

S1v = (v\Lambda  if v 2 {F

t1, . . . , F tm },

^S1v otherwise.

Because {F t1, . . . , F tm } ` Dom(S0) while {F t1, . . . , F tm} " Dom(S1) = ?, it follows size(S1) < size(S0).

The following theorem shows that the algorithm is sound (i.e., the substitutions Unify produces whenit terminates are in fact solutions) and complete (i.e.,

Unify produces a solution if there is one), as well as

showing it produces principal solutions. We write =*=) for the reflexive transitive closure of ==).

Theorem 5.16 (Soundness, Completeness, & Principality). Let \Delta  be a *-compatible constraint setand let E =

E-env(\Delta ). Then:

1. \Delta  has a solution if and only if Unify(simplify(\Delta ), {[ ]}, E) =*=) Unify(?, S, E) for some S.
2. If Unify(simplify(\Delta ), {[ ]}, E) =*=) Unify(?, S, E), then S is a principal solution for \Delta .
Proof. Part 1 follows from lemmas 5.7, 5.8, 5.11, 5.12 and 5.15. For part 2, first note that if Unify terminatesafter

n >= 1 steps beyond the initial call, then the returned substitution S applied to \Delta  produces a constraintset of the form:

S\Delta  = (Sn \Omega E (Sn-1 \Omega E (Sn-2 \Omega E * * * (S1 \Omega E S0) * * * )))\Delta 

= Sn((Sn-1 \Omega E (Sn-2 \Omega E * * * (S1 \Omega E S0) * * * ))\Delta )
= Sn(Sn-1((Sn-2 \Omega E * * * (S1 \Omega E S0) * * * )\Delta ))

...

= Sn(Sn-1(Sn-2(* * * ((S1 \Omega E S0)\Delta ) * * * )))
= Sn(Sn-1(Sn-2(* * * (S1(S0\Delta )) * * * )))

where S0 = {[ ]} and S1, . . . , Sn are the n successive substitutions produced by the n rewrite steps. The firstequality above is by the definition of

S, while all remaining equalities are by lemma 3.18. Starting from the

37

last equality above, we can also write the following sequence of equalities:

S\Delta  = Sn(Sn-1(Sn-2(Sn-3(* * * (S1(S0\Delta )) * * * ))))

= (Sn \Omega En-1 Sn-1)(Sn-2(Sn-3(* * * (S1(S0\Delta )) * * * )))
= ((Sn \Omega En-1 Sn-1) \Omega En-2 Sn-2)(Sn-3(* * * (S1(S0\Delta )) * * * ))

...

= ((* * * (((Sn \Omega En-1 Sn-1) \Omega En-2 Sn-2) \Omega En-3 Sn-3) * * * ) \Omega E1 S1)(S0\Delta )
= (((* * * (((Sn \Omega En-1 Sn-1) \Omega En-2 Sn-2) \Omega En-3 Sn-3) * * * ) \Omega E1 S1) \Omega E0 S0)\Delta 

where E0 = E and Ei = Si-1(Ei-1) for every 1 <= i <= n - 1. Invoking lemma 5.7, part 2 of lemma 5.8 andlemma 5.12, it is now readily checked that the substitution

(((* * * (((Sn \Omega En-1 Sn-1) \Omega En-2 Sn-2) \Omega En-3 Sn-3) * * * ) \Omega E1 S1) \Omega E0 S0)
is a principal solution for \Delta . Hence, S is a principal solution for \Delta .

Note that Unify diverges exactly when there is no solution. The evaluation strategy does not matter,because lemmas 5.11 and 5.15 imply termination when there is a solution and lemma 5.12 implies divergence

when no solution exists.

6 Type Inference Algorithm
This section defines a procedure which, given a *-term M , generates a finite set \Gamma (M ) of constraints, thesolvability of which is equivalent to the typability of the term

M . We use this to prove the principalityproperty for System I and to define a complete type-inference algorithm. An example of a run of the

type-inference algorithm is presented in appendix A.

If M = x, for fresh ff 2 TVarb: Typ(M) = ff,

Env(M) = {x 7! ff},
\Gamma (M) = ?,
Skel(M) = hVAR, Env(M) ` M : ff,i.

If M = (N1N2), for fresh F 2 EVarb, fi 2 TVarb: Typ(M) = fi,

Env(M) = Env(N1) ^ F Env(N2),
\Gamma (M) = \Gamma (N1) [ F \Gamma (N2) [ {Typ(N1) .= F Typ(N2) ! fi},
Skel(M) = hAPP, Env(M) ` M : fi, Skel(N1) (F Skel(N2))i.

If M = (*x.N), for fresh ff 2 TVarb: Typ(M) = (Env(N)(x) ! Typ(N) if Env(N)(x) defined,ff ! Typ(N) otherwise,

Env(M) = Env(N)\x,
\Gamma (M) = \Gamma (N),
Skel(M) = hR, Env(M) ` M : Typ(M), Skel(N)i where

if x 2 FV(N) then R = ABS-I else R = ABS-K.

Figure 6: Definition of \Gamma (M ), Skel(M ), Typ(M ), and Env(M ).
Definition 6.1 (Algorithm Generating Constraints and Skeleton). For every *-term M , figure 6 givesan inductive definition of a set of constraints \Gamma (

M ) and a derivation skeleton Skel(M), defined simultaneouslywith a type Typ(
M ) and a type environment Env(M ). In this definition, for a given subterm occurrence
N , when a fresh variable is chosen, the same fresh variable must be used in Env(N ), Typ(N ), \Gamma (N ), andSkel(

N ). The process of going from M to \Gamma (M ) and Skel(M ) is uniquely determined up to the choice ofexpansion variables and type variables.

38

Lemma 6.2 (Constraint Set is *-Compatible). Let M be an arbitrary *-term. The constraint set \Gamma (M )induced by

M is *-compatible.

Proof. This is by induction on M . An appropriate induction hypothesis is stated using the functions Typ(M ),Env(

M ) and \Gamma (M ) in figure 6 with polarities inserted. Accordingly, define:

* If M = x, then for fresh ff 2 TVarb:

+-Typ(M ) = +ff ,+-

Env(M ) = {x 7! -ff} ,+-
\Gamma (M ) = ? .

* If M = (N P ), then for fresh F 2 EVarb and fresh fi 2 TVarb:

+-Typ(M ) = +fi ,+-

Env(M ) = +-Env(N ) ^ -F +-Env(P ) ,+-
\Gamma (M ) = +-\Gamma (N ) [ F +-\Gamma (P ) [ {+-Typ(N ) .= +F +-Typ(P ) ! -fi} .

Note that an outer ocurrence of F is inserted without a polarity in +-Typ(M ), consistent with the useof polarities in definitions 4.4 and 4.8.

* If M = (*x.N ), then for fresh ff 2 TVarb:

+-Typ(M ) = (+-Env(N )(x) ! +-Typ(N ) if +-Env(N )(x) defined ,-ff ! +-Typ(N ) otherwise ,
+-Env(M ) = +-Env(N )\x ,+-

\Gamma (M ) = +-\Gamma (N ) .

By omitting all polarities in +-Typ(M ), +-Env(M) and +-\Gamma (M ), we get precisely Typ(M ), Env(M ) and\Gamma (

M ), and we can also go from the latter to the former without ambiguity.For each

*-term M , we define Triple(M ) = \Gamma +-Typ(M ), +-Env(M ), +-\Gamma (M )\Delta . The induction hypothesisspecifies 6 properties of

Triple(M ):

(0) Triple(M ) is of the form

+-Typ(M ) = (_ae)+ ,+-

Env(M ) = {x1 : (oe1)-, . . . , xm : (oem)-} ,+-
\Gamma (M ) = { ~F1(_ae1)+ .= ~F1(_oe1)-, . . . , ~Fn(_aen)+ .= ~Fn(_oen)-} ,

for some _ae, _aei 2 R!, _oei 2 S! and oej 2 S, and ~Fi 2 EVar*, with m, n >= 0 and Var(_aei) " Var(_oei) = ?for every 1 <=

i <= n. Note that every constraint in \Gamma (M ) is good of form (a) in definition 4.3; goodconstraints of form (

b) and form (c) are generated only once the process of fi-unification is started.

(1) Triple(M ) is well-named, i.e., given the form of Triple(M ) described in property (0), the type:

_ae ^ oe1 ^ * * * ^ oem ^ ~F1(_ae1 ^ _oe1) ^ * * * ^ ~Fn(_aen ^ _oen)
is well-named.
(2) If expansion variable F 2 EVar occurs in Triple(M ), it occurs exactly once as +F .
(3) If type variable ff 2 TVar occurs in Triple(M ), it occurs exactly once as -ff and at most once as +ff.
(4) Identical to condition (D) in definition 4.8 with \Delta  = \Gamma (M ).

39

(5) For every *-term N , if neither M nor N is a subterm occurrence of the other, then

Var\Gamma Triple(M )\Delta  " Var\Gamma Triple(N )\Delta  = ? .

Although we do not use it in the induction, it is worth pointing out in property (0), {x1, . . . , xm} = FV(M )and

n is the number of subterm occurences in M that are applications.Observe that (1), (2) and (3) here imply (A), (B) and (C) in definition 4.8, while (4) here is identical to

(D) in definition 4.8. The hard part is to set up the induction hypothesis above; the rest of the induction isroutine, if somewhat tedious.

Let IH(M ) denote the 6 parts of the induction hypothesis relativized to *-term M . We omit the straight-forward verification that IH(

x) is true, for every *-variable x. Assuming that IH(N ) is true, it is also readilychecked that IH(
*x.N ) is true, and we therefore omit the details.Finally, assuming that IH(

N ) and IH(P ) are true, we want to show that IH(N P ) is true. Part (0) inIH(
N P ) follows from (0) in both IH(N ) and IH(P ), and the definitions of +-Typ(N P ), +-Env(N P ) and+-\Gamma (

N P ). Each of parts (1), (2), (3) and (5) in IH(N P ) follows from the corresponding parts in IH(N ) andIH(
P ). For part (4) in IH(N P ), we need to show that graph(\Gamma (N P )) is acyclic. Let \Delta 0 be the set:

\Delta 0 = {Typ(N ) .= F Typ(P ) ! fi}.
This is the new constraint, of form (a) as specified in definition 4.3, which is added to \Gamma (N ) and F \Gamma (P ) toobtain \Gamma (

N P ). Then

graph(\Gamma (N P )) = graph(\Gamma (N )) [ graph(\Gamma (P )) [ graph(\Delta 0) where, by definition 4.6,

graph(\Delta 0) = 8?!?:{

ff y F, ff y fi} if Typ(N ) = ff 2 TVar,{

v y fi v 2 Var(_ae) and E-path(v, \Delta 0) = " } if Typ(N ) = oe ! _ae

for some oe 2 S and _ae 2 R! .

The acyclicity of graph(\Gamma (N P )) follows from the acyclity of graph(\Gamma (N )) by part 4 in IH(N ), the acyclity of
graph(\Gamma (P )) by part 4 in IH(P ), and the fact Var(Triple(N )) " Var(Triple(P )) = ? by part (5) in IH(N ) (oralso part (5) in IH(

P )). This last fact guarantees v 6y w for all v 2 Var(F \Gamma (P )) and w 2 Var(\Gamma (N )).

Remark 6.3. Not every *-compatible constraint set is induced by a *-term; for example, a *-compatibleconstraint set \Delta  as simple as {

ff .= F fi ! fl} is not induced by any *-term. Moreover, the same constraintset \Delta  may be induced by different

*-terms; for example, \Gamma (*x.*y.M ) = \Gamma (*y.*x.M ) for all *-terms M .

Lemma 6.4 (All Derivations Instances of Skel(M )). If D is a derivation of System I with final judge-ment

A ` M : o/ , then there is a substitution S such that D = S(Skel(M )).

Proof. By induction on the structure of D. (See the proof of theorem 22 in the appendix of [Kfo99].)

Theorem 6.5 (Constraint Set and Skeleton Equivalent). Let M be a *-term. Then a substitution Sis a solution for \Gamma (

M ) if and only if S(Skel(M )) is a derivation of System I. Thus, \Gamma (M ) is solvable if andonly if
M is typable in System I.

Proof. By induction on M , using the definitions of \Gamma (M ), Skel(M ), and substitution together with lemma 2.19.

Corollary 6.6 (Undecidability of Beta-Unification). It is undecidable whether an arbitrarily chosen
*-compatible constraint set \Delta  has a solution.

From the principality property for *-compatible fi-unification, we can derive the following.
Theorem 6.7 (Principal Typings and Completeness of Type Inference). Given *-term M , let PTbe the algorithm such that

PT(M ) = (S(Skel(M )) if some evaluation of Unify(\Gamma (M )) converges and returns S,undefined if every evaluation of Unify(\Gamma (M )) diverges,
It holds that if M is typable in System I, then PT(M ) returns a principal typing for M , else PT(M ) diverges.Thus, System I has the principality property and PT is a complete type inference algorithm for System I.

40

Proof. By lemma 6.2 and theorem 5.16, if S = Unify(\Gamma (M )) is defined, it is a principal solution for \Gamma (M).By theorem 6.5,

S(Skel(M )) is a typing for M . By lemma 6.4, if D is a typing for M , then D = S0(Skel(M ))for some substitution S0, which must be a solution for \Gamma (

M ) by theorem 6.5. By definition 4.13, it must holdthat
S0(\Gamma (M )) = S00(S(\Gamma (M ))) for some substitution S00. Thus, D = S00(PT(M ))7, proving that PT(M ) isa principal typing for

M .

7 Skeletons and Derivations at Finite Ranks
This section makes a finer analysis of the relationship between Skel(M ) and \Gamma (M ) for an arbitrary *-term
M . We then define the "rank" of skeletons and derivations, and the "rank" of solutions for constraint sets.Finally, we prove a correspondence between the rank of typings for

M and the rank of solutions for \Gamma (M).

Definition 7.1 (Left Types). For every skeleton S we define the set of left types of S, denoted left-types(S),and the final type of S, denoted

final-type(S). If S is the skeleton hR, J, Q1 * * * Qni where J is the judgement
A `? M : o/, then

final-type(S) = o/ ,

left-types(S) = 8???!???:

? if n = 0 and R = VAR,
left-types(Q1) [ left-types(Q2) [ {final-type(Q1)} if n = 2 and R = APP,{

F o/ o/ 2 left-types(Q1) } if n = 1 and R = F 2 EVar,
left-types(Q1) [ * * * [ left-types(Qn) otherwise.

A simple induction (omitted) shows that a type in left-types(S) is always of the form ~F _o/ for some ~F 2 EVar*
and _o/ 2 T!. In words, ~F _o/ 2 left-types(S) iff _o/ is the final type of the left premise Q1 in a subskeletonhAPP

, J, Q1Q2i of S. The number of types in left-types(S) is therefore the number of times rule APP is usedin S.

The definition of left-types(S) is somewhat complicated, but is adjusted in order to be exactly the set ofleft types of a corresponding constraint set. Let \Delta  be the constraint set {

o/1 .= o/ 01, . . . , o/n .= o/ 0n}. We definethe set
left-types(\Delta ) by:

left-types(\Delta ) = {o/1, o/2, . . . , o/n} .
Lemma 7.3 relates left-types(S) and left-types(\Delta ).
Definition 7.2 (The `Split' Operation). The operation split( ) is first defined on a single constraint
o/ .= o/ 0, where o/, o/ 0 2 T are arbitrary:

split(o/ .= o/ 0) = 8?!?:

F split(o/0 .= o/ 00) if o/ = F o/0 and o/ 0 = F o/ 00,
split(o/1 .= o/ 01) [ split(o/2 .= o/ 02) if o/ = o/1 ^ o/2 and o/ 0 = o/ 01 ^ o/ 02,{

o/ .= o/ 0} otherwise.

What split( ) does is this:8 If o/ and o/ 0 are types such that o/ = e[o/1, . . . , o/n] and o/ 0 = e[o/ 01, . . . , o/ 0n] where
o/i 6= o/ 0i for every 1 <= i <= n, then

split(o/ .= o/ 0) = { ~F1o/1 .= ~F1o/ 01, . . . , ~Fno/n .= ~Fno/ 0n} ,
where ~Fi = E-path(\Lambda (i), e) for every 1 <= i <= n. We extend the operation to constraint sets \Delta . If \Delta  = ?,then

split(\Delta ) = ?. If \Delta  = {o/ .= o/ 0} [ \Delta 0, then split(\Delta ) = split(o/ .= o/ 0) [ split(\Delta 0).

Lemma 7.3 (Relating Left Types of Skeletons and Left Types of Constraint Sets). Let M be a
*-term, S = Skel(M ) and \Delta  = \Gamma (M ). We then have, for every substitution S:

left-types\Gamma S(S)\Delta  = left-types\Gamma split(S\Delta )\Delta 
In particular, if S is the identity substitution, then left-types(S) = left-types(\Delta ).

7This requires some additional facts about substitutions, e.g., the principal solution constructed by Unify is "safe" for
composition in a certain sense. It also depends on the fact that E-path(v, Skel(M)) = E-path(v, \Gamma (M)) for all v 2 Var.

8The operation split( ) here does only a part of the operation simplify( ) in figure 5. The two are not identical.

41

Proof. By induction on the structure of M . To push the induction through, we prove a slightly strongerinduction hypothesis, namely,
IH: For every substitution S, every sequence ~F of fresh and distinct basic E-variables,and every offset

t 2 {0, 1}*, we have left-types(Sh ~F Sit) = left-types\Gamma split(Sh ~F \Delta it)\Delta .

We relativize IH to S and \Delta  by writing IH(S, \Delta ).For the base case

M = x, we have Skel(M ) = hVAR, x : ff ` x : ff, i and \Gamma (M ) = ?. The desiredconclusion is immediate in this case.

Proceeding inductively, let M = N1N2. For i = 1, 2, let Si = Skel(Ni) and \Delta i = \Gamma (Ni). Using thesimultaneous definitions of Skel(

M ) and \Gamma (M ) in figure 6, posing also _aei = Typ(Ni) and Ai = Env(Ni) for
i = 1, 2, we have:

S = Skel(M ) = hAPP, A1 ^ H A2 ` M : fi, S1 (H S2)i , (a)
\Delta  = \Gamma (M ) = \Delta 1 [ H\Delta 2 [ {_ae1 .= H _ae2 ! fi} , (b)

where H 2 EVarb and fi 2 TVarb are fresh. Let S be a substitution, ~F a sequence of fresh and distinctbasic E-variables, and

t 2 {0, 1}*. Suppose Sh ~F \Lambda it = e, paths(e) = (u1, . . . , un) where n = #2(e) >= 1, and
~Gi = E-path(\Lambda (i), e), for every 1 <= i <= n. By definition 2.17, it is easy to see that:

Sh ~F Sit = e[ShSit*u1 , . . . , ShSit*un ] .
Hence, by definition 7.1 together with (a) above and the fact that final-type(S1) = _ae1, we have:

left-types(Sh ~F Sit) = S1<=i<=n ~Gi left-types(ShSit*ui ) (c)

= S1<=i<=n ~Gi \Gamma left-types(ShS1it*ui) [ left-types(ShH S2it*ui ) [ {Sh_ae1it*ui }\Delta 
For arbitrary o/1, . . . , o/n, o/ 01, . . . , o/ 0n 2 T, it is readily checked that:

split(e[o/1, . . . , o/n] .= e[o/ 01, . . . , o/ 0n]) = ~G1\Gamma split(o/1 .= o/ 01)\Delta  [ * * * [ ~Gn\Gamma split(o/n .= o/ 0n)\Delta  .
Moreover, if o/i or o/ 0i is in T! for every 1 <= i <= n, then:

split(e[o/1, . . . , o/n] .= e[o/ 01, . . . , o/ 0n]) = ~G1{o/1 .= o/ 01} [ * * * [ ~Gn{o/n .= o/ 0n} ,
which in turn implies that:

left-types\Gamma split(e[o/1, . . . , o/n] .= e[o/ 01, . . . , o/ 0n])\Delta  = { ~G1o/1, . . . , ~Gno/n} .
Hence, by definition 7.1 together with (b), we also have:

left-types\Gamma split(Sh ~F \Delta it)\Delta  = left-types\Gamma split(Sh ~F \Delta 1it)\Delta  [ left-types\Gamma split(Sh ~F H\Delta 2it)\Delta  [ (d)

left-types\Gamma split(Sh ~F _ae1it .= Sh ~F (H _ae2 ! fi)it)\Delta 

= S1<=i<=n ~Gi ileft-types(split(Sh\Delta 1it*ui )) [

left-types(split(ShH\Delta 2it*ui )) [ {Sh_ae1it*ui }j
The equality of (c) and (d) follows from IH(S1, \Delta 2) and IH(S2, \Delta 2), which implies IH(S, \Delta ) is also true.The last case of the induction is

M = (*x.N ). There are two subcases, depending on whether x 2 FV(N )or not. Consider the first subcase only; the second is analyzed in the same way. Let S0 = Skel(

N ) and\Delta 0 = \Gamma (
N ). Using the simultaneous definitions of Skel(M ) and \Gamma (M ) in figure 6, posing also Typ(N ) = _aeand Env(

N ) = A[x 7! oe], we have:

S = Skel(M ) = hABS-I, A ` M : oe ! _ae, S0i , (e)
\Delta  = \Gamma (M ) = \Gamma (N ) = \Delta 0 . (f)

That IH(S, \Delta ) is true in this case follows from definition 7.1, together with (e), (f) and IH(S 0, \Delta 0). Remainingdetails omitted.

42

Definition 7.4 (Rank of Types). For every s 2 {L, R, 0, 1}*, let #L(s) denote the number of occurrencesof

L in s. Formally,

#L(s) = 8?!?:

0 if s = ",
1 + #L(t) if s = L * t,
#L(t) if s = R * t or 0 * t or 1 * t.

Let o/ 2 T. There is a smallest (and, therefore, unique) ' 2 T2 with n >= 1 holes such that

1. o/ = '[o/1, . . . , o/n] for some o/1, . . . , o/n 2 T.
2. None of the types in {o/1, . . . , o/n} contains an occurrence of "^".
The rank of hole \Lambda (i) in ' is given by hole-rank(\Lambda (i), ') = #L(path(\Lambda (i), ')). If ' = \Lambda , i.e., o/ does notmention any "^", we define

rank(o/ ) = 0. If ' 6= \Lambda , we define rank(o/ ) by:

rank(o/ ) = 1 + max{hole-rank(\Lambda (i), ') | 1 <= i <= #2(')} .
Let T ae T be a non-empty finite subset of types. We define rank(T ) by:

rank(T ) = max{ rank(o/) o/ 2 T } .
If T = ?, we define rank(T ) = 0. This definition of rank is equivalent to others found in the literature.
Definition 7.5 (Rank of Skeletons, Derivations and Typings). Let J be the following judgement ofSystem I:

x1 : o/1, . . . , xk : o/k ` M : o/
for some appropriate types o/1, . . . , o/k, o/ and *-term M . We say that o/1, . . . , o/k are the environment types in
J and o/ is the derived type in J. If S is a skeleton of System I, an environment type (resp., a derived type)in S is an environment type (resp., a derived type) in one of the judgements of S.

If S is a skeleton of System I where every environment type has rank 0 and every derived type has rank0, we write

rank(S) = 0 and say that S is a rank-0 skeleton.Let
k >= 1. If S is a skeleton of System I where every environment type has rank <= k -1 and every derivedtype has rank <=

k, we write rank(S) <= k and say that S is a skeleton of rank at most k. If rank(S) <= kbut
rank(S) 6<= k - 1, we write rank(S) = k and say that S is a rank-k skeleton. A particular subset of therankk skeletons are the rank-k derivations, and a particular subset of the rank-k derivations are the rank-ktypings.

Definition 7.6 (Lambda-Terms in Special Form). Let M be a *-term. We say that M is in specialform if

M = (*y1 * * * *yn.N )z1 * * * zn where N is not a *-abstraction, FV(N ) ` {y1, . . . , yn} and z1, . . . , znare
n distinct *-variables, with n >= 0.Let

M = *y1 * * * yn.N be a *-term (not necessarily in special form) where N is not a *-abstraction, with
n >= 0, and let FV(M ) = {x1, . . . , xm} with m >= 0. We define the special form of M by:

special(M ) = (*x1 * * * xmy1 * * * yn.N )z1 * * * zm+n ,
where z1, . . . , zm+n are m + n distinct fresh *-variables. Clearly, special(M ) is a *-term in special form. (Itis not the case in general that if

M is in special form, then special(M ) = M .)

Lemma 7.7 (Relating Rank of Typings and Rank of Left Types). Let M be a *-term and let D bea typing for

M . If M is in special form, then rank(D) = rank(left-types(D)).

The conclusion of the lemma is generally false if M is not in special form. Consider, for example, the
*-term M = xx: There is a typing D for xx of rank 2, while rank(left-types(D)) = 0.

43

Proof. If D is a derivation with final judgement x1 : o/1, . . . , xm : o/m `? P : o/ , we define the set of types
final-type*(D) by:

final-type*(D) = {o/1 ! ff, . . . , o/m ! ff, o/ }
where ff is a fresh T-variable (not occurring anywhere in D). Although the usual definition of "rank" allowsus to write the equation:

rank(final-type*(D)) = rank(o/1 ! * * * ! o/m ! o/ ) ,
we have to avoid the type on the right-hand side of this equation because, if o/ 62 T!, it is not legal accordingto our syntax of types (definition 2.3).

We also define left-types*(D) = left-types(D) [ final-type*(D). Without restrictions on the *-term P , wenow prove by induction on the structure of D that:

IH: rank(D) = rank\Gamma left-types*(D)\Delta  .

This is the induction hypothesis, which we write IH(D) when relativized to D.For the base case, we have D = hVAR

, x : _o/ ` x : _o/ , i and left-types*(D) = {_o/ ! ff, _o/ }. This impliesIH(D) is true for the base case.

Suppose the final judgement in D is obtained by using ABS-I, i.e., D = hABS-I, A ` *x.M : o/ ! _o/ , D0i
where D0 = hR, A[x 7! o/ ] ` M : _o/ , ~Qi for some rule R and appropriate sequence ~Q of subderivations. Wenow have the following sequence of equalities:

rank(D) = rank(D0) by definition of rank(D),

= rank\Gamma left-types*(D0)\Delta  by IH(D0),
= rank\Gamma (left-types*(D0) - {o/ ! ff, _o/ }) [ {o/ ! _o/ }\Delta 
= rank\Gamma left-types*(D)\Delta  by definition of left-types*(D0),

which implies IH(D) is true for the case when ABS-I is the last rule used in D.We omit the case when the final judgement in D is obtained by using ABS-K. This case is an easy
variation of the preceding case, and we omit all the straightforward details.Suppose the final judgement in D is obtained by using APP, i.e., D = hAPP

, A1 ^ A2 ` M N : _o/ , D1 D2i
where D1 = hR1, A1 ` M : o/ ! _o/ , ~Q1i and D2 = hR2, A2 `? N : o/, ~Q2i, for some rules R1 and R2 and
appropriate sequences ~Q1 and ~Q2 of subderivations. Let

A1 = x1 : o/ 11 , . . . , xm : o/ 1m, y1 : o/ 1m+1, . . . , yn : o/ 1m+n
A2 = x1 : o/ 21 , . . . , xm : o/ 2m, z1 : o/ 2m+1, . . . , zp : o/ 2m+p

for some m, n, p >= 0, where the sets {x1, . . . , xm}, {y1, . . . , yn} and {z1, . . . , zp} are pairwise disjoint. Thisimplies that

A1 ^ A2 = x1 : o/ 11 ^ o/ 21 , . . . , xm : o/ 1m ^ o/ 2m, y1 : o/ 1m+1, . . . , yn : o/ 1m+n, z1 : o/ 2m+1, . . . , zp : o/ 2m+p
By the definition of final-type*( ), we thus have:

final-type*(D1) = {o/ 11 ! ff, . . . , o/ 1m ! ff, o/ 1m+1 ! ff, . . . , o/ 1m+n ! ff, o/ ! _o/ } ,
final-type*(D2) = {o/ 21 ! ff, . . . , o/ 2m ! ff, o/ 2m+1 ! ff, . . . , o/ 2m+p ! ff, o/ } ,
final-type*(D) = {o/ 11 ^ o/ 21 ! ff, . . . , o/ 1m ^ o/ 2m ! ff,

o/ 1m+1 ! ff, . . . , o/ 1m+n ! ff, o/ 2m+1 ! ff, . . . , o/ 2m+p ! ff, _o/ } .

A straightforward calculation now shows that:

(#) rank(final-type*(D) [ {o/ ! _o/ }) >= rank\Gamma final-type*(D1) [ final-type*(D2)\Delta  .

44

Finally, we have the following sequence of equalities:

rank(D) = max{rank(D1), rank(D2), rank\Gamma final-type*(D)\Delta }

= rank\Gamma left-types*(D1) [ left-types*(D2) [ final-type*(D)\Delta 
= rank\Gamma left-types(D) [ final-type*(D1) [ final-type*(D2) [ final-type*(D)\Delta 
= rank\Gamma left-types(D) [ final-type*(D)\Delta 
= rank\Gamma left-types*(D)\Delta  ,

where the second equality follows from IH(D1) and IH(D2), and the fourth equality from (#) and the factthat {

o/ ! _o/ } ` left-types(D). This establishes IH(D) when APP is the last rule used in D.Suppose the final judgement in D is obtained by using rule ^, i.e., D = h^

, A1 ^ A2 `e M : o/1 ^ o/2, D1 D2i
where D1 = hR1, A1 `? M : o/1, ~Q1i and D2 = hR2, A2 `? M : o/2, ~Q2i, for some rules R1 and R2 and appropriate sequences ~Q1 and ~Q2 of subderivations. Suppose FV(M ) = {x1, . . . , xm} for some m >= 0, so that

A1 = x1 : o/ 11 , . . . , xm : o/ 1m
A2 = x1 : o/ 21 , . . . , xm : o/ 2m
A1 ^ A2 = x1 : o/ 11 ^ o/ 21 , . . . , xm : o/ 1m ^ o/ 2m

Hence, by the definition of final-type*( ):

final-type*(D1) = {o/ 11 ! ff, . . . , o/ 1m ! ff, o/1} ,
final-type*(D2) = {o/ 21 ! ff, . . . , o/ 2m ! ff, o/2} ,
final-type*(D) = {o/ 11 ^ o/ 21 ! ff, . . . , o/ 1m ^ o/ 2m ! ff, o/1 ^ o/2} .

It is therefore clear that:

(##) rank\Gamma final-type*(D)\Delta  >= rank\Gamma final-type*(D1) [ final-type*(D2)\Delta  .
We now have the following sequence of equalities:

rank(D) = max{rank(D1), rank(D2), rank\Gamma final-type*(D)\Delta }

= rank\Gamma left-types*(D1) [ left-types*(D2) [ final-type*(D)\Delta 
= rank\Gamma left-types(D) [ final-type*(D1) [ final-type*(D2) [ final-type*(D)\Delta 
= rank\Gamma left-types(D) [ final-type*(D)\Delta 
= rank\Gamma left-types*(D)\Delta  ,

where the second equality follows from IH(D1) and IH(D2), and the fourth equality from (##). This establishesIH(D) when rule ^ is the last used in D.

The last case of the induction is when the final judgement in D is obtained by using rule F , for some
F 2 EVar. This case is straightforward and simpler than all the preceding cases. We omit all the details ofthis last case.

To complete the proof of lemma 7.7, consider an arbitrary *-term M in special form and a typing D for
M . Then D must have the following form (see definition 7.6):

...

ABS-x` *y
1 * * * *yn.N : o/1 ! * * * ! o/n ! _o/

...

R1z
1 : o/1 `? z1 : o/1 APP

z1 : o/1 ` (*y1 * * * *yn.N)z1 : o/2 ! * * * ! o/n ! _o/

...

R2z
2 : o/2 `? z2 : o/2 APP

...

APPz
1 : o/1, . . . , zn-1 : o/n-1 ` (*y1 * * * *yn.N)z1 * * * zn-1 : o/n ! _o/

...

Rnz
n : o/n `? zn : o/n APP

z1 : o/1, . . . , zn : o/n ` (*y1 * * * *yn.N)z1 * * * zn : _o/

45

for some o/1, . . . , o/n 2 T and _o/ 2 T!, where ABS-x 2 {ABS-I, ABS-K} and Ri 2 {VAR, ^} [ EVar for every1 <=

i <= n. By the definition of left-types( ) and left-types*( ), we have:

left-types*(D) = left-types(D) [ final-type*(D) = left-types(D) [ {o/1 ! ff, . . . , o/n ! ff, _o/ } .
Because o/1 ! * * * ! o/n ! _o/ 2 left-types(D) and rank(o/1 ! * * * ! o/n ! _o/ ) = rank({o/1 ! ff, . . . , o/n ! ff, _o/ }),it now follows that

rank\Gamma left-types*(D)\Delta  = rank\Gamma left-types(D)\Delta  which, together with IH(D), implies the con-clusion of the lemma.

Definition 7.8 (Rank of Solutions of Constraint Sets). Let \Delta  be the non-empty *-compatible con-straint set {

o/1 .= o/ 01, . . . , o/n .= o/ 0n}, and let k >= 0. We say that a substitution S : Var ! (E [ T!) is a solutionfor \Delta  of rank at most

k provided:

1. S is a solution for \Delta .
2. max{rank(So/1), . . . , rank(So/n)} <= k.
We say that S is a rank-k solution for \Delta  if S is of rank <= k but not <= k - 1. If \Delta  = ?, every substitutionis a solution for \Delta , and we define the rank of a solution for \Delta  = ? to be 0 (this is an arbitrary choice which

does not affect the analysis).
Theorem 7.9 (Rank-k Typings vs. Rank-k Solutions). Let M be a *-term and M 0 = special(M ).The following are equivalent conditions, for all

k >= 0:

1. There is a rank-k typing for M .
2. There is a rank-k typing for M 0.
3. There is a rank-k solution for \Gamma (M 0).

In the theorem statement we can restrict k to be 6= 1. It is easy to see there is no rank-1 typing for any
*-term P (as opposed to a derivation). Moreover, it can be shown that there is no rank-1 solution for \Gamma (P )for any

*-term P , using the fact that all positive inner occurrences of expansion variables in \Gamma (P ) are atrank 2 (details omitted). This last assertion does not hold for

*-compatible constraint sets in general.

Proof. Let k >= 0 be fixed throughout the proof. We first prove that, given an arbitrary o/ 2 T and arbitrary
z 2 *-Var, there is a derivation, call it D(z : o/ ), whose final judgement is z : o/ `? z : o/ where ? = " or? = e depending on whether

o/ 2 T! or not. For this, we write o/ in the form o/ = e[_o/1, . . . , _o/j] where e isan expansion with #

2(e) = j >= 1 and _o/1, . . . , _o/j 2 T!. The construction of D(z : o/ ) is a straightforwardinduction on the size of

e, obtained by using repeatedly rule ^ and rule F in figure 1; rule ^ (resp. rule F )is used as many times as there are occurrences of "^" (resp. occurrences of

F ) in e. We omit the details ofthis induction.

If rank(o/ ) = 0, then rank\Gamma D(z : o/ )\Delta  = 0. If rank(o/ ) = 1, then rank(_o/1) = * * * = rank(_o/j) = 0 and j >= 2,
which in turn implies rank\Gamma D(z : o/ )\Delta  = 2. If rank(o/ ) = k >= 2, then max{rank(_o/1), . . . , rank(_o/j)} = k which
in turn implies rank\Gamma D(z : o/ )\Delta  = k + 1. Note that for all o/ 2 T, it holds that rank\Gamma D(z : o/ )\Delta  6= 1.We now prove the equivalence of parts 1 and 2 in the theorem statement: There is a rankk typing for Miff there is a rankk typing for M 0. The right-to-left implication is easy to see, because M is a subterm of M 0.For the left-to-right implication, suppose D is a rankk typing for M . Hence, D is of the form D = hR, J, ~Qiwhere
J is the judgement x1 : o/1, . . . , xm : o/m ` M : o/ . We can assume that R 2 {VAR, ABS-I, ABS-K, APP}in the judgement

J, which must therefore be of the form (see definition 7.6):

x1 : o/1, . . . , xm : o/m ` *y1 * * * *yn.N : o/m+1 ! * * * ! o/m+n ! _o/
for some o/1, . . . , o/m+n 2 T and _o/ 2 T!, where n >= 0 and N is not a *-abstraction.If

rank(D) = 0, then rank(o/i) = 0 for every i 2 {1, . . . , m + n}. There are no rank-1 typings, i.e., typingsof rank at most 1 but not 0. If

rank(D) = k >= 2, then rank(o/i) <= k - 1 for every i 2 {1, . . . , m + n}. The

46

desired typing D0 for M 0 has the following form:

~Q

Rx
1 : o/1, . . . , xm : o/m ` M : o/m+1 ! * * * ! o/m+n ! _o/ ABS-I

...

ABS-I` *x
1 * * * *xm.M : o/1 ! * * * ! o/m+n ! _o/ D(z1 : o/1) APP

z1 : o/1 ` (*x1 * * * *xm.M)z1 : o/2 ! * * * ! o/m+n ! _o/ D(z2 : o/2) APP

... D(z

m+n : o/m+n) APP

z1 : o/1, . . . , zm+n : o/m+n ` (*x1 * * * *xm.M)z1 * * * zm+n : _o/

It is easy to check that if rank(D) = 0 then rank(D0) = 0, and if rank(D) >= 2 then rank(D0) = rank(D).We next prove the equivalence of parts 2 and 3 in the theorem statment: There is a rankk typing for M 0iff there is a rankk solution for \Gamma (M 0). Let S0 = Skel(M 0) and \Delta 0 = \Gamma (M 0). By lemma 6.4 and theorem 6.5,there is a typing D0 for

M 0 iff there is a solution S for \Delta 0 such that D0 = S(S0). We also have:

left-types(D0) = left-types\Gamma S(S0)\Delta  = left-types\Gamma split(S\Delta 0)\Delta 
where the second equality follows from lemma 7.3. Hence, we also have:

rank(D0) = k iff rank\Gamma left-types(D0)\Delta  = k

iff rank\Gamma left-types(S(S0))\Delta  = k
iff rank\Gamma left-types(split(S\Delta 0))\Delta  = k
iff S is a rank-k solution for \Delta 0 ,

where the first "iff" is true by lemma 7.7 and the last "iff" follows from the fact that k 6= 1.

8 Termination and Decidability at Finite Ranks
This section defines UnifyFR, an adaptation of algorithm Unify which produces a solution S with boundedrank

k for a *-compatible constraint set \Delta . The definition of UnifyFR differs from Unify only in the "modeof operation" as presented in figure 7. The invocation of

UnifyFR on \Delta  at rank k produces a solution Sif
Unify(\Delta ) produces S and rank(S\Delta ) <= k. Otherwise, UnifyFR halts indicating failure, unlike Unify whichdiverges if it can not find a solution.

Note that the principality of solutions produced by UnifyFR follows from the principality of solutionsproduced by

Unify.The presentation of

UnifyFR in figure 7 includes two new operations, "the coding of a constraint set \Delta as a pair (
o/, o/ 0)" and "the decomposition of a pair (o/, o/ 0) as a constraint set \Delta (o/, o/ 0)". These are preciselystated in definitions 8.1 and 8.2.

Definition 8.1 (From Constraint Sets to Constraint Pairs). The coding p\Delta q of a constraint set \Delta  ={

o/1 .= o/ 01, . . . , o/n .= o/ 0n} is the pair (o/, o/ 0) given by:

p\Delta q = (o/, o/ 0) = \Gamma  (o/1 ^ * * * ^ (o/n-1 ^ o/n)), (o/ 01 ^ * * * ^ (o/ 0n-1 ^ o/ 0n)) \Delta  .
To show that for a fixed k >= 0, an evaluation of UnifyFR(\Delta , k) terminates, we need to reason about therank of a constraint in a constraint set. The following definitions support this.

Definition 8.2 (*-Compatible Pairs). Let (o/, o/ 0) be a pair of types. We define its constraint decomposi-tion sequence

d(o/, o/ 0) = (', ^o/1, . . . , ^o/n, ^o/ 01, . . . , ^o/ 0n) with 1 + 2n entries, where ' 2 T2 with n >= 0 holes is thelargest (and therefore unique) type context such that

1. o/ = '[o/1, . . . , o/n] and o/ 0 = '[o/ 01, . . . , o/ 0n], where {o/i, o/ 0i} = {^o/i, ^o/ 0i } for every 1 <= i <= n.

47

Metavariable conventions:

* _ae 2 R!, ae 2 R, _oe, _oei 2 S!, oe 2 S, o/, o/ 0 2 T, e 2 E, ff 2 TVar, F 2 EVar.
Mode of operation:

* Initial call: UnifyFR(\Delta , k) ) UnifyFR(p\Delta q, {[ ]} , E-env(\Delta ), k) where k >= 0.*

Final call: UnifyFR\Gamma (o/, o/ ), S, E, k\Delta  ) S.*
UnifyFR\Gamma (o/0, o/ 00), S0, E, k\Delta  ) UnifyFR\Gamma (o/1, o/ 01), S1, E, k\Delta , provided:

- \Delta (o/0, o/ 00) = \Delta  [ ~F {ae .= oe} and ae .= oe ) S is an instance of one of the rewrite rules.
- (o/1, o/ 01) = (So/0, So/ 00) and S1 = S \Omega E S0 .
- rank(o/1) <= k and rank(o/ 01) <= k.

Rewrite rules:

ff .= _oe ) {[ff := _oe]} (rule 1)

_ae .= ff ) {[ff := _ae]} (rule 2)
F _ae .= e[_oe1, . . . , _oen] ) {[F := e]} (rule 3)

Applying substitutions to constraint sets:

* S? = ?.*

S({o/ .= o/0} [ \Delta ) = {So/ .= So/0} [ S\Delta .

Figure 7: Algorithm UnifyFR (every part other than "Mode of operation" is copied from figure 5).

2. For every 1 <= i <= n, if hole-rank(\Lambda (i), ') is even, then (o/i, o/ 0i ) = (^o/i, ^o/ 0i ).
3. For every 1 <= i <= n, if hole-rank(\Lambda (i), ') is odd, then (o/i, o/ 0i ) = (^o/ 0i , ^o/i).
If ~Gi = E-path(\Lambda (i), ') for 1 <= i <= n, then the constraint set decomposition of (o/, o/ 0) is:

\Delta (o/, o/ 0) = { ~G1(^o/1 .= ^o/ 01), . . . , ~Gn(^o/n .= ^o/ 0n)}.
If \Delta (o/, o/ 0) is a *-compatible constraint set, then we say that (o/, o/ 0) is a *-compatible pair. In this case, ^o/i 2 Rand ^

o/ 0i 2 S for 1 <= i <= n, so we can let ^o/i = aei and ^o/ 0i = oei for 1 <= i <= n and write \Delta (o/, o/ 0) in the form:

\Delta (o/, o/ 0) = { ~G1(ae1 .= oe1), . . . , ~Gn(aen .= oen)}.
Note that simplify\Gamma \Delta (o/, o/ 0)\Delta  = \Delta (o/, o/ 0), because d(o/, o/ 0) chooses the largest ' with the stated property. For
the same reason, note also that \Delta (o/, o/ ) = ?. We define the rank of constraint ~Gi(aei .= oei) in (o/, o/ 0):

rank\Gamma  ~Gi(aei .= oei), (o/, o/ 0)\Delta  = hole-rank(\Lambda (i), ').
We also define h(o/, o/ 0):

h(o/, o/ 0) = min{ hole-rank(\Lambda (i), ') 1 <= i <= n },
i.e., h(o/, o/ 0) is a lower bound on the L-distance of all the holes in ' from its root (viewed as a binary tree).If

o/ = o/ 0 = ', i.e., ' has 0 holes, we leave h(o/, o/ 0) undefined.

Definition 8.3 (Successful and Unsuccessful Evaluations of UnifyFR). Let \Delta  be a *-compatible con-straint set and

k >= 0. Consider a fixed, but otherwise arbitrary, evaluation of UnifyFR(\Delta , k):

UnifyFR\Gamma (o/0, o/ 00), {[ ]}, E, k\Delta  ) UnifyFR\Gamma (o/1, o/ 01), S1, E, k\Delta  ) * * * ) UnifyFR\Gamma (o/i, o/ 0i ), Si, E, k\Delta  ) * * * ,

48

where (o/0, o/ 00) = p\Delta q and E = E-env(\Delta ). We say this evaluation succeeds if it halts at the ith call with
o/i = o/ 0i , for some i >= 0, in which case it also returns the substitution Si.We say this evaluation of

UnifyFR(\Delta , k) fails if either it diverges or it halts at the ith call with o/i 6= o/ 0i ,for some
i >= 0. In the latter case, we also say that the evaluation halts unsuccessfully, which means that
o/i 6= o/ 0i and for all *-compatible pairs (o/, o/ 0) and all substitutions S,

UnifyFR\Gamma (o/i, o/ 0i ), Si, E, k\Delta  6) UnifyFR\Gamma (o/, o/ 0), S, E, k\Delta  ,
i.e., the evaluation is unable to continue beyond the ith call.
Definition 8.4 (Evaluating *-Compatible Pairs). Let (o/0, o/ 00) and (o/1, o/ 01) be *-compatible pairs. Letrule a be one of the 3 rules listed in figure 5. We write

(o/0, o/ 00) ==a) (o/1, o/ 01)
iff \Delta (o/0, o/ 00) = { ~G1(ae1 .= oe1), . . . , ~Gn(aen .= oen)} and there is i 2 {1, . . . , n} such that:

1. aei .= oei ) S is an instance of rule a.
2. (o/1, o/ 01) = (So/0, So/ 00).
In such a case, we say that (o/0, o/ 00) evaluates to, or reduces to, (o/1, o/ 01) by rule a using constraint ~Gi(aei .= oei).
Moreover, if rank\Gamma  ~Gi(aei .= oei), (o/0, o/ 00)\Delta  = k, we say that the constraint aei .= oei is at rank k and that theevaluation from (

o/0, o/ 00) to (o/1, o/ 01) is also at rank k, indicated by writing

(o/0, o/ 00) ===(a,k)) (o/1, o/ 01).

We write (o/0, o/ 00) ) (o/1, o/ 01) in case (o/0, o/ 00) ==a) (o/1, o/ 01) for some rule a, and =*=) for the reflexive transitive
closure of ). Let R ` {1, 2, 3}. Let (o/0, o/ 00) ) * * * ) (o/n, o/ 0n) be an evaluation sequence with n >= 1 steps.
We write (o/0, o/ 00) =n=R) (o/n, o/ 0n) to indicate that the evaluation has n steps, and that each step is carried out
using rule a for some a 2 R.Finally, if there is no pair (

o/1, o/ 01) such that (o/0, o/ 00) ==R) (o/1, o/ 01), then we say that the pair (o/0, o/ 00) is inR

-normal form.

Lemma 8.5 (Evaluating without Rule 3). Let R = {1, 2} and (o/0, o/ 00) a *-compatible pair. Then there
is a bound M (o/0, o/ 00) solely depending on (o/0, o/ 00) such that for every evaluation with R, say (o/0, o/ 00) =n=R) (o/1, o/ 01),
we have n <= M (o/0, o/ 00). In words, a diverging evaluation of (o/0, o/ 00) must use rule 3 infinitely many times.

Proof. Consider a single evaluation step (o/0, o/ 00) ==R) (o/1, o/ 01). Let \Delta 0 = \Delta (o/0, o/ 00). and \Delta 1 = \Delta (o/1, o/ 01).
Then TVar(\Delta 1) is a strict subset of TVar(\Delta 0). The desired bound M (o/0, o/ 00) is therefore the size of the set
TVar(\Delta 0).

Definition 8.6 (E-Redexes in *-Compatible Pairs). Let (o/, o/ 0) be a *-compatible pair and k >= 0. Wedefine the set of E-redexes of (

o/, o/ 0) at rank k as the following subset of the constraints in \Delta (o/, o/ 0):

E-redexes\Gamma (o/, o/ 0), k\Delta  = { ~G(F _ae .= oe) 2 \Delta (o/, o/ 0) rank\Gamma  ~G(F _ae .= oe), (o/, o/ 0)\Delta  = k } .
Lemma 8.7 (Ordering E-Redexes in *-Compatible Pairs). Let (o/, o/ 0) be a *-compatible pair and fixthe integer

k >= 0. Then we can list the constraints in E-redexes\Gamma (o/, o/ 0), k\Delta  in a particular order:

~G1(F1 _ae1 .= oe1) , ~G2(F2 _ae2 .= oe2) , . . . , ~Gn(Fn _aen .= oen)

such that for every 1 <= j <= n:

Fj 62 EVar( ~G1) [ * * * [ EVar( ~Gj-1) .
In particular, for j = n, we have Fn 62 EVar( ~G1) [ * * * [ EVar( ~Gn-1).

49

Proof. Let A = {F1, . . . , Fn} and B = EVar - A. If ~G 2 EVar*, we write ~G6B for the sequence in A* obtained
from ~G after erasing all E-variables in B. We define disjoint subsets A1, A2, A3, . . . of A as follows:

A1 = { F 2 EVar ~G(F _ae .= oe) 2 E-redexes\Gamma (o/, o/ 0), k\Delta  and ~G6B = " } .
If E-redexes\Gamma (o/, o/ 0), k\Delta  6= ?, then clearly A1 6= ?. For every i >= 1, define:

Ai+1 = { F 2 EVar ~G(F _ae .= ~Goe) 2 E-redexes\Gamma (o/, o/ 0), k\Delta  and ~G6B 2 A1 * * * Ai } .
This definition of A1, A2, A3, . . . is not circular, because \Delta (o/, o/ 0) is a *-compatible constraint set, implyingthat

E-path(F, \Delta (o/, o/ 0)) is uniquely defined without repeated entries, for every F 2 EVar. Because A isfinite, there is a smallest

p such that A = A1 [ * * * [ Ap. Moreover, by definition, if Ai+1 6= ? then Ai 6= ?.Hence, assuming
A 6= ?, we have a partition of A into p >= 1 disjoint (non-empty) subsets. We partitionE-redexes\Gamma (
o/, o/ 0), k\Delta  similarly, by defining a subset \Delta i of constraints, one for every i >= 1:

\Delta i = { ~G(F _ae .= oe) 2 E-redexes\Gamma (o/, o/ 0), k\Delta  F 2 Ai }
Clearly, E-redexes\Gamma (o/, o/ 0), k\Delta  = \Delta 1 [ * * * [ \Delta p. For every 1 <= i <= p, let Ai = {Fi,1, . . . , Fi,ni }. Thus, inparticular,

n = n1 + n2 + * * * + np. To conclude the proof, we assign a fixed but otherwise arbitrary order toeach \Delta 

i separately:

~Gi,1(Fi,1 _aei,1 .= oei,1) , . . . , ~Gi,ni (Fi,ni _aei,ni .= oei,ni ) .

The sequence 1, 2, . . . , n in the lemma statement is just the sequence (appropriately renamed):

(1, 1), . . . , (1, n1), (2, 1), . . . , (2, n2), . . . , (p, 1), . . . , (p, np) .
If ~G(F _ae .= oe) is in \Delta i, for some 1 <= i <= p, then E-path(F, \Delta (o/, o/ 0)) = ~G with | ~G6B| = i - 1 by construction.This, together with the fact that the E-path of a variable is uniquely defined and does not contain repeated
entries, implies that for all 1 <= j <= p and all 1 <= r <= nj it holds that

Fj,r 62 EVar( ~Gi,q)
where either i = j and 1 <= q < r, or 1 <= i < j and 1 <= q <= ni. The conclusion of the lemma follows.
Definition 8.8 (Conservative E-Redexes in *-Compatible Pairs). Let (o/, o/ 0) be a *-compatible pair,
k >= 0, and ~G(F _ae .= oe) be an E-redex of (o/, o/ 0) at rank k. We say ~G(F _ae .= oe) is conservative if its reductiondecreases the number of E-redexes at rank

k. Specifically, if there is a *-compatible pair (o/1, o/ 01) such that

(o/, o/ 0) ==3) (o/1, o/ 01) by reducing ~GF _ae .= ~Goe, then |E-redexes\Gamma (o/, o/ 0), k\Delta | > |E-redexes\Gamma (o/1, o/ 01), k\Delta |.

Lemma 8.9 (Conservative E-Redexes Exist). Let (o/, o/ 0) be a *-compatible pair and fix integer k >= 0.If E-redexes\Gamma (

o/, o/ 0), k\Delta  6= ?, then there is a constraint in E-redexes\Gamma (o/, o/ 0), k\Delta  which is conservative.

Proof. If there is exactly one constraint ~G(F _ae .= oe) in E-redexes\Gamma (o/, o/ 0), k\Delta , then the lemma conclusion is
readily verified: The reduction of ~G(F _ae .= oe) does not create E-redexes at rank k, although it may createE-redexes at ranks 6=

k. If E-redexes\Gamma (o/, o/ 0), k\Delta  contains n >= 2 constraints, say

~G1(F1 _ae1 .= oe1) , ~G2(F2 _ae2 .= oe2) , . . . , ~Gn(Fn _aen .= oen) ,

then, by lemma 8.7, they can be ordered so that Fn 62 EVar( ~G1) [ * * * [ EVar( ~Gn-1). The last constraint

~Gn(Fn _aen .= oen) in this list is a conservative E-redex at rank k.

Lemma 8.10 (Evaluating with Rule 3 at a Fixed Rank). Let R = {1, 2} as in lemma 8.5.Hypothesis: Let (

o/0, o/ 00) be a *-compatible pair in R-normal form, with k = h(o/0, o/ 00), and consider anarbitrary evaluation with the rules in R (with no rank restriction) and rule 3 restricted to conservative

E-redexes at rank k, i.e.,

50

(#) (o/0, o/ 00) ==a1) (o/1, o/ 01) ==a2) (o/2, o/ 02) ==a3) * * * ===ai) (o/i, o/ 0i ) ===ai+1) * * *
where for every i >= 1, either ai 2 R or ai = 3 and the step (o/i-1, o/ 0i-1) ==3) (o/i, o/ 0i ) is the result of reducing a
conservative E-redex at rank k.Conclusion: The evaluation shown in (#) cannot be infinite. Moreover, if (

o/i, o/ 0i ) cannot be evaluatedfurther, i.e., if (
o/i, o/ 0i ) is in R-normal form and in (3, k)-normal form (see definition 8.4), then either o/i = o/ 0ior
h(o/i, o/ 0i ) > k.

Proof. We assume E-redexes\Gamma (o/, o/ 0), k\Delta  6= ?, otherwise the conclusion follows immediately from lemma 8.5.For arbitrary

*-compatible pair (o/, o/ 0), define the measure:

P (o/, o/ 0) = |E-redexes\Gamma (o/, o/ 0), h(o/, o/ 0)\Delta | = the number of E-redexes of (o/, o/ 0) at rank h(o/, o/ 0).
We also define the measure N (o/, o/ 0) as follows:

N (o/, o/ 0) = i P (o/, o/ 0), size\Gamma \Delta (o/, o/ 0)\Delta j .
The size( ) function is given in definition 5.13. We use the lexicographic ordering on pairs of natural numbersand, relative to this ordering, we show that

N (o/, o/ 0) is strictly decreasing - provided also that the evaluationstarts from a
*-compatible pair (o/0, o/ 00) in R-normal form.If rule 1 or rule 2 is used, then

P (o/, o/ 0) does not change, but size\Gamma \Delta (o/, o/ 0)\Delta  decreases by at least 2. Ingeneral,
rule 1 and rule 2 can introduce new E-redexes, but these are necessarily at ranks strictly greaterthan
h(o/, o/ 0), because the evaluation under consideration starts at (o/0, o/ 00) in R-normal form.If

rule 3 is used, then P (o/, o/ 0) decreases by lemma 8.9, while in general size\Gamma \Delta (o/, o/ 0)\Delta  increases. Becausewe restrict

rule 3 to conservative E-redexes at rank h(o/, o/ 0), all new E-redexes are at ranks > h(o/, o/ 0).It follows that the measure

N (o/, o/ 0) is well-ordered, of order type !2. This implies the conclusion of thelemma.

Definition 8.11 (Rank-Increasing Evaluations). Let R = {1, 2}. Let (o/0, o/ 00) be a *-compatible pair.A rank-increasing evaluation of (

o/0, o/ 00) is of the form:

(o/0, o/ 00) =*=R) (o/1, o/ 01) =*=R1) (o/2, o/ 02) =*=R2) * * *
where (o/1, o/ 01) is in R-normal form and, for every i >= 1, if o/i 6= o/ 0i then Ri = R [ {(3, ki)} where ki = h(o/i, o/ 0i )and (

o/i+1, o/ 0i+1) is in Ri-normal form.

Lemma 8.12 (Rank-Increasing Evaluations Complete). Let \Delta  be a *-compatible constraint set, andlet (

o/, o/ 0) = p\Delta q. If a rank-increasing evaluation of (o/, o/ 0) diverges, then \Delta  has no solution.

Proof. A rank-increasing evaluation of (o/, o/ 0) induces an evaluation of Unify(\Delta ) such that, if the evaluationof (

o/, o/ 0) diverges, then the induced evaluation of Unify(\Delta ) also diverges. By lemma 5.11, if \Delta  has a solution,then every evaluation of

Unify(\Delta ) terminates. This implies the desired result.

Theorem 8.13 (Decidability of Finite-Rank Beta-Unification). Let \Delta  be a *-compatible constraintset and let

k be a fixed but otherwise arbitrary integer >= 1.

1. \Delta  has a solution of rank <= k if and only if there is a successful evaluation of UnifyFR(\Delta , k).
2. There is an evaluation of UnifyFR(\Delta , k) which terminates.
3. It is decidable whether \Delta  has a solution of rank <= k.

We purposely impose the restriction k 6= 0 because, if \Delta  has more than one constraint and p\Delta q = (o/, o/ 0),then

rank{o/, o/ 0} >= 1. In such a case, an evaluation of UnifyFR(\Delta , 0) always fails, even if \Delta  has a rank-0solution.

We conjecture part 2 of the theorem can be strengthened to: "Every evaluation of UnifyFR(\Delta , k) termi-nates". The conjecture will be settled if one proves that every evaluation of a

*-compatible pair (o/0, o/ 00) thatdiverges is rank-increasing; lemma 8.10 proves it for only a particular evaluation strategy.

51

Proof. For the left-to-right implication in part 1, suppose \Delta  has a solution. By theorem 5.16, Unify(\Delta ) =*=) S
for some substitution S, which is also a principal solution for \Delta . The evaluation Unify(\Delta ) =*=) S induces
an evaluation UnifyFR(\Delta , `) =*=) S for some ` >= 0. Let ` be the least integer such that UnifyFR(\Delta , `) =*=) S.Suppose

S is a rank-m solution for \Delta , with m >= 0. Because S is a principal solution for \Delta , every other
solution is of rank >= m. If m >= 1, it is easy to see that ` = m, which also implies that UnifyFR(\Delta , k) =*=) Sfor every

k >= m. (If m = 0 and \Delta  has more than one constraint, then ` = 1.)

For the right-to-left implication in part 1, suppose there is a successful evaluation UnifyFR(\Delta , k) =*=) S forsome

k >= 0, and suppose k is the least integer with this property. (We do not need to impose the restriction

k 6= 0 for this implication.) The evaluation UnifyFR(\Delta , k) =*=) S induces an evaluation Unify(\Delta ) =*=) S. Bytheorem 5.16,

S is a principal solution for \Delta . Moreover, if k = 0 or k >= 2, then S is a rank-k solution; andif
k = 1, then S is of rank <= k.We prove parts 2 and 3 of the theorem simultaneously. Let (

o/0, o/ 00) = p\Delta q and consider a rank-increasingevaluation of (
o/0, o/ 00) as specified in definition 8.11:

(o/0, o/ 00) =*=R) (o/1, o/ 01) =*=R1) (o/2, o/ 02) =*=R2) * * *
Such an evaluation of (o/0, o/ 00) always exists by lemma 8.10 and, depending on whether it diverges or not,there are two cases. In the first case, if the evaluation diverges, \Delta  has no solution by lemma 8.12 and,
moreover, there is n >= 1 such that kn > k where kn is given in definition 8.11. In this case, the inducedevaluation of

UnifyFR(\Delta , k) terminates unsuccessfully.In the second case, the evaluation of (

o/0, o/ 00) exhibited above terminates at (o/n, o/ 0n) with o/n = o/ 0n. Thereare two subcases, depending on whether

kn > k or not. In the first subcase, kn > k, it is clear that theinduced evaluation of
UnifyFR(\Delta , k) terminates unsuccessfully, corresponding to the fact that every solutionfor \Delta  has rank >=
kn > k. In the second subcase, kn <= k, the induced evaluation of UnifyFR(\Delta , k) terminatessuccessfully, corresponding to the fact that there is a rankkn principal solution for \Delta .

Corollary 8.14 (Decidability of Finite-Rank Typability). Let M be a *-term and let k >= 0. It isdecidable whether there is a rankk typing for M in system I.

Proof. For k <= 1, there is a typing for M of rank <= 1 iff M is simply-typable. For k >= 2, the result followsfrom theorems 7.9 and 8.13.

References
[AC98] R. Amadio and P.-L. Curien. Domains and Lambda Calculi, vol. 46 of Cambridge tracts intheoretical computer science. Cambridge University Press, 1998.

[Ban97] A. Banerjee. A modular, polyvariant, and type-based closure analysis. In Proc. 1997 Int'l Conf.Functional Programming. ACM Press, 1997.
[CDC80] M. Coppo and M. Dezani-Ciancaglini. An extension of the basic functionality theory for the

*-calculus. Notre Dame J. Formal Logic, 21(4):685-693, 1980.

[CDCV80] M. Coppo, M. Dezani-Ciancaglini, and B. Venneri. Principal type schemes and *-calculussemantics. In Hindley and Seldin [HS80], pp. 535-560.

[CDCV81] M. Coppo, M. Dezani-Ciancaglini, and B. Venneri. Functional characters of solvable terms. Z.Math. Logik Grundlag. Math., 27(1):45-58, 1981.
[CG92] M. Coppo and P. Giannini. A complete type inference algorithm for simple intersection types. In17th Colloq. Trees in Algebra and Programming, vol. 581 of LNCS, pp. 102-123. Springer-Verlag,

1992.
[DM82] L. Damas and R. Milner. Principal type schemes for functional programs. In Conf. Rec. 9thAnn. ACM Symp. Princ. of Prog. Langs., pp. 207-212, 1982.

52

[GJS96] J. Gosling, B. Joy, and G. Steele. The Java Language Specification. Addison Wesley, 1996.
[HS80] J. R. Hindley and J. P. Seldin, eds. To H. B. Curry: Essays on Combinatory Logic, LambdaCalculus, and Formalism. Academic Press, 1980.

[Jen98] T. Jensen. Inference of polymorphic and conditional strictness properties. In Conf. Rec. POPL'98: 25th ACM Symp. Princ. of Prog. Langs., 1998.
[Jim96] T. Jim. What are principal typings and what are they good for? In Conf. Rec. POPL '96: 23rdACM Symp. Princ. of Prog. Langs., 1996.
[JMZ92] B. Jacobs, I. Margaria, and M. Zacchi. Filter models with polymorphic types. Theoret. Comput.Sci., 95:143-158, 1992.
[Kfo96] A. J. Kfoury. Beta-reduction as unification. A refereed extensively edited version is [Kfo99].This preliminary version was presented at the Helena Rasiowa Memorial Conference, July 1996.
[Kfo99] A. J. Kfoury. Beta-reduction as unification. In D. Niwinski, ed., Logic, Algebra, and ComputerScience (H. Rasiowa Memorial Conference, December 1996), Banach Center Publication, Volume 46, pp. 137-158. Springer-Verlag, 1999. Supersedes [Kfo96] but omits a few proofs includedin the latter.

[KW94] A. J. Kfoury and J. B. Wells. A direct algorithm for type inference in the rank-2 fragment of thesecond-order

*-calculus. In Proc. 1994 ACM Conf. LISP Funct. Program., pp. 196-207, 1994.

[KW99] A. J. Kfoury and J. B. Wells. Principality and decidable type inference for finite-rank intersectiontypes. In Conf. Rec. POPL '99: 26th ACM Symp. Princ. of Prog. Langs., pp. 161-174, 1999.

Superseded by [KW02].
[KW02] A. J. Kfoury and J. B. Wells. Principality and type inference for intersection types usingexpansion variables. Supersedes [KW99] and contains proofs omitted in [KW0X], Aug. 2002.

[KW0X] A. J. Kfoury and J. B. Wells. Principality and type inference for intersection types usingexpansion variables. Theoret. Comput. Sci., 200X. Supersedes [KW99], omitted proofs included

in the full report [KW02]. Accepted subject to revisions.
[Lei83] D. Leivant. Polymorphic type inference. In Conf. Rec. 10th Ann. ACM Symp. Princ. of Prog.Langs., pp. 88-98, 1983.

[MTHM97] R. Milner, M. Tofte, R. Harper, and D. B. MacQueen. The Definition of Standard ML (Revised).MIT Press, 1997.
[Pie94] B. Pierce. Bounded quantification is undecidable. Inform. & Comput., 112:131-165, 1994.
[PJHH+93] S. L. Peyton Jones, C. Hall, K. Hammond, W. Partain, and P. Wadler. The Glasgow Haskellcompiler: A technical overview. In Proc. UK Joint Framework for Information Technology

(JFIT) Technical Conf., 1993.
[Pot80] G. Pottinger. A type assignment for the strongly normalizable *-terms. In Hindley and Seldin[HS80], pp. 561-577.

[RDR88] S. Ronchi Della Rocca. Principal type schemes and unification for intersection type discipline.Theoret. Comput. Sci., 59(1-2):181-209, Mar. 1988.
[RDRV84] S. Ronchi Della Rocca and B. Venneri. Principal type schemes for an extended type theory.Theoret. Comput. Sci., 28(1-2):151-169, Jan. 1984.
[Sal78] P. Sall'e. Une extension de la th'eorie des types en *-calcul. In G. Ausiello and C. B"ohm, eds.,Fifth International Conference on Automata, Languages and Programming, vol. 62 of LNCS,

pp. 398-410. Springer-Verlag, July 1978.

53

[SM96] 'E. Sayag and M. Mauny. A new presentation of the intersection type discipline through principaltypings of normal forms. Technical Report RR-2998, INRIA, Oct. 16, 1996.
[SM97] 'E. Sayag and M. Mauny. Structural properties of intersection types. In Proceedings of the 8th In-ternational Conference on Logic and Computer Science - Theoretical Foundations of Computing

(LIRA), pp. 167-175, Novi Sad, Yugoslavia, Sept. 1997.
[Urz97] P. Urzyczyn. Type reconstruction in F!. Math. Structures Comput. Sci., 7(4):329-358, 1997.
[vB93] S. J. van Bakel. Intersection Type Disciplines in Lambda Calculus and Applicative Term Rewrit-ing Systems. Ph.D. thesis, Catholic University of Nijmegen, 1993.

[Wel94] J. B. Wells. Typability and type checking in the second-order *-calculus are equivalent and un-decidable. In Proc. 9th Ann. IEEE Symp. Logic in Comput. Sci., pp. 176-185, 1994. Superseded

by [Wel99].
[Wel96] J. B. Wells. Typability is undecidable for F+eta. Tech. Rep. 96-022, Comp. Sci. Dept., BostonUniv., Mar. 1996.

[Wel99] J. B. Wells. Typability and type checking in System F are equivalent and undecidable. Ann.Pure Appl. Logic, 98(1-3):111-156, 1999. Supersedes [Wel94].
[Wel02] J. B. Wells. The essence of principal typings. In Proc. 29th Int'l Coll. Automata, Languages,and Programming, vol. 2380 of LNCS, pp. 913-925. Springer-Verlag, 2002.

A Complete Run of the Type-Inference Procedure
We revisit example 2.22, illustrating a run of the type-inference procedure in section 6. The *-term in this ex-ample is (

*x.*y.xy)(*z.zz). The steps presented below are obtained by running an actual implementation ofthe procedure, which is found at

http://www.church-project.org/modular/compositional-analysis/.(This is only one of several implementations available at the website, which are all developed in the context

of the compositional-analysis effort of the Church Project.) There are non-essential differences betweenthe initial and final skeletons below and those in example 2.22 for the same

*-expression; we follow theorganization in the "type-inference report" produced by the implementation at the forementioned website.

1. Initial typing judgement:

` (*x.*y.xy)(*z.zz) : ff6

2. Initial skeleton:

@ : ff6
*x : ff0
*y : F0ff1

@ : ff2
x : ff0 F0

y : ff1

F2
*z : ff3 ^ F1ff4

@ : ff5
z : ff3 F1

z : ff4

54

3. Initial constraint set:

{ ff0 .= F0 ff1 ! ff2,

F2 ff3 .= F2 (F1 ff4 ! ff5),
ff0 ! F0 ff1 ! ff2 .= F2 (ff3 ^ F1 ff4 ! ff5) ! ff6 }

4. Final substitution, obtained by running algorithm Unify in section 5 on the initial constraint set:

{[ ff0 := (F1 ff4 ! ff2) ^ F1 ff4 ! ff2,

ff01 := F1 ff4 ! ff2,
ff11 := ff4,
ff3 := F1 ff4 ! ff2,
ff5 := ff2,
ff6 := (F1 ff4 ! ff2) ^ F1 ff4 ! ff2,
F0 := \Lambda  ^ F1 \Lambda ,
F2 := \Lambda  ]}

5. Final skeleton, also a derivation, obtained by applying the final substitution to the initial skeleton:

@ : (F1ff4 ! ff2) ^ F1ff4 ! ff2
*x : (F1ff4 ! ff2) ^ F1ff4 ! ff2

*y : (F1ff4 ! ff2) ^ F1ff4

@ : ff2
x : (F1ff4 ! ff2) ^ F1ff4 ! ff2 ^

y : F1ff4 ! ff2 F1

y : ff4

*z : (F1ff4 ! ff2) ^ F1ff4

@ : ff2
z : F1ff4 ! ff2 F1

z : ff4

55