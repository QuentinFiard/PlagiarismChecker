

Advanced Topics in Types and Programming LanguagesAdvanced Topics in
Types and Programming Languages

Benjamin C. Pierce, editor

The MIT Press
Cambridge, Massachusetts
London, England

(C)2005 Massachusetts Institute of Technology
All rights reserved. No part of this book may be reproduced in any form by
any electronic of mechanical means (including photocopying, recording, or
information storage and retrieval) without permission in writing from the
publisher.

This book was set in Lucida Bright by the editor and authors using the LATEX
document preparation system.

Printed and bound in the United States of America.

Library of Congress CatalogingnginngPublication Data
Advanced Topics in Types and programming languages / Benjamin C. Pierce,
editor

p. cm.
Includes bibliographical references and index.
ISBN 0ng262ng16228ng8 (hc.: alk. paper)
1. Programming languages (Electronic computers). I. Pierce, Benjamin C.
QA76.7.A36 2005
005.13--dc22

200457123

10 9 8 7 6 5 4 3 2 1

Contents
Preface ix
I Precise Type Analyses 1
1 Substructural Type Systems 3

David Walker

1.1 Structural Properties 4
1.2 A Linear Type System 6
1.3 Extensions and Variations 17
1.4 An Ordered Type System 30
1.5 Further Applications 36
1.6 Notes 40

2 Dependent Types 45

David Aspinall and Martin Hofmann

2.1 Motivations 45
2.2 Pure FirstngOrder Dependent Types 50
2.3 Properties 54
2.4 Algorithmic Typing and Equality 56
2.5 Dependent Sum Types 61
2.6 The Calculus of Constructions 64
2.7 Relating Abstractions: Pure Type Systems 71
2.8 Programming with Dependent Types 74
2.9 Implementation of Dependent Types 83
2.10 Further Reading 86

vi Contents

3 Effect Types and RegionngBased Memory Management 87

Fritz Henglein, Henning Makholm, and Henning Niss

3.1 Introduction and Overview 87
3.2 Value Flow by Typing with Labels 90
3.3 Effects 102
3.4 RegionngBased Memory Management 106
3.5 The Tofte-Talpin Type System 114
3.6 Region Inference 123
3.7 More Powerful Models for RegionngBased Memory

Management 127
3.8 Practical RegionngBased Memory Management Systems 133

II Types for LowngLevel Languages 137
4 Typed Assembly Language 141

Greg Morrisett

4.1 TALng0: ControlngFlowngSafety 142
4.2 The TALng0 Type System 146
4.3 TALng1: Simple MemoryngSafety 155
4.4 TALng1 Changes to the Type System 161
4.5 Compiling to TALng1 164
4.6 Scaling to Other Language Features 167
4.7 Some Real World Issues 172
4.8 Conclusions 175

5 ProofngCarrying Code 177

George Necula

5.1 Overview of Proof Carrying Code 177
5.2 Formalizing the Safety Policy 182
5.3 VerificationngCondition Generation 187
5.4 Soundness Proof 199
5.5 The Representation and Checking of Proofs 204
5.6 Proof Generation 214
5.7 PCC beyond Types 216
5.8 Conclusion 219

Contents vii
III Types and Reasoning about Programs 221
6 Logical Relations and a Case Study in Equivalence Checking 223

Karl Crary

6.1 The Equivalence Problem 224
6.2 NonngTypengDirected Equivalence Checking 225
6.3 TypengDriven Equivalence 227
6.4 An Equivalence Algorithm 228
6.5 Completeness: A First Attempt 232
6.6 Logical Relations 233
6.7 A Monotone Logical Relation 236
6.8 The Main Lemma 237
6.9 The Fundamental Theorem 239
6.10 Notes 243

7 Typed Operational Reasoning 245

Andrew Pitts

7.1 Introduction 245
7.2 Overview 246
7.3 Motivating Examples 247
7.4 The Language 253
7.5 Contextual Equivalence 261
7.6 An Operationally Based Logical Relation 266
7.7 Operational Extensionality 279
7.8 Notes 288

IV Types for Programming in the Large 291
8 Design Considerations for MLngStyle Module Systems 293

Robert Harper and Benjamin C. Pierce

8.1 Basic Modularity 294
8.2 Type Checking and Evaluation of Modules 298
8.3 Compilation and Linking 302
8.4 Phase Distinction 305
8.5 Abstract Type Components 307
8.6 Module Hierarchies 317
8.7 Signature Families 320
8.8 Module Families 324
8.9 Advanced Topics 338
8.10 Relation to Some Existing Languages 341
8.11 History and Further Reading 343

viii Contents

9 Type Definitions 347

Christopher A. Stone

9.1 Definitions in the Typing Context 351
9.2 Definitions in Module Interfaces 358
9.3 Singleton Kinds 367
9.4 Notes 384

V Type Inference 387
10 The Essence of ML Type Inference 389

Franc,ois Pottier and Didier Re'my

10.1 What Is ML? 389
10.2 Constraints 407
10.3 HMD^XE^ 422
10.4 Constraint Generation 429
10.5 Type Soundness 434
10.6 Constraint Solving 438
10.7 From MLngthengCalculus to MLngthengLanguage 451
10.8 Rows 460

A Solutions to Selected Exercises 491
References 535
Index 567

Preface
Overview
Work in type systems for programming languages now touches many parts
of computer science, from language design and implementation to software
engineering, network security, databases, and analysis of concurrent and disng
tributed systems. The aim of this book, together with its predecessor, Types
and Programming Languages (Pierce [2002]--henceforth TAPL) is to offer a
comprehensive and accessible introduction to the area's central ideas, results,
and techniques. The intended audience includes graduate students and reng
searchers from other parts of computer science who want get up to speed in
the area as a whole, as well as current researchers in programming languages
who need comprehensible introductions to particular topics. Unlike TAPL, the
present volume is conceived not as a unified text, but as a collection of more
or less separate articles, authored by experts on their particular topics.

Required Background
Most of the material should be accessible to readers with a solid grasp of the
basic notations and techniques of operational semantics and type systems--
roughly, the first half of TAPL. Some chapters depend on more advanced
topics from the second half of TAPL or earlier chapters of the present volng
ume; these dependencies are indicated at the beginning of each chapter. Interng
chapter dependencies have been kept to a minimum to facilitate reading in
any order.

Topics
Precise Type Analyses The first three chapters consider ways of extending
simple type systems to give them a better grip on the run time behavior of

x Preface

programs. The first, Substructural Type Systems, by David Walker, surveys
type systems based on analogies with "substructural" logics such as linear
logic, in which one or more of the structural rules of conventional logics--
which allow dropping, duplicating, and permuting assumptions--are omitted
or allowed only under controlled circumstances. In substructural type sysng
tems, the type of a value is not only a description of its "shape," but also
a capability for using it a certain number of times; this refinement plays a
key role in advanced type systems being developed for a range of purposes,
including static resource management and analyzing deadlocks and livelocks
in concurrent systems. The chapter on Dependent Types, by David Aspinall
and Martin Hofmann, describes a yet more powerful class of type systems, in
which the behavior of computations on particular runngtime values (not just
generic "shapes") may be described at the type level. Dependent type sysng
tems blur the distinction between types and arbitrary correctness assertions,
and between typechecking and theorem proving. The power of full dependent
types has proved difficult to reconcile with language design desiderata such
as automatic typechecking and the "phase distinction" between compile time
and run time in compiled languages. Nevertheless, ideas of dependent typng
ing have played a fruitful role in language design and theory over the years,
offering a common conceptual foundation for numerous forms of "indexed"
type systems. Effect Types and RegionngBased Memory Management, by Fritz
Henglein, Henning Makholm, and Henning Niss, introduces yet another idea
for extending the reach of type systems: in addition to describing the shape
of an expression's result (a static abstraction of the possible values that the
expression may yield when evaluated), its type can also list a set of possible
"effects," abstracting the possible computational effects (mutations to the
store, input and output, etc.) that its evaluation may engender. Perhaps the
most sophisticated application of this idea has been in memory management
systems based on static "region inference," in which the effects manipulated
by the typechecker track the program's ability to read and write in particular
regions of the heap. For example, the ML Kit Compiler used a region analyng
sis internally to implement the full Standard ML language without a garbage
collector.

Types for LowngLevel Languages The next part of the book addresses anng
other research thrust that has generated considerable excitement over the
past decade: the idea of adapting type system technologies originally develng
oped for highnglevel languages to lownglevel languages such as assembly code
and virtual machine bytecode. Typed Assembly Language, by Greg Morrisett,
presents a lownglevel language with a type system based on the parametric
polymorphism of System F and discusses how to construct a typengpreserving

Preface xi
compiler from a highnglevel language, through a series of typed intermeding
ate languages, down to this typed assembly code. ProofngCarrying Code, by
George Necula, presents a more general formulation in a logical setting with
close ties to the dependent types described in Aspinall and Hofmann's chapng
ter. The strength of this presentation is that it offers a natural transition
from conventional type safety properties, such as memory safety, to more
general security properties. A driving application area for both approaches is
enforcing security guarantees when dealing with untrusted mobile code.

Types and Reasoning about Programs One attraction of rich type systems
is that they support powerful methods of reasoning about programs--not
only by compilers, but also by humans. One of the most useful, the techng
nique of logical relations, is introduced in the chapter Logical Relations and a
Case Study in Equivalence Checking, by Karl Crary. The extended example--
proving the correctness of an algorithm for deciding a typengsensitive behavng
ioral equivalence relation on terms in the simply typed lambdangcalculus with
a Unit type--foreshadows ideas developed further in Christopher Stone's
chapter on type definitions. Typed Operational Reasoning, by Andrew Pitts,
develops a more general theory of typed reasoning about program equivng
alence. Here the examples focus on proving representation independence
properties for abstract data types in the setting of a rich language combinng
ing the universal and existential polymorphism of System F with records and
recursive function definitions.

Types for Programming in the Large One of the most important projects
in language design over the past decade and more has been the use of typeng
theory as a framework for the design of sophisticated module systems--
languages for assembling large software systems from modular components.
One highly developed line of work is embodied in the module systems found
in modern ML dialects. Design Considerations for MLngStyle Module Systems,
by Robert Harper and Benjamin C. Pierce, offers an informal guided tour of
the principal features of this class of module systems--a "big picture" introng
duction to a large but highly technical body of papers in the research literang
ture. Type Definitions, by Christopher A. Stone, addresses the most critical
and technically challenging feature of the type systems on which MLngstyle
module systems are founded: singleton kinds, which allow type definitions to
be internalized rather than being treated as metanglevel abbreviations.

Type Inference The ML family of languages--including Standard ML, Objecng
tive Caml, and Moscow ML, as well as more distant relatives such as Haskell--

xii Preface

has for decades been a showcase for advances in typed language design and
compiler implementation, and for the advantages of software construction in
richly typed languages. One of the main reasons for the success of these lanng
guages is the combination of power and convenience offered by their type
inference (or type reconstruction) algorithms. Basic ML type inference has
been described in many places, but descriptions of the more advanced techng
niques used in production compilers for fullngblown languages have until now
been widely dispersed in the literature, when they were available at all. In
The Essence of ML Type Inference, Franc,ois Pottier and Didier Re'my offer a
comprehensive, unified survey of the area.

Exercises
Most chapters include numerous exercises. The estimated difficulty of each
exercise is indicated using the following scale:

n' Quick check 30 seconds to 5 minutes
n'n' Easy <= 1 hour
n'n'n' Moderate <= 3 hours
n'n'n'n' Challenging > 3 hours

Exercises marked n' are intended as realngtime checks of important concepts.
Readers are strongly encouraged to pause for each one of these before movng
ing on to the material that follows. Some of the most important exercises are
labeled Recommended.

Solutions to most of the exercises are provided in Appendix A. To save
readers searching for solutions to exercises for which solutions are not availng
able, these are marked 3.

Electronic Resources
Additional materials associated with this book can be found at:

http://www.cis.upenn.edu/~bcpierce/attapl
Resources available on this site will include errata for the text, pointers to
supplemental material contributed by readers, and implementations associng
ated with various chapters.

Acknowledgments
Many friends and colleagues have helped to improve the chapters as they
developed. We are grateful to Amal Ahmed, Lauri Alanko, Jonathan Aldrich,

Preface xiii
Derek Dreyer, Matthias Felleisen, Robby Findler, Kathleen Fisher, Nadji Gaung
thier, Michael Hicks, Steffen Jost, Xavier Leroy, William Lovas, Kenneth Macng
Kenzie, Yitzhak Mandelbaum, Martin Mu"ller, Simon Peyton Jones, Norman
Ramsey, Yann Re'gisngGianas, Fermin Reig, Don Sannella, Alan Schmitt, Peter
Sewell, Vincent Simonet, Eijiro Sumii, David Swasey, Joe Vanderwaart, Yanling
Wang, Keith Wansbrough, Geoffrey Washburn, Stephanie Weirich, Dinghao
Wu, and Karen Zee for helping to make this a much better book than we could
have done alone. Stephanie Weirich deserves a particularly warm round of
thanks for numerous and incisive comments on the whole manuscript. Nate
Foster's assistance with copy editing, typesetting, and indexing contributed
enormously to the book's final shape.

The work described in many chapters was supported in part by grants from
the National Science Foundation. The opinions, findings, conclusions, or recng
ommendations expressed in these chapters are those of the author(s) and do
not necessarily reflect the views of the NSF.

P a r t I
Precise Type Analyses
1 Substructural Type Systems

David Walker

Advanced type systems make it possible to restrict access to data structures
and to limit the use of newlyngdefined operations. Oftentimes, this sort of
access control is achieved through the definition of new abstract types under
control of a particular module. For example, consider the following simplified
file system interface.

type file

val open : string ! file option
val read : file ! string * file
val append : file * string ! file
val write : file * string ! file
val close : file ! unit

By declaring that the type file is abstract, the implementer of the module
can maintain strict control over the representation of files. A client has no way
to accidentally (or maliciously) alter any of the file's representation invariants.
Consequently, the implementer may assume that the invariants that he or
she establishes upon opening a file hold before any read, append, write or
close.

While abstract types are a powerful means of controlling the structure of
data, they are not sufficient to limit the ordering and number of uses of funcng
tions in an interface. Try as we might, there is no (static) way to prevent a
file from being read after it has been closed. Likewise, we cannot stop a client
from closing a file twice or forgetting to close a file.

This chapter introduces substructural type systems, which augment stanng
dard type abstraction mechanisms with the ability to control the number and
order of uses of a data structure or operation. Substructural type systems are
particularly useful for constraining interfaces that provide access to system

4 1 Substructural Type Systems

resources such as files, locks and memory. Each of these resources undergoes
a series of changes of state throughout its lifetime. Files, as we have seen, may
be open or closed; locks may be held or not; and memory may be allocated or
deallocated. Substructural type systems provide sound static mechanisms for
keeping track of just these sorts of state changes and preventing operations
on objects in an invalid state.

The bulk of this chapter will focus on applications of substructural type
systems to the control of memory resources. Memory is a pervasive resource
that must be managed carefully in any programming system so it makes an
excellent target of study. However, the general principles that we establish
can be applied to other sorts of resources as well.

1.1 Structural Properties

Most of the type systems in this book allow unrestricted use of variables in the
type checking context. For instance, each variable may be used once, twice,
three times, or not at all. A precise analysis of the properties of such variables
will suggest a whole new collection of type systems.

To begin our exploration, we will analyze the simplyngtyped lambda calcung
lus, which is reviewed in Figure 1ng1. In this discussion, we are going to be
particularly careful when it comes to the form of the typengchecking context \Gamma  .
We will consider such contexts to be simple lists of variablengtype pairs. The
"," operator appends a pair to the end of the list. We also write (\Gamma 1; \Gamma 2) for
the list that results from appending \Gamma 2 onto the end of \Gamma 1. As usual, we alng
low a given variable to appear at most once in a context and to maintain this
invariant, we implicitly alphangconvert bound variables before entering them
into the context.

We are now in position to consider three basic structural properties satng
isfied by our simplyngtyped lambda calculus. The first property, exchange,
indicates that the order in which we write down variables in the context is
irrelevant. A corollary of exchange is that if we can type check a term with
the context \Gamma  , then we can type check that term with any permutation of the
variables in \Gamma  . The second property, weakening, indicates that adding extra,
unneeded assumptions to the context, does not prevent a term from type
checking. Finally, the third property, contraction, states that if we can type
check a term using two identical assumptions (x2:T1 and x3:T1) then we can
check the same term using a single assumption.

1.1.1 Lemma [Exchange]: If \Gamma 1; x1:T1; x2:T2; \Gamma 2 ` t : T then

\Gamma 1; x2:T2; x1:T1; \Gamma 2 ` t : T 2

1.1.2 Lemma [Weakening]: If \Gamma 1; \Gamma 2 ` t : T then \Gamma 1; x1:T1; \Gamma 2 ` t : T 2

1.1 Structural Properties 5
Syntax

b ::= booleans:

true true
false false
t ::= terms:

x variable
b boolean
if t then t else t conditional
*x:T.t abstraction
t t application
T ::= types:

Bool booleans
T!T type of functions
\Gamma  ::= contexts:

; empty context
\Gamma  ; x:T term variable binding

Typing \Gamma  ` t : T

\Gamma 1; x:T; \Gamma 2 ` x : T (TngVar)

\Gamma  ` b : Bool (TngBool)
\Gamma  ` t1 : Bool \Gamma  ` t2 : T \Gamma  ` t3 : T

\Gamma  ` if t1 then t2 else t3 : T

(TngIf)
\Gamma  ; x:T1 ` t2 : T2

\Gamma  ` *x:T1.t2 : T1!T2 (TngAbs)
\Gamma  ` t1 : T11!T12 \Gamma  ` t2 : T11

\Gamma  ` t1 t2 : T12 (TngApp)

Figure 1ng1: Simplyngtyped lambda calculus with booleans

1.1.3 Lemma [Contraction]: If \Gamma 1; x2:T1; x3:T1; \Gamma 2 ` t : T2 then

\Gamma 1; x1:T1; \Gamma 2 ` E,x2 , x1G*E,x3 , x1G*t : T2 2

1.1.4 Exercise [Recommended, n']: Prove that exchange, weakening and contracng

tion lemmas hold for the simplyngtyped lambda calculus. 2

A substructural type system is any type system that is designed so that one
or more of the structural properties do not hold. Different substructural type
systems arise when different properties are withheld.

* Linear type systems ensure that every variable is used exactly once by

allowing exchange but not weakening or contraction.

* Affine type systems ensure that every variable is used at most once by

allowing exchange and weakening, but not contraction.

* Relevant type systems ensure that every variable is used at least once by

allowing exchange and contraction, but not weakening.

* Ordered type systems ensure that every variable is used exactly once and

in the order in which it is introduced. Ordered type systems do not allow
any of the structural properties.

6 1 Substructural Type Systems

The picture below can serve as a mnemonic for the relationship between
these systems. The system at the bottom of the diagram (the ordered type sysng
tem) admits no structural properties. As we proceed upwards in the diagram,
we add structural properties: E stands for exchange; W stands for weakening;
and C stands for contraction. It might be possible to define type systems conng
taining other combinations of structural properties, such as contraction only
or weakening only, but so far researchers have not found applications for
such combinations. Consequently, we have excluded them from the diagram.

ordered (none)

linear (E)
affine (E,W) relevant (E,C)

unrestricted (E,W,C)

The diagram can be realized as a relation between the systems. We say system
q1 is more restrictive than system q2 and write q1vq2 when system q1 exhibits
fewer structural rules than system q2. Figure 1ng2 specifies the relation, which
we will find useful in the coming sections of this chapter.

1.2 A Linear Type System

In order to safely deallocate data, we need to know that the data we deallong
cate is never used in the future. Unfortunately, we cannot, in general, deduce
whether data will be used after execution passes a certain program point: The
problem is clearly undecidable. However, there are a number of sound, but
useful approximate solutions. One such solution may be implemented using
a linear type system. Linear type systems ensure that objects are used exactly
once, so it is completely obvious that after the use of an object, it may be
safely deallocated.

1.2 A Linear Type System 7
q ::= system:

ord ordered
lin linear
rel relevant
aff affine
un unrestricted

ord v lin (QngOrdLin)
lin v rel (QngLinRel)
lin v aff (QngLinAff)

rel v un (QngRelUn)
aff v un (QngAffUn)

q v q (QngReflex)
q1 v q2 q2 v q3

q1 v q3 (QngTrans)

Figure 1ng2: A relation between substructural type systems

Syntax
Figure 1ng3 presents the syntax of our linear language, which is an extension
of the simplyngtyped lambda calculus. The main addition to be aware of, at
this point, are the type qualifiers q that annotate the introduction forms for
all data structures. The linear qualifier (lin) indicates that the data structure
in question will be used (i.e., appear in the appropriate elimination form) exng
actly once in the program. Operationally, we deallocate these linear values
immediately after they are used. The unrestricted qualifier (un) indicates that
the data structure behaves as in the standard simplyngtyped lambda calculus.
In other words, unrestricted data can be used as many times as desired and
its memory resources will be automatically recycled by some extranglinguistic
mechanism (a conventional garbage collector).

Apart from the qualifiers, the only slightly unusual syntactic form is the
elimination form for pairs. The term split t1 as x,y in t2 projects the first
and second components from the pair t1 and calls them x and y in t2. This
split operation allows us to extract two components while only counting
a single use of a pair. Extracting two components using the more convenng
tional projections ss 1 t1 and ss2 t1 requires two uses of the pair t1. (It is also
possible, but a bit tricky, to provide the conventional projections.)

To avoid dealing with an unnecessarily heavy syntax, we adopt a couple
abbreviations in our examples in this section. First, we omit all unrestricted
qualifiers and only annotate programs with the linear ones. Second, we freely
use nngary tuples (triples, quadruples, unit, etc.) in addition to pairs and also
allow multingargument functions. The latter may be defined as singlengargument
functions that take linear pairs (triples, etc) as arguments and immediately
split them upon entry to the function body. Third, we often use MLngstyle type

8 1 Substructural Type Systems

Syntax

q ::= qualifiers:

lin linear
un unrestricted
b ::= booleans:

true true
false false
t ::= terms:

x variable
q b boolean
if t then t else t conditional
q <t,t> pair

split t as x,y in t split
q *x:T.t abstraction
t t application
P ::= pretypes:

Bool booleans
T*T pairs
T!T functions
T ::= types:

q P qualified pretype
\Gamma  ::= contexts:

; empty context
\Gamma  ; x:T term variable binding

Figure 1ng3: Linear lambda calculus: Syntax

declarations, value declarations and let expressions where convenient; they
all have the obvious meanings.

Typing
To ensure that linear objects are used exactly once, our type system maintains
two important invariants.

1. Linear variables are used exactly once along every controlngflow path.
2. Unrestricted data structures may not contain linear data structures. More

generally, data structures with less restrictive type may not contain data
structures with more restrictive type.

To understand why these invariants are useful, consider what could hapng
pen if either invariant is broken. When considering the first invariant, asng
sume we have constructed a function free that uses its argument and then
deallocates it. Now, if we allow a linear variable (say x) to appear twice, a
programmer might write <free x,free x>, or, slightly more deviously,

(*z.*y.<free z,free y>) x x.
In either case, the program ends up attempting to use and then free x after it
has already been deallocated, causing the program to crash.

Now consider the second invariant and suppose we allow a linear data
structure (call it x) to appear inside an unrestricted pair (un <x,3>). We can

1.2 A Linear Type System 9
Context Split \Gamma  C^ \Gamma 1 ffi \Gamma 2

; C^ ; ffi ; (MngEmpty)

\Gamma  C^ \Gamma 1 ffi \Gamma 2
\Gamma  ; x:un P C^ D^\Gamma 1; x:un PE^ ffi D^\Gamma 2; x:un PE^ (MngUn)

\Gamma  C^ \Gamma 1 ffi \Gamma 2
\Gamma  ; x:lin P C^ D^\Gamma 1; x:lin PE^ ffi \Gamma 2 (MngLin1)

\Gamma  C^ \Gamma 1 ffi \Gamma 2
\Gamma  ; x:lin P C^ \Gamma 1 ffi D^\Gamma 2; x:lin PE^ (MngLin2)

Figure 1ng4: Linear lambda calculus: Context splitting

get exactly the same effect as above by using the unrestricted data structure
multiple times:

let z = un <x,3> in
split z as x1,_ in
split z as x2,_ in
<free x1,free x2>

Fortunately, our type system ensures that none of these situations can occur.

We maintain the first invariant through careful context management. When
type checking terms with two or more subterms, we pass all of the unreng
stricted variables in the context to each subterm. However, we split the linear
variables between the different subterms to ensure each variable is used exng
actly once. Figure 1ng4 defines a relation, \Gamma  C^ \Gamma 1 ffi \Gamma 2, which describes how to
split a single context in a rule conclusion (\Gamma  ) into two contexts (\Gamma 1 and \Gamma 2) that
will be used to type different subterms in a rule premise.

To check the second invariant, we define the predicate q(T) (and its extenng
sion to contexts q(\Gamma  )) to express the types T that can appear in a qngqualified
data structure. These containment rules state that linear data structures can
hold objects with linear or unrestricted type, but unrestricted data structures
can only hold objects with unrestricted type.

* q(T) if and only if T = q0 P and qvq0

* q(\Gamma  ) if and only if D^x:TE^ 2 \Gamma  implies qD^TE^
Recall, we have already defined qvq0 such that it is reflexive, transitive and
linvun.

Now that we have defined the rules for containment and context splitting,
we are ready for the typing rules proper, which appear in Figure 1ng5. Keep in
mind that these rules are constructed anticipating a callngbyngvalue operational
semantics.

It is often the case when designing a type system that the rules for the
base cases, variables and constants, are hardly worth mentioning. However,

10 1 Substructural Type Systems

Typing \Gamma  ` t : T

un D^\Gamma 1; \Gamma 2E^
\Gamma 1; x:T; \Gamma 2 ` x : T (TngVar)

un D^\Gamma  E^
\Gamma  ` q b : q Bool (TngBool)

\Gamma 1 ` t1 : q Bool
\Gamma 2 ` t2 : T \Gamma 2 ` t3 : T

\Gamma 1 ffi \Gamma 2 ` if t1 then t2 else t3 : T (TngIf)

\Gamma 1 ` t1 : T1 \Gamma 2 ` t2 : T2

q(T1) q(T2)

\Gamma 1 ffi \Gamma 2 ` q <t1,t2> : q (T1*T2) (TngPair)

\Gamma 1 ` t1 : q (T1*T2)
\Gamma 2; x:T1; y:T2 ` t2 : T

\Gamma 1 ffi \Gamma 2 ` split t1 as x,y in t2 : T (TngSplit)

qD^\Gamma  E^ \Gamma  ; x:T1 ` t2 : T2
\Gamma  ` q *x:T1.t2 : q T1!T2 (TngAbs)
\Gamma 1 ` t1 : q T11!T12 \Gamma 2 ` t2 : T11

\Gamma 1 ffi \Gamma 2 ` t1 t2 : T12 (TngApp)

Figure 1ng5: Linear lambda calculus: Typing

in substructural type systems these cases have a special role in defining the
nature of the type system, and subtle changes can make all the difference.
In our linear system, the base cases must ensure that no linear variable is
discarded without being used. To enforce this invariant in rule (TngVar), we
explicitly check that \Gamma 1 and \Gamma 2 contain no linear variables using the condition
un D^\Gamma 1; \Gamma 2E^. We make a similar check in rule (TngBool). Notice also that rule (Tng
Var) is written carefully to allow the variable x to appear anywhere in the
context, rather than just at the beginning or at the end.

1.2.1 Exercise [n']: What is the effect of rewriting the variable rule as follows?

un D^\Gamma  E^
\Gamma  ; x:T ` x : T (TngBrokenVar)

The inductive cases of the typing relation take care to use context splitting
to partition linear variables between various subterms. For instance, rule (Tng
If) splits the incoming context into two parts, one of which is used to check
subterm t1 and the other which is used to check both t2 and t3. As a result,
a particular linear variable will occur once in t2 and once in t3. However, the
linear object bound to the variable in question will be used (and hence deng
allocated) exactly once at run time since only one of t2 or t3 will be executed.

The rules for creation of pairs and functions make use of the containment
rules. In each case, the data structure's qualifier q is used in the premise of
the typing rule to limit the sorts of objects it may contain. For example, in the
rule (TngAbs), if the qualifier q is un then the variables in \Gamma  , which will inhabit
the function closure, must satisfy un D^\Gamma  E^. In other words, they must all have

1.2 A Linear Type System 11
unrestricted type. If we omitted this constraint, we could write the followng
ing badly behaved functions. (For clarity, we have retained the unrestricted
qualifiers in this example rather than omitting them.)

type T = un (un bool ! lin bool)

val discard =

lin *x:lin bool.

(lin *f:T.lin true) (un *y:un bool.x)

val duplicate =

lin *x:lin bool.

(lin *f:T.lin <f (un true),f (un true)>)) (un *y:un bool.x)

The first function discards a linear argument x without using it and the secng
ond duplicates a linear argument and returns two copies of it in a pair. Hence,
in the first case, we fail to deallocate x and in the second case, a subsequent
function may project both elements of the pair and use x twice, which would
result in a memory error as x would be deallocated immediately after the first
use. Fortunately, the containment constraint disallows the linear variable x
from appearing in the unrestricted function (*y:bool. x).

Now that we have defined our type system, we should verify our intended
structural properties: exchange for all variables, and weakening and contracng
tion for unrestricted variables.

1.2.2 Lemma [Exchange]: If \Gamma 1; x1:T1; x2:T2; \Gamma 2 ` t : T then

\Gamma 1; x2:T2; x1:T1; \Gamma 2 ` t : T. 2

1.2.3 Lemma [Unrestricted Weakening]: If \Gamma  ` t : T then

\Gamma  ; x1:un P1 ` t : T. 2

1.2.4 Lemma [Unrestricted Contraction]:

If \Gamma  ; x2:un P1; x3:un P1 ` t : T3 then
\Gamma  ; x1:un P1 ` E,x2 , x1G*E,x3 , x1G*t : T3. 2

Proof: The proofs of all three lemmas follow by induction on the structure
of the appropriate typing derivation. 2

Algorithmic Linear Type Checking
The inference rules provided in the previous subsection give a clear, conng
cise specification of the linearlyngtyped programs. However, these rules are
also highly nonngdeterministic and cannot be implemented directly. The pring
mary difficulty is that to implement the nonngdeterministic splitting operation,

12 1 Substructural Type Systems

Algorithmic Typing \Gamma in ` t : T;\Gamma out
\Gamma 1; x:un P; \Gamma 2 ` x : un P;\Gamma 1; x:un P; \Gamma 2

(AngUVar)

\Gamma 1; x:lin P; \Gamma 2 ` x : lin P;\Gamma 1; \Gamma 2 (AngLVar)

\Gamma  ` q b : q Bool;\Gamma  (AngBool)
\Gamma 1 ` t1 : q Bool;\Gamma 2
\Gamma 2 ` t2 : T;\Gamma 3 \Gamma 2 ` t3 : T;\Gamma 3

\Gamma 1 ` if t1 then t2 else t3 : T;\Gamma 3 (AngIf)

\Gamma 1 ` t1 : T1;\Gamma 2 \Gamma 2 ` t2 : T2;\Gamma 3

q(T1) q(T2)

\Gamma 1 ` q <t1,t2> : q (T1*T2);\Gamma 3 (AngPair)

\Gamma 1 ` t1 : q (T1*T2);\Gamma 2
\Gamma 2; x:T1; y:T2 ` t2 : T;\Gamma 3

\Gamma 1 ` split t1 as x,y in t2 :

T;\Gamma 3 / (x:T1; y:T2)

(AngSplit)

q=un ) \Gamma 1 C^ \Gamma 2 / (x:T1)

\Gamma 1; x:T1 ` t2 : T2;\Gamma 2

\Gamma 1 ` q *x:T1.t2 : q T1!T2;\Gamma 2 / (x:T1)

(AngAbs)

\Gamma 1 ` t1 : q T11!T12;\Gamma 2 \Gamma 2 ` t2 : T11;\Gamma 3

\Gamma 1 ` t1 t2 : T12;\Gamma 3

(AngApp)

Figure 1ng6: Linear lambda calculus: Algorithmic type checking

\Gamma  C^ \Gamma 1 ffi \Gamma 2, we must guess how to split an input context \Gamma  into two parts. Forng
tunately, it is relatively straightforward to restructure the type checking rules
to avoid having to make these guesses. This restructuring leads directly to a
practical type checking algorithm.

The central idea is that rather than splitting the context into parts before
checking a complex expression composed of several subexpressions, we can
pass the entire context as an input to the first subexpression and have it
return the unused portion as an output. This output may then be used to
check the next subexpression, which may also return some unused portions
of the context as an output, and so on. Figure 1ng6 makes these ideas concrete.
It defines a new algorithmic type checking judgment with the form \Gamma in `
t : T;\Gamma out, where \Gamma in is the input context, some portion of which will be
consumed during type checking of t, and \Gamma out is the output context, which
will be synthesized alongside the type T.

There are several key changes in our reformulated system. First, the base
cases for variables and constants allow any context to pass through the judgng
ment rather than restricting the number of linear variables that appear. In
order to ensure that linear variables are used, we move these checks to the
rules where variables are introduced. For instance, consider the rule (AngSplit).
The second premise has the form

\Gamma 2; x:T1; y:T2 ` t2 : T;\Gamma 3
If T1 and T2 are linear, then they should be used in t2 and should not appear
in \Gamma 3. Conversely, T1 and T2 are unrestricted, then they will always appear

1.2 A Linear Type System 13
in \Gamma 3, but we should delete them from the final outgoing context of the rule
so that the ordinary scoping rules for the variables are enforced. To handle
both the check that linear variables do not appear and the removal of unreng
stricted variables, we use a special "context difference" operator (/). Using
this operator, the final outgoing context of the rule (AngSplit) is defined to be
\Gamma 3 / (x:T1; y:T2). Formally, context difference is defined as follows.

\Gamma  / ; C^ \Gamma 
\Gamma 1 / \Gamma 2 C^ \Gamma 3 (x:lin P) 62 \Gamma 3

\Gamma 1 / D^\Gamma 2; x:lin PE^ C^ \Gamma 3

\Gamma 1 / \Gamma 2 C^ \Gamma 3 \Gamma 3 C^ \Gamma 4; x:un P; \Gamma 5

\Gamma 1 / D^\Gamma 2; x:un PE^ C^ \Gamma 4; \Gamma 5
Notice that this operator is undefined when we attempt to take the difng
ference of two contexts, \Gamma 1 and \Gamma 2, that contain bindings for the same linear
variable (x:lin P). If the undefined quotient \Gamma 1 / \Gamma 2 were to appear anywhere
in a typing rule, the rule itself would not be considered defined and could not
be part of a valid typing derivation.

The rule for abstraction (AngAbs) also introduces a variable and hence it also
uses context difference to manipulate the output context for the rule. Abng
stractions must also satisfy the appropriate containment conditions. In other
words, rule (AngAbs) must check that unrestricted functions do not contain
linear variables. We perform this last check by verifying that when the funcng
tion qualifier is unrestricted, the input and output contexts from checking the
function body are the same. This equivalence check is sufficient because if a
linear variable was used in the body of an unrestricted function (and hence
captured in the function closure), that linear variable would not show up in
the outgoing context.

It is completely straightforward to check that every rule in our algorithmic
system is syntax directed and that all our auxiliary functions including conng
text membership tests and context difference are easily computable. Hence,
we need only show that our algorithmic system is equivalent to the simpler
and more elegant declarative system specified in the previous section. The
proof of equivalence can be a broken down into the two standard compong
nents: soundness and completeness of the algorithmic system with respect to
the declarative system. However, before we can get to the main results, we
will need to show that our algorithmic system satisfies some basic structural
properties of its own. In the following lemmas, we use the notation LD^\Gamma  E^ and
UD^\Gamma  E^ to refer to the list of linear and unrestricted assumptions in \Gamma  respecng
tively.

14 1 Substructural Type Systems

1.2.5 Lemma [Algorithmic Monotonicity]: If \Gamma  ` t : T;\Gamma  0 then UD^\Gamma  0E^ C^ UD^\Gamma  E^

and LD^\Gamma  0E^ ` LD^\Gamma  E^. 2

1.2.6 Lemma [Algorithmic Exchange]: If \Gamma 1; x1:T1; x2:T2; \Gamma 2 ` t : T;\Gamma 3 then

\Gamma 1; x2:T2; x1:T1; \Gamma 2 ` t : T;\Gamma  03 and \Gamma 3 is the same as \Gamma  03 up to transposition of
the bindings for x1 and x2. 2

1.2.7 Lemma [Algorithmic Weakening]: If \Gamma  ` t : T;\Gamma  0 then \Gamma  ; x:T0 ` t : T;

\Gamma  0; x:T0. 2

1.2.8 Lemma [Algorithmic Linear Strengthening]: If \Gamma  ; x:lin P ` t : T;

\Gamma  0; x:lin P then \Gamma  ` t : T;\Gamma  0. 2

Each of these lemmas may be proven directly by induction on the initial
typing derivation. The algorithmic system also satisfies a contraction lemma,
but since it will not be necessary in the proofs of soundness and completeng
ness, we have not stated it here.

1.2.9 Theorem [Algorithmic Soundness]: If \Gamma 1 ` t : T;\Gamma 2 and LD^\Gamma 2E^ C^ ; then

\Gamma 1 ` t : T. 2

Proof: As usual, the proof is by induction on the typing derivation. The strucng
tural lemmas we have just proven are required to push through the result, but
it is mostly straightforward. 2

1.2.10 Theorem [Algorithmic Completeness]: If \Gamma 1 ` t : T then \Gamma 1 ` t : T;\Gamma 2

and LD^\Gamma 2E^ C^ ;. 2

Proof: The proof is by induction on the typing derivation. 2

Operational Semantics
To make the memory management properties of our language clear, we will
evaluate terms in an abstract machine with an explicit store. As indicated in
Figure 1ng7, stores are a sequence of variablengvalue pairs. We will implicitly
assume that any variable appears at most once on the leftnghand side of a pair
so the sequence may be treated as a finite partial map.

A value is a pair of a qualifier together with some data (a prevalue w). For
the sake of symmetry, we will also assume that all values are stored, even
base types such as booleans. As a result, both components of any pair will be
pointers (variables).

We define the operation of our abstract machine using a contextngbased,
smallngstep semantics. Figure 1ng7 defines the computational contexts E, which

1.2 A Linear Type System 15
w ::= prevalues:

b boolean
<x,y> pair
*x:T.t abstraction
v ::= values:

q w qualified prevalue
S ::= stores:

; empty context
S; x , v store binding

E ::= evaluation contexts:

[ ] context hole
if E then t else t if context
q <E,t> fst context
q <x,E> snd context
split E as x,y in t split context
E t fun context
x E arg context

Figure 1ng7: Linear lambda calculus: Runngtime data

are terms with a single hole. Contexts define the order of evaluation of terms--
they specify the places in a term where a computation can occur. In our case,
evaluation is leftngtongright since, for example, there is a context with the form
E t indicating that we can reduce the term in the function position before reng
ducing the term in the argument position. However, there is no context with
the form t E. Instead, there is only the more limited context x E, indicating
that we must reduce the term in the function position to a pointer x before
proceeding to evaluate the term in the argument position. We use the notang
tion E[t] to denote the term composed of the context E with its hole plugged
by the computation t.

The operational semantics, defined in Figure 1ng8, is factored into two reng
lations. The first relation, (S;t) -! (S0;t0), picks out a subcomputation to
evaluate. The second relation, (S;t) -!fi (S0;t0), does all the real work. In
order to avoid creation of two sets of operational rules, one for linear data,
which is deallocated when used, and one for unrestricted data, which is never
deallocated, we define an auxiliary function, S q, x, to manage the differences.

D^S1,x , v,S2E^ lin, x C^ S1,S2
S un, x C^ S

Aside from these details, the operational semantics is standard.

Preservation and Progress
In order to prove the standard safety properties for our language, we need to
be able to show that programs are wellngformed after each step in evaluation.
Hence, we will define typing rules for our abstract machine. Since these typing
rules are only necessary for the proof of soundness, and have no place in an

16 1 Substructural Type Systems

Topnglevel Evaluation (S;t) -! (S0;t0)

(S;t) -!fi (S;t0)
(S;E[t]) -! (S;E[t0]) (EngCtxt)

Evaluation (S;t) -!fi (S0;t0)

(S;q b) -!fi (S; x , q b;x) (EngBool)

S(x) = q true
(S;if x then t1 else t2) -!fi (S q, x;t1)

(EngIf1)

S(x) = q false
(S;if x then t1 else t2) -!fi (S q, x;t2)

(EngIf2)

(S;q <y,z>) -!fi (S; x , q <y,z>;x) (EngPair)

S(x) = q <y1,z1>
(S;split x as y,z in t) -!fi

(S q, x;E,y , y1G*E,z , z1G*t)

(EngSplit)

(S;q *y:T.t) -!fi (S; x , q *y:T.t;x)

(EngFun)
S(x1) = q *y:T.t

(S;x1 x2) -!fi (S q, x1;E,y , x2G*t) (

EngApp)

Figure 1ng8: Linear lambda calculus: Operational semantics

implementation, we will extend the declarative typing rules rather than the
algorithmic typing rules.

Figure 1ng9 presents the machine typing rules in terms of two judgments,
one for stores and the other for programs. The store typing rules generate a
context that describes the available bindings in the store. The program typng
ing rule uses the generated bindings to check the expression that will be
executed.

With this new machinery in hand, we are able to prove the standard progress
and preservation theorems.

1.2.11 Theorem [Preservation]: If ` (S;t) and (S;t) -! (S0;t0) then

` (S0;t0). 2

1.2.12 Theorem [Progress]: If ` (S;t) then (S;t) -! (S0;t0) or t is a value. 2
1.2.13 Exercise [Recommended, n']: You will need a substitution lemma to comng

plete the proof of preservation. Is the following the right one?

Conjecture: Let \Gamma 3 C^ \Gamma 1 ffi \Gamma 2. If \Gamma 1; x:T ` t1 : T1 and \Gamma 2 ` t : T then
\Gamma 3 ` E,x , tG*t1 : T1. 2

1.2.14 Exercise [n'n'n', 3]: Prove progress and preservation using TAPL, Chapters 9

and 13, as an approximate guide. 2

1.3 Extensions and Variations 17
Store Typing ` S : \Gamma 

` ; : ; (TngEmptyS)
` S : \Gamma 1 ffi \Gamma 2 \Gamma 1 ` lin w : T

` S,x , lin w : \Gamma 2; x:T (TngNextlinS)

` S : \Gamma 1 ffi \Gamma 2 \Gamma 1 ` un w : T

` S,x , un w : \Gamma 2; x:T (TngNextunS)

Program Typing ` (S;t)

` S : \Gamma  \Gamma  ` t : T

` (S;t) (TngProg)

Figure 1ng9: Linear lambda calculus: Program typing

1.3 Extensions and Variations

Most features found in modern programming languages can be defined to
interoperate successfully with linear type systems, although some are trickier
than others. In this section, we will consider a variety of practical extensions
to our simple linear lambda calculus.

Sums and Recursive Types
Complex data structures, such as the recursive data types found in MLnglike
languages, pose little problem for linear languages. To demonstrate the cenng
tral ideas involved, we extend the syntax for the linear lambda calculus with
the standard introduction and elimination forms for sums and recursive types.
The details are presented in Figure 1ng10.

Values with sum type are introduced by injections q inlP t or q inrP t,
where P is T1+T2, the resulting pretype of the term. In the first instance, the
underlying term t must have type T1, and in the second instance, the underng
lying term t must have type T2. The qualifier q indicates the linearity of the
argument in exactly the same way as for pairs. The case expression will exeng
cute its first branch if its primary argument is a left injection and its second
branch if its primary argument is a right injection. We assume that + binds
more tightly that ! but less tightly than *.

Recursive types are introduced with a rollP t expression, where P is the
recursive pretype the expression will assume. Unlike all the other introducng
tion forms, roll expressions are not annotated with a qualifier. Instead, they
take on the qualifier of the underlying expression t. The reason for this disng
tinction is that we will treat this introduction form as a typing coercion that
has no real operational effect. Unlike functions, pairs or sums, recursive data
types have no data of their own and therefore do not need a separate qualing
fier to control their allocation behavior. To simplify the notational overhead

18 1 Substructural Type Systems

t ::= terms:

... as before
q inlP t left inj.
q inrP t right inj.
case t (inl x ) t | inr y ) t) case
rollP t roll into rec type
unroll t unroll from rec type
fun f(x:T1):T2.t recursive fun
P ::= pretypes:

... as before
a pretype variables
T1+T2 sum types
rec a.T recursive types

Typing \Gamma  ` t : T

\Gamma  ` t : T1 q(T1) q(T2)

\Gamma  ` q inlT1+T2 t : q (T1+T2) (TngInl)
\Gamma  ` t : T2 q(T1) q(T2)

\Gamma  ` q inrT1+T2 t : q (T1+T2) (TngInr)

\Gamma 1 ` t : q (T1+T2)
\Gamma 2; x:T1 ` t1 : T \Gamma 2; y:T2 ` t2 : T

\Gamma 1 ffi \Gamma 2 ` case t (inl x ) t1 | inr y ) t2) : T

(TngCase)

\Gamma  ` t : E,a , PG*q P1 P = rec a.q P1

\Gamma  ` rollP t : q P

(TngRoll)

\Gamma  ` t : P P = rec a.q P1

\Gamma  ` unroll t : E,a , PG*q P1 (TngUnroll)
un D^\Gamma  E^ \Gamma  ; f:un T1!T2; x:T1 ` t : T2

\Gamma  ` fun f(x:T1):T2.t : un T1!T2

(TngTFun)

Figure 1ng10: Linear lambda calculus: Sums and recursive types

of sums and recursive types, we will normally omit the typing annotations on
their introduction forms in our examples.

In order to write computations that process recursive types, we add recurng
sive function declarations to our language as well. Since the free variables in
a recursive function closure will be used on each recursive invocation of the
function, we cannot allow the closure to contain linear variables. Hence, all
recursive functions are unrestricted data structures.

A simple but useful data structure is the linear list of Ts:

type T llist = rec a.lin (unit + lin (T * lin a))
Here, the entire spine (aside from the terminating value of unit type) is linear
while the underlying T objects may be linear or unrestricted. To create a fully
unrestricted list, we simply omit the linear qualifiers on the sum and pairs
that make up the spine of the list:

type T list = rec a.unit + T * a

1.3 Extensions and Variations 19

After defining the linear lists, the memory conscious programmer can write
many familiar listngprocessing functions in a minimal amount of space. For
example, here is how we map an unrestricted function across a linear list.
Remember, multingargument functions are abbreviations for functions that acng
cept linear pairs as arguments.

fun nil(_:unit) : T2 llist =

roll (lin inl ())

fun cons(hd:T2, tl:T2 llist) : T2 llist =

roll (lin inr (lin <hd,tl>))

fun map(f:T1!T2, xs:T1 llist) : T2 llist =

case unroll xs (

inl _ ) nil()
| inr xs )

split xs as hd,tl in
cons(f hd,map lin <f,tl>))

In this implementation of map, we can observe that on each iteration of the
loop, it is possible to reuse the space deallocated by split or case operations
for the allocation operations that follow in the body of the function (inside
the calls to nil and cons).

Hence, at first glance, it appears that map will execute with only a constant
space overhead. Unfortunately, however, there are some hidden costs as map
executes. A typical implementation will store local variables and temporaries
on the stack before making a recursive call. In this case, the result of f hd will
be stored on the stack while map iterates down the list. Consequently, rather
than having a constant space overhead, our map implementation will have an
O(n) overhead, where n is the length of the list. This is not too bad, but we
can do better.

In order to do better, we need to avoid implicit stack allocation of data
each time we iterate through the body of a recursive function. Fortunately,
many functional programming languages guarantee that if the last operation
in a function is itself a function call then the language implementation will
deallocate the current stack frame before calling the new function. We name
such function calls tail calls and we say that any language implementation
that guarantees that the current stack frame will be deallocated before a tail
call is tailngcall optimizing.

Assuming that our language is tailngcall optimizing, we can now rewrite map
so that it executes with only a constant space overhead. The main trick inng
volved is that we will explicitly keep track of both the part of the input list we
have yet to process and the ouput list that we have already processed. The

20 1 Substructural Type Systems

output list will wind up in reverse order, so we will reverse it at the end. Both
of the loops in the code, mapRev and reverse are tailngrecursive functions.
That is, they end in a tail call and have a spacengefficient implementation.

fun map(f:T1!T2, input:T1 llist) : T2 llist =

reverse(mapRev(f,input,nil()),nil())

and mapRev(f:T1!T2,

input:T1 llist,
output:T2 llist) : T2 llist =
case unroll input (

inl _ ) output
| inr xs )

split xs as hd,tl in
mapRev (f,tl,cons(f hd,output)))

and reverse(input:T2 llist, output:T2 llist)

case unroll input (

inl _ ) output
| inr xs )

split xs as hd,tl in
reverse(tl,cons(hd,output)))

This link reversal algorithm is a wellngknown way of traversing a list in
constant space. It is just one of a class of algorithms developed well before
the invention of linear types. A similar algorithm was invented by Deutsch,
Schorr, and Waite for traversing trees and graphs in constant space. Such conng
stant space traversals are essential parts of markngsweep garbage collectors--
at garbage collection time there is no extra space for a stack so any traversal
of the heap must be done in constant space.

1.3.1 Exercise [n'n'n']: Define a recursive type that describes linear binary trees

that hold data of type T in their internal nodes (nothing at the leaves). Write
a constantngspace function treeMap that produces an identicallyngshaped tree
on output as it was given on input, modulo the action of the function f that
is applied to each element of the tree. Feel free to use reasonable extensions
to our linear lambda calculus including mutually recursive functions, nngary
tuples and nngary sums. 2

Polymorphism
Parametric polymorphism is a crucial feature of almost any functional lanng
guage, and our linear lambda calculus is no exception. The main function of
polymorphism in our setting is to support two different sorts of code reuse.

1.3 Extensions and Variations 21

1. Reuse of code to perform the same algorithm, but on data with different

shapes.

2. Reuse of code to perform the same algorithm, but on data governed by

different memory management strategies.

To support the first kind of polymorphism, we will allow quantification
over pretypes. To support the second kind of polymorphism, we will allow
quantification over qualifiers. A good example of both sorts of polymorphism
arises in the definition of a polymorphic map function. In the code below, we
use a and b to range over pretype variables as we did in the previous section,
and p to range over qualifier variables.

type (p1,p2,a) list =

rec a.p1 (unit + p1 (p2 a * (p1,p2,a) list))

map :

8a,b.

8pa,pb.

lin ((pa a ! pb b)*(lin,pa,a) list)!(lin,pb,b) list

The type definition in the first line defines lists in terms of three parameters.
The first parameter, p1, gives the usage pattern (linear or unrestricted) for the
spine of the list, while the second parameter gives the usage pattern for the
elements of the list. The third parameter is a pretype parameter, which gives
the (pre)type of the elements of list. The map function is polymorphic in the
argument (a) and result (b) element types of the list. It is also polymorphic
(via parameters pa and pb) in the way those elements are used. Overall, the
function maps lists with linear spines to lists with linear spines.

Developing a system for polymorphic, linear type inference is a challenging
research topic, beyond the scope of this book, so we will assume that, unlike
in ML, polymorphic functions are introduced explicitly using the syntax \Lambda a.t
or \Lambda p.t. Here, a and p are the type parameters to a function with body t. The
body does not need to be a value, like in ML, since we will run the polymorphic
function every time a pretype or qualifier is passed to the function as an
argument. The syntax t0 [P] or t0 [q] applies the function t0 to its pretype
or qualifier argument. Figure 1ng11 summarizes the syntactic extensions to the
language.

Before we get to writing the map function, we will take a look at the polyng
morphic constructor functions for linear lists. These functions will take a
pretype parameter and two qualifier parameters, just like the type definition
for lists.

22 1 Substructural Type Systems

q ::= qualifiers:

... as before
p polymorphic qualifier
t ::= terms:

... as before
q \Lambda a.t pretype abstraction
t [P] pretype application

q \Lambda p.t qualifier abstraction
t [q] qualifier application
P ::= pretypes:

... as before
8a.T pretype polymorphism
8p.T qualifier polymorphism

Figure 1ng11: Linear lambda calculus: Polymorphism syntax

val nil : 8a,p2.(lin,p2,a) list =

\Lambda a,p2.roll (lin inl ())

val list :

8a,p2.lin (p2 a * (lin,p2,a) list)!(lin,p2,a) list =
\Lambda a,p2.

*cell : lin (p2 a * (lin,p2,a) list).

roll (lin inr (lin cell))

Now our most polymorphic map function may be written as follows.

val map =

\Lambda a,b. \Lambda pa,pb.
fun aux(f:(pa a ! pb b),

xs:(lin,pa,a) list)) : (lin,pb,b) list =
case unroll xs (

inl _ ) nil [b,pb] ()
| inr xs ) split xs as hd,tl in

cons [b,pb] (pb <f hd,map (lin <f,tl>)>))

In order to ensure that our type system remains sound in the presence
of pretype polymorphism, we add the obvious typing rules, but change very
little else. However, adding qualifier polymorphism, as we have done, is a
little more involved. Before arriving at the typing rules themselves, we need
to adapt some of our basic definitions to account for abstract qualifiers that
may either be linear or unrestricted.

First, we need to ensure that we propagate contexts containing abstract
qualifiers safely through the other typing rules in the system. Most imporng
tantly, we add additional cases to the context manipulation rules defined in
the previous section. We need to ensure that linear hypotheses are not dung
plicated and therefore we cannot risk duplicating unknown qualifiers, which
might turn out to be linear. Figure 1ng12 specifies the details.

1.3 Extensions and Variations 23
Context Split \Gamma  C^ \Gamma 1 ffi \Gamma 2

\Gamma  C^ \Gamma 1 ffi \Gamma 2
\Gamma  ; x:p P C^ D^\Gamma 1; x:p PE^ ffi \Gamma 2 (MngAbs1)

\Gamma  C^ \Gamma 1 ffi \Gamma 2
\Gamma  ; x:p P C^ \Gamma 1 ffi D^\Gamma 2; x:p PE^ (MngAbs2)

Figure 1ng12: Linear context manipulation rules

\Delta  ::= type contexts:

; empty
\Delta ; a pretype var.
\Delta ; p qualifier var.

Typing \Delta ; \Gamma  ` t : T

qD^\Gamma  E^ \Delta ; a; \Gamma  ` t : T
\Delta ; \Gamma  ` q \Lambda a.t : q 8a.T (TngPAbs)

\Delta ; \Gamma  ` t : q 8a.T FVD^PE^ ` \Delta 

\Delta ; \Gamma  ` t [P] : E,a , PG*T (TngPApp)

qD^\Gamma  E^ \Delta ; p; \Gamma  ` t : T
\Delta ; \Gamma  ` q \Lambda p.t : q 8p.T (TngQAbs)
\Delta ; \Gamma  ` t : q1 8p.T FVD^qE^ ` \Delta 

\Delta ; \Gamma  ` t [q] : E,p , qG*T (TngQApp)

Figure 1ng13: Linear lambda calculus: Polymorphic typing

Second, we need to conservatively extend the relation on type qualifiers
q1vq2 so that it is sound in the presence of qualifier polymorphism. Since
the linear qualifier is the least qualifier in the current system, the following
rule should hold.

lin v p (QngLinP)
Likewise, since un is the greatest qualifier in the system, we can be sure the
following rule is sound.

p v un (QngPUn)
Aside from these rules, we will only be able to infer that an abstract qualng
ifier p is related to itself via the general reflexivity rule. Consequently, linng
ear data structures can contain abstract ones; abstract data structures can
contain unrestricted data structures; and data structure with qualifier p can
contain other data with qualifier p.

In order to define the typing rules for the polymorphic linear lambda calng
culus proper, we need to change the judgment form to keep track of the type
variables that are allowed to appear free in a term. The new judgment uses
the type context \Delta  for this purpose. The typing rules for the introduction and
elimination forms for each sort of polymorphism are fairly straightforward
now and are presented in Figure 1ng13.

24 1 Substructural Type Systems

The typing rules for the other constructs we have seen are almost unng
changed. One relatively minor alteration is that the incoming type context
\Delta  will be propagated through the rules to account for the free type variables.
Unlike term variables, type variables can always be used in an unrestricted
fashion; it is difficult to understand what it would mean to restrict the use
of a type variable to one place in a type or term. Consequently, all parts of \Delta 
are propagated from the conclusion of any rule to all premises. We also need
the occasional side condition to check that whenever a programmer writes
down a type, its free variables are contained in the current type context \Delta .
For instance the rules for function abstraction and application will now be
written as follows.

qD^\Gamma  E^ FVD^T1E^ ` \Delta  \Delta ; \Gamma  ; x:T1 ` t2 : T2

\Delta ; \Gamma  ` q *x:T1.t2 : q T1!T2 (TngAbs)
\Delta ; \Gamma 1 ` t1 : q T1!T2 \Delta ; \Gamma 2 ` t2 : T1

\Delta ; \Gamma 1 ffi \Gamma 2 ` t1 t2 : T2 (TngApp)
The most important way to test our system for faults is to prove the type
substitution lemma. In particular, the proof will demonstrate that we have
made safe assumptions about how abstract type qualifiers may be used.

1.3.2 Lemma [Type Substitution]:

1. If \Delta ; p; \Gamma  ` t : T and FVD^qE^ 2 \Delta  then \Delta ; E,p , qG*\Gamma  ` E,p , qG*t : E,p , qG*T
2. If \Delta ; a; \Gamma  ` t : T and FVD^PE^ 2 \Delta  then \Delta ; E,a , PG*\Gamma  ` E,a , PG*t : E,a , PG*T 2

1.3.3 Exercise [n']: Sketch the proof of the type substitution lemma. What strucng

tural rule(s) do you need to carry out the proof? 2

Operationally, we will choose to implement polymorphic instantiation usng
ing substitution. As a result, our operational semantics changes very little.
We only need to specify the new computational contexts and to add the evalng
uation rules for polymorphic functions and application as in Figure 1ng14.

Arrays
Arrays pose a special problem for linearly typed languages. If we try to prong
vide an operation fetches an element from an array in the usual way, perhaps
using an array index expression a[i], we would need to reflect the fact that
the ith element (and only the ith element) of the array had been "used." Howng
ever, there is no simple way to reflect this change in the type of an array as the
usual form of array types (array(T)) provides no mechanism to distinguish
between the properties of different elements of the array.

1.3 Extensions and Variations 25
E ::= evaluation contexts:

E [P] pretype app context
E [q] qualifier app context

(S;q \Lambda a.t) -!fi (S; x , q \Lambda a.t;x) (EngPFun)

S(x) = q \Lambda a.t
(S;x [P]) -!fi (S q, x;E,a , PG*t) (

EngPApp)

(S;q \Lambda p.t) -!fi (S; x , q \Lambda p.t;x) (EngQFun)

S(x) = q \Lambda p.t
(S;x [q1]) -!fi (S q, x;E,p , q1G*t) (

EngQApp)

Figure 1ng14: Linear lambda calculus: Polymorphic operational semantics

We dodged this problem when we constructed our tuple operations by
defining a pattern matching construct that simultaneously extracted all of
the elements of a tuple. Unfortunately, we cannot follow the same path for
arrays because in modern languages like Java and ML, the length of an array
(and therefore the size of the pattern) is unknown at compile time.

Another nonngsolution to the problem is to add a special builtngin iterator
to process all the elements in an array at once. However, this last prevents
programmers from using arrays as efficient, constantngtime, randomngaccess
data structures; they might as well use lists instead.

One way out of this jam is to design the central array access operations so
that, unlike the ordinary "get" and "set" operations, they preserve the number
of pointers to the array and the number of pointers to each of its elements.
We avoid our problem because there is no change to the array data structure
that needs to be reflected in the type system. Using this idea, we will be able
to allow programmers to define linear arrays that can hold a collection of
arbitrarily many linear objects. Moreover, programmers will be able to access
any of these linear objects, one at a time, using a convenient, constantngtime,
randomngaccess mechanism.

So, what are the magic pointerngpreserving array access operations? Actung
ally, we need only one: a swap operation with the form swap (a[i],t). The
swap replaces the ith element of the array a (call it t0) with t and returns a
(linear) pair containing the new array and t0. Notice the number of pointers
to t and t0 does not change during the operation. If there was one pointer
to t (as an argument to swap) before the call, then there is one pointer to t
afterward (from within the array a) and vice versa for t0. If, in addition, all of
the elements of a had one pointer to them before the swap, then they will all
have one pointer to them after the swap as well. Consequently, we will find
it easy to type the swap operation, even when it works over linear arrays of
linear objects.

26 1 Substructural Type Systems

In addition to swap, we provide functions to allocate an array given its list
of elements (array), to determine array length (length) and to deallocate
arrays (free). The last operation is somewhat unusual in that it takes two
arguments a and f, where a is an array of type lin array(T) and f is a
function with type T!unit that is run on each element of T. The function
may be thought of as a finalizer for the elements; it may be used to deallocate
any linear components of the array elements, thereby preserving the single
pointer property.

Our definition of arrays is compatible with the polymorphic system from
the previous subsection, but for simplicity, we formalize it in the context of
the simplyngtyped lambda calculus (see Figure 1ng15).

1.3.4 Exercise [Recommended, n']: The typing rule for array allocation (TngArray)

contains the standard containment check to ensure that unrestricted arrays
cannot contain linear objects. What kinds of errors can occur if this check is
omitted? 2

1.3.5 Exercise [n'n', 3]: With the presence of mutable data structures, it is possible

to create cycles in the store. How should we modify the store typing rules to
take this into account? 2

The swap and free functions are relatively lownglevel operations. Fortung
nately, it is easy to build more convenient, highernglevel abstractions out of
them. For instance, the following code defines some simple functions for mang
nipulating linear matricies of unrestricted integers.

type iArray = lin array(int)
type matrix = lin array(iArray)

fun dummy(x:unit):iArray = lin array()
fun freeElem(x:int):unit = ()
fun freeArray(a:iArray):unit = free(a,freeElem)
fun freeMatrix(m:matrix):unit = free(m,freeArray)

fun get(a:matrix,i:int,j:int):lin (matrix * int) =

split swap(a[i],dummy()) as a,b in
split swap(b[j],0) as b,k in
split swap(b[j],k) as b,_ in
split swap(a[i],b) as a,junk in
freeArray(junk);
lin <a,k>

1.3 Extensions and Variations 27
P ::= pretypes:

... as before
array(T) array pretypes
t ::= terms:

... as before
q array(t, : : : ,t) array creation
swap(t[t],t) swap
length(t) length
free(t,t) deallocate
w ::= prevalues:

... as before
array[n,x, : : : ,x] array
E ::= evaluation contexts:

... as before
q array(v, : : : ,v,E,t, : : : ,t)

array context
swap(E(t),t) swap context
swap(v(E),t) swap context
swap(v(v),E) swap context
length(E) length context
free(E,t) free context
free(v,E) free context

Typing \Gamma  ` t : T

q(T) \Gamma  ` ti : T (for 1 <= i <= n)
\Gamma  ` q array(t1, : : : ,tn) : q array(T)

(TngArray)

\Gamma  ` t1 : q1 array(T1)
\Gamma  ` t2 : q2 int \Gamma  ` t3 : T1

\Gamma  ` swap(t1[t2],t3) :

lin (q1 array(T1) * T1)

(TngSwap)

\Gamma  ` t : q array(T)
\Gamma  ` length(t) : lin (q array(T) * int)

(TngLength)
\Gamma  ` t1 : q array(T) \Gamma  ` t2 : T ! unit

\Gamma  ` free(t1,t2) : unit

(TngFree)

Evaluation (S;t) -!fi (S0;t0)

(S;q array(x0, : : : ,xn-1)) -!fi

((S; x , q array[n,x0, : : : ,xn-1];x)

(EngArray)

S(xi) = qi j
S = S1; xa , q array[n, : : : ,xj, : : : ]; S2
S0 = S1; xa , q array[n, : : : ,xe, : : : ]; S2

(S; swap(xa[xi],xe))

-!fi (S0 qi, xi;lin <xa,xj >)

(EngSwap)
S(x) = q array[n,x0, : : : ,xn-1]

(S;length(x)) -!fi (S;lin <x,un n>)

(EngLength)
S(xa) = q array[n,x0, : : : ,xn-1]

(S;free(xa,xf ))

-!fi (S q, xa;App(xf ,x0, : : : ,xn-1))

(EngFree)

where
App(xf ,*) C^ ()
App(xf ,x0,. . . ) C^ xf x0;App(xf ,. . . )

Figure 1ng15: Linear lambda calculus: Arrays

28 1 Substructural Type Systems

fun set(a:matrix,i:int,j:int,e:int):matrix =

split swap(a[i],dummy()) as a,b in
split swap(b[j],e) as b,_ in
split swap(a[i],b) as a,junk in
freeArray(junk);
a

1.3.6 Exercise [n'n', 3]: Use the functions provided above to write matrixngmatrix

multiply. Your multiply function should return an integer and deallocate both
arrays in the process. Use any standard integer operations necessary. 2

In the examples above, we needed some sort of dummy value to swap into
an array to replace the value we wanted to extract. For integers and arrays
it was easy to come up with one. However, when dealing with polymorphic
or abstract types, it may not be possible to conjure up a value of the right
type. Consequently, rather than manipulating arrays with type q array(a)
for some abstract type a, we may need to manipulate arrays of options with
type q array(a + unit). In this case, when we need to read out a value, we
always have another value (inr ()) to swap in in its place. Normally such
operations are called destructive reads; they are a common way to preserve
the single pointer property when managing complex structured data.

Reference Counting
Array swaps and destructive reads are dynamic techniques that can help overng
come a lack of compilengtime knowledge about the number of uses of a parng
ticular object. Reference counting is another dynamic technique that serves a
similar purpose. Rather than restricting the number of pointers to an object
to be exactly one, we can allow any number of pointers to the object and keep
track of that number dynamically. Only when the last reference is used will
the object be deallocated.

There are various ways to integrate reference counts into the current sysng
tem. Here, we choose the simplest, which is to add a new qualifier rc for
referencengcounted data structures, and operations that allow the programmer
to explicitly increment (inc) and decrement (dec) the counts (see Figure 1ng16).
More specifically, the increment operation takes a pointer argument, increng
ments the reference count for the object pointed to, and returns two copies
of the pointer in a (linear) pair. The decrement operation takes two argung
ments, a pointer and a function, and works as follows. In the case the object
pointed to (call it x) has a reference count of 1 before the decrement, the
function is executed with x as a linear argument. Since the function treats x

1.3 Extensions and Variations 29
Syntax

q ::= qualifiers:

... as before
rc ref. count
t ::= terms:

... as before
inc(t) increment count
dec(t,t) decrement count

Qualifier Relations

rc v un (QngRCUn)
lin v rc (QngLinRC)

Typing \Gamma  ` t : T

\Gamma  ` t : rc P
\Gamma  ` inc(t) : lin (rc P * rc P) (TngInc)
\Gamma  ` t1 : rc P \Gamma  ` t2 : lin P ! unit

\Gamma  ` dec(t1,t2) : unit

(TngDec)

Figure 1ng16: Linear lambda calculus: Reference counting syntax and typing

linearly, it will deallocate x before it completes. In the other case, when x has
a reference count greater than 1, the reference count is simply decremented
and the function is not called; unit is returned as the result of the operation.

The main typing invariant in this system is that whenever a referenceng
counted variable appears in the static typengchecking context, there is one
dynamic reference count associated with it. Linear typing will ensure the
number of references to an object is properly preserved.

The new rc qualifier should be treated in the same manner as the linear
qualifier when it comes to context splitting. In other words, a referenceng
counted variable should be placed in exactly one of the leftnghand context
or the rightnghand context (not both). In terms of containment, the rc qualing
fier sits between unrestricted and linear qualifiers: A referencengcounted data
structure may not be contained in unrestricted data structures and may not
contain linear data structures. Figure 1ng16 presents the appropriate qualifier
relation and typing rules for our reference counting additions.

In order to define the execution behavior of referencengcounted data strucng
tures, we will define a new sort of stored value with the form rc(n) w. The
integer n is the reference count: it keeps track of the number of times the
value is referenced elsewhere in the store or in the program.

The operational semantics for the new commands and referencengcounted
pairs and functions are summarized in Figure 1ng17. Several new bits of nong
tation show up here to handle the relatively complex computation that must
go on to increment and decrement reference counts. First, in a slight abuse
of notation, we allow q to range over static qualifiers un, lin and rc as well
as dynamic qualifiers un, lin and rc(n). Context will disambiguate the two

30 1 Substructural Type Systems

different sorts of uses. Second, we extend the notation S q,x so that q may
be rc(n) as well as lin and un. If n is 1 then Src(n), x removes the binding
x,rc(n) w from S. Otherwise, Src(n), x replaces the binding x,rc(n) w with
x,rc(nng1) w. Finally, given a store S and a set of variables X, we define the
function incr(S;X), which produces a new store S0 in which the reference
count associated with any referencengcounted variables x2X is increased by 1.

To understand how the reference counting operational semantics works,
we will focus on the rules for pairs. Allocation and use of linear and unreng
stricted pairs stays unchanged from before as in rules (EngPair') and (EngSplit').
Rule (EngPairRC) specifies that allocation of referencengcounted pairs is siming
lar to allocation of other data, except for the fact that the dynamic reference
count must be initialized to 1. Use of referencengcounted pairs is identical to
use of other kinds of pairs when the reference count is 1: We remove the

pair from the store via the function Src(n), x as shown in rule and substing
tute the two components of the pair in the body of the term as shown in
(EngSplit'). When the reference count is greater than 1, rule (EngSplitRC) shows
there are additional complications. More precisely, if one of the components
of the pair, say y1, is referencengcounted then y1's reference count must be
increased by 1 since an additional copy of y1 is substituted through the body
of t. We use the incr function to handle the possible increase. In most reng
spects, the operational rules for referencengcounted functions follow the same
principles as referencengcounted pairs. Increment and decrement operations
are also relatively straightforward.

In order to state and prove the progress and preservation lemmas for our
referencengcounting language, we must generalize the type system slightly. In
particular, our typing contexts must be able specify the fact that a particular
reference should appear exactly n times in the store or current computation.
Referencengcounted values in the store are described by these contexts and
the contextngsplitting relation is generalized appropriately. Figure 1ng18 sumng
marizes the additional typing rules.

1.3.7 Exercise [n'n'n', 3]: State and prove progress and preservation lemmas for

the simplyngtyped linear lambda calculus (functions and pairs) with reference
counting. 2

1.4 An Ordered Type System

Just as linear type systems provide a foundation for managing memory allong
cated on the heap, ordered type systems provide a foundation for managing
memory allocated on the stack. The central idea is that by controlling the

1.4 An Ordered Type System 31
v ::= values:

... as before
rc(n) w refngcounted value
E ::= evaluation contexts:

... as before
inc(E) inc context
dec(E,t) dec context
dec(x,E) dec context

Evaluation (S;t) -!fi (S0;t0)

D^q 2 {un,lin}E^
(S;q <y,z>) -!fi (S; x , q <y,z>;x)

(EngPair')

(S;rc <y,z>) -!fi

(S; x , rc(1) <y,z>;x) (EngPairRC)

S(x) = q <y1,z1>
D^q 2 {un,lin,rc(1)}E^

(S;split x as y,z in t) -!fi

(S q, x;E,y , y1G*E,z , z1G*t)

(EngSplit')

S(x) = rc(n) <y1,z1> D^n > 1E^

incr(S;{y1,z1}) = S0

(S;split x as y,z in t) -!fi
((S0 rc(n), x);E,y , y01G*E,z , z01G*t)

(EngSplitRC)

D^q 2 {un,lin}E^
(S;q *y:T.t) -!fi (S; x , q *y:T.t;x)

(EngFun')
(S;rc *y:T.t) -!fi

(S; x , rc(1) *y:T.t;x) (EngFunRC)

S(x1) = q *y:T.t
D^q 2 {un,lin,rc(1)}E^

(S;x1 x2) -!fi (S q, x1;E,y , x2G*t) (

EngApp')

S(x1) = rc(n) *y:T.t
D^n > 1 and X = FVD^*y:T.tE^E^

incr(S;X) = S0

(S;x1 x2) -!fi (S0 rc(n), x1;E,y , x2G*t)

(EngAppRC)

incr(S;{x}) = S0

(S;inc(x)) -!fi (S0;lin <x,x>) (EngInc)

D^S(x) = rc(n) wE^ (n > 1)

(S;dec(x,xf )) -!fi (S rc(n), x;un ())

(EngDec1)

S = S1,x , rc(1) w,S2

S0 = S1,x , lin w,S2

(S;dec(x,xf )) -!fi (S0;xf x) (EngDec2)

Figure 1ng17: Linear lambda calculus: Reference counting operational semantics

exchange property, we are able to guarantee that certain values, those values
allocated on the stack, are used in a firstngin/lastngout order.

To formalize this idea, we organize the store into two parts: a stack, which
is a sequence of locations that can be accessed on one end (the "top") and
a heap, which is like the store described in previous sections of this chapng
ter. Pairs, functions and other objects introduced with unrestricted or linear
qualifiers are allocated on the heap as before. And as before, when a linear
pair or function is used, it is deallocated. Also, we allow programmers to allong
cate simple data structures on the stack. Without the exchange property, an
ordered object can only be used when it is at the top of the stack. When this
happens, the ordered object is popped off the top of the stack.

32 1 Substructural Type Systems

Syntax

\Gamma  ::= typing contexts:

... as before
\Gamma  ; x:rc(n)P rc(n) context

Store Typing

` S : \Gamma 1 ffi \Gamma 2 \Gamma 1 ` rc w : rc P

` S,x , rc(n) w : \Gamma 2; x:rc(n) P (TngNextrcS)

Context Splitting

\Gamma  C^ \Gamma 1 ffi \Gamma 2 n = i + j

\Gamma  ; x:rc(n)P C^

D^\Gamma 1; x:rc(i)PE^ ffi D^\Gamma 2; x:rc(j)PE^

(MngRC)

(when i or j is 0, the corresponding binding is
removed from the context)

Variable Typing

un D^\Gamma 1; \Gamma 2E^

\Gamma 1; x:rc(1)P; \Gamma 2 ` x : rc P (TngRCVar)

Figure 1ng18: Linear lambda calculus: Reference counting runngtime typing

Syntax
The overall structure and mechanics of the ordered type system are very
similar to the linear type system developed in previous sections. Figure 1ng19
presents the syntax. One key change from our linear type system is that we
have introduced an explicit sequencing operation let x = t1 in t2 that first
evaluates the term t1, binds the result to x, and then continues with the evalng
uation of t2. This sequencing construct gives programmers explicit control
over the order of evaluation of terms, which is crucial now that we are introng
ducing data that must be used in a particular order. Terms that normally can
contain multiple nested subexpressions such as pair introduction and funcng
tion application are syntactically restricted so that their primary subterms
are variables and the order of evaluation is clear.

The other main addition is a new qualifier ord that marks data allocated on
the stack. We only allow pairs and values with base type to be stackngallocated;
functions are allocated on the unordered heap. Therefore, we declare types
ord T1 ! T2 and terms ord *x:T.t to be syntactically illngformed.

Ordered assumptions are tracked in the type checking context \Gamma  like other
assumptions. However, they are not subject to the exchange property. Moreng
over, the order that they appear in \Gamma  mirrors the order that they appear on
the stack, with the rightmost position representing the stack's top.

Typing
The first step in the development of the type system is to determine how
assumptions will be used. As before, unrestricted assumptions can be used

1.4 An Ordered Type System 33
Syntax

q ::= qualifiers:

ord ordered
lin linear
un unrestricted
t ::= terms:

x variable
q b Boolean
if t then t else t conditional
q <x,y> pair
split t as x,y in t split
q *x:T.t abstraction

x y application
let x = t in t sequencing
P ::= pretypes:

Bool booleans
T*T pairs
T!T functions
T ::= types:

q P qualified pretype
\Gamma  ::= contexts:

; empty context
\Gamma  ; x:T term variable binding

Figure 1ng19: Ordered lambda calculus: Syntax

as often as the programmer likes but linear assumptions must be used exng
actly once along every control flow path. Ordered assumptions must be used
exactly once along every control flow path,in the order in which they appear.

As before, the context splitting operator (\Gamma  C^ \Gamma 1 ffi \Gamma 2) helps propagate asng
sumptions properly, separating the context \Gamma  into \Gamma 1 and \Gamma 2. Some sequence
of ordered assumptions taken from the leftnghand side of \Gamma  are placed in \Gamma 1
and the remaining ordered assumptions are placed in \Gamma 2. Otherwise, the splitng
ting operator works the same as before. In the typing rules, the context \Gamma 2
is used by the first subexpression to be evaluated (since the top of the stack
is at the right) and \Gamma 1 is used by the second subexpression to be evaluated.
Formally, we define the "C^" relation in terms of two subsidiary relations: "C^1,"
which places ordered assumptions in \Gamma 1, and "C^2," which places ordered asng
sumptions in \Gamma 2. See Figure 1ng20.

The second step in the development of the type system is to determine the
containment rules for ordered data structures. Previously, we saw that if an
unrestricted object can contain a linear object, a programmer can write funcng
tions that duplicate or discard linear objects, thereby violating the central
invariants of the system. A similar situation arises if linear or unrestricted
objects can contain stack objects; in either case, the stack object might be
used out of order, after it has been popped off the stack. The typing rules
use the qualifier relation q1vq2, which specifies that ordvlinvun, to ensure
such problems do not arise.

The typing rules for the ordered lambda calculus appear in Figure 1ng21. For
the most part, the containment rules and context splitting rules encapsulate

34 1 Substructural Type Systems

Context Split \Gamma  C^ \Gamma 1 ffi \Gamma 2

\Gamma  C^2 \Gamma 1 ffi \Gamma 2

\Gamma  C^ \Gamma 1 ffi \Gamma 2 (MngTop)
; C^1 ; ffi ; (MngEmpty)

\Gamma  C^1 \Gamma 1 ffi \Gamma 2
\Gamma  ; x:ord P C^1 D^\Gamma 1; x:ord PE^ ffi \Gamma 2 (MngOrd1)

\Gamma  C^2 \Gamma 1 ffi \Gamma 2
\Gamma  ; x:ord P C^2 \Gamma 1 ffi D^\Gamma 2; x:ord PE^ (MngOrd2)

\Gamma  C^1 \Gamma 1 ffi \Gamma 2
\Gamma  C^2 \Gamma 1 ffi \Gamma 2 (Mng1to2)
\Gamma  C^1;2 \Gamma 1 ffi \Gamma 2
\Gamma  ; x:lin P C^1;2 D^\Gamma 1; x:lin PE^ ffi \Gamma 2 (MngLinA)

\Gamma  C^1;2 \Gamma 1 ffi \Gamma 2
\Gamma  ; x:lin P C^1;2 \Gamma 1 ffi D^\Gamma 2; x:lin PE^ (MngLinB)

\Gamma  C^1;2 \Gamma 1 ffi \Gamma 2
\Gamma  ; x:un P C^1;2 D^\Gamma 1; x:un PE^ ffi D^\Gamma 2; x:un PE^

(MngUn)

Figure 1ng20: Ordered lambda calculus: Context splitting

the tricky elements of the type system. The rules for pairs illustrate how this
is done. The rule for introducing pairs (TngOPair) splits the incoming context
into two parts, \Gamma 1 and \Gamma 2; any ordered assumptions in \Gamma 2 will represent data
closer to the top of the stack than \Gamma 1. Therefore, if the pair (x) and its two
components x1 and x2 are all allocated on the stack, then the pointer x will
end up on top, x2 next and x1 on the bottom. The elimination rule for pairs
(TngOSplit) is careful to maintain the proper ordering of the context. As above,
the rule splits the context into \Gamma 1 and \Gamma 2, where \Gamma 2, which represents data on
top of the stack, is used in a computation t1 that generates a pair. The context
\Gamma 1; x1:T1; x2:T2 is used to check t2. Notice that if both components of the
pair, x1 and x2, were allocated on the stack when the pair was introduced,
they reappear back in the context in the appropriate order.

Consider the following function, taking a boolean and a pair allocated seng
quentially at the top of the stack. The boolean is at the very top of the stack
and the integer pair is next (the top is to the right). If the boolean is true,
it leaves the components of the pair (two unrestricted integers) in the same
order as given; otherwise, it swaps them.

*x:ord (ord (int * int) * bool).

split x as p,b in
if b then

p
else

split p as i1,i2 in
ord <i2,i1>

1.4 An Ordered Type System 35
Typing \Gamma  ` t : T

un D^\Gamma 1; \Gamma 2E^
\Gamma 1; x:T; \Gamma 2 ` x : T (TngOVar)

un D^\Gamma  E^
\Gamma  ` q b : q Bool (TngOBool)

\Gamma 2 ` t1 : q Bool
\Gamma 1 ` t2 : T \Gamma 1 ` t3 : T

\Gamma 1 ffi \Gamma 2 ` if t1 then t2 else t3 : T (TngOIf)

\Gamma 1 ` x1 : T1 \Gamma 2 ` x2 : T2

q(T1) q(T2)

\Gamma 1 ffi \Gamma 2 ` q <x1,x2> : q (T1*T2) (TngOPair)

\Gamma 2 ` t1 : q (T1*T2)
\Gamma 1; x1:T1; x2:T2 ` t2 : T

\Gamma 1 ffi \Gamma 2 ` split t1 as x1,x2 in t2 : T

(TngOSplit)
qD^\Gamma  E^ \Gamma  ; x:T1 ` t2 : T2

\Gamma  ` q *x:T1.t2 : q T1!T2 (TngOAbs)
\Gamma 1 ` x1 : q T11!T12 \Gamma 2 ` x2 : T11

\Gamma 1 ffi \Gamma 2 ` x1 x2 : T12 (TngOApp)

\Gamma 2 ` t1 : T1
\Gamma 1; x:T1 ` t2 : T2

\Gamma 1 ffi \Gamma 2 ` let x = t1 in t2 : T2 (TngOLet)

Figure 1ng21: Ordered lambda calculus: Typing

Operational Semantics
To define the operational semantics for our new ordered type system, we will
divide our previous stores into two parts, a heap H and a stack K. Both are
just a list of bindings as stores were before (see Figure 1ng22). We also define a
couple of auxiliary functions. The first says what it means to add a binding to
the store. This is straightforward: unrestricted and linear bindings are added
to the heap and ordered bindings are added to the top of the stack.

(H;K),x , ord w C^ (H;K,x , ord w)
(H;K),x , lin w C^ (H,x , lin w;K)
(H;K),x , un w C^ (H,x , un w;K)

The second function specifies how to remove a binding from the store.
Notice that ordered deallocation will only remove the object at the top of the
stack.

D^H;K,x , vE^ ord, x C^ H;K
D^H1,x , v,H2;KE^ lin, x C^ H1,H2;K
D^H;KE^ un, x C^ H;K

With these simple changes, the evaluation rules from previous sections can
be reused essentially unchanged. However, we do need to add the evaluation
context for sequencing (let x = E in t) and its evaluation rule:

(S;let x = x1 in t2) -!fi (S;E,x , x1G*t1) (EngLet)

36 1 Substructural Type Systems

S ::= stores:

H;K complete store
H ::= heap:

; empty heap
H; x , lin w linear heap binding
H; x , un w unrestricted heap binding

K ::= stack:

; empty stack
K; x , ord w stack binding

Figure 1ng22: Ordered lambda calculus: Operational semantics

1.4.1 Exercise [Recommended, n']: Write a program that demonstrates what can

happen if the syntax of pair formation is changed to allow programmers to
write nested subexpressions (i.e., we allow the term ord <t1,t2> rather than
the term ord <x,y>). 2

1.4.2 Exercise [Recommended, n'n']: Demonstrate the problem with allowing orng

dered functions (i.e., admitting the syntax ord *x:T1.t and ord T1 ! T2) by
writing a wellngtyped program that uses ordered functions and gets stuck. 2

1.4.3 Exercise [n'n'n']: Modify the language so that programmers can use stackng

allocated, ordered functions. There are many solutions to this problem, some
more sophisticated than others. 2

1.5 Further Applications

Memory management applications make good motivation for substructural
type systems and provides a concrete framework for studying their properng
ties. However, substructural types systems, and their power to control the
number and order of uses of data and operations, have found many appling
cations outside of this domain. In the following paragraphs, we informally
discuss a few of them.

Controlling Temporal Resources
We have studied several ways that substructural type systems can be used to
control physical resources such as memory and files. What about controlling
the temporal resources? Amazingly, substructural type systems can play a
role here as well: Careful crafting of a language with an affine type system,
where values are used at most once, can ensure that computations execute in
polynomial time.

1.5 Further Applications 37

To begin, we will allow our polynomial time language to contain affine
booleans, pairs and (nonngrecursive) functions. In addition, to make things inng
teresting, we will add affine lists to our language, which have constructors
nil and cons and a special iterator to recurse over objects with list type.
Such iterators have the following form.

iter (stop ) t1 | x with y ) t2)
If t1 has type T and t2 also has type T (under the assumption that x has type
T1 and y has type T1 list), our iterator defines a function from T1 lists to
objects with type T. Operationally, the iterator does a case to see whether its
input list is nil or cons(hd,tl) and executes the corresponding branch. We
can define the operation of iterators using two simple rules.1

iter (stop ) t1 | hd with rest ) t2) nil -!fi t1 (EngIterNil)

iter (stop ) t1 | hd with rest ) t2) v2 -!*fi v02
iter (stop ) t1 | hd with rest ) t2) cons(v1,v2) -!fi

E,hd , v1G*E,rest , v02G*t2

(EngIterCons)

In the second rule, the iterator is invoked inductively on v2, giving the result
v02, which is used in term t2. The familar append function below illustrates
the use of iterators.

val append : T list!T list!T list =

iter (

stop ) *(l:T list).l
| hd with rest ) *(l:T list).cons(hd,rest l))

When applied to a list l1, append builds up a function that expects a second
list l2 and concatenates l2 to the end of l1. Clearly, append is a polynomial
time function, a linearngtime one in fact, but it is straightforward to write exng
ponential time algorithms in the language as we have defined it so far. For
instance:

val double : T list!T list =

iter (stop ) nil | hd with rest ) cons(hd,cons(hd,rest)))

val exp : T list!T list =

iter (stop ) nil | hd with rest ) double (cons(hd,rest)))

1. Since we are not interested in memory management here, we have simplified our operang
tional semantics from previous parts of this chapter by deleting the explicit store and using
substitution instead. The operational judgment has the form t -!fit0 and, in general, is defined
similarly to the operational systems in TAPL.

38 1 Substructural Type Systems

The key problem here is that it is trivial to write iterators like double that
increase the size of their arguments. After constructing one of these, we can
use it as the inner loop of another, like exp, and cause an exponential blowng
up in running time. But this is not the only problem. Higherngorder functions
make it even easier to construct exponentialngtime algorithms:

val compose =

*(fg:(T list!T list) * (T list!T list)).

*(x:T list).

split fg as f,g in f (g x)

val junk : T
val exp2 : T list!T list!T list =

iter (

stop ) *(l:T list).cons(junk,l)
| hd with rest ) *(l:T list).compose <rest,rest> l)

Fortunately, a substructural type system can be used to eliminate both
problems by allowing us to define a class of nonngsizengincreasing functions
and by preventing the construction of troublesome higherngorder functions,
such as exp2.

The first step is to demand that all userngdefined objects have affine type.
They can be used zero or one times, but not more. This restriction immeding
ately rules out programs such as exp2. System defined operators like cons
can be used many times.

The next step is to put mechanisms in place to prevent iterators from inng
creasing the size of their inputs. This can be achieved by altering the cons
constructor so that it can only be applied when it has access to a special
resource with type R.

operator cons : (R,T,T list) ! T list
There is no constructor for resources with type R so they cannot be generated
out of thin air; we can only apply fcons as many times as we have resources.
We also adapt the syntax for iterators as follows.

iter (stop ) t1 | hd with tl and r ) t2)
Inside the second clause of the iterator, we are only granted a single resource
(r) with which to allocate data. Consequently, we can allocate at most one
cons cell in t2. This provides us with the power to rebuild a list of the same
size, but we cannot write a function such as double that doubles the length
of the list or exp that causes an exponential increase in size. To ensure that

1.5 Further Applications 39
a single resource from an outer scope does not percolate inside the iterator
and get reused on each iteration of the loop, we require that iterators be
closed, mirroring the containment rules for recursive functions defined in
earlier sections of this chapter.

Although restricted to polynomial time, our language permits us to write
many useful functions in a convenient fashion. For instance, we can still write
append much like we did before. The resource we acquire from destructing
the list during iteration can be used to rebuild the list later.

val append : T list ! T list ! T list =

iter (

stop ) *(l:T list).l
| hd with rest and r ) *(l:T list). cons(r,hd,rest l))

We can also write double if our input list comes with appropriate credits,
in the form of unused resources.

val double : (T*R) list ! T list =

iter (

stop ) nil
| hd with rest and r1 )

split hd as x,r2 in cons(r1,hd,cons(r2,hd,rest)))

Fortunately, we will never be able to write exp, unless, of course, we are
given an exponential number of credits in the size of the input list. In that
case, our function exp would still only run in linear time with respect to our
overall input (list and resources included).

The proof that all (firstngorder) functions we can define in this language run
in polynomial time uses some substantial domain theory that lies outside
the scope of this book. However, the avid reader should see Section 1.6 for
references to the literature where these proofs can be found.

Compiler Optimizations
Many compiler optimizations are enabled when we know that there will be at
most one use or at least one use of a function, expression or data structure.
If there is at most one use of an object then we say that object has affine
type. If there is at least one use then we say the object has relevant (or strict)
type. The following sorts of optimizations employ usage information directly;
several of them have been implemented in the Glasgow Haskell Compiler.

* Floating in bindings. Consider the expression let x = e in (*y....x...).

Is it a good idea to float the binding inside the lambda and create the new

40 1 Substructural Type Systems

expression *y.let x = e in (...x...)? The answer depends in part on
how many times the resulting function is used. If it is used at most once,
the optimization might be a good one: we may avoid computing e and will
never compute it more than once.

* Inlining expressions. In the example above, if we have the further informang

tion that x itself is used at most once inside the body of the function, then
we might want to substitute the expression e for x. This may give rise to
further local optimizations at the site where e is used. Moreover, if it turns
out that e is used zero times (as opposed to one time) we will have saved
ourselves the trouble of computing it.

* Thunk update avoidance. In lazy functional languages such as Haskell,

evaluation of function parameters is delayed until the parameter is acng
tually used in the function body. In order to avoid recomputing the value
of the parameter each time it is used, implementers make each parameter
a thunk--a reference that may either hold the computation that needs to
be run or the value itself. The first time the thunk is used, the computation
will be run and will produce the necessary result. In general, this result is
stored back in the thunk for all future uses of the parameter. However, if
the compiler can determine that the data structure is used as most once,
this thunk update can be avoided.

* Eagerness. If we can tell that a Haskell expression is used at least once,

then we can evaluate it right away and avoid creating a thunk altogether.

The optimizations described above may be implemented in two phases. The
first phase is a program analysis that may be implemented as affine and/or
relevant type inference. After the analysis phase, the compiler uses the inforng
mation to transform programs. Formulating compiler optimizations as type
inference followed by typengdirected translation has a number of advantages
over other techniques. First, the language of types can be used to communing
cate optimization information across modular boundaries. This can facilitate
the process of scaling intrangprocedural optimizations to interngprocedural opng
timizations. Second, the type information derived in one optimization pass
can be maintained and propagated to future optimization passes or into the
back end of the compiler where it can be used to generate Typed Assembly
Language or ProofngCarrying Code, as discussed in Chapters 4 and 5.

1.6 Notes

Substructural logics are very old, dating back to at least Orlov (1928), who axng
iomatized the implicational fragment of relevant logic. Somewhat later, Moh

1.6 Notes 41
(1950) and Church (1951) provided alternative axiomatizations of the releng
vant logic now known as R. In the same time period, Church was developing
his theory of the lambda calculus at Princeton University, and his *I calculus
(1941), which disallowed abstraction over variables that did not appear free
in the body of the term, was the first substructural lambda calculus. Lambek
(1958) introduced the first "ordered logic," and used it to reason about natung
ral language sentence structure. More recently, Girard (1987) developed linear
logic, which gives control over both contraction and weakening, and yet prong
vides the full power of intuitionistic logic through the unrestricted modality
"!". O'Hearn and Pym (1999) show that the logic of bunched implications prong
vides another way to recapture the power of intuitionistic logic while giving
control over the structural rules.

For a comprehensive account of the history of substructural logics, please
see Dos^en (1993), who is credited with coining the phrase "substructural
logic," or Restall (2005). Restall's textbook on substructural logics (2000) prong
vides good starting point to those looking to study the technical details of
either the proof theory or model theory for these logics.

Reynolds pioneered the study of substructural type systems for programng
ming languages with his development of syntactic control of interference
(1978; 1989), which prevents two references from being bound to the same
variable and thereby facilitates reasoning about Algol programs. Later, Ging
rard's development of linear logic inspired many researchers to develop funcng
tional languages with linear types. One of the main applications of these new
type systems was to control effects and enable inngplace update of arrays in
pure functional languages.

Lafont (1988) was the one of the first to study programming languages
with linear types, developing a linear abstract machine. He was soon followed
by many other researchers, including Baker (1992) who informally showed
how to compile Lisp into a linear assembly language in which all allocation,
deallocation and pointer manipulation is completely explicit, yet safe. Anng
other influential piece of work is due to Chirimar, Gunter, and Riecke (1996)
who developed an interpretation of linear logic based on reference countng
ing. The reference counting scheme described here is directly inspired by the
work of Chirimar et al., but the technical setup is slightly different; we have
explicit operations to increment and decrement reference counts whereas inng
crementing and decrementing counts in Chirimar's system is done implicitly.
Stephanie Weirich suggested the invariant for proving our reference countng
ing system sound. Turner and Wadler (1999) summarize two computational
interpretations that arise directly through the CurryngHoward isomorphism
from Girard's linear logic. They differ from the account given in this chapter
as neither account has both shared, usable data structures and deallocation.
Unfortunately, these two features together appear incompatible with a type

42 1 Substructural Type Systems

system derived directly from linear logic and its single unrestricted modality.

The development of practical linear type systems with two classes of type,
one linear and one unrestricted, began with Wadler's work (1990) in the early
nineties. The presentation given in this chapter is derived from Wadler's work
and is also inspired by work from Wansbrough and Peyton Jones (1999) and
Walker and Watkins (2001). Wansbrough and Peyton Jones included qualifier
subtyping and bounded parametric polymorphism in their system in addition
to many of the features described here. Walker and Watkins added reference
counting features to a language with linear types and also memory regions.
The idea of formulating the system with a generic context splitting operator
was taken from Cervesato and Pfenning's presentation of Linear LF (2002).

The algorithmic type system described in section 1ng5 solves what is comng
monly known in the linear logic programming and theorem proving literature,
as the resource management problem. Many of the ideas for the current preng
sentation came from work by Cervesato, Hodas, and Pfenning (2000), who
solve the more general problem that arises when linear logic's additive conng
nectives are considered. Hofmann takes a related approach when solving the
type inference problem for a linearlyngtyped functional language (1997a).

The ordered type system developed here is derived from Polakow and Pfenng
ning's ordered logic (1999), in the same way that the practical linear type
systems mentioned above emerged from linear logic. It was also inspired by
the ordered lambda calculus of Petersen, Harper, Crary, and Pfenning (2003),
though there are some technical differences. Ahmed and Walker (2003) and
Ahmed, Jia, and Walker (2003) use an ordered, modal logic to specify memory
invariants and have integrated the logical specifications into a lownglevel typed
language. Igarashi and Kobayashi (2002) have used ordered types to explore
the more general problem of resource usage analysis. In addition, they have
developed effective type inference algorithms for their type systems.

Recently, O'Hearn (2003) has proposed bunched typing, a new form of subng
structural typing, to control interference between mutable variables, generng
alizing Reynolds's earlier work on syntactic control of interference. These
bunched types were derived from earlier work by O'Hearn and Pym (1999)
on bunched logic. Together, Reynolds, Ishtiaq, and O'Hearn (Reynolds, 2000;
Ishtiaq and O'Hearn, 2001) have used bunched logic to develop a system for
verifying programs that explicitly allocate and deallocate data.

Analysis and reasoning about the time and space complexity of programs
has always been an important part of computer science. However, the use
of programming language technology, and type systems in particular, to aung
tomatically constrain the complexity of programs is somewhat more recent.
For instance, Bellantoni and Cook (1992) and Leivant (1993) developed predng
icative systems that control the use and complexity of recursive functions.

1.6 Notes 43
It is possible to write all, and only, the polynomialngtime functions in their
system. However, it is not generally possible to compose functions and thereng
fore many "obviously" polynomialngtime algorithms cannot be coded naturally
in their system. Girard (1998), Hofmann (2000; 1999), and Bellantoni, Niggl,
and Schwichtenberg (2000) show how linear type systems can be used to alng
leviate some of these difficulties. The material presented in this chapter is
derived from Hofmann's work.

One of the most successful and extensive applications of substructural
type systems in programming practice can be found in the Concurrent Clean
programming language (No"cker, Smetsers, van Eekelen, and Plasmeijer, 1991).
Clean is a commercially developed, pure functional programming language. It
uses uniqueness types (Barendsen and Smetsers, 1993), which are a variant of
linear types, and strictness annotations (No"cker and Smetsers, 1993) to help
support concurrency, I/O and inngplace update of arrays. The implementation
is fast and is fully supported by a wide range of program development tools
including an Integrated Development Environment for project management
and GUI libraries, all developed in Clean itself.

Substructural type systems have also found gainful employment in the inng
termediate languages of the Glasgow Haskell Compiler. For instance, Turner,
Wadler, and Mossin (1995) and Wansbrough and Peyton Jones (1999) showed
how to use affine types and affine type inference to optimize programs as
discussed earlier in this chapter. They also use extensive strictness analysis
to avoid thunk creation.

Recently, researchers have begun to investigate ways to combine substrucng
tural type systems with dependent types and effect systems such as those
described in Chapters 2 and 3. The combination of both dependent and subng
structural types provides a very powerful tool for enforcing safe memory
management and more general resourcengusage protocols. For instance, Deng
Line and Fa"hndrich developed Vault (2001; 2002), a programming language
that uses static capabilities (Walker, Crary, and Morrisett, 2000) (a hybrid
form of linear types and effects) to enforce a variety of invariants in Microsoft
Windows device drivers including locking protocols, memory management
protocols and others. Cyclone (Jim et al., 2002; Grossman et al., 2002), a
completely typengsafe substitute for C, also uses linear types and effects to
grant programmers finenggrained control over memory allocation and deallong
cation. In each of these cases, the authors do not stick to the pure linear types
described here. Instead, they add coercions to the language to allow linearlyng
typed objects to be temporarily aliased in certain contexts, following a long
line of research on this topic (Wadler, 1990; Odersky, 1992; Kobayashi, 1999;
Smith, Walker, and Morrisett, 2000; Aspinall and Hofmann, 2002; Foster, Terng
auchi, and Aiken, 2002; Aiken, Foster, Kodumal, and Terauchi, 2003).

2 Dependent Types

David Aspinall and Martin Hofmann

In the most general sense, dependent types are typengvalued functions. This
definition includes, for example, the type operators of F ! such as Pair. When
applied to two types S and T, this yields the type Pair S T whose elements
are pairs D^s; tE^ of elements s from S and t from T (see TAPL, Chapter 29).
However, the terminology "dependent types" is usually used to indicate a
particular class of typengvalued functions: those functions which send terms
to types. In this chapter we study this kind of dependency.

2.1 Motivations

We begin the chapter by looking at a few representative examples of where
typengterm dependency occurs naturally.

Programming with Vectors and Format Strings
The prototypical example of programming with dependent types is introng
duced by the type family of vectors (onengdimensional arrays):

Vector :: Nat ! *
This kinding assertion states that Vector maps a natural number k:Nat to
a type. The idea is that the type Vector k contains vectors of length k of
elements of some fixed type, say data.

To use vectors, we need a way of introducing them. A useful initialization
function takes a length n, a value t of type data, and returns a vector with n

The system studied in this chapter is the dependently typed lambdangcalculus, *LF (Figures 2ng1,
2ng2), extended with \Sigma ngtypes (Figure 2ng5) and the Calculus of Constructions (Figure 2ng7). The
associated OCaml implementation, called deptypes, can be found on the book's web site.

46 2 Dependent Types

elements all set to t. The typing of such an init function is written like this,

init : \Pi n:Nat. data ! Vector n
and the application init k t has type Vector k.

The type of init introduces the dependent product type (or "Pi type"), writng
ten \Pi x:S.T. This type generalizes the arrow type of the simply typed lambdang
calculus. It is the type of functions which map elements s:S to elements of
E,x , sG*T. In contrast to the simplyngtyped case, the result type of a function
with a \Pi ngtype can vary according to the argument supplied. According to
Seldin (2002), the \Pi ngtype goes back to Curry and is thus almost as old as the
lambda calculus itself.

A more interesting way of building up vectors is given by the constant
empty vector empty : Vector 0 and a constructor for building longer vectors:

cons : \Pi n:Nat. data ! Vector n ! Vector (n+1):
The typing of cons expresses that cons takes three arguments: a natural
number n, an element of type data, and a vector of length n. The result is
a vector of length n+1. This means that, for example, if v : Vector 5 and
x : data, then cons 5 x v : Vector 6.

The dependent product type \Pi x:S.T is somewhat analogous to the uning
versal type 8X.T of System F. The type of a term t with type 8X.T also
varies with the argument supplied; but in the case of a type abstraction, the
argument is a type rather than a term. If A is a type, then t A:E,X , AG*T. In
System F (and F !), type variation occurs only with type arguments, whereas
in dependent type theory it may occur with termnglevel arguments.

The reader familiar with programming with ordinary arrays will have realng
ized that by using a type of arrays instead of vectors we could avoid depenng
dent typing. The initialization function for onengdimensional arrays could be
given the simple type Nat ! data ! Array, where Array is the type of arrays
with entries of type data. The point of the dependent typing is that it reveals
more information about the behavior of a term, which can be exploited to
give more precise typings and exclude more of the badly behaved terms in a
type system. For example, with the dependent type of vectors, we can type a
function that returns the first element of a nonngempty vector:

first : \Pi n:Nat.Vector(n+1) ! data
The function first can never be applied to an empty vector--nonngemptiness
is expressed within the type system itself! This is a useful gain. With ordinary
arrays instead of dependentlyngtyped vectors, we would need some special
way to deal with the case when first is applied to the empty array. We
could return an adnghoc default element, or we might use a languagengbased

2.1 Motivations 47
exception mechanism to indicate the error. Either mechanism is more clumsy
than simply prohibiting illegal applications of first from being written.

We suggested that \Pi x:S.T generalizes the function space S!T of simply
typed lambda calculus. In fact, we can treat S!T simply as an abbreviation:

S!T C^ \Pi x:S.T where x does not appear free in T
For example, \Pi x:Nat.Nat is exactly equivalent to Nat ! Nat. We will conng
tinue to write the arrow ! whenever possible, to increase readability.

Another favorite example of a function with a useful dependent typing is
sprintf of the C language.1 Recall that sprintf accepts a format string and
list of arguments whose types must correspond to the declarations made
in the format string. It then converts the given arguments into a string and
returns it. A simplified form of sprintf might have the typing:

sprintf : \Pi f:Format. Data(f) ! String
where we suppose that Format is a type of valid print formats (for examng
ple, considered as character lists) and that Data(f) is the type of data corng
responding to format f. The function Data(f) evaluates the type that the
format string describes, which might include clauses like these:

Data([]) C^ Unit
Data("%d"::cs) C^ Nat * Data(cs)
Data("%s"::cs) C^ String * Data(cs)
Data(c::cs) C^ Data(cs)

This example is rather different to the case of vectors. Vectors are uniform:
we introduce operations that are parametric in the length n, and the family
of types Vector n is indexed by n. In the case of format strings, we use case
analysis over values to construct the type Data(f) which depends on f in
an arbitrary way. Unsurprisingly, this nonnguniform kind of dependent type is
more challenging to deal with in practical type systems for programming.

2.1.1 Exercise [n']: Suggest some dependent typings for familiar data types and

their operations. For example, consider matrices of size n * m and the typing
of matrix multiplication, and a type of dates where the range of the day is
restricted according to the month. 2

1. A sprintfnglike formating function can also be typed in ML without dependent types if
formats are represented as appropriate higherngorder functions rather than strings. For details
see Danvy (1998).

48 2 Dependent Types

The CurryngHoward Correspondence
A rather different source for dependent typing is the CurryngHoward correng
spondence, also known by the slogan propositionsngasngtypes (Howard, 1980).
Under this correspondence simple types correspond to propositions in the
implicational fragment of constructive logic. A formula has a proof if and
only if the corresponding type is inhabited. For instance, the formula

((A!B) ! A) ! (A!B) ! B
is valid in constructive logic and at the same time is inhabited, namely by
*f.*u.u(f u). The underlying philosophical idea behind this correspondence
is that a constructive proof of an implication A =) B ought to be understood
as a procedure that transforms any given proof of A into a proof of B.

If propositions are types, then proofs are terms. We can introduce a type
constructor Prf which maps a formula A (understood as a type) into the type
of its proofs Prf A, and then a proof of A =) B becomes a *ngterm of type
Prf A ! Prf B. Often the type constructor Prf is omitted, notationally identing
fying a proposition with the type of its proofs. In that case, a proof of A =) B
is simply any term of type A!B.

Generalizing the correspondence to firstngorder predicate logic naturally
leads to dependent types: a predicate B over type A is viewed as a typeng
valued function on A; a proof of the universal quantification 8x:A.B(a)
is--constructively--a procedure that given an arbitrary element x of type A
produces a proof of B(x). Hence under the CurryngHoward correspondence
we should identify universal quantification with dependent product: a proof
of 8x:A.B(x) is a member of \Pi x:A.B(x). Indeed, Per MartinngLo"f, one of the
protagonists of dependent typing (1984), was motivated by this extension. In
particular, he introduced typengtheoretic equivalents to existential quantificang
tion (\Sigma ngtypes) and equality (identity types), used in the next example.

An important application of the CurryngHoward correspondence is that it
allows one to freely mix propositions and (programming language) types. For
example, an indexing function ith(n) to access elements of vectors of length
n could be given the type

\Pi n:Nat.\Pi l:Nat.Lt(l,n)!Vector(n)!T
where Lt(l,n) is the proposition asserting that l is less than n. Perhaps more
interestingly, we can package up types with axioms restricting their elements.
For instance, the type of binary, associative operations on some type T may
be given as

\Sigma m:T!T!T.\Pi x:T.\Pi y:T.\Pi z:T.Id (m(x,m(y,z))) (m(m(x,y),z))

2.1 Motivations 49
Here \Sigma x:A.B(x) is the type of pairs (a,b) where a:A and b:B(a) and Id t1 t2
is the type of proofs of the equality t1=t2. In MartinngLo"f's type theory existenng
tial quantification is rendered with \Sigma ngtypes, the idea being that a constructive
proof of 9x:A.B(x) would consist of a member a of type A and a proof, thus
a member, of B(a)--in other words, an element of \Sigma a:A.B(a).

2.1.2 Exercise [n']: Write down a type which represents a constructive version of

the axiom of choice, characterised by: if for every element a of a type A there
exists an element b of B such that P(a,b) then there exists a function f mapng
ping an arbitrary x:A to an element of B such that P(x, f x). 2

2.1.3 Exercise [n']: Suppose that f : A!C, g : B!C are two functions with equal

target domain. Using setngtheoretic notation we can form their pullback as
{D^a; bE^ 2 A * B | f a C^ g b}. Define an analogous type using \Sigma  and Id. 2

Logical Frameworks
Dependent types have also found application in the representation of other
type theories and formal systems. Suppose that we have an implementation
of dependent types and want to get a roughngandngready typechecker for simply
typed lambda calculus. We may then make the following declarations:

Ty :: *
Tm :: Ty ! *
base : Ty
arrow : Ty ! Ty ! Ty
app : \Pi A:Ty.\Pi B:Ty.Tm(arrow A B) ! Tm A !Tm B
lam : \Pi A:Ty.\Pi B:Ty.(Tm A ! Tm B) ! Tm(arrow A B)

Here Ty represents the type of simple type expressions and for A:Ty the
type Tm A represents the type of lambda terms of type A. We have a constant
base:Ty representing the base type and a function arrow representing the
formation of arrow types. As for terms we have a function app that accepts
to types A,B, a term of type arrow A B, a term of type A and yields a term of
type B: the application of the two.

Somewhat intriguingly, the function corresponding to lambda abstraction
takes a "function" mapping terms of type A to terms of type B and returns a
term of type arrow A B. This way of using functions at one level to represent
dependencies at another level is particularly useful for representing syntax
with binders, and the technique is known as higherngorder abstract syntax.

We can now represent familiar terms such as the identity on A:Ty by

idA = lam A A (*x:Tm A.x)

50 2 Dependent Types

or the Church numeral 2 on type A by

two = *A:Ty.lam A (arrow (arrow A A) A)

(*x:Tm A.lam _ _ (*f:Tm(arrow A A).

app _ _ f (app _ _ f x)))

(replacing some obvious type arguments by underscores to aid readability).

Logical frameworks are systems which provide mechanisms for representng
ing syntax and proof systems which make up a logic. The exact representation
mechanisms depend upon the framework, but one approach exemplified in
the Edinburgh Logical Framework (Harper, Honsell, and Plotkin, 1993) is sugng
gested by the slogan judgmentsngasngtypes, where types are used to capture the
judgments of a logic.2

2.1.4 Exercise [n']: Write down some typing declarations which introduce a judgng

ment expressing an evaluation relation for the representation of simply typed
terms shown above. You should begin with a type family Eval which is pang
rameterized on a simple type A and two terms of type Tm A, and declare four
terms which represent the rules defining the compatible closure of onengstep
betangreduction. 2

2.2 Pure FirstngOrder Dependent Types

In this section we introduce one of the simplest systems of dependent types,
in a presentation called *LF. As the name suggests, this type system is based
on a simplified variant of the type system underlying the Edinburgh LF, menng
tioned above. The *LF type theory generalizes simply typed lambdangcalculus
by replacing the arrow type S!T with the dependent product type \Pi x:S.T
and by introducing type families. It is pure, in the sense that it has only \Pi ng
types; it is firstngorder, in the sense that it does not include higherngorder type
operators like those of F !. Under the CurryngHoward correspondence, this
system corresponds to the 8,!ngfragment of firstngorder predicate calculus.

Syntax
The main definition of *LF appears in Figure 2ng1 and 2ng2. The terms are
the same as those of the simply typed lambda calculus *!. The types inng
clude type variables X which can be declared in the context but never appear
bound. Type variables range over proper types as well as type familes such as

2. Judgments are the statements of a logic or a type system. For example, wellngformedness,
derivability, wellngtypedness. In LF these judgments are represented as types and derivations of
a judgment are represented as members.

2.2 Pure FirstngOrder Dependent Types 51
*LF
Syntax

t ::= terms:

x variable
*x:T.t abstraction
t t application
T ::= types:

X type/family variable
\Pi x:T.T dependent product type
T t type family application
K ::= kinds:

* kind of proper types
\Pi x:T.K kind of type families
\Gamma  ::= contexts:

; empty context
\Gamma  ; x:T term variable binding
\Gamma  ; X::K type variable binding

Wellngformed kinds \Gamma  ` K

\Gamma  ` * (WfngStar)
\Gamma  ` T :: * \Gamma  ; x:T ` K

\Gamma  ` \Pi x:T.K (WfngPi)

Kinding \Gamma  ` T :: K

X :: K 2 \Gamma  \Gamma  ` K

\Gamma  ` X :: K (KngVar)
\Gamma  ` T1 :: * \Gamma  ; x:T1 ` T2 :: *

\Gamma  ` \Pi x:T1.T2 :: * (KngPi)
\Gamma  ` S :: \Pi x:T.K \Gamma  ` t : T

\Gamma  ` S t : E,x , tG*K (KngApp)
\Gamma  ` T :: K \Gamma  ` KjK0

\Gamma  ` T :: K0 (KngConv)

Typing \Gamma  ` t : T

x:T 2 \Gamma  \Gamma  ` T :: *

\Gamma  ` x : T (TngVar)
\Gamma  ` S :: * \Gamma  ; x:S ` t : T

\Gamma  ` *x:S.t : \Pi x:S.T (TngAbs)
\Gamma  ` t1 : \Pi x:S.T \Gamma  ` t2 : S

\Gamma  ` t1 t2 : E,x , t2G*T (TngApp)
\Gamma  ` t : T \Gamma  ` T j T0 :: *

\Gamma  ` t : T0 (TngConv)

Figure 2ng1: Firstngorder dependent types (*LF)

Vector :: Nat ! *. We may use type and term variables declared in a fixed
initial context to simulate the builtngin types and operators of a programming
language.3 Apart from variables, types may be dependent products or type
family applications. The latter allow us to instantiate families, for example,
to give types such as Vector k for k:Nat.

Kinds allow us to distinguish between proper types and type families.
Proper types have kind * while type families have dependent product kinds
of the form \Pi x:T.K.

Contexts may bind term variables and type variables.

3. Strictly speaking, we should consider a signature as a special form of context and conng
sider the term and type variables declared in it to be the constants of the language. This isn't
necessary when we move to richer type theories in which it is possible to define data types.

52 2 Dependent Types

*LF

Kind Equivalence \Gamma  ` K j K0

\Gamma  ` T1 j T2 :: * \Gamma  ; x:T1 ` K1 j K2

\Gamma  ` \Pi x:T1.K1 j \Pi x:T2.K2 (QKngPi)

\Gamma  ` K
\Gamma  ` K j K (QKngRefl)
\Gamma  ` K1 j K2
\Gamma  ` K2 j K1 (QKngSym)
\Gamma  ` K1 j K2 \Gamma  ` K2 j K3

\Gamma  ` K1 j K3 (QKngTrans)

Type Equivalence \Gamma  ` S j T :: K

\Gamma  ` S1 j T1 :: * \Gamma  ; x:T1 ` S2 j T2 :: *

\Gamma  ` \Pi x:S1.S2 j \Pi x:T1.T2 :: *

(QTngPi)
\Gamma  ` S1 j S2 :: \Pi x:T.K \Gamma  ` t1 j t2 : T

\Gamma  ` S1 t1 j S2 t2 : E,x , t1G*K

(QTngApp)
\Gamma  ` T : K

\Gamma  ` T j T :: K (QTngRefl)
\Gamma  ` T j S :: K
\Gamma  ` S j T :: K (QTngSym)

\Gamma  ` S j U :: K \Gamma  ` U j T :: K

\Gamma  ` S j T :: K (QTngTrans)

Term Equivalence \Gamma  ` t1jt2 : T

\Gamma  ` S1 j S2 :: * \Gamma  ; x:S1 ` t1 j t2 : T

\Gamma  ` *x:S1.t1 j *x:S2.t2 : \Pi x:S1.T

(QngAbs)
\Gamma  ` t1 j s1 : \Pi x:S.T \Gamma  ` t2 j s2 : S

\Gamma  ` t1 t2 j s1 s2 : E,x , t2G*T

(QngApp)
\Gamma  ; x:S ` t : T \Gamma  ` s : S

\Gamma  ` (*x:S.t) s j E,x , sG*t : E,x , sG*T

(QngBeta)

\Gamma  ` t : \Pi x:S.T x 62 FVD^tE^

\Gamma  ` *x:T.t x j t : \Pi x:S.T (QngEta)

\Gamma  ` t : T
\Gamma  ` t j t : T (QngRefl)
\Gamma  ` t j s : T
\Gamma  ` s j t : T (QngSym)
\Gamma  ` s j u : T \Gamma  ` u j t : T

\Gamma  ` s j t : T (QngTrans)

Figure 2ng2: Firstngorder dependent types (*LF)--Equivalence rules

Typechecking Rules
The rules in Figure 2ng1 define three judgment forms, for checking kind forng
mation, kinding, and typing.

The characteristic typing rules of the system are the abstraction and appling
cation rules for terms, altered to use \Pi ngtypes. The abstraction introduces a
dependent product type, checking that the domain type S is wellngformed:

\Gamma  ` S :: * \Gamma  ; x:S ` t : T

\Gamma  ` *x:S.t : \Pi x:S.T (TngAbs)
The term application rule eliminates a term with this type, substituting the
operand in the \Pi ngtype:

\Gamma  ` t1 : \Pi x:S.T \Gamma  ` t2 : S

\Gamma  ` t1 t2 : E,x , t2G*T (TngApp)

2.2 Pure FirstngOrder Dependent Types 53

The wellngformedness check in TngAbs uses the kinding rules to ensure that S
is a type. Notice that this check may again invoke the typing rules, in the rule
KngApp, which checks the instantiation of a type family. The kind formation
judgment also invokes the wellngformedness of types (in the first premise of
WfngPi), so the three judgment forms are in fact mutually defined. One conseng
quence is that proofs of properties in this system typically proceed by simulng
taneous proofs for the different judgment forms, using derivation height as
an overall measure or alternatively simultaneous structural induction.

There are two conversion rules, KngConv and TngConv, which allow us to
replace a kind or type with another one that is equivalent.

Kinds have the general form \Pi x1:T1. : : : xn:Tn.* but in the typing rules
we only ever need to check for proper types with kind *. Nevertheless, we
include the KngConv to ensure that kinding is closed under conversion within
the Ti. There is no mechanism for forming kinds by abstraction, so the only
way to construct an object of a kind other than * is by declaring it in the
context.

Equivalence Rules
One of the main questions in any type system is when two types should be
considered equivalent. Type equivalence is in particular needed in the appling
cation rules TngApp and KngApp. To show that some actual argument has an
acceptable type for a function or type family, we may need to use the rule
TngConv to convert the type. In fact, the algorithmic typing rules introduced
later on show that this is the only place where type equivalence is needed.

But what should our notion of type equivalence be? Without adding speng
cial equality axioms, we can consider natural notions of equality which arise
from the type structure. With dependent types, a natural notion is to equate
types that differ only in their term components, when those term compong
nents themselves should be considered equal. So the question is reduced to
considering notions of term equality.

A first example is a typengfamily application containing a fingredex, since we
consider fingequivalent *ngterms to be equal: T ((*x:S.x) z) j T z. A slightly
different and more concrete example is two different applications of the
Vector family: Vector (3 + 4) j Vector 7. It seems reasonable that a typeng
checker should accept each of these pairs of types as being equivalent. But
we quickly come across more complex equivalences involving more comng
putation, or even, requiring proof in the general case. For example, supng
posing x is an unknown value of type Nat and f:Nat ! Nat is a function
whose behavior is known. If it happens that f x=7 for all x then we have
Vector (f x) j Vector 7, but this equality could be more difficult to add
to an automatic typechecker.

54 2 Dependent Types

The question of what form of type equivalence to include in a system of deng
pendent types is therefore a central consideration in the design of the system.
Many different choices have been studied, leading to systems with fundang
mentally different character. The most notable distinction between systems
is whether or not typechecking is decidable.

In the first case, we may choose to include only basic equalities which are
manifestly obvious. This is the viewpoint favored by MartinngLo"f, who considng
ers definitional equality to be the proper notion of equivalence. The first two
equalities above are definitional: 3 + 4 is definitionally equal to 7 by the rules
of computation for addition. Alternatively, one may prefer to include as many
equalities as possible, to make the theory more powerful. This is the approach
followed, for example, in the type theory implemented by the NuPrl system
(1986). This formulation of type theory includes type equivalences like the
third example above, which may require arbitrary computation or proof to
establish. In such a type system, typechecking is undecidable.

For *LF, we axiomatize definitional equality based on the type structure,
which includes fi and j equality on lambda terms. It is possible to define this
using a relation of equality defined via compatible closure of untyped reducng
tion (this is the approach followed by Pure Type Systems, see Section 2.7).
Instead, we give a declarative, typed definition of equivalence, using rules
which follow the same pattern as the typing rules. The advantage of this apng
proach is that it is more extensible than the "untyped" approach and avoids
the need to establish properties of untyped reduction. See Chapter 6 in this
volume for further explanation of the issues here.

The rules for equivalence are shown in Figure 2ng2. Again there are three
judgments, for equivalence of each of the syntactic categories of terms, types,
and kinds. The only interesting rules are QngBeta and QngEta which introduce
fi and jngequivalence on terms; the remaining rules are purely structural and
express that equivalence is a congruence.

2.3 Properties

In this section we mention some basic properties of *LF. We don't go very far:
in Section 2.4 we introduce an algorithmic presentation of *LF which allows
us to establish further properties indirectly but rather more easily.

Basic Properties
The following properties use some additional notation. Inclusion is defined
between contexts as \Gamma  ` \Delta  iff x:T 2 \Gamma  implies x:T 2 \Delta , in other words,

2.3 Properties 55
\Gamma  ` \Delta  means that \Delta  is a permutation of an extension of \Gamma  . We write \Gamma  ` J
for an arbitrary judgment, amongst the six defined in Figures 2ng1 and 2ng2. We
write \Gamma  ` K; K0 to stand for both \Gamma  ` K and \Gamma  ` K0, and similarly for other
judgments.

2.3.1 Lemma [Permutation and Weakening]: Suppose \Gamma  ` \Delta . Then \Gamma  ` J implies

\Delta  ` J. 2

2.3.2 Lemma [Substitution]: If \Gamma  ; x:S; \Delta  ` J and \Gamma  ` s : S, then \Gamma  ; E,x , sG*\Delta  `

E,x , sG*J. 2

2.3.3 Lemma [Agreement]: Judgments in the system are in agreement, as follows:

1. If \Gamma  ` T :: K then \Gamma  ` K.
2. If \Gamma  ` t : T then \Gamma  ` T :: *.
3. If \Gamma  ` K j K0 then \Gamma  ` K, K0.
4. If \Gamma  ` T j T0 :: K then \Gamma  ` T, T0 :: K.
5. If \Gamma  ` t j t0 : T then \Gamma  ` t, t0 : T. 2
2.3.4 Exercise [n'n', 3]: Prove the lemmas above. 2

Strong Normalization
As an auxiliary device for the soundness and completeness of algorithmic
typechecking we will now introduce general beta reduction which permits
reductions within the scope of abstractions.

We define beta reduction on *LF terms by the four rules:

t1 -!fi t01
*x:T1.t1 -!fi *x:T1.t01 (BetangAbs)

t1 -!fi t01
t1 t2 -!fi t01 t2 (BetangApp1)

t2 -!fi t02
t1 t2 -!fi t1 t02 (BetangApp2)

(*x:T1.t1) t2 -!fi E,x , t2G*t1 (BetangAppAbs)
Notice that this reduction does not go inside the type labels of * abstractions.

The following central result is required to ensure completeness and terming
nation of typechecking, proved in the next section.

56 2 Dependent Types

2.3.5 Theorem [Strong normalization]: The relation -!fi is strongly normalizng

ing on wellngtyped terms. More precisely, if \Gamma  ` t:T then there is no infinite
sequence of terms D^tiE^i>=1 such that t C^ t1 and ti -!fi ti+1 for i >= 1. 2

Proof: This can be proved by defining a reductionngpreserving translation
from *LF to the simplyngtyped lambdangcalculus as follows. First, for every type
variable X, no matter of what kind, we introduce a simple type variable X".
Second, for each type expression T, no matter of what kind, we define a simng
ple type expression T" by \Pi x:S.T" C^ S"!T" and (T t)" C^ T". Finally, the
mapping -" is extended to terms and contexts by applying it to all type exng
pressions occurring within.

Now we can show by induction on typing derivations in *LF that \Gamma  ` t:T
implies \Gamma  " ` t":T"; from which the result follows by the strong normalization
theorem for fingreduction of the simply typed lambda calculus. 2

Since -!fi is finitely branching, this implies that for each term t there exists
a number uD^tE^ such that if D^tiE^1<=i<=k is a reduction sequence starting from t,
that is, t=t1 and ti -!fi ti+1 for 1 <= i < k then k <= uD^tE^. A term t0 such that
t -!fi* t0 and t0 6 -!fi is called a (fi) normal form of t. Since -!fi is confluent,
see below, normal forms are unique and we may write t0 C^ nfD^tE^.

2.3.6 Theorem: The relation -!fi is confluent. 2

2.3.7 Exercise [n'n'n', 3]: Prove the theorem in the following way: first show that

-!fi is locally confluent in the sense that if t -!fi t1 and t -!fi* t2 then
t1 -!fi* t0 and t2 -!fi t0 for some t0. Then conclude confluence using the
fact that -!fi is strongly normalizing. This last part is a standard result from
term rewriting known as Newman's Lemma.

Alternatively, you can prove confluence directly using Tait-MartinngLo"f's
method of parallel reduction, see TAPL, Chapter 30. 2

2.4 Algorithmic Typing and Equality

To implement *LF, we need to find a formulation of the system that is closer
to an algorithm. As usual, we follow the strategy of reformulating the rules
to be syntaxngdirected, so that they can be used to define an algorithm going
from premises to conclusion (see the description of the implementation in
Section 2.9) . We also need an algorithm for deciding type equivalence.

The algorithmic presentation of *LF is shown in Figures 2ng3 and 2ng4. The
judgments mirror the defining presentation, with the addition of a context
checking judgment. (This is used only to check an initial context: the rules
otherwise maintain context wellngformation when extending contexts going
from conclusions to premises.)

2.4 Algorithmic Typing and Equality 57

The nonngsyntaxngdirected rules Kngconv and Tngconv are removed. To replace
Tngconv, we add equivalence testing in the algorithmic rules for applications,
KAngapp and TAngapp.

The equivalence testing rules in Figure 2ng4 assume that they are invoked
on wellngtyped phrases. We show these rules with contexts \Gamma  to facilitate exng
tensions to typengdependent equalities or definitions in the context (used in
the implementation), although in the rules for pure *LF, the context plays no
role in equivalence testing.

The equivalence testing algorithm on terms that is suggested by these rules
is similar to the one described in Chapter 6, but we do not make use of type
information. (Similarly, the type equivalence rules do not record kinds.) The
algorithmic judgment \Gamma  `n~ s j t for arbitrary terms is defined mutually with
\Gamma  `n~ s jwh t which is defined between weak head normal forms. Weak head
reduction is a subset of the fi reduction -!fi, defined by the rules:

t1 -!wh t01
t1 t2 -!wh t01 t2 (WHngApp1)
(*x:T1.t1) t2 -!wh E,x , t2G*t1 (WHngAppAbs)
Weak head reduction only applies fingreduction in the head position. The imng
plementation described in Section 2.9 adds expansion of definitions to this
reduction; see Chapter 9 for a thorough treatment of how to do this.

2.4.1 Theorem [Weak head normal forms]: If \Gamma  ` t:T then there exists a unique

term t0 C^ whnfD^tE^ such that t -!wh* t0 6 -!wh. 2

The theorem is a direct consequence of Theorem 2.3.5 and of the fact that

-!wh is deterministic (a partial function).

Correctness of the Algorithm
We will now show that the typechecking algorithm defined by the algorithmic
rules is sound, complete, and terminates on all inputs.

Since the algorithm checks the context only as it is extended, and (for efng
ficiency) does not check the type of variables in the leaves, we can only exng
pect to show soundness for contexts which are wellngformed. The soundness
lemma makes use of an auxiliary algorithmic judgment for context formation:

`n~ ; (WFAngEmpty)
`n~ \Gamma  \Gamma  `n~ T :: *

`n~ \Gamma  ; x:T (WFAngTm)
`n~ \Gamma  \Gamma  `n~ K

`n~ \Gamma  ; X::K (WFAngTy)

58 2 Dependent Types

Algorithmic kind formation \Gamma  `n~ K

\Gamma  `n~ * (WFAngStar)
\Gamma  `n~ T :: * \Gamma  ; x:T `n~ K

\Gamma  `n~ \Pi x:T.K (WFAngPi)

Algorithmic kinding \Gamma  `n~ T :: K

X :: K 2 \Gamma 
\Gamma  `n~ X :: K (KAngVar)
\Gamma  `n~ T1 :: * \Gamma  ; x:T1 `n~ T2 :: *

\Gamma  `n~ \Pi x:T1.T2 :: * (KAngPi)

\Gamma  `n~ S :: \Pi x:T1.K \Gamma  `n~ t : T2

\Gamma  `n~ T1 j T2

\Gamma  `n~ S t : E,x , tG*K (KAngApp)

Algorithmic typing \Gamma  `n~ t : T

x:T 2 \Gamma 
\Gamma  `n~ x : T (TAngVar)
\Gamma  `n~ S :: * \Gamma  ; x:S `n~ t : T

\Gamma  `n~ *x:S.t : \Pi x:S.T (TAngAbs)
\Gamma  `n~ t1 : \Pi x:S1.T \Gamma  `n~ t2 : S2

\Gamma  `n~ S1 j S2

\Gamma  `n~ t1 t2 : E,x , t2G*T (TAngApp)

Figure 2ng3: Algorithmic presentation of *LF

Algorithmic kind equivalence \Gamma  `n~ K j K0

\Gamma  `n~ * j * (QKAngStar)
\Gamma  `n~ T1 j T2 \Gamma  ; x:T1 `n~ K1 j K2

\Gamma  `n~ \Pi x:T1.K1 j \Pi x:T2.K2 (QKAngPi)

Algorithmic type equivalence \Gamma  `n~ S j T

\Gamma  `n~ X j X (QTAngVar)
\Gamma  `n~ S1 j T1 \Gamma  ; x:T1 `n~ S2 j T2

\Gamma  `n~ \Pi x:S1.S2 j \Pi x:T1.T2 (QTAngPi)
\Gamma  `n~ S1 j S2 \Gamma  `n~ t1 j t2

\Gamma  `n~ S1 t1 j S2 t2 (QTAngApp)

Algorithmic term equivalence \Gamma  `n~ s j t

\Gamma  `n~ whnfD^sE^ jwh whnfD^tE^

\Gamma  `n~ s j t (QAngWH)
\Gamma  `n~ x jwh x (QAngVar)
\Gamma  ; x:S `n~ t1 j t2
\Gamma  `n~ *x:S.t1 jwh *x:S.t2 (QAngAbs)
\Gamma  `n~ s1 jwh s2 \Gamma  `n~ t1 jwh t2

\Gamma  `n~ s1 t1 jwh s2 t2 (QAngApp)
\Gamma  ; x:S `n~ s x j t s not a *

\Gamma  `n~ s jwh *x:S.t (QAngNabs1)
\Gamma  ; x:S `n~ s j t x t not a *

\Gamma  `n~ *x:S.s jwh t (QAngNabs2)

Figure 2ng4: Algorithmic presentation of *LF--Equivalence rules

2.4 Algorithmic Typing and Equality 59
2.4.2 Lemma [Soundness of algorithmic *LF]: Each of the algorithmic judgments

is sound, in the following sense:

1. If \Gamma  `n~ K then \Gamma  ` K.
2. If \Gamma  `n~ T :: K then \Gamma  ` T :: K.
3. If \Gamma  `n~ t : T then \Gamma  ` t : T.
4. If \Gamma  `n~ K; K0 and \Gamma  `n~ K j K0, then \Gamma  ` K j K0.
5. If \Gamma  `n~ T; T0 :: K and \Gamma  `n~ T j T0 then \Gamma  ` T j T0 :: K.
6. If \Gamma  `n~ t; t0 : T and \Gamma  `n~ t j t0 then \Gamma  ` t j t0 :: K.
where in each case, we additionally assume `n~ \Gamma  . 2

Proof: By induction on algorithmic derivations. 2
To establish completeness of algorithmic subtyping and later on terminang
tion we need to induct on the length of normalization sequences which we
formalize as follows.

Recall that uD^sE^ denotes an upper bound on the length of any -!fi reducng
tion sequence starting from s. We write |s| for the size of the term s.

2.4.3 Definition: We associate an !2ngvalued weight to each judgment arising in a

possible derivation of an equality judgment by

wD^\Delta  `n~ s1 j s2E^ C^ w D^\Delta  `n~ s1 jwh s2E^ + 1
wD^\Delta  `n~ s1 jwh s2E^ C^ ! * D^uD^s1E^ + uD^s2E^E^ + |s1| + |s2| + 1: 2

2.4.4 Lemma [Completeness of algorithmic *LF]: Each of the algorithmic judgng

ments is complete, in the following sense:

1. If \Gamma  ` K then \Gamma  `n~ K.
2. If \Gamma  ` T : K then for some K0, we have \Gamma  `n~ T : K0 and \Gamma  `n~ K j K0 and \Gamma  `n~ K0.
3. If \Gamma  ` t : T then for some T0, we have \Gamma  `n~ t : T0 and \Gamma  `n~ T j T0 and

\Gamma  `n~ T0 :: *.

4. If \Gamma  ` t1 j t2 : T then \Gamma  `n~ t1 j t2.
5. If \Gamma  ` T1 j T2 :: K then \Gamma  `n~ T1 j T2. 2

60 2 Dependent Types

Proof: One first proves that each of the declarative rules is admissible in the
algorithmic system. The result then follows by induction on derivations in
the declarative system. The only rules that are not immediately obvious are
the transitivity rules for equivalence of kinds, types, and terms, and the rule
QngApp. These two are left as exercises with solutions. 2

2.4.5 Exercise [n'n'n']: Show that rule QTngTrans is admissible for the algorithmic

system in the sense that whenever \Gamma  ` ti:T for i C^ 1; 2; 3 and \Gamma  `n~ t1 j t2 and
\Gamma  `n~ t2 j t3 then \Gamma  `n~ t1 j t3. 2

2.4.6 Exercise [n'n'n']: Show that rule QngApp is admissible for the algorithmic sysng

tem in the sense that whenever \Gamma  ` t1 t2 : T and \Gamma  ` s1 s2 : T and \Gamma  `n~ t1 j
s1 and \Gamma  `n~ t2 j s2 then \Gamma  `n~ t1t2 j s1s2. 2

Given soundness and completeness, we also want to know that our algong
rithm terminates on all inputs. This also demonstrates the decidability of the
original judgments.

2.4.7 Theorem [Termination of typechecking]: The algorithmic presentation

yields a terminating algorithm for typechecking. 2

We highlight the crucial ideas of the proof of Theorem 2.4.7 here; the deng
tails are left to the diligent reader (Exercise 2.4.9 below). The equivalence
judgment \Gamma  `n~ t1 j t2 introduces a possible source of nontermination when
invoked on nonngwellngtyped terms (for example, \Omega  C^ \Delta \Delta  where \Delta  C^ *x:A.x x).
Here, computation of weak head normal form runs into an infinite loop. We
must be careful that equivalence testing is called only on wellngtyped terms.

The crucial termination property for term equality that we need is captured
by the following lemma.

2.4.8 Lemma: Suppose that \Gamma  ` t1:T1 and \Gamma  ` t2:T2. Then the syntaxngdirected

backwards search for a derivation of \Gamma  `n~ t1 j t2 always terminates. Equivang
lently, there is no infinite derivation ending in \Gamma  `n~ t1 j t2. 2

Proof: We claim that the weight of any premise of a rule is always less than
the weight of the conclusion which excludes any infinite derivation tree. In
other words we argue by induction on the length of reduction sequences
and, subordinately, on the size of terms. This property is obviously satisng
fied for QAngWH, QAngAbs, QAngApp. To deal with rule QAngNabs1 (and similarly,
QAngNabs2) note that s must be of the form y u1 ... un whereby uD^s xE^ C^
uD^sE^. The size, however, goes down, as the *ngsymbol has disappeared. 2

2.4.9 Exercise [n'n'n', 3]: Complete the proof of 2.4.2, 2.4.4, and 2.4.7. 2

2.5 Dependent Sum Types 61
Properties of *LF
We can use the algorithmic presentation of *LF to prove additional properties
enjoyed by the main definition. We just mention one example: type preservang
tion under fingreduction.

2.4.10 Theorem [Preservation]: If \Gamma  ` t : T and t -!fi t0, then \Gamma  ` t0 : T also. 2

Proof: We show a slightly restricted form of the theorem, for wellngformed
contexts \Gamma  . More precisely, wellngformed contexts are those which can be built
using the same rules as for `n~ \Gamma  (page 57), but in the declarative system; the
corresponding assertion is written ` \Gamma  . It is easy to extend the completeness
lemma to show that ` \Gamma  implies `n~ \Gamma  .

The crucial case is that of an outermost fingreduction (BetangAppAbs), when
t C^ (*x:T1.t1) t2 for some T1, t1, t2.

By Lemma 2.4.4, we know that \Gamma  `n~ (*x:T1.t1) t2 : T0 for some T0 with
\Gamma  `n~ TjT0 and \Gamma  `n~ T0 :: *. The first judgment must have been derived with
TAngApp preceded by TAngAbs, so we have the derivability of

\Gamma  `n~ T1 :: * \Gamma  `n~ T1 j S1 \Gamma  ; x:T1 `n~ t1 : S2 \Gamma  `n~ t2 : S1
in the algorithmic system, with T0 C^ E,x , t2G*S2.

By the above and the assumptions about \Gamma  , we have `n~ \Gamma  ; x:T1. Hence
by Lemma 2.4.2, we can go back to get analogs of the statements above in
the declarative system. For the last case, to establish the equivalence \Gamma  `
T1 j S1 :: * we use Lemma 2.3.3 to get \Gamma  ` S1 :: * and then \Gamma  `n~ S1 :: *.

Now by TngConv we have \Gamma  ` t2:S2 and so with substitution, Lemma 2.3.2,
we get \Gamma  ` E,x , t2G*t1 : E,x , t2G*S2 and then the result follows using TngConv
again, with another hop between the systems and Lemma 2.3.3, to show the
equivalence \Gamma  ` E,x , t2G*S2 j T :: *. 2

2.4.11 Exercise [n'n'n', 3]: Generalize the proof above to arbitrary contexts \Gamma  . 2

2.5 Dependent Sum Types

Figure 2ng5 shows extensions to *LF to add dependent sum (or "Sigma") types,
written \Sigma x:T1.T2. Dependent sums were motivated briefly in the introducng
tion. They generalize ordinary product types in a similar way to the way
that dependent products generalize ordinary function spaces. The degenerng
ate nonngdependent case, when x does not appear free in T2, amounts to the
ordinary product, written as T1 * T2.

We extend the terms and types of *LF given in Figure 2ng1 with pairs, projecng
tion operations, and the type constructor itself. Notice that the pair (t1,t2)

62 2 Dependent Types

Extends *LF (2ng1 and 2ng2)
New syntax

t ::= . . . terms:

(t, t:\Sigma x:T.TE^ typed pair
t.1 first projection
t.2 second projection
T ::= . . . types:

\Sigma x:T.T dependent sum type

Kinding \Gamma  ` T :: K

\Gamma  ` S :: * \Gamma  ; x:S ` T :: *

\Gamma  ` \Sigma x:S.T :: * (KngSigma)

Typing \Gamma  ` t : T

\Gamma  ` \Sigma x:S.T :: *
\Gamma  ` t1 : S \Gamma  ` t2 : E,x , t1G*T

\Gamma  ` (t1,t2:\Sigma x:S.T) : \Sigma x:S.T (TngPair)

\Gamma  ` t : \Sigma x:S.T

\Gamma  ` t.1 : S (TngProj1)

\Gamma  ` t : \Sigma x:S.T
\Gamma  ` t.2 : E,x , t.1G*T (TngProj2)

Term Equivalence \Gamma  ` t1jt2 : T

\Gamma  ` \Sigma x:S.T :: *
\Gamma  ` t1 : S \Gamma  ` t2 : E,x , t1G*T

\Gamma  ` (t1,t2:\Sigma x:S.T).1 j t1 : S (QngProj1)

\Gamma  ` \Sigma x:S.T :: *
\Gamma  ` t1 : S \Gamma  ` t2 : E,x , t1G*T

\Gamma  ` (t1,t2:\Sigma x:S.T).2 j t2 : E,x , t1G*T

(QngProj2)

\Gamma  ` t : \Sigma x:S.T

\Gamma  ` (t.1, t.2:\Sigma x:S.T) j t : \Sigma x:S.T

(QngSurjPair)

Figure 2ng5: Dependent sum types

is annotated explicitly with a type \Sigma x:T1.T2 in the syntax. The reason for this
is that the type of such a pair cannot be reconstructed from the types of t1
and t2 alone. For example, if S:T!* and x:T and y:S x the pair (x,y) could
have both \Sigma z:T.S z and \Sigma z:T.S x as a type.

The most cluttered typing rule is the one which introduces a dependent
pair, TngPair. It must check first that the \Sigma ngtype itself is allowed, and then that
each component has the requested type. The projection rules are straightforng
ward: compare the second projection with the rule TngApp in Figure 2ng1.

The equality relation on terms is extended to \Sigma ngtypes by three rules. The
first two define the elimination behavior of projections on a pair (compare
with the beta rule for \Pi ngtypes). The third rule, QngSurjPair, is known as surng
jective pairing. This rule is a form of eta rule for \Sigma ngtypes: it states that every
pair can be formed using the pair constructor.

Algorithmic Typing with Dependent Sum Types
To extend the algorithm to deal with \Sigma ngtypes, we first extend the notions of
beta and weaknghead reduction. In both, the main clause is projection on a

2.5 Dependent Sum Types 63

Extends *LF algorithm (2ng3 and 2ng4)

Algorithmic kinding \Gamma  `n~ T :: K

\Gamma  `n~ T1 :: * \Gamma  ; x:T1 `n~ T2 :: *

\Gamma  `n~ \Sigma x:T1.T2 :: * (KAngSigma)

Algorithmic typing \Gamma  `n~ t : T

\Gamma  `n~ \Sigma x:T1.T2 :: *
\Gamma  `n~ t1 : T01 \Gamma  `n~ T01 j T1
\Gamma  `n~ t2 : T02 \Gamma  `n~ T02 j E,x , t1G*T2

\Gamma  `n~ (t1,t2:\Sigma x:T1.T2) : \Sigma x:T1.T2

(TAngPair)
\Gamma  `n~ t : \Sigma x:T1.T2

\Gamma  `n~ t.1 : T1 (TAngProj1)
\Gamma  `n~ t : \Sigma x:T1.T2
\Gamma  `n~ t.2 : E,x , t.1G*T2 (TAngProj2)

Algorithmic type equivalence \Gamma  `n~ S j T

\Gamma  `n~ S1 j T1 \Gamma  ; x:T1 `n~ S2 j T2

\Gamma  `n~ \Sigma x:S1.S2 j \Sigma x:T1.T2 (QTAngSigma)

Algorithmic term equivalence \Gamma  `n~ t jwh t0

\Gamma  `n~ ti j t0i
\Gamma  `n~ (t1,t2:T) jwh (t01,t02:T0) (QAngPair)

\Gamma  `n~ ti j t.i t not a pair

\Gamma  `n~ (t1,t2:T) jwh t (QAngPairngNE)
\Gamma  `n~ t.i j ti t not a pair

\Gamma  `n~ t jwh (t1,t2:T) (QAngNEngPair)

Figure 2ng6: Algorithmic typing for \Sigma ngtypes

pair. Beta reduction also allows reduction inside the components of a pair.

(t1,t2:T):i -!fi ti (BetangProjPair)

t -!fi t0
t.i -!fi t0:i (BetangProj)

t1 -!fi t01
(t1,t2:T) -!fi (t01,t2:T) (BetangPair1)

t2 -!fi t02
(t1,t2:T) -!fi (t1,t02:T) (BetangPair2)
Weak head reduction just has two new cases:

(t1,t2:T):i -!wh ti (WHngProjPair)

t -!wh t0
t.i -!wh t0.i (WHngProj)
Using the weak head reduction, the algorithmic typing and equality judgng
ments are extended with the rules in Figure 2ng6 to deal with \Sigma ngtypes.

2.5.1 Exercise [n'n'n', 3]: Extend Lemmas 2.4.2, 2.4.4 and 2.4.7 to \Sigma ngtypes. (No surng

prises are to be expected.) 2

64 2 Dependent Types

Extends *LF (2ng1 and 2ng2)
New syntax

t ::= . . . terms:

all x:T.t universal quantification
T ::= . . . types:

Prop propositions
Prf family of proofs

Kinding \Gamma  ` T :: K

\Gamma  ` Prop :: * (Kngprop)
\Gamma  ` Prf :: \Pi x:Prop. * (Kngprf)

Typing \Gamma  ` t : T

\Gamma  ` T :: * \Gamma  ; x : T ` t : Prop

\Gamma  ` all x:T.t : Prop (TngAll)

Type Equivalence \Gamma  ` S j T :: K

\Gamma  ` T :: * \Gamma  ; x:T ` t : Prop
\Gamma  ` Prf (all x:T.t) j \Pi x:T.Prf t :: *

(QTngAll)

Figure 2ng7: The Calculus of Constructions (CC)

2.6 The Calculus of Constructions

The Calculus of Constructions (CC), one of the most famous systems of deng
pendent types, was introduced by Coquand and Huet (1988) as a setting for
all of constructive mathematics. While it has turned out that CC needs to be
extended with certain features (in particular inductive types [Mohring, 1986]),
its simplicity in relationship to its expressivity is unprecedented.

In our framework CC can be formulated as an extension of *LF which has
a new basic type Prop and a new type family Prf. Elements of the type
Prop represent propositions, and also "datatypes" such as the type of natng
ural numbers (we use the term "datatype" to refer to usual programming
language types, as opposed to types of proofs of a proposition). Propositions
and datatypes are identified in CC by taking the CurryngHoward isomorphism
as an identity. The type family Prf assigns to each proposition or datatype
p : Prop the type Prf p of its proofs, or, in the case of datatypes, its memng
bers. CC has one new term former all x:T.t, and two rules which relate it
to Prf. The additions to *LF are shown in Figure 2ng7.

In most presentations and implementations of CC the type Prf t is notang
tionally identified with the term t. This is convenient and enhances readabilng
ity, however, we will not adopt it for the sake of compatibility. The original
formulation of CC went as far as using the same notation, namely (x:A) for
all three binders: \Pi ,all,*. That did not enhance readability at all and was
thus given up after some time!

CC contains F ! as a subsystem by an obvious translation. For example,
here is the type of an encoding of natural numbers in CC:

2.6 The Calculus of Constructions 65

nat = all a:Prop.all z:Prf a.all s:Prf a !Prf a. a
Recall that A!B abbreviates \Pi x:A.B.

Notice that nat is a member of type Prop. The natural numbers inhabit the
type Prf nat. Accordingly, we have

zero = *a:Prop.*z:Prf a.*s:Prf a ! Prf a.z : Prf nat

succ = *n:Prf nat.*a:Prop.*z:Prf a.

*s:Prf a ! Prf a.s(n a z s) : Prf nat ! Prf nat

add = *m:Nat.*n:Nat.m nat n succ : Prf nat ! Prf nat ! Prf nat
Regarding higherngorder polymorphism here is how we define existential types
in CC:

exists = *f:A!Prop.all c:Prop.all m:(\Pi x:Prop.Prf (f x)!Prf c).c
Here A is any type; we obtain System F's existential types with A=Prop; we
obtain existential quantification over natural numbers with A=Nat.

2.6.1 Exercise [n', 3]: Define the term corresponding to existential introduction

of type: \Pi f:A!Prop.\Pi a:Prop.\Pi i:Prf (f a).Prf (exists f). 2

Conversely, existential elimination corresponds to applying a term of type
exists f to an appropriately typed argument.

2.6.2 Exercise [n'n'n', 3]: Formalize the translation from F ! into CC. 2

The combination of type dependency and impredicativity a` la System F
yields an astonishing expressive power. For example, we can define Leibniz
equality as follows:

eq = *a:Prop.*x:Prf a.*y:Prf a.

all p:Prf a!Prop.all h:Prf (p x).p y
: \Pi a:Prop.Prf a ! Prf a ! Prop

We can now prove reflexivity of equality by exhibiting an inhabitant of the
type \Pi a:Prop. \Pi x:Prf a. Prf (eq a x x). Indeed,

eqRefl = *a:Prop. *x:Prf a. *p:Prf a ! Prop. *h:Prf (p x).h
is such a term.
2.6.3 Exercise [n'n', 3]: State and prove symmetry and transitivity of equality. 2

In a similar way, we can define other logical primitives such as boolean conng
nectives and quantifiers and then prove mathematical theorems. Occasionally
we have to assume additional axioms. For example, induction for the natural
numbers can be stated, but not proved; it is thus convenient to work under
the assumption:

66 2 Dependent Types

natInd : \Pi p:Prf nat !Prop.Prf (p zero)

! (\Pi x:Prf nat.Prf (p x) ! Prf (p(succ x)))

! \Pi x:Prf nat.Prf (p x)

With that assumption in place we can for example prove associativity of adng
dition in the form of a term of type:

\Pi x:Prf nat.\Pi y:Prf nat.\Pi z:Prf nat.

Prf (eq nat (add x (add y z)) (add (add x y) z))

2.6.4 Exercise [n'n'n']: Find such a term. 2

The task of finding proof terms inhabiting types is greatly simplified by
an interactive goalngdirected theorem prover such as LEGO (Luo and Pollack,
1992; Pollack, 1994) or Coq (Barras et al., 1997), or a structurengdriven text
editor for programming, such as Agda or Alfa (Coquand, 1998; Hallgren and
Ranta, 2000).

Algorithmic Typing and Equality for CC
We will now consider algorithmic typechecking for the pure CC. The beta
reduction relation is extended with a clause for all:

t -!fi t0

all x:T.t -!fi all x:T.t0 (BetangAll)

2.6.5 Theorem: The relation -!fi is strongly normalizing on wellngtyped terms of

CC. 2

Proof: One can prove this directly using Tait's reducibility method; see, for
example, Coquand and Huet (1988) or Luo and Pollack (1992). Alternatively,
we can define a reductionngpreserving mapping from CC into F ! by "forgetng
ting" type dependency--e.g., by mappingeq a t1 t2 to 8P :P ! P . Therefore,
an alleged infinite reduction sequence in CC would entail an infinite reduction
sequence in F !. The details are beyond the scope of this survey. 2

With this result in place it is now possible to establish soundness, completeng
ness, and termination of algorithmic typing. The additional rules for the alng
gorithm (extending those for *LF) are presented in Figure 2ng8.

The Calculus of Inductive Constructions
The fact that induction cannot be proved is a flaw of the impredicative enng
coding of datatypes. Not only is it aesthetically unappealing to have to make

2.6 The Calculus of Constructions 67

Extends *LF algorithm (2ng3 and 2ng4)

Algorithmic kinding \Gamma  `n~ T :: K

\Gamma  `n~ Prop :: * (KAngProp)

\Gamma  `n~ t:Prop
\Gamma  `n~ Prf t :: * (KAngPrf)

Algorithmic typing \Gamma  `n~ t : T

\Gamma  `n~ T :: * \Gamma  ; x:T `n~ t : Prop

\Gamma  `n~ all x:T.t : Prop (QTngAllngE)

Algorithmic type equivalence \Gamma  `n~ S j T

t -!wh all x:T1.t2
\Gamma  `n~ S1 j T1 \Gamma  ; x:S1 `n~ S2 j Prf t2

\Gamma  `n~ \Pi x:S1.S2 j Prf t

(QKAngPingPrf)

\Gamma  `n~ \Pi x:S1.S2 j Prf t

\Gamma  `n~ Prf t j \Pi x:S1.S2 (QKAngPrfngPi)

\Gamma  `n~ s j t
\Gamma  `n~ Prf s j Prf t (QKAngPrf)

Algorithmic term equivalence \Gamma  `n~ t jwh t0

\Gamma  `n~ S1 j T1 \Gamma  ; x:S1 `n~ s j t

\Gamma  `n~ all x:S.s jwh all x:T.t (QAngAllngE)

Figure 2ng8: Algorithmic typing for CC

assumptions on an encoding; more seriously, the assumption of natInd deng
stroys the analog of the progress theorem (see TAPL, $8.3). For example, the
following term does not reduce to a canonical form:

natInd (*x:Prf nat.nat) zero (*x:Prf nat.*y:Prf nat.zero) zero
For these reasons, Mohring (1986) and subsequent authors (Werner, 1994;
Altenkirch, 1993) have combined CC with inductive definitions as originally
proposed (for a predicative system) by MartinngLo"f (1984). In the thus obtained
Calculus of Inductive Constructions (CIC) as implemented in the Coq theorem
prover (Barras et al., 1997) we can declare the type nat:Prop as an inducng
tive type with constructors zero:Prf nat and succ:Prf nat!Prf nat. This
generates a constant:

natInd : \Pi p:Prf nat!Prop.Prf (p zero) !

(\Pi x:Prf nat.Prf (p x) ! Prf (p(succ x))) !

\Pi x:Prf nat.Prf (p x)

which obeys the following equality rules:

natInd p hz hs zero j hz
natInd p hz hs (succ n) j hs n (natInd p hz hs n)

This clearly provides induction, but it also allows us to define primitive reng
cursive functions such as addition by

68 2 Dependent Types

add = *x:Prf nat.*y:Prf nat.natInd (*x:nat.nat)

y (*y:nat.*r:nat.succ r) x

Notice that we instantiated natInd with the constant "predicate" *x:nat.nat.

The mechanism of inductive definitions is not restricted to simple inducng
tive types such as nat. CIC, as well as MartinngLo"f's predicative systems (as
implemented in ALF [Magnusson and Nordstro"m, 1994]) admit the inductive
definition of type families as well. For example, with nat already in place we
may define an inductive family

vector : Prf nat ! Prop
with constructors nil : Prf (vector zero) and

cons : \Pi x:Prf nat. Prf nat !

Prf (vector x) ! Prf (vector(succ x))

The (automatically generated) induction principle then has the typing

vecInd : \Pi p:\Pi x:nat.Prf (vector x) ! Prop.

Prf (p zero nil) !
(\Pi x:Prf nat.\Pi y:Prf (vector x).

\Pi a:Prf nat.Prf (p y)!Prf (cons x a y)) !
\Pi x:Prf nat.\Pi y:Prf (vector x).Prf (p x y)

2.6.6 Exercise [n'n', 3]: What are the equality rules for this induction principle by

analogy with the equations for natInd? 2

Let us see how we can define the exceptionngfree first function from the
introduction for these vectors. We first define an auxiliary function first0
that works for arbitrary vectors by

first' = vecInd (*x:Prf nat.*v:Prf (vector x).nat)

zero
(*x:Prf nat.*y:Prf (vector x).

*a:Prf nat.*prev:Prf nat.a) :
\Pi x:Prf nat.\Pi v:Prf (vector x).Prf nat

This function obeys the equations:

first' zero nil = zero
first' (succ x) (cons x a y) = a

We obtain the desired function first by instantiation

first = *x:Prf nat.*y:Prf (vector (succ x)).

first' (succ x) y

2.6 The Calculus of Constructions 69
The default value zero can be omitted in a system like ALF which allows
the definition of dependentlyngtyped functions by pattern matching. In that
system one would merely declare the type of first and write down the single
pattern

first x (cons x a y) = a
ALF can then work out that this defines a total function. The extension of patng
tern matching to dependent types was introduced in Coquand (1992) which
also contains beautiful examples of proofs (as opposed to programs) defined
by pattern matching. McBride (2000) has studied translations of such patng
tern matching into traditional definitions using recursion/induction princing
ples like vecInd.

2.6.7 Exercise [n'n'n', 3]: Define using vecInd a function

concat : \Pi x:Prf nat.\Pi y:Prf nat.Prf (vector x) !

Prf (vector y) !
Prf (vector (add x y))

How does it typecheck? 2

As a matter of fact, the CIC goes beyond the type system sketched here in
that it allows quantification over kinds, so, for example, the "predicate" p in
natInd may be an arbitrary type family. This means that using the constant
family p = *x:nat.Prop we can define a function eqZero: Prf nat ! Prop
which equals true when applied to zero and false on all other arguments.
This facility turns out to be useful to define the exceptionngfree first function
on vectors which was presented in the introduction.

Another additional feature of the CIC is the separation of propositions and
datatypes into two disjoint universes Prop and Set. Both behave like our
Prop, the difference lies in a program extraction feature that maps developng
ments in the CIC to programs in an extension of F ! with inductive types
and general recursion. Types and terms residing in Prop are deleted by this
translation; only types and terms in Set are retained. In this way, it is possing
ble to extract correct programs from formal correctness proofs. Details can
be found in PaulinngMohring (1989).

Sigma Types in CC
It is unproblematic and useful to combine CC with \Sigma ngtypes as described in
Section 2.5 and Figure 2ng5. This allows one to form types of algebraic strucng
tures, for instance

70 2 Dependent Types

Semigrp = \Sigma a:Prop.\Sigma op:Prf a ! Prf a ! Prf a.

\Pi x:Prf a.\Pi y:Prf a.\Pi z:Prf a.

Prf (eq a (op x (op y z)) (op (op x y) z));

This system is contained in Luo's Extended Calculus of Constructions (ECC)
(1994) which additionally permits \Pi  and \Sigma  quantification over kinds. For conng
sistency reasons which we will briefly describe next this requires an infinite
hierarchy of ever higher kinds *0, *1, *2, .... For instance, in ECC one has

\Sigma X:*3. X : *4
ECC has been implemented in the LEGO system (Luo and Pollack, 1992).

It is quite another matter to ask for a reflection of \Sigma ngtypes into the universe
Prop of datatypes and propositions, by analogy with the way all is treated.
The temptation is to introduce a term former ex y:T.t : Prop when x:T `
t:Prop, together with an equality rule asserting that

Pr (ex y:T.t) j \Sigma y:T.Prf t:
Coquand (1986) has shown that the resulting system is unsound in the sense
that all types are inhabited and strong normalization fails. Intuitively, the
reason is that in this system we are able to define

prop = ex x:Prop.nat
and now have a mapping i:Prop!Prf prop defined by

i = *x:Prop.(x,zero:prop)
as well as a left inverse j:Prf prop !Prop given by

j = *x:Prf prop.x.1.
Thus, we have reflected the universe Prop into one of its members, which
allows one to encode (after some considerable effort) one of the setngtheoretic
paradoxes showing that there cannot be a set of all sets.

This must be contrasted with the impredicative existential quantifier exists
defined on page 65. The difference between exists and the hypothetical term
former ex is that exists does not allow one to project out the existential
witness in case it is of type Prop.

An existential quantifier which does not provide first and second projecng
tions, but only the impredicative elimination rule known from System F is
called a weak sum, weak \Sigma ngtype, or existential. In contrast, the \Sigma ngtypes with
projections are sometimes called strong.

We conclude this section by remarking that it is unproblematic to have
"small" strong \Sigma ngtypes in the CC, that is, if t1:Prop and x:Prf t1 ` t2:Prop
then oe x:Prf t1.t2:Prop with the equivalence

Prf(oe x:Prf t1.t2) j \Sigma x:Prf t1.Prf t2:

2.7 Relating Abstractions: Pure Type Systems 71
2.6.8 Exercise [n'n'n', 3]: An "approximation" for oe x:Prf t1.t2 is given by

exists = all c:Prop.all b:\Pi x:Prf t1.Prf t2 ! Prf c.c.
Define pairing and first projection for exists. Unfortunately, it is not possing
ble to define a second projection. 2

2.7 Relating Abstractions: Pure Type Systems

The Calculus of Constructions is a very expressive system, but at first sight,
somewhat difficult to understand because of the rich mix of different "levng
els" of typing (especially in its original formulation with Prf implicit). Given
a lambda term *x : S:t, we cannot tell without (possibly lengthy) further analng
ysis of S and t whether this is a termnglevel function, a type abstraction, a type
family, a type operator, or something else.

Partly as an attempt to explain the fine structure of CC, Barendregt introng
duced the lambda cube of typed calculi (briefly introduced in TAPL, Chapter
30), illustrated below:

F ! CC

F

""
""

*

""
""

* *
*!

""
""

*P

""
""

The cube relates previously known typed lambda calculi (recast within a
uniform syntax) to CC, by visualizing three "dimensions" of abstraction. In
the bottom left corner, we have *!with ordinary termngterm abstraction. Movng
ing rightwards, we add the typengterm abstraction characteristic of dependent
types: *P is the Lambda Cube's version of our *LF. Moving upwards, we add
the termngtype abstraction of System F, capturing polymorphism. Finally, movng
ing towards the back plane of the cube, we add the higherngorder typengtype
abstraction characteristic of F !.

Pure Type Systems
The type systems of the Lambda Cube, and many others besides, can be deng
scribed in the setting of pure type systems (Terlouw, 1989; Berardi, 1988;
Barendregt, 1991, 1992; Jutting, McKinna, and Pollack, 1994; McKinna and
Pollack, 1993; Pollack, 1994). There is an simple and elegant central defining
tion of Pure Type System (PTS) using just six typing rules, which captures a

72 2 Dependent Types

*P
Syntax

t ::= terms:

s sort
x variable
*x:t.t abstraction
t t application
\Pi x:t.t dependent product type
s ::= sorts:

* sort of proper types
2 sort of kinds
\Gamma  ::= contexts:

; empty context
\Gamma  ; x:T variable binding

Typing \Gamma  ` t : T

\Gamma  ` *: 2 (TngStar)

x:T 2 \Gamma 
\Gamma  ` x : T (TngVar)
\Gamma  ` S : * \Gamma  ; x:S ` t : T

\Gamma  ` *x:S.t : \Pi x:S.T (TngAbs)
\Gamma  ` t1 : \Pi x:S.T \Gamma  ` t2 : S

\Gamma  ` t1 t2 : E,x , t2G*T (TngApp)
\Gamma  ` S : si \Gamma  ; x:S ` T : sj

\Gamma  ` \Pi x:S.T : sj (TngPi)
\Gamma  ` t : T T j T0 \Gamma  ` T0 : s

\Gamma  ` t : T0 (TngConv)

where D^si; sj E^ 2 {D^*; *E^; D^*; 2E^}.

Figure 2ng9: Firstngorder dependent types, PTSngstyle (*P)

large family of systems constructed using \Pi ngtypes. This uniform presentation
allows one to establish basic properties for many systems at once, and also
to consider mappings between type systems (songcalled PTS morphisms).

A presentation of *LF as a Pure Type System is given in Figure 2ng9.
The first thing to notice about PTSs is that there is a single syntactic cateng
gory of terms, used to form types, terms, and abstractions and applications
of different varieties. Although formally there is a single syntactic category,
we use the same metangvariables as before, to aid intuition. (So the letters T
and K and also range over the syntactic category of terms, but the system will
determine that they are types and kinds, respectively).

To allow levels of types and kinds to be distinguished, the PTS framework
uses tokens called sorts to classify different categories of term, within the
formal system itself. The system *P requires two sorts: first, *, which is the
kind of all proper types, as used before, and second, 2, which is the sort
that classifies wellngformed kinds. Judgments of the form \Gamma  ` T : * replace
\Gamma  ` T :: * from Figure 2ng1, and judgments \Gamma  ` K : 2 replace \Gamma  ` K.

The rule TngPi controls formation of \Pi ngtypes, by restricting which sorts we
are allowed to quantify over. In turn, this restricts which *ngabstractions can
be introduced by TngAbs. For *LF, there are two instances of *ngabstraction and

2.7 Relating Abstractions: Pure Type Systems 73
two instances of \Pi ngformation. In the PTS presentation, these are captured by
the two pairs of sorts allowed in TngPi. When si C^ sj C^ *, we have the firstng
order dependent product type, and when sj C^ 2 we have the kind of type
families, corresponding respectively to KngPi and WfngPi in Figure 2ng1.

The conversion rule is the main point of departure. The equivalence relang
tion s j t in Pure Type Systems is defined between untyped terms, as the
compatible closure of fingreduction. This has a strong effect on the metang
theory.

2.7.1 Exercise [n'n'n'n']: Using the obvious mapping from the syntax of *LF into

the syntax of *P, give a proposition stating a connection between the two
presentations. Try to prove your proposition. 2

Systems of the LambdangCube and Beyond
The other systems of the Lambda Cube can be expressed using the same rules
as in Figure 2ng9, with the single difference of changing the combinations of
pairs of sorts D^si; sj E^ allowed in TngPi. This controls which kind of abstractions
we can put into the context. The table below characterises the systems of the
Lambda Cube:

System PTS formation rules

*! { (*,*) }
*P { (*,*), (*,2) }
F { (*,*), (2,*) }
F ! { (*,*), (2,*), (2, 2) }
CC { (*,*), (*,2), (2,*), (2, 2) }

Further PTSs are given by adjusting the axiom TngStar of Figure 2ng9, which
is another parameter in the formal definition of PTS. For example, if we take
the axiom to be

\Gamma  ` *: * (TngTypeType)
(together with the TngPi restriction of {D^*; *E^}), we obtain a system where *
is the sort of all types including itself. In this system, all types are inhabng
ited and there are nonngnormalizing terms (as in the result of Coquand, 1986
mentioned on page 70). Though this renders the logical interpretation of the
system meaningless, it is debatable whether such systems may nonetheless
be useful in some situations as type systems for programming languages.

For further details of Pure Type Systems, we refer the reader to the referng
ences given at the end of the chapter.

74 2 Dependent Types

2.8 Programming with Dependent Types

The task of building practical programming languages with dependent types
is a topic of current research. Early languages include Pebble (Lampson and
Burstall, 1988) and Cardelli's Quest (Cardelli and Longo, 1991). Programming
in MartinngLo"f's type theory is described in the monograph (Smith, Nordstro"m,
and Petersson, 1990). More recently, Augustsson introduced a language called
Cayenne (1998), with a syntax based on the functional programming lanng
guage Haskell, and Xi and Pfenning studied the language Dependent ML,
based around a fragment of Standard ML (1998; 1999). The difference beng
tween Cayenne and Dependent ML goes beyond the choice of underlying lanng
guage, and serves to illustrate a fundamental design decision for practical
programming with dependent types.

Languages with Undecidable Typechecking
Given the expressivity of dependent types as illustrated in previous sections
it is natural and tempting to add them to a programming language. The
price for this expressivity is, however, the complexity of typechecking. As
we have explained, typechecking dependent types requires deciding equality
of terms as a subtask which in turn requires the underlying term language
to be strongly normalizing. On the other hand, most practical programming
languages provide general recursion with possible nontermination. Simply
adding dependent types to a Turingngcomplete term language invariably leads
to undecidable typechecking.

Of course, typechecking remains semingdecidable, so one can simply wait
for an answer for a reasonable amount of time before giving up and turning
the typechecker off. This is basically the (surprisingly successful) approach
undertaken in Cayenne. Another example is the theorem prover PVS (1996)
which includes a dependentlyngtyped programming language (at the time of
writing, in an experimental stage), and also has semingdecidable typechecking.
In PVS, however, it is possible to resort to interactive theorem proving to aid
the type checker.

Undecidablef typechecking is not to the taste of all programming language
designers, and for reasons such as scalability, may not be suitable for general
application. The alternative is to consider dependently typed languages built
around standard programming language features, yet with lowngcomplexity
typechecking algorithms. To achieve this one must sacrifice some of the genng
erality of dependent types. Dependent ML (DML) is a proposal which follows
this approach, which we will investigate in more detail in the remainder of

2.8 Programming with Dependent Types 75
this section. A type system closely related to that of DML, but aimed at
Haskell, was studied by Zenger, under the name indexed types (1997).

Exactly because this class of type systems have the desirable feature that
they provide "static" typechecking independently from execution or equivang
lence checking of terms, some authors prefer not to call them "dependent"
at all. The definition of dependent types given in Chapter 8 is slightly stricter
than ours, and contrasts statically typed languages like DML and Indexed
Types with languages where there is a lack of phase distinction between the
compilation and execution of a program (see page 305).

A Simplified Version of Dependent ML
The crucial idea behind DML is that type dependency on terms is not allowed
for arbitrary types, but only for certain index sorts. Typechecking gives rise
to wellngbehaved constraint systems on terms belonging to index sorts. Typeng
checking and even (to an extent) type inference can then be reduced to a
constraintngsolving problem over the index sorts, which is decidable.

In this presentation we fix the index sorts to be integer numbers and linear
subsets thereof, although Pfenning and Xi consider richer possibilities. We
also base the language on the lambdangcalculi we have studied so far, rather
than a form of Standard ML.

Before going into details we will look at some simple examples concerning
vectors. We write int for the index sort of integers and assume a basic type
data and a basic type family Vector : int!* where Vector[n] denotes
arrays over data of length n as usual. Note that, for example, Vector[ng1]
will be empty. Next, we introduce the constants

nil : Vector[0]
cons : \Pi n:int.data ! Vector[n] ! Vector[n+1]

and a construct for pattern matching obeying the following typing rule:

\Gamma  ` t1 : Vector[i] \Gamma  ; i=0 ` t2 : T
\Gamma  ; n:int; x:data; l:Vector[n]; i=n+1 ` t3:T

\Gamma  ` match t1 with nil ! t2 | cons[n](x,l) ! t3 : T (MatchngVector)
There are several things to notice here. Types distinguish between ordinary
nonngdependent function spaces T1!T2 and type families indexed by index
sorts, \Pi x:I.T. Application for \Pi ngtypes is written using square brackets. Conng
texts contain bindings of index variables to index sorts, type variables to
types, and constraints over terms of index sort. Here the constraints are equang
tions; in general they may be propositions of some restricted form so as to
retain decidability.

76 2 Dependent Types

In our setting, nil, cons, and match are just interesting for their typing
behaviors. We might postulate the obvious conversion rules for instances of
match, to define a term equality judgment as studied earlier. But it is imporng
tant to realize that we needn't do this for the purpose of typechecking, since
for DMLngstyle systems term equality is completely decoupled from typing.

In examples we will allow the definition of recursive functions by first
declaring them with their type and then giving an accordingly typed impleng
mentation which may involve calls to the function being defined.4

Example: Appending Vectors
We want to define a function for appending two vectors. It should obey the
following typing:

append : \Pi m:int.\Pi n:int.Vector[m] ! Vector[n] ! Vector[m+n]
To do this we define the body of append as follows:

appendngbody = *m:int.*n:int.*l:Vector[m].*t:Vector[n].

match l with

nil ! t
| cons[r](x,y) ! cons[r+n](x,append[r][n](y,t)

We should prove that appendngbody has the same type as append. Let \Gamma  C^
m:int, n:int, l:Vector[m], t:Vector[n]. After applying the rule MatchngVector
backwards we are required to show that

\Gamma  ; m=0 ` t : Vector[m+n]
and

\Gamma  ; r:int; x:data; y:Vector[r]; m=r+1 `

cons[r+n](x,append[r][n](y,t) : Vector[m+n]

For the first requirement, we notice that \Gamma  ; m=0 ` n=m+n:int from which the
claim will follow by the type conversion rule and the obvious type equivalence
which equates instances of Vector indexed by equal index terms:

\Gamma  ` i=j

\Gamma  ` Vector[i]=Vector[j]
This rule is an instance of QTngApp for DML families.

For the second requirement, we first notice that, given the purported typing
of append, the appendngsubterm has type Vector[r+n], thus, by the typing of
cons the term itself has type Vector[r+n+1], but in the given context, this is
equal to Vector[m+n] hence the required typing follows by type conversion
again.

4. One can achieve this effect with a constant fixT : (T!T) ! T for any type T.

2.8 Programming with Dependent Types 77
Example: Splitting a Vector
This example illustrates DML's restricted form of \Sigma ngtypes. Again, we have
both dependent sums indexed by index sorts, and nonngdependent sums (i.e.,
ordinary cartesian products). We will use the following type abbreviation:

T(m) = \Sigma p:int.\Sigma q:{ i | p+i=m }.Vector[p] * Vector[q]
The type T(m) has elements of the form (p,(q,(k,l))), which we shall write
as (p,q,k,l) to avoid excessive parentheses. The terms p and q are integer
indices, obeying the constraint p + q C^ m.

Now we can define a split function that partitions a vector into two pieces
of given lengths:

split : \Pi m:int.Vector[m] ! T(m)

splitngbody = *m:int.*l:Vector[m].

match l with

nil ) (0,0,nil,nil) : T(0)
| cons[r](x,y) ) let (p,q,u,v) = split[r](y) in

if test(x) then (p+1, q, cons[p](x,u), v) : T(r+1)

else (p, q+1, u, cons[q](x,v)) : T(r+1)

where test(x) is some unspecified booleanngvalued term. The typing of split
guarantees that the result vectors could be appended to form a vector with
the same length as the input. Notice that we can say that there is some pair
p and q such that p+q=m where m is the length of the input, but with the
restricted form of predicates in DML, we cannot say that p is equal to the
number of elements x from the input for which test(x) is true.

To see how split is typed, let \Gamma  C^ m:int, l:Vector[m]. We have \Gamma  ; m=0 `
T(0)=T(m) which deals with the first case of the match. For the second case,
we need to show

\Gamma  ; p:int; q:int; p+q=r; u:Vector[p]; v:Vector[q]; r+1=m `

(p+1, q, cons[p](x,u), v) : T(r+1) = T(m)

and similarly for the elsengbranch of the if statement. Again this follows
from trivial equational reasoning, and the expected rules for sum types.

Definition of Simplified DML
Figure 2ng10 summarizes the syntax of our simplified form of DML. Most of
the typing rules are routine, so we leave completing the system to exercises.

The definition of DML is closely related to *LF with \Sigma ngtypes, except that
dependencies are restricted to special terms of index sorts, so there is a parng
titioning of the syntax. Index sorts comprise the integers and subsets of index

78 2 Dependent Types

DML

I ::= index sorts:

int index sort of integers
{x:I | P} subset sort
P ::= propositions:

P ^ P conjunction
i<=i index inequality
i ::= index terms:

x variable
q constant q 2 Z
qi multiplication by q 2 Z
i+i addition
t ::= terms:

x variable
*x:I.t index abstraction
t[i] index application
*x:T.t abstraction
t t application

(i, t) index pairing
(t, t) term pairing
let (x, y)=t in t projection
T ::= types:

X type/family variable
\Pi x:I.T indexed product
\Sigma x:I.T indexed sum
T[i] type family application
T1 ! T2 function type
T1 * T2 cartesian product
K ::= kinds:

* kind of proper types
\Pi x:I.K kind of type families
\Gamma  ::= contexts:

; empty context
\Gamma  ; x:T term variable binding
\Gamma  ; x:I index variable binding
\Gamma  ; P constraint

Figure 2ng10: Simplified Dependent ML (DML)

sorts. Subset formation is permitted only with respect to a restricted set of
predicates. In our case, these are conjunctions of linear inequalities (equalng
ity of two indices, i1=i2, can be defined as i1<=i2 ^ i2<=i1). Index terms
themselves are restricted to variables, constants, addition of terms and mulng
tiplication by constants. Given an index sort, proposition, or index term I,
we write FIVD^IE^ to stand for the free (index) variables of I. We use the same
category of variables for index variables and ordinary variables, but we can
tell from a typing context whether a variable ranges over index terms or orng
dinary terms. Given a context \Gamma  , let IVD^\Gamma  E^ stand for the set of index variables
declared in \Gamma  . A term I in the index syntax is wellngformed in \Gamma  just in case
FIVD^IE^ ` IVD^\Gamma  E^; no typing rules are needed to check wellngformedness in the inng
dex syntax. For contexts, we assume as usual that no variable is bound more
than once, and moreover, that the free variables appearing in declarations
x:I and constratints P are declared earlier in the context.

Ordinary terms include index terms in application position and in the first
component of pairs. There are types depending on index terms, but there are
no types depending on ordinary terms. As a result, function space and carteng

2.8 Programming with Dependent Types 79
sian product cannot be defined as special cases of \Pi  and \Sigma ngtypes, but must
be included as primitives. Kinds are just as in LF, except that dependency is
restricted to index sorts I.

In the typing rules we assume given two semantically defined judgments:

\Gamma  |C^ P P is a consequence of \Gamma 
\Gamma  |C^ i : I i:I follows from the assumptions of \Gamma 

These judgments depend only on the index assumptions and propositions in
\Gamma  , and their intention should be clear. For example, we have:

x:{y:int | y>=8}, z:int, z>=9 |C^ x+z >= 13
The judgments can be defined formally using the obvious interpretation of
the index syntax in Z (see Exercise 2.8.1).

In practice we are of course interested an algorithm for deriving the two
judgments. In our simplified version of DML, both judgments \Gamma  |C^ P and
\Gamma  |C^ i:I are decidable, and there are wellngknown methods which we can
use for handling linear equalities over the integers. In the case of a more
complicated index language the judgments might both be undecidable; for
instance, if we allow multiplication of index terms and existential quantifing
cation in propositions then undecidability follows from the undecidability of
Hilbert's 10th problem.

In the typing rules, the semantic judgment is used whenever we need to
check that an index term belongs to an index sort. For example, the rule for
type family application becomes:

\Gamma  ` S :: \Pi x:I.K \Gamma  |C^ i : I

\Gamma  ` S[i] : E,x , iG*K (DMLngKngApp)
The typing rules for the remainder of the language are defined similarly to
*LF and the simplyngtyped lambda calculus. For instance, we have the followng
ing rule for index abstraction:

\Gamma  ; x:I ` t : T
\Gamma  ` *x:I.t : \Pi x:I.T (DMLngIngAbs)
but for ordinary abstraction we introduce the arrow:

\Gamma  ; x:S ` t : T
\Gamma  ` *x:S.t : S ! T (DMLngTngAbs)
There are similarly two rules for pairing and for projections. For the projecng
tion of an indexed pair, we have the dependent case:

\Gamma  ` t : \Sigma x:I.T \Gamma  ; x:I; y:T ` t0 : T0

\Gamma  ` let (x,y)=t in t0 : T0 (DMLngIngProj)

80 2 Dependent Types

We can also follow the same procedure as for *LF to formulate an algorithng
mic version of typing; the difference is that algorithmic type equality amounts
to checking of index constraints which can be performed semantically by conng
straint solving, without any normalization. In particular, equality of terms
is not intertwined with typechecking at all. The crucial rule for algorithmic
equality is

\Gamma  `n~ S1 j S2 \Gamma  |C^ i1 = i2

\Gamma  `n~ S1 i1 j S2 i2 (DMLngQIAngApp)
where the second judgment is an instance of the semantic consequence judgng
ment \Gamma  |C^ P.

2.8.1 Exercise [n'n']: Give a semantic interpretation of DML index syntax. Considng

ering only the index variables in \Gamma  , an index environment j is a function
from index variables to integers. Given this notion, we can define \Gamma  |C^ P as
8j: j |C^ \Gamma  : =) j |C^ P. Complete the definition. 2

2.8.2 Exercise [n'n'n', 3]: Complete the presentation of DML by defining the typeng

checking judgments and give an algorithm for typechecking. 2

Closing Example: Certifying Parameters
Several motivating application examples have been given for DML in the literng
ature, including eliminating array bounds checks and unnecessary cases from
pattern matches. Rather than repeat those examples, we give a slightly differng
ent kind of example to illustrate the use of DMLngstyle typing to certify that
constraints are met on parameters of functions.5

The scenario is that we are programming for an embedded system which is
providing safety features for an onboard computer in an automobile. We are
provided with a system call:

brake : int * int ! unit
where it is safety critical that whenever brake is called with parameters
(x,y) then some proposition P D^x; yE^ must be satisfied, for example, a conng
junction of linear inequalities describing some "safe window."

To guarantee this, we should try to type our main program under the folng
lowing assumed typing for brake. Notice that brake is provided as a system
call, so we can assume an arbitrary typing for it.

brake : {(x,y) : int * int | P} ! unit

5. This example is taken from the project Mobile Resource Guarantees (EU ISTng2001ng33149);
see http://www.lfcs.inf.ed.ac.uk/mrg.

2.8 Programming with Dependent Types 81
where P encodes P D^x; yE^. Unfortunately, this typing does not quite fit into
the DMLngframework since it unduly mixes index sorts and ordinary types.
To repair this, we introduce a type family Int : int ! * with the intuition
that Int(x) is a singleton type containing just the integer x, as a "runngtime"
integer rather than an index term. We also need special typings for runngtime
integers:

0 : Int(0)
1 : Int(1)
plus : \Pi x,y:int.Int(x) ! Int(y) ! Int(x+y)
timesq : \Pi x:int.Int(x) ! Int(qx)

where q is a fixed integer. These typings allow us to reflect the index terms
in ordinary terms. Moreover, we need a type family Bool:int!* with the
intuition that Bool(x) contains true if 1<=x and Bool(x) contains false if
x<=0. Now we can suppose constants:

true : \Pi x:int|1<=x. Bool(x)
false : \Pi x:int|x<=0. Bool(x)
leq : \Pi x,y:int. Int(x) ! Int(y) ! Bool(1+yngx)

(where we write \Pi x:int|P.T as an abbreviation of \Pi x:{x:int | P}. T).

We also need a construct for case distinction obeying the following typing
rule:

\Gamma  ` t1 : Bool(i) \Gamma  ; 1<=i ` t2 : T \Gamma  ; i<=0 ` t3:T

\Gamma  ` if t1 then t2 else t3 : T
Notice that if we define boolean negation in terms of ifngthenngelse then we
would obtain the typing:

not : \Pi x:int. Bool(x) ! Bool(1ngx)
because 1<=x |C^ 1ngx<=0 and x<=0 |C^ 1<=1ngx. Unfortunately, the derived typng
ings for conjunction and disjunction are rather weak:

andalso,orelse : \Pi x,y:int.Bool(x)!Bool(y) ! \Sigma z:int.Bool(z)
Xi introduces a separate index sort of booleans with the usual operations on
the index level. This gives tighter typings for the boolean operations like

orelse : \Pi x,y:bool.Bool(x)!Bool(y)!Bool(x ^ y):
The price is that constraint solving for such a combined theory is much more
complex.

Returning to the example with the system call, let us suppose that the
linear constraint P simply states x+y<=10 and that the main function is just
a wrapper around brake that makes sure the constraint is actually met, i.e.

main(x,y) = if x+y<=10 then call brake(x,y) else call brake(0,0)

82 2 Dependent Types

Here is the corresponding DML version. We assume that the system call brake
satisfies the typing

brake : \Pi x,y:int|x+y<=10.Int(x) ! Int(y) ! unit
main : \Pi x,y:int.Int(x) ! Int(y) ! unit
mainngbody = *x,y:int.*xx:Int(x).*yy:Int(y).

if leq[x+y,10](plus[x,y](xx,yy))

then brake[x,y](xx,yy)
else brake[0,0](0,0)

Although this example is rather simple, it illustrates the general technique
for connecting index sort constraints to function calls. The fact that this defng
inition is type correct guarantees that the required safe window for calls to
brake is indeed always obeyed.

Summary and Outlook
We have shown the theory of a simplified fragment of Pfenning and Xi's
DML demonstrating the important feature that typechecking amounts to conng
straint solving, for example, in the domain of integers, rather than normalizng
ing terms. In this way, it becomes possible to retain decidability of typecheckng
ing in the presence of general recursion.

The DML examples show that index annotations are quite heavy. Fortung
nately, most can be inferred automatically by a process known as elaboration.
It is plausible that in the examples we can reconstruct the annotations by reng
placing them by indeterminate linear terms in the index variables in scope
and then solving for the coefficients. In Xi's thesis (1998), elaboration is preng
sented in detail as a logic program in the style of our algorithmic subtyping.

One of the design criteria behind the original DML was to allow ordinary
Standard ML programs to be extended with additional type annotations. Curng
rent research in dependent type systems for programming seeks further adng
vances at the programming language level. The aim is to provide more comng
fortable highnglevel notations and new programming language abstractions for
applying dependent type theory. One example of this is by enriching pattern
matching, see McBride (2000) and McBride and McKinna (2004).

Underlying type theories such as CIC are amply expressive for this purpose;
the challenge lies in making these systems more convenient to use, by adding
programming language constructions, notational conveniences and advanced
inference techniques. Present implementations, oriented towards mathematng
ical interactive proof development, need to be adapted to programming lanng
guage settings. These exciting developments leave much to be expected for
the future of programming with dependent types.

2.9 Implementation of Dependent Types 83
2.9 Implementation of Dependent Types

In this final section we describe an OCaml implementation of the dependent
type theory described in preceding sections. The implementation allows decng
larations and definitions of both terms and types. Typechecking occurs as
soon as a declaration or definition is given. A term may be given with a type,
which will be checked, or without, in which case one will be inferred. Similarly
for kinds. Finally, we can ask to normalise wellngtyped terms.

The typechecking algorithm proceeds by evaluating the rules in Figures 2ng4
and 2ng3 and the later tables extending these judgments. More precisely, we
have (simultaneously defined) functions:

val whnf : term ! term
val typeof : context ! term ! ty
val kindof : context ! ty ! kind
val checkkind : context ! kind ! unit
val tyeqv : context ! ty ! ty ! bool
val kindeqv : context ! ty ! ty ! bool
val tmeqv : context ! ty ! ty ! bool

These functions are implemented by encoding the algorithmic rules using
pattern matching. For example, the definition of tmeqv begins like so:

tmeqv ctx tm1 tm2 =

let tm1' = whred true ctx tm1 in
let tm2' = whred true ctx tm2 in
match (tm1',tm2') with

(TmVar(fi,i,j), TmVar(fi',i',j')) ! i=i'
| (TmAbs(_,x,tyS1,tmS2),TmAbs(_,y,tyT1,tmT2))!

let ctx' = addbinding ctx x (VarBind(tyS1)) in
tmeqv ctx' tmS2 tmT2
...

(the first argument of whred is a flag indicating whether to allow definitions
in the context to be expanded).

We stress that the implementation is a direct rendition of the syntax and
rules described earlier. It does not include any of the numerous desirable feang
tures that make programming with dependent types more convenient, such
as argument synthesis (Harper and Pollack, 1991) or interactive, goalngdirected
construction of terms. Conversely, because the implementation is simple, it
should be straightforward to experiment with extensions. The program is
built on the F ! implementation from TAPL and uses the same design and
data structures (see TAPL, Chapters 6, 7, and 30).

84 2 Dependent Types

We illustrate the use of the implementation by way of some examples.
Notice that the ASCII input to the system to produce a type like \Pi x:A.B is
Pi x:A.B.

Examples
With the commands

A : *;
Nat : *;
zero : Nat;
succ : \Pi n:Nat.Nat;
Vector : \Pi n:Nat.*;

we declare variables A,Nat, constants zero and succ intended to denote zero
and successor on the natural numbers, and a type Vector depending on type
Nat. Note that the implementation does not support !; we must use \Pi ngtypes
throughout. Next, we declare functions to form vectors by

nil : Vector zero
cons : \Pi n:Nat. \Pi x:A. \Pi v:Vector n. Vector (succ n)

allowing us to define a function for forming vectors of length three:

one = succ zero;two = succ one;
mkthree = *x:A.*y:A.*z:A.

cons two z (cons one y (cons zero x nil));

The implementation will respond by inferring the type of mkthree:

mkthree : \Pi x:A. \Pi y:A. \Pi z:A. Vector (succ two)
We can now partially apply mkthree to two elements of type A by

a:A; b:A;
mkthree a b;

resulting in the response

*z:A.

cons (succ (succ zero)) z
(cons (succ zero) b (cons zero a nil)) :

\Pi z:A.Vector(succ (succ (succ zero)))

This response exhibits two weaknesses of the implementation. First, defining
tions are always expanded in results; this will in practice almost always lead
to unreadable outpt. Second, the first arguments to cons must be given exng
plicitly and are printed out while they could be inferred from the types of the

2.9 Implementation of Dependent Types 85
second arguments. Practical implementations of dependent types overcome
both these problems. For instance, in LEGO (Luo and Pollack, 1992), mkthree
would be defined (in our notation) as

mkthree = *x:A.*y:A.*z:A. cons z (cons y (cons x nil));
and the response to mkthree a b would be

*z:A.cons z (cons b (cons a nil))) : \Pi z:A.Vector three
For LEGO to know that the first argument to cons is implicit we must declare
cons by

\Pi n|Nat. \Pi x:A. \Pi v:Vector n. Vector (succ n)
where the bar indicates implicitness for argument synthesis.

Returning to our experimental checker, let us illustrate \Sigma ngtypes. We declare
three types

A:*; B:\Pi x:A.*; C:\Pi x:A.\Pi y:B x.*;
and define

S = \Sigma x:A.\Sigma y:B x.C x y;
Supposing

a:A; b:B a; c: C a b;
then we can form

(a,(b,c:\Sigma y:B a.C a y):S);
which is an element of S. The first type annotation is actually redundant and
the implementation allows one to abbreviate the above by

(a,b,c:S)
If we declare

Q : \Pi x:S.*;
x:S; y:Q x;

Then the following typecast succeeds

y:Q (x.1,x.2.1,x.2.2:S);
thus illustrating the builtngin surjective pairing.

Here, finally, is the definition of natural numbers in CC:

nat = all a:Prop.all z:Prf a.all s:\Pi x:Prf a.Prf a. a;
Note that Prf always requires parentheses in the implementation.

We also remark that by default the implementation prints the weaknghead
normal form of input terms. The fingnormal form of a term t is printed with
the command Normal t.

86 2 Dependent Types

2.10 Further Reading

Dependent type theories have been widely investigated, much of the develng
opment building on the pioneering work of Per MartinngLo"f. This is not the
place for a comprehensive overview of the literature; rather we provide a few
pointers into work related to the developments in this chapter.

The Edinburgh Logical Framework and its type system are described in
Harper, Honsell, and Plotkin (1993). Our definition of *LF has the same type
structure, but omits signatures, and includes declarative equality judgments
rather than an untyped equivalence relation. A more complete recent develng
opment which also includes equality judgments is in Harper and Pfenning
(2004).

Richer type theories than LF are considered in many places. The calculus
of constructions was introduced in Coquand and Huet (1988) and further
developed in related type theories (Mohring, 1986; Luo, 1994; Pollack, 1994).
Algorithms for typechecking with dependent types were first considered by
Coquand (1991), Cardelli (1986; 1988b), and also within the closely related
AUTOMATH system of de Bruijn (1980).

The best survey of Pure Type Systems remains Barendregt's handbook arting
cle (1992), which includes a description of the *ngCube. Although the definition
of PTS is elegant and short, developing the metangtheory for PTSs has been surng
prisingly challenging. Several important results and improvements have been
made since Barendregt's article. For example, Pollack (1994), studied formalng
ization of the metangtheory of PTSs in type theory itself, Poll (1998) established
the expansion postponement property for the class of normalizing PTSs, and
Zwanenburg (1999) studied the addition of subtyping to PTSs.

Type theories which combine inductive types and quantification over kinds,
such as CIC, do not permit an easy normalization proof by translation into a
simplyngtyped normalizing sytem as was the case for the pure CC. Therefore,
strong normalization must be proved from scratch for those systems. So far
only partial proofs have been published for CIC as it is implemented in Coq;
the closest work so far is in the recent PhD thesis of Miquel (2001). For UTT
as implemented in LEGO, a strong normalization proof is given in Goguen
(1994), which introduces the idea of a typed operational semantics as a more
controlled way of managing reduction in a typed setting.

A topic we have not considered here is the semantics of dependent types.
There has been considerable study; see Hofmann (1997b) for a particular
approach and some comparison with the literature. Notable contributions
include Cartmell (1986), Erhard (1988), Streicher (1991), and Jacobs (1999).

3

Effect Types and RegionngBased Memory
Management

Fritz Henglein, Henning Makholm, and Henning Niss

Typengbased program analysis is program analysis based on the concepts, theng
ories and technologies developed for type systems and employed in the defing
nition of programming languages. It is a vast field of research with numerous
applications and considerable practical impact. Applications include strictng
ness analysis, data representation analysis, bindingngtime analysis, soft typing
(also called dynamic typing inference), boxing analysis, pointer aliasing, value
flow analysis (and all its applications), regionngbased memory management,
communication topology analysis, Year 2000 type analysis, cryptographic
protocol verification, locking, race detection, and others; see Palsberg (2001)
for an overview of additional applications.

This chapter presents typengbased program analysis based on type and efng
fect systems (or effect type systems) and illustrates their application in regionng
based memory management, which is the chapter's ultimate focus. Classical
type systems express properties of values, not the computations leading to
those values. Effect types describe all important effects of computation, not
just their results. Regionngbased memory management refers to programming
where heap data is allocated in individually managed regions that are explicng
itly allocated and deallocated. As we shall see, statengofngthengart regionngbased
memory management employs effect type systems to ensure region safety,
which guarantees that no accesses to unallocated or deallocated regions ocng
cur at run time.

3.1 Introduction and Overview

Regionngbased memory management has a wellngdeveloped theory, has been
subject to practicengoriented engineering, and is deployed in industrialngquality
language implementations and prototype systems. We provide a consolidated

88 3 Effect Types and RegionngBased Memory Management

review of the state of the art in regionngbased memory management and use
it as an application domain to develop fundamental concepts of effect type
systems step by step.

Value Flow and Simple Effect Analyses
In $3.2, we introduce BL, a standard typed higherngorder functional language.
Then we present an TL, an extension of BL, with atomic labels p (tags, names)
and corresponding tagging and untagging operations t at p and t ! p. Evalung
ation of t at p equips the value v of t with label p resulting in a tagged value
hvip; correspondingly, evaluation of t ! p0 simply checks that p in the value
hvip of t equals label p0 before returning v. We present a type system which
ensures that the check in t ! p0 always succeeds. Thus, the labels and their
operations can be thought of as annotations that let us trace where values are
created and used at runngtime; they express and make explicit value flow inforng
mation of the underlying BL program. The connection of TL and the value flow
information expressed in it to regionngbased memory management is a reinng
terpretation of labels as regions and tagging/untagging operations as region
access operations. An expression t at p is then reinterpreted as "evaluate t,
allocate it in the region bound to p, and return the corresponding pointer,"
and t ! p is reinterpreted as "evaluate t to a pointer into the region bound to
p and load its contents from there." This leaves the problem of figuring out
when to allocate and deallocate a region. The basic idea is extracting lifetime
information about values living in a region ae from typing derivations: If a
(sub)term t that contains uses of a region ae can be typed such that ae neither
occurs in the typing assumptions nor in the result, we take this to mean that
ae does not need to exist before evaluating t or after. So we can evaluate t by
first allocating a new region ae, then evaluating t, and finally deallocating ae.
To express this we extend TL with a construct new ae:t and add straightforng
ward evaluation and typing rules to give language STL. $3.2 concludes with
the observation that STL is unsound because the typing judgments do not
capture accesses to regions from the environment part in lexical closures;
that is, important properties of the computation (evaluation) itself are not
reflected in (the types of) the values produced by those computations.

The unsoundness motivates the use of effect type systems to capture acng
cesses to regions during an evaluation. In $3.3, we introduce effect types
(types and effects), which represent relevant effects (accesses to regions) of
an evaluation together with the type of its result. The basic lifetime interpreng
tation of typing judgments for region allocation and deallocation with explicit
effects is then sound since all accesses to regions are represented in the effect
of an expression, as are those from the environment part of a lexical closure.

3.1 Introduction and Overview 89
RegionngBased Effect Analyses
The development in $3.2 and $3.3 is focused on the conceptual roles of
types, effects, value flow information, and lifetime interpretation of typing
judgments. In particular, the type systems are monomorphic, and regions
cannot be passed as parameters. Turning our attention to realistic regionng
based memory management, $3.4 extends the region annotations by adding
region abstraction and region application. This extension provides the basis
for region polymorphism, which is crucial for practicality. The key result of
this section is conditional correctness: If a region annotated program does not
run into an error (in particular, does not access an unallocated or deallocated
region) then it has the same result as the underlying program without region
annotations. This result by itself shows that region annotations may introng
duce errors during evaluation, but do not otherwise change the semantics of
the underlying program. It is noteworthy that conditional correctness holds
for all regionngannotated terms independent of any type system.

$3.5 presents TT, the Tofte-Talpin region type system, in a simplified form
and adapted to our setting. The main result in this section is type soundng
ness: no TTngannotated term can go wrong. Combining soundness with conding
tional correctness we obtain correctness: A TTngannotated program produces
the same result as the underlying unannotated program. This section highng
lights the role of the type system: its job is to ensure soundness; conditional
correctness is already taken care of.

RegionngBased Systems: Inference and Systems
There are usually many different wellngannotated versions of a given underlyng
ing program, all of which are correct. They do not have the same efficiency
characteristics: Some retain regions substantially longer during execution
than others. In $3.6 we turn to the question of how to automatically infer
"good" region annotations. Region inference is technically complex. The secng
tion discusses the algorithmic techniques that have been used for TT inferng
ence and a number of restricted cases, providing pointers to the relevant
literature for detailed descriptions.

The Tofte-Talpin type system enforces a stack discipline on region allong
cation and deallocation driven by a lexically scoped regionngcreation expresng
sion. $3.7 presents refinements of its standard implementation to accomng
plish better region performance for lexically scoped regions: region resetting
and delayed allocation/early deallocation. Furthermore, it discusses region
lifetime subtyping and systems where region allocation and deallocation are
decoupled altogether: calculus of capabilities for continuation passing style
programs and imperative regions.

90 3 Effect Types and RegionngBased Memory Management

Finally, $3.8 surveys implementations with statically checked regionngbased
memory management: ML Kit with Regions, a Standard ML compiler; Cyclone
and Vault, which are typengsafe Cnglike languages with explicit region manageng
ment and other novel extensions; and prototype systems for Java and Prolog.
It briefly reviews systems and libraries for regionngbased programming with no
static region safety guarantees, but with dynamic or nongregion fault detection.

3.2 Value Flow by Typing with Labels

The language BL, also called Finitary PCF (Jung and Stoughton, 1993; Loader,
2001), is a simply typed lambdangcalculus with general recursion (fix), Boolean
values and callngbyngvalue semantics. It is the underlying language, for which
we shall develop regionngbased memory management based on effect type sysng
tems in this section. Its syntax and smallngstep operational semantics are given
in Figure 3ng1.

Tagged Language
In this subsection we introduce TL, which is BL extended with explicit tagging
and untagging operations. Syntax and operational semantics are defined in
Figure 3ng2, extending the definitions for BL in Figure 3ng1.

The category of label variables ae designates a denumerable set of label varing
ables ae0; ae1; : : : . Like ordinary program variables, label variables are atomic
and have no internal structure. For convenience we may abbreviate label exng
pression to label. Labels p can only consist of label variables for now. We shall
extend p later. Anticipating their reinterpretation later, we shall also call label
variables region variables and labels regions or places.

Operationally, evaluation of t at p consists of tagging the value of t with
label p. We write the result of tagging value v with p as hvip. The untagging
operation t at p0 evaluates t to a tagged value hvip, checks that its label p
matches p0 and, if so, returns the underlying value v. If the label does not
match, the evaluation gets stuck--it goes wrong. As we shall see, the typing
rules of TL guarantee that evaluation never goes wrong in this way for wellng
typed terms.

The tagging and untagging operations serve to name certain sets of values
and to mark where such values are constructed and used. Note the following:

* Multiple subterms of a term may have the same label.

* Even though a label may occur only once in a program, it may tag multiple

values at run time; for example, in *x0:D^x0 at ae0E^ the same label ae0 will

3.2 Value Flow by Typing with Labels 91
Terms

t ::= terms:

v value expression
x variable
t t application
if t then t else t conditional
fix x:t recursion
v ::= value expressions:

*x:t abstraction
bv truth value
bv ::= truth values:

tt true
ff false

Evaluation rules t -! t0

D^*x:t12E^ v2 -! E,x , v2G*t12 (EngBeta)

fix x:t -! E,x , fix x:tG*t (EngFixBeta)
if tt then t2 else t3 -! t2 (EngIfTrue)
if ff then t2 else t3 -! t3 (EngIfFalse)

t1 -! t01
t1 t2 -! t01 t2 (EngApp1)

t2 -! t02
v1 t2 -! v1 t02 (EngApp2)

t1 -! t01
if t1 then t2else t3 -! if t01 then t2else t3 (EngIf)

Types

T ::= types:

bool Boolean type
T ! T function type

Typing rules \Gamma  ` t : T

x 62 \Gamma  0
\Gamma  ; x : T; \Gamma  0 ` x : T (TngVar)

\Gamma  ` bv : bool (TngBool)

\Gamma  ` t1 : bool
\Gamma  ` t2 : T \Gamma  ` t3 : T

\Gamma  ` if t1 then t2 else t3 : T (TngIf)

\Gamma  ; x : T1 ` t : T2
\Gamma  ` *x:t : T1 ! T2 (TngAbs)
\Gamma  ` t0 : T1 ! T2 \Gamma  ` t1 : T1

\Gamma  ` t0 t1 : T2 (TngApp)
\Gamma  ; x : T ` t : T
\Gamma  ` fix x:t : T (TngFix)
Derived form

let x C^ t1 in t2 defC^ D^*x:t2E^ t1

Figure 3ng1: Base language BL

tag multiple values if the function is called multiple times with different
argument values.

* Labels let us distinguish values produced in different places even though

they are extensionally equal; for example, in a call f D^tt at ae0E^ D^tt at ae1E^
we can keep track of the uses of both arguments separately even though
they are the same values.

* We distinguish between v at p and hvip. The former denotes an unevalng

uated expression, where v has not been tagged with p yet, and the latng
ter denotes the result of performing the tagging. This distinction will be

92 3 Effect Types and RegionngBased Memory Management

New terms

t ::= . . . terms:

t at p tagging
t ! p untagging
v ::= . . . value expressions:

hvip tagged value

p ::= label expressions:

ae label variable

New evaluation rules t -! t0

t -! t0
t at ae -! t0 at ae (EngTag)

v at ae -! hviae (EngTagBeta)

t -! t0
t ! ae -! t0 ! ae (EngUntag)

hviae ! ae -! v (EngUntagBeta)

New types

T ::= . . . types:

T at p tagged value type

New typing rules \Gamma  ` t : T

\Gamma  ` t : T
\Gamma  ` t at p : T at p (TngTag)

\Gamma  ` t : T at p

\Gamma  ` t ! p : T (TngUntag)

\Gamma  ` v : T
\Gamma  ` hvip : T at p (TngTagValue)

Figure 3ng2: Tagged language, TL (extension of BL)

important when interpreting labels as regions later on: evaluation of the
former has the effect of accessing the region p whereas the latter does not.

A term is closed if it has no free occurrences of variables. (Closed terms
may have free occurrences of label variables.) A closed value expression is a
value.

We write t t-! t0 if t -! t0 can be derived from the TL evaluation rules;
that is, the evaluation rules of both Figures 3ng1 and 3ng2. A term t is final (or
a final state) if there is no term t0 such that t t-! t0. Each value expression
is final. We call all final states that are not value expressions stuck (or stuck
states).

We write t # t0 if t t-!

* t0 and t0 is final. We write t # if there exists t0

such that t # t0. If t has no final state and thus does not terminate we write
t ".

For simplicity we shall think of BL as a subset of TL. This is justified since
all BLngterms are also TLngterms and both evaluation and typing relations for
TL are conservative over BL. For emphasis we may write t

BL-! t0 if t t-! t0

and t; t0 are BLngterms.

3.2 Value Flow by Typing with Labels 93
Labels as Value Flow Information
The label erasure (or simply erasure) of a TLngterm is the BLngterm we obtain by
erasing all occurrences of at p, ! p and h:ip in it. More precisely, we define
erasure and its inverse, completion, as follows:

3.2.1 Definition [Erasure, completion]: Let t 2 TL. Then the erasure ktk of

term t is defined as follows:

kxk C^ x
kt1 t2k C^ kt1k kt2k
kif t1 then t2 else t3k C^ if kt1k then kt2k else kt3k

kfix x:tk C^ fix x:ktk

k*x:tk C^ *x:ktk

kttk C^ tt
kffk C^ ff
kt at pk C^ ktk

kt ! pk C^ ktkflflfl

hvipflflfl C^ kvk

Conversely, we call a TLngterm t0 a completion of BLngterm t if kt0k C^ t. 2

Note that erasures are BLngterms. Note also that erasures are closed under
substitution:

3.2.2 Proposition: kE,x , t2G*t1k C^ E,x , kt2kG*kt1k 2

A constructor/deconstructor completion (or con/decon completion) is a comng
pletion where each value expression is tagged and untagging takes place
in each destructive context; labels must not occur anywhere else. Formally,
con/decon completions are generated from t in Figure 3ng3.

In a con/decon completion each value gets tagged when it is created, and
every such tag is checked and removed immediately before the underlying
untagged value is destructed--that is, when it is needed as the function in a
function application or as the Boolean test in a conditional. In this fashion
the label p in t ! p tells us which value expressions could have constructed
the value of t.

For this to be true, however, evaluations of TLngterms must not get stuck due
to label mismatch in a redex hviae ! ae0. Intuitively, the reason for this is as
follows. It would be clearly wrong to conclude that evaluation of t ! ae1 uses
a value constructed by a value expression labeled ae1 in the original source

94 3 Effect Types and RegionngBased Memory Management

Con/decon completion templates

t ::= :

v
x
D^t ! pE^ t
if D^t ! pE^ then t else t
fix x:t

v ::= :

D^*x:tE^ at p abstraction
bv at p truth value
bv ::= truth values:

tt true
ff false

Figure 3ng3: Con/decon completions

program if t evaluates to httiae0 . Note, however, that httiae0 ! ae1 is stuck,
which means t ! ae1 gets stuck. Conversely, if an evaluation does not get
stuck, all its computation steps of the form httiae ! ae0 succeed, which is only
possible if ae C^ ae0. In that case a subterm t ! ae expresses that the value of t
is constructed from one of the value expressions labeled ae.

As we shall see, the type system of TL guarantees that no stuck states can
occur during evaluation of (wellngtyped) TLngterms. So the label information in
TLngterms can be soundly interpreted as value flow information.

3.2.3 Example: Consider the BLngprogram t0:

let fst= *u:*v:u in

(let x C^ *p:p tt ff in *y:*q:q D^x fstE^ y)
tt

Value flow analysis should tell us that x may be applied to fst (which is rather
easy to see), fst may be applied to tt (which is not immediately obvious from
the source code), and the *ngabstraction *y:*p:p D^x fstE^ y may be applied to
tt, but *p:p D^x fstE^ y is not applied anywhere.

The following con/decon completion t1 of t0 captures this:

let fst= *lK u:*lbv:u in

(let x C^ *lxp:D^D^plK ttlt E^lb fflf E^ in

*lf y:*lc q:D^D^qlq D^xlx fstE^E^ld yE^)
ttlt

To make the completion more readable, we have written *px:t for D^*x:tE^ at p,
bvp for bv at p, and D^tp t0E^ for D^t ! pE^ t0. 2

3.2.4 Exercise [n', 3]: Show that t1 is a TLngterm by giving a TLngtyping derivation

for it. 2

3.2 Value Flow by Typing with Labels 95
3.2.5 Exercise [n', 3]: Give a reduction sequence t1 t-! : : : t-! tk such that tk is

final. Which (EngUntagBeta) reduction steps occur in it? Which labels occur in
those steps? 2

3.2.6 Exercise [n', 3]: Note that t0 is the erasure of t1: kt1k C^ t0. Give a reduction

sequence kt1k

BL-! : : : BL-! t0

m such that t0m is final. How are tk from Exerng

cise 3.2.5 and t0m related to each other? How long is the reduction sequence

for t0 to tk in comparison to the reduction sequence for t1? (Generalize to
arbitrary TLngterms and their erasures.) 2

3.2.7 Exercise [n'n']: Let S be a substitution mapping the labels occurring in t1 to

(not necessarily different) labels. Consider the term SD^t1E^, which is t1 with
its labels substituted according to S. Is SD^t1E^ TLngtypable? If so, does closure
under all substitutions hold for all closed TLngterms? If not, for which subset
of the closed TLngterms does it hold? 2

Correctness
A TLngterm can be thought of as an instrumented version of the underlying
BLngterm. Intuitively, this is because an evaluation of a TLngterm performs the
same proper computation steps as its erasure (the underlying BLngterm), with
interspersed auxiliary label reduction steps (EngTagBeta) and (EngUntagBeta).

Correctness means that evaluation of TLngterms gives the "same" results as
evaluation of their underlying BLngterms. It is factored into two orthogonal
parts:

1. Conditional correctness, which states that TLngterms produce the same reng

sults as their underlying BLngterms unless they get stuck. Conditional corng
rectness is a property of the evaluation rules for TL and BL alone; it is
independent of their typing rules.

2. Soundness, which states that TLngterms do not get stuck.
It is instructive to see how this method works in a technically very simple
setting such as TL. For this reason we shall introduce it below. The same
results for more expressive languages with effect typing, region scoping and
polymorphism will be proved later on in $3.4 and $3.5.

3.2.8 Definition: Define relations : t1-! : and : t2-! : on TLngterms as follows:

1. t1 t2-! t2 if t1 -! t2 is derived by application of Axiom (EngTagBeta) or

(EngUntagBeta) from Figure 3ng2.

2. t1 t1-! t2 if t1 -! t2 is derived from all evaluation rules of Figures 3ng1 and

3ng2, but without application of Axioms (EngTagBeta) or (EngUntagBeta). 2

96 3 Effect Types and RegionngBased Memory Management

Each t1-! reduction step corresponds to a reduction step in the underlying
BLngterm whereas t2-! reductions do not change the underlying BLngterm at all.
This is captured in the following lemma.

3.2.9 Lemma [Simulation]: Let t; t1; t2 range over TLngterms.

1. If v is a value expression then so is kvk.
2. t2-! is strongly normalizing.
3. If t1 t1-! t2 then kt1k

BL-! kt

2k.

4. If t1 t2-! t2 then kt1k C^ kt2k. 2

3.2.10 Exercise [n'n', 3]: Prove Lemma 3.2.9. 2

Using Lemma 3.2.9 we can prove the following theorem. It states that evalng
uation of a TLngterm performs basically the same computation steps as the
underlying BLngterm until it gets stuck or arrives at a value expression.

3.2.11 Theorem [Conditional Correctness]: For TLngterms t; t0 we have:

1. If t t-!

* t0 then ktk BL

-!

* kt0k.

2. If t " then ktk ".
3. If ktk gets stuck then t gets stuck, too. 2
3.2.12 Exercise [n']: Prove Theorem 3.2.11. 2

The next lemma says that the type of a term is preserved under evaluation.
3.2.13 Lemma [Subject Reduction (Preservation)]: Let t; t0 be TLngterms. If \Gamma  `

t : T and t t-! t0 then \Gamma  ` t0 : T. 2

3.2.14 Exercise [n'n', 3]: Prove Lemma 3.2.13 in standard fashion: by induction on

t t-! t0 and formulating the requisite substitution lemma. 2

3.2.15 Lemma [Progress]: If ` t : T then either t C^ v for some value (closed value

expression) v or there exists t0 such that t t-! t0. 2

Proof: (Sketch) The lemma follows from the following statement: For all derivng
able \Gamma  ` t : T, if \Gamma  C^ ; then

1. there exists t0 such that t t-! t0, or

3.2 Value Flow by Typing with Labels 97

2. (a) if T is of the form T0 ! T00 then t C^ *x:t00 for some x; t00, and

(b) if T C^ bool then t 2 {tt; ff}.

This statement can be proved by rule induction on \Gamma  ` t : T. 2

The Progress Lemma says that a wellngtyped closed term is not stuck. Tong
gether with the Subject Reduction Lemma it says that, since all its reducts are
wellngtyped, too, it never gets stuck.

3.2.16 Theorem [Soundness]: If ` t : T then evaluation of t does not get stuck. 2

Putting the Conditional Correctness Theorem and the Soundness Theorem
together we obtain as a corollary the correctness of TL relative to BL:

3.2.17 Corollary [Correctness]: Let t be a closed TLngterm and v a TLngvalue.

1. t " iff ktk ".

2. ktk

BL-!* kvk iff there exists a TLngvalue v0 with kv0k C^ kvk and t t-!* v0. 2

3.2.18 Exercise [n'n']: Prove Corollary 3.2.17. 2

Inference of Value Flow Information
Given a BLngterm t we are interested in finding a con/decon completion to
obtain value flow information about t. Note, however, that a BLngterm t may
have many different con/decon completions, and while each provides sound
value flow information, some provide better information than others. For exng
ample, the trivial completion in which each label operation in a term has the
same label aeh contains no useful value flow information: it says that any value
created anywhere may be used anywhere. Correct, but trivial. Intuitively, we
are interested in a con/decon completion with a maximal number of distinct
labels, as this gives the most finenggrained value flow information.

3.2.19 Exercise: Consider t0 C^

let fst = *u:*v:u in

(let x C^ *p:p tt ff in *y:*q:q D^x fstE^ y)
tt

again and its con/decon completion t1 =

let fst= *lK u:*lbv:u in

(let x C^ *lxp:D^D^plK ttlt E^lb fflf E^ in *lf y:*lc q:D^D^qlq D^xlx fstE^E^ld yE^)
ttlt .

98 3 Effect Types and RegionngBased Memory Management

Does there exist another con/decon completion of t0 with more distinct lang
bels or is t1 maximal in this sense? 2

Indeed, it can be shown that each BLngterm has a con/decon completion such
that any other of its con/decon completions can be obtained by applying a
label substitution to it. We call it a principal completion of the given BLngterm.
In particular, principal completions have the maximal possible number of
distinct labels. Furthermore, they are unique up to renaming of labels.

We shall not go into any technical details on how to infer principal compleng
tions, but present the basic ideas.

A con/decon completion template for a BLngterm t is a con/decon comng
pletion of t in which each label variable occurs exactly once. Clearly, each
con/decon completion that satisfies the TLngtyping rules is a substitution inng
stance (mapping labels to labels) of this template. Furthermore, it can be
shown that a substitution gives rise to a wellngtyped con/decon completion
if and only if it satisfies a set of equational constraints between the temng
plate labels. That set can be computed in linear time from the con/decon
completion, and a most general solution of the constraints can likewise be
computed in linear time. The most general solution, in turn, gives rise to a
principal completion when applied to the con/decon completion template.
What we have described is the standard method for simple type inference by
equational constraint extraction and solution; see, for example, Wand (1987b)
and Henglein (1989) for simple type inference and Mossin (1997, Section 2)
for its application to value flow analysis.

The pleasant properties of processing sets of equational constraints--in
particular, existence of most general/principal solutions and efficient increng
mental algorithms for computing them (unification)--have led to type sysng
tems whose design has been driven to a considerable degree by a desire to
deploy efficient unification technology for automatic inference, not only by
semantic or logical analysis for capturing relevant semantic information.

Labels as Regions
We can think of region variables as being bound to memory regions and
(re)interpret tagging and untagging operations as follows. The value hvip deng
notes a(ny) pointer into region p where v is stored. The tagging operation
t at p is implemented by storing the value of t in region p. Its result is the
pointer to where the value is stored. The untagging operation t ! p is impleng
mented as evaluating t to a pointer, checking that it points into region p and,
if it does, retrieving the pointer's value. The TL type system guarantees that
all checks succeed and so can be elided at run time.

3.2 Value Flow by Typing with Labels 99
New terms

t ::= . . . terms:

new ae:t regionngscoped term
p ::= label expressions:

* deleted/inaccessible region)

New evaluation rules t ST-! t0

t -! t0
new ae:t -! new ae:t (EngNew)

new ae:v -! E,ae , *G*v (EngNewBeta)
New typing rules \Gamma  ` t : T

\Gamma  ` t : T
ae 62 frvD^\Gamma  ; TE^

\Gamma  ` new ae:t : T (TngNewUnsound)

Figure 3ng4: Scoped tagged language (unsound), STL (basis: TL)

Now consider the (derivable) judgment \Gamma  ` t : T for a subterm t in a prong
gram. Assume that ae occurs in t in tagging and/or untagging operations. If
ae does not occur in \Gamma  then, intuitively, the environment in which t evaluates
contains no values in ae; it is empty. Furthermore, if ae does not occur in T eing
ther, then no values stored in ae are needed by the context of t; all the values
stored in ae can be deleted.

This leads us to the introduction of terms with (lexically) scoped regions:
new ae:t. Here new ae:t binds region variable ae in t. The semantics of new ae:t
is as follows: allocate a new region, bind it to ae, evaluate t and, finally, dealng
locate the region bound to ae. This results in a stackngoriented memory manng
agement discipline: the most recently allocated region is deallocated first.

Figure 3ng4 shows new ae:t and corresponding evaluation and typing rules,
which extend TL to STL. In rule (TngNewUnsound) function frvD^\Gamma  ; TE^ denotes
the set of region variables that occur freely in \Gamma  and T.

Rule (EngNew) expresses that a regionngscoped term new ae:t is evaluated by
reducing t to a value v. During this reduction, it is possible that region ae
is accessed. After evaluation is complete new ae:v is reduced to E,ae , *G*v by
rule (EngNewBeta), where * is substituted for all occurrences of ae in v. In
particular, all occurrences in v of the form hv0iae are replaced by hv0i*. Since
rule (EngUntagBeta) from Figure 3ng2 requires a proper region variable, any
access to such a value gets stuck. Note, in particular, that the term hv0i* ! *
is stuck. In this fashion the substitution of * for ae makes all values stored
in ae inaccessible in ensuing computation steps, which models deleting the
whole region of values stored in ae.

The bad news is that STL is unsound: Stuck states can occur. The reason
for this is that a term t with derivable judgment \Gamma  ` t : T may still access
region ae during evaluation even if ae occurs neither in \Gamma  nor T.

100 3 Effect Types and RegionngBased Memory Management

3.2.20 Example: Consider the following STLngterm tf C^:

new ae0:let x C^ tt at ae0 in *y:if x ! ae0 then y else ff at ae1
It reduces as follows:

new ae0:let x C^ tt at ae0 in *y:if x ! ae0 then y else ff at ae1 -!
new ae0:let x C^ httiae0 in *y:if x ! ae0 then y else ff at ae1 -!
new ae0:*y:if httiae0 ! ae0 then y else ff at ae1 -!
*y:if htti* ! * then y else ff at ae1

Note that ae0 occurs freely in *y:if httiae0 ! ae0 then y else ff at ae1 before
performing the last reduction step. Its type bool at ae1 ! bool at ae1, howng
ever, does not mention ae0. Note that

*y:if htti* ! * then y else ff at ae1
is a value; it is not stuck. It is easy to see, however, how it can give rise to a
stuck state. The program tf D^tt at ae1E^ is a wellngtyped STLngprogram of type
bool at ae1, yet evaluation gets stuck:

tf D^tt at ae1E^ *-!
D^*y:if htti* ! * then y else ff at ae1E^ D^tt at ae1E^ -!
if htti* ! * then ff at ae1 else ff at ae1

To continue evaluation would require reduction of htti* ! * to a Boolean
value; htti* ! *, however, is stuck. 2

In $3.3 we introduce explicit effects into types to capture the accesses to
regions needed for evaluation. This is the path taken by Tofte and Talpin
(1997) in their groundngbreaking work on regionngbased memory management.

Notes on Value Flow Analysis
Although Reynolds (1969) was the first to look at the problem of computng
ing flow for structured data and called it data set computation, we follow
Schwartz (1975) in using the term value flow to emphasize its general apng
plicability to primitive, structured, and higherngorder data. Schwartz (1975)
developed value flow analysis for structured values in the context of SETL
and was the first to suggest exploiting lifetime analysis based on value flow
analysis for regionngbased memory management. Closure analysis, the term inng
troduced by Sestoft (1989), and control flow analysis, the term used by Shivers
(1988; 1991), focus on the flow of function values (function closures). Note

3.2 Value Flow by Typing with Labels 101
that data and control flow are interdependent for higherngorder languages; see
Mossin (1997, Section 1.4) for a discussion of this. Shivers coined the term
0CFA, which in other literature is also used for the monovariant value flow
analyses above (which is different from Shivers' 0CFA, however; see Mossin
[1997] for a discussion). Another form of monovariant value flow analysis is
setngbased analysis (Heintze, 1994).

Palsberg and O'Keefe (1995) showed that safety analysis, a constraintngbased
analysis, characterizes typability in Amadio and Cardelli's type system (1993)
with recursive subtyping, providing a type theoretic characterization of monong
variant value flow analysis. Constraintngbased value flow analysis for objectng
oriented languages was pioneered by Palsberg and Schwartzbach (1990, 1994).
See Nielson, Nielson, and Hankin (1999) for a presentation of monovariant
value flow analysis based on flow logic and abstract interpretation.

Classical data flow analysis corresponds to value flow analysis for primitive
data (only); it has been used in compilers already in the early 1960s. See Aho,
Sethi, and Ullman (1986) for its history.

Monovariant value flow analysis is directional: values flow from construcng
tor points (value expressions) to uses, but not the other way around. The
value flow information for BL as expressed in TLngcompletions corresponds to
a very simple (and inexpressive) value flow analysis: equational flow analysis,
in which value flows are treated symmetrically (Heintze, 1995). Intuitively,
this means all flows are bidirectional: values do not only "flow" from their
creation points to their uses, as in monovariant value flow analysis (0CFA),
but somewhat weirdly, also the other way around. The typengbased presentang
tion of equational value flow analysis in this section owes greatly to Mossin
(1997, Section 2), where it is called simple flow analysis.

Polymorphic value flow analysis was developed by Mossin (1997), extendng
ing earlier work by Dussart, Henglein, and Mossin (1995) and Henglein and
Mossin (1994) on combining subtyping, parametric polymorphism and polyng
morphic recursion for bindingngtime analysis. Polymorphic value flow analng
ysis is modular and can be computed asymptotically in the same time as
monomorphic value flow analysis. Transitive closure is the algorithmic botng
tleneck in both. Efficient algorithms are given by Fa"hndrich, Rehof, and Das
(2000), Rehof and Fa"hndrich (2001), and Gustavsson and Svenningsson (2001).

Polymorphic equational value flow analysis underlies Tofte-Talpin style
regionngbased memory management; see $3.5. Regionngbased memory manageng
ment based on directional value flow analysis appears possible, but has not
been explored. The recognition that region inference performs a form of value
flow and dependency analysis is folklore; it has been exploited by Helsen and
Thiemann (2004) for polymorphic specialization. Deriving regionngbased memng
ory management systematically from typengbased value flow analysis appears

102 3 Effect Types and RegionngBased Memory Management

to be new, however. The syntactic modeling of region deallocation by * is due
to Helsen and Thiemann (2000) and Calcagno (2001).

See $3.4 and the following sections for more references on regionngbased
memory management.

3.3 Effects

We have seen in the previous subsection that the soundness of a typing rule
may depend not only on the results of evaluations, but on certain aspects
of the evaluation itself, in other words on how a value is computed, not just
which value is computed. To capture properties of evaluation we introduce
effects.

Effect Type Judgments
The basic effect type judgment is

\Gamma  ` t :' T
where ' is an effect expression (henceforth simply called effect) and 'T is an
effect type or type and effect. The judgment should be read informally as "Unng
der the assumptions \Gamma  , the evaluation of t may have the observable effect ',
and it eventually yields a value of type T, if any." For program analysis purng
poses observable may also be understood as interesting. When an evaluation
has no observable effect, we say it has the empty effect, written ;, and ;T is
abbreviated to T.

In a callngbyngname language, \Gamma  is a sequence of effect type assumptions of the
form x : 'T, since x may be bound to unevaluated thunks, whereas in a callng
byngvalue language we have type assumptions of the form x : T since variables
are bound to values, whose evaluation is guaranteed to always have the empty
effect. Analogously, in a callngbyngname language we have general functional
types of the form '1T1 ! '2T2; in a callngbyngvalue language, however, we can
restrict ourselves to functional types of the form T1 ! 'T2.1

1. The syntax 'T has been chosen here for several reasons:

* It expresses that yielding a value of type T is the last "effect" of evaluation; that is it occurs

after '.

* Functional types in a callngbyngvalue language end up being written T1 ! 'T2, which is conng

sistent with the notation used in the literature where the delayed effect ' is written above
the function type arrow.

* It is consistent with the syntax M'T used in monadic interpretations of type and effect

systems in the literature.

3.3 Effects 103
Terms

t ::= terms:

v value expression
x variable
t t application
if t then t else t conditional
t at p tagging
t ! p untagging
new ae:t labelngscoped term
fix x:t recursion
v ::= value expressions:

*x:t abstraction
bv truth value
hvip tagged value

bv ::= truth values:

tt true
ff false
p ::= label/region expressions:

ae label/region variable

* deleted/inaccessible label/region

Effect expressions

' ::= {ae, . . . , ae} effect expressions:

Types

T ::= types:

bool Boolean type
T ! 'T function type
T at p tagged value type

Effect typing rules \Gamma  ` t :' T

x 62 \Gamma  0
\Gamma  ; x : T; \Gamma  0 ` x :' T (TEngVar)

\Gamma  ` bv :' bool (TEngBool)

\Gamma  ` t1 :' bool
\Gamma  ` t2 :' T \Gamma  ` t3 :' T

\Gamma  ` if t1 then t2 else t3 :' T (TEngIf)

\Gamma  ; x : T1 ` t :'2 T2
\Gamma  ` *x:t :'1 T1 ! '2T2 (TEngAbs)

\Gamma  ` t0 :' T1 ! 'T2

\Gamma  ` t1 :' T1

\Gamma  ` t0 t1 :' T2 (TEngApp)
\Gamma  ` t :' T p 2 '

\Gamma  ` t at p :' T at p (TEngAt)
\Gamma  ` t :' T at p p 2 '

\Gamma  ` t ! p :' T (TEngFrom)

\Gamma  ` v :' T
\Gamma  ` hvip :' T at p (TEngCell)
\Gamma  ` t :' T ae 62 frvD^\Gamma  ; TE^

\Gamma  ` new ae:t :'-{ae} T (TEngNew)

\Gamma  ; x : T ` t :' T
\Gamma  ` fix x:t :' T (TEngFix)

Figure 3ng5: Scoped effect typed language ETL(sound)

Effect Typed Language ETL
We shall now present an effect typing system for language ETL. ETL has the
same source terms and evaluation rules as STL. The only difference to STL
is its effect type system. Syntax and effect typing rules for ETL are given in
Figure 3ng5.

An effect is a finite set of region variables. Note that it must not contain *.
A judgment \Gamma  ` t :' T is intended to express that, assuming the free variables

104 3 Effect Types and RegionngBased Memory Management

of t are bound to values of types according to \Gamma  , the regions that t accesses
during evaluation are included in ' and the result of the evaluation has type
T if it terminates.

The typing rules of Figure 3ng5 are basically those corresponding to the
monomorphic subset of the ToftengTalpin system, which we shall encounter in

$3.5.2 They are inspired by a desire to employ equational constraint solving
for effect expressions as much as possible.

Since we are only interested in whether a particular region may be accessed
during evaluation of a term or not, our effect system does not record the
order in which effects take place. We simply record the set of region variables
that may be accessed during evaluation of t. In this sense our effect type
system is controlngflow insensitive. Effect type systems that capture evaluation
order in their effects are discussed briefly later.

Soundness
Effects make the region variables accessed during evaluation sufficiently "visng
ible" to ensure that the typing rule for new ae:t is sound.

3.3.1 Example: Consider the term

tf C^ new ae0:let x C^ tt at ae0 in *y:if x ! ae0 then y else ff at ae1
from Example 3.2.20 again. Whereas it is typable in STL even though it gets
stuck when applied to an argument, it is not typable in ETL. To see this,
consider the letngexpression tl

let x C^ tt at ae0 in *y:if x ! ae0 then y else ff at ae1
inside tf . Its ETL effect type Tl is {ae0}D^bool at ae1 ! {ae0}bool at ae1E^. Note that
ae0 occurs in the effect, but in neither the function type's domain nor its range
type. This reflects the fact that an application of tl may access region ae0.
Since ae0 2 frvD^bool at ae1 ! {ae0}bool at ae1E^, rule (TEngNew) is not applicable,
and so there is no way of inferring a type for tf , which indeed would be
unsound. 2

3.3.2 Exercise [n'n', 3]: Give a derivation of ` tl : Tl. Argue that any ETLngderivable

type T for tl must contain an occurrence of ae0. 2

2. The only substantial difference is rule (TEngApp). It is more restrictive than the corresponding
rule (RTngApp) in the sense that it requires '2 ` ' in rule (RTngApp) to be solved equationally.
Note that, in general, the typing rules of TT in $3.5 are for con/decon completions (only). They
can be derived from ETL by merging rules (TEngFrom) and (TEngCell) into the other rules.

3.3 Effects 105
Generally, we can prove the following soundness theorem.
3.3.3 Theorem [Soundness of ETL]: If ` t :' T then evaluation of t does not get

stuck. 2

We shall not prove this result here. The techniques will be presented in

$3.5 for a more general type system.

3.3.4 Exercise [n'n'n'n', 3]: Prove correctness for ETL. Do so by extending the Conng

ditional Correctness Theorem and the Soundness Theorem for TL to ETL. 2

Notes on Effect Type Systems
Type and effect systems are introduced by Lucassen, Gifford and Jouvelot
(Gifford and Lucassen, 1986; Lucassen, 1987; Lucassen and Gifford, 1988;
Jouvelot and Gifford, 1989) for integrating imperative operations, notably upng
datable references and control effects, into functional languages. Type and
effect inference using unification technology, which is the basis for region
inference, is developed by Jouvelot and Gifford (1991) and Talpin and Joung
velot; Talpin and Jouvelot (1992; 1994). Tofte and Talpin (1997) develop it
into region inference for regionngbased memory management.

Nielson and Nielson (1994, 1996) pioneered type and effect systems with
behaviors or causal effects, where effect types model order of evaluation. In
such systems the language of effect expressions has operators for sequenng
tial composition and choice. They also provide for recursively defined effect
expressions. The sequential composition operator captures the sequential orng
der of the execution of effects. The choice operator corresponds to choice
of one effect or another. This changes the nature of effects substantially as
they basically turn into process algebras, with their own nontrivial theory.
Modeling order of execution is key to capturing synchronization properties
of concurrent processes, where atomic effects include sending and receiving
messages. See Amtoft, Nielson, and Nielson (1999) and Nielson, Nielson, and
Hankin (1999) for references on soundness, inference and applications.

The applications of type and effect systems include verification of crypng
tographic protocols by effect type checking (Gordon and Jeffrey, 2001b,a,
2002), behavioral type systems for asynchronous programming (Igarashi and
Kobayashi, 2001; Rajamani and Rehof, 2001; Chaki, Rajamani, and Rehof,
2002; Rajamani and Rehof, 2002), and interference analysis for concurrent
threads (see Flanagan and Qadeer [2003] for references).

In terms of the computational *ngcalculus of Moggi (1989), types are assong
ciated with values and effect types with computations; that is, intuitively, an
effect type 'T corresponds to an (effect indexed) monad type M'T. This conng

106 3 Effect Types and RegionngBased Memory Management

nection is investigated by Semmelroth and Sabry (1999), Wadler (2003), and
Fluet (2004).

3.4 RegionngBased Memory Management

Regionngbased memory management is a particular way to manage the dyng
namically (or heapng) allocated memory of a program. Traditionally, the heap
is managed either explicitly by the programmer using constructs such as C's
malloc and free, or automatically by a garbage collector leaving the prong
grammer with only the responsibility of when to allocate memory. Regionng
based memory management uses explicit instructions for the allocation and
deallocation of memory, but the safety of the explicit deallocations is guarng
anteed by a type system, and in some cases a compilengtime analysis called
"region inference" ($3.6) can insert the allocation and deallocation instrucng
tions automatically.

Basically a region is a subngheap containing a number of heapngallocated valng
ues, and the heap is a collection of regions. A region starts out empty and
grows when a value is allocated in it. A region can grow independently of the
other regions constituting the heap; that is, one can allocate values in all reng
gions currently available. Regions can only shrink when the complete region
is deallocated; one does not deallocate individual values.

In summary, we use three region primitives: (1) allocation of a new region,
(2) allocation of a value in a region, and (3) deallocation of a complete region
(and thereby all values allocated in the region). In contrast to TL in $3.2 we
simply elide dereferencing.

A RegionngAnnotated Language
Our regionngannotated language RAL is a lambda calculus with a fixedngpoint
operator and (Boolean) constants, extended with explicit region annotations.
Its syntax and evaluation semantics are defined in Figure 3ng6. As usual, *x:t
and fix x:u binds the variable x in t and u, respectively. Similarly, *ae:u and
new ae:t binds the region variable ae in u and t, respectively.

By analogy with $3.2, we define basic semantic notions for RAL. We write
t

RAL-! t0 if t -! t0 can be derived from the RAL evaluation rules in Figure 3ng6.

A RALngterm t is final if there is no term t0 such that t

RAL-! t0. Note that each

value expression is final. All other final terms are stuck.

We write t -!* t0 if t

RAL-!* t0 and t0 is final and t # if there exists t0 such

that t # t0. If t has no final state and thus does not terminate, we write t ".
The relation !*! on terms is defined by: t !*! t0 if t -!* t0 and t0 is final.

3.4 RegionngBased Memory Management 107
Terms

t ::= terms:

u value or almostngvalue
x variable
if t then t else t conditional
fix x:u recursion
t t application
t E,E,pG*G* region application
new ae:t region creation
u ::= almostngvalues:

v value
D^*x:tE^ at p abstraction
D^*ae:uE^ at p region abstraction
v ::= value expressions:

bv truth value
h*x:tip closure
h*ae:uip region closure

bv ::= truth values:

tt true
ff false
p ::= places:

ae region variable

* deallocated

Evaluation t

RAL-! t0

t1 -! t01
if t1 then t2else t3 -! if t01 then t2else t3 (REngIf)

if tt then t2 else t3 -! t2 (REngIfTrue)
if ff then t2 else t3 -! t3 (REngIfFalse)

t1 -! t01
t1 t2 -! t01 t2 (REngApp1)

t2 -! t02
v1 t2 -! v1 t02 (REngApp2)
*x:t at ae -! h*x:tiae (REngClos)
h*x:tiae v -! E,x , vG*t (REngBeta)

u -! u0
fix x:u -! fix x:u0 (REngFix)

fix x:v
-! E,x , fix x:vG*v (REngFixBeta)

t -! t0
t E,E,pG*G* -! t0 E,E,pG*G* (REngRApp)
*ae1:u at ae2 -! h*ae1:uiae2 (REngRClos)
h*ae1:uiae2 E,E,pG*G* -! E,ae1 , pG*u (REngRBeta)

t1 -! t01
new ae:t1 -! new ae:t01 (REngNew)

new ae:v -! E,ae , *G*v (REngDealloc)

Figure 3ng6: Regionngannotated language, RAL

3.4.1 Definition: Let the function "evalRD^*E^" from terms to {tt; ff; ?; wrong} be:

a) evalRD^t0E^ C^ bv iff t0 !*!R bv.
b) evalRD^t0E^ C^ ? iff there is an infinite sequence t1; t2; : : : ; ti; : : : such that

ti

RAL-! ti+

1 for 0 <= i.

c) evalRD^t0E^ C^ wrong iff t0 !*! t where t is not a value. 2

108 3 Effect Types and RegionngBased Memory Management

Recall that the new ae:t construct introduces a new region variable ae. The
variable ae can be used to annotate valuengproducing terms within t. The alng
location of the new region in our system is implicit; it happens automating
cally when the execution focus moves inside the new binder. Implicit alphang
conversion makes sure that the new does not capture any foreign region varing
ables before the allocation. On the other hand, deallocation is explicit in the
evaluation semantics. The (REngDealloc) rule records the fact that a value
stored in the deallocated region is no longer available by replacing the region
variable with the special marker *. The "dangling pointers" to deallocated valng
ues can be manipulated freely as long as one does not attempt to read the
values they point to. At that point execution will get stuck, because there is no
reduction rule for an expression of the form "h*x:ti* v." Rule (REngBeta) that
would ordinarily reduce it applies only when the place is a ae, which explicitly
does not include * as in the effect typed language ETL.

Observe that the substitution E,ae , *G* in (REngDealloc) can affect allocang
tion expressions D^* * * E^ at ae as well as already allocated values h* * * iae. In the
former case we end up with a "D^* * * E^ at *" expression which asks to allong
cate something in a region that does not exist anymore. This is impossible, of
course, but the occurrence of such a subterm is not an error. The error hapng
pens if the expression is eventually executed, in which case execution will get
stuck because (REngClos) and (REngRClos) demand a ae rather than a p after the
"at." Similarly a * can appear as the actual parameter in a region application,
and the application can even be reduced without an error.

A novel aspect of the regionngannotated language, compared to the tagged
language described previously, is the presence of region abstractions. The inng
tention is that a region abstraction "*ae:u," where u is an "almostngvalue (see
Figure 3ng6) ranging over normal values and yetngtongbengallocated abstractions,
is the natural counterpart to a normal abstraction only at the level of reng
gions. One can apply such an abstraction to an actual place parameter p in
which case evaluation proceeds by substituting the place p for the formal
parameter ae in u, and then evaluates the result of this substitution. Region
abstractions allow one to parameterize a function over the regions necessary
for the evaluation of the function. Typically, this means parameterizing over
the regions containing the input to the function and the regions in which the
output should be stored. We say that such a function is region polymorphic
in the region parameters.

For example, consider the following program computing Fibonacci numng
bers.3

3. In examples we shall allow ourselves to use features such as integers allocated in regions
even though they are not part of the formal development.

3.4 RegionngBased Memory Management 109

fix fib. *n.

if n<2 then 1
else fib(nng2)+fib(nng1)

One possible region annotation of this program is (ignore everything but the
first line for now):

fix fib. (*aei. (*aeo. (*n.

if new ae. (n < (2 at ae) then 1 at aeo)
else new ae1.

new ae2.fibE,E,ae2G*G*E,E,ae1G*G* (new ae.n ngat ae2 (2 at ae))
+ataeonew ae3.fibE,E,ae3G*G*E,E,ae1G*G* (new ae.n ngat ae3 (1 at ae))
) at aei) at aei) at aef

The point is that the fib function expects two region parameters at runtime:
one, aei, in which the input n is stored, and one, aeo, in which the function
is supposed to store its result. Thus, any caller of fib is required to choose
appropriate actual regions for these as witnessed in the two calls to fib in
the body.

Observe that, since the only way to allocate and deallocate a region is via
the new construct, it is not possible for the function to deallocate a region
associated with a parameter, and similarly, the function cannot itself allong
cate such a region. The consequence is that the lifetime of regions passed as
parameters to a function encompasses the lifetime of the complete function
invocation. In order to avoid large, longnglived regions, it is therefore imporng
tant to allow the body of a recursive function to use actual parameters to
recursive invocations different from the formal parameters. This is referred
to as region polymorphic recursion in the literature, as it allows us to choose
different instantiations of the polymorphically bound region parameters for
different invocations.

Continuing the Fibonacci example above, it is crucial that the two recursive
calls to fib can each supply their own actual parameters (in this case ae2; ae1
and ae3; ae1). Thus, for each call we store the arguments in separate regions
whose lifetimes are just the duration of the function call. The results need
slightly longer lifetimes, since we need to add those up to give the result of
the original call, but they can be stored in the same region. (The example is
taken from Tofte and Talpin [1997].)

3.4.2 Exercise [n'n']: What would happen to the regionngbehavior of the Fibonacci

program if region polymorphic recursion were disallowed (that is, if the reng
cursive calls were required to use the formal region parameters as actual
region parameters)? 2

110 3 Effect Types and RegionngBased Memory Management

The original calculus proposed by Tofte and Talpin (let us call it the TT calng
culus) differs from our RAL in a number of ways. The most conspicuous difng
ference is that the regionngcreation construct "new ae:t" is written "letregion
ae in t." A more subtle one is that TT restricts the places where region abng
stractions and recursive function definitions can occur. Region abstractions
are only allowed in the definition of recursive functions, and a recursive funcng
tion definition must appear in a let binding. These restrictions are implicit
in the syntax of TT--it combines recursion and region abstraction in a single
combined construction

t ::C^ letrec f[ae1; : : : ; aek](x) at ae C^ t1 in t2
which corresponds to the RAL expression

let f C^ fix f:D^*ae1; : : : ; aek; ae0:D^*x:t1E^ at ae0E^ at ae in t2
Using the letrec as an abbreviation, we can rewrite the Fibonacci example
to the following program:

letrec fib[aei; aeo] (n) at aef =

if new ae. (n < (2 at ae) then 1 at aeo)
else

new ae1.

new ae2. fib[ae2; ae1] (new ae. n ngat ae2 (2 at ae))
+at aeonew ae3. fib[ae3; ae1] (new ae. n ngat ae3 (1 at ae))

3.4.3 Exercise [n'n']: This unfolding of the TT letrec uses abstraction over multing

ple regions at once, which is not actually part of the RAL calculus. Show how
nngary region abstractions can be simulated using our unary ones. 2

3.4.4 Exercise [n']: What is the role of the ae0 parameter in the above RAL expanng

sion of TT's letrec construction? Can you guess why it is not part of the
original TT syntax? 2

3.4.5 Exercise [n']: What is the role of ae in the letrec construction? Is it really

operationally necessary? 2

The dynamic semantics presented by Tofte and Talpin (1997) stresses that
regions are allocated and deallocated according to a stack discipline. A runng
time configuration contains a region environment that maps region variables
to concrete regions (denoted by r), and a store that maps (concrete) regions to
the values stored in them. Evaluation of a new ae:t then proceeds as follows:
(1) first choose a fresh (concrete) region r and extend the region environment

3.4 RegionngBased Memory Management 111
with a binding ae , r and the store with a binding r , ; where ; is the
empty region containing no values; (2) then proceed with the evaluation of
t in this extended runtime configuration; (3) complete the evaluation of the
entire term by removing the bindings for ae and r from the configuration.

That original formulation is closer to an operational understanding of how
the region operations work than the storengless semantics we use here. On the
other hand, the storengless semantics is easier to reason about, a trick due to
Helsen and Thiemann (2000) and Calcagno (2001). See Calcagno et al. (2002)
for a proof that the two styles of semantics are indeed equivalent.

Reusing Deallocated Memory
Intuitively it should be safe to reuse deallocated memory (indicated by the
special place *) while executing a regionngsafe program. More formally, assume
that t* is a term containing deallocated values and that t is constructed from
t* by replacing some of these with new values. Then if t* evaluates to some
value or loops indefinitely (that is, it does not go wrong), then so does t.

3.4.6 Proposition: Let Val be the set of values and Dead be the subset of values of

the form "h: : :i*." Let the relation _ between terms be the compatible closure
of Dead * Val. That is, t* _ t if t arises from t* by replacing some (zero or
more) deallocated values by arbitrary new values.

If t* _ t and evalRD^t*E^ C^ Y T^ wrong, then evalRD^tE^ C^ Y , too. 2

Proof: Left as an exercise (n'n', 3). 2
Annotating Programs with Regions Preserves Meanings
Region annotating a program is the process of adding region annotations to
it to make the memory management explicit (see $3.6 for how to do this aung
tomatically). Thus, the process takes a program written in BL and produces a
program written in RAL. The intention is, of course, that the regionngannotated
program is supposed to have the same behavior as the original program. In
other words, we shall prove that adding region annotations preserves the
meaning of the program. We make this precise in the present section. We
do so by starting with a regionngannotated program and showing that it beng
haves the same as the program obtained by removing all region annotations
(thereby obtaining a program in BL, Figure 3ng1).

By analogy with erasure for TLngterms, going from a term in the regionng
annotated language RAL to a term in the underlying base language BL is a
matter of erasing all region annotations.

112 3 Effect Types and RegionngBased Memory Management

kbvk C^ bvflflflfl
if t0 then t1else t

2 flflflfl C^ if kt0k

then kt1k
else kt2k
kxk C^ x

kD^*x:tE^ at pk C^ *x:ktkflflfl

h*x:tipflflfl C^ *x:ktk

kt1 t2k C^ kt1k kt2k
kfix x:uk C^ fix x:kuk

knew ae:tk C^ ktk
kD^*ae:uE^ at pk C^ kukflflfl

h*ae:uipflflfl C^ kuk

kt E,E,pG*G*k C^ ktk

Figure 3ng7: Definition of the erasure function

3.4.7 Definition: The erasure ktk of a regionngannotated term t is the BLngterm

defined by removing the region annotations, as shown in Figure 3ng7. 2

The ideal meaningngpreservation statement would be: For any regionngannong
tated program t, if evalRD^tE^ C^ Y then evalD^ktkE^ C^ Y and vice versa. Unforng
tunately that is not true, since t can go wrong due to memoryngmanagement
errors (such as trying to read a value after it has been deallocated) that have
no counterpart in ktk. What we can prove, however, is the following theorem:

3.4.8 Theorem [Conditional correctness]: Let t be a regionngannotated program

(i.e., formally, any term), and assume evalRD^tE^ T^ wrong. Then evalRD^tE^ C^
evalD^ktkE^. 2

In other words, a regionngannotated program behaves the same as the origng
inal unannotated program, unless it goes wrong. Our semantics for regionng
annotated programs does not allow us to distinguish between going wrong
because of memoryngmanagement errors and going wrong due to plain old
type errors, but it would be straightforward (though tedious) to extend the
semantics with such a notion and then prove that if evalD^ktkE^ T^ evalD^tE^ then
evalD^tE^ is memoryngwrong rather than typengwrong. Since we are primarily conng
cerned with wellngtyped programs, we will not pursue that further.

The proof of the theorem proceeds through a series of lemmas:

3.4.9 Lemma: Assume that t is a value v or an almostngvalue u. Then ktk is a value

for BL. 2

Proof: By structural induction on t. The induction hypothesis is used in the
case of region abstractions and closures, which disappear during erasure.
(This is why the body of a region abstraction is restricted to be an almostng
value rather than an arbitrary term.) 2

3.4 RegionngBased Memory Management 113
3.4.10 Lemma [Simulation]: Assume t

RAL-! t0. Then either (a) ktk -! kt0k or (b)

ktk C^ kt0k. 2

Proof: By induction on the derivation of t

RAL-! t0.

For the rules (REngIf), (REngApp1), and (REngApp2), apply the induction hypotheng
sis. If this application yields case (a), use the corresponding context rule from
BL. In the case of (REngApp2), Lemma 3.4.9 ensures that erasure of the function
expression is still a value, such that the corresponding BL rule is available.

For the rule (REngFix), first observe that since the body of the fix is an almostng
value, the only rules that can establish the reduction u

RAL-! u0 are (REngClos)

and (REngRClos). Then, by inspection of each of these rules we find kuk C^ ku0k,
and thus also kfix x:uk C^ kfix x:u0k.

For (REngIfTrue), (REngIfFalse), (REngBeta), and (REngFixBeta), the ktk -! kt0k
case applies through the corresponding BL reductions.

For (REngRApp) and (REngNew), use the induction hypothesis directly.
For (REngClos) and (REngRClos), ktk C^ kt0k holds trivially. The case is siming
lar for (REngRBeta) and (REngDealloc), because the erasure hides the effect of
region substitutions. 2

3.4.11 Lemma [Simulated progress]: Assume t

RAL-! t0 yet not ktk -! kt0k. Then

t0 is strictly smaller than t under a size measure where unevaluated abstracng
tions are considered "larger" (for example, twice as large) than closures. 2

Proof: From the proof of Lemma 3.4.10 it is clear that the derivation of
t

RAL-! t0 must consist of a stack of context rules with one of the axioms

(REngClos), (REngRClos), (REngRBeta), or (REngDealloc) at the top. Because the
context rules do not themselves add material to the term, it is sufficient to
check the lemma for those four axioms. For (REngClos) and (REngRClos), the
size measure is explicitly defined to make the lemma true. For (REngRBeta) or
(REngDealloc), the region substitution does not change the size of its argung
ment, whereas the reductions remove either the * or the new binder. 2

3.4.12 Lemma: Assume evalRD^tE^ C^ bv. Then evalD^ktkE^ C^ bv, too. 2

Proof: We have that t !*! bv. By applying Lemma 3.4.10 to each of the reng
duction steps in turn, we get ktk

BL
-!* kbvk C^ bv. Since bv has no successor,

evalD^ktkE^ C^ bv. 2

3.4.13 Lemma: Assume evalRD^t0E^ C^ ?. Then evalD^kt0kE^ C^ ?, too. 2

Proof: The assumption gives us an infinite series of reductions t0

RAL-! t

1

RAL-!

* * *

RAL-! ti : : : . By Lemma 3.4.10, we get for each i >= 0 that either ktik C^ kti+

1k

114 3 Effect Types and RegionngBased Memory Management

or ktik

BL-! kti+

1k. Lemma 3.4.11 guarantees that there does not exist an N

such that ktik 6

BL-! kti+

1k for all i > N. Therefore, by choosing certain i's,

we get an infinite series of BL reductions kt0k

BL-! flflti

1flfl

BL-! * * * BL-! flflflti

j flflfl : : : .

Hence evalD^kt0kE^ C^ ?. 2

Proof: [of Theorem 3.4.8] Assume that evalRD^tE^ T^ wrong. Then evalRD^tE^ is eing
ther bv or ?, and one of the last two lemmas gives us evalD^ktkE^ C^ evalRD^tE^. 2

3.5 The Tofte-Talpin Type System

One of the features that differentiates Tofte and Talpin's region language
from other regionngbased systems (such as Hanson [1990], Ross [1967], and
Schwartz [1975]) is the presence of a type system. The type system is sound
(page 117) and thus wellngtyped programs do not go wrong at runtime. In the
present setting, this means that if the term t is wellngtyped then evalRD^tE^ T^
wrong. In particular, wellngtyped programs are memory safe. In contrast to
this, in the other systems mentioned above, the programmer has to establish
memory safety manually, and this is essentially just as hard as establishing
memory safety of Cnglike malloc/free programs.

In Figure 3ng8, we define a region type system for RAL, called RTL for "Regionng
Typed Language." The judgment \Gamma  ` t :' T reads: in type environment \Gamma  the
term t has type T and effect '. The effect captures the regions that have to
be live (that is, allocated) for the term to evaluate without memory problems.
In types, 8X:T binds the type variable X in T, \Pi ae:'T binds the region variable
ae in T and ', and 8ffl:T binds the effect variable ffl in T. We denote the sets of
free type variables, free region variables, and free effect variables of a type T
by ftvD^TE^, frvD^TE^, and fevD^TE^, respectively. These are extended to typing conng
texts in the obvious manner. We write E,X , TG*, E,ae , pG*, and E,ffl , 'G* for the
capturengavoiding substitutions of type T for the type variable X, place p for
the region variable ae, and effect ' for the effect variable ffl, respectively.

The typing rules in Figure 3ng8 are natural extensions of the typing rules for
the effect typed language in Figure 3ng5 (page 103). The regionngannotated lanng
guage, is however, both type polymorphic and effect polymorphic. The type
system includes standard rules for introducing and eliminating type polyng
morphism and the obvious variations for effect polymorphism. Compared to
System F (TAPL, Chapter 23) we do not have explicit syntax for these introng
ductions and eliminations. As already mentioned, the language also contains
region polymorphism. Region polymorphism is explicit in the syntax because
it has operational significance.

Effect polymorphism is the natural complement to type polymorphism and
higherngorder functions. Consider a higherngorder polymorphic function such

3.5 The Tofte-Talpin Type System 115
Type expressions

p 2 Place places

ffl 2 EffVar effect variables
' 2 PfinD^Place [ EffVarE^ effects
T ::= type expressions:

X type variable
bool Boolean type
D^T ! 'T; pE^ function type
D^\Pi ae:'T; pE^ region function
8X:T type polymorphism
8ffl:T effect polymorphism

Typing rules \Gamma  ` t :' T

\Gamma  D^xE^ C^ T
\Gamma  ` x :' T (RTngVar)
\Gamma  ` bv :' bool (RTngBool)

\Gamma  ` t1 :' bool
\Gamma  ` t2 :' T \Gamma  ` t3 :' T

\Gamma  ` if t1 then t2 else t3 :' T (RTngIf)

\Gamma  ; x : T1 ` t :'2 T2 p 2 '
\Gamma  ` D^*x:tE^ at p :' D^T1 ! '2T2; pE^ (RTngAbs)

\Gamma  ; x : T1 ` t :'2 T2
\Gamma  ` h*x:tip :' D^T1 ! '2T2; pE^ (RTngClos)

\Gamma  ` t0 :' D^T1 ! '2T2; pE^
\Gamma  ` t1 :' T1 p 2 ' '2 ` '

\Gamma  ` t0 t1 :' T2 (RTngApp)
\Gamma  ; x : T ` u :' T
\Gamma  ` fix x:u :' T (RTngFix)
\Gamma  ` u :'

0 T ae 62 frvD^\Gamma  E^ p 2 '

\Gamma  ` D^*ae:uE^ at p :' D^\Pi ae:'

0T; pE^ (RTngRAbs)

\Gamma  ` u :'

0 T ae 62 frvD^\Gamma  E^

\Gamma  ` h*ae:uip :' D^\Pi ae:'

0T; pE^ (RTngRClos)

\Gamma  ` t :' D^\Pi ae:'

0T; pE^

p 2 ' E,ae , p0G*'0 ` '

\Gamma  ` t E,E,p0G*G* :' E,ae , p0G*T (RTngRApp)
\Gamma  ` t :';ae T ae 62 frvD^\Gamma  ; TE^

\Gamma  ` new ae:t :' T (RTngNew)
\Gamma  ` t :' T X 62 ftvD^\Gamma  E^

\Gamma  ` t :' 8X:T (RTngTGen)
\Gamma  ` t :' 8X:T
\Gamma  ` t :' E,X , T0G*T (RTngTInst)
\Gamma  ` t :' T ffl 62 fevD^\Gamma  ; 'E^

\Gamma  ` t :' 8ffl:T (RTngEGen)
\Gamma  ` t :' 8ffl:T
\Gamma  ` t :' E,ffl , '0G*T (RTngEInst)

Figure 3ng8: The RTL region type system

as list map: it takes a function and a list as arguments and applies the funcng
tion to each element in the list. In the regionngfree base language, map has type
8ff; fi:D^ff ! fiE^ * ff list ! fi list. What is the effect of applying the equivang
lent of map in the regionngannotated language to such arguments? It certainly
has to include the effect, ' say, of applying the argument function, and thus
the type of the regionngannotated map function would have to reflect that in
the latent effect of the complete function:

8ff; fi:D^ff ! 'fiE^ * D^ff list; aeE^ ! {ae;ae

0}['D^fi list; ae0E^

(see page 121 for the typing rules concerning lists). However, that would only
allow us to apply map to functions with latent effect '. We could of course inng

116 3 Effect Types and RegionngBased Memory Management

spect the complete program and make sure that all effects were large enough
that this is not a problem, but this approach would unnecessarily keep many
regions alive. Instead, we can employ effect polymorphism to propagate the
effect of the functional argument to the effect of the complete evaluation of
map as in 8ff; fi:8ffl:D^ff ! fflfiE^ * D^ff list; aeE^ ! {ae;ae

0}[fflD^fi list; ae0E^.

The RTL type system is based on the type system of the TT calculus in Tofte
and Talpin (1997).4 Compared to TT, RTL has moved effect enlargement upng
wards in the derivation tree so that the axioms are responsible for introducng
ing proper effects. This simplifies both the presentation of the rules and the
soundness proof slightly, and it is possible to establish a metangproperty of
the type system that allows effects to be enlarged. Moreover, the RTL system,
with its SystemngFnglike polymorphism in types, regions, and effects, is more
permissive than the TT system with its letngpolymorphism. The restrictions
present in the original system were there to simplify the region inference
algorithm.

The typing rules of RTL can be applied in sequence to obtain a typing of
the letrec construction in the TT system. Recall, that a TT letrec

letrec f[ae1; : : : ; aek](x) at ae C^ t1 in t2
is expressed in RAL as

let f C^ fix f:D^*ae1; : : : ; aek; ae0:D^*x:t1E^ at ae0E^ at ae in t2
The combined construction can be typed by a stack of RTL rules:

\Gamma  ; f , T12; x , T ` t1 :'1 T1 D^

RTngAbsE^
\Gamma  ; f , T12 ` t14 :ae

0 T

14 D^RTngRAbsE^

\Gamma  ; f , T12 ` t13 :' T13 D^

RTngEGenE^.

..

D^RTngEGenE^
\Gamma  ; f , T12 ` t13 :' T12 D^

RTngFixE^
\Gamma  ` t11 :' T12 D^

RTngTGenE^.

..

D^RTngTGenE^
\Gamma  ` t11 :' T11 \Gamma  ; f , T11 ` t2 :' T2 D^

RTngLetE^
\Gamma  ` letrec f[ae1; : : : ; aek](x) at ae C^ t1 in t2 :' T2

4. The type system in that paper is not defined explicitly. The paper presents a typed translang
tion from a language resembling our Base Language BL to the TT calculus. From this translation
one can extract a type system for TT.

3.5 The Tofte-Talpin Type System 117
where

t14 C^ D^*x:t1E^ at ae0 T14 C^ D^T ! '1T1; ae0E^
t13 C^ D^*ae1; : : : ; aek; ae0:t14E^ at ae T13 C^ D^\Pi ae1; : : : ; aek; ae0:ae

0T

14; aeE^

T12 C^ 8ffl1:: : : 8ffln:T13

t11 C^ fix f:t13 T11 C^ 8X1:: : : 8Xm:T12:

As usual with letngpolymorphism, each time f is mentioned in t2, its type
scheme must immediately be fully instantiated. This principle is extended
to the effect and region abstractions; these must also be fully instantiated
(applied, in the case of region abstraction) each time f is mentioned in t2 or
in t1. Thus, the original TT type system does not allow expressions in general
to have type D^\Pi ae:'T; pE^; in particular, region abstractions cannot be passed
as parameters to, or returned from, functions.

Syntactic Type Soundness
We will now prove that typable programs are memory safe. We do so by esng
tablishing type soundness--that is, that wellngtyped programs do not go wrong.
The type soundness proof is structured as a standard sequence of substitung
tion, subject reduction, and progress lemmas. This approach was pioneered
by Helsen and Thiemann (2000) in the context of regionngbased languages,
and apparently independently discovered by Calcagno (2001) for a bigngstep
semantics. Tofte and Talpin (1997) also proved type soundness, albeit not ding
rectly but as a consequence of their correctness theorem of region inference
and using a complex conginductive proof technique.

As usual, we start by showing that one can massage derivations so that the
typing context only mentions the free variables of the term and so that the
derivation does not end with one of the instantiation rules.

3.5.1 Lemma: If \Gamma  ` t :' T, domD^\Gamma  0E^ C^ fvD^tE^, and \Gamma  and \Gamma  0 agree when both are

defined, then \Gamma  0 ` t :' T. 2

Proof: Straightforward induction on the typing derivation. 2
3.5.2 Lemma: Let S be a substitution of the form E,ae , pG*, E,ffl , 'G*, or E,X , TG*. If

\Gamma  ` t :' T can be derived in n steps, then likewise can S\Gamma  ` St :S' ST. 2

Proof: Left as an exercise (n'). 2
3.5.3 Lemma: Assume that \Gamma  ` v :' T has a derivation in n steps. Then it has a

derivation in at most n steps where the last rule used is neither (RTngTInst)
nor (RTngEInst). 2

118 3 Effect Types and RegionngBased Memory Management

Proof: By induction on n. All but the cases for (RTngTInst) and (RTngEInst) eing
ther are direct or are simple applications of the induction hypothesis. Thus,
assume that the derivation ends with (RTngEInst) (the case for (RTngTInst) is
similar). Apply the induction hypothesis to the derivation of its premise; this
gives a derivation that concludes in a type with the shape 8ffl:T0 yet does
not end with (RTngEInst) or (RTngTInst). It cannot end with (RTngVar), (RTngIf),
(RTngApp), (RTngFix), (RTngRApp), or (RTngNew) either, because variables, conding
tionals, applications, fixedngpoints, region applications, and region creations
are not values. The only other rule that can conclude 8ffl:T0 is (RTngEGen), so
the whole derivation now must end with

\Gamma  ` v :' T0 ffl 62 fevD^\Gamma  ; 'E^ D^

RTngEGenE^
\Gamma  ` v :' 8ffl:T0 D^

RTngEInstE^
\Gamma  ` v :' T

where T C^ E,ffl , '0G*T0 for some '0.

Lemma 3.5.2 now gives a derivation of E,ffl , '0G*\Gamma  ` v :E,ffl,'

0G*' E,ffl , '0G*T0 in

n - 2 steps. But since ffl 62 fevD^\Gamma  ; 'E^, this conclusion is the same as \Gamma  ` v :' T,
so we can use that instead of the original derivation. Now apply the induction
hypothesis to this new derivation. 2

3.5.4 Lemma [Canonical Forms]:

1. if v is a value of type bool, then v is of the form bv;
2. if v is a value of type D^T1 ! 'T2; pE^ then v is of the form h*x:tip;
3. if v is a value of type D^\Pi ae:'T; pE^ then v is of the form h*ae:uip. 2
Proof: Left as an exercise (n', 3). 2

We next prove some lemmas about effects. First, one can always enlarge the
effect attributed to a term and obtain a derivable typing. Second, if a value can
be typed, then it can also be typed with an empty effect; that is, evaluation of
values does not cause any observable effects.

3.5.5 Lemma: If \Gamma  ` t :' T and ' ` '0, then \Gamma  ` t :'

0 T.

2

Proof: Straightforward induction on the typing derivation. 2
3.5.6 Lemma: Let v be a value. If \Gamma  ` v :' T then \Gamma  ` v :; T. 2

Proof: From Lemma 3.5.3 we get a derivation of \Gamma  ` v :' T that ends with
neither (RTngTInst) nor (RTngEInst). Therefore, the derivation must end with
one of the typing rules for values. By inspecting each of the rules (RTngBool),
(RTngClos), and (RTngRClos) for values we see that we can construct a derivang
tion of \Gamma  ` v :; T (by choosing the effect to be empty in each case). 2

3.5 The Tofte-Talpin Type System 119

Having established these basic lemmas we can now prove the lemmas leadng
ing to the type soundness result.

3.5.7 Lemma [Substitution]: If \Gamma  ; x1 : T1 ` t :' T and \Gamma  ` t1 :; T1, then \Gamma  `

E,x1 , t1G*t :' T. 2

Proof: By induction on the typing derivation for t. The cases are all standard,
except for (RTngVar) where t C^ x1. By (RTngVar) itself, T C^ T1 and since E,x1 ,
t1G*x1 C^ t1, the second assumption combined with Lemma 3.5.5 gives us the
desired derivation. 2

3.5.8 Proposition [Subject Reduction]: If \Gamma  ` t :' T and t

RAL-! t0 then

\Gamma  ` t0 :' T. 2

Proof: By induction over the typing derivation.

The rules (RTngVar), (RTngBool), (RTngClos), and (RTngRClos) cannot occur;
these rules require t to have a shape that makes t

RAL-! t0 impossible.

The cases for the rules (RTngAbs) and (RTngRAbs) are immediate; the evaluang
tion step must be by rule (REngClos) or (REngRClos), and we can immediately
construct typings for the reduct using (RTngClos) or (RTngRClos).

For the rule (RTngIf), use case analysis on the last step in the derivation of
t

RAL-! t0. The only possibilities are (REngIf), (REngIfTrue), and (REngIfFalse). In the

two latter cases, t0 is one of the branches of the conditional, and the soughtng
for conclusion is already one of the premises of (RTngIf). In the case of (REngIf),
use the induction hypothesis on the typing of the condition; by reusing the
existing typing derivations for the branches, we can produce a typing for t0
using (RTngIf) again.

For the rule (RTngApp), again use case analysis on the derivation of t

RAL-!

t0. The possible rules are now (REngApp1), (REngApp2), and (REngBeta). The two
former are analogous to (REngIf) above, so consider (REngBeta). The term t must
be of the form h*x:tbiae v, and the premises to (RTngApp) are (1) \Gamma  ` h*x:tbiae :'
D^T0 ! '

0T; aeE^ and (2) \Gamma  ` v :' T0, where further ae 2 ' and '0 ` '. Now,

h*x:tbiae is a value and thus by Lemma 3.5.3 there exists a derivation of (1)
ending with (RTngClos) which must include a (subng)derivation of (3) \Gamma  ; x : T0 `
tb :'

0 T. Applying first Lemma 3.5.6 to (2) yields \Gamma  ` v :; T0 and then applying

Lemma 3.5.7 to (3) above and this, we get a derivation of \Gamma  ` E,x , vG*tb :'

0 T

as required because '0 ` ' and we can enlarge the effect (Lemma 3.5.5).

For the rule (RTngFix), the reduction must be by (REngFix) or (REngFixBeta).
Again, the case for (REngFix) is analogous to (REngIf), so assume (REngFixBeta).
The term t must be of the form fix x:v and the typing derivation has a subng
derivation of (1) \Gamma  ; x : T ` v :' T. First, apply Lemma 3.5.6 to get \Gamma  ; x : T ` v :;
T and use this and (RTngFix) to construct a derivation of (2) \Gamma  ` fix x:v :; T.
Now, Lemma 3.5.7 applied to (1) and (2) yields \Gamma  ` E,x , fix x:vG*v :' T.

120 3 Effect Types and RegionngBased Memory Management

For the rule (RTngRApp), the reduction must be by (REngRApp) (similar to
the other context rules above) or (REngRBeta). The term t must be of the
form h*ae1:uiae E,E,pG*G*, and the typing derivation has a subngderivation of (1)
\Gamma  ` h*ae1:uiae :' D^\Pi ae1:'

0T0; aeE^ where further ae 2 ', E,ae

1 , pG*'0 ` ', and T C^

E,ae1 , pG*T0. Now, h*ae1:uiae is a value and thus by Lemma 3.5.3 there exists a

derivation of (1) ending with (RTngRClos) which must include a subngderivation
of (2) \Gamma  ` u :'

0 T0 where ae

1 62 frvD^\Gamma  E^. Applying Lemma 3.5.2 to (2) and

E,ae1 , pG*, we get a derivation of E,ae1 , pG*\Gamma  ` E,ae1 , pG*u :E,ae1,pG*'

0 E,ae

1 , pG*T0 as

required because E,ae1 , pG*\Gamma  C^ \Gamma  (since ae1 62 frvD^\Gamma  E^), E,ae1 , pG*'0 ` ' which we

can enlarge (Lemma 3.5.5), and T C^ E,ae1 , pG*T0.

For the rule (RTngNew), t reduces by (REngNew) or (REngDealloc). Only the
latter case is interesting. The term t must be of the form new ae:v and the
typing derivation must include a derivation of \Gamma  ` v :';ae T where ae 62 frvD^\Gamma  ; TE^.
Then, by Lemma 3.5.6 we have \Gamma  ` v :; T. Applying Lemma 3.5.2 we thus get a
derivation of E,ae , *G*\Gamma  ` E,ae , *G*v :E,ae,*G*; E,ae , *G*T, that is \Gamma  ` E,ae , *G*v :; T
(since ae 62 frvD^\Gamma  ; TE^). Now use Lemma 3.5.5 to recover the original effect '.

For the rule (RTngTGen) (the case for rule (RTngEGen) is analogous) we have
a derivation of \Gamma  ` t :' T0 where X 62 ftvD^\Gamma  E^ and T C^ 8X:T0. Apply the inng
duction hypothesis to this to get \Gamma  ` t0 :' T0. Since still X 62 ftvD^\Gamma  E^ we can
use (RTngTGen) to construct a derivation of \Gamma  ` t0 :' T where T C^ 8X:T0 as
required.

For the rule (RTngTInst) (the case for rule (RTngEInst) is analogous) we have
a derivation of \Gamma  ` t :' 8X:T0 where T C^ E,X , T00G*T0 for some T00. Again apply
the induction hypothesis to this and get \Gamma  ` t0 :' 8X:T0 and use (RTngTInst)
to construct a derivation of \Gamma  ` t0 :' T where T C^ E,X , T00G*T0 as required. 2

3.5.9 Proposition [Progress]: If ; ` t :' T and * 62 ', then either t is a value or

there is some t0 such that t

RAL-! t0. 2

Proof: By induction over the typing derivation of ; ` t :' T.

If the last rule in the derivation is (RTngTGen), (RTngEGen), (RTngTInst), or
(RTngEInst), the conclusion follows directly from the induction hypothesis
(since the typing context remains empty and the effect remains the same in
each premise). For example, for (RTngTGen) we have a derivation of ; ` t :' T0
where T C^ 8X:T0. Applying the induction hypothesis to this we get that either
t is a value, or there exists some t0 such that t

RAL-! t0 as required.

The case (RTngVar) is impossible (since \Gamma  is empty by assumption).
The cases for (RTngBool), (RTngClos), and (RTngRClos) are immediate.
For (RTngAbs) and (RTngRAbs), there are immediate reductions by (REngClos)
or (REngRClos), respectively.

For (RTngFix): If u in fix x:u is a value v then (REngFixBeta) applies and we
have a reduction. If u is an abstraction or a region abstraction, then it itself

3.5 The Tofte-Talpin Type System 121
reduces (by either (REngClos) or (REngRClos)), and we obtain a reduction by
(REngFix). This exhausts the possible syntactic forms of a nonngvalue u.

For (RTngApp), t is an application t0 t1, and we we have derivations of ; `
t0 :' D^T1 ! '2T; pE^ and ; ` t1 :' T1 for some p 2 ' and '2 ` '. Apply
the induction hypothesis to each of these. This either gives a reduction for at
least one of them (in which case we can reduce t by (REngApp1) or (REngApp2)),
or shows that t1 and t2 are both values. In this latter case, by Lemma 3.5.4, t0
must have the form \Omega *x0:t00ffp. Now we can apply the (REngBeta) rule to obtain
a reduction, because p 2 ' cannot be * and so must be a region variable.

The cases for (RTngRApp) and (RTngIf) are similar, but simpler.
For (RTngNew), t is new ae:t1, and we have a derivation of ; ` t1 :';ae T.
Since ae is (by definition) not *, the induction hypothesis applies to t1. We get
that either t1 is a value, in which case we get a reduction using (REngDealloc),
or t1 reduces to another term t01, in which case we get a reduction using
(REngNew). 2

3.5.10 Theorem: If ; ` t :; T, then either (1) there is some value v such that

t !* v and ; ` v :; T, or (2) for each t0 such that t !* t0 there is some t00
such that t0 !+ t00. 2

Proof: Straightforward consequence of Propositions 3.5.8 and 3.5.9. 2
3.5.11 Corollary [Type soundness]: If ; ` t :; bool, then it is not the case that

evalRD^tE^ C^ wrong. 2

Extensions
The regionngannotated language that we have presented only has Booleans
and functions, but it is straightforward to add most other common types of
data to it. As an example, in Figure 3ng9 we give the necessary rules for exng
tending the system with lists. The proofs of the metaproperties (in particular
type soundness and conditional correctness) carry through to this extended
system without any changes to the existing cases.

Rule (RTngCons) implies that when adding a new element in front of a list,
it must have the same type as the elements already there. That is hardly
surprising, but note that it implies that the region part of the type must also
be the same. Thus, the different elements of a list are always allocated in the
same region and therefore will be deallocated at the same time. If a single
element of the list turns out to have a long lifetime, the region type system
propagates that long lifetime to all the other elements!

3.5.12 Exercise [Recommended, n'n', 3]: Using Figure 3ng9 as a guideline, write rules

to extend the system with one or more of: Let bindings (a lambda abstraction

122 3 Effect Types and RegionngBased Memory Management

New syntactic forms

t ::= . . . terms:

D^t :: tE^ at p list constructor
case t0 of nil)t1D^x::x0E^)t2 case on lists

v ::= . . . values:

hv :: vip cons cell
nil empty list
T ::= . . . types:

D^T list; pE^ type of lists

New erasure rules

knilk C^ nil

kD^t1 :: t2E^ at pk C^ kt1k :: kt2kflflfl

ht1 :: t2ipflflfl C^ kt1k :: kt2kflflfl
case t0 of nil)t1D^x::x0E^)t2 flflfl C^

case kt0k of nil)kt1kD^x::x0E^)kt2k

New evaluation rules t

RAL-! t0

t1

RAL-! t0

1

D^t1 :: t2E^ at p

RAL-! D^t0

1 :: t2E^ at p

(EngCons1)

t2

RAL-! t0

2

D^v1 :: t2E^ at p

RAL-! D^v

1 :: t02E^ at p

(EngCons2)

D^v1 :: v2E^ at ae

RAL-! hv

1 :: v2iae (EngConsAlloc)

t0

RAL-! t0

0

case t0 of nil ) t1 | D^x :: x0E^ ) t2
-! case t00 of nil ) t1 | D^x :: x0E^ ) t2

(EngCase)

case nil of nil ) t1 | D^x :: x0E^ ) t2

RAL-! t

1

(EngCaseNil)

case hv :: v0iae of nil ) t1 | D^x :: x0E^ ) t2

-! E,x0 , v0G*E,x , vG*t2

(EngCaseCons)

New typing rules \Gamma  ` t :' T

\Gamma  ` nil :' D^T list; pE^ (RTngNil)

\Gamma  ` t1 :' T
\Gamma  ` t2 :' D^T list; pE^ p 2 '

\Gamma  ` D^t1 :: t2E^ at p :' D^T list; pE^ (RTngCons)
\Gamma  ` v1 :' T \Gamma  ` v2 :' D^T list; pE^

\Gamma  ` hv1 :: v2ip :' D^T list; pE^

(RTngConsCell)
\Gamma  ` t0 :' T0 T0 C^ D^T list; pE^ p 2 '

\Gamma  ` t1 :' T00 \Gamma  ; x : T; x0 : T0 ` t2 :' T00

\Gamma  ` case t0 of nil)t1D^x::x0E^)t2 :' T00

(RTngCase)

Figure 3ng9: Extending the system with a list type

allocates a closure on the heap, so a let binding cannot simply be simulated as
a fingredex); pairs and records; sums and variants; and general recursive types
(equing or isong). Verify that the Conditional Correctness and Type Soundness
theorems still hold for your rules. 2

3.5.13 Exercise [n'n'n'n']: References can be added easily to the type system with

rules like

\Gamma  ` t :' T p 2 '

\Gamma  ` ref t at p :' D^T ref; pE^ (RTngRef)

\Gamma  ` t :' D^T ref; pE^ p 2 '

\Gamma  ` !t :' T (RTngDeref)

3.6 Region Inference 123

\Gamma  ` t :' D^T ref; pE^ \Gamma  ` t0 :' T p 2 '

\Gamma  ` t:=t0 :' unit (RTngAssign)
Of course, these rules need to be combined with the usual value restriction
on type and effect polymorphism, as discussed on pages 335-336 in TAPL.
Which extensions to the semantics and soundness proofs are necessary for
proving these rules sound? 2

The typing rules presented in the above exercise correspond exactly to the
way updatable references are handled in the ML Kit. Observe that since the
(RTngAssign) rule demands equality between the type of the value stored in
the reference and the type of the new value, the rule forces the two values to
have the same lifetime. For longnglived references, such as those found with
container classes in objectngoriented programs, this behavior is inadequate.
No better solution has, however, been proposed yet.

3.6 Region Inference

So far, we have said a lot about the region type system and how regionng
annotated programs are supposed to be executed, but next to nothing about
where the region annotations come from.

One easy answer would be, "why, the programmer wrote them"--but alas,
this answer would not be easy for the programmer. Realistic programs usually
need quite a lot of region abstractions and applications in order to distribute
their data over several regions while still being region typable, and it is not
always obvious exactly where they should be put. While it just might be possing
ble to write a nontrivial wellngtyped program in the regionngannotated language,
it would be quite impossible to maintain it.

Thus, the idea of using a region type system to check the safety of reng
gion annotations goes hand in hand with the idea that the region annotations
themselves are the product of an automatic compilengtime analysis. The hung
man programmer writes a program t in BL, whereupon the compiler will conng
struct a regionngannotated program t0 such that kt0k C^ t and t0 is wellngtyped
in RTL. This process is known as region inference, because Tofte and Talpin
(1994) viewed it as akin to a type reconstruction ("inference") problem.

3.6.1 Exercise [Recommended, n']: One can easily formulate a trivial region inferng

ence: Just choose a single fixed ae, annotate each lambda abstraction (and
other allocating expressions) in the input program with "at ae," and then
wrap the entire program in a single new construction. This evidently always
produces a regionngannotated program that erases to the input program, but
will it always be RTLngtypable? 2

124 3 Effect Types and RegionngBased Memory Management

Of course, the trivial region inference is worthless from a memoryngmanang
gement point of view. It produces a regionngannotated program that never
deallocates anything until the entire computation is finished. What we want
is the opposite: region annotations that deallocate data as soon as allowed
by the region type system. Unfortunately it is not known whether "best posng
sible region annotations" in this sense always exist, but good approximate
solutions are available.

The articles by Tofte and Talpin (1994, 1997) do not themselves present
an algorithm for region inference, but the nondeterministic region inference
system they present has evidently been constructed with an inference algong
rithm in mind. The inference algorithm was published by Tofte and Birkedal
(1998). We do not have the space to describe it in detail, but instead show
how it works in the context of an example. Consider the term

letrec m(f) = if f(0) then 0 else m(*x:f(x+1)) + 1
in m(*x:x=10)

Let us initially assume an that oracle has told us that the "correct" regionng
polymorphic type scheme for m is

8ffl1; ffl2:\Pi ae1; ae2:{ae2}D^D^int ! {ffl1}bool; ae1E^ ! {ffl2;ffl1;ae1}int; ae2E^:
The driving force in the region inference algorithm is an attempt to construct
the RTL typing tree for the regionngannotated program. The search proceeds
much like the familiar Algorithm W , unifying types as well as region variables
and effect positions as we go. We don't know yet what to do with typingngrule
premises of the form ae 2 ' or ' ` '0, so let us initially just collect them for
further processing.

By the time we have analyzed the subexpression m(*x:f(x+1)), the uning
ficationngbased inference has built the typing tree shown in Figure 3ng10. (For
bevity, we assume a primitive rule for adding one to an integer--it allows
concluding \Gamma  ` t+1 :' int from \Gamma  ` t :' int).

A set of collected effect constraints are also shown on the figure. Luckily,
the effect polymorphism in the oracle's type scheme has a form that allows
the possible instantiations of the effect fields in it to be descibed with subset
and inclusion constraints; in this case '4 ` '5 and ae4 2 '5.

3.6.2 Exercise [n', 3]: Locate where in the proof tree the other collected constraints

come from. 2

Whenever we choose concrete substitutions for the symbols ', '3, '4,
and '5 that satisfy the constraints, we get a valid proof. What it is proof of
depends on the substitutions we choose for ' and '3, because these effect

3.6 Region Inference 125

...
\Gamma  ` m E,E,ae4; ae5G*G* :' D^D^int ! '4bool; ae4E^ ! '5int; ae5E^

\Gamma  0 ` f :'1 D^int ! '3bool; ae3E^

\Gamma  0 ` x :'4 int
\Gamma  0 ` x+1 :'4 int
\Gamma  0 ` f(x+1) :'4 bool
\Gamma  ` D^*x:f(x+1)E^ at ae4 :' D^int ! '4bool; ae4E^
\Gamma  ` m E,E,ae4; ae5G*G*(D^*x:f(x+1)E^ at ae4) :' int

where \Gamma  is m : 8ffl1; ffl2:\Pi ae1; ae2:{ae2}D^D^int ! {ffl1}bool; ae1E^ ! {ffl2;ffl1;ae1}int; ae2E^; f : D^int ! '3bool; ae3E^ and
\Gamma  0 is \Gamma  ; x : int. Collected effect constraints: '4 ` '5, ae4 2 '5, {ae5} ` ', '3 ` '4, ae3 2 '4, ae4 2 ',
'5 ` ', ae5 2 '.

Figure 3ng10: A partially regionnginferred proof tree

metangvariables occur in the conclusion. On the other hand, '4 and '5 do not
occur in the conclusion, so we can eliminate them from the constraint set and
simplify it to {ae4 2 '; ae5 2 '; ae3 2 '; '3 ` '}. Much of (Tofte and Birkedal,
1998) is concerned with giving precise rules for such manipulations.

Observe now that the constaints imply that ae4 and ae5 must appear in the
effect position of the concluding statement, but there is no reason for any
of them to appear in either the type or the environment. Therefore, we are
allowed to insert a new around the expression, and thus deallocate the closure
for m E,E,ae4; ae5G*G* as well as the one for *x:f(x+1) after the call returns. By doing
so, we make ae4 and ae5 invisible from outside the expression, so constraints
that mention them can be dropped from the constraint set. On the other
hand, ae3 cannot be finished off in this way yet, because it occurs (explicitly)
in the environment \Gamma  .

The final result of the analysis of the expression is thus the judgment

\Gamma  ` new ae4; ae5:\Gamma m E,E,ae4; ae5G*G*(D^*x:f(x+1)E^ at ae4)\Delta  :' int
plus the (simplified) constraint set {ae3 2 '; '3 ` '}.
3.6.3 Exercise [n'n']: Why didn't the region inference insert a new ae5:* * * around

the subexpression D^*x:f(x+1)E^ at ae4? 2

The analysis of the rest of the body of m is unsurprising; it ends with
m : * * * ; f : D^int ! '3bool; ae3E^ ` if f(0) then 0 else D^* * * E^+1 :' int

126 3 Effect Types and RegionngBased Memory Management

and still with the same constraint set {ae3 2 '; '3 ` '} (another copy of each
of these constraints was produced by the analysis of f(0)).

This gives the immediate type D^D^int ! '3bool; ae3E^ ! 'int; ae0E^ for m, where
ae0 was added by the letrec construction itself. Since neither ae3 nor ae0 apng
pears in the (empty) environment for letrec, we can abstract over them and
make them region parameters. Finally we can abstract over effects by introng
ducing an effect variable for each effect metangvariable in the simplified conng
straint set that is not connected to the environment by subset constraints.
In the effectngpolymorphic type, each ' position becomes the set of effect
and region variables that must be in the effect, according to the constraints.5
Thus the effect abstraction simply encapsulates the (transitive closure of the)
simplified constraint set.

It turns out our oracle was right! The abstracted type of m is exactly what
it said it would be, with ffl1 corresponding to '3, ffl2 to ', ae1 to ae3, and ae2 to
ae0. Now the analysis of the body of the letrec is unsurprising; we get the
following regionngannotated program:

letrec m[ae1](f) =

if f(0) then 0
else new ae4; ae5:\Gamma m E,E,ae4G*G* at ae5(D^*x:f(x+1)E^ at ae4)\Delta  + 1
in new ae6; ae7:\Gamma m E,E,ae6G*G* at ae7(D^*x:x=10E^ at ae6)\Delta 

Where did the oracle get its prediction of m's type from? Tofte and Birkedal
(1998) construct it by Mycroft iteration: First, m's body is analyzed under the
optimistic assumption that m itself will have the type scheme

8ffl1; ffl2:\Pi ae1; ae2:{ae2}D^D^int ! {ffl1}bool; ae1E^ ! {ffl2}int; ae2E^
that is, with no constraints at all between the various region and effect parts
of polymorphic instances. If the type scheme constructed after the initial
iteration does not match (which in this case it doesn't), a new iteration is
tried with the new type scheme as assumption, and so forth until a fixpoint
is reached.

The trick, of course, lies in ensuring that a fixpoint is eventually reached; it
might well be that it just produces a list of ever larger type schemes. The
original region inference algorithm (Tofte and Birkedal, 1998) solved this
problem by heuristically omitting certain opportunities for region and effect

5. The way this is done in the published formulation of the algorithm includes considering
one effect variable in each latent effect to be special; it is called the handle and is the one that
corresponds to the entire effect. The distinction between the handle and other effect variables
is present in the original TT calculus even though it has no special role in the soundness and
correctness proofs.

3.7 More Powerful Models for RegionngBased Memory Management 127
abstractions such that the iterative computation of a fixpoint for the recursive
function's type scheme could be guaranteed to terminate. The cost of this apng
proach is that completeness fails: Example programs can be constructed for
which the region inference algorithm leads to region annotations that are not
the best possible.

Later Birkedal and Tofte (2001) rephrased the algorithm in terms of conng
straint solving. This reworked algorithm seems to be complete in the sense
that for any regionngannotated term t that can be TTngtyped, the inference algong
rithm's output on ktk will have as least as good space behavior as t. However,
Birkedal and Tofte prove only a weaker "restricted completeness" result; full
completeness in the sense described here was not considered in the article.

Another restricted case with an easy region inference problem is known. It
is when the input program can be typed with first order types, that is, such
that neither the argument nor the return type for any function includes a
function type itself. Then there is no reason to use effect polymorphism, and
one never needs to generalize over region variables that appear only in latent
effects. (For since there is only one arrow in each type, such a variable could
just as well have been discharged by a new within the lambda abstraction.)
These two facts lead to a bounded representation of the latent effect: We
simply need to know for each of the p positions in the argument and return
types whether the actual p is in the latent effect. That solves the termination
problem, and with a bit of ingenuity one does not even need fixpoint iteration
for finding the best type scheme.

This principle has been used to derive a region inference for an adaptation
of the Tofte-Talpin system for a Prolog dialect which is naturally first order;
see Makholm (2000, Chapter 10).

3.6.4 Exercise [n']: Why does effect polymorphism not make sense in a firstngorder

program? 2

3.7 More Powerful Models for RegionngBased Memory Management

Unfortunately, even with regionngpolymorphic recursion, the Tofte-Talpin
model (as expressed either as RTL or the original TT) is not quite strong
enough to achieve reasonable object lifetimes. At fault is the very idea of
new--that the lifetime of a region must coincide with the time it takes to
execute some subexpression of the original program. To see how this is a
problem, let us look at how the ToftengTalpin system treats the classic "Game
of Life" example. The task is to simulate a cellular automaton for n genng
erations, starting from a specified state. This is a typical case of iterative

128 3 Effect Types and RegionngBased Memory Management

programming, and the problems we will discover are common for iterative
programs in general.

The standard way of programming an iteration in a functional language is
to use tail recursion:

let rec nextgen(g) = \Omega read g; create and return new generationff
let rec life(n,g) = if n=0 then g

else life(nng1,nextgen(g))

We shall leave the details of nextgen unspecified here and in the followng
ing discussion. We assume, for simplicity, that a single region holds all the
pieces of a generation description, and, for the sake of the argument, that the
iteration count n needs to be heapngallocated, too.

The ordinary TT region inference algorithm annotates the Game of Life
example as follows:

letrec nextgen[ae](g) = \Omega read g from ae; create new gen. at aeff
letrec life[aen; aeg](n,g) =

if n=0 then g
else new ae0n

in life[ae0n; aeg]((nng1) at ae0n, nextgen[aeg](g))

There are two major problems here. First, the recursive call of life is not a
tail call anymore because it takes some work to deallocate a region at the end
of new. Therefore all the ae0n regions will pile up on the call stack during the itng
eration and be deallocated only when the final result has been found. Second,
any typable region annotation of the program must let the nextgen function
construct its result in the same region that contains its input. This means
that the program has a serious space leak: all the intermediatenggeneration
data will be deallocated only when the result of the iteration is deallocated.

Both of these problems are caused by the fact that new aligns the lifetime
of its region with the hierarchical expression evaluation. Several solutions for
this have been proposed, but because their formal properties have not been
as thoroughly explored as the TT calculus, we will only present them briefly.

Region Resetting in the ML Kit
The ML Kit's region implementation (Birkedal et al., 1996; Tofte et al., 2001b)
is based on the TT system. Its solution to the tail recursion problem is based
on a concept of resetting a region, meaning that its entire contents are deng
allocated whereas the region itself continues existing.

After a TT region inference, a special storagengmode analysis (Birkedal, Tofte,
and Vejlstrup, 1996) that runs after region inference amends the region anng

3.7 More Powerful Models for RegionngBased Memory Management 129
notations to control resetting: Each "at ae" annotation gets replaced by either
"atbot ae," meaning first reset the region and then allocate the new object as
the new oldest object in the region, or "attop ae," meaning allocate without
resetting the region.

With this system one can rewrite the original Life program as follows to
obtain better region behavior:

let rec copy(g) = \Omega read g; make fresh copyff
let rec life'((n,g) as p)

= if n=0 then p

else life'(nng1,copy(nextgen(g)))
let rec life(p) = snd (life' (p))

where copy (whose body is omitted here for brevity) takes apart a generang
tion description and constructs a fresh, identical copy. Region inference and
storagengmode analysis will then produce the region annotations

letrec nextgen[ae; ae0](g) = \Omega read g from ae; new gen. at ae0ff
letrec copy[ae0; ae](g) = \Omega read g from ae0; fresh copy atbot aeff
letrec life'[aen; aeg]((n,g) as p)

= if n=0 then p

else life'[aen; aeg]((nng1) atbot aen,

new ae0g
in copy[ae0g; atbot aeg]

(nextgen[aeg; ae0g](g)))
letrec life[aen; aeg](p) = snd (life'[aen; aeg](p))

Letting life0 return the entire p instead of just g forces region inference to
place all of the ns in aen. A memory leak in aen is prevented by the atbot
allocation, whose effect is that the region aen is reset prior to placing nng1 in it.

The memory leak in aeg is prevented with the introduction of the copy funcng
tion. Now the new generation can be constructed in a temporary region ae0g
that gets deallocated before the recursive call; once the old generation is not
needed anymore, the new generation is copied into aeg with the atbot mode,
which frees the old generation. (The atbot annotation in the passing of the
region parameter serves to allow copy to actually reset the region; the need
for this extra annotation has to do with aliasing between region variables.)

The storagengmode analysis works by changing the region annotation for an
allocation to atbot if the value to be allocated is the only live value whose
type includes the region name, as determined by a simple local liveness analng
ysis. Neither a formal definition of the storagengmode analysis nor a proof that
it is safe has appeared in the literature, but it is described briefly by Birkedal,

130 3 Effect Types and RegionngBased Memory Management

Tofte, and Vejlstrup (1996), together with a number of other analyses that
the ML Kit uses to implement the region model efficiently.

This solution does make it possible for iterative computations to run in
constant space (assuming, in the Life example, that the size of a single g is
bounded), but it is by no means obvious that precisely these were the changes
one needed to make to the original unannotated program to improve the
space behavior. Furthermore, inserting such region optimizations in the prong
gram impede maintainability because they obscure the intended algorithm.

Aiken-Fa"hndrich-Levien's Analysis for Early Deallocation
Aiken, Fa"hndrich, and Levien (1995) extend the TT system in another direcng
tion, decoupling dynamic region allocation and deallocation from the introng
duction of region variables with the new construct.

In the AFL system, entry into a new block introduces a region variable, but
does not allocate a region for it. During evaluation of the body of new, a reng
gion variable goes through precisely three states: unallocated, allocated, and
finally deallocated. After a TT region inference (and possibly also storageng
mode analysis as in the ML Kit), a constraintngbased analysis--guided by a
higherngorder datangflow analysis for region variables--is used to insert explicit
region allocation E,E,alloc aeG*G* and deallocation commands E,E,free aeG*G* into the
program. Ideally the E,E,alloc aeG*G* happens right before the first allocation in
the region, and E,E,free aeG*G* just after the last read from the region, but someng
times they need to be pushed farther away from the ideal placements because
the same region annotations on a function body must match all call sites.

With this system, the Life example can be improved by rewriting the origing
nal program to

let rec copy(g) = \Omega read g; make fresh copyff
let rec life(n,g) = if n=0 then copy(g)

else life(nng1,nextgen(g)),

making the base case return a fresh copy of its input rather than the input
itself. This program is analyzed as6

letrec nextgen[ae; ae0](g)

= E,E,alloc ae0G*G* \Omega read g from ae; new gen. at ae0ff E,E,free aeG*G*
letrec copy[ae; ae0](g)

= E,E,alloc ae0G*G* \Omega read g from ae; fresh copy at ae0ff E,E,free aeG*G*

6. The syntax here is not identical with the one used by Aiken, Fa"hndrich, and Levien (1995);
for example, they write "free_after ae t" for what we write as "t E,E,free aeG*G*."

3.7 More Powerful Models for RegionngBased Memory Management 131

letrec life[aen; aeg; ae0](n,g)

= if n=0

then E,E,free aenG*G* copy[aeg; ae0](g)
else new ae0n; ae0g

in life[ae0n; ae0g; ae0]

(E,E,alloc ae0nG*G* (nng1) at ae0n E,E,free aenG*G*,

nextgen[aeg; ae0g](g))

Because deallocation of each region is done explicitly and not by new, the
body of new is a tail call context, and the regions containing the old n and g
can be freed as soon as nng1 and nextgen(g) have been computed. Without
rewriting the original program this would not be the case, because a function
must either always free one of its input regions or never do it.

Imperative Regions: The Henglein-Makholm-Niss Calculus
Recently Henglein, Makholm, and Niss (2001) published a region system that
completely severs the connection between region lifetimes and expression
structures by eliminating the new construct. Instead, the region annotations
form an imperative sublanguage manipulating region handles asynchronously
with respect to the expression structure.

The HMN system does not, as the two previously sketched solutions, build
on top of the Tofte-Talpin model and its region inference algorithm; instead
it has its own region type system (proved sound by Niss, 2002) and inference
algorithm (Makholm, 2003). Starting anew means that the system is concepng
tually simpler while still incorporating the essential features of ML Kitnglike
resetting and AFLngstyle early deallocation as special cases. On the other hand,
the theory has not yet been extended to higherngorder functions.

In the HMN system it is possible to handle the Game of Life with no rewritng
ing at all. A function can pass regions as output (indicated by o: below) as
well as receive them as input (indicated by i:); HMN region inference prong
duces

letrec nextgenE,i: ae; o: ae0G*(g)

= E,E,new ae0G*G* \Omega read g from ae; new gen. at ae0ff E,E,release aeG*G*
letrec lifeE,i: aen; aeg; o: ae0G*(n,g)

= if n=0 then E,E,release aenG*G* g E,E,ae0 := aegG*G*

else lifeE,i: ae0n; ae0g; o: ae0G*

(E,E,new ae0nG*G* (nng1) at ae0n E,E,release aenG*G*,

nextgenE,i: aeg; o: ae0gG*(g))

where each iteration of life decides for itself whether to release the region
it gets as its second parameter or to return it back to the caller.

132 3 Effect Types and RegionngBased Memory Management

The E,E,ae0 := aegG*G* operation serves the same purpose as the copy operation
in the AFL solution, but is very cheap at runtime--it just renames the region
that was previously called aeg to ae0, whereupon it is returned to the caller.

The renaming of regions means that the regionngannotated types of values
can change during the execution of the program. To manage that, the HMN
region type system is based around a typing judgment with the shape

\Psi  ` {\Delta 1; \Gamma 1} t : T {\Delta 2; \Gamma 2}
where the contexts \Gamma 1 and \Gamma 2 describe the types of the local variables before
and after t is evaluated. The sets of region variables \Psi , \Delta 1, and \Delta 2 describe
the available region variables.

Other advanced features of the HMN system include referencengcounted reng
gions with a linear type discipline for region handles, "constant" region pang
rameters that correspond to the region abstraction of the Tofte-Talpin model,
and a subtyping discipline for regions that allows extensive manipulation of
dangling pointers.

Other Models
A number of more powerful region models and associated region type sysng
tems have been proposed without an accompanying inference algorithm.

Walker, Crary, and Morrisett (2000) have developed a region model with a
region typengsystem for a continuationngpassing style language, intended to be
used for translating the Tofte-Talpin execution model to certified machine
code. To handle the CPS transformation of region abstractions, a very adng
vanced type system with bounded quantification over regions and effects was
necessary. The final system is much stronger than the Tofte-Talpin system itng
self, but little is known about how to make automatic region inference utilize
this extra strength.

Walker and Watkins (2001) have developed a region type system in which
region references can be stored in data structures such as lists. They are still
not completely first class, because they must have linear types (see Chapng
ter 1), but the system is strong enough to reason about heterogeneous lists
(i.e., lists whose elements are allocated in different regions).

Another, more restricted, way of allowing heterogeneous structures is found
in the system (Grossman et al., 2002). Cyclone employs a kind of subtyping
on region lifetimes and a simpler notion of effects: A region variable ae outng
lives another region variable ae0 if the lifetime of ae encompasses the lifetime
of ae0. In that event, a value allocated in the region denoted by ae can safely be
used instead of the same value allocated in the region denoted by ae0. Cyclone
supports subtyping of values according to this principle.

3.8 Practical RegionngBased Memory Management Systems 133
3.8 Practical RegionngBased Memory Management Systems

The ML Kit
The ML Kit7 essentially implements the theory described in $3.4 to $3.6 with
two important extensions: first, it includes region resetting and storagengmode
analysis as described in $3.7, and, second, it includes a multiplicity inference
allowing the compiler to allocate finite regions on the runtime stack (Birkedal,
Tofte, and Vejlstrup, 1996). The multiplicity analysis is a typengbased analyng
sis that determines, whether each region is finite or infinite. A finite region
is one into which the analysis can determine that only one value will ever
be written; all other regions are infinite. The importance of finite regions is
that they can be stackngallocated since it is known in advance how large they
are. Furthermore, since regions in the Tofte and Talpin region language folng
low a stackngdiscipline aligned with the expression structure of the program,
such regions can even be allocated on the normal runtime stack, giving a parng
ticularly simple, efficient implementation. The latest incarnation of the ML
Kit even includes a garbage collector (Hallenberg, Elsman, and Tofte, 2002),
which is useful in situations where it is not practical to make a program more
region friendly. See Tofte et al. (2001b) for a comprehensive introduction to
programming with regions in the ML Kit, and Tofte et al. (2001a) for a survey
of the interplay between theory and practice in the ML Kit.

Cyclone
Cyclone,8 a dialect of C designed to prevent safety violations, uses regions
both as a memory management discipline and as a way to guarantee safety
(through type soundness). Cyclone includes three kinds of regions: a single
global (or heap) region; stack regions (corresponding to stack frames allong
cated from statement blocks); and dynamic regions (corresponding to our
lexically scoped regions).

Instead of having effect variables as in the Tofte and Talpin system, Cyclone
uses an operator on types (with no operational significance). The regions_of
operator represents the region variables that occur free in a type; the crung
cial trick is that the regions_of operator applied to a type variable is simng
ply left abstract until the type variable is instantiated. Intuitively, instead of
propagating the effect of functional arguments via effect variables, they are
propagated via the regions_of operator. Returning to the map example on

7. http://www.itngc.dk/research/mlkit
8. http://www.cs.cornell.edu/projects/cyclone/

134 3 Effect Types and RegionngBased Memory Management

page 115 we get the following Cyclone type for map:

8ff; fi:D^ff ! fiE^ * D^ff list; aeE^ ! {ae;ae

0}[regions_ofD^ff!fiE^D^fi list; ae0E^:

For practical reasons, a major aspect in the design of Cyclone was to make
it easy for C programmers to write Cyclone applications and to port legacy
C code to Cyclone. In particular, requiring programmers to write regionng
annotations as seen in the present chapter is out of the question. Cyclone
addresses this by combining inference of region annotations with defaults
that work in many cases.

Cyclone began as a compiler for producing typed assembly language (see
Chapter 4) and as such can be seen as one way to realize proofngcarrying code
(see Chapter 5). The region aspects of Cyclone are described by Grossman
et al. (2002); a system overview is given by Jim et al. (2002).

Other Systems
The ML Kit and Cyclone are both mature systems. Several research protong
types demonstrating various principles for regionngbased memory manageng
ment have been described in the literature.

One trend has been to adapt Tofte and Talpin's system (and its spirit) to
other languages. Christiansen and Velschow (1998) describe RegJava, which
is a simple, regionngannotated core subset of Java and an accompanying imng
plementation. Makholm and Sagonas (2002) extend a Prolog compiler with
regionngbased memory management and region inference based on Henglein,
Makholm, and Niss (2001).

Another trend has been to vary the fundamental assumption that regions
should be allocated and deallocated according to a stackngdiscipline. In this ding
rection the present authors have constructed a prototype implementation of
the system of Henglein et al. (2001) for a small functional language with funcng
tion pointers (but not lexical closures containing free variables). Cyclone can
also be seen as the practical realization of some of the ideas in the Calculus
of Capabilities (Walker, Crary, and Morrisett, 2000).

Finally, regionngbased memory management without the memory safety guarng
antees offered by region types has a long history. The basic idea, of gaining
extra efficiency by bulk allocations and deallocations, is certainly natural. Sysng
tems using regionnglike abstractions for their memory management date as far
back as 1967 (Ross, 1967; Schwartz, 1975; Hanson, 1990). In contrast to these
special purpose region abstractions, the GNU C Library provides an abstracng
tion, called obstacks, to application programmers (GNU, 2001).

Also in this line of work is Gay and Aiken's RC compiler translating reng
gion annotated C programs to ordinary C programs with library support for

3.8 Practical RegionngBased Memory Management Systems 135
regions (2001). At runtime, each region is equipped with a reference count
keeping track of the number of (external) references to objects in the region.
The operation for deleting a region can then flag instances that attempt to
delete a region with nonngzero reference count. A type system provides the
compiler the opportunity to remove some of the reference count operations,
but it does not guarantee memory safety as the type systems discussed in
this chapter do.P a r t I I

Types for LowngLevel Languages
Types for LowngLevel Languages

the next two chapters explore a number of techniques that can be used to
extend highnglevel typing ideas to programs written in lownglevel languages.
This problem is interesting for a number of reasons. It seems natural to asng
sume that lownglevel code obtained by compiling wellngtyped highnglevel prong
grams should have the same semantics and similar typing properties. Yet, it
is not immediately clear how to write a typengchecker for lownglevel programs.

Type checking is a convenient way to ensure that a program has certain
semantic properties, such as memory safety. Type checking has gained acng
ceptance as a major component of the security infrastructure in distributed
systems that share code between hosts that do not trust each other. Nong
table examples are the Java Virtual Machine (JVM) (Lindholm and Yellin, 1997)
and the Microsoft Common Language Infrastructure (CLI) (Gordon and Syme,
2001; Gough, 2002), both of which feature type checkers for intermediate
languages used for the distribution of code in distributed systems. Such disng
tribution schemes rely on lownglevel languages in order to delegate to the unng
trusted code producer most or all of the compilation effort, and to reduce or
eliminate the need for a trusted compiler on the receiving side. This strategy
also has the potential to give the code producer some flexibility in the choice
of the highnglevel language in which the development of the code takes place.

The distribution of untrusted mobile code is the main scenario that we will
use to guide our design choices. We refer to a system that receives and exeng
cutes untrusted code as a host and to the untrusted code itself as an agent.
Hosts want to have strong guarantees about the safety of the agent's exeng
cution. Probably the most basic guarantee is memory safety, which ensures
that the agent does not attempt to dereference memory addresses to which it
has not been given access. But often hosts need to have stronger guarantees,
such as type safety with respect to a certain type system, or bounded execung

140 Types for LowngLevel Languages

tion and resource usage, or proper use of the provided APIs. We shall start
to address the memory safety and type safety aspects first and then show
how the techniques that we develop can be applied to more complex safety
polices.

It is worth pointing out that, in the absence of type checking, alternative
mechanisms for ensuring the memory safety of untrusted code are based on
coarsenggrained memory protection, enforced either by hardware or by softng
ware. Hardware memory protection is used when the untrusted code is run
in a separate address space. A software equivalent is software fault isolang
tion (SFI) (Wahbe et al., 1993), in which the untrusted code is instrumented
with runngtime checks that prevent memory accesses outside a prengconfigured
memory range. In both of these cases, the communication between the unng
trusted code and the host system is expensive because it must involve copyng
ing of data into the untrustedngcode address space.

Most of the challenges in typing lownglevel languages arise because we canng
not abstract details of how highnglevel features are implemented. In JVM and
CLI, these problems are attenuated by keeping in the intermediate language
the most troublesome highnglevel features, such as exceptions and dynamic
dispatch.

In these two chapters, we examine instead an extreme situation, in which
the untrusted code is written in assembly language. Correspondingly, the
type system must be more expressive than would be necessary for similar
programs written in a highnglevel language. In essence, a type checker for a
lownglevel language verifies not only the wellngtypedness of the corresponding
highnglevel constructs but also that the construct has been compiled correctly.
Most of the mechanisms that we'll need can be expressed using types. Indeed,
Chapter 4 describes a type system that is appropriate for assembly language.
Since such a large part of lownglevel type checking is closer to program verificang
tion than type checking, we use in Chapter 5 a method based on logic. Besides
being an instructive alternative presentation of type systems and type checkng
ing, that approach will allow us to move seamlessly beyond type checking
and into checking more complex properties of the untrusted code.

4 Typed Assembly Language

Greg Morrisett

How can we ensure that when we download some code that the code will not
do something "bad" when we execute it? One idea is to leverage the principle
of proofngcarrying code introduced by Necula and Lee. The principle of PCC is
that we can eliminate the need to trust a piece of code by requiring a formal,
machinengcheckable proof that the code has some desired properties. The key
insight is that checking a proof is usually quite easy, and can be done with a
relatively small (and hence trustworthy) proofngchecking engine.

If we are to effectively use PCC to build trustworthy systems, then we must
solve two problems:

1. What properties should we require of the code?
2. How do code producers construct a formal proof that their code has the

desired properties?

The first question is extremely context and application dependent. It requires
that we somehow rule out all "bad" things without unduly restricting "good"
things, and make both "bad" and "good" formal. The second question is imng
possible to solve automatically for arbitrary code assuming nonngtrivial safety
properties. So, how are we to take advantage of PCC?

One approach is based on typengpreserving compilation. The idea here is to
focus on some form of type safety as the desired property. The advantage
of focusing on type safety is that programmers are willing to do the hard
part--construct a proof that some code is typengsafe. The way they do this is
by writing the code in a highnglevel language (e.g., Java or ML). If the source
they write doesn't typengcheck, then they rewrite the code until it does. In this
respect, they are engaging in a form of interactive theorem proving.

Once the initial proof is done, a typengpreserving compiler takes over, mapng
ping the typengsafe source code through a series of successively lowernglevel

142 4 Typed Assembly Language

intermediate languages to target code. As it transforms the code, it also (conng
ceptually) transforms the proof. It is usually much easier to do this sort of
transformation than to prove type safety directly on the generated code.

Of course, such a methodology demands that as part of the compilation
process, we design a series of typed intermediate languages, culminating with
typed machine code. Intermediate languages such as the Java Virtual Machine
Language (JVML) and Microsoft's Common Language Infrastructure (CLI) are
targets of typengpreserving compilers for a number of highnglevel languages,
including Java, C#, and ML.

However, both the JVM and CLI are relatively highnglevel "CISCnglike" abstract
machines. That is, they have prengconceived notions of methods and objects
which may be incompatible with an efficient encoding for a given language.
For instance, the JVM does not support tailngcalls, making the implementation
of functional languages impractical. The CLI does support tailngcalls, but there
are other features that it lacks. For instance, arrays are treated as covariant
in the type system, and thus require a runngtime check upon update.

Of course, there will never be a universal, portable typed intermediate lanng
guage (TIL) that supports all possible languages and implementation strateng
gies. Nonetheless, we seek a principled approach to the design of TILs that
minimizes the need to add new features and typing rules. In particular, we
seek a more "RISCnglike" design for type systems that makes it possible to enng
code highnglevel language features and to support a variety of optimizations.

4.1 TALng0: ControlngFlowngSafety

We begin our design for a "RISC"ngstyle typed assembly language by focusng
ing on one safety property, known as controlngflow safety. Informally, we wish
to ensure that a program does not jump to arbitrary machine addresses
throughout its execution, but only to a wellngdefined subset of possible entry
points. Controlngflow safety is a crucial building block for building dynamic
checks into a system. For instance, before performing a system call, such
as a file read, we might need to check that the arguments to the call have
the right properties (e.g., the file has been opened for reading and the desng
tination buffer is sufficiently large.) Without controlngflow safety, a malicious
client could jump past these checks and directly into the underlying routine.

A focus on controlngflow safety will also let us start with an extremely simple
abstract machine and demonstrate the key ideas of adapting a type system
to machine code. In subsequent sections, we will expand this machine and its
type system to accommodate more features.

The syntax for our controlngflowngsafe assembly language, which we will call
TALng0, is given in Figure 4ng1. We assume a fixed set of k generalngpurpose

4.1 TALng0: ControlngFlowngSafety 143
r ::= registers:

r1 | r2 | * * * | rk
v ::= operands:

n integer literal
` label or pointer
r registers

' ::= instructions:

rd:=v
rd:=rs+v
if r jump v
I ::= instruction sequences:

jump v
'; I

Figure 4ng1: Instructions and operands for TALng0

registers and a few representative instructions based on a subset of MIPS
assembly language. To keep the language readable, we use a somewhat more
familiar notation for instructions than the usual cryptic "mov," "add," etc.
Intuitively, each instruction uses the value in a source register (rs) and an
operand to compute a value which is placed in the destination register (rd).
In this setting, an operand is either another register, a wordngsized immediate
integer,1 or a label. We use "value" to refer to an operand that is not a register.

For our purposes, it is also useful to define instruction sequences (I) as lists
of instructions terminated by an explicit, unconditional control transfer (i.e., a
jump). Of course, when the assembly code is mapped down to machine code,
jumps to adjacent blocks can be eliminated since the code will fall through.
We could make the order of instruction sequences and hence fallngthroughs
explicit, but we prefer a simpler, more uniform assembly language to present
the key ideas.

Here is an example TALng0 code fragment that computes the product of
registers r1 and r2, placing the final result in r3 before jumping to a return
address assumed to be in r4.

prod: r3 := 0; // res := 0

jump loop

loop: if r1 jump done; // if a = 0 goto done

r3 := r2 + r3; // res := res + b
r1 := r1 + ng1; // a := a ng 1
jump loop

done: jump r4 // return
1. As we are dealing with an assembly language, we ignore the issue of fitting a full wordngsized
integer into a single instruction.

144 4 Typed Assembly Language

R ::= register files:

{r1 C^ v1; : : : ; rk C^ vk}
h ::= heap values:

I code

H ::= heaps:

{`1 C^ h1; : : : ; `m C^ hm}
M ::= machine states:

D^H; R; IE^

Figure 4ng2: TALng0 abstract machine syntax

We model evaluation of TALng0 assembly programs using a rewriting relang
tion between abstract machine states. Rather than model the execution of
a concrete machine, we use a highernglevel representation for machine states
which maintains certain distinctions. For instance, in a real machine, labels
are resolved during program loading to some machine address which is also
represented as an integer. In our abstract machine, we maintain the distincng
tion between labels and arbitrary integers because this will allow us to easily
state and then prove our desired safety property--that any control flow inng
struction can only branch to a valid, labelled entry point. Indeed, our abstract
machine will get stuck if we try to transfer control to an integer as opposed
to a label. So, the problem of enforcing the safety property now reduces to
ensuring that our abstract machine cannot get stuck.

However, to support this level of abstraction, we must worry about the
situation where a label is added to an integer, or where a test is done on a
label. One possibility is to assume a coercion function intof which maps lang
bels to integers, and use intofD^`E^ whenever ` appears as an operand to an
arithmetic instruction. Though a perfectly reasonable approach, there are a
number of reasons one might avoid it: First, it violates the abstraction that
we are attempting to provide which may lead to subtle information flows.
In some security contexts, this could be undesirable. Second, such a coerng
cion would make it harder to prove the equivalence of two program states,
where labels are ffngconverted. In turn, this would restrict an implementation's
freedom to rengarrange code or recycle its memory.2 Finally, it simplifies the
type system if we simply treat labels as abstract. In particular, if we included
such a coercion, we would need some form of subtyping to validate the coerng
cion. However, we emphasize that it is possible to expose labels as machine
integers if desired.

The syntax for TALng0 abstract machines is given in Figure 4ng2. An abstract
machine state M contains three components: (1) A heap H which is a finite,

2. The problem can be avoided by assuming a coercion relation between labels and integers
that respects the alphangequivalence class of labels.

4.1 TALng0: ControlngFlowngSafety 145
partial map from labels to heap values (h), (2) a register file R which is a total
map from registers to values, and (3) a current instruction sequence I. The
instruction sequence is meant to model the sequence of instructions pointed
to by the program counter in a concrete machine. One way to think of the
machine's operation is that it prengfetches sequences of instructions up to the
nearest jump whenever a controlngtransfer is made.

We consider heaps and register files to be equivalent up to rengordering. We
also consider the labels in the domain of H to bind the free occurrences of
those labels in the rest of the abstract machine. Finally, we consider abstract
machine states to be equivalent up to alphangconversion of bound labels.

The rewriting rules for TALng0 are as follows:

HD^ ^RD^vE^E^ C^ I
D^H; R; jump vE^ -! D^H; R; IE^ (JUMP)

D^H; R; rd:=v; IE^ -! D^H; RE,rd C^ ^RD^vE^G*; IE^ (MOV)

RD^rsE^ C^ n1 ^RD^vE^ C^ n2
D^H; R; rd:=rs+v; IE^ -! D^H; RE,rd C^ n1 + n2G*; IE^ (ADD)

RD^r E^ C^ 0 HD^ ^RD^vE^E^ C^ I0
D^H; R; if r jump v; IE^ -! D^H; R; I0E^ (IFngEQ)

RD^r E^ C^ n n T^ 0
D^H; R; if r jump v; IE^ -! D^H; R; IE^ (IFngNEQ)

The rules make use of ^R which simply lifts R from operating on registers to
operands:

^RD^r E^ C^ RD^r E^
^RD^nE^ C^ n
^RD^`E^ C^ `

Notice that for jump and a successful ifngjump we simply load a new instrucng
tion sequence from the heap and begin executing it. Of course, this assumes
that the destination operand evaluates to some label ` (as opposed to an inng
teger), and that the heap provides a binding for `. Otherwise, the machine
cannot make the transition and becomes stuck. For instance, if we attempted
to evaluate jump 42, then no transition could occur. In other words, if we can
devise a type system that rules out such stuck machine states, then we can
be assured that all control transfers must go to properly labelled instruction
sequences.

Of course, there are other ways this particular abstract machine can get
stuck. For instance, if we attempt to add an integer to a label, or test a label

146 4 Typed Assembly Language

using if, then the machine will get stuck. This reflects our choice to leave
labels abstract.

4.1.1 Exercise [n', 3]: Taking H to be a heap that maps the labels prod, loop,

and done to their respective instruction sequences above, and taking R0 C^
{r1=2,r2=2,r3=0,r4=exit} where exit is some unspecified label, show
that D^H; R0; jump prodE^ steps to a state D^H; R; jump r4E^ with RD^r3E^ C^ 4. 2

4.1.2 Exercise [Recommended, n'n'n', 3]: Build an interpreter for the TALng0 abng

stract machine in your favorite programming language. 2

4.1.3 Exercise [n'n'n', 3]: Formulate a semantics for a concrete machine based on

the TALng0 instruction set. The concrete machine should manipulate only inng
tegers and have states of the form D^M; R; pcE^ where M is a memory mapping
32ngbit integers to 32ngbit integers, R is a register file, and pc holds a 32ngbit inng
teger for the next instruction to execute. You should assume an isomorphism
encode and decode that maps instructions to and from distinct integers.

Then, prove that the TALng0 abstract machine is faithful to the concrete
machine by establishing a simulation relation between abstract and concrete
machine states and by showing that this relation is preserved under evaluang
tion. 2

4.2 The TALng0 Type System

The goal of the type system for TALng0 is to ensure that any wellngformed abng
stract machine M cannot get stuck--that is, there always exists an M0 such
that M -! M0. Obviously, our type system is going to have to distinguish lang
bels from integers to ensure that the operands of a control transfer are labels.
But we must also ensure that, no matter how many steps are taken by the abng
stract machine, it never gets into a stuck state (i.e., typing is preserved.) Thus,
when we transfer control to a label, we need to know what kinds of values it
expects to have in the registers.

To this end, we define our type syntax in Figure 4ng3. There are four basic
type constructors. Obviously, int will be used to classify integer values and
code types will classify labels. Furthermore, codeD^\Gamma  E^ will classify those labels
which, when jumped to, expect to have values described by \Gamma  in the associated
register. Here, \Gamma  is a register file type--a total function from registers to types.
In this respect, we can think of a label as a continuation which takes a record
of values described by \Gamma  as an argument.

We also support universal polymorphism in TALng0 through the addition of
type variables (ff) and quantified types (8ff:o/). As usual, we consider types

4.2 The TALng0 Type System 147
o/ ::= operand types:

int wordngsized integers
codeD^\Gamma  E^ code labels
ff type variables
8ff:o/ universal polymorphic types

\Gamma  ::= register file types:

{r1 : o/1; : : : ; rk : o/k}
\Psi  ::= heap types:

{`1 : o/1; : : : ; `n : o/n}

Figure 4ng3: TALng0 type syntax

up to alphangequivalence of bound type variables. Finally, we consider register
file types and heap types to be equivalent up to rengordering.

With these static constructs in hand, we can now formalize the type system
using the inference rules in Figure 4ng4. The first judgment, \Psi  ` v : o/, is used
to determine the type of a value. Recall that a value is a registerngfree operand,
so there is no need for a register context in the judgment. Integer literals are
given type int, whereas labels are given the type assigned to them by the
heap type context \Psi . Note that this rule only applies when the label is in the
domain of \Psi .

The second judgment, \Psi ; \Gamma  ` v : o/ lifts value typing to operands. A register
is given the type assigned by the register file type \Gamma  . In addition, a polymorng
phic operand can be instantiated with any type, in a fashion similar to ML.3

The next judgment, \Psi  ` ' : \Gamma 1 ! \Gamma 2 is used to check instructions. The notang
tion is meant to suggest that the instruction expects a register file described
by \Gamma 1 on input, and produces a register file described by \Gamma 2 on output. Note
that for the if instruction, we must ensure that the destination operand v
is a code pointer that expects a register file described by the same \Gamma  as any
subsequent instruction. This ensures that, no matter which way the branch
goes, the resulting machine state will be wellngformed.

The judgment \Psi  ` I : codeD^\Gamma  E^ assigns an instruction sequence I the type
codeD^\Gamma  E^ when the sequence expects to be given a register file described by \Gamma  .
In particular, a jump instruction's type is dictated by the type of its operand.
The code type for a sequence of instructions is determined from composing
tion. Most importantly, we can generalize the type of an instruction sequence
by abstracting any type variables. Note that there is no need to prevent abng
straction of type variables which occur free in the context \Psi , as is the case
with generalization in ML. This is because \Psi  will only contain closed types
(see below). Thus, generalization is always possible.

3. We could also include instantiation for values, but to keep things simple, we have omitted
that rule.

148 4 Typed Assembly Language

Values \Psi  ` v : o/

\Psi  ` n : int (sngint)
\Psi  ` ` : \Psi D^`E^ (snglab)

Operands \Psi ; \Gamma  ` v : o/

\Psi ; \Gamma  ` r : \Gamma  D^r E^ (sngreg)

\Psi  ` v : o/
\Psi ; \Gamma  ` v : o/ (sngval)
\Psi ; \Gamma  ` v : 8ff:o/
\Psi ; \Gamma  ` v : o/E,o/0=ffG* (snginst)

Instructions \Psi  ` ' : \Gamma 1 ! \Gamma 2

\Psi ; \Gamma  ` v : o/
\Psi  ` rd:=v : \Gamma  ! \Gamma  E,rd : o/G* (sngmov)
\Psi ; \Gamma  ` rs : int \Psi ; \Gamma  ` v : int

\Psi  ` rd:=rs+v : \Gamma  ! \Gamma  E,rd : intG* (sngadd)
\Psi ; \Gamma  ` rs : int \Psi ; \Gamma  ` v : codeD^\Gamma  E^

\Psi  ` if rs jump v : \Gamma  ! \Gamma  (sngif)

Instruction Sequences \Psi  ` I : o/

\Psi ; \Gamma  ` v : codeD^\Gamma  E^
\Psi  ` jump v : codeD^\Gamma  E^ (sngjump)
\Psi  ` ' : \Gamma  ! \Gamma 2 \Psi  ` I : codeD^\Gamma 2E^

\Psi  ` '; I : codeD^\Gamma  E^ (sngseq)

\Psi  ` I : o/
\Psi  ` I : 8ff:o/ (snggen)

Register Files \Psi  ` R : \Gamma 

8r :\Psi  ` RD^r E^ : \Gamma  D^r E^

\Psi  ` R : \Gamma  (sngregfile)

Heaps ` H : \Psi 

8` 2 domD^\Psi E^:\Psi  ` HD^`E^ : \Psi D^`E^

FTVD^\Psi D^`E^E^ C^ ;

` H : \Psi  (sngheap)

Machine States ` M

` H : \Psi  \Psi  ` R : \Gamma  \Psi  ` I : codeD^\Gamma  E^

` D^H; R; IE^

(sngmach)

Figure 4ng4: TALng0 typing rules

The judgment \Psi  ` R : \Gamma  asserts that the register file R is accurately deng
scribed by \Gamma  , under the assumptions of \Psi . Similarly, the judgment ` H : \Psi 
asserts that the heap H is accurately described by \Psi . This is essentially the
same rule as a "letrec" for declarations in a conventional functional language:
We get to assume that the labels have their advertised type, and then check
for any inconsistencies within their definitions. This allows labels to refer to
one another directly. Note also that we require the types in \Psi  to be closed so
that generalization remains valid.

Finally, the judgment ` D^H; R; IE^ puts the pieces together: We must have
some type assignment \Psi  that describes the heap H, a register file typing \Gamma 
that describes R consistent with \Psi , and I must be a continuation with a preng
condition of \Gamma  on the register file, under the assumptions of \Psi .

4.2 The TALng0 Type System 149
Some Examples and Subtleties
As a simple example of the type system in action, let us revisit the prod
example:

prod: r3 := 0; // res := 0

jump loop

loop: if r1 jump done; // if a = 0 goto done

r3 := r2 + r3; // res := res + b
r1 := r1 + (ng1); // a := a ng 1
jump loop

done: jump r4 // return
Let \Gamma  be the register file type:

{r1,r2,r3:int,r4:8ff.code{r1,r2,r3:int,r4:ff}}
Registers r1, r2, and r3 are assigned the type int, and r4 is assigned a polyng
morphic code type for reasons revealed below. Let \Psi  be the label type assignng
ment that maps prod, loop, and and done to codeD^\Gamma  E^. Let I be the instruction
sequence associated with loop and let us verify that it is indeed wellngformed
with the type that we have assigned it.

We must show that \Psi  ` I : codeD^\Gamma  E^. It suffices to show that each instruction
preserves \Gamma  , since the final jump is to loop, which expects \Gamma  . For the first
instruction, we must show \Psi  ` if r1 jump done : \Gamma  ! \Gamma  using the SngIF rule:

SngREG
\Psi ; \Gamma  ` r1 : \Gamma  D^r1E^ C^ int

SngLAB
\Psi  ` done : \Psi D^doneE^ C^ codeD^\Gamma  E^

SngVAL
\Psi ; \Gamma  ` done : codeD^\Gamma  E^

\Psi  ` if r1 jump done : \Gamma  ! \Gamma 

Next, we must show that adding r2 to r3 preserves \Gamma  :

SngREG
\Psi ; \Gamma  ` r2 : \Gamma  D^r2E^ C^ int

SngREG
\Psi ; \Gamma  ` r3 : \Gamma  D^r3E^ C^ int

\Psi  ` r3 := r2 + r3 : \Gamma  ! \Gamma 
Then, we must show that subtracting 1 from r1 preserves \Gamma  :

SngREG
\Psi ; \Gamma  ` r1 : \Gamma  D^r2E^ C^ int

SngINT
\Psi  ` -1 : int

SngVAL
\Psi ; \Gamma  ` -1 : int

\Psi  ` r1 := r1 + (ng1) : \Gamma  ! \Gamma 

150 4 Typed Assembly Language

Finally, we must show that the jump which terminates the sequence has type
codeD^\Gamma  E^, using the SngJUMP rule:

SngLAB
\Psi ; \Gamma  ` loop : \Psi D^loopE^ C^ codeD^\Gamma  E^

SngVAL
\Psi ; \Gamma  ` loop : codeD^\Gamma  E^

\Psi  ` jump loop : codeD^\Gamma  E^

Stringing the subngproofs together using the SngSEQ rule, we can thus confirm
that \Psi  ` I : codeD^\Gamma  E^.

Carrying on, we can show that each label's code has the type associated
with it. However, there is a major subtlety with the last jump r4 instruction
and the type that we have assigned r4 throughout the code. To understand
this, consider the following:

foo: r1 := bar;

jump r1

bar: ...
What type can we assign to bar? Without the polymorphism, it must be a
code type codeD^\Gamma  E^ such that \Gamma  D^r1E^ C^ codeD^\Gamma  E^, since the label bar will be in
register r1 when we jump to it. But with only simple types (i.e., no subtyping,
polymorphism, or recursive types), there is no solution to this equation.

With our support for polymorphism, the problem can be averted. In parng
ticular, we can assign bar a polymorphic type o/ of the form 8ff:code{r1 :
ff; : : : }. At the jump instruction, we have a register file context of the form
\Gamma  C^ {r1 : o/; : : : } and we must show that \Gamma  ` r1 : codeD^\Gamma  E^. Using SngINST, we
can instantiate the type of r1, which is o/, with o/ to derive \Gamma  ` r1 : code{r1 :
o/; : : : }.

This explains why we have used a polymorphic type for r4 in the prod
example above. Of course, this problem can be solved in other ways. Clearly,
adding recursive types provides a solution to the problem. An alternative is to
add some type Top which is greater than or equal to all other types, and use
this to forget the type of a register as we jump through it. Yet another solution
is to treat register file types as partial maps, and provide a form of subtyping
that lets you forget the type of a register, thereby making it unusable as an
operand until it is assigned a value. This last approach was the one used by
the original TAL. We prefer the approach based on polymorphism, because
there are many other compelling uses of this feature.

4.2.1 Exercise [n', 3]: Draw the derivation of wellngformedness for the instruction

sequences associated with prod and done. 2

4.2 The TALng0 Type System 151

For instance, polymorphism can also be used to achieve a type for "joinng
points" in a controlngflow graph. Consider the situation where we have two
jumps from distinct contexts to the same label:

{r1:int,...}
jump baz

...
{r1:code{...},...}
jump baz

What type should baz require of register r1? Again, without support for some
form of polymorphism or subtyping, we would be forced to make the types
the same, in which case this code would be rejected. The problem could be
worked around by, for instance, always loading an integer into r1 before
jumping to this label. But that would slow down the program with unnecng
essary instructions. Fortunately, polymorphism saves us again. In particular,
we can assign baz a type of the form 8ff:code{r1:ff,...}. Then, at the first
jump, we would instantiate ff to int, whereas at the second jump, we would
instantiate ff with the appropriate code type. Of course, the addition of Top
would also provide a convenient mechanism for typing join points.

One other feature that polymorphism provides which cannot be captured
through simple subtyping, is the idea of calleengsaves registers. A calleengsave
register is a register whose value should remain the same across a procedure
call. If the procedure wishes to use that register, then it is responsible for
saving and restoring its value before returning to the caller. Of course, we
don't yet have a way to save and restore registers to memory, but a procedure
could shuffle values around into different registers.

Suppose we wish to call a procedure, such as prod, and guarantee that the
register r5 is preserved across the call. We can accomplish this by requiring
the procedure's entry label to have a type of the form:

8ff.{r5:ff,r4:8fi.code{r5:ff,r4:fi, : : : }, : : : }
where r4 is the register which is meant to hold the return address for the
procedure, and ": : :" does not contain a free occurrence of ff. Note that the
return address's type specifies that r5 must have the same type (ff) upon reng
turn as was originally passed in. Furthermore, the procedure is required to
treat r5 uniformly since its type is abstract. Since there is no way to manung
facture values of abstract type, and since we've only passed in one ff value,
it must be that if the procedure ever returns, then r5 has the same value in
it as it did upon entry (see Exercise 4.2.5.) Note that the procedure is free to
move r5's value into some other register, and to use r5 to hold other values.
But before it can return, it must restore the original value.

152 4 Typed Assembly Language

So, it is clear that polymorphism can play a unifying role in the design
of type systems for lownglevel languages. It provides a way for us to conveng
niently "forget" types, which is necessary for jumps through registers and
join points. But it also provides an ability to capture critical compiler invaring
ants, such as calleengsaves registers.

4.2.2 Exercise [Recommended, n', 3]: Suppose we change the done instruction seng

quence from jump r4 to jump r1. Show that there is no way to prove the
resulting code is wellngtyped. 2

4.2.3 Exercise [Recommended, n'n'n', 3]: Reformulate the type system by eliming

nating type variables and universal polymorphism in favor of a Top type and
subtyping. Then show how the product example can be typed under your
rules. 2

4.2.4 Exercise [n'n'n', 3]: Reformulate the type system by using recursive types in

lieu of polymorphism. Then show how the product example can be typed
under your rules. 2

4.2.5 Exercise [n'n'n'n', 3]: Prove that the approach to calleengsaves registers actung

ally preserves values. Hint: one relatively easy way to prove this is suggested
by Crary (1999). Another possible solution is to adapt Reynolds' relational seng
mantics for the polymorphic lambda calculus (1983) to the TAL setting. The
result should follow as a "free theorem" (Wadler, 1989). 2

Proof of Type Soundness for TALng0
We now wish to show that the type system given in the previous section
actually enforces our desired safety property. In particular, we wish to show
that, given a wellngtyped machine state M, then M cannot get stuck (i.e., jump
to an integer or undefined label.) It suffices to show that a wellngtyped machine
state is not immediately stuck (progress), and that when it steps to a new
machine state M0, that state is also wellngtyped (preservation). For then, by
induction on the length of an evaluation sequence, we can argue that there is
no stuck M0 such that M -!* M0.

Our first step is to establish a set of substitution lemmas which show that
derivations remain possible after substituting types for type variables:

4.2.6 Lemma [Type Substitution]: If:

1. \Psi ; \Gamma  ` v : o/1, then \Psi ; \Gamma  E,o/=ffG* ` v : o/1E,o/=ffG*.
2. \Psi  ` ' : \Gamma 1 ! \Gamma 2 then \Psi  ` ' : \Gamma 1E,o/=ffG* ! \Gamma 2E,o/=ffG*.

4.2 The TALng0 Type System 153

3. \Psi  ` I : o/1, then \Psi  ` I : o/1E,o/=ffG*.
4. \Psi  ` R : \Gamma  , then \Psi  ` R : \Gamma  E,o/=ffG*. 2

The register substitution lemma ensures that typing is preserved when we
look up a value in the register file. It corresponds to the value substitution
lemma in a soundness proof for a conventional lambda calculus.

4.2.7 Lemma [Register Substitution]: If ` H : \Psi , \Psi  ` R : \Gamma  and \Psi ; \Gamma  ` v : o/ then

\Psi ; \Gamma  ` ^RD^vE^ : o/ 2

As usual, we shall need a Canonical Values lemma that tells us what kind
of value we have from its type:

4.2.8 Lemma [Canonical Values]: If ` H : \Psi  and \Psi  ` v : o/ then:

1. If o/ C^ int then v C^ n for some n.
2. If o/ C^ codeD^\Gamma  E^ then v C^ ` for some ` 2 domD^HE^ and \Psi  ` HD^`E^ : codeD^\Gamma  E^. 2

This extends to operands as follows:
4.2.9 Lemma [Canonical Operands]: If ` H : \Psi , \Psi  ` R : \Gamma  , and \Psi ; \Gamma  ` v : o/ then:

1. If o/ C^ int then ^RD^vE^ C^ n for some n.
2. If o/ C^ codeD^\Gamma  E^ then ^RD^vE^ C^ ` for some ` 2 domD^HE^ and \Psi  ` HD^`E^ :

codeD^\Gamma  E^. 2

4.2.10 Theorem [Soundness of TALng0]: If ` M, then there exists an M0 such that

M -! M0 and ` M0. 2

Proof: Suppose M C^ D^H; R; IE^ and ` M. By inversion of the SngMACH rule, there
exists a \Psi  and \Gamma  such that (a) ` H : \Psi , (b) \Psi  ` R : \Gamma  , and (c) \Psi  ` I : codeD^\Gamma  E^.
The proof proceeds by induction on I.

case I C^ jump v: From (c) and inversion of SngJUMP, we have \Psi ; \Gamma  ` v :
codeD^\Gamma  E^. From the Canonical Operands lemma, we know that there exists an
I0 such that HD^^RD^vE^E^ C^ I0 and \Psi  ` I0 : codeD^\Gamma  E^. Taking M0 C^ D^H; R; I0E^, we
can show M -! M0 via the JUMP rule. We must now show ` D^H; R; I0E^, but this
follows immediately.

case I C^ rd:=v; I0: From inversion of the SngSEQ rule, we have \Psi  ` rd:=v : \Gamma  !
\Gamma 2 and \Psi  ` I0 : codeD^\Gamma 2E^ for some \Gamma 2. Then, by inversion of the SngMOV rule, we
have \Psi ; \Gamma  ` v : o/ and \Gamma 2 C^ \Gamma  E,rd : o/G* for some o/. By the Register Substitution
lemma, we have \Psi ; \Gamma  ` ^RD^vE^ : o/. Taking M0 C^ D^H; RE,rd C^ ^RD^vE^G*; I0E^, we see
that M -! M0 via the MOV rule. From the SngREGFILE rule, we conclude that
\Psi  ` RE,rd C^ ^RD^vE^G* : \Gamma  E,rd : o/G*.

154 4 Typed Assembly Language

case I C^ rd:=rs+v; I0: From inversion of SngSEQ, we have \Psi  ` rd:=rs+v :
\Gamma  ! \Gamma 2 and \Psi  ` I0 : codeD^\Gamma 2E^ for some \Gamma 2. Then, by inversion of the SngADD
rule, we have \Psi ; \Gamma  ` rs : int, \Psi ; \Gamma  ` v : int and \Gamma 2 C^ \Gamma  E,rd : intG*. From
the and Canonical Operand lemma, we know that there exists integers n1
and n2 such that RD^rsE^ C^ n1 and ^RD^vE^ C^ n2. Taking n C^ n1 + n2 and M0 C^
D^H; RE,rd C^ nG*; I0E^, we see that M -! M0 via the ADD rule. By the SngINT and
SngVAL rules, \Psi ; \Gamma  E,rd : intG* ` n : int. Thus, by the SngREGFILE rule, we conclude
that \Psi  ` RE,rd C^ nG* : \Gamma  E,rd : intG*.

case I C^ if rs jump v; I0: From inversion of the SngSEQ rule, we have \Psi  `
if rs jump v : \Gamma  ! \Gamma 2 and \Psi  ` I0 : codeD^\Gamma 2E^ for some \Gamma 2. Then, by inversion
of the SngIF rule, we have \Psi ; \Gamma  ` rs : int, \Psi ; \Gamma  ` v : codeD^\Gamma  E^ and \Gamma 2 C^ \Gamma  . By
the Canonical Operands lemma, there exists an ` and I2 such that ^RD^vE^ C^ `,
HD^`E^ C^ I2, and \Psi  ` I2 : codeD^\Gamma  E^. Also by Canonical Operands, RD^rsE^ C^ n
for some integer n. If n C^ 0 then M -! D^M; R; I2E^ via IFngEQ. If n T^ 0 then
M -! D^M; R; I0E^ via IFngNEQ. In either case, the wellngformedness of the resulting
machine state follows from the SngMACH rule. 2

Proof Representation and Checking
It is not clear whether type inference for TALng0 machine states is decidable.
That is, given a machine state D^H; R; IE^, does there exist a \Psi  and \Gamma  such that
` H : \Psi , \Psi  ` R : \Gamma  , and \Psi  `: codeD^\Gamma  E^? On the one hand, this seems posng
sible since the type system is so simple. On the other hand, the system, as
presented, supports polymorphic recursion for which inference is known to
be undecidable in the context of the lambda calculus. Furthermore, as we
progress to more advanced typing features, the decidability of type reconng
struction will surely vanish. Thus, in any practical realization, we must reng
quire some help for constructing a proof that the code is indeed typengcorrect.

In the case of TALng0, it is sufficient to provide types for the labels (i.e.,
\Psi ). Indeed, it is even possible to omit types for some labels and keep reconng
struction decidable. We really only need enough type information to cut each
loop in the controlngflow graph, or for those labels that are moved into regng
isters. Minimizing the type information is an important goal in any practical
system, since the size of the types can often be larger than the code itself!
However, it is desirable to keep the type checker as simple as possible so that
we can trust it is properly enforcing the type system.

One way to keep the type checker simple is to modify the syntax so that
type reconstruction is entirely syntax directed. By this, we mean simply that
for any given term, at most one rule should apply. Furthermore, the checker
should not have to "guess" any of the subnggoal components. For TALng0, this
could be accomplished by (a) requiring types on all labels and (b) adding a
form of explicit type instantiation to operands (e.g., vE,o/G*).

4.3 TALng1: Simple MemoryngSafety 155

An alternative approach is to force the code provider to ship an explicit
representation of the complete proof of wellngformedness, along with the code,
and make sure that the proof and the code have the same instructions, labels,
etc. Of course, these proof will tend to be much larger than the code itself, but
we can use various techniques to reduce the size of the proof representation
(see for instance Necula and Lee, 1998b).

Such a separation of proofs and code is advantageous because we can ship
the binary machine code (as opposed to the assembly code), disassemble it,
and then compare it against the assemblynglevel proof. If everything checks
out, then we can load the binary and execute it directly. Such an approach
is called proofngcarrying code (Necula, 1997, 1998) and was first used by Necng
ula's Touchstone compiler (Necula and Lee, 1998a), and the SpecialngJ comng
piler (Colby et al., 2000), both of which are described more fully in the next
chapter.

Indeed, we could even go so far as to pass along the proof of soundness for
the entire type system, and a proof that the abstract machine is faithful to the
concrete machine's semantics! This would ensure that the code consumer has
to trust nothing but (a) the formalization of the concrete machine semantics,
and (b) the proof checker. This is the approach proposed by Appel and Felty
and is called foundational proofngcarrying code (2000).

In the rest of this chapter, we will remain vague about how proofs are to be
represented. The key thing to note is that we are not limited in the choice of
type constructors by issues of inference. Rather, we will require that the code
producer provide us with enough evidence that we can easily reconstruct and
check the proof of wellngformedness. Therefore, our only limitation will be the
incompletenesses of the resulting proof system.

4.2.11 Exercise [n'n'n'n', 3]: Build a typengchecker for TALng0 in your favorite programng

ming language. Assume that you are given as input a set of labels, their assong
ciated types, and instruction sequences. Furthermore, assume that operands
are augmented with explicit syntax for polymorphic instantiation. 2

4.3 TALng1: Simple MemoryngSafety

TALng0 includes registers and heapngallocated code, but provides no support
for allocated data. In this section, we will add primitive support for allocated
objects that can be shared by reference (i.e., pointer) and extend our safety
property to include a notion of objectnglevel memory safety: No memory access
should read or write a data object at a given location unless the program has
been granted access to that location.

156 4 Typed Assembly Language

From a typing perspective, the critical issue will be how to accommodate
locations that hold values of different types at different times during the
execution of the program. We need such a facility to at least support the
construction of compound values, such as tuples, records, datatype construcng
tors, or objects. A highnglevel language, such as ML, provides mechanisms to
allocate and initialize data structures as a single expression. For instance,
{x = 3, y = 4} is an expression that builds a record with two components. At
the assembly level, such highnglevel compound expressions must be broken
into machinenglevel steps. We must first allocate space for the object, and then
initialize the components by storing them in that space. To prevent someone
from treating an uninitialized component as if it holds a valid value, we must
use a different type. But obviously, once we initialize that component, its type
should change to reflect that it is now valid for use.

Already, we have support for storing values of different types in registers.
For instance, nothing prevents us from moving a code value into a register
currently holdingan int. However, when we add allocated data objects, we
can no longer track the changes easily due to aliasing. Let ptrD^o/E^ denote a
pointer to a data object of type o/ and consider this sequence of instructions:

{r1:ptr(code(...))}
1. r3 := 0;
2. Mem[r1] := r3;
3. r4 := Mem[r1];
4. jump r4

We assume upon entry that r1 is a pointer to a data location that contains
a code label. The first two instructions overwrite the contents of memory at
the location in r1 with the integer 0. The third instruction loads the value
from the location in r1 and jumps to it. Clearly, this code should be rejected
by the typengchecker as it violates our controlngflow safety property. To ensure
this, we might require that the type system update the type of r1 whenever
we store through it. For instance, after the second instruction, the type of r1
would change from ptr(code(...)) to ptr(int). Then at instruction four,
the code would be rejected because of an attempt to jump to an integer.

Now consider this sequence:

{r1:ptr(code(...)),r2:ptr(code(...))}
1. r3 := 0;
2. Mem[r1] := r3;
3. r4 := Mem[r2];
4. jump r4

The code is exactly the same except that instead of loading the value pointed
to by r1, we load the value pointed to by r2. Should this code typengcheck?

4.3 TALng1: Simple MemoryngSafety 157
The answer depends on whether or not r1 and r2 hold the same value--that
is, whether or not they are aliases for the same location. There is no problem
when they are not aliases, but when they are, the code behaves the same as
in the previous example (i.e., attempts to jump to the integer 0.) It becomes
clear that to prevent this problem, whenever we update a memory location
with a value of a different type, we must update the types of all aliases to
that location. To do so, the type system must track whether or not two values
are the same and, more generally, whether or not two code labels behave the
same.

Of course, there is no complete logic for tracking the equalities of values
and computations, but it is possible to construct a powerful type system
that allows us to conservatively track equality of some values. For instance
see the work on alias types (Smith, Walker, and Morrisett, 2000; Walker and
Morrisett, 2001; DeLine and Fa"hndrich, 2001). But all of these systems are,
in my opinion, technically daunting. Furthermore, certifying compilers for
highnglevel languages rarely need such complex machinery.

Nonetheless, we need some support for (a) allocating and initializing data
structures that are to be shared, and (b) stackngallocating procedure frames.
Therefore, we will focus on typing principles that try to strike a balance beng
tween expressiveness and complexity. After all, our goal is to provide a simple
but expressive structure for implementing typengsafe, highnglevel languages on
conventional architectures.

In particular, we will use the type system to separate locations into one
of two classes: The first class, called shared pointers, will support arbitrary
aliasing. However, the types of the contents of shared pointers must remain
invariant. That is, we can never write a value of a different type into the
contents of a shared location. This is the same basic principle that MLngstyle
refs and other highnglevel languages follow.

The second class of locations, called unique pointers, will support updates
that change the type of the contents. However, unique pointers cannot be
aliased. In particular, we will prevent unique pointers from being copied.
Thus, they will behave much the same way as registers.

The combination of unique and shared pointers will provide us with a simng
ple, but relatively flexible framework for dealing with memory. In particular,
we will be able to use unique pointers to handle the thorny problem of alng
locating and initializing shared data structures. We will also be able to use
unique pointers to model data structures whose lifetime is controlled by the
compiler, such as stack frames.

158 4 Typed Assembly Language

r ::= registers:

r1 | r2 | * * * | rk gp registers
sp stack pointer
' ::= instructions:

* * * as in TALng0
rd:= Mem[rs + n] load from memory
Mem[rd + n] := rs store to memory
rd:= malloc n allocate n heap words
commit rd become shared
salloc n allocate n stack words

sfree n free n stack words
v ::= operands:

r registers
n integer literals
` code or shared data pointers
uptrD^hE^ unique data pointers
h ::= heap values:

I instruction sequences
hv1; : : : ; vni tuples

Figure 4ng5: TALng1 syntax additions

The TALng1 Extended Abstract Machine
Figure 4ng5 gives a set of syntactic extensions to TALng0 which are used in the
definition of TALng1. We have added six new instructions: Two of the instrucng
tions can be used to load a value from memory into a register, or to store
a register's value to memory respectively. The effective address for both inng
structions is calculated as a wordnglevel offset from a base register. The other
instructions are nonngstandard. The malloc instruction is used to allocate an
object with n words. A (unique) reference to the object is placed in the desng
tination register. Typically, malloc will be implemented by the concrete mang
chine using a small sequence of inlined instructions or a procedure call. We
abstract from these details here so that our abstract machine can support a
wide variety of allocation techniques. The commit instruction is used to cong
erce a unique pointer to a shared pointer. It has no real runngtime effect but it
makes it easier to state and prove the invariants of the type system.

The salloc and sfree constructs manipulate a special unique pointer
which is held in a distinguished register called sp (stack pointer). The instrucng
tion salloc attempts to grow the stack by n words, whereas sfree shrinks
the stack by n words. The type system will prevent the stack from underng
flowing, so in principle, sfree could be implemented by a simple arithmetic
operation (e.g., sp := sp + n.) Unfortunately, stack overflow will not be capng
tured by this type system. Therefore, we assume that the salloc instruction
checks for overflow and aborts the computation somehow.

As before, we will model machine states using a triple of a heap, register
file, and instruction sequence. And, as before, register files will map registers
to wordngsized values, while heaps will map labels to heapngvalues. We extend

4.3 TALng1: Simple MemoryngSafety 159
heap values to include tuples of wordngsized values. Thus, a label can refer to
either code or data. We could also use the heap to store unique data values,
but this would make it more difficult to prove that the pointers to these values
are indeed unique. Instead, we will extend operands with terms of the form
uptrD^hE^ and use such a term to represent a unique pointer to a heap value h.

The rewriting rules for the instructions of TALng1 that overlap with TALng0
remain largely the same. However, we must prevent unique pointers from beng
ing copied. More precisely, we must prevent the situation where we have two
references to the same unique data. Note that, for the addition and if instrucng
tions, the use of a unique pointer as an operand will cause the machine to get
stuck since the operands must be integers to make progress. However, the
typing for assignment (r :=v) must be changed to prevent copies of unique
pointers:

^RD^vE^ T^ uptrD^hE^

D^H; R; rd:=v; IE^ -! D^H; RE,rd C^ vG*; IE^ (MOVng1)
This rule can only fire when the source operand is not a unique pointer.

We must now give the rewriting rules for the new instructions:

D^H; R; rd:= malloc n; IE^ -! D^H; RE,rd C^ uptrhm1; : : : ; mniG*; IE^ (MALLOC)

rd T^ sp ` 62 domD^HE^
D^H; RE,rd C^ uptrD^hE^G*; commit rd; IE^ -! D^HE,` C^ hG*; RE,rd C^ `G*; IE^ (COMMIT)

RD^rsE^ C^ ` HD^`E^ C^ hv0; : : : ; vn; : : : ; vn+mi
D^H; R; rd:= Mem[rs + n]; IE^ -! D^H; RE,rd C^ vnG*; IE^ (LDngS)

RD^rsE^ C^ uptrhv0; : : : ; vn; : : : ; vn+mi
D^H; R; rd:= Mem[rs + n]; IE^ -! D^H; RE,rd C^ vnG*; IE^ (LDngU)

RD^rdE^ C^ ` HD^`E^ C^ hv0; : : : ; vn; : : : ; vn+mi RD^rsE^ C^ v v T^ uptrD^hE^

D^H; R; Mem[rd + n] := rs; IE^ -! D^HE,` C^ hv0; : : : ; v; : : : ; vn+miG*; R; IE^

(STngS)

RD^rdE^ C^ uptrhv0; : : : ; vn; : : : ; vn+mi; RD^rsE^ C^ v v T^ uptrD^hE^
D^H; R; Mem[rd + n] := rs; IE^ -! D^H; RE,rd C^ uptrhv0; : : : ; v; : : : ; vn+miG*; IE^

(STngU)

RD^spE^ C^ uptrhv0; : : : ; vpi p + n <= MAXSTACK
D^H; R; salloc nE^ -! D^H; RE,sp C^ uptrhm1; : : : ; mn; v0; : : : ; vpiG*E^ (SALLOC)

RD^spE^ C^ uptrhm1; : : : ; mn; v0; : : : ; vpi
D^H; R; sfree nE^ -! D^H; RE,sp C^ uptrhv0; : : : ; vpiG*E^ (SFREE)
The malloc instruction places a unique pointer to a tuple of n words in the
destination register. We assume that the memory management subsystem

160 4 Typed Assembly Language

has initialized the tuple with some arbitrary integer values m1; : : : ; mn. Recall
that the rewriting rules prevent these unique pointers from being copied.
However, the commit instruction allows us to move a unique pointer into the
heap where it can be shared. As we will see, however, shared pointers must
have invariant types, whereas unique pointers' types can change.

The memoryngload instruction has two variants, depending upon whether
the source register holds a value that is shared or unique. If it is shared, then
we must look up the binding in the heap to get the heap value. If it is unique,
then the heap value is immediately available. Then, in both cases, the heap
value should be a tuple. We extract the nth word and place it in the destination
register.

The memoryngstore instruction is the dual and is used to update the nth
component of a tuple. Note that the machine gets stuck on an attempt to
store a unique pointer, thereby preventing copies from leaking into a data
object.

As a simple example of the use of these constructs, consider the following
code:

copy: {r1:ptr(int,int), r2,r3:int}

r2 := malloc 2;
r3 := Mem[r1];
Mem[r2] := r3;
r3 := Mem[r1+1];
Mem[r2+1] := r3;
commit r2;
{r1:ptr(int,int), r2:ptr(int,int), r3:int }

The code is meant to do a deep copy of the data structure pointed to by
r1 and place the copy in register r2. Suppose that r 1 holds a label `1 and
HD^`1E^ C^ h3; 5i. After executing the malloc instruction, r2 will hold a unique
pointer to a pair of (arbitrary) integers of the form uptrhm1; m2i. After the
load and store, the first integer component of r1 will have been copied into
the first component of r2. Thus, the contents of `2 will have changed to
uptrh3; m2i. After the second load and store, the second component will have
been copied, so r2 will hold the value uptrh3; 5i. Finally, after the commit
instruction, r2 will hold a fresh, shared label `2 and the heap will have been
extended so that it maps `2 to the heap value h3; 5i.

Here is an example program which uses salloc and sfree:

foo: {sp : uptr(int), r1 : code{...}}

salloc 2; // {sp : uptr(int,int,int)}
Mem[sp] := r1; // {sp : uptr(code{...},int,int)}
sfree 1 // {sp : uptr(int,int)}

4.4 TALng1 Changes to the Type System 161
o/ ::= operand types:

* * * as in TALng0
ptrD^oe E^ shared data pointers
uptrD^oe E^ unique data pointers
8ae:o/ quantification over allocated types

oe ::= allocated types:

ffl empty
o/ value type
oe1; oe2 adjacent
ae allocated type variable

Figure 4ng6: TALng1 types

On input, the stack has one integer element and r1 has a code pointer. The
first instruction grows the stack by two words. The second instruction stores
the value in r1 into the top of the stack. The third instruction frees one of
the words. Note that salloc becomes stuck if we attempt to allocate more
than MAXSTACK (total) words and that sfree becomes stuck if we attempt to
shrink the stack by more words than are on the stack. Finally, note that our
stacks grow "up" (indexing is positive) whereas the common convention is to
have stacks that grow down. The only reason for this choice is that it unifies
unique pointers to tuples with stacks. If we wanted to support downward
stacks, then we could introduce a new kind of data structure (e.g., stptr.)

4.3.1 Exercise [Recommended, n', 3]: Show how stackngpush and stackngpop instrucng

tions can be explained using the primitives provided by TALng1. Explain how a
sequence of pushes or a sequence of pops can be optimized. 2

4.3.2 Exercise [n'n'n', 3]: Modify the abstract machine so that unique pointers are

allocated in the heap, just like shared pointers, but are represented as a
tagged value of the form uptr(`). Then show that the machine maintains
the invariant that there is at most one copy of a unique pointer. 2

4.4 TALng1 Changes to the Type System

What changes and additions are needed to the type system to ensure that the
new abstract machine won't get stuck? In particular, how do we ensure that
when we do a load, the source register contains a data pointer (as opposed
to an integer or code label), and the data pointer points to a heap value that
has at least as many components as the offset requires? Similarly, how do
we ensure that for a store, the destination register is a data pointer to a large
enough heap value? And how do we ensure that the stack does not underflow?
How do we ensure that we don't try to copy a unique pointer? In short, how
do we ensure progress?

162 4 Typed Assembly Language

Heap Values \Psi  ` v : o/

\Psi ; \Gamma  ` vi : o/i
\Psi  ` hv1; : : : ; vni : o/1; : : : ; o/n (sngtuple)

Operands \Psi  ` v : o/

\Psi ; \Gamma  ` h : oe
\Psi ; \Gamma  ` uptrD^hE^ : uptrD^oe E^ (snguptr)

Figure 4ng7: TALng1 typing rules (heap values and operands)

Figure 4ng6 gives a new set of types for classifying TALng1 values. The o/
types are used to classify values and operands, whereas the oe types are
used to classify heapngallocated data. We have added three new operand types
corresponding to shared pointers (ptrD^oe E^), unique pointers (uptrD^oe E^), and
polymorphism over allocated types (8ae:o/.)

The allocated types (oe ) consist of sequences of operand types. The syntax
supports nesting structure (i.e., trees) but we implicitly treat adjacency as
associative with ffl as a unit. So, for instance:

ptrD^int; D^ae; D^int; fflE^E^E^ C^ ptrD^D^int; aeE^; intE^
Allocated types also support variables (ae) which are useful for abstracting
a chunk of memory. That is, ff can be used to abstract a single wordngsized
type, whereas ae can be used to abstract a type of arbitrary size. As we will
see, polymorphism over allocated types is the key to efficient support for
procedures.

Figures 4ng7 and 4ng8 give the new typing rules. As in TALng0, we take \Gamma  to be
a total map from registers to operand types. We are also assuming that \Psi  is
a finite partial function from labels to allocated operand types (i.e., code or
ptr types.)

The wellngformedness rules for tuples and unique pointers are straightforng
ward. The sngmovng1 rule defines the new type for the move instruction. It has
as a prengcondition that the value being moved should not be a unique pointer.

The typing rule for malloc requires a nonngnegative integer argument, and
updates the destination register's type with a unique pointer of an nngtuple
of integers. The commit instruction expects a unique pointer in the given
register, and simply changes its type to a shared pointer.

The load and store instructions require two rules each, depending upon
whether they are operating on unique pointers. Notice that for the store rules,
we are not allowed to place a unique pointer into the data structure. Notice
also that that when storing into a unique pointer, there is no requirement
that the new value have the same type as the old value. In contrast, for shared
pointers, the old and new values must have the same type.

4.4 TALng1 Changes to the Type System 163
Instructions \Psi  ` ' : \Gamma 1 ! \Gamma 2

\Psi ; \Gamma  ` v : o/ o/ T^ uptrD^oe E^

\Psi  ` rd:=v : \Gamma  ! \Gamma  E,rd : o/G* (sngmovng1)

n >= 0
\Psi  ` rd:= malloc n : \Gamma  ! \Gamma  E,rd : uptrhint; : : : ; int-- -z ""

n

iG* (sngmalloc)

\Psi ; \Gamma  ` rd : uptrD^oe E^ rd T^ sp
\Psi  ` commit rd : \Gamma  ! \Gamma  E,rd : ptrD^oe E^G* (sngcommit)

\Psi ; \Gamma  ` rs : ptrD^o/1; : : : ; o/n; oe E^
\Psi  ` rd := Mem[rs + n] : \Gamma  ! \Gamma  E,rd : o/nG* (snglds)

\Psi ; \Gamma  ` rs : uptrD^o/1; : : : ; o/n; oe E^
\Psi  ` rd := Mem[rs + n] : \Gamma  ! \Gamma  E,rd : o/nG* (sngldu)

\Psi ; \Gamma  ` rs : o/n o/n T^ uptrD^oe 0E^ \Psi ; \Gamma  ` rd : ptrD^o/1; : : : ; o/n; oe E^

\Psi  ` Mem[rd + n] := rs : \Gamma  ! \Gamma  (sngsts)
\Psi ; \Gamma  ` rs : o/ o/ T^ uptrD^oe 0E^ \Psi ; \Gamma  ` rd : uptrD^o/1; : : : ; o/n; oe E^

\Psi  ` Mem[rd + n] := rs : \Gamma  ! \Gamma  E,rd : uptrD^o/1; : : : ; o/; oe E^G* (sngstu)

\Psi ; \Gamma  ` sp : uptrD^oe E^ n >= 0
\Psi  ` salloc n : \Gamma  ! \Gamma  E,sp : uptrD^int; : : : ; int-- -z ""

n

; oe E^G* (sngsalloc)

\Psi ; \Gamma  ` sp : uptrD^o/1; : : : ; o/n; oe E^
\Psi  ` sfree n : \Gamma  ! \Gamma  E,sp : uptrD^oe E^G* (sngsfree)

Figure 4ng8: TALng1 typing rules (instructions)

The rules for salloc and sfree are straightforward. For sfree n we check
that there are at least n values on the stack to avoid underflow. Note that the
rule does not allow allocated type variables (ae) to be eliminated, reflecting
the fact that, in general, we do not know how many words are occupied by ae.
For instance, ae could be instantiated with ffl in which case there are no values.
A similar restriction holds for loads and stores--we must at least know the
sizes up through the word component we are projecting or storing.

164 4 Typed Assembly Language

To prevent the machine from becoming stuck, salloc would ideally check
that adding n words to the stack would not exceed MAXSTACK. But alas, we
cannot always determine the current length of the stack. In particular, if its
type contains an allocated variable ae, then we are in trouble. One way around
this problem is to change the abstract machine so that it does not get stuck
upon overflow by defining a transition (e.g., by jumping to a prengdefined lang
bel). This would correspond to a machine trap due to an illegal access.

It is possible to extend our soundness proof for TALng0 to cover the new
constructs in TALng1 and show that a wellngformed machine state cannot get
stuck, except when the stack overflows. In the proof of soundness, one critical
property we must show is that any typing derivation remains valid under an
extension of the heap. In particular, if ` H : \Psi  and \Psi  ` h : o/, then ` HE,` C^
hG* : \Psi E,` : o/G*. Another critical property is that we would have to show that
a given label ` that occurs in the heap has exactly one type throughout the
execution of the program. In other words, once we have committed a pointer
so that it can be shared, its type must remain invariant.

4.4.1 Exercise [n'n'n'n', 3]: Extend the proof of soundness to cover the new feang

tures in TALng1. 2

4.5 Compiling to TALng1

At this point, TALng1 provides enough mechanism that we can use it as a tarng
get language for the compiler of a polymorphic, procedural language with
integers, tuples, records, and function pointers (but not yet lexically nested
closures.) As a simple example, let us start with the following C code:

int prod(int x, int y) {

int a = 0;
while (x != 0) {

a = a + y;
x = x ng 1;
}
return a;
}

int fact(int z) {

if (z != 0) return prod(fact(zng1),z);
else return 1;
}

and show how it may be compiled to TALng1, complete with typing annotations
on the code labels. We assume a calling convention where arguments are

4.5 Compiling to TALng1 165
passed on the stack, and the return address is passed in r4. We also assume
that results are returned in register r1, and arguments are popped off the
stack by the callee. Finally, we assume that registers r2 and r3 are freely
available as scratch registers.

Let us first translate the prod function under these conventions:

prod: 8a,b,c,s.

code{r1:a,r2:b,r3:c,sp:uptr(int,int,s),

r4:8d,e,f.code{r1:int,r2:d,r3:e,r4:f,sp:uptr(s)}}
r2 := Mem[sp]; // r2:int, r2 := x
r3 := Mem[sp+1]; // r3:int, r3 := y
r1 := 0 // r1:int, a := 0
jump loop

loop: 8s.code{r1,r2,r3:int,sp:uptr(int,int,s),

r4:8d,e,f.code{r1:int,r2:d,r3:e,r4:f,sp:uptr(s)}}
if r2 jump done; // if x $ 0 goto done
r1 := r1 + r3; // a := a + y
r2 := r2 + (ng1); // x := x ng 1
jump loop

done: 8s.code{r1,r2,r3:int,sp:uptr(int,int,s),

r4:8d,e,f.code{r1:int,r2:d,r3:e,r4:f,sp:uptr(s)}}
sfree 2; // sp:uptr(s)
jump r4

The code itself is rather straightforward. What is most interesting is the types
we have placed on the labels. Note that, upon input to prod, r1, r2, and r3 can
have any types, since we have abstracted their types. Note also that the stack
pointer has type uptr(int,int,s) and thus has two integers at the front,
but can have any sequence of values following, since we have abstracted the
tail with an allocated type variable s. The return address in r4 is polymorphic
for r2 and r3 to allow values of any type in those registers upon return. As
discussed earlier, the type of r4 is abstracted by the return address to alng
low jumping through that register. Furthermore, the return address demands
that the stack have type uptr(s), reflecting that the callee should pop the
arguments before jumping to the return address. Thus, the contents of the
rest of the stack is guaranteed to be preserved since s is abstract.

In general, a sourcenglevel procedure that takes arguments of types o/1; : : : ; o/n
and returns a value of type o/ would translate to a label with the same type as
prod's, except that the stack pointer would have type uptrD^o/1; : : : ; o/n; sE^, and
r4's return code type would expect r1 to have type o/.

The types for the loop and done labels are similar to prod's, except that
registers r1,r2, and r3 must hold integers. The reader is encouraged to check
that the resulting code is wellngformed according to the typing rules for TALng1.

166 4 Typed Assembly Language

Now let us translate the recursive factorial procedure using the same callng
ing conventions:

fact: 8a,b,c,s.

code{r1:a,r2:b,r3:c,sp:uptr(int,s),

r4:8d,e,f.code{r1:int,r2:d,r3:e,r4:f,sp:uptr(s)}}
r1 := Mem[sp]; // r1:int, r1 := z
if r1 jump retn // if z = 0 goto retn
r2 := r1 + (ng1); // r2:int, r2 := zng1
salloc 2 // sp:uptr(int,int,int,s)
Mem[sp+1] := r4; // sp:uptr(int,(8d,e,f.code{...}),int,s)
Mem[sp] := r2; // sp:uptr(int,(8d,e,f.code{...}),int,s)
r4 := cont;
jump fact // r1 := fact(zng1)

cont: 8c,s',d,e,f.

code{r1:int,r2:d,r3:e,r4:f,

sp:uptr(8d,e,f.code{...},int,s')}
r4 := Mem[sp]; // restore original return address
Mem[sp] := r1; // sp:uptr(int,int,s')
jump prod // tail call prod(fact(zng1),z)

retn: 8b,c,s.

code{r1:int,r2:b,r3:c,sp:uptr(int,s),

r4:8d,e,f.code{r1:int,r2:d,r3:e,r4:f,sp:uptr(s)}}
r1 := 1;
sfree 1; // sp:uptr(s)
jump r4 // return 1

The first couple of instructions load the argument from the stack, test if it
is zero, and if so, jump to the retn block where the argument is popped off
the stack and the value 1 is returned. If the argument z is nonngzero, then we
must calculate zng1, pass it in a recursive call to fact, and then pass the result
along with z to the prod function.

To do the recursive call, we must allocate stack space for the return address
(r4) and the argument zng1, and save those values on the stack. Then we must
load a new return address into r4, namely cont and finally jump to fact.
When the recursive call returns, control will transfer to the cont label. Notice
that cont expects the stack to hold the original return address and the value
of z. We restore the original return address by loading it from the stack. We
then overwrite the same stack slot with the result of fact(zng1). Finally, we
do a tailngcall to prod.

It is important to recognize that the calling conventions we chose are not
specific to the abstract machine. For instance, we could have chosen a convenng

4.6 Scaling to Other Language Features 167
tion where the return address is pushed on the stack, or where arguments are
passed in registers, introduced calleengsaves registers, etc. In contrast, virtual
machines languages such as the JVML and CLI bake the notion of procedure
and procedure call into the language. To add support for different calling
conventions (e.g., tailngcalls, or a tailored convention for leaf procedures) reng
quires additions and changes to the abstract machine and its type system.
In contrast, by focusing on a more primitive set of type constructors (e.g.,
8, code, and uptr types), we are able to accommodate many conventions
without change to the type system.

4.5.1 Exercise [Recommended, n'n', 3]: Rewrite the fact procedure with a calling

convention where the arguments and return address are placed on the stack.
Include typing annotations on the labels and convince yourself that the code
typengchecks. 2

4.6 Scaling to Other Language Features

TALng1 only supports simple tuple or recordnglike data structures. Thus, it
is insufficient for compiling realngworld highnglevel languages which provide
data abstraction mechanisms such as closures, algebraic datatypes, objects,
and/or arrays.

Simple Objects and Closures
Support for closures and simple forms of objects is readily accommodated
by adding existential abstraction for both operand and allocated types:

o/ ::= : : : | 9ff:o/ | 9ae:o/
The rules for introducing and eliminating existentials on operands are exng
tremely simple:

\Psi ; \Gamma  ` v : o/E,o/0=ffG*

\Psi ; \Gamma  ` v : 9ff:o/ (sngpack)

\Psi ; \Gamma  ` v : 9ff:o/ ff 62 FTVD^\Gamma  E^

\Psi ; \Gamma  ` v : o/ (sngunpack)
(There are two similar rules for existentials that abstract allocated types.) The
first rule allows us to abstract a common type for some components of a data
structure. For instance, if r has type

ptr(code{r1:int,r2:int,...},int)

168 4 Typed Assembly Language

then we can use the sngpack rule to treat the value as if it has type

9ff:ptr(code{r1:ff,r2:int,...},ff):
Now, such a value can only be used by eliminating the existential using the
sngunpack rule. However, we are required to continue treating ff as abstract
and distinct from any other type that may be in our context.

As suggested by Pierce and Turner (1993), we can use existentials to encode
very simple forms of objects. For example, consider an object interface that
looks like this, written in a Javangstyle:

interface Point {

int getX();
int getY();
}

and consider two classes that implement this interface:

class C1 implements Point {

int x = 0, y = 0;
int getX() { return x; }
int getY() { return y; }
}

class C2 implements Point {

int x = 0, y = 0 , n = 0;
int getX() { n++; return x; };
int getY() { n++; return y; }
}

We can think of objects as pairs of a method table and an instance variable
frame. The methods take the instance variable frame as an implicit "self"
argument. For instance, the C1 class would have an instance frame that holds
two integers, whereas the C2 class would have an instance frame that holds
three integers. Thus, at an intermediate language level, C1's get operations
would have type:

ptr(int,int) ! int
while C2's operations would have type:

ptr(int,int,int) ! int
When we build a C1 object or a C2 object, we need to hide the type of the inng
stance frame so that only the methods can gain access to and manipulate the

4.6 Scaling to Other Language Features 169
values of the instance variables. We also need to hide the type of the instance
frames so that we can give the objects a common type. We can achieve this
by using an existential to abstract the type of the instance frame and pairing
the methods with the instance frame. At an intermediate level, the type of a
Point object would thus be something like:

9ff:ptr(ptr(ff ! int,ff ! int),ff)
Note that for any value with this type, we cannot directly access the instance
variables because their type is abstract (i.e., ff). However, once such an obng
ject is unpacked, we can project out a method and the instance frame, and
pass the frame to the method because the methods expect an ff value as an
argument.

Closures are simple forms of objects where the instance frame holds the
environment, and there is a single method for applying the closure to its
arguments. Thus, with the simple addition of existential types, we have the
ability to encode the primary features of modern languages, notably closures
and objects. Indeed, the original TAL paper (Morrisett, Walker, Crary, and
Glew, 1999) showed how a polymorphic, core functional language could be
mapped to a version of typed assembly with support for existentials. This
translation was based on previous work of Minamide, Morrisett, and Harper
(1996).

Of course, in a more realistic implementation, we might represent objects
without the level of indirection on instance variables, and instead of passing
only the instance variables to methods, we could pass the whole object to a
method. With the addition of recursive types (uff:o/) and the usual isomorng
phism (uff:o/ C^ o/E,uff:o/=ffG*), this becomes possible:

9ae:uff:ptr(ptr(ff ! int,ff ! int),ae)
Notice that in the above encoding, we have abstracted an allocated type (ae)
which is used to describe the rest of the object after the method pointer. Furng
thermore, the methods in the method table expect to take values of type ff
which is isomorphic to the type of the (unpacked) object. That is, the methng
ods take in the whole object (including the method table) instead of just the
instance variables.

This last encoding of objects is closely based on ideas of Bruce (1995;
2002). There are many other potential encodings (see Bruce, Cardelli, and
Pierce, 1997, for a nice overview.) In short, it is possible to draw upon the
wealth of literature on object and closure encodings to find a small set of
rengusable type constructors, such as Fngbounded existentials, to provide your
typed assembly language with enough power to support compilation of modng
ern objectngoriented or functional languages, without baking in a particular

170 4 Typed Assembly Language

object model. Again, this contrasts with the JVM and CLI which fix on a single
object model and provide poor support for encoding languages outside that
model.

One problem with these object encodings is that they do not readily supng
port a form of "downngcasting" where we perform a runngtime test to determine
whether an object implements a given interface. Such operations are common
in languages such as Java, where the lack of parametric polymorphism and
the erroneous addition of covariant arrays requires dynamic type tests. In
general, dynamic type tests can be accomplished by using some form of repng
resentation types (Crary, Weirich, and Morrisett, 1998), but these encodings
are relatively heavyweight and do not support the actual representations used
by implementations. Glew (1999) suggested and implemented extensions to
TALx86 that better supports practical implementations.

Arrays, Arithmetic, and Dependent Types
In TALng1, we are restricted to using constant offsets to access the data comng
ponents of an object. Similarly, we can only allocate objects whose size is
known at compile time. Thus, we cannot directly encode arrays.

The simplest way to add arrays is to revert to highnglevel, CISCnglike inng
structions. We could imagine adding a primitive rd:= newarray(ri; rs) which
would allocate an array with ri elements, and initialize all of the components
with the value in rs, returning a pointer to the array in register rd. To read
components out of an array, we might have an operation rd:= ldarr(rs; ri)
which would load the r thi component of array rs, placing the result in rd. Dung
ally, the operation starr(rs; rd; ri) would store the value in rs into the r thi
component of array rd.

To ensure type safety for the ldarr and starr operations, we would need
to check that the element offset ri did not exceed the number of elements in
the array and jump to an exception handler if this constraint is not met. In
turn, this would demand that we (implicitly) maintain the size of the array
somewhere. For instance, we could represent an array with n elements as a
tuple of n + 1 components with the size in the first slot.

4.6.1 Exercise [Recommended, n'n', 3]: Extend the TALng1 abstract machine with

rewriting rules for arrays as described above and provide typing rules for the
new instructions. 2

The advantage of the approach sketched above is that it leaves the type
system simple. However, it has a number of drawbacks: First, there is no way
to eliminate the check that an offset is in bounds, even if we know and can
prove that this is the case. Second, this approach requires that we maintain

4.6 Scaling to Other Language Features 171
the size of the array at runtime, even though the size might be statically apng
parent. Third, the real machinenglevel operations that make up the primitive
subscript and update operations would not be subject to lownglevel optimizang
tions (e.g., instruction scheduling, strength reduction, and induction variable
elimination.)

An alternative approach based on dependent types was suggested by Xi
and Harper (2001) and implemented (to some degree) in TALx86. The key
idea behind the approach, called DTAL, is to first add a form of compilengtime
expressions to the type system:

e ::C^ n | e1 + e2 | e1 - e2 | e1 * e2 | i | * * *
A compilengtime expression is made up of constants (n), arithmetic operations,
and compilengtime integer variables (i). We then allow type constructors to deng
pend upon (i.e., be indexed by) a compile time expression. For instance, the
type arr(o/; 30 + 12) would classify those arrays that have 42 components,
each of which is a value of type o/. Similarly, the type int(36) would clasng
sify those integer values that are equal to 36--in other words, int(36) is a
singleton type.

To support integers whose value is unknown, or arrays whose number of elng
ements are unknown, we can use a suitably quantified compilengtime variable.
For instance, the type 9i:int(i) would classify any integer value, and the
type 9i:arr(o/,i*2) would classify arrays of o/ values with an even number
of components. More importantly, the type

8i1,i2.code{r1:int(i1),r2:arr(T,i1),r3:int(i2)}
would classify code that expects r2 to hold an array with i1 elements, r1 to
hold an integer equal to i1, and r3 to hold some other integer equal to i2.
Thus, we can use this limited form of dependent types to track an important
relation between two values--that one register holds the number of elements
in the array pointed to by another register.

To support the elimination of array bounds checks, we need to go beyond
equality relations and track refinements of values as we perform tests. For
instance, in a context with the code type above, if we wanted to use r3 to
index into array r2, it should be sufficient to check that the value in r3 is
greater than or equal to 0, and less than r1:4

sub: 8i1,i2.code{r1:int(i1),r2:arr(T,i1),r3:int(i2), ...}

if r3<0 jump L;
rt := r3 ng 1;
if rt>=0 jump L;
rd := ldarr(r2,r3) // rd := Mem[r2+r3]

4. In practice, this can be determined using a single unsigned comparison.

172 4 Typed Assembly Language

In other words, the ldarr operation above should typengcheck since we are in
a context where r2 is an array of size i1, r3 is an integer equal to i2, and
the predicate D^i2 >= 0E^ ^ D^i2 < i1E^ is true. To support this validation, DTAL
checked instructions under a typing context of the form D^\Gamma  ; P E^ where P was
a predicate that was assumed to be true. Tests, such as the blt r3, ERROR
instruction, would typically add conjuncts to the context's predicate.

For example, typengchecking for the fragment above would proceed as folng
lows:

1. sub: 8i1,i2.(...; true)
2. if r3<0 jump L; // ({...}; true ^ (i2 >= 0))
3. rt := r3 ng 1; // ({...,rt:int(i2ngi1)};(i2 >= 0))
4. if rt>=0 jump L; // ({...,rt:int(i2ngi1)};(i2 >= 0)^(i2ngi1 < 0))
5. rd := ldarr(r2,r3)

After checking line 2, the context's predicate (true) has been refined by
adding the conjunct i2 >= 0 since r3 has type int(i2) and the test can only
fall through when r3 is greater than or equal to zero. At line 3, rt is given
the type int(i2ngi1) since r1 has type int(i1) and r3 has type int(i2) and
the operation places r3 ng r1 into rt. Then, at line 4, the test adds the conng
junct i1ngi1 < 0 to the fallngthrough continuation's context. Finally, at line 5,
we are able to satisfy the prengcondition of the ldarr construct since we are
in a context where the index lies between 0 and the size of the array.

In DTAL, the predicates used for refinements were restricted to linear inng
equalities so as to keep typengchecking decidable. But in general, we could add
support for arbitrary predicates, and simply require that the code producer
provide an explicit proof that the current (inferred) predicate implied the
necessary prengconditions. In other words, we can fall back to a very general
proofngcarrying code framework, as described in the following chapter.

However, as the designer of the type system, we would still be responsible
for providing the code producer a set of sound (and relatively complete) inferng
ence rules for proving these relations. Though this is possible, it is nowhere
as easy as the simple proofs that we have presented here.

4.7 Some Real World Issues

Clearly, TALng1 and the extensions described earlier provide the mechanisms
needed to implement only very simple languages. Furthermore, most of the
operations of the machine have a onengtongone correspondence with the operang
tions of a typical RISCngstyle machine. Some operations, such as commit could
be pushed into the proof representation since they have no runngtime effect.

4.7 Some Real World Issues 173
And abstracting other operations, such as malloc, insulates us from details
of the memory management runtime.

Of course, there are a number of simple extensions that could be made
to make the type system a little more useful. For instance, we could annong
tate primitive memory type components with flags to control whether that
component supports readngonly, writengonly, or readngwrite access.

4.7.1 Exercise [n', 3]: Assuming you added type qualifiers for readngonly and writeng

only access to tuple components. How would you change the abstract mang
chine so that you captured their intended meaning? 2

We could also add support for subtyping in a number of ways. For instance,
we could take: ptrD^oe ; oe 0E^ <= ptrD^oe E^. That is, we can safely forget the tail of a
sequence of values, for both ptr and uptr types. We can also consider a readng
write component to be a subtype of a readngonly or a writengonly component.
For shared, readngonly components, we can support covariant deep subtyping,
and for writengonly components, we can have contrangvariant subtyping. Interng
estingly, it is sound to have covariant subtyping on readngwrite components
of unique pointers. All of these extensions were supported in some form for
TALx86.

An issue not addressed here is support for primitive values of sizes less
than a machine word (e.g., a char or short). But this too is relatively easy
to accommodate. The key thing is that we need some function from operand
types to their sizes so that we can determine whether or not a ld or st is
used at the right offset. A slightly more troublesome problem is the issue of
alignment. On many architectures (e.g., the MIPS, SPARC, and Alpha), priming
tive datatypes must be naturally aligned. For instance, a 64ngbit value (e.g., a
double) should be placed on a doublengword boundary. Of course, the comng
piler can arrange to insert padding to ensure this property, if we assume
that malloc places objects on maximally aligned boundaries. Still, we might
need to add a wellngformedness judgment to memory types to ensure that they
respect alignment constraints.

The approach to typing the stack is powerful enough to accommodate
standard procedure calls, but cannot handle nested procedures, even if they
are "downwardngonly" as in Pascal. To support this, we would, in general,
need some form of static pointers back into the stack (or display.) The STAL
type system supports a limited form of such pointers which also provides
the mechanisms needed to implement exceptions (Morrisett et al., 2002).
These extensions were used in the TALx86 implementation. An alternative
approach, based on intersection types, is suggested by Crary's TALT (Crary,
2003) which has the advantage that it better supports stackngallocated obng
jects. A more general approach is to integrate support for regions into the

174 4 Typed Assembly Language

type system in the style of Cyclone (Grossman, Morrisett, Jim, Hicks, Wang,
and Cheney, 2002) or one of the other regionngbased systems described in
Chapter 3.

The original TAL used a different mechanism, based on initialization flags
and subtyping, to support sharedngobject initialization. More recently, the work
of Petersen et al. (2003) provides an approach to initialization based on a
"fuse" calculus. The approach based on initialization flags has the advantage
that uninitialized objects are first class, which is useful in some contexts,
such as "tailngallocation" (Minamide, 1998). Neither our approach based on
unique pointers nor the fuse calculus supports this. Furthermore, neither
approach supports the initialization of circular data structures, which is imng
portant when building recursive closures. These concerns motivated the deng
sign of alias types (Smith, Walker, and Morrisett, 2000) which handles all of
these concerns and more, and which were implemented in TALx86. Recently,
Ahmed and Walker (2003) have suggested yet another approach based on an
embedding of the logic of bunched implications within a type system.

It is possible to add a free instruction to TALng1 which takes a unique
pointer and returns it to the runtime for renguse. In some sense, free is the
ultimate typengchanging operation, for it is simply a way to recycle memory so
that it can later be used to hold values of a different type. Unfortunately, it is
not so easy to provide a free operation for shared pointers.

4.7.2 Exercise [Recommended, n', 3]: Given an example program that could "go

wrong" if we allowed free to operate on shared pointers. 2

As noted earlier, the type system is closed under extensions to the heap,
but not necessarily a shrinking heap. It can be shown that if a location is not
reachable from the registers (or from reachable code) then a heap value can be
safely thrown away. But discovering that this property is true requires more
than a single machine instruction. Indeed, it requires a runngtime examination
of the pointernggraph to determine the unreachable objects.

Therefore, with the introduction of shared data pointers, we are essentially
buying into the need for a garbage collector to effectively recycle memory.
Of course, to support accurate garbage collection requires that we provide
enough information that the collector can determine pointers from other data
values at runngtime. Furthermore, the collector requires knowledge of the size
of heap objects. Finally, many collectors require a number of subtle properng
ties to hold (e.g., no pointers to the interior of heap objects) before they can
be invoked. Capturing all of these constraints in a useful type system is still
somewhat of a challenge.

TALx86 and the proposed TALT use a conservative collector to recycle
memory. Conservative collectors do not require precise information about

4.8 Conclusions 175
which objects are pointers. However, they tend to have leaks, since they someng
times think an integer is a pointer to an unreachable object. Like other collecng
tors, a number of invariants must hold in order for the collection to be sound.
The TALT system formalizes these constraints as part of its type system.

Another possibility is to integrate the Capability types which provide a
general support for regions at the TAL level (Walker, Crary, and Morrisett,
2000). With this type system, it is possible to code up a copying collector
within the language as suggested by Wang and Appel (2001). However, doing
an efficient copying collector requires a bit more technical machinery. Some
of these issues are resolved by Monnier, Saha, and Shao (2001).

Finally, note that, at this point, a paper and pencil proof of the soundness
of a system that incorporates these extensions becomes quite large (and teng
dious) and we are therefore likely to make mistakes. To avoid such pitfalls,
we would be wise to encode the abstract machine and type system in some
formal system where the proof can be verified. For example, Crary encodes
his TALT abstract machine and typing rules using the LF framework (2003)
whereas Hamid et al. have done this using Coq (2002). Another approach
championed by Appel and Felty (2000) is called Foundational Proof Carryng
ing Code, whereby the types are semantically constructed using higherngorder
logic in such a way that they are by definition sound with respect to the
(concrete) machine's semantics.

4.8 Conclusions

Type systems for lownglevel code, including compiler intermediate languages
and target languages, are an exciting area of research. In part, this is because
the "human constraint" is lifted since the typing annotations are produced
and consumed by machines instead of humans. That is, we do not have to
worry about the type system being too complicated for the average programng
mer, or that it requires too many typing annotations. These concerns often
dominate the design of type systems for highnglevel languages. Of course, it
is still important to keep the design as simple and orthogonal as possible
so that we can construct proofs of soundness and have confidence in the
implementation. Ideally, proofs should be carried out in a machinengchecked
environment.

Lownglevel languages also present new challenges to type system designers.
For instance, the issues of initialization and memory recycling are of little
concern in highnglevel languages, since these details are meant to be handled
by the compiler and runngtime system. Yet, the nittynggritty details of the runng
time system are crucial for the proper functioning of the system.

5 ProofngCarrying Code

George Necula

In the previous chapter we saw that one can adapt many of the ideas from
type systems for highnglevel languages to assembly language. In this chapter,
we describe yet another technique that can be used to type check assembly
language programs. This time, however, we are going to depart from trading
tional typengchecking approaches and see how one can adapt ideas from prong
gram verification to this problem. In the process of doing so, we are going
to obtain a framework that can be adapted more easily to the verification of
code properties that go beyond type safety.

5.1 Overview of Proof Carrying Code

ProofngCarrying Code (PCC) (Necula, 1997; Necula and Lee, 1996) is a general
framework that allows the host to check quickly and easily that the agent has
certain safety properties. The key technical detail that makes PCC powerful is
a requirement that the agent producer cooperates with the host by attaching
to the agent code an "explanation" of why the code complies with the safety
policy. Then all that the host has to do to ensure the safe execution of the
agent is to define a framework in which the "explanation" must be conducted,
along with a simple yet sufficiently strong mechanism for checking that (a) the
explanation is acceptable (i.e., is within the established framework), that (b)
the explanation pertains to the safety policy that the host wishes to enforce,
and (c) that the explanation matches the actual code of the agent.

There are a number of possible forms of explanations each with its own
advantages and disadvantages. Safety explanations must be precise and comng
prehensive, just like formal proofs. In fact, in this chapter, the explanations
are going to be formal proofs encoded in such a way that they can be checked
easily and reliably by a simple proof checker.

178 5 ProofngCarrying Code

There are several ways to implement the PCC concept, and all share the
common requirement that the untrusted code contains information whose
purpose is to simplify the verification task. At one extreme, we have the JVML
and CLI verifiers, which rely on typing declarations present in the untrusted
code to check the safety of the code. The KVM (Sun) implementation of the
JVML verifier does further require that the code contains loop invariants in
order to simplify and speed up the verification. Typed Assembly Language
(described in Chapter 4) pushes these ideas to the level of assembly language.
The most general instance of PCC, called Foundational ProofngCarrying Code
(FPCC) (Appel, 2001; Appel and Felty, 2000), reduces to a minimum the size
of the verifier and puts almost the entire burden of verification on the agent
producer, who now has to produce and send with the agent detailed proofs
of safety. In this chapter, we describe an instantiation of PCC that is similar
to TAL in that it operates on agents written in assembly language, and is
similar to FPCC in that it requires detailed proofs of safety to accompany the
agent code. However, the architecture that we describe here uses a verifier
that is more complex than that of FPCC, and thus somewhat less trustworthy.
However, the advantage of this architecture is that is places a smaller burden
on the agent producer than FPPC, and has been shown to scale to verifying
even very large programs (Colby et al., 2000). We are going to refer to this
architecture as the Touchstone PCC architecture.

A highnglevel view of the architecture of the Touchstone PCC system is
shown in Figure 5ng1. The agent contains, in addition to its executable conng
tent, checkingngsupport data that allows the PCC infrastructure resident on
the receiving host to check the safety of the agent. The PCC infrastructure is
composed of two main modules. The verificationngcondition generator (VCGen)
scans the executable content of the agent and checks directly simple syntactic
conditions (e.g., that direct jumps are within the code boundary). Each time
VCGen encounters an instruction whose execution could violate the safety
policy, it asks the Checker module to verify that the dangerous instruction
executes safely in the actual current context.

In order to construct a formal proof of a program, we need to reason about
them using mathematical concepts. VCGen "compiles" programs to logical
formulae in such a way that the aspects of the execution of the program that
are relevant to the security policy are brought out.

VCGen can be quite simple because it relies on the Checker to verify comng
plex safety requirements. There are some cases, however, when VCGen might
have to understand complex invariants of the agent code in order to follow its
control and data flow. For example, VCGen must understand the loop strucng
ture of the agent in order to avoid scanning the loop body an unbounded
number of times. Also, VCGen must be able to understand even obscure conng

5.1 Overview of Proof Carrying Code 179
Figure 5ng1: The Touchstone PCC architecture
trol flow, as in the presence of indirect jumps or function pointers. In such
situations, VCGen relies on code annotations that are part of the checking
support and are packaged with the agent. This puts most of the burden of
handling the complex controlngflow issues on the agent producer and keeps
the VCGen simple.

The Checker module verifies for VCGen that all dangerous instructions are
used in a safe context. The Checker module described in this chapter requires
that VCGen formulates the safety preconditions of the dangerous instrucng
tions as formulas in a logic. We call these formulas the verification conditions.
The Checker expects to find in the checkingngsupport data packaged with the
agent a formal proof that the safety precondition is met. For the verification
to succeed, the Checker must verify the validity of the verificationngcondition
proofs for all dangerous instructions identified by VCGen.

The Touchstone PCC infrastructure described here can be customized to
check various safety policies. The "Safety Policy" element in Figure 5ng1 is a
collection of configuration data that specifies the precise logic that VCGen
uses to encode the verification conditions, along with the trusted proof rules
that can be used in the safety proofs supplied by the agent producer. For
example, the host might require that the untrusted code interacts correctly
with the runtime system of a Java Virtual Machine. This can be enforced in

180 5 ProofngCarrying Code

type maybepair = Int of int | Pair of int * int
let rec sum(acc : int, x : maybepair list) =

match x with
| nil ! acc
| (Int i) :: tail ! sum(acc + i, tail)
| (Pair (l, r)) :: tail ! sum (acc + l + r, tail)

Figure 5ng2: OCaml source for the example agent

our system by a safety policy requiring that the code is wellngtyped with reng
spect to the typing rules of Java. It is important to separate the safety policy
configuration data from the rest of the infrastructure both for conceptual and
for engineering reasons. This architecture allows the infrastructure to work
with multiple safety policies, without changing most of the implementation.

An Example Agent
In the rest of this chapter, we explore the design and implementation details
of the PCC infrastructure. The infrastructure can be configured to check many
safety policies. In the example that we use here, we check a simple typengsafety
policy for an agent written in a generic assembly language. The agent is a
function that adds all the elements in a list containing either integers or pairs
of integers. If this agent were written in OCaml, its source code might be as
shown Figure 5ng2.

In order to write the agent in assembly language, we must decide what
is the representation strategy for lists and for the maybepair type. For the
purpose of this example, we represent a list as either the value 0 (for the
empty list), or a pointer to a twongword memory area. The first word of the
memory area contains a list element, and the second element contains the
tail of the list. In order to represent an element of type maybepair in an
economical way we ensure that any element of kind PairD^x; yE^ is an evenng
valued pointer to a twongword memory area containing x and y. We represent
an element of kind Int x as the integer 2x + 1 (to ensure that it is odd and
thus distinguishable from a pair). For example, the representation of the list
[Int 2; Pair (3, 4)] has the concrete representation shown in Figure 5ng3.
Notice the tagged representation of the Int 2 element of the list.

In our examples, we will use the simple subset of a generic assembly lanng
guage shown below. The expressions e contain arithmetic and logic operang
tions involving constants and registers. This is the same assembly language

5.1 Overview of Proof Carrying Code 181
Figure 5ng3: Concrete representation of the list [Int 2; Pair (3, 4)]
that was used in Chapter 4, except that we relax slightly the syntax of memng
ory addresses, and we replace the general form of indirect jump with a return
instruction.

rx :C^ e assign the result of e to register rx
rx :C^ MemE,eG* load rx from address e
MemE,e0G* :C^ e store the result of e to address e0
jump L jump to a label L
if e jump L branch to label L if e is true
return return from the current function

Given our representation strategy and the choice of assembly language inng
structions, the code for the agent is shown in Figure 5ng4. On entry to this code
fragment, registers rx and racc contain the value of the formal arguments x
and acc respectively. The code fragment also uses temporary registers rt and
rs. To simplify the handling of the return instruction, we use the convention
that the return value is always contained in the register rR.

The safety policy in this case requires that all memory reads be from pointng
ers that are either nonngnull lists, in which case we can read either the first or
the second field of a list cell, or from pointers to elements of the Pair kind.
In the case of a memory write, the safety policy constrains the values that can
be written to various addresses as follows: in the first word of a list cell we
can write either an odd value or an even value that is a pointer to an element
of Pair kind, and in the second word of a list cell we can write either zero
or a pointer to some list cell. There are no constraints on what we can write
to the elements of a Pair. The restrictions on memory writes ensure that
the contents of the accessible memory locations is consistent with the type
assigned to their addresses.

The safety policy specifies not only requirements on the agent behavior but
can also specify assumptions that the agent can make about the context of
the execution. In the case of our agent, the safety policy might specify that
the contents of the register rx on entry is either zero or a pointer to a list

182 5 ProofngCarrying Code

1 sum: ; rx : maybepair list
2 Loop:
3 if rx T^ 0 jump LCons ; Is rx empty?
4 rR :C^ racc
5 return
6 LCons: rt :C^ MemE,rxG* ; Load the first data
7 if evenD^rtE^ jump LPair
8 rt :C^ rt div 2
9 racc :C^ racc + rt
10 jump LTail
11 LPair: rs :C^ MemE,rtG* ; Get the first pair element
12 racc :C^ MemE,racc + rsG*
13 rt :C^ MemE,rt + 4G* ; and the second element
14 racc :C^ racc + rt
15 LTail: rx :C^ MemE,rx + 4G*
16 jump Loop

Figure 5ng4: Assembly code for the function in Figure 5ng2

cell. Also, the safety policy can allow the agent to assume that the value read
from the first word of a list cell is either odd or otherwise a pointer to a Pair
cell. Similarly, the agent can assume that the value it reads from the second
word of a cell is either null or else a pointer to a list cell. We formalize this
safety policy in the next section.

5.2 Formalizing the Safety Policy

At the core of a safety policy is a list of instructions whose execution may
violate safety. The safety policy specifies, for each one, what is the verification
condition that guarantees its safe execution. In the variant of PCC described
here, the instructions that are handled specially are the memory operations
along with the function calls and returns. This choice is hard coded in the
verificationngcondition generator. However, the specific verification condition
for each of these instructions is customizable. In such an implementation, we
can control very precisely what memory locations can be read, what memory
locations can be written and what can be written into them, what functions
we call and in what context, and in what context we return from a function.
This turns out to be sufficient for a very large class of safety policies. We shall
explore in Section 5.7 a safety policy for which this is not sufficient and for
which we must change the verification condition generator.

5.2 Formalizing the Safety Policy 183

The customizable elements of the safety policy are the following:

* A language of symbolic expressions and formulas that can be used to exng

press verification conditions.

* A set of function preconditions and postconditions for all functions that

form the interface between the host and the agent.

* A set of proof rules for verification conditions.

In the rest of this section we describe in turn these elements.

The Syntax of the Logic
For this presentation we use a firstngorder language of symbolic expressions
and formulas, as shown below:

Formulas F ::C^ true | F1 ^ F2 | F1 . F2 | F1 ) F2 | 8x:F | 9x:F

| addr Ea | E1 C^ E2 | E1 T^ E2 | f E1 : : : En
Expressions E ::C^ x | sel Em Ea | upd Em Ea Ev | f E1 : : : En

We consider here only the subset of logical connectives that we need for
examples. In practice, a full complement of connectives can be used. The
formula D^addr EaE^ is produced by VCGen as a verification condition for a
memory read or a memory write to address Ea. This formula holds whenever
Ea denotes a valid address. Formulas can also be constructed using a set of
formula constructors that are specific to each safety policy.

The language of expressions contains variables and a number of construcng
tors that includes integer numerals and arithmetic operators, and can also be
extended by safety policies. A notable expression construct is D^sel Em EaE^
that is used to denote the contents of memory address denoted by Ea in
memory state Em. The construct D^upd Em Ea EvE^ denotes a new memory state
that is obtained by storing the value Ev at address Ea in memory state Em.
For example, the contents of the address c in a memory that is obtained from
memory state m after writing the value 1 at address a followed by writing of
value 2, can be written:

sel D^upd D^upd m a 1E^ b 2E^ c
A safety policy extends the syntax of the logic by defining new expression
and formula constructors. In particular, for our example agent we add conng
structors for encoding types and a predicate constructor for encoding the
typing judgment:

Word types W ::C^ int | ptr {S} | list W | {x | FD^xE^}
Structure types S ::C^ W | W ; S
Formulas F ::C^ : : : | E : W | listinv Em

184 5 ProofngCarrying Code

We distinguish among types the word types, whose values fit in a machine
register or memory word. Pointers can point to an area of memory containing
a sequence of words. The word type {x | FD^xE^} contains all those values for
which the formula F is true (this type is sometimes called a comprehension
or set type). The typing formula constructor ":" is written in infix notation.
We also add the listinv formula constructor that will be used to state that
the contents of the memory satisfies the representation invariant for lists of
pairs. The precise definition of the typing and the listinv formulas will be
given on page 200, with respect to a predetermined mapping of values and
memory addresses to types. Informally, we say that listinv M holds when
each memory address that is assigned a pointer type contains values that are
assigned appropriate types.

Using these constructors we can write the lownglevel version of the ML typing
judgment x : maybepair list as

x : list {y | D^even yE^ ) y : ptr {int; int}}
In the rest of this section we use the abbreviation mp_list for the type
maybepair list. Notice that we have builtngin the recursive type of lists in
our logic, in order to avoid the need for recursion at the level of the logic, but
we choose to express the union and tuple types explicitly.

5.2.1 Exercise [Recommended, n']: The singleton type is a type populated by a

single value. Write a formula in the above logic corresponding to the assertion
that x has type singleton for the value v. Show also how you can write using
our language of types the singleton type for the value v. 2

5.2.2 Exercise [Recommended, n']: Consider an alternative representation for the

maybepair type. A value of this type is a pointer to a tagged memory area
containing a tag word followed either by another word encoding an Int if the
tag value if 0, or by two words encoding a Pair if the tag value is 1. Write the
formula corresponding to the assertion that x has this representation. 2

The Preconditions and Postconditions
A PCC safety policy contains preconditions and postconditions for the funcng
tions that form the interface between the agent and the host. These are either
functions defined by the agent and invoked by the host or library functions
exported by the host for use by the agent. These preconditions and postconng
ditions are expressed as logic formulas that use a number of formula and
expression constructors specific to the safety policy.

Function preconditions and postconditions at the level of the assembly
language are expressed in terms of argument and return registers, and thus

5.2 Formalizing the Safety Policy 185
specify also the calling convention. For verification purposes, we model the
memory as a pseudongregister rM .

The function precondition and postcondition for our agent are:

Presum C^ rx : mp_list ^ listinv rM
Postsum C^ listinv rM

The safety policy requires that the memory state be wellngtyped after the agent
returns and allows the agent to assume that the memory state is wellngtyped
when the host invokes it. Notice that we do not specify constraints on the
integer arguments and results. This reflects our decision that any value whatng
soever can be used as an integer.

Technically, the preconditions and postconditions are not wellngformed forng
mulas in our logic because they use register names as expressions. However,
we can obtain valid formulas from them once we have a substitution of regng
ister names with expressions. We shall see later how this works out in detail.

5.2.3 Exercise [Recommended, n']: Write the precondition and postcondition of a

function of OCaml type (int * int) * int list ! int list. The first
argument is represented as a pointer to a sequence of two integers; the secng
ond is a list. Consider that the return value is placed in register rR. 2

5.2.4 Exercise [Recommended, n']: Consider a function that takes in register r1 a

pointer to a sequence of integer lists. The length of the sequence is passed
in register r2. The function does not return anything. Write the precondition
and postcondition for this function. 2

The Proof Rules
The last part of the safety policy is a set of proof rules that can be used to reang
son about formulas in our logic in general and about verification conditions
in particular. In Figure 5ng5 we show, in natural deduction form, a selection of
the derivation rules for the firstngorder logical connectives. We show the conng
junction introduction (andi) and the two conjunction eliminations (andel,
ander), and the similar rules for implication. We also have two rules (mem0
and mem1) that allow us to reason about the sel and upd constructors for
memory expressions. These two rules should not be necessary for most typeng
based safety policies because in those cases all we care to know about the
contents of a memory location is its type, not its value.

Note that in this set of base proof rules we do not yet specify when we can
prove that addr holds. This is the prerogative of the safetyngpolicy specific
rules that we describe next.

186 5 ProofngCarrying Code

F1 F2

F1 ^ F2 (andi)
F1 ^ F2

F1 (andel)
F1 ^ F2

F2 (ander)

F1

...

F2
F1 ) F2 (impi)
F1 ) F2 F1

F2 (impe)
A C^ A0
sel D^upd M A V E^ A0 C^ V (mem0)

A T^ A0
sel D^upd M A V E^ A0 C^ sel M A0 (mem1)

Figure 5ng5: Builtngin proof rules

Each safety policy can extend the builtngin proof rules with new rules. In fact,
this is necessary if the safety policy uses formula constructors beyond the
builtngin ones. The rules specific to our safety policy are shown in Figure 5ng6.
We have rules for reasoning about the type constructors: lists (nil, cons),
set types (set) and pointers to sequences (this and next). These are similar
to corresponding rules from type systems with recursive types and tuples.
Next come two rules for reasoning about the typing properties of reading
and writing from pointers. The rule sel says that the location referenced by a
pointer to a word type in a wellngtyped memory state has the given word type.
The rule upd is used to prove that a wellngtyped write preserves wellngtypedness
of memory. These rules are similar to corresponding rules for reference types.

Notice that these proof rules are exposing more concrete implementation
details than the corresponding sourcenglevel rules. For example, the cons rule
specifies that a list cell is represented as a pointer to a pair of words, of which
the first one stores the data and the second the tail of the list.

Finally, the ptraddr rule relates the safetyngpolicy specific formula conng
structors with the builtngin addr memory safety formula constructor. This rule
says that addresses that can be proved to have pointer type in our type sysng
tem are valid addresses. And since this is the only rule whose conclusion
uses the addr constructor, the safety policy is essentially restricting memory
accesses to such addresses.

5.2.5 Exercise [Recommended, n'n']: Add a new array type constructor to our

safety policy and write the proof rules for its usage. An array is represented

5.3 VerificationngCondition Generation 187
0 : list W (nil)
E : list W E T^ 0

E : ptr {W ; list W } (cons)

E : {y | FD^yE^}

FD^EE^ (set)
E : ptr {W ; S}

E : ptr {W } (this)

E : ptr {W ; S}
E + 4 : ptr {S} (next)
A : ptr {W } listinv M

D^sel M AE^ : W (sel)
listinv M A : ptr {W } V : W

listinv D^upd M A V E^ (upd)

A : ptr {W }

addr A (ptraddr)

Figure 5ng6: Proof rules specific to the example safety policy

as a pointer to a memory area that contains the number of elements in the
array in the first word and then the array elements in order. Consider first
the case where each element is a word type (as in OCaml), and then the case
when each element can be a structure (as in C). 2

We have shown here just a few of the rules for a simple safety policy.
A safety policy for a full language can easily have hundreds of proof rules.
For example, the Touchstone implementation of PCC for the Java type sysng
tem (Colby et al., 2000) has about 150 proof rules.

5.3 VerificationngCondition Generation

So far, we have shown how to set up the safety policy; now we need to deng
scribe a method for enforcing it. An analogous situation in the realm of highng
level type systems is when we have setup a type system, with a language of
types and a set of typing rules, and we need to design a type checker for
it. A type checker must scan the code and must know what typing rule to
apply at each point in the code. In fact, some type checkers work by explicng
itly collecting typing constraints that are solved in a separate module. Our
PCC infrastructure accomplishes a similar task, and separates the scanning
of the code from the decision of what safety policy proof rules to apply. The
scanning is done by the verificationngcondition generator, which also identifies
what must be checked for each instruction. How the check is performed is
decided by the Checker module, with considerable help from the proof that
accompanies the code. In a regular type checker, there is no pressing need
to separate code scanning from the construction of the typing derivation,

188 5 ProofngCarrying Code

since the scanning process is often simple and the structure of the typing
derivation closely follows that of the code. This is not true for lownglevel type
checking. In fact, programs written in assembly language may have very little
structure.

To illustrate some of the difficulties of type checking lownglevel code, conng
sider the following fragment of code written in ML, where x is a variable
of type T list and the variable t occurs in the expression e also with type
T list:

match x with

_ :: t ! e

A type checker for ML parses this code, constructs an abstract syntax tree
(AST) and then it verifies its wellngtypedness in a relatively simple manner by
traversing the AST. This is possible because the match expression packages
in one construction all the elements that are needed for type checking: the
expression to be matched, the patterns with the variables they define, and the
bodies of the cases.

Consider now one particular compilation of this code fragment:

rt :C^ rx
rt :C^ rt + 4
if rx C^ 0 jump LNil
rt :C^ MemE,rtG*
:::

We assume that the variable x is allocated to register rx and that the exng
pression e is compiled with the assumption that, on entry, the variable t is
allocated to the register rt. We observe that the code for compiling the match
construct is spread over several nonngcontiguous instructions mixed with the
instructions that implement the cases themselves. This is due to the intrinsing
cally sequential nature of assembly language. It would be hard to implement
a type checker for assembly language that identifies the code for the match
by recognizing patterns, as a sourcenglevel type checker does. Also, such a type
checker would be sensitive to code generation and optimization choices.

Another difficulty is that some highnglevel operations are split into several
small operations. For example the extraction of the tail of the list is separated
into the computation of an address in register rt and a memory load. We
cannot check one of the two instructions in isolation of the other because they
both can be used in other contexts as well. Furthermore, it is not sufficient
to type check the addition rt + 4 as we would do in a highnglevel language
(i.e., verify that both operands have compatible arithmetic types). Instead we
need to remember that we added the constant 4 to the contents of register
rx, so that when we reach the load instruction, we can determine that we

5.3 VerificationngCondition Generation 189
are loading the second word from a list cell. Additionally, our typengchecking
algorithm has to be flow sensitive and path sensitive because the outcomes
of conditional expressions sometimes determine the type of values. In our
example, if the conditional falls through then we know that rx points to a
list cell and therefore that rt points to the second element in a list cell. If,
however, the conditional jumps to LNil, then we cannot even assign a type
to rt after the addition.

Yet another complication with assembly language is that, unlike in highng
level languages, we cannot count on a variable having a single type throughng
out its scope. In assembly language the registers play the role of variables and
since there is a finite number of them, compilers reuse them aggressively to
hold different data at different program points. In our example, the register
rt is used before the load to hold both a pointer to a memory location conng
taining a list and after the load instruction to hold a list. We must thus keep
different types for registers for different program points. Chapter 4 discusses
these problems extensively.

There are a number of approaches for overcoming these difficulties. All of
them do maintain different types for registers at different program points but
differ on how they handle the dependency on conditionals and the splitting
of highnglevel operations into several instructions. At one extreme is the Java
Bytecode Verifier (Lindholm and Yellin, 1997), which typechecks programs
written in the Java Virtual Machine Language (JVML). The JVML is relatively
highnglevel and maintains complicated operations bundled in highnglevel conng
structs. For instance, in JVML you cannot separate the address computation
from the memory access itself. In the context of our example, this means that
the addition and the load instruction would be expressed as one bytecode inng
struction. The JVML is designed such that the outcome of conditionals does
not matter for type checking. For example, arrayngbounds checks and pointer
nullngchecks are bundled with the memory access in highnglevel bytecode inng
structions. This approach simplifies the typengchecking problem but has the
disadvantage that the agent producer cannot really do much optimization.
Also this approach puts more burden on the code receiver for compiling and
optimizing the code.

Another approach is Typed Assembly Language (TAL), described in Chapng
ter 4, where a more sophisticated type system is used to keep track of the inng
termediate result of unbundled instructions. But even in TAL some lownglevel
instructions are treated as bundles for the purpose of verification. Examples
are memory allocation and array accesses.

Here we are going to describe a type checking method that can overcome
the difficulties described above. The method is based on symbolic evaluation,
and it was originally used in the context of program verification. The method

190 5 ProofngCarrying Code

is powerful enough to verify full correctness of a program, not just its wellng
typedness, which will come in handy when we consider safety policies beyond
type safety.

Symbolic Evaluation
In order to introduce symbolic evaluation, consider the code fragment from
above but without the conditional.

rt :C^ rx
rt :C^ rt + 4
rt :C^ MemE,rtG*

This fragment exhibits the problems due to reuse of registers with different
types and the splitting of highnglevel operations into lownglevel instructions.
We have already observed that it is more important to remember the effect of
the addition instruction than it is to type check it immediately as we see it. In
fact, we are going to postpone all checking as much as possible and are going
to focus on "remembering" the effect of instructions instead. Observe that if
we allow arbitrary complex operands in our instructions, we can rewrite the
above code sequence as follows:

rt :C^ MemE,rx + 4G*
In this variant, the address computation is bundled with the memory access,
and we can actually perform the usual pattern matching to recognize what
typing rule to apply. Symbolic evaluation is a technique that has the effect of
collecting the results of intermediate computations to create the final result
as a complex expression whose meaning is equivalent to the entire computang
tion. A symbolic evaluator is an interpreter that maintains for each register a
symbolic expression. We will use the symbol oe to range over symbolic states,
which are mappings from register names to symbolic expressions. The symng
bolic state is initialized with a distinct fresh variable for each register, to
model the lack of information about the initial values of the registers. For
our example the initial symbolic state is:

oe0 C^ {rt C^ t; rx C^ x; rM C^ m}
where t and x are distinct fresh variables. Technically, this symbolic state
says that at the given program point the following invariant holds:

9t:9x:9m:rt C^ t ^ rx C^ x ^ rM C^ m
The symbolic evaluator proceeds forward to interpret the instructions and
modifies the symbolic state as specified by the instruction. We show below
the sequence of symbolic states during symbolic evaluation.

5.3 VerificationngCondition Generation 191

oe C^ {rt C^ t; rx C^ x; rM C^ m}
rt :C^ rx

oe C^ {rt C^ x; rx C^ x; rM C^ m}
rt :C^ rt + 4

oe C^ {rt C^ x + 4; rx C^ x; rM C^ m}
rt :C^ MemE,rtG*

oe C^ {rt C^ D^sel m D^x + 4E^E^; rx C^ x; rM C^ m}

When the instruction "rt :C^ rx" is processed, the symbolic evaluator looks
up the value of rx in the current symbolic state and then sets rt to that
value. Notice how at the time the load instruction is processed, the symbolic
evaluator can figure out that the address being accessed is x + 4.

In order to handle memory reads and writes we use a pseudongregister rM
and the sel and upd constructors introduced in Section 5.2. For memory
loads and writes, the symbolic evaluator also emits the required verification
conditions using the addr constructor. For example, the verification condition
for the load instruction would be D^addr D^x + 4E^E^.

Another element of interest is the handling of conditionals. In order to
allow for path sensitive checking the symbolic evaluator maintains, in adng
dition to the symbolic state, a list of assumptions about the state. These
assumptions are simply formulas involving the same existentially quantified
variables that the symbolic state uses. As the symbolic evaluator follows the
branches of a conditional, it extends the list of assumptions with formulas
that capture the outcome of the conditional expression.

If we now add back the conditional instruction in our example, the symbolic
state and the set of assumptions (initially A) at each point are shown below:

oe C^ {rt C^ t; rx C^ x; rM C^ m}; A
rt :C^ rx

oe C^ {rt C^ x; rx C^ x; rM C^ m}; A
rt :C^ rt + 4

oe C^ {rt C^ x + 4; rx C^ x; rM C^ m}; A
if rx C^ 0 jump LNil

oe C^ {rt C^ x + 4; rx C^ x; rM C^ m}; A ^ x T^ 0
rt :C^ MemE,rtG*

oe C^ {rt C^ sel m D^x + 4E^; rx C^ x; rM C^ m}; A ^ x T^ 0
:::
LNil: oe C^ {rt C^ x + 4; rx C^ x; rM C^ m}; A ^ x C^ 0

The symbolic state immediately before the load instruction essentially states
that the following invariant holds at that point:

9t:9x:9m:rt C^ x ^ rx C^ x + 4 ^ rM C^ m ^ A ^ x T^ 0

192 5 ProofngCarrying Code

This means that the Checker module would have to check the following
verification condition for the load instruction:

8t:8x:8m:D^rt C^ x ^ rx C^ x + 4 ^ rM C^ m ^ A ^ x T^ 0E^ ) addr D^x + 4E^
Symbolic evaluation has many applications in program analysis. In the folng
lowing two exercises you can explore how one can use symbolic evaluation to
verify easily the correctness of some code transformations.

5.3.1 Exercise [Recommended, n']: Consider the following two code fragments.

The one on the right has been obtained from the one on the left by perng
forming a few simple local optimizations. First, we did register allocations,
by renaming register ra, rb, rc, and rd to r1, r2, r3 and r4 respectively. Then
we removed the dead instruction from line 1. We performed copy propang
gation followed by common subexpression elimination in line 5. Finally, we
performed instruction scheduling by moving the instruction from line 3 to be
the last in the block.

1 ra :C^ 2
2 ra :C^ rb + 1
3 rc :C^ ra + 2
4 rd :C^ 1
5 rd :C^ rb + rd

r1 :C^ r2 + 1
r4 :C^ r1
r3 :C^ r1 + 2

Show that the result of symbolic evaluation for the registers live at the end of
the two basic blocks is identical if you start with symbolic states {rb C^ b} and
{r2 C^ b} respectively. This suggests that symbolic evaluation is insensitive to
some common optimizations. 2

5.3.2 Exercise [Recommended, n']: Now consider the first code fragment shown

in Exercise 5.3.1 and add the instruction "ra :C^ 3" immediately before line 5.
In this case it is not correct to perform commonngsubexpression elimination.
Show now that the result of symbolic evaluation is different for the modified
code fragment and the transformed code from Exercise 5.3.1. This suggests
that symbolic evaluation can be use to verify the result of compiler optimizang
tions. This technique is in fact so powerful that it can be used to verify most
optimizations that the GNU C compiler performs (Necula, 2000). 2

Before we can give a complete formal definition of the VCGen, we must
consider what happens in the cases when the symbolic evaluator should not
follow directly the controlngflow of the program. Two such cases are for loops
(when following the controlngflow would make VCGen loop forever) and for
functions (when it is desirable to scan the body of a function only once). In
order to handle those cases, VCGen needs some assistance from the agent
producer, in the form of code annotations.

5.3 VerificationngCondition Generation 193
The Role of Program Annotations
The VCGen module attempts to execute the untrusted program symbolically
in order to signal all potentially unsafe operations. To make this execution
possible in finite time and without the need for conservative approximations
on the part of VCGen, we require that the program be annotated with invaring
ant predicates. At least one such invariant must be specified for each cycle
in the program's controlngflow graph. An easy but conservative way to enforce
such a constraint is to require an invariant annotation for every backward
branch target.

The agent code shown in Figure 5ng4 has one loop whose body starts at the
label Loop. There must be one invariant annotation somewhere in that loop.
Let us say that the agent producer places the following invariant at label Loop:

Loop: INV C^ rx : mp_list ^ listinv rM
The invariant annotation says that whenever the execution reaches the lang
bel Loop the contents of register rx is a list. It also says that the contents
of the memory satisfies the representation invariants of lists. Just like the
preconditions and postconditions, the invariants can refer to register names.

A valid question at this point is who discovers this annotation and how.
There are several possibilities. First, annotations can be inserted by hand by
the programmer. This is the only alternative when the agent code is prong
grammed directly in assembly language or when the programmer wants to
handngoptimize the output of a compiler. It is true that this method does not
scale well, but it is nevertheless a feature of PCC that the code receiver does
not care whether the code is produced by a trusted compiler, and will gladly
accept code that was written or optimized by hand.

Another possibility is that the annotations can be produced automatically
by a certifying compiler. For our simple type safety policy the only annotang
tions that are necessary consist of type declarations for the live registers at
that point. See Necula (1998) for more details.

Finally, note that the invariant annotations are required but cannot be
trusted to be correct as they originate from the same possibly untrusted
source as the code itself. Nevertheless, VCGen can still use them safely, as
described in the next section.

The VerificationngCondition Generator
Now we have all the elements necessary to describe the verificationngcondition
generator for the case of one function whose precondition and postcondition
are specified by the safety policy. We will assume that each invariant annotang

194 5 ProofngCarrying Code

tion occupies one instruction slot, even though in practice they are stored in
a separate region of the agent. Let Inv be the partial mapping from program
counters to invariant predicates. If i 2 DomD^InvE^, then there is an invariant
Invi at program counter i. Next, for a more uniform treatment of functions
and loops, we will consider that the first instruction in each agent function
is an invariant annotation with the precondition predicate. In our example,
this means that Inv1 C^ rx : mp_list ^ listinv rM . This, along with the loop
invariant (with the same predicate) at index 2 are all the loop invariants in
the example. Thus, DomD^InvE^ C^ {1; 2}, and the first few lines of our agent
example are modified as follows:

1 sum: INV rx : mp_list ^ listinv rM
2 Loop: INV rx : mp_list ^ listinv rM
3 if rx T^ 0 jump LCons ; list is empty

Given a symbolic state oe and an expression e that contains references to
register names, we write D^oe eE^ to denote the result of substituting the regisng
ter names in e with the expressions given by oe . We extend this notation to
formulas F that refer to register names (e.g., function preconditions or postng
conditions, or loop invariants). We also write oe E,r  eG* to denote a symbolic
state that is the same as oe but with register r mapped to e.

We write \Pi i for the instruction (or annotation) at the program counter i.
The core of the verificationngcondition generator is a symbolic evaluation
function SE that given a value i for the program counter and a symbolic state
oe , produces a formula that captures all of the verification conditions from
the given program counter until the next return instruction or invariant. The
definition of the SE function is shown below:

SED^i; oe E^ C^

8??????????
??????!?
?????????????
??:

SED^i + 1; oe E,r  oe eG*E^ if \Pi i C^ r :C^ e
D^oe eE^ ) SED^L; oe E^ ^ if \Pi i C^ if e jump L

D^not D^oe eE^E^ ) SED^i + 1; oe E^
addr D^oe aE^ ^ if \Pi i C^ r :C^ MemE,aG*

SED^i + 1; oe E,r  D^oe D^sel rM aE^E^G*E^
addr D^oe aE^ ^ if \Pi i C^ MemE,aG* :C^ e

SED^i + 1; oe E,rM  D^oe D^upd rM a eE^E^G*
oe Post if \Pi i C^ return
oe I if \Pi i C^ INV I

Symbolic evaluation is defined by case analysis of the instruction contained
at a given program counter. Symbolic evaluation is undefined for values of
the program counter that do not contain a valid instruction. In the case of a
set instruction, the symbolic evaluator substitutes the current symbolic state
into the rightnghand side of the instruction and then uses the result as the new

5.3 VerificationngCondition Generation 195
value of the destination register. Then the symbolic evaluator continues with
the following instruction. For a conditional, the symbolic evaluator adds the
proper assumption about the outcome of the conditional expression. Memory
operations are handled like assignments but with the generation of additional
verification conditions.

When either the return instruction or an invariant is encountered, the symng
bolic evaluator stops with a predicate obtained by substituting the current
symbolic state into the postcondition or the invariant formula. The symbolic
evaluator also ensures (using a simple check not shown here) that each loop
in the code has at least one invariant annotation. This ensures the termination
of the SE function.

What remains to be shown is how the verificationngcondition generator uses
the SE function. For each invariant in the code, VCGen starts a symbolic evalng
uation with a symbolic state initialized with distinct variables. Assuming that
the set of registers is {r1; : : : ; rn}, we define the global verification condition
VC as follows:

V C C^ Vi2DomD^InvE^ 8x1 : : : xn: oe0 Invi ) SED^i + 1; oe0E^

where oe0 C^ {r1 C^ x1; : : : ; rn C^ xn}

Essentially the VCGen evaluates symbolically every path in the program
that connects two invariants or an invariant and a return instruction. In Figng
ure 5ng7 we show the operation of the VCGen algorithm on the agent code from
Figure 5ng4 (after we have added the invariant annotations for the preconding
tion and the loop, as explained at the beginning of this section). We show on
the left the program points and a brief description of each action. Some acng
tions result in extending the stack of assumptions that the Checker is allowed
to make. These assumptions are shown underlined and with an indentation
level that encodes the position in the stack of each assumption. Thus an
assumption at a given indentation level implicitly discards all previously ocng
curring assumptions at the same or larger indentation level. Finally, we show
rightngjustified and boxed the checking goals submitted to the Checker.

There are two invariants (in lines 1 and 2) and for each one we generate
fresh new variables for registers, we assume that the invariant holds, and
then we start the symbolic evaluator. For the first invariant, the symbolic
evaluator when starting in line 2 encounters an invariant and terminates.

Every boxed formula shown flushed right in Figure 5ng7 is a verification
condition that VCGen produces and the Checker module has to verify for
some arbitrary values of the initial variables.

Notice that the invariant formulas are used both as assumptions and as
verification conditions. There is a strong similarity between the role of inng
variants and that of predicates in a proof by induction. In the latter case the

196 5 ProofngCarrying Code

1: Generate fresh values rM C^ m0, rR C^ r0, rx C^ x0, racc C^ acc0,

rt C^ t0 and rs C^ s0
1: Assume Invariant x0 : mp_list

listinv m0
2: Invariant x0 : mp_list

listinv m0
2: Generate fresh values rM C^ m1, rR C^ r1, rx C^ x1, racc C^ acc1,

rt C^ t1 and rs C^ s1
2: Assume Invariant x1 : mp_list

listinv m1
3: Branch 3 taken x1 T^ 0
6: Check load addr x1
7: Branch 7 taken even D^sel m1 x1E^
11: Check load addr D^sel m1 x1E^
13: Check load addr D^D^sel m1 x1E^ + 4E^
15: Check load addr D^x1 + 4E^
16: Goto Loop
2: Invariant D^sel m1 D^x1 + 4E^E^ : mp_list

listinv m1
7: Branch 7 not taken odd D^sel m1 x1E^
10: Goto LTail
15: Check load addr D^x1 + 4E^
16: Goto Loop
2: Invariant D^sel m1 D^x1 + 4E^E^ : mp_list

listinv m1
3: Branch 3 not taken x1 C^ 0
5: Return listinv m1

Figure 5ng7: The sequence of actions taken by VCGen

5.3 VerificationngCondition Generation 197
listinv m1

x1 : mp_list x1 T^ 0

CONSx

1 : ptr {maybepair; mp_list} THIS

x1 : ptr {maybepair}

SELD^sel m

1 x1E^ : maybepair SET

even D^sel m1 x1E^ ) D^sel m1 x1E^ : ptr {int; int} even D^sel m1 x1E^

IMPED^sel m

1 x1E^ : ptr {int; int} THIS

D^sel m1 x1E^ : ptr {int}

PTRADDRaddr D^sel m

1 x1E^

Figure 5ng8: Proof of a verification condition

predicate is assumed to hold and with this assumption we must prove that it
holds for a larger value in a well founded order. This effectively ensures that
the invariant formulas are preserved through an arbitrary execution from one
invariant point to another.

Let us consider now how one proves the verification conditions. The first
interesting one is the addr from line 6. Let

maybepair defC^ {y | evenD^yE^ ) y : ptr {int; int}}
To construct its proof, we first derive x1 : ptr {maybepair; mp_list} using
the rule cons with the assumptions x1 : mp_list and x1 T^ 0. Then we can
derive addr x1 using the rule ptraddr.

A more interesting case is that of proving addr D^sel m1 x1E^ from the
assumptions x1 : mp_list, listinv m1, x1 T^ 0, and even D^sel m1 x1E^. This
proof is shown in Figure 5ng8.

5.3.3 Exercise [n'n', 3]: Construct the the proof of the verification condition correng

sponding to the loop invariant from line 2. You must prove that sel m1 D^x1 +
4E^ : mp_list from the assumptions x1 : mp_list, listinv m1, x1 T^ 0, and
even D^sel m1 x1E^. 2

5.3.4 Exercise [n'n'n']: Notice that we have to prove that sel m1 x1 : ptr {int} sevng

eral times as a step in proving those verification conditions from Figure 5ng7
that refer to D^sel m1 x1E^. Show how you can add an invariant to the program
to achieve the effect of proving this fact only once. 2

198 5 ProofngCarrying Code

We have been arguing that symbolic evaluation is just an alternative method
for type checking, with additional benefits for checking more complex safety
policies. Since there is a simple type checker at the source level for our type
system, it seems reasonable to wonder whether we could hope to build aung
tomatically the proofs of these verification conditions. This is indeed possing
ble for such typengbased safety policies. Consider for instance how the proof
shown in Figure 5ng8 could be constructed through a goalngdirected manner.
The goal is an addr formula, and we observe that only the ptraddr among
our rules (shown in Figure 5ng6) has a conclusion that matches the goal. The
subgoal now is D^sel m1 x1E^ : ptr {int}. In order to prove that the result
of reading from a memory location has a certain type, we must prove that
the memory is wellngtyped and the address has some pointer type. When we
try to prove that x1 has a pointer type, we find among the assumptions that
x1 : mp_list. The remaining steps can be easily constructed by a theorem
prover that knows the details of the type system. This general strategy was
used successfully to construct a simple theorem prover that can build autong
matically and efficiently proofs of verification conditions for the entire Java
type safety policy (Colby et al., 2000).

5.3.5 Exercise [n'n'n']: Extend the verificationngcondition generator approach shown

here to handle a function call instruction call L, where L is a label that is
considered the start of a function. For each such function there is a preconng
dition and a postcondition. Make the simplifying assumption that the call
instruction saves the return address and a set of calleengsave registers on a
special stack that cannot be manipulated directly by the program. A ret inng
struction always returns to the last return address saved on the stack and
also restores the calleengsave registers. 2

5.3.6 Exercise [n'n']: It is sometimes useful to use more kinds of annotations in

addition to the loop invariants. For example, the agent producer might know
that a certain point in the code is not reachable, as is the case for the label L1
in the code fragment shown below:

call exit
L1: UNREACHABLE

...
In such a case it is useful to add an annotation UNREACHABLE to signal to
the symbolic evaluator that it can stop the evaluation at that point. Show how
you can change the symbolic evaluator to handle these annotation without
allowing the agent producer to "lie" about reachability of code. 2

5.3.7 Exercise [n'n']: Extend the symbolic evaluator to handle the indirect jump

instruction jump at e, where e must evaluate to a valid program counter.

5.4 Soundness Proof 199
Indirect jumps are often used to implement efficiently switch statements, in
which case the destination address is one of a staticallyngknown set of labels.
Assume that immediately after the indirect jump instruction there is an annong
tation of the form JUMPDEST(L1, L2) to declare that the destination address
is one of L1 or L2. 2

5.3.8 Exercise [n'n'n'n', 3]: Extend the symbolic evaluator to handle stack frames.

The basic idea is that there is a dedicated stack pointer register rSP that alng
ways points at the last used stack word. This register can only be incremented
or decremented by a constant amount. You can ignore stack overflow issues.
The stack frame for a function has a fixed size that is declared with an anng
notation. The only accesses to it are through the stack pointer register along
with a constant offset. The key insight is that since there is no aliasing to
the stack frame slots they can be treated as pseudo registers. Make sure you
handle properly the overlapping of stack frames at function calls. 2

This completes our simplified account of the operation of VCGen. Note
that the VCGen defined here constructs a global verification condition that
it then passes to the Checker module. This approach, while natural and easy
to describe, turns out to be too wasteful. For large examples on the order of
millions of instructions it is quite common for this monolithic formula to reng
quire hundreds of megabytes for storage, slowing down the checking process
considerably. A highnglevel type checker that would construct an explicit typng
ing derivation would be just as wasteful. A more efficient VCGen architecture
passes to the Checker module each verification condition as it is produced.
After the checker validates it, the verification condition is discarded and the
symbolic evaluation resumes. This optimization might not seem interesting
from a scientific point of view, but it is illustrative of a number of engineering
details that must be addressed to make PCC scalable.

5.4 Soundness Proof

In this section we prove that the type checking technique presented so far
is sound, in the sense that "wellngtyped programs cannot go wrong." More
precisely, we prove that if the global verification condition for a program is
provable using the proof rules given by the safety policy, then the program
is guaranteed to execute without violating memory safety. The method we
use is similar to those used for type systems for highnglevel languages. We
define formally the operational semantics of the assembly language, along
with the notion of "going wrong." It is a bit more difficult to formalize the
notion of wellngtyped programs. In highnglevel type systems there is a direct

200 5 ProofngCarrying Code

connection between the typing derivations and the abstractngsyntax tree of
the program. In our case, the connection is indirect: we first use a verificationng
condition generator and then we exhibit a derivation of the global verification
condition using the safety policy proof rules. In order to reflect this staging in
the operation of our type checker, we split the soundness proof into a proof
of soundness of the set of safety policy rules and a proof of soundness of the
VCGen algorithm.

Soundness of the Safety Policy
The ultimate goal of our safety policy is to provide memory safety. In order to
prove that our typing rules enforce memory safety, we must first define the
semantics of the expression and formula constructors that we have defined.

The semantic domain for the expressions is the set of integers,1 except for
the memory expressions that we model using partial maps from integers to
integers.

Next we observe that the typing formulas involving pointer types and the
listinv formulas have a wellngdefined meaning only in a given context that
assigns types to addresses. The necessary context is a mapping M from a
valid address to the word type of the value stored at that address. Since we
do not consider allocation or deallocation, our type system ensures that the
mapping M remains constant throughout the execution of the program.

We write |C^M F when the formula F holds in the memory typing M. A few
of the most interesting cases from the definition of |C^M are shown below:

|C^M F1 ^ F2 iff |C^M F1 and |C^M F2
|C^M F1 ) F2 iff whenever |C^M F1 then |C^M F2
|C^M 8x:FD^xE^ iff 8e 2 Z: |C^M FD^eE^

|C^M a : int iff a 2 Z
|C^M a : list W iff a C^ 0 . D^MD^aE^ C^ W ^ MD^a + 4E^ C^ list W E^
|C^M a : ptr {S} iff 8i:0 <= i < |S| ) MD^a + 4 * iE^ C^ Si
|C^M a : {y | FD^yE^} iff |C^M FD^aE^

|C^M listinv m iff 8a 2 DomD^ME^:a 2 DomD^mE^ and |C^M m a : MD^aE^
|C^M addr a iff a 2 DomD^ME^

In the above definition we used the notation |S| for the length of a sequence
of word types S, and Si for the ith element of the sequence.

1. A more accurate model would use integers modulo 232 in order to reflect the finite range of
integers that are representable as machine words.

5.4 Soundness Proof 201

With these definitions we can now start to prove the soundness of the
derivation rules. Given a rule with variables x1; : : : ; xn, premises H1; : : : ; Hm
and conclusion C, we must prove

|C^M 8x1:8x2: : : : 8xn:D^H1 ^ * * * ^ HmE^ ) C
For example, the soundness of rule sel requires proving the following fact:

|C^M 8a:8W :8m:D^a : ptr {W }E^ ^ D^listinv mE^ ) D^sel m aE^ : W
From the first assumption we derive that MD^aE^ C^ W . From the second
assumption we derive that |C^M m a : W and since |C^M D^sel m aE^ C^ m a we
obtain the desired conclusion.

5.4.1 Exercise [Recommended, n']: Prove that cons and next are sound. 2
5.4.2 Exercise [n'n', 3]: Prove the soundness of the remaining rules shown in Figng

ure 5ng6. 2

An Operational Semantics for Assembly Language
Next we formalize an operational semantics for the assembly language. We
model the execution state as a mapping ae from register names to values.
Just like in the previous chapter, the domain of values is Z, except for the
rM register, which takes as values partial mappings from Z to Z. Since we do
not consider allocation and deallocation, the domain of the memory mapping
does not change. Let Addr be that domain. The operational semantics is
defined only for programs whose memory accesses are only to addresses in
the Addr domain.

We write D^ae eE^ for the result of evaluating in the register state ae the exng
pression e, which can refer to register names. We write aeE,rr  vG* for the new
register state obtained after setting register rr to value v in state ae.

The operational semantics is defined in Figure 5ng9 in the form of a smallng
step transition relation D^i; aeE^ O"" D^i; ae0E^ from a given program counter and
register state to another such pair. Notice that the transition relation is deng
fined for memory operations only if the referenced addresses are valid.

We follow the usual convention and leave the transition relation undefined
for those states where the execution is considered unsafe. For instance, the
transition relation is not defined if the program counter is outside the code
area or if it points to an unrecognized instruction. More importantly, the
transition relation is not defined if a memory access is attempted at an invalid
address.

202 5 ProofngCarrying Code

D^i; aeE^ O""

8??????????
?????????????
?!??????
?????????????
?????:

D^i + 1; aeE,rd  ae eG*E^; if \Pi i C^ set rd to e
D^i + 1; aeE,rd  ae D^sel rM eE^G*E^; if \Pi i C^ load rd from e

and ae e 2 Addr
D^i + 1; aeE,rM  ae D^upd rM e2 e1E^G*E^; if \Pi i C^ write e1 to e2

and ae e2 2 Addr
D^L; aeE^; if \Pi i C^ if e goto L

and ae e
D^i + 1; aeE^; if \Pi i C^ if e goto L

and ae D^not eE^
D^i + 1; aeE^; if \Pi i C^ INV I

Figure 5ng9: The abstract machine for the soundness proof

Soundness of VerificationngCondition Generation
The soundness theorem for VCGen states that if the verification condition
holds, and all addresses that are in DomD^ME^ are valid addresses (i.e., they
belong to Addr), then the execution starting at the beginning of the agent in a
state that satisfies the precondition will make progress either forever or until
it reaches a return instruction in a state that satisfies the postcondition. What
this theorem rules out is the possibility that the execution gets stuck either
because it tries to execute an instruction at an invalid program counter, or it
tries to dereference an invalid address. The formal statement of the theorem
is the following:

5.4.3 Theorem [Soundness of VCGen]: Let ae1 be a state such that |C^M ae1 Pre. If

DomD^ME^ ` Addr and if |C^M V C then the execution starting at D^1; ae1E^ can
make progress either forever, or until it reaches a return instruction in state
ae, in which case |C^M ae Post. 2

We prove by induction on the number of execution steps that either we
have reached the return instruction, or else we can make further progress.
As in all proofs by induction, the most delicate issue is the choice of the
induction hypothesis. Informally, our induction hypothesis is that for each
execution state there is a "corresponding" state of the symbolic evaluator.

In order to express the notion of correspondence, we must consider the difng
ferences between the concrete execution states ae (mapping register names to

5.4 Soundness Proof 203
values) and the symbolic evaluation states oe (mapping register names to symng
bolic expressions that use expression constructors and variables). To bridge
these two notions of states we need a mapping OE from variables that appear
in oe , to values. For a symbolic expression e that contains variables, we write
D^OE eE^ for the result of replacing the variables in e as specified by OE and evalng
uating the result. Consequently, we write OE ffi oe for a mapping from register
names to values that maps each register name ri to the value OE D^oe riE^. Thus
OE ffi oe is a concrete execution state.

The main relationship that we impose between ae and oe is that there exists
a mapping OE such that ae C^ OE ffi oe . The full induction hypothesis relates these
states with the program counter i, and is defined as follows:

IH D^i; ae; oe ; OEE^ defC^ ae C^ OE ffi oe and |C^M OE D^SED^i; oe E^E^
The core of the soundness proof is the following lemma:
5.4.4 Theorem [Progress]: Let \Pi  be a program such that |C^M VC and DomD^ME^ `

Addr. For any execution state D^i; aeE^ and oe and OE such that IHD^i; ae; oe ; OEE^
then either:

* \Pi i C^ return, and |C^M ae Post, or

* there exist new states ae0, oe 0 and a mapping OE0 such that D^i; aeE^ ! D^i0; ae0E^

and IHD^i0; ae0; oe 0; OE0E^. 2

Proof: The proof is by case analysis on the current instruction. Since we have
that |C^M OE SED^i; oe E^ we know that SED^i; oe E^ is defined, hence the program
counter is valid and \Pi i is a valid instruction. We show here only the most
interesting cases.

Case: \Pi i C^ return. In this case SED^i; oe E^ C^ oe Post and from |C^M OE SED^i; oe E^
along with ae C^ OE ffi oe we can infer that |C^M ae Post.

Case: \Pi i C^ load rd from e. In this case SED^i; oe E^ C^ addr D^oe eE^ ^ SED^i +
1; oe E,rd  oe D^sel rM eE^G*E^. Let oe 0 C^ oe E,rd  oe D^sel rM eE^G*, ae0 C^ aeE,rd 
ae D^sel rM eE^G*, i0 C^ i + 1 and OE0 C^ OE. In order to prove progress, we must
prove ae e 2 Addr. The induction hypothesis IHD^i; ae; oe ; OEE^ ensures that |C^M
D^addr D^OED^oe eE^E^E^, which in turn means that D^ae eE^ 2 DomD^ME^. Since we require
that the memory typing be defined only on valid addresses we obtain the
progress condition.

Next we have to prove that the induction hypothesis is preserved. The only
interesting part of this proof is that OE0 ffi oe 0 C^ ae0, which in turn requires
proving that OED^oe D^sel rM eE^E^ C^ ae D^sel rM eE^. This follows from OE ffi oe C^ ae.

Case: \Pi i C^ INV I. In this case SED^i; oe E^ C^ oe I. We know that |C^M OED^oe IE^ and
therefore |C^M ae I. The execution can always make progress for an invariant

204 5 ProofngCarrying Code

instruction and we must choose i0 C^ i + 1 and ae0 C^ ae. We know that |C^M VC
and hence

|C^M 8x1: : : : :8xn:oe0 I ) SED^i + 1; oe0E^

where oe0 C^ {r1 C^ x1; : : : ; rn C^ xn}. We choose oe 0 C^ oe0 and OE0 as follows:

OE0 C^ {x1 C^ ae r1; : : : ; xn C^ ae rn}
This ensures that ae C^ OE0 ffi oe 0 and also that |C^M OE0 SED^i + 1; oe 0E^, which
completes this case of the proof. 2

5.4.5 Exercise [Recommended, n', 3]: Finish the proof of Theorem 5.4.4 by provng

ing the remaining cases (assignment, conditional branch and memory write). 2

The progress theorem constitutes the inductive case of the proof of the
soundness theorem 5.4.3.

5.4.6 Exercise [n']: Prove Theorem 5.4.3. 2

5.5 The Representation and Checking of Proofs

In previous sections, we showed how verificationngcondition generation can be
used to verify certain properties of lownglevel code. The soundness theorem
states that VCGen constructs a valid verification condition for an agent prong
gram only if the agent meets the safety policy. One way to verify the validity
of the verification condition is to witness a derivation using a sound system
of proof rules. In PCC such a derivation must be attached to the untrusted
code so that the Checker module can find and check it. For this to work propng
erly in practice, we need a framework for encoding proofs of logical formulas
so that they are relatively compact and easy to check. We would like to have a
framework and not just one proof checker for a given logic because we want
to be able to change the set of axioms and inference rules as we adapt PCC to
different safety policies. We would like to be able to adapt proof checking to
other safety policies with as few changes to the infrastructure as possible. In
this section we present a logical framework derived from the Edinburgh Logng
ical Framework (Harper, Honsell, and Plotkin, 1993), along with associated
proof representation and proof checking algorithms, that have the following
desirable properties:

* The framework can be used to encode judgments and derivations from a

wide variety of logics, including firstngorder and higherngorder logics.

* The implementation of the proof checker is parameterized by a highnglevel

description of the logic. This allows a unique implementation of the proof
checker to be used with many logics and safety policies.

5.5 The Representation and Checking of Proofs 205

* The proof checker performs a directed, onengpass inspection of the proof

object, without having to perform search. This leads to a simple impleng
mentation of the proof checker that is easy to trust and install in existing
extensible systems.

* Even though the proof representation is detailed, it is also compact.

The above desiderata are important not only for proofngcarrying code but
for any application where proofs are represented and manipulated explicitly.
One such application is a proofnggenerating theorem prover. A theorem prover
that generates an explicit proof object for each successfully proved predicate
enables a distrustful user to verify the validity of the proved theorem by
checking the proof object. This effectively eliminates the need to trust the
soundness of the theorem prover at the relatively small expense of having to
trust a much simpler proof checker.

The first impulse when designing efficient proof representation and valing
dation algorithms is to specialize them to a given logic or a class of related
logics. For example, we might define the representation and validation algong
rithms by cases, with one case for each proof rule in the logic. This approach
has the major disadvantage that new algorithms must be designed and imng
plemented for each logic. To make matters worse, the size of such proof
checking implementations grow with the number of proof rules in the logic.
We would prefer instead to use general algorithms parameterized by a highng
level description of the particular logic of interest.

We choose the Edinburgh Logical Framework (LF) as the starting point in
our quest for efficient proof manipulation algorithms because it scores very
high on the first three of the four desirable properties listed above. Edinburgh
LF is a simple variant of *ngcalculus with the property that, if a predicate is
represented as an LF type then any LF expression of that type is a proof of that
predicate. Thus, the simple logicngindependent LF typengchecking algorithm can
be used for checking proofs.

The Edinburgh Logical Framework
The Edinburgh Logical Framework (also referred to as LF) has been introng
duced by Harper, Honsell, and Plotkin (1993) as a metalanguage for highnglevel
specification of logics. LF provides natural support for the management of
binding operators and of the hypothetical and schematic judgments through
LF bound variables. Consider for example, the usual formulation of the imng
plication introduction rule impi in firstngorder logic, shown in Figure 5ng5. This
rule is hypothetical because the proof of the rightnghand side of the implicang
tion can use the assumption that the leftnghand side holds. However, there is

206 5 ProofngCarrying Code

a side condition requiring that this assumption not be used elsewhere in the
proof. As we shall see below, LF can represent this side condition in a natural
way by representing the assumption as a local variable bound in the proof
of the right side of the implication. The fact that these techniques are supng
ported directly by the logical framework is a crucial factor for the succinct
formalization of proofs.

The LF type theory is a language with entities at three levels: objects, types
and kinds, whose abstract syntax is shown below:

Kinds K ::C^ Type | \Pi x:A:K
Types A ::C^ a | A M | \Pi x:A1:A2
Objects M ::C^ x | c | M1M2 | *x:A:M

Types are used to classify objects and similarly, kinds are used to classify
types. The type \Pi x:A:B is a dependent function type with x bound in B. In the
special case when x does not occur in B, we use the more familiar notation
A ! B. Also, Type is the base kind, a is a type constant and c is an object
constant. Dependent types are covered in detail in Chapter 2.

The encoding of a logic in LF is described by an LF signature \Sigma  that contains
declarations for a set of LF type constants and object constants correspondng
ing to the syntactic formula constructors and to the proof rules. For a more
concrete discussion, I describe in this section the LF representation of the
safety policy that we have developed for our example agent.

The syntax of the logic is described in Figure 5ng10. This signature defines
an LF type constant for each kind of syntactic entity in the logic: expressions
('), formulas (o), word types (w ), and structure types (s). Then, there is an LF
constant declaration for each syntactic constructor, whose LF type describes
the arity of the constructor and the types of the arguments and constructed
value. Two of these are worth explaining. The settype constructor, used to
represent word types of the form {y | FD^yE^}, has one argument, the funcng
tion F from expressions to formulas; similarly, the all constructor encodes
universally quantified formulas. In both of these cases, we are representing a
binding in the object logic (i.e., the logic that is being represented) with a bindng
ing in LF. The major advantage of this representation is that ffngequivalence
and fingreduction in the object logic are supported implicitly by the similar
mechanisms in LF. This higherngorder representation strategy is essential for a
concise representation of logics with binding constructs.

The LF representation function [*" is defined inductively on the structure
of expressions, types and formulas. For example:

[P ) D^P ^ P E^" C^ imp [P " D^and [P " [P "E^

[8x:addr x" C^ all D^*x : ':addr xE^

5.5 The Representation and Checking of Proofs 207

' : Type
o : Type
w : Type
s : Type

zero : '
sel : ' ! ' ! '
upd : ' ! ' ! ' ! '

int : w
list : w ! w
seq1 : w ! s
seq2 : w ! s ! s
ptr : s ! w
settype : D^' ! oE^ ! w

true : o
and : o ! o ! o
impl : o ! o ! o
all : D^' ! oE^ ! o
eq : ' ! ' ! o
neq : ' ! ' ! o
addr : ' ! o
hastype : ' ! w ! o
ge : ' ! ' ! o

D^aE^ D^bE^
Figure 5ng10: LF signature for the syntax of firstngorder predicate logic with
equality and subscripted variables, showing expression (a) and predicate
(b) constructors

5.5.1 Exercise [n']: Write the LF representation of the predicate 8a:a : ptr {int} )

addr a. 2

The strategy for representing proofs in LF is to define a type family "pf "
indexed by representation of formulas. Then, we represent the proof of "F"
as an LF expression having type "pf F." This representation strategy is called
"judgments as types and derivations as objects" and was first used in the
work of Harper, Honsell, and Plotkin (1993). Note that the dependent types
of LF allow us to encode not only that an expression encodes a proof but also
which formula it proves.

One can view the axioms and inference rules as proof constructors. This
justifies representing the axioms and inference rules in a manner similar to
the syntactic constructors, by means of LF constants. The signature shown
in Figure 5ng11 contains a fragment of the proof constructors required for the
proof rules shown in Figure 5ng5 (for firstngorder logic) and Figure 5ng6 (for our
safety policy). Note how the dependent types of LF can define precisely the
meaning of each rule. For example, the declaration of the constant "andi"

208 5 ProofngCarrying Code

pf : o ! Type
truei : pf true
andi : \Pi p :o:\Pi r :o:pf p ! pf r ! pf D^and p r E^
andel : \Pi p :o:\Pi r :o:pf D^and p r E^ ! pf p
ander : \Pi p :o:\Pi r :o:pf D^and p r E^ ! pf r
impi : \Pi p :o:\Pi r :o:D^pf p ! pf r E^ ! pf D^impl p r E^
impe : \Pi p :o:\Pi r :o:pf D^impl p r E^ ! pf p ! pf r
alli : \Pi p :' ! o:D^\Pi v :':pf D^p vE^E^ ! pf D^all pE^
alle : \Pi p :' ! o:\Pi e :':pf D^all pE^ ! pf D^p eE^
mem0 : \Pi m :':\Pi a :':\Pi v :':\Pi a0 :':pf D^eq a a0E^ ! pf D^eq D^sel D^upd m a vE^ a0E^ vE^

mem1 :

\Pi m :':\Pi a :':\Pi v :':\Pi a0 :':

pf D^neq a a0E^ ! pf D^eq D^sel D^upd m a vE^ a0E^ D^sel m a0E^E^

cons : \Pi E :':\Pi W :w:

pf D^hastype E D^list W E^E^ ! pf D^neq E zeroE^ !
pf D^hastype E D^ptr D^seq2 W D^seq1 D^list W E^E^E^E^E^:
set : \Pi E :':\Pi F :' ! o:pf D^hastype E D^settype FE^E^ ! pf D^F EE^:

Figure 5ng11: LF signature for safety policy proof rules

says that, in order to construct the proof of a conjunction of two predicates,
one can apply the constant "andi" to four arguments, the first two being the
two conjuncts and the other two being the representations of proofs of the
conjuncts respectively.

The LF representation function [*" is extended to derivations and is defined
recursively on the derivation, as shown in the following examples (the letters
D are used to name subngderivations):

[ D1

F1

D2

F2

F1 ^ F2

"

C^ andi [F1" [F2" [D1" [D2"

[ F1

... Du

F2
F1 ) F2

"

C^ impi [F1" [F2" D^*u :pf [F1":[Du"E^

5.5 The Representation and Checking of Proofs 209

M C^ impi [F" D^and [F" [F"E^

D^*x:pf [F":andi [F" [F" x xE^

Figure 5ng12: LF representation of a proof of F ) D^F ^ F)

In the representation of the implication introduction proof rule, the letter
u is the name of the assumption that F1 holds. Note how the representation
encodes the constraint that this assumptions must be local to the proof of F2.

To conclude the presentation of the LF representation, consider the proof
of the formula "F ) D^F ^ FE^." The LF representation of this proof is shown in
Figure 5ng12.

5.5.2 Exercise [n']: Write the LF representation of the proof of the formula 8a:a :

ptr {int} ) addr a, using the proof rules from our safety policy. 2

The LF Type System
The main advantage of using LF for proof representation is that proof validity
can be checked by a simple typengchecking algorithm. That is, to check that the
LF object M is the representation of a valid proof of the predicate F we use
the LF typing rules (to be presented below) to verify that M has type pf [F"
in the context of the signature \Sigma  declaring the valid proof rules.

Type checking in the LF type system is defined by means of four judgments
described below:

\Gamma  `LF A : K A is a valid type of kind K
\Gamma  `LF M : A M is a valid object of type A
A jfij B type A is fijngequivalent to type B
M jfij N object M is fijngequivalent to object N

where \Gamma  is a typing context assigning types to LF variables. These typing judgng
ment are with respect to a given signature \Sigma .

The derivation rules for the LF typing judgments are shown in Figure 5ng13.
For the fijngequivalence judgments we omit the rules that define it to be an
equivalence and a congruence.

As an example of how LF type checking is used to perform proof checking,
consider LF term M shown in Figure 5ng12, representing a proof of the predng
icate F ) D^F ^ F by implication introduction followed by conjunction introng
duction. It is easy to verify, given the LF typing rules and the declaration of the

210 5 ProofngCarrying Code

Types \Gamma  `LF A : K

\Sigma D^aE^ C^ K

\Gamma  `LF a : K
\Gamma  `LF A : \Pi x:B:K \Gamma  `LF M : B

\Gamma  `LF A M : E,MffxG*K
\Gamma  `LF A : Type \Gamma  ; x : A `LF B : Type

\Gamma  `LF \Pi x:A:B : Type

Objects \Gamma  `LF M : A

\Sigma D^cE^ C^ A

\Gamma  `LF c : A

\Gamma  D^xE^ C^ A

\Gamma  `LF x : A
\Gamma  ; x : A `LF M : B
\Gamma  `LF *x:A:M : \Pi x:A:B
\Gamma  `LF M : \Pi x:A:B \Gamma  `LF N : A

\Gamma  `LF MN : E,NffxG*B
\Gamma  `LF M : A A jfij B

\Gamma  `LF M : B

Equivalence M jfij N

D^*x:A:ME^N jfij E,NffxG*M

Figure 5ng13: The LF type system

constants involved, that this proof has the LF type "pf D^imp[F" D^and[F" [F"E^E^."
The adequacy of LF type checking for proof checking in the logic under conng
sideration is stated formally in the Theorems 5.5.3 and 5.5.4 below. These
theorems follow immediately from lemmas proved in Harper, Honsell, and
Plotkin (1993). They continue to hold if the logic is extended with new exng
pression and predicate constructors.

5.5.3 Theorem [Adequacy of syntax representation]:

1. If E is a closed expression, then * `LF [E" : '. If M is a closed LF object such

that * `LF M : ', then there exists an expression E such that [E" jfij M.

2. If W is a wordngtype, then * `LF [W " : w . If M is a closed LF object such that

* `LF M : w , then there exists a word type W such that [W " jfij M.

3. If S is a structured type, then * `LF [S" : s. If M is a closed LF object such

that * `LF M : s, then there exists a structured type S such that [S" jfij M.

4. If F is a closed formula, then * `LF [F" : o. If M is a closed LF object such

that * `LF M : o, then there exists a formula F such that [F" jfij M. 2

5.5.4 Theorem [Adequacy of Derivation Representation]:

1. If D is a derivation of F then * `LF [D" : pf [F".

5.5 The Representation and Checking of Proofs 211

2. If M is a closed LF object such that * `LF M : pf [F", then there exists a

derivation D of F such that [D" jfij M. 2

In the context of PCC, Theorem 5.5.4(2) says that if the agent producer
can exhibit an LF object having the type "pf [VC"" then there is a derivation
of the verification condition within the logic, which in turn means that the
verification condition is valid and the agent code satisfies the safety policy.

Owing to the simplicity of the LF type system, the implementation of the
type checker is simple and easy to trust. Furthermore, because all of the deng
pendencies on the particular object logic are separated in the signature, the
implementation of the type checker can be reused directly for proof checking
in various firstngorder or higherngorder logics. The only logicngdependent comng
ponent of the proof checker is the signature, which is usually easy to verify
by visual inspection.

Unfortunately, the abovengmentioned advantages of LF representation of
proofs come at a high price. The typical LF representation of a proof is large,
due to a significant amount of redundancy. This fact can already be seen in
the proof representation shown in Figure 5ng12, where there are six copies
of F as opposed to only three in the predicate to be proved. The effect of
redundancy observed in practice increases nonnglinearly with the size of the
proofs. Consider for example, the representation of the proof of the nngway
conjunction F ^ : : : ^ F. Depending on how balanced is the binary tree repreng
senting this predicate, the number of copies of F in the proof representation
ranges from an expected value of n log n (when the tree is perfectly balanced)
to a worse case value of n2=2 (when the tree degenerates into a list). The
redundancy of representation is not only a space problem but also leads to
inefficient proof checking, because all of the redundant copies have to be
type checked and then checked for equivalence with instances of F from the
predicate to be proved.

The proof representation and checking framework presented in the next
section is based on the observation that it is possible to retain only the skeleng
ton of an LF representation of a proof and to use a modified LF typengchecking
algorithm to reconstruct on the fly the missing parts. The resulting implicit LF
(or LFi) representation inherits the advantages of the LF representation (i.e.,
small and logicngindependent implementation of the proof checker) without
the disadvantages (i.e., large proof sizes and slow proof checking).

Implicit LF
The solution to the redundancy problem is to eliminate the redundant subng
terms from the proof. In most cases we can eliminate all copies of a given

212 5 ProofngCarrying Code

subterm from the proof and rely instead on the copy that exists within the
predicate to be proved, which is constructed by the VCGen and is trusted to
be well formed. But now the code receiver will be receiving proofs with missng
ing subterms. One possible strategy is for the code receiver to reconstruct
the original form of the proof and then to use the simple LF type checking
algorithm to validate it. But this does not save proofngchecking time and reng
quires significantly more working memory than the size of the incoming LFi
proof. Instead, we modify the LF typengchecking algorithm to reconstruct the
missing subterms while it performs type checking. One major advantage of
this strategy is that terms that are reconstructed based on copies from the
verification condition do not need to be type checked themselves.

We will not show the formal details of the type reconstruction algorithm
but will show instead how it operates on a simple example. For expository
purposes, the missing proof subterms are marked with placeholders, written
as *. Consider now the proof of the predicate F ) D^F ^ FE^ of Figure 5ng12. If
we replace all copies of "F" with placeholders we get the following LFi object:

impi *1 *2 D^*u :*3:andi *4 *5 u uE^
This implicit proof captures the structure of the proof without any redunng
dant information. The subterms marked with placeholders can be recovered
while verifying that the term has type "pf D^impl[F" D^and[F" [F"E^E^," as deng
scribed below.

Reconstruction starts by recognizing the topnglevel constructor impi. The
expected type of the entire term, "pf D^impl [F" D^and [F" [F"E^E^," is "matched"
against the result type of the impi constant, as given by the signature \Sigma . The
result of this matching is an instantiation for placeholders 1 and 2 and a
residual typengchecking constraint for the explicit argument of impi, as folng
lows:

*1 j [F"
*2 j and [F" [F"
` D^*u :*3:andi *4 *5 u uE^ : pf [F" ! pf D^and [F" [F"E^

Reconstruction continues with the remaining typengchecking constraint. From
its type we can recover the value of placeholder 3 and a typing constraint for
the body:

*3 j pf [F"
u : pf [F" ` andi *4 *5 u u : pf D^and [F" [F"E^

Now andi is the topnglevel constant and by matching its result type as declared
in the signature with the goal type of the constraint we get the instantiation

5.5 The Representation and Checking of Proofs 213
for placeholders 4 and 5 and two residual typing constraints:

*4 j [F"
*5 j [F"
u : pf [F" ` u : pf [F"
u : pf [F" ` u : pf [F"

The remaining two constraints are solved by the variable typing rule. Note
that this step involves verifying the equivalence of the objects [F" from the
assumption and the goal. This concludes the reconstruction and checking of
the entire proof. We reconstructed the full representation of the proof by inng
stantiating all placeholders with wellngtyped LF objects. We know that these
instantiations are wellngtyped because they are ultimately extracted from the
original constraint type, which is assumed to contain only wellngtyped subng
terms.

The formalization of the reconstruction algorithm described informally
above is in two stages. First, we show a variant of the LF type system, called
implicit LF or LFi, that extends LF with placeholders. This type system has the
property that all wellngtyped LFi terms can be reconstructed to wellngtyped LF
terms. However, unlike the original LF type system, the LFi type system is not
amenable to a direct implementation of deterministic type checking. Instead,
we use a separate reconstruction algorithm.

An object M is fully reconstructed, or fully explicit, when it is placeholder
free. We write PFD^ME^ to denote this property. We extend this notation to type
environments and write PFD^\Gamma  E^ to denote that all types assigned in \Gamma  to varing
ables are placeholder free.

The LFi typing rules are an extension of the LF typing rules with two new
typing rules for dealing with implicit abstraction and placeholders, and one
new fingequivalence rule dealing with implicit abstraction. These additions are
shown in Figure 5ng14. The LFi typing judgment is written \Gamma  `i M : A.

Note that according to the LFi type system placeholders cannot occur on
a function position, but only as arguments in an application. This restriction
allows us to simplify the reconstruction algorithm by avoiding higherngorder
unification. Note also that several LFi rules require that the types involved
do not contain placeholders. This restriction simplifies greatly the proofs of
soundness of the reconstruction algorithms and does not seem to diminish
the effectiveness of the LFi representation.

A quick analysis of the LFi typing rules reveals that they are not directly
useful for type checking or type inference. The main reason is that type checkng
ing an application involves "guessing" appropriate A and N. The type A can
sometimes be recovered from the type of the application head, but the term

214 5 ProofngCarrying Code

Objects \Gamma  `i M : A

\Gamma  `i M : A A jfij B PFD^AE^

\Gamma  `i M : B
\Gamma  ; x : A `i M : B
\Gamma  `i *x:*:M : \Pi x:A:B

\Gamma  `i M : \Pi x:A:B \Gamma  `i N : A PFD^AE^

\Gamma  `i M N : E,N=xG*B
\Gamma  `i M : \Pi x:A:B \Gamma  `i N : A PFD^AE^

\Gamma  `i M * : E,N=xG*B

Equivalence M jfij N

D^*x:*:ME^N jfij E,N=xG*M

Figure 5ng14: The rules that are new in the LFi type system

N in an application to a placeholder cannot be found easily in general. This
is not a problem for us because we need the LFi typengsystem only as a step in
proving the correctness of the typengreconstruction algorithm, and not as the
basis for an implementation of a typengchecking algorithm.

The only property of interest of the LFi type system is that once we have
a typing derivation we can reconstruct the object involved and a correspondng
ing LF typing derivation for it. To make this more precise we introduce the
notation M % M0 to denote that M0 is a fullyngreconstructed version of the
implicit object M (i.e., PFD^M0E^). This means that M0 can be obtained from M
by replacing all of its placeholders with fullyngexplicit LF objects. Note that the
reconstruction relation is not a function as there might be several reconstrucng
tions of a given implicit object or type.

5.5.5 Theorem [Soundness of LFi typing]: If \Gamma  `i M : A and PFD^\Gamma  E^, PFD^AE^, then

there exists M0 such that M % M0 and \Gamma  `LF M0 : A. 2

5.5.6 Exercise [n'n', 3]: Prove Theorem 5.5.5 2

5.6 Proof Generation

We have seen that a successfully checked proof of the verification condition
guarantees that the verification condition is valid, which in turn guarantees
that the code adheres to the safety policy. The PCC infrastructure is simple,
easyngtongtrust and automatic. But this is only because all the difficult tasks
have been delegated to the code and proof producers. The first difficult task,
besides writing code that is indeed safe, is to generate the code annotations
consisting of loop invariants for all loops and of function specifications for all

5.6 Proof Generation 215
Figure 5ng15: Interaction between untrusted PCC tools (continuous lines)
and trusted PCC infrastructure (interrupted lines)

local functions. The other difficult task is to prove the verification condition
produced by the verificationngcondition generator.

Fortunately there are important situations when both the generation of
the annotations and of the proof can be automated. Consider the situation
in which there exists a highnglevel language, perhaps a domainngspecific one,
in which the safety policy is guaranteed to be satisfied by a combination of
static and runngtime checks. For example, if the safety policy is memory safety
then any memoryngsafe highnglevel language can be used. The key insight is that
in these systems the safety policy is guaranteed to hold by the design of the
static and runngtime checks. In essence, the highnglevel type checker acts as a
theorem prover. All we have to do is to show that a sufficient number and
kind of static and runngtime checks have been performed.

Figure 5ng15 shows the interaction between the untrusted PCC tools used by
the code producer and the trusted PCC infrastructure used by the code reng
ceiver. The annotations are generated automatically by a certifying compiler
from highnglevel language to assembly language. For safety polices that follow
closely the highnglevel type system, it is surprisingly easy for a compiler to
produce the loop invariants, which are essentially conjunctions of type decng
larations for the live registers at the given program point. This is information
that the compiler can easily maintain and emit.

Before it can generate the required proofs, the code producer must pass
the annotated code to a local copy of VCGen. The proof itself is generated by
a theorem prover customized for the specific safety policy. As discussed in
Section 5.3, such a theorem prover is little more than a type checker. However,
unlike a regular type checker or theorem prover, the PCC theorem prover
must generate explicit representation of the proofs. The architecture shown
in Figure 5ng15 is described in detail in Necula (1998).

216 5 ProofngCarrying Code

Figure 5ng16: A privacy policy
5.7 PCC beyond Types

The presentation of PCC so far has focused on typengbased safety policies. We
have shown that verification condition generation followed by theorem provng
ing can overcome many of the difficulties of type checking programs written
in lownglevel languages. It should be obvious that we can take the example
that we used so far and change the type system by simply changing the proof
rules, with no changes to the infrastructure itself. But the machinery we have
constructed in the process can be used to enforce more complex safety pong
lices than are usually associated with types. And we can do this with very
few changes, thanks both to the modular design of the infrastructure and to
the choice of using the lowernglevel mechanism of logic rather than commitng
ting to a highnglevel type system. However, everytime the set of proof rules is
changed, one must redo the proof of soundness. In this section, we explore
one example of a safety policy that goes beyond types.

Consider a safety policy that allows access to two host services: read the
contents of a local file and send data over the network. The host wishes to
enforce the policy that the agent cannot send data after it has read local files.
This is a conservative way to ensure that no local file contents will be leaked.
This example is taken from Schneider (2000).

This safety policy can be described using the state machine shown in Figng
ure 5ng16. Initially the agent is in the public state in which it can use both the
send and the read services. However, once it uses the read service the agent
transitions in the private state, in which it can use only the read service.

In order to enforce such a safety policy, it is sufficient to check that the
send service cannot be used after the read service has been used. At the
level of assembly language, these services would be most likely implemented
as function calls. In that case the privacy safety policy can be implemented as
a precondition on the send function. Instead of introducing a general mechang
nism for handling function calls (see Exercise 5.3.5), we use a specialngpurpose
handling of the instructions call read and call send.

5.7 PCC beyond Types 217

In the presentation of PCC from previous sections, there is no element
of the state of the computation that reflects whether a certain function has
been invoked or not. One way to address this issue is to require that the agent
code keep track of its own public/private state at runngtime, presumably in a
register or a memory location. Then the postcondition of read would require
that this state element reflect the private state and the precondition of send
would require that the state element reflect the public state. This strategy
is appropriate when the producer of the agent code wishes to use runngtime
checking to enforce the safety policy, in which case it would have to prove
that the appropriate checks have been inserted. This strategy also has the
benefit of not requiring any changes in the PCC infrastructure.

We will pursue another alternative. We will modify VCGen and the symbolic
evaluator to keep track of the public/private state. And since we prefer to exng
tend the PCC infrastructure with a generalngpurpose mechanism rather than a
specific policy, the VCGen extension should be able to record any information
about the history of the execution, not just its public/private state.

For this purpose we extend the symbolic evaluation state with another
pseudongregister, called rH to store a sequence of interesting events in the
past of the computation. The set of symbolic expressions that this register
can have are shown below:

Histories H ::C^ x | event V H
Events V ::C^ init | read | send

Additionally we add a number of formulas that we can use for stating propng
erties of the history of execution:

Formulas F ::C^ : : : | publicState H | privateState H
As usual when we extend the language of formulas we must also extend
the proof rules. For our safety policy we add the following three proof rules:

publicState D^event init HE^ (init)

publicState H
publicState D^event send HE^ (send)

privateState D^event read HE^ (read)
The definition of the VCGen and the symbolic evaluator can remain unng
changed for the instructions considered so far, except that the rH register
can be used in loop invariants and function preconditions and postconding
tions. In particular, for the privacy safety policy the invocations of the read

218 5 ProofngCarrying Code

and send services can be handled in the symbolic evaluator as follows:

SED^i; oe E^ C^

8?????????!

?????????:

: : :
SED^i + 1; oe E,rH  D^oe D^event read rHE^E^G*E^ if \Pi i C^ call read
publicState D^oe rHE^ ^ if \Pi i C^ call send
SED^i + 1; oe E,rH  D^oe D^event send rHE^E^G*E^

The symbolic evaluator extends the history state with information about
the services that were used. Additionally, the send call requires through
its precondition that the history of the computation be consistent with the
public state of the safety policy. A realistic symbolic evaluator would supng
port a generalngpurpose function call instruction, in which case the effect of
the read and send functions could be achieved by appropriate function preng
conditions and postconditions.

5.7.1 Exercise [n'n', 3]: Add two actions lock e and unlock e that can be used

to acquire and release a lock that is denoted by the expression e. Define a
PCC safety policy (extensions to the logic, new proof rules and changes to
the symbolic evaluator) that requires correct use of locks: a lock cannot be
acquired or released twice in a row, and the agent must release all locks upon
return. 2

5.7.2 Exercise [n'n', 3]: The verificationngcondition generator that we described in

Section 5.3 cannot enforce a safety policy that allows the agent to "probe" the
accessibility of a memory page by attempting a read from an address within
that page. This is a common way to check for stack overflow in many systems.
Show how you can change the symbolic evaluator to use the history register
for the purpose of specifying such a safety policy. 2

This example shows how to use PCC for safety policies that go beyond type
checking. In fact, PCC is extremely powerful in this sense. Any safety policy
that could be enforced by an interpreter using runngtime checking could in
principle be enforced by PCC. A major advantage of PCC over interpreters is
that it can check properties that would be very expensive to check at run time.
Consider, for example, how complicated it would be to write an interpreter
that enforces at runngtime a fine grained memory safety policy. Each memory
word would have to be instrumented with information whether it is accessible
or not. By comparison, we can use PCC along with a strong type system to
achieve the same effect, with no runngtime penalty.

5.8 Conclusion 219
5.8 Conclusion

Below is a list of the most important ways in which PCC improves over other
existing techniques for enforcing safe execution of untrusted code:

* PCC operates at load time before the agent code is installed in the host

system. This is in contrast with techniques that enforce the safety policy
by relying on extensive runngtime checking or even interpretation. As a reng
sult PCC agents run at nativengcode speed, which can be ten times faster
than interpreted agents (written for example using Java bytecode) or 30%
faster than agents whose memory operations are checked at run time.

Additionally, by doing the checking at load time it becomes possible to enng
force certain safety policies that are hard or impossible to enforce at run
time. For example, by examining the code of the agent and the associated
"explanation" PCC can verify that a certain interrupt routine terminates
within a given number of instructions executed or that a video frame renng
dering agent can keep up with a given frame rate. Runngtime enforcement
of timing properties of such fine granularity is hard.

* The trusted computing base in PCC is small. PCC is simple and small beng

cause it has to do a relatively simple task. In particular, PCC does not have
to discover on its own whether and why the agent meets the safety policy.

* For the same reason, PCC can operate even on agents expressed in nativeng

code form. And because PCC can verify the code after compilation and opng
timization, the checked code is ready to run without needing an additional
interpreter or compiler on the host. This has serious software engineering
advantages since it reduces the amount of security critical code and it is
also a benefit when the host environment is too small to contain an inng
terpreter or a compiler, such as is the case for many embedded software
systems.

* PCC is general. All PCC has to do is to verify safety explanations and to

match them with the code and the safety policy. By standardizing a lanng
guage for expressing the explanations and a formalism for expressing the
safety policies, it is possible to implement a single algorithm that can perng
form the required check, for any agent code, any valid explanation and a
large class of safety policies. In this sense a single implementation of PCC
can be used for checking a variety of safety policies.

The PCC infrastructure is designed to complement a cryptographic authenng
tication infrastructure. While cryptographic techniques such as digital signg
natures can be used by the host to verify external properties of the agent

220 5 ProofngCarrying Code

program, such as freshness and authenticity, or the author's identity, the
PCC infrastructure checks internal semantic properties of the code such as
what the code does and what it does not do. This enables the host to prevent
safety breaches due to either malicious intent (for agents originating from unng
trusted sources) or due to programming errors (for agents originating from
trusted sources).

However, proofngcarrying code is not without costs. The most notable chalng
lenge to using PCC is the difficulty of producing code annotations and proofs.
In some cases, these can be produced automatically based on some highnglevel
language invariants. But in general a human is required to be involved and the
more complex the safety policy the more onerous the burden of proof can be
expected to be. All that PCC offers in this direction is a way to shift this burng
den from the code received to the code producer who can be expected to have
more computational power, and especially more knowledge of why the code
satisfies the safety policy.

Proofngcarrying code is a witness to the fact that programming language
technology and type theory are the basis of valuable techniques for solving
practical engineering problems. However, in the process of applying these
techniques for the design of a PCC infrastructure, it became necessary to
adapt the offngthengshelf techniques in nonngtrivial ways to the particular apng
plication domain. Some of that adaptation can be carried out in a theoretical
setting, such as the extension of Edinburgh LF to implicit LF, while other parts
involve real engineering.

P a r t I I I
Types and Reasoning
about Programs

6

Logical Relations and a Case Study in
Equivalence Checking

Karl Crary

Logical relations are a fundamental technique for proving properties of prong
gramming languages. Logical relations arise when a property is to be proven
of all wellngformed terms in the language, but that property is not preserved
by one or more of the language's elimination forms. For example, one such
property is termination: if a function expression tfun and its argument targ
both terminate, it does not follow that the application of tfun to targ necessarng
ily terminates.

In cases such as this, it is impossible to prove directly by induction on
typing derivations that all wellngformed terms enjoy the property in question.
However, such a property may nevertheless be true; for example, normalizang
tion holds for all wellngtyped terms in the simply typed lambdangcalculus (TAPL,
Chapter 12). Logical relations surmount this difficulty by proving a stronger
property based on a term's type. In the example above, for tfun one would
show (informally speaking) not only that tfun itself terminates, but also that
any application of tfun to a terminating argument also terminates.

The classic application of logical relations is to prove various sorts of terming
nation properties, especially strong normalization (Tait, 1967). A very simple
example of a logical relation argument is given in TAPL, Chapter 12, to prove
a simple termination result. However, the technique has wide applicability
beyond just termination properties. This chapter will develop the technique
of logical relations via a case study in decision procedures for equivalence
of terms. Then, the next chapter will exploit this technique in developing a
powerful theory of typed operational reasoning.

This chapter draws on material from TAPL, Chapters 1 through 12, 23,
and 29. As usual, we will identify terms that differ only in the names of bound
variables, and our substitution is capture avoiding. (Recall TAPL, $5.3.)

224 6 Logical Relations and a Case Study in Equivalence Checking

Syntax

t ::= terms:

x variable
*x:T.t abstraction
t t application
k constant
T ::= types:

b base type
T!T type of functions
\Gamma  ::= contexts:

; empty context
\Gamma  ; x:T term variable binding

Typing \Gamma  ` t : T

x:T 2 \Gamma 
\Gamma  ` x : T (TngVar)
\Gamma  ; x:T1 ` t2 : T2
\Gamma  ` *x:T1.t2 : T1!T2 (TngAbs)
\Gamma  ` t1 : T11!T12 \Gamma  ` t2 : T11

\Gamma  ` t1 t2 : T12 (TngApp)

\Gamma  ` k : b (TngConst)

Equivalence \Gamma  ` s j t : T

\Gamma  ` t : T
\Gamma  ` t j t : T (QngRefl)
\Gamma  ` t j s : T
\Gamma  ` s j t : T (QngSymm)
\Gamma  ` s j t : T \Gamma  ` t j u : T

\Gamma  ` s j u : T (QngTrans)
\Gamma  ; x:T1 ` s2 j t2 : T2
\Gamma  ` *x:T1.s2 j *x:T1.t2 : T1!T2 (QngAbs)
\Gamma  ` s1 j t1 : T1!T2 \Gamma  ` s2 j t2 : T1

\Gamma  ` s1 s2 j t1 t2 : T2

(QngApp)
\Gamma  ; x:T1 ` s12 j t12 : T2 \Gamma  ` s2 j t2 : T1

\Gamma  ` (*x:T1.s12) s2 j E,x , t2G*t12 : T2

(QngBeta)
\Gamma  ; x:T1 ` s x j t x : T2

\Gamma  ` s j t : T1!T2 (QngExt)

Figure 6ng1: Simply typed lambdangcalculus with a base type (*!b)

6.1 The Equivalence Problem

We are concerned with the problem of determining whether or not two terms
in the simply typed lambda calculus are equivalent. The system we will conng
sider is formulated in Figure 6ng1. In order that the problem not be trivial, the
system includes a single base type b that is inhabited by an unspecified set
of constants. The constants are ranged over by the metavariable k.

The equivalence judgment, which will be our key subject of concern, is
written \Gamma  ` s j t : T, meaning that (in context \Gamma  ) the terms s and t are
equivalent, when considered as members of the type T. (The alert reader may
observe that the type T at which terms are compared does not play an imporng
tant role in the rules in Figure 6ng1; however, it will be of critical importance
in our future developments.) It is important to observe that this notion of
equivalence is defined directly, rather than by an appeal to an operational

6.2 NonngTypengDirected Equivalence Checking 225
semantics. For this reason, this form of equivalence is often referred to as
definitional equivalence.

The equivalence system consists of seven rules. The first three rules exng
press that term equivalence is an equivalence relation, and the next two rules
express that it is a congruence with respect to abstraction and application.
Finally, there are two substantiative rules. The first expresses that a beta reng
dex is equivalent to its contractum. The second is an extensionality principle;
it says that two functions (i.e., terms of type T1!T2) are equivalent if all apng
plications to an argument are equivalent.1 (A variable is used to stand in for
all possible arguments.)

Motivation
Term equivalence is important for a variety of reasons, but one of the most
important applications of the system relates not to the equivalence of terms,
but of types. Recall the language *! from TAPL, Chapter 29. In *! the type
system provided type expressions of higher kind in order to provide a facility
for type operators. As a result, the type system of *! was essentially a copy
of the simply typed lambda calculus "one level up," in which terms became
types and types became kinds.

Conversely, we may view the simply typed lambda calculus as the type
system of *! viewed "one level down," in which types become terms and
kinds become types. Thus, the type b in *!b corresponds to the kind * of
types in *!. By solving the problem of checking equivalence of terms, we
also learn how to check equivalence of types, which is in turn essential to the
problem of type checking.

Note that *!b contains no actual terms standing for types such as Nat;
they correspond to the uninterpreted constants k of type b. Terms standing
for builtngin type operators such as ! would correspond to constants of type
b!b!b. For simplicity, we include no such builtngin operators, but they would
be easy to add.

6.2 NonngTypengDirected Equivalence Checking

The most common strategy for checking for term equivalence is normalizeng
andngcompare. To determine whether two wellngtyped terms, say s and t, are

1. Although extensionality considerably broadens definitional equivalence, many systems preng
fer to omit extensionality because it can sometimes complicate equivalence checking. However,
for the approach to equivalence checking we discuss in this chapter, extensionality actually
simplifies matters, so we do not hesitate to include it.

226 6 Logical Relations and a Case Study in Equivalence Checking

equal, the strategy computes their normal forms s0 and t0 using a reduction
relation derived from the equivalence rules and then compares to see if s0
and t0 are identical.2 The original terms s and t are equivalent if and only if
the normal forms s0 and t0 are identical.

Normalizengandngcompare relies on three facts:

* One must be able to derive a reduction relation s)t from the equivalence

rules. This relation must be suitable in the sense that, if \Gamma  ` s : T and
\Gamma  ` t : T, then \Gamma  ` s j t : T iff s a* t, where a* is the symmetric,
transitive closure of ). For *!b a suitable relation is given in Figure 6ng2.

* The reduction relation must be confluent, meaning that if r )* s and

r )* t then there exists some term u such that s )* u and t )* u. If the
relation is confluent, then its symmetric, transitive closure may be decided
by comparing normal forms, as stated by Lemma 6.2.1 below.

* The reduction relation must be normalizing, meaning that every term must

have a normal form, and those normal forms must be effectively comng
putable. Given the existence and computability of normal forms, one may
use the preceding two facts to show that two terms are equivalent exactly
when their normal forms coincide.

6.2.1 Lemma: Suppose ) is confluent and the normal forms of s and t are s0 and

t0. Then sa*t iff s0 = t0. 2

Proof: Exercise [n'n', 3]. 2

In summary, to employ the normalizengandngcompare strategy, one must deng
fine a suitable reduction relation, and prove that it is suitable, confluent, and
normalizing. In some cases, the strategy is not applicable, either because the
suitable relation fails to be confluent and normalizing, or because no suitable
relation can be defined in the first place. It is this latter case that will arise
in the next section. In fact, many proofs of normalization employ a logical
relation (such as those in the presence of polymorphism [Girard, Lafont, and
Taylor, 1989]), so the normalizengandngcompare strategy, even when applicable,
often still involves logical relations.

6.2.2 Exercise [n'n']: Prove one half of the suitability of ) for definitional equivng

alence: if \Gamma  ` s j t : T then s a* t. (Hint: in the case for QngExt, use the
reduction rule QRngEta.) 2

2. Actually, nearly all implementations of equivalence checkers refine this strategy to interng
leave comparison with the computation of normal forms. This is done for two reasons: First, if
the terms are inequivalent, it can be detected earlier. Second, once any corresponding compong
nents of the normal forms are determined to be equivalent, they can be discarded. Thus, one
can avoid storing the entire normal forms, which can be large.

6.3 TypengDriven Equivalence 227
Parallel reduction s ) t

t ) t (QRngRefl)
s2 ) t2
*x:T1.s2 ) *x:T1.t2 (QRngAbs)

s1 ) t1 s2 ) t2

s1 s2 ) t1 t2 (QRngApp)

s1 ) t1 s2 ) t2
(*x:T1.s1) s2 ) E,x , t2G*t1 (QRngBeta)

s ) t x not free in s

*x:T.s x ) t (QRngEta)

Figure 6ng2: Parallel reduction of terms
New syntactic forms

t ::= . . . terms:

unit unit term
T ::= . . . types:

Unit unit type

Typing \Gamma  ` t : T

\Gamma  ` unit : Unit (TngUnit)

Equivalence \Gamma  ` s j t : T

\Gamma  ` s : Unit \Gamma  ` t : Unit

\Gamma  ` s j t : Unit (QngUnit)

Figure 6ng3: Unit type (*!b1)

6.2.3 Exercise [n'n']: Because of the rule QRngEta, the reduction relation ) is conflung

ent only for wellngtyped terms. Give an example of an illngtyped term for which
confluence fails. 2

6.3 TypengDriven Equivalence

One case in which the normalizengandngcompare strategy is inapplicable is when
the definition of equivalence is type sensitive. The example we will work with
arises when we add a second base type corresponding to Unit (recall TAPL,

$11.2). The important thing about this type is that it contains exactly one
element; the sole element of Unit is written unit. These additions are sumng
marized in Figure 6ng3.

The interesting facet of the extension with unit is its equivalence rule:

\Gamma  ` s : Unit \Gamma  ` t : Unit

\Gamma  ` s j t : Unit (QngUnit)
This rule expresses the fact that, since the type Unit contains exactly one
element, any two elements of Unit must actually be the same. It is important

228 6 Logical Relations and a Case Study in Equivalence Checking

to note that this rule is strictly stronger than the alternative rule:

\Gamma  ` unit j unit : Unit (QngUnitngWeak)
Although QngUnitngWeak is sound (indeed, it is derivable from either QngUnit
or QngRefl), it cannot derive equivalences involving unit variables, such as:

TngUnitx:Unit; y:Unit ` x : Unit TngUnitx:Unit; y:Unit ` y : Unit

QngUnitx:Unit; y:Unit ` x j y : Unit

This example also illustrates why the normalizengandngcompare strategy is
inapplicable once the unit type is added. The terms x and y must be judged to
be equivalent, but the reason for this has nothing to do with the form of x or
y. Indeed, x and y are already in normal form according to the usual reduction
relation. The terms must be judged equivalent because of their types, and the
normalizengandngcompare strategy has no way to account for that.

There are a variety of ways to address this difficulty. Many repair the
normalizengandngcompare strategy by, in one way or another, giving it the abilng
ity to exploit type information. However, we will consider an entirely different
strategy, an algorithm that tests for equivalence directly, without computing
normal forms.

6.3.1 Exercise [n']: The need for types in deciding equivalence is not limited to

open terms. Give two closed terms that are equivalent but have distinct norng
mal forms. 2

6.4 An Equivalence Algorithm

We wish to devise an algorithm for the equivalence problem. Stated precisely,
the problem is this: Supposing \Gamma  ` s : T and \Gamma  ` t : T, determine whether or
not \Gamma  ` s j t : T.

To solve this problem, we will employ a typengdriven algorithm. This algong
rithm is based on two main observations:

1. If T is Unit, we can immediately return true. This is because we then have

\Gamma  ` s : Unit and \Gamma  ` t : Unit from our assumptions, and \Gamma  ` s j t :
Unit follows directly by QngUnit.

2. If T is T1!T2, we can reduce the problem to a related problem where T is

just T2. To do so, we replace any query of the form:

\Gamma  ` s ?j t : T1!T2

6.4 An Equivalence Algorithm 229

with the equivalent query:

\Gamma  ; x:T1 ` s x ?j t x : T2
These queries are equivalent because the latter judgment immediately imng
plies the former using the QngExt rule, and the former implies the latter
using the QngApp rule and a weakening lemma:

6.4.1 Lemma [Weakening]: If \Gamma  ` s j t : T then \Gamma  ; x:S ` s j t : T. 2

Proof: Straightforward induction on equivalence and typing derivations.
(Recall TAPL Lemma 9.3.7.) 2

The significance of these observations is that they give us a means to reng
duce an equivalence problem at an arbitrary type to one at the base type b.
Therefore, it remains only to find an algorithm that decides equivalence at
type b.

Equivalence at Base Type
At type b we can use a variant of the normalizengandngcompare strategy. Inforng
mally, this is because we address elsewhere the type Unit, which mandated
typengdirected consideration. The normalization phase (discussed in detail beng
low) will place the equivalence problem in one of five forms (or a symmetric
form):3

1. \Gamma  ` x s1 ... sn ?j x t1 ... tn : b
2. \Gamma  ` k ?j k : b
3. \Gamma  ` x s1 ... sm ?j y t1 ... tn : b (where x T^ y)

4. \Gamma  ` x s1 ... sn ?j k : b
5. \Gamma  ` k ?j k0 : b (where k T^ k0)

Clearly, in case 2 we may immediately return true, and in case 5 we may
immediately return false. We may also return false in case 3, since we know
nothing about what the variables x and y represent, and therefore they could
return distinct types. Similarly, we can return false for case 4.

3. Note that in case 1, x must be applied to the same number of arguments on each side, since
both sides have the same type.

230 6 Logical Relations and a Case Study in Equivalence Checking

However, in case 1, a subtlety remains: Suppose, for example, that we wish
to determine whether x s j x t : b, where x has the type T!b, and s and t
have type T. Since we know nothing about what the variable x represents, this
equivalence holds exactly when s j t : T. Thus, although x s j x t : b is an
equivalence problem at type b, to decide it we must still decide an equivalence
problem at type T (which could be anything, such as Unit), and we have seen
that we cannot do so with a simple syntactic comparison.

Thus, if the normalization portion of the normalizengandngcompare phase
writes the problem in the form:

\Gamma  ` x s1 ... sn ?j x t1 ... tn : b
the comparisons of si to ti should be done using the entire typengdriven algong
rithm, and not simple syntactic comparison.

Weak Head Normalization
One additional insight is necessary to understand the algorithm. Since the
comparison portion works on a term of the form x t1 ... tn by using the
entire algorithm on the subterms ti, there is no point in normalizing the
term any more than is required to put it in that form.

For example, if we wish to determine whether x s j x t : b, where x has the
type Unit!b, and s and t have type Unit, the answer will always be true, so
any effort spent normalizing s or t is wasted.

Consequently, our algorithm will employ a less aggressive form of norng
malization called weak head normalization. In weak head normalization, the
leftmost, outermost redex is always selected for reduction, and the process
is halted as soon as the term begins with something other than a lambda
abstraction.

Such terms of type b will always either be a constant k or be in the form
x t1 ... tn. These terms are called paths. (Although some other terms--such
as abstractions--are also weak head normal, those other terms cannot have
type b so they will not arise.)

The Algorithm
An algorithm based on the preceding observations is given in Figure 6ng4. The
algorithm is given in the form of rules defining four relations:

1. Algorithmic term equivalence: \Gamma  ` s a t : T. This portion of the algorithm

is directed by the type T. It works by driving the type T down to b. All of \Gamma  ,
s, t, and T are inputs to this relation.

6.4 An Equivalence Algorithm 231
Syntax
p; q ::= paths:

x variable
p t application
k constant

Weak head reduction s ; t

(*x:T11.t12) t2 ; E,x , t2G*t12 (QARngBeta)

t1 ; t01
t1 t2 ; t01 t2 (QARngApp)

Weak head normalization s + t

s ; t t + u

s + u (QANngReduce)

t 6;
t + t (QANngNormal)

Algorithmic term equivalence \Gamma  ` s a t : T

s + p t + q \Gamma  ` p $ q : b

\Gamma  ` s a t : b (QATngBase)
\Gamma  ; x:T1 ` s x a t x : T2

\Gamma  ` s a t : T1!T2 (QATngArrow)

\Gamma  ` s a t : Unit (QATngOne)

Algorithmic path equivalence \Gamma  ` p $ q : T

x:T 2 \Gamma 
\Gamma  ` x $ x : T (QAPngVar)
\Gamma  ` p $ q : T1!T2 \Gamma  ` s a t : T1

\Gamma  ` p s $ q t : T2

(QAPngApp)

\Gamma  ` k $ k : b (QAPngConst)

Figure 6ng4: Equivalence algorithm for *!b1

2. Algorithmic path equivalence: \Gamma  ` p $ q : T. This portion of the algorithm

is directed by the structure of the paths p and q. It works by checking
that the head variables of p and q are the same (or that p and q are the
same constant), and then comparing corresponding subterms of the path
for algorithmic term equivalence. The type T is an output of this relation,
and \Gamma  , p, and q are inputs.

3. Weak head reduction: s ; t. This portion of the algorithm reduces one

redex at the head of the term s. It implements one step of weak head
normalization.

4. Weak head normalization: s + t. This portion of the algorithm computes

weak head normal forms by performing weak head reductions until no
more can be performed. (We write t 6; to mean that there exists no term
t0 such that t ; t0.)

6.4.2 Exercise [n'n', 3]: Handngexecute the algorithm on:

f:(Unit!Unit)!b ` f (*x:Unit:unit)

?a f (*x:Unit.x) : b!b

2

232 6 Logical Relations and a Case Study in Equivalence Checking

6.4.3 Exercise [n'n'n'n', 3]: Prove that the algorithm is sound. That is, show that if

\Gamma  ` s a t : T (where \Gamma  ` s : T and \Gamma  ` t : T) then \Gamma  ` s j t : T. 2

6.5 Completeness: A First Attempt

There are two parts to showing that the algorithm is correct. First, we wish to
show that the algorithm is sound; that is, that the algorithm says yes only for
equivalent terms. We considered soundness in Exercise 6.4.3. Second, we wish
to show that the algorithm is complete; that is, that the algorithm says yes for
all equivalent terms. Completeness is a good deal trickier than soundness,
and is the subject of the remainder of this chapter.

We wish to show the following result:

6.5.1 Proposition: If \Gamma  ` s j t : T then \Gamma  ` s a t : T. 2

Our first attempt to prove this would naturally be to try proving it directly
by induction on derivations. This attempt encounters a variety of difficulties,
most of which are surmountable. Because of the QngRefl rule, we must first
prove something about typing:

6.5.2 Proposition: If \Gamma  ` t : T then \Gamma  ` t a t : T. 2

With this addition, several cases for the two propositions go through withng
out difficulty: for Proposition 6.5.1, TngConst and TngUnit; and for Proposing
tion 6.5.2, QngRefl, QngExt, and QngUnit. Four other rules are more difficult, but
can be dealt with, as follows:

* Cases QngSymm and QngTrans: For these cases, we must prove lemmas stating

that the algorithm is symmetric and transitive (Lemmas 6.5.3 and 6.5.4
below).

* Case QngAbs (TngAbs is similar): Here we wish to show that \Gamma  ` *x:T1.s2 a

*x:T1.t2 : T1!T2, for which we must prove that:

\Gamma  ; x:T1 ` (*x:T1.s2)x a (*x:T1.t2)x : T2
However, the induction hypothesis provides us a related but different fact:

\Gamma  ; x:T1 ` s2 a t2 : T2
To conclude this case from the available information, we need another
lemma stating that the algorithm is closed under weak head expansion
(Lemma 6.5.5 below).

6.6 Logical Relations 233
6.5.3 Lemma [Algorithmic Symmetry]: If \Gamma  ` s a t : T then \Gamma  ` t a s : T. 2
6.5.4 Lemma [Algorithmic Transitivity]: If \Gamma  ` s a t : T and \Gamma  ` t a u : T

then \Gamma  ` s a u : T. 2

Proof: Both proofs are by induction on derivations, with a simultaneous inng
duction showing the analogous property for algorithmic path equivalence. 2

6.5.5 Lemma [Algorithmic Weak Head Closure]: If \Gamma  ` s a t : T and s0 ;* s

and t0 ;* t then \Gamma  ` s0 a t0 : T. 2

Proof: By induction on the derivation of algorithmic term equivalence. 2
6.5.6 Exercise [n', 3]: Verify Lemma 6.5.5. 2

Trouble with Application
This leaves four rules: two dealing with application (TngApp and QngApp), and two
dealing with variables and substitution (TngVar and QngBeta). It is the applicang
tion rules that bring the proof attempt to a standstill.4

The essential problem is that the induction hypothesis gives us no inforng
mation about what happens when a term is applied to an argument. Consider
the case QngApp:

\Gamma  ` s1 j t1 : T1!T2 \Gamma  ` s2 j t2 : T1

\Gamma  ` s1 s2 j t1 t2 : T2 (QngApp)
The induction hypothesis gives us that \Gamma  ` s1 a t1 : T1!T2 and \Gamma  ` s2 a
t2 : T1. We wish to conclude that \Gamma  ` s1 s2 a t1 t2 : T2, but we cannot.

By inversion on \Gamma  ` s1 a t1 : T1!T2 we obtain the fact that \Gamma  ; x:T1 `
s1 x a t1 x : T2, but that is as close as we get, since the behavior of the algong
rithm comparing s1 x to t1 x is entirely different from its behavior comparing
s1 s2 to t1 t2.

6.6 Logical Relations

The problem discussed above arises because the algorithmic equivalence reng
lation is not logical, in the following sense:5

4. The variable and substitution rules could be addressed using a device we develop in Secng
tion 6.9, but we will not bother to employ it here, since this proof attempt is doomed by
application.
5. Actually, it is more precise to say that algorithmic term equivalence is not evidently logical;
that is, we cannot prove it at this stage in the proof. (See Exercise 6.9.12.)

234 6 Logical Relations and a Case Study in Equivalence Checking

6.6.1 Definition: Suppose RD^s; t; TE^ is a relation indexed by types T, such that s

and t are terms having type T. Then R is logical if whenever RD^s1; t1; T1!T2E^
and RD^s2; t2; T1E^ hold, it follows that RD^s1 s2; t1 t2; T2E^ also holds. 2

That is, a relation is logical when the relatedness of two applications s1 s2
and t1 t2 is inherited from the pairwise relatedness of their constituent funcng
tion and argument (s1 with t1, and s2 with t2). Such a relation is called
"logical" because it respects the actions of the logical operators (in this case
implication) that correspond to the language's type constructors.

The idea behind proof by logical relations is to circumvent problems resultng
ing from the absence of logicality by defining another relation that is logical,
and that also implies the desired property (in this case algorithmic equivang
lence). The new, logical relation is then used in the induction hypothesis in
the proof.

Our overall proof strategy, then, consists of three stages:

1. Define a suitable logical relation. When two terms are related by the logical

relation, we will say that they are logically equivalent.

2. Show that logical equivalence implies algorithmic equivalence.
3. Show that definitional equivalence implies logical equivalence.

A Logical Relation
A direct way to define a logical relation is essentially by fiat. The definition
proceeds inductively by cases on the index type, asserting algorithmic equivng
alence at base types, and asserting exactly the necessary property at function
types. This gives us the following first attempt at a definition of logical equivng
alence:

\Gamma  ` s is t : T if and only if either:

T=Unit,
or T=b and \Gamma  ` s a t : b,
or T=T1!T2 and for all s0, t0,

if \Gamma  ` s0 is t0 : T1
then \Gamma  ` s s0 is t t0 : T2.

Note that the first clause of the definition could equivalently be "T=Unit and
\Gamma  ` s a t : Unit," since the algorithmic equivalence at Unit always holds.

6.6 Logical Relations 235
Monotonicity
This relation is clearly logical, and at base types it just as clearly implies alng
gorithmic equivalence. The question is, does it imply algorithmic equivalence
at function types? The answer turns out to be almost, but not quite:

Suppose \Gamma  ` s is t : T1!T2. We wish to show that \Gamma  ` s a t : T1!T2, for
which it is sufficient to show:

\Gamma  ; x:T1 ` s x a t x : T2
Since T2 is smaller than T1!T2, we can conclude by induction that the desired
algorithmic equivalence follows from the corresponding logical equivalence.
Thus it remains to show:

\Gamma  ; x:T1 ` s x is t x : T2
From the definition of logical equivalence, we can deduce the desired logical
equivalence from:

1. \Gamma  ; x:T1 ` s is t : T1!T2, and
2. \Gamma  ; x:T1 ` x is x : T1.

The latter is not obvious, but we will be able to prove it (for our final defng
inition). The former, on the other hand, is very similar to our assumption,
\Gamma  ` s is t : T1!T2. All we need to know is that logical equivalence is
preserved when bindings are added to the context. This property is called
monotonicity (or, preservation under weakening).

Failure of Monotonicity
Unfortunately, monotonicity fails for our current definition of logical equivang
lence. It is not difficult to show monotonicity for the algorithm:

6.6.2 Lemma [Algorithmic Monotonicity]: Suppose \Gamma  0 ' \Gamma  . Then:

1. If \Gamma  ` s a t : T then \Gamma  0 ` s a t : T.
2. If \Gamma  ` p $ q : T then \Gamma  0 ` p $ q : T. 2

Proof: By induction on derivations. 2

The lemma gives us monotonicity of logical equivalence for type b, and
logical equivalence is trivially monotone for type Unit. That leaves T1!T2,
where monotonicity fails.

236 6 Logical Relations and a Case Study in Equivalence Checking

To see why, let us attempt to prove the special case where the context is
extended with a single binding. We suppose \Gamma  ` s is t : T1!T2 and attempt
to show \Gamma  ; x:S ` s is t : T1!T2. By the definition, it is sufficient to show
that if \Gamma  ; x:S ` s0 is t0 : T1 then \Gamma  ; x:S ` s s0 is t t0 : T2. Since T2 is
smaller than T1!T2, induction gives us monotonicity for T2, so it is sufficient
to show that \Gamma  ` s s0 is t t0 : T2. This follows from our original supposition
by the definition of logical equivalence, provided that \Gamma  ` s0 is t0 : T1.
Unfortunately, our second supposition provides only \Gamma  ; x:S ` s0 is t0 : T1.
Thus, at type T1 we need not monotonicity (which induction could provide),
but the converse, antitonicity (or, preservation under strengthening), which is
certainly false.

6.6.3 Exercise [n']: Let antitonicity be the property that if \Gamma  ; x:S ` s is t : T then

\Gamma  ` s is t : T. Produce a counterexample for antitonicity. 2

6.6.4 Exercise [n'n'n']: Suppose the language contains exactly one constant k. Prong

duce a counterexample for monotonicity and give the proof. 2

6.7 A Monotone Logical Relation

Earlier we addressed the problem of logicality by fiat, crafting a definition
that provided exactly the necessary property. We can address the problem of
monotonicity in essentially the same manner. The problem is that the defining
tion's clause for function types could hold for a context \Gamma  , but not evidently
hold for a larger context \Gamma  0.

To resolve this difficulty, we revise the definition so that the clause for
function types must hold not only for the current context \Gamma  , but also for any
extended context \Gamma  0 ' \Gamma  . This gives us our final definition of logical equivang
lence:

6.7.1 Definition [Logical Equivalence]:

\Gamma  ` s is t : T if and only if either:

T=Unit,
or T=b and \Gamma  ` s a t : b,
or T=T1!T2 and, for all s0, t0 and all \Gamma  0 ' \Gamma  ,

if \Gamma  0 ` s0 is t0 : T1
then \Gamma  0 ` s s0 is t t0 : T2. 2

With this definition, we can easily prove the monotonicity of logical equivang
lence:

6.7.2 Lemma [Logical Monotonicity]: If \Gamma  ` s is t : T and \Gamma  0 ' \Gamma  then \Gamma  0 ` s is

t : T. 2

6.8 The Main Lemma 237
Proof: By induction on T, appealing to algorithmic monotonicity in the case
where T = b. 2

An Aside
A logical relation made monotone in this manner is often called a Kripke logng
ical relation, by analogy to Kripke models for modal logic. Modal logic is a
form of logic designed for reasoning about the differences between various
degrees or forms of truth, typically including contingent truths--truths that
happen to hold given the existing state of affairs--and necessary (or "cateng
gorical") truths, which must hold in any reasonable state of affairs.

A Kripke model for modal logic is based on a set of "worlds," where each
world supports a different set of truths. The set of worlds is additionally
structured by a notion of which worlds are "reachable" from which other
worlds. In such a model, a contingent truth is one that holds in the current
world, and a necessary truth is one that holds in all worlds reachable from the
current world. (Any world not reachable from the current world is ignored,
since there is no way to observe its existence.)

The connection to Kripke models arises in the logical relation's use of a
context \Gamma  , which we may view as specifying a world. Each world provides a
different set of variables, and we may reach another world by adding variables
to the current context. Thus, when we require that our logical relation be
monotone (that is, that it continues to hold in all reachable contexts), we are
saying that we are interested in necessary equivalence, not accidental (i.e.,
contingent) equivalence.6

6.8 The Main Lemma

With a monotone logical relation in hand, we are now ready to prove the comng
pleteness of the algorithm. Recalling our proof strategy from page 234, we
have accomplished the first step, the definition of a suitable logical relation.
We now wish to show that logical equivalence implies algorithmic equivang
lence. It will then remain to show that definitional equivalence implies logical
equivalence.

The former fact is established by the following "main lemma." The Main
Lemma actually establishes two facts simultaneously. First, it shows that
logical equivalence implies algorithmic equivalence. To appreciate the secng
ond fact, recall (from page 235) that to show that logical implies algorithmic

6. Exercise 6.6.4 in essence asks you to produce an example of an accidental equivalence, one
that holds only in a certain world.

238 6 Logical Relations and a Case Study in Equivalence Checking

equivalence, we also need to establish that variables are logically equivalent
to themselves. To do so, we prove the stronger result that algorithmically
equivalent paths are logically equivalent. The necessary result for variables
follows, since a variable is always algorithmically path equivalent to itself
(rule QAPngVar).

In the following proof, observe how inseparably the two induction hypotheng
ses of the lemma are intertwined. It is typical of logical relations proofs to use
a lemma such as this, wherein one clause of the lemma establishes the logical
relation and the other clause exploits it. This structure of the proof usually
results from the definition of the logical relation in the arrow case, where the
relation appears on both the left and the right of the implication.

6.8.1 Lemma [Main Lemma]:

1. If \Gamma  ` s is t : T then \Gamma  ` s a t : T.
2. If \Gamma  ` p $ q : T then \Gamma  ` p is q : T. 2

Proof: By induction on T.
Case: T C^ b

1. Suppose \Gamma  ` s is t : b. By definition, \Gamma  ` s a t : b.

2. Suppose \Gamma  ` p $ q : b. Since p and q are paths, it follows that p 6; and

q 6;, so p + p and q + q by QANngNormal. Therefore \Gamma  ` p a q : b by
QATngBase, and \Gamma  ` p is q : b follows by the definition.

Case: T C^ Unit

1. For any s and t, \Gamma  ` s a t : Unit by QATngOne.

2. For any p and q, \Gamma  ` p is q : Unit by the definition.
Case: T C^ T1!T2

1. Suppose \Gamma  ` s is t : T1!T2. We wish to show that \Gamma  ` s a t : T1!T2.

It is sufficient to show that \Gamma  ; x:T1 ` s x a t x : T2. This will follow by
induction, if we can show that \Gamma  ; x:T1 ` s x is t x : T2.

By induction (using the second clause), since \Gamma  ; x:T1 ` x $ x : T1 (by
QAPngVar), we may deduce that \Gamma  ; x:T1 ` x is x : T1. Therefore, since
D^\Gamma  ; x:T1E^ ' \Gamma  , we may conclude that \Gamma  ; x:T1 ` s x is t x : T2, as desired.

2. Suppose \Gamma  ` p $ q : T1!T2. We wish to show that \Gamma  ` p is q : T1!T2.

Suppose further that \Gamma  0 ' \Gamma  and \Gamma  0 ` s is t : T1. Then we wish to show

6.9 The Fundamental Theorem 239

that \Gamma  0 ` p s is q t : T2. This will follow by induction, if we can show that
\Gamma  0 ` p s $ q t : T2.

By induction (using the first clause), \Gamma  0 ` s a t : T1. By algorithmic monong
tonicity (Lemma 6.6.2), \Gamma  0 ` p $ q : T1!T2. Therefore, by rule QAPngApp,
\Gamma  0 ` p s $ q t : T2, as required. 2

6.9 The Fundamental Theorem

The final step in the completeness proof is to show that definitional equivang
lence implies logical equivalence. We will refer to the theorem showing this
fact as the "Fundamental Theorem."

Recall our attempted proof from Section 6.5. The principal problem we enng
countered was with application; we could not deduce from the algorithmic
equivalence of two functions anything about the equivalence of their applicang
tions to arguments. We have solved that problem by using a logical relation,
which explicitly provides the necessary conclusions about applications.

Structural Properties of Logical Equivalence
Since we are now using logical equivalence in place of algorithmic equivang
lence, we must revisit some of our other devices from Section 6.5. To adng
dress the QngSymm, QngTrans, QngAbs, and TngAns, we showed that the algorithm is
symmetric, transitive, and closed under weak head reduction (Lemmas 6.5.3,
6.5.4, and 6.5.5). We will now require analogs of these lemmas applicable to
logical equivalence:

6.9.1 Lemma [Logical Symmetry]: If \Gamma  ` s is t : T then \Gamma  ` t is s : T. 2

Proof: By induction on T, appealing to algorithmic symmetry (Lemma 6.5.3)
in the case where T = b. 2

6.9.2 Lemma [Logical Transitivity]: If \Gamma  ` s is t : T and \Gamma  ` t is u : T then

\Gamma  ` s is u : T. 2

Proof: Exercise [Recommended, n'n', 3]. 2
6.9.3 Lemma [Logical Weak Head Closure]: If \Gamma  ` s is t : T and s0 ;* s and

t0 ;* t then \Gamma  ` s0 is t0 : T. 2

Proof: By induction on T; in the case where T = b, we appeal to algorithmic
weak head closure (Lemma 6.5.5). 2

240 6 Logical Relations and a Case Study in Equivalence Checking

Closure under Substitution
There remain two more cases we did not consider in Section 6.5, TngVar and
QngBeta. We could deal with TngVar immediately, since a consequence of the
Main Lemma is that variables are logically equivalent to themselves. However,
we will actually end up dealing with TngVar somewhat differently in light of one
last remaining complication. (See the TngVar case of Theorem 6.9.8.)

That final complication stems from the rule QngBeta:

\Gamma  ; x:T1 ` s12 j t12 : T2 \Gamma  ` s2 j t2 : T1

\Gamma  ` (*x:T1.s12) s2 j E,x , t2G*t12 : T2 (QngBeta)
Suppose we employ the obvious induction hypothesis: if \Gamma  ` s j t : T then
\Gamma  ` s is t : T. Then, for the QngBeta case, we need to show that:

\Gamma  ` (*x:T1.s12) s2 is E,x , t2G*t12 : T2
Using logical weak head closure (Lemma 6.9.3), it is sufficient to show that:

\Gamma  ` E,x , s2G*s12 is E,x , t2G*t12 : T2
Induction provides us with \Gamma  ; x:T1 ` s12 j t12 : T2 and \Gamma  ` s2 j t2 : T1.

Thus, we could complete the proof by showing that logical equivalence is
closed under logically equivalent substitutions. Unfortunately, it is not clear
how to prove such a proposition at this stage in the completeness proof, as
the form of the logical relation gives us no leverage on the matter.

The Theorem
Fortunately, we can work around this difficulty by building this notion of
equivalent substitutions into the Fundamental Theorem itself. First we reng
quire a few definitions:

6.9.4 Definition [Substitutions]: A substitution is a function from some set of

variables to terms. 2

6.9.5 Definition [Substitutions and Terms]: Suppose fl is a substitution and t

is a term such that the free variables of t are contained in domD^flE^. Then we
write flD^tE^ to refer to the term resulting from simultaneously carrying out on
t all the substitutions specified by fl. 2

6.9.6 Definition [Substitution Extension]: Suppose x 62 domD^flE^. Then we deng

fine flE,x , tG* as the substitution with domain domD^flE^ [ {x} such that:

D^flE,x , tG*E^D^yE^ C^ (flD^yE^ x T^ yt x C^ y 2

6.9 The Fundamental Theorem 241
6.9.7 Definition [Logically Equivalent Substitutions]: Logical equivalence of

substitutions is defined as follows:

\Gamma  0 ` fl is ffi : \Gamma  if domD^flE^ C^ domD^ffiE^ C^ domD^\Gamma  E^ and for every x:T 2 \Gamma  we
have \Gamma  0 ` flD^xE^ is ffiD^xE^ : T. 2

Now we can state the Fundamental Theorem by uniformly considering all
equivalences under the application of equivalent substitutions. Since typing
never depends on equivalence, we can separate the Fundamental Theorem
into two parts (one for typing and one for equivalence) and prove each in
turn.

6.9.8 Theorem [Fundamental Theorem 1]: If \Gamma  ` t : T and \Gamma  0 ` fl is ffi : \Gamma  then

\Gamma  0 ` flD^tE^ is ffiD^tE^ : T. 2

Proof: By induction on derivations. We show several cases; the rest are left
as exercises.

Case TngVar: t C^ x

with x:T 2 \Gamma 

By assumption, \Gamma  0 ` flD^xE^ is ffiD^xE^ : T.
Case TngAbs: t C^ *x:T1.t2

T C^ T1!T2

We wish to show that \Gamma  0 ` flD^*x:T1.t2E^ is ffiD^*x:T1.t2E^ : T1!T2. Suppose
\Gamma  00 ' \Gamma  0 and \Gamma  00 ` s0 is t0 : T1. We wish to show that \Gamma  00 ` (*x:T1:flD^t2E^)s0 is
(*x:T1:ffiD^t2E^)t0 : T2. By logical weak head closure (Lemma 6.9.3), it is suffing
cient to show that \Gamma  00 ` E,x , s0G*flD^t2E^ is E,x , t0G*ffiD^t2E^ : T2.

By logical monotonicity, \Gamma  00 ` fl is ffi : \Gamma  . Thus, \Gamma  00 ` flE,x , s0G* is
ffiE,x , t0G* : D^\Gamma  ; x:T1E^. Therefore, by induction, \Gamma  00 ` flE,x , s0G*D^t2E^ is ffiE,x ,
t0G*D^t2E^ : T2, which is equivalent to the desired conclusion.

Case TngApp: t C^ t1 t2

T C^ T12

By induction, \Gamma  0 ` flD^t1E^ is ffiD^t1E^ : T1!T2 and \Gamma  0 ` flD^t2E^ is ffiD^t2E^ : T1.
By the definition of the logical relation, since \Gamma  0 ' \Gamma  , we may conclude \Gamma  0 `
flD^t1E^flD^t2E^ is ffiD^t1E^ffiD^t2E^ : T2. That is, \Gamma  0 ` flD^t1 t2E^ is ffiD^t1 t2E^ : T2. 2

6.9.9 Theorem [Fundamental Theorem 2]: If \Gamma  ` s j t : T and \Gamma  0 ` fl is ffi : \Gamma 

then \Gamma  0 ` flD^sE^ is ffiD^tE^ : T. 2

Proof: By induction on derivations. We show one case; the rest are left as
exercises.

242 6 Logical Relations and a Case Study in Equivalence Checking

Case QngBeta: s C^ (*x:T1.s12) s2

t C^ E,x , t2G*t12 : T2
T C^ T2

By induction, \Gamma  0 ` flD^s2E^ is ffiD^t2E^ : T1. Thus \Gamma  0 ` flE,x , flD^s2E^G* is ffiE,x ,
ffiD^t2E^G* : D^\Gamma  ; x:T1E^. Therefore, by induction:

\Gamma  0 ` flE,x , flD^s2E^G*D^s12E^ is ffiE,x , ffiD^t2E^G*D^t12E^ : T2
By rearranging substitutions:

\Gamma  0 ` E,x , flD^s2E^G*flD^s12E^ is ffiD^E,x , t2G*t12E^ : T2
Finally, by logical weak head closure (Lemma 6.9.3):

\Gamma  0 ` (*x:T1.flD^s12E^)flD^s2E^ is ffiD^E,x , t2G*t12E^ : T2
That is:

\Gamma  0 ` flD^(*x:T1.s12) s2E^ is ffiD^E,x , t2G*t12E^ : T2 2
6.9.10 Exercise [Recommended, n'n'n']: Complete the proof of Theorems 6.9.8 and

6.9.9. 2

Now we can establish the algorithm's completeness, using the Fundamental
Theorem with an identity substitution:

6.9.11 Corollary [Completeness]: If \Gamma  ` s j t : T then \Gamma  ` s a t : T. 2

Proof: Suppose \Gamma  ` s j t : T. Let fl be the identity substitution on domD^\Gamma  E^.
For all x:T in \Gamma  , observe that \Gamma  ` x is x : T by the Main Lemma. Therefore
\Gamma  ` fl is fl : \Gamma  . By the Fundamental Theorem, \Gamma  ` flD^sE^ is flD^tE^ : T, which is
to say \Gamma  ` s is t : T. Therefore \Gamma  ` s a t : T by the Main Lemma. 2

6.9.12 Exercise [n']: An irony arises from the use logical relations to show comng

pleteness: it turns out that algorithmic equivalence actually is logical after all
(at least for wellngformed terms); we just cannot prove it until we have already
proven the algorithm to be sound and complete. Show that if \Gamma  ` s1 a t1 :
T1!T2 and \Gamma  ` s2 a t2 : T1 (where \Gamma  ` s1 : T1!T2, \Gamma  ` t1 : T1!T2, \Gamma  ` s2 : T1,
and \Gamma  ` t2 : T1), then \Gamma  ` s1 s2 a t1 t2 : T2. 2

6.9.13 Exercise [n'n'n'n']: We have shown that the equivalence algorithm is sound

and complete. To show that the algorithm decides the equivalence problem,
it remains to show that it terminates on all wellngformed inputs. Show that if
\Gamma  ` s : T and \Gamma  ` t : T then there exists no infinite proof search rooted in
\Gamma  ` s a t : T.

Hint: Termination is a corollary of completeness. You will not need to prove
any additional nonngtrivial facts about the algorithm. 2

6.10 Notes 243
New syntactic forms

t ::= . . . terms:

ht; ti pair
t.1 first projection
t.2 second projection
T ::= . . . types:

T1 * T2 product type

Typing \Gamma  ` t : T

\Gamma  ` t1 : T1 \Gamma  ` t2 : T2

\Gamma  ` ht1; t2i : T1 * T2 (TngPair)

\Gamma  ` t : T1 * T2

\Gamma  ` t.1 : T1 (TngProj1)
\Gamma  ` t : T1 * T2

\Gamma  ` t.2 : T2 (TngProj2)

Equivalence \Gamma  ` s j t : T

\Gamma  ` s1 j t1 : T1 \Gamma  ` s2 j t2 : T2

\Gamma  ` hs1; s2i j ht1; t2i : T1 * T2 (QngPair)

\Gamma  ` s j t : T1 * T2
\Gamma  ` s.1 j t.1 : T1 (QngProj1)

\Gamma  ` s j t : T1 * T2
\Gamma  ` s.2 j t.2 : T2 (QngProj2)
\Gamma  ` s1 j t : T1 \Gamma  ` s2 : T2

\Gamma  ` hs1; s2i.1 j t : T1

(QngBetangProd1)

\Gamma  ` s2 j t : T2 \Gamma  ` s1 : T1

\Gamma  ` hs1; s2i.2 j t : T2

(QngBetangProd2)

\Gamma  ` s.1 j t.1 : T1 \Gamma  ` s.2 j t.2 : T2

\Gamma  ` s j t : T1 * T2

(QngExtngProd)

Figure 6ng5: Product types (*!*b1)

6.9.14 Exercise [Recommended, n'n'n'n']: Our language can be extended straightforng

wardly with pairs. Figure 6ng5 gives the extended syntax and type system, and
Figure 6ng6 extends the equivalence algorithm to account for pairs. Extend the
completeness proof to cover the extended language and algorithm. 2

6.9.15 Exercise [n'n'n']: Unfortunately, some extensions of the technique of logical

relations, such as for universal types, are not as simple as that for pairs.
Suppose our language and algorithm are extended in the natural manner to
support universal types as in System F (TAPL, Chapter 23). To prove the alng
gorithm complete involves defining a logical relation. However, to define the
necessary logical relation is not straightforward. Observe what goes wrong. 2

6.10 Notes

The ideas behind logical relations were first developed by Tait (1967) and
Howard (1973), and were refined further by Plotkin (1980). Logical relations
were first proposed as a general proof technique by Statman (1985).

244 6 Logical Relations and a Case Study in Equivalence Checking

Syntax
p; q ::= . . . paths:

p.1 first projection
p.2 second projection

Weak head reduction s ; t

ht1; t2i.1 ; t1 (QARngBetangProd1)
ht1; t2i.2 ; t2 (QARngBetangProd2)

t ; t0
t.1 ; t0.1 (QARngProj1)

t ; t0
t.2 ; t0.2 (QARngProj2)

Algorithmic term equivalence \Gamma  ` s a t : T

\Gamma  ` s.1 a t.1 : T1 \Gamma  ` s.2 a t.2 : T2

\Gamma  ` s a t : T1 * T2

(QATngProd)

Algorithmic path equivalence \Gamma  ` p $ q : T

\Gamma  ` p $ q : T1 * T2
\Gamma  ` p.1 $ q.1 : T1 (QAPngProj1)

\Gamma  ` p $ q : T1 * T2
\Gamma  ` p.2 $ q.2 : T2 (QAPngProj2)

Figure 6ng6: Equivalence algorithm for *!*b1

The idea of using a Kripke logical relation to show the completeness of an
equivalence algorithm is due to Coquand (1991), who applies it to algorithms
for various similar type systems. Unlike the algorithm we consider here, Cong
quand's algorithms are not typengdirected. Coquand's technique was adopted
by Stone and Harper (2000), who use a more sophisticated form of logical reng
lation to show the completeness of an equivalence algorithm for a language
with singleton kinds. (Singleton kinds arise from a form of type definitions,
and are discussed in $9.3.)

A broader survey of applications of logical relations appears in Mitchell's
Foundations for Programming Languages (1996). A good introductory text on
modal logic and Kripke models is Sally Popkorn's First Steps in Modal Logic
(1994). A shorter introduction to modal logic from a different perspective
(leaving out connections to Kripke models) is given by Pfenning and Davies
(2001).

7 Typed Operational Reasoning

Andrew Pitts

The aim of this chapter is to explain, by example, some methods for reasonng
ing about equivalence of programs based directly upon a type system and
an operational semantics for the programming language in question. We will
concentrate on methods for reasoning about equivalence of representations
of abstract data types. This provides an excellent example: it is easy to appreng
ciate why such methods are useful and at the same time nonngtrivial problems
have to be solved to get a sound reasoning principle in the presence of nonng
termination and recursion. Rather than just treat abstract data types, we will
cover full existential types, using a programming language combining a pure
fragment of ML (including records and recursive functions) with System F.

7.1 Introduction

As explained in TAPL, Chapter 24, type systems involving existentially quanng
tified type variables provide a useful foundation for explaining and relating
various features of programming languages to do with information hiding.
To establish the properties of such typengtheoretic interpretations of inforng
mation hiding requires a theory of semantic equivalence for expressions of
existential type. Methods involving typengindexed families of relations between
between expressions have proved very useful in this respect. Study of relang
tional properties of typed calculi goes back to the logical relations for simply
typed lambda calculus in Plotkin (1973) and Statman (1985) and discussed in
Chapter 6, and the notion of relational parametricity for polymorphic types
in Reynolds (1983). More relevant to the kind of example considered in this
chapter is Mitchell's principle for establishing the denotational equivalence
of programs involving higherngorder functions and different implementations
of an abstract datatype in terms of the existence of a simulation relation beng

246 7 Typed Operational Reasoning

tween the implementations (Mitchell, 1991a). This principle was extended by
Plotkin and Abadi (1993) to encompass all the (possibly impredicative) exisng
tential types of the GirardngReynolds polymorphic lambda calculus.

One feature of these works is that they develop proof principles for denong
tational models of programming languages. The relevance of such principles
to the operational behavior of programs relies upon `goodness of fit' results
(some published, some not) connecting operational and denotational semanng
tics. Another feature of the above works is that they do not treat the use of
general recursive definitions; and so the languages considered are not Turng
ing powerful. It is folklore that a proof principle for denotational equality at
existential type, phrased in terms of the existence of certain simulation relang
tions, is still valid in the presence of recursively defined functions of higher
type, provided one imposes some admissibility conditions on the notion of
relation. In fact using techniques for defining operationally based logical reng
lations developed in Pitts (2000), we will see in this chapter that suitable
admissibility conditions for relations and an associated proof principle for
operational equivalence at existential type can be phrased directly, and quite
simply, in terms of the syntax and operational semantics of a programming
language combining existential types with recursively defined, higherngorder
functions. The programming language we work with combines a pure fragng
ment of ML (including records and recursive functions) with the polymorphic
lambda calculus of Girard (1972) and Reynolds (1974).

7.2 Overview

In order to get the most out of this chapter you should have some familiarity
with TAPL, Chapters 23 and 24. The material in this chapter is technically
quite intricate (especially the definition and properties of the logical relation
in $7.6) and it is easy to lose sight of the wood for the trees. So here is an
overview of the chapter.

Equivalence of programs One application of formal semantics of programng

ming languages is to give a mathematically precise definition of what it
means for one program to be semantically equal to another. In this chapter
we use operational semantics and discuss a notion of program equivalence
called contextual equivalence ($7.5).

Extensionality principles In order to reason about program equivalence, it

is useful to establish the validity of proof methods for it. The most basic
method uses the congruence property--reasoning by "replacing equals by
equals"--which holds of contextual equivalence by construction. In $7.1

7.3 Motivating Examples 247

we discuss informally some methods for proving contextual equivalence
of implementations of abstract datatypes. The discussion culminates with
the Extensionality Principle 7.3.6. One goal of this chapter is to give a
mathematically precise formulation of this principle and to establish its
validity.

Logical relations The Extensionality Principle is phrased in terms of typeng

respecting relations between the terms of our example language. In order
to formulate this principle precisely and then prove it we develop an alterng
native characterisation of contextual equivalence in terms of a certain "logng
ical relation" ($7.6). The combination of features in our language--higherng
order recursive functions and fully impredicative polymorphic types--
force us to use a form of logical relation with quite a difficult definition.
Chapter 6 presents another use of logical relations with a simpler defining
tion; as such, that chapter provides a useful warmngup for this one.

7.3 Motivating Examples

In this section we motivate the use of logical relations for reasoning about
existential types by giving some examples.

To begin, let us recall the syntax for expressions involving existentially
quantified type variables from TAPL, Chapter 24. If T is a type expression and
X is a type variable, then we write {9X,T} for the corresponding existentially
quantified type. Free occurrences of X in T become bound in this type expresng
sion. We write E,X , SG*T for the result of substituting a type S for all free
occurrences of X in T, renaming bound type variables as necessary to avoid
capture.1 It t is a term of type E,X , SG*T, then we can "pack" the type S and
the term t together to get a term

{*S,t} as {9X,T} (7.1)
of the indicated existential type. To eliminate such terms we use the form

let {*X,x}=t1 in t2 (7.2)
This is a binding construct: free occurrences of the type variable X and the
value variable x in t2 become bound in the term. The typing of such terms
goes as follows:

if t1 has type {9X,T} and t2 has type T2 when we assume the variable
x has type T, then provided X does not occur free in T2, we can conclude
that the term in (7.2) has type T2.

1. Throughout this chapter we will always identify expressions, be they types or terms, up to
renaming of bound variables.

248 7 Typed Operational Reasoning

(Such rules are better presented symbolically, but we postpone doing that
until we give a formal definition of the language we will be using, in the next
section.) The italicized restriction on free occurrences of X in T2 in the above
rule is what distinguishes an existential type from a typengindexed dependent
sum, where there is free access both to the type component as well as the
term component of a "packed" term: see Mitchell and Plotkin (1988), p. 474 et
seq, for a discussion of this point.

Since we wish to consider existential types in the context of an MLnglike
language, we adopt an eager strategy for evaluating expressions like (7.1)
and (7.2). Thus to evaluate the first, one evaluates t to canonical form, v say,
and returns the canonical form {*S,v} as {9X,T}; to evaluate the second,
one evaluates t1 to canonical form, {*S,v} as {9X,T} say, and then evalung
ates E,X , SG*E,x , vG*t2.

7.3.1 Example: Consider the existentially quantified record type

type Counter = {9X, {mk:X, inc:X!X, get:X!Int}}
where Int is a type of integers. Values of type Counter consist of some type
together with values of the appropriate types implementing mk, inc, and get.
For example

val counter1 = {*Int, {mk = 0,

inc = *x:Int.x+1,
get = *x:Int.x } as Counter

and

val counter2 = {*Int, {mk = 0,

inc = *x:Int.xng1,
get = *x:Int.0ngx } as Counter

are both values of type Counter. The terms

let {*X,x} = counter1 in x.get(x.inc(x.mk))
let {*X,x} = counter2 in x.get(x.inc(x.mk))

(where we use the syntax r.f for selecting field f of record r) are both terms
of type Int which evaluate to 1. By contrast, of the terms

let {*X,x} = counter1 in x.get(x.inc(1))
let {*X,x} = counter2 in x.get(x.inc(1))

the first evaluates to 2, whereas the second evaluates to 0; but in this case
neither term is wellngtyped. Indeed, it is the case that any wellngtyped closed
term involving occurrences of the term counter1 will exhibit precisely the
same evaluation behavior if we replace those occurrences by counter2. In
other words, counter1 and counter2 are equivalent in the following sense. 2

7.3 Motivating Examples 249
7.3.2 Definition [Contextual equivalence, informally]: We write t1 C^ctx t2:T

to indicate that two terms t1 and t2 of the same type T are contextually equivng
alent. By definition, this means that for all wellngtyped terms tE,t1G* containing
instances of t1, if tE,t2G* is the term obtained by replacing those instances
by t2, then tE,t1G* and tE,t2G* give exactly the same observable results when
evaluated. 2

This notion of program equivalence assumes we have already fixed upon a
definition of the "observable results" of evaluating terms. It also presupposes
that the meaning of a wellngtyped term should only depend upon the final
result (if any) of evaluating it. This is reasonable for deterministic and nonng
interactive programming even in the presence of computational effects like
sidengeffecting state or raising exceptions, provided we include those effects as
part of the observable results of evaluation. Certainly, contextual equivalence
is a widely used notion of program equivalence in the literature and it is the
one we adopt here.

For the terms in Example 7.3.1, it is the case that

counter1 C^ctx counter2:Counter (7.3)
but the quantification over all possible contexts tE,-G* in the definition of C^ctx
makes a direct proof of this and similar facts rather difficult. Thus one is
led to ask whether there are proof principles for contextual equivalence that
make proving such equivalences at existential types more tractable. Since
values {*S,v} as {9X,T} of a given existential type {9X,T} are specified by
pairs of data S and v, as a first stab at such a proof principle one might
try componentwise equivalence. Equivalence in the second component will of
course mean contextual equivalence; but in the first component, where the
expressions involved are types, what should equivalence mean? If we take
it to mean syntactic identity, C^, (which for us includes renaming of bound
variables) we obtain the following proof principle.2

7.3.3 Principle [Extensionality for 9ngtypes, Version I]: For an existential type

E defC^ {9X,T}, types T1, T2, and values v1, v2, if T1 C^ T2 and v1 C^ctx v2:E,X ,
T2G*T, then ({*T1,v1} as E) C^ctx ({*T2,v2} as E):{9X,T}. 2

The hypotheses of Principle 7.3.3 are far too strong for it to be very useful.
For example, it cannot be used to prove (7.3), since in this case T1 C^ Int C^ T2,
but

2. This and subsequent proof principles for {9X,T} are called extensionality principles by
analogy with the familiar extensionality principle for functions; it is a convenient terminology,
but perhaps the analogy is a little stretched.

250 7 Typed Operational Reasoning

val v1 = {mk=0, inc=*x:Int.x+1, get=*x:Int.x}
and

val v2 = {mk=0, inc=*x:Int.xng1, get=*x:Int.0ngx}
are clearly not contextually equivalent values of the record type

{mk:Int,inc:Int!Int,get:Int!Int}
(for example, we get different integers when evaluating tE,v1G* and tE,v2G* when
tE,-G* is (-.inc)0). However, they do become contextually equivalent if in
the second term we use a variant of integers in which the roles of positive
and negative are reversed. Such "integers" are of course in bijection with
the usual ones and this leads us to our second version of an extensionality
principle for existential types--in which the use of syntactic identity as the
notion of type equivalence is replaced by the more flexible one of bijection.
A bijection i : T1 Z. T2 means a closed term i : T1!T2 for which there is
a closed term i-1 : T2!T1 which is a twongsided inverse up to contextual
equivalence: i-1(i x1) C^ctx x1 : T1 and i(i-1 x2) C^ctx x2 : T2.

7.3.4 Principle [Extensionality for 9ngtypes, Version II]: For each existential

type E defC^ {9X,T}, types T1, T2, and values v1, v2, if there is a bijection
i : T1 Z. T2 such that T(i) v1 C^ctx v2 : E,X , T2G*T, then

({*T1,v1} as E) C^ctx ({*T2,v2} as E) : {9X,T}:
In stating this principle we have used the notation T(i) for the "action" of
types T on bijections i: given a type T, possibly containing free occurrences
of a type variable X, one can define an induced bijection T(i) : E,X , T1G*T Z.
E,X , T2G*T (with inverse T(i-1)). For example, if T is the type

{mk:X, inc:X!X, get:X!Int}
then T(i) is

*x:{ mk:T1, inc:T1!T1, get:T1!Int}.

{ mk = i(x.mk),

inc = *x2:T2.i(x.inc(i-1 x2)),
get = *x2:T2.x.get(i-1 x2)) }

and T(i-1) is

*x:{ mk:T2, inc:T2!T2, get:T2!Int}.

{ mk = i-1(x.mk),

inc = *x1:T1.i-1(x.inc(i x1)),
get = *x1:T1.x.get(i x1)) }:

7.3 Motivating Examples 251
(In general, if T is a simple type then the definition of T(i) and T(i-1) can
be done by induction on the structure of T; for recursively defined types, the
definition of the induced bijection is not so straightforward.) 2

We can use this second version of the extensionality principle for existenng
tial types to prove the contextual equivalence in (7.3), using the bijection

i defC^ (*x:Int.0ngx) : Int Z. Int:
This does indeed satisfy T(i) v1 C^ctx v2 : Int when v1, v2, and T are deng
fined as above. (Of course these contextual equivalences, and indeed the fact
that this particular term i is a bijection, all require proof; but the methods
developed in this chapter render this straightforward.) However, the use of
bijections between types is still too restrictive for proving many common exng
amples of contextual equivalence of abstract datatype implementations, such
as the following.

7.3.5 Example: Consider the following existentially quantified record type, where

Bool is a type of booleans.

type Semaphore = {9X, {bit:X, flip:X!X, read:X!Bool}}
The following terms have type Semaphore:

val semaphore1 =

{*Bool, {bit = true

flip = *x:Bool.not x,
read = *x:Bool.x } as Semaphore;
val semaphore2 =

{*Int, {bit = 1,

flip = *x:Int.0ng2*x,
read = *x:Int.x >= 0} as Semaphore

There is no bijection Bool Z. Int, so one cannot use Principle 7.3.4 to prove

semaphore1 C^ctx semaphore2 : Semaphore: (7.4)
Nevertheless, this contextual equivalence does hold. An informal argument
for this makes use of the following relation r : Bool $ Int between values
of type Bool and of type Int.

r defC^ {D^true; mE^ | m C^ D^-2E^n for some even n >= 0}

[ {D^false; mE^ | m C^ D^-2E^n for some odd n >= 0}:

Write si for the second component of semaphorei (i C^ 1; 2). Then

252 7 Typed Operational Reasoning

* s1.bit evaluates to true; s2.bit evaluates to 1; and D^true; 1E^ 2 r ;

* if D^t1; t2E^ 2 r , then (s1.flip)t1 and (s2.flip)t2 evaluate to a pair of

values which are again r ngrelated;

* if D^t1; t2E^ 2 r , then (s1.read)t1 and (s2.read)t2 evaluate to the same

boolean value.

The informal argument for the contextual equivalence (7.4) goes as follows:
"any context tE,-G* which is wellngtyped whenever its hole `-' is filled with a
term of type Semaphore can only make use of a term placed in its hole by
opening it as an abstract pair {X,x} and applying the methods bit, flip,
and read in some combination; therefore the above observations about r
are enough to show that tE,semaphore1G* and tE,semaphore2G* always have the
same evaluation behavior." 2

The validity of this informal argument and in particular the assumptions
it makes about the way a context can "use" its hole are far from immediate
and need formal justification. Leaving that for later, at least we can state the
relational principle a bit more precisely.

7.3.6 Principle [Extensionality for 9ngtypes, Final Version]: For each existenng

tial type E defC^ {9X,T}, types T1, T2, and values v1, v2, if there is a relation
r : T1 $ T2 between terms of type T1 and of type T2, such that D^v1; v2E^ 2 TE,r G*,
then ({*T1,v1} as E) C^ctx ({*T2,v2} as E) : {9X,T}. 2

Evidently this principle presupposes the existence of an "action" of types on
termngrelations that sends relations r : T1 $ T2 to relations TE,r G* : E,X ,
T1G*T $ E,X , T2G*T and with certain other properties. It is the definition of
this action that is at the heart of the matter. It has to be phrased with some
care in order for the above extensionality principle to be valid for languages
involving nonngtermination of evaluation (through the presence of fixpoint reng
cursion for example). We will give a precise definition in $7.6 (Definition 7.6.9)
for a language combining impredicative polymorphism with fixpoint recurng
sion at the level of terms. How best to define such relational actions in the
presence of recursion at the level of types is still a matter for research (see
Exercise 7.8.1).

7.3.7 Note: Principle 7.3.4 generalizes Principle 7.3.3, because if T1 C^ T2, then the

identity function i defC^ *x:T1.x is a bijection T1 Z. T2 satisfying

(T(i) v) C^ctx v (for any v)

7.4 The Language 253
so that v1 C^ctx v2 implies (T(i) v1) C^ctx v2. Principle 7.3.6 generalizes Prinng
ciple 7.3.4, because each bijection i : T1 Z. T2 can be replaced by its graph

ri defC^ {D^u1; u2E^ | i u1 C^ctx u2}
which in fact has the property that D^v1; v2E^ 2 TE,riG* if and only if (T(i) v1) is
contextually equivalent to v2. 2

As mentioned in the Introduction, Principle 7.3.6 is an operational genng
eralization of similar principles for the denotational semantics of abstract
datatypes over the simply typed lambda calculus (Mitchell, 1991a) and relang
tionally parametric models of the polymorphic lambda calculus (Plotkin and
Abadi, 1993). It permits many examples of contextual equivalence at existenng
tial types to be proved rather easily. Nevertheless, we will see in $7.7 that it is
incomplete for the particular MLnglike language we consider here, in the sense
that ({*T1,v1} as E) C^ctx ({*T2,v2} as E) : {9X,T} can hold even though
there is no relation r for which D^v1; v2E^ 2 TE,r G* holds (see Example 7.7.4).

7.4 The Language

In this section we define a small, MLnglike programming language that we will
use in the rest of the chapter. It combines Girard's System F (1972) (in other
words, the polymorphic lambda calculus of Reynolds [1974]) with recursively
defined functions, record types and ground types; in common with ML (Milng
ner, Tofte, Harper, and MacQueen, 1997), evaluation order is strict (i.e., leftngtong
right, callngbyngvalue). We will call the language FML. Its syntax and type system
are specified in Figure 7ng1 and its operational semantics in Figure 7ng2.

Syntax
In Figure 7ng1, X and x respectively range over disjoint countably infinite sets
of type variables and value variables; l ranges over a countably infinite set
of field labels; c ranges over the constants true, false and n (for n 2 Z);
Gnd is either the type of booleans Bool or the type of integers Int; and op
ranges over a fixed collection of arithmetic and boolean operations (such as
+, =, not, etc).

To simplify the definition of the language's operational semantics we emng
ploy the now quite common device of using a syntax for terms that is in a
"reduced" (or "Angnormal") form, with all sequential evaluation expressed via
letngexpressions. For example, the general form of (leftngtongright, callngbyngvalue)
function application is coded by

t1 t2 defC^ let x1=t1 in (let x2=t2 in x1 x2): (7.5)

254 7 Typed Operational Reasoning

Syntax

t ::= terms:

v value
if v then t else t conditional
op(vi i21::n) operation
v v application
v.l projection
v T type application
let {*X,x}=v in t unpacking
let x=t in t sequencing
v ::= values:

x value variable
c constant
fun x(x:T)=t:T recursive function
{li=vi i21::n} record value
*X.v type abstraction
{*T,v} as {9X,T} package value
T ::= types:

X type variable
Gnd ground type
T!T function type
{li:Ti i21::n} record type
8X.T universally quantified type
{9X,T} existentially quantified type
\Gamma  ::= typing contexts:

; empty context
\Gamma  ; x:T nonngempty context
\Gamma  ; X nonngempty context

Typing terms \Gamma  ` t : T

x:T 2 \Gamma 
\Gamma  ` x : T (TngVar)

\Gamma  ` c : Typeof D^cE^ (TngConst)
\Gamma  ; f:T; x:T1 ` t : T2 T C^ T1!T2

\Gamma  ` fun f(x:T1)=t:T2 : T (TngFun)

D^\Gamma  ` vi : TiE^ i21::n
\Gamma  ` {li=vi i21::n} : {li:Ti i21::n} (TngRcd)

\Gamma  ; X ` v : T X AE ftvD^\Gamma  E^

\Gamma  ` *X.v : 8X.T (TngTabs)
\Gamma  ` v1 : E,X , T1G*T T0 C^ {9X, T}

\Gamma  ` {*T1,v1} as T0 : T0 (TngPack)

\Gamma  ` v : Bool
\Gamma  ` t1 : T \Gamma  ` t2 : T

\Gamma  ` if v then t1 else t2 : T (TngIf)

op:Gnd1,...,Gndn!Gnd

D^\Gamma  ` vi : GndiE^ i21::n

\Gamma  ` op(vi i21::n) : Gnd (TngOp)
\Gamma  ` v1 : T1!T2 \Gamma  ` v2 : T1

\Gamma  ` v1 v2 : T2 (TngApp)
\Gamma  ` v : {li:Ti i21::n}

\Gamma  ` v.lj : Tj (TngProj)

\Gamma  ` v : 8X.T
\Gamma  ` v T1 : E,X , T1G*T (TngTapp)

\Gamma  ; X; x:T ` t : T1
X AE ftvD^\Gamma  ; T1E^ \Gamma  ` v : {9X,T}

\Gamma  ` let {*X,x}=v in t : T1 (TngUnpack)
\Gamma  ` t1 : T1 \Gamma  ; x:T1 ` t2 : T2

\Gamma  ` let x=t1 in t2 : T2 (TngSeq)

Figure 7ng1: FML syntax and typing

7.4 The Language 255
As a further simplification, function abstraction and recursive function decng
laration have been rolled into the one form fun f(x:T1) = t:T2, which correng
sponds to the expressions

let fun f (x:T1) = t:T2 in f end in Standard ML
or let rec f (x:T1) = t:T2 in f in Ocaml.

Ordinary function abstraction can be coded as

*x:T1.t defC^ fun f(x:T1) = t:T2 (7.6)
where f does not occur freely in t (and T2 is the type of t, given f has type
T1!T2 and x has type T1). In what follows we shall use the abbreviations (7.5)
and (7.6) without further comment. We shall also use infix notation for appling
cation of constant arithmetic and boolean operators such as +, =, etc.

7.4.1 Remark [Valuengrestriction]: Note that the operation *X.D^-E^ of polymorng

phic generalization is restricted to apply only to values. This is a real reng
striction since for a nonngvalue term t, one cannot define *X.t to be the term
let x=t in *X.x, since the latter will in general be an illngtyped term. In an MLng
like language *X.t is not yet fully evaluated if t is a nonngvalue; and thus evalng
uation must go under type abstraction *X.D^-E^ and work on terms at types
with free type variables. By imposing the restriction that *X.t is only wellng
formed when t is a value we can restrict attention to the evaluation of closed
terms of closed type, simplifying the technical development. The restriction
does not seem to affect the expressiveness of FML in practice and is comparang
ble to the "value restriction" on letngbound polymorphism used in the 1997
revision of Standard ML (Milner et al., 1997) and in Objective Caml (Leroy,
2000). However, this restriction does have an effect on the properties of FML.
For example, with the restriction the type 8X.X contains no closed values (see
Exercise 7.7.6); whereas without the restriction there are closed values of that
type, such as *X. (fun f(x:Bool) = f x : X) true. The "emptiness" of 8X.X
plays a role in the properties explored in Example 7.7.4 and Remark 7.7.7. 2

Operational Semantics
Although we do not do so, the operational semantics of FML could be specing
fied in the style of the Definition of Standard ML (Milner, Tofte, Harper, and
MacQueen, 1997) as a syntaxngdirected, inductively defined relation between
terms and values.3 Here we are interested primarily in the notion of contexng

3. That Definition uses environments assigning values to value variables. For reasons of techng
nical convenience we eliminate the use of environments by substituting them into the term
and only considering the evaluation relation between closed terms and values.

256 7 Typed Operational Reasoning

Frame stack syntax

S ::= frame stacks:

Id nil stack
S ffi D^x.tE^ stack cons

Typing frame stacks \Gamma  ` S : T1 C, T2

\Gamma  ` Id : T C, T (SngNil)
\Gamma  ; x:T1 ` t : T2 \Gamma  ` S : T2 C, T3

\Gamma  ` S ffi D^x.tE^ : T1 C, T3 (SngCons)

Primitive reductions t1 ; t2

if true then t1 else t2

; t1 (RngIfTrue)

if false then t1 else t2

; t2 (RngIfFalse)

the value of opD^ci i21::nE^ is c

op(ci i21::n) ; c (RngOp)
v1 is fun f(x:T1)=t:T2
v1 v2 ; E,f , v1G*E,x , v2G*t (RngAppAbs)

{li=vi i21::n}.j ; vj (RngProjRcd)
(*X.v)T ; E,X , TG*v (RngTappTabs)
v is {*T1,v1} as {9X,T}

let {*X,x}=v in t
; E,X , T1G*E,x , v1G*t

(RngUnpackPack)

Termination hS; ti # and t #

hId; vi # (SngNilVal)
hS; E,x , vG*ti #
hS ffi D^x.tE^; vi # (SngConsVal)
hS ffi D^x.t2E^; t1i #
hS; let x=t1 in t2i # (SngSeq)

t1 ; t2 hS; t2i #

hS; t1i # (SngRed)

hId; ti #

t # (Term)

Figure 7ng2: FML operational semantics

tual equivalence (Definition 7.3.2) that this evaluation relation determines by
observing the results of evaluating terms in context. Because evaluation in
FML is strict and the language has a sufficiently expressive collection of conng
structs for deconstructing values, it turns out that the notion of contextual
equivalence is not affected much by the choice of what to observe of evaluang
tion. Most reasonable choices give rise to the same equivalence as the one we
adopt (see Exercise 7.5.10 below), which is based upon observing termination:
whether or not a term evaluates to some value, we care not which. So instead
of defining the relation of evaluation between terms and values, we proceed
directly to a definition of the termination relation, t #, for FML. This is given
in Figure 7ng2, using an auxiliary notion of frame stack. (The conventions and
notations used in Figure 7ng2 in connection with binding, free variables and
substitution are summarized in Figure 7ng3.)

Frame stacks are finite lists of individual "evaluation frames." They provide
a convenient syntax for the notion of evaluation context EE,-G* (Felleisen and
Hieb, 1992; Wright and Felleisen, 1994). Every closed term can be decomposed

7.4 The Language 257
Binding constructs

let {*X,x}=v in D^-E^
let x=t in D^-E^
fun f(x:T1)=D^-:T2E^
*X.D^-E^
8X.D^-E^
{9X,D^-E^}
S ffi D^x.D^-E^E^

We identify expressions up to renaming of
bound value and type variables.

Notation for free variable sets

ftvD^EE^ is the finite set of free type variables

of the expression E (a type, a term, or a
frame stack);

fvD^EE^ is the finite set of free value variables

of an expression E (a term, or a frame stack,
but not a type, since types do not contain
occurrences of value variables).

Closed types, terms and frame stacks

A type T is closed if ftvD^TE^ C^ ;.
A term or frame stack E is closed if fvD^EE^ C^
; (even if ftvD^EE^ 6C^ ;).

Notation for substitution

E,X , TG*E denotes the result of captureng

avoiding substitution of a type T for all free
occurrences of a type variable X in E (a type,
a term, or a frame stack);

E,x , vG*E denotes the result of captureng

avoiding substitution of a value v for all free
occurrences of the value variable x in a term
or frame stack E.

(Note that as their name suggests, value variables
stand for unknown values--the substitution of a
nonngvalue term for a variable makes no sense synng
tactically, in that it may result in an illngformed exng
pression.)

Figure 7ng3: Binding, free variables and substitution

uniquely as EE,tG* where the evaluation context EE,-G* is a context with a unique
hole (-) occurring in the place where the next step of evaluation (called a
primitive reduction in Figure 7ng2), if any, will take place. With FML's reduced
syntax, such evaluation contexts turn out to be just nested sequences of the
letngconstruct

EE,-G* C^ let x1=(...(let xn=D^-E^ in tn)...) in t1:
The corresponding frame stack

S C^ Id ffi D^x1.t1E^ ffi * * * ffi D^xn.tnE^
records this sequence as a list of evaluation frames, xi.ti (with free occurng
rences of xi in ti being bound in xi.ti). Under this correspondence it can be
shown that EE,tG* evaluates to some value in the standard evaluationngstyle (or
"bigngstep") structural operational semantics if and only if hS; ti # holds, for
the relation h-; -i # defined in Figure 7ng2. Not only does the use of frame

258 7 Typed Operational Reasoning

stacks enable a conveniently syntaxngdirected inductive definition of terminang
tion, but also frame stacks play a big role in $7.6 when defining the logical
relation that we use to establish properties of FML contextual equivalence.

7.4.2 Exercise [Recommended, n'n']: Consider a relation hS1; t1i -! hS2; t2i deng

fined by cases according to the structure of the term t1 and the frame stack
S1, as follows:

* hS ffi D^x.tE^; vi -! hS; E,x , vG*ti

* hS; let x=t1 in t2i -! hS ffi D^x.t2E^; t1i

* hS; t1i -! hS; t2i, if t1 ; t2.
Show that

hS0@S; ti # a D^9vE^ hS; ti -!* hId; vi & hS0; vi # (7.7)
where -!* denotes the reflexivengtransitive closure of the -! relation, and
S0@S is the frame stack obtained by appending the two lists of evaluation
frames S0 and S. Deduce that t # holds if and only if there is some value v
with hId; ti -!* hId; vi. 2

Typing
We will consider the termination relation only for frame stacks and terms
that are wellngtyped. A term t is wellngtyped with respect to a particular typing
context \Gamma  if a typing judgment

\Gamma  ` t : T (7.8)
can be derived for some type T using the rules in Figure 7ng1. We identify
typing contexts \Gamma  up to rearranging their constituent hypotheses ("X" or "x :
X") and eliminating duplicates. Thus a typical typing context looks like

\Gamma  C^ X1; : : : ; Xm; x1 : T1; : : : ; xn : Tn
where the type variables Xi and the value variables xj are all distinct (and
m C^ 0 or n C^ 0 is allowed). The typing judgments that are derivable from
the rules all have the property that the free type variables of T and each Tj
occur in the set {X1; : : : ; Xm}, and the free value variables of t occur in the set
{x1; : : : ; xn}. This is ensured by including some explicit sidengconditions about
free variable occurrences in the typing rules (TngAbs) and (TngUnpack). In TAPL,
Chapters 23 and 24, such sidengconditions are implicit, being subsumed by

7.4 The Language 259
extra wellngformedness conditions for typing judgments. Also, we have chosen
to include sufficient explicit type information in terms to ensure that for any
given \Gamma  and t, there is at most one T for which (7.8) holds. Apart from such
minor differences, the rules in Figure 7ng1 for inductively generating the valid
FML typing judgments are all quite standard.

The judgment for typing frame stacks takes the form

\Gamma  ` S : T1 C, T2 (7.9)
where, in terms of the evaluation context corresponding to S, T2 is the overall
type of the context, given that T1 is the type of the hole. The rules for genng
erating this judgment are given in Figure 7ng2. Unlike for terms, we have not
included explicit type information in the syntax of frame stacks; for example,
Id is not tagged with a type. However, it is not hard to see that, given \Gamma  , S,
and T1, there is at most one T2 for which (7.9) holds. This property is enough
for our purposes, since the argument type of a frame stack will always be
supplied in any particular situation in which we use it.

7.4.3 Exercise [n', 3]: Write \Gamma  ` hS; ti : T to mean that \Gamma  ` S : T0 C, T and \Gamma  ` t :

T0 hold for some type T0. Using the relation -! from Exercise 7.4.2, show that
if ; ` hS1; t1i : T and hS1; t1i -! hS2; t2i, then ; ` hS2; t2i : T. 2

Unwinding Recursive Functions
In what follows we will need a finiteness property of recursively defined funcng
tions with respect to the termination relation. This unwinding property, as
it is called, is a syntactic analog of the fact that the denotation of a reng
cursively defined function is constructed as the least upper bound (lub) of
finite approximations obtained by successively unfolding its definition startng
ing with the bottom denotation, i.e., the totally undefined partial function.
This gives rise to the useful principle of Scott induction in denotational seng
mantics: given an admissible property of denotations, i.e., one closed under
the formation of lubs of increasing chains, to show that it holds of the denong
tation of recursively defined data it suffices to show that it holds of bottom
and is closed under application of the function that defines the data as a
fixed point. Here we use a syntactic analog of Scott induction for recursively
defined functions, fun f(x:T1) = u:T2, in order to prove the "fundamental
property" (Lemma 7.6.17) of the logical relation constructed in $7.6.

The proof of the unwinding property that we give here is made easier by
our syntaxngdirected definition of termination using frame stacks. For stateng
ments and proofs of similar properties see for example: Mason, Smith, and
Talcott (1996), Section 4.3, Pitts and Stark (1998), Theorem 3.2, Birkedal and
Harper (1999), Section 3.1, and Lassen (1998), Section 4.5.

260 7 Typed Operational Reasoning

7.4.4 Theorem [Unwinding]: Given any closed recursive function value F of the

form fun f(x:T1)=u:T2, define the followings abbreviations4 :

F0 defC^ fun f(x:T1) = (f x) : T2
Fn+1 defC^ fun f(x:T1) = E,f , FnG*u : T2

Thus F0 is a closed function value describing a function of type T1!T2 that
diverges when applied to any argument, and the Fn are obtained from this
by repeatedly substituting for the the value variable f in the body u of the
original function value F. Then for all terms t containing at most f free we
have E,f , FG*t # if and only if D^9nE^ E,f , FnG*t #. 2

Proof: By definition of the relation t # in terms of the relation hS; ti # (via
rule (Term) in Figure 7ng2), it suffices to prove the more general property that
for all terms t and frame stacks S (containing at most f free) we have

hE,f , FG*S; E,f , FG*ti # a D^9nE^ hE,f , FnG*S; E,f , FnG*ti # (7.10)
The proof of (7.10) is via a series of straightforward, if somewhat tedious,
inductions that we leave as an exercise. 2

7.4.5 Exercise [n'n'n', 3]: This exercise leads you through a proof of (7.10). First

prove that

hE,f , FnG*S; E,f , FnG*ti # ) hE,f , FG*S; E,f , FG*ti # (7.11)
holds for all n, S and t by induction on the derivation of hE,f , FnG*S; E,f ,
FnG*ti # from the rules in Figure 7ng2. Conversely show that

hE,f , FG*S; E,f , FG*ti # ) D^9nE^ hE,f , FnG*S; E,f , FnG*ti # (7.12)
holds for all S and t, by induction on the derivation of hE,f , FG*S; E,f , FG*ti #
from the rules. To do this, you will first need to prove by induction on n that

hE,f , FnG*S; E,f , FnG*ti # ) hE,f , Fn+1G*S; E,f , Fn+1G*ti # (7.13)
holds for all n, S and t; the base case n C^ 0 involves yet another induction,
this time over the derivation of hE,f , F0G*S; E,f , F0G*ti # from the rules. 2

4. Note that in the definition of Fn+1, the outer binding instance of f is a dummy, since f does
not occur free in E,f , FnG*u.

7.5 Contextual Equivalence 261
7.5 Contextual Equivalence

Definition 7.3.2 gave an informal definition of the notion of contextual equivng
alence that applies to any (typed) programming language. In giving a precise
definition of this notion for the FML language we will take the more abstract,
relational approach of Gordon (1998) and Lassen (1998) that avoids the exng
plicit use of program contexts tE,-G* in favor of congruence relations. For one
thing, program contexts are an inconveniently concrete notion, because subng
stitution of terms t0 for the hole "-" in a context tE,-G* to produce a term
tE,t0G* may involve the capture of free variables in t0 by binders in tE,-G*. For
example, when we replace the hole "-" in the context fun f(x:T) = f E,-G* by
the term f x, its free value variables are captured by the funngbinder. Conng
sequently, contexts have to be treated more concretely than terms since reng
naming their bound variables may not preserve their meaning. For example,
if we identified fun f(x:T) = f E,-G* with fun g(x:T) = g E,-G* (where f and g
are distinct value variables), then we should have to identify the results of
filling the hole with f x, that is, we should have to identify the syntactically
unequal terms fun f(x:T) = f(f x) and fun g(x:T) = g(f x). But more than
this, the abstract treatment of contextual equivalence that we use focuses atng
tention upon the key features of this kind of program equality, namely that it
is a congruence and is "adequate" for observing termination. In a nutshell, we
will define contextual equivalence to be the largest typengrespecting congrung
ence relation between FML terms that is adequate for observing termination.

7.5.1 Definition: A typengrespecting binary relation between FML terms is a set R

of quadruples D^\Gamma  ; t; t0; TE^, each consisting of a typing context, two terms and
a type satisfying \Gamma  ` t : T and \Gamma  ` t0 : T. Figure 7ng4 defines the properties
of reflexivity, symmetry, transitivity, substitutivity, and compatibility for such
relations; R has one of these properties if it is closed under the axioms and
rules under the corresponding heading in the figure. In these figures, and
elsewhere, we write \Gamma  ` t R t0 : T instead of D^\Gamma  ; t; t0; TE^ 2 R. We say that R is

* an equivalence relation if it has the reflexivity, symmetry and transitivity

properties;

* a congruence relation if it is an equivalence relation with the substitutivity

and compatibility properties;

* adequate (for the termination relation # defined in Figure 7ng2) if whenever

; ` t R t0 : T holds, then t # holds if and only if t0 # does. 2

7.5.2 Definition: We will need to use the following constructions on typengresng

pecting binary relations.

262 7 Typed Operational Reasoning

Reflexivity

\Gamma  ` t : T

\Gamma  ` t R t : T
Symmetry

\Gamma  ` t R t0 : T

\Gamma  ` t0 R t : T
Transitivity

\Gamma  ` t R t0 : T \Gamma  ` t0 R t00 : T

\Gamma  ` t R t00 : T
Substitutivity

\Gamma  ` v R v0 : T1 \Gamma  ; x : T1 ` t R t0 : T2

\Gamma  ` E,x , vG*t R E,x , v0G*t0 : T2

\Gamma  ; X ` t R t0 : T
\Gamma  ` E,X , T1G*t R E,X , T1G*t0 : E,X , T1G*T
Compatibility

D^x:TE^ 2 \Gamma 

\Gamma  ` x R x : T

\Gamma  ` c R c : Typeof D^cE^
\Gamma  ; f:T1!T2; x:T1 ` t R t0 : T2

\Gamma  ` fun f(x:T1)=t:T2 R
fun f(x:T1)=t0:T2 : T1!T2

D^\Gamma  ` vi R v0i : TiE^ i21::n
\Gamma  ` {li=vi i21::n} R {li=v0i i21::n}

: {li:Ti i21::n}

\Gamma  ; X ` v R v0 : T X AE ftvD^\Gamma  E^

\Gamma  ` *X.v R *X.v0 : 8X.T

\Gamma  ` v1 R v01 : E,X , T1G*T
\Gamma  ` {*T1,v1} as {9X,T} R
{*T1,v01} as {9X,T} : {9X,T}

\Gamma  ` v R v0 : Bool
\Gamma  ` t1 R t01 : T \Gamma  ` t2 R t02 : T

\Gamma  ` if v then t1 else t2 R

if v0 then t01 else t02 : T

op:Gnd1,...,Gndn!Gnd

D^\Gamma  ` vi R v0i : GndiE^ i21::n

\Gamma  ` op(vi i21::n) R op(v0i i21::n) : Gnd
\Gamma  ` v1 R v01 : T1!T2 \Gamma  ` v2 R v02 : T1

\Gamma  ` v1 v2 R v01 v02 : T2
\Gamma  ` v R v0 : {li:Ti i21::n}

\Gamma  ` v.lj R v0.lj : Tj

\Gamma  ` v R v0 : 8X.T
\Gamma  ` v T1 R v0 T1 : E,X , T1G*T

\Gamma  ; X; x:T ` t R t0 : T1
X AE ftvD^\Gamma  ; T1E^ \Gamma  ` v R v0 : {9X,T}

\Gamma  ` let {*X,x}=v in t R

let {*X,x}=v0 in t0 : T1

\Gamma  ` t1 R t01 : T1 \Gamma  ; x:T1 ` t2 R t02 : T2

\Gamma  ` let x=t1 in t2 R let x=t01 in t02 : T2

Figure 7ng4: Properties of a typengrespecting relation R between FML terms

(i) The identity relation is Id defC^ {D^\Gamma  ; t; t; TE^ | \Gamma  ` t : T}.
(ii) The reciprocal of the relation R is Rop defC^ {D^\Gamma  ; t0; t; TE^ | \Gamma  ` t R t0 : T}.
(iii) The composition of relations R1 and R2 is

R1 ffi R2 defC^ {D^\Gamma  ; t; t00; TE^ | 9t0: \Gamma  ` t R1 t0 : T & \Gamma  ` t0 R2 t00 : T}.

7.5 Contextual Equivalence 263

(iv) The transitive closure of the relation R is the countable union R+ defC^S

i2N Ri, where R0 C^ R and Ri+1 C^ R ffi Ri.

(v) The open extension of the relation R is denoted Rffi and consists of all

quadruples D^\Gamma  ; t; t0; TE^ such that ; ` oe D^tE^ R oe D^t0E^ : oe D^TE^ holds for all
\Gamma  ngclosing substitutions oe . If \Gamma  C^ X1; : : : ;Xm; x1 : T1; : : : ;xn : Tn, then a \Gamma  ng
closing substitution is given by a function E,Xi , Ti | i C^ 1::mG* mapping the
type variables Xi to closed types Ti and by a function E,xj , vj | j C^ 1::nG*
mapping the value variables xj to closed values vj of appropriate type,
namely satisfying ; ` vj : E,Xi , Ti | i C^ 1::mG*Tj .

(Note that Rffi only depends on the quadruples of the form D^;; t; t0; TE^ in
R.) 2

We wish to define contextual equivalence to be the largest adequate conng
gruence relation, but it is not immediately clear why a largest such relation
exists. Therefore we give a theorem rather than a definition.

7.5.3 Theorem [FML contextual equivalence, C^ctx]: There exists a largest typeng

respecting binary relation between FML terms that is a congruence and adeng
quate. We call it contextual equivalence and write it C^ctx. 2

Proof: The proof makes use of the following series of facts, only the last of
which is not entirely straightforward to prove (see Exercise 7.5.4).

(i) The identity relation Id is an adequate congruence relation.
(ii) The collection of adequate relations is closed under taking unions.
(iii) Every compatible relation is reflexive, i.e., contains Id.
(iv) The set of all of compatible relations is closed under the operations

of composition and reciprocation; similarly for the set of all substitutive
relations and the set of all adequate relations.

(v) If the union of a nonngempty family of compatible relations is transing

tive, it is also compatible; similarly, if the union of a nonngempty family of
reflexive and substitutive relations is transitive, it is also (reflexive and)
substitutive.

Let C^ctx be the union of the family of relations that are adequate, compatible
and substitutive. Note that this family is nonngempty by (i). By (ii), C^ctx is adng
equate. So it suffices to show that it is a congruence relation. It is certainly
reflexive by (i); and (iv) implies that it is also symmetric and transitive. So it
just remains to show that it is compatible and substitutive, and this follows
from (v), whose proof needs (iii). 2

264 7 Typed Operational Reasoning

7.5.4 Exercise [n'n']: Prove properties (iii) and (v) stated in the above proof. 2

It is not easy to use either the formulation in terms of contexts in Defing
nition 7.3.2 or the more abstract characterisation of Theorem 7.5.3 to prove
that a particular pair of terms are contextually equivalent. For example, it is
not easy to see from these characterisations that terms in the primitive reducng
tion relation of Figure 7ng2 are contextually equivalent (Corollary 7.5.8). That
this is so follows from the coincidence of C^ctx with a notion of equivalence
popularized by Mason and Talcott (1991).

7.5.5 Definition [ciungEquivalence, C^ciu]: Two closed FML terms belonging to the

same (closed) type are ciungequivalent if they have the same termination beng
havior when they are paired with any frame stack (a "use" of the terms);
the relation is extended to open terms via closing substitutions (or "closed
instantiations"--thus we arrive at an explanation of the rather cryptic name
for this equivalence).

More formally, we define C^ciu to be the typengrespecting relation Rffi (usng
ing the operation from Definition 7.5.2(v)), where R consists of quadruples
D^;; t; t0; TE^ satisfying ; ` t : T, ; ` t0 : T, and 8S: hS; ti # a hS; t0i #. 2

7.5.6 Lemma: For any frame stack S and term t, define a term SE,tG* by induction of

the length of the stack S as follows:

IdE,tG* defC^ t
S ffi D^x.t0E^E,tG* defC^ SE,let x=t in t0G* 9=; (7.14)

Then hS; ti # if and only if SE,tG* # (i.e., hId; SE,tG*i #). 2
Proof: This is proved by induction on the length of S. The base case S C^ Id
is trivial. The induction step follows from the fact that hS; let x=t in t0i #
holds if and only if it was derived using rule (SngSeq) in Figure 7ng4, if and only
if hS ffi D^x.t0E^; ti # holds. 2

7.5.7 Theorem [CIU Theorem for FML]: The contextual and ciungequivalence relang

tions coincide. 2

Proof: We first show that C^ctx is contained in C^ciu. Suppose

\Gamma  ` t C^ctx t0 : T: (7.15)
Since C^ctx satisfies the substitutivity and reflexivity properties from Figure 7ng4,
it follows that

; ` oe D^tE^ C^ctx oe D^t0E^ : oe D^TE^ (7.16)

7.5 Contextual Equivalence 265
for any \Gamma  ngclosing substitution oe . For any frame stack S, since C^ctx satisfies
the compatibility (and reflexivity) properties from Figure 7ng4, from (7.16) we
deduce that ; ` SE,oe D^tE^G* C^ctx SE,oe D^t0E^G* : oe D^TE^ (using the notation of (7.14)).
Since C^ctx is adequate, this means that SE,oe D^tE^G* # if and only if SE,oe D^t0E^G* #;
hence by Lemma 7.5.6, hS; oe D^tE^i # if and only if hS; oe D^t0E^i #. As this holds for
all oe and S, we have \Gamma  ` t C^ciu t0 : T, as required.

To complete the proof of the theorem we have to show conversely that
C^ciu is contained in C^ctx. We can deduce this as a corollary of a stronger
characterisation of C^ctx in terms of logical relations (Theorem 7.6.25) that we
establish later; so we postpone the rest of this proof until then. 2

7.5.8 Corollary [Conversions]: The following are valid contextual equivalences:

(i) \Gamma  ` if true then t1 else t2 C^ctx t1 : T and

\Gamma  ` if false then t1 else t2 C^ctx t2 : T, where \Gamma  ` ti : T for i C^ 1; 2.

(ii) \Gamma  ` op(ci i21::n) C^ctx c : Gnd, where c is the value of opD^ci i21::nE^ and

Typeof D^cE^ C^ Gnd.

(iii) \Gamma  ` v1 v2 C^ctx E,f , v1G*E,x , v2G*t : T2,

where v1 C^ fun f(x:T1)=t:T2.

(iv) \Gamma  ` {li=vi i21::n}.j C^ctx vj : Tj,

where \Gamma  ` {li=vi i21::n} : {li:Ti i21::n}.

(v) \Gamma  ` (*X.v)T1 C^ctx E,X , T1G*v : E,X , T1G*T, where \Gamma  ` v : 8X.T.
(vi) \Gamma  ` let {*X,x}=({*T1,v1} as {9X,T}) in t C^ctx E,X , T1G*E,x , v1G*t :

T2, where \Gamma  ; X; x:T ` t : T2 with X AE ftvD^\Gamma  ; T2E^.

(vii) \Gamma  ` let x=v in t C^ctx E,x , vG*t : T2, where \Gamma  ` v : T1 and \Gamma  ; x:T1 `

t : T2.

(viii) \Gamma  ` let x1=t1 in (let x2=t2 in t) C^ctx

let x2=(let x1=t1 in t2) in t : T, where \Gamma  ` t1 : T1,
\Gamma  ; x1:T1 ` t2 : T2 and \Gamma  ; x2:T2 ` t : T. 2

Proof: These are all ciungequivalences, so we can just apply Theorem 7.5.7 (usng
ing the difficult half of the theorem whose proof we have postponed to $7.6!).
The ciungequivalences all follow easily from the definition of the termination
relation (Figure 7ng2) except for the last one, where one can apply property (7.7)
from Exercise 7.4.2 to reduce proving (viii) for C^ciu to the special case when
t1 is a value: see the following exercise. 2

266 7 Typed Operational Reasoning

7.5.9 Exercise [n', 3]: Given

; ` t1 : T1
x1:T1 ` t2 : T2
x2:T2 ` t : T

use property (7.7) to show for all frame stacks S that

hS ffi D^x1.let x2=t2 in tE^; t1i # iff hS ffi D^x2.tE^ ffi D^x1.t2E^; t1i #:
Deduce part (viii) of Corollary 7.5.8. 2
7.5.10 Exercise [n'n']: Recall from Definition 7.5.1 the notion of an adequate typeng

respecting binary relation. Let us call a typengrespecting binary relation R
truengadequate if, whenever ; ` t R t0 : Bool holds, hId; ti -!* hId; truei
holds if and only if hId; t0i -!* hId; truei does. Here -!* is the relation deng
fined in Exercise 7.4.2. One can adapt the proof of Theorem 7.5.3 to show that
there is a largest typengrespecting binary relation C^truectx between FML terms that
is a congruence and truengadequate. Show that C^truectx coincides with contexng
tual equivalence, C^ctx. 2

7.6 An Operationally Based Logical Relation

We now have a precise definition of contextual equivalence for FML terms. Beng
fore showing that the Extensionality Principle 7.3.6 holds for existential types
in FML, we need a precise definition of the action of types on termngrelations,
r , TE,r G*, mentioned in the principle. That is the topic of this section. We will
end up with a characterisation of C^ctx in terms of a logical relation, yielding
several useful extensionality properties of contextual equivalence.

7.6.1 Notation: Let Typ denote the set of closed FML types. Given T 2 Typ, let

* TermD^TE^ denote the set of closed terms of type T, i.e., those terms t for

which ; ` t : T holds;

* ValD^TE^ denote the subset of TermD^TE^ whose elements are values; and

* StackD^TE^ denote the set of closed frame stacks whose argument type is T,

i.e., those frame stacks S for which ; ` S : T C, T0 for some T0 2 Typ.

Given T; T0 2 Typ, let

* TRelD^T; T0E^ denote the set of all subsets of TermD^TE^ * TermD^T0E^; we call

its elements termngrelations;

7.6 An Operationally Based Logical Relation 267

* VRelD^T; T0E^ denote the set of all subsets of ValD^TE^ * ValD^T0E^; we call its

elements valuengrelations;

* SRelD^T; T0E^ denote the the set of all subsets of StackD^TE^ * StackD^T0E^; we

call its elements stackngrelations. 2

Note that every valuengrelation is also a termngrelation (since values are parng
ticular sorts of term): VRelD^T; T0E^ ` TRelD^T; T0E^. On the other hand we can
obtain a valuengrelation from a termngrelation just by restricting attention to
values: given r 2 TRelD^T; T0E^, define r v 2 VRelD^T; T0E^ by

r v defC^ {D^v; v0E^ 2 ValD^TE^ * ValD^T0E^ | D^v; v0E^ 2 r }: (7.17)
We will be particularly interested in termngrelations r that are indistinguishng
able, as far as termination properties are concerned, from their value restricng
tions, r v. Definition 7.6.3 makes this precise, using a Galois connection beng
tween termngrelations and stackngrelations. The definition may appear to be
rather mysterious; its nature will emerge as we develop the action of types
on termngrelations and its properties. First we recall for the reader what is
meant in general by a "Galois connection."

7.6.2 Definition: A Galois connection between partially ordered sets D^P ; <=P E^ and

D^Q; <=QE^ is specified by a pair of functions f : P ! Q and g : Q ! P satisfying
q <=Q f D^pE^ if and only if p <=P gD^qE^, for all p 2 P and q 2 Q. 2

7.6.3 Definition [Closed and valuable termngrelations]: Let T 2 Typ and T0 2

Typ be closed types. Given a termngrelation r 2 TRelD^T; T0E^, define a stackng
relation r s 2 SRelD^T; T0E^ by

D^S; S0E^ 2 r s if and only if for all D^t; t0E^ 2 r , hS; ti # holds if and only if
hS0; t0i # does.

Conversely, given a stackngrelation s 2 SRelD^T; T0E^, define a termngrelation st 2
TRelD^T; T0E^ by

D^t; t0E^ 2 st if and only if for all D^S; S0E^ 2 s, hS; ti # holds if and only if
hS0; t0i # does.

Call a termngrelation r 2 TRelD^T; T0E^ closed if it satisfies r C^ r s t and valuable if
it satisfies r C^ r v s t. 2

7.6.4 Note: The operator D^-E^s t is denoted D^-E^?? in Pitts (1998; 2000). 2

268 7 Typed Operational Reasoning

7.6.5 Lemma: The operations D^-E^s and D^-E^t for turning termngrelations into stackng

relations and vice versa, form a Galois connection:

s ` r s if and only if r ` st: (7.18)
Hence the operator D^-E^s t on termngrelations is monotone (r1 ` r2 implies
D^r1E^s t ` D^r2E^s t), inflationary (r ` r s t), and idempotent (D^r s tE^s t C^ r s t ). 2

Proof: If s ` r s, then for any D^t; t0E^ 2 r we have for all D^S; S0E^ 2 s that
D^S; S0E^ 2 r s, so hS; ti # iff hS0; t0i #; hence D^t; t0E^ 2 st. Thus s ` r s implies
r ` st. The converse implication holds by a similar argument. Once we have
(7.18), the other properties follow by standard arguments true of any Galois
connection, which we give in case the reader has not seen them before.

Thus for any termngrelation r , since r s ` r s, from (7.18) we conclude that
r ` r s t ; so D^-E^s t is inflationary (and symmetrically, so is the operator D^-E^t s
on stackngrelations).

Now we can deduce that D^-E^s and D^-E^t are orderngreversing. For if r1 ` r2,
then r1 ` r2 ` r s t2 , so by (7.18), r s2 ` r s1. Similarly, s1 ` s2 implies st2 ` st1.
Hence D^-E^s t is monotone (and so is D^-E^t s).

Finally, for idempotence, in view of the inflationary property we just have to
show D^r s tE^s t ` r s t. But applying (7.18) to r s t ` r s t we get r s ` D^r s t E^s; applying
the orderngreversing operator D^-E^t to this yields D^r s tE^s t ` r s t , as required. 2

7.6.6 Corollary: Every valuable termngrelation is--in particular--a closed termng

relation. 2

Proof: Note that because D^-E^s t is idempotent (by the above lemma), any
termngrelation of the form r s t is closed. Thus valuable termngrelations (ones
satisfying r C^ r v s t) are in particular closed. 2

The following exercise establishes a supply of valuable termngrelations that
we will need later.

7.6.7 Exercise [Recommended, n'n']: Given any valuengrelation r 2 VRelD^T; T0E^, show

that r s t is valuable, i.e., satisfies r s t C^ D^r s tE^v s t. 2

Closed termngrelations (and hence also valuable termngrelations) have excelng
lent "admissibility" properties that we record in the following lemma.

7.6.8 Lemma: If r 2 TRelD^T; T0E^ satisfies r C^ r s t (and in particular if it is valuable),

then it has the following properties.

Equivalencengrespecting If D^t; t0E^ 2 r , ; ` t C^ciu t1 : T, and ; ` t0 C^ciu t01 :

T, then D^t1; t01E^ 2 r .

7.6 An Operationally Based Logical Relation 269
Admissibility Given recursive function values F defC^ fun f(x:T1)=u:T2 and

F0 defC^ fun f(x:T1)=u0:T2, let Fn and F0n (n C^ 0; 1; : : :) be their "unwindings,"
as in Theorem 7.4.4. If D^E,x , FnG*t; E,x , F0nG*t0E^ 2 r for all n C^ 0; 1; : : :, then
D^E,x , FG*t; E,x , F0G*t0E^ 2 r . 2

Proof: Suppose D^t; t0E^ 2 r , ; ` t C^ciu t1 : T and ; ` t0 C^ciu t01 : T. To see
that D^t1; t01E^ 2 r , since r C^ D^r sE^t, it suffices to show for all D^S; S0E^ 2 r s that
hS; t1i # iff hS0; t01i #. But

hS; t1i # iff hS; ti # (since ; ` t C^ciu t1 : T)

iff hS0; t0i # (since D^S; S0E^ 2 r s and D^t; t0E^ 2 r )
iff hS0; t01i # (since ; ` t0 C^ciu t01 : T).

For the Admissibility property we apply the Unwinding Theorem. Suppose
D^E,x , FnG*t; E,x , F0nG*t0E^ 2 r holds for all n C^ 0; 1; : : :. Then for any D^S; S0E^ 2 r s
we have

hS; E,x , FG*ti #

iff for some n, hS; E,x , FnG*ti # (by Theorem 7.4.4)
iff for some n, hS0; E,x , F0nG*t0i # (since D^S; S0E^ 2 r s and

D^E,x , FnG*t; E,x , F0nG*t0E^ 2 r )
iff hS; E,x , F0G*t0i # (by Theorem 7.4.4 again)

and therefore D^E,x , FG*t; E,x , F0G*t0E^ 2 D^r sE^t; but r s t C^ r . 2

7.6.9 Definition [Action of types on termngrelations]: The action of types on

termngrelations takes the following form: if TD^XE^ is a type whose free type
variables lie among the list X C^ X1; : : : ; Xn, then given a corresponding list
of term relations r1 2 TRelD^T1; T01E^; : : : ; rn 2 TRelD^Tn; T0nE^, we define a term
relation TE,r G* 2 TRelD^E,X , TG*T; E,X , T0G*TE^. The definition is by induction on
the structure of T as follows.

XiE,r G* defC^ D^riE^v s t
GndE,r G* defC^ D^IdGndE^s t
D^T1!T2E^E,r G* defC^ funD^T1E,r G*; T2E,rG*E^s t
{li:Ti i21::n}E,r G* defC^ {li=TiE,r G* i21::n}s t

D^8X.TE^E,r G* defC^ D^*r .TE,r ; rG*E^s t
{9X,T}E,r G* defC^ {9r ,TE,r ; rG*}s t

270 7 Typed Operational Reasoning

IdGnd 2 VRelD^Gnd; GndE^
is {D^c; cE^ | Typeof D^cE^ C^ Gnd}.

funD^r1; r2E^ 2 VRelD^T1!T2; T01!T02E^,
given r1 2 TRelD^T1; T01E^ and r2 2 TRelD^T2; T02E^,
is defined by:

D^v; v0E^ 2 funD^r1; r2E^ if and only if for all
D^v1; v01E^ 2 D^r1E^v, it is the case that
D^v v1; v0 v01E^ 2 r2.

{li=ri i21::n} 2 VRelD^{li:Ti i21::n};

{li:T0i i21::n}E^
given D^ri 2 TRelD^Ti; T0i E^ i21::nE^,
is defined by:

D^v; v0E^ 2 {li=ri i21::n} if and only if for all
i 2 1::n, it is the case that
D^v.li; v0.liE^ 2 ri.

*r .RD^r E^ 2 VRelD^8X.T; 8X.T0E^,
given RD^r E^ 2 TRelD^E,X , T1G*T; E,X , T01G*T0E^E^ for
r 2 TRelD^T1; T01E^ and T1; T01 2 Typ,
is defined by:

D^v; v0E^ 2 *r .RD^r E^ if and only if for all
T1; T01 2 Typ and all r 2 TRelD^T1; T01E^, it
is the case that D^v T1; v0 T01E^ 2 RD^r E^.

{9r ,RD^r E^} 2 VRelD^{9X,T}; {9X,T0}E^,
given RD^r E^ 2 TRelD^E,X , T1G*T; E,X , T01G*T0E^E^ for
r 2 TRelD^T1; T01E^ and T1; T01 2 Typ,
is defined by:

D^v; v0E^ 2 {9r ,RD^r E^} if and only if there
exist T1; T01 2 Typ, r 2 TRelD^T1; T01E^ and
D^v1; v01E^ 2 RD^r E^ with
v C^ {*T1,v1} as {9X,T} and
v0 C^ {*T01,v01} as {9X,T0}.

Figure 7ng5: Typengdirected constructions on termngrelations

In addition to the operations on termng, valueng and stackngrelations given in
Definition 7.6.3, these definitions make use of the operations for constructing
valuengrelations from termngrelations given in Figure 7ng5. 2

We can use the action of types on termngrelations to define a typengrespecting
binary relation between open terms (in the sense of Definition 7.5.1) by inng
sisting that if we substitute related terms for the free value variables, the reng
sulting terms are still related. This "mapping related things to related things"
property is the common characteristic of the wide variety of constructs called
logical relations that have arisen since the seminal work of Plotkin (1973) and
Statman (1985) concerning simply typed *ngcalculus; see also Chapter 6.

7.6.10 Definition [Logical relation, \Delta ]: Given \Gamma  ` t : T and \Gamma  ` t0 : T, with

\Gamma  C^ X1; : : : ;Xm; x1 : T1; : : : ;xn : Tn say, we write \Gamma  ` t \Delta  t0 : T to mean that
for all \Gamma  ngclosing substitutions oe ; oe 0 (cf. Definition 7.5.2(v)) and all families of
termngrelations r C^ D^ri 2 TRelD^oe D^XiE^; oe 0D^XiE^E^ i21::mE^, if D^oe D^xj E^; oe 0D^xj E^E^ 2 Tj E,r G*v
holds for each j C^ 1; : : : ; n, then D^oe D^tE^; oe 0D^t0E^E^ 2 TE,r G*. 2

7.6.11 Remark: Since it is far from straightforward, the form of Definitions 7.6.9

and 7.6.10 deserves some explanation. These definitions embody certain exng

7.6 An Operationally Based Logical Relation 271
tensionality and parametricity properties (see $7.7 and Theorem 7.7.8) that
we wish to show hold for FML contextual equivalence: eventually we show
that the above logical relation \Delta  coincides with contextual equivalence (Theong
rem 7.6.25). To get that coincidence we have to formulate the definition of \Delta 
so that it satisfies the crucial property of Lemma 7.6.17 below (the songcalled
fundamental property of the logical relation) and is adequate (Lemma 7.6.24).
The definition of the action of types on termngrelations in Definition 7.6.9 is
carefully formulated to ensure these properties hold.

First of all, note the use of closing substitutions to reduce the logical reng
lation for open terms to that for closed ones. This builds in the "instantiang
tion" aspect of ciungequivalence that we wish to prove of contextual equivang
lence. (It also means that the logical relation has the "monotonicity" propng
ertymonotonicity property of logical relations considered in Chapter 6.)

Secondly, we want TE,r G* to always be a closed termngrelation, because then it
has the equivalencengrespecting and admissibility properties noted in Lemma
7.6.8. This accounts for the use of D^-E^s t in the definition. The D^-E^s and D^-E^t
operators build into the logical relation a delicate interplay between terms
and frame stacks. Of course this relies on the formulation of the operational
semantics of FML in $7ng3: although more traditional "bigngstep" or "smallng
step" operational semantics lead to the same termination relation (cf. Exerng
cise 7.4.2), the pairing between frame stacks and terms defined in Figure 7ng2
is ideal for our purposes.

Lastly, the callngbyngvalue nature of FML dictates that relational parametricng
ity properties of polymorphic types should be with respect to termngrelations
that are valuable; but instead of letting r range over such relations in the
definition of D^8X.TE^E,r G* and {9X,T}E,r G* we have used an equivalent formulang
tion in which r ranges over all termngrelations (of appropriate type), but type
variables X are interpreted using the closure of the valuengrestriction operang
tor D^-E^v: for in fact as r ranges over all termngrelations, r v s t ranges over all
valuable termngrelations. 2

The rest of this section is devoted to showing that contextual equivalence
and ciungequivalence coincide with the logical relation.

7.6.12 Lemma: Each of the term relations TE,r G* defined in Definition 7.6.9 is valuable,

i.e., satisfies TE,r G* C^ TE,rG*v s t, and hence in particular by Corollary 7.6.6 is
closed. 2

Proof: It is immediate from the definition that each TE,rG* is of the form r s t
for some valuengrelation r ; so just apply Exercise 7.6.7. 2

The following lemma helps with calculations involving the action on termng
relations of function types. We give its proof in detail since it typifies the kind

272 7 Typed Operational Reasoning

of reasoning needed when working with the Galois connection given by the
D^-E^s and D^-E^t operators. (For related properties for record and 8ngtypes, see
Exercise 7.6.14.)

7.6.13 Lemma: The operation funD^-; -E^ from Definition 7.6.9(ii) satisfies

funD^r1; D^r2E^s tE^s t v C^ funD^r1; D^r2E^s tE^ (7.19)
funD^D^r1E^v s t ; D^r2E^s t E^ C^ funD^r1; D^r2E^s tE^: (7.20)

Proof: To prove (7.19), first note that since D^-E^s t is inflationary (Lemma 7.6.5)
we have funD^r1; D^r2E^s tE^ ` funD^r1; D^r2E^s t E^s t ; and since funD^r1; D^r2E^s tE^ is a valueng
relation, it follows that funD^r1; D^r2E^s tE^ ` funD^r1; D^r2E^s t E^s t v. For the reverse
inclusion it suffices to prove

funD^r1; D^r2E^s t E^s t ` funD^r1; D^r2E^s t E^ (7.21)
and then apply D^-E^v to both sides (noting that funD^r1; D^r2E^s t E^, being a valueng
relation, is equal to funD^r1; D^r2E^s tE^v). For (7.21) we use the following simple
property of the termination relation (Figure 7ng2) with respect to application:

hS ffi D^f.f v1E^; vi # a hS; v v1i #
and hence

D^hS; v v1i # a hS0; v0 v01i #E^ a

D^hS ffi D^f.f v1E^; vi # a hS0 ffi D^f.f v01E^; v0i #E^ (7.22)

If D^v; v0E^ 2 funD^r1; D^r2E^s t E^ and D^v1; v01E^ 2 D^r1E^v, then we have D^v v1; v0 v01E^ 2
D^r s2E^t by definition of the funD^-; -E^ operation on termngrelations (Figure 7ng5).
So if D^S; S0E^ 2 D^r2E^s, then

hS; v v1i # a hS0; v0 v01i #

and hence by (7.22)

hS ffi D^f.f v1E^; vi # a hS0 ffi D^f.f v01E^; v0i #:
Since this holds for all D^v; v0E^ 2 funD^r1; D^r2E^s tE^, we deduce that

D^S; S0E^ 2 D^r2E^s & D^v1; v01E^ 2 D^r1E^v )

D^S ffi D^f.f v1E^; S0 ffi D^f.f v01E^E^ 2 funD^r1; D^r2E^s tE^s:

So for any D^S; S0E^ 2 D^r2E^s and D^v1; v01E^ 2 D^r1E^v, since

D^S ffi D^f.f v1E^; S0 ffi D^f.f v01E^E^ 2 funD^r1; D^r2E^s t E^s

7.6 An Operationally Based Logical Relation 273
it follows that if

D^v; v0E^ 2 funD^r1; D^r2E^s t E^s t (7.23)
then hS ffi D^f.f v1E^; vi # a hS0 ffi D^f.f v01E^; v0i #, and hence by (7.22) it folng
lows that hS; v v1i # a hS0; v0 v01i #. Since this holds for all D^S; S0E^ 2 D^r2E^s,
it follows that D^v v1; v0 v01E^ 2 D^r2E^s t whenever D^v1; v01E^ 2 D^r1E^v. So D^v; v0E^ 2
funD^r1; D^r2E^s t E^ whenever (7.23) holds; thus we have proved the inclusion in
(7.21), as required.

Turning to the proof of (7.20), first note that since since D^-E^s t is inflationng
ary, we have D^r1E^v ` D^r1E^v s t . So since funD^-; -E^ is clearly orderngreversing
in its first argument, we have funD^D^r1E^v s t; D^r2E^s tE^ ` funD^D^r1E^v; D^r2E^s t E^; and
funD^D^r1E^v; D^r2E^s tE^ C^ funD^r1; D^r2E^s t E^, because funD^-; -E^ only depends upon the
values related by its first argument. Thus to prove (7.20), we just have to show

funD^r1; D^r2E^s t E^ ` funD^D^r1E^v s t ; D^r2E^s t E^: (7.24)
For this we use the following fact about termination

hS ffi D^x.v xE^; v1i # a hS; v v1i #
which is immediate from the definition in Figure 7ng2. From this it follows that

D^hS; v v1i # a hS0; v0 v01i #E^ a

D^hS ffi D^x.v xE^; v1i # a hS0 ffi D^x.v0 xE^; v01i #E^ (7.25)

If D^v; v0E^ 2 funD^r1; D^r2E^s tE^ and D^v1; v01E^ 2 D^r1E^v, then by definition of funD^-; -E^
we have D^v v1; v0 v01E^ 2 D^r2E^s t. So if D^S; S0E^ 2 D^r2E^s, then

hS; v v1i # a hS0; v0 v01i #

and hence by (7.25) we have

hS ffi D^x.v xE^; v1i # a hS0 ffi D^x.v0 xE^; v01i #:
Since this holds for all D^v1; v01E^ 2 D^r1E^v, we deduce that

D^S; S0E^ 2 D^r2E^s & D^v; v0E^ 2 funD^r1; D^r2E^s tE^ )

D^S ffi D^x.v xE^; S0 ffi D^x.v0 xE^E^ 2 D^r1E^v s:

So for any D^S; S0E^ 2 D^r2E^s and D^v; v0E^ 2 funD^r1; D^r2E^s tE^, since D^S ffi D^x.v xE^; S0 ffi
D^x.v0 xE^E^ 2 D^r1E^v s, it follows for any D^v1; v01E^ 2 D^D^r1E^v s t E^v ` D^D^r1E^v sE^t that
we have hS ffi D^x.v xE^; v1i # a hS0 ffi D^x.v0 xE^; v01i #, and hence by (7.25) that
hS; v v1i # a hS0; v0 v01i #. Since this holds for all D^S; S0E^ 2 D^r2E^s, it follows that
D^v v1; v0 v01E^ 2 D^r2E^s t. Hence D^v; v0E^ 2 funD^D^r1E^v s t; D^r2E^s tE^ whenever D^v; v0E^ 2
funD^r1; D^r2E^s t E^, as required for (7.24). 2

274 7 Typed Operational Reasoning

7.6.14 Exercise [Recommended, n']: Show that constructions (iii) and (iv) in Defining

tion 7.6.9 satisfy

{li=D^riE^s t i21::n}s t v C^ {li=D^riE^s t i21::n} (7.26)

D^*r .RD^r E^s t E^s t v C^ *r .RD^r E^s t: (7.27)

(Cf. the proof of Lemma 7.6.13.) 2
7.6.15 Lemma: For all ground types Gnd, D^IdGndE^s t v C^ IdGnd. 2

Proof: Since D^-E^s t is idempotent (Lemma 7.6.5), we have IdGnd ` D^IdGndE^s t;
and since IdGnd is a valuengrelation it follows that IdGnd ` D^IdGndE^s t v. To prove
the reverse inclusion, for each constant c of type Gnd consider

diverge defC^ (fun f(b:Bool) = f b : Bool)true

Sc defC^ Id ffi D^x. if x=c then true else divergeE^:

Note that for all constants c0 of type Gnd

hSc; c0i # a c C^ c0: (7.28)
Furthermore, since D^c0; c00E^ 2 IdGnd iff c0 C^ c00, we have that D^Sc; ScE^ 2 D^IdGndE^s;
so if the constants c and c0 satisfy D^c; c0E^ 2 D^IdGndE^s t , then we have hSc; ci # a
hSc; c0i #. So by (7.28), D^c; c0E^ 2 D^IdGndE^s t implies c C^ c0; thus D^IdGndE^s t v `
IdGnd. 2

7.6.16 Lemma: The action of types on termngrelations of Definition 7.6.9 has the folng

lowing substitution property. For any types T and T0 with ftvD^TE^ ` X; X and
ftvD^T0E^ ` X, it is the case that D^E,X , T0G*TE^E,r G* C^ TE,T0E,r G*; rG*. 2

Proof: This follows by induction on the structure of the type T; for the base
case when T C^ X, use Lemma 7.6.12. 2

7.6.17 Lemma [Fundamental property of the logical relation]: The logical reng

lation \Delta  of Definition 7.6.10 has the substitutivity and compatibility properng
ties defined in Figure 7ng4. 2

Proof: The first substitutivity property in Figure 7ng4 (closure under substing
tuting values for value variables) holds for \Delta  because of the way it is deng
fined in terms of closing substitutions. The second substitutivity property
(closure under substituting types for types variables) holds for \Delta  because of
Lemma 7.6.16.

7.6 An Operationally Based Logical Relation 275

Now consider the compatibility properties given in Figure 7ng4. There is one
for each clause in the grammar of FML terms and values (Figure 7ng1). We conng
sider each in turn, giving the details in some cases and setting the others as
exercises (with solutions).

Value variables: This case is immediate from the definition of \Delta  in Defining
tion 7.6.10.

Constants: We have to show for each constant c, with Typeof D^cE^ C^ Gnd
say, that D^c; cE^ 2 GndE,r G* C^ D^IdGndE^s t. But by definition of IdGnd (Figure 7ng5),
D^c; cE^ 2 IdGnd; and IdGnd ` D^IdGndE^s t by Lemma 7.6.5.

Recursive functions: Using property (7.19) and the fact that each TE,r G* is
valuable and hence closed (Lemma 7.6.12), the compatibility property for reng
cursive functions reduces to proving the property in Exercise 7.6.18.

Record values: This case follows from the property in Exercise 7.6.19.
Type abstractions: This case follows from the property in Exercise 7.6.20.
Package values: This case follows easily from the definition of {9r ,RD^r E^}
in Figure 7ng5, using Lemma 7.6.16.

Conditionals: This case follows from the property in Exercise 7.6.21.
Operations: In view of Lemma 7.6.15, this compatibility property follows
once we prove D^op(ci i21::n); op(ci i21::n)E^ 2 D^IdGndE^s t for any (suitably typed)
constants ci and operator op. But if the value of op(ci i21::n) is the constant c
say, then for any S

hS; op(ci i21::n)i # a hS; ci #:
Hence for any D^S; S0E^ 2 D^IdGnd0E^s (where Gnd0 C^ Typeof D^cE^), we have

hS; op(ci i21::n)i # a hS; ci #

a hS0; ci # (since D^c; cE^ 2 IdGnd0)
a hS0; op(ci i21::n)i #:

So we do indeed have D^op(ci i21::n); op(ci i21::n)E^ 2 D^IdGndE^s t.

Applications: This case amounts to proving that if recursive function values
v and v0 satisfy D^v; v0E^ 2 funD^r1; r2E^s t for some closed termngrelations r1 and
r2, then for any D^v1; v01E^ 2 r1 it is the case that D^v v1; v0 v01E^ 2 r2. But this
property follows immediately from the definition of funD^-; -E^ using the first
part of Lemma 7.6.13: for

D^v; v0E^ 2 funD^r1; r2E^s t v

C^ funD^r1; D^r2E^s t E^s t v (since r2 is closed)
C^ funD^r1; D^r2E^s t E^ (by (7.19))
C^ funD^r1; r2E^ (since r2 is closed).

276 7 Typed Operational Reasoning

Projections: This case is similar to the previous one, but using property
(7.26) from Exercise 7.6.14 rather than (7.19).

Type applications: This case is similar to the previous one, using property
(7.27) from Exercise 7.6.14.

Unpacking: This case follows from the property in Exercise 7.6.22.
Sequencing: This case follows from the property in Exercise 7.6.23. 2

7.6.18 Exercise [Recommended, n'n'n']: Suppose

F defC^ fun f(x:T1)=t:T2 2 ValD^T1!T2E^
F0 defC^ fun f(x:T01)=t0:T02 2 ValD^T01!T02E^
r1 2 TRelD^T1; T01E^
r2 2 TRelD^T2; T02E^

satisfy r2 C^ D^r2E^s t and

D^E,f , vG*E,x , v1G*t; E,f , v0G*E,x , v01G*t0E^ 2 r2;
for all D^v; v0E^ 2 funD^r1; r2E^ and D^v1; v01E^ 2 D^r1E^v.

(7.29)

Use the admissibility property of valuable termngrelations established in Lemng
ma 7.6.8 to show that D^F; F0E^ 2 funD^r1; r2E^. 2

7.6.19 Exercise [n'n']: Suppose for i 2 1::n that vi 2 ValD^TiE^, v0i 2 ValD^T0iE^ and ri 2

TRelD^Ti; T0i E^ with ri C^ D^riE^s t. Putting

v defC^ {li=vi i21::n} 2 ValD^{li:Ti i21::n}E^
v0 defC^ {li=v0i i21::n} 2 ValD^{li:T0i i21::n}E^

show that if D^vi; v0iE^ 2 ri for i 2 1::n, then D^v; v0E^ is in the valuengrelation
{li=ri i21::n} defined in Figure 7ng5. 2

7.6.20 Exercise [n'n']: Let T and T0 be types with at most X free. For each T1; T01 2 Typ

and r 2 TRelD^T1; T01E^ suppose we are given a closed termngrelation RD^r E^ in
TRelD^E,X , T1G*T; E,X , T01G*T0E^E^ (i.e., RD^r E^ C^ RD^r E^s t). Show that if the values v
and v0 satisfy

X ` v : T
X ` v0 : T0
8T1; T01 2 Typ; r 2 TRelD^T1; T01E^: D^E,X , T1G*v; E,X , T01G*v0E^ 2 RD^r E^

then D^*X.v; *X.v0E^ is in the valuengrelation *r .RD^r E^ defined in Figure 7ng5. 2

7.6 An Operationally Based Logical Relation 277
7.6.21 Exercise [n'n']: Suppose D^v; v0E^ 2 D^IdBoolE^s t and D^t1; t01E^; D^t2; t02E^ 2 r , where

r 2 TRelD^T; T0E^ is closed (i.e., r C^ D^r E^s t). Show that

D^if v then t1 else t2; if v0 then t01 else t02E^
is in r . 2
7.6.22 Exercise [n'n']: Let T and T0 be types with at most X free. For each T1; T01 2 Typ

and r1 2 TRelD^T1; T01E^ suppose we are given a closed termngrelation RD^r1E^ C^
RD^r1E^s t in TRelD^E,X , T1G*T; E,X , T01G*T0E^E^. Suppose we are also given a closed
termngrelation r2 C^ D^r2E^s t 2 TRelD^T2; T02E^ for some closed types T2; T02 2 Typ.
Show that if the terms t; t0 satisfy

X; x : T ` t : T2
X; x : T0 ` t0 : T02
8T1; T01 2 Typ; r1 2 TRelD^T1; T01E^; D^v1; v01E^ 2 D^r1E^v:

D^E,X , T1G*E,x , v1G*t; E,X , T1G*E,x , v1G*tE^ 2 r2

then whenever D^v; v0E^ 2 {9r1,RD^r1E^}s t v, it is also the case that

D^let {*X,x}=v in t; let {*X,x}=v0 in t0E^
is in r2. 2
7.6.23 Exercise [n'n']: Suppose we are given r1 2 TRelD^T1; T01E^, r2 2 TRelD^T2; T02E^ with

r1 valuable (i.e., r1 C^ D^r1E^v s t ) and r2 closed (i.e., r2 C^ D^r2E^s t ). Show that if the
terms t2; t02 satisfy

x : T1 ` t2 : T2
x : T01 ` t02 : T02
8D^v1; v01E^ 2 D^r1E^v: D^E,x , v1G*t2; E,x , v01G*t02E^ 2 r2

then whenever D^t1; t01E^ 2 r1, it is also the case that

D^let x=t1 in t2; let x=t01 in t02E^
is in r2. 2
7.6.24 Lemma [Adequacy]: The logical relation \Delta  is adequate (Definition 7.5.1). 2

Proof: Suppose ; ` t \Delta  t0 : T; we have to show that t # holds iff t0 # does,
or equivalently that

hId; ti # iff hId; t0i #: (7.30)

278 7 Typed Operational Reasoning

Unraveling Definition 7.6.10, the assumption that the closed terms t and t0
of closed type T are \Delta ngrelated means that D^t; t0E^ 2 TE,G*, the latter being the
action of the type T on the empty list of termngrelations. By Lemma 7.6.12, TE,G*
is valuable; so D^t; t0E^ 2 TE,G*v s t. Hence to prove (7.30), it suffices to show that
D^Id; IdE^ 2 D^TE,G*vE^s; but for any D^v; v0E^ 2 TE,G*v,

hId; vi # iff hId; v0i #
holds trivially by axiom (SngNilVal) in Figure 7ng2. 2

We are finally able to put all the pieces together and prove the main result
of this section. At the same time we complete the proof of Theorem 7.5.7.

7.6.25 Theorem [C^ctx equals \Delta  equals C^ciu]: FML contextual equivalence, C^ctx, (as

defined in Theorem 7.5.3) coincides with the logical relation \Delta  of Defining
tion 7.6.10 and with ciungequivalence, C^ciu (Definition 7.5.5): \Gamma  ` t C^ctx t0 : T
holds if and only if \Gamma  ` t \Delta  t0 : T does, if and only if \Gamma  ` t C^ciu t0 : T does. 2

Proof: It suffices to show that the following chain of inclusions holds:

C^ctx

(1)` C^

ciu

(3)`

\Delta 

(2)` C^

ctx:

(1) This is the half of Theorem 7.5.7 that we have already proved in $7.5.
(2) We have not yet shown that \Delta  is an equivalence relation; and in fact we

will only deduce this once we have shown that it coincides with C^ctx and
C^ciu (which are easily seen to be equivalence relations). However, we have
shown that \Delta  is compatible, substitutive and adequate (Lemmas 7.6.17 and
7.6.24). In the proof of Theorem 7.5.3 we constructed C^ctx as the union of
all such typengrespecting relations, without regard to whether they were
also equivalence relations; therefore \Delta  is contained in C^ctx.

(3) Noting how C^ciu and \Delta  are defined on open terms via substitutions, we

can combine the first part of Lemma 7.6.8 with Lemma 7.6.12 to give

\Gamma  ` t C^ciu t0 : T & \Gamma  ` t0 \Delta  t00 : T ) \Gamma  ` t \Delta  t00 : T: (7.31)
We noted in the proof of Theorem 7.5.3 that every compatible termngrelation
is reflexive. (This is easily proved by induction on the structure of terms.)
So since \Delta  is compatible (Lemma 7.6.17) it is in particular reflexive. So
we can take t0 C^ t00 in (7.31) to deduce that \Gamma  ` t C^ctx t0 : T implies
\Gamma  ` t \Delta  t0 : T. 2

7.7 Operational Extensionality 279
7.7 Operational Extensionality

In this section we develop some of the consequences of Theorem 7.6.25.
Now that we know that contextual equivalence coincides with ciungequivalence
(Theorem 7.5.7), when giving general properties of C^ctx we restrict attention
to closed terms of closed type where possible, since the corresponding propng
erty for open terms can be obtained via closing substitutions.

7.7.1 Theorem [Extensionality for values]: We now give extensionality princing

ples for the various types of value; for package values, the principle is a forng
malization of the final one discussed in the Introduction (Principle 7.3.6).

1. Constants: Given constants c, c0 of the same ground type, Gnd say, ; `

c C^ctx c0 : Gnd holds if and only if c C^ c0.

2. Functions: Given f:T1!T2; x:T1 ` t : T2 and f:T1!T2; x:T1 ` t0 : T2,

writing v and v0 for the recursive function values fun f(x:T1)=t:T2 and
fun f(x:T1)=t0:T2 respectively, then ; ` v C^ctx v0 : T1!T2 if and only
if for all ; ` v1 : T1, it is the case that ; ` E,f , vG*E,x , v1G*t C^ctx E,f ,
v0G*E,x , v1G*t0 : T2.

3. Records: Given values ; ` vi : Ti and ; ` v0i : Ti for i 2 1::n, then

; ` {li=vi i21::n} C^ctx {li=v0i i21::n} : {li:Ti i21::n} if and only if for each
i 2 1::n, ; ` vi C^ctx v0i : Ti.

4. Type abstractions: Given X ` v : T and X ` v0 : T, then ; ` *X.v C^ctx

*X.v0 : 8X.T if and only if for all closed types T0, ; ` E,X , T0G*v C^ctx E,X ,
T0G*v0 : E,X , T0G*T.

5. Packages: For any closed existential type {9X,T}, closed types T1, T2, and

values ; ` vi : E,X , TiG*T (i C^ 1; 2),

; ` {*T1,v1} as {9X,T} C^ctx {*T2,v2} as {9X,T} : {9X,T}
holds if there is some termngrelation r 2 TRelD^T1; T2E^ with D^v1; v2E^ 2 TE,r G*. 2
Proof:

1. The property for constants follows from Lemma 7.6.15 combined with

Theorem 7.6.25.

2. Suppose for all ; ` v1 : T1 that

; ` E,f , vG*E,x , v1G*t C^ctx E,f , v0G*E,x , v1G*t0 : T2 (7.32)

280 7 Typed Operational Reasoning

where v and v0 are as in part 2 of the theorem. To show ; ` v C^ctx
v0 : T1!T2, by Theorem 7.6.25 it suffices to show ; ` v \Delta  v0 : T1!T2,
i.e., that D^v; v0E^ 2 D^T1!T2E^E,G* C^ funD^T1E,G*; T2E,G*E^s t. In fact we show that
D^v; v0E^ 2 funD^T1E,G*; T2E,G*E^. For this we have to prove that if D^v1; v01E^ 2 T1E,G*v,
then D^v v1; v0 v01E^ 2 T2E,G*. By Theorem 7.6.25 again, this is the same as
showing: if ; ` v1 C^ctx v01 : T1, then ; ` v v1 C^ctx v0 v01 : T2. As noted in
Corollary 7.5.8, we can turn the primitive reduction for function applicang
tion into a ciungequivalence and hence by Theorem 7.6.25 into a contextual
equivalence:

; ` v v1 C^ctx E,f , vG*E,x , v1G*t : T2 (7.33)
and similarly for v0 v01. Therefore we just need to show: if ; ` v1 C^ctx v01 :
T1, then ; ` E,f , vG*E,x , v1G*t C^ctx E,f , v0G*E,x , v01G*t0 : T2. But this
follows from the assumption (7.32) using the reflexivity and substitutivity
properties of C^ctx. So we have established one half (the difficult half) of
the property in 2. For the converse, if ; ` v C^ctx v0 : T1!T2, then for any
; ` v1 : T1, the compatibility properties of C^ctx give ; ` v v1 C^ctx v0 v1 :
T2; and then as before, we can compose with (7.33) to get (7.32).

3. We leave the extensionality property for records as an exercise (7.7.2).
4. For the property for type abstractions, suppose

8T0 2 Typ: ; ` E,X , T0G*v C^ctx E,X , T0G*v0 : E,X , T0G*T: (7.34)
Note that since \Delta  coincides with C^ctx (Theorem 7.6.25) it is reflexive and
hence X ` v \Delta  v : T holds. According to Definition 7.6.10 this means
that for all T1; T01 2 Typ and r 2 TRelD^T1; T01E^, D^E,X , T1G*v; E,X , T01G*vE^ 2
TE,r G*. Since TE,r G* is closed (Lemma 7.6.12), we can combine (7.34) with the
first part of Lemma 7.6.8 (using C^ctx in place of C^ciu by virtue of Theong
rem 7.6.25) to conclude that D^E,X , T1G*v; E,X , T01G*v0E^ 2 TE,r G* for all r . Then
using the equivalence in Corollary 7.5.8(v), we have

8T1; T01 2 Typ; r 2 TRelD^T1; T01E^: D^(*X.v)T1; (*X.v0)T01E^ 2 TE,r G*
and hence D^*X.v; *X.v0E^ is in *r .TE,r G*. Since *r .TE,r G* ` D^*r .TE,r G*E^s t and
the latter is equal to D^8X.TE^E,G* by definition, we have ; ` *X.v \Delta  *X.v0 :
8X.T, and hence by Theorem 7.6.25, ; ` *X.v C^ctx *X.v0 : 8X.T. So
we have established one half (the difficult half) of the property in 4. The
argument for the other half is similar to that for property 2, using Corolng
lary 7.5.8(v) and the congruence properties of C^ctx.

7.7 Operational Extensionality 281

5. Finally, let us consider the extensionality property for package values.

(Note that unlike the other four, this only gives a sufficient condition for
contextual equivalence; Example 7.7.4 below shows that the condition is
not necessary.) If D^v1; v2E^ 2 TE,r G*, then from Definition 7.6.9 we have

D^{*T1,v1} as {9X,T}; {*T2,v2} as {9X,T}E^ 2 {9r ,TE,r G*}

` {9r ,TE,r G*}s t
C^ {9X,T}E,G*:

Thus ; ` {*T1,v1} as {9X,T} \Delta  {*T2,v2} as {9X,T} : {9X,T} and we
can apply Theorem 7.6.25 to get the desired contextual equivalence. 2

7.7.2 Exercise [n'n', 3]: Use Theorem 7.6.25, Corollary 7.5.8 and the definition of

the termngrelation {li=ri i21::n} in Definition 7.6.9 to deduce extensionality propng
erty 3 of Theorem 7.7.1. 2

To see how Theorem 7.7.1(5) can be used in practice, we will apply it to
establish the contextual equivalence of Example 7.3.5 from the Introduction.

7.7.3 Example: Recall the type Semaphore and its values semaphore1, semaphore2

from Example 7.3.5. To show ; ` semaphore1 C^ctx semaphore2 : Semaphore
using Theorem 7.7.1(5), it suffices to show that D^v1; v2E^ 2 TE,r G* where

T defC^ {bit:X, flip:X!X, read:X!Bool}
v1 defC^ {bit=true, flip=*x:Bool.not x, read=*x:Int.x}
v2 defC^ {bit=1, flip=*x:Int.0ng2*x, read=*x:Int.x >= 0}

and r 2 VRelD^Bool; IntE^ is

r defC^ {D^true; mE^ | m C^ D^-2E^n for some even n >= 0} [

{D^false; mE^ | m C^ D^-2E^n for some odd n >= 0}:

Since r is a valuengrelation, we can use Lemma 7.6.13 to slightly simplify TE,r G*:

TE,r G* defC^ {bit=r s t ; flip=funD^r s t ; r s tE^s t ; read=funD^r s t; Ids tBoolE^s t }s t

C^ {bit=r s t ; flip=funD^r ; r s tE^s t; read=funD^r ; Ids tBoolE^s t}s t :

So since D^-E^s t is inflationary, to prove D^v1; v2E^ 2 TE,r G*, it suffices to show

D^true; 1E^ 2 r
D^*x:Bool.not x; *x:Int.0ng2*xE^ 2 funD^r ; r s t E^

D^*x:Int.x; *x:Int.x >= 0E^ 2 funD^r ; Ids tBoolE^:

282 7 Typed Operational Reasoning

These follow from the definition of r --the first trivially and the second two
once we combine the definition of funD^-; -E^ with the fact (Lemma 7.6.8)
that closed relations such as r s t and Ids tBool respect ciungequivalence. For exng
ample, if D^v1; v01E^ 2 r , then (*x:Bool.not x)v1 and (*x:Int.0ng2*x)v01 are
ciungequivalent to r ngrelated values v2 and v02; then since D^v2; v02E^ 2 r ` r s t and
the latter is closed, we have D^(*x:Bool.not x)v1; (*x:Int.0ng2*x)v01E^ 2 r s t.
As this holds for all D^v1; v01E^ 2 r , we have D^*x:Bool.not x; *x:Int.0ng2*xE^ in
funD^r ; r s tE^. 2

Theorem 7.7.1(5) gives a sufficient condition for contextual equivalence of
package values, but the condition is not necessary: it can be the case that
{* T1, v1} as {9X, T} is contextually equivalent to {* T2, v2} as {9X, T}
even though there is no r 2 TRelD^T1; T2E^ with D^v1; v2E^ 2 TE,r G*. The rest of
this section is devoted to giving an example of this unpleasant phenomenon
(based on a suggestion of Ian Stark arising out of our joint work on logical
relations for functions and dynamically allocated names in Pitts and Stark,
1993).

7.7.4 Example: Consider the following types and terms.

P defC^ (X!Bool)!Bool
Q defC^ {9X,P}
N defC^ 8X.X
diverge defC^ (fun f(b:Bool) = f b : Bool)true

G defC^ fun g(f:N!Bool) = diverge : Bool
G0 defC^ fun g(f:Bool!Bool) =

(if f true then

if f false then diverge else true
else diverge) : Bool:

Thus N is a type with no values (Exercise 7.7.6); G is a function that diverges
when applied to any value of type N!Bool; and G0 is a function that diverges
when applied to any value of type Bool!Bool except ones (such as the idenng
tity function) that map true to true and false to false, in which case it
returns true. We claim that

(i) there is no r 2 TRelD^N; BoolE^ for which D^G; G0E^ 2 PE,r G* holds,
(ii) but nevertheless ; ` {*N,G} as Q C^ctx {*Bool,G0} as Q : Q. 2

7.7 Operational Extensionality 283
Proof: For (i) note that the definition of N implies that ValD^NE^ C^ ;, i.e., there
are no closed values of type N (Exercise 7.7.6). So any r 2 TRelD^N; BoolE^ satisng
fies r v C^ ;. Now

PE,r G*v defC^ D^(X!Bool)!BoolE^E,r G*v

defC^ funD^D^X!BoolE^E,r G*; Ids t

BoolE^s t v

C^ funD^D^X!BoolE^E,r G*; Ids tBoolE^ using (7.19)
defC^ funD^funD^r v s t; Ids t

BoolE^s t; Ids tBoolE^

C^ funD^funD^r v s t; Ids tBoolE^s t v; Ids tBoolE^ by definition of funD^-; -E^

C^ funD^funD^r v s t; Ids tBoolE^; Ids tBoolE^ using (7.19)
C^ funD^funD^r ; Ids tBoolE^; Ids tBoolE^ using (7.20)
C^ funD^funD^r v; Ids tBoolE^; Ids tBoolE^ by definition of funD^-; -E^.

Since r v C^ ;, we have funD^r v; Ids tBoolE^ C^ ValD^N!BoolE^*ValD^Bool!BoolE^; and
we know by Theorem 7.6.25 that Ids tBool is the relation {D^t; t0E^ | ; ` t C^ctx
t0 : Bool}. Therefore

PE,r G*v C^ {D^v; v0E^ | ; ` v v1 C^ctx v0 v01 : Bool

for all v1 2 ValD^N!BoolE^ and v01 2 ValD^Bool!BoolE^ }:

However, ; ` G v1 C^ctx G0 v01 : Bool does not hold if we take v1 and v01 to be
the values

v1 defC^ fun f(x:N) = diverge : Bool
v01 defC^ fun f(x:Bool) = x : Bool
since evaluation of G v1 does not terminate, whereas evaluation of G0 v01 does.
Therefore D^G; G0E^ AE PE,r G*v, for any r 2 TRelD^N; BoolE^.

Turning to the proof of (ii), now we know that it cannot be deduced from
the extensionality principle for package values in Theorem 7.7.1, we have to
prove this contextual equivalence by brute force. The termination relation
defined in Fig. 7ng2 provides a possible strategy (if rather a tedious one) for
proving ciungequivalences and hence contextual equivalences--by what one
might call termination induction. Thus to prove (ii) it suffices to prove that
the two terms are ciungequivalent:

8S: hS; {*N,G} as Qi # a hS; {*Bool,G0} as Qi #:
Attempting to do this by induction on the derivation of terminations h-; -i #
(for all S simultaneously), one rapidly realizes that a stronger induction hyng
pothesis is needed: prove for all frame stacks S and terms t that

284 7 Typed Operational Reasoning

hE,x , {*N,G} as QG*S; E,x , {*N,G} as QG*ti #
if and only if hE,x , {*Bool,G0} as QG*S; E,x , {*Bool,G0} as QG*ti #.

It is possible to prove this by induction on the definition of the termination
relation in Fig. 7ng2 (for all S and t simultaneously). We omit the details except
to note that the only difficult induction step is for the primitive reduction
(RngUnpackPack) in Fig. 7ng3 in the case that t is the form let{*X,g}=x in t0.
For that step, one can first show for all frame stacks S and terms t that

hE,X , NG*E,g , GG*S; E,X , NG*E,g , GG*ti #
if and only if hE,X , BoolG*E,g , G0G*S; E,X , BoolG*E,g , G0G*ti #.

This also is proved by induction on the definition of the termination relation.
Once again we omit the details except to note that now the only difficult inng
duction step is for the primitive reduction (RngAppAbs) in the case that t is of
the form g v for some value v. To prove that step one can use Lemma 7.7.5
below. This lemma lies at the heart of the reason why the contextual equivang
lence in (ii) is valid: if an argument supplied to G0 is sufficiently polymorphic
(which is guaranteed by the existential abstraction), then when specialized to
Bool it cannot have the functionality (true , true, false , false) needed
to distinguish G0 from the divergent behavior of G. 2

7.7.5 Lemma: For any value v satisfying X; g:P ` v : X!Bool, evaluation of G0(E,X ,

BoolG*E,g , G0G*v) does not terminate. 2

Proof: To prove this we can use the logical relation from the previous secng
tion. Consider the following valuengrelation in VRelD^Bool; BoolE^:

r defC^ {D^true; trueE^; D^false; falseE^; D^true; falseE^}:
Note that

D^X!BoolE^E,r G*v defC^ funD^rv s t ; Ids tBoolE^s t v

(7.20)C^ funD^r; Ids t

BoolE^s t v

(7.19)C^ funD^r ; Ids t

BoolE^ (7.35)

and hence

PE,r G*v defC^ funD^D^X!BoolE^E,r G*; Ids tBoolE^s t v C^ funD^D^X!BoolE^E,r G*v; Ids tBoolE^s t v

(7.35)C^ funD^funD^r ; Ids t

BoolE^; Ids tBoolE^s t v

(7.19)C^ funD^funD^r ; Ids t

BoolE^; Ids tBoolE^: (7.36)

If D^v1; v01E^ 2 funD^r ; Ids tBoolE^, since D^true; trueE^; D^false; falseE^ 2 r and Ids tBool
is contextual equivalence (Theorem 7.6.25) we get

; ` v1 true C^ctx v01 true : Bool
; ` v1 false C^ctx v01 false : Bool:

7.7 Operational Extensionality 285
So using Corollary 7.5.8(iii) and the congruence properties of C^ctx, we have

G0 v1 C^ctx (if v1 true then

if v1 false then diverge else true
else diverge)

C^ctx (if v01 true then

if v01 false then diverge else true
else diverge)

C^ctx G0 v01

Therefore D^G0 v1; G0 v01E^ 2 Ids tBool whenever D^v1; v01E^ 2 funD^r ; Ids tBoolE^; and so
D^G0; G0E^ 2 PE,r G*v, by (7.36). Hence using Lemma 7.6.17 we have

D^E,X , BoolG*E,g , G0G*v; E,X , BoolG*E,g , G0G*vE^ 2 D^X!BoolE^E,r G*v

C^ funD^r ; Ids tBoolE^ by (7.35).

So since D^true; falseE^ 2 r , we get

D^E,X , BoolG*E,g , G0G*v true; E,X , BoolG*E,g , G0G*v falseE^ 2 Ids tBool:
Thus (E,X , BoolG*E,g , G0G*v)true and (E,X , BoolG*E,g , G0G*v)false are
contextually equivalent closed terms of type Bool. Therefore it cannot be
the case that the first evaluates to true and the second to false (cf. Exerng
cise 7.5.10); but in that case, by definition of G0, it must be that evaluation of
G0(E,X , BoolG*E,g , G0G*v) does not terminate. 2

7.7.6 Exercise [n', 3]: By considering the possible typing derivations from the rules

in Figure 7ng1, show that there is no value v satisfying ; ` v : 8X.X. (Note
that the syntactic restriction on values of universally quantified type menng
tioned in Remark 7.4.1 plays a crucial role here.) 2

7.7.7 Remark [The role of nonngtermination]: Example 7.7.4 shows that the logng

ical relation presented here is incomplete for proving contextual equivalence
of FML values of existential type. The example makes use of the fact that, beng
cause of the presence of recursive function values, evaluation of FML terms
need not terminate. However, it seems that the source of the incompleteness
has more to do with the existence of types with no values (such as 8X.X) than
with nonngtermination. Eijiro Sumii (private communication) has suggested the

286 7 Typed Operational Reasoning

following, "terminating" version of Example 7.7.4:

P defC^ (X!Bool)!Bool
Q defC^ {9X,P}
N defC^ 8X.X
H defC^ *f:N!Bool. false
H0 defC^ *f:Bool!Bool.

(if f true then

if f false then false else true
else false) : Bool:

Consider a version of FML with only nonngrecursive function abstractions (i.e.
with *x:T.t rather than fun f(x:T) = t:T0). Evaluation is terminating in this
version. So to be nonngtrivial, contextual equivalence should be formulated in
terms of observing convergence to the same ground value in all contexts of
ground type. Making corresponding changes to the definition of the operang
tions D^-E^s and D^-E^t on termng and stackngrelations, one could develop a logical
relation for this terminating version of FML. It seems that properties (i) and (ii)
in Example 7.7.4 are also true of H and H0 in this version (the first by the same
argument we gave, but the second by a different argument that nevertheless
hinges on the observation at the end of the proof of Example 7.7.4). We leave
investigating this as an extended exercise for the reader. 2

The proof of Lemma 7.7.5 exploits "relational parametricity" properties of
polymorphic types in FML. In fact Theorem 7.6.25 tells us far more about the
properties of type abstraction values than just the extensionality property of
Theorem 7.7.1(4).

7.7.8 Theorem [Relational parametricity for 8ngtypes]: Given X ` v : T and

X ` v0 : T, then ; ` *X.v C^ctx *X.v0 : 8X.T if and only if for all closed
types T1; T01 2 Typ and all termngrelations r 2 TRelD^T1; T01E^ it is the case that
D^E,X , T1G*v; E,X , T01G*v0E^ 2 TE,r G*. 2

Proof: By Theorem 7.6.25, we have that ; ` *X.v C^ctx *X.v0 : 8X.T iff
; ` *X.v \Delta  *X.v0 : 8X.T, i.e., iff D^*X.v; *X.v0E^ 2 D^8X.TE^E,G* C^ D^*r :TE,r G*E^s t.
Since *X.v and *X.v0 are values, the latter is the case iff D^*X.v; *X.v0E^ 2
D^*r :TE,r G*E^s t v, and by Lemma 7.6.12 and Exercise 7.6.14 D^*r :TE,r G*E^s t v C^ *r :TE,r G*.
Hence ; ` *X.v C^ctx *X.v0 : 8X.T iff D^*X.v; *X.v0E^ 2 *r :TE,r G*. By definition
(Figure 7ng5), this is the case iff for all for all closed types T1; T01 2 Typ and
all termngrelations r 2 TRelD^T1; T01E^, D^(*X.v)T1; (*X.v0)T01E^ 2 TE,r G*; and the

7.7 Operational Extensionality 287
latter holds iff D^E,X , T1G*v; E,X , T01G*v0E^ 2 TE,r G*, because (*X.v)T1 C^ciu E,X ,
T1G*v and (*X.v0)T01 C^ciu E,X , T01G*v0 (so that we can use Lemmas 7.6.8 and
7.6.12). 2

The force of Theorem 7.7.1(4) is to give a method for establishing that two
type abstraction values are contextually equivalent. By contrast, the force of
Theorem 7.7.8 is to give us useful properties of families of values parameterng
ized by type variables. Given such a value, X ` v : T, since C^ctx is reflexive,
we have ; ` *X.v C^ctx *X.v : 8X.T; hence the theorem has the following
corollary.

7.7.9 Corollary: Given a value X ` v : T, for all T1; T01 2 Typ and all r 2

TRelD^T1; T01E^, it is the case that D^E,X , T1G*v; E,X , T01G*vE^ 2 TE,r G*. 2

Such "relational parametricity" properties can often be exploited for provng
ing contextual equivalences: we already saw an example in the proof of Lemng
ma 7.7.5 and other examples can be found in Pitts (2000), Bierman, Pitts, and
Russo (2000), and Johann (2002). However, the strict nature of function apng
plication and type abstraction in FML means that it does not satisfy all the
parametricity properties one might expect. For example, in Pitts (2000), $7, it
is shown that

{9X,T} Z. 8Y.(8X.T!Y)!Y
holds in the polymorphic version of PCF (Plotkin, 1977) studied in that pang
per (where Z. is "bijection up to contextual equivalence"--see Principle 7.3.4).
However this bijection does not hold in general for FML (Exercise 7.7.10).

7.7.10 Exercise [n'n'n']: Consider the type N defC^ 8X.X from Example 7.7.4 that you

showed has no closed values in Exercise 7.7.6. Show that there cannot exist
values

i 2 ValD^{9X,N}!8Y.(8X.N!Y)!YE^
j 2 ValD^(8Y.(8X.N!Y)!Y)!{9X,N}E^

that are mutually inverse, in the sense that

p:{9X,N} ` j(i p) C^ctx p : {9X,N}
y:8Y.(8X.N!Y)!Y ` i(j y) C^ctx y : 8Y.(8X.N!Y)!Y: 2

7.7.11 Exercise [n'n'n', 3]: Verify the claim made in Note 7.3.7 that Principle 7.3.4 is

a special case of Principle 7.3.6. To do so, you will first have to give a defining
tion of the action of FML types on bijections mentioned in Principle 7.3.4. 2

288 7 Typed Operational Reasoning

7.8 Notes

This chapter is a revised and expanded version of Pitts (1998) and also draws
on material from Pitts (2000).

In discussing typed operational reasoning we have focused on reasoning
about contextual equivalence of program phrases. Being by construction a
congruence, contextual equivalence permits us to use the usual forms of
equational reasoning (replacing equals by equals) when deriving equivalences
between phrases. However, its definition does not lend itself to establishng
ing the basic laws that are needed to get such reasoning going. We studied
two characterisations of contextual equivalence in order to get round this
problem: ciungequivalence (Definition 7.5.5) and a certain kind of operationally
based logical relation (Definition 7.6.10).

contextual equivalence!vs. bisimilarity The informal notion of contextual
equivalence (Definition 7.3.2) has been studied for a wide variety of prong
gramming languages. If the language's operational semantics involves nonng
determinism--usually because the language supports some form of concurng
rent or interactive computation--then contextual equivalence tends to idenng
tify too many programs and various conginductive notions of bisimilarity are
used instead (see the textbook by Sangiorgi and David, 2001, for example).
But even if we remain within the realm of languages with deterministic operng
ational semantics, one may ask to what extent the results of this chapter are
stable with respect to adding further features such as recursive datatypes,
mutable state, and objectngoriented features a` la Objective Caml.

Ciungequivalence has the advantage of being quite robust in this respect--
it can provide a characterisation of contextual equivalence in the presence
of such features (Honsell, Mason, Smith, and Talcott, 1995; Talcott, 1998).
However, its usefulness is mainly limited to establishing basic laws such as
the conversions in Corollary 7.5.8; it cannot be used directly to establish exng
tensionality properties such as those in Theorem 7.7.1 without resorting to
tedious "termination inductions" of the kind we sketched in the proof of Exng
ample 7.7.4. Ciungequivalence is quite closely related to some notions of "apng
plicative bisimilarity" that have been applied to functional and objectngbased
languages (Gordon, 1995, 1998), in that their congruence properties can both
be established using a clever technique due to Howe (1996). The advantage of
applicative bisimilarity is that it has extensionality built into its definition; so
when it does coincide with contextual equivalence, this provides a method of
establishing some extensionality properties for C^ctx (such as (1)-(4) in Theong
rem 7.7.1, but not, as far as I know, property (5) for package values).

The kind of operationally based logical relation we developed in this chapng
ter provides a very powerful analysis of contextual equivalence. We used it

7.8 Notes 289
to prove not only conversions and simple extensionality principles for FML,
but also quite subtle properties of C^ctx such as Theorems 7.7.1(5) and 7.7.8.
Similar logical relations can be used to prove some properties of MLngstyle
references and of linear types: see Pitts and Stark (1998), Bierman, Pitts, and
Russo (2000), and Pitts (2002). Unfortunately, the characteristic feature of
logical relations--that functions are related iff they map related arguments
to related results--makes it difficult to define them in the presence of "recurng
sive features." I mean by the latter programming language features which in a
denotational semantics lead one to have to solve domain equations in which
the defined domain occurs both positively (to the left of an even number
of function space constructions) and negatively (to the left of an odd numng
ber of function space constructions). Recursive datatypes involving function
types can lead to such domain equations; as does the use of references to
functions in ML. Suitable logical relations can be defined in the denotational
semantics of languages with such features using techniques such as those in
Pitts (1996), but they tell us properties of denotational equality, which is ofng
ten a poor (if safe) approximation to contextual equivalence. For this reason
people have tried to develop syntactical analogs of these denotational loging
cal relations: see Birkedal and Harper (1999). The unwinding theorem (Theong
rem 7.4.4) provides the basis for such an approach. However, it seems like a
fresh idea is needed to make further progress. Therefore I set a last exercise,
whose solution is not included.

7.8.1 Exercise [n'n'n'n'. . . , 3]: Extend FML with isorecursive types, uX.T, as in Figure

20ng1 of TAPL, Chapter 20. By finding an operationally based logical relation as
in $7.6 or otherwise, try to prove the kind of properties of contextual equivng
alence for this extended language that we developed for FML in this chapter.
(For the special case of isongrecursive types uX.T for which T contains no negng
ative occurrences of X, albeit for a nonngstrict functional language, see Johann
(2002). The generalized ideal model of recursive polymorphic in Vouillon and
Mellie`s (2004) uses the same kind of Galois connection as we used in $7.6 and
may well shed light on this exercise. Recent work by Sumii and Pierce [2005]
is also relevant.) 2

P a r t I V
Types for Programming
in the Large

8

Design Considerations for MLngStyle
Module Systems

Robert Harper and Benjamin C. Pierce

A programming language for largengscale software development must prong
vide some means of breaking large programs into parts of manageable size,
commonly known as modules. The division into modules is chosen to reng
flect natural divisions of labor within a program, minimizing redundancy and
maximizing opportunities for renguse (Parnas, 1972).

The literature on modularity is extensive, covering both methodology--
how best to decompose programs into modules with a variety of desirable
engineering characteristics--and mechanisms used to support modular prong
gramming. In this chapter, we focus on the latter, laying out a set of core
requirements and design issues and developing linguistic mechanisms for adng
dressing them. The heart of our story is the module system found in presentng
day dialects of ML, but the discussion touches on modularity features from a
range of other languages such as C, Modula, and Java.

Our presentation emphasizes type systems for modularity grounded in the
framework of TAPL. To keep the discussion focused on basic concepts and
avoid typengtheoretic technicalities, the presentation is informal. However, the
material will be easier to follow for readers with some familiarity with basic
concepts of subtyping (TAPL, Chapter 15), universal polymorphism (TAPL,
Chapter 23), existential polymorphism and abstract types (TAPL, Chapter 24),
and type operators (TAPL, Chapter 29). Some more advanced typing features
are also mentioned in passing, but prior acquaintance with these features
is not assumed; these include recursive types (TAPL, Chapters 20 and 21),
bounded quantification (TAPL, Chapters 26 and 28), dependent types (Chapng
ter 2 of this volume) and singletons (Chapter 9).

The chapter begins in $8.1 to $8.3 with a suite of basic modularity mechng
anisms: modules and signatures, namespace management, separate comping
lation, interngmodule type checking, and principal signatures. $8.4 introduces

294 8 Design Considerations for MLngStyle Module Systems

the central concept of the phase distinction and the terminology of firstng and
secondngclass module systems. $8.5 discusses abstract data types. Abstract
types arise by sealing a module with a signature that selectively suppresses
the definitions of its type components. Data abstraction raises a number of
important technical issues, including representation independence and the
avoidance problem. $8.6 extends the module language with nested hierarng
chies of modules. $8.7 discusses two alternative mechanisms for representng
ing families of signatures--explicitly parameterized signatures and the less
familiar but more flexible idea of fibered signatures, which allow any submodng
ule in a signature to be considered a posteriori as the "index" of a signature
family. $8.8 extends this discussion to families of modules defined by funcng
tors and raises the issue of coherence. We compare two approaches to the
coherence problem--sharing by construction, which is based on parameterng
ized signatures, and sharing by specification, based on fibered signatures--
and explain why the latter scales well while the former does not. We then
discuss the pragmatic motivations for module families in more depth, exng
ploring several classes of situations in which functors arise naturally. The
section closes with a discussion of generative and applicative functors. $8.9
briefly describes three more advanced topics in module system design: firstng
class modules, in which modules can be treated as ordinary values; higherng
order modules, in which functors are treated on the same footing as other
modules; and recursive modules, which permit selfngreference. $8.10 relates
the modularity concepts of this chapter to the mechanisms found in several
wellngknown languages. $8.11 closes the chapter with historical remarks and
additional suggestions for further reading.

8.1 Basic Modularity

Informally, a module (or structure) is a collection of components, which may
include procedure or function definitions, variable declarations, type defining
tions, and initialization code--specifics will vary from one language to anng
other. A program consists of a collection of bindings of module names to
modules. One module is specified as the root--the main entry point of the
program.

One module in a program may refer to another by using the latter's name in
an external reference. The occurrences of external references between modng
ules determine a dependency ordering in which the referring module depends
on the module to which it refers. (We assume for now that cyclic dependenng
cies between modules are not allowed; $8.9 discusses relaxing this restricng
tion.) The job of a linker is to compose a complete program by resolving

8.1 Basic Modularity 295
external references, creating module bindings for each of the external referng
ences in the partial program under construction until no unresolved referng
ences remain.

To support separate compilation, the dependency of one module on anng
other is mediated by a signature (or interface) that describes the externally
visible components of the latter module. A signature must be sufficiently exng
pressive as to enable clients of a module to be compiled without reference to
its implementation. This information typically includes type declarations for
procedures and variables and the definitions of type variables.

In practice, most languages support modularity through a mixture of linng
guistic and extranglinguistic mechanisms. For example, modules are often orng
ganized as files, and module naming conventions are often tied to file system
naming conventions. To avoid such complications, we concentrate on a modng
ule language that emphasizes the central concepts, relegating its realization
in specific languages and development environments to informal discussions
in $8.10.

Syntax
We employ a notation for modules and signatures that is loosely based on
ML. We consider the module language to be constructed in terms of some
underlying core language, whose details we do not care too much about. The
principal point of contact between the module and core language consists
of references to components of modules from within core language expresng
sions. To account for the type definitions in signatures, it is necessary to
enrich the definition of type equivalence to ensure that type components are
synonymous with their definitions.

The grammar given in Figure 8ng1 defines the syntax of a basic module sysng
tem that we enrich as further ideas are developed. We use the metavariables
x and y to range over term variables, s, t, and u to range over terms, X and Y
to range over type variables, S, T, and U to range over types, m and n to range
over module variables, M and N to range over module expressions, and I and
J to range over signatures and signature variables.1

A program consists of a sequence of bindings, each of which is either a
module binding or an signature binding. A module binding binds a module

1. We are departing slightly from TAPL's metavariable conventions here. In TAPL, lowercase
identifiers were used consistently for termnglevel expressions and variables, and uppercase
identifiers for typenglevel expressions and variables. Here, we are using M and N for moduleng
level expressions and m and n for modulenglevel variables. Also, we use I and J to denote both
signatures and signature variables. No confusion results from this overlap, since in any case
we regard a signature variable as just an abbreviation for its definition.

296 8 Design Considerations for MLngStyle Module Systems

P ::= programs:

B1 : : : Bn binding sequence
B ::= bindings:

module m E,: IG* = M module binding
signature J = I signature binding
M ::= modules:

m module variable
mod { CB1; : : : ; CBn } basic module
I ::= signatures:

J signature variable
sig { CD1; : : : ; CDn } basic signature
CB ::= component bindings:

type X E,> XG* = T type binding
val x E,> xG* = t value binding

CD ::= component declarations:

type X E,> XG* = T type declaration
val x E,> xG* : T value declaration
T ::= . . . types:

m.X type selection
t ::= . . . terms:

m.x value selection
\Gamma  ::= typing contexts:

; empty
\Gamma  ; D declaration
D ::= declarations:

m : I module declaration

Figure 8ng1: Basic module syntax

variable to a module expression, perhaps with a specified signature. A signang
ture binding binds a signature variable to a signature. The scope of a binding
in a program is the remainder of the program following that binding. The
final module binding is the root module.

Signature bindings are used to give names to signatures: a bound signature
variable is simply an abbreviation for the rightnghand side of its binding.

A basic module consists of a sequence of component bindings, which are
either type bindings or value bindings. A type binding is a binding of a type
variable to a type expression. A value binding binds a runngtime entity to a
term variable. These entities may include procedures, classes, objects, mutang
ble reference cells, and other structures from the core language.

Each component binding has both a label, which is underlined, and a varing
able, which is not. The variable governs references to that binding within the
module; the label governs reference from outside of the module. For this reang
son the label is sometimes called the external name of the component, and
the variable its internal name. The use of a label from outside of a module to
designate one of its components is called an external reference; the use of a
variable from inside the module to designate a preceding binding is called an
internal reference. If m is a module variable, then m.X is an external reference
to the type component of m labeled X, and m.X is an external reference to the
value component of m labeled x.

8.1 Basic Modularity 297

Internal names are bound variables whose scope is the rest of the module
in which they occur. As such, internal names may be chosen (and renamed)
arbitrarily without affecting the meaning of the module, subject only to the
usual requirement that distinct bound variables not be confused in a given
scope. In contrast the external name of a component of a module cannot be
renamed without affecting the entire program in which that module occurs.
This distinction between external and internal names is necessary for both
conceptual and technical reasons (detailed in $8.6). In most cases, however,
it is not important to emphasize the distinction, so we take the liberty of prong
viding a single name for each component binding with the understanding that
it plays a dual role as both the external and internal name of that component.

A basic signature consists of a sequence of component declarations, either
a type declaration or a value declaration. A type declaration is a labeled type
binding, with the same syntactic form as a type binding in a module. A value
declaration defines the type of a term variable, but does not give its actual
binding. As with bindings, we usually assign a single name to each declaration
with the understanding that it serves as both the internal and external name
of that component.

Examples
Here is a simple module binding:

module m = mod {

type X = Nat
val x = 5
}

The module bound to m includes one type binding and one value binding.
These components are designated, externally, by m.X and m.x. Note that these
are, respectively, corenglanguage type and value expressions: the grammar of
the core language is enriched to include external references to components
of modules.

Here is a more interesting module binding:

module n = mod {

type X = *W:*. W * W
val f = *y:X(Nat). plus y.1 y.2
}

The rightnghand side of the type binding X has kind *!* (i.e., this module is
exporting a type operator). The rightnghand side of the term binding f uses
the previously bound operator X. This illustrates the impact of the module
language on corenglanguage type checking: in order to check that the coreng

298 8 Design Considerations for MLngStyle Module Systems

language expression *y:X(Nat). plus y.1 y.2 is well typed, we need to use
the modulenglevel information that X is definitionally equal to *W:*. W * W.

The signature I introduced by the binding

signature I = sig {

type X = Nat
val x : X
}

describes the module m above, in a sense to be made precise shortly. Similarly,

signature J = sig {

type X = *W:*. W * W
val f : X(Nat) ! Nat
}

binds J to a signature corresponding to the module n.

8.2 Type Checking and Evaluation of Modules

To avoid getting bogged down in formalities, we describe type checking and
evaluation throughout the chapter in English prose rather than giving precise,
formal definitions. $8.11 offers a number of pointers into the literature for
readers interested in a more technical treatment.

Type Checking
Signatures are used to describe modules. If a signature I accurately describes
a module M, then we say that M implements I. This relation may be defined in
one of two ways. The direct method simply defines a correspondence between
a module and any signature that it may implement. An indirect method is to
associate with each module M a unique (up to suitable equivalences) principal
signature|seesignatures, which is the "most precise" (least in the subtyping
ordering) signature implemented by M. The latter method, though elegant,
applies only in languages where every module actually has a principal signg
nature. We start by defining the implementation relation directly and later
discuss conditions under which it may be reduced to subtyping.

We say that a basic module M implements a basic signature I if M contains
at least the type and value components specified by I, up to type equivang
lence. That is, each type component declared in I must be bound in M with
the same kind and an equivalent definition. (A type definition in a signature is
an equational constraint that must be satisfied by any implementation of that
signature.) Moreover, each value component declared in I must be matched
by a value binding in M with a subtype of the type specified in I. The subtypng
ing relation here is inherited from the core language, enriched to include the

8.2 Type Checking and Evaluation of Modules 299
expansion of definitions introduced by type bindings in modules and signang
tures.

When a module binding specifies a signature, the type checker ensures
that its rightnghand side implements this signature. For example, the following
bindings are wellngformed because the module bound to m implements the
signature I:

signature I = sig {

type T = Int
type U = Int * Int
val x : U
}

module m : I = mod {

type T = Int
type U = T * T
val x : T * T = (3,4)
}

Since I provides definitions for the types T and U and declares the value x,
it follows that m.T and m.U are valid type expressions (equal, respectively, to
Int and Int * Int), and m.x is a valid value expression (of type m.T * m.T,
which is equivalent to m.U).

To account for external references during type checking, each module varing
able is assigned a signature by a typing context. The assignment of a signature
to a module variable amounts to the assumption that it will be bound to a
module implementing that signature. This is enforced during linking, which
is described in more detail in $8.3.

Signature Matching
Since signatures are descriptions of modules, it is natural to consider a subng
typing relation between signatures, called signature matching and written
I<:J. A signature I may be considered to be a subngsignature of a signature
J only if any module implementing I also implements J (this is the ordinary
subsumption principle from type systems with subtyping). Said differently,
if I is a subngsignature of J, then I expresses stronger requirements on an
implementation than does J. When I<:J we say that I matches J.

There is some room for variation in how the signature matching relation is
defined, subject only to the requirement that it validate subsumption. There
are two wellngknown styles of signature matching, which we call structural and
nominal. Structural matching is based entirely on the requirements imposed
by the signature, without requiring any declarations. Nominal matching is
based on the explicit declaration of subtyping relationships among signang

300 8 Design Considerations for MLngStyle Module Systems

tures. Such declarations are often tied to a naming mechanism for modules
and signatures, which gives rise to the terminology. (This distinction exactly
mirrors the distinction between structural and nominal subtype relations disng
cussed in TAPL, $19.3.)

Structural matching affords greater flexibility, since it does not require the
programmer to explicitly specify that one signature subsumes another. Howng
ever, structural matching does not preclude unintended matching relationng
ships; this is at once a strength and a weakness. Nominal matching sacrifices
flexibility for simplicity by requiring explicit declaration of matching relationng
ships among signatures. Nominal matching precludes unintended matching
relationships, but requires that any intended ones be explicitly stated. This
rigidity can sometimes lead to significant problems in practice. For example,
in Java, it is impossible to create a new interface J that lies above an existing
class or interface I without modifying the source code of I, which may be
unavailable, for example, if I is part of a commercial library.

The definition of structural matching is guided by purely semantic considng
erations: it is the largest prengorder on signatures that validates the subsumpng
tion principle. That is, I<:J iff every module implementing I also implements
J. This is ensured by the following requirements:

1. Every type declaration in J must be matched by a corresponding type decng

laration in I. Moreover, their definitions must be equivalent, taking into
account the preceding type declarations in I.

2. Every value declaration in J must be matched by a corresponding value

declaration in I. Moreover, the type declared in I must be a subtype of
that declared in J, taking account of the preceding type bindings in I.

These conditions do not impose any ordering requirements on components
and permit the subngsignature to have components not present in the superng
signature. (In the terminology of record subtyping from TAPL, Chapter 15,
the subtype relation between signatures permits width subtyping, depth subng
typing, and permutation, with one caveat: in contrast to record subtyping,
permutation must be limited to respect the scoping of internal names for
components. For example, a value specification cannot be permuted to preng
cede a type specification on which it depends.) For example, according to this
definition the signature

signature I = sig {

type T = Int
type U = T * T
type V = Int
}

matches the signature

8.2 Type Checking and Evaluation of Modules 301

signature J = sig {

type T = Int
type U = Int * T
}.

8.2.1 Exercise [n'n'n'n']: How much of the development in the rest of the chapter

can be carried out in a nominal setting? 2

Principal Signatures
The principal signature of a module, when it exists, is the most precise signang
ture that the module implements. If a module M has a principal signature IM ,
then M implements another signature I exactly when IM matches I. Checking
whether a module implements a signature is thus reduced to checking the
subtyping relation between this signature and the module's principal signang
ture. Naturally, this reduction is possible only if every module expression has
a principal signature; otherwise there is some module expression M and a signg
nature I such that M implements I, yet there is no way to express this fact as
a subtyping relationship.

Unfortunately few module languages have principal signatures for all modng
ule expressions. One reason is that the language of signatures may be too
weak to permit a precise description of the properties of a module. For examng
ple, if subtyping for signatures is nominal, then the inferred signature for a
module is not, in general, its smallest signature in the declared subtyping hing
erarchy. A workngaround for weak signatures is to draw a distinction between
a signature expression and its internal representation in a type checker. Every
wellngformed signature has an internal representation, but some modules may
have an internal representation that is not denotable by a signature of the
language itself. This creates an unnatural separation between what a particng
ular type checking algorithm knows about a module and what a programmer
may state about it in a signature. An alternative solution is to require that
the programmer specify a signature for every module, which is then deemed
to be the smallest signature for that module, even if it is larger (i.e., weaker)
than necessary. This avoids the need for principal signatures, at the expense
of some verbosity as well as some loss of flexibility when the specified signang
ture precludes uses of the module that would otherwise be permissible.

Evaluation
Complete programs (those with no free variables) are executed by evaluating
each of the module bindings in the order given. A basic module is evaluated
by evaluating each of its component bindings in turn according to the rules of

302 8 Design Considerations for MLngStyle Module Systems

the core language, resulting in a module value. We insist on a "call by value"
binding discipline for module variables: a module variable is bound to the
value of its binding. The motivation for this requirement is explained in $8.5.

The notion of an initializer for a module arises here as a value binding
whose rightnghand side has a sidengeffect (initializing the module's internal
state) when evaluated. For example, evaluating the rightnghand side of the
binding of f in

module p = mod {

val f =

let r = ref 0 in
*x:Nat. r := plus x (!r)
}

allocates a storage cell and then returns a function whose body uses this
cell. This example also illustrates the need to distinguish between module
expressions and module values. Each time the expression mod { val f = ... }
is evaluated, a new cell is allocated and a different module value results.

8.3 Compilation and Linking

The process of evaluating a program may be decomposed into two steps:
compilation and execution. For present purposes, the most important aspect
of compilation is type checking, and the most important aspect of execution
is linking. We shall not concern ourselves with code generation or the execung
tion of compiled code. A key distinction between compilation and execution
is that the former may be performed on a modulengbyngmodule basis, provided
only that we are given the signatures of the free module variables occurng
ring in a module, whereas the latter is performed on a complete program in
which we have at hand the bindings of all of its free module variables. We
follow Cardelli (1997) in modelling linking as a process of binding modules
to module variables.

Compilation
To support code renguse and team development, it is important to compile
modules independently from one another. To compile a module, it is necesng
sary to have an assignment of a signature to each of its free module variables
(external references) provided by the typing context. There are two main
methods of obtaining this context: separate and incremental compilation.2

2. We caution the reader that this terminology is not standard; these and related phrases are
used with a variety of loosely related meanings in the literature.

8.3 Compilation and Linking 303
The difference is whether the signatures of free module variables are explicng
itly given by the programmer (separate compilation) or are inferred by the
compiler from the source code of the referenced module (incremental comping
lation). Both separate and incremental compilation may be supported in the
same language. Furthermore, both mechanisms are compatible with cutngoff
compilation (Adams, Tichy, and Weinert, 1994): if the source code of a modng
ule has changed, but its signature has not, then there is no need to recompile
modules that depend on it--recompilation may be "cut off" at that point.

In a separate compilation system, the programmer states signature asng
sumptions for each of the external references in a module. This is typically
achieved by "import" declarations that state such assumptions. The module
is compiled relative to these assumptions, independently of whether the imng
plementation of the externally referenced modules is available. This affords
maximal flexibility in the order of development of the modules in a program
and permits renguse of libraries of previously compiled modules whose source
may not be available at all. Separate compilation places a burden on the
linker to ensure that the binding of a module variable implements the preng
sumed signature. A subtle point is that two different modules may import
the same module, but with a different assumed signature. The linker must
ensure that each such assumption is satisfied to ensure safety, or else insist
that all imports specify equivalent signatures. Since most conventional linkng
ers are incapable of verifying typing constraints, it is usually necessary to
devise languagengspecific linkers or to introduce postnglinking checks (similar
to Java bytecode verification) to ensure type safety.

In an incremental compilation system, it is not necessary to specify the
signatures of externally referenced modules. Instead, the compiler consults
the implementation of a module to determine its signature, which is used for
compiling any module that depends on it. This implies that the implementang
tion of any externally referenced module must be present in order to compile
the referring module. This impedes independent development, but avoids the
need to ensure that the binding of a module implements the presumed signg
nature, since it does so by explicit construction. A module system that lacks
principal signatures cannot properly support incremental compilation.

Linking
A linker assembles a complete program from a collection of module bindng
ings, called the linking context.3 This is achieved by tracing the external

3. We are talking here about conventional static linking. Languages that support dynamic linkng
ing permit name resolution during execution.

304 8 Design Considerations for MLngStyle Module Systems

references occurring in the collection of program fragments (starting with
a specified root module), and building a sequence of module bindings that
is consistent with the occurrences of these references. Whenever an external
reference is encountered, its binding is determined by consulting the linkng
ing context, and emitted as part of the resulting fully linked program. The
external reference is thereby said to be resolved. The occurrence of external
references constrains the order of the bindings in the fully linked program,
but it does not completely determine it. Further constraints on the order of
bindings are imposed by initialization code whose side effects constitute an
implicit dependency of one module on another.

This motivates the definition of a dependency relation among a set of modng
ules, consisting of its reference dependencies together with its initialization
dependencies. Reference dependencies are determined by inspection of the
code of a module. If a module N contains an external reference m to a module
M, then N is said to contain a reference dependency on M. Signatures may also
contain reference dependencies on modules, for if a signature I contains a
reference m to a module M, then I depends on M and hence m must be bound
before I can be used. (At this point such dependencies are inessential, beng
cause they can only arise in type selections of the form m.X, which may be
replaced by their definitions. However, once abstract types are introduced in

$8.5, such references are not in general eliminable in this way.) Initialization
dependencies arise when the evaluation of one module is materially affected
by the evaluation of another, even though no reference dependency need exng
ist between them. Initialization dependencies cannot always be determined
by inspection; for example, one module may read a file that another writes
without either sharing a common reference. Therefore, initialization depenng
dencies must be explicitly specified (by some means not detailed here) to
ensure that they are respected by the linker.

Ordinarily, the dependency relation among a collection of modules is reng
quired to be acyclic, precluding circular dependencies of a module on itself
(whether via intermediate modules or not). This is enough to ensure that it
is always possible to find a linear ordering of modules consistent with the
dependency relation. It is possible to permit circular dependencies, at the
expense of considerable complications in the general case; see $8.9.

It is worth noticing that, in the simple setting we are describing at the mong
ment, all the external references to a given module m, everywhere in a given
set of modules, are guaranteed to be resolved to the same module value at
link time--that is, external references are definite. These definite references
are to be contrasted with the indefinite references that arise with parameterng
ized modules and signatures (see $8.8). Indefinite references raise difficulties
related to aliasing, called coherence problems.

8.4 Phase Distinction 305
8.4 Phase Distinction

Most modern programming languages are statically typed, meaning that type
checking may be performed prior to, and independently of, execution. Statng
ically typed languages maintain a clear separation between the static (type
checking) and dynamic (execution) phases of processing, and are therefore
said to respect the phase distinction.4 This can be made precise by considerng
ing the forms of reasoning required during type checking to test type equivang
lence. If type checking may be performed without testing equivalence of runng
time expressions, then the phase distinction is respected, and the language is
said to be statically typed. If, however, type checking requires testing equivang
lence of runngtime expressions (sometimes called "symbolic execution"), then
the phase distinction is violated, and the language is said to be dependently
typed.5 Examples of dependently typed programming languages include Rusng
sell (Donahue and Demers, 1985), Pebble (Burstall and Lampson, 1984), and
Cayenne (Augustsson, 1998). See Chapter 2 for further information on depenng
dently typed languages.

Since modules contain bindings for types, testing type equivalence involves
reasoning about the identity of the type components of modules. But since
modules also contain bindings for values, we are at risk of violating the phase
distinction. For example, a type expression of the form m.X appears superng
ficially to be dependent on the entire module m, including its dynamic comng
ponents. Consequently, checking equality of m.X with another type threatng
ens to require comparison of modules for equality, in violation of the phase
distinction. We take it as a fundamental design principle that a module sysng
tem should preserve the phase distinction in the sense that a module system
should be statically typed if the underlying core language is. The type theory
of modularity developed in this chapter is carefully designed to ensure that
the phase distinction is preserved.

The phase distinction is related to the distinction between firstng and secondng
class modules. Informally, a firstngclass module expression is one whose type

4. This terminology was introduced by Cardelli (1988a) in an attempt to relate phases to a
universe distinction in type theory. The present formulation is derived from Harper, Mitchell,
and Moggi's definition (1990).
5. The natural contrasting phrase is "dynamically typed," but this conflicts with the term's
established usage to refer to languages (such as Java or Scheme) with runngtime dispatch on
tagged data. Our use of the phase "dependently typed" stresses the core semantic issue, rather
than focusing on purely syntactic features such as the occurrence of terms in types. The modng
ule language of this chapter will exhibit superficial syntactic dependencies that do not, in fact,
amount to semantic dependencies in the sense used here. Technically this is achieved by reng
stricting type selection to separable modules--those with a fully transparent interface; see
Dreyer, Crary, and Harper (2003) for further details.

306 8 Design Considerations for MLngStyle Module Systems

components are not determined until runngtime; otherwise it is secondngclass.
The essential difference between a firstng and a secondngclass module expresng
sion is whether or not its type components are determined statically (during
type checking) or dynamically (during execution). A roughngandngready criterion
for a module expression to be firstngclass is that the bindings of its type comng
ponents depend on the outcome of a runngtime test. If so, then the identity of
its type components cannot be determined statically, rendering the module
firstngclass; if not, it is secondngclass. (Consequently, a module expression with
no type components is vacuously secondngclass, even though its evaluation
may involve arbitrary runngtime computation.)

All basic module expressions, including module values, are secondngclass
because they explicitly specify their type components. For example, the folng
lowing module expression is secondngclass:

mod {

type X = Nat
val f = *x:X. x
type Y = Bool
}

On the other hand, consider the following module expression, M
if ...moon is full... then m1 else m2
where m1 and m2 are bound by the following declarations:

module m1 = mod {

type X = Int
type Y = X!X
val x = 3
val f = succ
}
module m2 = mod {

type X = Bool
type Y = X!X
val x = false
val f = not
}

The expression M is chosen so that the definitions of its type components X
and Y are dependent on a runngtime test whose outcome cannot be predicted
at typechecking time. Consequently, it is firstngclass.

If, instead, m2 were defined as follows, then the bindings of X and Y would
not be dependent on a runngtime condition:

8.5 Abstract Type Components 307

module m2 = mod {

type X = Bool
type Y = Bool!Bool
val x = true
val f = not
}

In this case M is secondngclass, despite its syntactic form. The distinction beng
tween firstng and secondngclass module is a matter of evaluation behavior.

Up to this point, the type system for modules we have developed so far is
too weak to permit any firstngclass module expressions to be wellngtyped. For
example, the conditional M given above does not implement any signature
in the language of signatures developed thus far, for the simple reason that
signatures must reveal the definitions of their type components. To assign a
signature to M it is necessary to suppress the identity of its type component,
X. To do so, we require a richer language of signatures.

8.5 Abstract Type Components

So far in our development signatures are transparent--a signature I for a
module M must reveal the definitions of the type components of M. As we
have just mentioned, a firstngclass module expression cannot implement a
transparent signature. Worse, limiting ourselves to transparent signatures imng
pedes modular programming by creating tight dependencies of one module
on another. A transparent signature for a module M must expose the repreng
sentations of its type components, and modules that makes use of M may be
sensitive to that choice. Consequently, any change to M has a knockngon effect
on all modules that make use of it. In many cases such a close coupling is
unnecessary, and therefore undesirable.

The solution to both of these shortcomings is to permit not only concrete
(or transparent) type declarations in signatures, as we have until now, but
also abstract (or opaque) type declaration revealing the existence, but not the
definition, of a type component. An abstract type declaration is said to "hold
its type abstract," or to "hide its representation." Signatures in which type
declarations may be either concrete and abstract are said to be translucent,
because they partially reveal their type components. Transparent signatures,
which reveal all of their type components, and opaque signatures, which hold
all of their type components abstract, are two important limiting cases.

Signatures with abstract type declarations are similar to existential types
(see Mitchell and Plotkin (1988) and TAPL, Chapter 24). Just as with existenng
tial types, translucent signatures permit changing the type definitions within

308 8 Design Considerations for MLngStyle Module Systems

CD ::= component declarations:

type X E,> XG* opaque type
type X E,> XG* = T transparent type

Figure 8ng2: Translucent signature syntax

a module without fear of disrupting the type correctness of any module that
makes use of it. In short, translucency supports representation independence
in much the same manner as do existential types. However, the relationship
to existentials is more analogical than technically accurate. In particular, exng
istentials do not support dot notation for existential types (i.e., given an exisng
tential package p with an abstract type component X, one cannot just refer
to p.X; instead, p must first be "opened" in some particular lexical scope),
and so do not offer a fully satisfactory foundation for module systems. In
particular, dot notation is required to give adequately expressive types for
hierarchical and parameterized modules, as explained in $8.6 and $8.8. This
point is discussed in detail by Cardelli and Leroy (1990) and Lillibridge (1997).

The passage to translucent signatures has surprisingly farngreaching conng
sequences. Most immediately, translucent signatures support a flexible form
of data abstraction and permit formation of firstngclass module expressions.
Translucent types are crucial for permitting finenggrained control over the
propagation of type definitions in hierarchical and parameterized modules
while maintaining static typing. Less obviously, they make possible a number
of significant enrichments of the module language with a minimum of adding
tional machinery. In particular, translucent signatures provide typengindexed
families of signatures "for free" and support a direct and natural way of enng
suring type compatibility among the arguments of a parameterized module.
(See $8.7, $8.6 and $8.8 for further discussion of these points.) It is remarkng
able that a single mechanism, translucent signatures, not only affords flexng
ible type abstraction, but also provides all of the supporting apparatus reng
quired for several important extensions to the basic formalism. As might be
expected, this increase in expressiveness goes handnginnghand with some signifng
icant metangtheoretic challenges. Thus, in terms of both power and cost, the
extension to translucent signatures is the most significant step in the chapter.

Translucent Signatures
To support translucency we extend the syntax of our language to permit two
forms of type declaration--one that reveals the definition, and one that supng

8.5 Abstract Type Components 309
presses it, as detailed in Figure 8ng2. For example, the signature

signature I = sig {

type X
type Y = X!Nat
val c : X
val f : Y
}

specifies the existence of type components named X and Y, revealing the defng
inition of Y, but hiding the definition of X.

The signature matching relation is generalized to permit "forgetting" of
type definitions: an abstract type declaration type X in a superngsignature may
be matched by either an abstract or a concrete type declaration in the subng
signature. For example, the signature

signature J = sig {

type X = Nat
type Y = X!Nat
val c : X
val f : Y
}

matches the signature I.

As we noted on page 300, the definitions of type components of a signang
ture are propagated forward when checking whether one signature matches
another. So, for example, the signature

signature K = sig {

type X = Nat
type Y = X!Nat
val c : Nat
val f : Nat!X
}

matches the signature J, and so, perhaps surprisingly, it also matches the
signature I.

8.5.1 Exercise [n', 3]: Check in detail that K matches J and I. 2

A module implements a translucent signature if it provides the type comng
ponents specified in the signature with, where given, bindings equivalent to
the specified definitions. During type checking, the definitions of type comng
ponents of a module are again propagated forward while checking the reng
mainder of the components against the specified signature. For example, the
module M declared by the binding

310 8 Design Considerations for MLngStyle Module Systems

module m =

mod {

type X = Nat
type Y = X!Nat
val c = 5
val f = *x:X. succ x
}

implements the translucent signature I given above.
8.5.2 Exercise [n', 3]: Check in detail that M implements I. 2

Sealing
To limit the visibility of the type components of a module M to the degree
specified in the signature I, it is necessary to seal M with I, written M:>I. (Note
the similarity to the termnglevel ascription operator described in TAPL, Chapter
11.) A sealed module expression M:>I is wellngformed only if M implements I;
the sealed module is considered to implement I (and, by subsumption, the
supertypes of I). A sealed module is evaluated by stripping off the seal and
evaluating the underlying module. This reflects the informal idea that data
abstraction is relevant only during type checking and has no significance at
run time.

For example, consider the signature, I, given in the preceding subsection,
and the following module expression, M:

mod {

type X = Nat
type Y = X!Nat
val c = 5
val f = *x:X. succ x
}

It is easy to check that M implements I, so that M:>I is a wellngformed module
expression with signature I. Since X is held abstract by I, no use of the sealed
module may rely on its identity.

A "decorated" module binding of the form module m : I = M may be seen as
syntactic sugar for the "bare" binding module m = (M:>I)--that is, the modng
ule M is implicitly sealed with signature I by the binding. For example, if M
and I are as in the preceding example, then the module binding

module m = M:>I
assigns to m the signature I. Since I holds X abstract, m.X is opaque, whereas
m.Y is equivalent to m.X!Int.

8.5 Abstract Type Components 311
M; N ::= . . . modules:

M ! I sealing

T; U ::= . . . type:

M .X type selection
t; u ::= . . . term:

M .x value selection

Figure 8ng3: Mechanisms for abstraction

The formalization of abstract types considered here differs from convenng
tional existential types (as described in TAPL, Chapter 24) by separating the
imposition of abstraction on a module from any means of binding that modng
ule or its components to variables. In the existential framework abstraction
is imposed through a binding construct that holds the representation type
of the abstract type abstract within a specified scope, which is a single core
language expression. For this reason existential types are sometimes said to
impose a closed scope abstraction discipline. However, in the presence of
translucent sums, it is also necessary to make direct reference to abstract
types within types, as well as terms. Achieving this using existential types reng
quires that the abstract type binding be "extruded" to encompass essentially
the region of a program in which it is used. In practice this means that the
lowestnglevel, and most widely used, abstract types must be given the largest
scope, thereby everting the natural structure of the program. In contrast the
present framework is based on an open scope mechanism in which abstracng
tion is imposed without specifying the scope in which it may be used. This
avoids the complex rengstructuring required in the pure existential framework,
and, moreover, scales naturally to support later extensions to the language.
To support openngscope abstraction we extend the grammar of module expresng
sions to permit sealing, remove signatures from module bindings, and permit
type and value selection from an arbitrary module expression. (See Figure 8ng3
for the revised grammar.)

One consequence of sealing modules with abstract type components is that
signatures may now contain unavoidable dependencies on modules. For exng
ample, consider the following bindings:

signature I = sig {

type X
val c : X
val f : X!X
}

312 8 Design Considerations for MLngStyle Module Systems

module m : I = mod {

type X = Int
val c = 0
val f = succ
}
signature J = sig {

type Y
val d : m.X
}
module n : J = mod {

type Y = m.X
val d = m.f(m.f(m.c))
}.

Since J contains a reference to m.X, which is opaque, the signature J is only
sensible within the scope of the binding for m. The meaning of the signature
J is tied to the binding of the module variable m. In particular, any module
implementing J must define Y to be equivalent to m.X.

Determinacy and Abstraction
Any adequate abstraction mechanism must ensure representation indepenng
dence, which ensures that the behavior of clients are insulated from the deng
tails of the implementation of an abstraction. We will not attempt to give a
precise definition of independence here (but see work by Reynolds (1974) and
Mitchell (1986)). At a minimum, though, it should ensure that if the modules M
and N implement the interface I, then replacing M:>I by N:>I should not disng
turb the type correctness of a program. In particular, if the type X is abstract
in I, then the definition of X must not "leak" from M:>I so as to affect the
type correctness of client code. For if it did, then we could choose N to conng
flict with M on the definition of X and violate even this minimum requirement
for abstraction.

This suggests that representation independence is closely tied up with type
equivalence--when is one abstract type equivalent to another? In particular,
when is (M:>I).X equivalent to (N:>I).X? To ensure that type equality is
reflexive (as surely it ought to be), we must ensure that this equivalence hold
whenever M and N are equivalent. But module equivalence is, in general, undeng
cidable and, moreover, conflicts with the phase distinction, both undesirable.
To avoid this, we simply prohibit type selection from sealed modules so that
embarrassing questions such as these never arise.

Another strong reason to limit type selection is to ensure type safety in
the presence of firstngclass modules. Since type expressions may be compared

8.5 Abstract Type Components 313
for equality with other types during type checking, it is important to ensure
that every type expression stand for a fixed type at compile time. Surprisingly,
firstngclass modules violate this seemingly innocent requirement. For example,
if M is the conditional module expression

if ... moonngisngfull ...

then mod { type X = Int }
else mod { type X = Bool }

then M.X might turn out to be either Int or Bool, but we cannot tell which at
compile time. Consequently, it makes no sense to compare M.X for equality
with another type. The following exercise shows that permitting such type
expressions is, in fact, unsound.

8.5.3 Exercise [n'n'n']: Devise an expression t involving unrestricted selection from

the firstngclass module expression M that incurs a type error at run time. 2

Now a firstngclass module expression such as this can only be wellngformed
if we seal it with an interface that hides the identity of the type compong
nent X. This establishes a close connection between firstngclass modules and
sealing that provides further support for the prohibition of type selection
from sealed modules. More generally, since a sealed module may, in fact, be
firstngclass, its abstract type components may or may not be statically wellng
determined. Consequently, we must "assume the worst" of it, and prohibit
type selection.

At the present stage of development, only sealing poses any problems for
type selection, but, as we enrich the language, further constructs (such as apng
plication of a generative functor) raise similar concerns. It is therefore useful
to isolate a subset of module expressions, the determinate ones, whose type
components are statically known and can be selected without fear of violating
safety or representation independence. The remaining module expressions
are said to be indeterminate; they do not permit type selection.

Basic module expressions, including module values, are determinate beng
cause they provide explicit definitions for their type components. For examng
ple, the module expression (call it M)

mod {

type X = Bool
type Y = X!X
val x = false
val f = not
}

is determinate because we can see immediately that M.X is equivalent to Bool
and M.Y is equivalent to Bool!Bool.

314 8 Design Considerations for MLngStyle Module Systems

By forcing evaluation of its rightnghand side, a module binding resolves any
indeterminacy before the module variable is bound to the resulting value.
Consequently, module variables are also determinate. For example, consider
the following module binding:

module m = if ... moonngisngfull ...

then mod { type X = Int }
else mod { type X = Bool }

Even though the conditional is indeterminate, the variable m is determinate. In
fact, the only way (so far) to make use of an indeterminate module expression
is to bind it to a variable and refer to that variable to access its components.

This sheds light on the informal idea that abstract types are "new" in the
sense of being distinct from all other types in a program, regardless of any
coincidences of representation. By ffngconversion the name of a bound variable
is automatically changed so as to avoid clashes with any other module varing
able in scope at that point in the program, thereby ensuring that its abstract
type components are "new."

8.5.4 Exercise [n']: What would go wrong if we changed the evaluation of module

bindings to callngbyngname? 2

For the time being, module values and variables are the only determinate
module expressions. Sealed modules are indeterminate, for the reasons outng
lined above.

8.5.5 Exercise [n']: Show that if sealed modules were determinate, then represenng

tation independence could be violated. That is, find a wellngtyped term t whose
type correctness is destroyed by replacing one implementation of an abstract
type with another. 2

8.5.6 Exercise [n']: Why would it be bad for two copies of M:>I to induce interng

changeable abstract type components? 2

This same observation also accounts for the informal idea that data abng
straction ties a type to a particular set of operations that interpret it: any
nonngtrivial computation with a value of that type must be through these opng
erations. This greatly facilitates maintaining a representation invariant on the
data structure, since those, and only those, operations may potentially violate
it. Moreover, by insisting that sealed modules are indeterminate, we ensure
that the operations from two different abstract types are not interchangeable,
even if the underlying representations of values of those types are the same.

8.5 Abstract Type Components 315
8.5.7 Exercise [Recommended, n'n']: Devise an example of two implementations

of an abstract signature that share a common representation type but differ
in the operations used to interpret it. Assuming that these two implementang
tions give rise to the same (but hidden) abstract type, give a program (using
sealing as a determinate construct) that incurs an error that would otherwise
be avoided. 2

An important special case of this arises when the implementation of an
abstraction involves private state. In that case two instances of the abstract
type must be kept distinct, even though both the representation type and
the code of the associated operations are identical! The following exercise
explores one example of what can go wrong.

8.5.8 Exercise [Recommended, n'n']: Devise an implementation of a hash table inng

volving state, and show that, if two instances of the hash table were to deterng
mine equivalent abstract types, then errors could arise that would otherwise
be avoided. 2

The Avoidance Problem
Consider a local module binding construct of the form

let module m = M in M'.
This expression implements the signature I0 provided that (1) M implements
some signature I, and (2) M0 implements some signature I0 under the assumpng
tion that m implements I.

At first glance, it would seem reasonable to say that the principal signature
for a let expression would simply be the principal signature (I0) of its body.
But what if the principal signature of the body involves an abstract type comng
ponent from M? For example, consider the following the module expression:

let

module m = M :> I
in

mod { val z = m.y }

where I is the signature

sig {

type X
val y : X
}.

316 8 Design Considerations for MLngStyle Module Systems

Clearly, the principal signature of the body of the let is sig { val z : m.X }.
But this signature cannot be the type of N, because it involves an essential
reference to the locally bound module variable m. (An analogous observation
for the unpack form for existential types motivates the scoping restrictions
discussed in TAPL, $28.7.)

It is tempting to consider N to be illngformed, since it attempts to export
the type m.X outside of its scope. But this neglects the possibility that N has
some signature that does not involve m.X. For example, if the core language
subtype relation has a maximal type Top, then another possible signature for
the body of the let is sig { val z : Top }. Indeed, this may even be the prinng
cipal signature for N. In general, the principal signature of a let expression
of the form let module m = M in M0 is the least signature for M0 that does not
involve the bound module variable m.

The problem of finding such a signature is called the avoidance problem.
First reported by Ghelli and Pierce (1992) in the context of System F<=, the
avoidance problem is a central design issue for module systems that support
data abstraction. Unfortunately, it does not appear to admit a completely satng
isfactory solution. In some languages (including ML), there exists a signature
I involving a module variable m with more than one minimal superngsignature
avoiding m, none of which is least. In such cases the occurrence of m cannot
be avoided without losing valuable type information.

8.5.9 Exercise [n'n'n']: Consider a signature I

sig {

type X = *W:*. m.Z
type Y = m.Z
}

containing a free module variable m whose signature has an abstract type
component Z. Show that I has infinitely many superngsignatures that avoid m,
but none that is a subngsignature of all the others Assume, for this exercise,
that the core language is just F !, with no subtyping between corenglanguage
types. (For substantial extra credit, find a similar example where the core
language is full F<=.) 2

What to do? A fallback position is to admit as well formed those let exng
pressions for which there is a principal signature avoiding the bound modng
ule variable, and to reject all others. The trouble is that there is no simple
characterization of which modules admit principal signatures and which do
not. Reliance on a particular algorithm for detecting cases for which a prinng
cipal signature exists ruins the declarative nature of the type system. An alng

8.6 Module Hierarchies 317
CB ::= . . . component bindings:

module m E,> mG* = M module binding
CD ::= . . . component declarations:

module m E,> mG* : I module declaration

M ::= . . . modules:

M.m module selection

Figure 8ng4: Mechanisms for hierarchy

ternative is to require the programmer to specify the signatures of all let
expressions. Rather than solving the problem, this approach simply shifts
the burden to the programmer. Another possibility is to prohibit leaving the
scope of a module variable whose signature has an abstract type component.
This means that all abstract types must be global, rather than local. To soften
the blow we may rename locally declared abstract types with special names
that indicate that they are "hidden," relying on a programming convention
to avoid using types with such names. Such a convention may be systemating
cally imposed by "name mangling" during elaboration of the source language
program into internal form. Using this approach, hiding abstract types can
be handled in much the same manner as type inference, pattern compilation,
and overloading resolution (Dreyer, Crary, and Harper, 2003).

8.6 Module Hierarchies

To avoid name clashes, it is useful to organize a collection of module bindings
into "clusters" of closely related bindings with more limited crossngcluster deng
pendencies. This may be achieved by permitting module bindings to occur as
components of other modules (with the usual distinction between its internal
and external names). Correspondingly, we introduce a new form of module
expression, the selection of a module component from another module. The
additional syntax to support module hierarchies is given in Figure 8ng4.

A module that is bound within another is called a submodule of the surng
rounding module. Most of the properties and relations associated with modng
ules are extended recursively to subngmodules. For example, if all of the subng
modules of a module are determinate, then so is the module itself. Equivng
alently, if any subngmodule is indeterminate (in particular, if it is sealed),
then the module itself is indeterminate. The implementation relation between
modules and signatures is extended recursively to submodules so that the
module

318 8 Design Considerations for MLngStyle Module Systems

module q = mod {

module m = mod {

val x = 5
val y = 6
}
module n = mod {

val z = 7
}
}

implements this signature:

signature Q = sig {

module m : sig { val x:Nat val y:Nat }
module n : sig { val z:Nat }
}

The signature matching relation is extended covariantly to submodules. For
example, the signature Q above matches the signature

signature Q' = sig {

module m : sig { val y:Nat }
}

(among others).

Besides simple namespace management, hierarchical modularity is also
useful in representing compound abstractions. A familiar example is the dicng
tionary abstraction, which builds on the concept of a linearly ordered type
of keys. The layering of dictionaries atop keys is naturally expressed using a
module hierarchy.

signature Ordered = sig {

type X
val leq : X * X ! Bool
}

signature Dict = sig {

module key : Ordered
type Dict : *!*
val new : 8V. Dict V
val add : 8V. Dict V ! key.X ! V ! Dict V
val member : 8V. Dict V ! key.X ! Bool
val lookup : 8V. Dict V ! key.X ! V
}

The Ordered signature specifies a type equipped with a binary operation that
is intended to be a total ordering of that type. The Dict signature specifies a
subngmodule key implementing an ordered type.

8.6 Module Hierarchies 319

The types of the operations declared in the signature Dict make reference
to the type key.X, the type of keys. This illustrates the dependence of the
"rest" of a signature on (the type components of) a preceding subngmodule
declaration. Strictly speaking, the type selections key.X occurring within the
signature Dict refer to the internal name of the subngmodule key, whereas any
selections from a module implementing Dict refer to the external name, or
label, of that subngmodule. To distinguish these two aspects of the subngmodule
declaration we may write the Dict signature as follows:

signature Dict = sig {

module key > k : Ordered
type Dict : *!*
val new : 8V. Dict V
val add : 8V. Dict V ! k.X ! V ! Dict V
val member : 8V. Dict V ! k.X ! Bool
val lookup : 8V. Dict V ! k.X ! V
}

In most cases it is not necessary to make explicit the distinction between the
internal and external name of a subngmodule, and we rarely do. However, there
are situations in which the distinction is critical, as in the following example.
Consider the following module expression (call it M):

mod {

type X = Int
module m = mod {

type X = Bool
val f = *a:X. 3
}
}

We wish to assign a signature to M that specifies M.m.f to be a function of
type M.m.X!M.X. Without distinguishing internal from external names, there
is no way to write such a signature while holding M.m.X and M.X abstract. The
only possible attempt

sig {

type X
module m : sig { type X val f : X ! X }
},

fails because of shadowing of the outer declaration of X by the inner one.
However, by distinguishing the internal from the external name, we may write
the desired signature as follows:

320 8 Design Considerations for MLngStyle Module Systems

sig {

type X > X'
module m : sig { type X > X" val f : X" ! X' }
}.

Since the internal name is a bound variable, it may be renamed at will, thereby
avoiding problems of shadowing.

Returning to the Dict signature, the declaration of the subngmodule key
indicates that any module implementing Dict comes equipped with its own
ordered type of keys. At first glance this may seem unnatural, since we do
not ordinarily expect a dictionary abstraction to provide an ordered type of
keys, but rather to require one. The distinction is largely a matter of perspecng
tive. Even though the key subngmodule is a component of an implementation
of Dict, it would ordinarily be obtained "off the shelf" by reference to anng
other module such as the type of integers ordered by magnitude, or the type
of strings ordered lexicographically. However, nothing precludes defining the
key module "in place," for example in the case that there is precisely one dicng
tionary in use in an entire program. Conversely, we would ordinarily expect
the type constructor Dict to be constructed as part of the implementation of
Dict, but this need not be the case. We might, in fact, copy this type from anng
other module, say a generic implementation of balanced binary search trees.
Or we may choose to construct a suitable data structure "on the spot." Thus,
the components of a module may sometimes play the role of an "argument"
to that module, yet at other times play the role of a "result." This flexibilng
ity is of particular importance when considering families of signatures and
modules, to which we now turn.

8.7 Signature Families

To support code renguse, it is important to isolate repeated patterns in both
modules and signatures so that we may consolidate what is common to many
instances, allowing only the essential differences to vary. This is achieved by
introducing families of signatures and modules that isolate the pattern and
that may be specialized to recover a specific instance of the pattern. In this
section we consider families of signatures; families of modules are discussed
in $8.8.

A good example of the need for signature families is provided by the Dict
abstraction in the preceding section. An implementation of the Dict signang
ture for an ordered type of keys takes the following form:

8.7 Signature Families 321

module dict1 = mod {

module key = key1
type Dict = *X:* . ...
...
}

Here key1 is some module implementing the signature Ordered. The princing
pal signature for dict1 specifies the type of keys:

signature Dict1 = sig {

module key : sig {

type X = key1.X
val leq : X * X ! Bool
}
type Dict : *!*
...
}

We may seal the module dict1 with the signature Dict1 to ensure that the
type constructor Dict is held abstract. Note that it would not make sense to
seal dict1 with the signature Dict.

8.7.1 Exercise [n']: Why? 2

Now suppose that we wish to implement a second dictionary whose keys
are drawn from the module key2. As matters stand, we have no choice but to
replicate the same text, replacing key1 by key2 wherever it occurs.

signature Dict2 = sig {

module key : sig {

type X = key2.X
val leq : X * X ! Bool
}
type Dict : *!*
...
}

module dict2 :> Dict2 = mod {

module key = key2
type Dict : *!* = ...
...
}

Doing this makes the code unnecessarily difficult to modify--any change to
the signature Dict must be replicated for dict1 and dict2.

322 8 Design Considerations for MLngStyle Module Systems

Clearly, what is needed is some means of isolating the common pattern as
a family of modules implementing a corresponding family of signatures, both
indexed by the type of keys. That way we may obtain each dictionary signang
ture and module as an instance of the family for the corresponding ordered
type of keys. We turn first to the representation of families of signatures;
families of modules are considered in the next section.

Representing Families
There are two main ways of representing families, parameterization and fing
bration.6 Using parameterization, we explicitly abstract the type of keys from
the Dict signature using a form of *ngabstraction.

signature DictP = *Y:*.

sig {

module key : sig {

type X = Y
val leq : X * X ! Bool
}
type Dict : *!*
...
}

Instances are obtained by application, writing

signature Dict1 = DictP(key1.X)
signature Dict2 = DictP(key2.X)

to obtain the signatures Dict1 and Dict2 that we wrote out explicitly above.

Using fibration, on the other hand, we simply specify the type of keys by
"patching" the generic Dict signature using a "where clause" as follows:

signature Dict1 = Dict where key.X = key1.X
signature Dict2 = Dict where key.X = key2.X

As with parameterization, the result of these declarations is the same as the
explicit definitions of Dict1 and Dict2 given earlier. Observe that Dict1 and
Dict2 both match Dict.7

6. This terminology is borrowed from category theory, which considers two methods for repng
resenting families of categories F indexed by a category I. An indexed category is a functor
IndF : Iop ! Cat mapping I into the "category of categories"--roughly, a function from I to
categories. A fibration is a functor (satisfying some conditions) FibF : F ! I assigning to each
family in F its index in I. Our use of this terminology is analogical, not technically precise.
7. These where clauses can be thought of as a form of "signature inheritance," analogous to
the "code inheritance" found in objectngoriented languages. The fact that where clauses give
rise to subtypes is a natural corollary.

8.7 Signature Families 323

In both representations, the family of signatures is indexed by a type. While
theoretically sufficient, it is pragmatically unfortunate that, in both repreng
sentations, the indexing type is separated from its interpretation in terms
of operations. For example, since a type can be ordered in several differng
ent ways--for example, strings might be ordered lexicographically or by the
prefix ordering--it is preferable to maintain the association of a type with
its ordering operation. This may be achieved by generalizing typengindexed
families to modulengindexed families. In the present case this would amount
to parameterization or fibration over a module implementing the signature
Ordered. In parameterized form this would be written

signature DictP' = *key : Ordered.

sig {

module key = key
type Dict = ...
...
}

with instances

signature Dict1 = DictP'(key1)
signature Dict2 = DictP'(key2).

In fibered form we would write

signature Dict1 = Dict where key = key1
signature Dict2 = Dict where key = key2.

In either case, instantiation of a signature family by a module may be viewed
as a convenient form of type indexing, since it is only the type components
of the instantiating module that affect the result. This is particularly useful
in situations where the indexing module contains several type components,
possibly nested within subngmodules.

8.7.2 Exercise [n'n'n']: Give a formal definition of the operation I where m = M, makng

ing explicit any restrictions that must be made for this operation to be sensing
ble. 2

Parameterization vs. Fibration
The chief advantage of parameterization over fibration is familiarity. It is
natural (especially for functional programmers) to consider a family of signg
natures indexed over implementations of a signature I as a "function" mapng
ping implementations of I to signatures. Representing signature families by

324 8 Design Considerations for MLngStyle Module Systems

parameterization requires a modest enrichment of the syntax to permit *ng
abstractions and applications of signatures, an extension of signature equivng
alence to account for instantiation by substitution, and an extension of the
type system to classify parameterized signatures as a kind of function. Fiberng
ing, on the other hand, avoids the need for a new form of signature family by
exploiting submodule declarations, which are useful for other reasons.

A more important difference is that the parameterized approach requires
the programmer to anticipate the patterns of abstraction and instantiation
that may arise in any future use of a given signature. When several (type
or module) components are involved, it can be difficult to anticipate which
are to be thought of as parameters and which are to be thought of as conng
structed components of the module. Indeed, the context may dictate one
choice in one situation, and another in another. The fibered approach avoids
the need to anticipate the future, because it affords a kind of "after the fact"
parameterization--any module or abstract type component may be considng
ered to be the "argument" in a given situation without prior arrangement.

Taken in isolation, one may argue the advantages and disadvantages of eing
ther representation as compared to the other, with neither coming out a clear
winner. However, when examined in the larger context of modular programng
ming, a distinct advantage for fibration over parameterization emerges. To
explain why this is the case, we must first consider families of modules.

8.8 Module Families

Needless to say, the justifications for introducing families of signatures apply
just as well to implementations. Continuing with the example from $8.7, we
might well require, in the same program, several different dictionary modng
ules, differing only in the choice of key type. We would then like to abstract
the common pattern by forming a family of modules indexed by modules
satisfying a particular signature (Ordered).

A natural representation of a family of modules is as a *ngabstraction of a
module expression over a module variable of a specified signature. Such an
abstraction is called a parameterized module, or functor.8 Instances of the
family are obtained by functor application.9

The syntax required to support functors is given in Figure 8ng5. (This gramng
mar permits higherngorder functors, but for now we concentrate on the firstng

8. Rod Burstall once remarked that if we do not call the factorial function a "parameterized
integer," then we should not call a functor a "parameterized module"!
9. We adopt here an indexed approach to module families, but it is worth noticing that a
fibered approach also makes sense and has been explored under the name mixin modules; we
discuss these briefly on page 343 below.

8.8 Module Families 325
M; F ::= . . . modules:

*( m:I) N functor
F(M) application
I ::= . . . signatures:

\Pi  ( m:I1)I2 functor signature
*m:I1.I2 parameterized signature
I1 I2 application
I where X=T where signature

Figure 8ng5: Mechanisms for functors

order case, in which only basic modules may be provided as functor argung
ments. See $8.9 for a discussion of the higherngorder case.) The metavariables
F and G range over functors.

In $8.7 we noted that it would be useful to define a family of dictionary
modules indexed by the type of keys. Using the notation of Figure 8ng5, a
dictionary functor might be written

module dictFun = *key:Ordered. mod { ... }
where ... represents some implementation of the dictionary type and opng
erations. The dictionary module dict1 (with signature Dict1, defined on
page 320) would then be obtained by applying dictFun to the key module
key1:

module dict1 = dictFun(key1)

If a functor is a kind of function, then its signature should be like a function
type--for example, the signature of the dictFun functor should be something
like this:

signature DictFun =

Ordered !

sig {

type Dict : *!*
val new : 8V. Dict V
val add : 8V. Dict V ! key.X ! V ! Dict V
val member : 8V. Dict V ! key.X ! Bool
val lookup : 8V. Dict V ! key.X ! V
}

However, the arrow notation does not quite give us what we need because it
does not express the dependency between the argument and the result of the
dictionary functor--i.e., the fact that the module key appearing in the result
signature is precisely the functor's argument. To capture this dependency,
we need an additional form of signature, called a functor signature, of the

326 8 Design Considerations for MLngStyle Module Systems

form \Pi m:I.J. Such a signature binds the module variable m in the signature
J, permitting the dependency of the result signature on the argument to be
expressed. The signature I is the called the domain, and J is called the range.
(The signature \Pi m:I.J is a form of dependent function type; see Chapter 2
for background.) The type of the dictionary functor given above may now be
written as follows:

signature DictFun =

\Pi key:Ordered.

sig {

type Dict : *!*
val new : 8V. Dict V
val add : 8V. Dict V ! key.X ! V ! Dict V
val member : 8V. Dict V ! key.X ! Bool
val lookup : 8V. Dict V ! key.X ! V
}

Instantiating DictFun by a module M implementing the domain signature
Ordered yields a module whose type is the instance of the range signature
obtained by replacing key by M throughout.

8.8.1 Exercise [n']: One might guess that a family of modules would have a family

of signatures, but, instead of this, we introduced a new notion of functor
signatures. Why? 2

8.8.2 Exercise [n']: Note that DictFun can be written more concisely in terms of

the parameterized signature family DictP, as \Pi key:Ordered. DictP(key).
Can DictFun also be expressed using the fibered signature family Dict? 2

Functor arguments are required to be determinate because the range signg
nature may involve type selections from the domain parameter (as in the
example above). Substitution of the argument for the parameter results in a
specialization of the range signature. Rather than use substitution, we may
also formulate the typing rule for functor application using subsumption.
Just as for ordinary function types, functor signatures are contravariant in
the domain and covariant in the range. This implies that we may weaken a
functor signature by strengthening its domain type. In particular, if F is a
functor with signature \Pi m:I.J, and M is a determinate module with transparng
ent signature I0<:I, then F also implements the signature \Pi m:I0.J. Since I0
is transparent, any type selection of the form m.X in J may be replaced by its
definition in I0, thereby eliminating the dependence of the range signature
on the functor argument. This results in a signature of the form I0!J0, where
J0<:J. By covariance F implements I0!J0, and hence F(M) implements J0. In

8.8 Module Families 327
effect we've performed the substitution of M for m in J using the types of F
and M alone, rather than by inspecting M itself.

8.8.3 Exercise [n', 3]: Work out the type checking of the application dictFun(M),

where M is a determinate implementation of the key signature Ordered of
your choosing, using the rules just described. 2

Coherence
Since families of modules are just functions from modules to modules, one
might guess that the language design issues they raise would be just the ones
familiar from higherngorder functional programming languages. However, a
closer look reveals a significant difficulty, called the coherence problem, that
must be overcome in any practical language with module families.

Suppose we have defined modules ab and bc, each providing a function f
that maps between some input type In and some output type Out. For ab, the
input and output types are A and B; for bc they are B and C:

module ab = mod {

type In = A
type Out = B
val f : In ! Out = /* ... some function from A to B */
}

module bc = mod {

type In = B
type Out = C
val f : In ! Out = /* ... some function from B to C */
}

Since the output type of ab is the same as the input type of bc, we can write
a third module of the same form that uses the f functions of ab and bc to
construct its own f mapping from A to C.

module ac = mod {

type In = A
type Out = C
val f = *x:In. bc.f (ab.f x)
}

The point to notice here is that the wellngtypedness of ac.f depends on the
fact that the result type of ab.f is the same as the argument type of bc.f.

Now, suppose that we have a lot of modules of the same form as ab and
bc, and we want to write many modules like ac that "compose" the transforng

328 8 Design Considerations for MLngStyle Module Systems

mations provided by a pair of existing modules.10 We would like to write a
composition functor that encapsulates, once and for all, the boilerplate inng
volved in building these composite modules. To do this, we first define a
generic signature for "transformers"; this is the type of the inputs and the
output of the composition functor.

signature Tr =

sig {

type In
type Out
val f : In ! Out
}

Both ab and bc implement Tr.

A naive first attempt at writing the composition functor itself would be
this:

module compose =

*m:Tr. *n:Tr.

mod {

type In = m.In
type Out = n.Out
val f = *x:In. n.f (m.f x)
}

However, this is not well typed: the type expected by n.f is n.In, while the
type returned by m.f is m.Out, and we have no reason to believe that these
are the same. That is, we have failed to express the fact that, for composition
to make sense, the argument modules m and n must be coherent in the sense
that they share this type.

There are two wellngknown techniques for ensuring coherence, called sharng
ing by construction (also sharing by parameterization or Pebblengstyle sharing)
and sharing by specification (or MLngstyle sharing). Sharing by construction
was invented by Burstall and Lampson (1984) in their Pebble language and
has been explored by many people, famously Jones (1996). Sharing by specng
ification was originated by MacQueen (1984) and is used in the ML module
system.

10. One realngworld domain where this sort of situation arises is in networking protocol toolkits
such as FoxNet (Biagioni, Haines, Harper, Lee, Milnes, and Moss, 1994) and Ensemble (van Reng
nesse, Birman, Hayden, Vaysburd, and Karr, 1998): the modules ab and bc in the example
correspond to individual protocol layers or "micro protocols," the functions f correspond to
the processing performed by each protocol layer, and the input and output types correspond
to different packet or message formats. Composite modules like ac correspond to protocol
stacks such as TCP/IP.

8.8 Module Families 329

Sharing by specification relies on the technique of fibered signature faming
lies introduced in $8.7: the required coherence between the module paramng
eters m and n is expressed by refining the signature of n so that the only
modules to which compose can legally be applied are those whose Out comng
ponent coincides with the In component of m:

module compose =

*m:Tr. *n:(Tr where In = m.Out).

mod {

type In = m.In
type Out = n.Out
val f = *x:In. n.f (m.f x)
}

The type of this functor is

\Pi (m:Tr) \Pi (n:Tr where In = m.Out)

Tr where In=m.In and Out=m.Out

(writing and as a more readable synonym for where).

Before we go on, a short digression on notation is in order. The defining
tion of compose that we have just given is a little hard to read: since we
have defined functors to take just one parameter at a time and used currying
to write multiplengargument functors, the inherently symmetric sharing relang
tion between m.Out and n.In has to be dengsymmetrized. We can recover the
symmetry in two steps. We begin by unngcurrying compose--i.e., we rewrite
compose into a onengargument functor whose parameter is a module with two
subngmodules m and n:

signature TrPair = sig {

module m : Tr
module n : Tr where In = m.Out
}

module compose =

*p:TrPair.

mod {

type In = p.m.In
type Out = p.n.Out
val f = *x:In. p.n.f (p.m.f x)
}

Second, we rewrite the signature TrPair in a symmetric way using a new
keyword sharing:

330 8 Design Considerations for MLngStyle Module Systems

signature TrPair = sig {

module m : Tr
module n : Tr
sharing n.In = m.Out
}

The signature of compose now becomes:

\Pi (p:TrPair) Tr where In=p.m.In where Out=p.m.Out
Fortunately, sharing declarations add no foundational complexity to the lanng
guage: they are simple syntactic sugar. The sharing form just desugars into
the primitive where form--i.e., the compiler can straightforwardly expand the
second definition of TrPair into the first. This syntax clarifies the essential
intuition that the argument to compose is not simply a pair of transformer
modules, but a coherent pair of modules.11

The sharingngbyngconstruction style expresses the coherence required by the
compose functor in a different way: by "factoring out" the shared type as
another parameter to compose. To achieve this, we first replace the signature
Tr by a signature family, indexed by the types In and Out:

signature Tr = *In:*. *Out:*.

sig {

val f : In ! Out
}

module ab = mod { val f : A ! B = ... }

: Tr A B

module cb = mod { val f : B ! C = ... }

: Tr B C

Similarly, the signature of composable pairs, TrPair is parameterized on
three types:

signature TrPair = *In:*. *Mid:*. *Out:*.

sig {

module m : Tr In Mid
module n : Tr Mid Out
}

The coherence between m and n is expressed here by the fact that their signang
tures both mention the same type Mid. Now we can write a compose functor

11. That is, in categoryngtheoretic terms, not just a product but a pullback.

8.8 Module Families 331

module compose =

*In:*. *Mid:*. *Out:*.

*p : TrPair In Mid Out.

mod {

val f = *x:In. p.n.f (p.m.f x)
}

of type:

\Pi In:*. \Pi Mid:*. \Pi Out:*.

\Pi p:(TrPair In Mid Out).

Tr In Out

We are using a little syntactic sugar here to make the example easier to read:
compose takes three types and a module as parameters, whereas, strictly
speaking, functors can only take modules as parameters. What we've written
can be regarded as an abbreviation for a heavier notation where each "bare
type" parameter is wrapped in a little module.

Sharing by construction has an appealing directness, especially for prong
grammers trained in the mental habits of higherngorder functional languages.
Moreover, since it relies only on abstraction and application for defining
signature families, it can be carried out even in rudimentary module sysng
tems lacking the translucency required to express fibered signatures. Unforng
tunately, it suffers from a defect that makes it difficult to use in practice: it
does not scale to deep hierarchies of functors.

To see why, note how the parameterized form of the compose functor has
to take the "middle type" Mid as an explicit parameter. This is not so bad
in the present example, where the hierarchy is shallow. But suppose that,
for some reason, we want to write a functor that composes together four
transformations.

In the fibered style, we can write another signature that packages together
two TrPairs with an appropriate sharing declaration relating the final outng
put of the first with the initial input of the second:

signature TrQuad = sig {

module xy : TrPair
module zw : TrPair
sharing zw.m.In = xy.n.Out
}

Note how the coherence between the first and second transformations and
between the third and fourth is expressed by the two uses of the TrPair
signature--all that needs to be stated explicitly in TrQuad is the coherence
of the second and third. The compose4 functor is equally straightforward to
write, using three applications of the original compose:

332 8 Design Considerations for MLngStyle Module Systems

module compose4 =

*q:TrQuad.

let xtheny = compose q.xy in
let zthenw = compose q.zw in
let p = mod { module m = xtheny, module n = zthenw } in
compose p

In the parameterized style, on the other hand, the TrQuad signature is
much more awkward:

signature TrQuad = *T1:*. *T2:*. *T3:*. *T4:*. *T5:*.

sig {

module xy : TrPair T1 T2 T3
module zw : TrPair T3 T4 T5
}

Note how the "internal" coherence constraints on xy and zw have "come to
the outside" as parameters to TrQuad. Now compose4 looks like this:

module compose4 =

*T1:*. *T2:*. *T3:*. *T4:*. *T5:*.

*q : TrQuad T1 T2 T3 T4 T5.

let xtheny = compose T1 T2 T3 q.xy in
let zthenw = compose T3 T4 T5 q.zw in
let p = mod { module m = xtheny, module n = zthenw } in
compose T1 T3 T5 p

The type parameters to compose4 are nuisance parameters: they are present
solely to express the required type sharing relationships among the "real"
arguments to the functor.

8.8.4 Exercise [n']: Suppose we extended this pattern to write compose8 (using

two applications of compose4 and one of compose). How many type paramng
eters would compose8 need to take in the parameterized style? What about
compose16? 2

This example shows how sharing by parameterization forces the "plumbng
ing" required to ensure coherence of a functor low in the dependency hierng
archy to be recapitulated by every highernglevel functor that uses it, by yet
higher level functors that use these, etc. Setting up this plumbing (and worse,
maintaining it as the program evolves), quickly becomes impractical except
for shallow hierarchies. This failure of scalability was observed early on by
MacQueen (1984), but has not been widely recognized.

It is important to emphasize that the representation of signature families
bears strongly on the method of expressing sharing relationships. If signature

8.8 Module Families 333
families are represented in parameterized form, then sharing by construction
is the only available method of ensuring coherence. We must instantiate two
families by application to the common types or modules to ensure compatng
ibility. On the other hand, if signature families are represented in fibered
form, then either method of ensuring coherence is available, since we may
either specialize two or more signatures with the common component using
the where construct, or we may specify that they cohere on the common comng
ponents using sharing. The crucial reason for this is that a fibered signature
is a signature--it can be instantiated, or not, as a given situation demands.
This allows decisions about parameterization and sharing to be performed in
a natural "postnghoc" manner. Since each module internally recapitulates the
whole module dependency graph, coherence requirements can be satisfied
simply by adding a few equations tying together subgraphs as appropriate.

The Pragmatics of Functors
Since relatively few presentngday languages support families of modules, it is
worth surveying the practical motivations for including them in a module
system. These fall into several categories:

1. Many abstractions are naturally parametric in a type and its associated opng

erations. For example, we illustrated in $8.8 that a dictionary abstraction is
naturally parametric in both the type of its keys and the interpretation of
that type as prengordered. Thus, functors arise naturally in shared libraries.

2. Many programs are naturally functorial in nature. For example, the arching

tecture of the FoxNet implementation of TCP/IP (Biagioni et al., 1994) and
related networking protocols is based on treating each "layer" of a protocol
stack as a functor that is parametric in the layers that occur "above" and
"below" it in the protocol hierarchy. To take another example, the SML/NJ
compiler for Standard ML implements crossngcompilation by defining the
central code generation module to be parametric in the target architecture
module, so that several code generators can be simultaneously active and
share the bulk of the code. Thus, some program architectures are naturally
functorial.

3. A variety of linkngtime techniques--based on mechanisms such as "path

hacking," class loaders, and various tools provided by the programming
environment--are commonly used to achieve effects similar to those exng
pressible using functors. For example, partial linking of several object files
into a single, furthernglinkable object file (using ld ngr in Unix, for example)
is nothing but a means of defining a functor whose parameters are the

334 8 Design Considerations for MLngStyle Module Systems

unresolved modules and whose result is the partially linked module conng
structed by the linker. Because such devices are extranglinguistic in nature,
they can be unsafe because the external tools are not aware of typing reng
strictions. In particular, when used for languages with abstract types, such
devices may violate coherence constraints, leading to unsafe code. Thus,
functors codify and formalize certain extranglinguistic programming pracng
tices.

Some of the problems addressed by functors are also amenable to treatng
ment by more primitive modularity mechanisms. (This helps explain why the
software industry has not yet ground to a halt due to the lack of functors
in mainstream languages!) These mechanisms are often more convenient for
specific purposes, even if they may be subsumed or explained by the more
general mechanism of functors.

For example, Haskell encourages the use of type classes to define interng
pretations of types by operations. One may, for instance, introduce a class of
ordered types as those that come equipped with a binary relation on them. Inng
stances of this class are introduced by specifying the (sole) interpretation of
a type by a given binary relation. Instances are often conditional on other
instance requirements. For example, one may declare the type Int to be
prengordered by the standard magnitude comparison function, and one may
declare the product type (A,B) to be prengordered lexicographically (say), prong
vided that A and B are also ordered. In the terminology of this chapter, type
classes are simply signatures and instance declarations are functors mapping
zero or more instances of some classes to an instance of a designated class.
(This use of functors is limited in that a given type may implement the class
of ordered types in at most one way, whereas in general a type may admit
many orderings. A benefit of this limitation is that the "functor applications"
required to calculate appropriate instances of classes may be performed aung
tomatically by the compiler.)

Another case where a more primitive mechanism may suffice concerns a
parameterized abstraction, such as dictionaries (parameterized on keys), prong
vided by a library. If we happen to know that any given program using this
abstraction instantiates it just once, then the abstraction itself need not be
functorized. Instead, the dictionary library can simply be a module containng
ing an unresolved external reference to a key module that must be resolved
in the linking context of each program that uses it. Specifying the instance is
generally achieved by extranglinguistic mechanisms such as modifying a search
path or installing a specialngpurpose loader, but such mechanisms could also
be internalized as a part of the module language.

8.8 Module Families 335

Another important special case is found in objectngoriented languages. The
nearest analogs of modules in these languages are classes and objects. Obng
jects may be viewed as firstngclass modules with one abstract type, which
specifies the types of the instance variables of the object. (This corresponng
dence between objects and modules is explored in depth in TAPL, Chapter
24.) While sufficient to capture some common cases, this idiom makes it awkng
ward to manage a collection of interngrelated abstract types. (One example is
the mathematical notion of a vector space, which involves an abstract type
of vectors together with a related type of scalars, each with its own set of
associated operations.) Another issue is that these languages offer no analog
of sharing (by parameterization or specification) of representations, which
is the core issue underlying the wellngknown difficulties with binary methods
(Bruce et al., 1996).

Classes provide a limited form of modularity by serving as the locus of code
sharing for all instances of the class. But inheritance is, by its very nature,
antingmodular in that it couples the code of a subngclass to the code of its
superngclass. In particular, there is no notion of signature for a class, nor--in
most objectngoriented languages12--any means of inheriting from an unknown
(abstract) superngclass. Moreover, if a subngclass determines a subtype of the
superngclass type, it is impossible to determine anything about the behavior
of an instance of a class from its type alone. For knowing that o is an object
of a (nonngfinal) class C means only that o is an instance of some subngclass
of C, whose behavior may be totally unrelated to instances of C itself. For
these reasons classes provide only a weak form of modularity, and cannot be
considered to replace it. Fisher and Reppy have examined these issues in the
design of the Moby language (1999).

An oftenngrepeated argument for functors is that they may be used as a
replacement for a linking mechanism. The idea is that all interngmodule referng
ences are to be mediated by a functor--the songcalled fully functorized style
of programming--so as to improve program readability by making explicit all
crossngmodule references. But adopting a fully functorized style amounts to
replacing each definite reference in a module by an indefinite reference--the
free module variable is *ngabstracted in the functor. A central "linking module"
then applies these functors in dependency order to construct the complete
system; i.e., the behavior of the linker itself is internalized and made explicit
as a modulenglevel program. Experience has shown this to be a bad idea: all
this parameterization--most of it unnecessary--gives rise to spurious coherng
ence issues, which must be dealt with by explicitly (and tediously) decorating

12. Languages with mixin modules are, in this respect, closer to the module systems we are
discussing.

336 8 Design Considerations for MLngStyle Module Systems

I ::= . . . signatures:

\Pi G ( m:I1):I2 generative functor
\Pi A ( m:I1):I2 applicative functor

Figure 8ng6: Mechanisms for applicative and generative functors

module code with numerous sharing declarations, resulting in a net decrease
in clarity and readability for most programs.

Functors and Determinacy
When is a functor application determinate? There are two possibilities, deng
pending on whether we take the functor to be generative or applicative. If
generative, each instance of a functor that yields an abstract type "generates"
a new abstract type at the point of instantiation. If applicative, there is one
abstract type covering all instances of the functor with equivalent arguments.
The difference between these two forms of functor is that the application of
a generative functor is indeterminate, whereas the application of an applicang
tive functor is determinate. To model both forms of functor we introduce two
forms of functor signature, as described in Figure 8ng6.

Needless to say, the classification of functors into applicative and generang
tive is not arbitrary. If the body of a functor is indeterminate, then the functor
can only be regarded as generative. Otherwise, an application of such a funcng
tor would be determinate, even though it is essentially a substitution instance
of its indeterminate body. Thus a functor may be deemed applicative only if
its body is determinate, but we may regard any functor as generative, by neng
glecting the possible determinacy of its body. Therefore, it is natural to posit
that the applicative functor type is a subtype of the corresponding generative
functor type.

8.8.5 Exercise [n'n'n']: Show that it is unsound to consider the generative functor

type to match the applicative. (Hint: Adapt the solution to Exercise 8.5.6.) 2

Assuming we have both applicative and generative functors at our disposal,
when is it appropriate to use one or the other? Let us consider several examng
ples.

If a functor implements an abstract type using pernginstance state, it should
be generative. For example, consider the implementation of a type of symng
bols using a hash table. (Here and elsewhere, we omit the result signature on
functors for the sake of brevity.)

8.8 Module Families 337

signature ST = sig {

type Symbol
val str2sym : String ! Symbol
val sym2str : Symbol ! String
val eq : Symbol * Symbol ! Bool
}

module stFun :> \Pi G m:(sig{}).ST =

*G m:(sig{}). mod {

type Symbol = Int
val table : string array = Array.new (100, NONE)
val str2sym = *s:String. ...
val sym2str = *s:Symbol.

case Array.sub (table, n) of

SOME x ) x | NONE ) ...
val eq = *(n1,n2) = (n1 = n2)
}

module stOne = stFun (mod{})
module stTwo = stFun (mod{})

The two instances, stOne and stTwo, of stFun generate distinct abstract
Symbol types, and stOne.Symbol is distinct from stTwo.Symbol. Were these
types confused, symbols from one table could be intermixed with symbols
from another, leading to incorrect results and runngtime exceptions that could
be avoided by keeping them apart. In particular, the NONE clause in the body
of stFun can safely be omitted if the functor is generative, but must be inng
cluded (or we run the risk of a match failure) if it is applicative.

A natural example of an applicative functor is one whose argument consists
solely of types and whose result does not involve any effects. For in such a
case there is no reason to distinguish abstract types in different instances
of the functor. For example, consider a functor setFun that takes a type of
elements as argument and yields an abstract type of sets of these elements.

signature setFunInt =

\Pi A m:(sig { type X }).

sig {

type Set
val insert : m.X * Set ! Set
... }

module setFun :> setFunInt =

*A m : sig { type X }.

mod {

type Set = ...
val insert = ... }

338 8 Design Considerations for MLngStyle Module Systems

Notice that the functor itself is sealed with an applicative functor type to
ensure that the Set type in the result is abstract.

One consequence of restricting an applicative functor to have a determing
nate body is that neither its body nor any of its subngmodules may be sealed.
(Were we to do so, the body would be indeterminate, forcing the functor to
be generative.) This explains why we sealed the setFun functor itself, rather
than writing it in the form

module setFun =

*m:sig { type X }.

(mod {

type Set = ...
val insert = ...
} :>
sig {

type Set
val insert : m.X * Set ! Set
...
}).

While sealing the functor itself can be used to impose abstraction on its
instances, it cannot be used to impose abstraction within the body of the
functor. One way to remedy this deficiency is to distinguish two forms of
sealing, static sealing and dynamic sealing, and two associated forms of inng
determinacy, static indeterminacy and dynamic indeterminacy. The dynamic
forms of sealing and indeterminacy are just those considered up to now. The
static forms are added solely to enrich the class of applicative functors. A
statically sealed module is statically indeterminate, which ensures represenng
tation independence. An applicative functor body is permitted to be statically
indeterminate, but not dynamically indeterminate (which would force genng
erativity). The terminology stems from considering that, for an applicative
functor, abstraction is imposed once when the functor is typengchecked, rather
than each time the functor is applied; the abstraction effect is "static," rather
than "dynamic."

8.9 Advanced Topics

FirstngClass Modules
The framework developed here is compatible with treating modules as firstng
class values, by which we mean that we may readily enrich the language to
permit modules to be manipulated as ordinary values in the core language.
For example, we may store a module in a data structure, then retrieve it and

8.9 Advanced Topics 339
reconstitute it as a modulenglevel expression, without violating representation
independence or type safety. We need only ensure that any means of creating
a module from a core language computation is considered indeterminate so
as to preserve safety and representation independence.

Why not just do away with the distinction between the core and module
languages entirely? While this would seem to simplify matters by collapsng
ing a distinction, it complicates the type theory significantly, requiring that
the core language be enriched with the mechanisms required to support
modularity. These include types for submodules and functors, a subtyping
relation, and the means to ensure static type checking in their presence.
These complications are not insurmountable. One such formalism was develng
oped by Harper and Lillibridge (1994), who also showed that the type checkng
ing problem for this language is undecidable, due to complex interactions
between subtyping, impredicative polymorphism, and type sharing specifing
cations. Dreyer, Crary, and Harper's formalism (Dreyer, Crary, and Harper,
2003), on the other hand, achieves adequate expressiveness, including supng
port for firstngclass modules, without incurring undecidability.

Finally, even if we were to attempt to consolidate the module and core levng
els, we would find ourselves facing the same questions at a higher level. For,
as the development of this chapter makes clear, once we introduce separate
compilation (as surely we must), we once again face the same questions of
modularity, at the level of compilation units. Module arise even when you try
to avoid them!

HigherngOrder Modules
Higherngorder modules--i.e., functors taking functors as parameters--present
some interesting further difficulties. The classic (if somewhat contrived) mong
tivating example is the apply functor, defined as follows:

module apply =

*f:(\Pi i:I.J).

*i:I.

f(i)
module m :> I = ...
module f :> \Pi i:I.J = ...
module n = f(m)
module p = apply(f)(m)

One might expect that n and p are equivalent, since both apply f to m. But this
need not be so, at least if we wish to give a single type for apply that governs
all of its uses. For then we must specify whether the argument, f, to apply

340 8 Design Considerations for MLngStyle Module Systems

is applicative or generative. If it is required to be applicative, we may ascribe
the following type to apply:

\Pi A f:(\Pi A i:I.J). \Pi A i:I. (J where X=f(i).X).
This expresses the dependence of the result type X on the two arguments
consistent with the definition of apply. Indeed, apply(f)(a).X is equivalent
to f(a).X, as desired.

On the other hand the functor argument to apply might be taken to be
generative, in which case the best typing for apply is

\Pi G f:(\Pi G i:I.J). \Pi G i:I. J
Since f is taken to be generative, we lose type sharing information in the
result, because the application f(a) is indeterminate, and hence the "type"
f(a).X is illngformed. Consequently, the abstract type X in n and p are not
known by the type checker to be the same.

It has been suggested that there should only be one apply functor that
covers both cases illustrated above. To do so requires that we employ a
form of intersection type (at the level of signatures) that captures the two
forms of behavior just described. An alternative, suggested by MacQueen and
Tofte (1994), is to refrain from assigning types to functors, in effect rengtypeng
checking the body on each use. This means that the code, and not just the
type, of the functor must be available to all clients, which precludes separate
compilation.

Static and Dynamic Equivalence
There are two main choices for module equivalence: static equivalence and
dynamic equivalence. Static equivalence deems two modules to be equivalent
whenever their static parts are equivalent. This is the coarsest equivalence beng
tween modules that conservatively extends core language type equivalence,
and is therefore the most permissive choice. The alternative, dynamic equivng
alence, considers both the static and dynamic parts of modules in the defining
tion of equivalence. Dynamic equivalence is, in general, undecidable, so some
conservative approximation must be used in practice.

However, dynamic equivalence makes it possible to distinguish two differng
ent interpretations of the same type without generativity. For example, if f is
a module variable of functor type, and M and N are determinate modules of its
domain type, then f(M).X is equivalent to f(N).X iff M and N are equivalent
modules. Static equivalence ignores the dynamic part of these two modules,
whereas dynamic equivalence would distinguish these types if M and N differ
only in their dynamic components.

8.10 Relation to Some Existing Languages 341
Recursive Modules
The model of linking discussed in $8.1 requires that the dependency relation
among modules be acyclic--that there be a linear ordering of the modules
consistent with their dependencies. It is natural to consider whether this reng
striction might be lifted to permit a more general form of "crossnglinking"
of modules. Since cyclic dependencies amount to (direct or indirect) selfng
reference, one approach to modelling such a generalization is via recursive
modules (Crary, Harper, and Puri, 1999; Russo, 2001). Another approach is
to devise a linking formalism that permits cyclic dependencies (Ancona and
Zucca, 1998; Hirschowitz and Leroy, 2002; Flatt and Felleisen, 1998).

Cyclic dependencies raise some significant problems that must be addressed
in any satisfactory solution. Most importantly, permitting recursive modules
should not disrupt the semantics of the underlying language. Without restricng
tion, cyclic dependencies among modules can introduce a type A satisfying
the equation A = A ! Int, or a value v of type Int satisfying the equation
v=v+1. In most languages such equations have no solution, and should not be
permitted. Another issue is the interaction with effects. Permitting cyclic deng
pendencies conflicts with the need for a linear initialization order consistent
with dependencies. Care must be taken to ensure that values are not referng
enced before they are defined (or, at a minimum, that such references are
caught at run time). Finally, for maximum flexibility, mutually recursive modng
ules should be separately compilable. This requires some form of "forward"
declaration to cut cycles in the dependency graph. It also requires a linking
formalism that can support mutually crossngreferencing modules, even in the
presence of type declarations.

8.10 Relation to Some Existing Languages

The design issues discussed in this chapter are largely motivated by the ML
module system. There are two closely related realizations of the ML module
system, the Standard ML module system and the Objective Caml module sysng
tem. Basic modules are called structures, signatures are called signatures, and
functors are songcalled in both cases. Both designs provide for hierarchy and
parameterization using essential the same mechanisms as described here,
and both adopt the approach to sharing by specification described in $8.8.
The designs differ significantly in their treatment of separate compilation,
the avoidance problem, and higherngorder modularity. The two languages are
based on rather different foundations. Standard ML is defined by an elaborang
tion relation that constitutes an algorithmic specification of the wellngformed
programs. Objective Caml lacks a formal definition, but the design follows
quite closely a type theory of the general kind considered here.

342 8 Design Considerations for MLngStyle Module Systems

Standard ML, as officially defined (Milner, Tofte, Harper, and MacQueen,
1997), permits only firstngorder, generative functors, provides no support for
separate or incremental compilation, and handles the avoidance problem by a
technical device that sacrifices principality. To amplify the last point first, the
elaboration relation that defines the static semantics of Standard ML relies on
an internal notion of "type names" that are generated during elaboration. Hidng
den abstract types are represented by type names that cannot be designated
by any Standard ML type expression, and hence internal "signatures" are not
expressible by any signature in the language. Consequently, the Standard ML
module system does not in general admit principal (source language) signang
tures. As to separate compilation, the formal definition of Standard ML does
not address it, so each implementation provides its own mechanisms. The
most widely used implementation, Standard ML of New Jersey (SML/NJ), has
a wellngdeveloped compilation manager (Blume and Appel, 1999; Blume, 2002)
that supports incremental and cutngoff compilation. SML/NJ also provides exng
tensions to permit higherngorder modularity that rely on elaborate internal
representations of functors that cannot be written in any source language signg
nature, and is therefore incompatible with separate compilation. Moscow/ML
(Sestoft, 2003; Russo, 1998) is an implementation of Standard ML based on a
typengtheoretic interpretation of the language. It provides recursive and firstng
class structures, and both applicative and generative functors.

Objective Caml permits higherngorder, applicative functors, supports sepang
rate and incremental compilation, and handles the avoidance problem by sacng
rificing principality. Again taking the last point first, Objective Caml rejects
certain wellngformed programs (in the sense of the underlying type theory of
the language) when the implementation does not succeed in weakening a signg
nature to avoid the occurrence of an abstract type (Dreyer, Crary, and Harper,
2003). The commitment to applicative functors stems from a desire to permit
type selections of the form f(m).X in sharing specifications.

The Haskell (Peyton Jones, 2003) module system is rather weak, providing
only rudimentary namespace management. This deficiency is ameliorated by
type classes. Viewed in terms of the framework of this chapter, the Haskell
type class system amounts to a stylized use of modules. Polymorphic abstracng
tion is generalized to functor abstraction--expressions take not only types,
but associated operations, as arguments. The functor arguments are generng
ated automatically during type inference based on a significant methodologng
ical restriction: no type may admit more than one interpretation by a given
set of operations. (For example, in conjunction with type classes no type may
be partially ordered in more than one way in a given program.) These interng
pretations are specified by type class declarations that amount to functor
definitions. The type checker implicitly instantiates these functors (through

8.11 History and Further Reading 343
a process of backchaining) to determine the required implicit arguments. Exng
perimental designs for richer modularity mechanisms have been proposed
in the literature. For example, Jones (1996) regards modules as polymorphic
records, which forces the programmer to manage explicitly the separation of
the static from the dynamic parts of a module.

Flatt and Felleisen's units (1998) provide a form of modularity for Scheme
programs (and other languages) that emphasizes separate compilation and
recursive linking. Their language does not consider type abstraction or the
associated problems of type sharing. In their realization, units are firstngclass
values, amounting to records in the underlying language. In other formung
lations, units are used to structure existing C code to provide namespace
management and a flexible linking formalism (Reid et al., 2000).

Ancona and Zucca's mixin modules (1998; 2002) isolate a variety of comng
binators for combining modules into programs. As suggested by Bracha and
Cook (1990), mixins provide a basis for modelling inheritance, as well as supng
porting cyclic dependency relationships among modules. Mixins may be seen
as fibered representations of families of modules in which instantiation is
represented by "mixing in" one module with another.

8.10.1 Exercise [n'n'n']: The C language lacks an internal notion of module, preferng

ring instead to exploit the ambient file system to provide most of the requisite
mechanisms. Discuss. 2

8.10.2 Exercise [n'n'n']: The Java language also lacks direct analogs of most of the

mechanisms we have introduced. However, Java does offer a rich collection
of program structuring mechanisms, some of which can be used to achieve
effects similar to the ones illustrated here. Discuss. 2

8.11 History and Further Reading

The development of the linguistic and methodological foundations of data
abstraction and modularity dates back to the earliest days of academic comng
puter science (Parnas, 1972). Seminal work by Wirth (1973) and Hoare (1972)
(among many others) was influential on the development of languages in the
Algol family such as Pascal (Jensen and Wirth, 1975), Modulang2 (Wirth, 1983),
CLU (Liskov, 1993), and Modulang3 (Cardelli, Donahue, Jordan, Kalsow, and
Nelson, 1989). The Lisp family of languages (Steele, 1990) influenced the deng
sign of ML (Gordon, Milner, and Wadsworth, 1979), which introduced type
inference, polymorphism, and abstract types. This sparked the development
of several languages, such as Hope (Burstall, MacQueen, and Sannella, 1980),
Standard ML (Milner, Tofte, Harper, and MacQueen, 1997), Objective Caml

344 8 Design Considerations for MLngStyle Module Systems

(Leroy, 2000), and Haskell (Peyton Jones, 2003), founded on these ideas. The
ML module system, originally proposed by MacQueen (1984), further develng
oped in the design of Standard ML and Objective Caml, forms the conceptual
basis for much of the material presented in this chapter.

The theoretical framework employed in this chapter (and in TAPL) is the
typed *ngcalculus. One important topic was to develop type systems to support
data abstraction. A fundamental first step was taken by Mitchell and Plotkin
(1988) who related abstract types to secondngorder existential quantification,
extending the connection between type polymorphism and secondngorder uning
versal quantification discovered by Girard (1972) and Reynolds (1974). Macng
Queen (1986) pointed out that existential types are not adequate for expressng
ing modular structure, suggesting instead a formalism based on dependent
types. These initial steps provided the impetus for further research into type
systems for modularity with the overall goal of providing the abstraction
guarantees afforded by existential types and the flexible modular programng
ming mechanisms afforded by dependent types.

One strand of research focused on enriching the existential framework to
support controlled propagation of type sharing information in a program.
Three important developments were Harper and Lillibridge's translucent sum
types (1994; Lillibridge, 1997), Cardelli and Leroy's "dot notation" (1990) and
Leroy's manifest types (1994; 1996), and Stone and Harper's singleton kinds
(2000; Stone, 2000). These type systems support hierarchy and parametering
zation with control over the propagation of type sharing relationships, even
in the presence of firstngclass modules.

Another strand focused on developing the mechanisms of dependent types
to support higherngorder modules. Building on MacQueen's suggestions, Harper
and Mitchell proposed a calculus of dependent types suitable for modelling
many aspects of the ML module system (1993). This framework was further
refined by Harper, Mitchell, and Moggi (1990) to ensure respect for the phase
distinction in a fully expressive higherngorder module system. Further work
by Russo (1999) further underscored the point that the apparent dependenng
cies are not really dependencies at all, by performing a "manual" form of
phasengsplitting during elaboration in the setting of a typengtheoretic semantics
for Standard ML. This formalism also provided the foundation for compilng
ing modules into typed intermediate languages (Shao, League, and Monnier,
1998). Shao (1999) considered a type system that ensures the existence of
principal signatures, at the expense of ruling out some programs that are
expressible in ML.

The abstractngtype formalisms provided only weak support for higherngorder
modules, and the dependentngtype formalisms provided no support for abng
straction. Leroy introduced applicative functors (1995) in an effort to enrich

8.11 History and Further Reading 345
the abstract type formalism with richer higherngorder constructs, but in the
process sacrificed generative type abstraction. A fully comprehensive formalng
ism was introduced by Dreyer, Crary, and Harper (2003), based on interpretng
ing type abstraction as a pro forma computational effect.

A rather different approach to the semantics of modularity is the elabong
ration framework of The Definition of Standard ML (Milner, Tofte, Harper,
and MacQueen, 1997). The type checking rules for modular programming
are given by an algorithm (expressed in inference rule format) for computng
ing an internal representation of the signature of a module. A weakness of
this approach is that it lacks any connection with the typed *ngcalculus forng
malisms that form the foundation for the semantics and implementation of
programming languages. This deficiency was addressed by Russo (1998), who
rengformulated The Definition using constructs from type theory. Harper and
Stone (2000) provided an alternative definition for Standard ML based on a
separation between elaboration, which included type inference, overloading
resolution, pattern compilation, and semantics, which was based on a founng
dational type theory for modularity.

Garcia et al. (2003) make an interesting comparison of the modularity mechng
anisms found in several popular languages, from the point of view of supportng
ing a particular style of "generic programming."

9 Type Definitions

Christopher A. Stone

Practical uses of interesting type systems often involve large and complex
types, and it is useful to have methods for abbreviating these types. The
simplest idea is to treat these definitions purely as metanglevel constructs (deng
rived forms), an approach with few theoretical complications. For example, in
a language with recursive and variant types (e.g., *u in TAPL, Chapter 20), we
could define

Nat defC^ uY.<zero:Unit, succ:Y>
NatList defC^ uX. <nil:Unit, cons:Nat * X>

after which the cons function for lists could be described as having the type
Nat ! NatList ! NatList rather than the much larger type

(uY. <zero:Unit, succ:Y>) !

(uX. <nil:Unit, cons:(uY.<zero:Unit, succ:Y>) * X>) !

(uX. <nil:Unit, cons:(uY.<zero:Unit, succ:Y>) * X>).

As long as these definitions are nonngcircular, they are convenient but inessenng
tial syntactic sugar. In principle the symbolic names can all be replaced by
their definitions, and so we can ignore them when reasoning about the lanng
guage itself: we may write types such as Nat ! NatList ! NatList inforng
mally, but "officially" we always mean the corresponding expanded type.

It is not always possible or practical, however, to omit type definitions from
the language being studied. In some instances type definitions are explicitly
part of the language itself. For example, the ML language permits type defining
tions by the user using the type keyword. C and C++ allow similar definitions
with the typedef keyword.

Alternatively, a language implementation might preserve definitions rather
than substituting them away; expanding all definitions can lead to signifing

348 9 Type Definitions

cantly larger types. Techniques such as DAG representations and hash conng
sing (Shao, League, and Monnier, 1998) can ameliorate this problem but the
results can be significantly less readable: if a type is originally written using
abbreviations, it is often desirable to retain them for displaying the type (e.g.,
when reporting errors during type checking, as discussed in TAPL, $11.4).

If type definitions are included in the language or its implementation, we
would still like to know that properties such as type safety continue to hold,
and that our algorithms (e.g., for type checking or code transformations) are
correct. However, the addition of definitional mechanisms can change the
properties of type systems in ways that are not immediately obvious. For
example, suppose X is an operator mapping types to types. In F !, the type
equivalence X T1 j X T2 holds if and only if T1 j T2. But if X is defined as the
constant operator *Y::*.Int, then suddenly X T1 j X T2 holds for arbitrary
T1 and T2.

As definitional mechanisms become more sophisticated, ensuring a proper
implementation can be more difficult. For example, after the module defining
tion (using roughly the syntax of Chapter 8)

module n = mod

type t = Nat
val x : t = 3
end

we can use n.t as a synonym for Nat. In this case we have a definition not for
the simple name t, but for the entire projection n.t. Moreover, module comng
ponents can be referenced indirectly; we cannot eliminate the type definition
just by replacing n.t by Nat. For example, the further definitions

module n' = n

module diag = *(p : sig

type t
val x : t
end).
mod

type u = p.t * p.t
val y : u = {p.x, p.x}
end

module nn = diag(n')
nowhere mention the projection n.t, yet a correct type checker must nevng
ertheless conclude both that n0.t is a synonym for int (by definition the
components of n0 are the same as the components of n) and that nn.u is

349
equal to the type int * int (guaranteed by the definition of diag). Additionng
ally, the definition for u in the functor's result, which depends on the specific
functor argument, must be retained in order to type check further uses of
diag.

It is therefore useful to study type definitions as primitive concepts. The
focus here is definitions for types because these have the most significant
effect on type equivalence and type checking and hence on language propng
erties such as safety. Very similar approaches are used, however, to study
termnglevel definitions and their effects upon term equivalence.

We look at three approaches to adding type definitions to a language. Secng
tion 9.1 defines the language *let, which adds primitive definitions of type
variables to the typing context. The context can record X::K if X is an unng
known type variable of kind K, and can record X::K=T if X is known to be
equal to the type T of kind K. This mechanism directly allows definitions
analogous to NatList above.

Section 9.2 formalizes parts of Chapter 8 by considering a calculus *L M of
secondngclass modules based on translucent sums. Again we have the choice
between specifying either just a kind or both a kind and a definition, but now
here all type definitions appear in module interfaces. This requires specifying
a language of modules and interfaces, and also introduces a limited form of
dependent type (since modules, which contain terms, can appear in types).

Finally, Section 9.3 defines *S, a generalization of *let that incorporates
definitions into the kind system itself. The kind * classifies all ordinary types,
while the new, morengprecise singleton kind S(T) classifies only those ordinary
types equivalent to T. This allows definitions at any point where a kind is
specified. We then relate *L M to *S by showing that modules can be translated
away using a phasengsplitting transformation.

All three systems are described as variants of F !*j, the higherngorder polyng
morphic lambda calculus extended with product types and with extensionalng
ity (eta). The types and kinds of this base language are shown in Figure 9ng1,
and the terms are shown in Figure 9ng2. Although not formally part of the
system, many examples will assume the existence of familiar base types (e.g.,
Nat or Bool) and terms (e.g., numeric constants and addition).

The least usual aspect of the formulation of F !*j is the use of the judgment
\Gamma  ` \Pi , which formalizes the notion of \Gamma  being a wellngformed context (see
TAPL, 30.3.18). A typing context is wellngformed if all bound variables are disng
tinct, and if each type within the context is wellngformed with respect to the
preceding portion of the context. For convenience in working with the sysng
tem, all judgments are designed to require (directly or indirectly) that their
typing context be wellngformed.

The evaluation rules for terms are standard and have been omitted.

350 9 Type Definitions

F !*j

T ::= types:

X type variable
T!T type of functions
T * T type of pairs
8X::K.T universal type
*X::K.T type operator abstraction
T T type operator application
K ::= kinds:

* kind of proper types
K)K kind of type operators

Context Validity \Gamma  ` \Pi 

* ` \Pi  (CTXngEmpty)
\Gamma  ` T :: * x 62 domD^\Gamma  E^

\Gamma  ; x:T ` \Pi  (CTXngType)
\Gamma  ` \Pi  X 62 domD^\Gamma  E^

\Gamma  ; X::K ` \Pi  (CTXngKind)

Kinding \Gamma  ` T :: K

X::K 2 \Gamma  \Gamma  ` \Pi 

\Gamma  ` X :: K (KngVar)
\Gamma  ; X::K1 ` T2 :: K2
\Gamma  ` *X::K1.T2 :: K1)K2 (KngAbs)
\Gamma  ` T1 :: K11)K12 \Gamma  ` T2 :: K11

\Gamma  ` T1 T2 :: K12 (KngApp)
\Gamma  ` T1 :: * \Gamma  ` T2 :: *

\Gamma  ` T1!T2 :: * (KngArrow)
\Gamma  ` T1 :: * \Gamma  ` T2 :: *

\Gamma  ` T1 * T2 :: * (KngTimes)
\Gamma  ; X::K1 ` T2 :: *
\Gamma  ` 8X::K1.T2 :: * (KngAll)

Type Equivalence \Gamma  ` S j T :: K

\Gamma  ` T :: K
\Gamma  ` T j T :: K (QngRefl)
\Gamma  ` T j S :: K
\Gamma  ` S j T :: K (QngSym)
\Gamma  ` S j U :: K \Gamma  ` U j T :: K

\Gamma  ` S j T :: K (QngTrans)
\Gamma  ` S1 j T1 :: * \Gamma  ` S2 j T2 :: *

\Gamma  ` S1 ! S2 j T1 ! T2 :: *

(QngArrow)

\Gamma  ` S1 j T1 :: * \Gamma  ` S2 j T2 :: *

\Gamma  ` S1 * S2 j T1 * T2 :: * (QngTimes)

\Gamma  ; X::K1 ` S2 j T2 :: *
\Gamma  ` 8X::K1.S2 j 8X::K1.T2 :: * (QngAll)

\Gamma  ; X::K1 ` S2 j T2 :: K2
\Gamma  ` *X::K1.S2 j *X::K1.T2 :: K1)K2 (QngAbs)

\Gamma  ` S1 j T1 :: K11)K12

\Gamma  ` S2 j T2 :: K11

\Gamma  ` S1 S2 j T1 T2 :: K12 (QngApp)

\Gamma  ; X::K11 ` S12 j T12 :: K12

\Gamma  ` S2 j T2 :: K11

\Gamma  ` (*X::K11.S12)S2 j E,X , T2G*T12 :: K12

(QngBeta)

\Gamma  ; X::K1 ` S X j T X : K2

\Gamma  ` S j T : K1!K2 (QngExt)

Figure 9ng1: Types and kinds of F !*j

9.1 Definitions in the Typing Context 351
t ::= terms:

x variable
*x:T.t abstraction
t t application
*X::K.t type abstraction
t [T] type application
{t,t} pair
t.1 first projection
t.2 second projection

Typing \Gamma  ` t : T

x:T 2 \Gamma  \Gamma  ` \Pi 

\Gamma  ` x : T (TngVar)
\Gamma  ; x:T1 ` t2 :: T2
\Gamma  ` *x:T1.t2 :: T1!T2 (TngAbs)
\Gamma  ` t1 : T11)T12 \Gamma  ` t2 : T11

\Gamma  ` t1 t2 : T12 (TngApp)

\Gamma  ; X::K1 ` t2 : T2
\Gamma  ` *X::K1.t2 : 8X::K1.T2 (TngTAbs)
\Gamma  ` t1 : 8X::K11.T12 \Gamma  ` T2 :: K11

\Gamma  ` t1 [T2] : E,X , T2G*K12

(TngTApp)
\Gamma  ` t1 : T1 \Gamma  ` t2 : T2

\Gamma  ` {t1,t2} : T1 * T2 (TngPair)

\Gamma  ` t1 : T11 * T12

\Gamma  ` t1.1 : T11 (TngProj1)
\Gamma  ` t1 : T11 * T12

\Gamma  ` t1.2 : T12 (TngProj2)
\Gamma  ` t : S \Gamma  ` S j T :: *

\Gamma  ` t : T (TngEq)

Figure 9ng2: Terms of F !*j

9.1 Definitions in the Typing Context

In a language with eager evaluation, sidengeffects prevent us from eliminatng
ing termnglevel definitions by replacing variables by their definitions. As an
alternative, therefore, closedngscope termnglevel definitions are often treated as
derived forms involving applications, namely

let x=t1 in t2 defC^ (*x:T1.t2) t1
where T1 is the type of t1. In languages with type operators a similar approach
can be used at the level of types, putting

let X=T1 in T2 defC^ (*X::K1.T2) T1
where K1 is the kind of the type T1.

However, a type definition used within a term does not correspond to an
instantiation of a polymorphic abstraction as one might expect. Although

let X=Nat in (*x:X.x+1)(4)
is semantically reasonable, the polymorphic instantiation

352 9 Type Definitions

*let Extends F !*j
New syntactic forms

\Gamma  ::= . . . contexts:

\Gamma  ; X::K=T openngscope definition
t ::= . . . terms:

let X = T in t closedngscope definition

Type Equivalence \Gamma  ` S j T :: K

X::K=T 2 \Gamma  \Gamma  ` \Pi 

\Gamma  ` X j T :: K (QngDef)

Context Validity \Gamma  ` \Pi 

\Gamma  ` T :: K X 62 domD^\Gamma  E^

\Gamma  ; X::K=T ` \Pi  (CTXngDef)

Kinding \Gamma  ` T :: K

X::K=T 2 \Gamma  \Gamma  ` \Pi 

\Gamma  ` X :: K (KngDef)

Typing Rules \Gamma  ` t : T

\Gamma  ` T1 :: K1 \Gamma  ` T2 :: *

\Gamma  ; X::K1=T1 ` t2 : T2

\Gamma  ` let X=T1 in t2 : T2 (TngTLet)

Evaluation rules t -! t0

let X=T in t -! E,X , TG*t (EngTLet)

Figure 9ng3: Adding definitions to the context

(*X::*. (*x:X.x+1)(4))[Nat]
is illngtyped because its subngterm *X::*. (*x:X.x+1)(4) is illngtyped.

We therefore extend F !*j by making definitions of type variables into a
primitive notion, resulting in the language *let shown in Figure 9ng3. The synng
tax of contexts is broadened to permit defined type variables, and the new
rule QngDef equates type variables with their definitions. Equivalence of wellng
formed types therefore depends upon definitions in the typing context. In
*let we can prove

X::*=Int ` Int!X j X!Int :: *
but not

X::*=Bool ` Int!X j X!Int :: *
or

X::* ` Int!X j X!Int :: *:
This is an immediate difference from ordinary F !*j, where type equivalence
can be determined by looking only at the two types involved (in this case,
Int!X and X!Int, which are never equal in F !*j).

Context validity is extended by the rule CTXngDef, which requires that defng
initions make sense in the preceding context. Consequently, type definitions

9.1 Definitions in the Typing Context 353
` \Pi 
` Nat :: *

...
\Gamma  ; x:X ` x : X

...
\Gamma  ; x:X ` X j Nat
\Gamma  ; x:X ` x : Nat

...
\Gamma  ; x:X ` 1 : Nat
\Gamma  ; x:X ` x+1 : Nat
\Gamma  ` *x:X. x+1 : X!Nat

...
\Gamma  ` 4 : Nat

...
\Gamma  ` X j Nat
\Gamma  ` Nat j X
\Gamma  ` 4 : X
\Gamma  ` (*x:X. x+1)(4) : Nat
` (let X=Nat in (*x:X. x+1)(4)) : Nat

Figure 9ng4: Typing of let X=Nat in (*x:X.x+1)(4), using \Gamma  defC^ X::*=Nat

in wellngformed contexts are never circular, which will ensure that all defining
tions can in principle be substituted away.1

The new kinding rule KngDef looks up the kind of a defined type variable,
paralleling the F !*j rule KngVar for type variables without definitions.

Definitions in the context are openngscope; they can be considered ambient
and usable anywhere. We can also use this mechanism to describe the typng
ing of primitive closedngscope (local) type definitions; the type checking rule
TngTLet puts the definition into the context for use while type checking a speng
cific term. Thus, for example, the code let X=Nat in (*x:X.x+1)(4) would
be wellngtyped in the presence of natural numbers and addition; a proof apng
pears in Figure 9ng4, where the omitted leaf proofs are uninteresting contextng
validity checks.

The following propositions collect a number of useful properties of *let.
They are all provable via induction on derivations.

9.1.1 Proposition [Weakening]:

1. If \Gamma 1; \Gamma 3 ` T :: K and \Gamma 1; \Gamma 2; \Gamma 3 ` \Pi  then \Gamma 1; \Gamma 2; \Gamma 3 ` T :: K.
2. If \Gamma 1; \Gamma 3 ` S j T :: K and \Gamma 1; \Gamma 2; \Gamma 3 ` \Pi  then \Gamma 1; \Gamma 2; \Gamma 2 ` S j T :: K. 2
1. The nonngcircularity requirement for context validity would not prevent T itself from being a
recursive type, as in the Nat and NatList examples, assuming recursive types were added to
the language.

354 9 Type Definitions

9.1.2 Proposition [Validity]:

1. If \Gamma  ` J for any judgment form J then \Gamma  ` \Pi .
2. If \Gamma 1; \Gamma 2 ` \Pi  then \Gamma 1 ` \Pi  and domD^\Gamma 1E^ " domD^\Gamma 2E^ C^ ;.
3. If \Gamma  ` T :: K then FVD^TE^ ` domD^\Gamma  E^.
4. If \Gamma  ` S j T :: K then \Gamma  ` S :: K and \Gamma  ` T :: K. 2

9.1.3 Proposition [Substitution]:

1. If \Gamma 1; X::K; \Gamma 2 ` J for any judgment form J and \Gamma 1 ` T :: K then \Gamma 1; E,X ,

TG*\Gamma 2 ` E,X , TG*J.

2. If \Gamma 1; X::K=S; \Gamma 2 ` J for any judgment form J and \Gamma 1 ` S j T :: K then

\Gamma 1; E,X , TG*\Gamma 2 ` E,X , TG*J.

3. If \Gamma 1; X::K; \Gamma 2 ` S :: L and \Gamma 1 ` T j T0 :: K then \Gamma 1; E,X , TG*\Gamma 2 ` E,X , TG*S j

E,X , T0G*S :: L. 2

9.1.4 Exercise [n'n', Recommended]: Explain why the type system would be unng

sound if the premise \Gamma  ` T2 :: * were omitted from TngTLet. 2

9.1.5 Exercise [n'n', Recommended]: Suppose we wanted to add primitive type defng

initions to the simplyngtyped calculus *!. What changes to that language would
be appropriate? 2

Deciding Equivalence
The hardest part of type checking in *let, as in F !, is deciding type equivang
lence. There are multiple ways to approach this. For example, we could define
a notion of reduction (and/or parallel reduction) that allows betangreduction
and allows a variable to be replaced by its definition, a step known as deltang
reduction.2 Such notions of reduction can be shown to be confluent and
normalizing (Severi and Poll, 1994), which provides a method for determinng
ing type equivalence: compute normal forms and check for equality up to
bound variables.

2. Some authors (e.g., Barendregt, 1984) instead use the name deltangreduction to refer to the
slightly different process of executing builtngin primitive operators, e.g., replacing 3+4 by 7 in a
language where addition and integer constants are taken as primitive.

9.1 Definitions in the Typing Context 355

If explicit definitions are being used to keep the representation small, howng
ever, then computing normal forms can be an expensive way to determine
type equivalence. For example, if we had definitions such as

Pair defC^ *Y::*.(Y * Y)
List defC^ *Y::*. (uX. <nil:Unit, cons:{Nat,X}>)

we would like to be able to determine that List(List(Pair(Nat))) and
List(List(Nat * Nat)) are equivalent without expanding them to their comng
mon (but noticeably larger) normal form. Although for arbitrary types we
might not be able to do any better, in practice code reuses the same defined
names and so simple shortngcircuiting heuristics can help.

One approach to avoiding explicit construction of normal forms involves
simultaneous reduction and comparison of the types using weak head reducng
tion, as discussed in Chapter 6. Instead of fully normalizing the types, only
the "outermost" applications or definitions are reduced. If the resulting types
turn out to have the same shape, then corresponding subngcomponents of the
types can be recursively compared. Conversely, if the two types are weak
head normalized but fail to have the same structure then the types are not
equivalent and the algorithm can shortngcircuit and report inequivalence.

Figure 9ng5 presents an algorithmic version of equivalence in this fashion.
The weak head normalization relation \Gamma  ` T1 + Tn specifies that there is
a finite sequence of types T1; : : : ; Tn with n >= 1 such that each weak head
reduces to the next, and such that Tn is weak head normal. Given \Gamma  and S
there is at most one T such that \Gamma  ` S + T.

The algorithmic type equivalence judgment \Gamma  ` S a T :: K holds if the
weak head normal forms of T1 and T2 are structurally equivalent; this is the
algorithmic equivalent to type equivalence for wellngformed types. As in Chapng
ter 6, extensional equivalence is implemented here for types with arrow kinds
by applying both sides to a fresh variable and checking for equivalent results.

Finally, the structural equivalence judgment \Gamma  ` T1 $ T2 " K implements
equivalence for weak headngnormal types only; T1 and T2 must have the same
shape and their subcomponents must be algorithmically equivalent. Then K
will be the common kind of T1 and T2. Given \Gamma  , S, and T, there is at most one
rule that can apply.

Conveniently, the correctness of this comparison algorithm can be shown
using the same logical relations proof as in Chapter 6 with only minor moding
fications. We here are interested in equivalence of types that are classified by
kinds, but this corresponds exactly to the problem considered in Chapter 6
of equivalence of terms classified by types. In particular, the kind * here corng
responds to the base type b from Chapter 6. Rewriting the logical equivalence

356 9 Type Definitions

Weak Head Reduction \Gamma  `n~ T ; T0

\Gamma  `n~ (*X::K11.T12)T2 ; E,X , T2G*T12

X::K=T 2 \Gamma 

\Gamma  `n~ X ; T
\Gamma  `n~ T1 ; T01
\Gamma  `n~ T1 T2 ; T01 T2

Weak head normalization \Gamma  `n~ T + T0

\Gamma  `n~ T ; S \Gamma  `n~ S + T0

\Gamma  `n~ T + T0

\Gamma  `n~ T 6;
\Gamma  `n~ T + T

Algorithmic type equivalence \Gamma  `n~ S a T :: K

\Gamma  `n~ S + S0 \Gamma  `n~ T + T0

\Gamma  `n~ S0 $ T0 " *

\Gamma  `n~ S a T :: *
\Gamma  ; X::K1 `n~ S X a T X :: K2 X 62 domD^\Gamma  E^

\Gamma  `n~ S a T :: K1)K2

Structural type equivalence \Gamma  `n~ S $ T " K

X::K 2 \Gamma 
\Gamma  `n~ X $ X " K
\Gamma  `n~ S1 a T1 " * \Gamma  `n~ S2 a T2 " *

\Gamma  `n~ S1!S2 $ T1!T2 " *
\Gamma  `n~ S1 a T1 " * \Gamma  `n~ S2 a T2 " *

\Gamma  `n~ S1 * S2 $ T1 * T2 " *
\Gamma  ; X::K1 `n~ S2 a T2 " * X 62 domD^\Gamma  E^

\Gamma  `n~ 8X::K1.S2 $ 8X::K1.T2 " *

\Gamma  `n~ S1 $ T1 " K1)K2

\Gamma  `n~ S2 a T2 :: K1

\Gamma  `n~ S1 S2 $ T1 T2 " K2

Figure 9ng5: Algorithmic equivalence with definitions

relation to refer to types and kinds (and simplifying it a bit, as we have no
"unit kind") yields:

9.1.6 Definition [Logical Equivalence]: Logical equivalence is defined as folng

lows:

\Gamma  ` S is T :: K if and only if either:

K=* and \Gamma  ` S a T :: *,
or K=K1)K2 and for all S0, T0, and for all \Gamma  0 ' \Gamma  ,

if \Gamma  0 ` S0 is T0 :: K1
then \Gamma  0 ` S S0 is T T0 :: K2. 2

Similarly, fl or ffi will now represent a substitutions mapping type variables
to types. Recall that flE,X , TG* is the substitution that agrees with fl except
that it maps X to the type T.

The biggest difference from Chapter 6 is that we must be more careful
about substitutions. The proof of the Fundamental Theorem of Logical Relang

9.1 Definitions in the Typing Context 357
tions will not go through if we allow substitutions that replace a defined type
variable by an unrelated type. (Specifically, the QngDef case would fail.) The
following definition builds in this restriction, while still being easy to show
symmetric and transitive:

9.1.7 Definition: \Gamma  0 ` fl is ffi :: \Gamma  if and only if

* For every X::K 2 \Gamma  we have \Gamma  0 ` flD^XE^ is ffiD^XE^ :: K.

* For every X::K=T 2 \Gamma  we have \Gamma  0 ` flD^XE^ is ffiD^XE^ :: K, \Gamma  0 ` flD^XE^ is

ffiD^TE^ :: K, and \Gamma  0 ` flD^TE^ is ffiD^XE^ :: K. 2

9.1.8 Exercise [n'n'n', Recommended]: Show how to adapt the methods of Chapng

ter 6 to prove that if \Gamma  ` S :: K and \Gamma  ` T :: K then it is decidable whether
\Gamma  ` S j T :: K in *let. 2

A major advantage of this variant algorithm is that it allows further refineng
ments. For example, an implementation might check for alphangequivalence
of corresponding components before reducing. Thus, a request to compare
List(T1) with List(T2) could directly check whether T1 and T2 are equivang
lent without expanding the definition of List.

One must be careful in trying to optimize, though, since the addition of
definitions alters usual properties of type equivalence. In F !*j the equivalence
X T1 j X T2 holds if and only if T1 j T2. In a *letngstyle language, however, we
can prove

X::(*)*)=(*Y::*.Nat) ` X Nat j X Bool
even though Nat and Bool are not equivalent--both applications are provng
ably equal to Nat. Therefore, although comparing X T1 with X T2 by showing
that T1 and T2 are equivalent may often be faster than expanding out a defng
inition for X, if the arguments are inequivalent we may need to consider the
expansion anyway.3

One might think to specialngcase variables like X above whose definitions
completely ignore their arguments, but similar behavior can arise more genng
erally.

9.1.9 Exercise [Recommended, n'n']: Find a typing context and pairwise inequivang

lent T1, T2, and T3 such that X T1 j X T2 but X T2 6j X T3 (and so X cannot
completely ignore its argument). 2

3. The presence of definitions has consequences for unification as well (e.g., in implementang
tions of ML type inference): the most general substitution making X T1 and X T2 equal might
not make T1 and T2 unify.

358 9 Type Definitions

If the simultaneous comparison process finds no shortngcuts, it will do work
equivalent to entirely normalizing and comparing the two types. It may still
be more memoryngefficient, however, than separate normalizations. Full norng
mal forms are not explicitly computed and stored; when two subcomponents
of the types are found to be equal their reduced forms can be immediately
discarded, freeing up memory for the rest of the comparison.

9.1.10 Exercise [n'n'n', 3]: Extend the fullomega checker to include definitions, and

make type equivalence checking as efficient as possible. 2

9.2 Definitions in Module Interfaces

In the presence of modules, type definitions are often permitted to appear
within interfaces. The most interesting aspect of the theory of MLngstyle modng
ule systems involves tracking information about the types involved, given
that type components in modules may have definitions that are not syntacting
cally apparent.

One line of research in formalizing the type theory of MLnglike module sysng
tems (as discussed in Chapter 8) led to the calculi known as translucent sums
(Harper and Lillibridge, 1994) and manifest types (Leroy, 1994). These similar
systems largely correspond to the module systems of Revised Standard ML
(Milner, Tofte, Harper, and MacQueen, 1997) and (with some extensions--see
Leroy [1995]) of Objective Caml.

The Language *L M
Figure 9ng6 defines a minimalist language *L M with secondngclass modules, based
on the calculus of Lillibridge (1997). Modules are not firstngclass values able
to be passed to termnglevel functions, and similarly interfaces are not types.
Though simpler than any module system usable in practice, *L M is still comng
plex enough to demonstrate many issues discussed in Chapter 8.

In ML, modules can contain any combination of named value, type, and
subngmodule components in any order. *L M instead builds up modules starting
with two primitives: modules that contain a single unnamed term, written
LtM, and modules that contain a single unnamed type, written LT::KM. The
contents of primitive modules can be extracted by using the ! operator.

For each sort of module, there are corresponding interfaces. The interface
LTM classifies primitive modules containing a value of type T, while the opaque
interface LKM classifies modules containing a type of kind K. Modules containng
ing types may also have a transparent interface LK=TM if they contain just the
type T (or a provably equivalent type) of kind K.

9.2 Definitions in Module Interfaces 359
*L M extends F !*j
Syntax

\Gamma  ::= . . . contexts:

m:I module variable
W ::= determinate modules:

m variable
LvM term module
LT::KM type module
LW,WM pairing
W.1 first projection
W.2 second projection
*m:I.M functor
Wv ::= module values:

LvM term module
LT::KM type module
LWv,Wv M pairing
*m:I.M functor
M ::= modules:

W determinates
LtM term module
LM,MM pairing
M.1 first projection
M.2 second projection
M M application
M :> I generative sealing
I ::= interfaces:

LTM term interface
LKM opaque interface
LK=TM transparent interface
\Sigma m:I.I pair interface
\Pi m:I.I functor interface
t ::= . . . terms:

!M module projection
T ::= . . . types:

!W module projection

Derived Forms
I1 * I2 defC^ \Sigma m:I1.I2 D^m 62 FVD^I2E^E^

I1 ! I2 defC^ \Pi m:I1.I2 D^m 62 FVD^I2E^E^
Context Validity \Gamma  ` \Pi 

\Gamma  ` I m 62 domD^\Gamma  E^

\Gamma  ; m:I ` \Pi  (CTXngMod)

WellngFormed Interface \Gamma  ` I

\Gamma  ` T :: *

\Gamma  ` LTM (IngTerm)

\Gamma  ` \Pi 
\Gamma  ` LKM (IngOpaque)
\Gamma  ` T :: K

\Gamma  ` LK=TM (IngTransp)
\Gamma  ; m:I1 ` I2
\Gamma  ` \Sigma m:I1.I2 (IngSigma)

\Gamma  ; m:I1 ` I2
\Gamma  ` \Pi m:I1.I2 (IngPi)

Subinterface \Gamma  ` I <: I0

\Gamma  ` T j T0 :: *

\Gamma  ` LTM <: LT0M (SIngTerm)

\Gamma  ` LKM <: LKM (SIngOpaque)
\Gamma  ` T j T0 :: K
\Gamma  ` LK=TM <: LK=T0M (SIngTransp)

\Gamma  ` T :: K
\Gamma  ` LK=TM <: LKM (SIngForget)

Figure 9ng6: Syntax, typing, and semantics for *L M

360 9 Type Definitions

Subinterface (continued) \Gamma  ` I <: I0

\Gamma  ` \Pi m:I11.I12
\Gamma  ` I21 j I11 \Gamma  ; m:I21 ` I12 <: I22

\Gamma  ` \Pi m:I11.I12 <: \Pi m:I21.I22 (SIngPi)

\Gamma  ` \Sigma m:I21.I22
\Gamma  ` I11 <: I21 \Gamma  ; m:I11 ` I12 <: I22

\Gamma  ` \Sigma m:I11.I12 <: \Sigma m:I21.I22

(SIngSigma)

Interface Equivalence \Gamma  ` I <: I0

\Gamma  ` I <: I0 \Gamma  ` I0 <: I

\Gamma  ` I j I0 (QIngEqv)

Kinding \Gamma  ` T :: K

\Gamma  ` W : LKM
\Gamma  ` !W :: K (KngMProj)

Type Equivalence \Gamma  ` S j T :: K

\Gamma  ` T :: K \Gamma  ` W : LK=TM

\Gamma  ` !W j T :: K (QngMProj)

WellngFormed Modules \Gamma  ` M : I

\Gamma  ` t : T
\Gamma  ` LtM : LTM (MngTerm)

\Gamma  ` T :: K
\Gamma  ` LT::KM : LK=TM (MngType)
\Gamma  ` M : I0 \Gamma  ` I0 <: I

\Gamma  ` M : I (MngSub)

\Gamma  ` \Pi  m:I 2 \Gamma 

\Gamma  ` m : I (MngVar)
\Gamma  ; m:I1 ` M2 : I2
\Gamma  ` *m:I1.M2 : \Pi m:I1.I2 (MngAbs)
\Gamma  ` M1 : I1 \Gamma  ` M2 : I2

\Gamma  ` LM1,M2M : I1 * I2 (MngPair)

\Gamma  ` M : \Sigma m:I1.I2

\Gamma  ` M.1 : I1 (MngFst)
\Gamma  ` M : I1 * I2

\Gamma  ` M.2 : I2 (MngSnd)
\Gamma  ` M1 : I1!I2 \Gamma  ` M2 : I1

\Gamma  ` M1 M2 : I2 (MngApply)

\Gamma  ` W : LKM
\Gamma  ` W : LK=!WM (MngSelf)

\Gamma  ` \Sigma m:I1.I2
\Gamma  ` W : \Sigma m:I01.I2 \Gamma  ` W.1 : II

\Gamma  ` W : \Sigma m:I1.I2 (MngSelf1)
\Gamma  ` W : \Sigma m:I1.I02 \Gamma  ` W.2 : I2

\Gamma  ` W : I1 * I2 (MngSelf2)

\Gamma  ` M : I
\Gamma  ` (M :> I) : I (MngSeal)

Typing \Gamma  ` t : T

\Gamma  ` M : LTM

\Gamma  ` !M : T (TngModngProj)

Figure 9ng6: Syntax, typing, and semantics for *L M, continued

9.2 Definitions in Module Interfaces 361
Module Evaluation M -! M0

t -! t0
LtM -! Lt0M (EMngTerm)

M1 -! M10
LM1,M2M -! LM01,M2M (EMngPair1)

M2 -! M20
LWv 1,M2M -! LWv 1,M2M (EMngPair2)

M1 -! M10
M1.1 -! M01.1 (EMngProj1)

M1 -! M10
M1.2 -! M01.2 (EMngProj2)
LWv1,Wv2M.1 -! Wv 1 (EMngPairBeta1)

LWv 1,Wv2M.2 -! Wv 2 (EMngPairBeta2)

M1 :> I2 -! M1 (EMngSeal)

M1 -! M01
M1 M2 -! M01 M2 (EMngApp1)

M2 -! M02
Wv M2 -! Wv M02 (EMngApp2)
(*m:I11.M12)Wv2 -! E,s , Wv2G*M12

(EMngAppAbs)

Term Evaluation t -! t0

M -! M0
!M -! !M0 (EngMProj)

!LvM -! v (EngMProjV)

Figure 9ng6: Syntax, typing, and semantics for *L M, continued

More complex modules can be created by using the modulenglevel pairing
operator L * , * M. The projection operators .1 and .2 then access the subng
modules within such a pair.

Interfaces of modulengpairs are given by specifying the interfaces of the
two submodules. However, in order to permit specifications such as "a modng
ule containing an abstract type and a term of that type," these interfaces
are allowed to be dependent. The interface \Sigma m:I1.I2 classifies module pairs
whose first component satisfies the interface I1 and whose second compong
nent satisfies I2, where the latter interface may refer to the contents of the
first component by the name m. (In the vocabulary of Chapter 8, m is an inng
ternal name for the first component of the module pair, while the external
names of the two components are always 1 and 2.)

For example, consider again the module n, defined by

module n = mod

type t = Nat
val x : t = 3
end

This is in essence a module containing a single type and a single term, and
hence can be encoded into *L M as

L LNat::*M, L3M M.

362 9 Type Definitions

This module satisfies the very precise interface

\Sigma m:L*=NatM. LNatM,
which describes it as containing the type Nat and a natural number. This
interface is completely equivalent to

\Sigma m:L*=NatM. L!mM,
which is an interface satisfied by modules containing the type Nat and a value
of that same type.

The encoding of n further matches the strictly more abstract (less informang
tive) interface

\Sigma m:L*M. L!mM
specifying only that the module contains some type and a value of that type.

Parameterized modules, or functors, are simply modulenglevel functions.
Thus, for example, the diag functor defined above can be encoded as

*m:(\Sigma m':L*M. L!m'M).

L L!m.1 * !m.1::*M, L{!m.2,!m.2}M M

The argument of this functor is required to be a module pair containing a
type and a value of that type (in subngmodules); it then returns a module pair
containing a pair type and a pair value (in subngmodules). By convention, first
and second projections bind most tightly, followed by applications, !, and
finally the binary operators such as * . Thus the type being returned by this
functor is (!(m.1)) * (!(m.1)).

Interfaces for functors are also dependent, because the types in the funcng
tor's result may depend upon the types contained in the functor's argument
value. The interface \Pi m:I1.I2 classifies functors that require an argument
satisfying I1 and which return a result satisfying I2, where I2 can involve the
argument value m. Thus, one possible mostngprecise interface describing the
encoded diag functor would be

\Pi m:(\Sigma m':L*M. L!m'M).

(\Sigma m":L*=!m.1 * !m.1M. L!m"M).

In both \Sigma m:I1.I2 and \Pi m:I1.I2 the variable m is bound in I2. In those
cases where m does not appear in I2 we can omit mention of the dependent
variable, writing nonngdependent pair interfaces as I1 * I2, and nonngdependent
functor interfaces as I1!I2.

The remaining module expression is the sealing operation M :> I. This is
the generative sealing operation of Chapter 8, taking a module M and hiding

9.2 Definitions in Module Interfaces 363
all information about that module except what is explicitly mentioned in the
interface I. This is used for informationnghiding purposes, in order to create
abstract (opaque) types.

The syntax separates out a syntactic set of modules which are determinate
(have type components that are predictable at compilengtime) in the terming
nology of Chapter 8. Only determinate modules are allowed in types. Some
nonngvalues (e.g., L LNat::*M, LBool::*M M.1) are syntactically determinate and
so can appear within types. This design results from the fact that we must
allow module projections such as !m.1 within types, yet it is desirable for the
syntax of types to be closed under replacements of variables by values (e.g.,
replacing m by L LNat::*M, LBool::*M M).4

Typing and Evaluation Rules
The static semantics of *L M appears in Figure 9ng6. The judgment \Gamma  ` I defines
the wellngformedness of interfaces, which requires all types in the interface
to be wellngformed. More interesting is the subinterface relation \Gamma  ` I <: I0,
which is nontrivial even though *L M has no subtyping relation. The key rule
here is SIngForget, which specifies that a module with a transparent interface
can be used as if it had the corresponding opaque interface; type definitions
in interfaces may be neglected when not relevant. Subtyping for other base
interfaces coincides with equivalence. For simplicity SIngPi specifies that interng
faces for functors are invariant in their domain (contravariance would be a
reasonable alternative), but otherwise the dependent interfaces are covariant.

9.2.1 Exercise [n']: Find a syntactically different (but equivalent) precise interface

for the diag functor above, and a strictly lessngprecise interface also satisfied
by diag. 2

9.2.2 Exercise [n', Recommended]: The language *L M has a subnginterface relation,

but no subtyping. Suppose we added this, e.g., with Nat <: Top. How should
the interfaces LNatM and LTopM be related? How about L*=NatM and L*=TopM? 2

Interface equivalence could be defined directly, but it is shorter as in rule
QIngEqv to define equivalent interfaces as being mutual subinterfaces.

*L M adds the single kinding rule KngMProj, stating that we can project from
a syntactically determinate module W to obtain a type as long as W is a module
whose interface guarantees that it contains a type. In this rule we need only

4. An alternative is to redefine substitution so that it reduces any new projectionsngfromngpairng
values introduced (Lillibridge, 1997).

364 9 Type Definitions

check that W has an opaque interface of the form LKM because by subsumption
and SIngForget, any module with a transparent interface also has an opaque
interface.

Type equivalence is extended as in *let, but the new rule QngMProj looks
for type definitions that occur in transparent interfaces rather than for type
definitions directly in the context.

The rules MngTerm and MngType give precise interfaces to the two sorts of
primitive modules; transparent interfaces can be weakened by subsumption
as specified in MngSub.

The rules MngVar through MngApply are similar to those in other systems
with dependent types. The only surprise might be the requirement of nonng
dependent interfaces in the rules MngSnd and MngApply. In many systems appling
cations of (or projections from) items whose classifier has dependencies can
be handled using substitution, but substitution of general modules may lead
to illngformed types, as only syntactically determinate modules may appear in
types.

The rule MngSelf is justified by the following observation: assume a determing
nate module W satisfies the interface LKM. Now consider the interface LK=!WM;
this is the interface of a module containing a single type, specifically the type
contained in W. Clearly W itself satisfies this description and hence ought to
have this latter interface. MngSelf ensures that this is always provable. The
rules MngSelf1 and MngSelf2 are similar, and allow the MngSelf rule to be apng
plied to submodules of a larger module. For example, by using all three rules
we can conclude

m : L*M * L*M ` m : L*=!m.1M * L*=!m.2M;
i.e., that if m is a module containing two types, then it satisfies an interface
requiring a pair containing the two types in m.

In the presence of the Self rules, the more usual dependent typing rules
are admissible for determinate modules (Lillibridge, 1997):

\Gamma  ` W : \Sigma m:I1.I2
\Gamma  ` W.2 : E,m , W.1G*I2 (MngSndW)
\Gamma  ` M1 : \Pi m:I1.I2 \Gamma  ` W2 : I1

\Gamma  ` M1 W2 : E,m , W2G*I2 (MngApplyW)
For example, suppose that we had M1 : \Pi m:L*M. L*=!m * !mM and W2 : L*M.
The interface of if M1 is dependent so we cannot directly use MngApply to
type check the application M1 W2, but we can show, using SIngPi, SIngForget,
SIngOpaque, and MngSub, that M1 satisfies the strictly less precise interface

9.2 Definitions in Module Interfaces 365
\Pi m:L*=!W2M. L*=!m * !mM and hence that M1 satisfies the equivalent interface
\Pi m:L*=!W2M. L*=!W2 * !W2M, i.e., we have that M1 : L*=!W2M ! L*=!W2 * !W2M.
Now by MngSelf we have W2 : L*=!W2M, so the premises of MngApply are satisfied
and we obtain M1 W2 : L*=!W2 * !W2M, exactly as the admissible rule MngApplyW
predicts.

Finally, the MngSeal rule is an explicit form of subsumption hiding all inforng
mation not mentioned in the specified interface. The module

LLNat::*M,L3MM
has the very precise interface L*=NatM * LNatM, allowing the contents of its
second projection to be used as a natural number. In contrast, the sealed
module

LLNat::*M,L3MM :> \Sigma m0:L*M.L!m0M
must be checked as having only the more abstract interface \Sigma m0:L*M.L!m0M.
This enforces abstraction; we know that we could change this line to

LLBool::*M,LtrueMM :> \Sigma m0:L*M.L!m0M
and any code using the module would continue to type check.

The evaluation relation for modules looks very much like the evaluation
relation for any lambda calculus with pairs. The one completely new rule
is EMngSeal. This sealing operation is generative and affects type checking
by mimicking the creation of a fresh abstract type whenever the sealing opng
eration is performed, but once we have checked that abstraction is being
respected we can ignore the sealing; when the program begins running it has
no observable effect.

Type Equivalence and Type Checking
The translucent sums calculus suffers from the avoidance problem discussed
in Chapter 8, and hence fails to have mostngspecific interfaces.

9.2.3 Exercise [n'n'n']: Find a *L M module that (even up to equivalence) does not

have a mostngprecise interface. 2

This makes type checking difficult, though in practice programs can often be
restricted to subsets guaranteed to have principal interfaces. Leroy (1996),
for example, considers modules restricted to named form where every subexng
pression has a name. Thus, instead of writing

(*m::L*M. m) ( LLNat::*M, LBool::*MM.2 )

366 9 Type Definitions

Natural interface \Gamma  `n~ W " I

m:I 2 \Gamma 
\Gamma  `n~ m " I
\Gamma  `n~ LT::KM " LK=TM
\Gamma  `n~ W1 " \Sigma m:I1.I2

\Gamma  `n~ W1.1 " I1
\Gamma  `n~ W1 " \Sigma m:I1.I2
\Gamma  `n~ W1.2 " E,m , W1.1G*I1

Weak head reduction \Gamma  `n~ T ; T0

\Gamma  `n~ !W " LK=TM

\Gamma  `n~ !W ; T
\Gamma  `n~ !(LW1,W2M.1) ; !W1
\Gamma  `n~ !(LW1,W2M.2) ; !W2
\Gamma  `n~ (*X::K11.T12)T2 ; E,X , T2G*T12

\Gamma  `n~ T1 ; T01
\Gamma  `n~ T1 T2 ; T01 T2

Figure 9ng7: Algorithmic equivalence for *L M

we must assign names to all intermediate module computations, e.g.:

let m1 = *m::L*M. m
in let m2 = LNat::*M

in let m3 = LBool::*M

in let m4 = Lm2, m3M

in let m5 = m4.2

in let m = m1 m5

in ...

Given these restrictions, every module has a mostngspecific interface.

Even in the absence of mostngspecific interface, however, type equivalence
remains decidable. A similar comparison algorithm to that for *let will work,
except that now it is module projections of the form !W that may have defining
tions. For example, if m : L*M * L*=NatM then !m.2 is known to be equivalent
to Nat.

When does !W have a definition? A necessary, though not sufficient, conng
dition is that W have a transparent interface. For example, starting from the
bare assumptions that m1 : L*M and m2 : L*=!m1M (which would be the case
if m1 were a module containing an abstract type, and m2 were defined as beng
ing m1), then intuitively !m2 has as its definition the abstract type !m1, while
!m1 itself has no definition. Using MngSelf, though, we can further show that
m1 : L*=!m1M. For the purposes of an algorithm, it is not useful to say that !m1
has itself as a definition.

In general, the MngSelf rule allows more equations to be added to the interng
faces of determinate modules, but never introduces any "new" information.
It therefore is irrelevant when trying to detect definitions, and this leads to
the notion of the natural interface of a module. The natural interface is the

9.3 Singleton Kinds 367
mostngprecise interface that can be computed without using the rule MngSelf.
We say that the type !W has the definition T if its natural interface is a transng
parent interface LK=TM. Figure 9ng7 defines an algorithmic judgment \Gamma  `n~ W " I
for computing the natural interface I given \Gamma  and W. Figure 9ng7 then extends
weak head reduction to reduce type projections from determinate modules.

Algorithmic and structural type equivalence are not shown, as they are
very similar to the definition for *let; the only difference would be that strucng
tural type equivalence must be extended to equate !W (where !W is weak head
normal) with itself.

9.2.4 Exercise [n', 3]: Verify that according to the definition of weak head reducng

tion shown in Figure 9ng7 we have m : (\Sigma m0:L*M.L*=!m0M) `n~ !m.2 + !m.1. 2

Proofs of properties of module languages such as *L M can quickly become
difficult, however, because the type equivalence relation now is defined in
terms of all the other judgments of the static semantics, including wellng
formedness of modules (via QngMProj) and hence on wellngformedness of terms.
However, soundness and decidability results have been shown for systems
closely related to *L M(Lillibridge, 1997; Dreyer, Crary, and Harper, 2003).

9.3 Singleton Kinds

In *let, definitions were recorded with a new sort of context entry. Instead
of just listing the kinds of type variables, contexts could additionally specify
definitions. Definitions in *L M were similar, but the choice between kind and
kindngwithngdefinition was in module interfaces.

In general, wherever a language normally requires a kind, we could allow
either the kind or the kind and a specific type. For example, we could extend
F !*j with a new sort of polymorphic abstraction, written, *X::K1=T1.t2, that
is allowed to be instantiated only with the argument T1 (or an equivalent
type).

With this mechanism, we could now express type definitions in terms of
polymorphic instantiation. The derived form becomes

let X=T1 in t2 defC^ (*X::K1=T1.t2) [T1]
where K1 is the kind of T1. The constraint on the function argument--namely
that the value passed in for X will be T1--is enough to type check the function
body. This definition repeats the type T1, but the result still can be signifing
cantly smaller than E,X , T1G*t2.

Minamide, Morrisett, and Harper (1996) used this idea for the purposes of
polymorphic closure conversion. The goal was to turn both free term varing
ables and free type variables of functions into arguments; this was useful in

368 9 Type Definitions

the context of a typengpassing interpretation of polymorphism (Tarditi et al.,
1996) where types are computed and analyzed at run time. By using restricted
polymorphic abstractions, they were able to preserve wellngformedness when
pulling types out of function bodies.

The cases where this sort of construct is genuinely useful are probably rare,
but rather than trying to predict exactly where definitions will and will not
be needed, the more general approach is to permit definitions at all points
where type variables appear. One natural formulation of this idea augments
the kinds themselves to include definitions.

The singleton kind S(T::K) classifies exactly those types of kind K provably
equivalent to T. For example, the kind S(int * int :: *) classifies all types
that are provably equivalent to the type of pairs of integers; up to equivang
lence there is exactly one such type. Then instead of choosing between a kind
specification Y::* or a kindngandngdefinition specification Y::*=Nat, we specify
either Y::* or Y::S(Nat :: *).

Figure 9ng8 defines *S, an alternate variant of F !*j including singleton kinds.
Because the changes are pervasive, the type and kind judgments are shown
in full rather than just listing additions to F !*j.

The builtngin singleton kinds in *S are of the form S(T) where T is restricted
to be an ordinary type of kind *. We will show later, however, that more
general singleton kinds of the form S(T::K) are nevertheless expressible.

The types of *S include ordinary types, type operators, and (to permit exng
pressiveness similar to that of *L M) pairs of types. The addition of singletons
allows kinds to refer to types, and thus it is natural to permit the kinds clasng
sifying type operators or pairs of types to be dependent. The kind \Sigma X::K1.K2
classifies pairs whose first component has kind K1 and second component
has kind K2, where K2 can use the type variable X to refer to the value of the
first component. In the case where K2 does not mention X, we can abbreving
ate this to K1 * K2. Thus, for example, we give the pair of types (a collection
of two types, not the single type for a pair of values) {Nat,Nat} the kind
* * * stating simply that it is a pair of types, or give it the very precise kind
S(Nat) * S(Nat), i.e., that we have a pair of types whose components are
both equal to Nat, or an inngbetween kind such as \Sigma X::*. S(X), i.e., that we
have a pair of types whose first component has kind *, and whose second
component is the same as the first, or S(Nat) * *, i.e., that the first type is
Nat and the second is some proper type, and so on.

Similarly, the kind \Pi X::K1.K2 classifies type operators that take an argung
ment X of kind K1 and return a result of kind K2, where K2 can depend on the
argument X. If K2 does not mention X then the kind can be written K1)K2.

Thus, possible kinds for the identity function *X::*.X on types will include
the familiar *)* as well as the very precise kind \Pi X::*. S(X), stating that,

9.3 Singleton Kinds 369
*S extends F !*j
Syntax

K ::= kinds:

* kind of proper types
S(T) singleton kind
\Pi X::K.K kind of type operators
\Sigma X::K.K kind of pairs of types
T ::= types:

X type variable
T!T type of functions
T * T type of pairs of terms
8X::K.T universal type
*X::K.T type operator abstraction
T T type operator application
{T,T} pair of types
ss1 T first projection
ss2 T second projection

Derived Forms
K1 * K2 defC^ \Sigma X::K1.K2 D^X 62 FVD^K2E^E^
K1 ) K2 defC^ \Pi X::K1.K2 D^X 62 FVD^K2E^E^

Kind validity \Gamma  ` K

\Gamma  ` \Pi 

\Gamma  ` * (WKng*)
\Gamma  ` T :: *

\Gamma  ` S(T) (WKngSing)
\Gamma  ; X::K1 ` K2
\Gamma  ` \Pi X::K1.K2 (WKngPi)

\Gamma  ; X::K1 ` K2
\Gamma  ` \Sigma X::K1.K2 (WKngSigma)

Subkinding \Gamma  ` K <: L

\Gamma  ` \Pi 
\Gamma  ` * <: * (SKng*)
\Gamma  ` S j T :: *
\Gamma  ` S(S) <: S(T) (SKngSing)

\Gamma  ` T :: *
\Gamma  ` S(T) <: * (SKngForget)

\Gamma  ` L1 <: K1
\Gamma  ; X::L1 ` K2 <: L2

\Gamma  ` \Pi X::K1.K2

\Gamma  ` \Pi X::K1.K2 <: \Pi X::L1.L2 (SKngPi)

\Gamma  ` K1 <: L1
\Gamma  ; X::K1 ` K2 <: L2

\Gamma  ` \Sigma X::L1.L2

\Gamma  ` \Sigma X::K1.K2 <: \Sigma X::L1.L2 (SKngSigma)

Kind Equivalence \Gamma  ` K j L

\Gamma  ` K <: L \Gamma  ` L <: K

\Gamma  ` K j L (QKngEqv)

Kinding rules \Gamma  ` T :: K

X::K 2 \Gamma  \Gamma  ` \Pi 

\Gamma  ` X :: K (KngVar)
\Gamma  ` T :: *
\Gamma  ` T :: S(T) (KngSIntro)
\Gamma  ; X::K1 ` T2 :: K2
\Gamma  ` *X::K1.T2 :: \Pi X::K1.K2 (KngAbs)
\Gamma  ` T1 :: \Pi X::K1.K2 \Gamma  ` T2 :: K1

\Gamma  ` T1 T2 :: E,X , T2G*K2 (KngApp)

Figure 9ng8: Singleton kinds

370 9 Type Definitions

Kinding rules (continued) \Gamma  ` T :: K

\Gamma  ` T1 :: * \Gamma  ` T2 :: *

\Gamma  ` T1!T2 :: * (KngArrow)
\Gamma  ` T1 :: * \Gamma  ` T2 :: *

\Gamma  ` T1 * T2 :: * (KngTimes)
\Gamma  ; X::K1 ` T2 :: *
\Gamma  ` 8X::K1.T2 :: * (KngAll)

\Gamma  ` \Sigma X::K1.K2
\Gamma  ` T1 :: K1 \Gamma  ` T2 :: E,X , T1G*K2

\Gamma  ` {T1,T2} :: \Sigma X::K1.K2 (KngPair)

\Gamma  ` T :: \Sigma X::K1.K2

\Gamma  ` ss1 T :: K1 (KngFst)
\Gamma  ` T :: \Sigma X::K1.K2
\Gamma  ` ss2 T :: E,X , ss1 TG*K2 (KngSnd)

\Gamma  ` T :: \Pi X::K1.L
\Gamma  ; X :: K1 ` T(X) :: K2 X 62 FVD^TE^

\Gamma  ` T :: \Pi X::K1.K2

(KngAbsSelf)
\Gamma  ` T :: \Sigma X::K01.K2 \Gamma  ` ss1 T :: K1

\Gamma  ` T :: \Sigma X::K1.K2

(KngSelf1)
\Gamma  ` T :: \Sigma X::K1.K02 \Gamma  ` ss2 T :: K2

\Gamma  ` T :: K1 * K2

(KngSelf2)
\Gamma  ` T :: K1 \Gamma  ` K1 <: K2

\Gamma  ` T :: K2 (KngSub)

Equivalence rules \Gamma  ` S j T :: K

\Gamma  ` T :: K
\Gamma  ` T j T :: K (QngRefl)
\Gamma  ` T j S :: K
\Gamma  ` S j T :: K (QngSym)

\Gamma  ` S j U :: K \Gamma  ` U j T :: K

\Gamma  ` S j T :: K (QngTrans)
\Gamma  ` S1 j T1 :: \Pi X::K1.K2

\Gamma  ` S2 j T2 :: K1

\Gamma  ` S1 S2 j T1 T2 :: E,X , S1G*K2 (QngApp)

\Gamma  ` S j T :: \Sigma X::K1.K2

\Gamma  ` ss1 S j ss1 T :: K1 (QngFst)
\Gamma  ` S j T :: \Sigma X::K1.K2
\Gamma  ` ss2 S j ss2 T :: E,X , ss1 SG*K2 (QngSnd)

\Gamma  ` \Sigma X::K1.K2
\Gamma  ` S1 j T1 :: K1
\Gamma  ` S2 j T2 :: E,X , S1G*K2

\Gamma  ` {S1,S2} j {T1,T2} :: \Sigma X::K1.K2 (QngPair)

\Gamma  ` K1 j K2 \Gamma  ; X :: K1 ` S2 j T2 :: K2
\Gamma  ` *X::K1.S2 j *X::K2.T2 :: \Pi X::K1.K2

(QngAbs)
\Gamma  ` K1 j K2 \Gamma  ; X :: K1 ` T1 j T2 :: *

\Gamma  ` 8X::K1.T1 j 8X::K2.T2 :: *

(QngAll)
\Gamma  ` S :: S(T)

\Gamma  ` S j T :: S(S) (QngSElim)

\Gamma  ` \Sigma X::K1.K2
\Gamma  ` ss1S j ss1T :: K1
\Gamma  ` ss2S j ss2T :: E,X , ss1 SG*K2

\Gamma  ` S j T :: \Sigma X::K1.K2 (QngPairngExt)
\Gamma  ` S :: \Pi X::K1.L1 \Gamma  ` T :: \Pi X::K1.L2

\Gamma  ; X :: K1 ` S X j T X :: K2

\Gamma  ` S j T :: \Pi X::K1.K2

(QngExt)
\Gamma  ` S j T :: L \Gamma  ` L <: K

\Gamma  ` S j T :: K (QngSub)

Figure 9ng8: Singleton kinds, continued

9.3 Singleton Kinds 371
given any type X of kind *, the function returns a result equal to X. There are
infinitely many other possibilities as well, including S(Nat))S(Nat), which
states that the function can be applied to the type Nat and will return the
same type Nat.

Every type of kind S(T) is, by the definition of *S, also a proper type of
kind *. This induces a subkinding relation with S(T) <: * for any type T. Subng
kinding between singleton kinds coincides with equivalence, and subkinding
is lifted to the kinds of functions and of pairs in the normal way; e.g., function
kinds are contravariant in their argument and covariant in their result.

9.3.1 Exercise [n']: The language *S has subkinding but not subtyping. If subtypng

ing were added, with Nat <: Top, then how should the kinds S(Nat) and
S(Top) be related? 2

The wellngformedness rules for types are mostly the familiar rules for a
dependentlyngtyped (or, in this case, dependentlyngkinded) lambda calculus with
functions and pairs. Five rules stand out for special consideration, however.
Rule KngSub is a subsumption rule that makes use of the subkinding rule; a
type with a morengprecise kind can also be used as a type with a lessngprecise
kind. Rule KngSIntro is the introduction rule for singleton kinds. This rule alng
lows a wellngformed type T of kind * to be given the more precise singleton
kind S(T).

Rules KngSelf1 and KngSelf2 serve the same purpose as MngSelf1 and MngSelf2
in the translucent sum calculus, while KngAbsSelf serves a similar purpose
for kinds of type operator abstractions. In most type systems all three rules
would be admissible, but here they allow more precise typings. For examng
ple, suppose Y is a pair of types, that is, Y::* * *. Now consider the kind
S(ss1 Y) * S(ss2 Y); i.e., the kind of pairs of types whose first component is
equal to the first component of Y, and whose second component is equal
to the second component of Y. Regardless of whether the language includes
etangequivalence for types (*S does), Y itself should satisfy this latter kind.
Rules KngSelf1 and KngSIntro allow us to conclude that Y : S(ss1 Y) * *, and
then KngSelf2 and KngSIntro allow us to further prove Y : S(ss1 Y) * S(ss2 Y).

Similarly, assume Z :: *)*. The kind \Pi X::*. S(Z X) classifies all type opng
erators that, when given a type argument X, yield the same result as Z does
when given X. Again, Z itself has this property and rule KngAbsSelf is used to
prove it.

Collectively, the three Self rules ensure that types have every kind that
their etangexpansions do.

Rules QngRefl through QngAll are standard for a lambda calculus with deng
pendencies; they insure that definitional equivalence is a congruence on wellng
formed types. Rule QngSElim is the elimination rule for singleton kinds, letting

372 9 Type Definitions

us make use of the fact that a type has a singleton kind. Rules QngPairngExt
and QngExt yield extensionality: componentwisengequivalent pairs are equivng
alent and pointwisengequivalent functions are equivalent. Finally, we have a
subsumption rule for equivalence, QngSub, corresponding to the subsumption
rule for typing.

The addition of singleton kinds has more consequences for equivalence
than might appear at first. An attentive reader may have noticed that the
definition of type equivalence omits the betangreduction rule for function apng
plications and the two standard rules for reducing projections from pairs. A
surprising fact about languages with singletons, noticed by Aspinall (1994),
is that other elimination rules can become admissible (i.e., if the premises are
provable using the above rules then so is the conclusion):

\Gamma  ` T1 :: K1 \Gamma  ` T2 :: K2

\Gamma  ` ss1 {T1,T2} j T1 :: K1 (QngBetangFst)
\Gamma  ` T1 :: K1 \Gamma  ` T2 :: K2

\Gamma  ` ss2 {T1,T2} j T2 :: K2 (QngBetangSnd)
\Gamma  ; X::K1 ` T12 :: K12 \Gamma  ` T2 :: K12
\Gamma  ` (*X::K11.T12)T2 j E,X , T2G*T12 :: E,X , T2G*K12 (QngAppAbs)
More importantly (since we would have added betangequivalence had it not
been admissible), the kind at which two types are compared can determine
whether or not they are equivalent. Types do not have unique kinds, and a
pair of types can be equivalent at one kind but not another.

For example, consider the identity function on types, *X::*.X, and the
constant function *X::*.Nat. There is no way to prove the judgment

(*X::*.X) j (*X::*.Nat) :: (*)*):
However, by subsumption both functions also have the kind S(Nat))*, and
at this kind we can prove

` (*X::*.X) j (*X::*.Nat) :: (S(Nat))*):
Viewed as functions that will only be applied to the argument Nat, the two
functions do return the same result Nat. By extensionality, then, the two funcng
tions are equivalent at kind S(Nat))*.

Using this result and Rule QngApp we can further show that

Y :: (S(Nat))*))* ` Y(*X::*.X) j Y(*X::*.Nat) :: *:
In this equivalence judgment, both sides are normal with respect to beta and
etangreduction. Y itself has no obvious definition that can be expanded away.
Nevertheless, equivalence remains decidable; one algorithm appears below.

9.3 Singleton Kinds 373

S(T :: *) defC^ S(T)
S(T :: S(T0)) defC^ S(T)
S(T :: \Pi X::K1.K2) defC^ \Pi X::K1.S(T X :: K2) where X 62 FVD^TE^

S(T :: \Sigma X::K1.K2) defC^ S(ss1 T :: K1) * S(ss2 T :: E,X , ss1 TG*K2)

Figure 9ng9: Labeled singleton kinds

Singletons at Higher Kinds
In *let the context could contain definitions for type operators, for example
Y :: (*)*) = (*X::*.X!X). We cannot directly represent this definition as
Y :: S(*X::*.X!X) because the kind S(T) is wellngformed only for types T of
kind *.

Using extensionality, however, more general singletons are definable. For
example, one can show that the kind

\Pi X::*.S(X!X)
classifies all type operators that are equivalent to *X::*.X!X at kind *)*.

More generally, whenever T :: K holds we can define the kind of types
equivalent to T at kind K as a derived form, written S(T :: K). Again the kind
classifier is crucial, since the function *X::*.X should have kind

S((*X::*.Nat) :: S(Nat))*)
but not kind

S((*X::*.Nat) :: *)*):
Figure 9ng9 defines labeled singleton kinds S(T::K) by induction on the size
of the classifying kind K. The sizes of kinds are defined as follows:

sizeD^*E^ defC^ 1
sizeD^S(T)E^ defC^ 2
sizeD^\Sigma X::K1.K2E^ defC^ 1 + sizeD^K1E^ + sizeD^K2E^
sizeD^\Pi X::K1.K2E^ defC^ 1 + sizeD^K1E^ + sizeD^K2E^

An easy inductive proof shows that substitutions have no effect on the size
of kinds, and hence the labeled singleton kinds in Figure 9ng9 are wellngdefined.

These labeled singletons behave exactly as one would expect. To show this,
we start with some basic facts about *S.

374 9 Type Definitions

9.3.2 Proposition [Weakening]: 1. If \Gamma 1; \Gamma 3 ` J for any *S judgment form J and

\Gamma 1; \Gamma 2; \Gamma 3 ` \Pi  then \Gamma 1; \Gamma 2; \Gamma 3 ` J.

2. If \Gamma 1; X::K; \Gamma 2 ` J and \Gamma 1 ` L <: K then \Gamma 1; X::L; \Gamma 2 ` J. 2
9.3.3 Proposition [Substitution]:

1. If \Gamma 1; X::K; \Gamma 2 ` J for any judgment form J and \Gamma 1 ` T :: K then \Gamma 1; E,X ,

TG*\Gamma 2 ` E,X , TG*J.

2. If \Gamma 1; X::K; \Gamma 2 ` S :: L and \Gamma 1 ` T j T0 :: K then \Gamma 1; E,X , TG*\Gamma 2 ` E,X , TG*S j

E,X , T0G*S :: E,X , TG*L. 2

9.3.4 Proposition [Validity]:

1. If \Gamma  ` T :: K then FVD^TE^ [ FVD^KE^ ` domD^\Gamma  E^.
2. If \Gamma 1; \Gamma 2 ` \Pi  then \Gamma 1 ` \Pi  and domD^\Gamma 1E^ " domD^\Gamma 2E^ C^ ;.
3. If \Gamma  ` K then \Gamma  ` \Pi .
4. If \Gamma  ` T :: K then \Gamma  ` K.
5. If \Gamma  ` S j T :: K then \Gamma  ` S :: K and \Gamma  ` T :: K. 2

At this point we can consider properties of the labeled singletons themng
selves.

9.3.5 Proposition: E,X , SG*D^S(T :: K)E^ C^ S(E,X , SG*T :: E,X , SG*K). 2

Proof: By induction on the size of K. 2
9.3.6 Proposition [Labeled Singletons]: 1. If \Gamma  ` T :: K then \Gamma  ` T :: S(T::K).

2. If \Gamma  ` S :: S(T :: K) and \Gamma  ` T :: K then \Gamma  ` S j T :: K.
3. If \Gamma  ` S j T :: K and \Gamma  ` K <: L then \Gamma  ` S(S::K) <: S(T::L).
4. If \Gamma  ` T :: K then \Gamma  ` S(T::K) <: S(T::S(T::K)). 2
Proof: We show the proof of just the first part, which follows by induction
on the size of K. Assume \Gamma  ` T :: K.

Case: K C^ *, so S(T::K) C^ S(T).
Then \Gamma  ` S :: S(T) by Rule KngSIntro.

9.3 Singleton Kinds 375
Case: K C^ S(S), so S(T::K) C^ S(T).
By Proposition 9.3.4(5) we have \Gamma  ` S(S), so by inversion of Rule WKngSing we
have \Gamma  ` S :: *. Therefore \Gamma  ` S(S) <: *, and so by KngSub we have \Gamma  ` T :: *
and hence \Gamma  ` T :: S(T) by KngSIntro.

Case: K C^ \Pi X::K1.K2, so S(T::K) C^ \Pi X::K1.S(T X :: K2).
By Proposition 9.3.4(5) and inversion we have \Gamma  ; X::K1 ` \Pi , so by Proposing
tion 9.3.2(1) and KngApp, \Gamma  ; X::K1 ` T X :: K2. By the inductive hypothesis,
\Gamma  ; X::K1 ` T X :: S(T X :: K2). Thus by Rule KngAbsSelf we have \Gamma  ` T ::
\Pi X::K1.S(T X :: K2) as desired.

Case: K C^ \Sigma X::K1.K2, so S(T::K) C^ S(ss1 T :: K1) * S(ss2 T :: E,X , ss1 TG*K2)
By KngFst and KngSnd and the inductive hypothesis, we have \Gamma  ` ss1 T ::
S(ss1 T :: K1) and \Gamma  ` ss2 T :: S(ss2 T :: E,X , ss1 TG*K2). Therefore, by
Rules KngSelf1 and KngSelf2 the desired result follows. 2

9.3.7 Exercise [n'n']: Prove Part 2 of Proposition 9.3.6. Why do we need the extra

assumption \Gamma  ` T :: K ? 2

At this point, it is not too hard to show that the Beta rules are admissible,
as there is a natural proof involving labeled singletons.

9.3.8 Exercise [n'n', Recommended]: Prove that rules QngBetangFst, QngBetangSnd, and

QngAppAbs are admissible. 2

Aspinall (1994) took a slightly different approach to formalizing a lanng
guage with singletons. His language *<={} included only a very restricted form
of extensionality. The encoding of labeled singletons used here was thus
unavailable, and labeled singletons were therefore made primitive language
constructs.5 The properties of Proposition 9.3.6 are then axioms describng
ing the behavior of these primitive singletons. In this formulation, Proposing
tion 9.3.6(4) is necessary to have principal kinds; otherwise

* :> S(Nat::*)

:> S(Nat::S(Nat::*))
:> S(Nat::S(Nat::S(Nat::*)))
:> * * *

would be an infinite sequence of increasingly morengprecise kinds for Nat.

An interesting consequence of making labeled singletons primitive is that
Aspinall was able to define the equivalence judgment \Gamma  ` S j T :: K as
syntactic sugar for the judgment \Gamma  ` S :: S(T :: K); there was not a separate
collection of rules defining the equivalence judgment.

5. More precisely, Aspinall studied term equivalence in a language with singleton types, but
the ideas apply just as well for type equivalence with singleton kinds.

376 9 Type Definitions

A disadvantage of making labeled singletons primitive rather than relying
on extensionality is that mostngprecise classifiers can be large. For example, in
an Aspinallngstyle system the mostngprecise kind of *X::*.*Y::*.X would be

S((*X::*.*Y::*.X) ::

\Pi X::*.S((*Y::*.X) :: (\Pi Y::*.S(X :: *))))

rather than

\Pi X::*. \Pi Y::*. S(X)
as in *S. The advantages are not entirely onengsided; S(Z :: *)*)*) seems
simpler than the *S kind \Pi Y1::*.\Pi Y2::*.S(Z Y1 Y2).

Algorithmic Type Equivalence
Figure 9ng10 shows an algorithmic version of equivalence for wellngkinded *S
types. The general framework is very similar to that for *let and *L M.

First of all, there is a judgment for computing "natural kinds" in analogy
with the natural interfaces for modules in Figure 9ng7. These are the mostng
precise kind available without using singleton introduction rules, and a type
has a definition T if its natural kind is a singleton S(T).

The algorithmic equivalence relation is defined by induction on the clasng
sifying kind: type operators are compared by applying both sides to a fresh
variable (to determine if they are pointwise equivalent), while pairs of types
are compared componentwise. Types of kind * are headngnormalized and comng
pared structurally very much as before. Finally, types with singleton kinds are
easy to compare because of the precondition that the two types actually have
the kind at which they are being compared; any two types of kind S(T) are
equivalent to T and hence equivalent to each other.

Viewed as an algorithm with inputs \Gamma  , S, and T, the structural equivalence
judgment both compares S and T and determines the natural kind of S. This
kind is used only to determine the kind at which to compare arguments of
two irreducible applications.

Finally, there is a kind equivalence algorithm, necessary since kinds can
contain types, and hence can be equivalent without being identical.

9.3.9 Exercise [n'n', Recommended]: Show that

Y::(S(Nat))*))* `n~ Y(*X::*.X) a Y(*X::*.Nat) :: *
is provable, but

Y::(*)*))* `n~ Y(*X::*.X) a Y(*X::*.Nat) :: *
is not. 2

9.3 Singleton Kinds 377
Natural kind \Gamma  `n~ T " K

X::K 2 \Gamma 
\Gamma  `n~ X " K
\Gamma  `n~ T1 " \Pi X::K1.K2
\Gamma  `n~ T1 T2 " E,X , T2G*K2

\Gamma  `n~ T1 " \Sigma X::K1.K2

\Gamma  `n~ ss1 T1 " K1
\Gamma  `n~ T1 " \Sigma X::K1.K2
\Gamma  `n~ ss2 T2 " E,X , ss1 T1G*K2

Weak head reduction \Gamma  `n~ T ; T0

\Gamma  `n~ T " S(T0)

\Gamma  `n~ T ; T0
\Gamma  `n~ (*X::K11.T12)T2 ; E,X , T2G*T12

\Gamma  `n~ ss1 {T1,T2} ; T1
\Gamma  `n~ ss2 {T1,T2} ; T2

\Gamma  `n~ T1 ; T01
\Gamma  `n~ T1 T2 ; T01 T2

\Gamma  `n~ T1 ; T01
\Gamma  `n~ ss1 T1 ; ss1 T01

\Gamma  `n~ T1 ; T01
\Gamma  `n~ ss2 T1 ; ss2 T01

Head Normalization \Gamma  `n~ S + T

\Gamma  `n~ S ; S0 \Gamma  `n~ S0 + T

\Gamma  `n~ S + T

\Gamma  `n~ S 6;
\Gamma  `n~ S + S

Type Equivalence \Gamma  `n~ S $ T :: K

\Gamma  `n~ S + S0 \Gamma  `n~ T + T0

\Gamma  `n~ S0 $ T0 " *

\Gamma  `n~ S a T :: *
\Gamma  `n~ S a T :: S(T0)

X 62 domD^\Gamma  E^
\Gamma  ; X::K1 `n~ S X a T X :: K2

\Gamma  `n~ S a T :: \Pi X::K1.K2

\Gamma  `n~ ss1 S a ss1 T :: K1
\Gamma  `n~ ss2 S a ss2 T :: E,X , ss1 SG*K2

\Gamma  `n~ S a T :: \Sigma X::K1.K2

Structural Type Equivalence \Gamma  `n~ S $ T " K

X::K 2 \Gamma 
\Gamma  `n~ X $ X " K
\Gamma  `n~ S1 a T1 :: * \Gamma  `n~ S2 a T2 :: *

\Gamma  `n~ S1!S2 $ T1!T2 " *
\Gamma  `n~ S1 a T1 :: * \Gamma  `n~ S2 a T2 :: *

\Gamma  `n~ S1 * S2 $ T1 * T2 " *
\Gamma  `n~ K1 a L1 X 62 domD^\Gamma  E^

\Gamma  ; X::K1 `n~ S2 a T2 :: *

\Gamma  `n~ 8X::K1.S2 $ 8X::L1.T2 " *

\Gamma  `n~ S1 $ T1 " \Pi X::K1.K2

\Gamma  `n~ S2 a T2 :: K1

\Gamma  `n~ S1 S2 $ T1 T2 " E,X , S2G*K2

\Gamma  `n~ S1 $ T1 " \Sigma X::K1.K2

\Gamma  `n~ ss1 S1 $ ss1 T1 " K1
\Gamma  `n~ S1 $ T1 " \Sigma X::K1.K2
\Gamma  `n~ ss2 S1 $ ss2 T1 " E,X , ss1 S1G*K2

Kind Equivalence \Gamma  `n~ K a L

\Gamma  `n~ * a *
\Gamma  `n~ S a T :: *
\Gamma  `n~ S(S) a S(T)
\Gamma  `n~ K1 a K2 X 62 domD^\Gamma  E^

\Gamma  ; X::K1 `n~ K2 a L2

\Gamma  `n~ \Pi X::K1.K2 a \Pi X::L1.L2

\Gamma  `n~ K1 a K2 X 62 domD^\Gamma  E^

\Gamma  ; X::K1 `n~ K2 a L2

\Gamma  `n~ \Sigma X::K1.K2 a \Sigma X::L1.L2

Figure 9ng10: Algorithmic equivalence for *S

378 9 Type Definitions

The equivalence algorithm is correct and terminating for wellngformed types:
9.3.10 Fact: Assume \Gamma  ` S :: K and \Gamma  ` T :: K. Then \Gamma  `n~ S a T :: K if and only if

\Gamma  ` S j T :: K. Furthermore, the judgment \Gamma  `n~ S a T :: K is always decidable
(i.e, proof search will terminate whether or not S and T are equivalent). 2

The correctness of this equivalence algorithm is nontrivial. The approach
suggested in Chapter 6 does not directly apply because there is no a priori
reason to believe that algorithmic equivalence is symmetric and transitive.
The problem is in the "asymmetry" of the rules. The structural equivalence
judgment \Gamma  `n~ S $ T " K computes the natural kind K of S as it goes along,
but might have just as well computed the natural kind of T instead. Although
we the two natural kinds turn out to be provably equivalent, this does not
guarantee that the algorithm is unaffected--kinds in the classifier end up in
the context, which can affect how later weak head normalizations proceed,
which could a priori result in a different answer or affect termination.

If the algorithm cannot be shown directly to be symmetric or transitive,
then a logical equivalence relation defined as for *let cannot directly be
shown to be symmetric or transitive. Stone and Harper (2000; 2005) showed,
however, that variants of Kripke logical relations can be used to prove the
correctness of closelyngrelated algorithms, from which the correctness of the
above algorithm can be derived.

PhasengSplitting
*L M added secondngclass modules to a language and in so doing increased
the number of sorts of entities in the language: modules and interfaces, in
addition to the prengexisting terms, types, and kinds. Interestingly, modules
and interfaces can sometimes be decomposed into uses of terms, types, and
kinds. Some compilers for Standard ML (Petersen, Cheng, Harper, and Stone,
2000; Shao, 1997, 1998) even implement modules using this technique.

The translation is possible if the module system has a phase distinction, as
discussed in Chapter 8: types in modules must depend only on other types.
*L M appears to violate this requirement, as the type !W may involve term
values. Similarly, a functor application M1 M2 can yield a module containing
types, and the result syntactically appears to depend on all of M2, which can
contain terms.

As observed by Harper, Mitchell, and Moggi (1990), however, the depenng
dency of types on the terms in modules is illusory. References to modules in
types really involve only the type components of that module; all else is irrelng
evant. Similarly, in a functor application M1 M2 the types returned to depend
only on types defined in M1 and types defined in M2; there is no way that the
terms in these modules can affect the resulting types.

9.3 Singleton Kinds 379

It is therefore possible to split every module into a type part and a term
part, referred to here as the static and dynamic parts of the module; the
former can be represented as a type (perhaps of a higher kind), and the latter
as a term (potentially polymorphic).

A module containing many types and many values would split into a colng
lection of types (not to be confused with the type of a tuple of terms) and
a collection of values. In parallel, a functor application can be split into an
application of types (the type part of the functor applied to the type part of
the argument) and an application of a polymorphic term (the term part of the
functor applied to both the type part of the argument and the term part of
the argument). For example, the functor

module diag = *(p : sig

type t
val x : t
end).
mod

type u = p.t * p.t
val y : u = {p.x, p.x}
end

which we encoded in *L M as

*m:(\Sigma m':L*M. L!m'M). L L!m.1 * !m.1M, L{!m.2,!m.2}M M
could have its behavior with respect to producing types modeled by the
type operator *X::*. X * X, since diag takes a type in its argument and
returns a corresponding pair type in its result. Similarly, the behavior of
diag in producing terms can be modeled as the polymorphic abstraction
*X::*. *x:X. {x,x}, representing that it takes a type and a term of that
type in the argument, and that it returns a pair value.

Interfaces can be split correspondingly into a kind classifying the static
portion of the module, and a type classifying the dynamic portion of the
module. For example, a specification

diag : (\Pi m:(\Sigma m':L*M. L!m'M). (\Sigma m":L*=!m.1 * !m.1M. L!m"M))
could be split into two specifications for the static and dynamic parts of diag:

diags :: \Pi X::*. S(X * X)
and

diagd : 8X::*. X ! diags(X).
Equations in *L M interfaces become singleton kinds after phasengsplitting.

Figure 9ng11 specifies a formal translation from *L M into *S. For simplicity,
the translation maintains the invariant that every module and every interface

380 9 Type Definitions
Modules

|m|s := Xm |m|d := xm
|LtM|s := S0 |LtM|d := v
|LT::KM|s := |T| |LT::KM|d := t0
|LM1,M2M|s := { |M1|s, |M2|s } |LM1,M2M|d := { |M1|d, |M2|d }
|M.1|s := ss1(|M|s) |M.1|d := ss1(|M|d)
|M.2|s := ss2(|M|s) |M.2|d := ss2(|M|d)
|*m:I.M|s := *Xm:|I|s.|M|s |*m:I.M|d := *Xm:|I|s.

*xm:|I|d(Xm).

|M|d
|M1 M2|s := |M1|s |M2|s |M1 M2|d := (|M1|d [|M2|s]) |M2|d
|M :> I|s := |M|s |M :> I|d := |M|d

Interfaces

|LTM|s := K0 |LTM|d(Ts) := |T|
|LKM|s := K |LKM|d(Ts) := T0
|LK=TM|s := S(|T| :: K) |LK=TM|d(Ts) := T0
|\Pi m:I1.I2|s := \Pi Xm::|I1|s. |\Pi m:I1.I2|d(Ts) := 8Xm::|I1|s.

|I2|s [if Xm 62 FVD^TsE^] |I1|d(Xm) !

(|I2|d(Ts Xm))
|\Sigma m:I1.I2|s := \Sigma Xm::|I1|s. |\Sigma m:I1.I2|d(Ts) := |I1|d(ss1 Ts) *

|I2|s (E,Xm , ss1 TsG*|I2|d(ss2 Ts))

Types and Contexts

|X| := X |*| := *
|T1!T2| := |T1| ! |T2| |\Gamma  ; X::K| := |\Gamma  |; X::K
|T1 * T2| := |T1| * |T2| |\Gamma  ; x:T| := |\Gamma  |; x:|T|
|8X::K1.T2| := 8X::K1.|T2| |\Gamma  ; m:I| := |\Gamma  |; Xm::|I|s;
|*X::K1.T2| := *X::K1.|T2| xm:|I|d(Xm)
|T1 T2| := |T1| |T2|
|!W| := |W|s

Terms

|x| := x |{t1,t2}| := { |t1|, |t2| }
|*x:T.t| := *x:|T|.|t| |t.1| := |t|.1
|t1 [t2]| := |t1| [ |t2| ] |t.2| := |t|.2
|*X::K.t| := *X::K.|t| |!M| := |M|d
|t1 T2| := |t1| |T2|

Figure 9ng11: Phasengsplitting translation

9.3 Singleton Kinds 381
has static and dynamic parts. Since *L M contains primitive modules that conng
tain only terms or only types, the translation uses an arbitrary term t0 of
some type T0 to represent the dynamic part of a module containing only a
type (an obvious choice for t0 would be the value of type Unit), and uses an
arbitrary type S0 of kind K0 representing the static part of a module containng
ing only a term.

Also, for every module variable m we assume there exists a type variable Xm
and a term variable xm. These will be bound to the static and dynamic parts
respectively of whatever m would have been bound to in the original code.

Figure 9ng11 begins by defining |M|s, which is a type expression containng
ing all the types in the module M. In most cases this is straightforward. The
static part of a module variable m is the corresponding type variable Xm; the
static part of a module containing the type T is T itself, or more precisely, the
translation of T, which eliminates occurrences of modules (see below). The
static part of the first or second projection from a module pair is the first or
second projection the pair's static part. The static part of an application is
the application of its static parts.

The static part of a sealed module is defined to be the static part of the
underlying module; generative sealing is the one construct in *L M with no
direct equivalent in *S. The *S language has no abstraction mechanism, and
there is no easy way to add a generative construct to its equational theory
of types. However, since sealing has no dynamic effect it is possible to take a
wellngformed *L M term and erase all occurrence of sealing, yielding a wellngtyped
and behaviorallyngequivalent term. Implementations of *L M based on phaseng
splitting typically first do type checking in *L M to ensure that abstraction is
being respected, and then erase the sealing as they perform phasengsplitting.

The definition |M|d of the dynamic part of a module M is similar. The dyng
namic part of a functor is parameterized both by the static part of the argung
ment and the dynamic part, since values returned by a functor can depend
both on the types in the argument and the values in the argument. Modng
ule applications then turn into the corresponding polymorphic instantiation
followed by an application.

The static part |I|s of a module interface I is a kind describing the types
in any module satisfying I. Singleton kinds are used to describe equations
found in transparent interfaces.

The dynamic part of a module interface is more interesting. The values
in a module may be describable only in terms of the types in the module.
For example, after phasengsplitting the dynamic part of a module of interface
\Sigma m:L*M.L!mM (a module containing an abstract type and a value of that type)
can only be described as containing a value whose type is contained in the
static part of that same module. The definition of the dynamic part of an inng

382 9 Type Definitions

terface, |I|d(Ts), is therefore defined in terms of both the interface I and
the static part Ts of a module satisfying I. Such a static part is available wherng
ever the dynamic part of an interface is needed. For example, the definition of
the dynamic part of a functor module with argument interface I is a polymorng
phic function requiring in succession both Xm (the static part of the functor's
argument) and a valid dynamic part for a module with that static part, i.e., a
value of type |I|d(Xm).

Recall that the static part of a module application is the application of
the static parts. Therefore, when computing the dynamic part of an interface
\Pi m:I1.I2, we know that the module being returned satisfies the interface I2
and that the static part of the module being returned is the static part of this
functor applied to the static part of the functor argument. Thus, the type of
the value returned by the dynamic part is |I2|d(Ts Xm), where Ts is the static
part of the functor as a whole.

Similarly, if we have a module pair with interface \Sigma m:I1.I2 having static
part Ts, then the static parts of the components are ss1 Ts and ss2 Ts respecng
tively. Further, since I2 may contain freengoccurrences of m, its dynamic part
may refer to Xm. Xm stands for the static part of (i.e., the types in) in the
module's first component, so we can replace it by ss1 Ts, the static part of
the module's first component. No similar substitution is needed for xm; the
dynamic part of I2 is still a type and cannot contain term variables.

The translation of |T| of a type is very simple. Phasengsplitting is possing
ble because references to modules in types just involve the types in these
modules. We can therefore replace all module projections of the form !W by
the static part |W|s of W. Similarly, the translation of a term goes through
and translates all types, and replaces every projection !M of a value from a
module by the dynamic part of M.

The translation of a context translates types, leaves kinds alone (since *L M
kinds do not contain types, terms, or variables), and replaces every assumpng
tion of a module variable m with assumptions for the two corresponding varing
ables Xm and xm.

9.3.11 Exercise [n'n', Recommended]: Compute the static and dynamic parts for

the *L M definition of the diag functor. How do these differ from the intuitive
translations given above? 2

We can show that this transformation turns wellngformed *L M code into wellng
formed *S code. We distinguish proofs in the two languages *L M and *S by
writing `LM and `S respectively.

9.3.12 Lemma: If Y 62 FVD^IE^ then |I|d(Ts) C^ E,Y , TsG*|Id|(Y). 2

9.3 Singleton Kinds 383
9.3.13 Theorem [PhasengSplitting]:

1. If \Gamma  `LM \Pi  then |\Gamma  | `S \Pi .
2. If \Gamma  `LM T :: K then |\Gamma  | `S |T| :: K.
3. If \Gamma  `LM S j T :: K then |\Gamma  | `S |S| j |T| :: K.
4. If \Gamma  `LM t : T then |\Gamma  | `S |t| : |T|.
5. If \Gamma  `LM I then |\Gamma  | `S |I|s, and if further Y 62 domD^\Gamma  E^ and Y 6C^ Xm for every

m then |\Gamma  |; Y::|I|s `S |I|d(Y) :: *.

6. If \Gamma  `LM I1 <: I2 then |\Gamma  | `S |I1|s <: |I2|s and if further Y 62 domD^\Gamma  E^ and

Y 6C^ Xm for every m then |\Gamma  |; Y::|I1|s `S |I1|d(Y) j |I2|d(Y) :: *.

7. If \Gamma  `LM I1 j I2 then |\Gamma  | `S |I1|s <: |I2|s and if further Y 62 domD^\Gamma  E^ and

Y 6C^ Xm for every m then |\Gamma  |; Y::|I1|s `S |I1|d(Y) j |I2|d(Y) :: *.

8. If \Gamma  `LM M : I then |\Gamma  | `S |M|s :: |I|s and |\Gamma  | `S |M|d : |I|d(|M|s). 2
Proof: By induction on derivations and cases on the last rule used. Two repng
resentative cases are sketched here.

Case IngSigma: \Gamma  `LM \Sigma m:I1.I2 because \Gamma  ; m:I1 `LM I2.
By the inductive hypothesis, |\Gamma  |; Xm::|I1|s; xm:|I1|d(Xm) `S |I2|s. Inspecng
tion of *S shows that terms variables have no effect on the wellngformedness of
kinds, so we have |\Gamma  |; Xm::|I1|s `S |I2|s and hence
|\Gamma  | `S \Sigma Xm::|I1|s.|I2|s. That is, |\Gamma  | `S |\Sigma m:I1.I2|.

Also by the inductive hypothesis |\Gamma  |; Xm::|I1|s; xm:|I1|d(Xm); Y2:|I2|s `S
|I2|d(Y2) :: * where Y2 is fresh. By Proposition 9.3.2(1) and the observang
tion that term variables have no effect on the wellngformedness of types, we
have |\Gamma  |; Y::(\Sigma Xm::|I1|s.|I2|s); Xm::|I1|s; Y2:|I2|s `S |I2|d(Y2) :: *.
By Proposition 9.3.3(1), |\Gamma  |; Y::(\Sigma Xm::|I1|s.|I2|s); Y2:E,Xm , ss1 YG*|I2|s `S
E,Xm , ss1 YG*|I2|d(Y2) :: *. By Lemma 9.3.12 and Proposition 9.3.3(1),
|\Gamma  |; Y::(\Sigma Xm::|I1|s.|I2|s) `S E,Xm , ss1 YG*|I2|d(ss2 Y) :: *. That is,
|\Gamma  |; Y::(\Sigma Xm::|I1|s.|I2|s) `S |\Sigma m:I1.I2|d(Y) :: *.

Case MngSelf2: \Gamma  `LM W : I1 * I2 because \Gamma  `LM W : \Sigma m:I1.I02 and \Gamma  `LM W.2 :
I2.

By the inductive hypothesis, |\Gamma  | `S |W|s :: \Sigma Xm::|I1|s.|I02|s and |\Gamma  | `S
ss2 |W|s :: |I2|s. By Rule KngSelf2, then, |\Gamma  | `S |W|s :: |I1|s * |I2|s. That
is, |\Gamma  | `S |W|s :: |I1 * I2|s. Similarly, by the inductive hypothesis we have
|\Gamma  | `S |W|d : |I1|d(ss1 |W|s) * : : : and |\Gamma  | `S ss2 |W|d : |I2|d(ss2 |W|s).
Since *S has no subtyping and terms can be shown to have unique types up to
equivalence, it follows that |\Gamma  | `S |W|d : |I1|d(ss1 |W|s) * |I2|d(ss2 |W|s).
That is, |\Gamma  | `S |W|d : |I1 * I2|d(|W|s). 2

384 9 Type Definitions

Many variations on the phasengsplitting transformation are possible. Also,
instead of relying on singleton kinds, type definitions can be eliminated durng
ing phasengsplitting. This approach is taken by the FLINT compiler for Stanng
dard ML (Shao, 1998).

If the source language *L Mis modified to make \Pi  interfaces contravariant in
their domains, then to type check the result we either need to add a limited
form of subtyping in *S (in addition to the subkinding that already exists),
or to insert explicit type coercions (BreazungTannen, Coquand, Gunter, and
Scedrov, 1991) This last approach is taken by the TILT compiler for Standard
ML (Petersen, Cheng, Harper, and Stone, 2000).

9.3.14 Exercise [n'n', Recommended]:

1. Suppose we add terms of the form let m=M in t to *L M, allowing modules

to be defined locally within terms. Can the phasengsplitting algorithm be
extended to handle such terms?

2. Suppose we added a conditional expression at the module level to *L M,

if t then M else M0. Can the phasengsplitting algorithm be extended to hanng
dle these modules? 2

9.3.15 Exercise [n'n'n'n', 3]: Formally specify a method for obtaining more optimized

*S code corresponding to *L M inputs. For example, the diag functor encoded
in *L M might split into *X::*. X * X and *X::*. *x:X. {x,x} as originally
suggested. Verify that your optimization preserves wellngformedness of code,
in analogy with Theorem 9.3.13. 2

9.4 Notes

Primitive definitions are permitted in most implementations of *ngcalculusng
based systems. The AUTOMATH system (de Bruijn, 1980; van Daalen, 1980),
for example, relied vitally on definitions, as do modern systems such as Coq
(Barras et al., 1997). Most directly related to the system *let is the work of
Severi and Poll (1994), who studied a pure type system supporting primitive
definitions at all levels. They observed that one might wish to permit primng
itive definitions for items (e.g., kinds) even if the language does not include
operators parameterized by such items. Their decidability proof is not based
on logical relations, but instead defines a rewrite rule implementing betang
delta reduction, which they show to be confluent and strongly normalizing.

For many references on the theory of module systems, see Chapter 8; the
presentation of *L M is most similar to that of Lillibridge (1997) and Dreyer,
Crary, and Harper (2003).

9.4 Notes 385

Aspinall (1994) suggested that if types are viewed as program specificang
tions, then singleton types would allow very specific specifications (e.g., reng
quiring that a particular function not only map natural numbers to natural
numbers, but that it compute factorials; the function could be specified as beng
gin a member of a singleton type, namely the type of all terms equivalent to
a reference implementation for factorial). He presented a system of labeled
singleton types with betangequivalence and a limited form of extensionality
for lambda abstractions. Stone and Harper (2000) proved decidability of a
system essentially equivalent to *S, and later simplified their proof (Stone
and Harper, 2005). Coquand, Pollack, and Takeyama (2003) took a different
approach to deciding equivalence in the presence of singletons and extensionng
ality; their algorithm is based on etangexpanding and expanding definitions,
followed by a comparison for betangequivalence.

Courant (2002) has studied a system with labeled singleton types but no
extensionality principles at all; then equivalence depends on the typing conng
text but not the classifier at which the comparison is taking place, and so
it was possible to use a more traditional approach to equivalence by proving
confluence and strongngnormalization of a rewrite relation similar to that used
by Severi and Poll.

P a r t V
Type Inference
10 The Essence of ML Type Inference

Franc,ois Pottier and Didier Re'my

10.1 What Is ML?

The name ML appeared during the late seventies. It then referred to a generalng
purpose programming language that was used as a metanglanguage (whence its
name) within the theorem prover LCF (Gordon, Milner, and Wadsworth, 1979).
Since then, several new programming languages, each of which offers several
different implementations, have drawn inspiration from it. So, what does ML
stand for today?

For a semanticist, ML might stand for a programming language featuring
firstngclass functions, data structures built out of products and sums, mutang
ble memory cells called references, exception handling, automatic memory
management, and a callngbyngvalue semantics. This view encompasses the Stanng
dard ML (Milner, Tofte, and Harper, 1990) and Caml (Leroy, 2000) families of
programming languages. We refer to it as MLngthengprogrammingnglanguage.

For a type theorist, ML might stand for a particular breed of type systems,
based on the simplyngtyped *ngcalculus, but extended with a simple form of
polymorphism introduced by let declarations. These type systems have deng
cidable type inference; their type inference algorithms strongly rely on firstng
order unification and can be made efficient in practice. Besides Standard ML
and Caml, this view encompasses programming languages such as Haskell
(Peyton Jones, 2003) and Clean (Brus, van Eekelen, van Leer, and Plasmeijer,
1987), whose semantics is rather different--indeed, it is nonstrict and pure
(Sabry, 1998)--but whose type system fits this description. We refer to it as
MLngthengtypengsystem. It is also referred to as the HindleyngMilner type discipline
in the literature.

Code for this chapter may be found on the book's web site.

390 10 The Essence of ML Type Inference

For us, ML might also stand for the particular programming language whose
formal definition is given and studied in this chapter. It is a core calculus feang
turing firstngclass functions, local definitions, and constants. It is equipped
with a callngbyngvalue semantics. By customizing constants and their semanng
tics, one may recover data structures, references, and more. We refer to this
particular calculus as MLngthengcalculus.

Why study MLngthengtypengsystem today, such a long time after its initial disng
covery? One may think of at least two reasons.

First, its treatment in the literature is often cursory, because it is considng
ered either as a simple extension of the simplyngtyped *ngcalculus (TAPL, Chapng
ter 9) or as a subset of Girard and Reynolds' System F (TAPL, Chapter 23).
The former view is supported by the claim that local (let) definitions, which
distinguish MLngthengtypengsystem from the simplyngtyped *ngcalculus, may be unng
derstood as a simple textual expansion facility. However, this view tells only
part of the story, because it fails to give an account of the principal types
property enjoyed by MLngthengtypengsystem, leads to a naive type inference alng
gorithm whose time complexity is exponential not only in the worst case
but in the common case, and breaks down when the language is extended
with side effects, such as state or exceptions. The latter view is supported by
the fact that every type derivation within MLngthengtypengsystem is also a valid
type derivation within an implicitlyngtyped variant of System F. Such a view is
correct but again fails to give an account of type inference for MLngthengtypeng
system, since type inference for System F is undecidable (Wells, 1999).

Second, existing accounts of type inference for MLngthengtypengsystem (Milner,
1978; Damas and Milner, 1982; Tofte, 1988; Leroy, 1992; Lee and Yi, 1998;
Jones, 1999) often involve heavy manipulations of type substitutions. Such
a ubiquitous use of type substitutions is often quite obscure. Furthermore,
actual implementations of the type inference algorithm do not explicitly mang
nipulate substitutions; instead, they extend a standard firstngorder unification
algorithm, where terms are updated in place as new equations are discovered
(Huet, 1976; Martelli and Montanari, 1982). Thus, it is hard to tell, from these
accounts, how to write an efficient type inference algorithm for MLngthengtypeng
system. Yet, in spite of the increasing speed of computers, efficiency remains
crucial when MLngthengtypengsystem is extended with expensive features, such
as Objective Caml's object types (Re'my and Vouillon, 1998), variant types
(Garrigue, 1998), or polymorphic methods (Garrigue and Re'my, 1999).

Our emphasis on efficiency might come as a surprise, since type inference
for MLngthengtypengsystem is known to be dexptimengcomplete (Kfoury, Tiuryn,
and Urzyczyn, 1990; Mairson, Kanellakis, and Mitchell, 1991). In practice,
however, most implementations of it behave well. This apparent contradicng
tion may be explained by observing that types usually remain small and

10.1 What Is ML? 391
that let constructs are never deeply nested towards the left. Indeed, unng
der the assumption that types have bounded size and that programs have
bounded "scheme depth," type inference may be performed in quasinglinear
time (McAllester, 2003). In MLngthengprogrammingnglanguage, algebraic data type
definitions allow complex data structures to be described by concise expresng
sions, such as "list X," which helps achieve the boundedngtypengsize property.

In fact, in such favorable circumstances, even an inefficient algorithm may
behave well. For instance, some deployed implementations of type inference
for MLngthengtypengsystem contain sources of inefficiency (see remark 10.1.21
on page 404) and do not operate in quasinglinear time under the boundedng
typengsize assumption. However, such implementations are put under greater
stress when types become larger, a situation that occurs in some programs
(Saha, Heintze, and Oliva, 1998) and also arises when large, transparent type
expressions are used instead of algebraic data types, as in Objective Caml's
objectngoriented fragment (Re'my and Vouillon, 1998).

For these reasons, we believe it is worth giving an account of MLngthengtypeng
system that focuses on type inference and strives to be at once elegant and
faithful to an efficient implementation, such as Re'my's (1992a). In this presenng
tation, we forego type substitutions and instead put emphasis on constraints,
which offer a number of advantages.

First, constraints allow a modular presentation of type inference as the
combination of a constraint generator and a constraint solver, allowing sepng
arate reasoning about when a program is correct and how to check whether
it is correct. This perspective has long been standard in the setting of the
simplyngtyped *ngcalculus: see, for example, Wand (1987b) and TAPL, Chapng
ter 22. In the setting of MLngthengtypengsystem, such a decomposition is prong
vided by the reduction of typability problems to acyclic semingunification probng
lems (Henglein, 1993; Kfoury, Tiuryn, and Urzyczyn, 1994). This approach,
however, was apparently never used in production implementations of MLng
thengprogrammingnglanguage. An experimental extension of SML/NJ with polyng
morphic recursion (Emms and LeiSS, 1996) did reduce type inference to a
semingunification problem. Semingunification found applications in the closely
related area of program analysis; see, for example, Fa"hndrich, Rehof, and Das
(2000) and Birkedal and Tofte (2001). In this chapter, we give a constraintng
based description of a "classic" implementation of MLngthengtypengsystem, which
is based on firstngorder unification and a mechanism for creating and instanng
tiating principal type schemes.

Second, it is often natural to define and implement the solver as a conng
straint rewriting system. The constraint language allows reasoning not only
about correctness--is every rewriting step meaningngpreserving?--but also
about lownglevel implementation details, since constraints are the data strucng

392 10 The Essence of ML Type Inference

x; y ::= Identifiers:

z Variable
m Memory location
c Constant
t ::= Expressions:

x Identifier
*z:t Function
t t Application
let z C^ t in t Local definition
v; w ::= Values:

z Variable

m Memory location
*z:t Function
c v1 : : : vk Data

c 2 Q+ ^ k <= aD^cE^
c v1 : : : vk Partial application

c 2 Q- ^ k < aD^cE^
E ::= Evaluation Contexts:

E,G* Empty context
E t Left side of an application
v E Right side of an application
let z C^ E in t Local definition

Figure 10ng1: Syntax of MLngthengcalculus

tures manipulated throughout the type inference process. For instance, deng
scribing unification in terms of multingequations allows reasoning about the
sharing of nodes in memory, which a substitutionngbased approach cannot
account for. Last, constraints are more general than type substitutions, and
allow smooth extensions of MLngthengtypengsystem with recursive types, rows,
subtyping, and more. These arguments are developed, for example, in Jouanng
naud and Kirchner (1991).

Before delving into the details of this new presentation of MLngthengtypeng
system, it is worth recalling its standard definition. Thus, in what follows,
we first define the syntax and operational semantics of MLngthengcalculus, and
equip it with a type system, known as Damas and Milner's type system.

MLngthengCalculus
The syntax of MLngthengcalculus is defined in Figure 10ng1. It is made up of sevng
eral syntactic categories.

Identifiers group several kinds of names that may be referenced in a prong
gram: variables, memory locations, and constants. We let x and y range over
identifiers. Variables--also called program variables, to avoid ambiguity--are
names that may be bound to values using * or let binding forms; in other
words, they are names for function parameters or local definitions. We let
z and f range over program variables. We sometimes write for a program
variable that does not occur free within its scope: for instance, * :t stands for
*z:t, provided z is fresh for t. (We say that z is fresh for t when z does not ocng

10.1 What Is ML? 393
cur free in t.) Memory locations are names that represent memory addresses.
They are used to model references (see Example 10.1.9 below). Memory locang
tions never appear in source programs, that is, programs that are submitted
to a compiler. They only appear during execution, when new memory blocks
are allocated. Constants are fixed names for primitive values and operations,
such as integer literals and integer arithmetic operations. Constants are elng
ements of a finite or infinite set Q. They are never subject to ffngconversion,
in contrast to variables and memory locations. Program variables, memory
locations, and constants belong to distinct syntactic classes and may never
be confused.

The set of constants Q is kept abstract, so most of our development is
independent of its concrete definition. We assume that every constant c has
a nonnegative integer arity aD^cE^. We further assume that Q is partitioned into
subsets of constructors Q+ and destructors Q-. Constructors and destructors
differ in that the former are used to form values, while the latter are used to
operate on values.

10.1.1 Example [Integers]: For every integer n, one may introduce a nullary conng

structor ^n. In addition, one may introduce a binary destructor ^+, whose apng
plications are written infix, so t1 ^+ t2 stands for the double application ^+ t1
t2 of the destructor ^+ to the expressions t1 and t2. 2

Expressions--also known as terms or programs--are the main syntactic catng
egory. Indeed, unlike procedural languages such as C and Java, functional
languages, including MLngthengprogrammingnglanguage, suppress the distinction
between expressions and statements. Expressions consist of identifiers, *ng
abstractions, applications, and local definitions. The *ngabstraction *z:t repreng
sents the function of one parameter named z whose result is the expression t,
or, in other words, the function that maps z to t. Note that the variable z is
bound within the term t, so (for instance) the notations *z1:z1 and *z2:z2
denote the same entity. The application t1 t2 represents the result of calling
the function t1 with actual parameter t2, or, in other words, the result of
applying t1 to t2. Application is leftngassociative, that is, t1 t2 t3 stands for
D^t1 t2E^ t3. The construct let z C^ t1 in t2 represents the result of evaluating
t2 after binding the variable z to t1. Note that the variable z is bound within
t2, but not within t1, so for instance let z1 C^ z1 in z1 and let z2 C^ z1 in z2
are the same object. The construct let z C^ t1 in t2 has the same meaning as
D^*z:t2E^ t1, but is dealt with in a more flexible way by MLngthengtypengsystem. To
sum up, the syntax of MLngthengcalculus is that of the pure *ngcalculus, extended
with memory locations, constants, and the let construct.

Values form a subset of expressions. They are expressions whose evaluang
tion is completed. Values include identifiers, *ngabstractions, and applications

394 10 The Essence of ML Type Inference

of constants, of the form c v1 : : : vk, where k does not exceed c's arity if c
is a constructor, and k is smaller than c's arity if c is a destructor. In what
follows, we are often interested in closed values--ones that do not contain
any free program variables. We use the metangvariables v and w for values.

10.1.2 Example: The integer literals : : : ; d-1; ^0; ^1; : : : are nullary constructors, so they

are values. Integer addition ^+ is a binary destructor, so it is a value, and
so is every partial application ^+ v. Thus, both ^+ ^1 and ^+ ^+ are values. An
application of ^+ to two values, such as ^2^+^2, is not a value. 2

10.1.3 Example [Pairs]: Let D^*; *E^ be a binary constructor. If t1 are t2 are expresng

sions, then the double application D^*; *E^ t1 t2 may be called the pair of t1
and t2, and may be written D^t1; t2E^. By the definition above, D^t1; t2E^ is a value
if and only if t1 and t2 are both values. 2

Stores are finite mappings from memory locations to closed values. A store
u represents what is usually called a heap, that is, a collection of values,
each of which is allocated at a particular address in memory and may contain
pointers to other elements of the heap. MLngthengprogrammingnglanguage allows
overwriting the contents of an existing memory block--an operation someng
times referred to as a side effect. In the operational semantics, this effect is
achieved by mapping an existing memory location to a new value. We write IJ
for the empty store. We write uE,m , vG* for the store that maps m to v and
otherwise coincides with u. When u and u0 have disjoint domains, we write
uu0 for their union. We write domD^uE^ for the domain of u and rangeD^uE^ for
the set of memory locations that appear in its codomain.

The operational semantics of a pure language like the *ngcalculus may be
defined as a rewriting system on expressions. Because MLngthengcalculus has
side effects, however, we define its operational semantics as a rewriting sysng
tem on configurations. A configuration t=u is a pair of an expression t and a
store u. The memory locations in the domain of u are not considered bound
within t=u, so, for instance, m1=D^m1 , ^0E^ and m2=D^m2 , ^0E^ denote distinct
entities. (In the literature, memory locations are often considered bound inng
side configurations. This offers the advantage of making memory allocation a
deterministic operation. However, there is still a need for nonngffngconvertible
configurations: rules RngExtend and RngContext in Figure 10ng2 cannot otherng
wise be correctly stated! Quite a few papers run into this pitfall.)

A configuration t=u is closed if and only if t has no free program variables
and every memory location that appears within t or within the range of u is in
the domain of u. If t is a closed source program, its evaluation begins within
an empty store--that is, with the configuration t=IJ. Because source programs
do not contain memory locations, this configuration is closed. Furthermore,
we shall see that closed configurations are preserved by reduction.

10.1 What Is ML? 395
D^*z:tE^ v -! E,z , vG*t (RngBeta)
let z C^ v in t -! E,z , vG*t (RngLet)

t=u ffi-! t0=u0
t=u -! t0=u0 (RngDelta)

t=u -! t0=u0
domD^u00E^ # domD^u0E^
rangeD^u00E^ # domD^u0 \ uE^

t=uu00 -! t0=u0u00 (RngExtend)

t=u -! t0=u0
EE,tG*=u --n~ EE,t0G*=u0 (RngContext)

Figure 10ng2: Semantics of MLngthengcalculus

Note that, instead of separating expressions and stores, it is possible to
make store fragments part of the syntax of expressions; this idea, proposed in
Crank and Felleisen (1991), has also been used for the encoding of reference
cells in process calculi.

A context is an expression where a single subexpression has been replaced
with a hole, written E,G*. Evaluation contexts form a strict subset of contexts. In
an evaluation context, the hole is meant to highlight a point in the program
where it is valid to apply a reduction rule. Thus, the definition of evaluation
contexts determines a reduction strategy: it tells where and in what order
reduction steps may occur. For instance, the fact that *z:E,G* is not an evalung
ation context means that the body of a function is never evaluated--that is,
not until the function is applied. The fact that t E is an evaluation context
only if t is a value means that, to evaluate an application t1 t2, one should
fully evaluate t1 before attempting to evaluate t2. More generally, in the case
of a multiple application, it means that arguments should be evaluated from
left to right. Of course, other choices could be made: for instance, defining
E ::C^ : : : | t E | E v | : : : would enforce a rightngtongleft evaluation order, while
defining E ::C^ : : : | t E | E t | : : : would leave the evaluation order unspecing
fied, effectively allowing reduction to alternate between both subexpressions,
and making evaluation nondeterministic (because side effects could occur in
different order). The fact that let z C^ v in E is not an evaluation context
means that the body of a local definition is never evaluated--that is, not until
the definition itself is reduced. We write EE,tG* for the expression obtained by
replacing the hole in E with the expression t.

Figure 10ng2 defines first a relation -! between arbitrary configurations,
then a relation --n~ between closed configurations. If t=u -! t0=u holds for
every store u, then we write t -! t0 and say that the reduction is pure.

The semantics need not be deterministic. That is, a configuration may reng
duce to two different configurations. In fact, our semantics is deterministic

396 10 The Essence of ML Type Inference

only if the relation ffi-!, which is a parameter to our semantics, is itself deng
terministic. In practice, ffi-! is usually deterministic, up to ffngconversion of
memory locations. As explained above, the semantics could also be made
nondeterministic by a different choice in the definition of evaluation contexts.

The key reduction rule is RngBeta, which states that a function application
D^*z:tE^ v reduces to the function body, namely t, where every occurrence of
the formal argument z has been replaced with the actual argument v. The *
construct, which prevented the function body t from being evaluated, disapng
pears, so the new term may (in general) be further reduced. Because MLngtheng
calculus adopts a callngbyngvalue strategy, rule RngBeta is applicable only if the
actual argument is a value v. In other words, a function cannot be invoked unng
til its actual argument has been fully evaluated. Rule RngLet is very similar to
RngBeta. Indeed, it specifies that let z C^ v in t has the same behavior, with reng
spect to reduction, as D^*z:tE^ v. Substitution of a value for a program variable
throughout a term is expensive, so RngBeta and RngLet are never implemented
literally: they are only a simple specification. Actual implementations usually
employ runtime environments, which may be understood as a form of explicit
substitutions (Abadi, Cardelli, Curien, and Le'vy, 1991; Hardin, Maranget, and
Pagano, 1998). Note that our choice of a callngbyngvalue reduction strategy has
essentially no impact on the type system; the programming language Haskell,
whose reduction strategy is known as lazy or callngbyngneed, also relies on the
HindleyngMilner type discipline.

Rule RngDelta describes the semantics of constants. It states that a certain
relation ffi-! is a subset of -!. Of course, since the set of constants is unng

specified, the relation ffi-! must be kept abstract as well. We require that, if
t=u ffi-! t0=u0 holds, then

(i) t is of the form c v1 : : : vn, where c is a destructor of arity n; and
(ii) domD^uE^ is a subset of domD^u0E^.
Condition (i) ensures that ffingreduction concerns full applications of destrucng
tors only, and that these are evaluated in accordance with the callngbyngvalue
strategy. Condition (ii) ensures that ffingreduction may allocate new memory
locations, but not deallocate existing locations. In particular, a "garbage colng
lection" operator, which destroys unreachable memory cells, cannot be made
available as a constant. Doing so would not make much sense anyway in the
presence of RngExtend. Condition (ii) allows proving that, if t=u reduces (by

-!) to t0=u0, then domD^uE^ is also a subset of domD^u0E^; checking this is left as
an exercise to the reader.

Rule RngExtend states that any valid reduction is also valid in a larger store.
The initial and final stores u and u0 in the original reduction are both exng

10.1 What Is ML? 397
tended with a new store fragment u00. The rule's second premise requires that
the domain of u00 be disjoint with that of u0 (and consequently, also with that
of u), so that the new memory locations are indeed undefined in the original
reduction. (They may, however, appear in the image of u.) The last premise
ensures that the new memory locations in u00 do not accidentally carry the
same names as the locations allocated during the original reduction step, that
is, the locations in domD^u0 \ uE^. The notation A # B stands for A " B C^ IJ.

Rule RngContext completes the definition of the operational semantics by
defining --n~, a relation between closed configurations, in terms of -!. The
rule states that reduction may take place not only at the term's root, but also
deep inside it, provided the path from the root to the point where reduction
occurs forms an evaluation context. This is how evaluation contexts deterng
mine an evaluation strategy. As a purely technical point, because --n~ relates
closed configurations only, we do not need to require that the memory long
cations in domD^u0 \ uE^ be fresh for E; indeed, every memory location that
appears within E must be a member of domD^uE^.

10.1.4 Example [Integers, continued]: The operational semantics of integer adding

tion may be defined as follows:

^k1 ^+ ^k2 ffi-! "k1 + k2 (RngAdd)

The leftnghand term is the double application ^+ ^k1 ^k2, while the rightnghand
term is the integer literal ^k, where k is the sum of k1 and k2. The distinction
between object level and meta level (that is, between ^k and k) is needed here
to avoid ambiguity. 2

10.1.5 Example [Pairs, continued]: In addition to the pair constructor defined in

Example 10.1.3, we may introduce two destructors ss1 and ss2 of arity 1. We
may define their operational semantics as follows, for i 2 {1; 2}:

ssi D^v1; v2E^ ffi-! vi (RngProj)
Thus, our treatment of constants is general enough to account for pair conng
struction and destruction; we need not build these features explicitly into the
language. 2

10.1.6 Exercise [Booleans, Recommended, n'n', 3]: Let true and false be nullary

constructors. Let if be a ternary destructor. Extend the semantics with

if true v1 v2 ffi-! v1 (RngTrue)

if false v1 v2 ffi-! v2 (RngFalse)
Let us use the syntactic sugar if t0 then t1 else t2 for the triple applicang
tion of if t0 t1 t2. Explain why these definitions do not quite provide the
expected behavior. Without modifying the semantics of if, suggest a new

398 10 The Essence of ML Type Inference

definition of the syntactic sugar if t0 then t1 else t2 that corrects the
problem. 2

10.1.7 Example [Sums]: Booleans may in fact be viewed as a special case of the more

general concept of sum. Let inj1 and inj2 be unary constructors, called reng
spectively left and right injections. Let case be a ternary destructor, whose
semantics is defined as follows, for i 2 {1; 2}:

case D^inji vE^ v1 v2 ffi-! vi v (RngCase)
Here, the value inji v is being scrutinized, while the values v1 and v2, which
are typically functions, represent the two arms of a standard case construct.
The rule selects an appropriate arm (here, vi) based on whether the value unng
der scrutiny was formed using a left or right injection. The arm vi is executed
and given access to the data carried by the injection (here, v). 2

10.1.8 Exercise [n', 3]: Explain how to encode true, false, and the if construct

in terms of sums. Check that the behavior of RngTrue and RngFalse is properly
emulated. 2

10.1.9 Example [References]: Let ref and ! be unary destructors. Let :C^ be a binary

destructor. We write t1 :C^ t2 for the double application :C^ t1 t2. Define the
operational semantics of these three destructors as follows:

ref v=IJ ffi-! m=D^m , vE^ if m is fresh for v (RngRef)

!m=D^m , vE^ ffi-! v=D^m , vE^ (RngDeref)
m :C^ v=D^m , v0E^ ffi-! v=D^m , vE^ (RngAssign)
According to RngRef, evaluating ref v allocates a fresh memory location m and
binds v to it. The name m must be chosen fresh for v to prevent inadvertent
capture of the memory locations that appear free within v. By RngDeref, evalung
ating !m returns the value bound to the memory location m within the current
store. By RngAssign, evaluating m :C^ v discards the value v0 currently bound to
m and produces a new store where m is bound to v. Here, the value returned
by the assignment m :C^ v is v itself; in MLngthengprogrammingnglanguage, it is
usually a nullary constructor D^E^, pronounced unit. 2

10.1.10 Example [Recursion]: Let fix be a binary destructor, whose operational seng

mantics is:

fix v1 v2 ffi-! v1 D^fix v1E^ v2 (RngFix)
fix is a fixpoint combinator: it effectively allows recursive definitions of
functions. Indeed, the construct letrec f C^ *z:t1 in t2 provided by MLng
thengprogrammingnglanguage may be viewed as syntactic sugar for let f C^
fix D^*f:*z:t1E^ in t2. 2

10.1 What Is ML? 399
10.1.11 Exercise [Recommended, n'n', 3]: Assuming the availability of Booleans and

conditionals, integer literals, subtraction, multiplication, integer comparison,
and a fixpoint combinator, most of which were defined in previous examng
ples, define a function that computes the factorial of its integer argument,
and apply it to ^3. Determine, step by step, how this expression reduces to a
value. 2

It is straightforward to check that, if t=u reduces to t0=u0, then t is not a
value. In other words, values are irreducible: they represent completed comng
putations. The proof is left as an exercise to the reader. The converse, howng
ever, does not hold: if the closed configuration t=u is irreducible with respect
to --n~, then t is not necessarily a value. In that case, the configuration t=u is
said to be stuck. It represents a runtime error, that is, a situation that does not
allow computation to proceed, yet is not considered a valid outcome. A closed
source program t is said to go wrong if and only if the initial configuration
t=IJ reduces to a stuck configuration.

10.1.12 Example: Runtime errors typically arise when destructors are applied to arng

guments of an unexpected nature. For instance, the expressions ^+ ^1 m and
ss1 ^2 and !^3 are stuck, regardless of the current store. The program let z C^

^+ ^+ in z 1 is not stuck, because ^+ ^+ is a value. However, its reduct through
RngLet is ^+ ^+ 1, which is stuck, so this program goes wrong. The primary
purpose of type systems is to prevent such situations from arising. 2

10.1.13 Remark: The configuration !m=u is stuck if m is not in the domain of u. In

that case, however, !m=u is not closed. Because we consider --n~ as a relang
tion between closed configurations only, this situation cannot arise. In other
words, the semantics of MLngthengcalculus never allows the creation of danng
gling pointers. As a result, no particular precautions need be taken to guard
against them. Several strongly typed programming languages do nevertheng
less allow dangling pointers in a controlled fashion (Tofte and Talpin, 1997;
Walker, Crary, and Morrisett, 2000; DeLine and Fa"hndrich, 2001; Grossman,
Morrisett, Jim, Hicks, Wang, and Cheney, 2002). 2

Damas and Milner's Type System
MLngthengtypengsystem was originally defined by Milner (1978). Here, we reprong
duce the definition given a few years later by Damas and Milner (1982), which
is written in a more standard style: typing judgments are defined inductively
by a collection of typing rules. We refer to this type system as DM.

We must first define types. In DM, types are terms built out of type conng
structors and type variables. Furthermore, they are firstngorder terms: that is,

400 10 The Essence of ML Type Inference

in the grammar of types, none of the productions binds a type variable. This
situation is identical to that of the simplyngtyped *ngcalculus.

We begin with several considerations concerning the specification of type
constructors.

First, we do not wish to fix the set of type constructors. Certainly, since
MLngthengcalculus has functions, we need to be able to form an arrow type
T ! T0 out of arbitrary types T and T0; that is, we need a binary type conng
structor !. However, because MLngthengcalculus includes an unspecified set of
constants, we cannot say much else in general. If constants include integer
literals and integer operations, as in Example 10.1.1, then a nullary type conng
structor int is needed; if they include pair construction and destruction, as in
Examples 10.1.3 and 10.1.5, then a binary type constructor * is needed; etc.

Second, it is common to refer to the parameters of a type constructor by
position, that is, by numeric index. For instance, when one writes T ! T0, it
is understood that the type constructor ! has arity 2, that T is its first pang
rameter, known as its domain, and that T0 is its second parameter, known as
its codomain. Here, however, we refer to parameters by names, known as ding
rections. For instance, we define two directions domain and codomain and let
the type constructor ! have arity {domain; codomain}. The extra generality
afforded by directions is exploited in the definition of nonstructural subtypng
ing (Example 10.2.9) and in the definition of rows ($10.8).

Last, we allow types to be classified using kinds. As a result, every type
constructor must come not only with an arity, but with a richer signature,
which describes the kinds of the types to which it is applicable and the
kind of the type that it produces. A distinguished kind ? is associated with
"normal" types, that is, types that are directly ascribed to expressions and
values. For instance, the signature of the type constructor ! is {domain ,
?; codomain , ?} ) ?, because it is applicable to two normal types and
produces a normal type. Introducing kinds other than ? allows viewing some
types as illngformed: this is illustrated, for instance, in $10.8. In the simplest
case, however, ? is really the only kind, so the signature of a type constructor
is nothing but its arity (a set of directions), and every term is a wellngformed
type, provided every application of a type constructor respects its arity.

10.1.14 Definition: Let d range over a finite or denumerable set of directions and ^

over a finite or denumerable set of kinds. Let ? be a distinguished kind. Let K
range over partial mappings from directions to kinds. Let F range over a finite
or denumerable set of type constructors, each of which has a signature of the
form K ) ^. The domain of K is called the arity of F, while ^ is referred to
as its image kind. We write ^ instead of K ) ^ when K is empty. Let ! be a
type constructor of signature {domain , ?; codomain , ?} ) ?. 2

10.1 What Is ML? 401

The type constructors and their signatures collectively form a signature S.
In the following, we assume that a fixed signature S is given and that every
type constructor in it has finite arity, so as to ensure that types are machine
representable. However, in $10.8, we shall explicitly work with several distinct
signatures, one of which involves type constructors of denumerable arity.

A type variable is a name that is used to stand for a type. For simplicity,
we assume that every type variable is branded with a kind, or in other words,
that type variables of distinct kinds are drawn from disjoint sets. Each of
these sets of type variables is individually subject to ffngconversion: that is,
renamings must preserve kinds. Attaching kinds to type variables is only a
technical convenience; in practice, every operation performed during type
inference preserves the property that every type is wellngkinded, so it is not
necessary to keep track of the kind of every type variable. It is only necessary
to check that all types supplied by the programmer, within type declarations,
type annotations, or module interfaces, are wellngkinded.

10.1.15 Definition: For every kind ^, let V^ be a disjoint, denumerable set of type

variables. Let X, Y, and Z range over the set V of all type variables. Let _X and
_Y range over finite sets of type variables. We write _X_Y for the set _X [ _Y and

often write X for the singleton set {X}. We write ftvD^oE^ for the set of free type
variables of an object o. 2

The set of types, ranged over by T, is the free manyngkinded term algebra
that arises out of the type constructors and type variables. Types are given
by the following inductive definition:

10.1.16 Definition: A type of kind ^ is either a member of V^, or a term of the form

F {d1 , T1; : : : ; dn , Tn}, where F has signature {d1 , ^1; : : : ; dn , ^n} ) ^
and T1; : : : ; Tn are types of kind ^1; : : : ; ^n, respectively. 2

As a notational convention, we assume that, for every type constructor F,
the directions that form the arity of F are implicitly ordered, so that we may
say that F has signature ^1 \Omega  : : : \Omega  ^n ) ^ and employ the syntax F T1 : : : Tn
for applications of F. Applications of the type constructor ! are written infix
and associate to the right, so T ! T0 ! T00 stands for T ! D^T0 ! T00E^.

In order to give meaning to the free type variables of a type, or more genng
erally, of a typing judgment, traditional presentations of MLngthengtypengsystem,
including Damas and Milner's, employ type substitutions. Most of our preng
sentation avoids substitutions and uses constraints instead. However, we do
need substitutions on a few occasions, especially when relating our presentang
tion to Damas and Milner's.

10.1.17 Definition: A type substitution ` is a total, kindngpreserving mapping of type

variables to types that is the identity everywhere but on a finite subset of V ,

402 10 The Essence of ML Type Inference

which we call the domain of ` and write domD^`E^. The range of `, which we
write rangeD^`E^, is the set ftvD^`D^domD^`E^E^E^. A type substitution may naturally
be viewed as a total, kindngpreserving mapping of types to types. 2

If ~X and ~T are respectively a vector of distinct type variables and a vector
of types of the same (finite) length such that, for every index i, Xi and Ti
have the same kind, then E,~X , ~TG* denotes the substitution that maps Xi to
Ti for every index i and is the identity elsewhere. The domain of E,~X , ~TG* is
a subset of _X, the set underlying the vector ~X. Its range is a subset of ftvD^_TE^,
where _T is the set underlying the vector ~T. (These may be strict subsets; for
instance, the domain of E,X , XG* is the empty set, since this substitution is the
identity.) Every substitution ` may be written under the form E,~X , ~TG*, where
_X C^ domD^`E^. Then, ` is idempotent if and only if _X # ftvD^_TE^ holds.

As pointed out earlier, types are firstngorder terms. As a result, every type
variable that appears within a type T appears free within T. Things become
more interesting when we introduce type schemes. As its name implies, a
type scheme may describe an entire family of types; this effect is achieved via
universal quantification over a set of type variables.

10.1.18 Definition: A type scheme S is an object of the form 8_X:T, where T is a type

of kind ? and the type variables _X are considered bound within T. Any type
of the form E,~X , ~TG*T is called an instance of the type scheme 8_X:T. 2

One may view the type T as the trivial type scheme 8IJ:T, where no type varing
ables are universally quantified, so types of kind ? may be viewed as a subset
of type schemes. The type scheme 8_X:T may be viewed as a finite way of
describing the possibly infinite family of its instances. Note that, throughout
most of this chapter, we work with constrained type schemes, a generalization
of DM type schemes (Definition 10.2.2).

Typing environments, or environments for short, are used to collect asng
sumptions about an expression's free identifiers.

10.1.19 Definition: An environment \Gamma  is a finite ordered sequence of pairs of a prong

gram identifier and a type scheme. We write IJ for the empty environment and
";" for the concatenation of environments. An environment may be viewed as
a finite mapping from program identifiers to type schemes by letting \Gamma  D^xE^ C^ S
if and only if \Gamma  is of the form \Gamma 1; x : S; \Gamma 2, where \Gamma 2 contains no assumption
about x. The set of defined program identifiers of an environment \Gamma  , written
dpiD^\Gamma  E^, is defined by dpiD^IJE^ C^ IJ and dpiD^\Gamma  ; x : SE^ C^ dpiD^\Gamma  E^ [ {x}. 2

To complete the definition of Damas and Milner's type system, there reng
mains to define typing judgments. A typing judgment takes the form \Gamma  ` t : S,
where t is an expression of interest, \Gamma  is an environment, which typically conng
tains assumptions about t's free program identifiers, and S is a type scheme.

10.1 What Is ML? 403
\Gamma  D^xE^ C^ S

\Gamma  ` x : S (dmngVar)
\Gamma  ; z : T ` t : T0
\Gamma  ` *z:t : T ! T0 (dmngAbs)
\Gamma  ` t1 : T ! T0 \Gamma  ` t2 : T

\Gamma  ` t1 t2 : T0 (dmngApp)

\Gamma  ` t1 : S \Gamma  ; z : S ` t2 : T

\Gamma  ` let z C^ t1 in t2 : T (dmngLet)

\Gamma  ` t : T _X # ftvD^\Gamma  E^

\Gamma  ` t : 8_X:T (dmngGen)
\Gamma  ` t : 8_X:T
\Gamma  ` t : E,~X , ~TG*T (dmngInst)

Figure 10ng3: Typing rules for DM

Such a judgment may be read: under assumptions \Gamma  , the expression t has the
type scheme S. By abuse of language, it is sometimes said that t has type S.
A typing judgment is valid (or holds) if and only if it may be derived using
the rules that appear in Figure 10ng3. An expression t is wellngtyped within the
environment \Gamma  if and only if there exists some type scheme S such that the
judgment \Gamma  ` t : S holds; it is illngtyped within \Gamma  otherwise.

Rule dmngVar allows fetching a type scheme for an identifier x from the
environment. It is equally applicable to program variables, memory locations,
and constants. If no assumption concerning x appears in the environment
\Gamma  , then the rule isn't applicable. In that case, the expression x is illngtyped
within \Gamma  . Assumptions about constants are usually collected in a songcalled ining
tial environment \Gamma 0. It is the environment under which closed programs are
typechecked, so every subexpression is typechecked under some extension \Gamma 
of \Gamma 0. Of course, the type schemes assigned by \Gamma 0 to constants must be conng
sistent with their operational semantics; we say more about this later ($10.5).
Rule dmngAbs specifies how to typecheck a *ngabstraction *z:t. Its premise reng
quires the body of the function, t, to be wellngtyped under an extra assumption
that causes all free occurrences of z within t to receive a common type T. Its
conclusion forms the arrow type T ! T0 out of the types of the function's
formal parameter, T, and result, T0. It is worth noting that this rule always
augments the environment with a type T--recall that, by convention, types
form a subset of type schemes--but never with a nontrivial type scheme.
Rule dmngApp states that the type of a function application is the codomain
of the function's type, provided that the domain of the function's type is a
valid type for the actual argument. Rule dmngLet closely mirrors the operang
tional semantics: whereas the semantics of the local definition let z C^ t1
in t2 is to augment the runtime environment by binding z to the value of
t1 prior to evaluating t2, the effect of dmngLet is to augment the typing enving

404 10 The Essence of ML Type Inference

ronment by binding z to a type scheme for t1 prior to typechecking t2. Rule
dmngGen turns a type into a type scheme by universally quantifying over a set
of type variables that do not appear free in the environment; this restriction
is discussed in Example 10.1.20 below. Rule dmngInst, on the contrary, turns a
type scheme into one of its instances, which may be chosen arbitrarily. These
two operations are referred to as generalization and instantiation. The nong
tion of type scheme and the rules dmngGen and dmngInst are characteristic of
MLngthengtypengsystem: they distinguish it from the simplyngtyped *ngcalculus.

10.1.20 Example: It is unsound to allow generalizing type variables that appear free

in the environment. For instance, consider the typing judgment z : X ` z :
X (1), which, according to dmngVar, is valid. Applying an unrestricted version
of dmngGen to it, we obtain z : X ` z : 8X:X (2), whence, by dmngInst, z : X `
z : Y (3). By dmngAbs and dmngGen, we then have IJ ` *z:z : 8XY:X ! Y. In
other words, the identity function has unrelated argument and result types!
Then, the expression D^*z:zE^ ^0 ^0, which reduces to the stuck expression ^0 ^0,
has type scheme 8Z:Z. So, wellngtyped programs may cause runtime errors:
the type system is unsound.

What happened? It is clear that the judgment (1) is correct only because
the type assigned to z is the same in its assumption and in its rightnghand
side. For the same reason, the judgments (2) and (3)--the former of which
may be written z : X ` z : 8Y:Y--are incorrect. Indeed, such judgments defeat
the very purpose of environments, since they disregard their assumption.
By universally quantifying over X in the rightnghand side only, we break the
connection between occurrences of X in the assumption, which remain free,
and occurrences in the rightnghand side, which become bound. This is correct
only if there are in fact no free occurrences of X in the assumption. 2

10.1.21 Remark: A naive implementation of dmngGen would traverse the environment

\Gamma  in order to compute the set of its free type variables. However, the numng
ber of entries in \Gamma  may be linear in the program size, so, even if types have
bounded size, the time required by this computation may be linear in the
program size. Since it is performed at every let node, this naive approach
gives type inference quadratic time complexity. To avoid this pitfall, our conng
straint solver annotates every type variable with an integer rank, which allows
telling, in constant time, whether it appears free in \Gamma  (page 444). 2

It is a key feature of MLngthengtypengsystem that dmngAbs may only introduce a
type T, rather than a type scheme, into the environment. Indeed, this allows
the rule's conclusion to form the arrow type T ! T0. If instead the rule were
to introduce the assumption z : S into the environment, then its conclusion
would have to form S ! T0, which is not a wellngformed type. In other words,

10.1 What Is ML? 405
this restriction is necessary to preserve the stratification between types and
type schemes. If we were to remove this stratification, thus allowing univerng
sal quantifiers to appear deep inside types, we would obtain an implicitlyng
typed version of System F (TAPL, Chapter 23). Type inference for System F
is undecidable (Wells, 1999), while type inference for MLngthengtypengsystem is
decidable, as we show later, so this design choice has a rather drastic impact.

10.1.22 Exercise [Recommended, n']: Build a type derivation for the expression *z1:

let z2 C^ z1 in z2. 2

10.1.23 Exercise [Recommended, n']: Let int be a nullary type constructor of signang

ture ?. Let \Gamma 0 consist of the bindings ^+ : int ! int ! int and ^k : int, for every
integer k. Can you find derivations of the following valid typing judgments?
Which of these judgments are valid in the simplyngtyped *ngcalculus, where
let z C^ t1 in t2 is syntactic sugar for D^*z:t2E^ t1?

\Gamma 0 ` *z:z : int ! int
\Gamma 0 ` *z:z : 8X:X ! X
\Gamma 0 ` let f C^ *z:z^+^1 in f ^2 : int

\Gamma 0 ` let f C^ *z:z in f f ^2 : int

Show that the expressions ^1 ^2 and *f:D^f fE^ are illngtyped within \Gamma 0. Could these
expressions be wellngtyped in a more powerful type system? 2

DM enjoys a number of nice theoretical properties, which have practical
implications.

First, it is sound: that is, wellngtyped programs do not go wrong. This essenng
tial property ensures that programs that are accepted by the typechecker may
be compiled without runtime checks. Establishing this property requires (i)
suitable hypotheses about the semantics of constants and the type schemes
assigned to constants in the initial environment, and (ii) in the presence of
side effects, a slight restriction of the syntax of let constructs, known as the
value restriction.

Furthermore, there exists an algorithm that, given a (closed) environment \Gamma 
and a program t, tells whether t is wellngtyped with respect to \Gamma  , and if so, prong
duces a principal type scheme S. A principal type scheme is such that (i) it is
valid, that is, \Gamma  ` t : S holds, and (ii) it is most general, that is, every judgment
of the form \Gamma  ` t : S0 follows from \Gamma  ` t : S by dmngInst and dmngGen. (For the
sake of simplicity, we have stated the properties of the type inference algong
rithm only in the case of a closed environment \Gamma  ; the specification is slightly
heavier in the general case.) This implies that type inference is decidable: the
compiler need not require expressions to be annotated with types. The fact
that, under a fixed environment \Gamma  , all of the type information associated with

406 10 The Essence of ML Type Inference

an expression t may be summarized in the form of a single, principal type
scheme is also key to modular programming. Indeed, exporting a value out
of a module requires explicitly assigning a type scheme to it as part of the
module's signature. If the chosen type scheme is not principal, then part of
the value's (hence, of the module's) potential for reuse is lost.

Road Map
Before proving the above claims, we first generalize our presentation by movng
ing to a constraintngbased setting. The necessary tools--the constraint lanng
guage, its interpretation, and a number of constraint equivalence laws--are
introduced in $10.2. In $10.3, we describe the standard constraintngbased type
system HMD^XE^ (Odersky, Sulzmann, and Wehr, 1999). We prove that, when
constraints are made up of equations between free, finite terms, HMD^XE^ is
a reformulation of DM. In the presence of a more powerful constraint lanng
guage, HMD^XE^ is an extension of DM. In $10.4, we show that type inference
may be viewed as a combination of constraint generation and constraint solvng
ing, as promised earlier. Then, in $10.5, we give a type soundness theorem. It
is stated purely in terms of constraints, but--thanks to the results developed
in the previous sections--applies equally to HMD^XE^ and DM.

Throughout this core material, the syntax and interpretation of constraints
are left partly unspecified. Thus, the development is parameterized with reng
spect to them--hence the unknown X in the name HMD^XE^. We really describe
a family of constraintngbased type systems, all of which share a common conng
straint generator and a common type soundness proof. Constraint solving,
however, cannot be independent of X: on the contrary, the design of an efng
ficient solver is heavily dependent on the syntax and interpretation of conng
straints. In $10.6, we consider constraint solving in the particular case where
constraints are made up of equations interpreted in a free tree model, and
define a constraint solver on top of a standard firstngorder unification algong
rithm.

The remainder of this chapter deals with extensions of the framework. In

$10.7, we explain how to extend MLngthengcalculus with a number of features,
including products, sums, references, recursion, algebraic data types, and reng
cursive types. Last, in $10.8, we extend the type language with rows and use
them to assign polymorphic type schemes to operations on records and varing
ants.

10.2 Constraints 407
oe ::= type scheme:

8_XE,CG*:T
C; D ::= constraint:

true truth
false falsity
P T1 : : : Tn predicate application
C ^ C conjunction
9_X:C existential quantification
def x : oe in C type scheme introduction
x _ T type scheme instantiation

C; D ::= Syntactic sugar for constraints:

: : : As before
oe _ T Definition 10.2.3
let x : oe in C Definition 10.2.3
9oe Definition 10.2.3
def \Gamma  in C Definition 10.2.4
let \Gamma  in C Definition 10.2.4
9\Gamma  Definition 10.2.4

Figure 10ng4: Syntax of type schemes and constraints

10.2 Constraints

In this section, we define the syntax and logical meaning of constraints. Both
are partly unspecified. Indeed, the set of type constructors (Definition 10.1.14)
must contain at least the binary type constructor !, but might contain more.
Similarly, the syntax of constraints involves a set of songcalled predicates on
types, which we require to contain at least a binary subtyping predicate <=, but
might contain more. (The introduction of subtyping, which is absent in DM,
has little impact on the complexity of our proofs, yet increases the frameng
work's expressive power. When subtyping is not desired, we interpret the
predicate <= as equality.) The logical interpretation of type constructors and
of predicates is left almost entirely unspecified. This freedom allows reasonng
ing not only about Damas and Milner's type system, but also about a family
of constraintngbased extensions of it.

Syntax of Constraints
We now define the syntax of constrained type schemes and of constraints and
introduce some extra constraint forms as syntactic sugar.

10.2.1 Definition: Let P range over a finite or denumerable set of predicates, each

of which has a signature of the form ^1 \Omega  : : : \Omega  ^n ) *, where n >= 0. For every
kind ^, let C^^ and <=^ be distinguished predicates of signature ^ \Omega  ^ ) *. 2

10.2.2 Definition: The syntax of type schemes and constraints is given in Figure 10ng4.

It is further restricted by the following requirements. In the type scheme
8_XE,CG*:T and in the constraint x _ T, the type T must have kind ?. In the conng

408 10 The Essence of ML Type Inference

straint P T1 : : : Tn, the types T1; : : : ; Tn must have kind ^1; : : : ; ^n, respectively,
if P has signature ^1 \Omega : : :\Omega ^n ) *. We write 8_X:T for 8_XE,trueG*:T, which allows
viewing DM type schemes as a subset of constrained type schemes. 2

We write T1 C^^ T2 and T1 <=^ T2 for the binary predicate applications C^^ T1 T2
and <=^ T1 T2, and refer to them as equality and subtyping constraints, respecng
tively. We often omit the subscript ^, so T1 C^ T2 and T1 <= T2 are wellngformed
constraints whenever T1 and T2 have the same kind. By convention, 9 and def
bind tighter than ^; that is, 9_X:C ^ D is D^9_X:CE^ ^ D and def x : oe in C ^ D
is D^def x : oe in CE^ ^ D. In 8_XE,CG*:T, the type variables _X are bound within
C and T. In 9_X:C, the type variables _X are bound within C. The sets of free
type variables of a type scheme oe and of a constraint C, written ftvD^oe E^ and
ftvD^CE^, respectively, are defined accordingly. In def x : oe in C, the identifier
x is bound within C. The sets of free program identifiers of a type scheme
oe and of a constraint C, written fpiD^oe E^ and fpiD^CE^, respectively, are defined
accordingly. Note that x occurs free in the constraint x _ T.

The constraint true, which is always satisfied, mainly serves to indicate
the absence of a nontrivial constraint, while false, which has no solution,
may be understood as the indication of a type error. Composite constraints
include conjunction and existential quantification, which have their standard
meaning, as well as type scheme introduction and type scheme instantiation
constraints, which are similar to Gustavsson and Svenningsson's constraint
abstractions (2001). In order to be able to explain these last two forms, we
must first introduce a number of derived constraint forms:

10.2.3 Definition: Let oe be 8_XE,DG*:T. If _X # ftvD^T0E^ holds, then oe _ T0 (read: T0 is an

instance of oe ) stands for the constraint 9_X:D^D ^ T <= T0E^. We write 9oe (read: oe
has an instance) for 9_X:D and let x : oe in C for 9oe ^ def x : oe in C. 2

Constrained type schemes generalize Damas and Milner's type schemes, while
this definition of instantiation constraints generalizes Damas and Milner's nong
tion of instance (Definition 10.1.18). Let us draw a comparison. First, Damas
and Milner's instance relation is binary (given a type scheme S and a type T,
either T is an instance of S, or it isn't), and is purely syntactic. For instance,
the type Y ! Z is not an instance of 8X:X ! X in Damas and Milner's sense,
because Y and Z are distinct type variables. In our presentation, on the other
hand, 8X:X ! X _ Y ! Z is not an assertion; rather, it is a constraint, which
by definition is 9X:D^true ^ X ! X <= Y ! ZE^. We later prove that it is equivalent
to 9X:D^Y <= X ^ X <= ZE^ and to Y <= Z, and, if subtyping is interpreted as equality,
to Y C^ Z. That is, oe _ T0 represents a condition on (the ground types denoted
by) the type variables in ftvD^oe ; T0E^ for T0 to be an instance of oe , in a logical,
rather than purely syntactic, sense. Second, the definition of instantiation

10.2 Constraints 409
constraints involves subtyping, to ensure that any supertype of an instance
of oe is again an instance of oe (see rule CngExTrans on page 418). This is conng
sistent with the purpose of subtyping: to allow a subtype where a supertype
is expected (TAPL, Chapter 15). Third and last, every type scheme oe is now
of the form 8_XE,CG*:T. The constraint C, whose free type variables may or may
not be members of _X, is meant to restrict the set of instances of the type
scheme 8_XE,CG*:T. This is evident in the instantiation constraint 8_XE,CG*:T _ T0,
which by Definition 10.2.3 stands for 9_X:D^C ^ T <= T0E^: the values that _X may
assume are restricted by the demand that C be satisfied. This requirement
vanishes in the case of DM type schemes, where C is true. Our notions of conng
strained type scheme and of instantiation constraint are standard, coinciding
with those of HMD^XE^ (Odersky, Sulzmann, and Wehr, 1999).

Let us now come back to an explanation of type scheme introduction and
instantiation constraints. In brief, the construct def x : oe in C binds the name
x to the type scheme oe within the constraint C. If C contains a subconstraint
of the form x _ T, where this occurrence of x is free in C, then this subconng
straint acquires the meaning oe _ T. Thus, the constraint x _ T is indeed an
instantiation constraint, where the type scheme that is being instantiated is
referred to by name. The constraint def x : oe in C may be viewed as an exng
plicit substitution of the type scheme oe for the name x within C. Later ($10.4),
we use such explicit substitutions to supplant typing environments. That is,
where Damas and Milner's type system augments the current typing enving
ronment (dmngAbs, dmngLet), we introduce a new def binding in the current
constraint; where it looks up the current typing environment (dmngVar), we
employ an instantiation constraint. (The reader may wish to look ahead at Figng
ure 10ng9 on page 431.) The point is that it is then up to a constraint solver to
choose a strategy for reducing explicit substitutions--for instance, one might
wish to simplify oe before substituting it for x within C--whereas the use of
environments in standard type systems such as DM and HMD^XE^ imposes an
eager substitution strategy, which is inefficient and thus never literally impleng
mented. The use of type scheme introduction and instantiation constraints
allows separating constraint generation and constraint solving without comng
promising efficiency, or, in other words, without introducing a gap between
the description of the type inference algorithm and its actual implementation.
Although the algorithm that we plan to describe is not new (Re'my, 1992a), its
description in terms of constraints is: to the best of our knowledge, the only
close relative of our def constraints is to be found in Gustavsson and Svenng
ningsson (2001). An earlier work that contains similar ideas is Mu"ller (1994).
Approaches based on semingunification (Henglein, 1989, 1993) achieve a siming
lar separation between constraint generation and constraint solving, but are
based on a rather different constraint language.

410 10 The Essence of ML Type Inference

In the type system of Damas and Milner, every type scheme S has a fixed,
nonempty set of instances. In a constraintngbased setting, things are more
complex: given a type scheme oe and a type T, whether T is an instance
of oe (that is, whether the constraint oe _ T is satisfied) depends on the
meaning assigned to the type variables in ftvD^oe ; TE^. Similarly, given a type
scheme, whether some type is an instance of oe (that is, whether the conng
straint 9Z:oe _ Z, where Z is fresh for oe , is satisfied) depends on the meaning
assigned to the type variables in ftvD^oe E^. Because we do not wish to allow
forming type schemes that have no instances, we often use the constraint
9Z:oe _ Z. In fact, we later prove that it is equivalent to 9oe , as defined above.
We also use the constraint form let x : oe in C, which requires oe to have an
instance and at the same time associates it with the name x. Because the def
form is more primitive, it is easier to work with at a low level, but it is no
longer explicitly used after $10.2; we always use let instead.

10.2.4 Definition: Environments \Gamma  remain as in Definition 10.1.19, except DM type

schemes S are replaced with constrained type schemes oe . The set of free
program identifiers of an environment \Gamma  , written fpiD^\Gamma  E^, is defined by fpiD^IJE^ C^
IJ and fpiD^\Gamma  ; x : oe E^ C^ fpiD^\Gamma  E^ [ fpiD^oe E^. We write dfpiD^\Gamma  E^ for dpiD^\Gamma  E^ [ fpiD^\Gamma  E^. We
define def IJ in C as C and def \Gamma  ; x : oe in C as def \Gamma  in def x : oe in C. Similarly,
we define let IJ in C as C and let \Gamma  ; x : oe in C as let \Gamma  in let x : oe in C. We define
9IJ as true and 9D^\Gamma  ; x : oe E^ as 9\Gamma  ^ def \Gamma  in 9oe . 2

In order to establish or express certain laws of equivalence between conng
straints, we need constraint contexts. A constraint context is a constraint with
zero, one, or several holes, written E,G*. The syntax of contexts is as follows:

C ::C^ E,G* | C | C ^ C | 9_X:C | def x : oe in C | def x : 8_XE,CG*:T in C
The application of a constraint context C to a constraint C, written CE,CG*, is
defined in the usual way. Because a constraint context may have any number
of holes, C may disappear or be duplicated in the process. Because a hole
may appear in the scope of a binder, some of C's free type variables and free
program identifiers may become bound in CE,CG*. We write dtvD^CE^ and dpiD^CE^
for the sets of type variables and program identifiers, respectively, that C may
thus capture. We write let x : 8_XE,CG*:T in C for 9_X:C ^ def x : 8_XE,CG*:T in C.
(Being able to state such a definition is why we require multinghole contexts.)
We let X range over existential constraint contexts, defined by X ::C^ 9_X:E,G*.

Meaning of Constraints
We have defined the syntax of constraints and given an informal description
of their meaning. We now give a formal definition of the interpretation of
constraints. We begin with the definition of a model:

10.2 Constraints 411
10.2.5 Definition: For every kind ^, let M^ be a nonempty set, whose elements

are called the ground types of kind ^. In the following, t ranges over M^, for
some ^ that may be determined from the context. For every type constructor
F of signature K ) ^, let F denote a total function from MK into M^, where
the indexed product MK is the set of all mappings T of domain domD^KE^ that
map every d 2 domD^KE^ to an element of MKD^dE^. For every predicate symbol
P of signature ^1 \Omega  : : : \Omega  ^n ) *, let P denote a predicate on M^1 * : : : * M^n.
For every kind ^, we require the predicate C^^ to be equality on M^ and the
predicate <=^ to be a partial order on M^. 2

For the sake of convenience, we abuse notation and write F for both the
type constructor and its interpretation, and similarly for predicates.

By varying the set of type constructors, the set of predicates, the set of
ground types, and the interpretation of type constructors and predicates, one
may define an entire family of related type systems. We refer to the collection
of these choices as X. Thus, the type system HMD^XE^, described in $10.3, is
parameterized by X.

The following examples give standard ways of defining the set of ground
types and the interpretation of type constructors.

10.2.6 Example [Syntactic models]: For every kind ^, let M^ consist of the closed

types of kind ^. Then, ground types are types that do not have any free type
variables, and form the songcalled Herbrand universe. Let every type construcng
tor F be interpreted as itself. Models that define ground types and interpret
type constructors in this manner are referred to as syntactic. 2

10.2.7 Example [Tree models]: Let a path ss be a finite sequence of directions. The

empty path is written ffl and the concatenation of the paths ss and ss0 is written
ss * ss0. Let a tree be a partial function t from paths to type constructors
whose domain is nonempty and prefixngclosed and such that, for every path
ss in the domain of t, if the type constructor tD^ssE^ has signature K ) ^, then
ss * d 2 domD^tE^ is equivalent to d 2 domD^KE^ and, furthermore, for every
d 2 domD^KE^, the type constructor tD^ss * dE^ has image kind KD^dE^. If ss is in
the domain of t, then the subtree of t rooted at ss, written t=ss, is the partial
function ss0 , tD^ss * ss0E^. A tree is finite if and only if it has finite domain. A
tree is regular if and only if it has a finite number of distinct subtrees. Every
finite tree is thus regular. Let M^ consist of the finite (respectively regular)
trees t such that tD^fflE^ has image kind ^: then, we have a finite (respectively
regular) tree model.

If F has signature K ) ^, one may interpret F as the function that maps
T 2 MK to the ground type t 2 M^ defined by tD^fflE^ C^ F and t=d C^ T D^dE^ for
d 2 domD^T E^, that is, the unique ground type whose head symbol is F and

412 10 The Essence of ML Type Inference

whose subtree rooted at d is T D^dE^. Then, we have a free tree model. Note
that free finite tree models coincide with syntactic models, as defined in the
previous example. 2

Rows ($10.8) are interpreted in a tree model, albeit not a free one. The folng
lowing examples suggest different ways of interpreting the subtyping preding
cate.

10.2.8 Example [Equality models]: The simplest way of interpreting the subtypng

ing predicate is to let <= denote equality on every M^. Models that do so
are referred to as equality models. When no predicate other than equality is
available, we say that the model is equalityngonly. 2

10.2.9 Example [Structural, nonstructural subtyping]: Let a variance * be a

nonempty subset of {-; +}, written - (contravariant), + (covariant), or +- (inng
variant) for short. Define the composition of two variances as an associative,
commutative operation with + as neutral element, +- as absorbing element
(that is, +-- C^ +-+ C^ +-+- C^ +-), and such that -- C^ +. Now, consider a free
(finite or regular) tree model, where every direction d comes with a fixed varing
ance *D^dE^. Define the variance *D^ssE^ of a path ss as the composition of the
variances of its elements. Let a` be a partial order on type constructors such
that (i) if F1 a` F2 holds and F1 and F2 have signature K1 ) ^1 and K2 ) ^2, reng
spectively, then K1 and K2 agree on the intersection of their domains and ^1
and ^2 coincide; and (ii) F0 a` F1 a` F2 implies domD^F0E^ " domD^F2E^ ` domD^F1E^.
Let a`+, a`-, and a`+- stand for a`, a', and C^, respectively. Then, define the interng
pretation of subtyping as follows: if t1; t2 2 M^, let t1 <= t2 hold if and only if,
for every path ss 2 domD^t1E^ " domD^t2E^, t1D^ssE^ a`*D^ssE^ t2D^ssE^ holds. It is not diffing
cult to check that <= is a partial order on every M^. The reader is referred to
Amadio and Cardelli (1993), Kozen, Palsberg, and Schwartzbach (1995), and
Brandt and Henglein (1997) for more details about this construction. Models
that define subtyping in this manner are referred to as nonstructural subtypng
ing models.

A simple nonstructural subtyping model is obtained by: letting the direcng
tions domain and codomain be contrang and covariant, respectively; introducng
ing, in addition to the type constructor !, two type constructors ? and ? of
signature ?; and letting ? a` ! a` ?. This gives rise to a model where ? is the
least ground type, ? is the greatest ground type, and the arrow type construcng
tor is, as usual, contravariant in its domain and covariant in its codomain.
This form of subtyping is called nonstructural because comparable ground
types may have different shapes: consider, for instance, ? and ? ! ?.

A typical use of nonstructural subtyping is in type systems for records. One
may, for instance, introduce a covariant direction content of kind ?, a kind

10.2 Constraints 413
ffi, a type constructor abs of signature ffi, a type constructor pre of signature
{content , ?} ) ffi, and let pre a` abs. This gives rise to a model where
pre t <= abs holds for every t 2 M?. Again, comparable ground types may
have different shapes: consider, for instance, pre ? and abs. $10.8 says more
about typechecking operations on records.

Nonstructural subtyping has been studied, for example, in Kozen, Palsberg,
and Schwartzbach (1995), Palsberg, Wand, and O'Keefe (1997), Jim and Palsng
berg (1999), Pottier (2001b), Su et al. (2002), and Niehren and Priesnitz (2003).

An important particular case arises when any two type constructors related
by a` have the same arity (and thus also the same signatures). In that case, it
is not difficult to show that any two ground types related by subtyping must
have the same shape, that is, if t1 <= t2 holds, then domD^t1E^ and domD^t2E^ must
coincide. For this reason, such an interpretation of subtyping is usually reng
ferred to as atomic or structural subtyping. It has been studied in the finite
(Mitchell, 1984, 1991b; Tiuryn, 1992; Pratt and Tiuryn, 1996; Frey, 1997; Reng
hof, 1997; Kuncak and Rinard, 2003; Simonet, 2003) and regular (Tiuryn and
Wand, 1993) cases. Structural subtyping is often used in automated program
analyses that enrich standard types with atomic annotations without altering
their shape. 2

Many other kinds of constraints exist, which we lack space to list; see
Comon (1994) for a short survey.

Throughout this chapter, we assume (unless otherwise stated) that the set
of type constructors, the set of predicates, and the model--which, together,
form the parameter X--are arbitrary, but fixed.

As usual, the meaning of a constraint is a function of the meaning of its
free type variables and of its free program identifiers, which are respectively
given by a ground assignment and a ground environment.

10.2.10 Definition: A ground assignment OE is a total, kindngpreserving mapping from

V into M. Ground assignments are extended to types by OED^F T1 : : : TnE^ C^
FD^OED^T1E^; : : : ; OED^TnE^E^. Then, for every type T of kind ^, OED^TE^ is a ground type
of kind ^.

A ground type scheme s is a set of ground types, which we require to be
upwardngclosed with respect to subtyping: that is, t 2 s and t <= t0 must imng
ply t0 2 s. A ground environment  is a partial mapping from identifiers to
ground type schemes.

Because the syntax of type schemes and constraints is mutually recursive,
so is their interpretation. The interpretation of a type scheme oe under a
ground assignment OE and a ground environment  is a ground type scheme,
written D^OE; E^oe . It is defined in Figure 10ng5. The " is the upward closure

414 10 The Essence of ML Type Inference

Interpretation of type schemes:

D^OE; E^D^8_XE,CG*:TE^ C^

"{OEE,~X , ~tG*D^TE^ ; OEE,~X , ~tG*;  |C^ C}

Interpretation of constraints:

OE;  |C^ true (CMngTrue)
P D^OED^T1E^; : : : ; OED^TnE^E^

OE;  |C^ P T1 : : : Tn (CMngPredicate)

OE;  |C^ C1
OE;  |C^ C2

OE;  |C^ C1 ^ C2 (CMngAnd)
OEE,~X , ~tG*;  |C^ C

OE;  |C^ 9_X:C (CMngExists)
OE; E,x , D^OE; E^oe G* |C^ C

OE;  |C^ def x : oe in C (CMngDef)

OED^TE^ 2 D^xE^
OE;  |C^ x _ T (CMngInstance)

Figure 10ng5: Meaning of constraints

operator and |C^ is the constraint satisfaction predicate, defined next. The inng
terpretation of a constraint C under a ground assignment OE and a ground
environment  is a truth value, written OE;  |C^ C (read: OE and  satisfy C).
The threengplace predicate |C^ is defined by the rules in Figure 10ng5. A conng
straint C is satisfiable if and only if OE;  |C^ C holds for some OE and . It is
false (or unsatisfiable) otherwise. 2

Let us now explain these definitions. The interpretation of the type scheme
8_XE,CG*:T is a set of ground types, which we may refer to as the type scheme's
ground instances. It contains the images of T under extensions of OE with
new values for the universally quantified variables _X; these values may be
arbitrary, but must be such that the constraint C is satisfied. We implicitly
require ~X and ~t to have matching kinds, so that OEE,~X , ~tG* remains a kindng
preserving ground assignment. This set is upward closed, so any ground type
that lies above a ground instance of oe is also a ground instance of oe . This
interpretation is standard; see, for example, Pottier (2001a).

The rules that define |C^ (Figure 10ng5) are syntaxngdirected. CMngTrue states
that the constraint true is a tautology, that is, holds in every context. No rule
matches the constraint false, which means that it holds in no context. CMng
Predicate states that the meaning of a predicate application is given by the
predicate's interpretation within the model. More specifically, if P's signature
is ^1 \Omega  : : : \Omega  ^n ) *, then, by wellngformedness of the constraint, every Ti is of
kind ^i, so OED^TiE^ is a ground type in M^i . By Definition 10.2.5, P denotes a
predicate on M^1 * : : : * M^n , so the rule's premise is mathematically wellng
formed. It is independent of , which is natural, since a predicate application
has no free program identifiers. CMngAnd requires each of the conjuncts to be

10.2 Constraints 415
valid in isolation. CMngExists allows the type variables ~X to denote arbitrary
ground types ~t within C, independently of their image through OE. CMngDef
deals with type scheme introduction constraints, of the form def x : oe in C.
It binds x, within C, to the ground type scheme currently denoted by oe . Last,
CMngInstance concerns type scheme instantiation constraints of the form x _
T. Such a constraint is valid if and only if the ground type denoted by T is a
member of the ground type scheme denoted by x.

It is possible to prove that the constraints def x : oe in C and E,x , oe G*C have
the same meaning, where the latter denotes the capturengavoiding substitution
of oe for x throughout C. As a matter of fact, it would have been possible to
use this equivalence as a definition of the meaning of def constraints, but the
present style is pleasant as well. This confirms our claim that the def form is
an explicit substitution form.

Because constraints lie at the heart of our treatment of MLngthengtypengsystem,
most of our proofs involve establishing logical properties of constraints.
These properties are usually not stated in terms of the satisfaction preding
cate |C^, which is too lownglevel. Instead, we reason in terms of entailment or
equivalence assertions. Let us first define these notions.

10.2.11 Definition: We write C1 dh C2, and say that C1 entails C2, if and only if,

for every ground assignment OE and for every ground environment , the
assertion OE;  |C^ C1 implies OE;  |C^ C2. We write C1 j C2, and say that C1
and C2 are equivalent, if and only if C1 dh C2 and C2 dh C1 hold. 2

In other words, C1 entails C2 when C1 imposes stricter requirements on
its free type variables and program identifiers than C2 does. Note that C is
unsatisfiable if and only if C j false holds. It is straightforward to check
that entailment is reflexive and transitive and that j is indeed an equivalence
relation.

We immediately exploit the notion of constraint equivalence to define what
it means for a type constructor to be covariant, contravariant, or invariant
with respect to one of its parameters. Let F be a type constructor of signature
^1 \Omega  : : : \Omega  ^n ) ^. Let i 2 {1; : : : ; n}. F is covariant (respectively contravariant,
invariant) with respect to its ith parameter if and only if, for all types T1; : : : ; Tn
and T0i of appropriate kinds, the constraint F T1 : : : Ti : : : Tn <= F T1 : : : T0i : : : Tn
is equivalent to Ti <= T0i (respectively T0i <= Ti, Ti C^ T0i ).

10.2.12 Exercise [n', 3]: Check the following facts: (i) in an equality model, covaring

ance, contravariance, and invariance coincide; (ii) in an equality free tree
model, every type constructor is invariant with respect to each of its parameng
ters; and (iii) in a nonstructural subtyping model, if the direction d has been
declared covariant (respectively contravariant, invariant), then every type conng

416 10 The Essence of ML Type Inference

structor whose arity includes d is covariant (respectively contravariant, inng
variant) with respect to d. 2

In the following, we require the type constructor ! to be contravariant
with respect to its domain and covariant with respect to its codomain--a
standard requirement in type systems with subtyping (TAPL, Chapter 15).
This requirement is summed up by the following equivalence law:

T1 ! T2 <= T01 ! T02 j T01 <= T1 ^ T2 <= T02 (CngArrow)
Note that this requirement bears on the interpretation of types and of the
subtyping predicate. In an equality free tree model, by (i) and (ii) in the exerng
cise above, it is always satisfied. In a nonstructural subtyping model, it boils
down to requiring that the directions domain and codomain be declared conng
travariant and covariant, respectively. In the general case, we do not have any
knowledge of the model and cannot formulate a more precise requirement.
Thus, it is up to the designer of the model to ensure that CngArrow holds.

We also exploit the notion of constraint equivalence to define what it means
for two type constructors to be incompatible. Two type constructors F1 and
F2 with the same image kind are incompatible if and only if all constraints
of the form F1 ~T1 <= F2 ~T2 and F2 ~T2 <= F1 ~T1 are false. Note that in an equality
free tree model, any two distinct type constructors are incompatible. In the
following, we often indicate that a newly introduced type constructor must
be isolated. We implicitly require that, whenever both F1 and F2 are isolated,
F1 and F2 be incompatible. Thus, the notion of isolation provides a concise
and modular way of stating a collection of incompatibility requirements. We
require the type constructor ! to be isolated.

Reasoning with Constraints
In this section, we give a number of equivalence laws that are often useful and
help understand the meaning of constraints. To begin, we note that entailng
ment is preserved by arbitrary constraint contexts, as stated by the theorem
below. As a result, constraint equivalence is a congruence. Throughout this
chapter, these facts are often used implicitly.

10.2.13 Theorem [Congruence]: C1 dh C2 implies CE,C1G* dh CE,C2G*. 2

Next, we define what it means for a constraint to determine a set of type
variables. In brief, C determines _Y if and only if, given a ground assignment
for ftvD^CE^ \ _Y and given that C holds, it is possible to reconstruct, in a unique
way, a ground assignment for _Y. Determinacy appears in the equivalence law
CngLetAll on page 418 and is exploited by the constraint solver in $10.6.

10.2 Constraints 417
10.2.14 Definition: C determines _Y if and only if, for every environment \Gamma  , two

ground assignments that satisfy def \Gamma  in C and that coincide outside _Y must
coincide on _Y as well. 2

We now give a toolbox of constraint equivalence laws. It is worth noting
that they do not form a complete axiomatization of constraint equivalence;
in fact, they cannot, since the syntax and meaning of constraints is partly
unspecified.

10.2.15 Theorem: All equivalence laws in Figure 10ng6 hold. 2

Let us explain. CngAnd and CngAndAnd state that conjunction is commutang
tive and associative. CngDup states that redundant conjuncts may be freely
added or removed, where a conjunct is redundant if and only if it is entailed
by another conjunct. Throughout this chapter, these three laws are often used
implicitly. CngExEx and CngEx* allow grouping consecutive existential quanting
fiers and suppressing redundant ones, where a quantifier is redundant if and
only if the variables bound by it do not occur free within its scope. CngExAnd
allows conjunction and existential quantification to commute, provided no
capture occurs; it is known as a scope extrusion law. When the rule is oring
ented from left to right, its sidengcondition may always be satisfied by suitable
ffngconversion. CngExTrans states that it is equivalent for a type T to be an
instance of oe or to be a supertype of some instance of oe . We note that the inng
stances of a monotype are its supertypes, that is, by Definition 10.2.3, T0 _ T
and T0 <= T are equivalent. As a result, specializing CngExTrans to the case
where oe is a monotype, we find that T0 <= T is equivalent to 9Z:D^T0 <= Z^Z <= TE^,
for fresh Z, a standard equivalence law. When oriented from left to right, it
becomes an interesting simplification law: in a chain of subtyping constraints,
an intermediate variable such as Z may be suppressed, provided it is local, as
witnessed by the existential quantifier 9Z. CngInId states that, within the scope
of the binding x : oe , every free occurrence of x may be safely replaced with oe .
The restriction to free occurrences stems from the sidengcondition x 62 dpiD^CE^.
When the rule is oriented from left to right, its other sidengconditions, which
require the context let x : oe in C not to capture oe 's free type variables or
free program identifiers, may always be satisfied by suitable ffngconversion.
CngIn* complements the previous rule by allowing redundant let bindings to
be simplified. We note that CngInId and CngIn* provide a simple procedure for
eliminating let forms. CngInAnd states that the let form commutes with conng
junction; CngInAnd* spells out a common particular case. CngInEx states that it
commutes with existential quantification. When the rule is oriented from left
to right, its sidengcondition may always be satisfied by suitable ffngconversion.
CngLetLet states that let forms may commute, provided they bind distinct

418 10 The Essence of ML Type Inference

C1 ^ C2 j C2 ^ C1 D^CngAndE^
D^C1 ^ C2E^ ^ C3 j C1 ^ D^C2 ^ C3E^ D^CngAndAndE^

C1 ^ C2 j C1 if C1 dh C2 D^CngDupE^

9_X:9_Y:C j 9_X_Y:C D^CngExExE^

9_X:C j C if _X # ftvD^CE^ D^CngEx*E^

D^9_X:C1E^ ^ C2 j 9_X:D^C1 ^ C2E^ if _X # ftvD^C2E^ D^CngExAndE^
9Z:D^oe _ Z ^ Z <= TE^ j oe _ T if Z 62 ftvD^oe; TE^ D^CngExTransE^
let x : oe in CE,x _ TG* j let x : oe in CE,oe _ TG* D^CngInIdE^

if x 62 dpiD^CE^ and dtvD^CE^ # ftvD^oeE^ and {x} [ dpiD^CE^ # fpiD^oeE^

let \Gamma  in C j 9\Gamma  ^ C if dpiD^\Gamma E^ # fpiD^CE^ D^CngIn*E^

let \Gamma  in D^C1 ^ C2E^ j D^let \Gamma  in C1E^ ^ D^let \Gamma  in C2E^ D^CngInAndE^
let \Gamma  in D^C1 ^ C2E^ j D^let \Gamma  in C1E^ ^ C2 if dpiD^\Gamma E^ # fpiD^C2E^ D^CngInAnd*E^

let \Gamma  in 9_X:C j 9_X:let \Gamma  in C if _X # ftvD^\Gamma E^ D^CngInExE^
let \Gamma 1; \Gamma 2 in C j let \Gamma 2; \Gamma 1 in C D^CngLetLetE^

if dpiD^\Gamma 1E^ # dpiD^\Gamma 2E^ and dpiD^\Gamma 2E^ # fpiD^\Gamma 1E^ and dpiD^\Gamma 1E^ # fpiD^\Gamma 2E^

let x : 8_XE,C1 ^ C2G*:T in C3 j C1 ^ let x : 8_XE,C2G*:T in C3 if _X # ftvD^C1E^ D^CngLetAndE^

let \Gamma  ; x : 8_XE,C1G*:T in C2 j let \Gamma  ; x : 8_XE,let \Gamma  in C1G*:T in C2 D^CngLetDupE^

if _X # ftvD^\Gamma E^ and dpiD^\Gamma E^ # fpiD^\Gamma E^

let x : 8_XE,9_Y:C1G*:T in C2 j let x : 8_X_YE,C1G*:T in C2 if _Y # ftvD^TE^ D^CngLetExE^

let x : 8_X_YE,C1G*:T in C2 j 9_Y:let x : 8_XE,C1G*:T in C2 D^CngLetAllE^

if _Y # ftvD^C2E^ and 9_X:C1 determines _Y

9X:D^T <= X ^ let x : X in CE^ j let x : T in C if X 62 ftvD^T; CE^ D^CngLetSubE^

~X C^ ~T ^ E,~X , ~TG*C j ~X C^ ~T ^ C D^CngEqE^

true j 9_X:D^~X C^ ~TE^ if _X # ftvD^_TE^ D^CngNameE^
E,~X , ~TG*C j 9_X:D^~X C^ ~T ^ CE^ if _X # ftvD^_TE^ D^CngNameEqE^

Figure 10ng6: Constraint equivalence laws

10.2 Constraints 419
program identifiers and provided no free program identifiers are captured
in the process. CngLetAnd allows the conjunct C1 to be moved outside of the
constrained type scheme 8_XE,C1 ^ C2G*:T, provided it does not involve any of
the universally quantified type variables _X. When oriented from left to right,
the rule yields an important simplification law: indeed, taking an instance of
8_XE,C2G*:T is less expensive than taking an instance of 8_XE,C1 ^C2G*:T, since the
latter involves creating a copy of C1, while the former does not. CngLetDup alng
lows pushing a series of let bindings into a constrained type scheme, provided
no capture occurs in the process. It is not used as a simplification law but as a
tool in some proofs. CngLetEx states that it does not make any difference for a
set of type variables _Y to be existentially quantified inside a constrained type
scheme or part of the type scheme's universal quantifiers. Indeed, in either
case, taking an instance of the type scheme means producing a constraint
where _Y is existentially quantified. CngLetAll states that it is equivalent for
a set of type variables _Y to be part of a type scheme's universal quantifiers
or existentially bound outside the let form, provided these type variables are
determined. In other words, when a type variable is sufficiently constrained,
it does not matter whether it is polymorphic or monomorphic. Together, Cng
LetEx and CngLetAll allow, in some situations, hoisting existential quantifiers
out of the leftnghand side of a let form.

10.2.16 Example: CngLetAll would be invalid without the condition that 9_X:C1 deng

termines _Y. Consider, for instance, the constraint let x : 8Y:Y ! Y in D^x _
int ! int ^ x _ bool ! boolE^ (1), where int and bool are incompatible nullary
type constructors. By CngInId and CngIn*, it is equivalent to 8Y:Y ! Y <= int !
int ^ 8Y:Y ! Y <= bool ! bool which, by Definition 10.2.3, means 9Y:D^Y !
Y <= int ! intE^ ^ 9Y:D^Y ! Y <= bool ! boolE^, that is, true. Now, if CngLetAll
was valid without its sidengcondition, then (1) would also be equivalent to
9Y:let x : Y ! Y in D^x _ int ! int^x _ bool ! boolE^, which by CngInId and CngIn*
is 9Y:D^Y ! Y <= int ! int ^ Y ! Y <= bool ! boolE^. By CngArrow and CngExTrans,
this is int C^ bool, that is, false. Thus, the law is invalid in this case. It is easy to
see why: when the type scheme oe contains a 8Y quantifier, every instance of
oe receives its own 9Y quantifier, making Y a distinct (local) type variable; but
when Y is not universally quantified, all instances of oe share references to a
single (global) type variable Y. This corresponds to the intuition that, in the
former case, oe is polymorphic in Y, while in the latter case, it is monomorphic
in Y. It is possible to prove that, when deprived of its sidengcondition, CngLetAll
is only an entailment law, that is, its rightnghand side entails its leftnghand side.
Similarly, it is in general invalid to hoist an existential quantifier out of the
leftnghand side of a let form. To see this, one may study the (equivalent) conng
straint let x : 8XE,9Y:X C^ Y ! YG*:X in D^x _ int ! int ^ x _ bool ! boolE^.
Naturally, in the above examples, the sidengcondition "true determines Y" does

420 10 The Essence of ML Type Inference

not hold: by Definition 10.2.14, it is equivalent to "two ground assignments
that coincide outside Y must coincide on Y as well," which is false when M?
contains two distinct elements, such as int and bool here.

There are cases, however, where the sidengcondition does hold. For instance,
we later prove that 9X:Y C^ int determines Y; see Lemma 10.6.7. As a result,
CngLetAll states that let x : 8XYE,Y C^ intG*:Y ! X in C (1) is equivalent to
9Y:let x : 8XE,Y C^ intG*:Y ! X in C (2), provided Y 62 ftvD^CE^. The intuition is
simple: because Y is forced to assume the value int by the equation Y C^ int, it
makes no difference whether Y is or isn't universally quantified. By CngLetAnd,
(2) is equivalent to 9Y:D^Y C^ int ^ let x : 8X:Y ! X in CE^ (3). In an efficient
constraint solver, simplifying (1) into (3) before using CngInId to eliminate the
let form is worthwhile, since doing so obviates the need for copying the type
variable Y and the equation Y C^ int at every free occurrence of x inside C. 2

CngLetSub is the analog of an environment strengthening lemma: roughly
speaking, it states that, if a constraint holds under the assumption that x has
type X, where X is some supertype of T, then it also holds under the assumpng
tion that x has type T. The last three rules deal with the equality predicate.
CngEq states that it is valid to replace equals with equals; note the absence of a
sidengcondition. When oriented from left to right, CngName allows introducing
fresh names ~X for the types ~T. As always, ~X stands for a vector of distinct
type variables; ~T stands for a vector of the same length of types of appropring
ate kind. Of course, this makes sense only if the definition is not circular, that
is, if the type variables _X do not occur free within the terms _T. When oriented
from right to left, CngName may be viewed as a simplification law: it allows
eliminating type variables whose value has been determined. CngNameEq is
a combination of CngEq and CngName. It shows that applying an idempotent
substitution to a constraint C amounts to placing C within a certain context.

So far, we have considered def a primitive constraint form and defined
the let form in terms of def, conjunction, and existential quantification. The
motivation for this approach was to simplify the (omitted) proofs of several
constraint equivalence laws. However, in the remainder of this chapter, we
work with let forms exclusively and never employ the def construct. This ofng
fers us an extra property: every constraint that contains a false subconstraint
must be false.

10.2.17 Lemma: CE,falseG* j false. 2

Reasoning with Constraints in an EqualityngOnly Syntactic Model
We have given a number of equivalence laws that are valid with respect to
any interpretation of constraints, that is, within any model. However, an imng

10.2 Constraints 421
portant special case is that of equalityngonly syntactic models. Indeed, in that
specific setting, our constraintngbased type systems are in close corresponng
dence with DM. In brief, we aim to prove that every satisfiable constraint C
such that fpiD^CE^ C^ IJ admits a canonical solved form and to show that this
notion corresponds to the standard concept of a most general unifier. These
results are exploited when we relate HMD^XE^ with Damas and Milner's system
(p. 428).

Thus, let us now assume that constraints are interpreted in an equalityng
only syntactic model. Let us further assume that, for every kind ^, (i) there
are at least two type constructors of image kind ^ and (ii) for every type conng
structor F of image kind ^, there exists t 2 M^ such that tD^fflE^ C^ F. We refer to
models that violate (i) or (ii) as degenerate; one may argue that such models
are of little interest. The assumption that the model is nondegenerate is used
in the proof of Theorem 10.3.7. Last, throughout the present subsection we
manipulate only constraints that have no free program identifiers.

A solved form is a conjunction of equations, where the leftnghand sides are
distinct type variables that do not appear in the rightnghand sides, possibly
surrounded by a number of existential quantifiers. Our definition is identing
cal to Lassez, Maher, and Marriott's solved forms (1988) and to Jouannaud
and Kirchner's tree solved forms (1991), except we allow for prenex existenng
tial quantifiers, which are made necessary by our richer constraint language.
Jouannaud and Kirchner also define dag solved forms, which may be expong
nentially smaller. Because we define solved forms only for proof purposes,
we need not take performance into account at this point. The efficient conng
straint solver presented in $10.6 does manipulate graphs, rather than trees.
Type scheme introduction and instantiation constructs cannot appear within
solved forms; indeed, provided the constraint at hand has no free program
identifiers, they can be expanded away. For this reason, their presence in the
constraint language has no impact on the results contained in this section.

10.2.18 Definition: A solved form is of the form 9_Y:D^~X C^ ~TE^, where _X # ftvD^_TE^. 2

Solved forms offer a convenient way of reasoning about constraints beng
cause every satisfiable constraint is equivalent to one. This property is estabng
lished by the following lemma.

10.2.19 Lemma: Every constraint is equivalent to either a solved form or false. 2

It is possible to impose further restrictions on solved forms. A solved form
9_Y:D^~X C^ ~TE^ is canonical if and only if its free type variables are exactly _X. This
is stated, in an equivalent way, by the following definition.

10.2.20 Definition: A canonical solved form is a constraint of the form 9_Y:D^~X C^ ~TE^,

where ftvD^_TE^ ` _Y and _X # _Y. 2

422 10 The Essence of ML Type Inference

10.2.21 Lemma: Every solved form is equivalent to a canonical solved form. 2

It is easy to describe the solutions of a canonical solved form: they are the
ground refinements of the substitution E,~X , ~TG*. Hence, every canonical
solved form is satisfiable.

The following definition allows entertaining a dual view of canonical solved
forms, either as constraints or as idempotent type substitutions. The latter
view is commonly found in standard treatments of unification (Lassez, Maher,
and Marriott, 1988; Jouannaud and Kirchner, 1991) and in classic presentang
tions of MLngthengtypengsystem.

10.2.22 Definition: If E,~X , ~TG* is an idempotent substitution of domain _X, let 9E,~X ,

~TG* denote the canonical solved form 9_Y:D^~X C^ ~TE^, where _Y C^ ftvD^_TE^. An idemng

potent substitution ` is a most general unifier of the constraint C if and only
if 9` and C are equivalent. 2

By definition, equivalent constraints admit the same most general unifiers.
Many properties of canonical solved forms may be reformulated in terms
of most general unifiers. By Lemmas 10.2.19 and 10.2.21, every satisfiable
constraint admits a most general unifier.

10.3 HMD^XE^

Constraintngbased type systems appeared during the 1980s (Mitchell, 1984;
Fuh and Mishra, 1988) and were widely studied during the following decade
(Curtis, 1990; Aiken and Wimmers, 1993; Jones, 1994; Smith, 1994; Palsberg,
1995; Trifonov and Smith, 1996; Fa"hndrich, 1999; Pottier, 2001b). We now
present one such system, baptized HMD^XE^ because it is a parameterized exng
tension of Hindley and Milner's type discipline; the meaning of the parameter
X was explained on page 411. Its original description is due to Odersky, Sulzng
mann, and Wehr (1999). Since then, it has been completed in a number of
works including Mu"ller (1998), Sulzmann, Mu"ller, and Zenger (1999), Sulzng
mann (2000), Pottier (2001a), and Skalka and Pottier (2002). Each of these
presentations introduces minor variations. Here, we follow Pottier (2001a),
which is itself inspired by Sulzmann, Mu"ller, and Zenger (1999).

Definition
Our presentation of HMD^XE^ relies on the constraint language introduced in

$10.2. Technically, our approach to constraints is less abstract than that
of Odersky, Sulzmann, and Wehr (1999). We interpret constraints within a
model, give conjunction and existential quantification their standard meanng

10.3 HMD^XE^ 423
\Gamma  D^xE^ C^ oe C dh 9oe

C; \Gamma  ` x : oe (hmxngVar)
C; D^\Gamma  ; z : TE^ ` t : T0
C; \Gamma  ` *z:t : T ! T0 (hmxngAbs)
C; \Gamma  ` t1 : T ! T0 C; \Gamma  ` t2 : T

C; \Gamma  ` t1 t2 : T0 (hmxngApp)
C; \Gamma  ` t1 : oe C; D^\Gamma  ; z : oe E^ ` t2 : T

C; \Gamma  ` let z C^ t1 in t2 : T (hmxngLet)

C ^ D; \Gamma  ` t : T _X # ftvD^C; \Gamma  E^

C ^ 9_X:D; \Gamma  ` t : 8_XE,DG*:T (hmxngGen)

C; \Gamma  ` t : 8_XE,DG*:T

C ^ D; \Gamma  ` t : T (hmxngInst)
C; \Gamma  ` t : T C dh T <= T0

C; \Gamma  ` t : T0 (hmxngSub)
C; \Gamma  ` t : oe _X # ftvD^\Gamma  ; oe E^

9_X:C; \Gamma  ` t : oe (hmxngExists)

Figure 10ng7: Typing rules for HMD^XE^

ing, and derive a number of equivalence laws ($10.2). Odersky et al., on the
other hand, do not explicitly rely on a logical interpretation; instead, they
axiomatize constraint equivalence, that is, they consider a number of equivang
lence laws as axioms. Thus, they ensure that their highnglevel proofs, such as
type soundness and correctness and completeness of type inference, are inng
dependent of the lownglevel details of the logical interpretation of constraints.
Their approach is also more general, since it allows dealing with other loging
cal interpretations, such as "openngworld" interpretations, where constraints
are interpreted not within a fixed model, but within a family of extensions
of a "current" model. In this chapter, we have avoided this extra layer of abng
straction and given fixed meaning to constraints, making things somewhat
simpler. However, the changes required to adopt Odersky et al.'s approach
would not be extensive, since the forthcoming proofs do indeed rely mostly
on constraint equivalence laws, rather than on lownglevel details of the logical
interpretation of constraints.

Another slight departure from Odersky et al.'s work lies in the fact that
we have enriched the constraint language with type scheme introduction and
instantiation forms, which were absent in the original presentation of HMD^XE^.
To prevent this addition from affecting HMD^XE^, we require the constraints
that appear in HMD^XE^ typing judgments to have no free program identifiers.
Note that this does not prevent them from containing let forms.

The type system HMD^XE^ consists of a fourngplace judgment whose parameng
ters are a constraint C, an environment \Gamma  , an expression t, and a type scheme
oe . A judgment is written C; \Gamma  ` t : oe and is read: under the assumptions C
and \Gamma  , the expression t has type oe . One may view C as an assumption about

424 10 The Essence of ML Type Inference

the judgment's free type variables and \Gamma  as an assumption about t's free prong
gram identifiers. Recall that \Gamma  now contains constrained type schemes, and
that oe is a constrained type scheme.

We would like the validity of a typing judgment to depend not on the synng
tax, but only on the meaning of its constraint assumption. We enforce this
point of view by considering judgments equal modulo equivalence of their
constraint assumptions. In other words, the typing judgments C; \Gamma  ` t : oe
and D; \Gamma  ` t : oe are considered identical when C j D holds. A judgment is
valid, or holds, if and only if it is derivable via the rules given in Figure 10ng7.
Note that a valid judgment may involve an arbitrary constraint. A (closed)
program t is wellngtyped within the (closed) environment \Gamma  if and only if a
judgment of the form C; \Gamma  ` t : oe holds for some satisfiable constraint C. One
might wonder why we do not make the apparently stronger requirement that
C ^ 9oe be satisfiable; however, by inspection of the typing rules, the reader
may check that, if the above judgment is derivable, then C dh 9oe holds, hence
the two requirements are equivalent.

Let us now explain the rules. Like dmngVar, hmxngVar looks up the environng
ment to determine the type scheme associated with the program identifier x.
Its second premise plays a minor technical role: as noted in the previous parang
graph, its presence helps simplify the definition of wellngtypedness. hmxngAbs,
hmxngApp, and hmxngLet are identical to dmngAbs, dmngApp, and dmngLet, respecng
tively, except that the assumption C is made available to every subderivation.
We recall that the type T may be viewed as the type scheme 8IJE,trueG*:T (Defing
nitions 10.1.18 and 10.2.2). As a result, types form a subset of type schemes,
which implies that \Gamma  ; z : T is a wellngformed environment and C; \Gamma  ` t : T a
wellngformed typing judgment. To understand hmxngGen, it is best to first conng
sider the particular case where C is true. This yields the following, simpler
rule:

D; \Gamma  ` t : T _X # ftvD^\Gamma  E^

9_X:D; \Gamma  ` t : 8_XE,DG*:T (hmxngGen')

The second premise is identical to that of dmngGen: the type variables that
are generalized must not occur free within the environment. The conclusion
forms the type scheme 8_XE,DG*:T, where the type variables _X have become uning
versally quantified, but are still subject to the constraint D. Note that the
type variables that occur free in D may include not only _X, but also other
type variables, typically free in \Gamma  . hmxngGen may be viewed as a more liberal
version of hmxngGen', whereby part of the current constraint, namely C, need
not be copied if it does not concern the type variables that are being generng
alized, namely _X. This optimization is important in practice, because C may
be very large. An intuitive explanation for its correctness is given by the conng

10.3 HMD^XE^ 425
straint equivalence law CngLetAnd, which expresses the same optimization in
terms of let constraints. Because HMD^XE^ does not use let constraints, the opng
timization is hardngwired into the typing rule. As a last technical remark, let
us point out that replacing C ^ 9_X:D with C ^ D in hmxngGen's conclusion
would not affect the set of derivable judgments; this fact may be established
using hmxngExists and Lemma 10.3.1. hmxngInst allows taking an instance of
a type scheme. The reader may be surprised to find that, contrary to dmng
Inst, it does not involve a type substitution. Instead, the rule merely drops
the universal quantifier, which amounts to applying the identity substitung
tion ~X , ~X. One should recall, however, that type schemes are considered
equal modulo ffngconversion, so it is possible to rename the type scheme's
universal quantifiers prior to using hmxngInst. The reason why this provides
sufficient expressive power appears in Exercise 10.3.2 below. The constraint
D carried by the type scheme is recorded as part of the current constraint
in hmxngInst's conclusion. The subsumption rule hmxngSub allows a type T to
be replaced at any time with an arbitrary supertype T0. Because both T and
T0 may have free type variables, whether T <= T0 holds depends on the curng
rent assumption C, which is why the rule's second premise is an entailment
assertion. An operational explanation of hmxngSub is that it requires all uses
of subsumption to be explicitly recorded in the current constraint. Note that
hmxngSub remains a useful and necessary rule even when subtyping is interng
preted as equality: then, it allows exploiting the type equations found in C.
Last, hmxngExists allows the type variables that occur only within the current
constraint to become existentially quantified. As a result, these type variables
no longer occur free in the rule's conclusion; in other words, they have beng
come local to the subderivation rooted at the premise. One may prove that
the presence of hmxngExists in the type system does not augment the set of
wellngtyped programs, but does augment the set of valid typing judgments; it
is a pleasant technical convenience. Indeed, because judgments are considng
ered equal modulo constraint equivalence, constraints may be transparently
simplified at any time. (By simplifying a constraint, we mean replacing it with
an equivalent constraint whose syntactic representation is considered simng
pler.) Bearing this fact in mind, one finds that an effect of rule hmxngExists
is to enable more simplifications: because constraint equivalence is a conng
gruence, C j D implies 9_X:C j 9_X:D, but the converse does not hold in
general. For instance, there is in general no way of simplifying the judgment
X <= Y <= Z; \Gamma  ` t : oe , but if it is known that Y does not appear free in \Gamma  or
oe , then hmxngExists allows deriving 9Y:D^X <= Y <= ZE^; \Gamma  ` t : oe , which is the
same judgment as X <= Z; \Gamma  ` t : oe . Thus, an interesting simplification has
been enabled. Note that X <= Y <= Z j X <= Z does not hold, while, according to
CngExTrans, 9Y:D^X <= Y <= ZE^ j X <= Z does.

426 10 The Essence of ML Type Inference

A pleasant property of HMD^XE^ is that strengthening a judgment's conng
straint assumption (that is, weakening the judgment itself) preserves its vang
lidity. It is worth noting that in traditional presentations, which rely more
heavily on type substitutions, the analog of this result is a type substitung
tion lemma; see for instance Tofte (1988), Lemma 2.7; Re'my (1992a), Lemma
1; Leroy (1992), Proposition 1.2; and Skalka and Pottier (2002), Lemma 3.4.
Here, the lemma further states that weakening a judgment does not alter the
shape of its derivation, a useful property when reasoning by induction on
type derivations.

10.3.1 Lemma [Weakening]: If C0 dh C, then every derivation of C; \Gamma  ` t : oe may be

turned into a derivation of C0; \Gamma  ` t : oe with the same shape. 2

10.3.2 Exercise [Recommended, n'n']: In some presentations of HMD^XE^, hmxngInst

is replaced with the following variant:

C; \Gamma  ` t : 8_XE,DG*:T C dh E,~X , ~TG*D

C; \Gamma  ` t : E,~X , ~TG*T (hmxngInst')
Show that hmxngInst' is admissible in our presentation of HMD^XE^--that is, if its
premise is derivable according to the rules of Figure 10ng7, then so is its conng
clusion. Thus, the choice between hmxngInst and hmxngInst' is only stylistic: it
makes no difference in the system's expressive power. Because hmxngInst is
more elementary, choosing it simplifies some proofs. 2

10.3.3 Exercise [n']: Give a derivation of true; IJ ` *z:z : int ! int. Give a derivation

of true; IJ ` *z:z : 8X:X ! X. Check that the former judgment also follows
from the latter via hmxngInst' (Exercise 10.3.2), and determine which derivang
tion of true; IJ ` *z:z : int ! int this path gives rise to. 2

We do not give a direct type soundness proof for HMD^XE^. Instead, in the
forthcoming sections, we prove that wellngtypedness in HMD^XE^ is equivalent
to the satisfiability of a certain constraint and use that characterization as
a basis for our type soundness proof. A direct type soundness result, based
on a denotational semantics, may be found in Odersky, Sulzmann, and Wehr
(1999). Another type soundness proof, which follows Wright and Felleisen's
syntactic approach (1994), appears in Skalka and Pottier (2002). Last, a hybrid
approach, which combines some of the advantages of the previous two, is
given in Pottier (2001a).

An Alternate Presentation of HMD^XE^
The presentation of HMD^XE^ given in Figure 10ng7 has only four syntaxngdirected
rules out of eight. It is a good specification of the type system, but it is far

10.3 HMD^XE^ 427
\Gamma  D^xE^ C^ 8_XE,DG*:T

C ^ D; \Gamma  ` x : T (hmdngVarInst)

C; D^\Gamma  ; z : TE^ ` t : T0
C; \Gamma  ` *z:t : T ! T0 (hmdngAbs)

C; \Gamma  ` t1 : T ! T0 C; \Gamma  ` t2 : T

C; \Gamma  ` t1 t2 : T0 (hmdngApp)

C ^ D; \Gamma  ` t1 : T1 _X # ftvD^C; \Gamma  E^
C ^ 9_X:D; D^\Gamma  ; z : 8_XE,DG*:T1E^ ` t2 : T2

C ^ 9_X:D; \Gamma  ` let z C^ t1 in t2 : T2

(hmdngLetGen)
C; \Gamma  ` t : T C dh T <= T0

C; \Gamma  ` t : T0 (hmdngSub)
C; \Gamma  ` t : T _X # ftvD^\Gamma  ; TE^

9_X:C; \Gamma  ` t : T (hmdngExists)

Figure 10ng8: An alternate presentation of HMD^XE^

from an algorithmic description. As a first step towards such a description,
we provide an alternate presentation of HMD^XE^, where generalization is perng
formed only at let expressions and instantiation takes place only at referng
ences to program identifiers (Figure 10ng8). This presentation only has two
nonngsyntaxngdirected rules, making it sometimes easier to reason about. It has
the property that all judgments are of the form C; \Gamma  ` t : T, rather than
C; \Gamma  ` t : oe . The following theorem states that the two presentations are
indeed equivalent.

10.3.4 Theorem: C; \Gamma  ` t : T is derivable via the rules of Figure 10ng8 if and only if it

is a valid HMD^XE^ judgment. 2

This theorem shows that the rule sets of Figures 10ng7 and 10ng8 derive
the same monomorphic judgments, that is, the same judgments of the form
C; \Gamma  ` t : T. The fact that judgments of the form C; \Gamma  ` t : oe , where oe is
a not a monotype, cannot be derived using the new rule set is a technical
simplification, without deep significance.

10.3.5 Exercise [n'n'n', 3]: Show that it is possible to simplify the presentation of

Damas and Milner's type system in an analogous manner. That is, define an
alternate set of typing rules for DM, which allows deriving judgments of the
form \Gamma  ` t : T; then, show that this new rule set is equivalent to the previous
one, in the same sense as above. Which auxiliary properties of DM does your
proof require? A solution is given by Clement, Despeyroux, Despeyroux, and
Kahn (1986). 2

428 10 The Essence of ML Type Inference

Relating HMD^XE^ with Damas and Milner's Type System
In order to explain our interest in HMD^XE^, we wish to show that it is more genng
eral than Damas and Milner's type system. Since HMD^XE^ really is a family of
type systems, we must make this statement more precise. First, every memng
ber of the HMD^XE^ family contains DM. Conversely, DM contains HMD^C^E^, the
constraintngbased type system obtained by specializing HMD^XE^ to the setting
of an equalityngonly syntactic model.

The first of these assertions is easy to prove because the mapping from
DM judgments to HMD^XE^ judgments is essentially the identity: every valid
DM judgment may be viewed as a valid HMD^XE^ judgment under the trivial
assumption true. This statement relies on the fact that the DM type scheme
8_X:T is identified with the constrained type scheme 8_XE,trueG*:T, so DM type
schemes (respectively environments) form a subset of HMD^XE^ type schemes
(respectively environments). Its proof is easy and relies on Exercise 10.3.2.

10.3.6 Theorem: If \Gamma  ` t : S holds in DM, then true; \Gamma  ` t : S holds in HMD^XE^. 2

We are now interested in proving that HMD^C^E^, as defined above, is conng
tained within DM. To this end, we must translate every HMD^C^E^ judgment to
a DM judgment. It turns out that this is possible if the original judgment's
constraint assumption is satisfiable. The translation relies on the fact that
the definition of HMD^C^E^ assumes an equalityngonly syntactic model. Indeed, in
that setting, every satisfiable constraint admits a most general unifier (Defing
nition 10.2.22), whose properties we make essential use of.

Unfortunately, due to lack of space, we cannot give the details of this transng
lation, which are fairly involved. Let us merely say that, given a type scheme
oe and an idempotent type substitution ` such that ftvD^oe E^ ` domD^`E^ and
9` dh 9oe hold, the translation of oe under ` is a DM type scheme, written
Joe K`. Its meaning is intended to be the same as that of the HMD^XE^ type
scheme `D^oe E^. For instance, under the identity substitution, the translation of
the HMD^XE^ type scheme 8XYE,X C^ Y ! YG*:X is the DM type scheme 8Z:Z ! Z.
The translation is extended to environments in such a way that J\Gamma  K` is defined
when ftvD^\Gamma  E^ ` domD^`E^ holds. We are now ready to state the main theorem.

10.3.7 Theorem: Let C; \Gamma  ` t : oe hold in HMD^C^E^. Let ` be a most general unifier of

C such that ftvD^\Gamma  ; oe E^ ` domD^`E^. Then, J\Gamma  K` ` t : Joe K` holds in DM. 2

Note that, by requiring ` to be a most general unifier of C, we also require C
to be satisfiable. Judgments that carry an unsatisfiable constraint cannot be
translated.

Together, Theorems 10.3.6 and 10.3.7 yield a precise correspondence beng
tween DM and HMD^C^E^: there exists a compositional translation from each to

10.4 Constraint Generation 429
the other. In other words, they may be viewed as two equivalent formulations
of a single type system. One might also say that HMD^C^E^ is a constraintngbased
formulation of DM. Furthermore, Theorem 10.3.6 states that every member of
the HMD^XE^ family is an extension of DM. This explains our double interest in
HMD^XE^, as an alternate formulation of DM, which we believe is more pleasant
for reasons already discussed, and as a more expressive framework.

10.4 Constraint Generation

We now explain how to reduce type inference problems for HMD^XE^ to conng
straint solving problems. A type inference problem consists of a type environng
ment \Gamma  , an expression t, and a type T of kind ?. The problem is to determine
whether there exists a satisfiable constraint C such that C; \Gamma  ` t : T holds. A
constraint solving problem consists of a constraint C. The problem is to deng
termine whether C is satisfiable. To reduce a type inference problem D^\Gamma  ; t; TE^
to a constraint solving problem, we must produce a constraint C that is both
sufficient and necessary for C; \Gamma  ` t : T to hold. Below, we explain how to
compute such a constraint, which we write J\Gamma  ` t : TK. We check that it is
indeed sufficient by proving J\Gamma  ` t : TK; \Gamma  ` t : T. That is, the constraint
J\Gamma  ` t : TK is specific enough to guarantee that t has type T under environng
ment \Gamma  . We say that constraint generation is sound. We check that it is indeed
necessary by proving that, for every constraint C, the validity of C; \Gamma  ` t : T
implies C dh J\Gamma  ` t : TK. That is, every constraint that guarantees that t has
type T under environment \Gamma  is at least as specific as J\Gamma  ` t : TK. We say
that constraint generation is complete. Together, these properties mean that
J\Gamma  ` t : TK is the least specific constraint that guarantees that t has type T
under environment \Gamma  .

We now see how to reduce a type inference problem to a constraint solving
problem. Indeed, if there exists a satisfiable constraint C such that C; \Gamma  `
t : T holds, then, by the completeness property, C dh J\Gamma  ` t : TK holds, so
J\Gamma  ` t : TK is satisfiable. Conversely, by the soundness property, if J\Gamma  ` t : TK
is satisfiable, then we have a satisfiable constraint C such that C; \Gamma  ` t : T
holds. In other words, t is wellngtyped with type T under environment \Gamma  if and
only if J\Gamma  ` t : TK is satisfiable.

The reader may be somewhat puzzled by the fact that our formulation
of the type inference problem requires an appropriate type T to be known
in advance, whereas the very purpose of type inference seems to consist in
discovering the type of t! In other words, we have made T an input of the conng
straint generation algorithm, instead of an output. Fortunately, this causes
no loss of generality, because it is possible to let T be a type variable X, chong

430 10 The Essence of ML Type Inference

sen fresh for \Gamma  . Then, the constraint produced by the algorithm will contain
information about X. This is the point of the following exercise.

10.4.1 Exercise [Recommended, n']: Let X 62 ftvD^\Gamma  E^. Show that, if there exist a satng

isfiable constraint C and a type T such that C; \Gamma  ` t : T holds, then there
exists a satisfiable constraint C0 such that C0; \Gamma  ` t : X holds. Conclude that,
given a closed environment \Gamma  and an arbitrary type variable X, the term t is
wellngtyped within \Gamma  if and only if J\Gamma  ` t : XK is satisfiable. 2

This shows that providing T as an input to the constraint generation proceng
dure is not essential. We adopt this style because it is convenient. A somewhat
naive alternative would be to provide \Gamma  and t only, and to have the procedure
return both a constraint C and a type T (Sulzmann, Mu"ller, and Zenger, 1999).
It turns out that this does not quite work, because C and T may mention
"fresh" variables, which we must be able to quantify over, if we are to avoid
an informal treatment of "freshness." Thus, the true alternative is to provide
\Gamma  and t only and to have the procedure return a type scheme oe (Bourdoncle
and Merz, 1997; Bonniot, 2002).

The existence of a sound and complete constraint generation procedure
is the analog of the existence of principal type schemes in classic presentang
tions of MLngthengtypengsystem (Damas and Milner, 1982). Indeed, a principal
type scheme is least specific in the sense that all valid types are substitution
instances of it. Here, the constraint J\Gamma  ` t : TK is least specific in the sense
that all valid constraints entail it. More about principal types and principal
typings may be found in Jim (1996) and Wells (2002).

How do we perform constraint generation? A standard approach (Sulzng
mann, Mu"ller, and Zenger, 1999; Bonniot, 2002) is to define J\Gamma  ` t : TK by
induction on the structure of t. At every let node, following hmdngLetGen,
part of the current constraint, namely D, is turned into a type scheme, namely
8_XE,DG*:T, which is used to extend the environment. Then, at every occurrence
of the program variable that was bound at this let node, following hmdng
VarInst, this type scheme is retrieved from the environment, and a copy of
D is added back to the current constraint. If such an approach is adopted, it is
important to simplify the type scheme 8_XE,DG*:T before it is stored in the enng
vironment, because it would be inefficient to copy an unsimplified constraint.
In other words, in an efficient implementation of this standard approach,
constraint generation and constraint simplification cannot be separated.

Type scheme introduction and elimination constraints, which we introng
duced in $10.2 but did not use in the specification of HMD^XE^, are intended
as a means of solving this problem. By extending our vocabulary, we are able
to achieve the desired separation between constraint generation, on the one
hand, and constraint solving and simplification, on the other hand, without

10.4 Constraint Generation 431

Jx : TK C^ x _ T
J*z:t : TK C^ 9X1X2:D^let z : X1 in Jt : X2K ^ X1 ! X2 <= TE^
Jt1 t2 : TK C^ 9X2:D^Jt1 : X2 ! TK ^ Jt2 : X2KE^
Jlet z C^ t1 in t2 : TK C^ let z : 8XE,Jt1 : XKG*:X in Jt2 : TK

Figure 10ng9: Constraint generation

compromising efficiency. Indeed, by exploiting these new constraint forms,
we may define a constraint generation procedure whose time and space comng
plexity is linear, because it no longer involves copying subconstraints back
and forth between the environment and the constraint that is being generng
ated. (It is then up to the constraint solver to perform simplification and
copying, if and when necessary.) In fact, the environment is suppressed alng
together: we define Jt : TK by induction on the structure of t--notice the
absence of the parameter \Gamma  . Then, the constraint J\Gamma  ` t : TK discussed above
becomes syntactic sugar for let \Gamma  in Jt : TK. We now employ the full constraint
language: the program identifiers that appear free in t may also appear free in
Jt : TK, as part of instantiation constraints. They become bound when Jt : TK
is placed within the context let \Gamma  in E,G*. A similar approach to constraint genng
eration appears in Mu"ller (1994).

The defining equations for Jt : TK appear in Figure 10ng9. We refer to them
as the constraint generation rules. The definition is quite terse and certainly
simpler than the declarative specification of HMD^XE^ given in Figure 10ng7; yet,
we prove below that the two are equivalent.

Before explaining the definition, we state the requirements that bear on
the type variables X1, X2, and X, which appear bound in the rightnghand sides
of the second, third, and fourth equations. These type variables must have
kind ?. They must be chosen distinct (that is, X1 6C^ X2 in the second equang
tion) and fresh for the objects that appear on the leftnghand side--that is, the
type variables that appear bound in an equation's rightnghand side must not
occur free in the term and type that appear in the equation's leftnghand side.
Provided this restriction is obeyed, different choices of X1, X2, and X lead
to ffngequivalent constraints--that is, to the same constraint, since we idenng
tify objects up to ffngconversion--which guarantees that the above equations
make sense. Since expressions do not have free type variables, the freshness
requirement may be simplified to: type variables that appear bound in an
equation's rightnghand side must not appear free in T. However, this simplificang
tion would be rendered invalid by the introduction of open type annotations

432 10 The Essence of ML Type Inference

within expressions. Note that we are able to state a precise (as opposed to inng
formal) freshness requirement. This is made possible by the fact that Jt : TK
has no free type variables other than those of T, which in turn depends on
our explicit use of existential quantification to limit the scope of auxiliary
variables.

Let us now review the four equations. The first equation may be read: x
has type T if and only if T is an instance of the type scheme associated with
x. Note that we no longer consult the type scheme associated with x in the
environment--indeed, there is no environment. Instead, we merely generate
an instantiation constraint, where x appears free. (For this reason, every prong
gram identifier that occurs free within t typically also occurs free within
Jt : TK.) This constraint acquires its full meaning when it is later placed within
a context of the form let x : oe in E,G*. This equation roughly corresponds to
hmdngVarInst. The second equation may be read: *z:t has type T if and only
if, for some X1 and X2, (i) under the assumption that z has type X1, t has type
X2, and (ii) T is a supertype of X1 ! X2. Here, the types associated with z
and t must be fresh type variables, namely X1 and X2, because we cannot in
general guess them. These type variables are bound so as to guarantee that
the generated constraint is unique up to ffngconversion. They are existentially
bound because we intend the constraint solver to discover their value. Conng
dition (i) is expressed by the subconstraint let z : X1 in Jt : X2K. This makes
sense as follows. The constraint Jt : X2K typically contains a number of inng
stantiation constraints bearing on z, of the form z _ Ti. By wrapping it within
the context let z : X1 in E,G*, we effectively require every Ti to be a supertype
of X1. Note that z does not occur free in the constraint let z : X1 in Jt : X2K,
which is necessary for wellngformedness of the definition, since it does not
occur free in *z:t. This equation roughly corresponds to hmdngExists, hmdng
Abs, and hmdngSub. The third equation may be read: t1 t2 has type T if and
only if, for some X2, t1 has type X2 ! T and t2 has type X2. Here, the fresh
type variable X2 stands for the unknown type of t2. This equation roughly
corresponds to hmdngApp. The last equation, which roughly corresponds to
hmdngLetGen, may be read: let z C^ t1 in t2 has type T if and only if, under
the assumption that z has every type X such that Jt1 : XK holds, t2 has type
T. As in the case of *ngabstractions, the instantiation constraints bearing on z
that appear within Jt2 : TK are given a meaning via a let prefix. The difference
is that z may now be assigned a type scheme, as opposed to a monotype.
An appropriate type scheme is built as follows. The constraint Jt1 : XK is the
least specific constraint that must be imposed on the fresh type variable X
so as to make it a valid type for t1. In other words, t1 has every type X such
that Jt1 : XK holds, and none other. That is, the type scheme 8XE,Jt1 : XKG*:X,
abbreviated oe in the following, is a principal type scheme for t1. It is interng

10.4 Constraint Generation 433
esting to note that there is no question of which type variables to generalize.
Indeed, by construction, no type variables other than X may appear free in
Jt1 : XK, so we cannot generalize more variables. On the other hand, it is valid
to generalize X, since it does not appear free anywhere else. This interesting
simplification is inspired by Sulzmann, Mu"ller, and Zenger (1999), where a
similar technique is used. Now, what happens when Jt2 : TK is placed inside
the context let z : oe in E,G*? When placed inside this context, an instantiation
constraint of the form z _ T0 acquires the meaning oe _ T0, which by defining
tion of oe and by Lemma 10.4.6 (see below) is equivalent to Jt1 : T0K. Thus, the
constraint produced by the fourth equation simulates a textual expansion of
the let construct, where every occurrence of z would be replaced with t1.
Thanks to type scheme introduction and instantiation constraints, however,
this effect is achieved without duplication of source code or constraints. In
other words, constraint generation has linear time and space complexity.

10.4.2 Exercise [n', 3]: Define the size of an expression, of a type, and of a conng

straint, viewed as abstract syntax trees. Check that the size of Jt : TK is linear
in the sum of the sizes of t and T. 2

10.4.3 Exercise [Recommended, n', 3]: Compute and simplify, as best as you can,

the constraint Jlet f C^ *z:z in f f : TK. 2

We now state several properties of constraint generation. We begin with
soundness, whose statement was explained above.

10.4.4 Theorem [Soundness]: let \Gamma  in Jt : TK; \Gamma  ` t : T. 2

The following lemmas are used in the proof of the completeness property
and in a number of other occasions. The first two state that Jt : TK is covaring
ant with respect to T. Roughly speaking, this means that enough subtyping
constraints are generated to achieve completeness with respect to hmdngSub.

10.4.5 Lemma: Jt : TK ^ T <= T0 dh Jt : T0K. 2
10.4.6 Lemma: X 62 ftvD^TE^ implies 9X:D^Jt : XK ^ X <= TE^ j Jt : TK. 2

The next lemma gives a simplified version of the second constraint generang
tion rule, in the specific case where the expected type is an arrow type. Thus,
fresh type variables need not be generated; one may directly use the arrow's
domain and codomain instead.

10.4.7 Lemma: J*z:t : T1 ! T2K is equivalent to let z : T1 in Jt : T2K. 2

We conclude with the completeness property. The theorem states that if,
within HMD^XE^, t has type T under assumptions C and \Gamma  , then C must be at

434 10 The Essence of ML Type Inference

least as specific as let \Gamma  in Jt : TK. The statement requires C and \Gamma  to have
no free program identifiers, which is natural, since they are part of an HMD^XE^
judgment. The hypothesis C dh 9\Gamma  excludes the somewhat pathological situang
tion where \Gamma  contains constraints not apparent in C. This hypothesis vanishes
when \Gamma  is the initial environment; see Definition 10.5.2.

10.4.8 Theorem [Completeness]: Let C dh 9\Gamma  . Assume fpiD^C; \Gamma  E^ C^ IJ. If C; \Gamma  ` t : T

holds in HMD^XE^, then C entails let \Gamma  in Jt : TK. 2

10.5 Type Soundness

We are now ready to establish type soundness for our type system. The
statement that we wish to prove is sometimes known as Milner's slogan:
"Wellngtyped programs do not go wrong" (Milner, 1978). Below, we define wellng
typedness in terms of our constraint generation rules, for the sake of conng
venience, and establish type soundness with respect to that particular defng
inition. Theorems 10.3.6 and 10.4.8 imply that type soundness also holds
when wellngtypedness is defined with respect to the typing judgments of DM
or HMD^XE^. We establish type soundness by following Wright and Felleisen's
songcalled syntactic approach (1994). The approach consists of isolating two inng
dependent properties. Subject reduction, whose exact statement will be given
below, implies that wellngtypedness is preserved by reduction. Progress states
that no stuck configuration is wellngtyped. It is immediate to check that, if both
properties hold, then no wellngtyped program can reduce to a stuck configung
ration. Subject reduction itself depends on a key lemma, usually known as a
(term) substitution lemma. Here is a version of this lemma, stated in terms of
the constraint generation rules.

10.5.1 Lemma: let z : 8_XE,Jt2 : T2KG*:T2 in Jt1 : T1K entails JE,z , t2G*t1 : T1K. 2

Before going on, let us give a few definitions and formulate several reng
quirements. First, we must define an initial environment \Gamma 0, which assigns a
type scheme to every constant. A couple of requirements must be established
to ensure that \Gamma 0 is consistent with the semantics of constants, as specified

by ffi-!. Second, we must extend constraint generation and wellngtypedness to
configurations, as opposed to programs, since reduction operates on configung
rations. Last, we must formulate a restriction to tame the interaction between
side effects and letngpolymorphism, which is unsound if unrestricted.

10.5.2 Definition: Let \Gamma 0 be an environment whose domain is the set of constants

Q. We require ftvD^\Gamma 0E^ C^ IJ, fpiD^\Gamma 0E^ C^ IJ, and 9\Gamma 0 j true. We refer to \Gamma 0 as the
initial typing environment. 2

10.5 Type Soundness 435
10.5.3 Definition: Let ref be an isolated, invariant type constructor of signature

? ) ?. A store type M is a finite mapping from memory locations to types. We
write ref M for the environment that maps every m 2 domD^ME^ to ref MD^mE^.
Assuming domD^uE^ and domD^ME^ coincide, the constraint Ju : MK is defined
as the conjunction of the constraints JuD^mE^ : MD^mE^K, where m ranges over
domD^uE^. Under the same assumption, the constraint Jt=u : T=MK is defined
as Jt : TK ^ Ju : MK. A closed configuration t=u is wellngtyped if and only if
there exist a type T and a store type M such that domD^uE^ C^ domD^ME^ and the
constraint let \Gamma 0; ref M in Jt=u : T=MK is satisfiable. 2

The type ref T is the type of references (that is, memory locations) that
store data of type T (TAPL, Chapter 13). It must be invariant in its parameter,
reflecting the fact that references may be both read and written.

A store is a complex object: it may contain values that indirectly refer to
each other via memory locations. In fact, it is a representation of the graph
formed by objects and pointers in memory, which may contain cycles. We rely
on store types to deal with such cycles. In the definition of wellngtypedness,
the store type M imposes a constraint on the contents of the store--the value
uD^mE^ must have type MD^mE^--but also plays the role of a hypothesis: by placng
ing the constraint Jt=u : T=MK within the context let ref M in E,G*, we give
meaning to free occurrences of memory locations within Jt=u : T=MK, and
stipulate that it is valid to assume that m has type MD^mE^. In other words, we
essentially view the store as a large, mutually recursive binding of locations
to values. The context let \Gamma 0 in E,G* gives meaning to occurrences of constants
within Jt=u : T=MK.

We now define a relation between configurations that plays a key role in the
statement of the subject reduction property. The point of subject reduction is
to guarantee that wellngtypedness is preserved by reduction. However, such a
simple statement is too weak to be amenable to inductive proof. Thus, for the
purposes of the proof, we must be more specific. To begin, let us consider the
simpler case of a pure semantics, that is, a semantics without stores. Then,
we must state that if an expression t has type T under a certain constraint,
then its reduct t0 has type T under the same constraint. In terms of generated
constraints, this statement becomes: let \Gamma 0 in Jt : TK entails let \Gamma 0 in Jt0 : TK.
Let us now return to the general case, where a store is present. The stateng
ment of wellngtypedness for a configuration t=u now involves a store type
M whose domain is that of u. So, the statement of wellngtypedness for its
reduct t0=u0 must involve a store type M0 whose domain is that of u0, which
is larger if allocation occurred. The types of existing memory locations must
not change: we must request that M and M0 agree on domD^ME^, that is, M0
must extend M. Furthermore, the types assigned to new memory locations in

436 10 The Essence of ML Type Inference

domD^M0E^\domD^ME^ might involve new type variables, that is, variables that do
not appear free in M or T. We must allow these variables to be hidden--that
is, existentially quantified--otherwise the entailment assertion cannot hold.
These considerations lead us to the following definition:

10.5.4 Definition: t=u v t0=u0 holds if and only if, for every type T and for every

store type M such that domD^uE^ C^ domD^ME^, there exist a set of type variables
_Y and a store type M0 such that _Y # ftvD^T; ME^ and ftvD^M0E^ ` _Y [ ftvD^ME^ and

domD^M0E^ C^ domD^u0E^ and M0 extends M and

let \Gamma 0; ref M in Jt =u : T=M K
dh 9_Y:let \Gamma 0; ref M0 in Jt0=u0 : T=M0K:

The relation v is intended to express a connection between a configuration
and its reduct. Thus, subject reduction may be stated as: D^--n~E^ ` D^vE^, that
is, v is indeed a conservative description of reduction. 2

We have introduced an initial environment \Gamma 0 and used it in the definition
of wellngtypedness, but we haven't yet ensured that the type schemes assigned
to constants are an adequate description of their semantics. We now forng

mulate two requirements that relate \Gamma 0 with ffi-!. They are specializations of
the subject reduction and progress properties to configurations that involve
an application of a constant. They represent proof obligations that must be

discharged when concrete definitions of Q, ffi-!, and \Gamma 0 are given.

10.5.5 Definition: We require (i) D^ ffi-!E^ ` D^vE^; and (ii) if the configuration c v1 : : :

vk=u (where k >= 0) is wellngtyped, then either it is reducible, or c v1 : : : vk is a
value. 2

The last point that remains to be settled before proving type soundness
is the interaction between side effects and letngpolymorphism. The following
example illustrates the problem:

let r C^ ref *z:z in let C^ D^r :C^ *z:D^z ^+ ^1E^E^ in !r true
This expression reduces to true ^+ ^1, so it must not be wellngtyped. Yet, if
natural type schemes are assigned to ref, !, and :C^ (see Example 10.7.5), then
it is wellngtyped with respect to the rules given so far, because r receives the
polymorphic type scheme 8X:ref D^X ! XE^, which allows writing a function of
type int ! int into r and reading it back with type bool ! bool. The problem
is that letngpolymorphism simulates a textual duplication of the letngbound
expression ref *z:z, while the semantics first reduces it to a value m, causing
a new binding m , *z:z to appear in the store, then duplicates the address m.

10.5 Type Soundness 437
The new store binding is not duplicated: both copies of m refer to the same
memory cell. For this reason, generalization is unsound in this case, and must
be restricted. Many authors have attempted to come up with a sound type
system that accepts all pure programs and remains flexible enough in the
presence of side effects (Tofte, 1988; Leroy, 1992). These proposals are often
complex, which is why they have been abandoned in favor of an extremely
simple syntactic restriction, known as the value restriction (Wright, 1995).

10.5.6 Definition: A program satisfies the value restriction if and only if all subexng

pressions of the form let z C^ t1 in t2 are in fact of the form let z C^ v1 in
t2. In the following, we assume that either all constants have pure semantics,
or all programs satisfy the value restriction. 2

Put slightly differently, the value restriction states that only values may be
generalized. This eliminates the problem altogether, since duplicating values
does not affect a program's semantics. Note that any program that does not
satisfy the value restriction can be turned into one that does and has the
same semantics: it suffices to change let z C^ t1 in t2 into D^*z:t2E^ t1 when
t1 is not a value. Of course, such a transformation may cause the program to
become illngtyped. In other words, the value restriction causes some perfectly
safe programs to be rejected. In particular, in its above form, it prevents genng
eralizing applications of the form c v1 : : : vk, where c is a destructor of arity
k. This is excessive, because many destructors have pure semantics; only a
few, such as ref, allocate new mutable storage. Furthermore, we use pure
destructors to encode numerous language features ($10.7). Fortunately, it is
easy to relax the restriction to allow generalizing not only values, but also
a more general class of nonexpansive expressions, whose syntax guarantees
that such expressions cannot allocate new mutable storage (that is, expand
the domain of the store). The term nonexpansive was coined by Tofte (1988).
Nonexpansive expressions may include applications of the form c t1 : : : tk,
where c is a pure destructor of arity k and t1; : : : ; tk are nonexpansive. Exng
perience shows that this slightly relaxed restriction is acceptable in practice.
Some limitations remain: for instance, constructor functions (that is, funcng
tions that do not allocate mutable storage and build a value) are regarded
as ordinary functions, so their applications are considered potentially expanng
sive, even though a naked constructor application would be a value and thus
considered nonexpansive. For instance, in the expression let f C^ c v in
let z C^ f w in t, where c is a constructor of arity 2, the partial application
c v, to which the name f is bound, is a constructor function (of arity 1). The
program variable z cannot receive a polymorphic type scheme, because f w
is not a value, even though it has the same semantic meaning as c v w, which
is a value. A recent improvement to the value restriction (Garrigue, 2004)

438 10 The Essence of ML Type Inference

provides a partial remedy. Technically, the effect of the value restriction (as
stated in Definition 10.5.6) is summarized by the following result.

10.5.7 Lemma: Under the value restriction, the production E ::C^ let z C^ E in t

may be suppressed from the grammar of evaluation contexts (Figure 10ng1)
without altering the operational semantics. 2

We are finished with definitions and requirements. Let us now turn to the
type soundness results.

10.5.8 Theorem [Subject reduction]: D^--n~E^ ` D^vE^. 2

Subject reduction ensures that wellngtypedness is preserved by reduction.
10.5.9 Corollary: Let t=u --n~ t0=u0. If t=u is wellngtyped, then so is t0=u0. 2

Let us now state the progress property.
10.5.10 Theorem [Progress]: If t=u is wellngtyped, then either it is reducible, or t is

a value. 2

We may now conclude:
10.5.11 Theorem [Type Soundness]: Wellngtyped source programs do not go wrong. 2

Recall that this result holds only if the requirements of Definition 10.5.5 are
met. In other words, some proof obligations remain to be discharged when

concrete definitions of Q, ffi-!, and \Gamma 0 are given. This is illustrated by several
examples in $10.7 and $10.8.

10.6 Constraint Solving

We have introduced a parameterized constraint language, given equivalence
laws describing the interaction between its logical connectives, and exploited
them to prove theorems about type inference and type soundness, which
are valid independently of the nature of primitive constraints--the songcalled
predicate applications. However, there would be little point in proposing a
parameterized constraint solver, because much of the difficulty of designng
ing an efficient constraint solver lies precisely in the treatment of primitive
constraints and in its interaction with letngpolymorphism. In this section, we
focus on constraint solving in the setting of an equalityngonly free tree model.
Thus, the constraint solver developed here allows performing type inference
for HMD^C^E^ (that is, for Damas and Milner's type system) and for its extension
with recursive types. Of course, some of its mechanisms may be useful in
other settings. The program analysis and type inference literature abounds

10.6 Constraint Solving 439
with constraintngbased systems of all kinds; a short list of papers that put parng
ticular emphasis on constraint solving is Aiken and Wimmers (1992), Henng
glein (1993), Niehren, Mu"ller, and Podelski (1997), Fa"hndrich (1999), Melski
and Reps (2000), Mu"ller, Niehren, and Treinen (2001), Pottier (2001b), Nielng
son, Nielson, and Seidl (2002), McAllester (2002; 2003), and Simonet (2003).

We begin with a rulengbased presentation of a standard, efficient firstngorder
unification algorithm. This yields a constraint solver for a subset of the conng
straint language, except for the type scheme introduction and instantiation
forms. On top of it, we build a full constraint solver, which corresponds to
the code that accompanies this chapter.

Unification
Unification is the process of solving equations between terms. It was first
introduced by Robinson (1971), but his original algorithm could be very inng
efficient. Efficient algorithms, which perform unification in quasinglinear time,
were independently proposed by Martelli and Montanari (1976; 1982) and by
Huet (1976, Chapter 5). Both algorithms rely on a data structure that effing
ciently solves the unionngfind problem (Tarjan, 1975). Martelli and Montanari's
algorithm performs unification in topological (topngdown) order, and is thus
restricted to the acyclic case, that is, to the case where equations are interng
preted in a syntactic model. In this specific case, unification may actually be
performed in truly linear time (Paterson and Wegman, 1978). On the other
hand, Huet's algorithm is able to deal with cyclic structures. The acyclicity
check is postponed until the very end of the solving process if equations are
interpreted within a syntactic model, or omitted altogether if working within
a regular tree model. Except for the final acyclicity check, Huet's algorithm is
incremental. Furthermore, it is simple; we present a version of it here. Knight
(1989) and Baader and Siekmann (1994) also describe Huet's algorithm, and
provide further historical background and references.

Following Jouannaud and Kirchner (1991), we specify the algorithm as a
(nondeterministic) system of constraint rewriting rules. As suggested above,
it is almost the same for finite and regular tree models; only one rule, which
implements the occurs check, must be removed in the latter case. In other
words, the algorithm works with possibly cyclic data structures and does
not rely in an essential way on the occurs check. In order to more closely
reflect the behavior of the actual algorithm, and in particular the unionngfind
data structure, we modify the syntax of constraints by replacing equations
with multingequations--equations involving an arbitrary number of types, as
opposed to exactly two.

440 10 The Essence of ML Type Inference

10.6.1 Definition: Let there be, for every kind ^ and for every n >= 1, a predicate

C^n^, of signature ^n ) *, whose interpretation is (nngary) equality. The predicate
constraint C^n^ T1 : : : Tn is written T1 C^ : : : C^ Tn, and called a multingequation.
We consider the constraint true as a multingequation of length 0 and let ffl
range over all multingequations. In the following, we identify multingequations
up to permutations of their members, so a multingequation ffl of kind ^ may
be viewed as a finite multiset of types of kind ^. We write ffl C^ ffl0 for the
multingequation obtained by concatenating ffl and ffl0. 2

Thus, we are interested in the following subset of the constraint language:

U ::C^ true | false | ffl | U ^ U | 9_X:U
Equations are replaced with multingequations; no other predicates are availng
able. Type scheme introduction and instantiation forms are absent.

10.6.2 Definition: A multingequation is standard if and only if its variable memng

bers are distinct and it has at most one nonvariable member. A constraint
U is standard if and only if every multingequation inside U is standard and
every variable that occurs (free or bound) in U is a member of at most one
multingequation inside U. (Note that to be a member of ffl implies, but is not
equivalent to, to occur free in ffl.) 2

A unionngfind algorithm maintains equivalence classes (that is, disjoint sets)
of variables, and associates with each class a descriptor, which in our case is
either absent or a nonvariable term. Thus, a standard constraint represents
a state of the unionngfind algorithm. A constraint that is not standard may be
viewed as a superposition of a state of the unionngfind algorithm, on the one
hand, and of control information, on the other hand. For instance, a multing
equation of the form ffl C^ T1 C^ T2, where ffl is made up of distinct variables
and T1 and T2 are nonvariable terms, may be viewed, roughly speaking, as the
equivalence class ffl C^ T1, together with a pending request to solve T1 C^ T2 and
to update the class's descriptor accordingly. Because multingequations encode
both state and control, our specification of the unification algorithm remains
rather abstract. It would be possible to give a lowernglevel description, where
state (standard conjunctions of multingequations) and control (pending binary
equations) are distinguished.

10.6.3 Definition: Let U be a conjunction of multingequations. Y is dominated by X

with respect to U (written: Y OEU X) if and only if U contains a conjunct of the
form X C^ F ~T C^ ffl, where Y 2 ftvD^_TE^. U is cyclic if and only if the graph of OEU
exhibits a cycle. 2

10.6 Constraint Solving 441
D^9_X:U1E^ ^ U2 ! 9_X:D^U1 ^ U2E^ D^SngExAndE^

if _X # ftvD^U2E^

X C^ ffl ^ X C^ ffl0 ! X C^ ffl C^ ffl0 D^SngFuseE^

X C^ X C^ ffl ! X C^ ffl D^SngStutterE^
F ~X C^ F ~T C^ ffl ! ~X C^ ~T ^ F ~X C^ ffl D^SngDecomposeE^
F T1 : : : Ti : : : Tn C^ ffl ! 9X:D^X C^ Ti ^ F T1 : : : X : : : Tn C^ fflE^ D^SngNameng1E^

if Ti 62 V ^ X 62 ftvD^T1; : : : ; Tn; fflE^

F ~T C^ F0 ~T0 C^ ffl ! false D^SngClashE^

if F 6C^ F0

T ! true D^SngSingleE^
U ^ true ! U D^SngTrueE^

U ! false D^SngCycleE^

if the model is syntactic and U is cyclic

UE,falseG* ! false D^SngFailE^

if U 6C^ E,G*

Figure 10ng10: Unification

The specification of the unification algorithm consists of a set of constraint
rewriting rules, given in Figure 10ng10. Rewriting is performed modulo ffng
conversion, modulo permutations of the members of a multingequation, modng
ulo commutativity and associativity of conjunction, and under an arbitrary
context. The specification is nondeterministic: several rule instances may be
simultaneously applicable.

SngExAnd is a directed version of CngExAnd, whose effect is to float up all
existential quantifiers. In the process, all multingequations become part of a
single conjunction, possibly causing rules whose leftnghand side is a conjuncng
tion of multingequations, namely SngFuse and SngCycle, to become applicable.
SngFuse identifies two multingequations that share a common variable X, and
fuses them. The new multingequation is not necessarily standard, even if the
two original multingequations were. Indeed, it may have repeated variables or
contain two nonvariable terms. The purpose of the next few rules, whose
leftnghand side consists of a single multingequation, is to deal with these sitng
uations. SngStutter eliminates redundant variables. It only deals with varing

442 10 The Essence of ML Type Inference

ables, as opposed to terms of arbitrary size, so as to have constant time cost.
The comparison of nonvariable terms is implemented by SngDecompose and
SngClash. SngDecompose decomposes an equation between two terms whose
head symbols match. It produces a conjunction of equations between their
subterms, namely ~X C^ ~T. Only one of the two terms remains in the original
multingequation, which may thus become standard. The terms ~X are copied:
there are two occurrences of ~X on the rightnghand side. For this reason, we
require them to be type variables, as opposed to terms of arbitrary size. (We
slightly abuse notation by using ~X to denote a vector of type variables whose
elements are not necessarily distinct.) By doing so, we allow explicit reasoning
about sharing: since a variable represents a pointer to an equivalence class,
we explicitly specify that only pointers, not whole terms, are copied. As a
result of this decision, SngDecompose is not applicable when both terms at
hand have a nonvariable subterm. SngNameng1 remedies this problem by introng
ducing a fresh variable that stands for one such subterm. When repeatedly
applied, SngNameng1 yields a unification problem composed of songcalled small
terms only--that is, where sharing has been made fully explicit. SngClash comng
plements SngDecompose by dealing with the case where two terms with differng
ent head symbols are equated; in a free tree model, such an equation is false,
so failure is signaled. SngSingle and SngTrue suppress multingequations of size
1 and 0, respectively, which are tautologies. SngCycle is the occurs check: it
signals failure if the constraint is cyclic. It is applicable only in the case of
syntactic unification, that is, when ground types are finite trees. It is a global
check: its leftnghand side is an entire conjunction of multingequations. SngFail
propagates failure; U ranges over unification constraint contexts.

The constraint rewriting system in Figure 10ng10 enjoys the following propng
erties. First, rewriting is strongly normalizing, so the rules define a (nondeng
terministic) algorithm. Second, rewriting is meaningngpreserving. Third, every
normal form is either false or of the form 9_X:U, where U is satisfiable. The
latter two properties indicate that the algorithm is indeed a constraint solver.

10.6.4 Lemma: The rewriting system ! is strongly normalizing. 2
10.6.5 Lemma: U1 ! U2 implies U1 j U2. 2
10.6.6 Lemma: Every normal form is either false or of the form XE,UG*, where X is an

existential constraint context, U is a standard conjunction of multingequations
and, if the model is syntactic, U is acyclic. These conditions imply that U is
satisfiable. 2

10.6 Constraint Solving 443
A Constraint Solver
On top of the unification algorithm, we now define a constraint solver. Its
specification is independent of the rules and strategy employed by the uning
fication algorithm. However, the structure of the unification algorithm's norng
mal forms as well as the logical properties of multingequations are exploited
when performing generalization, that is, when creating and simplifying type
schemes. Like the unification algorithm, the constraint solver is specified in
terms of a reduction system. However, the objects that are subject to rewritng
ing are not just constraints: they have more complex structure. Working
with such richer states allows distinguishing the solver's external language--
namely, the full constraint language, which is used to express the problem
that one wishes to solve--and an internal language, introduced below, which
is used to describe the solver's private data structures. In the following, C
and D range over external constraints, that is, constraints that were part of
the solver's input. External constraints are to be viewed as abstract syntax
trees, subject to no implicit laws other than ffngconversion. As a simplifying
assumption, we require external constraints not to contain any occurrence of
false--otherwise the problem at hand is clearly false. Internal data structures
include unification constraints U, as previously studied, and stacks, whose
syntax is as follows:

S ::C^ E,G* | SE,E,G* ^ CG* | SE,9_X:E,G*G* | SE,let x : 8_XE,E,G*G*:T in CG* | SE,let x : oe in E,G*G*
In the second and fourth productions, C is an external constraint. In the last
production, we require oe to be of the form 8_XE,UG*:X, and we demand 9oe j
true. Every stack may be viewed as a onenghole constraint context (page 410);
indeed, one may interpret E,G* as the empty context and *E,*G* as context comng
position, which replaces the hole of its first context argument with its second
context argument. A stack may also be viewed, literally, as a list of frames.
Frames may be added and deleted at the inner end of a stack, that is, near the
hole of the constraint context that it represents. We refer to the four kinds of
frames as conjunction, existential, let, and environment frames, respectively.
A state of the constraint solver is a triple S; U; C where S is a stack, U is a
unification constraint, and C is an external constraint. The state S; U; C is to
be understood as a representation of the constraint SE,U ^ CG*, that is, the
constraint obtained by placing both U and C within the hole of the constraint
context S. The notion of ffngequivalence between states is defined accordingly.
In particular, one may rename type variables in dtvD^SE^, provided U and C are
renamed as well. In brief, the three components of a state play the following
roles. C is an external constraint that the solver intends to examine next. U

444 10 The Essence of ML Type Inference

is the internal state of the underlying unification algorithm; one might think
of it as the knowledge that has been obtained so far. S tells where the type
variables that occur free in U and C are bound, associates type schemes with
the program variables that occur free in C, and records what should be done
after C is solved. The solver's initial state is usually of the form E,G*; true; C,
where C is the external constraint that one wishes to solve, that is, whose
satisfiability one wishes to determine. If the constraint to be solved is of the
form let \Gamma 0 in C, and if the type schemes that appear within \Gamma 0 meet the
requirements that bear on environment frames, as defined above, then it is
possible to pick let \Gamma 0 in E,G*; true; C as an initial state. For simplicity, we make
the (unessential) assumption that states have no free type variables.

The solver consists of a (nondeterministic) state rewriting system, given in
Figure 10ng11. Rewriting is performed modulo ffngconversion. SngUnify makes
the unification algorithm a component of the constraint solver, and allows the
current unification problem U to be solved at any time. Rules SngExng1 to SngExng4
float existential quantifiers out of the unification problem into the stack and
through the stack up to the nearest enclosing let frame, if there is any, or to
the outermost level, otherwise. Their sidengconditions prevent capture of type
variables, and can always be satisfied by suitable ffngconversion of the leftng
hand state. If S; U; C is a normal form with respect to these five rules, then U
must be either false or a conjunction of standard multingequations, and every
type variable in dtvD^SE^ must be either universally quantified at a let frame or
existentially bound at the outermost level. (Recall that, by assumption, states
have no free type variables.) In other words, provided these rules are applied
in an eager fashion, there is no need for existential frames to appear in the
machine representation of stacks. Instead, it suffices to maintain, at every let
frame and at the outermost level, a list of the type variables that are bound
at this point and, conversely, to annotate every type variable in dtvD^SE^ with
an integer rank, which allows telling, in constant time, where the variable is
bound: type variables of rank 0 are bound at the outermost level, and type
variables of rank k >= 1 are bound at the kth let frame down in the stack S.
The code that accompanies this chapter adopts this convention. Ranks were
initially described in Re'my (1992a) and have also been studied by McAllester
(2003).

Rules SngSolvengEq to SngSolvengLet encode an analysis of the structure of the
third component of the current state. There is one rule for each possible case,
except false, which by assumption cannot arise, and true, which is dealt with
further on. SngSolvengEq discovers an equation and makes it available to the
unification algorithm. SngSolvengId discovers an instantiation constraint x _ T
and replaces it with oe _ T, where the type scheme oe C^ SD^xE^ is the type

10.6 Constraint Solving 445

S; U; C ! S; U0; C D^SngUnifyE^

if U ! U0

S; 9_X:U; C ! SE,9_X:E,G*G*; U; C D^SngExng1E^

if _X # ftvD^CE^

SE,D^9_X:S0E^ ^ DG*; U; C ! SE,9_X:D^S0 ^ DE^G*; U; C D^SngExng2E^

if _X # ftvD^DE^

SE,let x : 8_XE,9_Y:S0G*:T in DG*; U; C ! SE,let x : 8_X_YE,SG*:0T in DG*; U; C D^SngExng3E^

if _Y # ftvD^TE^

SE,let x : oe in 9_X:S0G*; U; C ! SE,9_X:let x : oe in S0G*; U; C D^SngExng4E^

if _X # ftvD^oeE^

S; U; T1 C^ T2 ! S; U ^ T1 C^ T2; true D^SngSolvengEqE^

S; U; x _ T ! S; U; SD^xE^ _ T D^SngSolvengIdE^
S; U; C1 ^ C2 ! SE,E,G* ^ C2G*; U; C1 D^SngSolvengAndE^

S; U; 9_X:C ! SE,9_X:E,G*G*; U; C D^SngSolvengExE^

if _X # ftvD^UE^

S; U; let x : 8_XE,DG*:T in C ! SE,let x : 8_XE,E,G*G*:T in CG*; U; D D^SngSolvengLetE^

if _X # ftvD^UE^

SE,E,G* ^ CG*; U; true ! S; U; C D^SngPopngAndE^
SE,let x : 8_XE,E,G*G*:T in CG*; U; true ! SE,let x : 8_XXE,E,G*G*:X in CG*;

U ^ X C^ T; true D^SngNameng2E^
if X 62 ftvD^U; TE^ ^ T 62 V

SE,let x : 8_XYE,E,G*G*:X in CG*; Y C^ Z C^ ffl ^ U; true ! SE,let x : 8_XYE,E,G*G*:`D^XE^ in CG*;

Y ^ Z C^ `D^fflE^ ^ `D^UE^; true D^SngCompressE^
if Y 6C^ Z ^ ` C^ E,Y , ZG*

SE,let x : 8_XYE,E,G*G*:X in CG*; Y C^ ffl ^ U; true ! SE,let x : 8_XE,E,G*G*:X in CG*; ffl ^ U; true D^SngUnNameE^

if Y 62 X [ ftvD^ffl; UE^

SE,let x : 8_X_YE,E,G*G*:X in CG*; U; true ! SE,9_Y:let x : 8_XE,E,G*G*:X in CG*; U; true D^SngLetAllE^

if _Y # ftvD^CE^ ^ 9_X:U determines _Y

SE,let x : 8_XE,E,G*G*:X in CG*; U1 ^ U2; true ! SE,let x : 8_XE,U2G*:X in E,G*G*; U1; C D^SngPopngLetE^

if _X # ftvD^U1E^ ^ 9_X:U2 j true

SE,let x : oe in E,G*G*; U; true ! S; U; true D^SngPopngEnvE^

Figure 10ng11: A constraint solver

446 10 The Essence of ML Type Inference

scheme carried by the nearest environment frame that defines x in the stack
S. It is defined as follows:

SE,E,G* ^ CG*D^xE^ C^ SD^xE^

SE,9_X:E,G*G*D^xE^ C^ SD^xE^ if _X # ftvD^SD^xE^E^
SE,let y : 8_XE,E,G*G*:T in CG*D^xE^ C^ SD^xE^ if _X # ftvD^SD^xE^E^

SE,let y : oe in E,G*G*D^xE^ C^ SD^xE^ if x 6C^ y
SE,let x : oe in E,G*G*D^xE^ C^ oe

If x 2 dpiD^SE^ does not hold, then SD^xE^ is undefined and the rule is not appling
cable. If it does hold, then the rule may always be made applicable by suitable
ffngconversion of the leftnghand state. Recall that, if oe is of the form 8_XE,UG*:X,
where _X # ftvD^TE^, then oe _ T stands for 9_X:D^U ^ X C^ TE^. The process of
constructing this constraint is informally referred to as "taking an instance
of oe ." In the worst case, it is just as inefficient as textually expanding the
corresponding let construct in the program's source code, and leads to exng
ponential time complexity. In practice, however, the unification constraint
U is often compact because it was simplified before the environment frame
let x : oe in E,G* was created, which explains why the solver usually performs
well. (The creation of environment frames, performed by SngPopngLet, is disng
cussed below.) SngSolvengAnd discovers a conjunction. It arbitrarily chooses to
explore the left branch first, and pushes a conjunction frame onto the stack,
so as to record that the right branch should be explored afterwards. SngSolveng
Ex discovers an existential quantifier and enters it, creating a new existential
frame to record its existence. Similarly, SngSolvengLet discovers a let form and
enters its leftnghand side, creating a new let frame to record its existence. The
choice of examining the leftnghand side first is not arbitrary. Indeed, examinng
ing the rightnghand side first would require creating an environment frame--
but environment frames must contain simplified type schemes of the form
8_XE,UG*:X, whereas the type scheme 8_XE,DG*:T is arbitrary. In other words, our
strategy is to simplify type schemes prior to allowing them to be copied by
SngSolvengId, so as to avoid any duplication of effort. The sidengconditions of Sng
SolvengEx and SngSolvengLet may always be satisfied by suitable ffngconversion
of the leftnghand state.

Rules SngSolvengEq to SngSolvengLet may be referred to as forward rules, beng
cause they "move down into" the external constraint, causing the stack to
grow. This process stops when the external constraint at hand becomes true.
Then part of the work has been finished, and the solver must examine the
stack in order to determine what to do next. This task is performed by the
last series of rules, which may be referred to as backward rules, because they
"move back out," causing the stack to shrink and possibly scheduling new
external constraints for examination. These rules encode an analysis of the

10.6 Constraint Solving 447
structure of the innermost stack frame. There are three cases, correspondng
ing to conjunction, let, and environment frames. The case of existential stack
frames need not be considered, because rules SngExng2 to SngExng4 allow either
fusing them with let frames or floating them up to the outermost level, where
they shall remain inert. SngPopngAnd deals with conjunction frames. The frame
is popped, and the external constraint that it carries is scheduled for examng
ination. SngPopngEnv deals with environment frames. Because the rightnghand
side of the let construct at hand has been solved--that is, turned into a uning
fication constraint U--it cannot contain an occurrence of x. Furthermore, by
assumption, 9oe is true. Thus, this environment frame is no longer useful: it
is destroyed. The remaining rules deal with let frames. Roughly speaking,
their purpose is to change the state SE,let x : 8_XE,E,G*G*:T in CG*; U; true into
SE,let x : 8_XE,UG*:T in E,G*G*; true; C, that is, to turn the current unification conng
straint U into a type scheme, turn the let frame into an environment frame,
and schedule the rightnghand side of the let construct (that is, the external
constraint C) for examination. In fact, the process is more complex, because
the type scheme 8_XE,UG*:T must be simplified before becoming part of an enng
vironment frame. The simplification process is described by rules SngNameng2
to SngPopngLet. In the following, we refer to type variables in _X as young and
to type variables in dtvD^SE^ \ _X as old. The former are the universal quanting
fiers of the type scheme that is being created; the latter contain its free type
variables.

SngNameng2 ensures that the body T of the type scheme that is being created
is a type variable, as opposed to an arbitrary term. If it isn't, then it is reng
placed with a fresh variable X, and the equation X C^ T is added so as to recall
that X stands for T. Thus, the rule moves the term T into the current unificang
tion problem, where it potentially becomes subject to SngNameng1. This ensures
that sharing is made explicit everywhere. SngCompress determines that the
(young) type variable Y is an alias for the type variable Z. Then, every free
occurrence of Y other than its defining occurrence is replaced with Z. In an
actual implementation, this occurs transparently when the unionngfind algong
rithm performs path compression (Tarjan, 1975, 1979). We note that the rule
does not allow substituting a younger type variable for an older one; indeed,
that would make no sense, since the younger variable could then possibly
escape its scope. In other words, in implementation terms, the unionngfind alng
gorithm must be slightly modified so that, in each equivalence class, the repng
resentative element is always a type variable with minimum rank. SngUnName
determines that the (young) type variable Y has no occurrences other than its
defining occurrence in the current type scheme. (This occurs, in particular,
when SngCompress has just been applied.) Then, Y is suppressed altogether.
In the particular case where the remaining multingequation ffl has cardinal 1,

448 10 The Essence of ML Type Inference

it may then be suppressed by SngSingle. In other words, the combination of
SngUnName and SngSingle is able to suppress young unused type variables as
well as the term that they stand for. This may, in turn, cause new type varing
ables to become eligible for elimination by SngUnName. In fact, assuming the
current unification constraint is acyclic, an inductive argument shows that
every young type variable may be suppressed unless it is dominated either
by X or by an old type variable. (In the setting of a regular tree model, it is
possible to extend the rule so that young cycles that are not dominated either
by X or by an old type variable are suppressed as well.) SngLetAll is a directed
version of CngLetAll. It turns the young type variables _Y into old variables.
How to tell whether 9_X:U determines _Y is discussed later (see Lemma 10.6.7).
Why SngLetAll is an interesting and important rule will be explained shortly.
SngPopngLet is meant to be applied when the current state has become a norng
mal form with respect to SngUnify, SngNameng2, SngCompress, SngUnName, and
SngLetAll, that is, when the type scheme that is about to be created is fully
simplified. It splits the current unification constraint into two components
U1 and U2, where U1 is made up entirely of old variables, as expressed by
the sidengcondition _X # ftvD^U1E^, and U2 constrains young variables only, as
expressed by the sidengcondition 9_X:U2 j true. Note that U2 may still conng
tain free occurrences of old type variables, so the type scheme 8_XE,U2G*:X that
appears on the rightnghand side is not necessarily closed. It is not obvious
why such a decomposition must exist; Lemma 10.6.10 proves that it does.
Let us say for now that SngLetAll plays a role in guaranteeing its existence,
whence comes part of its importance. Once the decomposition U1 ^ U2 is
obtained, the behavior of SngPopngLet is simple. The unification constraint U1
concerns old variables only, that is, variables that are not quantified in the
current let frame; thus, it need not become part of the new type scheme and
may instead remain part of the current unification constraint. This is justing
fied by CngLetAnd and CngInAnd* and corresponds to the difference between
hmxngGen' and hmxngGen discussed in $10.3. The unification constraint U2, on
the other hand, becomes part of the newly built type scheme 8_XE,U2G*:X. The
property 9_X:U2 j true guarantees that the newly created environment frame
meets the requirements imposed on such frames. Note that the more type
variables are considered old, the larger U1 may become, and the smaller U2.
This is another reason why SngLetAll is interesting: by allowing more varing
ables to be considered old, it decreases the size of the type scheme 8_XE,U2G*:X,
making it cheaper to instantiate.

To complete our description of the constraint solver, there remains to exng
plain how to decide when 9_X:U determines _Y, since this predicate occurs in
the sidengcondition of SngLetAll. The following lemma describes two important
situations where, by examining the structure of an equation, it is possible to

10.6 Constraint Solving 449
discover that a constraint C determines some of its free type variables _Y (Defng
inition 10.2.14). In the first situation, the type variables _Y are equated with or
dominated by a distinct type variable X that occurs free in C. In that case,
because the model is a free tree model, the values of the type variables _Y
are determined by the value of X: they are subtrees of it at specific positions.
For instance, X C^ Y1 ! Y2 determines Y1Y2, while 9Y1:D^X C^ Y1 ! Y2E^ deterng
mines Y2. In the second situation, the type variables _Y are equated with a
term T, all of whose type variables are free in C. Again, the value of the type
variables _Y is then determined by the values of the type variables ftvD^TE^. For
instance, X C^ Y1 ! Y2 determines X, while 9Y1:D^X C^ Y1 ! Y2E^ does not. In the
second situation, no assumption is in fact made about the model. (Note that
X C^ Y1 ! Y2 determines Y1Y2 and determines X, but does not simultaneously
determine XY1Y2.)

10.6.7 Lemma: Let _X # _Y. Assume either ffl is X C^ ffl0, where X 62 _X_Y and _Y ` ftvD^ffl0E^, or

ffl is _Y C^ T C^ ffl0, where ftvD^TE^ # _X_Y. Then, 9_X:D^C ^ fflE^ determines _Y. 2

Thanks to Lemma 10.6.7, an efficient implementation of SngLetAll comes
to mind. The problem is, given a constraint 9_X:U, where U is a standard conng
junction of multingequations, to determine the greatest subset _Y of _X such that
9D^_X \ _YE^:U determines _Y. By the first part of the lemma, it is safe for _Y to inng
clude all members of _X that are directly or indirectly dominated (with respect
to U) by some free variable of 9_X:U. Those can be found, in time linear in
the size of U, by a topngdown traversal of the graph of OEU . By the second part
of the lemma, it is safe to close _Y under the closure law X 2 _X ^ D^8Y Y OEU
X ) Y 2 _YE^ ) X 2 _Y. That is, it is safe to also include all members of _X
whose descendants (with respect to U) have already been found to be memng
bers of _Y. This closure computation may be performed, again in linear time,
by a bottomngup traversal of the graph of OEU . When U is acyclic, it is possible
to show that this procedure is complete, that is, does compute the greatest
subset _Y that meets our requirement.

The above discussion has shown that when Y and Z are equated, if Y is
young and Z is old, then SngLetAll allows making Y old as well. If binding
information is encoded in terms of integer ranks, as suggested earlier, then
this remark may be formulated as follows: when Y and Z are equated, if the
rank of Y exceeds that of Z, then it may be decreased so that both ranks
match. As a result, it is possible to attach ranks with multingequations, rather
than with variables. When two multingequations are fused, the smaller rank is
kept. This treatment of ranks is inspired by Re'my (1992a); see the resolution
rule Fuse, as well as the simplification rules Propagate and Realize, in that
paper.

450 10 The Essence of ML Type Inference

Let us now state the properties of the constraint solver. First, the reduction
system is terminating, so it defines an algorithm.

10.6.8 Lemma: The reduction system ! is strongly normalizing. 2

Second, every rewriting step preserves the meaning of the constraint that
the current state represents. We recall that the state S; U; C is meant to repng
resent the constraint SE,U ^ CG*.

10.6.9 Lemma: S; U; C ! S0; U0; C0 implies SE,U ^ CG* j S0E,U0 ^ C0G*. 2

Last, we classify the normal forms of the reduction system:
10.6.10 Lemma: A normal form for the reduction system ! is one of (i) S; U; x _ T,

where x 62 dpiD^SE^; (ii) S; false; true; or (iii) X; U; true, where X is an existential
constraint context and U a satisfiable conjunction of multingequations. 2

In case (i), the constraint SE,U ^ CG* has a free program identifier x. In other
words, the source program contains an unbound program identifier. Such an
error could of course be detected prior to constraint solving, if desired. In
case (ii), the unification algorithm failed. By Lemma 10.2.17, the constraint
SE,U ^ CG* is then false. In case (iii), the constraint SE,U ^ CG* is equivalent to
XE,UG*, where U is satisfiable, so it is satisfiable as well. If the initial constraint
is closed, case (i) cannot arise, while cases (ii) and (iii) respectively denote
failure and success. Thus, Lemmas 10.6.9 and 10.6.10 indeed prove that the
algorithm is a constraint solver.

10.6.11 Remark: Type inference for MLngthengcalculus is dexptimengcomplete (Kfoury,

Tiuryn, and Urzyczyn, 1990; Mairson, Kanellakis, and Mitchell, 1991). Thus,
our constraint solver cannot run any faster, asymptotically. This cost is esng
sentially due to letngpolymorphism, which requires a constraint to be dung
plicated at every occurrence of a letngbound variable (SngSolvengId). In order
to limit the amount of duplication to a bare minimum, it is important that
rule SngLetAll be applied before SngPopngLet, allowing variables and constraints
that need not be duplicated to be shared. We have observed that algorithms
based on this strategy behave remarkably well in practice (Re'my, 1992a). In
fact, McAllester (2003) has proved that they have linear time complexity, prong
vided the size of type schemes and the (leftng) nesting depth of let constructs
are bounded. Unfortunately, many implementations of type inference for MLng
thengprogrammingnglanguage do not behave as efficiently as the algorithm preng
sented here. Some spend an excessive amount of time in computing the set
of nongeneralizable type variables; some do not treat types as dags, thus losng
ing precious sharing information; others perform the expensive occurs check
after every unification step, rather than only once at every let construct, as
suggested here (SngPopngLet). 2

10.7 From MLngthengCalculus to MLngthengLanguage 451
10.7 From MLngthengCalculus to MLngthengLanguage

In this section, we explain how to extend the framework developed so far
to accommodate operations on values of base type (such as integers), pairs,
sums, references, and recursive function definitions. Then, we describe algeng
braic data type definitions. Last, the issues associated with recursive types
are briefly discussed. For space reasons, exceptions are not discussed; the
reader is referred to (TAPL, Chapter 14).

Simple Extensions
Introducing new constants and extending ffi-! and \Gamma 0 appropriately allows
adding many features of MLngthengprogrammingnglanguage to MLngthengcalculus. In
each case, it is necessary to check that the requirements of Definition 10.5.5
are met, that is, to ensure that the new initial environment faithfully reflects
the nature of the new constants as well as the behavior of the new reducng
tion rules. Below, we describe several such extensions in isolation. The first
exercise establishes a technical result that is useful in the next exercises.

10.7.1 Exercise [Recommended, n']: Let \Gamma 0 contain the binding c : 8_X:T1 ! : : : !

Tn ! T. Prove let \Gamma 0 in Jc t1 : : : tn : T0K equivalent to let \Gamma 0 in 9_X:D^VniC^1Jti :
TiK ^ T <= T0E^. 2

10.7.2 Exercise [Integers, Recommended, n'n']: Integer literals and integer addition

have been introduced and given an operational semantics in Examples 10.1.1,
10.1.2, and 10.1.4. Let us now introduce an isolated type constructor int of
signature ? and extend the initial environment \Gamma 0 with the bindings ^n : int,
for every integer n, and ^+ : int ! int ! int. Check that these definitions meet
the requirements of Definition 10.5.5. 2

10.7.3 Exercise [Pairs, n'n', 3]: Pairs and pair projections have been introduced and

given an operational semantics in Examples 10.1.3 and 10.1.5. Let us now inng
troduce an isolated type constructor * of signature ? \Omega  ? ) ?, covariant in
both of its parameters, and extend the initial environment \Gamma 0 with the followng
ing bindings:

D^*; *E^ : 8XY:X ! Y ! X * Y

ss1 : 8XY:X * Y ! X
ss2 : 8XY:X * Y ! Y

Check that these definitions meet the requirements of Definition 10.5.5. 2

10.7.4 Exercise [Sums, n'n', 3]: Sums have been introduced and given an operational

semantics in Example 10.1.7. Let us now introduce an isolated type construcng
tor + of signature ? \Omega  ? ) ?, covariant in both of its parameters, and extend

452 10 The Essence of ML Type Inference

the initial environment \Gamma 0 with the following bindings:

inj1 : 8XY:X ! X + Y
inj2 : 8XY:Y ! X + Y

case : 8XYZ:D^X + YE^ ! D^X ! ZE^ ! D^Y ! ZE^ ! Z

Check that these definitions meet the requirements of Definition 10.5.5. 2
10.7.5 Exercise [References, n'n'n']: References have been introduced and given an

operational semantics in Example 10.1.9. The type constructor ref has been
introduced in Definition 10.5.3. Let us now extend the initial environment \Gamma 0
with the following bindings:

ref : 8X:X ! ref X

! : 8X:ref X ! X
:C^ : 8X:ref X ! X ! X

Check that these definitions meet the requirements of Definition 10.5.5. 2
10.7.6 Exercise [Recursion, Recommended, n'n'n', 3]: The fixpoint combinator fix

has been introduced and given an operational semantics in Example 10.1.10.
Let us now extend the initial environment \Gamma 0 with the following binding:

fix : 8XY:D^D^X ! YE^ ! D^X ! YE^E^ ! X ! Y
Check that these definitions meet the requirements of Definition 10.5.5. Reng
call how the letrec syntactic sugar was defined in Example 10.1.10, and
check that this gives rise to the following constraint generation rule:

let \Gamma 0 in Jletrec f C^ *z:t1 in t2 : TK
j let \Gamma 0 in let f : 8XYE,let f : X ! Y; z : X in Jt1 : YKG*:X ! Y in Jt2 : TK

Note the somewhat peculiar structure of this constraint: the program variable
f is bound twice in it, with different type schemes. The constraint requires
all occurrences of f within t1 to be assigned the monomorphic type X ! Y.
This type is generalized and turned into a type scheme before inspecting t2,
however, so every occurrence of f within t2 may receive a different type, as
usual with letngpolymorphism. A more powerful way of typechecking recurng
sive function definitions, proposed by (Mycroft, 1984) and known as polymorng
phic recursion, allows the types of occurrences of f within t1 to be possibly
distinct instances of a single type scheme. However, type inference for this
extension is equivalent to semingunification (Henglein, 1993), which has been
proved undecidable (Kfoury, Tiuryn, and Urzyczyn, 1993). Hence, type inferng
ence must either require type annotations or rely on a semingalgorithm. 2

10.7 From MLngthengCalculus to MLngthengLanguage 453

In the exercises above, we have considered a number of extensions (inteng
gers, booleans, pairs, etc.) in isolation. We have checked that each of them
preserves type soundness. Unfortunately, this does not in general imply that
their combination preserves type soundness. In fact, it is possible to prove
that these extensions are independent in a suitable sense and that indepenng
dent extensions may be safely combined. Unfortunately, we lack space to
further explain these notions.

Algebraic Data Types
Exercises 10.7.3 and 10.7.4 have shown how to extend the language with bing
nary, anonymous products and sums. These constructs are quite general but
still have several shortcomings. First, they are only binary, while we would
like to have kngary products and sums, for arbitrary k >= 0. Such a generalng
ization is of course straightforward. Second, more interestingly, their compong
nents must be referred to by numeric index (as in "extract the second comng
ponent of the pair"), rather than by name ("extract the component named y").
In practice, it is crucial to use names, because they make programs more
readable and more robust in the face of changes. One could introduce a
mechanism that allows defining names as syntactic sugar for numeric inng
dices. That would help a little, but not much, because these names would
not appear in types, which would still be made of anonymous products and
sums. Third, in the absence of recursive types, products and sums do not
have sufficient expressiveness to allow defining unbounded data structures,
such as lists. Indeed, it is easy to see that every value whose type T is comng
posed of base types (int, bool, etc.), products, and sums must have bounded
size, where the bound | T | is a function of T. More precisely, up to a conng
stant factor, we have | int | C^ | bool | C^ 1, | T1 * T2 | C^ 1 + | T1 | + | T2 |, and
| T1 + T2 | C^ 1 + maxD^| T1 |; | T2 |E^. The following example describes another
facet of the same problem.

10.7.7 Example: A list is either empty, or a pair of an element and another list. So,

it seems natural to try and encode the type of lists as a sum of some arbitrary
type (say, unit) on the one hand, and of a product of some element type and of
the type of lists itself on the other hand. With this encoding in mind, we can
go ahead and write code--for instance, a function that computes the length
of a list:

letrec length C^ *l:case l D^* :^0E^ D^*z:^1 ^+ length D^ss2 zE^E^
We have used integers, pairs, sums, and the letrec construct introduced in
the previous section. The code analyzes the list l using a case construct.

454 10 The Essence of ML Type Inference

If the left branch is taken, the list is empty, so 0 is returned. If the right
branch is taken, then z becomes bound to a pair of some element and the
tail of the list. The latter is obtained using the projection operator ss2. Its
length is computed using a recursive call to length and incremented by 1.
This code makes perfect sense. However, applying the constraint generation
and constraint solving algorithms eventually leads to an equation of the form
X C^ Y + D^Z * XE^, where X stands for the type of l. This equation accurately reng
flects our encoding of the type of lists. However, in a syntactic model, it has
no solution, so our definition of length is illngtyped. It is possible to adopt
a free regular tree model, thus introducing equirecursive types into the sysng
tem (TAPL, Chapter 20); however, there are good reasons not to do so (see
the section on Recursive Types on p. 459). 2

To work around this problem, MLngthengprogrammingnglanguage offers algeng
braic data type definitions, whose elegance lies in the fact that, while repreng
senting only a modest theoretical extension, they do solve the three problems
mentioned above. An algebraic data type may be viewed as an abstract type
that is declared to be isomorphic to a (kngary) product or sum type with named
components. The type of each component is declared, as well, and may refer
to the algebraic data type that is being defined: thus, algebraic data types are
isorecursive (TAPL, Chapter 20). In order to allow sufficient flexibility when
declaring the type of each component, algebraic data type definitions may be
parameterized by a number of type variables. Last, in order to allow the deng
scription of complex data structures, it is necessary to allow several algebraic
data types to be defined at once; the definitions may then be mutually recurng
sive. In fact, in order to simplify this formal presentation, we assume that
all algebraic data types are defined at once at the beginning of the program.
This decision is, of course, at odds with modular programming but will not
otherwise be a problem.

In the following, D ranges over a set of data types. We assume that data
types form a subset of type constructors. We require each of them to be isong
lated and to have image kind ?. Furthermore, ` ranges over a set L of labels,
which we use both as data constructors and as record labels. An algebraic
data type definition is either a variant type definition or a record type defining
tion, whose respective forms are

D ~X ss

kX

iC^1

`i : Ti and D ~X ss

kY

iC^1

`i : Ti:

In either case, k must be nonnegative. If D has signature ~^ ) ?, then the type
variables ~X must have kind ~^. Every Ti must have kind ?. We refer to _X as
the parameters and to ~T (the vector formed by T1; : : : ; Tk) as the components

10.7 From MLngthengCalculus to MLngthengLanguage 455
of the definition. The parameters are bound within the components, and the
definition must be closed, that is, ftvD^~TE^ ` _X must hold. Last, for an algebraic
data type definition to be valid, the behavior of the type constructor D with
respect to subtyping must match its definition. This requirement is clarified
below.

10.7.8 Definition: Consider an algebraic data type definition whose parameters

and components are respectively ~X and ~T. Let ~X0 and ~T0 be their images under
an arbitrary renaming. Then, D ~X <= D ~X0 dh ~T <= ~T0 must hold. 2

Because it is stated in terms of an entailment assertion, the above requireng
ment bears on the interpretation of subtyping. The idea is, since D ~X is deng
clared to be isomorphic to (a sum or a product of) ~T, whenever two types
built with D are comparable, their unfoldings should be comparable as well.
The reverse entailment assertion is not required for type soundness, and it
is sometimes useful to declare algebraic data types that do not validate it--
songcalled phantom types (Fluet and Pucella, 2002). Note that the requirement
may always be satisfied by making the type constructor D invariant in all of
its parameters. Indeed, in that case, D ~X <= D ~X0 entails ~X C^ ~X0, which must enng
tail ~T C^ ~T0 since ~T0 is precisely E,~X , ~X0G*~T. In an equality free tree model, every
type constructor is naturally invariant, so the requirement is trivially satisng
fied. In other settings, however, it is often possible to satisfy the requirement
of Definition 10.7.8 while assigning D a less restrictive variance. The following
example illustrates such a case.

10.7.9 Example: Let list be a data type of signature ? ) ?. Let Nil and Cons be data

constructors. Then, the following is a definition of list as a variant type:

list X ss \Sigma  D^Nil : unit; Cons : X * list XE^
Because data types form a subset of type constructors, it is valid to form the
type list X in the rightnghand side of the definition, even though we are still in
the process of defining the meaning of list. In other words, data type defining
tions may be recursive. However, because ss is not interpreted as equality, the
type list X is not a recursive type: it is nothing but an application of the unary
type constructor list to the type variable X. To check that the definition of list
satisfies the requirement of Definition 10.7.8, we must ensure that

list X <= list X0 dh unit <= unit ^ X * list X <= X0 * list X0
holds. This assertion is equivalent to list X <= list X0 dh X <= X0. To satisfy the
requirement, it is sufficient to make list a covariant type constructor, that is,
to define subtyping in the model so that list X <= list X0 j X <= X0 holds.

456 10 The Essence of ML Type Inference

Let tree be a data type of signature ? ) ?. Let root and sons be record
labels. Then, the following is a definition of tree as a record type:

tree X ss \Pi  D^root : X; sons : list D^tree XE^E^
This definition is again recursive, and relies on the previous definition. Beng
cause list is covariant, it is straightforward to check that the definition of tree
is valid if tree is made a covariant type constructor as well. 2

A prologue is a set of algebraic data type definitions, where each data type
is defined at most once and where each data constructor or record label apng
pears at most once. A program is a pair of a prologue and an expression.
The effect of a prologue is to enrich the programming language with new
constants. That is, a variant type definition extends the operational semanng
tics with several injections and a case construct, as in Example 10.1.7. A
record type definition extends it with a record formation construct and sevng
eral projections, as in Examples 10.1.3 and 10.1.5. In either case, the initial
typing environment \Gamma 0 is extended with information about these new conng
stants. Thus, algebraic data type definitions might be viewed as a simple
configuration language that allows specifying in which instance of MLngtheng
calculus the expression that follows the prologue should be typechecked and
interpreted. Let us now give a precise account of this phenomenon.

To begin, suppose the prologue contains the definition D ~X ss PkiC^1 `i : Ti.
Then, for each i 2 {1; : : : ; k}, a constructor of arity 1, named `i, is introduced.
Furthermore, a destructor of arity k + 1, named caseD, is introduced. When
k > 0, it is common to write case t E,`i : tiG*kiC^1 for the application caseD t t1
: : : tn. The operational semantics is extended with the following reduction
rules, for i 2 {1; : : : ; k}:

case D^`i vE^ E,`j : vj G*kjC^1 ffi-! vi v (RngAlgngCase)
For each i 2 {1; : : : ; k}, the initial environment is extended with the binding
`i : 8_X:Ti ! D ~X. It is further extended with the binding caseD : 8_XZ:D ~X !
D^T1 ! ZE^ ! : : : D^Tk ! ZE^ ! Z.

Now, suppose the prologue contains the definition D ~X ss QkiC^1 `i : Ti. Then,
for each i 2 {1; : : : ; k}, a destructor of arity 1, named `i, is introduced. Furng
thermore, a constructor of arity k, named makeD, is introduced. It is common
to write t:` for the application ` t and, when k > 0, to write {`i C^ ti}kiC^1 for
the application makeD t1 : : : tk. The operational semantics is extended with
the following reduction rules, for i 2 {1; : : : ; k}:

D^{`j C^ vj }kjC^1E^:`i ffi-! vi (RngAlgngProj)
For each i 2 {1; : : : ; k}, the initial environment is extended with the binding
`i : 8_X:D ~X ! Ti. It is further extended with the binding makeD : 8_X:T1 ! : : : !
Tk ! D ~X.

10.7 From MLngthengCalculus to MLngthengLanguage 457
10.7.10 Example: The effect of defining list (Example 10.7.9) is to make Nil and Cons

data constructors of arity 1 and to introduce a binary destructor caselist. The
definition also extends the initial environment as follows:

Nil : 8X:unit ! list X
Cons : 8X:X * list X ! list X
caselist : 8XZ:list X ! D^unit ! ZE^ ! D^X * list X ! ZE^ ! Z

Thus, the value ConsD^^0; NilD^E^E^, an integer list of length 1, has type list int. A
function that computes the length of a list may now be written as follows:

letrec length C^ *l:case l E, Nil : * :^0 | Cons : *z:^1 ^+ length D^ss2 zE^ G*
Recall that this notation is syntactic sugar for

letrec length C^ *l:caselist l D^* :^0E^ D^*z:^1 ^+ length D^ss2 zE^E^
The difference with the code in Example 10.7.7 appears minimal: the case
construct is now annotated with the data type list. As a result, the type inferng
ence algorithm employs the type scheme assigned to caselist, which is derived
from the definition of list, instead of the type scheme assigned to the anonyng
mous case construct, given in Exercise 10.7.4. This is good for a couple of
reasons. First, the former is more informative than the latter, because it conng
tains the type Ti associated with the data constructor `i. Here, for instance,
the generated constraint requires the type of z to be X * list X for some X, so
a good error message would be given if a mistake was made in the second
branch, such as omitting the use of ss2. Second, and more fundamentally,
the code is now wellngtyped, even in the absence of recursive types. In Examng
ple 10.7.7, a cyclic equation was produced because case required the type of
l to be a sum type and because a sum type carries the types of its left and
right branches as subterms. Here, caselist requires l to have type list X for
some X. This is an abstract type: it does not explicitly contain the types of
the branches. As a result, the generated constraint no longer involves a cyclic
equation. It is, in fact, satisfiable; the reader may check that length has type
8X:list X ! int, as expected. 2

Example 10.7.10 stresses the importance of using declared, abstract types,
as opposed to anonymous, concrete sum or product types, in order to obviate
the need for recursive types. The essence of the trick lies in the fact that the
type schemes associated with operations on algebraic data types implicitly
fold and unfold the data type's definition. More precisely, let us recall the type
scheme assigned to the ith injection in the setting of (kngary) anonymous sums:
it is 8X1 : : : Xk:Xi ! X1 + : : : + Xk, or, more concisely, 8X1 : : : Xk:Xi ! PkiC^1 Xi.

458 10 The Essence of ML Type Inference

By instantiating each Xi with Ti and generalizing again, we find that a more
specific type scheme is 8_X:Ti ! PkiC^1 Ti. Perhaps this could have been the
type scheme assigned to `i? Instead, however, it is 8_X:Ti ! D ~X. We now reng
alize that the latter type scheme not only reflects the operational behavior
of the ith injection but also folds the definition of the algebraic data type D
by turning the anonymous sum PkiC^1 Ti--which forms the definition's rightng
hand side--into the parameterized abstract type D ~X--which is the definition's
leftnghand side. Conversely, the type scheme assigned to caseD unfolds the
definition. The situation is identical in the case of record types: in either case,
constructors fold, destructors unfold. In other words, occurrences of data
constructors and record labels in the code may be viewed as explicit instrucng
tions for the typechecker to fold or unfold an algebraic data type definition.
This mechanism is characteristic of isorecursive types.

10.7.11 Exercise [n', 3]: For a fixed k, check that all of the machinery associated

with kngary anonymous products--that is, constructors, destructors, reduction
rules, and extensions to the initial typing environment--may be viewed as the
result of a single algebraic data type definition. Conduct a similar check in the
case of kngary anonymous sums. 2

10.7.12 Exercise [n'n'n', 3]: Check that the above definitions meet the requirements

of Definition 10.5.5. 2

10.7.13 Exercise [n'n'n', 3]: For the sake of simplicity, we have assumed that all data

constructors have arity one. If desired, it is possible to accept variant data
type definitions of the form D ~X ss PkiC^1 `i : ~Ti, where the arity of the data conng
structor `i is the length of the vector ~Ti, and may be an arbitrary nonnegative
integer. This allows, for instance, altering the definition of list so that the
data constructors Nil and Cons are respectively nullary and binary. Make the
necessary changes in the above definitions and check that the requirements
of Definition 10.5.5 are still met. 2

One significant drawback of algebraic data type definitions resides in the
fact that a label ` cannot be shared by two distinct variant or record type
definitions. Indeed, every algebraic data type definition extends the calculus
with new constants. Strictly speaking, our presentation does not allow a sinng
gle constant c to be associated with two distinct definitions. Even if we did
allow such a collision, the initial environment would contain two bindings
for c, one of which would then hide the other. This phenomenon arises in
actual implementations of MLngthengprogrammingnglanguage, where a new algeng
braic data type definition may hide some of the data constructors or record
labels introduced by a previous definition. An elegant solution to this lack of
expressiveness is discussed in $10.8.

10.7 From MLngthengCalculus to MLngthengLanguage 459
Recursive Types
We have shown that specializing HMD^XE^ with an equalityngonly syntactic model
yields HMD^C^E^, a constraintngbased formulation of Damas and Milner's type
system. Similarly, it is possible to specialize HMD^XE^ with an equalityngonly
free regular tree model, yielding a constraintngbased type system that may be
viewed as an extension of Damas and Milner's type discipline with recursive
types. This flavor of recursive types is sometimes known as equirecursive,
since cyclic equations, such as X C^ X ! X, are then satisfiable. Our theong
rems about type inference and type soundness, which are independent of the
model, remain valid. The constraint solver described in $10.6 may be used
in the setting of an equalityngonly free regular tree model; the only difference
with the syntactic case is that the occurs check is no longer performed.

Note that, although ground types are regular, types remain finite objects:
their syntax is unchanged. The u notation commonly employed to describe
recursive types may be emulated using type equations: for instance, the nong
tation uX:X ! X corresponds, in our constraintngbased approach, to the type
scheme 8XE,X C^ X ! XG*:X.

Although recursive types come for free, as explained above, they have not
been adopted in mainstream programming languages based on MLngthengtypeng
system. The reason is pragmatic: experience shows that many nonsensical
expressions are wellngtyped in the presence of recursive types, whereas they
are not in their absence. Thus, the gain in expressiveness is offset by the fact
that many programming mistakes are detected later than otherwise possible.
Consider, for instance, the following OCaml session:

ocaml ngrectypes
# let rec map f = function

| [] ! []
| x :: l ! (map f x) :: (map f l);;
val map : 'a ! ('b list as 'b) ! ('c list as 'c) = <fun>

This nonsensical version of map is essentially useless, yet wellngtyped. Its prinng
cipal type scheme, in our notation, is 8XYZE,Y C^ list Y ^ Z C^ list ZG*:X ! Y ! Z.
In the absence of recursive types, it is illngtyped, since the constraint Y C^
list Y ^ Z C^ list Z is then false.

The need for equirecursive types is usually suppressed by the presence of
algebraic data types, which offer isorecursive types, in the language. Yet, they
are still necessary in some situations, such as in Objective Caml's extensions
with objects (Re'my and Vouillon, 1998) or polymorphic variants (Garrigue,
1998, 2000, 2002), where recursive object or variant types are commonly inng
ferred. In order to allow recursive object or variant types while still rejecting
the above version of map, Objective Caml's constraint solver implements a

460 10 The Essence of ML Type Inference

selective occurs check, which forbids cycles unless they involve the type conng
structors h*i or E,*G* respectively associated with objects and variants. The
corresponding model is a tree model where every infinite path down a tree
must encounter the type constructor h*i or E,*G* infinitely often.

10.8 Rows

In $10.7, we have shown how to extend MLngthengprogrammingnglanguage with
algebraic data types, that is, variant and record type definitions, which we
now refer to as simple. This mechanism has a severe limitation: two distinct
definitions must define incompatible types. As a result, one cannot hope
to write code that uniformly operates over variants or records of different
shapes, because the type of such code is not even expressible.

For instance, it is impossible to express the type of the polymorphic record
access operation, which retrieves the value stored at a particular field ` inside
a record, regardless of which other fields are present. Indeed, if the label
` appears with type T in the definition of the simple record type D ~X, then
the associated record access operation has type 8_X:D ~X ! T. If ` appears
with type T0 in the definition of another simple record type, say D0 ~X0, then
the associated record access operation has type 8_X0:D0 ~X0 ! T0; and so on.
The most precise type scheme that subsumes all of these incomparable type
schemes is 8XY:X ! Y. It is, however, not a sound type scheme for the record
access operation. Another powerful operation whose type is currently not
expressible is polymorphic record extension, which copies a record and stores
a value at field ` in the copy, possibly creating the field if it did not previously
exist, again regardless of which other fields are present. (If ` was known to
previously exist, the operation is known as polymorphic record update.)

In order to assign types to polymorphic record operations, we must do
away with record type definitions: we must replace named record types, such
as D ~X, with structural record types that provide a direct description of the
record's domain and contents. (Following the analogy between a record and
a partial function from labels to values, we use the word domain to refer to
the set of fields that are defined in a record.) For instance, a product type is
structural: the type T1 * T2 is the (undeclared) type of pairs whose first comng
ponent has type T1 and whose second component has type T2. Thus, we wish
to design record types that behave very much like product types. In doing so,
we face two orthogonal difficulties. First, as opposed to pairs, records may
have different domains. Because the type system must statically ensure that
no undefined field is accessed, information about a record's domain must be
made part of its type. Second, because we suppress record type definitions,

10.8 Rows 461
labels must now be predefined. However, for efficiency and modularity reang
sons, it is impossible to explicitly list every label in existence in every record
type.

In what follows, we explain how to address the first difficulty in the simple
setting of a finite set of labels. Then we introduce rows, which allow dealing
with an infinite set of labels, and address the second difficulty. We define the
syntax and logical interpretation of rows, study the new constraint equivang
lence laws that arise in their presence, and extend the firstngorder unification
algorithm with support for rows. Then we review several applications of rows,
including polymorphic operations on records, variants, and objects, and disng
cuss alternatives to rows.

Because our interest is in typechecking and type inference issues, we do
not address the compilation issue: how does one efficiently compile polyng
morphic records or polymorphic variants? A few relevant papers are Pugh
and Weddell (1990), Ohori (1995), and Garrigue (1998). The problem of opng
timizing message dispatch in objectngoriented languages, which has received
considerable attention in the literature, is related.

Records with Finite Carrier
Let us temporarily assume that L is finite. In fact, for the sake of definiteness,
let us assume that L is the threengelement set {`a; `b; `c}.

To begin, let us consider only full records, whose domain is exactly L--in
other words, tuples indexed by L. To describe them, it is natural to introduce
a type constructor \Pi  of signature ? \Omega  ? \Omega  ? ) ?. The type \Pi  Ta Tb Tc repng
resents all records where the field `a (respectively `b, `c) contains a value
of type Ta (respectively Tb, Tc ). Note that \Pi  is nothing but a product type
constructor of arity 3. The basic operations on records, namely creation of
a record out of a default value, which is stored into every field, update of
a particular field (say, `b), and access to a particular field (say, `b), may be
assigned the following type schemes:

{*} : 8X:X ! \Pi  X X X
{* with `b C^ *} : 8XaXbX0bXc:\Pi  Xa Xb Xc ! X0b ! \Pi  Xa X0b Xc

*:{`b} : 8XaXbXc:\Pi  Xa Xb Xc ! Xb

Here, polymorphism allows updating or accessing a field without knowledge
of the types of the other fields. This flexibility stems from the key property
that all record types are formed using a single \Pi  type constructor.

This is fine, but in general, the domain of a record is not necessarily L: it
may be a subset of L. How may we deal with this fact while maintaining the
above key property? A naive approach consists of encoding arbitrary records

462 10 The Essence of ML Type Inference

in terms of full records, using the standard algebraic data type option, whose
definition is option X ss pre X+abs: We use pre for present and abs for absent:
indeed, a field that is defined with value v is encoded as a field with value pre
v, while an undefined field is encoded as a field with value abs. Thus, an arbing
trary record whose fields, if present, have types Ta, Tb, and Tc, respectively,
may be encoded as a full record of type \Pi  D^option TaE^ D^option TbE^ D^option
TcE^. This naive approach suffers from a serious drawback: record types still
contain no domain information. As a result, field access must involve a dyng
namic check, so as to determine whether the desired field is present; in our
encoding, this corresponds to the use of caseoption.

To avoid this overhead and increase programming safety, we must move
this check from runtime to compile time. In other words, we must make the
type system aware of the difference between pre and abs. To do so, we reng
place the definition of option by two separate algebraic data type definitions,
namely pre X ss pre X and abs ss abs. In other words, we introduce a unary
type constructor pre, whose only associated data constructor is pre, and a
nullary type constructor abs, whose only associated data constructor is abs.
Record types now contain domain information; for instance, a record of type
\Pi  abs D^pre TbE^ D^pre TcE^ must have domain {`b; `c}. Thus, the type of a field
tells whether it is defined. Since the type pre has no data constructors other
than pre, the accessor pre-1, whose type is 8X:pre X ! X, and which allows
retrieving the value stored in a field, cannot fail. Thus, the dynamic check has
been eliminated.

To complete the definition of our encoding, we now define operations on
arbitrary records in terms of operations on full records. To distinguish beng
tween the two, we write the former with angle braces, instead of curly braces.
The empty record hi, where all fields are undefined, may be defined as {abs}.
Extension at a particular field (say, `b) h* with `b C^ *i is defined as *r:*z:
{r with `b C^ pre z}. Access at a particular field (say, `b) *:h`bi is defined as
*z:pre-1z:{`b}. It is straightforward to check that these operations have the
following principal type schemes:

hi : \Pi  abs abs abs
h* with `b C^ *i : 8XaXbX0bXc:\Pi  Xa Xb Xc ! X0b ! \Pi  Xa D^pre X0bE^ Xc

*:h`bi : 8XaXbXc:\Pi  Xa D^pre XbE^ Xc ! Xb

It is important to notice that the type schemes associated with extension
and access at `b are polymorphic in Xa and Xc, which now means that these
operations are insensitive, not only to the type, but also to the presence or
absence of the fields `a and `c . Furthermore, extension is polymorphic in Xb,
which means that it is insensitive to the presence or absence of the field `b
in its argument. The subterm pre X0b in its result type reflects the fact that

10.8 Rows 463
`b is defined in the extended record. Conversely, the subterm pre Xb in the
type of the access operation reflects the requirement that `b be defined in its
argument.

Our encoding of arbitrary records in terms of full records was carried out
for pedagogical purposes. In practice, no such encoding is necessary: the data
constructors pre and abs have no machine representation, and the compiler
is free to lay out records in memory in an efficient manner. The encoding
is interesting, however, because it provides a natural way of introducing the
type constructors pre and abs, which play an important role in our treatment
of polymorphic record operations.

Once we forget about the encoding, the arguments of the type constructor
\Pi  are expected to be either type variables or formed with pre or abs, while,
conversely, the type constructors pre and abs are not intended to appear
anywhere else. It is possible to enforce this invariant using kinds. In addition
to ?, let us introduce the kind ffi of field types. Then, let us adopt the following
signatures: pre: ? ) ffi, abs : ffi, and \Pi  : ffi \Omega  ffi \Omega  ffi ) ?.

10.8.1 Exercise [Recommended, n', 3]: Check that the three type schemes given

above are wellngkinded. What is the kind of each type variable? 2

10.8.2 Exercise [Recommended, n'n']: Our \Pi  types contain information about every

field, regardless of whether it is defined: we encode definedness informang
tion within the type of each field, using the type constructors pre and abs.
A perhaps more natural approach would be to introduce a family of record
type constructors, indexed by the subsets of L, so that the types of records
with different domains are formed with different constructors. For instance,
the empty record would have type {}; a record that defines the field `a only
would have a type of the form {`a : Ta}; a record that defines the fields
`b and `c only would have a type of the form {`b : Tb; `c : Tc}; and so on.
Assuming that the type discipline is Damas and Milner's (that is, assuming
an equalityngonly syntactic model), would it be possible to assign satisfactory
type schemes to polymorphic record access and extension? Would it help to
equip record types with a nontrivial subtyping relation? 2

Records with Infinite Carrier
The treatment of records described above is not quite satisfactory, from pracng
tical and theoretical points of view. First, in practice, the set L of all record
labels that appear within a program could be very large. Because every record
type is just as large as L itself, even if the record that it describes only has a
few fields, this is unpleasant. Furthermore, in a modular setting, the set of all
record labels that appear within a program cannot be determined until link

464 10 The Essence of ML Type Inference

time, so it is still unknown at compile time, when each compilation unit is
separately typechecked. As a result, it may only be assumed to be a subset of
the infinite set of all syntactically valid record labels. Resolving these issues
requires coming up with a treatment of records that does not become more
costly as L grows and that, in fact, allows L to be infinite. Thus, from here
on, let us assume that L is infinite.

As in the previous section, we first concentrate on full records, whose dong
main is exactly L. The case of arbitrary records, whose domain is a subset of
L, will then follow in the same manner, by using the type constructors pre
and abs to encode domain information.

Of course, even though we have assumed that L is infinite, we must ensure
that every record has a finite representation. We choose to restrict our attenng
tion to records that are almost constant, that is, records where all fields but
a finite number contain the same value. Every such record may be defined in
terms of two primitive operations, namely (i) creation of a constant record
out of a value; for instance, {false} is the record where every field contains
the value false; and (ii) update of a record at a particular field; for instance,
{{false} with ` C^ 1} carries the value 1 at field ` and the value false at
every other field. As usual, an access operation allows retrieving the contents
of a field. Thus, the three primitive operations are the same as in the previous
subsection, only in the setting of an infinite number of fields.

If we were to continue as before, we would now introduce a type construcng
tor \Pi , equipped with an infinite family of type parameters. Because types
must remain finite objects, we cannot do so. Instead, we must find a finite
(and economical) representation of such an infinite family of types. This is
precisely the role played by rows.

A row is a type that denotes a function from labels to types or, equivang
lently, a family of types indexed by labels. Its domain is L--the row is then
complete--or a cofinite subset of L--the row is then incomplete. (A subset of
L is cofinite if and only if its complement is finite. Incomplete rows are used
only as building blocks for complete rows.) Because rows must admit a finite
representation, we build them out of two syntactic constructions, namely (i)
construction of a constant row out of a type; for instance, the notation @bool
denotes a row that maps every label in its domain to bool; and (ii) strict exng
tension of an incomplete row; for instance, D^` : int ; @boolE^ denotes a row
that maps ` to int and every other field in its domain to bool. Formally, @ is
a unary type constructor, while, for every label `, D^` : * ; *E^ is a binary type
constructor. These two constructions are reminiscent of the two operations
used above to build records. There are, however, a couple of subtle but imng
portant differences. First, @T may be a complete or incomplete row. Second,
D^` : T ; T0E^ is defined only if ` is not in the domain of the row T0, so this

10.8 Rows 465
construction is strict extension, not update. These aspects are made clear by
a kinding discipline, to be introduced later on.

It is possible for two syntactically distinct rows to denote the same funcng
tion from labels to types. For instance, according to the intuitive interpretang
tion of rows given above, the three complete rows D^` : int ; @boolE^, D^` : int ;
D^`0 : bool ; @boolE^E^, and D^`0 :bool ; D^` : int ; @boolE^E^ denote the same total funcng
tion from labels to types. In the following, we define the logical interpretation
of types in such a way that the interpretations of these three rows in the
model are indeed equal.

We may now make the record type constructor \Pi  a unary type constructor,
whose parameter is a row. Then, (say) \Pi  D^` : int ; @boolE^ is a record type, and
we intend it to be a valid type for the record {{false} with ` C^ 1}. The basic
operations on records may be assigned the following type schemes:

{*} : 8X:X ! \Pi  D^@XE^
{* with ` C^ *} : 8XX0Y:\Pi  D^` : X ; YE^ ! X0 ! \Pi  D^` : X0 ; YE^

*:{`} : 8XY:\Pi  D^` : X ; YE^ ! X

These type schemes are reminiscent of those given above. However, in the
previous section, the size of the type schemes was linear in the cardinal of L,
whereas here it is constant, even though L is infinite. This is made possible
by the fact that record types no longer list all labels in existence; instead, they
use rows. In the type scheme assigned to record creation, the constant row
@X is used to indicate that all fields have the same type in the newly created
record. In the next two type schemes, the row D^` : X` ; XE^ is used to separate
the type X`, which describes the contents of the field `, and the row X, which
collectively describes the contents of all other fields. Here, the type variable X
stands for an arbitrary row; it is often referred to as a row variable. The ability
of quantifying over row and type variables alike confers great expressiveness
to the type system.

We have explained, in an informal manner, how rows allow typechecking
operations on full records, in the setting of an infinite set of labels. We return
to this issue in Example 10.8.25. To deal with the case of arbitrary records,
whose domain is finite, we rely on the field type constructors pre and abs, as
explained previously. We return to this point in Example 10.8.30. In the folng
lowing, we give a formal exposition of rows. We begin with their syntax and
logical interpretation. Then we give some new constraint equivalence laws,
which characterize rows, and allow extending our firstngorder unification alng
gorithm with support for rows. We conclude with several illustrations of the
use of rows and some pointers to related work.

466 10 The Essence of ML Type Inference

Syntax of Rows
In the following, the set of labels L is considered denumerable. We let L range
over finite subsets of L. When ` AE L holds, we write `:L for {`} ] L. Before
explaining how the syntax of types is enriched with rows, we introduce row
kinds, whose grammar is as follows:

s ::C^ Type | RowD^LE^
Row kinds help distinguish between three kinds of types, namely ordinary
types, complete rows, and incomplete rows. While ordinary types are used to
describe expressions, complete or incomplete rows are used only as building
blocks for ordinary types. For instance, the record type \Pi  D^` : int ; @boolE^,
which was informally introduced above, is intended to be an ordinary type,
that is, a type of row kind Type. Its subterm D^` : int ; @boolE^ is a complete row,
that is, a type of row kind RowD^IJE^. Its subterm @bool is an incomplete row,
whose row kind is RowD^{`}E^. Intuitively, a row of kind RowD^LE^ denotes a famng
ily of types whose domain is L\L. In other words, L is the set of labels that the
row does not define. The purpose of row kinds is to outlaw meaningless types,
such as \Pi  D^intE^, which makes no sense because the argument to the record
type constructor \Pi  should be a (complete) row, or D^` :T1 ; ` : T2 ; @boolE^, which
makes no sense because no label may occur twice within a row.

Let us now define the syntax of types in the presence of rows. As usual, it
is given by a signature S (Definition 10.1.14), which lists all type constructors
together with their signatures. Here, for the sake of generality, we do not wish
to give a fixed signature S. Instead, we give a procedure that builds S out of
two simpler signatures, referred to as S0 and S1. The input signature S0 lists
the type constructors that have nothing to do with rows, such as !, *, int,
etc. The input signature S1 lists the type constructors that allow a row to be a
subterm of an ordinary type, such as the record type constructor \Pi . In a type
system equipped with extensible variant types or with object types, there
might be several such type constructors; see the sections on Polymorphic
Variants (p. 483) and Other Applications of Rows (p. 486). Without loss of
generality, we assume that all type constructors in S1 are unary. The point of
parameterizing the definition of S over S0 and S1 is to make the construction
more general: instead of defining a fixed type grammar featuring rows, we
wish to explain how to enrich an arbitrary type grammar with rows.

In the following, we let G (respectively H) range over the type constructors
in S0 (respectively S1). We let ^ range over the kinds involved in the defining
tion of S0 and S1, and refer to them as basic kinds. We let F range over the
type constructors in S. The kinds involved in the definition of S are comng
posite kinds, that is, pairs of a basic kind ^ and a row kind s, written ^:s.

10.8 Rows 467
This allows the kind discipline enforced by S to reflect that enforced by S0
and S1 and also to impose restrictions on the structure and use of rows,
as suggested above. For the sake of conciseness, we write K:s for the mapng
ping D^d , KD^dE^:sE^d2domD^KE^ and D^K ) ^E^:s for the (composite) kind signature
K:s ) ^:s. (In other words, we let :s distribute over basic signatures.) We use
symmetric notations to build a composite kind signature out of a basic kind
and a row kind signature.

10.8.3 Definition: The signature S is defined as follows:

F 2 domD^SE^ Signature Conditions

Gs D^K ) ^E^:s D^G : K ) ^E^ 2 S0

H K:RowD^IJE^ ) ^:Type D^H : K ) ^E^ 2 S1
@^;L ^:D^Type ) RowD^LE^E^
`^;L ^:D^Type \Omega  RowD^`:LE^ ) RowD^LE^E^ ` AE L

We sometimes refer to S as the row extension of S0 with S1. 2
Examples 10.8.7 and 10.8.8 suggest common choices of S0 and S1 and give a
perhaps more concretenglooking definition of the grammar of types that they
determine. First, however, let us explain the definition. The type constructors
that populate S come in four varieties: they may be (i) taken from S0, (ii)
taken from S1, (iii) a unary row constructor @, or (iv) a binary row constructor
D^` : * ; *E^. Let us review and explain each case.

Let us first consider case (i) and assume, for the time being, that s is Type.
Then, for every type constructor G in S0, there is a corresponding type conng
structor GType in S. For instance, S0 must contain an arrow type constructor
!, whose signature is {domain , ?; codomain , ?} ) ?. Then, S contains
a type constructor !Type, whose signature is {domain , ?:Type; codomain ,
?:Type} ) ?:Type. Thus, !Type is a binary type constructor whose parameng
ters and result must have basic kind ? and must have row kind Type; in other
words, they must be ordinary types, as opposed to complete or incomplete
rows. The family of all type constructors of the form GType, where G ranges
over S0, forms a copy of S0 at row kind Type: one might say, roughly speakng
ing, that S contains S0. This is not surprising, since our purpose is to enrich
the existing signature S0 with syntax for rows.

Perhaps more surprising is the existence of the type constructor Gs, for
every G in S0, and for every row kind s. For instance, for every L, S contains a
type constructor !RowD^LE^, whose signature is {domain , ?:RowD^LE^; codomain
, ?:RowD^LE^} ) ?:RowD^LE^. Thus, !RowD^LE^ is a binary type constructor whose
parameters and result must have basic kind ? and must have row kind RowD^LE^.
In other words, this type constructor maps a pair of rows that have a common
domain to a row with the same domain. Recall that a row is to be interpreted

468 10 The Essence of ML Type Inference

as a family of types. Our intention is that !RowD^LE^ maps two families of types
to a family of arrow types. This is made precise in the next subsection. One
should point out that the type constructors Gs , with s 6C^ Type, are required
only in some advanced applications of rows; Examples 10.8.28 and 10.8.39
provide illustrations. They are not used when assigning types to the usual
primitive operations on records, namely creation, update, and access (Examng
ples 10.8.25 and 10.8.30).

Case (ii) is simple: it simply means that S contains S1. It is only worth
noting that every type constructor H maps a parameter of row kind RowD^IJE^
to a result of row kind Type, that is, a complete row to an ordinary type.
Thanks to this design choice, the type \Pi  D^intTypeE^ is invalid: indeed, intType
has row kind Type, while \Pi  expects a parameter of row kind RowD^IJE^.

Cases (iii) and (iv) introduce new type constructors that were not present
in S0 or S1 and allow forming rows. They were informally described in the
previous subsection. First, for every ^ and L, there is a constant row construcng
tor @^;L. Its parameter must have row kind Type, while its result has row kind
RowD^LE^; in other words, this type constructor maps an ordinary type to a row.
It is worth noting that the row thus built may be complete or incomplete; for
instance, @?;IJ bool is a complete row, and may be used, for example, to build
the type \Pi  D^@?;IJ boolE^, while @?;{`} bool is an incomplete row, and may be
used, for example, to build the type \Pi  D^` : int ; @?;{`} boolE^. Second, for every
^, L, and ` AE L, there is a row extension constructor `^;L. We usually write
`^;L : T1 ; T2 for `^;L T1 T2 and let this symbol be right associative so as to
recover the familiar list notation for rows. According to the definition of S,
if T2 has row kind RowD^`:LE^, then `^;L : T1 ; T2 has row kind RowD^LE^. Thanks
to this design choice, the type D^`?;L : T1 ; `?;L : T2 ; @?;`:L boolE^ is invalid; inng
deed, the outer ` expects a parameter of row kind RowD^`:LE^, while the inner
` produces a type of row kind RowD^LE^.

The superscripts carried by the type constructors G, `, and @ in the signang
ture S make all kind information explicit, obviating the need for assigning
several kinds to a single type constructor. In practice, however, we often
drop the superscripts and use unannotated types. No ambiguity arises beng
cause, given a type expression T of known kind, it is possible to reconstruct
all superscripts in a unique manner. This is the topic of the next example and
exercises.

10.8.4 Example [Illngkinded types]: Assume that S0 contains type constructors int

and !, whose signatures are respectively ? and ? \Omega  ? ) ?, and that S1
contains a type constructor \Pi , whose signature is ? ) ?.

The unannotated type X ! \Pi D^XE^ is invalid. Indeed, because \Pi 's image row
kind is Type, the arrow must be !Type. Thus, the leftmost occurrence of X

10.8 Rows 469
must have row kind Type. On the other hand, because \Pi  expects a parameter
of row kind RowD^IJE^, its rightmost occurrence must have row kind RowD^IJE^--a
contradiction. The unannotated type X ! \Pi D^@XE^ is, however, valid, provided
X has kind ?:Type. In fact, it is the type of the primitive record creation operng
ation.

The unannotated type D^` : T ; ` : T ; T00E^ is also invalid: there is no way
of reconstructing the missing superscripts so as to make it valid. Indeed,
the row D^` : T0 ; T00E^ must have row kind RowD^LE^ for some L that does not
contain `. However, the context where it occurs requires it to also have row
kind RowD^LE^ for some L that does contain `. This makes it impossible to
reconstruct consistent superscripts.

Any type of the form \Pi D^\Pi D^TE^E^ is invalid, because the outer \Pi  expects a pang
rameter of row kind RowD^IJE^, while the inner \Pi  constructs a type of row kind
Type. This is an intentional limitation: unlike those of S0, the type construcng
tors of S1 are not lifted to every row kind s. (If they were, we would be led to
work not only with rows of ordinary types, but also with rows of rows, rows
of rows of rows, and so on. Re'my (1990) explores this avenue.) 2

10.8.5 Exercise [Recommended, n']: Consider the unannotated type

X ! \Pi D^` : int ; D^Y ! @XE^E^:
Can you guess the kind of the type variables X and Y, as well as the missing
superscripts, so as to ensure that this type has kind ?:Type? 2

10.8.6 Exercise [n'n'n', 3]: Propose a kind checking algorithm that, given an unanng

notated type T, given the kind of T, and given the kind of all type variables that
appear within T, ensures that T is wellngkinded, and reconstructs the missing
superscripts within T. Next, propose a kind inference algorithm that, given an
unannotated type T, discovers the kind of T and the kind of all type variables
that appear within T so as to ensure that T is wellngkinded. 2

We have given a very general definition of the syntax of types. In this view,
types, ranged over by the metangvariable T, encompass both "ordinary" types
and rows: the distinction between the two is established only via the kind
system. In the literature, however, it is common to establish this distinction
by letting distinct metangvariables, say T and R, range over ordinary types and
rows, respectively, so as to give the syntax a more concrete aspect. The next
two examples illustrate this style and suggest common choices for S0 and S1.

10.8.7 Example: Assume that there is a single basic kind ?, that S0 consists of the

arrow type constructor !, whose signature is ? \Omega  ? ) ?, and that S1 consists

470 10 The Essence of ML Type Inference

of the record type constructor \Pi , whose signature is ? ) ?. Then, the comng
posite kinds are ?:Type and ?:RowD^LE^, where L ranges over the finite subsets
of L. Let us employ T (respectively R) to range over types of the former (reng
spectively latter) kind, and refer to them as ordinary types (respectively rows).
Then, the syntax of types, as defined by the signature S, may be presented
under the following form:

T ::C^ X | T ! T | \Pi  R
R ::C^ X | R ! R | D^` : T ; RE^ | @T

Ordinary types T include ordinary type variables (that is, type variables of
kind ?:Type), arrow types (where the type constructor ! is really !Type), and
record types, which are formed by applying the record type constructor \Pi  to
a row. Rows R include row variables (that is, type variables of kind ?:RowD^LE^
for some L), arrow rows (where the row constructor ! is really !RowD^LE^ for
some L), row extension (whereby a row R is extended with an ordinary type T
at a certain label `), and constant rows (formed out of an ordinary type T). It
would be possible to also introduce a syntactic distinction between ordinary
type variables and row variables, if desired.

Such a presentation is rather pleasant, because the syntactic segregation
between ordinary types and rows makes the syntax less ambiguous. It does
not allow getting rid of the kind system, however: (row) kinds are still necesng
sary to keep track of the domain of every row. 2

10.8.8 Example: Assume that there are two basic kinds ? and ffi, that S0 consists

of the type constructors !, abs, and pre, whose respective signatures are
?\Omega ? ) ?, ffi, and ? ) ffi, and that S1 consists of the record type constructor \Pi ,
whose signature is ffi ) ?. Then, the composite kinds are ?:Type, ?:RowD^LE^,
ffi:Type, and ffi:RowD^LE^, where L ranges over the finite subsets of L. Let us emng
ploy T?, R?, Tffi, and Rffi, respectively, to range over types of these four kinds.
Then, the syntax of types, as defined by the signature S, may be presented
under the following form:

T? ::C^ X | T? ! T? | \Pi  Rffi
R? ::C^ X | R? ! R? | D^` : T? ; R?E^ | @T?

Tffi ::C^ X | abs | pre T?
Rffi ::C^ X | abs | pre R? | D^` : Tffi ; RffiE^ | @Tffi

Ordinary types T? are as in the previous example, except the record type
constructor \Pi  must now be applied to a row of field types Rffi. Rows R? are
unchanged. Field types Tffi include field type variables (that is, type variables
of kind ffi:Type) and applications of the type constructors abs and pre (which
are really absType and preType). Field rows Rffi include field row variables (that

10.8 Rows 471
is, type variables of kind ffi:RowD^LE^ for some L), applications of the row conng
structors abs and pre (which are really absRowD^LE^ and preRowD^LE^ for some L),
row extension, and constant rows, where row components are field types Tffi.

In many basic applications of rows, absRowD^LE^ and preRowD^LE^ are never reng
quired: that is, they do not appear in the type schemes that populate the
initial environment. (Applications where they are required appear in Potng
tier [2000].) In that case, they may be removed from the syntax. Then, the
nonterminal R? becomes unreachable from the nonterminal T?, which is the
grammar's natural entry point, so it may be removed as well. In that simpling
fied setting, the syntax of types and rows becomes:

T? ::C^ X | T? ! T? | \Pi  Rffi

Tffi ::C^ X | abs | pre T?
Rffi ::C^ X | D^` : Tffi ; RffiE^ | @Tffi

This is the syntax found in some introductory accounts of rows (Re'my, 1989;
Pottier, 2000). 2

Meaning of Rows
We now give meaning to the type grammar defined in the previous section
by interpreting it within a model. We choose to define a regular tree model,
but alternatives exist; see Remark 10.8.12 below. In this model, every type
constructor whose image row kind is Type (that is, every type constructor of
the form GType or H) is interpreted as itself, as in a free tree model. However,
every application of a type constructor whose image row kind is RowD^LE^ for
some L receives special treatment: it is interpreted as a family of types inng
dexed by L \ L, which we encode as an infinitely branching tree. To serve as
the root label of this tree, we introduce, for every ^ and for every L, a symbol
L^, whose arity is L \ L. More precisely,

10.8.9 Definition: The model, which consists of a set M^:s for every ^ and s, is the

regular tree algebra that arises out the following signature:

Symbol Signature Conditions
G D^K ) ^E^:Type D^G : K ) ^E^ 2 S0
H K:RowD^IJE^ ) ^:Type D^H : K ) ^E^ 2 S1
L^ ^:D^TypeL\L ) RowD^LE^E^

The first two lines in this signature coincide with the definitions of GType
and H in the signature S. Indeed, as stated above, we intend to interpret

472 10 The Essence of ML Type Inference

these type constructors in a syntactic manner, so each of them must have a
counterpart in the model. The third line introduces the symbols L^ hinted at
above.

According to this signature, if t is a ground type of kind ^:Type (that is, an
element of M^:Type), then its head symbol tD^fflE^ must be of the form G or H.
If t is a ground type of kind ^:RowD^LE^, then its head symbol must be L^, and
its immediate subtrees, which are indexed by L \ L, are ground types of kind
^:Type; in other words, the ground row t is effectively a family of ordinary
ground types indexed by L \ L. Thus, our intuition that rows denote infinite
families of types is made literally true.

We have defined the model; there remains to explain how types are mapped
to elements of the model.

10.8.10 Definition: The interpretation of the type constructors that populate S is

defined as follows.

1. Let D^G : K ) ^E^ 2 S0. Then, GType is interpreted as the function that maps

T 2 MK:Type to the ground type t 2 M^:Type defined by tD^fflE^ C^ G and
t=d C^ T D^dE^ for every d 2 domD^KE^. This is a syntactic interpretation.

2. Let D^H : K ) ^E^ 2 S1. Then, H is interpreted as the function that maps

T 2 MK:RowD^IJE^ to the ground type t 2 M^:Type defined by tD^fflE^ C^ H and
t=d C^ T D^dE^ for every d 2 domD^KE^. (Because H is unary, there is exactly
one such d.) This is also a syntactic interpretation.

3. Let D^G : K ) ^E^ 2 S0. Then, GRowD^LE^ is interpreted as the function that

maps T 2 MK:RowD^LE^ to the ground type t 2 M^:RowD^LE^ defined by tD^fflE^ C^
L^ and tD^`E^ C^ G and t=D^` * dE^ C^ T D^dE^=` for every ` 2 L \ L and d 2
domD^KE^. Thus, when applied to a family of rows, the type constructor
GRowD^LE^ produces a row where every component has head symbol G. This
definition may sound quite technical; its effect is summed up in a simpler
fashion by the equations CngRowngGD and CngRowngGL in the next section.

4. Interpret @^;L as the function that maps t1 2 M^:Type to the ground type

t 2 M^:RowD^LE^ defined by tD^fflE^ C^ L^ and t=` C^ t1 for every ` 2 L \ L. Note
that t=` does not depend on `: t is a constant ground row.

5. Let ` AE L. Then, `^;L is interpreted as the function that maps D^t1; t2E^ 2

M^:Type *M^:RowD^`:LE^ to the ground type t 2 M^:RowD^LE^ defined by tD^fflE^ C^ L^
and t=` C^ t1 and t=`0 C^ t2D^`0E^ for every `0 2 L \ `:L. This definition
is precisely row extension; indeed, the ground row t maps ` to t1 and
coincides with the ground row t2 at every other label `0. 2

10.8 Rows 473
Defining a model and an interpretation allows our presentation of rows to fit
within the formalism proposed earlier in this chapter ($10.2). It also provides
a basis for the intuition that rows denote infinite families of types. From a
formal point of view, the model and its interpretation allow proving several
constraint equivalence laws concerning rows, which are given and discussed
in the next subsection. Of course, it is also possible to accept these equivng
alence laws as axioms and give a purely syntactic account of rows without
relying on a model; this is how rows were historically dealt with (Re'my, 1993).

10.8.11 Remark: We have not defined the interpretation of the subtyping predicate,

because much of the material that follows is independent of it. One common
approach is to adopt a nonstructural definition of subtyping (Example 10.2.9),
where every L^ is considered covariant in every direction, and where the varing
ances and relative ordering of all other symbols (G and H) are chosen at will,
subject to the restrictions associated with nonstructural subtyping and to the
conditions necessary to ensure type soundness.

Recall that the arrow type constructor ! is contravariant in its domain and
covariant in its codomain. The record type constructor \Pi  is usually covariant.
These properties are exploited in proofs of the subject reduction theorem.
The type constructors ! and \Pi  are usually incompatible. This property is
exploited in proofs of the progress theorem. In the case of Example 10.8.7,
because no type constructors other than ! and \Pi  are present, these conding
tions imply that there is no sensible way of interpreting subtyping other than
equality. In the case of Example 10.8.8, two sensible interpretations of subng
typing exist: one is equality, while the other is the nonstructural subtyping
order obtained by letting pre a` abs. In the former interpretation, abs means
"definitely absent," while in the latter, it means "possibly absent." 2

10.8.12 Remark: The model proposed above is a regular tree model. Of course, it

is possible to adopt a finite tree model instead. Furthermore, other interpreng
tations of rows are possible: for instance, Fa"hndrich (1999) extends the set
constraints formalism with rows. In his model, an ordinary type is interpreted
as a set of values, while a row is interpreted as a set of functions from labels
to values. While the definition of the model may vary, the key point is that
the characteristic laws of rows, which we discuss next, hold in the model. 2

Reasoning with Rows
The interpretation presented in the previous section was designed to support
the intuition that a row denotes an infinite family of types, indexed by labels,
that the row constructor ` : * ; * denotes row extension, and that the row
constructor @ denotes the creation of a constant row. From a formal point of

474 10 The Essence of ML Type Inference

D^`1 : T1 ; `2 : T2 ; T3E^ C^ D^`2 : T2 ; `1 : T1 ; T3E^ D^CngRowngLLE^

@T C^ D^` : T ; @TE^ D^CngRowngDLE^
G @T1 : : : @Tn C^ @D^G T1 : : : TnE^ D^CngRowngGDE^
G D^` : T1 ; T01E^ : : : D^` : Tn ; T0nE^ C^ D^` : G T1 : : : Tn ; G T01 : : : T0nE^ D^CngRowngGLE^

Figure 10ng12: Equational reasoning with rows

view, the definition of the model and interpretation may be exploited to esng
tablish some reasoning principles concerning rows. These principles take the
form of equations between types (Figure 10ng12) and constraint equivalence
laws (Figure 10ng13), which we now explain and prove.

10.8.13 Remark: As stated earlier, we omit the superscripts of row constructors. We

also omit the side conditions that concern the kind of the type variables (X)
and type metangvariables (T) involved. Thus, each equation in Figure 10ng12
really stands for the (infinite) family of equations obtained by reconstructing
the missing kind information in a consistent way. For instance, the second
equation may be read @`:LT C^ D^`^;L : T ; @LTE^, where ` AE L and T has kind
^:Type. 2

10.8.14 Exercise [Recommended, n', 3]: Reconstruct all of the missing kind inforng

mation in the equations of Figure 10ng12. 2

10.8.15 Remark: There is a slight catch with the unannotated version of the second

equation in Figure 10ng12: its leftnghand side admits strictly more kinds than its
rightnghand side, because the former has row kind RowD^LE^ for every L, while
the latter has row kind RowD^LE^ for every L such that ` AE L holds. As a result,
while replacing the unannotated term D^` : T ; @TE^ with @T is always valid, the
converse is not: replacing the unannotated term @T with D^` : T ; @TE^ is valid
only if it does not result in an illngkinded term. 2

The first equation in Figure 10ng12 states that rows are equal up to commung
tation of labels. For the equation to be wellngkinded, the labels `1 and `2 must
be distinct. The equation holds under our interpretation because extension
of a ground row at `1 and extension of a ground row at `2 commute. The
second equation states that @T maps every label within its domain to T, that
is, @LT maps every label ` 62 L to T. This equation holds because @T is interng
preted as a constant row. The last two equations deal with the relationship
between the row constructors G and the ordinary type constructor G. Indeed,
notice that their leftnghand sides involve GRowD^LE^ for some L, while their rightng
hand sides involve GType. Both equations state that it is equivalent to apply

10.8 Rows 475
D^`1 : T1 ; T01E^ C^ D^`2 : T2 ; T02E^ j 9X:D^T01 C^ D^`2 : T2 ; XE^ ^ T02 C^ D^`1 : T1 ; XE^E^ D^CngMutatengLLE^

if X # ftvD^T1; T01; T2; T02E^ ^ `1 6C^ `2

@T C^ D^` : T0 ; T00E^ j T C^ T0 ^ @T C^ T00 D^CngMutatengDLE^
G T1 : : : Tn C^ @T j 9X1 : : : Xn:D^G X1 : : : Xn C^ T ^ VniC^1D^Ti C^ @XiE^E^ D^CngMutatengGDE^

if X1 : : : Xn # ftvD^T1; : : : ; Tn; TE^

G T1 : : : Tn C^ D^` : T ; T0E^ j 9X1 : : : Xn; X01 : : : X0n:D^G X1 : : : Xn C^ T ^

G X01 : : : X0n C^ T0 ^V

niC^

1D^Ti C^ D^` : Xi ; X0iE^E^E^

if X1 : : : Xn; X01 : : : X0n # ftvD^T1; : : : ; Tn; T; T0E^ D^CngMutatengGLE^

Figure 10ng13: Constraint equivalence laws involving rows

GRowD^LE^ at the level of rows or to apply GType at the level of types. Our interng
pretation of GRowD^LE^ was designed to give rise to these equations; indeed, the
application of GRowD^LE^ to n ground rows (where n is the arity of G) is interng
preted as a pointwise application of GType to the rows' components (item 3 of
Definition 10.8.10). Their use is illustrated in Examples 10.8.28 and 10.8.39.

10.8.16 Lemma: Each of the equations in Figure 10ng12 is equivalent to true. 2

The four equations in Figure 10ng12 show that two types with distinct head
symbols may denote the same element of the model. In other words, in the
presence of rows, the interpretation of types is no longer free: an equation of
the form T1 C^ T2, where T1 and T2 have distinct head symbols, is not necessarng
ily equivalent to false. In Figure 10ng13, we give several constraint equivalence
laws, known as mutation laws, that concern such "heterogeneous" equations,
and, when viewed as rewriting rules, allow solving them. To each equation
in Figure 10ng12 corresponds a mutation law. The soundness of the mutation
law, that is, the fact that its rightnghand side entails its leftnghand side, follows
from the corresponding equation. The completeness of the mutation law, that
is, the fact that its leftnghand side entails its rightnghand side, holds by design
of the model.

10.8.17 Exercise [Recommended, n', 3]: Reconstruct all of the missing kind inforng

mation in the laws of Figure 10ng13. 2

Let us now review the four mutation laws. For the sake of brevity, in the
following informal explanation, we assume that a ground assignment OE that

476 10 The Essence of ML Type Inference

satisfies the leftnghand equation is fixed, and write "the ground type T" for "the
ground type OED^TE^." CngMutatengLL concerns an equation between two rows,
which are both given by extension but exhibit distinct head labels `1 and `2.
When this equation is satisfied, both of its members must denote the same
ground row. Thus, the ground row T01 must map `2 to the ground type T2,
while, symmetrically, the ground row T02 must map `1 to the ground type
T1. This may be expressed by two equations of the form T01 C^ D^`2 : T2 ; : : :E^
and T02 C^ D^`1 : T1 ; : : :E^. Furthermore, because the ground rows T01 and T02
must agree on their common labels, the ellipses in these two equations must
denote the same ground row. This is expressed by letting the two equations
share a fresh, existentially quantified row variable X. CngMutatengDL concerns
an equation between two rows, one of which is given as a constant row, the
other of which is given by extension. Then, because the ground row @T maps
every label to the ground type T, the ground type T0 must coincide with the
ground type T, while the ground row T00 must map every label in its domain
to the ground type T. This is expressed by the equations T C^ T0 and @T C^ T00.
CngMutatengGD and CngMutatengGL concern an equation between two rows, one
of which is given as an application of a row constructor G, the other of which
is given either as a constant row or by extension. Again, the laws exploit
the fact that the ground row G T1 : : : Tn is obtained by applying the type
constructor G, pointwise, to the ground rows T1; : : : ; Tn. If, as in CngMutateng
GD, it coincides with the constant ground row @T, then every Ti must itself be
a constant ground row, of the form @Xi, and T must coincide with G X1 : : : Xn.
CngMutatengGL is obtained in a similar manner.

10.8.18 Lemma: Each of the equivalence laws in Figure 10ng13 holds. 2

Solving Equality Constraints in the Presence of Rows
We now extend the unification algorithm given in $10.6 with support for rows.
The extended algorithm is intended to solve unification problems where the
syntax and interpretation of types are as defined in the discussions above of
the syntax (p. 466) and meaning (p. 471) of rows. Its specification consists
of the original rewriting rules of Figure 10ng10, minus SngClash, which is reng
moved and replaced with the rules given in Figure 10ng14. Indeed, SngClash is
no longer valid in the presence of rows: not all distinct type constructors are
incompatible.

The extended algorithm features four mutation rules, which are in direct
correspondence with the mutation laws of Figure 10ng13, as well as a weakng
ened version of SngClash, dubbed SngClash', which applies when neither Sng
Decompose nor the mutation rules are applicable. (Let us point out that, in

10.8 Rows 477
D^`1 : X1 ; X01E^ C^ D^`2 : T2 ; T02E^ C^ ffl ! 9X:D^X01 C^ D^`2 : T2 ; XE^ ^ T02 C^ D^`1 : X1 ; XE^E^

^ D^`1 : X1 ; X01E^ C^ ffl D^SngMutatengLLE^
if `1 6C^ `2

@X C^ D^` : T ; T0E^ C^ ffl ! X C^ T ^ @X C^ T0 ^ @X C^ ffl D^SngMutatengDLE^
G T1 : : : Tn C^ @X C^ ffl ! 9X1 : : : Xn:D^G X1 : : : Xn C^ X ^ VniC^1D^Ti C^ @XiE^E^

^ @X C^ ffl D^SngMutatengGDE^

G T1 : : : Tn C^ D^` : X ; X0E^ C^ ffl ! 9X1 : : : Xn; X01 : : : X0n:D^G X1 : : : Xn C^ X ^

G X01 : : : X0n C^ X0 ^V

niC^

1D^Ti C^ D^` : Xi ; X0i E^E^E^

^ D^` : X ; X0E^ C^ ffl D^SngMutatengGLE^

F ~T C^ F0 ~T0 C^ ffl ! false D^SngClash'E^

if F 6C^ F0 and none of the four rules above applies

Figure 10ng14: Row unification (changes to Figure 10ng10)

SngDecompose, the metangvariable F ranges over all type constructors in the signg
nature S, so that SngDecompose is applicable to multingequations of the form
@X C^ @T C^ ffl or D^` : X ; X0E^ C^ D^` : T ; T0E^ C^ ffl.) Three of the mutation rules
may allocate fresh type variables, which must be chosen fresh for the rule's
leftnghand side. The four mutation rules paraphrase the four mutation laws
very closely. Two minor differences are (i) the mutation rules deal with multing
equations, as opposed to equations; and (ii) any subterm that appears more
than once on the rightnghand side of a rule is required to be a type variable,
as opposed to an arbitrary type. Neither of these features is specific to rows:
both may be found in the definition of the standard unification algorithm
(Figure 10ng10), where they help reason about sharing.

10.8.19 Exercise [n', 3]: Check that the rewriting rules in Figure 10ng14 preserve wellng

kindedness. Conclude that, provided its input constraint is wellngkinded, the
unification algorithm needs not keep track of kinds. 2

The properties of the unification algorithm are preserved by this extension,
as witnessed by the next three lemmas. Note that the termination of reduction
is ensured only when the initial unification problem is wellngkinded. The illng
kinded unification problem X C^ D^`1 : T ; YE^ ^ X C^ D^`2 : T ; YE^, where `1 and `2
are distinct, illustrates this point.

10.8.20 Lemma: The rewriting system ! is strongly normalizing. 2

478 10 The Essence of ML Type Inference

10.8.21 Lemma: U1 ! U2 implies U1 j U2. 2
10.8.22 Lemma: Every normal form is either false or of the form XE,UG*, where X is an

existential constraint context, U is a standard conjunction of multingequations
and, if the model is syntactic, U is acyclic. These conditions imply that U is
satisfiable. 2

The time complexity of standard firstngorder unification is quasinglinear. What
is, then, the time complexity of row unification? Only a partial answer is
known. In practice, the algorithm given in this chapter is extremely efficient
and appears to behave just as well as standard unification. In theory, the comng
plexity of row unification remains unexplored and forms an interesting open
issue.

10.8.23 Exercise [n'n'n', 3]: The unification algorithm presented above, although very

efficient in practice, does not have linear or quasinglinear time complexity. Find
a family of unification problems Un such that the size of Un is linear with reng
spect to n and the number of steps required to reach its normal form is
quadratic with respect to n. 2

10.8.24 Remark: Mutation is a common technique for solving equations in a large

class of nonngfree algebras that are described by syntactic theories (Kirchner
and Klay, 1990). The equations of Figure 10ng12 happen to form a syntactic
presentation of an equational theory. Thus, it is possible to derive a unificang
tion algorithm out of these equations in a systematic way (Re'my, 1993). Here,
we have presented the same algorithm in a direct manner, without relying on
the apparatus of syntactic theories. 2

Operations on Records
We now illustrate the use of rows for typechecking operations on records. We
begin with full records; our treatment follows Re'my (1992b).

10.8.25 Example [Full records]: As before, let us begin with full records, whose dong

main is exactly L. The primitive operations are record creation {*}, update
{* with ` C^ *}, and access *:{`}.

Let < denote a fixed strict total order on row labels. For every set of labels
L of cardinal n, let us introduce a D^n + 1E^ngary constructor {}L. We use the folng
lowing syntactic sugar: we write {`1 C^ t1; : : : ; `n C^ tn; t} for the application
{}L ti1 : : : tin t, where L C^ {`1; : : : ; `n} C^ {`i1; : : : ; `in} and `i1 < : : : < `in
holds. The use of the total order < makes the meaning of record expressions
independent of the order in which fields are defined; in particular, it allows
fixing the order in which t1; : : : ; tn are evaluated. We abbreviate the record

10.8 Rows 479
value {`1 C^ v1; : : : ; `n C^ vn; v} as {V; v}, where V is the finite function that
maps `i to vi for every i 2 {1; : : : ; n}.

The operational semantics of the above three operations may now be deng
fined in the following straightforward manner. First, record creation {*} is
precisely the unary constructor {}IJ. Second, for every ` 2 L, let update
{* with ` C^ *} and access *:{`} be destructors of arity 1 and 2, respectively,
equipped with the following reduction rules:

{{V; v} with ` C^ v0} ffi-! {VE,` , v0G*; v} D^RngUpdateE^

{V; v}:{`} ffi-! VD^`E^ D^` 2 domD^VE^E^ D^RngAccessng1E^
{V; v}:{`} ffi-! v D^` AE domD^VE^E^ D^RngAccessng2E^

In these rules, VE,` , vG* stands for the function that maps ` to v and coincides
with V at every other label, while VD^`E^ stands for the image of ` through V.
Because these rules make use of the syntactic sugar defined above, they are,
strictly speaking, rule schemes: each of them really stands for the infinite
family of rules that would be obtained if the syntactic sugar was eliminated.

Let us now define the syntax of types as in Example 10.8.7. Let the initial
environment \Gamma 0 contain the following bindings:

{}{`1;:::;`n} : 8X1 : : : XnX:X1 ! : : : ! Xn ! X ! \Pi  D^`1 : X1; : : : ; `n : Xn; @XE^

where `1 < : : : < `n
{* with ` C^ *} : 8XX0Y:\Pi  D^` : X ; YE^ ! X0 ! \Pi  D^` : X0 ; YE^

*:{`} : 8XY:\Pi  D^` : X ; YE^ ! X

Note that, in particular, the type scheme assigned to record creation {*} is
8X:X ! \Pi  D^@XE^. As a result, these bindings are exactly as stated in the discusng
sion of records with infinite carrier (p. 463).

To illustrate how these definitions work together, let us consider the prong
gram {{0} with `1 C^ true}:{`2}, which builds a record, extends it at `1, then
accesses it at `2. Can we build an HMD^XE^ type derivation for it, under the
constraint true and the initial environment \Gamma 0? To begin, by looking up \Gamma 0
and using hmxngInst, we find that {*} has type int ! \Pi  D^@intE^. Thus, assumng
ing that 0 has type int, the expression {0} has type \Pi  D^@intE^. Indeed, this
expression denotes a record all of whose fields hold an integer value. Then,
by looking up \Gamma 0 and using hmxngInst, we find that {* with `1 C^ *} has type
\Pi  D^`1 : int ; @intE^ ! bool ! \Pi  D^`1 : bool ; @intE^. May we immediately use hmxng
App to typecheck the application of {* with `1 C^ *} to {0}? Unfortunately,
no, because there is an apparent mismatch between the expected type \Pi 
D^`1 :int ; @intE^ and the effective type \Pi  D^@intE^. To work around this problem, let
us recall that, by CngRowngDL, the equation \Pi  D^@intE^ C^ \Pi  D^`1 : int ; @intE^ is equivng
alent to true. Thus, hmxngSub allows proving that {0} has type \Pi  D^`1 :int ; @intE^.

480 10 The Essence of ML Type Inference

Assuming that true has type bool, we may now apply hmxngApp and deduce

true; \Gamma 0 ` {{0} with `1 C^ true} : \Pi  D^`1 : bool ; @intE^:
We let the reader check that, in a similar manner involving CngRowngDL, CngRowng
LL, and hmxngSub, one may prove that {{0} with `1 C^ true}:{`2} has type int,
provided `1 and `2 are distinct. 2

10.8.26 Exercise [n'n', 3]: Unfold the definition of the constraint let \Gamma 0 in J{{0} with

`1 C^ true}:{`2} : XK, which states that X is a valid type for the above program.
Assuming that subtyping is interpreted as equality, simulate a run of the
constraint solver ($10.6), extended with support for rows, so as to solve this
constraint. Check that the solved form is equivalent to X C^ int. 2

10.8.27 Exercise [n'n'n']: Check that the definitions of Example 10.8.25 meet the reng

quirements of Definition 10.5.5. 2

10.8.28 Example [Record application]: Let us now introduce a more unusual primng

itive operation on full records. This operation accepts two records, the first of
which is expected to hold a function in every field and produces a new record,
whose contents are obtained by applying, pointwise, the functions in the first
record to the values in the second record. In other words, this new primitive
operation lifts the standard application combinator (which may be defined as
*f:*z:f z), pointwise, to the level of records. For this reason, we refer to it as
rapply. Its operational semantics is defined by making it a binary destructor
and equipping it with the following reduction rules:

rapply {V; v} {V0; v0} ffi-! {V V0; v v0} D^RngApplyng1E^
rapply {V; v} {V0; v0} ffi-! rapply {V; v} {V0E,` , v0G*; v0} D^RngApplyng2E^

if ` 2 domD^VE^ \ domD^V0E^

rapply {V; v} {V0; v0} ffi-! rapply {VE,`0 , vG*; v} {V0; v0} D^RngApplyng3E^

if `0 2 domD^V0E^ \ domD^VE^

In the first rule, V V0 is defined only if V and V0 have a common domain; it is
then defined as the function that maps ` to the expression VD^`E^ V0D^`E^. The
second and third rules, which are symmetric, deal with the case where some
field is explicitly defined in one input record but not in the other; in that case,
the field is made explicit by creating a copy of the record's default value.

The syntax of types remains as in Example 10.8.25. We extend the initial
environment \Gamma 0 with the following binding:

rapply : 8XY:\Pi  D^X ! YE^ ! \Pi  X ! \Pi  Y

10.8 Rows 481
To understand this type scheme, recall that the principal type scheme of
the standard application combinator (which may be defined as *f:*z:f z) is
8XY:D^X ! YE^ ! X ! Y. The type scheme assigned to rapply is very similar; the
most visible difference is that both arguments, as well as the result, are now
wrapped within the record type constructor \Pi . A more subtle, yet essential
change is that X and Y are now row variables: their kind is ?:RowD^IJE^. As
a result, the leftmost occurrence of the arrow constructor is really !RowD^IJE^.
Thus, we are exploiting the presence of type constructors of the form Gs,
with s 6C^ Type, in the signature S.

To illustrate how these definitions work together, let us consider the prong
gram rapply {` C^ not; succ} {` C^ true; 0}, where the terms not and succ
are assumed to have types bool ! bool and int ! int, respectively. Can
we build an HMD^XE^ type derivation for it, under the constraint true and
the initial environment \Gamma 0? To begin, it is straightforward to derive that the
record {` C^ not; succ} has type \Pi  D^` : bool ! bool ; @D^int ! intE^E^ (1). In orng
der to use rapply, however, we must prove that this record has a type of
the form \Pi  D^R1 ! R2E^, where R1 and R2 are rows. This is where CngRowngGD
and CngRowngGL (Figure 10ng12) come into play. Indeed, by CngRowngGD, the type
@D^int ! intE^ may be written @int ! @int. So, (1) may be written \Pi  D^` : bool !
bool ; @int ! @intE^ (2), which by CngRowngGL may be written \Pi  D^D^` : bool ;
@intE^ ! D^` : bool ; @intE^E^ (3). Thus, hmxngSub allows deriving that the record
{` C^ not; succ} has type (3). We let the reader continue and conclude that the
program has type \Pi  D^` : bool ; @intE^ under the constraint true and the initial
environment \Gamma 0.

This example illustrates a very important use of rows, namely to lift an
operation on ordinary values so as to turn it into a pointwise operation on
records. Here, we have chosen to lift the standard application combinator,
giving rise to rapply on records. The point is that, thanks to the expresng
sive power of rows, we were also able to lift the standard combinator's type
scheme in the most straightforward manner, giving rise to a suitable type
scheme for rapply. 2

10.8.29 Exercise [n'n'n', 3]: Check that the definitions of Example 10.8.28 meet the

requirements of Definition 10.5.5. 2

The previous examples have illustrated the use of rows to typecheck opng
erations on full records. Let us now move to records with finite domain. As
explained in the discussion above of records with finite carrier (p. 461), they
may be either encoded in terms of full records, or given a direct definition.
The latter approach is illustrated below.

10.8.30 Example [Finite records]: For every set of labels L of cardinal n, let us inng

troduce a nngary constructor hiL. We define the notations h`1 C^ t1; : : : ; `n C^ tni

482 10 The Essence of ML Type Inference

and hVi, where V is a finite mapping of labels to values, in a manner similar
to that of Example 10.8.25.

The three primitive operations on finite records, namely the empty record
hi, extension h* with ` C^ *i, and access *:h`i, may be defined as follows. First,
the empty record hi is precisely the nullary constructor hiIJ. Second, for every
` 2 L, let extension h* with ` C^ *i and access *:h`i be destructors of arity 1
and 2, respectively, equipped with the following reduction rules:

hhVi with ` C^ vi ffi-! hVE,` , vG*i D^RngExtendE^

hVi:h`i ffi-! VD^`E^ D^` 2 domD^VE^E^ D^RngAccessE^

Let us now define the syntax of types as in Example 10.8.8. Let the initial
environment \Gamma 0 contain the following bindings:

hi{`1;:::;`n} : 8X1 : : : Xn:X1 ! : : : ! Xn ! \Pi  D^`1 : pre X1; : : : ; `n : pre Xn; @absE^

where `1 < : : : < `n
h* with ` C^ *i : 8XX0Y:\Pi  D^` : X ; YE^ ! X0 ! \Pi  D^` : pre X0 ; YE^

*:h`i : 8XY:\Pi D^` : pre X ; YE^ ! X

Note that, in particular, the type scheme assigned to the empty record hi is
\Pi  D^@absE^. 2

10.8.31 Exercise [Recommended, n', 3]: Reconstruct all of the missing kind inforng

mation in the type schemes given in Example 10.8.30. 2

10.8.32 Exercise [Recommended, n'n', 3]: Give an encoding of finite records in terms

of full records, along the lines of the discussion of records with finite carrier
(p. 461). Check that the principal type schemes associated, via the encodng
ing, with the three operations on finite records are precisely those given in
Example 10.8.30. 2

10.8.33 Exercise [Recommended, n']: The extension operation, as defined above, may

either change the value of an existing field or create a new field, depending
on whether the field ` is or isn't present in the input record. This flavor is
known as free extension. Can you define a strict flavor of extension that is
not applicable when the field ` already exists? Can you define (free and strict
flavors of) a restriction operation that removes a field from a record? 2

10.8.34 Exercise [Recommended, n']: Explain why, when pre a` abs holds, subsumpng

tion allows a record with more fields to be supplied in a context where a
record with fewer fields is expected. This phenomenon is often known as
width subtyping. Explain why such is not the case when subtyping is interng
preted as equality. 2

10.8.35 Exercise [n'n'n', 3]: Check that the definitions of Example 10.8.30 meet the

requirements of Definition 10.5.5. 2

10.8 Rows 483
Polymorphic Variants
So far, we have emphasized the use of rows for flexible typechecking of operang
tions on records. The record type constructor \Pi  expects one parameter, which
is a row; informally speaking, one might say that it is a product constructor of
infinite arity. It appears natural to also define sums of infinite arity. This may
be done by introducing a new unary type constructor \Sigma , whose parameter is
a row.

As in the case of records, we use a nullary type constructor abs and a
unary type constructor pre in order to associate information with every row
label. Thus, for instance, the type \Sigma  D^`1 : pre T1 ; `2 : pre T2 ; @absE^ is intended
to contain values of the form `1 v1, where v1 has type T1, or of the form
`2 v2, where v2 has type T2. The type constructors abs and pre are not the
same type constructors as in the case of records. In particular, their subtyping
relationship, if there is one, is reversed. Indeed, the type \Sigma  D^`1 : pre T1 ;
`2 : abs ; @absE^ is intended to contain only values of the form `1 v1, where
v1 has type T1, so it is safe to make it a subtype of the above type; in other
words, it is safe to allow abs <= pre T2. In spite of this, we keep the names abs
and pre by tradition.

The advantages of this approach over algebraic data types are the same as
in the case of records. The namespace of data constructors becomes global,
so it becomes possible for two distinct sum types to share data constructors.
Also, the expressiveness afforded by rows allows assigning types to new opng
erations, such as filtering (see below), which allows functions that perform
case analysis to be incrementally extended with new cases. One disadvantage
is that it becomes more difficult to understand what it means for a function
defined by pattern matching to be exhaustive; this issue is, however, out of
the scope of this chapter.

10.8.36 Example [Polymorphic variants]: For every label ` 2 L, let us introduce a

unary constructor ` and a ternary destructor E, ` : * | * G* *. We refer to the forng
mer as a data constructor, and to the latter as a filter. Let us also introduce a
unary destructor E,G*. We equip these destructors with the following reduction
rules:

E, ` : v | v0 G* D^` wE^ ffi-! v w D^RngFilterng1E^
E, ` : v | v0 G* D^`0 wE^ ffi-! v0 D^`0 wE^ if ` 6C^ `0 D^RngFilterng2E^

Let us define the syntax of types as follows. Let there be two basic kinds ?
and *. Let S0 consist of the type constructors !, abs, and pre, whose respecng
tive signatures are ? \Omega  ? ) ?, *, and ? ) *. Let S1 consist of the record type
constructor \Sigma , whose signature is * ) ?. Note the similarity with the case of
records (Example 10.8.8).

484 10 The Essence of ML Type Inference

Subtyping is typically interpreted in one of two ways. One is equality. The
other is the nonstructural subtyping order obtained by letting ! be conng
travariant in its domain and covariant in its codomain, \Sigma  be covariant, !
and \Sigma  be incompatible, and letting abs a` pre. Compare this definition with
the case of records (Remark 10.8.11).

To complete the setup, let the initial environment \Gamma 0 contain the following
bindings:

` * : 8XY:X ! \Sigma  D^` : pre X ; YE^
E, ` : * | * G* * : 8XX0YY0:D^X ! YE^ ! D^\Sigma  D^` : X0 ; Y0E^ ! YE^ ! \Sigma  D^` : pre X ; Y0E^ ! Y

E,G* : 8X:\Sigma  D^@absE^ ! X

The first binding means, in particular, that if v has type T, then a value of the
form ` v has type \Sigma  D^` : pre T ; @absE^. This is a sum type with only one branch
labeled `, hence a very precise type for this value. However, it is possible to
instantiate the row variable Y with rows other than @abs. For instance, the
value ` v also has type \Sigma  D^` : pre T ; `0 : pre T0 ; @absE^. This is a sum type with
two branches, hence a somewhat less precise type, but still a valid one for
this value. It is clear that, through this mechanism, the value ` v admits an
infinite number of types. The point is that, if v has type T and v0 has type T0,
then both ` v and `0 v0 have type \Sigma  D^` : pre T ; `0 : pre T0 ; @absE^, so they may
be stored together in a homogeneous data structure, such as a list.

Filters are used to perform case analysis on variants, that is, on values of
a sum type. According to RngFilterng1 and RngFilterng2, a filter E, ` : v | v0 G* is a
function that expects an argument of the form `0 w and reduces to v w if `0 is
` and to v0 D^`0 wE^ otherwise. Thus, a filter defines a twongway branch, where the
label of the data constructor at hand determines which branch is taken. The
expressive power of filters stems from the fact that they may be organized
in a sequence, so as to define a multingway branch. The inert filter E,G*, which
does not have a reduction rule, serves as a terminator for such sequences. For
instance, the composite filter E, ` : v | E, `0 : v0 | E,G* G* G*, which may be abbreviated
as E, ` : v | `0 : v0 G*, may be applied either to a value of the form ` w, yielding
v w, or to a value of the form `0 w0, yielding v0 w0. Applying it to a value w
whose head symbol is not ` or `0 would lead to the term E,G* w, which is stuck,
since E,G* does not have a reduction rule.

For the type system to be sound, we must ensure that every application
of the form E,G* w is illngtyped. This is achieved by the third binding above: the
domain type of E,G* is \Sigma  D^@absE^, a sum type with zero branches, which contains
no values. The return type of E,G* may be chosen at will, which is fine; since it
can never be invoked, it can never return. The second binding above means
that, if v accepts values of type T and v0 accepts values of type \Sigma  D^` : T00 ; T0E^,
then the filter E, ` : v | v0 G* accepts values of type \Sigma  D^` : pre T ; T0E^. Note that

10.8 Rows 485
any choice of T00 will do, including, in particular, abs. In other words, it is
okay if v0 does not accept values of the form ` w. Indeed, by definition of the
semantics of filters, it will never be passed such a value. 2

10.8.37 Exercise [n'n'n', 3]: Check that the definitions of Example 10.8.36 meet the

requirements of Definition 10.5.5. 2

10.8.38 Remark: It is interesting to study the similarity between the type schemes

assigned to the primitive operations on polymorphic variants and those asng
signed to the primitive operations on records (Example 10.8.30). The type of
E,G* involves the complete row @abs, just like the empty record hi. The type
of E, ` : * | * G* * is pretty much identical to the type of record extension
h* with ` C^ *i, provided the three continuation arrows ! Y are dropped.
Last, the type of the data constructor ` is strongly reminiscent of the type
of record access *:h`i. With some thought, this is hardly a surprise. Indeed,
records and variants are dual: it is possible to encode the latter in terms of
the former and vicengversa. For instance, in the encoding of variants in terms
of records, a function defined by cases is encoded as a record of ordinary
functions, in continuationngpassing style. Thus, the encoding of E,G* is *f:f hi,
the encoding of E, ` : v | v0 G* is *f:f hv0 with ` C^ vi, and the encoding of
` v is *r:r:h`i v. The reader is encouraged to study the type schemes that
arise out of this encoding and how they relate to the type schemes given in
Example 10.8.36. 2

10.8.39 Example [Firstngclass messages]: In a programming language equipped with

both records and variants, it is possible to make the duality between these
two forms of data explicit by extending the language with a primitive operang
tion # that turns a record of ordinary functions into a single function, defined
by cases. More precisely, # may be introduced as a binary destructor, whose
reduction rule is

# v D^` wE^ ffi-! v:h`i w D^RngSendE^
What type may we assign to such an operation? In order to simplify the anng
swer, let us assume that we are dealing with full records (Example 10.8.25)
and full variants; that is, we have a single basic kind ?, and do not employ
abs and pre. Then, a suitable type scheme would be

8XY:\Pi  D^X ! @YE^ ! \Sigma  X ! Y
In other words, this operation accepts a record of functions, all of which have
the same return type Y, but may have arbitrary domain types, which are given
by the row X. It produces a function that accepts a parameter of sum type \Sigma  X

486 10 The Essence of ML Type Inference

and returns a result of type Y. The fact that the row X appears both in the \Sigma 
type and in the \Pi  type reflects the operational semantics. Indeed, according
to RngSend, the label ` carried by the value ` w is used to extract, out of the
record v, a function, which is then applied to w. Thus, the domain type of
the function stored at ` within the record v should match the type of w. In
other words, at every label, the domain of the contents of the record and the
contents of the sum should be type compatible. This is encoded by letting
a single row variable X stand for both of these rows. Note that the arrow in
X ! @Y is really !RowD^IJE^; once again, we are exploiting the presence of type
constructors of the form Gs, with s 6C^ Type, in the signature S.

If the record of functions v is viewed as an object, and if the variant ` w
is viewed as a message ` carrying a parameter w, then RngSend may be underng
stood as (firstngclass) message dispatch, a common feature of objectngoriented
languages. (The firstngclass qualifier refers to the fact that the message name
` is not statically fixed, but is discovered at runtime.) The issue of type inferng
ence in the presence of such a feature has been studied by Nishimura (1998),
Mu"ller and Nishimura (1998), and Pottier (2000). These papers address two isng
sues that are not dealt with in the above example, namely (i) accommodating
finite (as opposed to full) record and variants and (ii) allowing distinct methng
ods to have distinct result types. This is achieved via the use of subtyping
and of some form of conditional constraints. 2

10.8.40 Exercise [n'n'n', 3]: Check that the definitions of Example 10.8.39 meet the

requirements of Definition 10.5.5. 2

The name polymorphic variants stems from the highly polymorphic type
schemes assigned to the operations on variants (Example 10.8.36). A rowng
based type system for polymorphic variants was first proposed by Re'my
(1989). A somewhat similar, constraintngbased type system for polymorphic
variants was then studied by Garrigue (1998; 2000; 2002) and implemented
by him as part of the programming language Objective Caml.

Other Applications of Rows
Typechecking records and variants is the bestngknown application of rows.
Many variations of it are conceivable, some of which we have illustrated, such
as the choice between full and finite records and variants. However, rows may
also be put to other uses, of which we now list a few.

First, since objects may be viewed as records of functions, at least from a
typechecking point of view, rows may be used to typecheck objectngoriented
languages in a structural style (Wand, 1994; Re'my, 1994). This is, in particung
lar, the route followed in Objective Caml (Re'my and Vouillon, 1998). There,

10.8 Rows 487
an object type consists of a row of method types, and gives the object's interng
face. Such a style is considered structural, as opposed to the style adopted by
many popular objectngoriented languages, such as C++, Java, and C#, where an
object type consists of the name of its class. Thanks to rows, method invong
cation may be assigned a polymorphic type scheme, similar to that of record
access (Example 10.8.30), making it possible to invoke a specific method (say,
`) without knowing which class the receiver object belongs to.

Rows may also be used to encode sets of properties within types or to
encode type refinements, with applications in typengbased program analysis.
Some instances worth mentioning are soft typing (Cartwright and Fagan,
1991; Wright and Cartwright, 1994), exception analysis (Leroy and Pessaux,
2000; Pottier and Simonet, 2003), and static enforcement of an access control
policy (Pottier, Skalka, and Smith, 2001). BANE (Fa"hndrich, 1999), a versatile
program analysis toolkit, also implements a form of rows.

Variations on Rows
A type system may be said to have rows, in a broad sense, if mappings from
labels to types may be (i) defined incrementally, via some syntax for extending
an existing mapping with information about a new label and (ii) abstracted by
a type variable. In this chapter, which follows Re'my's ideas (1993; 1992a;
1992b), the former feature is provided by the row constructors D^` : * ; *E^,
while the latter is provided by the existence of row variables, that is, type
variables of row kind RowD^LE^ for some L. There are, however, type systems
that provide (i) and (ii) while departing significantly from the one presented
here. These systems differ mainly in how they settle some important design
choices:

1. Does a row denote a finite or an infinite mapping from labels to types?
2. Is a row with duplicate labels considered wellngformed? If not, by which

mechanism is it ruled out?

In Re'my's approach, every row denotes an infinite (in fact, cofinite) mapping
from labels to types. The type constructors abs and pre are used to encode
domain information within field types. A row with duplicate labels, such as
D^` : T1 ; ` : T2 ; T3E^, is ruled out by the kind system. Below, we mention a
number of type systems that make different design choices.

The first use of rows for typechecking operations on records, including
record extension, is due to Wand (1987a; 1988). In Wand's approach, rows deng
note finite mappings. Furthermore, rows with duplicate labels are considered
legal; row extension is interpreted as function extension, so that, if a label ocng
curs twice, the later occurrence takes precedence. This leads to a difficulty in

488 10 The Essence of ML Type Inference

the constraint solving process: the constraint D^` : T1 ; R1E^ C^ D^` : T2 ; R2E^ entails
T1 C^ T2, but does not entail R1 C^ R2, because R1 and R2 may have different
domains--indeed, their domains may differ at `. Wand's proposed solution
(1988) introduces a fourngway disjunction, because each of R1 and R2 may or
may not define `. This gives type inference exponential time complexity.

Later work (Berthomieu, 1993; Berthomieu and le Monie`s de Sagazan, 1995)
interprets rows as infinite mappings but sticks with Wand's interpretation of
row extension as function extension, so that duplicate labels are allowed. The
constraint solving algorithm rewrites the problematic constraint D^` :T1 ; R1E^ C^
D^` : T2 ; R2E^ to D^T1 C^ T2E^ ^ D^R1 C^{`} R2E^, where the new predicate C^L is interng
preted as row equality outside L. Of course, the entire constraint solver must
then be extended to deal with constraints of the form T1 C^L T2. The advanng
tage of this approach over Wand's lies in the fact that no disjunctions are
ever introduced, so that the time complexity of constraint solving apparently
remains polynomial.

Several other works make opposite choices, sticking with Wand's interpreng
tation of rows as finite mappings but forbidding duplicate labels. No kind
discipline is imposed: some other mechanism is used to ensure that dupling
cate labels do not arise. In Jategaonkar and Mitchell (1988) and Jategaonkar
(1989), somewhat ad hoc steps are taken to ensure that, if the row D^` : T ; XE^
appears anywhere within a type derivation, then X is never instantiated with
a row that defines `. In Gaster and Jones (1996), Gaster (1998), and Jones
and Peyton Jones (1999), explicit constraints prevent duplicate labels from
arising. This line of work uses qualified types (Jones, 1994), a constraintng
based type system that bears strong similarity with HMD^XE^. For every label
`, a unary predicate * lacks ` is introduced; roughly speaking, the constraint
R lacks ` is considered to hold if the (finite) row R does not define the label `.
The constrained type scheme assigned to record access is

*:h`i : 8XYE,Y lacks `G*:\Pi  D^` : X ; YE^ ! X:
The constraint Y lacks ` ensures that the row D^` : X ; YE^ is wellngformed. Alng
though interesting, this approach is not as expressive as that described in
this chapter. For instance, although it accommodates record update (where
the field being modified is known to exist in the initial record) and strict
record extension (where the field is known not to initially exist), it cannot exng
press a suitable type scheme for free record extension, where it is not known
whether the field initially exists. This approach has been implemented as the
"Trex" extension to Hugs (Jones and Peterson, 1999).

It is worth mentioning a line of type systems (Ohori and Buneman, 1988,
1989; Ohori, 1995) that do not have rows, because they lack feature (i) above,
but are still able to assign a polymorphic type scheme to record access. One

10.8 Rows 489
might explain their approach as follows. First, these systems are equipped
with ordinary, structural record types, of the form {`1 : T1; : : : ; `n : Tn}. Secng
ond, for every label `, a binary predicate * has ` : * is available. The idea is
that the constraint T has ` : T0 holds if and only if T is a record type that
contains the field ` : T0. Then, record access may be assigned the constrained
type scheme

*:h`i : 8XYE,X has ` : YG*:X ! Y:

This technique also accommodates a restricted form of record update, where
the field being written must initially exist and must keep its initial type; it
does not, however, accommodate any form of record extension, because of
the absence of row extension in the syntax of types. Although the papers
cited above employ different terminology, we believe it is fair to view them as
constraintngbased type systems. In fact, Odersky, Sulzmann, and Wehr (1999)
prove that Ohori's system (1995) may be viewed as an instance of HMD^XE^.
Sulzmann (2000) proposes several extensions of it, also presented as inng
stances of HMD^XE^, which accommodate record extension and concatenation
using new, ad hoc constraint forms in addition to * has `.

In the labelngselective *ngcalculus (Garrigue and Ai"tngKaci, 1994; Furuse and
Garrigue, 1995), the arrow type constructor carries a label, and arrows that
carry distinct labels may commute, so as to allow labeled function arguments
to be supplied in any order. Some of the ideas that underlie this type system
are closely related to rows.

Pottier (2003) describes an instance of HMD^XE^ where rows are not part of
the syntax of types: equivalent expressive power is obtained via an extenng
sion of the constraint language. The idea is to work with constraints of the
form R1 <=L R2, where L may be finite or cofinite, and to interpret such a
constraint as row subtyping inside L. In this approach, no new type variables
need be allocated during constraint solving; contrast this with SngMutatengLL,
SngMutatengGD, and SngMutatengGL in Figure 10ng14. One benefit is to simplify
the complexity analysis; another is to yield insights that lead to generalizang
tions of rows.

Even though rows were originally invented with type inference in mind,
they are useful in explicitly typed languages as well; indeed, other approaches
to typechecking operations on records appear quite complex (Cardelli and
Mitchell, 1991).

A Solutions to Selected Exercises

1.1.4 Solution: The proof of each lemma proceeds by induction on the typing

derivation. Almost all cases follow directly from the induction hypothesis.
The base cases are straightforward as well, but some slight amount of work
is involved. For instance, in the base case for weakening we are given the judgng
ment \Gamma 1; x:T; \Gamma 2 ` x : T. and must prove that for arbitrary \Gamma 3, \Gamma 1; x:T; \Gamma 2; \Gamma 3 `
x : T. The latter judgment follows directly from the variable rule as the rule
schema allows the context \Gamma 1; x:T; \Gamma 2; \Gamma 3. Notice, however, that if we were not
careful in the definition of the variable rule and had omitted \Gamma 2 from the conng
text in the rule schema, we would be unable to prove this weakening lemma.
Hence, while simple, the rules for the variables and constants play an integral
role in defining the structural properties of a type system.

1.2.1 Solution: Since the variable may only appear on the extreme rightnghand side

of the context, we will be unable to prove the exchange lemma. In the literng
ature, you will see this formulation of the variable rule all the time because
authors often treat contexts as finite partial maps. In other words, contexts
that differ only in the order in which we write down their elements are treated
equally and are never distinguished from one another. In this chapter, we
choose not to take this perspective so that we may study the complete set of
structure rules directly.

1.2.13 Solution: No: the lemma is false. Fortunately, the preservation theorem for

our language only depends upon a substitution lemma involving variables:
Lemma [Linear Variable Substitution]: Let \Gamma 3 C^ \Gamma 1 ffi \Gamma 2. If \Gamma 1; x:T ` t1 : T1
and \Gamma 2 ` y : T then \Gamma 3 ` E,x , yG*t1 : T1.

1.3.1 Solution: The type of linear trees with elements of type T follows.

type T tree = rec a.lin (unit + lin (T * a * a))
It will be convenient to define some constructors for trees of type T as well.

492 A Solutions to Selected Exercises

fun nilT (nil:unit) : T tree =

roll (lin inl nil)

fun nodeT (arg : lin (T * T tree * T tree)) : TL =

roll (lin inr arg)

As we recurse into the tree structure, we must create a list of subtrees that
have yet to be processed. This list will be constructed from parts of the tree
itself. In ML, we could define the appropriate sort of list using the following
datatype.

datatype (T1,T2) TL =

done
| right of T2 * T1 tree * TL
| left of T2 * T2 tree * TL

Let us assume that our recursive tree map procedure takes a tree t and a
TLnglist l as an argument. If l is the first constructor done, then all we have
to do is process t. If l is the second constructor (say right(elem,tr,l0))
then when we finish processing t, we have finished processing a left subtree,
but we still need to process the right subtree (tr) and glue the processed tree
element (elem) together with the results. We also need to recursively process
the rest of the list l0. If l is the last constructor (say left(elem,tl,l0)) then
when we finish processing t, we have just finished processing a right subtree
and we need to assemble the tree element (elem), the left subtree (tl) and the
recently finished right subtree, and recursively process the rest of the list.

In our linear lambda calculus, the ML type definition given above and its
associated constructors will be defined as follows. We will use in0, in1,...
inn-1 to inject into a nngary sum when n is greater than two.

type TL =

mu a.

lin (unit + lin (T2 * T1 tree * a)

+ lin (T2 * T2 tree * a))

fun done (nil:unit) : TL = roll (lin in0 nil)
fun right (arg : lin (T2 * T1 tree * TL)) : TL =

roll (lin in2 arg)

fun left (arg : lin (T2 * T2 tree * TL)) : TL =

roll (lin in1 arg)

The algorithm is factored into a topnglevel function treeMap and two helpers.
The first processes a subtree we have not seen yet. The second determines
what to do next by looking at the TL stack.

A Solutions to Selected Exercises 493

type FT = T1 ! T2
fun treeMap(f:FT,t:T1 tree) : T2 tree =

procTree (f,t,done())

and procTree(f:FT,t:T1 tree,tl:TL) : T2 tree =

case unroll t (

inl nil ) procTL (f,nilT2(),tl)
| inr tree )

split tree as elem,t1,t2 in
procTree (f,t1,right lin <f elem,t2,tl>)

and procTL(f:FT,t:T2 tree,tl:TL): T2 tree =

case unroll tl (

in0 nil ) t
| in1 arg )

split arg as elem,t2,tl in
procTree (f,t2,left lin <elem,t,tl>)
| in2 arg )

split arg as elem,t1,tl in
procTL (f,nodeT2 lin <elem,t1,t2>,tl)

1.3.4 Solution: If an unrestricted array can contain a linear object, the linear obng

ject might never be used because the programmer might forget to use the enng
tire array. Due to our swapping operational semantics for arrays, even though
an unrestricted array (containing linear objects) can be used many times, the
linear objects themselves can never be used more than once. In short, the
supposedly linear objects would actually be affine.

1.4.1 Solution: Consider the following expression. If we generalized the syntax

to allow nested sub expressions but made no change to the typing rules, it
would type check despite the fact that booleans are confused with integers.

let x = ord <true,true> in
let y = ord <ord <3,2>,x> in
split y as z1,z2 in
split z2 as b1,b2 in
if b1 then ... (* using an int as if it was a bool *)

Can we change the typing rules in some way to solve the soundness problem?
1.4.2 Solution: Consider the following wellngtyped expression.

let x1 = ord true in
let f = ord *y:ord bool.ord <x1,y> in
let x2 = ord false in
f x2

494 A Solutions to Selected Exercises

At the point of execution just before the function call, the stack will be orng
ganized with x1, which belongs to f's closure, at the bottom of the stack, f
allocated immediately on top of x1, and x2 allocated immediately on top of f.

When the function f is called, f should be deallocated, since ordered obng
jects are always deallocated when they are used. However, f is in the middle
of the stack rather than on top, so the ordered abstract machine gets stuck.
The main problem centers around checking ordered functions with ordered
arguments.

1.4.3 Solution: The previous problem demonstrates that the difficulty with orng

dered functions is that when the function has an ordered argument, the
function will appear in the middle of the stack when it is called. We cannot
deallocate the function at that point, but one thing we can do is substitute a
placeholder with type junk for the used function pointer. The only thing that
can be done with an object of type junk is to pop it off the stack. When the
code in the function body has used up the ordered function argument, the
junk item will appear at the top of the stack. At this point, programmer will
explicitly pop it off the stack and move on to using objects in the function's
closure.

The typing rule for the specialized ordered abstraction with ordered argung
ment appears below. We also give the typing rule for the command pop x; t,
which pops its argument (x) off the top of the stack and continues execution
with t below. It is up to you to define their operational rules.

\Gamma  ; f:ord junk; x:ord P1 ` t2 : T2
\Gamma  ` ord *f x:(ord P1).t2 : ord (ord P1)!T2 (TngAbs)

\Gamma 2 ` x : ord junk \Gamma 1 ` t : T

\Gamma 1 ffi \Gamma 2 ` pop x; t : T (TngPop)

2.1.1 Solution: We can introduce a type family for rectangular matrices thus:

Matrix :: Nat ! Nat ! *
idmatrix : \Pi n:Nat. Matrix n n
multmatrix : \Pi l:Nat. \Pi m:Nat. \Pi n:Nat.

Matrix l m ! Matrix m n ! Matrix l n

Suppose we have a dependent type for ranges of integers: {n...m} denotes
the type of integers between n and m inclusive, either n or m may be omitted.
A possible typing for dates is given by:

Year = {2003..} :: *
Month = {1..12} :: *
Day :: Month ! *

A Solutions to Selected Exercises 495
where

Day(n) C^ {1..31} if n 2 {1; 3; 5; 7; 8; 10; 12}
Day(n) C^ {1..30} if n 2 {4; 6; 9; 11}
Day(2) C^ {1..29}

A date is then given by an element of the \Sigma ngtype (see page 48):

Date :: \Sigma y:Year. \Sigma m:Month. Day(m)
Of course, we could gain more accuracy by making the type of days also
depend on the year.

2.1.2 Solution: A type representing the constructive axiom of choice for a predng

icate P is (\Pi a:A.\Sigma b:B. P(a,b)) ! (\Sigma f:A!B. \Pi x:A. P(x, f x)). It can be
shown in MartinngLo"f's type theory that this type is inhabited (MartinngLo"f,
1984).

2.1.3 Solution: \Sigma a:A.\Sigma b:B.Id(f a, g b)
2.1.4 Solution: Here are some terms representing fingreduction and its closure on

lambda terms:

Eval :: \Pi A:Ty. Tm A ! Tm A ! *
evalAppAbs : \Pi A:Ty. \Pi B:Ty.

\Pi t1:(Tm A ! Tm B).
\Pi t2:(Tm A) ! Eval (app (lam t1) t2) (t1 t2)
evalLam : \Pi A:Ty. \Pi B:Ty.

\Pi ft1,ft1':(Tm A ! Tm B).

(\Pi x: Tm A. Eval (ft1 x) (ft1' x))

! Eval (lam ft1) (lam ft2)
evalApp1 : \Pi A:Ty. \Pi B:Ty.

\Pi t1,t1':(Tm (arrow A B)).

\Pi t2: Tm B. Eval t1 t1'

! Eval (app t1 t2) (app t1' t2)
evalApp2 : \Pi A:Ty. \Pi B:Ty.

\Pi t1: (Tm (arrow A B)).

\Pi t2,t2': Tm B. Eval t2 t2'

! Eval (app t1 t2) (app t1 t2')

2.6.4 Solution: We give the solution in the syntax of the implementation.

eqSucc =

*x:Prf(nat).*y:Prf(nat).*h:Prf(eq nat x y).

h(*z:Prf(nat).eq nat (succ x) (succ z)) (eqRefl nat (succ x))
: \Pi x:Prf(nat).\Pi y:Prf(nat).Prf(eq nat x y) !

Prf(eq nat (succ x) (succ y));

496 A Solutions to Selected Exercises

addAssoc = *x:Prf(nat).*y:Prf(nat).*z:Prf(nat).

eq nat (add x (add y z)) (add (add x y) z);

proofOfAddAssoc = *x:Prf(nat).*y:Prf(nat).*z:Prf(nat).

natInd (*x1:Prf(nat).addAssoc x1 y z)

(eqRefl nat (add y z))
(*x1:Prf(nat).*p:Prf(addAssoc x1 y z).

eqSucc (add x1 (add y z)) (add (add x1 y) z) p)
x
: \Pi x:Prf(nat).\Pi y:Prf(nat).\Pi z:Prf(nat).Prf(addAssoc x y z);

2.7.1 Solution: Let i : SyntaxD^*LFE^ ! SyntaxD^*PE^ be the obvious mapping beng

tween the syntaxes, which collapses each *LF *ngconstruct to the single *P
*ngoperator, etc. (Except that type and term variables have disoint images).
Then we would hope to show:

1. \Gamma  `*LF t : T () iD^\Gamma  E^ `*P iD^tE^ : iD^TE^
2. \Gamma  `*LF T :: K () iD^\Gamma  E^ `*P iD^TE^ : iD^KE^
3. \Gamma  `*LF K () iD^\Gamma  E^ `*P iD^KE^ : 2
There are two difficulties in establishing this equivalence. First, the presentang
tion of *LF includes QngEta, but j equalities are not included in the definition
of PTS we gave. If QngEta is removed from *LF, the left to right direction is
straightforward. The right to left direction raises the second difficulty: we
must show that the untyped conversion relation of PTS can be simulated
by the declarative equality in *LF. This requires showing the ChurchngRosser
property for the PTS conversion.

2.8.1 Solution: To complete the definition, we must give a simultaneous definition

of the interpretation of index sorts, JIKj ` Z, index terms, JiKj 2 Z, and
satisfaction between environments and contexts, j |C^ \Gamma  and environments
and propositions, j |C^ P. The definitions are given below.

j |C^ ;
j |C^ \Gamma  ; x : I if j |C^ \Gamma  and jD^xE^ 2 JIKj

j |C^ \Gamma  ; P if j |C^ P

j |C^ P1 ^ P2 if j |C^ P1, j |C^ P2
j |C^ i1 <= i2 if Ji1Kj <= Ji2Kj

JxKj C^ jD^xE^
JqKj C^ q
JqiKj C^ q * JiKj
Ji1 + i2Kj C^ Ji1Kj + Ji2Kj

JintKj C^ Z
J{x:I | P}Kj C^

{ z 2 Z | jE,x , zG* |C^ P }

Finally, \Gamma  |C^ i : I is defined as 8j: j |C^ \Gamma  : =) JiKj 2 JIKj.

A Solutions to Selected Exercises 497
3.2.7 Solution: All TLngtyping rules are closed under arbitrary substitutions. Conng

sequently all substitutions of TLngtypable closed terms yield typable terms. In
particular, SD^t1E^ is TLngtypable.

3.2.18 Solution:

1. That t " implies ktk " follows directly from the Conditional Correctness

Theorem, part 2. Assume now t #, that is t terminates. By the Soundness

Theorem t cannot terminate with a stuck state, so t t-!

* v for some value

v. By Conditional Correctness, part 1, this implies that ktk -!* kvk. By
Lemma 3.2.9, part 1, kvk is also a value. Since all values are final (easy),
this shows that ktk #.

2. The implication from right to left follows directly from Conditional Corng

rectness, part 1. As for the converse direction, assume ktk -!* kvk. By
Soundness evaluation of t does not get stuck and by part 1 of the corollary

there exists a TLngvalue v0 such that t t-!

* v0. By Conditional Correctness,

part 1, we have ktk -!* kv0k. Since -! is deterministic and we also have
ktk -!* kvk by assumption, we can conclude that kv0k C^ kvk, and we are
done.

3.2.19 Solution: (Sketch) There is a better completion. The two occurrences of tt

can be given distinct labels.

3.4.2 Solution: Both of the two recursive calls would have to specify aei; aeo as

actual parameters, and so all intermediate arguments and results would end
up in the same two regions; namely the two argument regions supplied to the
function at the outermost level.

3.4.3 Solution: An nngary region abstraction can be converted into a stack of unary

ones, but one must decide where the intermediate region closures that the seng
mantics require are allocated. The following solution takes care not to cause
any net heap allocation in the translation of an nngary application:

D^*ae1; : : : ; aen:tE^ at ae ) D^*ae0:D^*ae1:* * * D^*aen:tE^ at ae0 * * *E^ at ae0E^ at ae

f E,E,ae1; : : : ; aenG*G* ) new ae0:f E,E,ae0G*G* E,E,ae1G*G* * * * E,E,aenG*G*

3.4.4 Solution: When the region abstraction is applied (i.e., each time f is menng

tioned), a closure must be allocated to contain the region parameters and the
free variables of the function body, because the ordinary BL parameter may
not be supplied right away. The parameter ae0 selects the region in which this
closure will be allocated. It is not part of the TT syntax for letrec because

498 A Solutions to Selected Exercises

this closure allocation is implicit in the letrec construct; instead the original
syntax for applying the region abstraction is

t ::C^ f[ae1; : : : ; aek] at ae0
which can be expressed as f E,E,ae1; : : : ; aek; ae0G*G* in RAL.
3.4.5 Solution: ae is the region where a closure for the region abstraction is allong

cated. This closure contains the values of the free variables of the lambda exng
pression. The intention in TT was that this closure would be consulted when
the region abstraction is applied, such that the variables could be moved to
the final closure in ae0. However, due to the syntactic requirement that the
region abstraction is applied whenever f is mentioned in t1 or t2, the free
variables will actually still be in scope at the application point. Since the body
of the region abstraction is also statically known, nothing actually needs to
be allocated in ae, and indeed the ML Kit, a practical realization of TT (refer to
Section 3.8), does not allocate this closure. But this was not realized when TT
was first formulated.

3.4.6 Solution: By a simple induction over the derivation of the evaluation relang

tion, we may prove that if t*

RAL-! t0

* and t* _ t, then there is a t0 such that

t

RAL-! t0 and t0

* _ t0.

Apply this lemma to each step of the reduction of the original t*. In the

case Y C^ bv, note that bv _ t implies bv C^ t.

3.5.2 Solution: The only interesting issue in the proof is that the substitutions

substitute from sets of variables to another syntactic class (from region varing
ables to places, for example). Observe, however, that everywhere in the typing
rules something is required to be a type, region, or effect variable (rather than,
say, a place or effect), it occurs in a binding context and so is unaffected by
substitution.

3.5.13 Solution: The reference operations would need a formal semantics, so we

would have to extend the evaluation and typing judgments with stores and
store typings as in Chapter 13 of TAPL. But that would break the lexical scopng
ing of region variables, on which the correct operation of rule (rengDealloc)
depends critically. So the entire semantic treatment of region allocation and
deallocation needs to be reworked. How to do this can be seen in Calcagno,
Helsen, and Thiemann (2002).

3.6.1 Solution: No. It is typable (if and) only if the input program satisfies our

syntactic restriction on the use of the fix operator, and is typable in (regionng
free) F with recursion, such that the type of the entire program is either bool

A Solutions to Selected Exercises 499
or a type variable. If the input program is illngtyped, it can never be region
annotated; a derivation of ; ` t :' T can be converted into a derivation of
; ` ktk : kTk in System F with recursion simply by erasing all of the regionng
related syntax. (kTk, is of course, T with the region annotations removed, in
a way similar to ktk.) Such an erasure transforms each RTL type rule into
either a wellngknown F rule or the identity rule that concludes any judgment
from itself.

3.6.3 Solution: The constraints collected during the analysis of that subexpresng

sion did not entail ae5 being in ' at all. It was only when the two sides of the
m application were combined that ae5 entered the picture. (The point here is
that construction of new must necessarily happen while each subterm is anang
lyzed; the raw type tree plus constraints does not immediately show where it
is useful to insert new except at the root.)

3.6.4 Solution: Effect polymorphism serves to enforce relations between the effect

parts of different arrow constructions in the polymorphic variant of a type.
In a firstngorder program, there is at most one arrow in each type, so there is
no need for explicit effect polymorphism.

5.2.1 Solution: The assertion that x has type singleton for value v can be writng

ten simply as x C^ v. The singleton type for the value v can be written
as {x | x C^ v} and correspondingly the assertion can also be written as x :
{x | x C^ v}

5.2.2 Solution: {x | x : ptr {{y | y C^ 0} ; int} . x : ptr {{y | y C^ 1} ; int; int}}.
5.2.3 Solution: We assume that the same listinv formula constructor is used to

specify that the contents of the memory is wellngtyped. The function specifing
cation is then:

Pre C^ r1 : ptr {int; int} ^ r2 : list int ^ listinv rM
Post C^ rR : list int ^ listinv rM

5.2.4 Solution: The challenge here is to express the sequence property. We can do

that either by adding a new type constructor or simply by using a universal
quantifier.

Pre C^ listinv rM ^ 8i:D^0 <= i ^ i < r2E^ ) D^r1 + 4 * iE^ : ptr {list int}
Post C^ listinv rM

5.2.5 Solution: We show the solution for the more complicated case when the

array elements are structures. We must add the array S type constructor,

500 A Solutions to Selected Exercises

where S is a structure type. We also add the (sizeof S N) formula to state
that the size of the structure S is N bytes.

In order to handle the sizeof formula constructor we add the following
two rules:

sizeof W 4

sizeof S N
sizeof D^W ; SE^ D^N + 4E^
By indexing into an array we can obtain pointers to elements, provided that
the index is in the bounds of the array. For the purpose of bounds checking
we must fetch the length of the array from memory and hence we must add
a requirement that the memory contents is wellngtyped.

A : array S D^sizeof S NE^ 0 <= I I < D^sel M AE^ listinv M

D^A + 4 + I * NE^ : ptr {S}

5.3.1 Solution: For the first program fragment the symbolic state at the end is

oe C^ {ra C^ b + 1; rb C^ b; rc C^ D^b + 1E^ + 2; rd C^ b + 1}. For the second
program fragment the resulting symbolic state is oe C^ {r1 C^ b + 1; r2 C^
b; rc C^ D^b + 1E^ + 2; rd C^ b + 1}. Notice that the symbolic state is the same,
considering the renaming of registers once we consider the

5.3.2 Solution: With the addition of the new instruction in the first code fragment,

the symbolic state at the end of the block becomes oe C^ {ra C^ 3; rb C^ b; rc C^
D^b + 1E^ + 2; rd C^ b + 1}. The symbolic state of register ra is different from the
symbolic state of the corresponding register (r1) in the second code fragment.

5.3.4 Solution: The key observation is that the symbolic evaluator carries precise

information about the result of the load in line 6 in Figure 5ng2. Everytime this
value is used, we have to prove that it has the right type. We have to ensure
that VCGen "forgets" the precise description of the result of the load, and
maintains only the fact that it is a value of type ptr {int}. We do this by
adding an invariant annotation immediately after the load:

:::
6 LCons: rt :C^ MemE,rxG* ; Load the first data
7 INV rt : ptr {int} ^ rx : ptr {maybepair; mp_list} ^ listinv rM
8 :::

When encountering this invariant, the VCGen assumes fresh values for all regng
isters and assumes that the invariant holds for these values. This effectively
means that the fact sel m1 x1 : ptr {int} is proved only once, when the
invariant is first encountered. Notice also that the invariant must preserve all
useful information about the live registers. For the rx register we know that
it is not equal to zero and has type mp_list, hence it is a pointer to a list cell.

A Solutions to Selected Exercises 501
5.3.5 Solution: We assume that for each function staring at address L in the agent

we have a precondition PreL and a postcondition PostL. These can be specing
fied by the agent producer using annotations. For example, in JVML they are
specified as types in a special table in the .class file that contains the agent.

Assume also that the set of registers is r1; : : : ; rn and that the calleengsave
registers are r1; : : : ; rCS. Unlike in the original symbolic evaluator we must
identify for each return instruction to which function it belongs, and thus
what postcondition to use. This can be done by carrying an additional pang
rameter in the symbolic evaluator to specify the postcondition to use for the
return instructions. Instead, we are going to assume that return instructions
are annotated with the starting address of the function to which they belong.
We also assume that each start of a function contains an invariant correng
sponding to the precondition. Now we can extend the symbolic evaluator as
follows:

SED^i; oe E^ C^ 8????!????:

: : :
D^oe PostLE^ if \Pi i C^ returnL
D^oe PreLE^ ^ if \Pi i C^ call L
8xCS+1: : : : :xn:D^oe 0 PostLE^ ) SED^i + 1; oe 0E^

where oe 0 C^ oe E,rCS+1 C^ xCS+1; : : : ; rn C^ xnG*. Thus a function call first asserts
that the precondition holds, then modifies the symbolic state so that the non
calleengsave registers are modified to have arbitrary values. The state oe 0 modng
els the state after the call. In this state the postcondition is assumed to hold
and the symbolic evaluation continues.

5.3.6 Solution: We extend the symbolic evaluator as follows:

SED^i; oe E^ C^ ( : : :false if \Pi 

i C^ UNREACHABLE

Notice that indeed we stop the evaluation at that point, but we require that
the agent producer proves that this context is never reachable. The agent
producer can actually produce a proof of false if this program point follows
a function call to a function that never returns and whose postcondition is
false, as is the case with the myexit function in the problem statement. It
is also possible to prove false at a program point following a conditional
branch that can be proved to be always taken.

5.3.7 Solution: We shall consider that each label in the program also acts as a

nullary constructor in the logic, denoting the program counter where it is
placed. We extend the symbolic evaluator to read the annotation that follows
an indirect jump and to require a proof that the address being jumped to

502 A Solutions to Selected Exercises

is equal to one of the declared destinations. Otherwise, the indirect jump is
handled as a conditional branch.

SED^i; oe E^ C^ 8????!????:

: : :
D^D^oe eE^ C^ L1 . D^oe eE^ C^ L2E^ ^ if \Pi i C^ jump at e
D^D^oe eE^ C^ L1 ) SED^L1; oe E^E^ ^ and \Pi i+1 C^ JUMPDEST(L1,L2)
D^D^oe eE^ C^ L2 ) SED^L2; oe E^E^

5.4.1 Solution: We prove here only the soundness of the cons rule. We must

prove the following statement: |C^M 8E:8W :D^E : list W E^ ^ D^E T^ 0E^ ) E :
ptr {W ; list W }. Assuming that the leftnghand side of the implication holds,
and using the definition of |C^M (see page 200), we derive that D^MD^EE^ C^ W ^
MD^E+4E^ C^ list W E^. Now we can verify the rightnghand side of the implication:
|C^M E : ptr {W ; list W }.

5.4.6 Solution: Let ae1 be a state such that |C^M ae1 Pre. We assume that DomD^ME^ `

Addr and |C^M V C. By convention the first instruction in the program (at
program counter 1) is an invariant INV Pre. Let oe1 C^ {r1 C^ x1; : : : ; rn C^ xn}
and o/1 C^ {x1 C^ ae1 r1; : : : ; xn C^ ae1 rn}. This means that ae1 C^ o/1 ffi oe1. We also
know that SED^1; oe1E^ C^ oe1 Pre and therefore we know that |C^M o/1 SED^1; oe1E^.
This allows us to establish that the induction hypothesis holds for the first
instruction: IH D^1; ae1; oe1; o/1E^.

We can prove by induction on the number of transition steps, that for any
D^i; aeE^ reachable from the initial state D^1; ae1E^, there exist oe and o/ such that
IHD^i; ae; oe ; o/E^. Furthermore, either i points to a return instruction or else we
can make further progress. The base case follows from the argument above
and the inductive step is proved using Theorem 5.4.4.

5.5.1 Solution:

all D^*a : ':

D^imp D^hastype a D^ptr D^seq1 intE^E^E^

D^addr aE^E^E^

5.5.2 Solution: The proof of the predicate 8a:a : ptr {int} ) addr a is:

ua : ptr {int}

ptraddraddr a

impiua : ptr {int} ) addr a

allia8a:a : ptr {int} ) addr a

The LF representation of this proof is shown below. Notice how the parameter
a and the hypothesis u are properly scoped by using higherngorder represenng
tation.

A Solutions to Selected Exercises 503

alli D^*a : ':D^imp D^hastype a D^ptr D^seq1 intE^E^E^

D^addr aE^E^E^
D^impi D^hastype a D^ptr D^seq1 intE^E^E^

D^addr aE^
D^*u : pf D^hastype a D^ptr D^seq1 intE^E^E^

D^ptraddr a D^seq1 intE^ uE^E^E^
In the above representation we used LF constants declared in Figure 5ng11
along with the following declaration for ptraddr:

ptraddr : \Pi A : ':\Pi S : s:pf D^hastype A D^ptr SE^E^ ! pf D^addr AE^
6.2.1 Solution: The if direction (s0 = t0 implies sa*t) follows directly from symng

metry and transitivity. For the onlyngif direction, suppose sa*t. We claim
that s and t have a common reduct (that is, there exists u such that s)*u
and t)*u):

Proof: The proof is by induction on s a* t.
Base step:
Suppose sa*t holds because s)t. Then let u be t.
Induction step: (Symmetry)
Suppose sa*t holds because ta*s. By induction, t and s have a common
reduct u.

Induction step: (Transitivity)
Suppose sa*t holds because sa*u0 and u0a*t. By induction, s and u0 have
a common reduct s00, and u0 and t have a common reduct t00. Thus u0)*s00
and u0)*t00, so by confluence there exists u such that s00)*u and t00)*u.
Therefore u is a common reduct of s and t. 2

We have shown that s and t have a common reduct u. Observe that s)*s0
and s)*u. By confluence, there exists r such that s0)*r and u)*r. But s0 is
a normal form, so r = s0. Hence u)*s0. Similarly u)*t0. Then, by confluence,
s0 and t0 must have a common reduct, but again they are normal forms so
they must be equal.

6.2.2 Solution: By induction on derivations. We show the case for QngExt; the othng

ers are straightforward. For QngExt, choose x so as not to be free in s or t.
By induction, s x a* t x. It is easy to show by induction that *x:T1.s x a*
*x:T1.t x (by repeatedly using QRngAbs). By QRngEta, *x:T1.s x ) s and
*x:T1.t x ) t. Therefore s a* t by symmetry and transitivity.

6.2.3 Solution: Let T and T0 be any two distinct types. Let t be *x:T.(*y:T0.y)x.

By QRngAbs and QRngBeta, t reduces to *x:T.x, and by QRngEta, t reduces to

504 A Solutions to Selected Exercises

*y:T0.y. These two terms are distinct normal forms, so they have no common
reduct.

6.3.1 Solution: s is *x:Unit.x and t is *x:Unit.unit.
6.6.3 Solution: The logical equivalence x:b ` x is x : b holds but ` x is x : b

does not.

6.6.4 Solution: The logical equivalence ` *x:b.x is *x:b.k : b!b holds, but

y:b ` *x:b.x is *x:b.k : b!b does not.

Proof: We begin by showing the former logical equivalence holds. Suppose
` s is t : b. We wish to show that ` (*x:b.x) s is (*x:b.k) t : b. It is
sufficient to show that: ` (*x:b.x) s a (*x:b.k) t : b. Since ` s is t : b,
we have that ` s a t : b. By inversion s + s0, t + t0, and ` s0 $ t0 : b. Since
the context is empty, and there exists only one constant, it is easy to verify
that s0 C^ t0 C^ k. Therefore ((*x:b.x) s) + k and ((*x:b.k) t) + k. The
desired conclusion follows.

Now we show that the latter logical equivalence does not hold. Let s C^
t C^ y. Then certainly y:b ` s is t : b. However, ((*x:b.x) s) + y and
((*x:b.k) t) + k, and y and k are not path equivalent. Therefore (*x:b.x) s
and (*x:b.k) t are not algorithmically equivalent and hence not logically
equivalent at b. 2

6.9.2 Solution: By induction on T. The case T C^ Unit is trivial, and the case T C^ b

follows from algorithmic transitivity (Lemma 6.5.4).

Suppose T C^ T1!T2. Then \Gamma  ` s is t : T1!T2 and \Gamma  ` t is u : T1!T2. We
wish to show that \Gamma  ` s is u : T1!T2. Suppose \Gamma  0 ' \Gamma  and \Gamma  0 ` s0 is u0 : T1.
Then we wish to show that \Gamma  0 ` s s0 is u u0 : T2.

By logical symmetry (Lemma 6.9.1), \Gamma  0 ` u0 is s0 : T1, and then by inng
duction, \Gamma  0 ` u0 is u0 : T1. By the definition of logical equivalence, we may
deduce \Gamma  0 ` s s0 is t u0 : T2 and also \Gamma  0 ` t u0 is u u0 : T2. By induction,
\Gamma  0 ` s s0 is u u0 : T2.

6.9.10 Solution:

Case TngConst: t C^ k

T C^ b

By the Main Lemma, \Gamma  0 ` k is k : b. Therefore \Gamma  0 ` flD^kE^ is ffiD^kE^ : b, since k
contains no free variables.

Case QngRefl:
Immediate by the first clause of the induction hypothesis.

A Solutions to Selected Exercises 505
Case QngSymm:
Immediate from the induction hypothesis and logical symmetry.
Case QngTrans:
By logical symmetry, \Gamma  0 ` ffi is fl : \Gamma  , so by logical transitivity, \Gamma  0 ` ffi is ffi : \Gamma  .
Therefore, by induction (using fl and ffi), \Gamma  0 ` flD^sE^ is ffiD^tE^ : T, and also
by induction (using ffi and ffi), \Gamma  0 ` ffiD^tE^ is ffiD^uE^ : T. By logical transitivity,
\Gamma  0 ` flD^sE^ is ffiD^uE^ : T.

Case QngAbs: s C^ *x:T1.s2

t C^ *x:T1.t2
T C^ T1!T2

We wish to show that \Gamma  0 ` flD^*x:T1.s2E^ is ffiD^*x:T1.t2E^ : T1!T2. Suppose
\Gamma  00 ' \Gamma  0 and \Gamma  00 ` s0 is t0 : T1. We wish to show that \Gamma  00 ` (*x:T1:flD^s2E^)s0 is
(*x:T1:ffiD^t2E^)t0 : T2. By logical weak head closure, it is sufficient to show
that \Gamma  00 ` E,x , s0G*flD^s2E^ is E,x , t0G*ffiD^t2E^ : T2.

By logical monotonicity, \Gamma  00 ` fl is ffi : \Gamma  . Thus, \Gamma  00 ` flE,x , s0G* is
ffiE,x , t0G* : D^\Gamma  ; x:T1E^. Therefore, by induction, \Gamma  00 ` flE,x , s0G*D^s2E^ is ffiE,x ,
t0G*D^t2E^ : T2, which is equivalent to the desired conclusion.

Case QngApp: s C^ s1 s2

t C^ t1 t2
T C^ T12

By induction, \Gamma  0 ` flD^s1E^ is ffiD^t1E^ : T1!T2 and \Gamma  0 ` flD^s2E^ is ffiD^t2E^ : T1.
By the definition of the logical relation, since \Gamma  0 ' \Gamma  , we may conclude \Gamma  0 `
flD^s1E^flD^s2E^ is ffiD^t1E^ffiD^t2E^ : T2. That is, \Gamma  0 ` flD^s1 s2E^ is ffiD^t1 t2E^ : T2.

Case QngExt: s C^ s

t C^ t
T C^ T1!T2

We wish to show that \Gamma  0 ` flD^sE^ is ffiD^tE^ : T1!T2. Suppose \Gamma  00 ' \Gamma  0 and
\Gamma  00 ` s0 is t0 : T1. We wish to show that \Gamma  00 ` flD^sE^ s0 is ffiD^tE^ t0 : T2.

By logical monotonicity, \Gamma  00 ` fl is ffi : \Gamma  . Thus, \Gamma  00 ` flE,x , s0G* is ffiE,x ,
t0G* : D^\Gamma  ; x:T1E^. Therefore, by induction, \Gamma  00 ` flE,x , s0G*D^s xE^ is ffiE,x ,
t0G*D^t xE^ : T2. That is, \Gamma  00 ` flD^sE^ s0 is ffiD^tE^ t0 : T2, as desired.

6.9.12 Solution: By soundness, \Gamma  ` s1 j t1 : T1!T2 and \Gamma  ` s2 j t2 : T1. By QngApp,

\Gamma  ` s1 s2 j t1 t2 : T2. By completeness, \Gamma  ` s1 s2 a t1 t2 : T2.

6.9.13 Solution: The key observation is that the leftng and rightnghand sides of the

algorithm do not interact, except insofar as a failure to match in path equivang
lence allows the algorithm to quit early. That is, except for early termination,
one can trace the execution of the algorithm ignoring the terms either to the

506 A Solutions to Selected Exercises

left or to the right of the arrows. Therefore we can devise a termination metric
that takes each side into account independently.

Therefore, define the metric MD^\Gamma  ` s a t : TE^ to be the size of the derivang
tion (if it exists) of \Gamma  ` s a s : T plus the size of the derivation (if it exists) of
\Gamma  ` t a t : T. Define the metric MD^\Gamma  ` p $ q : TE^ similarly. It is straightforng
ward to show that the metric decreases in each recursive call of the algorithm.
It is also straightforward to show that all normalizations terminate, since the
normalization derivations being sought already exist within the derivations
measured by the metric.

Thus, it remains to show only that the metric is actually defined, that is,
that there exist derivations of \Gamma  ` s a s : T and \Gamma  ` t a t : T. This follows
by the completeness of the algorithm from our assumptions that \Gamma  ` s : T
and \Gamma  ` t : T.

This strategy works precisely because the two sides of the algorithm do
not interact. It fails when the two sides do interact, such as in the algorithm
for full F<= (TAPL, Chapter 28), wherein bounded universal types on the rightng
hand side affect the context, which in turn affects the promotion of variables
on the leftnghand side. On the other hand, in the algorithm for kernel F<=, the
bounds on the leftng and rightnghand sides are required to be the same, so
the two sides do act independently (although the side being considered does
switch back and forth because of contravariance).

6.9.14 Solution: First, we extend the proofs of the basic algorithmic properties

(symmetry, transitivity, weak head closure, and monotonicity) to deal with
the new algorithm. These proofs are straightforward.

Second, we define logical equivalence as follows:

\Gamma  ` s is t : T if and only if either:

T=Unit,
or T=b and \Gamma  ` s a t : b,
or T=T1!T2 and, for all s0, t0 and all \Gamma  0 ' \Gamma  ,

if \Gamma  0 ` s0 is t0 : T1
then \Gamma  0 ` s s0 is t t0 : T2,
or T=T1 * T2 and \Gamma  ` s.1 is t.1 : T1 and

\Gamma  ` s.2 is t.2 : T2.

Third, we extend the proofs of the basic logical properties (symmetry, tranng
sitivity, weak head closure, and monotonicity) to deal with the new definition
of logical equivalence. These proofs are also straightforward.

Fourth, we extend the Main Lemma to account for product types (the other
cases are unchanged):

A Solutions to Selected Exercises 507
Case: T C^ T1 * T2

1. Suppose \Gamma  ` s is t : T1 * T2. We wish to show that \Gamma  ` s a t : T1 * T2.

The definition of logical equivalence provides that \Gamma  ` s.1 is t.1 : T1,
and so \Gamma  ` s.1 a t.1 : T1 follows by induction. Similarly, \Gamma  ` s.2 a
t.2 : T2. Therefore, \Gamma  ` s a t : T1 * T2.

2. Suppose \Gamma  ` p $ q : T1 * T2. We wish to show that \Gamma  ` p is q : T1 * T2.

The algorithm provides that \Gamma  ` p.1 $ q.1 : T1, so \Gamma  ` p.1 is q.1 : T1
follows by induction. Similarly, \Gamma  ` p.2 is q.2 : T2. Therefore \Gamma  ` p is
q : T1 * T2.

Finally, we extend the proof of the Fundamental Theorem to cover the new
typing and equivalence cases:

Case TngPair: t C^ ht1, t2i

T C^ T1 * T2

By induction, \Gamma  0 ` flD^t1E^ is ffiD^t1E^ : T1, so by logical weak head closure,
\Gamma  0 ` flD^ht1,t2iE^.1 is ffiD^ht1,t2iE^.1 : T1. Similarly, \Gamma  0 ` flD^ht1,t2iE^.2 is
ffiD^ht1,t2iE^.2 : T2. Therefore \Gamma  0 ` flD^ht1,t2iE^ is ffiD^ht1,t2iE^ : T1 * T2.

Case TngProj1: t C^ t1.1

T C^ T1

We wish to show that \Gamma  0 ` flD^t1.1E^ is ffiD^t1.1E^ : T1. By induction, \Gamma  0 `
flD^t1E^ is ffiD^t1E^ : T1 * T2, and the desired follows by the definition of logical
equivalence.

Case TngProj2:
Similar to the case for TngProj1.
Case QngPair: s C^ hs1, s2i

t C^ ht1, t2i
T C^ T1 * T2

By induction, \Gamma  0 ` flD^s1E^ is ffiD^t1E^ : T1, so by logical weak head closure,
\Gamma  0 ` flD^hs1,s2iE^.1 is ffiD^ht1,t2iE^.1 : T1. Similarly, \Gamma  0 ` flD^hs1,s2iE^.2 is
ffiD^ht1,t2iE^.2 : T2. Therefore \Gamma  0 ` flD^hs1,s2iE^ is ffiD^ht1,t2iE^ : T1 * T2.

Case QngProj1: s C^ s1.1

t C^ t1.1
T C^ T1

We wish to show that \Gamma  0 ` flD^s1.1E^ is ffiD^t1.1E^ : T1. By induction, \Gamma  0 `
flD^s1E^ is ffiD^t1E^ : T1 * T2, and the desired follows by the definition of logical
equivalence.

Case QngProj2:
Similar to the case for QngProj1.

508 A Solutions to Selected Exercises

Case QngBetangProd1: s C^ hs1,s2i.1

t C^ t
T C^ T1

By induction, \Gamma  0 ` flD^s1E^ is ffiD^tE^ : T1. Therefore, by logical weak head clong
sure, \Gamma  0 ` flD^hs1,s2i.1E^ is ffiD^tE^ : T1.

Case QngBetangProd2: s C^ hs1,s2i.2

t C^ t
T C^ T2

By induction, \Gamma  0 ` flD^s2E^ is ffiD^tE^ : T2. Therefore, by logical weak head clong
sure, \Gamma  0 ` flD^hs1,s2i.2E^ is ffiD^tE^ : T2.

Case QngExtngProd: s C^ s

t C^ t
T C^ T1 * T2

We wish to show that \Gamma  0 ` flD^sE^ is ffiD^tE^ : T1 * T2. It suffices to show that
\Gamma  0 ` flD^s.1E^ is ffiD^t.1E^ : T1 and \Gamma  0 ` flD^s.2E^ is ffiD^t.2E^ : T2, each of which
follows immediately by induction.

6.9.15 Solution: We must add a case for universal types to the definition of logical

equivalence. The most obvious definition is to quantify over all type argung
ments and compare the type applications at the corresponding instantiated
type:

\Gamma  ` s is t : 8X.T if and only if
for all closed types T0, \Gamma  ` s [T0] is t [T0] : E,X , T0G*T

Unfortunately, this is an invalid definition, because logical equivalence is
defined by induction on types, and there is no guarantee that the type E,X ,
T0G*T is smaller than 8X.T.

The problem is tied to the issue of impredicativity (TAPL, $23.10). In both
8X.T, the domain of the quantified type variable X includes the very type
being defined. This prevents the obvious definition from being wellngfounded.

For the simple definition attempt given above, the impredicativity probng
lem is fatal. Sometimes we can save the simple definition by changing the
language to be predicative. However, for an impredicative language, a more
sophisticated definition is required.

The solution to the problem is Girard's method of candidates (Girard, Lang
font, and Taylor, 1989). An explanation of Girard's method is beyond the
scope of this discussion, but informally the method works as follows: Instead
of quantifying over types, the definition of logical equivalence quantifies over
possible interpretations of types called candidates. Importantly, candidates

A Solutions to Selected Exercises 509
come equipped with their own notion of logical equivalence that can be deng
fined independently (i.e., without reference to the general definition of logical
equivalence). Thus, the definition of logical equivalence may refer to arbitrary
candidates and remain wellngfounded.

7.4.2 Hint: First prove

hS1; t1i -! hS2; t2i ) D^8SE^D^hS@S2; t2i # ) hS@S1; t1i #E^
by considering the different cases for -!. Deduce the `if' part of (7.7) from
this. For the `only if' part, show that

{D^S; tE^ | D^9S1; S2; vE^ S C^ S1@S2 & hS2; ti -!* hId; vi & hS1; vi #}
is closed under the axiom and rules in Figure 7ng2 inductively defining the
termination relation.

7.5.4 Solution: For property (iii), assuming R is compatible, argue by induction on

the derivation of \Gamma  ` t : T that this typing judgment implies that \Gamma  ` t R t :
T holds. For property (v), if R C^ Si2I Ri with I 6C^ ; and each Ri compatible,
first note that by (iii), R is reflexive since it contains at least one relation Ri.
For each of the compatibility properties in Figure 7ng4 with a single hypothesis,
it is clear that R has this property because each of the Ri does. For compatng
ibility properties with multiple hypotheses, we can break them down into a
chain of singlenghypothesis compatibilities and appeal to the transitivity of R
(which we are assuming). For example consider the compatibility property for
function application. It suffices to show that R satisfies

\Gamma  ` v1 R v01 : T1!T2 \Gamma  ` v2 : T1

\Gamma  ` v1 v2 R v01 v2 : T2 (A.1)

and

\Gamma  ` v1 : T1!T2 \Gamma  ` v2 R v02 : T1

\Gamma  ` v1 v2 R v1 v02 : T2 : (A.2)

For then if \Gamma  ` v1 R v01 : T1!T2 and \Gamma  ` v2 R v02 : T1, we get

\Gamma  ` v1 v2 R v01 v2 : T2 by (A.1), since \Gamma  ` v2 : T1
\Gamma  ` v01 v2 R v01 v02 : T2 by (A.2), since \Gamma  ` v01 : T1!T2.

and hence \Gamma  ` v1 v2 R v01 v02 : T2 by transitivity. Each of the singlenghypothesis
properties (A.1) and (A.2) holds of R because they hold for each Ri: each is
a special case of the compatibility property for function application because
each Ri, being compatible, is also reflexive by (iii).

510 A Solutions to Selected Exercises

7.5.10 Solution: Consider the frame stacks

S defC^ Id ffi D^x.(fun f(x0:Bool) = if x0 then true else f x0)xE^
ST defC^ Id ffi D^x.(fun f(x0:T) = true)xE^
Note that ; ` S : Bool C, Bool and ; ` ST : T C, Bool. It is not hard to see
for all ; ` b : Bool that

SE,bG* # iff hId; bi -!* hId; truei (A.3)
and for all ; ` t : T that

t # iff hId; STE,tG*i -!* hId; truei (A.4)
From (A.3) and the fact that C^ctx is a congruence (so that ; ` b C^ctx b0 : Bool
implies ; ` SE,bG* C^ctx SE,b0G* : Bool) it follows that C^ctx is truengadequate;
hence it is contained in C^truectx . Similarly, (A.4) and the fact that C^truectx is a
congruence implies that it is adequate and hence contained in C^ctx.

7.6.7 Solution: Since D^-E^s t is inflationary we have r ` r s t; and since r only relates

values, this implies r ` r s t v. Then since D^-E^s t is monotone, we have r s t `
r s t v s t. Conversely, since D^r 0E^v ` r 0 for any r 0, we have r s t v ` r s t ; and then
since D^-E^s t is monotone and idempotent, r s t v s t ` r s t s t C^ r s t.

7.6.14 Hint: The proof of (7.26) is just like the proof of (7.21), using the following

property of the termination relation:

D^hS; v.li # a hS0; v0.li #E^ iff D^hS ffi D^x.x.lE^; vi # a hS0 ffi D^x.x.lE^; v0i #E^.
Similarly, the proof of (7.27) follows from:

D^hS; v Ti # a hS0; v0 T0i #E^ iff D^hS ffi D^x.x TE^; vi # a hS0 ffi D^x.x T0E^; v0i #E^.
7.6.18 Solution: It suffices to show

D^8n C^ 0; 1; : : :E^ D^Fn; F0nE^ 2 funD^r1; r2E^ (A.5)
where Fn and F0n are the unwindings associated with F and F0 respectively, as
in Theorem 7.4.4. For if (A.5) holds, then using the fact that D^-E^s t is inflationng
ary

D^Fn; F0nE^ 2 funD^r1; r2E^ ` funD^r1; r2E^s t
for each n; so by the Admissibility property in Lemma 7.6.8 we have D^F; F0E^ 2
funD^r1; r2E^s t . Thus D^F; F0E^ 2 funD^r1; r2E^s t v C^ funD^r1; r2E^ by Lemma 7.6.13,
since D^r2E^s t C^ r2. (A.5) is proved by induction on n:

A Solutions to Selected Exercises 511
Base case n C^ 0: By definition of F0, hS; F0 v1i # does not hold for any S 2

StackD^T2E^ and v1 2 ValD^T1E^; similarly for F00. Hence for all D^v1; v01E^ 2 D^r1E^v,
D^F0 v1; F00 v01E^ 2 st for any s 2 SRelD^T2; T02E^ and hence in particular for
s C^ D^r2E^s. So D^F0 v1; F00 v01E^ 2 D^r2E^s t C^ r2 for all D^v1; v01E^ 2 D^r1E^v. Therefore
D^F0; F00E^ 2 funD^r1; r2E^.

Induction step: Suppose D^Fn; F0nE^ 2 funD^r1; r2E^. Then for any D^v1; v01E^ 2 D^r1E^v,

from (7.29) we have

D^E,f , FnG*E,x , v1G*t; E,f , F0nG*E,x , v01G*t0E^ 2 r2:
By definition of Fn+1 and Corollary 7.5.8 we have ; ` Fn+1v1 C^ctx E,f ,
FnG*E,x , v1G*t; and similarly, ; ` F0n+1v01 C^ctx E,f , F0nG*E,x , v01G*t0. So
since r2 is closed, we can apply the Equivalencengrespecting property in
Lemma 7.6.8 to conclude that D^Fn+1v1; F0n+1v01E^ 2 r2. Since this holds for
any D^v1; v01E^ 2 D^r1E^v, we have D^Fn+1; F0n+1E^ 2 funD^r1; r2E^.

7.6.19 Solution: To show D^v; v0E^ 2 {li=ri i21::n} we must show D^v.li; v0.liE^ 2 ri for

each i 2 1::n. Since each ri is closed, this is equivalent to showing D^v.li; v0.liE^ 2
D^riE^s t , i.e. that hS; v.lii # a hS0; v0.lii # holds for all D^S; S0E^ in D^riE^s. But by
definition of v, hS; v.lii # a hS; vii #; and similarly for v0. So it suffices to
show hS; vii # a hS0; v0i i; and this holds because by assumption D^vi; v0iE^ 2 ri
and D^S; S0E^ 2 D^riE^s.

7.6.20 Solution: To show D^*X.v; *X.v0E^ 2 *r .RD^r E^ we have to show for each T1; T01 2

Typ and r 2 TRelD^T1; T01E^ that D^(*X.v)T; (*X.v0)T0E^ 2 RD^r E^ . Since each
RD^r E^ is closed, this is equivalent to showing D^(*X.v)T; (*X.v0)T0E^ 2 RD^r E^s t,
i.e. that hS; (*X.v)Ti # a hS0; (*X.v0)T0i # holds for all D^S; S0E^ 2 RD^r E^s. But
hS; (*X.v)Ti # a hS; E,X , T1G*vi #; and similarly for v0. So it suffices to show
hS; E,X , T1G*vi # a hS; E,X , T01G*v0i #; and this holds because by assumption
D^E,X , T1G*v; E,X , T1G*vE^ 2 RD^r E^ and D^S; S0E^ 2 RD^r E^s.

7.6.21 Hint: To show D^if v then t1 else t2; if v0 then t01 else t02E^ 2 r C^ D^r E^s t it

suffices to show for all D^S; S0E^ 2 D^r E^s that

hS; if v then t1 else t2i # a hS0; if v0 then t01 else t02i #
or equivalently that

hS ffi D^x.if x then t1 else t2E^; vi # a

hS0 ffi D^x.if x then t01 else t02E^; v0i #:

Do this by proving that

D^S ffi D^x.if x then t1 else t2E^; S0 ffi D^x.if x then t01 else t02E^ 2 D^IdBoolE^s:

512 A Solutions to Selected Exercises

7.6.22 Solution: For any D^S; S0E^ 2 D^r2E^s it follows from the assumptions on t; t0 and

the definition of {9r1,RD^r1E^} (Figure 7ng5) that

D^S ffi D^y.let {*X,x}=y in tE^; S0 ffi D^y.let {*X,x}=y in t0E^E^
is in {9r1,RD^r1E^}s. Hence if D^v; v0E^ 2 {9r1,RD^r1E^}s t v ` D^{9r1,RD^r1E^}sE^t, then

hS ffi D^y.let {*X,x}=y in tE^; vi # a hS0 ffi D^y.let {*X,x}=y in t0E^; v0i #
and so hS; let {*X,x}=v in ti # a hS; let {*X,x}=v0 in t0i #. Since this is
true for all D^S; S0E^ 2 D^r2E^s, we deduce that

D^let {*X,x}=v in t; let {*X,x}=v in tE^ 2 D^r2E^s t C^ r2:
7.6.23 Solution: For any D^S; S0E^ 2 D^r2E^s it follows from the assumptions on t; t0

that D^S ffi D^x.t2E^; S0 ffi D^x.t02E^E^ 2 D^r1E^v s. Since D^D^r1E^v sE^t C^ r1, if D^t1; t01E^ 2 r1 then
we get hS ffi D^x.t2E^; t1i # a hS0 ffi D^x.t02E^; t01i #, and hence that

hS; let x=t1 in t2i # a hS0; let x=t01 in t02i #:
Since this holds for all D^S; S0E^ 2 D^r2E^s, we deduce that

D^let x=t1 in t2; let x=t01 in t02E^ 2 D^r2E^s t C^ r2:
7.7.10 Solution: Since N has no closed values, neither does {9X,N}. On the other

hand

val v = *Y.fun f(x:8X.N!Y) = (f x):Y
is a closed value of type 8Y.(8X.N!Y)!Y. If i and j were to exist with
the stated properties we could use them to construct from v a closed value
of type {9X,N}, which is impossible. (For i(j v) and v are ciungequivalent
(Theorem 7.5.7); so since v #, we also have i(j v) #. Hence by Exercise 7.4.2,
hId; j vi -!* hId; v0i for some v0, which is a closed value of type {9X,N}, by
Exercise 7.4.3.)

8.2.1 Solution: As of this writing, the question of how far nominal module sysng

tems can be pushed is wide open. A step in this direction was recently taken
by Odersky, Cremet, Rockl, and Zenger (2003).

8.5.3 Solution: Define m1 to be the module

module m1 = mod {

type X = Int
val c = 0
val f = succ
}

A Solutions to Selected Exercises 513
and define m2 to be the module

module m2 = mod {

type X = Bool
val c = true
val f = not
}.

Define M to be the expression if flip() then m1 else m2, where the function
flip:unit!bool alternates between true and false on each call. Now conng
sider the term t = M.f(M.c). This is wellngtyped, because M.f : M.X!M.X and
M.c : M.X. But evaluation of t goes wrong by applying either succ to a value
of type Bool or not to a value of type Int.

8.5.4 Solution: In a callngbyngname setting, variables may no longer be considered

determinate, because they stand for unevaluated module expressions. Thereng
fore we cannot "determinize" an indeterminate module expression by binding
it to a variable, with the result that there is no way to use its type components.

8.5.5 Solution: Consider the following declarations:

signature I = sig { type X val x : X }
module m = mod { type X = Int val x = 5 }
module n = mod { type X = Bool val x = true }

Then the term (*x : (m:>I).X ...)((m:>I).x) is well typed, but the term
(*x : (n:>I).X ...)((m:>I).x) is not.

8.5.6 Solution: For example, we might hash the same value in the two different

hash tables, producing two hash codes that, because they have the same type,
could be compared and (surprisingly) found to be different. Conversely, we
could get unlucky and hash two different values to the same hash code.

8.5.7 Solution: Consider the signature

signature INTDICT =

sig {

type T
val insert : T * Int ! T
val lookup : T * Int ! Bool
}

If M and N both implement INTDICT as a list of integers, but M requires that the
list be sorted while N does not, then interchanging N.lookup with M.lookup
could cause an inserted key not to be found.

514 A Solutions to Selected Exercises

8.5.9 Solution: The signature

signature J = sig {

type X : *!*
type Y : * }

is a superngsignature of I that avoids m. For each type A the signature

signature KA = sig {

type X : *!*
type Y = X(A) }

is also a superngsignature of I that avoids m. But the signature J is a proper
superngsignature of every signature KA, so it cannot be principal, and yet the
signatures KA and KB are incomparable whenever A and B are inequivalent
types.

For an example in System F<=, see Ghelli and Pierce (1992).

8.7.1 Solution: Because there would be no way to obtain instances of the comng

pletely abstract type (dict1:>Dict).X, and hence no way to ever put anyng
thing into a dictionary.

8.7.2 Solution:

sig { CD1, ..., CDn } where m = M C^

sig { CD1 where m=M, ..., CDn where m=M }

type X where m = M C^ type X
type X = T where m = M C^ type X = T

val x : T where m = M C^ val x : T
module m : I where m = M C^ module m : (I is M)
module n : I where m = M C^ module n : I D^if m 6C^ nE^

sig { CD1, ..., CDn } is M C^ sig { CD1 is M, ..., CDn is M }

type X is M C^ type X = M.X
type X = T is M C^ type X = T

val x : T is M C^ val x : T
module m : I is M C^ module m : (I is M.m)

8.8.1 Solution: A functor signature is an signature describing modulenglevel funcng

tions; a family of signatures is itself a function from modules to signatures.
The body of a functor signature is a family of signatures indexed by the
functor parameter. Or, in the slogan coined by Sannella, Sokolowski, and
Tarlecki (1992), parameterized (program specification) 6C^ (parameterized prong
gram) specification.

A Solutions to Selected Exercises 515

In a sense, in the case of firstngorder module systems, there is no real need
for functor signatures per se, because there are no variable functors. We could
just say that a family of modules has a family of signatures, each module inng
stance determining a corresponding signature instance. But for higherngorder
or separate compilation purposes we need a notation meaning "F is a functor
implementing signature I."

8.8.2 Solution: Yes, but we need to make sure that the dictFun functor includes

its parameter as a submodule of its result:

module dictFun =

*k:ordered.

mod {

module key = k
... (as before) ...
}

signature DictFun =

\Pi k:Ordered.

sig {

module key = k
type Dict : *!*
val new : 8V. Dict V
val add : 8V. Dict V ! key.X ! V ! Dict V
val member : 8V. Dict V ! key.X ! Bool
val lookup : 8V. Dict V ! key.X ! V
}

Or, more concisely, DictFun = \Pi m:K. (D where k = m).

8.8.4 Solution: The compose8 functor will require 9 type parameters; compose16

will require 17. Note that, in this series of examples, the part of each functor
that is doing useful work is the same size as as its predecessor, while the
amount of "nuisance parameterization" increases exponentially.

8.8.5 Solution: Let HashFun be a generative hash table functor. If, by subsumpng

tion, HashFun could be regarded as applicative, then two instances would
determine the same abstract type, permitting confusion of distinct hash tang
bles.

8.10.1 Solution: A module in our sense corresponds to a ".c" file, which conng

tains procedure and function definitions, type definitions, and declarations
of global variables. Procedures, functions, and variables may be made private
by declaring them static; otherwise they are presumed to be exported. An

516 A Solutions to Selected Exercises

signature in our sense corresponds to a ".h" file, which contains procedure
and function headers, type definitions, and declarations of global variables.
The compiled versions of modules correspond to ".o" files, which are linked
(e.g., using the ld command in Unix) into complete executable programs.

8.10.2 Solution: A rigorous comparison of Java's modularity features with the ones

described in this chapter is actually quite difficult. Here are some observang
tions, however.

A class in Java is a mediumngscale program structuring device, and is often
a unit of abstraction, maintaining interesting invariants among its fields and
allowing access to the fields only through its own methods. In these ways, a
class is like a module. However, Java classes do not have type components.
Conversely, class instantiation (in the sense of saying new to a class to get
an object) is something that we don't do with modules. Also, classes in Java
are not units of compilation--it is not generally possible to compile a class
separately from other classes that it refers to (e.g., because mutually recursive
references are allowed).

An object in Java is also something like a module, providing a collection
of named components; like classes, however, objects do not contain type
components1 --just methods (functions) and fields (reference cells holding
pointers to objects).

Both Java signatures and abstract classes (all of whose methods are virtual)
are something like signatures in the sense of this chapter, since they describe
the components of an object without providing implementations.

Signatures and abstract classes can be used to achieve separate compilang
tion in Java, but in a somewhat different style from the separate compilation
discussed here. One defines an signature I, then defines one class that imng
plements I and, separately, another that expects to be given an object impleng
menting I. These two classes can be compiled separately from each other.

Java's packages are also useful in structuring and decomposing the namesng
paces of large software systems, but they do not have many of the characterisng
tics of modules in our sense: packages are not units of separate compilation,
and there is no notion of an "signature of a package." This suggests that
packages could be turned into something more like real modules by equipng
ping them with signatures. This extension has been explored by Bauer, Appel,
and Felten (1999).

9.1.4 Solution: The premise \Gamma  ` T2 :: * in TngTLet ensures that the local variable X

appears only within the scope where it is defined and not in T2. Omitting the

1. . . . except in experimental extensions with virtual types (Thorup, 1997; Torgersen, 1998;
Igarashi and Pierce, 1999, etc.).

A Solutions to Selected Exercises 517
side condition would allow not just ` (let X=Nat in *y:X.y+1) : Nat!Nat
but also ` (let X=Nat in *y:X.y+1) : X!Nat. Thus, code such as

(let X=Nat in *y:X.y+1) (let X=Nat * Nat in {5,4})
would type check because the function could be given type X!Nat and the
argument could be given type X. At runngtime, however, this code would try to
increment a pair, and hence ought to be rejected.

9.1.5 Solution: If primitive definitions were added to the simplyngtyped lambda

calculus, we would probably want to allow type variables to appear in types
(requiring an extension of the syntax of types) and to allow type definitions to
appear in the context. In contrast to *let, though, every type variable would
have a definition (and be of kind *, since the language lacks type operators).
These definitions would induce a contextngsensitive type equivalence relation
based purely on definition expansion; thus adding the F ! rule TngEq would be
appropriate.

Given the lack of type operators, a further extension might be to allow
parameterized type definitions with fixed arity, i.e., to allow definitions such
as X(Y1,Y2) = Y1!Y2 in the context and then to allow fullyngapplied uses of X
such as X(Nat,Bool!Bool) to appear in types. This leads to the possibility
of illngformed types supplying the wrong number of arguments (e.g., X by itself
or X(Nat)) and so might require a type wellngformedness judgment.

9.1.8 Solution: This logical relation satisfies the same properties as that in Chapng

ter 6 (being a monotone partial equivalence relation and closed under weak
headngexpansion), for the same reasons.

A.1 Lemma:

1. If \Gamma  ` S is T :: K and \Gamma  0 ' \Gamma  then \Gamma  0 ` S is T :: K
2. If \Gamma  ` S is T :: K then \Gamma  ` T is S :: K.
3. If \Gamma  ` S is T :: K and \Gamma  ` T is U :: K then \Gamma  ` S is U :: K.
4. If \Gamma  ` S is T :: K and \Gamma  `n~ S0 ;* S and \Gamma  `n~ T0 ;* T then \Gamma  ` S0 is T0 :: K.

A corresponding version of the Main Lemma holds as well. It is no longer
true that all paths are weak headngnormal, so we make this an explicit requireng
ment in part 2:

A.2 Lemma [Main Lemma]: 1. If \Gamma  ` S is T :: K then \Gamma  `n~ S a T :: K.

2. If \Gamma  `n~ S $ T :: K where S and T are paths (a variable applied zero or more

times) with \Gamma  `n~ S + S and \Gamma  `n~ T + T, then \Gamma  ` S is T :: K. 2

518 A Solutions to Selected Exercises

Proof: By simultaneous induction on K. 2

Because the definition of logical equivalence of substitutions has changed,
we need to recheck that it is an equivalence relation.

A.3 Lemma:

1. If \Gamma  0 ` fl is ffi :: \Gamma  then \Gamma  0 ` ffi is fl :: \Gamma  .
2. If \Gamma  0 ` fl is fl0 :: \Gamma  and \Gamma  0 ` fl0 is fl00 :: \Gamma  then \Gamma  0 ` fl is fl00 :: \Gamma  . 2
Proof: 1. Follows from Lemma A.1(2).

2. Assume X::K 2 \Gamma  . Then by Lemma A.1(3) \Gamma  0 ` flD^XE^ is fl00D^XE^ :: K just as

before.

Alternatively, assume X::K=T 2 \Gamma  . Then among other consequences we
know that \Gamma  0 ` flD^XE^ is fl0D^XE^ :: K, \Gamma  0 ` flD^TE^ is fl0D^XE^ :: K, \Gamma  0 ` fl0D^XE^ is
fl00D^XE^ :: K, and \Gamma  0 ` fl0D^XE^ is fl00D^TE^ :: K. By Lemma A.1(2,3), then, \Gamma  0 `
flD^XE^ is fl00D^XE^ :: K, \Gamma  0 ` flD^TE^ is fl00D^XE^ :: K and \Gamma  0 ` flD^XE^ is fl00D^TE^ :: K
as required. 2

Finally, we have the Fundamental Theorem:
A.4 Theorem [Fundamental Theorem]:

1. If \Gamma  ` T :: K and \Gamma  0 ` fl is ffi :: \Gamma  then \Gamma  0 ` flD^TE^ is ffiD^TE^ : K.
2. If \Gamma  ` S j T :: K and \Gamma  0 ` fl is ffi :: \Gamma  then \Gamma  0 ` flD^SE^ is ffiD^TE^ : K. 2
Proof: We proceed by induction on derivations. Most of the cases are exactly
the same (modulo the transition from a lambdangcalculus of terms to a lambdang
calculus of types) as the corresponding proof in Chapter 6. The cases for the
new rules QngDef and KngDef follow directly from our assumptions for fl and
ffi. The cases for KngAll and QngAll are similar to each other; we sketch just the
former.

Case QngAll: \Gamma  ` 8X::K1.T2 :: * because \Gamma  ; X::K1 ` T2 :: *.
Using the Main Lemma we have that \Gamma  0; X::K1 ` flE,X,XG* is ffiE,X,XG* : \Gamma  ; X::K1.
By the inductive hypothesis we have \Gamma  0; X::K1 ` D^flE,X,XG*E^T2 is D^ffiE,X,XG*E^T2 :
*. By the Main Lemma, \Gamma  0; X::K1 ` D^flE,X,XG*E^T2 a D^ffiE,X,XG*E^T2 : *. Thus \Gamma  0 `
flD^8X::K1.T2E^ $ ffiD^8X::K1.T2E^ : *. Universallyngquantified types are weak
head normal, so by the Main Lemma one last time, \Gamma  0 ` flD^8X::K1.T2E^ is
ffiD^8X::K1.T2E^ : *. 2

A Solutions to Selected Exercises 519

Because the definition for logical equivalence of substitutions has become
more involved, the fact that the identity substitution is logically related to
itself is no longer an immediate corollary of the Main Lemma.

A.5 Lemma: Let fl be the identity substitution. If \Gamma  ` \Pi  then \Gamma  ` fl is fl :: \Gamma  . 2

Proof: By induction on the proof of \Gamma  ` \Pi .
Case CTXngType: \Gamma  C^ \Gamma  0; x:T with \Gamma  0 ` \Pi .
By the inductive hypothesis.
Case CTXngKind: \Gamma  C^ \Gamma  0; X::K with \Gamma  0 ` \Pi .
By the inductive hypothesis we have that \Gamma  0 ` fl is fl :: \Gamma  0. By monotonicity,
\Gamma  ` fl is fl :: \Gamma  0. Finally, by the Main Lemma we have \Gamma  ` X is X :: K, so
\Gamma  ` fl is fl :: \Gamma  .

Case CTXngDef: \Gamma  C^ \Gamma  0; X::K=T with \Gamma  0 ` T :: K.
By the inductive hypothesis and monotonicity we again have \Gamma  ` fl is fl :: \Gamma  0.
By the Fundamental Theorem, \Gamma  ` T is T :: K. By weak head expansion,
then, \Gamma  ` X is T :: K, \Gamma  ` T is X :: K, and \Gamma  ` X is X :: K. Therefore,
\Gamma  ` fl is fl :: \Gamma  . 2

A.6 Corollary [Completeness]: If \Gamma  ` S :: K and \Gamma  ` T :: K and \Gamma  ` S j T :: K

then \Gamma  `n~ S a T :: K. 2

Proof: Apply the Fundamental Theorem with the identity substitution. 2
A.7 Corollary [Termination]: If \Gamma  ` S :: K and \Gamma  ` T :: K then \Gamma  `n~ S a T ::

K is decidable (i.e., deterministic proof search must always terminate with
success or failure). 2

Proof: By completeness we know that \Gamma  `n~ S a S :: K and that \Gamma  `n~ T a T ::
K. We can show by induction on the former algorithm that the comparison of
S and T must terminate. 2

9.1.9 Solution: As one example, the equivalence

X :: (*)*)*) = (*Y::(*)*). Y Nat) ` X(*Z::*.Z) j X(*Z::*.Nat)
is provable, because both sides are provably equivalent to Nat. However,
given the same definition for X we have X(*Z::*.Nat) 6j X(*Z::*.Bool).

Pfenning and Schu"rmann (1998) give a syntactic criterion for detecting a
collection of injective type operators that yield equivalent results only when
given equivalent arguments, and hence can be treated specially by an impleng
mentation.

520 A Solutions to Selected Exercises

9.2.1 Solution: An equivalent mostngprecise interface would be

\Pi m:(\Sigma m':L*M. L!m'M).

(\Sigma m":L*=!m.1 * !m.1M. L!m.1 * !m.1M),

which is a subinterface of infinitely many interfaces, including

\Pi m:(\Sigma m':L*M. L!m'M). (\Sigma m":L*M. L!m"M)
and

\Pi m:(\Sigma m':L*=NatM. LNatM). (\Sigma m":L*=Nat * NatM. LNat * NatM).

9.2.2 Solution: If Nat <: Top then we could allow LNatM <: LTopM in analogy with

depth subtyping for records. In contrast, the interfaces L*=NatM and L*=TopM
must be unrelated, because a module containing the type Nat is not a module
containing the type Top nor vice versa. To see what goes wrong, assume that
L*=NatM <: L*=TopM and let M be the module LNatM. Then M : L*=NatM, which
by subsumption would further yield M : L*=TopM. At this point, we could then
show that !M j Nat and !M j Top and hence that Nat j Top.

9.2.3 Solution: The module defined by

(*m : \Sigma m:L*M.L!mM). L L *X::*.(!m.1)::*)*M, !m.2 M
(L LNat::*M, L3::NatM M :> \Sigma m:L*M.L!mM)

or, using syntactic sugar,

let m = L LNat::*M, L3::NatM M :> \Sigma m:L*M.L!mM
in

L L *X::*.(!m.1)::*)*M, !m.2 M

satisfies the interface \Sigma m0:L*)*M. L(!m0)(Nat)M and more generally the inng
terface \Sigma m0:L*)*M. L(!m0)(T)M for any type T, but it satisfies no interface
that is a subinterface of all of these.

9.3.1 Solution: If Nat <: Top then we should expect S(Nat) and S(Top) to be

kinds unrelated in the subkinding hierarchy. All types of kind S(Nat) are
provably equivalent to Nat, and hence should not be provably equivalent to
Top. See also Exercise A.

9.3.7 Solution: We again proceed by induction on the size of K. Assume \Gamma  ` S ::

S(T :: K) and \Gamma  ` T :: K.

Case: K C^ *, so S(T::K) C^ S(T).
Then \Gamma  ` S j T :: S(T) by Rule QngSElim, and \Gamma  ` S(T) <: * by SKngForget, so
\Gamma  ` S j T :: * by Rule QngSub.

A Solutions to Selected Exercises 521
Case: K C^ S(U), so S(T::K) C^ S(T).
By Rule QngSElim we have \Gamma  ` S j T :: S(S). By Proposition 9.3.4(5), inversion
of KngSing, and SKngForget we have \Gamma  ` S(S) <: *, so \Gamma  ` S j T :: * by
QngSub. Since \Gamma  ` T :: S(U), by similar arguments we have \Gamma  ` T j U :: *
and so \Gamma  ` S j U :: * and \Gamma  ` S(S) <: S(U). Therefore by QngSub we have
\Gamma  ` S j T :: S(U) as required.

Case: K C^ \Pi X::K1.K2, so S(T::K) C^ \Pi X::K1.S(T X :: K2).
By Proposition 9.3.4(5) and inversion we have \Gamma  ; X::K1 ` \Pi , so by Proposing
tion 9.3.2(1) and KngApp, \Gamma  ; X::K1 ` S X :: S(T X :: K2). By the same reasoning
we have \Gamma  ; X::K1 ` T X :: K2. By the inductive hypothesis, \Gamma  ; X::K1 ` S X j
T X :: K2. Therefore, by Rule QngExt we have \Gamma  ` S j T :: \Pi X::K1.K2.

Case: K C^ \Sigma X::K1.K2, so S(T::K) C^ S(ss1 T :: K1) * S(ss2 T :: E,X , ss1 TG*K2)
By KngFst and KngSnd we have \Gamma  ` ss1 S :: S(ss1 T :: K1) and \Gamma  ` ss2 S ::
S(ss2 T :: E,X , ss1 TG*K2). Again by KngFst and KngSnd we have \Gamma  ` ss1 T :: K1
and \Gamma  ` ss2 T :: E,X , ss1 TG*K2, so by the inductive hypothesis we have we
have \Gamma  ` ss1 S j ss1 T :: K1 and and \Gamma  ` ss1 S j ss2 T :: E,X , ss 1 TG*K2). By
Rule QngPairngExt, therefore, we have \Gamma  ` S j T :: \Sigma X::K1.K2 as desired.

By the definitions in Figure 9ng9 it is possible for S(T::K) to be a wellng
formed kind even if T does not satisfy kind K; for example, take T C^ Nat and
K C^ S(Nat!Nat). Then we have \Gamma  ` Nat :: S(Nat::S(Nat!Nat)) but not
\Gamma  ` Nat j Nat :: S(Nat!Nat).

9.3.8 Solution: Using the properties of Fact 9.3.6, we can show the admissibility

of QngBetangFst.

\Gamma  ` T1 :: K1
\Gamma  ` T1 :: S(T1 :: K1) \Gamma  ` T2 :: S(T1 :: K2)

\Gamma  ` {T1,T2} :: S(T1 :: K1) * K2

\Gamma  ` ss1 {T1,T2} :: S(T1 :: K1)

\Gamma  ` ss1 {T1,T2} j T1 :: K1
The proof for QngBetangSnd is exactly analogous, and a similar idea works for
QngAppAbs:

\Gamma  ; X::K11 ` T12 :: K12
\Gamma  ; X::K11 ` T12 :: S(T12 :: K12)
\Gamma  ` D^*X::K11.T12E^ :: D^\Pi X::K11.S(T12 :: K12)E^ \Gamma  ` T2 :: K12

\Gamma  ` (*X::K11.T12)T2 :: S(E,X , T2G*T12 :: E,X , T2G*K12)

\Gamma  ` (*X::K11.T12)T2 j E,X , T2G*T12 :: E,X , T2G*K12

522 A Solutions to Selected Exercises

9.3.9 Solution: Let \Gamma 1 defC^ Y::(S(Nat))*))*. Then

Y::(S(Nat))*))* `n~ Y(*X::*.X) a Y(*X::*.Nat) :: *
because

* \Gamma 1 `n~ Y(*X::*.X) + Y(*X::*.X)

* \Gamma 1 `n~ Y(*X::*.Nat) + Y(*X::*.Nat)

* \Gamma 1 `n~ Y(*X::*.X) $ Y(*X::*.X) " *, because

- \Gamma 1 `n~ Y $ Y " (S(Nat))*))*, and
- \Gamma 1 `n~ *X::*.X a *X::*.Nat : S(Nat))*, because

* \Gamma 1; Z::S(Nat) `n~ (*X::*.X)Z a (*X::*.Nat)Z :: *, because

* \Gamma 1; Z::S(Nat) `n~ (*X::*.X)Z + Nat

* \Gamma 1; Z::S(Nat) `n~ (*X::*.Nat)Z + Nat

* \Gamma 1; Z::S(Nat) `n~ Nat $ Nat " *.

The analogous proof for Y::(*)*))* `n~ Y(*X::*.X) a Y(*X::*.Nat) ::
* fails because it requires proving Y::(*)*))*; Z::* `n~ (*X::*.X)Z a
(*X::*.Nat)Z :: * and hence that Y::(*)*))*; Z::* `n~ Z $ Nat " *.

9.3.11 Solution: The compilengtime part is

*Xm::* * K0. {(ss1 Xm) * (ss1 Xm), S0}
and the runngtime part is

*Xm::* * K0. *xm:T0 * (ss1 Xm). {t0, {xm.2, xm.2}}:
These perform the same computations as the intuitive phasengsplittings, but
take some useless arguments (e.g., the second argument of the type pair Xm
and the first argument of the pair xm) and return some useless results (S0
and t0).

9.3.14 Solution:

1. Terms containing local modules can be translated as

|let m=M in t| := let Xm = |M|c in

let xm = |M|r in

|t|.

Both let forms can be expressed as derived forms in *S, or one could
extend the language to make them primitive.

A Solutions to Selected Exercises 523

2. Adding a conditional module expression destroys the phase distinction,

because the types in a conditional module, e.g.

if ... then LNat::*M else LUnit::*M;
depends on the runngtime value of the test.
10.1.22 Solution: Within Damas and Milner's type system, we have:

dmngLet
dmngVar z

1 : X ` z1 : X z1 : X; z2 : X ` z2 : X

dmngVar

dmngAbs z1 : X ` let z2 C^ z1 in z2 : XIJ ` *z

1:let z2 C^ z1 in z2 : X ! X

Note that, because X occurs free within the environment z1 : X, it is impossible
to apply dmngGen to the judgment z1 : X ` z1 : X in a nontrivial way. For this
reason, z2 cannot receive the type scheme 8X:X, and the whole expression
cannot receive type X ! Y, where X and Y are distinct.

10.1.23 Solution: It is straightforward to prove that the identity function has type

int ! int:

\Gamma 0; z : int ` z : int dmngVar
\Gamma 0 ` *z:z : int ! int dmngAbs
In fact, nothing in this type derivation depends on the choice of int as the type
of z. Thus, we may just as well use a type variable X instead. Furthermore,
after forming the arrow type X ! X, we may employ dmngGen to quantify
universally over X, since X no longer appears in the environment.

dmngGen

dmngAbs

dmngVar

\Gamma 0; z : X ` z : X

\Gamma 0 ` *z:z : X ! X X 62 ftvD^\Gamma 0E^

\Gamma 0 ` *z:z : 8X:X ! X

It is worth noting that, although the type derivation employs an arbitrary
type variable X, the final typing judgment has no free type variables. It is thus
independent of the choice of X. In the following, we refer to the above type
derivation as \Delta 0.

Next, we prove that the successor function has type int ! int under the
initial environment \Gamma 0. We write \Gamma 1 for \Gamma 0; z : int, and make uses of dmngVar
implicit.

dmngApp
dmngApp

\Gamma 1 ` ^+ : int ! int ! int \Gamma 1 ` z : int

\Gamma 1 ` ^+ z : int ! int \Gamma 1 ` ^1 : int

dmngAbs

\Gamma 1 ` z ^+ ^1 : int

\Gamma 0 ` *z:z ^+ ^1 : int ! int

524 A Solutions to Selected Exercises

In the following, we refer to the above type derivation as \Delta 1. We may now
build a derivation for the third typing judgment. We write \Gamma 2 for \Gamma 0; f : int !
int.

\Delta 1

\Gamma 2 ` f : int ! int \Gamma 2 ` ^2 : int

\Gamma 2 ` f ^2 : int dmngApp
\Gamma 0 ` let f C^ *z:z ^+ ^1 in f ^2 : int dmngLet

To derive the fourth typing judgment, we renguse \Delta 0, which proves that the
identity function has polymorphic type 8X:X ! X. We write \Gamma 3 for \Gamma 0; f :
8X:X ! X. By dmngVar and dmngInst, we have both \Gamma 3 ` f : D^int ! intE^ !
D^int ! intE^ and \Gamma 3 ` f : int ! int. Thus, we may build the following derivation:

\Delta 0 dmngApp

dmngApp

\Gamma 3 ` f : D^int ! intE^ ! D^int ! intE^

\Gamma 3 ` f : int ! int

\Gamma 3 ` f f : int ! int \Gamma 3 ` ^2 : int

\Gamma 3 ` f f ^2 : int
\Gamma 0 ` let f C^ *z:z in f f ^2 : int dmngLet

The first and third judgments are valid in the simplyngtyped *ngcalculus, beng
cause they use neither dmngGen nor dmngInst, and use dmngLet only to introduce
the monomorphic binding f : int ! int into the environment. The second judgng
ment, of course, is not: because it involves a nontrivial type scheme, it is not
even a wellngformed judgment in the simplyngtyped *ngcalculus. The fourth judgng
ment is wellngformed, but not derivable, in the simplyngtyped *ngcalculus. This is
because f is used at two incompatible types, namely D^int ! intE^ ! D^int ! intE^
and int ! int, inside the expression f f ^2. Both of these types are instances of
8X:X ! X, the type scheme assigned to f in the environment \Gamma 3.

By inspection of the rules, a derivation of \Gamma 0 ` ^1 : T must begin with an
instance of dmngVar, of the form \Gamma 0 ` ^1 : int. It may be followed by an arbitrary
number of instances of the sequence (dmngGen; dmngInst), turning int into a
type scheme of the form 8_X:int, then back to int. Thus, T must be int. Because
int is not an arrow type, there follows that the application ^1 ^2 cannot be
wellngtyped under \Gamma 0. In fact, because this expression is stuck, it cannot be
wellngtyped in a sound type system.

The expression *f:D^f fE^ is illngtyped in the simplyngtyped *ngcalculus, because
no type T may coincide with a type of the form T ! T0: indeed, T would be
a subterm of itself. In DM, this expression is illngtyped as well, but the proof
of this fact is slightly more complex. One must point out that, because f
is *ngbound, it must be assigned a type T (as opposed to a type scheme) in
the environment. Furthermore, one must note that dmngGen is not applicable
(except in a trivial way) to the judgment \Gamma 0; f : T ` f : T, because all of the

A Solutions to Selected Exercises 525
type variables in the type T appear free in the environment \Gamma 0; f : T. Once these
points are made, the proof is the same as in the simplyngtyped *ngcalculus.

It is important to note that the above argument crucially relies on the fact
that f is *ngbound and must be assigned a type, as opposed to a type scheme.
Indeed, we have proved earlier in this exercise that the selfngapplication f f is
wellngtyped when f is letngbound and is assigned the type scheme 8X:X ! X.
For the same reason, *f:D^f fE^ is wellngtyped in an implicitlyngtyped variant of
System F. It also relies on the fact that types are finite: indeed, *f:D^f fE^ is wellng
typed in an extension of the simplyngtyped *ngcalculus with recursive types,
where the equation T C^ T ! T0 has a solution.

Later, we will develop a type inference algorithm for MLngthengtypengsystem
and prove that it is correct and complete. Then, to prove that a term is illng
typed, it will be sufficient to simulate a run of the algorithm and to check
that it reports a failure.

10.3.2 Solution: Our hypotheses are C; \Gamma  ` t : 8_XE,DG*:T (1) and C dh E,~X , ~TG*D (2).

We may also assume, w.l.o.g., _X # ftvD^C; \Gamma  ; ~TE^ (3). By hmxngInst and (1), we have
C ^D; \Gamma  ` t : T, which by Lemma 10.3.1 yields C ^D ^~X C^ ~T; \Gamma  ` t : T (4). Now,
we claim that ~X C^ ~T dh T <= E,~X , ~TG*T (5) holds; the proof appears in the next
paragraph. Applying hmxngSub to (4) and to (5), we obtain C ^ D ^ ~X C^ ~T; \Gamma  `
t : E,~X , ~TG*T (6). By CngEq and by (2), we have C ^ ~X C^ ~T dh D, so (6) may be
written C ^ ~X C^ ~T; \Gamma  ` t : E,~X , ~TG*T (7). Last, (3) implies _X # ftvD^\Gamma  ; E,~X , ~TG*TE^ (8).
Applying rule hmxngExists to (7) and (8), we get 9_X:D^C ^ ~X C^ ~TE^; \Gamma  ` t : E,~X ,
~TG*T (9). By CngNameEq and by (3), 9_X:D^C ^ ~X C^ ~TE^ is equivalent to C, hence (9)

is the goal C; \Gamma  ` t : E,~X , ~TG*T.

There now remains to establish (5). One possible proof method is to unfold
the definition of dh and reason by structural induction on T. Here is another,
axiomatic approach. Let Z be fresh for T, ~X, and ~T. By reflexivity of subtyping
and by CngExTrans, we have true j T <= T j 9Z:D^T <= Z ^ Z <= TE^, which by
congruence of j and by CngExAnd implies ~X C^ ~T j 9Z:D^T <= Z ^ ~X C^ ~T ^ Z <=
TE^ (10). Furthermore, by CngEq, we have D^~X C^ ~T ^ Z <= TE^ j D^~X C^ ~T ^ Z <= E,~X ,
~TG*TE^ dh D^Z <= E,~X , ~TG*TE^ (11). Combining (10) and (11) yields ~X C^ ~T dh 9Z:D^T <=

Z ^ Z <= E,~X , ~TG*TE^, which by CngExTrans may be read ~X C^ ~T dh T <= E,~X , ~TG*T.

10.3.3 Solution: The simplest possible derivation of true; IJ ` *z:z : int ! int is

syntaxngdirected. It closely resembles the DamasngMilner derivation given in
Exercise 10.1.23.

true; z : int ` z : int hmxngVar
true; IJ ` *z:z : int ! int hmxngAbs

As in Exercise 10.1.23, we may use a type variable X instead of the type int,

526 A Solutions to Selected Exercises

then employ hmxngGen to quantify universally over X.

true; z : X ` z : X hmxngVar
true; IJ ` *z:z : X ! X hmxngAbs X # ftvD^true; IJE^

true; IJ ` *z:z : 8XE,trueG*:X ! X hmxngGen

The validity of this instance of hmxngGen relies on the equivalence true^true j
true and on the fact that judgments are identified up to equivalence of their
constraint assumptions.

If we now wish to instantiate X with int, we may use hmxngInst' as follows:

true; IJ ` *z:z : 8XE,trueG*:X ! X true dh E,X , intG*true

true; IJ ` *z:z : int ! int hmxngInst'

This is not, strictly speaking, an HMD^XE^ derivation, since hmxngInst' is not
part of the rules of Figure 10ng7. However, since the proof of Lemma 10.3.1
and the solution of Exercise 10.3.2 are constructive, it is possible to exhibit
the HMD^XE^ derivation that underlies it. We find:

Y C^ int; z : X ` z : X hmxngVar
Y C^ int; IJ ` *z:z : X ! X hmxngAbs
Y C^ int; IJ ` *z:z : 8X:X ! X hmxngGen

Y C^ int; IJ ` *z:z : Y ! Y hmxngInst
Y C^ int dh Y ! Y <= int ! int

Y C^ int; IJ ` *z:z : int ! int hmxngSub
9Y:D^Y C^ intE^; IJ ` *z:z : int ! int hmxngExists

Since 9Y:D^Y C^ intE^ is equivalent to true, the conclusion is indeed the desired
judgment.

10.4.1 Solution: Let X 62 ftvD^\Gamma  E^ (1). Assume that there exist a satisfiable constraint

C and a type T such that C; \Gamma  ` t : T (2) holds. Thanks to (1), we find that,
up to a renaming of C and T, we may further assume X 62 ftvD^C; TE^ (3). Then,
applying Lemma 10.3.1 to (2), we obtain C ^ T C^ X; \Gamma  ` t : T, which by hmxng
Sub yields C ^ T C^ X; \Gamma  ` t : X (4). Furthermore, by (3) and CngNameEq, we have
9X:D^C ^ T C^ XE^ j C. Because C is satisfiable, this implies that C ^ T C^ X is
satisfiable as well. As a result, we have found a satisfiable constraint C0 such
that C0; \Gamma  ` t : X holds.

Now, assume \Gamma  is closed and X is arbitrary. Then, (1) holds, so the previous
paragraph proves that, if t is wellngtyped within \Gamma  , then there exists a satisfing
able constraint C0 such that C0; \Gamma  ` t : X holds. By the completeness property,

A Solutions to Selected Exercises 527
we must then have C0 dh J\Gamma  ` t : XK. Since C0 is satisfiable, this implies that
J\Gamma  ` t : XK is satisfiable as well. Conversely, if J\Gamma  ` t : XK is satisfiable, then,
by the soundness property, t is wellngtyped within \Gamma  .

10.7.1 Solution: We have

let \Gamma 0 in Jc t1 : : : tn : T0K
j let \Gamma 0 in 9Z1 : : : Zn:D^VniC^1Jti : ZiK ^ c _ Z1 ! : : : ! Zn ! T0E^ (1)
j let \Gamma 0 in 9Z1 : : : Zn_X:D^VniC^1Jti : ZiK

^ T1 ! : : : ! Tn ! T <= Z1 ! : : : ! Zn ! T0E^

(2)

j let \Gamma 0 in 9_X:D^VniC^1Jti : TiK ^ T <= T0E^ (3)
where (1) is by definition of constraint generation; (2) is by CngInId; (3) is by
CngArrow, CngExAnd, and by Lemma 10.4.6.

10.7.2 Solution: We must first ensure that RngAdd respects v (Definition 10.5.4).

Since the rule is pure, it is sufficient to establish that let \Gamma 0 in J^n1 ^+ ^n2 : TK
entails let \Gamma 0 in J "n1 + n2 : TK. In fact, we have

let \Gamma 0 in J^n1 ^+ ^n2 : TK
j let \Gamma 0 in D^J^n1 : intK ^ J^n2 : intK ^ int <= TE^ (1)
j let \Gamma 0 in D^int <= int ^ int <= int ^ int <= TE^ (2)
j int <= T (3)
j let \Gamma 0 in J "n1 + n2 : TK (4)

where (1) and (2) are by Exercise 10.7.1; (3) is by CngIn* and by reflexivity of
subtyping; (4) is by Exercise 10.7.1 again.

Second, we must check that if the configuration c v1 : : : vk=u (where k >= 0)
is wellngtyped, then either it is reducible, or c v1 : : : vk is a value.

We begin by checking that every value that is wellngtyped with type int is of
the form ^n. Indeed, suppose that let \Gamma 0; ref M in Jv : intK is satisfiable. Then, v
cannot be a program variable, for a wellngtyped value must be closed. v cannot
be a memory location m, for otherwise ref MD^mE^ <= int would be satisfiable--
but the type constructors ref and int are incompatible. v cannot be ^+ or ^+ v0,
for otherwise int ! int ! int <= int or int ! int <= int would be satisfiable--but
the type constructors ! and int are incompatible. Similarly, v cannot be a
*ngabstraction. Thus, v must be of the form ^n, for it is the only case left.

Next, we note that, according to the constraint generation rules, if the
configuration c v1 : : : vk=u is wellngtyped, then a constraint of the form
let \Gamma 0; ref M in D^c _ X1 ! : : : ! Xk ! T ^ Jv1 : X1K ^ : : : ^ Jvk : XkKE^ is satisfiable.
We now reason by cases on c.

ffi Case c is ^n. Then, \Gamma 0D^cE^ is int. Because the type constructors int and !
are incompatible with each other, this implies k C^ 0. Since ^n is a constructor,
the expression is a value.

528 A Solutions to Selected Exercises

ffi Case c is ^+. We may assume k >= 2, because otherwise the expression is
a value. Then, \Gamma 0D^cE^ is int ! int ! int, so, by CngArrow, the above constraint
entails let \Gamma 0; ref M in D^X1 <= int ^ X2 <= int ^ Jv1 : X1K ^ Jv2 : X2KE^, which, by
Lemma 10.4.5, entails let \Gamma 0; ref M in D^Jv1 : intK ^ Jv2 : intKE^. Thus, v1 and
v2 are wellngtyped with type int. By the remark above, they must be integer
literals ^n1 and ^n2. As a result, the configuration is reducible by RngAdd.

10.7.5 Solution: We must first ensure that RngRef, RngDeref and RngAssign respect v

(Definition 10.5.4).

ffi Case RngRef. The reduction is ref v=IJ -! m=D^m , vE^, where m 62 fpiD^vE^ (1).
Let T be an arbitrary type. According to Definition 10.5.4, the goal is to show
that there exist a set of type variables _Y and a store type M0 such that
_Y # ftvD^TE^ and ftvD^M0E^ ` _Y and domD^M0E^ C^ {m} and let \Gamma 0 in Jref v : TK

entails 9_Y:let \Gamma 0; ref M0 in Jm=D^m , vE^ : T=M0K. Now, we have

let \Gamma 0 in Jref v : TK
j 9Y:let \Gamma 0 in D^ref Y <= T ^ Jv : YKE^ (2)
j 9Y:let \Gamma 0; ref M0 in D^m _ T ^ Jv : M0D^mE^KE^ (3)
j 9Y:let \Gamma 0; ref M0 in Jm=D^m , vE^ : T=M0K (4)

where (2) is by Exercise 10.7.1 and by CngInEx; (3) assumes M0 is defined as
m , Y, and follows from (1), CngInId and CngIn*; and (4) is by definition of
constraint generation.

ffi Case RngDeref. The reduction is !m=D^m , vE^ -! v=D^m , vE^. Let T be an
arbitrary type and let M be a store type of domain {m}. We have

let \Gamma 0; ref M in J!m=D^m , vE^ : T=MK
j let \Gamma 0; ref M in 9Y:D^ref MD^mE^ <= ref Y ^ Y <= T ^ Jv : MD^mE^KE^ (1)
j let \Gamma 0; ref M in 9Y:D^MD^mE^ C^ Y ^ Y <= T ^ Jv : MD^mE^KE^ (2)
j let \Gamma 0; ref M in D^MD^mE^ <= T ^ Jv : MD^mE^KE^ (3)
dh let \Gamma 0; ref M in D^Jv : TK ^ Jv : MD^mE^KE^ (4)
j let \Gamma 0; ref M in Jv=D^m , vE^ : T=MK (5)

where (1) is by Exercise 10.7.1 and by CngInId; (2) follows from CngExTrans and
from the fact that ref is an invariant type constructor; (3) is by CngNameEq;
(4) is by Lemma 10.4.5 and CngDup; and (5) is again by definition of constraint
generation.

ffi Case RngAssign. The reduction is m :C^ v=D^m , v0E^ -! v=D^m , vE^. Let T

A Solutions to Selected Exercises 529
be an arbitrary type and let M be a store type of domain {m}. We have

let \Gamma 0; ref M in Jm :C^ v=D^m , v0E^ : T=MK
dh let \Gamma 0; ref M in Jm :C^ v : TK (1)
j let \Gamma 0; ref M in 9Z:D^ref MD^mE^ <= ref Z ^ Jv : ZK ^ Z <= TE^ (2)
j let \Gamma 0; ref M in 9Z:D^MD^mE^ C^ Z ^ Z <= T ^ Jv : ZKE^ (3)
j let \Gamma 0; ref M in D^MD^mE^ <= T ^ Jv : MD^mE^KE^ (4)
dh let \Gamma 0; ref M in Jv=D^m , vE^ : T=MK (5)

where (1) is by definition of constraint generation; (2) is by Exercise 10.7.1
and CngInId; (3) follows from the fact that ref is an invariant type constructor;
(4) is by CngNameEq; and (5) is obtained as in the previous case.

Second, we must check that if the configuration c v1 : : : vk=u (where k >= 0)
is wellngtyped, then either it is reducible, or c v1 : : : vk is a value. We only
give a sketch of this proof; see the solution to Exercise 10.7.2 for details of a
similar proof.

We begin by checking that every value that is wellngtyped with a type of the
form ref T is a memory location. This assertion relies on the fact that the type
constructor ref is isolated.

Next, we note that, according to the constraint generation rules, if the
configuration c v1 : : : vk=u is wellngtyped, then a constraint of the form
let \Gamma 0; ref M in D^c _ X1 ! : : : ! Xk ! T ^ Jv1 : X1K ^ : : : ^ Jvk : XkKE^ is satisfiable.
We now reason by cases on c.

ffi Case c is ref. If k C^ 0, then the expression is a value; otherwise, it is
reducible by RngRef.

ffi Case c is !. We may assume k >= 1; otherwise the expression is a value.
By definition of \Gamma 0D^!E^, the above constraint entails let \Gamma 0; ref M in 9Y:D^ref Y !
Y <= X1 ! : : : ! Xk ! T ^ Jv1 : X1KE^, which, by CngArrow, Lemma 10.4.5, and
CngInEx, entails 9Y:let \Gamma 0; ref M in Jv1 : ref YK. Thus, v1 is wellngtyped with a
type of the form ref Y. By the remark above, v1 must be a memory location
m. Furthermore, because every wellngtyped configuration is closed, m must
be a member of domD^uE^. As a result, the configuration ref v1 : : : vk=u is
reducible by RngDeref.

ffi Case c is :C^. We may assume k >= 2, because otherwise the expression is a
value. As above, we check that v1 must be a memory location and a member
of domD^uE^. Thus, the configuration is reducible by RngAssign.

10.8.2 Solution: The record access operation *:h`bi may be given the type scheme

8Xb:{`b : Xb} ! Xb. However, this type scheme isn't satisfactory, because it
allows accessing `b only in records where `a and `c are undefined. The type
scheme 8XaXb:{`a : Xa; `b : Xb} ! Xb is also a valid type scheme for *:h`bi,

530 A Solutions to Selected Exercises

but allows accessing `b only in records where `a is defined and `c is not. To
sum up, a satisfactory description of *:h`bi requires a whole family of type
schemes, none of which is principal (more general than the others). A similar
problem arises with record extension h* with `b C^ *i.

A potential solution is to equip record types with a subtyping relationship,
so that (say) both {`a : Ta; `b : Tb} and {`a : Ta; `b : Tb; `c : Tc} are subtypes
of {`b : Tb}. Then, 8Xb:{`b : Xb} ! Xb becomes a satisfactory type scheme for
the record access operation *:h`bi. Indeed, the operation is now applicable
to any record that admits a type of the form {`b : Tb}, that is, thanks to
subtyping, to any record where `b is defined, regardless of which other fields
are defined.

However, this is only half a solution, because there still is a problem with
record extension. The type scheme 8Xb:{`b : Xb} ! {`b : Xb} is valid, and
makes record extension applicable to any record where `b is defined, which
is good. The trouble is with its return type: it states that only `b may be
safely assumed to be defined in the new record. In other words, it causes
static information about all fields other than `b to be lost. Addressing this
dramatic loss of precision is one of the key motivations for introducing rows.

10.8.5 Solution: We let the reader check that X must have kind ?:Type and Y must

have kind ?:RowD^{`}E^. The type with all superscripts made explicit is

X !Type \Pi  D^`?;RowD^IJE^ : intType ; D^Y !RowD^{`}E^ @?;RowD^{`}E^XE^E^:
In this case, because the type constructor \Pi  occurs on the rightnghand side
of the toplevel arrow, it is possible to guess that the type must have kind
?:Type. There are cases where it is not possible to guess the kind of a type,
because it may have several kinds; consider, for instance, @int.

10.8.27 Solution: For the sake of generality, we perform the proof in the presence of

subtyping, that is, we do not assume that subtyping is interpreted as equality.
We formulate some hypotheses about the interpretation of subtyping: the
type constructors D^` : * ; *E^, @, and \Pi  must be covariant; the type constructors
! and \Pi  must be isolated.

We begin with a preliminary fact: if the domain of V is {`1; : : : ; `n}, where
`1 < : : : < `n, then the constraint let \Gamma 0 in J{V; v} : TK is equivalent to
let \Gamma 0 in 9Z1 : : : ZnZ:D^VniC^1JVD^`iE^ : ZiK ^ Jv : ZK ^ \Pi  D^`1 : Z1; : : : ; `n : Zn; @ZE^ <= TE^.
We let the reader check this fact using the constraint generation rules, the
definition of \Gamma 0 and rule CngInId, and the above covariance hypotheses. We
note that, by CngRowngLL, the above constraint is invariant under a permutang
tion of the labels `1; : : : ; `n, so the above fact still holds when the hypothesis
`1 < : : : < `n is removed.

A Solutions to Selected Exercises 531

We now prove that rules RngUpdate, RngAccessng1, and RngAccessng2 enjoy subng
ject reduction (Definition 10.5.4). Because the store is not involved, the goal
is to establish that let \Gamma 0 in Jt : TK entails let \Gamma 0 in Jt0 : TK, where t is the redex
and t0 is the reduct.

ffi Case RngUpdate. We have:

let \Gamma 0 in J{{V; v} with ` C^ v0} : TK
j let \Gamma 0 in 9XX0Y:D^J{V; v} : \Pi  D^` : X ; YE^K ^ Jv0 : X0K ^ \Pi  D^` : X0 ; YE^ <= TE^ (1)
j let \Gamma 0 in 9XX0YZ1 : : : ZnZ:D^VniC^1JVD^`iE^ : ZiK ^ Jv : ZK

^ \Pi  D^`1 : Z1; : : : ; `n : Zn; @ZE^ <= \Pi  D^` : X ; YE^
^ Jv0 : X0K ^ \Pi  D^` : X0 ; YE^ <= TE^

(2)

where (1) is by Exercise 10.7.1, and (2) follows from the preliminary fact and
from CngExAnd, provided {`1; : : : ; `n} is the domain of V. We now distinguish
two subcases:

Subcase ` 2 domD^VE^. We may assume, w.l.o.g., that ` is `1. Then, by our
covariance hypotheses, the subconstraint in the second line of (2) entails
D^`2 : Z2; : : : ; `n : Zn; @ZE^ <= Y, which in turn entails \Pi  D^`1 : X0; `2 : Z2; : : : ; `n :
Zn; @ZE^ <= \Pi  D^` : X0 ; YE^. By transitivity of subtyping, the subconstraint in the
second and third lines of (2) entails \Pi  D^`1 : X0; `2 : Z2; : : : ; `n : Zn; @ZE^ <= T. By
this remark and by CngEx*, (2) entails

let \Gamma 0 in 9X0Z2 : : : ZnZ:D^Jv0 : X0K ^ VniC^2JVD^`iE^ : ZiK ^ Jv : ZK

^ \Pi  D^`1 : X0; `2 : Z2; : : : ; `n : Zn; @ZE^ <= TE^

(3)

which by our preliminary fact is precisely let \Gamma 0 in J{VE,` , v0G*; v} : TK.

Subcase ` AE domD^VE^. By CngRowngDL and CngRowngLL, the term D^`1 : Z1; : : : ; `n :
Zn; @ZE^ may be replaced with D^` : Z; `1 : Z1; : : : ; `n : Zn; @ZE^. Thus, reasoning as
in the previous subcase, we find that (2) entails

let \Gamma 0 in 9X0Z1 : : : ZnZ:D^Jv0 : X0K ^ VniC^1JVD^`iE^ : ZiK ^ Jv : ZK

^ \Pi  D^`1 : X0; `1 : Z1; : : : ; `n : Zn; @ZE^ <= TE^

(4)

which by our preliminary fact is precisely let \Gamma 0 in J{VE,` , v0G*; v} : TK.

ffi Cases RngAccessng1, RngAccessng2. We have:

let \Gamma 0 in J{V; v}:{`} : TK
j let \Gamma 0 in 9XY:D^J{V; v} : \Pi  D^` : X ; YE^K ^ X <= TE^ (1)
j let \Gamma 0 in 9XYZ1 : : : ZnZ:D^VniC^1JVD^`iE^ : ZiK ^ Jv : ZK

^ \Pi  D^`1 : Z1; : : : ; `n : Zn; @ZE^ <= \Pi  D^` : X ; YE^
^ X <= TE^

(2)

where (1) is by Exercise 10.7.1, and (2) follows from the preliminary fact and
from CngExAnd, provided {`1; : : : ; `n} is the domain of V. We now distinguish
two subcases:

532 A Solutions to Selected Exercises

Subcase ` 2 domD^VE^, i.e., (RngAccessng1). We may assume, w.l.o.g., that ` is
`1. Then, by our covariance hypotheses, the subconstraint in the second line
of (2) entails Z1 <= X. By transitivity of subtyping, by Lemma 10.4.5, and by
CngEx*, we find that (2) entails let \Gamma 0 in JVD^`E^ : TK.

Subcase ` AE domD^VE^, i.e., (RngAccessng2). By CngRowngDL and CngRowngLL, the
term D^`1 : Z1; : : : ; `n : Zn; @ZE^ may be replaced with D^` : Z; `1 : Z1; : : : ; `n :
Zn; @ZE^. Thus, reasoning as in the previous subcase, we find that (2) entails
let \Gamma 0 in Jv : TK.

Before attacking the proof of the progress property, let us briefly check that
every value v that is wellngtyped with type \Pi  T must be a record value, that is,
must be of the form {V; w}. Indeed, assume that let \Gamma 0; ref M in Jv : \Pi  TK
is satisfiable. Then, v cannot be a program variable, for a wellngtyped value
must be closed. Furthermore, v cannot be a memory location m, because
ref MD^mE^ <= \Pi  T is unsatisfiable: indeed, the type constructors ref and \Pi 
are incompatible (recall that \Pi  is isolated). Similarly, v cannot be a partially
applied constant or a *ngabstraction, because T0 ! T00 <= \Pi  T is unsatisfiable.
Thus, v must be a fully applied constructor. Since the only constructors in
the language are the record constructors {}L, v must be a record value. (If
there were other constructors in the language, they could be ruled out as
well, provided their return types are incompatible with \Pi .)

We must now prove that if the configuration c v1 : : : vk=u is is wellngtyped,
then either it is reducible, or c v1 : : : vk is a value. By the wellngtypedness hyng
pothesis, a constraint of the form let \Gamma 0; ref M in Jc v1 : : : vk : TK is satisfiable.

ffi Case c is {}L. If k is less than or equal to n + 1, where n is the cardinal
of L, then c v1 : : : vk is a value. Otherwise, unfolding the above constraint,
we find that it cannot be satisfiable, because \Pi  and ! are incompatible; this
yields a contradiction.

ffi Case c is {* with ` C^ *}. Analogous to the next case.
ffi Case c is *:{`}. If k C^ 0, then c v1 : : : vk is a value. Assume k >= 1. Then,
the constraint let \Gamma 0; ref M in Jc v1 : TK is satisfiable. By Exercise 10.7.1, this
implies that let \Gamma 0; ref M in Jv1 : \Pi  D^` : X ; YE^K is satisfiable. Thus, v1 must be a
record value, and the configuration is reducible by RngAccessng1 or RngAccessng2.

10.8.33 Solution: To make extension strict, it suffices to restrict its binding in the

initial environment \Gamma 0, as follows:

h* with ` C^ *i : 8XY:\Pi  D^` : abs ; YE^ ! X ! \Pi  D^` : pre X ; YE^:
The new binding, which is less general than the former, requires the field `
to be absent in the input record. The operational semantics need not be modng
ified, since strict extension coincides with free extension when it is defined.

A Solutions to Selected Exercises 533

Defining the operational semantics of (free) restriction is left to the reader.
Its binding in the initial environment should be:

* \ h`i : 8XY:\Pi  D^` : X ; YE^ ! \Pi  D^` : abs ; YE^
In principle, there is no need to guess this binding: it may be discovered
through the encoding of finite records in terms of full records (10.8.32). Strict
restriction, which requires the field to be present in the input record, may be
assigned the following type scheme:

* \ h`i : 8XY:\Pi  D^` : pre X ; YE^ ! \Pi  D^` : abs ; YE^
10.8.34 Solution: The informal sentence "supplying a record with more fields in a

context where a record with fewer fields is expected" may be understood as
"providing an argument of type \Pi  D^` : pre T ; T0E^ to a function whose domain
type is \Pi  D^` : abs ; T0E^," or, more generally, as "writing a program whose
wellngtypedness requires some constraint of the form \Pi  D^` : pre T ; T0E^ <= \Pi 
D^` : abs ; T0E^ to be satisfiable." Now, in a nonstructural subtyping order where
pre a` abs holds, such a constraint is equivalent to true. On the opposite, if
subtyping is interpreted as equality, then such a constraint is equivalent to
false. In other words, it is the law pre T <= abs j true that gives rise to width
subtyping.

It is worth drawing a comparison with the way width subtyping is defined in
type systems that do not have rows. In such type systems, a record type is of
the form {`1 : T1; : : : ; `n : Tn}. Let us forget about the types T1; : : : ; Tn, because
they describe the contents of fields, not their presence, and are thus orthogng
onal to the issue at hand. Then, a record type is a set {`1; : : : ; `n}, and width
subtyping is obtained by letting subtyping coincide with (the reverse of) set
containment. In a type system that exploits rows, on the other hand, a record
type is a total mapping from row labels to either pre or abs. (Because we are
ignoring T1; : : : ; Tn, let us temporarily imagine that pre is a nullary type conng
structor.) The above record type is then written {`1 : pre; : : : ; `n : pre; @abs}.
In other words, a set is now encoded as its characteristic function. Width subng
typing is obtained by letting pre a` abs and by lifting this ordering, pointwise,
to rows (which corresponds to our convention that rows are covariant).

References
Abadi, Marti'n, Luca Cardelli, PierrengLouis Curien, and JeanngJacques Le'vy. Explicit subng

stitutions. Journal of Functional Programming, 1(4):375-416, 1991. Summary in
ACM Symposium on Principles of Programming Languages (POPL), San Francisco,
California, 1990.

Adams, Rolf, Walter Tichy, and Annette Weinert. The cost of selective recompilang

tion and environment processing. ACM Transactions on Software Engineering and
Methodology, 3(1):3-28, January 1994.

Ahmed, Amal, Limin Jia, and David Walker. Reasoning about hierarchical storage.

In IEEE Symposium on Logic in Computer Science (LICS), Ottawa, Canada, pages
33-44, June 2003.

Ahmed, Amal and David Walker. The logical approach to stack typing. In ACM SIGng

PLAN Workshop on Types in Language Design and Implementation (TLDI), New
Orleans, Louisiana, pages 74-85, January 2003.

Aho, Alfred V., Ravi Sethi, and Jeffrey D. Ullman. Compilers: Principles, Techniques,

and Tools. AddisonngWesley, Reading, Massachusetts, 1986.

Aiken, Alexander, Manuel Fa"hndrich, and Raph Levien. Better static memory manng

agement: Improving regionngbased analysis of higherngorder languages. In ACM SIGng
PLAN Conference on Programming Language Design and Implementation (PLDI),
La Jolla, California, pages 174-185, June 1995.

Aiken, Alexander, Jeffrey S. Foster, John Kodumal, and Tachio Terauchi. Checking

and inferring local nonngaliasing. In ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI), San Diego, California, pages 129-140,
June 2003.

Aiken, Alexander and Edward L. Wimmers. Solving systems of set constraints. In

IEEE Symposium on Logic in Computer Science (LICS), Santa Cruz, California, pages
329-340, June 1992.

536 References

Aiken, Alexander and Edward L. Wimmers. Type inclusion constraints and type inferng

ence. In ACM Symposium on Functional Programming Languages and Computer
Architecture (FPCA), Copenhagen, Denmark, pages 31-41, June 1993.

Altenkirch, Thorsten. Constructions, Inductive Types and Strong Normalization. PhD

thesis, Laboratory for Foundations of Computer Science, University of Edinburgh,
Edinburgh, Scotland, 1993.

Amadio, Roberto M. and Luca Cardelli. Subtyping recursive types. ACM Transacng

tions on Programming Languages and Systems, 15(4):575-631, 1993. Summary
in ACM Symposium on Principles of Programming Languages (POPL), Orlando,
Florida, pp. 104-118; also DEC/Compaq Systems Research Center Research Report
number 62, August 1990.

Amtoft, Torben, Flemming Nielson, and Hanne Riis Nielson. Type and Effect Systems:

Behaviours for Concurrency. Imperial College Press, 1999.

Ancona, Davide and Elena Zucca. A theory of mixin modules: Basic and derived opng

erators. Mathematical Structures in Computer Science, 8(4):401-446, August 1998.

Ancona, Davide and Elena Zucca. A calculus of module systems. Journal of Functional

Programming, 12(2):91-132, March 2002.

Appel, Andrew W. Foundational proofngcarrying code. In IEEE Symposium on Logic in

Computer Science (LICS), Boston, Massachusetts, pages 247-258, June 2001.

Appel, Andrew W. and Amy P. Felty. A semantic model of types and machine instrucng

tions for proofngcarrying code. In ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages (POPL), Boston, Massachusetts, pages 243-253, January
2000.

Aspinall, David. Subtyping with singleton types. In International Workshop on Comng

puter Science Logic (CSL), Kazimierz, Poland, volume 933 of Lecture Notes in Comng
puter Science, pages 1-15. SpringerngVerlag, September 1994.

Aspinall, David and Martin Hofmann. Another type system for inngplace update. In

European Symposium on Programming (ESOP), Grenoble, France, volume 2305 of
Lecture Notes in Computer Science, pages 36-52. SpringerngVerlag, April 2002.

Augustsson, Lennart. Cayenne--A language with dependent types. In ACM SIGPLAN

International Conference on Functional Programming (ICFP), Baltimore, Maryland,
pages 239-250, 1998.

Baader, Franz and Jo"rg Siekmann. Unification theory. In D. M. Gabbay, C. J. Hogger,

and J. A. Robinson, editors, Handbook of Logic in Artificial Intelligence and Logic
Programming, volume 2, Deduction Methodologies, pages 41-125. Oxford Univerng
sity Press, 1994.

Baker, Henry G. Lively linear Lisp--look ma, no garbage! ACM SIGPLAN Notices, 27

(8):89-98, 1992.

Barendregt, Henk P. The Lambda Calculus. North Holland, revised edition, 1984.
Barendregt, Henk P. Introduction to generalized type systems. Journal of Functional

Programming, 1(2):125-154, 1991.

References 537
Barendregt, Henk P. Lambda calculi with types. In S. Abramsky, D. M. Gabbay, and

T. Maibaum, editors, Handbook of Logic in Computer Science, volume 2, Computang
tional Structures. Oxford University Press, 1992.

Barendsen, Erik and Sjaak Smetsers. Conventional and uniqueness typing in graph

rewrite systems. In Foundations of Software Technology and Theoretical Computer
Science (FSTTCS), Bombay, India, volume 761 of Lecture Notes in Computer Science,
pages 41-51. SpringerngVerlag, December 1993.

Barras, Bruno, Samuel Boutin, Cristina Cornes, Judicael Courant, JeanngChristophe

Filliatre, Eduardo Gimenez, Hugo Herbelin, Gerard Huet, Cesar Munoz, Chetan
Murthy, Catherine Parent, Christine PaulinngMohring, Amokrane Saibi, and Benjamin
Werner. The Coq proof assistant reference manual: Version 6.1. Technical Report
RTng0203, INRIA, 1997.

Bauer, Lujo, Andrew W. Appel, and Edward W. Felten. Mechanisms for secure modular

programming in Java. Technical Report TRng603ng99, Princeton University, 1999.

Bellantoni, Stephan and Stephan Cook. A new recursionngtheoretic characterization of

polytime functions. Computational Complexity, 2(2):97-110, 1992.

Bellantoni, Stephan, K.ngH. Niggl, and H. Schwichtenberg. Higher type recursion, raming

fication and polynomial time. Annals of Pure and Applied Logic, 104:17-30, 2000.

Berardi, Stefano. Towards a mathematical analysis of the CoquandngHuet calculus

of constructions and the other systems in Barendregt's cube. Technical report,
Department of Computer Science, CMU, and Dipartimento Matematica, Universita
di Torino, 1988.

Berthomieu, Bernard. Tagged types: A theory of order sorted types for tagged expresng

sions. Research Report 93083, LAAS, 7, avenue du Colonel Roche, 31077 Toulouse,
France, March 1993.

Berthomieu, Bernard and Camille le Monie`s de Sagazan. A calculus of tagged types,

with applications to process languages. In Workshop on Types for Program Analysis
(TPA), informal proceedings, pages 1-15, May 1995.

Biagioni, Edoardo, Nicholas Haines, Robert Harper, Peter Lee, Brian G. Milnes, and

Eliot B. Moss. Signatures for a protocol stack: A systems application of Stanng
dard ML. In ACM Symposium on Lisp and Functional Programming (LFP), Orlando,
Florida, pages 55-64, June 1994.

Bierman, G. M., A. M. Pitts, and C. V. Russo. Operational properties of Lily, a polymorng

phic linear lambda calculus with recursion. In Workshop on Higher Order Operang
tional Techniques in Semantics (HOOTS), Montre'al, Que'bec, volume 41 of Electronic
Notes in Theoretical Computer Science. Elsevier, September 2000.

Birkedal, Lars and Robert W. Harper. Constructing interpretations of recursive types

in an operational setting. Information and Computation, 155:3-63, 1999.

Birkedal, Lars and Mads Tofte. A constraintngbased region inference algorithm. Theong

retical Computer Science, 258:299-392, 2001.

538 References

Birkedal, Lars, Mads Tofte, and Magnus Vejlstrup. From region inference to von Neung

mann machines via region representation inference. In ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages (POPL), St. Petersburg Beach,
Florida, pages 171-183, 1996.

Blume, Matthias. The SML/NJ Compilation and Library Manager, May 2002. Available

from http://www.smlnj.org/doc/CM/index.html.

Blume, Matthias and Andrew W. Appel. Hierarchical modularity. ACM Transactions

on Programming Languages and Systems, 21(4):813-847, 1999.

Bonniot, Daniel. Typengchecking multingmethods in ML (a modular approach). In Interng

national Workshop on Foundations of ObjectngOriented Languages (FOOL), informal
proceedings, January 2002.

Bourdoncle, Franc,ois and Stephan Merz. Typengchecking higherngorder polymorphic

multingmethods. In ACM SIGPLAN-SIGACT Symposium on Principles of Programng
ming Languages (POPL), Paris, France, pages 302-315, January 1997.

Bracha, Gilad and William R. Cook. Mixinngbased inheritance. In ACM SIGPLAN Conferng

ence on Object Oriented Programming: Systems, Languages, and Applications (OOPng
SLA)/European Conference on ObjectngOriented Programming (ECOOP), Ottawa, Onng
tario, pages 303-311, October 1990.

Brandt, Michael and Fritz Henglein. Coinductive axiomatization of recursive type

equality and subtyping. In International Conference on Typed Lambda Calculi and
Applications (TLCA), Nancy, France, volume 1210 of Lecture Notes in Computer
Science, pages 63-81. SpringerngVerlag, April 1997. Full version in Fundamenta
Informaticae, 33:309-338, 1998.

BreazungTannen, Val, Thierry Coquand, Carl Gunter, and Andre Scedrov. Inheritance

as implicit coercion. Information and Computation, 93(1):172-221, July 1991. Also
in C. A. Gunter and J. C. Mitchell, editors, Theoretical Aspects of ObjectngOriented
Programming: Types, Semantics, and Language Design, MIT Press, 1994.

Bruce, Kim B. Typing in objectngoriented languages: Achieving expressibility and

safety, 1995. Available through http://www.cs.williams.edu/~kim.

Bruce, Kim B. Foundations of ObjectngOriented Languages: Types and Semantics. MIT

Press, 2002.

Bruce, Kim B., Luca Cardelli, Giuseppe Castagna, the Hopkins Objects Group

(Jonathan Eifrig, Scott Smith, Valery Trifonov), Gary T. Leavens, and Benjamin
Pierce. On binary methods. Theory and Practice of Object Systems, 1(3):221-242,
1996.

Bruce, Kim B., Luca Cardelli, and Benjamin C. Pierce. Comparing object encodings.

In International Symposium on Theoretical Aspects of Computer Software (TACS),
September 1997. An earlier version was presented as an invited lecture at the Third
International Workshop on Foundations of Object Oriented Languages (FOOL 3),
July 1996; full version in Information and Computation, 155(1-2):108ng133, 1999.

References 539
de Bruijn, Nicolas G. A survey of the project AUTOMATH. In J. P. Seldin and J. R.

Hindley, editors, To H. B. Curry: Essays in Combinatory Logic, Lambda Calculus,
and Formalism, pages 589-606. Academic Press, 1980.

Brus, Tom, Marko van Eekelen, Maarten van Leer, and Marinus Plasmeijer. Clean: A

language for functional graph rewriting. In ACM Symposium on Functional Prong
gramming Languages and Computer Architecture (FPCA), Portland, Oregon, volng
ume 274 of Lecture Notes in Computer Science, pages 364-384. SpringerngVerlag,
September 1987.

Burstall, Rod and Butler Lampson. A kernel language for abstract data types and

modules. In International Symposium on Semantics of Data Types, SophiangAntipolis,
France, volume 173 of Lecture Notes in Computer Science, pages 1-50. Springerng
Verlag, June 1984.

Burstall, Rod, David MacQueen, and Donald Sannella. HOPE: an experimental apng

plicative language. In ACM Symposium on Lisp and Functional Programming (LFP),
Stanford, California, pages 136-143, August 1980.

Calcagno, Cristiano. Stratified operational semantics for safety and correctness of reng

gion calculus. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL), London, England, pages 155-165, 2001.

Calcagno, Cristiano, Simon Helsen, and Peter Thiemann. Syntactic type soundness

results for the region calculus. Information and Computation, 173(2):199-221,
2002.

Cardelli, Luca. A polymorphic *ngcalculus with Type:Type. Research report 10,

DEC/Compaq Systems Research Center, May 1986.

Cardelli, Luca. Phase distinctions in type theory, 1988a. Manuscript, available from

http://www.luca.demon.co.uk.

Cardelli, Luca. Typechecking dependent types and subtypes. In Foundations of Logic

and Functional Programming, Trento, Italy, (December, 1986), volume 306 of Lecng
ture Notes in Computer Science, pages 45-57. SpringerngVerlag, 1988b.

Cardelli, Luca. Program fragments, linking, and modularization. In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), Paris, France,
pages 266-277, January 1997.

Cardelli, Luca, James Donahue, Mick Jordan, Bill Kalsow, and Greg Nelson. The

Modulang3 type system. In Proceedings of the Sixteenth Annual ACM Symposium
on Principles of Programming Languages, pages 202-212, January 1989.

Cardelli, Luca and Xavier Leroy. Abstract types and the dot notation. In IFIP TC2

Working Conference on Programming Concepts and Methods. North Holland, 1990.
Also appeared as DEC/Compaq SRC technical report 56.

Cardelli, Luca and Giuseppe Longo. A semantic basis for Quest. Journal of Functional

Programming, 1(4):417-458, October 1991. Summary in ACM Conference on Lisp
and Functional Programming, pp. 30ng43, 1990. Also available as DEC/Compaq SRC
Research Report 55, Feb. 1990.

540 References

Cardelli, Luca and John Mitchell. Operations on records. Mathematical Structures

in Computer Science, 1:3-48, 1991. Also in C. A. Gunter and J. C. Mitchell, eding
tors, Theoretical Aspects of ObjectngOriented Programming: Types, Semantics, and
Language Design, MIT Press, 1994; available as DEC/Compaq Systems Research
Center Research Report #48, August, 1989; and in the Proceedings of Workshop
on the Mathematical Foundations of Programming Semantics (MFPS), New Orleans,
Louisiana, Springer LNCS, volume 442, pp. 22ng52, 1989.

Cartmell, John. Generalised algebraic theories and contextual categories. Annals of

Pure and Applied Logic, 32:209-243, 1986.

Cartwright, Robert and Mike Fagan. Soft typing. In ACM SIGPLAN Conference on Prong

gramming Language Design and Implementation (PLDI), Toronto, Ontario, pages
278-292, June 1991.

Cervesato, Iliano, Joshua S. Hodas, and Frank Pfenning. Efficient resource manageng

ment for linear logic proof search. Theoretical Computer Science, 232(1-2):133-
163, February 2000.

Cervesato, Iliano and Frank Pfenning. A linear logical framework. Information and

Computation, 179(1):19-75, November 2002.

Chaki, Sagar, Sriram K. Rajamani, and Jakob Rehof. Types as models: Model checking

messagengpassing programs. In ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages (POPL), Portland, Oregon, pages 45-57, 2002.

Chirimar, Jawahar, Carl A. Gunter, and Jon G. Riecke. Reference counting as a comng

putational interpretation of linear logic. Journal of Functional Programming, 6(2):
195-244, March 1996.

Christiansen, Morten Voetmann and Per Velschow. Regionngbased memory manageng

ment in Java. Master's thesis, University of Copenhagen, Department of Computer
Science, 1998.

Church, Alonzo. The Calculi of Lambda Conversion. Princeton University Press, 1941.
Church, Alonzo. The weak theory of implication. Kontroliertes Denken: Untersuchunng

gen zum Logikkalk ul und zur Logik der Einzelwissenschaften, pages 22-37, 1951.

Clement, Dominique, Joelle Despeyroux, Thierry Despeyroux, and Gilles Kahn. A

simple applicative language: MiningML. In ACM Symposium on Lisp and Functional
Programming (LFP), Cambridge, Massachusetts, pages 13-27, August 1986.

Colby, Christopher, Peter Lee, George C. Necula, Fred Blau, Mark Plesko, and Kenneth

Cline. A certifying compiler for Java. ACM SIGPLAN Notices, 35(5):95-107, May
2000.

Comon, Hubert. Constraints in term algebras (short survey). In Conference on Algeng

braic Methodology and Software Technology (AMAST), June, 1993, Workshops in
Computing, pages 97-108. SpringerngVerlag, 1994.

Constable, Robert L., Stuart F. Allen, Mark Bromley, Rance Cleaveland, James F. Creng

mer, Robert W. Harper, Douglas J. Howe, Todd B. Knoblock, Paul Mendler, Prakash
Panangaden, James T. Sasaki, and Scott F. Smith. Implementing Mathematics with
the NuPRL Proof Development System. PrenticengHall, Englewood Cliffs, NJ, 1986.

References 541
Coquand, Catarina. The AGDA proof system homepage, 1998. http://www.cs.

chalmers.se/~catarina/agda/.

Coquand, Thierry. An analysis of Girard's paradox. In IEEE Symposium on Logic in

Computer Science (LICS), Cambridge, Massachusetts, pages 227-236, June 1986.

Coquand, Thierry. An algorithm for testing conversion in type theory. In G. Huet

and G. Plotkin, editors, Logical Frameworks, pages 255-279. Cambridge University
Press, 1991.

Coquand, Thierry. Pattern matching with dependent types. In Workshop on

Types for Proofs and Programs (TYPES), Ba*stad, Sweden, informal proceedng
ings. Available from ftp://ftp.cs.chalmers.se/pub/csngreports/baastad.
92/proc.ps.Z, June 1992.

Coquand, Thierry and Ge'rard Huet. The calculus of constructions. Information and

Computation, 76(2-3):95-120, February/March 1988.

Coquand, Thierry, Randy Pollack, and Makoto Takeyama. A logical framework with

dependently typed records. In International Conference on Typed Lambda Calculi
and Applications (TLCA), Valencia, Spain, volume 2701 of Lecture Notes in Comng
puter Science, pages 105-119. SpringerngVerlag, June 2003.

Courant, Judicae"l. Strong normalization with singleton types. In Workshop on Inng

tersection Types and Related Systems (ITRS), Copenhagen, Denmark, volume 70 of
Electronic Notes in Theoretical Computer Science. Elsevier, July 2002.

Crank, Erik and Matthias Felleisen. Parameterngpassing and the lambda calculus.

In ACM Symposium on Principles of Programming Languages (POPL), Orlando,
Florida, pages 233-244, January 1991.

Crary, Karl. A simple proof technique for certain parametricity results. In ACM SIGng

PLAN International Conference on Functional Programming (ICFP), Paris, France,
pages 82-89, September 1999.

Crary, Karl. Toward a foundational typed assembly language. In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), New Orleans,
Louisiana, pages 198-212, January 2003.

Crary, Karl, Robert Harper, and Sidd Puri. What is a recursive module? In ACM SIGng

PLAN Conference on Programming Language Design and Implementation (PLDI),
pages 50-63, May 1999.

Crary, Karl, Stephanie Weirich, and Greg Morrisett. Intensional polymorphism in

typengerasure semantics. In ACM SIGPLAN International Conference on Functional
Programming (ICFP), Baltimore, Maryland, pages 301-312, 1998. Full version in
Journal of Functional Programming, 12(6), Nov. 2002, pp. 567-600.

Curtis, Pavel. Constrained Quantification in Polymorphic Type Analysis. PhD thesis,

Cornell University, Ithaca, New York, February 1990.

van Daalen, Diederik T. The Language Theory of Automath. PhD thesis, Technische

Hogeschool Eindhoven, Eindhoven, The Netherlands, 1980.

542 References

Damas, Luis and Robin Milner. Principal type schemes for functional programs. In

ACM Symposium on Principles of Programming Languages (POPL), Albuquerque,
New Mexico, pages 207-212, 1982.

Danvy, Olivier. Functional unparsing. Journal of Functional Programming, 8(6):621-

625, 1998.

DeLine, Rob and Manuel Fa"hndrich. Enforcing highnglevel protocols in lownglevel softng

ware. In ACM SIGPLAN Conference on Programming Language Design and Impleng
mentation (PLDI), Snowbird, Utah, pages 59-69, June 2001.

Donahue, James and Alan Demers. Data types are values. ACM Transactions on

Programming Languages and Systems, 7(3):426-445, July 1985.

Dos^en, Kosta. A historical introduction to substructural logics. In K. Dos^en and

P. SchroederngHeister, editors, Substructural Logics, pages 1-30. Oxford University
Press, 1993.

Dreyer, Derek, Karl Crary, and Robert Harper. A type system for higherngorder modng

ules. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lanng
guages (POPL), New Orleans, Louisiana, pages 236-249, New Orleans, January
2003.

Dussart, Dirk, Fritz Henglein, and Christian Mossin. Polymorphic recursion and subng

type qualifications: Polymorphic bindingngtime analysis in polynomial time. In Interng
national Symposium on Static Analysis (SAS) , Paris, France, volume 983 of Lecture
Notes in Computer Science, pages 118-135. SpringerngVerlag, July 1995.

Emms, Martin and Hans LeiSS. Extending the type checker for SML by polymorng

phic recursion--A correctness proof. Technical Report 96ng101, Centrum fu"r
Informationsng und Sprachverarbeitung, Universita"t Mu"nchen, 1996.

Erhard, Thomas. A categorical semantics of constructions. In IEEE Symposium on

Logic in Computer Science (LICS), Edinburgh, Scotland, pages 264-273, July 1988.

Fa"hndrich, Manuel. Bane: A Library for Scalable ConstraintngBased Program Analysis.

PhD thesis, University of California at Berkeley, Berkeley, California, 1999.

Fa"hndrich, Manuel and Rob DeLine. Adoption and focus: Practical linear types for

imperative programming. In ACM SIGPLAN Conference on Programming Language
Design and Implementation (PLDI), Berlin, Germany, pages 13-24, June 2002.

Fa"hndrich, Manuel, Jakob Rehof, and Manuvir Das. Scalable contextngsensitive flow

analysis using instantiation constraints. In ACM SIGPLAN Conference on Programng
ming Language Design and Implementation (PLDI), Vancouver, British Columbia,
Canada, pages 253-263, June 2000.

Felleisen, Matthias and Robert Hieb. A revised report on the syntactic theories of

sequential control and state. Theoretical Computer Science, 103(2):235-271, 1992.

Fisher, Kathleen and John H. Reppy. The design of a class mechanism for Moby. In

ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI), Atlanta, Georgia, pages 37-49, May 1999.

References 543
Flanagan, Cormac and Shaz Qadeer. A type and effect system for atomicity. In

ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI), San Diego, California, pages 338-349, June 2003.

Flatt, Matthew and Matthias Felleisen. Units: Cool modules for HOT languages. In

ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI), Montre'al, Que'bec, pages 236-248, 1998.

Fluet, Matthew. Monadic regions. In Workshop on Semantics, Program Analysis and

Computing Environments for Memory Management (SPACE), informal proceedings,
January 2004.

Fluet, Matthew and Riccardo Pucella. Phantom types and subtyping. In IFIP Internang

tional Conference on Theoretical Computer Science (TCS), pages 448-460, August
2002.

Foster, Jeffrey S., Tachio Terauchi, and Alex Aiken. Flowngsensitive type qualifiers. In

ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI), Berlin, Germany, pages 1-12, June 2002.

Frey, Alexandre. Satisfying subtype inequalities in polynomial space. In International

Symposium on Static Analysis (SAS) , Paris, France, volume 1302 of Lecture Notes
in Computer Science, pages 265-277. SpringerngVerlag, September 1997.

Fuh, YoungChin and Prateek Mishra. Type inference with subtypes. In European Symng

posium on Programming (ESOP), Nancy, France, volume 300 of Lecture Notes in
Computer Science, pages 94-114. SpringerngVerlag, March 1988.

Furuse, Jun P. and Jacques Garrigue. A labelngselective lambdangcalculus with optional

arguments and its compilation method. RIMS Preprint 1041, Kyoto University,
October 1995.

Garcia, Ronald, Jaakko Jarvi, Andrew Lumsdaine, Jeremy Siek, and Jeremia h Willng

cock. A comparative study of language support for generic programming. In ACM
SIGPLAN Conference on Object Oriented Programming: Systems, Languages, and
Applications (OOPSLA), Anaheim, California, pages 115-134, October 2003.

Garrigue, Jacques. Programming with polymorphic variants. In ACM SIGPLAN Workng

shop on ML, informal proceedings, September 1998.

Garrigue, Jacques. Code reuse through polymorphic variants. In Workshop on Founng

dations of Software Engineering (FOSE), November 2000.

Garrigue, Jacques. Simple type inference for structural polymorphism. In Internang

tional Workshop on Foundations of ObjectngOriented Languages (FOOL), informal
proceedings, January 2002.

Garrigue, Jacques. Relaxing the value restriction. In International Symposium on

Functional and Logic Programming (FLOPS), Nara, Japan, volume 2998 of Lecture
Notes in Computer Science, pages 196-213. SpringerngVerlag, April 2004.

Garrigue, Jacques and Hassan Ai"tngKaci. The typed polymorphic labelngselective

lambdangcalculus. In ACM SIGPLAN-SIGACT Symposium on Principles of Programng
ming Languages (POPL), Portland, Oregon, pages 35-47, 1994.

544 References

Garrigue, Jacques and Didier Re'my. Extending ML with semingexplicit higherngorder

polymorphism. Information and Computation, 155(1):134-169, 1999.

Gaster, Benedict R. Records, variants and qualified types. PhD thesis, University of

Nottingham, Nottingham, England, July 1998.

Gaster, Benedict R. and Mark P. Jones. A polymorphic type system for extensible

records and variants. Technical Report NOTTCSngTRng96ng3, Department of Computer
Science, University of Nottingham, November 1996.

Gay, David and Alexander Aiken. Language support for regions. In ACM SIGPLAN

Conference on Programming Language Design and Implementation (PLDI), Snowng
bird, Utah, pages 70-80, June 2001.

Ghelli, Giorgio and Benjamin Pierce. Bounded existentials and minimal typing,

1992. Circulated in manuscript form. Full version in Theoretical Computer Science,
193(1-2):75-96, February 1998.

Gifford, David K. and John M. Lucassen. Integrating functional and imperative prong

gramming. In ACM Symposium on Lisp and Functional Programming (LFP), Camng
bridge, Massachusetts, pages 28-38, August 1986.

Girard, JeanngYves. Interpre'tation fonctionnelle et e'limination des coupures de l'arithng

me'tique d'ordre supe'rieur. The`se d'e'tat, University of Paris VII, 1972. Summary
in J. E. Fenstad, editor, Scandinavian Logic Symposium, pp. 63-92, NorthngHolland,
1971.

Girard, JeanngYves. Linear logic. Theoretical Computer Science, 50:1-102, 1987.
Girard, JeanngYves. Light linear logic. Information and Computation, 143:175-204,

1998.

Girard, JeanngYves, Yves Lafont, and Paul Taylor. Proofs and Types, volume 7 of Camng

bridge Tracts in Theoretical Computer Science. Cambridge University Press, 1989.

Glew, Neal. Type dispatch for named hierarchical types. In ACM SIGPLAN Internang

tional Conference on Functional Programming (ICFP), Paris, France, pages 172-182,
1999.

GNU. GNU C library, version 2.2.5, 2001. Available from http://www.gnu.org/

manual/glibcng2.2.5/html_mono/libc.html.

Goguen, Healfdene. A Typed Operational Semantics for Type Theory. PhD thesis,

LFCS, University of Edinburgh, Edinburgh, Scotland, 1994. Report ESCngLFCSng94ng
304.

Gordon, Andrew D. Bisimilarity as a theory of functional programming. In Workshop

on the Mathematical Foundations of Programming Semantics (MFPS), New Orleans,
Louisiana, volume 1 of Electronic Notes in Theoretical Computer Science. Elsevier,
April 1995.

Gordon, Andrew D. Operational equivalences for untyped and polymorphic object

calculi. In A. D. Gordon and A. M. Pitts, editors, HigherngOrder Operational Techng
niques in Semantics, Publications of the Newton Institute, pages 9-54. Cambridge
University Press, 1998.

References 545
Gordon, Andrew D. and Alan Jeffrey. Authenticity by typing for security protocols. In

IEEE Computer Security Foundations Workshop (CSFW), Cape Breton, Nova Scotia,
pages 145-159, 2001a.

Gordon, Andrew D. and Alan Jeffrey. Typing correspondence assertions for commung

niation protocols. In Workshop on the Mathematical Foundations of Programming
Semantics (MFPS), Aarhus, Denmark, volume 45 of Electronic Notes in Theoretical
Computer Science, pages 379-409. Elsevier, May 2001b.

Gordon, Andrew D. and Alan Jeffrey. Types and effects for asymmetric cryptographic

protocols. In IEE Computer Security Foundations Workshop (CSFW) , Cape Breton,
Nova Scotia, pages 77-91, 2002.

Gordon, Andrew D. and Don Syme. Typing a multinglanguage intermediate code.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), London, England, pages 248-260, January 2001.

Gordon, Michael J., Robin Milner, and Christopher P. Wadsworth. Edinburgh LCF,

volume 78 of Lecture Notes in Computer Science. SpringerngVerlag, 1979.

Gough, John. Compiling for the .NET Common Language Runtime. .NET series. Prenng

tice Hall, 2002.

Grossman, Dan, Greg Morrisett, Trevor Jim, Michael Hicks, Yanling Wang, and James

Cheney. Regionngbased memory management in Cyclone. In ACM SIGPLAN Conng
ference on Programming Language Design and Implementation (PLDI), Berlin, Gerng
many, pages 282-293, 2002.

Gustavsson, Jo"rgen and Josef Svenningsson. Constraint abstractions. In Symposium

on Programs as Data Objects (PADO), Aarhus, Denmark, volume 2053 of Lecture
Notes in Computer Science, pages 63-83. SpringerngVerlag, May 2001.

Hallenberg, Niels, Martin Elsman, and Mads Tofte. Combining region inference and

garbage collection. In ACM SIGPLAN Conference on Programming Language Deng
sign and Implementation (PLDI), Berlin, Germany, pages 141-152, June 2002.

Hallgren, Thomas and Aarne Ranta. An extensible proof text editor (abstract). In

International Conference on Logic for Programming and Automated Reasoning
(LPAR), Reunion Island, volume 1955 of Lecture Notes in Computer Science, pages
70-84. SpringerngVerlag, 2000.

Hamid, Nadeem, Zhong Shao, Valery Trifonov, Stefan Monnier, and Zhaozhong Ni.

A syntactic approach to foundational proofngcarrying code. In IEEE Symposium on
Logic in Computer Science (LICS), pages 89-100, July 2002.

Hanson, David R. Fast allocation and deallocation of memory based on object lifeng

times. Software--Practice and Experience, 20(1):5-12, 1990.

Hardin, The're`se, Luc Maranget, and Bruno Pagano. Functional runtimes within the

lambdangsigma calculus. Journal of Functional Programming, 8(2):131-172, March
1998.

Harper, Robert, Furio Honsell, and Gordon Plotkin. A framework for defining logics.

Journal of the ACM, 40(1):143-184, 1993. Summary in IEEE Symposium on Logic in
Computer Science (LICS), Ithaca, New York, 1987.

546 References

Harper, Robert and Mark Lillibridge. A typengtheoretic approach to higherngorder modng

ules with sharing. In ACM SIGPLAN-SIGACT Symposium on Principles of Programng
ming Languages (POPL), Portland, Oregon, pages 123-137, January 1994.

Harper, Robert and John C. Mitchell. On the type structure of Standard ML. ACM

Transactions on Programming Languages and Systems, 15(2):211-252, April 1993.
An earlier version appeared in ACM Symposium on Principles of Programming Lanng
guages (POPL), San Diego, California, under the title "The Essence of ML" (Mitchell
and Harper), 1988.

Harper, Robert, John C. Mitchell, and Eugenio Moggi. Higherngorder modules and the

phase distinction. In ACM Symposium on Principles of Programming Languages
(POPL), San Francisco, California, pages 341-354, January 1990.

Harper, Robert and Frank Pfenning. On equivalence and canonical forms in the LF

type theory. ACM Transactions on Computational Logic, 2004. To appear. An earng
lier version is available as Technical Report CMUngCSng00ng148, School of Computer
Science, Carnegie Mellon University.

Harper, Robert and Robert Pollack. Type checking with universes. Theoretical Comng

puter Science, 89:107-136, 1991.

Harper, Robert and Christopher Stone. A typengtheoretic interpretation of Standard

ML. In G. Plotkin, C. Stirling, and M. Tofte, editors, Proof, Language and Interaction:
Essays in Honour of Robin Milner. MIT Press, 2000.

Heintze, Nevin. Set based analysis of ML programs. In ACM Symposium on Lisp and

Functional Programming (LFP), Orlando, Florida, pages 306-317, June 1994.

Heintze, Nevin. Controlngflow analysis and type systems. In International Sympong

sium on Static Analysis (SAS) , Glasgow, Scotland, volume 983 of Lecture Notes in
Computer Science, pages 189-206. SpringerngVerlag, 1995.

Helsen, Simon and Peter Thiemann. Syntactic type soundness for the region calculus.

In Workshop on Higher Order Operational Techniques in Semantics (HOOTS), Monng
tre'al, Que'bec, volume 41(3) of Electronic Notes in Theoretical Computer Science,
pages 1-20. Elsevier, September 2000.

Helsen, Simon and Peter Thiemann. Polymorphic specialization for ML. ACM Transng

actions on Programming Languages and Systems, 26(4):652-701, July 2004.

Henglein, Fritz. Polymorphic Type Inference and SemingUnification. PhD thesis, Rutgers

University, April 1989. Available as NYU Technical Report 443, May 1989, from
New York University, Courant Institute of Mathematical Sciences, Department of
Computer Science, 251 Mercer St., New York, NY 10012, USA.

Henglein, Fritz. Type inference with polymorphic recursion. ACM Transactions on

Programming Languages and Systems, 15(2):253-289, 1993.

Henglein, Fritz, Henning Makholm, and Henning Niss. A direct approach to controlng

flow sensitive regionngbased memory management. In ACM SIGPLAN International
Conference on Principles and Practice of Declarative Programming (PPDP), Firenze,
Italy, pages 175-186, September 2001.

References 547
Henglein, Fritz and Christian Mossin. Polymorphic bindingngtime analysis. In European

Symposium on Programming (ESOP), Edinburgh, Scotland, volume 788 of Lecture
Notes in Computer Science, pages 287-301. SpringerngVerlag, April 1994.

Hirschowitz, Tom and Xavier Leroy. Mixin modules in a callngbyngvalue setting. In

European Symposium on Programming (ESOP), Grenoble, France, pages 6-20, April
2002.

Hoare, C. A. R. Proof of correctness of data representation. Acta Informatica, 1:

271-281, 1972.

Hofmann, Martin. A mixed modal/linear lambda calculus with applications to

bellantoningcook safe recursion. In International Workshop on Computer Science
Logic (CSL), Aarhus, Denmark, pages 275-294, August 1997a.

Hofmann, Martin. Syntax and semantics of dependent types. In A. M. Pitts and

P. Dybjer, editors, Semantics and Logic of Computation, pages 79-130. Cambridge
University Press, 1997b.

Hofmann, Martin. Linear types and nonngsizengincreasing polynomial time computang

tion. In IEEE Symposium on Logic in Computer Science (LICS), Trento, Italy, pages
464-473, June 1999.

Hofmann, Martin. Safe recursion with higher types and BCKngalgebra. Annals of Pure

and Applied Logic, 104(1-3):113-166, 2000.

Honsell, Furio, Ian A. Mason, Scott F. Smith, and Carolyn L. Talcott. A variable typed

logic of effects. Information and Computation, 119(1):55-90, 1995.

Howard, William A. Hereditarily majorizable functionals of finite type. In A. S. Troelng

stra, editor, Metamathematical Investigation of Intuitionistic Arithmetic and Analyng
sis, volume 344 of Lecture Notes in Mathematics, pages 454-461. SpringerngVerlag,
Berlin, 1973.

Howard, William A. The formulasngasngtypes notion of construction. In J. P. Seldin

and J. R. Hindley, editors, To H. B. Curry: Essays on Combinatory Logic, Lambda
Calculus, and Formalism, pages 479-490. Academic Press, 1980. Reprint of 1969
article.

Howe, Douglas J. Proving congruence of bisimulation in functional programming

languages. Information and Computation, 124(2):103-112, 1996.

Huet, Ge'rard. Re'solution d'equations dans les langages d'ordre 1,2, ...,!. The`se de

Doctorat d'Etat, Universite' de Paris 7, Paris, France, 1976.

Igarashi, Atsushi and Naoki Kobayashi. A generic type system for the Pingcalculus.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), London, England, pages 128-141, January 2001.

Igarashi, Atsushi and Naoki Kobayashi. Resource usage analysis. In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), Portland,
Oregon, pages 331-342, January 2002.

548 References

Igarashi, Atsushi and Benjamin C. Pierce. Foundations for virtual types. In European

Conference on ObjectngOriented Programming (ECOOP), Lisbon, Portugal, June 1999.
Also in informal proceedings of the Workshop on Foundations of ObjectngOriented
Languages (FOOL), January 1999. Full version in Information and Computation,
175(1): 34-49, May 2002.

Ishtiaq, Samin and Peter O'Hearn. BI as an assertion language for mutable data

structures. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL), London, England, pages 14-26, January 2001.

Jacobs, Bart. Categorical Logic and Type Theory. Studies in Logic and the Foundations

of Mathematics 141. Elsevier, 1999.

Jategaonkar, Lalita A. ML with extended pattern matching and subtypes. Master's

thesis, Massachusetts Institute of Technology, August 1989.

Jategaonkar, Lalita A. and John C. Mitchell. ML with extended pattern matching and

subtypes (preliminary version). In ACM Symposium on Lisp and Functional Prong
gramming (LFP), Snowbird, Utah, pages 198-211, Snowbird, Utah, July 1988.

Jensen, Kathleen and Niklaus Wirth. Pascal User Manual and Report. SpringerngVerlag,

second edition, 1975.

Jim, Trevor. What are principal typings and what are they good for? In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), St. Petersburg
Beach, Florida, pages 42-53, 1996.

Jim, Trevor, J. Greg Morrisett, Dan Grossman, Michael W. Hicks, James Cheney, and

Yanling Wang. Cyclone: A safe dialect of C. In General Track: USENIX Annual
Technical Conference, pages 275-288, June 2002.

Jim, Trevor and Jens Palsberg. Type inference in systems of recursive types with subng

typing, 1999. Manuscript, available from http://www.cs.purdue.edu/homes/
palsberg/draft/jimngpalsberg99.pdf.

Johann, Patricia. A generalization of shortngcut fusion and its correctness proof.

HigherngOrder and Symbolic Computation, 15(4):273-300, 2002.

Jones, Mark P. Qualified Types: Theory and Practice. Cambridge University Press,

1994.

Jones, Mark P. Using parameterized signatures to express modular structure. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL),
St. Petersburg Beach, Florida, January 21-24, 1996.

Jones, Mark P. Typing Haskell in Haskell. In ACM Haskell Workshop, informal prong

ceedings, October 1999.

Jones, Mark P. and John C. Peterson. The Hugs 98 user manual, 1999. Available from

http://www.haskell.org/hugs/.

Jones, Mark P. and Simon Peyton Jones. Lightweight extensible records for Haskell.

In ACM Haskell Workshop, informal proceedings, October 1999.

References 549
Jouannaud, JeanngPierre and Claude Kirchner. Solving equations in abstract algebras:

a rulengbased survey of unification. In J.ngL. Lassez and G. Plotkin, editors, Computang
tional Logic: Essays in honor of Alan Robinson, pages 257-321. MIT Press, 1991.

Jouvelot, Pierre and David Gifford. Algebraic reconstruction of types and effects.

In ACM Symposium on Principles of Programming Languages (POPL), Orlando,
Florida, pages 303-310, January 1991.

Jouvelot, Pierre and David K. Gifford. Reasoning about continuations with control

effects. In ACM SIGPLAN Conference on Programming Language Design and Imng
plementation (PLDI), Portland, Oregon, pages 218-226, June 1989.

Jung, Achim and Allen Stoughton. Studying the fully abstract model of PCF within its

continuous function model. In International Conference on Typed Lambda Calculi
and Applications (TLCA), Utrecht, The Netherlands, volume 664 of Lecture Notes in
Computer Science, pages 230-244. SpringerngVerlag, March 1993.

Jutting, L.S. van Benthem, James McKinna, and Robert Pollack. Checking algorithms

for Pure Type Systems. In International Workshop on Types for Proofs and Prong
grams (TYPES), Nijmegen, The Netherlands, May 1993, volume 806 of Lecture Notes
in Computer Science, pages 19-61. SpringerngVerlag, 1994.

Kfoury, Assaf J., Jerzy Tiuryn, and Pawel Urzyczyn. ML typability is dexptimeng

complete. In Colloquium on Trees in Algebra and Programming (CAAP), Copenng
hagen, Denmark, volume 431 of Lecture Notes in Computer Science, pages 206-
220. SpringerngVerlag, May 1990.

Kfoury, Assaf J., Jerzy Tiuryn, and Pawel Urzyczyn. The undecidability of the seming

unification problem. Information and Computation, 102(1):83-101, January 1993.

Kfoury, Assaf J., Jerzy Tiuryn, and Pawel Urzyczyn. An analysis of ML typability.

Journal of the ACM, 41(2):368-398, March 1994.

Kirchner, Claude and Francis Klay. Syntactic theories and unification. In IEEE Sympong

sium on Logic in Computer Science (LICS), Philadelphia, Pennsylvania, pages 270-
277, June 1990.

Knight, Kevin. Unification: a multidisciplinary survey. ACM Computing Surveys, 21

(1):93-124, March 1989.

Kobayashi, Naoki. Quasinglinear types. In ACM SIGPLAN-SIGACT Symposium on Princing

ples of Programming Languages (POPL), San Antonio, Texas, pages 29-42, January
1999.

Kozen, Dexter, Jens Palsberg, and Michael I. Schwartzbach. Efficient recursive subng

typing. Mathematical Structures in Computer Science, 5(1):113-125, 1995.

Kuncak, Viktor and Martin Rinard. Structural subtyping of nonngrecursive types is

decidable. In IEEE Symposium on Logic in Computer Science (LICS), Ottawa, Canada,
pages 96-107, June 2003.

Lafont, Yves. The linear abstract machine. Theoretical Computer Science, 59:157-180,

1988.

550 References

Lambek, Joachim. The mathematics of sentence structure. American Mathematical

Monthly, 65:154-170, 1958.

Lampson, Butler and Rod Burstall. Pebble, a kernel language for modules and abstract

data types. Information and Computation, 76:278-346, February/March 1988.

Lassen, So/ren Bo/gh. Relational Reasoning about Functions and Nondeterminism. PhD

thesis, Department of Computer Science, University of Aarhus, Aarhus, Denmark,
1998.

Lassez, JeanngLouis, Michael J. Maher, and Kim G. Marriott. Unification revisited. In

J. Minker, editor, Foundations of Deductive Databases and Logic Programming,
pages 587-625. Morgan Kaufmann, 1988.

Lee, Oukseh and Kwangkeun Yi. Proofs about a folklore letngpolymorphic type inferng

ence algorithm. ACM Transactions on Programming Languages and Systems, 20
(4):707-723, July 1998.

Leivant, Daniel. Stratified functional programs and computational complexity.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), Charleston, South Carolina, pages 325-333, January 1993.

Leroy, Xavier. Polymorphic typing of an algorithmic language. Research Report 1778,

INRIA, October 1992.

Leroy, Xavier. Manifest types, modules and separate compilation. In ACM SIGPLAN-

SIGACT Symposium on Principles of Programming Languages (POPL), Portland,
Oregon, pages 109-122, January 1994.

Leroy, Xavier. Applicative functors and fully transparent higherngorder modules.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), San Francisco, California, pages 142-153, January 1995.

Leroy, Xavier. A syntactic theory of type generativity and sharing. Journal of Funcng

tional Programming, 6(5):667-698, September 1996.

Leroy, Xavier. The Objective Caml system: Documentation and user's manual, 2000.

With Damien Doligez, Jacques Garrigue, Didier Re'my, and Je'ro^me Vouillon. Availng
able from http://caml.inria.fr.

Leroy, Xavier and Franc,ois Pessaux. Typengbased analysis of uncaught exceptions.

ACM Transactions on Programming Languages and Systems, 22(2):340-377, March
2000. Summary in ACM SIGPLAN-SIGACT Symposium on Principles of Programng
ming Languages (POPL), San Antonio, Texas, 1999.

Lillibridge, Mark. Translucent Sums: A Foundation for HigherngOrder Module Systems.

PhD thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh,
Pennsylvania, May 1997.

Lindholm, Tim and Frank Yellin. The Java Virtual Machine Specification. The Java

Series. AddisonngWesley, Reading, MA, January 1997.

Liskov, Barbara. A history of CLU. ACM SIGPLAN Notices, 28(3):133-147, 1993.

References 551
Loader, Ralph. Finitary PCF is not decidable. Theoretical Computer Science, 266(1-2):

341-364, September 2001.

Lucassen, John M. Types and Effects towards the Integration of Functional and Imperang

tive Programming. PhD thesis, Massachusetts Institute of Technology, Cambridge,
Massachusetts, August 1987. Technical Report MITngLCSngTRng408.

Lucassen, John M. and David K. Gifford. Polymorphic effect systems. In ACM Sympong

sium on Principles of Programming Languages (POPL), San Diego, California, pages
47-57, 1988.

Luo, Zhaohui. Computation and Reasoning: A Type Theory for Computer Science.

Number 11 in International Series of Monographs on Computer Science. Oxford
University Press, 1994.

Luo, Zhaohui and Robert Pollack. The LEGO proof development system: A user's

manual. Technical Report ECSngLFCSng92ng211, University of Edinburgh, May 1992.

MacQueen, David. Modules for Standard ML. In ACM Symposium on Lisp and Funcng

tional Programming (LFP), Austin, Texas, pages 198-207, 1984.

MacQueen, David. Using dependent types to express modular structure. In ACM

Symposium on Principles of Programming Languages (POPL), St. Petersburg Beach,
Florida, pages 277-286, January 1986.

MacQueen, David B. and Mads Tofte. A semantics for higherngorder functors. In Eung

ropean Symposium on Programming (ESOP), Edinburgh, Scotland, volume 788 of
Lecture Notes in Computer Science, pages 409-423. SpringerngVerlag, April 1994.

Magnusson, Lena and Bengt Nordstro"m. The ALF proof editor and its proof engine. In

International Workshop on Types for Proofs and Programs (TYPES), Nijmegen, The
Netherlands, May, 1993, volume 806 of Lecture Notes in Computer Science, pages
213-237. SpringerngVerlag, 1994.

Mairson, Harry G., Paris C. Kanellakis, and John C. Mitchell. Unification and ML type

reconstruction. In J.ngL. Lassez and G. Plotkin, editors, Computational Logic: Essays
in Honor of Alan Robinson, pages 444-478. MIT Press, 1991.

Makholm, Henning. Regionngbased memory management in Prolog. Master's thesis,

University of Copenhagen, Department of Computer Science, March 2000. Techning
cal Report DIKUngTRng00/09.

Makholm, Henning. A LanguagengIndependend Framework for Region Inference. PhD

thesis, University of Copenhagen, Department of Computer Science, Copenhagen,
Denmark, 2003.

Makholm, Henning and Kostis Sagonas. On enabling the WAM with region support.

In International Conference on Logic Programming (ICLP), volume 2401 of Lecture
Notes in Computer Science, pages 163-178. SpringerngVerlag, July 2002.

Martelli, Alberto and Ugo Montanari. Unification in linear time and space: A strucng

tured presentation. Internal Report B76ng16, Istituto di Elaborazione delle Inforng
mazione, Consiglio Nazionale delle Ricerche, Pisa, July 1976.

552 References

Martelli, Alberto and Ugo Montanari. An efficient unification algorithm. ACM Transng

actions on Programming Languages and Systems, 4(2):258-282, 1982.

MartinngLo"f, Per. Intuitionistic Type Theory. Bibliopolis, 1984.
Mason, Ian A., Scott F. Smith, and Carolyn L. Talcott. From operational semantics to

domain theory. Information and Computation, 128(1):26-47, 1996.

Mason, Ian A. and Carolyn L. Talcott. Equivalence in functional languages with effects.

Journal of Functional Programming, 1:287-327, 1991.

McAllester, David. On the complexity analysis of static analyses. Journal of the ACM,

49(4):512-537, July 2002.

McAllester, David. A logical algorithm for ML type inference. In International Conng

ference on Rewriting Techniques and Applications (RTA), Valencia, Spain, volume
2706 of Lecture Notes in Computer Science, pages 436-451. SpringerngVerlag, June
2003.

McBride, Conor. Dependently Typed Functional Programs and their Proofs. PhD thesis,

LFCS, University of Edinburgh, Edinburgh, Scotland, 2000.

McBride, Conor and James McKinna. The view from the left. Journal of Functional

Programming, 14(1):69-111, 2004.

McKinna, James and Robert Pollack. Pure Type Sytems formalized. In International

Conference on Typed Lambda Calculi and Applications (TLCA), Utrecht, The Netherng
lands, volume 664 of Lecture Notes in Computer Science, pages 289-305. Springerng
Verlag, March 1993.

Melski, David and Thomas Reps. Interconvertibility of a class of set constraints

and contextngfree language reachability. Theoretical Computer Science, 248(1-2),
November 2000.

Milner, Robin. A theory of type polymorphism in programming. Journal of Computer

and System Sciences, 17:348-375, August 1978.

Milner, Robin, Mads Tofte, and Robert Harper. The Definition of Standard ML. MIT

Press, 1990.

Milner, Robin, Mads Tofte, Robert Harper, and David MacQueen. The Definition of

Standard ML, Revised edition. MIT Press, 1997.

Minamide, Yasuhiko. A functional representation of data structures with a hole.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), San Diego, California, pages 75-84, January 1998.

Minamide, Yasuhiko, Greg Morrisett, and Robert Harper. Typed closure conversion.

In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), St. Petersburg Beach, Florida, pages 271-283, January 1996.

Miquel, Alexandre. Le calcul des constructions implicite: syntaxe et se'mantique. PhD

thesis, University Paris 7, Paris, France, 2001.

Mitchell, John C. Coercion and type inference. In ACM Symposium on Principles

of Programming Languages (POPL), Salt Lake City, Utah, pages 175-185, January
1984.

References 553
Mitchell, John C. Representation independence and data abstraction. In ACM Sympong

sium on Principles of Programming Languages (POPL), St. Petersburg Beach, Florida,
pages 263-276, January 1986.

Mitchell, John C. On the equivalence of data representations. In V. Lifschitz, editor,

Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of
John McCarthy, pages 305-330. Academic Press, 1991a.

Mitchell, John C. Type inference with simple subtypes. Journal of Functional Prong

gramming, 1(3):245-286, July 1991b.

Mitchell, John C. Foundations for Programming Languages. MIT Press, 1996.
Mitchell, John C. and Gordon D. Plotkin. Abstract types have existential types. ACM

Transactions on Programming Languages and Systems, 10(3):470-502, 1988. Sumng
mary in ACM Symposium on Principles of Programming Languages (POPL), New
Orleans, Louisiana, 1985.

Moggi, Eugenio. Computational lambdangcalculus and monads. In IEEE Symposium

on Logic in Computer Science (LICS), Asilomar, California, pages 14-23, June 1989.
Full version, titled Notions of Computation and Monads, in Information and Comng
putation, 93(1), pp. 55-92, 1991.

Moh, ShawngKwei. The deduction theorems and two new logical systems. Methodos, 2:

56-75, 1950.

Mohring, Christine. Algorithm development in the calculus of constructions. In IEEE

Symposium on Logic in Computer Science (LICS), Cambridge, Massachusetts, pages
84-91, June 1986.

Monnier, Stefan, Bratin Saha, and Zhong Shao. Principled scavenging. In ACM SIGng

PLAN Conference on Programming Language Design and Implementation (PLDI),
Snowbird, Utah, pages 81-91, June 2001.

Morrisett, Greg, Karl Crary, Neal Glew, and David Walker. Stackngbased typed assembly

language. Journal of Functional Programming, 12(1):43-88, January 2002.

Morrisett, Greg, David Walker, Karl Crary, and Neal Glew. From SystemngF to typed

assembly language. ACM Transactions on Programming Languages and Systems,
21(3):527-568, May 1999.

Mossin, Christian. Flow Analysis of Typed HigherngOrder Programs. PhD thesis, Uning

versity of Copenhagen, Department of Computer Science, Copenhagen, Denmark,
1997. Also available as Technical Report DIKUngTRng97/1.

Mu"ller, Martin. A constraintngbased recast of MLngpolymorphism. In International Workng

shop on Unification, June 1994. Also available as Technical Report 94ngRng243, CRIN,
Nancy, France.

Mu"ller, Martin. Notes on HMD^XE^, August 1998. Available from http://www.ps.

uningsb.de/~mmueller/papers/HMX.ps.gz.

Mu"ller, Martin, Joachim Niehren, and Ralf Treinen. The firstngorder theory of ordering

constraints over feature trees. Discrete Mathematics and Theoretical Computer
Science, 4(2):193-234, 2001.

554 References

Mu"ller, Martin and Susumu Nishimura. Type inference for firstngclass messages with

feature constraints. In Asian Computer Science Conference (ASIAN), Manila, The
Philippines, volume 1538 of Lecture Notes in Computer Science, pages 169-187.
SpringerngVerlag, December 1998.

Mycroft, Alan. Polymorphic type schemes and recursive definitions. In International

Symposium on Programming, Toulouse, France, volume 167 of Lecture Notes in
Computer Science, pages 217-228, Toulouse, France, April 1984. SpringerngVerlag.

Necula, George C. Proofngcarrying code. In ACM SIGPLAN-SIGACT Symposium on Prinng

ciples of Programming Languages (POPL), Paris, France, pages 106-119, January
1997.

Necula, George C. Compiling with Proofs. PhD thesis, Carnegie Mellon University,

Pittsburgh, Pennsylvania, September 1998. Technical report CMUngCSng98ng154.

Necula, George C. Translation validation for an optimizing compiler. In ACM SIGng

PLAN Conference on Programming Language Design and Implementation (PLDI),
Vancouver, British Columbia, Canada, pages 83-94, June 2000.

Necula, George C. and Peter Lee. Safe kernel extensions without runngtime checking.

In USENIX Symposium on Operating Systems Design and Implementation (OSDI),
Seattle, Washington, pages 229-243, October 1996.

Necula, George C. and Peter Lee. The design and implementation of a certifying

compiler. In ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI), Montre'al, Que'bec, pages 333-344, June 1998a.

Necula, George C. and Peter Lee. Efficient representation and validation of logical

proofs. In IEEE Symposium on Logic in Computer Science (LICS), Indianapolis, Inding
ana, pages 93-104, June 1998b.

Niehren, Joachim, Martin Mu"ller, and Andreas Podelski. Inclusion constraints over

nonngempty sets of trees. In Theory and Practice of Software Development (TAPng
SOFT), Lille, France, volume 1214 of Lecture Notes in Computer Science, pages
217-231. SpringerngVerlag, April 1997.

Niehren, Joachim and Tim Priesnitz. Nonngstructural subtype entailment in automata

theory. Information and Computation, 186(2):319-354, November 2003.

Nielson, Flemming and Hanne Riis Nielson. From CML to its process algebra. Theong

retical Computer Science, 155:179-219, 1996.

Nielson, Flemming, Hanne Riis Nielson, and Christopher L. Hankin. Principles of Prong

gram Analysis. SpringerngVerlag, 1999.

Nielson, Flemming, Hanne Riis Nielson, and Helmut Seidl. A succinct solver for ALFP.

Nordic Journal of Computing, 9(4):335-372, 2002.

Nielson, Hanne Riis and Flemming Nielson. Higherngorder concurrent programs with

finite communication topology. In ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages (POPL), Portland, Oregon, pages 84-97, January 1994.

References 555
Nishimura, Susumu. Static typing for dynamic messages. In ACM SIGPLAN-SIGACT

Symposium on Principles of Programming Languages (POPL), San Diego, California,
pages 266-278, 1998.

Niss, Henning. Regions are Imperative: Unscoped Regions and ControlngFlow Sensing

tive Memory Management. PhD thesis, University of Copenhagen, Department of
Computer Science, Copenhagen, Denmark, 2002.

No"cker, Erick and Sjaak Smetsers. Partially strict nonngrecursive data types. Journal

of Functional Programming, 3(2):191-215, 1993.

No"cker, Erick G. M. H., Sjaak E. W. Smetsers, Marko C. J. D. van Eekelen, and Maring

nus J. Plasmeijer. Concurrent clean. In Symposium on Parallel Architectures and
Languages Europe, Volume I: Parallel Architectures and Algorithms (PARLE), Eindng
hoven, The Netherlands, volume 505 of Lecture Notes in Computer Science, pages
202-219. SpringerngVerlag, June 1991.

Odersky, Martin. Observers for linear types. In European Symposium on Programng

ming (ESOP), Rennes, France, volume 582 of Lecture Notes in Computer Science,
pages 390-407. SpringerngVerlag, February 1992.

Odersky, Martin, Vincent Cremet, Christine Rockl, and Matthias Zenger. A nominal

theory of objects with dependent types. In International Workshop on Foundations
of ObjectngOriented Languages (FOOL), informal proceedings, 2003.

Odersky, Martin, Martin Sulzmann, and Martin Wehr. Type inference with constrained

types. Theory and Practice of Object Systems, 5(1):35-55, 1999. Summary in Interng
national Workshop on Foundations of ObjectngOriented Languages (FOOL), informal
proceedings, 1997.

O'Hearn, Peter. On bunched typing. Journal of Functional Programming, 13(4):747-

796, 2003.

O'Hearn, Peter and David Pym. The logic of bunched implications. Bulletin of Symbolic

Logic, 5(2):215-244, 1999.

Ohori, Atsushi. A polymorphic record calculus and its compilation. ACM Transacng

tions on Programming Languages and Systems, 17(6):844-895, November 1995.

Ohori, Atsushi and Peter Buneman. Type inference in a database programming lanng

guage. In ACM Symposium on Lisp and Functional Programming (LFP), Snowbird,
Utah, pages 174-183, July 1988.

Ohori, Atsushi and Peter Buneman. Static type inference for parametric classes. In

Conference on Object Oriented Programming: Systems, Languages, and Applicang
tions (OOPSLA), New Orleans, Louisiana, pages 445-456, October 1989. Also in C.
A. Gunter and J. C. Mitchell, editors, Theoretical Aspects of ObjectngOriented Prong
gramming: Types, Semantics, and Language Design, MIT Press, 1994.

Orlov, Ivan E. The calculus of compatibility of propositions (in Russian). Matematichng

eskii Sbornik, 35:263-286, 1928.

556 References

Owre, Sam, Sreeranga Rajan, John M. Rushby, Natarajan Shankar, and Mandayam K.

Srivas. PVS: Combining specification, proof checking, and model checking. In
International Conference on Computer Aided Verification (CAV), New Brunswick,
New Jersey, volume 1102 of Lecture Notes in Computer Science, pages 411-414.
SpringerngVerlag, July 1996.

Palsberg, Jens. Efficient inference of object types. Information and Computation, 123

(2):198-209, 1995.

Palsberg, Jens. Typengbased analysis and applications. In ACM SIGPLAN-SIGSOFT

Workshop on Program Analysis for Software Tools and Engineering (PASTE), Snowng
bird, Utah, pages 20-27, June 2001.

Palsberg, Jens and Patrick O'Keefe. A type system equivalent to flow analysis. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL), San
Francisco, California, pages 367-378, 1995.

Palsberg, Jens and Michael Schwartzbach. Type substitution for objectngoriented

programming. In ACM SIGPLAN Conference on Object Oriented Programming:
Systems, Languages, and Applications (OOPSLA)/European Conference on Objectng
Oriented Programming (ECOOP), Ottawa, Ontario, volume 25(10) of ACM SIGPLAN
Notices, pages 151-160, October 1990.

Palsberg, Jens and Michael I. Schwartzbach. ObjectngOriented Type Systems. Wiley,

1994.

Palsberg, Jens, Mitchell Wand, and Patrick M. O'Keefe. Type inference with nonng

structural subtyping. Formal Aspects of Computing, 9:49-67, 1997.

Parnas, David. The criteria to be used in decomposing systems into modules. Comng

munications of the ACM, 14(1):221-227, 1972.

Paterson, Michael S. and Mark N. Wegman. Linear unification. Journal of Computer

and System Sciences, 16:158-167, 1978.

PaulinngMohring, Christine. Extracting F!'s programs from proofs in the calculus

of constructions. In ACM Symposium on Principles of Programming Languages
(POPL), Austin, Texas, pages 89-104, January 1989.

Petersen, Leaf, Perry Cheng, Robert Harper, and Chris Stone. Implementing the TILT

internal language. Technical Report CMUngCSng00ng180, Department of Computer Scing
ence, Carnegie Mellon University, 2000.

Petersen, Leaf, Robert Harper, Karl Crary, and Frank Pfenning. A type theory for

memory allocation and data layout. In ACM SIGPLAN-SIGACT Symposium on Prinng
ciples of Programming Languages (POPL), New Orleans, Louisiana, pages 172-184,
January 2003.

Peyton Jones, Simon. Special issue: Haskell 98 language and libraries. Journal of

Functional Programming, 13, January 2003.

Pfenning, Frank and Rowan Davies. A judgmental reconstruction of modal logic.

Mathematical Structures in Computer Science, 11(4):511-540, 2001.

References 557
Pfenning, Frank and Carsten Schu"rmann. Algorithms for equality and unification

in the presence of notational definitions. In T. Altenkirch, W. Naraschewski,
and B. Reus, editors, International Workshop on Types for Proofs and Programs
(TYPES), Kloster Irsee, Germany, volume 1657 of Lecture Notes in Computer Scing
ence. SpringerngVerlag, 1998.

Pierce, Benjamin C. Types and Programming Languages. MIT Press, 2002.
Pierce, Benjamin C. and David N. Turner. Objectngoriented programming without reng

cursive types. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL), Charleston, South Carolina, pages 299-312, January 1993.

Pitts, Andrew M. Relational properties of domains. Information and Computation,

127:66-90, 1996.

Pitts, Andrew M. Existential types: Logical relations and operational equivalence.

In International Colloquium on Automata, Languages and Programming (ICALP),
Aalborg, Denmark, volume 1443 of Lecture Notes in Computer Science, pages 309-
326. SpringerngVerlag, 1998.

Pitts, Andrew M. Parametric polymorphism and operational equivalence. Mathematng

ical Structures in Computer Science, 10:321-359, 2000.

Pitts, Andrew M. Operational semantics and program equivalence. In G. Barthe, P. Dyng

bjer, and J. Saraiva, editors, Applied Semantics, Advanced Lectures, volume 2395 of
Lecture Notes in Computer Science, Tutorial, pages 378-412. SpringerngVerlag, 2002.

Pitts, Andrew M. and Ian D. B. Stark. Observable properties of higher order functions

that dynamically create local names, or: What's new? In International Symposium
on Mathematical Foundations of Computer Science, Gda'nsk, Poland, volume 711 of
Lecture Notes in Computer Science, pages 122-141. SpringerngVerlag, 1993.

Pitts, Andrew M. and Ian D. B. Stark. Operational reasoning for functions with local

state. In A. D. Gordon and A. M. Pitts, editors, HigherngOrder Operational Techniques
in Semantics, Publications of the Newton Institute, pages 227-273. Cambridge Uning
versity Press, 1998.

Plotkin, Gordon D. Lambdangdefinability and logical relations. Memorandum SAI-RM-

4, University of Edinburgh, Edinburgh, Scotland, October 1973.

Plotkin, Gordon D. LCF considered as a programming language. Theoretical Computer

Science, 5:223-255, 1977.

Plotkin, Gordon D. Lambdangdefinability in the full type hierarchy. In J. P. Seldin

and J. R. Hindley, editors, To H. B. Curry: Essays on Combinatory Logic, Lambda
Calculus and Formalism, pages 363-373. Academic Press, 1980.

Plotkin, Gordon D. and Marti'n Abadi. A logic for parametric polymorphism. In Inng

ternational Conference on Typed Lambda Calculi and Applications (TLCA), Utrecht,
The Netherlands, volume 664 of Lecture Notes in Computer Science, pages 361-375.
SpringerngVerlag, March 1993.

558 References

Polakow, Jeff and Frank Pfenning. Natural deduction for intuitionistic nonng

commutative linear logic. In International Conference on Typed Lambda Calculi
and Applications (TLCA), L'Aquila, Italy, volume 1581 of Lecture Notes in Computer
Science, pages 295-309. SpringerngVerlag, April 1999.

Poll, Erik. Expansion Postponement for Normalising Pure Type Systems. Journal of

Functional Programming, 8(1):89-96, 1998.

Pollack, Robert. The Theory of LEGO: A Proof Checker for the Extended Calculus of

Constructions. PhD thesis, University of Edinburgh, Edinburgh, Scotland, 1994.

Popkorn, Sally. First Steps in Modal Logic. Cambridge University Press, 1994.
Pottier, Franc,ois. A versatile constraintngbased type inference system. Nordic Journal

of Computing, 7(4):312-347, November 2000.

Pottier, Franc,ois. A semingsyntactic soundness proof for HMD^XE^. Research Report

4150, INRIA, March 2001a.

Pottier, Franc,ois. Simplifying subtyping constraints: a theory. Information and Comng

putation, 170(2):153-183, November 2001b.

Pottier, Franc,ois. A constraintngbased presentation and generalization of rows. In IEEE

Symposium on Logic in Computer Science (LICS), Ottawa, Canada, pages 331-340,
June 2003.

Pottier, Franc,ois and Vincent Simonet. Information flow inference for ML. ACM Transng

actions on Programming Languages and Systems, 25(1):117-158, January 2003.

Pottier, Franc,ois, Christian Skalka, and Scott Smith. A systematic approach to static

access control. In European Symposium on Programming (ESOP), Genova, Italy,
volume 2028 of Lecture Notes in Computer Science, pages 30-45. SpringerngVerlag,
April 2001.

Pratt, Vaughan and Jerzy Tiuryn. Satisfiability of inequalities in a poset. Fundamenta

Informaticae, 28(1-2):165-182, 1996.

Pugh, William and Grant Weddell. Twongdirectional record layout for multiple inng

heritance. In ACM SIGPLAN Conference on Programming Language Design and
Implementation (PLDI), White Plains, New York, pages 85-91, June 1990.

Rajamani, Sriram K. and Jakob Rehof. A behavioral module system for the pingcalculus.

In International Symposium on Static Analysis (SAS) , Paris, France, volume 2126 of
Lecture Notes in Computer Science, pages 375-394. SpringerngVerlag, July 2001.

Rajamani, Sriram K. and Jakob Rehof. Conformance checking for models of asynng

chronous message passing software. In International Conference on Computer
Aided Verification (CAV), Copenhagen, Denmark, pages 166-179, July 2002.

Rehof, Jakob. Minimal typings in atomic subtyping. In ACM SIGPLAN-SIGACT Symng

posium on Principles of Programming Languages (POPL), Paris, France, pages 278-
291, January 1997.

Rehof, Jakob and Manuel Fa"hndrich. Typengbased flow analysis: From polymorphic

subtyping to CFL reachability. In ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages (POPL), London, England, pages 54-66, 2001.

References 559
Reid, Alastair, Matthew Flatt, Leigh Stoller, Jay Lepreau, and Eric Eide. Knit: Comng

ponent composition for systems software. In USENIX Symposium on Operating
Systems Design and Implementation (OSDI), San Diego, California, pages 347-360,
October 2000.

Re'my, Didier. Typechecking records and variants in a natural extension of ML. In

ACM Symposium on Principles of Programming Languages (POPL), Austin, Texas,
pages 242-249, January 1989. Long version in C. A. Gunter and J. C. Mitchell, edng
itors, Theoretical Aspects of ObjectngOriented Programming: Types, Semantics, and
Language Design, MIT Press, 1994.

Re'my, Didier. Alge`bres Touffues. Application au Typage Polymorphe des Objets Enregng

istrements dans les Langages Fonctionnels. PhD thesis, Universite' Paris VII, 1990.

Re'my, Didier. Extending ML type system with a sorted equational theory. Research

Report 1766, Institut National de Recherche en Informatique et Automatisme, Rocng
quencourt, BP 105, 78 153 Le Chesnay Cedex, France, 1992a.

Re'my, Didier. Projective ML. In ACM Symposium on Lisp and Functional Programming

(LFP), San Francisco, California, pages 66-75, June 1992b.

Re'my, Didier. Syntactic theories and the algebra of record terms. Research Report

1869, Institut National de Recherche en Informatique et Automatisme, Rocquenng
court, BP 105, 78 153 Le Chesnay Cedex, France, 1993.

Re'my, Didier. Programming objects with MLngART: An extension to ML with abstract

and record types. In International Symposium on Theoretical Aspects of Computer
Software (TACS), Sendai, Japan, volume 789 of Lecture Notes in Computer Science,
pages 321-346. SpringerngVerlag, April 1994.

Re'my, Didier and Je'ro^me Vouillon. Objective ML: An effective objectngoriented extenng

sion to ML. Theory And Practice of Object Systems, 4(1):27-50, 1998. Summary
in ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL), Paris, France, 1997.

van Renesse, Robbert, Kenneth P. Birman, Mark Hayden, Alexey Vaysburd, and David

Karr. Building adaptive systems using Ensemble. Software: Practice and Experience,
28(9):963-979, August 1998.

Restall, Greg. An Introduction to Substructural Logics. Routledge, February 2000.
Restall, Greg. Relevant and substructural logics. In D. Gabbay and J. Woods, editors,

Handbook of the History and Philosophy of Logic, volume 6, Logic and the Modalities
in the Twentieth Century. Elsevier, 2005. To appear.

Reynolds, John C. Automatic computation of data set definitions. In Information

Processing 68, Edinburgh, Scotland, volume 1, pages 456-461. North Holland, 1969.

Reynolds, John C. Towards a theory of type structure. In Colloque sur la Programmang

tion, Paris, France, volume 19 of Lecture Notes in Computer Science, pages 408-425.
SpringerngVerlag, 1974.

560 References

Reynolds, John C. Syntactic control of interference. In ACM Symposium on Principles

of Programming Languages (POPL), Tucson, Arizona, pages 39-46, January 1978.
Reprinted in O'Hearn and Tennent, ALGOLnglike Languages, vol. 1, pages 273-286,
Birkha"user, 1997.

Reynolds, John C. Types, abstraction, and parametric polymorphism. In R. E. A.

Mason, editor, Information Processing 83, Paris, France, pages 513-523. Elsevier,
1983.

Reynolds, John C. Syntactic control of interference, part 2. Report CMUngCSng89ng130,

Carnegie Mellon University, April 1989.

Reynolds, John C. Intuitionistic reasoning about shared mutable data structure. In

J. Davies, A. W. Roscoe, and J. Woodcock, editors, Millennial Perspectives in Comng
puter Science: Proceedings of the 1999 OxfordngMicrosoft Symposium in honour of
Sir Tony Hoare. Palgrave Macmillan, 2000.

Robinson, J. Alan. Computational logic: The unification computation. Machine Intelng

ligence, 6:63-72, 1971.

Ross, Douglas T. The AED free storage package. Communications of the ACM, 10(8):

481-492, 1967.

Russo, Claudio V. Types for Modules. PhD thesis, Edinburgh University, Edinburgh,

Scotland, 1998. LFCS Thesis ECS-LFCS-98-389.

Russo, Claudio V. Nonngdependent types for standard ML modules. In ACM SIGPLAN

International Conference on Principles and Practice of Declarative Programming
(PPDP), Paris France, pages 80-97, September 1999.

Russo, Claudio V. Recursive structures for Standard ML. In ACM SIGPLAN Internang

tional Conference on Functional Programming (ICFP), Firenze, Italy, pages 50-61,
September 2001.

Sabry, Amr. What is a purely functional language? Journal of Functional Programng

ming, 8(1):1-22, January 1998.

Saha, Bratin, Nevin Heintze, and Dino Oliva. Subtransitive CFA using types. Technical

Report YALEU/DCS/TRng1166, Yale University, Department of Computer Science,
October 1998.

Sangiorgi, Davide and David. The ssngCalculus: a Theory of Mobile Processes. Camng

bridge University Press, 2001.

Sannella, Donald, Stefan Sokolowski, and Andrzej Tarlecki. Toward formal developng

ment of programs from algebraic specifications: Parameterisation revisited. Acta
Informatica, 29(8):689-736, 1992.

Schneider, Fred B. Enforceable security policies. ACM Transactions on Information

and System Security, 3(1):30-50, February 2000.

Schwartz, Jacob T. Optimization of very high level languages (parts I and II). Comng

puter Languages, 1(2-3):161-194, 197-218, 1975.

References 561
Seldin, Jonathan. Curry's anticipation of the types used in programming languages.

In Proceedings of the Annual Meeting of the Canadian Society for History and Phing
losophy of Mathematics, Toronto, Ontario, pages 143-163, May 2002.

Semmelroth, Miley and Amr Sabry. Monadic encapsulation in ML. In ACM SIGPLAN

International Conference on Functional Programming (ICFP), Paris, France, pages
8-17, September 1999.

Sestoft, Peter. Replacing function parameters by global variables. In ACM Sympong

sium on Functional Programming Languages and Computer Architecture (FPCA),
London, England, pages 39-53, September 1989. Also available as University of
Copenhagen, Department of Computer Science Technical Report 88ng7ng2.

Sestoft, Peter. Moscow ML homepage, 2003. http://www.dina.dk/~sestoft/

mosml.html.

Severi, Paula and Erik Poll. Pure type systems with definitions. In International Symng

posium on Logical Foundations of Computer Science (LFCS), St. Petersburg, Russia,
volume 813 of Lecture Notes in Computer Science, pages 316-328. SpringerngVerlag,
September 1994.

Shao, Zhong. An overview of the FLINT/ML compiler. In ACM SIGPLAN Workshop on

Types in Compilation (TIC), Amsterdam, The Netherlands, June 1997.

Shao, Zhong. Typed crossngmodule compilation. In ACM SIGPLAN International Conng

ference on Functional Programming (ICFP), Baltimore, Maryland, pages 141-152,
September 1998.

Shao, Zhong. Transparent modules with fully syntactic signatures. In ACM SIGPLAN

International Conference on Functional Programming (ICFP), Paris, France, pages
220-232, September 1999.

Shao, Zhong, Christopher League, and Stefan Monnier. Implementing typed interng

mediate languages. In ACM SIGPLAN International Conference on Functional Prong
gramming (ICFP), Baltimore, Maryland, pages 313-323, September 1998.

Shivers, Olin. Control flow analysis in Scheme. In ACM SIGPLAN Conference on Prong

gramming Language Design and Implementation (PLDI), Atlanta, Georgia, pages
164-174, June 1988.

Shivers, Olin. ControlngFlow Analysis of HigherngOrder Languages or Taming Lambda.

PhD thesis, Carnegie Mellon University, Pittsburgh, Pennsylvania, May 1991.

Simonet, Vincent. Type inference with structural subtyping: a faithful formalization

of an efficient constraint solver. In Asian Symposium on Programming Languages
and Systems (APLAS), Beijing, China, pages 283-302, November 2003.

Skalka, Christian and Franc,ois Pottier. Syntactic type soundness for HMD^XE^. In Workng

shop on Types in Programming (TIP), Dagstuhl, Germany, volume 75 of Electronic
Notes in Theoretical Computer Science. Elsevier, July 2002.

Smith, Frederick, David Walker, and Greg Morrisett. Alias types. In European Symng

posium on Programming (ESOP), Berlin, Germany, volume 1782 of Lecture Notes in
Computer Science, pages 366-381. SpringerngVerlag, April 2000.

562 References

Smith, Geoffrey S. Principal type schemes for functional programs with overloading

and subtyping. Science of Computer Programming, 23(2-3):197-226, December
1994.

Smith, Jan, Bengt Nordstro"m, and Kent Petersson. Programming in MartinngLo"f's Type

Theory: An Introduction. Oxford University Press, 1990.

Statman, Richard. Logical relations and the typed *ngcalculus. Information and Conng

trol, 65(2-3):85-97, May-June 1985.

Steele, Guy L., Jr. Common Lisp: The Language. Digital Press, 1990.
Stone, Christopher A. Singleton Kinds and Singleton Types. PhD thesis, Carnegie

Mellon University, Pittsburgh, Pennsylvania, August 2000.

Stone, Christopher A. and Robert Harper. Deciding type equivalence in a language

with singleton kinds. In ACM SIGPLAN-SIGACT Symposium on Principles of Prong
gramming Languages (POPL), Boston, Massachusetts, pages 214-227, January 2000.

Stone, Christopher A. and Robert Harper. Extensional equivalence and singleton

types. 2005. To appear.

Streicher, Thomas. Semantics of Type Theory. SpringerngVerlag, 1991.
Su, Zhendong, Alexander Aiken, Joachim Niehren, Tim Priesnitz, and Ralf Treinen.

The firstngorder theory of subtyping constraints. In ACM SIGPLAN-SIGACT Symng
posium on Principles of Programming Languages (POPL), Portland, Oregon, pages
203-216, January 2002.

Sulzmann, Martin. A General Framework for Hindley/Milner Type Systems with Conng

straints. PhD thesis, Yale University, Department of Computer Science, New Haven,
Connecticut, May 2000.

Sulzmann, Martin, Martin Mu"ller, and Christoph Zenger. Hindley/Milner style type

systems in constraint form. Research Report ACRC-99-009, University of South
Australia, School of Computer and Information Science, July 1999.

Sumii, Eijiro and Benjamin C. Pierce. A bisimulation for type abstraction and reng

cursion. In ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lanng
guages (POPL), Long Beach, California, 2005.

Sun. JavaTM 2 Platform Micro Edition (J2METM) Technology for Creating Mobile

Devices--White Paper. Sun Microsystems, May 2000. Available from http://java.
sun.com/products/kvm/wp/KVMwp.pdf.

Tait, William W. Intensional interpretations of functionals of finite type I. Journal of

Symbolic Logic, 32(2):198-212, June 1967.

Talcott, C. Reasoning about functions with effects. In A. D. Gordon and A. M. Pitts,

editors, Higher Order Operational Techniques in Semantics, Publications of the
Newton Institute, pages 347-390. Cambridge University Press, 1998.

Talpin, JeanngPierre and Pierre Jouvelot. Polymorphic type, region and effect inference.

Journal of Functional Programming, 2(2):245-271, 1992.

References 563
Talpin, JeanngPierre and Pierre Jouvelot. The type and effect discipline. Information

and Computation, 111:245-296, 1994.

Tarditi, David, Greg Morrisett, Perry Cheng, Christopher Stone, Robert Harper, and

Peter Lee. TIL: A typengdirected optimizing compiler for ML. In ACM SIGPLAN Conng
ference on Programming Language Design and Implementation (PLDI), Philadephia,
Pennsylvania, pages 181-192, May 1996.

Tarjan, Robert Endre. Efficiency of a good but not linear set union algorithm. Journal

of the ACM, 22(2):215-225, April 1975.

Tarjan, Robert Endre. Applications of path compression on balanced trees. Journal

of the ACM, 26(4):690-715, October 1979.

Terlouw, J. Een nadere bewijstheoretische analyse van GSTTs. Manuscript, University

of Nijmegen, Netherlands, 1989.

Thorup, Kresten Krab. Genericity in Java with virtual types. In European Conferng

ence on ObjectngOriented Programming (ECOOP), Jyva"skyla", Finland, volume 1241
of Lecture Notes in Computer Science, pages 444-471. SpringerngVerlag, June 1997.

Tiuryn, Jerzy. Subtype inequalities. In IEEE Symposium on Logic in Computer Science

(LICS), Santa Cruz, California, pages 308-317, June 1992.

Tiuryn, Jerzy and Mitchell Wand. Type reconstruction with recursive types and

atomic subtyping. In Theory and Practice of Software Development (TAPSOFT),
Orsay, France, volume 668 of Lecture Notes in Computer Science, pages 686-701.
SpringerngVerlag, April 1993.

Tofte, Mads. Operational Semantics and Polymorphic Type Inference. PhD thesis,

Computer Science Department, Edinburgh University, Edinburgh, Scotland, 1988.

Tofte, Mads and Lars Birkedal. A region inference algorithm. ACM Transactions on

Programming Languages and Systems, 20(4):724-767, 1998.

Tofte, Mads, Lars Birkedal, Martin Elsman, and Niels Hallenberg. Regionngbased memng

ory management in perspective. In ACM SIGPLAN International Conference on
Principles and Practice of Declarative Programming (PPDP), Firenze, Italy, pages
175-186, September 2001a.

Tofte, Mads, Lars Birkedal, Martin Elsman, Niels Hallenberg, Tommy Ho/jfeld Olesen,

and Peter Sestoft. Programming with regions in the ML Kit (for version 4). Technical
report, IT University of Copenhagen, October 2001b.

Tofte, Mads and JeanngPierre Talpin. Implementing the callngbyngvalue lambdangcalculus

using a stack of regions. In ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages (POPL), Portland, Oregon, January 1994.

Tofte, Mads and JeanngPierre Talpin. Regionngbased memory management. Information

and Computation, 132(2):109-176, February 1997.

Torgersen, Mads. Virtual types are statically safe. In International Workshop on Founng

dations of ObjectngOriented Languages (FOOL), informal proceedings, January 1998.

564 References

Trifonov, Valery and Scott Smith. Subtyping constrained types. In International Symng

posium on Static Analysis (SAS) , Aachen, Germany, volume 1145 of Lecture Notes
in Computer Science, pages 349-365. SpringerngVerlag, September 1996.

Turner, David N. and Philip Wadler. Operational interpretations of linear logic. Theng

oretical Computer Science, 227:231-248, 1999. Special issue on linear logic.

Turner, David N., Philip Wadler, and Christian Mossin. Once upon a type. In ACM

Symposium on Functional Programming Languages and Computer Architecture
(FPCA)San Diego, California, pages 1-11, June 1995.

Vouillon, Jerome and PaulngAndre' Mellie`s. Semantic types: A fresh look at the ideal

model for types. In ACM SIGPLAN-SIGACT Symposium on Principles of Programng
ming Languages (POPL), Venice, Italy, pages 52-63, 2004.

Wadler, Philip. Theorems for free! In ACM Symposium on Functional Programming

Languages and Computer Architecture (FPCA), London, England, pages 347-359,
September 1989.

Wadler, Philip. Linear types can change the world. In IFIP TC 2 Working Conference

on Programming Concepts and Methods, Sea of Galilee, Israel, pages 546-566, April
1990.

Wadler, Philip. The marriage of effects and monads. ACM Transactions on Computang

tional Logic, 4(1):1-32, 2003.

Wahbe, Robert, Steven Lucco, Thomas E. Anderson, and Susan L. Graham. Efficient

softwarengbased fault isolation. In ACM Symposium on Operating Systems Principles
(SOSP), Asheville, North Carolina, pages 203-216, December 1993.

Walker, David, Karl Crary, and Greg Morrisett. Typed memory management via static

capabilities. ACM Transactions on Programming Languages and Systems, 22(4):
701-771, July 2000.

Walker, David and Greg Morrisett. Alias types for recursive data structures. In ACM

SIGPLAN Workshop on Types in Compilation (TIC), Montre'al, Que'bec, September,
2000, volume 2071, pages 177-206. SpringerngVerlag, 2001.

Walker, David and Kevin Watkins. On regions and linear types. In ACM SIGPLAN

International Conference on Functional Programming (ICFP), Firenze, Italy, pages
181-192, September 2001.

Wand, Mitchell. Complete type inference for simple objects. In IEEE Symposium on

Logic in Computer Science (LICS), Ithaca, New York, pages 37-44, June 1987a.

Wand, Mitchell. A simple algorithm and proof for type inference. Fundamenta Inforng

maticae, 10:115-122, 1987b.

Wand, Mitchell. Corrigendum: Complete type inference for simple objects. In IEEE

Symposium on Logic in Computer Science (LICS), Edinburgh, Scotland, page 132,
1988.

Wand, Mitchell. Type inference for objects with instance variables and inheritance.

In C. A. Gunter and J. C. Mitchell, editors, Theoretical Aspects of ObjectngOriented

References 565

Programming: Types, Semantics, and Language Design, pages 97-120. MIT Press,
1994.

Wang, Daniel C. and Andrew W. Appel. Typengpreserving garbage collectors. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL),
London, England, pages 166-178, January 2001.

Wansbrough, Keith and Simon Peyton Jones. Once upon a polymorphic type. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL), San
Antonio, Texas, pages 15-28, January 1999.

Wells, Joe B. Typability and type checking in system F are equivalent and undecidable.

Annals of Pure and Applied Logic, 98(1-3):111-156, 1999.

Wells, Joe B. The essence of principal typings. In International Colloquium on Aung

tomata, Languages and Programming (ICALP), volume 2380 of Lecture Notes in
Computer Science, pages 913-925. SpringerngVerlag, 2002.

Werner, Benjamin. Une The'orie des Constructions Inductives. PhD thesis, Universite'

Paris 7, Paris, France, May 1994.

Wirth, Niklaus. Systematic Programming: An Introduction. Prentice Hall, 1973.
Wirth, Niklaus. Programming in Modulang2. Texts and Monographs in Computer Scing

ence. SpringerngVerlag, 1983.

Wright, Andrew K. Simple imperative polymorphism. Lisp and Symbolic Computation,

8(4):343-355, 1995.

Wright, Andrew K. and Robert Cartwright. A practical soft type system for Scheme.

In ACM Symposium on Lisp and Functional Programming (LFP), Orlando, Florida,
pages 250-262, June 1994. Full version available in ACM Transactions on Programng
ming Languages and Systems, 19(1):87-52, January 1997.

Wright, Andrew K. and Matthias Felleisen. A syntactic approach to type soundness.

Information and Computation, 115(1):38-94, November 1994.

Xi, Hongwei. Dependent Types in Practical Programming. PhD thesis, Carnegie Mellon

University, Pittsburgh, Pennsylvania, 1998.

Xi, Hongwei and Robert Harper. A dependently typed assembly language. In ACM SIGng

PLAN International Conference on Functional Programming (ICFP), Firenze, Italy,
pages 169-180, September 2001.

Xi, Hongwei and Frank Pfenning. Dependent types in practical programming. In ACM

SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL), San
Antonio, Texas, pages 214-227, January 1999.

Zenger, Christoph. Indexed types. Theoretical Computer Science, 187:147-165, 1997.
Zwanenburg, Jan. Pure type systems with subtyping. In International Conference

on Typed Lambda Calculi and Applications (TLCA), L'Aquila, Italy, volume 1581 of
Lecture Notes in Computer Science, pages 381-396. SpringerngVerlag, April 1999.

Index
0CFA, 101
n' "quick check" exercise, xii
n'n' easy exercise, xii
n'n'n' moderate exercise, xii
n'n'n'n' challenging exercise, xii
3 exercise without solution, xii

Angnormal form, 253
abbreviations, see type definitions
abstract types, 245-289, see also modng

ules, 454
access control with linear types, 3
adequacy, 277
admissible property, 259
affine types, see substructural types
Agda, 66
ALF, 68, 69
Alfa, 66
algebraic data types and type inference,

453-458
algorithmic type checking, see also unng

decidability
for the calculus of constructions,

66
for LF, 56-60, 62-63
for linear lambdangcalculus, 11-14
aliasing, see also syntactic control of

interference
and typed assembly language, 156
alias types, see typed assembly language
applicative bisimilarity, 288

arrays

and typed assembly language, 170-

171
in linear type systems, 24-28
AUTOMATH, 86, 384
avoidance problem, see signatures

Barendregt cube, see lambda cube
behavioral type systems, 105
bisimilarity, 288
bunched logic, see substructural logng

ics
bunched types, see substructural types

C, 43, 90, 106, 133, 343
C#, 142
Calculus of Capabilities, 134
Calculus of Constructions, 64-71, 86

with dependent sum types, 69-71
Calculus of Inductive Constructions,

66-69
Caml, 389
capability types and typed assembly

language, 175
Cayenne, 74, 305
CC, see Calculus of Constructions
CIC, see Calculus of Inductive Construcng

tions
ciungequivalence, 264, 288
Clean, 43, 389
CLI, see Common Language Infrastrucng

ture

568 Index

closing substitution, 263
closure analysis, 100
closures in TAL, 168-170
CLU, 343
coherence, see modules
Common Language Infrastructure, 139,

142, 178
compilation, separate, see modules
compilation, typengpreserving, 141
compiler optimizations

enabled by affine and relevant types,

39-40
enabled by linear types, 19
computational *ngcalculus, 105
concatenation of records, see type inng

ference
constraints, see also type inference

for type inference, 407-422
generation, 429-434
solving, 438-450
containment rules, see substructural

types
context

evaluation, 256
context splitting, see substructural types
contextual equivalence, 249, 261-266

vs. bisimilarity, 288
continuationngpassing style and regions,

132
contraction, see structural properties
control flow analysis, 100
control flow safety, see typed assemng

bly language
Coq, 66, 67, 86, 175, 384
cryptographic authentication infrastrucng

ture, see proofngcarrying code
CurryngHoward correspondence

and dependent types, 48-49
and linear logic, 41
cutngoff compilation, 303
Cyclone, 43, 90, 132-134, 174

Damas-Milner type system, 399-406

relation with HMD^XE^, 428-429

data types and type inference, 453-

458
decidability, see undecidability
definitional equality, see equivalence

checking
definitions, see type definitions
deltangreduction, 395
deltangreduction of type definitions, 354
Dependent ML, 74-82
dependent types, 45-86, see also LF,

calculus of constructions, calcung
lus of inductive constructions
and typed assembly language, 171-

172
decidable type checking for restricted

systems, 75
higherngorder abstract syntax and,

49, 206
implementation, 83-85
indexed types, 75
products, 46
semantics, 86
sums, 61-63, 69-71
sums vs. existentials (weak sums),

70
type inference, 82
undecidability of type checking, 74-

75
with substructural types, 43
dependently vs. statically typed lanng

guages, 305
determinate module, 363
DML, see Dependent ML
dot notation for existential types, 308

ECC, see Extended Calculus of Construcng

tions
Edinburgh Logical Framework, see LF
effect type systems, 89-90, 102-123,

see also regions
applications, 87
and interference analysis, 105
polymorphism, 114
and protocol verification, 105
region inference, 89-90

Index 569

and soundness of value flow analng

ysis, 104
with substructural types, 43
Tofte-Talpin type system, 89, 101,

114-123
value restriction and polymorphism,

123
effects, 390
equirecursive types, 454, 459
equivalence, see contextual equivalence,

cuingequivalence
equivalence checking, 223-244

definitional equality, 54
for LF, 53-54
erasure

in regionngbased analysis, 111-114
in value flow analysis, 93-97
evaluation context, 256
evaluation frame, 257
exchange, see structural properties
exercises, difficulty ratings, xii
existential types, see also abstract types

in typed assembly language, 168
vs. Sigma types, 70
vs. signatures, 307, 308
in typed assembly language, 167
Extended Calculus of Constructions, 70
extensionality principle, 225, 249, 250,

252, 279
external name, see modules
external references between modules,

294

families of modules, see modules
families of signatures, see signatures
fibered signatures, see signatures
Finitary PCF, 90
firstngclass modules, see modules
foundational proofngcarrying code (FPCC),

see proofngcarrying code
frame

evaluation, 257
functors, see modules
fundamental property, see logical reng

lations

Galois connection, 267
garbage collection, see memory manng

agement
generalization of a type scheme, 402-

404
generic programming, 345
Glasgow Haskell Compiler, 39, 43

Haskell, 43, 74, 334, 342, 344, 389
Herbrand universe, 411
hiding, see abstract types, modules
higherngorder abstract syntax in depenng

dent type systems, 49, 206
higherngorder modules, see modules
HM(X), see type inference
Hope, 343
Howe's method, 288

implicit syntax, see type inference and

dependent types
incremental compilation, see modules
indexed types, see dependent types
inference, see type inference
information hiding, see abstract types,

modules
instantiation of a type scheme, 402-

404, 407, 408
interfaces, see signatures
interference, see aliasing
interference analysis via effect type sysng

tems, 105
internal name, see modules
isorecursive types, 289, 454, 458, 459

Java, 90, 141, 142, 187, 300, 303, 305,

343
Java Virtual Machine, 139, 142, 178,

189
judgmentsngasngtypes, see LF

Kripke logical relation, 237
lambda cube, 71-73, 86
languagengbased security, see proofngcarrying

code, typed assembly language

570 Index

LCF, 389
LEGO, 66, 70, 85, 86
LF, 49-63, 86, 175

algorithmic type checking, 56-60,

62-63
with dependent sum types, 61-63
implicit, in proofngcarrying code sysng

tems, 211-214
Linear, 42
in proofngcarrying code systems, 205-

214
linear lambdangcalculus, 6-30

algorithmic type checking, 11-14
and arrays, 24-28
polymorphic, 20-24
with reference counting, 28-30
Linear LF, 42
linear logic, see substructural logics
linear types, see substructural types
linking, see modules
Lisp, 343
logical equivalence, 234
Logical Frameworks, see LF
logical relations, 223-289

fundamental property, 239-243, 274
history, 243-244
Kripke, 237
monotonicity, 235-237
operationally based, 266
and "recursive language features",

289

manifest types, see type definitions
memory management, see also regions

with linear types, 7, 14
with linear types and regions, 42,

132
reference counting, 28-30, 41
reuse, 111
stack discipline, 30, 89, 99, 157
with substructural types, 4
and typed assembly language, 174
memory safety, see typed assembly lanng

guage

Microsoft Common Language Infrasng

tructure, see Common Language
Infrastructure
mixin modules, 343
ML, 141, 142, 389-489

meanings of the term, 389
ML Kit, 90, 123, 128-130, 133
ML module system, see modules
ML type inference, see type inference
mobile code, see proofngcarrying code,

typed assembly language
Modulang2 and Modulang3, 343
modules, see also signatures

abstract type components, 307-317
applicative vs. generative functors,

336-338
coherence, 327-333
determinacy, 312-315
in existing programming languages,

341-343
external references between, 294
families of, 324-338
firstngclass, 312, 338-339
functors, 324-338
functors and determinacy, 336-338
hierarchies, 317-320
higherngorder, 339-340
internal vs. external names, 296, 317-

320
linking, 303-304
mixin modules, 343
ML module system, 341-342
phase distinction, 305-307
pragmatics of functors, 333-336
recursive, 341
separate and incremental compilang

tion, 302-303
static vs. dynamic equivalence, 340
units, 343
monad, 105
monotonicity property of logical relang

tions, 271

nominal vs. structural signature matchng

ing, 299

Index 571
nonstructural subtyping, 412
normalizengandngcompare algorithm for

equivalence checking, 225
NuPrl, 54

object encodings in TAL, 168-170
Objective Caml, 342, 343
objects, type inference for, 459
occurs check, 439
opaque interface, 358
operational extensionality, see extenng

sionality principle
operational reasoning using types, 245-

289
ordered lambdangcalculus, 30-36, 42
ordered logic, see substructural logics
ordered types, see substructural types

parameterized modules, see modules
parameterized signatures, see signatures
parametricity, see relational parametricng

ity
parametric polymorphism, see polymorng

phism
Pascal, 343
PCC, see proofngcarrying code
Pebble, 74, 305
phantom types, 455
phase distinction, see also modules

and dependent types, 75
phase splitting, see type definitions
Pi types, see dependent types
pointers, shared vs. unique, 157
polymorphic record update, 460
polymorphic recursion, 154, 452
polymorphic variants, 483-486
polymorphism, see also type inference

and regions, 110
in effect type systems, 114
in linear type systems, 20-24
and regions, 108
in typed assembly language, 146
in value flow analysis, 101
preng and postconditions, in proofngcarrying

code, 184

principal signature, see signatures
principal type schemes, 405, 430
principal typings, 430
privacy, guaranteeing with PCC, 216-

218
program analysis, typengbased, 87-135
program equivalence, see typed operng

ational reasoning
programming languages

C, 43, 90, 106, 133, 343
C#, 142
Caml, 389
Cayenne, 74, 305
Clean, 43, 389
CLU, 343
Cyclone, 43, 90, 132-134, 174
Dependent ML, 75-82
Haskell, 43, 74, 334, 342, 344, 389
Hope, 343
Java, 90, 141, 142, 187, 300, 303,

305, 343
LF, 86
Lisp, 343
ML, 141, 142, 389-489
ML Kit, 90, 123, 128-130, 133
Modulang2 and Modulang3, 343
Objective Caml, 342, 343
Pascal, 343
Pebble, 74, 305
Prolog, 90, 127, 134
Quest, 74
Russell, 305
Scheme, 305
Standard ML, 255, 341, 343, 345,

389
Vault, 43, 90
Prolog, 90, 127, 134
proofngcarrying code, 139-140, 177-220

architecture, 178-180
beyond types, 216-218
costs, 211, 220
for cryptographic authentication, 219
efficient proof representation in imng

plicit LF, 211-214

572 Index

foundational, 155, 175, 178
guaranteeing privacy, 216-218
preng and postconditions, 184
program annotation, 193
proof checking as LF type checkng

ing, 209-211
proof generation, 214-215
proof representation in LF, 205-214
safety policy, 182-187
and substructural types, 40
symbolic evaluation, 190-192, 194-

195
vs. typed assembly language, 141,

155, 178, 189
verification condition generation, 187-

190
propositionsngasngtypes, see CurryngHoward

correspondence
protocol verification with effect type

systems, 105
pure type systems (PTS), 71-73
PVS, 74

qualified types, 488
qualifiers, see type qualifiers
Quest, 74

record operations, 460-489
record update and extension, polymorng

phic, 460
recursive definitions, 398
recursive modules, see modules
recursive types, see also modules, reng

cursive
in linear type systems, 17
and type inference, 453-460
reference counting, see also memory

management
in linear type systems, 28-30, 41
references, 390, 398, 435, 452, see also

effects
regions, 87-135, see also effect type

systems
and continuationngpassing style, 132
erasure, 111-114

imperative, 131-132
inference, 89-90, 101, 123-127
lexically scoped, 89, 99-100
and linear types, 42, 132
polymorphic, 108-110
practical memoryngmanagement sysng

tems, 133-135
reuse of deallocated memory, 111
safety properties, 87, 106
and stackngoriented memory manageng

ment, 89, 99
and typed assembly language, 173,

175
register file type, 146
relational parametricity, 245, 271, 286,

287
relevant logic, see substructural logics
relevant types, see substructural types
resource management, see memory manng

agement, regions
row variables, see type inference
Russell, 305

safety policy, see proofngcarrying code
Scheme, 305
scheme, see type scheme
Scott induction, 259
sealing, see signatures, 362
security, see proofngcarrying code, typed

assembly language
separate compilation, see modules
setngbased analysis, 101
Sigma types, see dependent types
signatures, see also modules

avoidance problem, 315-317, 365
dot notation, 307
vs. existential types, 307, 308
families of, 320-324
fibered vs. parameterized, 322-324
matching, 299
nominal vs. structural matching, 299
opaque, 307
principal, 298, 301
role in separate compilation, 295
sealing, 310-312

Index 573

sealing, static vs. dynamic, 338
subsumption principle for, 299
translucent, 307-310
transparent, 307
singleton kinds, see type definitions
singleton types, 385
software fault isolation, 140
sorts in pure type systems, 72
stack typing, see typed assembly lanng

guage
Standard ML, 255, 341, 343, 345, 389
statically vs. dependently typed lanng

guages, 305
strictness analysis, 43
strict types, see relevant types
strong sum types, see dependent types
structural properties, 4-6

contraction, 4, 11, 41
exchange, 4, 11, 31, 32
weakening, 4, 11, 41
structural subtyping, 412
structural vs. nominal signature matchng

ing, 299
structures, see modules
submodules, see modules
substructural logics, 40-42
substructural types, 3-43

affine types, 5, 36-40, 43
bunched types, 42
containment rules, 9, 33
context splitting, 9, 42
context splitting, algorithmic, 11
with dependent types, 43
with effect type systems, 43
linear types, 5-30, 41, 43
ordered types, 5, 30-36, 42
relevant types, 5, 39
temporal resource management, 36
uniqueness types, 43
subtyping, see also constraints

and typed assembly language, 173
cong and contrangvariance, 412, 415
structural vs. nonstructural, 412

sum types, see also algebraic data types,

variant types
in dependent type systems, 61-63
in linear type systems, 17
surjective pairing, 62
symbolic evaluation, see proofngcarrying

code
syntactic control of interference, 41
syntaxngdirectedness, see algorithmic type

checking

TAL, see typed assembly language
TAPL, ix
temporal resource management with

substructural types, 36
theorem provers

Agda, 66
ALF, 68, 69
Alfa, 66
AUTOMATH, 86, 384
Coq, 66, 67, 86, 175, 384
LCF, 389
LEGO, 66, 70, 85, 86
NuPrl, 54
PVS, 74
TIL, see typed intermediate language
Tofte-Talpin type system, see effect type

systems
Touchstone PCC architecture, see proofng

carrying code
translucent sums, see type definitions
transparent interface, 358
typengbased program analysis, 87-135
type checking, see algorithmic type checkng

ing
type definitions, 347-385

for algebraic data types, 454
deltangreduction, 354
in module interfaces, 358-367
manifest types, 358
phase splitting, 378-384
primitive, 351-358
singleton kinds, 367-384
translucent sums, 358-367
type inference, 389-489

574 Index

and algebraic data types, 453-458
and dependent types, 82
HM(X), 389-489
objects, 459, 461, 486
polymorphic variants, 483-486
records, 460-489
and recursive types, 453-460
regions, 101, 123-127
regions and effect types, 89-90
row variables, 460-489
in typed assembly language, 154
and value flow analysis, 97-98
typengpreserving compilation, 141
type qualifiers, 7

linear qualifier, 7
ordered qualifier, 32
quantification over, 21
reference counting qualifier, 28
unrestricted qualifier, 7
type reconstruction, see type inference
type scheme, 402-404, 407
typed assembly language, 139-175

and aliasing, 156
and alias types, 157
and arrays, 170-171
and capability types, 175
closures, 168-170
compiling to, 164-172
control flow safety, 142-155
and dependent types, 171-172
encoding objects, 168-170
ensuring memory safety, 155-172
and existential types, 167-168
memory management, 174
and origins of Cyclone, 134
polymorphism, 146
vs. proofngcarrying code, 141, 155,

178, 189
and regions, 173, 175
stackngallocated memory, 157
and substructural types, 40
and stack typing, 173
and subtyping, 173
TALT, 173-175

TALx86, 170, 171, 173, 174
and type inference, 154
typed intermediate language, 142, see

also typed assembly language
typed operational reasoning, 245-289
typed operational semantics, 86
type and effect systems, see effect type

systems
Types and Programming Languages,

ix

undecidability

of dependent type checking, 54, 74-

75
of module type systems, 339
of type inference with polymorphic

recursion, 452
unification, 439-442

with record types, 476
uniqueness types, see substructural types
units, 343
untrusted code, see proofngcarrying code,

typed assembly language
unwinding property, 259-260
UTT, 86

value flow analysis, 88, 90-102

constraintngbased, 101
erasure, 93-97
polymorphic, 101
soundness with effect types, 104
type inference, 97-98
unsoundness without effect types,

88, 99
value restriction, 255, 437

in effect type systems, 123
variants, polymorphic, 483-486
Vault, 43, 90
verification conditions, see proofngcarrying

code

weak head normalization, 57, 230
weak sum types, see dependent types
weakening, see structural properties
web resources, xii