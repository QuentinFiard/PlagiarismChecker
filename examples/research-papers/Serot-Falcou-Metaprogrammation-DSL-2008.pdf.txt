

janvier 2008 - Journ'ees Francophones des Langages Applicatifs- JFLA08

M'etaprogrammation fonctionnelle appliqu'ee `a la

g'en'eration d'un DSL d'edi'e `a la programmation

parall`ele

J. S'erot1 & J. Falcou2
1: LASMEA - UMR 6602 CNRS/UBP,Campus des C'ezeaux, 63177 Aubi`ere CEDEX
Jocelyn.Serot@lasmea.univ-bpclermont.fr2: IEF - U. Paris-Sud Orsay

joel.falcou@ief.u-psud.fr

R'esum'e
On d'ecrit l'impl'ementation en MetaOcaml d'un petit langage d'edi'e (DSL) `a la
programmation parall`ele. Le langage repose sur la notion de squelettes qui autorisent la
sp'ecification de programmes parall`eles par simple composition de constructeurs de haut niveau
encapsulant des sch'emas communs et r'ecurrents de parall'elisme. On montre comment les facilit'es
de m'etaprogrammation offertes par MetaOcaml permettent d''eliminer presque totalement le
surco^ut `a l'ex'ecution du code g'en'er'e par rapport `a une implantation du m^eme programme 'ecrite
avec des primitives de bas niveau comme celles de mpi. Pour cela, la sp'ecification haut niveau
du programme est d'abord transform'ee en une repr'esentation 'equivalente sous la forme d'un
r'eseau de processus s'equentiels communiquants puis cette repr'esentation est utilis'ee pour g'en'erer
dynamiquement le code ex'ecut'e par chaque processeur de la machine.

1. Introduction

De nos jours, le principal style de programmation utilis'e pour exploiter les clusters de calculest celui dit par passage de messages, support'e par exemple par des biblioth`eques comme

mpi. Leprogrammeur est amen'e `a d'ecomposer explicitement son application en processus communiquants et

`a ordonnancer "`a la main" les communications entre ces processus. Cette approche, si elle permet `aun programmeur exp'eriment'e de tirer le meilleur parti d'une architecture donn'ee, conduit toutefois `a
des programmes longs `a 'ecrire et `a mettre au point compte-tenu du tr`es faible niveau d'abstractionutilis'e.

Les squelettes de parall'elisation ont 'et'e propos'es en r'eponse `a ce probl`eme. Un squelette encapsuleun sch'ema de parall'elisation r'ecurrent pour lequel une ou plusieurs impl'ementations efficaces sont
connues. De tels squelettes se pr'esentent classiquement comme des constructeurs g'en'eriques qui doivent^etre instanci'es avec les fonctions sp'ecifiques de l'application. Des exemples classiques de squelettes sont
pipeline, farm et divide-and-conquer. Avec cette approche, le travail du programmeur se limite`a choisir et combiner un ensemble de squelettes pris dans une base pr'ed'efinie, sans qu'il ait `a se
pr'eoccuper des d'etails de mise en oeuvre du parall'elisme sur l'architecture.

Les squelettes constituent un exemple de langage sp'ecifique d'un domaine d'application (DSL,Domain Specific Language) r'epondant `a un besoin d'abstraction. La n'ecessit'e de disposer d'un

formalisme permettant de sp'ecifier, puis de raisonner sur les programmes est une des raisons expliquantl'int'er^et pour ces approches. De nombreux travaux ont 'et'e consacr'es `a la d'efinition `a l'implantation

153

S'erot & Falcou
de syst`emes de programmation parall`eles fond'es sur les squelettes [1, 7, 2, 10, 9, 19]. Ces r'ealisationsiff`erent essentiellement sur la mani`ere dont le DSL correspondant est implant'e. En pratique cela
suppose de d'efinir la syntaxe et la s'emantique de ce DSL d'une part et les r`egles de transformationpermettant de passer de cette sp'ecification haut niveau `a une impl'ementation concr`ete bas niveau -
faisant appel `a des primitives mpi par exemple - d'autre part.

Pour la plupart des r'ealisations cit'ees, le DSL est implant'e sous la forme d'une biblioth`eque d'edi'eeau sein d'un langage de programmation h^ote (C++ ou Caml par exemple). Cette approche offre en

effet deux avantages : elle 'evite d'avoir `a implanter un analyseur lexical et syntaxique d'edi'e et ellefacilite l'interfa,cage aux fonctions s'equentielles (soit parce que ces fonctions sont 'ecrites dans le langage
h^ote, soit parce que cet interfacage peut se faire via les facilit'es offertes par ce langage h^ote). Mais,en contrepartie, cette mani`ere de proc'eder conduit `a des impl'ementations relativement peu efficaces,
compar'ees au code "bas-niveau" qu'un programmeur aurait 'ecrit pour le m^eme probl`eme. En effet,les squelettes 'etant par essence des objets d'ordre sup'erieur, leur support au sein d'un langage de
programmation implique toujours un surco^ut `a l'ex'ecution par rapport `a un code bas-niveau faisantappel directement `a des primitives

mpi.

Nous expliquons dans ce papier comment les techniques d''evaluation partielle et de m'etaprogramma-tion - utilis'es par ailleurs avec succ`es dans d'autres domaines d'applications - peuvent ^etre exploit'ees

pour r'esoudre le probl`eme sus-cit'e. Plus pr'ecis'ement, nous d'ecrivons l'implantation, en MetaOcaml,d'un petit DSL permettant

- la sp'ecification de programmes parall`eles sous la forme de combinaisons de squelettes- la g'en'eration automatique d'un programme bas-niveau 'equivalent, sous la forme d'un ensemble

de processus s'equentiels communiquants- l'ex'ecution de ce programme sur une architecture de type cluster via la biblioth`eque

mpi.

La plan suivi est le suivant. La section 2 rappelle bri`evement le principe de la m'etaprogrammationet comment celle-ci est support'ee au sein du langage M

etaOcaml. Dans la section 3 on explique enquoi cette technique pr'esente un int'er^et dans le contexte de la programmation parall`ele par passage de

messages. La section 4 est consacr'ee `a la pr'esentation d'un DSL d'edi'e `a programmation parall`ele parsquelettes. La s'emantique de ce langage est explicit'ee en termes de r'eseaux de processus s'equentiels
communiquants puis on en d'erive une impl'ementation en MetaOcaml. La section 5 pr'esente lesr'esultats exp'erimentaux obtenus avec cette impl'ementation. Un bref 'etat de l'art est fait dans la
section 6. La conclusion permet de faire le bilan des apports de ce premier prototype et d'indiquer lespistes de travail `a court et moyen termes.

2. M'etaprogrammation en MetaOcaml

De mani`ere tr`es g'en'erale, la m'etaprogrammation est la technique par laquelle un programmeparticulier peut analyser, transformer et g'en'erer d'autres programmes. La programmation multiniveaux (multi-staged programming), support'ee par le langage MetaOcaml, est une une instanceparticuli`ere de cette technique.

MetaOcaml [20] est une extension du langage Ocaml [17] permettant- de distinguer, gr^ace `a un syst`eme du "quotation", au moins deux niveaux dans un programme :

celui du code g'en'erant (le m'etaprogramme) et celui du code g'en'er'e (les programmes objets).- de g'en'erer et d'ex'ecuter le code correspondant `a ces programmes objets `a l'ex'ecution
- de garantir statiquement, via un syst`eme de typage adapt'e, que ceci se fait sans risque d'erreur`a l'ex'ecution
En pratique, cela signifie qu'un programme MetaOcaml peut, lors de son ex'ecution, construired'autres programmes et les ex'ecuter. Ceci se fait `a l'aide de trois constructeurs, nomm'es Brackets,
Escape et Run :

- la construction .< >. (brackets) permet de d'elimiter les fragments des programmes objets et

154

M'etaprogrammation fonctionnelle appliqu'ee `a la g'en'eration d'un DSL
donc `a retarder l'ex'ecution du code correspondant :
# let a = .< 1+2 >.;;
val a : int code = .<(1+2)>.

L'expression 1+2 n'est pas 'evalu'ee mais sa repr'esentation est m'emoris'ee dans la valeur a. Le typede

a refl`ete ceci1 : int code est le type des programmes qui, ex'ecut'es, produisent des valeurs detype

int. Le fragment de programme correspondant peut ^etre ins'er'e dans d'autre programmesou compil'e et ex'ecut'e.

- l'op'erateur .~ (escape) permet justement d'ins'erer un fragment de programme objet dans unautre :

#let b = .< 3 * .~a >.;;
val b : int code = .<(3*(1+2))>.

- l'op'erateur .! (run) compile et ex'ecute un programme objet :

#let c = .!b;;
val c : int = 9

3. M'etaprogrammation appliqu'ee `a la g'en'eration de code

parall`ele

Afin d'illustrer en quoi la m'etaprogrammation << `a la MetaOcaml >> pr'esente un int'er^et dansle cadre de la programmation parall`ele consid'erons un programme (hypoth'etique) dans lequel un
ensemble de 2N processus s''echangent des donn'ees selon le sch'ema suivant (cf figure 1) :- un processus de rang pair envoie une donn'ee, g'en'er'ee par une fonction

f, au processus de rangimpair imm'ediatement sup'erieur puis attend une r'eponse de ce m^eme processus

- un processus de rang impair re,coit une donn'ee du processus de rang pair imm'ediatementinf'erieur, applique une fonction

g `a cette donn'ee puis renvoie le r'esultat `a ce m^eme processus.

send;

recv

recv;send

P0 P1

send;

recv

recv;send

P2 P3

Fig. 1 - Exemple 1
Sur la quasi-totalit'e des architectures de type cluster, le mod`ele d'ex'ecution est de type SPMD(Single Program Multiple Data) ce qui signifie que le programmeur 'ecrit un seul programme qui
s'ex'ecute sur l'ensemble des processeurs. Ecrit avec des primitives de communication point `a point debas niveau de type

send et recv2 le code du programme pr'ec'edent ressemble alors `a ceci :

1Le type de a retourn'e par le compilateur MetaOcaml est en fait ('a, int) code ; le param`etre 'a est utilis'e par
le syst`eme de type pour garantir la correction du code dans le cas o`u des variables sont utilis'ees `a plusieurs niveaux.
Par souci de lisibilit'e, on l'omettra ici.

2On supposera par exemple que la signature de ces primitives est val send : 'a -> pid -> unit et val recv :

pid -> 'a. De telles primitives sont par exemple offertes par la biblioth`eque OcamlMpi.

155

S'erot & Falcou
let myrank = get_proc_rank() in
if myrank % 2 = 0 then

send (f()) (myrank+1);
recv (myrank+1)
else

let y = recv (myrank-1)
send (g y) (myrank-1);

Ici la primitive get proc rank() permet d'obtenir, `a l'ex'ecution, le rang3 effectif du processeur quiex'ecute le programme et la conditionnelle d'ecide, en fonction de ce rang, de la s'equence d'instructions
`a ex'ecuter.

On peut noter que dans ce programme, le sch'ema de communication est fixe et donc que, pourchaque processeur, le code `a ex'ecuter est connu d`es que le rang du dit processeur est connu. On
peut tirer parti de cette propri'et'e pour r'e'ecrire le programme pr'ec'edent de la mani`ere suivante enM

etaOcaml :

let pgm rank =

if rank % 2 = 0 then

.< send (f()) (rank+1); recv (rank+1) >.
else

.< let y = recv (rank-1) in send (g y) (rank-1) >.

let myrank = get_proc_rank() in
.!(pgm myrank)

Le code est ex'ecuter est d'esormais g'en'er'e dynamiquement au niveau de chaque processeur, puisex'ecut'e. Cette technique est extr^emement puissante puisqu'elle permet de sp'ecialiser - et donc
d'optimiser - le code ex'ecut'e par chaque processeur en fonction de param`etres qui ne sont connusqu'`a l'ex'ecution (`a la diff'erence de syst`emes de m'etaprogrammation op'erant `a la compilation comme
les templates de C++ ou Template Haskell [12]). On peut objecter que ceci se fait au d'etriment dutemps d'ex'ecution mais dans la mesure o`u la g'en'eration du code n'est faite qu'une fois, au d'ebut
de l'ex'ecution du programme, le surco^ut introduit peut ^etre totalement recouvert par le gain enperformance induit par le code optimis'e.

Dans la suite, on va exploiter cette id'ee pour donner une impl'ementation efficace d'un DSL adapt'e`a la programmation parall`ele par squelettes.

4. Un DSL pour la programmation parall`ele par squelettes

Le langage vis'e - appelons-le Skl- permet la sp'ecification de programmes parall`eles au moyend'un nombre limit'e de combinateurs (les squelettes). Ces squelettes encapsulent compl`etement les
activit'es de communication et de coordination associ'ees au parall'elisme. Les parties s'equentiellesde l'application sont sp'ecifi'ees sous la forme de fonctions pass'ees en param`etres. La structure de
l'application est statique (pas de cr'eation / suppression dynamique de processus).

On d'ecrit ici un jeu limit'e de squelettes, qui nous a servi `a valider l'approche4 :

3On utilise ici la terminologie mpi. Le rang permet de distinguer `a l'ex'ecution les copies d'un m^eme programme dans
un mod`ele SPMD.

4L'extension de ce jeu ne pose pas de probl`eme a priori d`es lors que ces squelettes peuvent ^etre d'ecrits dans les

termes de l'alg`ebre de processus d'etaill'ee par la suite.

156

M'etaprogrammation fonctionnelle appliqu'ee `a la g'en'eration d'un DSL
- le squelette pipe encapsule un parall'elisme de type flux : n 'etapes de calcul sont encha^in'ees surles donn'ees d'entr'ee, chaque 'etape pouvant s'ex'ecuter en parall`ele sur des donn'ees distinctes ;
- le squelette pardo encapsule un parall'elisme de type t^ache : n op'erations sont appliqu'ees enparall`ele sur chaque donn'ee d'entr'ee ;
- le squelette farm encapsule un parall'elisme de type donn'ees : une m^eme op'eration est appliqu'ee`a l'ensemble des donn'ees d'entr'ees ; le mod`ele d'ex'ecution sous-jacent est celui dit en "ferme

de processus", o`u un processus "ma^itre" distribue dynamiquement les donn'ees `a traiter `a unensemble de processus esclaves et collecte les r'esultats, afin de r'ealiser un 'equilibre de charge.

Dans la description pr'ec'edente, les "'etapes" (resp. "op'erations") sont elles-m^emes des squelettes ;en d'autres termes, le langage supporte naturellement l'imbrication des squelettes. L'insertion des
fonctions s'equentielles se fait donc via un "squelette" particulier, nomm'e Seq.

La syntaxe abstraite des programmes Skl est donc la suivante :

\Sigma  ::= Seq f|

Pipe \Sigma 1 . . . \Sigma n|
Pardo \Sigma 1 . . . \Sigma n|
Farm n \Sigma 
f ::= fonction de calcul s'equentielle
n ::= entier >= 1

Imaginons par exemple un programme pouvant se d'ecomposer en trois 'etapes : une 'etape deproduction de donn'ees (r'ealis'ee par une fonction

f), une 'etape de traitement de ces donn'ees enparall`ele `a l'aide d'une ferme `a trois esclaves (chacun ex'ecutant la m^eme fonction

g) et une 'etape detraitement des r'esultats (r'ealis'ee par une fonction
h) (cf figure 2). Ce programme s''ecrit de la mani`eresuivante en S
kl :

oe = Pipe(Seq f, Farm(3, Seq g), Seq h)

f FarmM h

g g g
Fig. 2 - Exemple 2

4.1. S'emantique

On donne ici une s'emantique des programmes Skl en termes de r'eseaux de processus s'equentielscommuniquants. Cette s'emantique servira de base `a la fonction d'interpr'etation qui, cod'ee en

MetaOcaml, va permettre de g'en'erer le code `a ex'ecuter par chaque processeur de la machine parall`elecible.

On commence par d'efinir ce que l'on entend exactement par r'eseau de processus s'equentielscommuniquant (RPSC).
Formellement, un RPSC est un triplet ss = hP, I, Oi o`u-

P est un ensemble de processus 'etiquet'es, c-`a-d. de paires (pid , oe) o`u pid est un identificateur(unique) de processus et

oe un triplet contenant : une liste de pr'ed'ecesseurs (pid des processus

157

S'erot & Falcou

p pour lesquels il existe un canal de communication de p au processus en question), une liste desuccesseurs (

pid des processus p pour lesquels il existe un canal de communication du processusen question `a

p) et un descripteur \Delta . On note L(ss) l'ensemble des pids d'un r'eseau de processus
ss. Pour un processus p, ses pr'ed'ecesseurs, successeurs and descripteur seront not'es I(p), O(p)et

ffi(p) respectivement.-
I(ss) ` L(ss) d'esigne l'ensemble des processus p pour lesquels I(p) = ;-
O(ss) ` L(ss) d'esigne l'ensemble des processus p pour lesquels O(p) = ;Le descripteur de processus \Delta  est une paire (

instrs, kind) o`u instrs est une s'equence de macro-instructions et
kind un drapeau (la signification de ce drapeau sera donn'ee plus loin).

\Delta  ::= hinstrs, kindi
instrs ::= instr1, . . . , instrnkind ::=

Regular | FarmM

La s'equence de macro-instructions d'ecrivant le comportement du processus est implicitement it'er'ee(en premi`ere approximation on consid`ere que les processus ne se terminent pas ; g'erer de mani`ere
"propre" la terminaison des processus complique la description du mod`ele et nous avons choisi de nepas d'etailler ce point ici).

Les macros-instructions utilisent toutes un mode d'adressage implicite se r'ef'erant `a quatre variablesnomm'ees

iv, ov, q et iws. Le jeu de macro-instructions est d'ecrit ci-dessous. Dans les explicationsaff'erentes,

p d'esigne le processus ex'ecutant l'instruction en question.

instr ::= SendTo | RecvFrom | Comp fid | RecvFromAny | SendToQ |

Ifq instrs1 instrs2 | GetIdleW | UpdateWs

L'instruction SendTo envoie le contenu de la variable v au processus dont le pid appara^it en dernierdans O(

p). L'instruction RecvFrom re,coit une donn'ee en provenance du processus dont le pid appara^iten premier dans I(

p) et 'ecrit cette donn'ee dans la variable iv. L'instruction Comp effectue un calculen appelant un fonction s'equentielle. L'argument de cette fonction est lu dans

iv et son r'esultat 'ecritdans
ov. L'instruction RecvFromAny attend (de mani`ere non-d'eterministe) une donn'ee de l'ensembledes processus dont les

pids apparaissent dans I(p). La donn'ee re,cue est plac'ee dans la variable iv etle
pid du processus 'emetteur est plac'e dans la variable q. L'instruction SendToQ envoie le contenude la variable

ov au processus dont le pid est donn'e dans la variable q. L'instruction Ifq compare lavaleur contenue dans la variable

q au pid list'e en premier dans I(p). En cas d''egalit'e, la s'equenced'instructions instrs

1 est ex'ecut'ee ; sinon instrs2 est ex'ecut'ee. L'instruction UpdateWs lit la variable qet met `a jour la variable

iws en cons'equence. La variable iws maintient la liste des processus esclaveslibres pour un processus ma^itre dans le cas d'un squelette de type

farm. L'instruction GetIdleWextrait un identificateur de processus de la liste
iws et le place dans la variable q. Conjointement, cesdeux derni`eres instructions encapsulent la strat'egie utilis'ee au sein du squelette

farm pour assurerl''equilibre de charge.

On d'efinit ensuite une alg`ebre simple permettant de construire, de mani`ere compositionnelle desr'eseaux de processus. On utilisera pour cela les notations suivantes. Si E est un ensemble, on note
E[e  e0] l'ensemble obtenu en rempla,cant e par e0 (en posant E[e  e0] = E si e /2 E). Cettenotation est suppos'ee associative `a gauche : E[

e  e0][f  f 0] signifie (E[e  e0])[f  f0]. Si
e1, . . . , em est un sous-ensemble index'e de E et OE : E ! E une fonction, on notera E[ei  OE(ei)]i=1..ml'ensemble (

. . . ((E[e1  OE(e1)])[e2  OE(e2)]) . . .)[em  OE(em)]. Sauf mention explicite, on notera
I(ssk) = {i1k, . . . , imk } et O(ssk) = {o1k, . . . , onk }. Par souci de concision, les listes I(ojk) et O(ijk) seront

not'ees sjk et djk respectivement. Pour les listes, on suppose d'efinie l'op'eration de concat'enation ++usuelle : si

l1 = [e11, . . . , em1 ] et l2 = [e12, . . . , en2 ] alors l1++l2 = [e11, . . . , em1 , e12, . . . ; en2 ]. La liste vide estnot'ee []. La longueur d'une liste

l ou le cardinal d'un ensemble l sont tous deux not'es |l|.

158

M'etaprogrammation fonctionnelle appliqu'ee `a la g'en'eration d'un DSL
L'op'erateur d.e cr'ee un r'eseau de processus contenant un seul processus `a partir de son descripteur.La fonction

New() fournit un nouveau pid `a chaque appel.

ffi 2 \Delta  l = New()d
ffie = h{(l, h[], [], ffii)}, {l}, {l}i (Singl)

L'op'erateur * "s'erialise" deux r'eseaux de processus, en connectant les sorties du second aux entr'eesdu premier :

ssi = hPi, Ii, Oii (i = 1, 2) |O1| = |I2| = m
ss1 * ss2 = h(P1 [ P2)[(oj1, oe)  OEd((oj1, oe), ij2)]j=1...m[(ij2, oe)  OEs((ij2, oe), oj1)]j=1...m,

I1, O2i

(Serial)

La r`egle pr'ec'edente utilise deux fonctions auxiliaires OEs et OEd d'efinies comme suit :
OEs((p, hs, d, hffi, Regularii), p0) = (p, h[p0]++s, d, h[RecvFrom]++ffi, Regularii)
OEd((p, hs, d, hffi, Regularii), p0) = (p, hs, d++[p0], hffi++[SendTo], Regularii)
OEs((p, hs, d, hffi, FarmMii), p0) = (p, h[p0]++s, d, hffi, FarmMii)
OEd((p, hs, d, hffi, FarmMii), p0) = (p, hs, d++[p0], hffi, FarmMii)

La fonction OEs (resp. OEd) ajoute un processus p0 aux pr'ed'ecesseurs (resp. successeurs) d'un processus
p et met `a jour sa liste de macro-instructions. Concr`etement, cela consiste `a ajouter au d'ebut (resp.`a la fin) de cette liste une instruction

RecvFrom (resp. SendTo), sauf pour les processus ma^itres ausein d'un squelette de type
farm, pour lesquels la liste d'instructions n'est pas modifi'ee (ces processussont identifi'es `a l'aide du drapeau kind, positionn'e `a la valeur

FarmM).

L'op'erateur k met deux r'eseaux de processus en parall`ele en fusionnant leurs entr'ees et sortiesrespectivement.

ssi = hPi, Ii, Oii (i = 1, 2)
ss1 k ss2 = hP1 [ P2, I1 [ I2, O1 [ O2i (Par)

L'op'erateur 1 relie deux r'eseaux de processus en connectant chaque sortie et sortie du second `ala sortie du premier. Cet op'erateur est utilis'e pour d'ecrire la structure cyclique qui correspond `a une
ferme de processus :

ssi = hPi, Ii, Oii (i = 1, 2) |O1| = 1 |I2| = m |O2| = n
ss1 1 ss2 = h(P1 [ P2)[(o1, oe)  \Phi ((o1, oe), I(ss2), O(ss2))][(ij2, oe)  OEs((ij2, oe), o1)]j=1...m

[(oj2, oe)  OEd((ij2, oe), o1)]j=1...n,

I1, O1i

(Join)

o`u \Phi (p, pss, psd) = \Phi s(\Phi d(p, psd), pss) et \Phi s (resp. \Phi d) est la g'en'eralisation de la fonction OEs (resp.
OEd) `a une liste de processus :

\Phi s(p, [p1, . . . , pn]) = OEs(. . . , OEs(OEs(p, p1), p2), . . . , pn)
\Phi d(p, [p1, . . . , pn]) = OEd(. . . , OEd(OEd(p, p1), p2), . . . , pn)

On peut d`es lors expliciter la fonction C transformant un programme Skl en un r'eseau de processus :

159

S'erot & Falcou

C[[Seq f]] = df eC
[[Pipe \Sigma 1 . . . \Sigma n]] = C[[\Sigma 1]] * . . . * C[[\Sigma n]]C

[[Farm n \Sigma ]] = dFarmMe 1 (C[[\Sigma ]]1 k . . . k C[[\Sigma ]]n)C
[[Pardo \Sigma 1 . . . \Sigma n]] = C[[\Sigma 1]] k . . . k C[[\Sigma n]]

o`u FarmM est le descripteur encapsulant le comportement d'un processus ma^itre au sein d'unsquelette

farm :

\Delta (FarmM) = h[RecvFromAny; Ifq [GetIdleW; SendToQ] [UpdateWs; SendTo]], FarmMi

4.2. Impl'ementation en MetaOcaml

L'int'egration ("embedding") du langage Skl au langage h^ote (MetaOcaml donc ici) se fait viaune fonction dite d'interpr'etation (

run) qui se charge de convertir une sp'ecification Skl en un codeex'ecutable, appel'e code r'esiduel, sur chaque processeur.

Concr`etement, le programme exemple donn'e au paragraphe pr'ec'edent s''ecrira alors de la mani`eresuivante :

let f () = (* code de la fonction s'equentielle g'en'erant les donn'ees `a traiter *)
let g x = (* code de la fonction s'equentielle de traitement des donn'ees *)
let h x = (* code de la fonction s'equentielle de traitement des r'esultats *)
let pgm = Pipe [seq f; Farm(3, seq g); seq h]
let _ = run pgm

Le programme Skl est ici d'ecrit via un type alg'ebrique r'ecursif :
type skl_tree =

Seq of seq_comp
| Pipe of skl_tree list
| Pardo of skl_tree list
| Farm of int * skl_tree

La d'efinition exacte du type seq comp sera donn'ee plus loin. Il suffit de dire pour l'instant que l'ondispose d'une fonction d' "encapsulation"

seq permettant de transformer toute fonction s'equentielle
f : 'a->'b en une valeur de type seq comp.

La g'en'eration du code r'esiduel par la fonction run se fait en deux temps :
1. la repr'esentation arborescente du programme parall`ele est d'abord transform'ee en unerepr'esentation de ce m^eme programme sous la forme d'un r'eseau de processus s'equentiels

communiquants (RPSC)
2. puis, le code r'esiduel est g'en'er'e en confrontant cette repr'esentation interm'ediaire - au sein delaquelle chaque processus est rep'er'e par un

pid unique - avec le rang effectif du processeursur lequel la fonction d'interpr'etation
run s'ex'ecute ; en d'autres termes ne sera g'en'er'e sur leprocesseur
i que le code correspondant au processus ayant le pid i au sein du RPSC.

160

M'etaprogrammation fonctionnelle appliqu'ee `a la g'en'eration d'un DSL
type process_network = {

procs: (pid * process_desc) list;
inputs: pid list;
outputs: pid list;
}

and process_desc = {

kind: process_kind;
instrs: instr list;
recvfrom: pid list;
sendto: pid list;
}

and process_kind = Regular | FarmM

and instr =

| Comp of seq_comp
| SendTo
| RecvFrom
| RecvFromAny
| SendToQ
| Ifq of instr list * instr list
| GetIdleW
| UpdateWs

and seq_comp = process_state -> unit
and process_state = {

mutable iv: seq_val;
mutable ov: seq_val;
mutable q: pid;
mutable iws: pid list
}

Fig. 3 - Listing 1

4.2.1. G'en'eration du r'eseau de processus

Le listing 1 donne la traduction des principaux types de donn'ees utilis'es pour cette 'etape.
Les types de process_network, process_desc, process_kind et instr d'ecoulent imm'ediatementdes d'efinitions donn'ees `a la section 4.1 et n'appellent pas de remarque particuli`ere. Les points

int'eressants concernent les types process_state et seq_comp.

Le type process_state regroupe les quatre variables manipul'ees par les macro-instructions et letype

seq_comp traduit d'esormais que l'effet des fonctions de calcul s'equentielles est de mettre `a jourl''etat d'un processus. En pratique, une telle fonction sera appel'ee avec comme argument le contenu

de la variable iv et son r'esultat sera 'ecrit dans la variable ov5.

Typage. Une difficult'e se pose toutefois lorsque l'on cherche `a pr'eciser le type seq_val ; en effet, letype des composantes

iv et ov d'epend in fine du type de la fonction s'equentielle de calcul ex'ecut'ee parle processus. En supposant que le type de cette fonction soit

'a->'b, on pourrait imaginer param'etrerle type
process_state :

type ('a,'b) process_state = {

mutable iv: 'a;
mutable ov: 'b;
... }

Mais dans ce cas, le type process_network devient ('a,'b) process_network et il est impossiblede d'efinir des r'eseaux dont les processus op`erent sur des donn'ees de types diff'erents

6.

Dans le contexte des DSLs m'etaprogramm'es, ce probl`eme est bien connu et appara^it chaque foisque les langages objet et h^ote sont statiquement typ'es (comme ici). La solution consiste en g'en'eral

5Une fonction s'equentielle de calcul doit donc avoir un type de la forme 'a -> 'b. On peut toujours de se ramener,
par d'ecurryfication si besoin, `a cette forme de signature.

6Ce probl`eme est analogue `a celui auquel on se heurte classiquement lorsque l'on cherche `a d'efinir une fonctionnelle

compose g'en'eralis'ee : si on 'ecrit let rec gen compose = function [f] -> f | f : :fs -> compose f (gen compose
fs), avec let compose f g = function x -> g (f x) alors le type inf'er'e est ('a -> 'a) list -> ('a -> 'a) ce qui
oblige toutes les fonctions a avoir la m^eme signature.

161

S'erot & Falcou
`a introduire un type << universel >> encapsulant de mani`ere uniforme tous les types susceptibles d'^etremanipul'es par les fonctions s'equentielles de calcul du programme. Dans notre cas, on d'efinit alors le
type seq val comme :
type seq_val = Int of int | Float of float | IntArray of int array | ...

et un wrapper assure l''etiquetage (resp. << d'es-'etiquetage >>) des donn'ees en provenance des (resp.pass'ees aux) fonctions s'equentielles de calcul. Par exemple, si

f est une fonction de type int -> float,on d'efinit :

let f' = function (Int x) -> Float (f x)

et c'est cette fonction qui est pass'ee au constructeur Seq afin de construire les programmes Skl :
let seq f = Seq (fun s -> s.ov <- f s.iv)

Remarque. Cette solution oblige 'evidemment `a cr'eer un wrapper sp'ecifique pour chaque fonctions'equentielle et `a recompiler l'interpr'eteur `a chaque fois que des types nouveaux sont requis. Elle induit
par ailleurs un surco^ut `a l'ex'ecution. On peut 'eviter ceci en contournant les r`egles du typage statiqued'O

caml au moyen des primitives Obj.repr et Obj.obj. On on a alors simplement :

type seq_val = Obj.repr
let (seq : ('a -> 'b) -> seq_comp) =

function f -> Seq (fun s -> s.ov <- Obj.repr (f (Obj.obj s.iv)))

Mais ceci se fait 'evidemment au d'etriment de la s^uret'e puisque le contr^ole de type est alors de factoinhib'e. Par exemple, un programme comme

Pipe [sql f; sql g], o`u f:int->float et g:int->int,est accept'e et d'eclenche 'evidemment une erreur `a l'ex'ecution.

En pratique, nous disposons de deux versions de l'interpr'eteur : la premi`ere, utilisant la d'efinition<< universelle >> de

seq val permet de v'erifier la coh'erence des types dans un programme Skl. Laseconde, utilisant
Obj.repr, permet de supprimer l'overhead li'e au tagging dynamique des valeurs.

Les op'erateurs d.e, *, k et 1 sont implant'es par traduction directe des r`egles de productions de las'emantique sur la base des types d'efinis ci-dessus. On ne reproduira donc ici que le code associ'e aux
deux premiers :
let singl d =

let p = new_pid () in
{ procs = [p, d]; inputs = [p]; outputs = [p] }

let serial pn1 pn2 =

if List.length pn1.outputs = List.length pn2.inputs then

{ procs = List.map

(function (pid, pd) ->

if List.mem pid pn1.outputs then

let dst = List.assoc pid (List.combine pn1.outputs pn2.inputs) in
(pid, add_dst pd dst)
else if List.mem pid pn2.inputs then

let src = List.assoc pid (List.combine pn2.inputs pn1.outputs) in
(pid, add_src pd src)

162

M'etaprogrammation fonctionnelle appliqu'ee `a la g'en'eration d'un DSL
else (pid, pd))
(pn1.procs @ pn2.procs);
inputs = pn1.inputs;
outputs = pn2.outputs }
else failwith "cannot serialize process networks: size mismatch"

Dans ce qui pr'ec`ede, les fonctions add_src et add_dst impl'ementent les fonctions OEs et OEd. Parexemple :

let add_dst pd1 pid2 =

match pd1.kind with

Regular -> {pd1 with instrs = pd1.instrs @ [SendTo]; sendto = pd1.sendto @ [pid2]}
| FarmM -> {pd1 with sendto = pd1.sendto @ [pid2]}

Enfin, la fonction expand_tree impl'emente la fonction de conversion C introduite `a la section 4.1par simple filtrage sur le type r'ecursif repr'esentant les programmes S

kl :

let (expand_tree : skl_tree -> process_network) = function t ->

let rec expand = function

Seq f -> singl {kind=Regular; instrs=[Comp f]; recvfrom=[]; sendto=[]; workers=[]}
| Pipe [] -> failwith "empty pipe"
| Pipe [t] -> expand t
| Pipe (t::ts) ->

serial (expand t) (expand (Pipe ts))
| Pardo [] -> failwith "empty pardo"
| Pardo [t] -> expand t
| Pardo (t::ts) ->

par (expand t) (expand (Pardo ts))
| Farm (n, t) ->

if n > 0 then

let workers =

let rec create n =

if n=1 then expand t
else

par (expand t) (create (n-1)) in
create n in
join (farmer workers.inputs) workers
else
failwith "cannot expand farm with n<=0 workers"
in
reset_pid ();
expand t

let farmer ws = singl {

kind=FarmM;
instrs=[RecvFromAny; Ifq ([GetIdleW; SendToQ],[UpdateWs; SendTo])];
recvfrom=[]; sendto=[]; workers=ws }

4.2.2. G'en'eration du code r'esiduel

La fonction code g'en`ere, `a partir de la repr'esentation du r'eseau de processus calcul'ee `a l''etapepr'ec'edente, le code r'esiduel sur un processeur de rang donn'e :

163

S'erot & Falcou
let code pn rank =

let mydesc = List.assoc rank pn.procs in
.< while true do .~(code_instrs mydesc mydesc.instrs) done >.

Le code est "assembl'e" par simple parcours de la liste de macro-instructions associ'ee au descripteurdu processus. C'est `a ce niveau que la variable d''etat du processus est cr'e'ee

7. Le contenu initial des

composantes iv, ov et q est indiff'erent. Les processus de type FarmM voient leur composante iwsinitialis'ee avec la liste des processus esclaves auxquels ils sont reli'es :

let code_instrs pd is =

let s = { iv=Obj.repr 0; ov=Obj.repr 0; q=0; iws=pd.workers } in
List.fold_left

(fun c i -> .< begin .~c; .~(code_instr pd s i) end >.)
.< () >.
is

Enfin la fonction code_instr g'en`ere le code correspondant `a chaque macro-instruction :
let rec code_instr pd s = function

Comp f -> .< f s >.
| SendTo ->

let dst = List.hd (List.rev pd.sendto) in
.< Mpi.send s.ov dst 0 Mpi.comm_world >.
| RecvFrom ->

let src = List.hd (pd.recvfrom) in
.< s.iv <- Obj.repr (Mpi.receive src Mpi.any_tag Mpi.comm_world) >.
| RecvFromAny ->

.< let r,q,_ = Mpi.receive_status Mpi.any_source Mpi.any_tag Mpi.comm_world in

s.ov <- Obj.repr r; s.q <- q >.
| SendToQ ->

.< Mpi.send s.ov s.q 0 Mpi.comm_world >.
| Ifq (is1,is2)->

.< if s.q = List.hd pd.recvfrom

then .~(code_instrs pd is1) else .~(code_instrs pd is2) >.
| GetIdleW ->

.< begin s.q <- List.hd s.iws; s.iws <- List.tl s.iws end >.
| UpdateWs ->

.< s.iws <- s.iws @ [s.q] >.

Une instruction Comp f produit un appel `a la fonction s'equentielle f . Les instructions SendTo,
SendToQ, RecvFrom et RecvFromAny sont traduites directement en appel aux primitives mpi (on utiliseici la biblioth`eque O

camlMpi [18]). Pour l'instruction Ifq l'op'erateur d''echappement de MetaOcamlpermet d'ins'erer directement dans le code produit les fragments correspondant aux deux branches de

la conditionnelle. Concernant les instructions GetIdleW et UpdateWs, on s'est content'e ici d'implanterune simple gestion du pool d'esclaves en tourniquet en manipulant la liste

iws (idle workers) en FIFO(retrait en t^ete par l'instruction
GetIdleW, insertion en queue par l'instruction UpdateWs). D'autresstrat'egies de gestion sont 'evidemment envisageables.

La fonction d'interpr'etation principale s''ecrit alors ais'ement :
7On tire parti ici de la possibilit'e offerte par MetaOcaml d'utiliser une variable d'efinie au niveau i aux niveaux i +n
("cross-stage persistence").

164

M'etaprogrammation fonctionnelle appliqu'ee `a la g'en'eration d'un DSL
let size = Mpi.comm_size Mpi.comm_world
let myrank = Mpi.comm_rank Mpi.comm_world

let run pgm =

let pn = expand_tree pgm in
let mycode = code pn myrank in
.! (mycode)

A titre d'exemple, voici le code r'esiduel produit sur chaque processeur pour le programme
Pipe[seq f; seq g; seq h] :

PID Code

2 .< while true do f s; Mpi.send s.ov 1 0 Mpi.comm_world done >.
1 .< while true do s.iv <- Obj.repr (Mpi.receive 2 0 Mpi.comm_world); g s;

Mpi.send s.ov 0 0 Mpi.comm_world done >.
0 .< while true do s.iv <- Obj.repr (Mpi.receive 1 0 Mpi.comm_world);

h s done >.

Ce code est identique `a celui qu'aurait 'ecrit un programmeur mpi exp'eriment'e.

5. R'esultats

Nous avons 'evalu'e l'impact de cette technique d'impl'ementation en mesurant le surco^ut (overhead)
ae en temps d'ex'ecution qu'elle introduit par rapport `a un code parall`ele 'ecrit directement `a l'aide deprimitives

mpi (Ocaml + biblioth`eque OcamlMPI v 1.0.1)8.

Ce surco^ut a 'et'e mesur'e pour deux types de programmes : des programmes ne mettant en jeu qu'unseul squelette et des programmes pour lesquels plusieurs squelettes sont imbriqu'es `a une profondeur

arbitraire. Pour le premier type de test, on observe l'effet de deux param`etres : la dur'ee d'ex'ecution
o/ de la fonction de calcul s'equentielle et la "taille" N du squelette (cette taille correspond au nombred''etages pour un squelette

pipe, au nombre de t^aches parall`eles pour un squelette pardo et au nombred'esclaves pour un squelette

farm). Pour le second type de test, nous nous sommes limit'es au casdu squelette
farm. On 'evalue alors les performances d'un programme form'e de P squelettes farmimbriqu'es, chacun mettant en jeu

! esclaves.

Les r'esultats ont 'et'e obtenus sur un cluster `a 30 noeuds de type PowerPC G5 pour N variant entre2 et 30 et

o/ = 1ms, 10ms, 100ms, 1s.

Pour le squelette pipe, ae n'exc`ede jamais 2 %. Pour farm et pardo, ae reste inf'erieur `a 3 % etdevient n'egligeable pour

N > 8 ou o/ > 10ms. En cas d'imbrication, le pire cas est obtenu pour P = 4et
! = 2 ; ae varie alors entre 7 % et 3 % quand o/ passe de 1ms `a 1s.

Ces r'esultats sont bien meilleurs que ceux obtenus avec des syst`emes de programmation parsquelettes n'exploitant pas la m'etaprogrammation. Dans l'impl'ementation d'ecrite dans [13], par

exemple, o`u les squelettes sont implant'ees comme de simples fonctions d'ordre sup'erieur ordonnan,cantdynamiquement (c-`a-d. `a l'ex'ecution) des primitives

mpi, le surco^ut 'etait de l'ordre de 10 `a 20 %. Pourla derni`ere version du syst`eme
skipper [14], dans laquelle les squelettes 'etaient traduits en graphesflots de donn'ees ex'ecut'es par un interpr'eteur d'edi'e, ce surco^ut atteignait parfois 100 %. D'autres

implantations, comme celle de Kuchen [7], dans laquelle les squelettes sont traduits par des appels dem'ethodes virtuelles en C++, font aussi 'etat de surco^ut `a l'ex'ecution - par rapport `a du code C+MPI
dans ce cas - de l'ordre de 20 `a 120 %.

8En utilisant la version << optimis'ee >> de l'interpr'eteur, i.e. celle exploitant les primitives Obj.repr et Obj.obj.

165

S'erot & Falcou
6. Travaux connexes

L'id'ee d'exploiter la m'etaprogrammation pour implanter de mani`ere efficace un DSL n'estpas neuve. Le principe sous-jacent consiste en transformer par 'evaluation partielle un couple
(interpr'eteur de ce langage, programme dans ce langage) en un programme compil'e . Les techniquesde programmation dite g'en'erative [6] qui en d'ecoulent visent en g'en'eral `a r'esoudre la tension entre
abstraction et performances, comme dans notre cas. Les biblioth`eques FFTW [4], EVE [3] et SPIRAL[15] peuvent ^etre vues comme des illustrations de cette approche.

Les langages fonctionnels offrent un substrat favorable pour la m'etaprogrammation gr^ace enparticulier aux fonctions d'ordre sup'erieur et `a la possibilit'e de coder tr`es facilement la syntaxe
abstraite du DSL sous la forme d'un type alg'ebrique du m'eta-langage. Dans [11], Sheard fait unerevue des techniques de m'etaprogrammation dans le contexte de la programmation fonctionnelle. Il
y introduit notamment le langage MetaML qui ajoute au langage ML des annotations permettant detransformer des expressions ML en fragment de code, d'ins'erer des fragments de code dans d'autres
fragments de code et d'ex'ecuter des fragments de code. Le langage MetaOcaml [20] d'evelopp'e parTaha et al. est une extension similaire du langage O

caml. Le langage Template Haskell [12] ajoute, deson cot'e, un large panel de facilit'es pour la m'etaprogrammation au langage Haskell, avec notamment

des possibilit'es pour le m'eta-langage d'acc'eder `a sa propre syntaxe abstraite (instrospection). Enrevanche, et contrairement `a MetaML et M

etaOcaml, la g'en'eration du code r'esiduel a lieu `a lacompilation et ne peut donc pas prendre en compte des donn'ees dynamiques.

Les probl'ematiques g'en'erales li'ees `a la d'efinition d'un DSL pour le parall'elisme sont 'etudi'ees parLengauer dans [8]. Mais, dans ce domaine, seul Herrmann, dans [5] semble avoir explor'e les possibilit'es
offertes par la g'en'eration dynamique de code avec MetaOcaml pour implanter un tel DSL. Le syst`emequ'il d'ecrit est similaire `a celui pr'esent'e ici mais en diff`ere toutefois en plusieurs points. Premi`erement,
le mod`ele de parall'elisme sur lequel il repose est restreint aux sch'emas fixes et d'eterministes (structuress'erie-parall`ele) ; il est donc impossible d'y exprimer des squelettes pour lesquels l'ordonnancement des
communications n'est pas connu `a la compilation (comme farm). Deuxi`emement, dans l'approched'ecrite, les squelettes ne font pas `a proprement partie du DSL mais sont d'efinis `a partir du vocabulaire
de ce dernier. Enfin, la s'emantique du langage n'est pas d'efinie formellement mais directement encod'eedans l'interpr'eteur en M

etaOcaml (il n'y pas de repr'esentation interm'ediaire explicite sous la formede r'eseau de processus communiquants en particulier).

7. Conclusion

Nous avons montr'e dans cet article comment les facilit'es de m'etaprogrammation offertes par lelangage M

etaOcaml permettent d'implanter efficacement un DSL d'edi'e `a la programmation parall`eleen conciliant haut niveau d'abstraction et performances. Le fait que le code r'esiduel soit g'en'er'e

`a l'ex'ecution est ici un avantage dans la mesure o`u cette g'en'eration peut prendre en compte laconfiguration effective de la machine (nombre de processeurs, . . . ). Bien sur le temps requis pour
g'en'erer ce code s'ajoute au temps d'ex'ecution de l'application elle-m^eme mais, pour des probl`emes detaille suffisante, il reste n'egligeable.

Le prototype d'ecrit ici ne g'en`ere que du bytecode, le compilateur natif de MetaOcaml n''etant pasdisponible sur toutes les plateformes. Dans la pratique ce point n'est pas critique dans la mesure o`u il
est parfaitement possible d'appeler des fonctions de calcul s'equentielles 'ecrites en C, C++ ou Fortranen s'appuyant sur la Foreign Function Interface d'O

caml. Une autre approche consisterait `a utiliserles facilit'es d'offshoring offertes par M
etaOcaml, c-`a-d. la possibilit'e de g'en'erer automatiquementdu code C `a partir de code O
caml.

Le principal probl`eme `a r'egler dans notre impl'ementation concerne toutefois le typage. La solutionretenue, avec deux versions de l'interpr'eteur, n'est pas th'eoriquement satisfaisante. Il reste donc `a voir

166

M'etaprogrammation fonctionnelle appliqu'ee `a la g'en'eration d'un DSL
dans quelle mesure certaines techniques d''elimination automatique des 'etiquettes de typage, d'ecritespar exemple dans [16], pourraient s'appliquer.

A plus long terme nous envisageons d'appliquer la techniques pr'esent'ee ici `a la r'eimpl'ementationd'autres syst`emes de programmation parall`ele fond'es sur les squelettes, comme Skipper[14] ou
OcamlP3L[19].

R'ef'erences

[1] B. Bacci, M. Danelutto, S. Orlando, S. Pelagatti, and M. Vanneschi. P3L : A Structured High Level

Programming Language And Its Structured Support. Concurrency : Practice and Experience, pages
225-255, 1995.

[2] M. Cole. Bringing Skeletons out of the Closet : A Pragmatic Manifesto for Skeletal Parallel Programming.

Parallel Computing, 3 :389-406, 2004.

[3] J. Falcou and J. S'erot. EVE : an object-oriented SIMD library. Scalable Computing : Practice and

Experience, 6(4) :31-42, 2005.

[4] Kang Su Gatlin and Larry Carter. Faster FFTs via architecture-cognizance. In IEEE PACT, pages

249-260, 2000.

[5] Christoph A. Herrmann. Generating message-passing programs from abstract specifications by partial

evaluation. Parallel Processing Letters, 15(3) :305-320, 2005.

[6] Neil D. Jones and Arne J. Glenstrup. Program generation, termination, and binding-time analysis.

In ICFP '02 : Proceedings of the seventh ACM SIGPLAN international conference on Functional
programming, pages 283-283, New York, NY, USA, 2002. ACM Press.

[7] H. Kuchen. A skeleton library. Proceedings of the 8th International Euro-Par Conference on Parallel

Processing, pages 620-629, 2002.

[8] Christian Lengauer, Don S. Batory, Charles Consel, and Martin Odersky, editors. Domain-Specific

Program Generation, International Seminar, Dagstuhl Castle, Germany, March 23-28, 2003, Revised
Papers, volume 3016 of Lecture Notes in Computer Science. Springer, 2004.

[9] G. Michaelson N. Scaife and S. Horiguchi. Parallel Standard ML with Skeletons. Scaleable Computing

Practise and Experience, 6(4), 2006.

[10] J. S'erot and D. Ginhac. Skeletons for parallel image processing : an overview of the SKiPPER project.

Parallel Computing, 28(12) :1785-1808, Dec 2002.

[11] Tim Sheard. Accomplishments and research challenges in meta-programming. In SAIG 2001 : Proceedings

of the Second International Workshop on Semantics, Applications, and Implementation of Program
Generation, pages 2-44, London, UK, 2001. Springer-Verlag.

[12] Tim Sheard and Simon Peyton Jones. Template metaprogramming for Haskell. In Manuel M. T.

Chakravarty, editor, ACM SIGPLAN Haskell Workshop 02, pages 1-16. ACM Press, October 2002.

[13] J. S'erot Embodying parallel functional skeletons : an experimental implementation on top of mpi. 3rd

Intl Euro-Par Conference on Parallel Processing, Aout 1997, Passau. Volume 1300 of LNCS, pp 629-633,
Springer.

[14] J. S'erot. Tagged-token data-flow for skeletons. Parallel Processing Letters, 11(4) :377-392, 2002.
[15] Jos'e M. F. Moura, Jeremy Johnson, Robert W. Johnson, David Padua, Viktor K. Prasanna, Markus

P"uschel, Bryan Singer, Manuela Veloso, and Jianxin Xiong. Generating platform-adapted dsp libraries
using SPIRAL. In High Performance Embedded Computing (HPEC), 2001.

[16] Emir Pa^salic, Walid Taha, Tim Sheard. Tagless staged interpreters for typed languages. SIGPLAN Not.,

37(9) : :218-229, 2002.

[17] http ://caml.inria.fr
[18] http ://caml.inria.fr/cgi-bin/hump.en.cgi ?contrib=401
[19] http ://ocamlp3l.inria.fr
[20] http ://www.metaocaml.com

167

janvier 2008 - Journ'ees Francophones des Langages Applicatifs- JFLA08

168