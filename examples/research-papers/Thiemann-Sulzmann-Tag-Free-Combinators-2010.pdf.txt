

Tag-free Combinators for Binding-Time

Polymorphic Program Generation

Peter Thiemann1 and Martin Sulzmann2
1 Albert-Ludwigs-Universit"at Freiburg, Germany

thiemann@informatik.uni-freiburg.de

2 Intaris martin.sulzmann@gmail.com

Abstract. Binding-time polymorphism enables a highly flexible bindingtime analysis for offline partial evaluation. This work provides the tools
to translate this flexibility into efficient program specialization in the
context of a polymorphic language.
Following the cogen-combinator approach, a set of combinators is defined
in Haskell that enables the straightforward transcription of a bindingtime polymorphic annotated program into the corresponding program
generator. The typing of the combinators mimics the constraints of the
binding-time analysis. The resulting program generator is safe, tag-free,
and it has no interpretive overhead.

1 Introduction
A polymorphic binding-time analysis empowers an offline partial evaluator toobtain specialization results on par with those of an online partial evaluator.
However, implemented specializers for polymorphic binding-time analysis so fardo not exploit the efficiency potential of offline partial evaluation. They are
interpreter-based, they pass and interpret binding-time descriptions at special-ization time, and they use tagging to distinguish ordinary static values from
dynamic values (generated code).For monomorphic binding-time analysis, there is a well-known approach to
obtain compiled, tag-free program generators that perform offline partial eval-uation. The cogen approach to partial evaluation [13] explains the direct construction of a program generator from a binding-time annotated program. Fortyped languages, this direct generation step is more efficient than going via the
Futamura projections, which can lead to multiple levels of data encoding [11].For example, the binding-time annotated

power function

power xD nS = if n =S 0 then lift 1 else x *D power x (n -S 1)
uses the superscripts S and D to indicate static and dynamic operations thathappen at specialization time and at run time, respectively. The lift expression

avoids a binding-time mismatch by converting the static constant 1 into therequired dynamic code at that point. The translation to a program generator
can be done in a compositional way, by specifying a translation for each an-notated syntactic construct: The constructs annotated with

S are translated to

themselves, the constructs annotated with D are translated to expressions thatgenerate the respective expression tree, and lift maps to the appropriate syntax
constructor. A translation to Haskell would look like this:
data Exp = Const Int | Mul Exp Exp -- and so on
power :: Exp -> Int -> Exp
power x n = if n==0 then Const 1 else Mul x (power x (n-1))

This simple example already demonstrates that the static data is neither encodednor tagged and that, consequently, the static expressions execute efficiently.

The methods used so far for translating binding-time annotated programs toprogram generators are only suitable for monovariant annotation schemes [1, 2,
18, 20]. They do not cover annotations created by the more precise polyvariantbinding-time analyses [5, 6, 8-10]. A polyvariant binding-time analysis enables
abstraction over concrete binding times. To continue the example, the powerfunction would receive three additional binding-time parameters that express
the binding times of the arguments x and n and of the result of power, whichmust be more dynamic than either argument:

(power :: Int ! Int ! Int) : 8fiflffi.(fi <= ffi, fl <= ffi) ) fi S7! fl S7! ffi
power fi fl ffi x n = if n =fl liftS,fl 0 then liftS,ffi 1

else liftfi,ffi x *ffi power fi fl x (n -fl liftS,fl 1)

Evidently, the lift expression must be generalized to liftfi,ffi which converts abase-type value of binding time

fi to binding time ffi. This conversion requires
fi <= ffi where the ordering is the least partial order such that S <= D. Theother constraint,

fl <= ffi, arises from the conditional. The binding time fl of thecondition is a lower bound of the binding time

ffi of the result.The translation of this annotated program to a satisfactory program generator becomes more tricky. Fig. 1 shows the naive approach, which is hardlysatisfactory. First, binding times have to be passed and tested explicitly in the
generator. Second, the generator relies on run-time tags to identify static anddynamic values in the

Value datatype as evident from the implementations of
pIf and pOp2: An untagged generator could omit stripping off (and reapplying)the

Bool and Exp tags. Indeed, the BT argument would not be needed for the pIfcombinator.

3 Third, the generator is not self-checking. Its type does not incorporate the constraints from the binding-time annotation, thus it can give rise torun-time errors because of binding-time mismatches. For example, an invocation

(powergen D D S) can result in a run-time error when attempting to execute
(pLift D S x).This particular generator has further shortcomings not addressed in this

work. For example, (powergen D D D x n) does not terminate, for any x and

3 Use of the combinator still requires a preceding binding-time analysis because it

expects its e1 and e2 arguments to carry the Exp tag if the condition carries an Exp
tag. Unlike the staged interpreters of Carette and coworkers [3], this pIf combinator
would not be suitable for online partial evaluation because the dynamic version of
the conditional does not convert static values in the branches to dynamic values.

2

data Value = Int Int | Bool Bool | Exp Exp
data BT = S | D
powergen :: BT -> BT -> BT -> Value -> Value -> Value
powergen b g d x n =

pIf g (pOp2 g opEqu n (pLift S g (Int 0)))

(pLift S d (Int 1))
(pOp2 d opMul (pLift b d x)

(powergen b g d x (pOp2 g opSub n (pLift S g 1))))
-- lifting values of base type
pLift :: BT -> BT -> Value -> Value
pLift S S (Int i) = Int i
pLift S D (Int i) = Exp (Const i)
pLift D D (Exp e) = Exp e
-- conditional
pIf :: BT -> Value -> Value -> Value -> Value
pIf S (Bool x) v1 v2 = if x v1 else v2
pIf D (Exp e) (Exp e1) (Exp e2) = Exp (If e e1 e2)
-- binary operator
pOp2 :: BT -> Op (Int -> Int -> Int) -> Value -> Value -> Value
pOp2 S op (Int x) (Int y) = Int (opvalue op x y)
pOp2 D op (Exp x) (Exp y) = Exp (opctor op [x, y])
-- operators
data Op t = Op { opvalue :: t, opctor :: [Exp] -> Exp }
opMul = Op (*) (\[x,y] -> Mul x y) :: Op (Int -> Int -> Int)
opSub = Op (-) (\[x,y] -> Sub x y) :: Op (Int -> Int -> Int)
opEqu = Op (==) (\[x,y] -> Equ x y) :: Op (Int -> Int -> Bool)

Fig. 1. Naive generator with binding-time polymorphism.

n, because the recursive call to powergen is implicitly static, that is, it is alwaysperformed at specialization time.

The present work is the first to address the construction of efficient programgenerators with polymorphic binding times. Because it applies to languages with
ML-style polymorphism, it paves the way for efficient program specialization forHaskell. It addresses all shortcomings of the naive generator.

1. No interpretive overhead. Binding-time descriptions are passed at runtime but they are never tested. Due to laziness they have virtually no cost.
2. Tag-free. The generator requires no tagging, neither type tags nor tags todistinguish static from dynamic values.
3. Safety. The typing of the generator ensures that binding-time inconsisten-cies in the input of the generator are caught by the type checker before

starting the specialization.
The main contribution is a set of combinators that enables the construction oftag-free program generators via a simple type-directed translation from a polymorphic binding-time type derivation to a Haskell program using these combi-nators. The starting point is the polyvariant binding-time analysis for ML-style
polymorphic languages by Glynn and coworkers [6].

3

powergen :: (...) => (forall a. a -> dx a) -> (forall a. a -> dn a)

-> (forall a. a -> dz a)
-> R Int (dx Int) -> R Int (dn Int) -> R Int (dz Int)
powergen dx dn dz x n =

cIf (dn bool) (dz int)

(cOp2 sEqInt oEqInt n (cSub (St int) (dn int) (R 0)))
(cSub (St int) (dz int) (R 1))
(cOp2 sMult oMult

(cSub (dx int) (dz int) x)
(powergen dx dn dz

x (cOp2 sMinus oMinus n (cSub (St int) (dn int) (R 1)))))
where { sEqInt = bop2 dn int int bool; sMinus = bop2 dn int int int;

sMult = bop2 dz int int int }

Fig. 2. Tagfree generator for specializations of power. The type signature is truncated
to save space.

The implementation is in Haskell [15] with various extensions (e.g., typefunctions [17], multi parameter type classes, rank-2 types [16], GADTs) as implemented by GHC. For lack of space, we assume familiarity with the languageand the extensions.

2 Tagfree Polymorphic Program Generation
Figure 2 contains the tag free variant of the polymorphic generator for the powerfunction shown in Fig. 1. Before delving into a detailed explanation of the combinators, let's introduce some preliminaries and run the generator on examples.Like the previous generator, the new generator receives three binding-time
parameters and two value parameters. Binding times are represented by poly-morphic functions that construct binding-time descriptions (bt descriptions),
which are passed to the combinators. A bt description has the same structure asthe underlying type but alternates binding times with regular type constructors.
Binding times are represented by two data types, St and Dy.
newtype St a = St a -- static annotation
newtype Dy a = Dy a -- dynamic annotation

For example, (St int :: St Int) describes a static integer and (St (St Int
-> Dy Bool)) is the type of a description of a static function with static inputand dynamic output. Descriptions are reified type arguments, which are never

evaluated.

Depending on the instantiation of the binding time parameters, powergen ex-hibits dramatically different behaviors as shown and labeled in Fig. 3. The nontermination of the third example is the expected behavior because the recursionin

powergen is always static. The error message for the last example accuratelyreflects the failing constraints of the binding-time analysis ($2.1, $2.3).

The computation of the generator happens in terms of a representation type
R t btd, which depends on the underlying type t and its bt description btd.

4

> -- an all static run computes the power function
> unR (powergen St St St (R 2) (R 5))
32
> -- a run with dynamic basis performs specialization
> toString $ unR $ powergen Dy St Dy (R (EVar "x")) (R 5)
"EOp2 (*) (EVar x) (EOp2 (*) (EVar x) (EOp2 (*) (EVar x)

(EOp2 (*) (EVar x) (EOp2 (*) (EVar x) (EInt 1)))))"
> -- nonterminating specialization
> toString $ unR $ powergen Dy Dy Dy (R (EVar"x")) (R (EVar"n"))
"EIf (EOp2 (==) (EVar n) (EInt 0)) (EInt 1) (EOp2 (*) (EVar x)
(EIf (EOp2 (==) (EOp2 (-) (EVar n) (EInt 1)) (EInt 0)) (EInt 1) (EOp2 (*) (EVar x)
(EIf (EOp2 (==) Interrupted.
> -- binding-time mismatch
> powergen Dy Dy St

No instances for (CIF Dy St, CSUB (Dy Int) (St Int) Int)

Fig. 3. Running powergen.

Any value that is passed into (out of) the generator must first be wrapped(unwrapped). As

R is an isomorphism, its use does not amount to tagging.4

-- representation type
newtype R t btd = R { unR :: ImpT t btd }
-- implementation type
type family ImpT t btd
--
type instance ImpT Int (St Int) = Int
type instance ImpT Bool (St Bool) = Bool
type instance ImpT [a] (St [ba]) = [ImpT a ba]
type instance ImpT (a -> b) (St (ba -> bb)) = ImpT a ba -> ImpT b bb
--
type instance ImpT a (Dy aa) = Exp a

The argument to the R constructor must have the implementation type, computedby the type function

ImpT. For type constructors with static bt descriptions, ImpTrebuilds the type constructors and translates components of the type recursively.

This strategy implies that static computations are implemented by themselves.If the translation hits a dynamic annotation, then well-formedness dictates that
further components of the type carry a dynamic annotation, too. Hence, anyvalue of dynamic type

a is implemented as an expression of type Exp a. Thelatter type is a GADT with the usual definition (see appendix).

2.1 Basic Combinators
Continuing the analysis of the code in Fig. 2, the cIf combinator takes two btdescriptions, one

(dn bool) describing the binding time of the condition and one

4 The reader may wonder why R t btd is needed as it is isomorphic to ImpT t btd.

However, when type inference equates R t1 b1 = R t2 b2 it can deduce that t1 =
t2 and b1 = b2. It cannot deduce these equalities from ImpT t1 b1 = ImpT t2 b2.

5

(dz int) fixing the binding time of the result of the conditional. The remainingarguments stand for the condition, the true-branch, and the false-branch, where
the two branches have the same representation type. cIf is overloaded suchthat there are instances for either static

dn and arbitrary dz or for dynamic dnand
dz. The type checker rejects any other combination of binding times (viaunresolved instance), thus enforcing the constraints of the binding-time analysis.

The definition shows that the bt descriptions are not touched.
class CIF bb bt where

cIf :: bb Bool -> bt shp

-> R Bool (bb Bool) -> R t (bt shp) -> R t (bt shp) -> R t (bt shp)
instance CIF St bt where

cIf _ _ b x y = if (unR b) then x else y
instance CIF Dy Dy where

cIf _ _ b x y = R (EIf (unR b) (unR x) (unR y))

The combinator cOp2 for binary primitive operations takes a bt descriptionfor the type of the operation, the operation itself, and its two arguments. It is
implemented in terms of a more general operator cConst, which injects constantsinto a generator, and function application

cApp. Again, the overloading of thesecombinators enables the dual use of static and dynamic operations.

data Op a = Op { opname :: String, opvalue :: a }
cOp2 btd op x y = cApp undefined (cApp btd (cConst btd op) x) y

Instead of examining the unwieldy type of cOp2, it is simpler and more general tolook at the

cConst operator (but see Appendix C). To safely embed a constantof arbitrary type in a generator requires that the constant's bt description is

uniform, that is, it is either completely static or completely dynamic [19]. Thisrequirement is stronger than the usual well-formedness (see $3.4), which can be
enforced locally. Uniformity is asserted with a two-parameter type class Uniform.
class Uniform t btd => CONST t btd where

cConst :: btd -> Op t -> R t btd
instance (AllStatic t aa) => CONST t (St aa) where

cConst btd op = R (toImpT btd (opvalue op))
instance (AllDynamic aa) => CONST t (Dy aa) where

cConst _ op = R (EConst op)

The dynamic case is straightforward, but the static case has a slight complica-tion. Because of the recursive definition of

ImpT for static bt descriptions, thetype checker needs a proof that
t is equal to ImpT t btd if btd is fully static.The class
Uniform defines identities providing this proof in the usual way.5

class Uniform t btd where

toImpT :: btd -> t -> ImpT t btd
fromImpT :: btd -> ImpT t btd -> t

5 See the appendix for the full definitions of Uniform, AllStatic, and AllDynamic.

6

2.2 Function Combinators
The encoding of functions follows the ideas of higher-order abstract syntax asin previous work [3, 18, 20]. Thus, the generator represents bound variables by

metavariables so that the cLam combinator for abstraction takes a function fromrepresentation type to representation type as an argument.

class CLAM bf bs bt where

cLam :: bf (bs as -> bt at)

-> (R s (bs as) -> R t (bt at)) -> R (s -> t) (bf (bs as -> bt at))
instance CLAM St bs bt where

cLam _ f = R $ (unR . f . R)
instance CLAM Dy Dy Dy where

cLam _ f = R $ ELam (unR . f . R)

The two instances for the overloaded cLam combinator reflect exactly the binding-time constraints: a static function does not restrict the binding time of its argument and result, whereas a dynamic function requires dynamic argument andresult. The function

ELam is the constructor for the typed (higher-order) abstractsyntax (see Appendix A).

The definitions of the combinators cApp for function application and cFixfor the fixpoint follow a similar scheme and are thus relegated to Appendix D.

2.3 Subtyping
Subtyping is the final important ingredient of binding-time analysis. This sub-typing does not take part on the value level, but on the level of bt descriptions

and expresses conversions between binding times. For example, a static integercan be converted into one of unknown binding time by the coercion

(cSub (St
int) (dz int) (R 1)) from Fig. 2.In general, a coercion

(cSub bfrom bto v) takes two bt descriptions andconverts value
v from binding time bfrom to binding time bto. The function
cSub is defined in type class CSUB.

class CSUB b1 b2 t where

cSub :: b1 -> b2 -> R t b1 -> R t b2

The instances of this class follow the inductive definition of the subtyping relationin the binding-time analysis (see $3.4). For base types, it corresponds to the wellknown lifting operation.
-- reflexivity
instance CSUB a a t where

cSub _ _ = id
-- base
instance CSUB (St Int) (Dy Int) Int where

cSub _ _ = R . EInt . unR
instance CSUB (St Bool) (Dy Bool) Bool where

cSub _ _ = R . EBool . unR

For function types, the code for the instances also follows the inductive definition,but it requires extra type annotations for technical reasons. Appendix E contains

the full definitions.

7

2.4 List Operations
Using the same principles as for functions, it is straightforward to develop com-binators that support partially static operations on recursive data types. The

signature for list-processing combinators serves as an example. Appendix F con-tains their implementations.

class L d da where

-- d : bt of list, da : bt of elements
cNil :: d [da s] -> R [a] (d [da s])
cCons :: d [da s] -> R a (da s) -> R [a] (d [da s]) -> R [a] (d [da s])
cHead :: d [da s] -> R [a] (d [da s]) -> R a [da s]
cTail :: d [da s] -> R [a] (d [da s]) -> R [a] [da s]
cNull :: d [da s] -> R [a] (d [da s]) -> R Bool (d Bool)

3 From Binding-Time Analysis to Tagfree Program

Generators

This section defines a translation that maps a polymorphic binding-time typederivation generated by the polymorphic binding-time analysis of Glynn and

coworkers [6] into a valid Haskell program that uses the combinators from $2.Precluding a formal correctness argument, we argue informally that the Haskell
types express the binding-time constraints and, thus, that Haskell's type sound-ness guarantees specialization soundness. Furthermore, our automatic translation scheme relieves the programmer from the cumbersome task of writing tag-free program generators by hand.

Before we formalize the type-directed translation scheme, we recapitulatethe essentials of Glynn's and coworkers polymorphic binding-time analysis and
establish connections to our set of combinators.

3.1 Underlying Type System
We consider the translation of an ML-style let-polymorphic typed language withbase types

Int and Bool. For brevity, the formalization omits structured datatypes, but the implementation supports them ($2.4).

Types t ::= ff | Int | Bool | t ! t
Type Schemes oe ::= t | 8_ff.tExpressions

e ::= x | *x.e | e e | let x = e in e

The vector notation _ff represents a sequence ff1, . . . ffn of type variables. Con-structors for numerals and Boolean values are recorded in some initial type

environment.The treatment of Haskell's advanced language feature such as type classes is
possible but postponed to future work. For instance, Glynn's and coworkers poly-morphic binding-time analysis is performed on GHC's internal System F style
type language CORE where type classes have already been 'removed' via thedictionary-passing translation. Hence, we would require combinators operating
on GHC's CORE language directly to properly deal with type classes.

8

\Delta  ` b : Int \Delta  ` b : Bool (fi : ff) 2 \Delta \Delta  ` fi : ff \Delta 1 ` o/1 : t1 \Delta 2 ` o/2 : t2\Delta 

1 [ \Delta 2 ` o/1

b7! o/

2 : t1 ! t2

Fig. 4. Shape Rules

3.2 Binding-Time Descriptions
On top of the underlying type structure we impose a binding-time (type) de-scription structure which reflects the structure of the underlying type system.

For instance, S S7! D describes a static function that takes a static value of basetype as an argument and returns a dynamic value of base type.

Annotations b ::= ffi | S | D
Binding-Time Descriptions o/ ::= fi | b | o/ b7! o/
Binding-Time Type Schemes j ::= o/ | 8 _fi, _ffi.C ) o/
Constraints C ::= (o/ <= o/ ) | wft(o/ ) | C ^ C

The grammar distinguishes annotation variables ffi, which may only be instan-tiated to

S or D, from binding-time type variables fi, which may be instantiatedto any
o/, including ffi. Constraints are described in $3.4.

3.3 Shapes
The binding-time description of an expression must generally have the same'shape' as its underlying type, in particular in the presence of polymorphism.

For this purpose, a shape environment \Delta  maps a polymorphic binding-timedescription variable to its corresponding underlying polymorphic type variable.
The judgment \Delta  ` o/ : t states that under shape environment \Delta  the binding-time description

o/ has shape t. A judgment \Delta  ` j : oe is valid if it can be derivedby the shape rules in Figure 4. For brevity, we omit the straightforward rule for

quantified types.The combinator system in $2 detects ill-shaped types via unresolved instances. For example, the (ill-shaped) type R (a -> b) (St Int) yields theunresolved type function application

ImpT (a -> b) (St Int).

3.4 Binding-Time Constraints
A subtype constraint (x <= y) is read as "y is at least as dynamic as x". It comesin various flavors: an ordering on annotations (* <=

a *), a structural ordering(* <=
s *) on bt descriptions, and an auxiliary ordering (* <=f *), which is usedin combination with the 'well-formed' constraint wft() to rule out 'ill-formed'

constraints such as S D7! S. Figure 5 summarizes the constraint rules.

9

(Sta) C ` (S <=a b) (Dyn) C ` (b <=a D)

(Hyp) C1, (b1 <=a b2), C2 ` (b1 <=a b2)

(Refl) C ` (b <=a b) (Trans) C ` (b1 <=a b2) C ` (b2 <=a b3)C ` (b

1 <=a b3)

(Basw) C ` wft(b) (Arroww)

C ` (b3 <=f o/1) C ` wft(o/1)
C ` (b3 <=f o/2) C ` wft(o/2)

C ` wft(o/1 b37! o/2)

(Basf ) C ` (b1 <=a b2)C ` (b

1 <=f b2) (Arrow

f ) C ` (b

1 <=a b2)

C ` (b1 <=f o/1 b27! o/3)

(Bass) C ` (b1 <=a b2)C ` (b

1 <=s b2) (Arrow

s)

C ` (b2 <=a b5)
C ` (o/4 <=s o/1) C ` (o/3 <=s o/6)

C ` (o/1 b27! o/3 <=s o/4 b57! o/6)

Fig. 5. Binding-Time Constraint Rules

Our combinator system detects ill-formed constraints via unresolved instances.For example, the irreducible constraint

CLAM Dy St St corresponds to the illformed description S D7! S. A binding-time description is only well-formed ifa dynamic annotation at the top of a binding-time description implies that all

its components are dynamic, too, because nothing can be known about them.Hence, the above constraint is ill-formed.

The remaining binding-time subtype relations are expressed via the typeclass

CSUB and its instances ($2.3). The instance bodies construct the necessarycoercions among binding-time values.

To be honest, the Haskell encoding leads to a slightly inferior system for thefollowing reasons. First, the transitivity rule (Trans) cannot be easily expressed
because the straightforward encoding in Haskell
instance (CSUB a b t, CSUB b c t) => CSUB a c t
requires guessing the intermediate type b during type class instance resolution. Asecond short-coming of the Haskell encoding is that out of

CSUB (St (a -> b))
(St (a -> c)) (Int -> Int) we cannot extract the proof term (a.k.a. dictio-nary) connected to

CSUB b c Int. The reverse direction is of course possible.Hence, if a program text requires

CSUB (St (a -> b)) (St (a -> c)) (Int
-> Int) but the surrounding context only provides CSUB b c Int, Haskell'stype inference will fail. A simple workaround for both problems is to provide

additional constraints which either mimic application of the transitivity rule orsupply the necessary proof terms.

10

3.5 Type-Directed Translation from BTA to Program Generators
Now everything is in place to describe the automatic construction of programgenerators based on our combinators out of Glynn and coworkers binding-time
analysis. The construction is achieved via a type-directed translation schemeand relies on judgments of the form

C, \Gamma  ` (e :: t) : o/  (eH CH ) where C isa binding-time constraint,
\Gamma  a binding-time environment, e an expression well-typed in the underlying system with type

t, o/ is a binding-time description, eHis the Haskell expression derived from
e instrumented with program generatorcombinators and
CH is a Haskell constraint which contains all the requestedcombinator instances including subtype (coercion) constraints.

Figure 6 contains the (non-syntax directed) translation rules. It is an easyexercise to make them syntax directed, following Glynn and coworkers [6].
In rule (Sub), C  CH denotes the translation of binding-time subtype con-straints (

o/1 <= o/2) to Haskell type class constraints CSUB o/1 o/2 t for some appropri-ate
t.6 Ill-formed binding-time descriptions are caught via unresolved instances.Hence, the translation simply drops the well-formed constraint wft(

o/ ). The trans-lation of the judgment
C ` (o/2 <=s o/1) to the Haskell setting may not hold anymore, unless
C contains redundant constraints as discussed in $3.4. Hence, weassume from now on that such redundant constraints are present in

C. In theresulting (Haskell) program text, the expression
eH is coerced to the expectedbt description
o/1 by inserting the combinator call cSub o/2 o/1. Descriptions suchas
o/1 occurring in expressions are short-hands for undefined :: o/1 where vari-ables appearing in

o/1 are bound by lexically scoped type annotations.7 Recallthat binding-time descriptions passed at run-time are never inspected. Thanks

to laziness they have virtually no cost.

Rule (Abs) and (App) are straightforward and do not contain any surprises.The rule (Let) additionally abstract over the binding-time descriptions _

fi and _ffiwhich then will be supplied with arguments at the instantiation site (see rule

(8E)). The function inst computes the corresponding binding-time descriptioninstances for each underlying type instance. Let

\Delta  be a shape environment, _ta sequence of underlying types, and _
ff a sequence of underlying type variables.Let inst(
\Delta , _t, _ff) = _o/ where _o/ are fresh binding-time types of appropriate shape:Each element of _

o/ is related to the corresponding element of _fi by the shapeenvironment
\Delta . That is, \Delta , ti ` o/ij where \Delta  ` fiij : ffi.

The last rule (Fix) deals with polymorphic recursion (in the binding-timedescriptions). A fixpoint iteration is required to compute the set of combinator

instances CIF etc. The constraints resulting from (e :: t) are split into those,which are not connected to _

ffi (C1H ), and those which constrain _ffi (C2H ). Thefixpoint operator F starts with

C2H plus the Haskell equivalent C20H of thesubtype constraints in
C2 and iterates until a fixpoint C3H is found. The exact

6 In a syntax-directed inference system the program text determines the type t.
7 The alternative is to build an explicit term of type o/1 as in Fig. 2.

11

definition of F is as follows:

F(\Gamma  [ {x : 8_ffi.C2H ) o/ }, e :: t)= F(

\Gamma  [ {x : 8_ffi.C2H ^ C3H ) o/}, e :: t) if C2H 6=set C3H=
C2H otherwise

where \Gamma  [ {x : 8_ffi.C2H ) o/ } ` (e :: t) : o/  (eH C3H ).The following example serves to illustrate the fixpoint iteration.

f x y = if x == 0 then 1 else f y (x-1)
Function f's most general binding time description is

8bx, by, b.(bx <= b) ^ (by <= b) ) bx S7! by S7! b
Binding-time polymorphism is required in the subexpression f y (x-1) for
building the instance by S7! bx S7! b.The first step of the translation yields the following (Haskell) constraints

from the program text:
SUB bx b Int, SUB by b Int,
CIF bx b,
CLAM St by b, CLAM St bx (by->b),
CAPP St b x b, CAPP St by (bx->b)

These constraints are not sufficient for the resulting program to type check. Forexample, at the instantiation site

f y (x-1) the constraint CIF by b is neededbut there is only
CIF bx b. Another iteration starting with the above constraintsleads to the fixpoint:

8

SUB bx b Int, SUB by b Int,
CIF bx b, CIF by b,
CLAM St by b, CLAM St bx (by->b), CLAM St bx b, CLAM St by (bx->b),
CAPP St bx b, CAPP St by (bx->b), CAPP St by b, CAPP St bx (by->b)

The fixpoint iteration must terminate because it only iterates over annota-tions whose shape is fixed/bound by the underlying type. Hence, the number of

instances arising is finite.An alternative translation scheme could employ the

cFix combinator alsoprovided by the library. It corresponds to a monomorphic (Fix) rule, which

requires no fixpoint iteration.In summary, the type-directed translation scheme builds a tight correspondence between the typing of the combinators and the typing rules of the binding-time analysis. It might be stated as a slogan in the following way.

Proposition 1. Let True, ; ` (e :: t) : o/  (eH CH ). Then, the resultingexpression

eH is well-typed in Haskell with type R t o/ under constraints CH.

8 The fixpoint iteration requires a variant of the (8E) rule which also infers the required

instantiation constraints, rather than simply checking if the provided constraints
imply the instantiation constraints. For reasons of space, we omit the straightforward
details.

12

We have no proof for this proposition, although it is easy in many cases to matchthe typing of a single combinator with its corresponding typing rule. An attempt
to prove it would have to overcome the shortcomings discussed in the precedingtext and it would have to draw on a formalization of a large subset of Haskell's
type system. Both tasks are out of scope of the present work.

4 Related Work and Conclusion
Among the large body of related work on partial evaluation (see the respec-tive overviews [7, 11]), there are only few works which consider offline partial
evaluation based on a polymorphic binding-time analysis for polymorphic lan-guages [6, 8, 9]. None of them consider the direct construction of program generators. Only Heldal and Hughes [8] deal with the pragmatics of constructing thespecializer. Other works that consider polymorphism concentrate either on polymorphic binding-time analysis for monomorphic languages [5, 10] or monomor-phic analysis for polymorphic languages [4, 12, 14].

Closely related are previous constructions of combinators that perform spe-cialization by the first author [18, 20] as well as combinators by Carette and
coworkers [3] that can be statically configured (either via overloading or via theML module language) to perform evaluation, compilation, or (online) partial
evaluation. Two main differences to the latter work are (1) that our combinatorsare geared towards offline partial evaluation and require a preceding bindingtime analysis and (2) that our combinators are dynamically configured by typepassing.

The present work complements the earlier work of Glynn and coworkers [6]and puts it into practice. Our combinators solve the open question of obtaining
safe and efficient (tag-free) program generators for ML-style languages basedon a polymorphic binding-time analysis. Our proof-of-concept implementation
relies on GHC's advanced (source) typing features and allows us to experimentwith smaller examples.

There are many opportunities for future work. We doubt that there an anal-ogous set of combinators that can be implemented in ML, but it is an interesting
question to consider. We believe that the approach is extensible to typing featuresof Haskell beyond ML. We further believe that the approach can be extended
to cater for typical partial evaluation features like program point specialization,multi-level specialization, or continuation-based specialization.

References

1. L. Birkedal and M. Welinder. Hand-writing program generator generators. In

M. V. Hermenegildo and J. Penjam, editors, Intl. Symp. Programming Languages,
Implementations, Logics and Programs (PLILP '94), volume 844 of LNCS, pages
198-214, Madrid, Spain, Sept. 1994. Springer.
2. A. Bondorf and D. Dussart. Improving CPS-based partial evaluation: Writing

cogen by hand. In P. Sestoft and H. So/ndergaard, editors, Proc. 1994 ACM Workshop Partial Evaluation and Semantics-Based Program Manipulation, pages 1-10,

13

Orlando, Fla., June 1994. University of Melbourne, Australia. Technical Report
94/9, Department of Computer Science.
3. J. Carette, O. Kiselyov, and C. chieh Shan. Finally tagless, partially evaluated: Tagless staged interpreters for simpler typed languages. J. Funct. Program., 19(5):509-
543, 2009.
4. A. De Niel, E. Bevers, and K. De Vlaminck. Partial evaluation of polymorphically

typed functional languages: the representation problem. In JTASPEFT/WSA'91,
pages 90-97, 1991.
5. D. Dussart, F. Henglein, and C. Mossin. Polymorphic recursion and subtype qualifications: Polymorphic binding-time analysis in polynomial time. In A. Mycroft,
editor, Proc. 1995 International Static Analysis Symposium, volume 983 of LNCS,
pages 118-136, Glasgow, Scotland, Sept. 1995. Springer.
6. K. Glynn, P. Stuckey, M. Sulzmann, and H. So/ndergaard. Boolean constraints

for binding-time analysis. In Programs as Data Objects II, volume 2053 of LNCS,
pages 39-62, Aarhus, Denmark, May 2001. Springer.
7. J. Hatcliff, T. AE. Mogensen, and P. Thiemann, editors. Partial Evaluation--

Practice and Theory. Proceedings of the 1998 DIKU International Summerschool,
volume 1706 of LNCS, Copenhagen, Denmark, 1999. Springer.
8. R. Heldal and J. Hughes. Binding-time analysis for polymorphic types. In PSI-01:

Andrei Ershov Fourth International Conference, Perspectives of System Informatics, volume 2244 of LNCS, pages 191-204, Novosibirsk, Russia, July 2001. Springer.
9. S. Helsen and P. Thiemann. Polymorphic specialization for ML. ACM TOPLAS,

26(4):1-50, July 2004.
10. F. Henglein and C. Mossin. Polymorphic binding-time analysis. In D. Sannella,

editor, Proc. 5th ESOP, volume 788 of LNCS, pages 287-301, Edinburgh, UK, Apr.
1994. Springer.
11. N. Jones, C. Gomard, and P. Sestoft. Partial Evaluation and Automatic Program

Generation. Prentice-Hall, 1993.
12. J. Launchbury. A strongly-typed self-applicable partial evaluator. In J. Hughes,

editor, Proc. FPCA 1991, volume 523 of LNCS, pages 145-164, Cambridge, MA,
USA, 1991. Springer.
13. J. Launchbury and C. K. Holst. Handwriting cogen to avoid problems with static

typing. In Draft Proceedings, Fourth Annual Glasgow Workshop on Functional
Programming, pages 210-218, Skye, Scotland, 1991. Glasgow University.
14. T. AE. Mogensen. Binding time analysis for polymorphically typed higher order

languages. In J. D'iaz and F. Orejas, editors, TAPSOFT '89, volume 351,352 of
LNCS, pages II, 298-312, Barcelona, Spain, Mar. 1989. Springer.
15. S. Peyton Jones, editor. Haskell 98 Language and Libraries, The Revised Report.

Cambridge University Press, 2003.
16. S. Peyton Jones, D. Vytiniotis, S. Weirich, and M. Shields. Practical type inference

for arbitrary-rank types. J. Funct. Program., 17(1):1-82, 2007.
17. T. Schrijvers, S. L. Peyton Jones, M. M. T. Chakravarty, and M. Sulzmann. Type

checking with open type functions. In P. Thiemann, editor, Proc. ICFP 2008,
pages 51-62, Victoria, BC, Canada, Oct. 2008. ACM Press, New York.
18. P. Thiemann. Cogen in six lines. In K. Dybvig, editor, Proc. 1996 ICFP, pages

180-189, Philadelphia, PA, May 1996. ACM Press, New York.
19. P. Thiemann. Aspects of the PGG system: Specialization for standard Scheme. In

Hatcliff et al. [7], pages 412-432.
20. P. Thiemann. Combinators for program generation. J. Funct. Program., 9(5):483-

525, Sept. 1999.

14

(Var) (x : j) 2 \Gamma  \Delta  ` j : oe C  CHC, \Gamma  ` (x :: oe) : j  (x C

H)

(Sub) C, \Gamma  ` (e :: t) : o/2  (eH CH) C ` (o/2 <=s o/1) C ` wft(o/1)C, \Gamma  ` (e :: t) : o/

1  (cSub o/2 o/1 eH CH ^ CSUB o/2 o/1 t)

(Abs)

C, \Gamma  [ {x : o/1} ` (e :: t2) : o/2  (eH CH)

C ` wft(o/1) \Delta  ` o/1 : t1

C, \Gamma  ` (*x.e :: t1 ! t2) : o/1 S7! o/2

(cLam ST(o/1 7! o/2) (*x.eH) CH ^ CLAM ST o/1 o/2})

(App)

C1, \Gamma  ` (e1 :: t1 ! t2) : (o/1 b7! o/2)  (e1H C1H)

C2, \Gamma  ` (e2 :: t1) : o/1  (e2H C2H)

C1 ^ C2, \Gamma  ` (e1 e2 :: t2) : o/2

(cApp (b (o/1 7! o/2)) e1H e2H C1H ^ C2H ^ CAPP b o/1 o/2)

(Let)

C1, \Gamma  ` (e1 :: t1) : o/1  (e1H C1H)

\Delta  ` o/1 : t1 _fi, _ffi ` fv(C1, o/1)\fv(\Gamma  )

where \Delta  ` fiij : ffi
C2, \Gamma  [ {x : 8 _fi_ffi.C1 ) o/1} ` (e2 :: t2) : o/2  (e2H C2H)

C2, \Gamma  ` (let x = (e1 :: 8_ff.t1) in e2 :: t2) : o/2

(let x = (* _fi.*_ffi.e1H :: 8_ff _fi_ffi.C1H ) R t1 o/1) in e2H C2H)

(8E)

C, \Gamma  ` (e :: 8_ff.t) : 8 _fi, _ffi.D ) o/  (eH CH)

\Delta  ` o/ : t inst(\Delta , _t, _ff) = _o/

C ` [_o// _fi, _b/_ffi]D
C, \Gamma  ` (e :: [_t/_ff]t) : [_o// _fi, _b/_ffi]o/  (eH _o/ _b CH)

(Fix)

j = 8_ffi.C2 ) o/ C2  C20H
C1 ^ C2, \Gamma  [ {x : j} ` (e :: t) : o/  (eH C1H ^ C2H)

C1 ^ C2 ` wft(o/) \Delta  ` j : t
fv(C1H) " _ffi = ; fv(C2H) ` _ffiF
(\Gamma  [ {x : 8_ffi.C20H ^ C2H ) o/}, e :: t) = C3H

C1, \Gamma  ` ((fix x :: t in e) :: t) : j

(let x = (*_ffi.eH :: 8_ffi.C3H ) R t o/) in x C1H)
Fig. 6. Type-direction translation rules

15

This appendix contains additional material for scrutiny by the interested reviewer. The source code of the combinators is available on-line at http://proglang.informatik.uni-freiburg.de/projects/polyspec/

A Expression Datatype
data Exp t where

EVar :: String -> Exp t
EBool :: Bool -> Exp Bool
EInt :: Int -> Exp Int
EIf :: Exp Bool -> Exp t -> Exp t -> Exp t
EConst :: Op t -> Exp t
EOp1 :: Op (a -> t) -> Exp a -> Exp t
EOp2 :: Op (a -> b -> t) -> Exp a -> Exp b -> Exp t
ELam :: (Exp a -> Exp b) -> Exp (a -> b)
EApp :: Exp (a -> b) -> Exp a -> Exp b
EFix :: Exp (a -> a) -> Exp a
ENil :: Exp [a]
ECons :: Exp a -> Exp [a] -> Exp [a]
EHead :: Exp [a] -> Exp a
ETail :: Exp [a] -> Exp [a]
ENull :: Exp [a] -> Exp Bool

16

B Uniform Binding-Time Descriptions
class Uniform t sh_t where

toImpT :: sh_t -> t -> ImpT t sh_t
fromImpT :: sh_t -> ImpT t sh_t -> t

toImpT = undefined
fromImpT = undefined

instance AllStatic t aa => Uniform t (St aa) where

toImpT ~(St sh) v = toImpT' sh v
fromImpT ~(St sh) v = fromImpT' sh v
instance AllDynamic aa => Uniform t (Dy aa)

class AllStatic t sh where

toImpT' :: sh -> t -> ImpT t (St sh)
toImpT' = error "toImp': AllStatic instance missing"
fromImpT' :: sh -> ImpT t (St sh) -> t
fromImpT' = error "fromImpT': AllStatic instance missing"
instance AllStatic Int Int where

toImpT' _ v = v
fromImpT' _ v = v
instance AllStatic Bool Bool where

toImpT' _ v = v
fromImpT' _ v = v

instance AllStatic' t aa => AllStatic [t] (Con1 aa) where

toImpT' ~(Con1 sh) vs = map (toImpT'' sh) vs
fromImpT' ~(Con1 sh) vs = map (fromImpT'' sh) vs
instance (AllStatic' s aa, AllStatic' t ab)

=> AllStatic (s -> t) (Con2 aa ab) where
toImpT' ~(Con2 sh_s sh_t) f = toImpT'' sh_t . f . fromImpT'' sh_s
fromImpT' ~(Con2 sh_s sh_t) f = fromImpT'' sh_t . f . toImpT'' sh_s

class AllStatic' t sh where

toImpT'' :: sh -> t -> ImpT t sh
fromImpT'' :: sh -> ImpT t sh -> t
instance AllStatic t aa => AllStatic' t (St aa) where

toImpT'' ~(St sh) v = toImpT' sh v
fromImpT'' ~(St sh) v = fromImpT' sh v

class AllDynamic aa
instance AllDynamic Int
instance AllDynamic Bool

instance AllDynamic' aa => AllDynamic [aa]
instance (AllDynamic' aa, AllDynamic' ab) => AllDynamic (aa -> ab)

class AllDynamic' aa
instance AllDynamic aa => AllDynamic' (Dy aa)

17

C Primitive Operators
-- construct bt description for function types
fun :: a -> b -> (a -> b)
fun = undefined

-- binary operators
-- bt description for uniformly annotated types of the form a -> b -> c
type BOP2 bt aa ab ac = bt ((bt aa) -> (bt ((bt ab) -> (bt ac))))
bop2 :: (forall a. a -> bt a) -> aa -> ab -> ac -> BOP2 bt aa ab ac
bop2 bt aa ab ac = bt (fun (bt aa) (bt (fun (bt ab) (bt ac))))

cOp2

:: (CONST

(ta -> tb -> tc)
(bt ((bt aa) -> (bt ((bt ab) -> (bt ac))))),
CAPP bt bt bt) =>
BOP2 bt aa ab ac
-> Op (ta -> tb -> tc)
-> R ta (bt aa)
-> R tb (bt ab)
-> R tc (bt ac)
cOp2 sh op x y =

cApp undefined (cApp sh (cConst sh op) x) y

-- unary operators
-- bt description for uniformly annotated types of the form a -> b
type BOP1 bt aa ab = bt ((bt aa) -> (bt ab))
bop1 :: (forall a. a -> bt a) -> a1 -> a2 -> BOP1 bt a1 a2
bop1 bt a1 a2 = bt (fun (bt a1) (bt a2))

cOp1 :: (CAPP bt bt bt, CONST (a -> b) (bt ((bt aa) -> (bt bb))))

=> BOP1 bt aa bb -> Op (a -> b) -> R a (bt aa) -> R b (bt bb)
cOp1 sh op x =

cApp sh (cConst sh op) x

18

D Function Application and Fixpoint
class CAPP bt ba bb where

cApp :: (LE bt ba, LE bt bb)

=> bt (Con2 (ba aa) (bb ab))
-> R (ta -> tb) (bt (Con2 (ba aa) (bb ab)))
-> (R ta (ba aa) -> R tb (bb ab))

instance CAPP St ba bb where

cApp _ f x = R $ unR f (unR x)

instance CAPP Dy Dy Dy where

cApp _ f x = R $ EApp (unR f) (unR x)

--
class CFIX bt ba where

cFix :: (LE bt ba)

=> (bt (Con2 (ba aa) (ba aa)))
-> R (ta -> ta) (bt (Con2 (ba aa) (ba aa)))
-> R ta (ba aa)

instance CFIX St ba where

cFix _ f = R $ fix (unR f)

instance CFIX Dy Dy where

cFix _ f = R $ EFix (unR f)

fix :: (a -> a) -> a
fix f = f (fix f)

19

E Subtyping for Functions
E.1 Static Functions
instance (CSUB b3 b1 t1, CSUB b2 b4 t2)

=> CSUB (St (Con2 b1 b2)) (St (Con2 b3 b4)) (t1->t2) where
cSub _ _ f = subStArrowContra (subStArrowCo f)

-- subStArrowCo casts result type
-- subStArrowContra casts argument type
-- we could of course merge both functions

-- we require lexically scoped type annotations to resolve ambiguities
subStArrowCo :: forall t1 t2 b1 b2 b4.

CSUB b2 b4 t2
=> R (t1->t2) (St (Con2 b1 b2)) -> R (t1->t2) (St (Con2 b1 b4))
subStArrowCo f = R $ (\x ->

let r1 :: ImpT (t1->t2) (St (Con2 b1 b2))

r1 = unR f
r2 :: ImpT t2 b2
r2 = r1 x
r3 :: R t2 b2
r3 = R r2
r4 :: R t2 b4
r4 = cSub undefined undefined r3
r5 :: ImpT t2 b4
r5 = unR r4
in r5)
--subStArrowCo f = R $ (\x -> unR (cSub (R ((unR f) x))))

subStArrowContra :: forall t1 t2 b1 b2 b3.

CSUB b3 b1 t1
=> R (t1->t2) (St (Con2 b1 b2)) -> R (t1->t2) (St (Con2 b3 b2))
subStArrowContra f = R $ (\x ->

let r1 :: R t1 b3

r1 = R x
r2 :: R t1 b1
r2 = cSub undefined undefined r1
r3 :: ImpT t1 b1
r3 = unR r2
r4 :: ImpT (t1->t2) (St (Con2 b1 b2))
r4 = unR f
r5 :: ImpT t2 b2
r5 = r4 r3
in r5)
-- subStArrowContra f = R $ (\x -> (unR f) (unR (cSub (R x))))

20

E.2 Dynamic Functions
-- CSUB (St (b1' -> b2)) (Dy (b3' -> b4')) (t1->t2)
-- implies due to wft that b3' and b4' dynamic
-- CSUB b3' b1' implies b1' dynamic, hence, we obtain
-- the following
instance (CSUB (Dy b3) (Dy b1) t1, CSUB b2 (Dy b4) t2)

=> CSUB (St (Con2 (Dy b1) b2)) (Dy (Con2 (Dy b3) (Dy b4))) (t1->t2) where
cSub _ _ f = subDyArrowContra (subDyArrowCo f)

subDyArrowCo :: forall t1 t2 b1 b2 b4.

CSUB b2 (Dy b4) t2
=> R (t1->t2) (St (Con2 (Dy b1) b2)) -> R (t1->t2) (St (Con2 (Dy b1) (Dy b4)))
subDyArrowCo f = R $ (\x ->

let r1 :: ImpT (t1->t2) (St (Con2 (Dy b1) b2))

r1 = unR f
r2 :: ImpT t2 b2
r2 = r1 x
r3 :: R t2 b2
r3 = R r2
r4 :: R t2 (Dy b4)
r4 = cSub undefined undefined r3
r5 :: ImpT t2 (Dy b4)
r5 = unR r4
in r5)
--subDyArrowCo f = R $ ELam $ (\x -> unR (cSub (R ((unR f) x))))

subDyArrowContra :: forall t1 t2 b1 b2 b3.

CSUB (Dy b3) (Dy b1) t1
=> R (t1->t2) (St (Con2 (Dy b1) (Dy b2)))
-> R (t1->t2) (Dy (Con2 (Dy b3) (Dy b2)))
subDyArrowContra f = R $ ELam $ (\x ->

let r1 :: R t1 (Dy b3)

r1 = R x
r2 :: R t1 (Dy b1)
r2 = cSub undefined undefined r1
r3 :: ImpT t1 (Dy b1)
r3 = unR r2
r4 :: ImpT (t1->t2) (St (Con2 (Dy b1) (Dy b2)))
r4 = unR f
r5 :: ImpT t2 (Dy b2)
r5 = r4 r3
in r5)
-- subStArrowContra f = R $ Elam $ (\x -> (unR f) (unR (cSub (R x))))

21

F List Processing
instance L St da where

cNil _ = R []
cCons _ = \(R x) (R y) -> R ( x:y )
cHead _ = R . head . unR
cTail _ = R . tail . unR
cNull _ = R . null . unR

instance L Dy Dy where

cNil _ = R ENil
cCons _ (R x) (R y) = R $ ECons x y
cHead _ (R x) = R $ EHead x
cTail _ (R x) = R $ ETail x
cNull _ = R . ENull . unR

22