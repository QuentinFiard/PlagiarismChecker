

Alias Types for Recursive Data Structures *

David Walker and Greg Morrisett

Cornell University

Abstract
Linear type systems permit programmers to deallocate or
explicitly recycle memory, but they are severly restricted by
the fact that they admit no aliasing. This paper describes
a pseudo-linear type system that allows a degree of aliasing and memory reuse as well as the ability to define complex recursive data structures. Our type system can encode
conventional linear data structures such as linear lists and
trees as well as more sophisticated data structures including
cyclic and doubly-linked lists and trees. In the latter cases,
our type system is expressive enough to represent pointer
aliasing and yet safely permit destructive operations such as
object deallocation. We demonstrate the flexibility of our
type system by encoding two common compiler optimizations: destination-passing style and Deutsch-Schorr-Waite
or "link-reversal" traversal algorithms.

1 Introduction
Type-safe programming languages, such as Haskell, Java,
and ML, do not give programmers control over memory
management. In particular, these languages do not allow programmers to separate allocation and initialization of
memory objects, nor do they allow explicit re-use of memory
objects. Rather, allocation and initialization of objects are
presented to the programmer as an atomic operation, and
re-use of memory is achieved "under the covers" through
garbage collection. In other words, memory management
is achieved by meta-linguistic mechanisms that are largely
outside the control of the programmer.

In type-unsafe languages such as C or C++, programmers have control over memory management so they can
tailor routines for application-specific constraints, where the
time and/or space overheads of general-purpose memory
management mechanisms do not suffice. However, such languages have a far more complicated and error-prone programming model. In particular, neither the static type systems, the compilers, nor the run-time systems of these languages prevent the accidental use of uninitialized objects,
or the accidental re-use of memory at an incompatible type.
Such errors are extremely costly to diagnose and correct.

Our ultimate goal is to provide support for programmercontrolled memory management, without sacrificing typesafety, and without incurring significant overhead. In addition, we hope to discover general typing mechanisms and
principles that allow greater lattitude in the design of lowlevel languages intended for systems applications or as the
target of certifying compilers [22, 23]. In this paper, we

*This material is based on work supported in part by the AFOSR
grant F49620-97-1-0013 and the National Science Foundation under
Grant No. EIA 97-03470. Any opinions, findings, and conclusions
or recommendations expressed in this publication are those of the
authors and do not reflect the views of these agencies.

take a step further towards these goals by developing a type
system that gives fine-grained control over memory management, for a rich class of recursively defined datatypes. We
demonstrate the power of the type system by showing how
we can safely encode two important classes of optimization,
destination-passing style and link-reversal traversals of data
structures.

1.1 Background
One well-known principle for proving type safety is based
upon type-invariance of memory locations. Simply put, this
property says that, when allocated, a memory object should
(conceptually) be stamped with its type, and that the type
of the object should not change during evaluation. When
this property is maintained, it is straightforward to prove
a subject-reduction or type-preservation property (see for
example [37, 11]), which is in turn crucial to establishing
type-soundness. There are many examples from language
design where this principle has been violated and resulted
in an unsoundness. For instance, the naive treatment of
polymorphic references in an ML-like language, or the covariant treatment of arrays in a Java-like language, both
violate this basic principle.

From the type-invariance principle, it becomes clear why
most type-safe languages do not support user-level initialization or memory recycling: the type o/ of the memory object cannot change, so (1) it must initially have type o/ and
(2) must continue to have type o/ after an evaluation step.
Atomic allocation and initialization ensures the first invariant, and the lack of explicit re-cycling ensures the second.
Thus, it appears that some meta-linguistic mechanism is
necessary to achieve memory management when the typeinvariance principle is employed.

Linear type systems [35, 33] employ a different principle
to achieve subject-reduction. In a linear setting, the crucial invariant is that memory objects must have exactly one
reference -- that is, no object can be aliased. Unlike the traditional approach, the type of a memory object can change
over time and thus, explicit initialization and re-cycling can
be performed in the language. Unfortunately, the inability to share objects through aliasing can have a steep cost:
Many common and efficient data structures that use sharing
or involve cycles cannot be implemented.

In recent previous work, we considered a generalization
of linear types that supported a very limited degree of aliasing [29]. Like linear type systems, our alias types supported
separation of allocation and initialization, and explicit reuse of memory, but unlike linear approaches, some objects
could have more than one reference. To achieve subject reduction, we tracked aliasing in the type system by giving
memory objects unique names, and maintained the invariant that the names were unique. We found that alias types
unified a number of ad-hoc features in our Typed Assembly

Language, including the treatment of initialization and control stacks. Furthermore, the alias type constructors were
easy to add to our type checker for TALx86 [31].

Unfortunately, the named objects in our alias-type system were restricted to a "second-class" status; though
named objects could be passed to and from functions, the
type system prevented a programmer from placing these objects in a recursive datatype such as a list or tree. The problem is that our type system did not track aliasing beyond a
certain compile-time "frontier", and in this respect, was similar to the k-limiting approaches used in alias analysis [12].
As a result, we could not embed linear datatypes into our
language, and the opportunities for user-level memory management were greatly reduced.

In this paper, we extend alias types to cover recursive
datatypes in full generality. Our type system is powerful
enough to encode linear variants of lists and trees, as well
as richer data structures with complex shapes and aliasing
relationships, such as cyclic or doubly-linked lists and trees.
The critical addition to the type system is a mechanism for
combining recursive type operators with first-class store abstractions that represent repeated patterns of aliasing. In
this respect, our work is inspired by the more complex approaches to alias and shape analysis that have recently appeared in the literature [7, 9, 26].

The generalization to recursive datatypes opens the door
for users or certifying compilers to have far more control
over the memory management of complex data structures.
To demonstrate this fact, we show how two classes of space
optimization can be encoded in a language based on recursive alias types. The first optimization, called destinationpassing style [34, 16, 5] transforms algorithms that are "tailrecursive modulo allocation" into properly tail-recursive algorithms, thereby avoiding the space overheads of a control
stack. The second optimization shows how we can safely encode Deutsch-Schorr-Waite algorithms [28] for traversing a
tree using minimal additional space, based on link-reversal.

In the following section, we motivate the type structure
of the language by introducing a series of type-theoretic abstraction mechanisms that enable suitable approximations
of the store. We then show how these constructors may be
used to encode a number of common data structures, without losing the ability to explicitly manage memory. Section 3
formalizes these ideas by presenting the syntax and static
semantics of a programming language that includes instructions for allocating, deallocating, and overwriting memory
objects. Section 4 shows how the destination-passing style
and link-reversal optimizations can be safely encoded in the
language. Section 5 presents an operational semantics for
the language and states a type soundness theorem. We close
in Section 6 by further discussing related work.

2 Types for describing store shapes
The linear type o/1 \Omega o/2 captures an extremely valuable memory management invariant: There is only one access path to
any value with this type. Consequently, if x has type o/1 \Omega  o/2
then once both its components have been extracted, it is
safe to reuse x to store new values with incompatible types.
Since the only way to access x's data is through x itself,
there is no chance that this reuse can introduce inconsistent
views of the store and unsoundness into the system.

Unfortunately, the restriction to a single access path
makes it impossible to construct a number of important data

structures. Our goal is to lift this restriction and yet retain
the capacity to reuse or deallocate memory when there is a
pointer to it. Our approach is based on the intuition that a
linear data structure may be decomposed into two parts, a
piece of state and a pointer to that state. Destructive operations such as memory reuse alter only the state component
and leave the pointer part unchanged. Consequently, if the
goal is to ensure no inconsistencies arise, only the state component need be treated linearly. The pointer may be freely
copied, making it possible to construct complex data structures with shared parts. Of course, in order to actually use
a pointer, there must be some way to relate it to the state
it points to. We make this relationship explicit in the type
system by introducing locations, `, that contain the state
component, and by specializing the type of a pointer to indicate the location it points to. Consider again the linear
pair o/1 \Omega  o/2. We factor it into two parts:

* A type for the state, called an aliasing constraint or

store description, that takes the form {` 7! ho/1, o/2i}.
This type states that at location ` there exists a memory block containing objects with types o/1 and o/2.

* A type for a pointer to the location: ptr(`). This type is

a singleton type--any pointer described by this type is
a pointer to the one location ` and to no other location.

This simple trick provides a tremendous flexibility advantage over conventional linear type systems because even
though constraints may not alias one another, there is no
explicit restriction on the way pointer types may be manipulated.

We build complicated data structures by joining a number of aliasing constraints together using the \Omega  constructor.
For example, the following DAG may be specified by the
constraints below.

3
-

-
,,,:

`1: `2: `3:

{`1 7! hptr(`2), ptr(`3)i} \Omega {

`2 7! hptr(`3)i} \Omega {
`3 7! hinti}

In this type, the locations `1, `2 and `3 are necessarily distinct from one another because they all appear on left-hand
sides in this collection of constraints. The type system maintains the invariant that if a store is described by constraints{

`1 7! o/1} \Omega  * * * \Omega  {`n 7! o/n} then each of the locations `i
must be different from one another. This invariant resembles
invariants for the typing context of a standard linear type
system. For example, the linear context x1:o/1, . . . , xn:o/n implies that the xi are distinct values with linear types o/i.
However, the analogy is not exact because a linear type system prevents any of the xi from being used more than once
whereas our calculus allows pointers to the locations `i to
be used over and over again and this flexibility makes it possible to represent aliasing: In the type above, there are two
paths from location `1 to location `3, one direct and one
indirect through location `2.

One other important invariant is that although the \Omega 
constructor is reminiscent of linear pairs, the ordering of the
constraints joined by \Omega  is not important: {`1 7! o/1}\Omega {`2 7!
o/2} is equivalent to {`2 7! o/2} \Omega  {`1 7! o/1}. For the sake
of brevity, we often abbreviate {`1 7! o/1} \Omega  {`n 7! o/n} with{

`1 7! o/1, . . . , `n 7! o/n}.

2

2.1 Abstraction mechanisms
Any particular store can be represented exactly using these
techniques1, even stores containing cyclic data structures.
For example, a node containing a pointer to itself may be
represented with the type {` 7! hptr(`)i}. However, the
principle difficulty in describing aliasing relationships is not
specifying one particular store but being able to specify a
class of stores using a single compact representation. We
use the following type-theoretic abstraction mechanisms to
describe a wide class of pointer-rich data structures.

Location Polymorphism In general, the particular location
` that contains an object is inconsequential to the algorithm
being executed. The relevant information is the connection
between the location `, the contents of the memory residing
there, and the pointers ptr(`) to that location. Routines
that only operate on specific concrete locations are almost
useless. If, for example, the dereference function could only
operate on a single concrete location `, we would have to implement a different dereference function for every location we
allocate in the store! By introducing location polymorphism,
it is possible to abstract away from the concrete location `
using a variable location ae, but retain the necessary dependencies. We use the meta-variable j to refer to locations
generically (either concrete or variable).

Store Polymorphism Any specific routine only operates
over a portion of the store. In order to use that routine
in multiple contexts, we abstract irrelevant portions of the
store using store polymorphism. A store described by the
constraints ffl \Omega {j 7! o/} contains some store of unknown size
and shape ffl as well as a location j containing objects with
type o/. We use the meta-variable C to range over aliasing
constraints in general.

Unions Unlike polymorphic types, unions provide users
with the abstraction of one of a finite number of choices.
A memory block that holds either an integer or a pointer
may be encoded using the type hinti [ hptr(j)i. However,
in order to use the contents of the block safely, there must
be some way to detect which element of the union the underlying value actually belongs to. There are several ways
to perform this test: through a pointer equality test with an
object of known type, by descriminating between small integers (including null/0) and pointers, or by distinguishing
between components using explicit tags. All of these options
will be useful in an implementation, but here we concentrate
on the third option. Hence, the alternatives above will be
encoded using the type hS(1), inti[hS(2), ptr(j)i where S(i)
is another form of singleton type -- the type containing only
the integer i.

Recursion As yet, we have defined no mechanism for describing regular repeated structure in the store. We use
standard recursive types of the form uff.o/ to capture this
notion. However, recursion by itself is not enough. Consider an attempt to represent a store containing a linked
list in the obvious way: {j 7! uff.hS(1)i [ hS(2), ffi}.2
An unfolding of this definition results in the type {j 7!

1We cannot represent a store containing a pointer into the middle
of a memory block.2

Throughout we use the convention that union binds tighter than
the recursion operator.

hS(1)i [ hS(2), hS(1)i [ hS(2), Listii}, rather than the type{

j 7! hS(1)i [ hS(2), ptr(j0)i, j0 7! hS(1)i [ hS(2), Listi}.
The former type describes a number of memory blocks flattened into the same location whereas the latter type describes a linked collection of disjoint nodes.

Encapsulation In order to represent linked recursive structures properly, each unfolding must encapsulate its own portion of the store. We use an existential type for this purpose.
Hence, a sensible representation for linked lists is

uff.hS(1)i [ 9[ae:Loc | {ae 7! ff}].hS(2), ptr(ae)i
The existential 9[ae:Loc | {ae 7! o/1}].o/2 may be read "there
exists some location ae, different from all others in the program, such that ae contains an object of type o/1, and the
value contained in this data structure has type o/2. More
generally, an existential has the form 9[\Delta  | C].o/. It abstracts a sequence of type variables with their kinds, \Delta , and
encapsulates a store described by some constraints C. In
our examples, we will omit the kinds from the sequence \Delta 
as they are clear from context. A similar definition gives
rise to trees:

uff.hS(1)i [ 9[ae1, ae2 | {ae1 7! ff, ae2 7! ff}].hS

(2), ptr(ae1), ptr(ae2)i

Notice that the existential abstracts a pair of locations and
that both locations are bound in the store. From this definition, we can infer that the two subtrees are disjoint. For
the sake of contrast, a DAG in which every node has a pair
of pointers to a single successor is coded as follows. Here,
reuse of the same location variable ae indicates aliasing.

uff.hS(1)i [ 9[ae | {ae 7! ff}].hS(2), ptr(ae), ptr(ae)i
Cyclic lists and trees with leaves that point back to their
roots also cause little problem--simply replace the terminal
node with a memory block containing a pointer type back
to the roots.

CircularList ={

ae1 7! uff.hS(1), ptr(ae1)i[9

[ae2 | {ae2 7! ff}].hS(2), ptr(ae2)i}

CircularT ree ={

ae1 7! uff.hS(1), ptr(ae1)i[9

[ae2, ae3 | {ae2 7! ff, ae3 7! ff}].hS

(2), ptr(ae2), ptr(ae3)i}

Parameterized Recursive Types One common data structure we are unable to encode with the types described so far
is the doubly-linked list. Recursive types only "unfold" in
one direction, making it easy to represent pointers from a
parent "down" to its children, or all the way back up to the
top-level store, but much more difficult to represent pointers
that point back up from children to their parents, which is
the case for doubly-linked lists or trees with pointers back
to their parent nodes. Our solution to this problem is to
use parameterized recursive types to pass a parent location
down to its children. In general, a parameterized recursive
type has the form rec ff (fi1:^1, . . . , fin:^n).o/ and has kind
(^1, . . . , ^n) ! Type. We will continue to use unparameterized recursive types uff.o/ in examples and consider them to
be an abbreviation for rec ff ().o/[ff ()/ff]. Once again, kinds

3

will be omitted when they are clear from the context. Trees
in which each node has a pointer to its parent may be encoded as follows.

{aeroot 7! hS(2), ptr(aeL), ptr(aeR)i} \Omega {

aeL 7! REC (aeroot, aeL)} \Omega {
aeR 7! REC (aeroot, aeR)}

where

REC =

rec ff (aeprt, aecurr).hS

(1), ptr(aeprt)i[9
[aeL, aeR | {aeL 7! ff (aecurr, aeL)}\Omega {

aeR 7! ff (aecurr, aeR)}].hS

(2), ptr(aeL), ptr(aeR), ptr(aeprt)i

The tree has a root node in location aeroot that points to a
pair of children in locations aeL and aeR, each of which are defined by the recursive type REC. REC has two arguments,
one for the location of its immediate parent aeprt and one for
the location of the current node aecurr. Either the current
node is a leaf, in which case it points back to its immediate
parent, or it is an interior node, in which case it contains
pointers to its two children aeL and aeR as well as a pointer to
its parent. The children are defined recursively by providing
the location of the current node (aecurr) for the parent parameter and the location of the respective child (aeL or aeR)
for the current pointer.

Function Types Functions are polymorphic with type arguments \Delta  and they express the shape of the store (C) required by the function: 8[\Delta  | C].(o/1, . . . , o/n)!0. The underlying term language will be written in continuation-passing
style and therefore functions never return, but instead call
another function (the function's continuation). We use the
notation "! 0" to indicate this fact. Continuation-passing
style is extremely convenient in this setting because it makes
the flow of control explicit in the language and the store
shape varies from one control-flow point to the next.

2.2 Summary of Type Structure
The formal syntax for the type constructor language is defined in the table below. We distinguish a subset of the
types, called small types, for which no additional storage
need be allocated when they are copied. The small types
contain objects such as integers, functions3 and data pointers. Function parameters are required to contain small types
because function application is modeled by substitution,
which copies values. Likewise, fields of memory blocks must
be small because field projection copies values.

kinds ^ ::= Loc | Store | Small | Type |

(^1, . . . , ^n) ! Type
con. vars fi ::= ae | ffl | ff
con. ctxts \Delta  ::= * | \Delta , fi:^
constructors c ::= j | C | o/

3For the purposes of this paper, we ignore the space required by
closures. The language is powerful enough to encode closure conversion in the style of Morrisett et al. [22]. If desired, closure environments can be represented as memory blocks and functions can be
required to be closed.

locations j ::= ae | `
constraints C ::= ; | C \Omega  {j 7! o/} | C \Omega  ffl

types o/ ::= ff | oe | hoe1, . . . , oeni |

o/1 [ o/2 | 9[\Delta  | C].o/ |
rec ff (\Delta ).o/ | c (c1, . . . , cn)
small types oe ::= ff | int | S(i) | ptr(j) |8

[\Delta  | C].(oe1, . . . , oen) ! 0

A judgement \Delta  ` c : ^ states that a type is well-formed
and has kind ^ according to the assignment of free type
variables to kinds given by \Delta . Locations have kind Loc,
aliasing constraints have kind Store, small types have the
kind Small, but like the other types, may also be given kind
Type. Recursive types have arrow kinds that can be eliminated through constructor application c (c1, . . . , cn). The
judgement \Delta  ` c1 = c2 : ^ states that type constructors c1
and c2 are equivalent and well-formed with kind ^. Types
are considered equivalent up to alpha-conversion of bound
variables and constraints are considered equivalent up to reordering of the elements in the sequence. A recursive type is
not considered equal to its unfolding. The formal rules for
these judgements are straightforward and have been omitted
due to space considerations. See the companion technical
report [36] for details.

We use the notation A[X/x] to denote the captureavoiding substitution of X for a variable x in A. Occasionally, we use the notation X[c1, . . . , cn/\Delta ] to denote captureavoiding substitution of constructors c1, . . . , cn for the corresponding type variables in the domain of \Delta . Substitution
is defined in the stardard way in all cases except for the
substitution of constraints in constraints. Substitution of
C0 for a constraint variable ffl in C appends the list C0 to the
list C. We use the notation C0@C to denote the result of
appending C to C0 (notice that C \Omega  C0 is not syntactically
well-formed). For example,

(; \Omega  a1 \Omega  * * * \Omega  am)@(; \Omega  a01 \Omega  * * * \Omega  a0n) =; \Omega 

a1 \Omega  * * * \Omega  am \Omega  a01 \Omega  * * * \Omega  a0n

Formally, substitution for constraints is defined as follows.

(C \Omega  ffl)[C0/ffl] = (C[C0/ffl])@C0
We will continue to omit the initial ";" when a constraint
is non-empty. For example, we write {j 7! o/} instead of; \Omega  {

j 7! o/}.

3 Term Structure
The term structure is split into three classes: values, instructions, and coercions. The grammar below describes
the syntax of the language.

values v ::= x | i | S(i) | v[c] |

fixf[\Delta  | C](x1:oe1, . . . , xn:oen).'
instruct's ' ::= new ae, x, i; ' | free v; ' |

let x = (v).i; ' | (v1).i := v2; ' |
case v (inl ) '1 | inr ) '2) |
v(v1, . . . , vn) | halt v |
coerce(fl); '
coercions fl ::= uniono/1[o/2(j) |

rollrec ff (\Delta ).o/ (c1,...,cn)(j) |
unroll(j) |
pack[c1,...,cn|C]as 9[\Delta |C].o/ (j) |

unpack j with \Delta 

4

\Delta ; \Gamma  ` v : o/

\Delta ; \Gamma  ` x : \Gamma (x) \Delta ; \Gamma  ` i : int \Delta ; \Gamma  ` S(i) : S(i)
\Delta  ` 8[\Delta 0 | C0].(oe1, . . . , oen) ! 0 = oef : Small \Delta \Delta 0; C0; \Gamma , f:oef, x1:oe1, . . . , xn:oen ` '

\Delta ; \Gamma  ` fixf[\Delta 0 | C0](x1:oe1, . . . , xn:oen).' : oef

\Delta ; \Gamma  ` v : 8[fi:^, \Delta 0 | C0].(oe1, . . . , oen) ! 0 \Delta  ` c : ^

\Delta ; \Gamma  ` v[c] : (8[\Delta 0 | C0].(oe1, . . . , oen) ! 0)[c/fi]

\Delta ; \Gamma  ` v : oe0 \Delta  ` oe0 = oe : Small

\Delta ; \Gamma  ` v : oe

\Delta ; \Gamma  ` v : o/0 \Delta  ` o/0 = o/ : Type

\Delta ; \Gamma  ` v : o/

Figure 1: Static Semantics: Values
Values Values consist of integers, singleton integers, and
functions. Their typing judgements have the form \Delta ; \Gamma  `
v : o/ where \Gamma  is a finite partial map from value variables
to small types. The rules are mostly standard and are presented in figure 1. Notice that functions may be recursive
and contain a specification of the polymorphic variables \Delta ,
the requirements on the store C and the types of the parameters. These preconditions are used to type the instruction
sequence that forms the body of the function. The value v[c]
denotes type application of the polymorphic function v to
type constructor c. We often abbreviate successive type applications v[c1] * * * [cn] by v[c1, . . . , cn]. Later, when we give
an operational semantics for the language, we will add other
values (such as pointers and memory blocks), but these objects only appear at run time and so we omit them for now.

Instructions Figure 2 present the typing rules for the instructions. The judgement \Delta ; C; \Gamma  ` ' states that in type
context \Delta , a store described by C and value context \Gamma , the
instruction sequence ' is well-formed.

The principle interest of the language is the typing
of memory management instructions. Operationally, the
new ae, x, i instruction allocates a memory block of size i
at a fresh location and substitutes the location for ae and a
pointer to that location for x in the remaining instructions.4
This operation is modeled in the type system by extending
the store description with a memory type of length i. Initially, the fields of the memory block have type S(0) since we
assume the allocator returns zeroed-out memory.5 Once a
block has been allocated, it may be operated on by accessor
functions let x = (v1).i and (v1).i := v2, which project from
or store into the ith field of v1. The projection operation is
well-formed if v1 is a pointer to some location j and that
location contains a object with type hoe1, . . . , oeni (where i is
less than n). In this case, the remaining instructions ' must
be well-formed given the additional assumption that x has
type oei. The update operation is similar in that v1 must be a
pointer to a location containing a memory block. However,

4For the purposes of alpha-conversion, ae and x are considered
bound by this instruction.5

If an allocator returns unzeroed, random memory, it is may be
modelled by adding a Top type and returning a memory block with
fields of type Top.

the remaining instructions are verified in a context where
the type of the memory block has changed: The ith field
has type oe where oe is the type of the object being stored
into that location, but is otherwise unconstrained. Although
surprising at first, this rule is sound because the constraints
behave linearly. Despite the fact that the type of a memory
block at a location changes, each location can only appear
once in the domain of a store type and therefore there is
no opportunity to introduce inconsistencies into the store
typing. Constraints such as {j 7! o/} \Omega  {j 7! o/0} will never
describe a well-formed store. The instruction free v frees
the memory block pointed to by v. This effect is reflected
in the typing rule for free by requiring that the remaining
instructions be well-formed in a context C0 that does not
include the location j.

The typing of the case expression is also somewhat unusual. Operationally, case checks the first field of the memory block in the location pointed to by a value v. If the first
field is a 1, execution continues with the first instruction sequence, and if it is a 2, execution continues with the second
instruction sequence. However the memory type constructorh* * *i

will not be the top-most type constructor (otherwise,
the case would be unnecessary). The type system expects
a union type to be the top-most and each alternative may
contain some number (possibly zero) of existential quantifiers to abstract the store encapsulated in that alternative.
The underlying memory value must have either tag 1 or tag
2 in its first field. As mentioned earlier, it is possible to formulate other union elimination constructs including pointer
equality checks or discrimination between pointers and small
integers (such as null implemented by 0).

Because the language has been defined in continuationpassing style, all instruction sequences are either terminated
by a function call v(v1, . . . , vn) or a call to the terminal continuation halt, which requires an integer argument. Function calls are well-formed if the polymorphic function v has
been fully instantiated, the constraints in the current context equal the constraints required by the function, and the
argument types match the types of the function parameters.

The last instruction coerce(fl) applies a typing coercion to the store. Coercions, unlike the other instructions
are for type-checking purposes only. Intuitively, coercions
may be erased before executing a program and the run5

\Delta ; C; \Gamma  ` '

\Delta , ae:Loc; C \Omega  {ae 7!

iz ""-- -
hS(0), . . . , S(0)i}; \Gamma , x:ptr(ae) ` '
\Delta ; C; \Gamma  ` new ae, x, i; ' (x 62 Dom(\Gamma ), ae 62 Dom(\Delta ))

\Delta ; \Gamma  ` v : ptr(j) \Delta  ` C = C0 \Omega  {j 7! hoe1, . . . , oeni} : Store \Delta ; C0; \Gamma  ` '

\Delta ; C; \Gamma  ` free v; '

\Delta ; \Gamma  ` v : ptr(j) \Delta  ` C = C0 \Omega  {j 7! hoe1, . . . , oeni} : Store \Delta ; C; \Gamma , x:oei ` '

\Delta ; C; \Gamma  ` let x = (v).i; ' `

1 <= i <= n
x 62 Dom(\Gamma )'

\Delta ; \Gamma  ` v1 : ptr(j) \Delta  ` C = C0 \Omega  {j 7! hoe1, . . . , oei, . . . , oeni} : Store

\Delta ; \Gamma  ` v2 : oe \Delta ; C0 \Omega  {j 7! hoe1, . . . , oe, . . . , oeni}; \Gamma  ` '

\Delta ; C; \Gamma  ` (v1).i := v2; ' (1 <= i <= n)

\Delta ; \Gamma  ` v : ptr(j) \Delta  ` C = C0 \Omega  {j 7! o/1 [ o/2} : Store
\Delta  ` o/1 = 9[\Delta 01 | C01]. * * * 9[\Delta 0j | C0j].hS(1), oe01, . . . , oe0ki : Type
\Delta  ` o/2 = 9[\Delta 001 | C001 ]. * * * 9[\Delta 00m | C00m].hS(2), oe001 , . . . , oe00ni : Type

\Delta ; C0 \Omega  {j 7! o/1}; \Gamma  ` '1 \Delta ; C0 \Omega  {j 7! o/2}; \Gamma  ` '2

\Delta ; C; \Gamma  ` case v (inl ) '1 | inr ) '2)

\Delta ; \Gamma  ` v : 8[* | C].(oe1, . . . , oen) ! 0 \Delta ; \Gamma  ` v1 : oe1 * * * \Delta ; \Gamma  ` vn : oen

\Delta ; C; \Gamma  ` v(v1, . . . , vn)

\Delta ; \Gamma  ` v : int
\Delta ; C; \Gamma  ` halt v

\Delta ; C ` fl =) \Delta 0; C0 \Delta 0; C0; \Gamma  ` '

\Delta ; C; \Gamma  ` coerce(fl); '

Figure 2: Static Semantics: Instructions
time behaviour will not be affected. The judgement form
\Delta ; C ` fl =) \Delta 0; C0 indicates that a coercion is well-formed,
extends the type context to \Delta 0, and produces new store constraints C0. These judgements are presented in figure 3.

Each coercion operates on a particular store location j.
The union coercion lifts the object at j into a union type
and the roll/unroll coercions witness the isomorphism
between a recursive type and its unfolding. The coercion
pack[c1,...,cn|C0[c1,...,cn/\Delta 0]]as 9[\Delta 0|C0].o/ (j) introduces an existential type by hiding the type constructors c1, . . . , cn and
encapsulating the store described by C0[c1, . . . , cn/\Delta 0]. The
unpack coercion eliminates an existential type, augments the
current constraints with the encapsulated C0, and extends
the type context \Delta  with \Delta 0, the hidden type constructors.

4 Applications
In this section, we show how our language can be used to
encode two common programming patterns, the destinationpassing style pattern, which constructs data structures efficiently and the Deutsch-Schorr-Waite or "link-reversal" patterns, which traverse data structures using minimal additional space.

4.1 Destination-Passing Style
An effective optimization for functional languages is the
destination-passing style (DPS) transformation. Wadler [34]
first realized that compilers could detect certain "almosttail-recursive" functions and automatically transform such
functions into more efficient tail-recursive functions. Since
then several other researchers have studied various facets of
this problem [16, 5, 18]. Our contribution is to provide a
type system that can be used in a type-preserving compiler
and is capable of verifying that the code resulting from the
transformation is safe.

Append is the canonical example of a function suitable
for DPS:

6

\Delta ; C ` fl =) \Delta 0; C0

\Delta  ` C = C0 \Omega  {j 7! o/i} : Store \Delta  ` o/1 : Type \Delta  ` o/2 : Type

\Delta ; C ` uniono/1[o/2(j) =) \Delta ; C0 \Omega  {j 7! o/1 [ o/2} (for i = 1 or 2)

\Delta  ` o/ = (rec ff (\Delta 0).o/0) (c1, . . . , cn) : Type \Delta  ` C = C0 \Omega  {j 7! o/0[rec ff (\Delta 0).o/0/ff][c1, . . . , cn/\Delta 0]} : Store

\Delta ; C ` rollo/ (j) =) \Delta ; C0 \Omega  {j 7! o/}

\Delta  ` C = C0 \Omega  {j 7! o/} : Store \Delta  ` o/ = (rec ff (\Delta 0).o/0) (c1, . . . , cn) : Type

\Delta ; C ` unroll(j) =) \Delta ; C0 \Omega  {j 7! o/0[rec ff (\Delta 0).o/0/ff][c1, . . . , cn/\Delta 0]}

\Delta 0 = fi1:^1, . . . , fin:^n * ` ci : ^i (for 1 <= i <= n)
\Delta  ` C = C00 \Omega  {j 7! o/[c1, . . . , cn/\Delta 0]} \Omega  C0[c1, . . . , cn/\Delta 0] : Store

\Delta ; C ` pack[c1,...,cn|C0[c1,...,cn/\Delta 0]]as 9[\Delta 0|C0].o/ (j) =) \Delta ; C00 \Omega  {j 7! 9[\Delta 0 | C0].o/}

\Delta  ` C = C00 \Omega  {j 7! 9[\Delta 0 | C0].o/} : Store
\Delta ; C ` unpack j with \Delta 0 =) \Delta , \Delta 0; C00 \Omega  {j 7! o/} @ C0

Figure 3: Static Semantics: Coercions
fun append (xs,ys) =

case xs of

[] -> []
| hd :: tl -> hd :: append (tl,ys)

Here, the second-last operation in the second arm of the
case is a function call and the last operation constructs a
cons cell. If the two operations were inverted, we would
have an efficient tail-recursive function. In DPS, the function allocates a cons cell before the recursive call and passes
the partially uninitialized value to the function, which computes its result and fills in the uninitialized part of the data
structure. If the input list xs is linear, it will not be used in
the future. In this case, it is possible to further optimize the
program by reusing the input list cells for the output list.
Our example performs both of these optimizations.

Before presenting the code for the optimized function,
we will need to define a number of abbreviations. Such abbreviations not only aid readability, but also help compress
typing information in a compiler [10]. First, recall the type
of integer lists List and their unrolling List0:

List = uff.hS(1)i [ 9[ae | {ae 7! ff}].hS(2), int, ptr(ae)i
List0 = hS(1)i [ 9[ae | {ae 7! List}].hS(2), int, ptr(ae)i

Given these list definitions, it will be useful to define the
following composite coercion.

rollListae1 packingae2 =

pack[ae2|{ae27!List}]as 9[ae2|{ae27!List}].hS(2),int,ptr(ae2)i(ae1);

unionList0(ae1);
rollList(ae1)

This coercion operates on a portion of the store with shape{

ae1 7! hS(2), int, ptr(ae2)i} \Omega  {ae2 7! List}. It packs up ae2
into an existential around ae1, lifts the resultant object up to

a union type and finally rolls it up, producing a store with
the shape {ae1 7! List}.

The function append0, presented in figure 4, implements
the inner loop of the optimized append function. A wrapper
function must check for the case that the input list is empty.
If not, it passes two pointers to the beginning of the first
list (aliases of one another) to append0 for parameters prev
and start. It also passes a pointer to the second element in
that list for parameter xs and a pointer to the second list for
parameter ys. Notice that the contents of location aes are not
described by the aliasing constraints. On the first iteration
of the loop aes is an alias of aep and on successive iterations,
it abstracted by ffl. However, these facts are not explicit in
the type structure and therefore aes cannot be used during
any iteration of the loop (cont will be aware that aes equals
aep and may use the resultant list).

The first place to look to understand this code is at the
aliasing constraints, which act as a loop invariant. Reading
the constraints in the type from left to right reveals that
the function expects a store with some unknown part (ffl)
as well as a known part. The known part contains a cons
cell at location aep that is linked to a List in location aexs.
Independent of either of these objects is a third location,
aeys, which also contains a List.

The first instruction in the function unrolls the recursive
type of the object at aexs to reveal that it is a union and can
be eliminated by a case statement. In the first branch of
the case, xs must point to null. The code frees the null cell,
resulting in a store at program point 1 that can be described
by the constraints ffl \Omega  {aep 7! hS(2), int, ptr(aexs)i} \Omega  {aeys 7!
List}. Observe that the cons cell at aep contains a dangling
pointer to memory location aexs, the location that has just
been freed and no longer appears in the constraints. Despite
the dangling pointer, the code is perfectly safe: The typing
rules prevent the pointer from being used.

Next, the second list ys is banged into the cons cell at aep.

7

fix append0 [ffl, aexs, aeys, aep, aes |

ffl \Omega  {aep 7! hS(2), int, ptr(aexs)i, aexs 7! List, aeys 7! List}].
(xs : aexs, ys : aeys, prev : ptr(aep), start : ptr(aes),

cont : o/c[ffl, aep, aes]).
unroll(aexs);
case xs

( inl =)

free xs; % 1.
(prev).3 := ys; % 2.
rollListaep packingaeys; % 3.
cont(start)|
inr =)

unpack aexs with aetl ; % 4.
let tl = (xs).3; % 5.
append0

[ffl \Omega  {aep 7! hS(2), int, ptr(aexs)i}, aetl, aeys, aexs, aes]
(tl, ys, xs, start, cont0))

where o/c[ffl, aep, aes] = 8[* | ffl \Omega  {aep 7! List}].(ptr(aes)) ! 0

Figure 4: Optimized Append
Hence, at program point 2, the store has a shape described
by ffl\Omega {aep 7! hS(2), int, ptr(aeys)i}\Omega {aeys 7! List}. The type
of the cons cell at aep is different here than at 1, reflecting
the new link structure of store. The tail of the cell no longer
points to location aexs, but to aeys instead. After packing
and rolling using the composite coercion, the store can be
described by ffl \Omega  {aep 7! List}. This shape equals the shape
expected by the continuation (see the definition of o/c), so
the function call is valid.

In the second branch of the case, xs must point to a
cons cell. The existential containing the tail of the list is unpacked and at program point 4, the store has shape ffl\Omega {aep 7!hS

(2), int, ptr(aexs)i}\Omega {aexs 7! hS(2), int, ptr(aetl)i}\Omega {aetl 7!
List} \Omega  {aeys 7! List}. It is now possible to project the tail
of xs. To complete the loop, the code uses polymorphic recursion. At the end of the second branch, the constraint
variable ffl for the next iteration of the loop is instantiated
with the current ffl and the contents of location aep, hiding
the previous node in the list. The location variables aexs and
aep are instantiated to reflect the shift to the next node in
the list. The locations aeys and aes are invariant around the
loop and therefore are instantiated with themselves.

The last problem is how to define the continuation
cont0 for the next iteration. The function should be tailrecursive, so we would like to use the continuation cont.
However, close inspection reveals that the next iteration
of append requires a continuation with type o/c[ffl \Omega  {aep 7!hS

(2), int, ptr(aexs)i}, aexs, aes] but that the continuation cont
has type o/c[ffl, aep, aes]. The problem is that this iteration
of the recursion has unrolled and unpacked the recursive
data structure pointed to by xs, but before "returning" by
calling the continuation, the list must be packed and rolled
back up again. Therefore, the appropriate definition of cont0
is cont ffi (rollList aep packing aexs). Once the continuation
packs aexs and rolls the contents of location aep into a List,
the constraints satisfy the requirements of the continuation
cont. Semantically, cont0 is equivalent to the following function.

fix [* | ffl \Omega  {aep 7! hS(2), int, ptr(aexs)i}{aexs 7! List}]

(start:ptr(aes)).
rollListaep packing aexs;
cont(start)
However, because coercions can be erased before running a
program, it is simple to arrange for cont0 to be implemented
by cont.

4.2 Deutsch-Schorr-Waite Algorithms
Deutsch-Schorr-Waite or "link reversal" algorithms, are
well-known algorithms for traversing data structures while
incurring minimal additional space overhead. These algorithms were first developed for executing the mark phase of
a garbage collector [28]. During garbage collection, there is
little or no extra space available for storing control information, so minimizing the overhead of the traversal is a must.
Recent work by Sobel and Friedman [30] has shown how to
automatically transform certain continuation-passing style
programs, those generated by anamorphisms [17], into linkreversal algorithms. Here we give an example how to encode
a link-reversal algorithm in our calculus.

For this application, we will use the definition of trees
from section 2.

T ree =

uff.hS(1)i [ 9[aeL, aeR | {aeL 7! ff, aeR 7! ff}].hS

(2), ptr(aeL), ptr(aeR)i

T ree0 =hS

(1)i [ 9[aeL, aeR | {aeL 7! T ree, aeR 7! T ree}].hS

(2), ptr(aeL), ptr(aeR)i

The code for the algorithm appears in figure 5. The
trick to the algorithm is that when recursing into the left
subtree, it uses space normally reserved for a pointer to that
subtree to point back to the parent node. Similarly, when
recursing into the right subtree, it uses the space for the
right pointer. In both cases, it uses the tag field of the data
structure to store a continuation that knows what to do next
(recurse into right subtree or follow the parent pointers back
up the tree). Before ascending back up out of the tree, the
algorithm restores the link structure to a proper tree shape
and the type system checks this is done properly. Notice
that all of the functions and continuations are closed, so
there is no stack hiding in the closures.

5 Operational Semantics and Type Soundness
In this section, we define the syntax and static semantics
of the values manipulated at run-time, including pointers,
memory blocks and the store and give an operational semantics for the language. The type system is sound with
respect to this semantics.

Run-time Values The run-time values consist of all the values defined in previous sections as well as pointers ptr(`),
memory blocks hv1, . . . , vni and witnessed values &(v). Witnessed values are introduced by coercions. For example, the
union coercion introduces a union witness and similarly for
roll and pack coercions. Notice that these values are always
type checked in an empty type context and empty value
context (evaluation of open terms is nonsensical).

8

% Traverse a tree node
letrec walk[ffl, ae1, ae2 | ffl \Omega  {ae1 7! T ree}]

(t : ptr(ae1), up : ptr(ae2), cont : o/c[ffl, ae1, ae2]).
unroll(ae1);
case t of

( inl =)

unionTree0(ae1);
rollTree(ae1);
cont(t, up)|
inr =)

unpackae1 with aeL, aeR ;
% store cont in tag position
(t).1 := cont;
let lef t = (t).2;
% store parent pointer as left subtree
(t).2 := up;
walk[ffl\Omega {

ae1 7! ho/c[ffl, ae1, ae2], ptr(ae2), ptr(aeR)i}\Omega {
aeR 7! T ree}, aeL, ae1]
(lef t, t, rwalk[ffl, ae1, ae2, aeL, aeR]))

% Walk the right-hand subtree
and rwalk[ffl, ae1, ae2, aeL, aeR | ffl\Omega {

ae1 7! ho/c[ffl, ae1, ae2], ptr(ae2), ptr(aeR)i}\Omega {
aeL 7! T ree}\Omega {
aeR 7! T ree}]
(left : ptr(aeL), t : ptr(ae1)).
let up = (t).2;
% restore left subtree
(t).2 := left;
let right = (t).3;
% store parent pointer as right subtree
(t).3 := up;
walk[ffl\Omega {

ae1 7! ho/c[ffl, ae1, ae2], ptr(aeL), ptr(ae2)i}\Omega {
aeL 7! T ree}, aeR, ae1]
(right, t, finish[ffl, ae1, ae2, aeL, aeR])

% Reconstruct tree node and return
and finish[ffl, ae1, ae2, aeL, aeR | ffl\Omega {

ae1 7! ho/c[ffl, ae1, ae2], ptr(aeL), ptr(ae2)i}\Omega {
aeL 7! T ree}\Omega {
aeR 7! T ree}]
(right : ptr(aeR), t : ptr(ae1)).
let up = (t).3;
% restore right subtree
(t).3 := right;
let cont = (t).1;
% restore tag
(t).1 := S(2);
packaeL,aeR (ae1);
unionTree0(ae1);
rollTree(ae1);
cont(t, up)

where o/c[ffl, ae1, ae2] =8

[* | ffl \Omega  {ae1 7! Tree}].(ptr(ae1), ptr(ae2)) ! 0

Figure 5: Deutsch-Schorr-Waite tree traversal with constant
space overhead

values v ::= * * * | ptr(`) | hv1, . . . , vni | &(v)
witnesses & ::= uniono/1[o/2 |

pack[c1,...,cn|S]as9[\Delta |C].o/ |
roll(rec ff (\Delta ).o/) (c1,...,cn)

* ` o/1 [ o/2 : Type *; * ` v : o/1 or *; * ` v : o/2*

; * ` uniono/1[o/2(v) : o/1 [ o/2

* ` o/ = (rec ff (\Delta ).o/0) (c1, . . . , cn) : Type*

; * ` v : o/0[rec ff (\Delta ).o/0/ff][c1, . . . , cn/\Delta ]*

; * ` rollo/ (v) : o/

\Delta  = fi1:^1, . . . , fin:^n * ` ci : ^i (for 1 <= i <= n)`

S : C[c1, . . . , cn/\Delta ] *; * ` v : o/[c1, . . . , cn/\Delta ]*

; * ` pack[c1,...,cn|S]as9[\Delta |C].o/ (v) : 9[\Delta  | C].o/

The pack coercion encapsulates a portion of the store,
S, which is a finite partial mapping from concrete locations
to values. We treat stores equivalent up to reordering of
their elements and use the notation S{` 7! v} to denote the
extension of S to include the mapping {` 7! v}. The notation is undefined if ` 2 Dom(S). The store well-formedness
judgement is written ` S : C and is given below.

S = {`1 7! v1, . . . , `n 7! vn}* `
C = {`1 7! o/1, . . . , `n 7! o/n} : Store*

; * ` vi : o/i (for 1 <= i <= n)`

S : C

There are no duplicate locations in the domain of a store
(otherwise, it would not be a finite partial map). However,
we will require a stronger property of stores to prove that
program evaluation cannot get stuck. Informally, there can
be no duplication of locations in the domain of the store
or in any encapsulated store. We call this property Global
Uniqueness.

Definition 1 (Global Uniqueness) GU(S) if and only if
there are no duplicate locations in L(S).

Definition 2 (Global Store Locations) L(S) is the
multi-set given by the following definition.

L({`1 7! v1, . . . , `n 7! vn})

= {`1, . . . , `n} ] L(v1) ] * * * ] L(vn)
L(pack[c1,...,cn|S]aso/ (v))

= L(S) ] L(v)

L(x) = L(x1) ] * * * ] L(xn)

for any other term construct x
where x1, . . . , xn are the subcomponents of x.

A program is a store paired with an instruction stream.
A program is well-formed, written ` (S, '), under the following circumstances.

Definition 3 (Well-formed Program) ` (S, ') iff

1. The store adheres to global uniqueness GU(S).
2. There exists constraints C such that ` S : C.
3. The instructions are well-formed with the given constraints: *; C; * ` '.

9

(S, ') 7-!P (S, ')

(S, new ae, x, i; ') 7-!P (S{` 7! v}, '[`/ae][ptr(`)/x])

where ` 62 S, ' and v =

iz ""-- -
hS(0), . . . , S(0)i

(S{` 7! hv1, . . . , vni}, free ptr(`); ') 7-!P (S, ')
(S{` 7! hv1, . . . , vni}, let x = (ptr(`)).i; ') 7-!P (S{` 7! hv1, . . . , vni}, '[vi/x])

where 1 <= i <= n

(S{` 7! hv1, . . . , vi, . . . , vni}, (ptr(`)).i := v0; ') 7-!P (S{` 7! hv1, . . . , v0, . . . , vni}, ')

where 1 <= i <= n

(S{` 7! v}, caseptr(`) (inl ) '1 | inr ) '2)) 7-!P (S{` 7! v0}, 'i)

where

i = 1 or 2
v = uniono/1[o/2 (&1(* * * &m(hS(i), v1, . . . , vni) * * *))
v0 = &1(* * * &m(hS(i), v1, . . . , vni) * * *)

(S, v(v1, . . . , vn)) 7-!P (S, `('))

where

v = v0[c1, . . . , cm]
v0 = fixf[\Delta  | C](x1:oe1, . . . , xn:oen).'
` = [c1, . . . , cm/\Delta ][v0/f][v1, . . . , vn/x1, . . . , xn]

(S, coerce(fl); ') 7-!P (S0, `('))

where fl(S) 7-!fl S0, `

Figure 6: Operational Semantics: Programs
Operational Semantics The small-step operational semantics for the language is given by a function P 7-!P P 0.
The majority of the operational rules are entirely standard
and formalize the intuitive rules described earlier in the paper. The operational rule for the coerce instruction depends
upon a separate semantics for coercions that has the form
S 7-!fl S0, ` where ` is a substitution of type constructors
for type constructors variables. Inspection of these rules
reveals that coercions do not alter the association between
locations and memory blocks; they simply insert witnesses
that alter the typing derivation so that it is possible to prove
a type soundness result. The rules for program and coercion
operational semantics may be found in figures 6 and 7.

Type Soundness We now have all the pieces necessary to
state and prove that execution of a program in our language
"can't get stuck." A stuck program is a program that is
not in the terminal configuration halt i and for which no
operational rule applies.

Theorem 4 (Type Soundness)
If ` (S, ') and (S, ') 7-!*P (S0, '0) then (S0, '0) is not stuck.

The proof itself uses standard Subject Reduction and
Progress lemmas in the style popularized by Wright and
Felleisen [37] and is mostly mechanical. Due to space
limitations, it has not been included. See the companion
technical report [36] for details.

6 Related Work
Our type system builds upon the foundational work by other
groups on syntactic control of interference [25] and linear

type systems in functional programming languages [35, 33,
2]. We also owe much to researchers in alias analysis for
imperative languages [12, 15, 7, 9, 26].

Our type system appears most closely related to the
shape analysis developed by Sagiv, Reps, and Wilhelm
(SRW) [26]. Although the precise relationship is currently
unknown to us, it is clear that several of the key features
that make SRW shape analysis more effective than similar
alias analyses can be expressed in our type system. More
specifically:

1. Unlike some other analyses, SRW shape nodes do not

contain information about concrete locations or the
site where the node was allocated. Our type system
drops information about concrete locations using location polymorphism.

2. SRW shape nodes are named with the set of program

variables that point to that node. Our type system
can only label a node with a single name, but we are
able to express the fact that a set of program variables
point to that node using the same singleton type for
each program variable in the set.

3. SRW shape nodes may be flagged as unshared. Linear

types account for unshared shape nodes.

4. A single SRW summary node describes many memory blocks, but through the process of materialization
a summary node may split off a new, separate shape
node. Summary nodes may be represented as recursive types in our framework and materialization can be
explained by the process of unrolling and unpacking a
recursive and existential type.

10

fl(S) 7-!fl S0, `

uniono/1[o/2 (`)(S{` 7! v}) 7-!fl S{` 7! uniono/1[o/2 (v)}, [ ]
rollo/ (`)(S{` 7! v}) 7-!fl S{` 7! rollo/ (v)}, [ ]
unroll(`)(S{` 7! rollo/(v)}) 7-!fl S{` 7! v}, [ ]
pack[c1,...,cn|C]as o/ (`)(S{` 7! v}S0) 7-!fl S{` 7! pack[c1,...,cn|S0]aso/ (v)}, [ ]

where C = {`1 7! o/1, . . . , `m 7! o/m} and S0 = {`1 7! v1, . . . , `m 7! vm}

unpack ` with \Delta  (S{` 7! pack[c1,...,cn|S0]as9[\Delta |C].o/ (v)}) 7-!fl SS0{` 7! v}, [c1, . . . , cn/\Delta ]

Figure 7: Operational Semantics: Coercions
One of the advantages to our approach is that our language
makes it straightforward to create dependencies between
functions and data using store or location polymorphism.
For example, in our implementation of the Deutsch-SchorrWaite algorithm, we manipulate continuations that know
how to reconstruct a well-formed tree from the current heap
structure and we are able to express this dependence in
the type system. Explicit manipulation of continuations is
necessary in sufficiently low-level typed languages such as
Typed Assembly Language when return addresses are interpreted as continuations [21].

Other work has focused on developing expressive pointer
logics for describing the shape of the store [20, 13, 27, 3].
Some of these logics can express more sophisticated pointer
relationships than the type structure described in this paper. For example, Benedikt et al. [3] provide a complex logic
that includes path equality and inequality relations, allocation constraints, reachability constraints and other connectives. Our type system is built by starting with the concept
of a finite partial map to describe the store and then using a
combination of standard type constructors such as singleton,
union, polymorphic, existential and recursive types. These
type constructors can be reused for a variety of different
purposes within a type-preserving compiler from representing closures [19] to data-flow analysis [8] to object encodings [24] to source-level polymorphism and existential types.
From an engineering perspective, there are definite advantages to reusing as much type structure as possible.

Several other authors have considered alternatives to
pure linear type systems that increase their flexibility. For
example, Kobayashi [14] extends standard linear types with
data-flow information and Minamide [18] uses a linear type
discipline to allow programmers to manipulate "data structures with a hole." Minamide's language allows users to
write programs that are compiled into destination-passing
style. However, Minamide's language is still quite high-level;
he does not show how to verify explicit pointer manipulation. Moreover, neither of these type systems provide the
ability to represent cyclic data structures.

Tofte, Talpin, and others [32, 4, 1, 6] have explored the
use of region-based memory management. In their work,
objects are allocated into one of several regions of memory. When a region is deallocated, all the objects in that
region are deallocated too. Region-based memory management performs extremely well in many circumstances, but
unlike systems based on linear types, space is not, in general,

reused on a per-object basis. Moreover, regions cannot be
encapsulated inside recursive data structures. However, we
believe that some of the techniques we have developed here
may be adapted to the region setting and we are eager to
investigate a combined framework that can take advantage
of both forms of typed memory management.

Acknowledgements
Fred Smith worked with us on the predecessor to this research and the many stimulating discussions we had togethercontributed to the current paper. Neal Glew made helpful

comments on an earlier draft of this paper.

References

[1] Alexander Aiken, Manuel F"ahndrich, and Raph Levien. Better static memory management: Improving region-based
analysis of higher-order languages. In ACM Conference on
Programming Language Design and Implementation, pages
174-185, La Jolla, California, 1995.

[2] Erik Barendsen and Sjaak Smetsers. Conventional and

uniqueness typing in graph rewrite systems (extended abstract). In Thirteenth Conference on the Foundations of
Software Technology and Theoretical Computer Science,
pages 41-51, Bombay, 1993. In Shyamasundar, ed., SpringerVerlag, LNCS 761.

[3] Michael Benedikt, Thomas Reps, and Mooly Sagiv. A decidable logic for describing linked data structures. In European Symposium on Programming, pages 2-19, Amsterdam,
March 1999.

[4] Lars Birkedal, Mads Tofte, and Magnus Vejlstrup. From

region inference to von Neumann machines via region representation inference. In Twenty-Third ACM Symposium on
Principles of Programming Languages, pages 171-183, St.
Petersburg, January 1996.

[5] Perry Cheng and Chris Okasaki. Destination-passing style

and generational garbage collection. Unpublished., November 1996.

[6] Karl Crary, David Walker, and Greg Morrisett. Typed memory management in a calculus of capabilities. In TwentySixth ACM Symposium on Principles of Programming Languages, pages 262-275, San Antonio, January 1999.

[7] Alain Deutsch. Interprocedural may-alias analysis for pointers: Beyond k-limiting. In ACM Conference on Programming Language Design and Implementation, pages 230-241,
Orlando, June 1994.

11

[8] Allyn Dimock, Robert Muller, Franklyn Turbak, and J. B.

Wells. Strongly typed flow-directed representation transformations. In ACM International Conference on Functional
Programming, pages 85-98, Amsterdam, June 1997.

[9] Rakesh Ghiya and Laurie J. Hendren. Is it a tree, a DAG, or

a cyclic graph? A shape analysis for heap-directed pointers
in C. In Twenty-Third ACM Symposium on Principles of
Programming Languages, pages 1-15, St. Petersburg Beach,
Florida, January 1996.

[10] Dan Grossman and Greg Morrisett. Scalable certification of

native code: Experience from compiling to TALx86. Technical Report TR2000-1783, Cornell University, February 2000.

[11] Robert Harper. A simplified account of polymorphic references. Information Processing Letters, 51(4):201-206, August 1994.

[12] Neil D. Jones and Steven Muchnick, editors. Flow analysis

and optimization of Lisp-like structures. Prentice-Hall, 1981.

[13] Nils Klarlund and Michael Schwartzbach. Graph types. In

Twentieth ACM Symposium on Principles of Programming
Languages, pages 196-205, Charleston, January 1993.

[14] Naoki Kobayashi. Quasi-linear types. In Twenty-Sixth ACM

Symposium on Principles of Programming Languages, pages
29-42, San Antonio, January 1999.

[15] James R. Larus and Paul N. Hilfinger. Detecting conflicts

between structure accesses. In ACM Conference on Programming Language Design and Implementation, pages 24-
31, June 1988.

[16] James Richard Larus. Restructuring Symbolic Programs for

Concurrent Execution on Multiprocessors. PhD thesis, University of California at Berkeley, May 1989. Available as
Berkeley technical report UCB/CSD 89/502.

[17] Erik Meijer, Maarten Fokkinga, and Ross Paterson. Functional programming with bananas, lenses, envelopes, and
barbed wire. In ACM Conference on Functional Programming and Computer Architecture, 1991. Also published in
Lecture Notes in Computer Science, 523, Springer-Verlag.

[18] Y. Minamide. A functional representation of data structures

with a hole. In Twenty-Fifth ACM Symposium on Principles of Programming Languages, pages 75-84, San Diego,
January 1998.

[19] Y. Minamide, G. Morrisett, and R. Harper. Typed closure

conversion. In Twenty-Third ACM Symposium on Principles of Programming Languages, pages 271-283, St. Petersburg, January 1996.

[20] Bernhard M"oller. Towards pointer algebra. Science of Computer Programming, 21:57-90, 1993.

[21] Greg Morrisett, Karl Crary, Neal Glew, and David Walker.

Stack-based Typed Assembly Language. In Second International Workshop on Types in Compilation, pages 95-117,
Kyoto, March 1998. Published in Xavier Leroy and Atsushi
Ohori, editors, Lecture Notes in Computer Science, volume
1473, pages 28-52. Springer-Verlag, 1998.

[22] Greg Morrisett, David Walker, Karl Crary, and Neal Glew.

From System F to Typed Assembly Language. In TwentyFifth ACM Symposium on Principles of Programming Languages, pages 85-97, San Diego, January 1998.

[23] George Necula and Peter Lee. The design and implementation of a certifying compiler. In ACM Conference on Programming Language Design and Implementation, pages 333
- 344, Montreal, June 1998.

[24] Benjamin Pierce and David Turner. Simple type-theoretic

foundations for object-oriented programming. Journal of
functional programming, 4:207-247, 1994.

[25] John C. Reynolds. Syntactic control of interference. In Fifth

ACM Symposium on Principles of Programming Languages,
pages 39-46, Tucson, 1978.

[26] Mooly Sagiv, Thomas Reps, and Reinhard Wilhelm. Solving shape-analysis problems in languages with destructive
updating. ACM Transactions on Programming Languages
and Systems, 20(1):1-50, January 1998.

[27] Mooly Sagiv, Thomas Reps, and Reinhard Wilhelm. Parametric shape analysis via 3-valued logic. In Twenty-Sixth
ACM Symposium on Principles of Programming Languages,
pages 105-118, San Antonio, January 1999.

[28] H. Schorr and W. M. Waite. An efficient machineindependent procedure for garbage collection in various list
structures. Communications of the ACM, 10(8):501-506,
August 1967.

[29] Frederick Smith, David Walker, and Greg Morrisett. Alias types. In European Symposium on
Programming, March 2000. To appear. Available at
http://www.cs.cornell.edu/talc/papers.html.

[30] Johnathan Sobel and Daniel Friedman. Recycling continuations. In ACM International Conference on Functional
Programming, pages 251-260, Baltimore, September 1998.

[31] TALx86. See http://www.cs.cornell.edu/talc for an implementation of Typed Assembly Language based on Intel's
IA32 architecture.

[32] Mads Tofte and Jean-Pierre Talpin. Implementation of the

typed call-by-value *-calculus using a stack of regions. In
Twenty-First ACM Symposium on Principles of Programming Languages, pages 188-201, Portland, Oregon, January
1994.

[33] David N. Turner, Philip Wadler, and Christian Mossin. Once

upon a type. In ACM International Conference on Functional Programming and Computer Architecture, San Diego,
CA, June 1995.

[34] Philip Wadler. Listlessness is Better than Laziness. PhD

thesis, Carnegie Mellon University, August 1985. Available
as Carnegie Mellon University technical report CMU-CS-85-
171.

[35] Philip Wadler. Linear types can change the world! In

M. Broy and C. Jones, editors, Progarmming Concepts and
Methods, Sea of Galilee, Israel, April 1990. North Holland.
IFIP TC 2 Working Conference.

[36] David Walker and Greg Morrisett. Alias types for recursive data structures (extended version). Technical Report
TR2000-1787, Cornell University, March 2000. Also available at http://www.cs.cornell.edu/talc/papers.html.

[37] Andrew K. Wright and Matthias Felleisen. A syntactic approach to type soundness. Information and Computation,
115(1):38-94, 1994.

12