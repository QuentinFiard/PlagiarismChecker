

Efficient  Local  Correctness  Checking  for  Single and  Alter na ting   Boo lea n  Equation  Systems 

B. Vergauwen, J.  Lewi 
K.U.Leuven, Department  of Computer  Science Celestijnenlaan  200A, B-3001 Leuven, Belgium 

E-maih  B~zt.VergauwenQcs.kuleuven.ac.be 

1  I n t r o d u c t i o n  
'Pransition systems play a  central role as formal models for reactive and concur- rent  systems. This  paper  deals  with the  problem of automatically verifying the 

correctness  of finite transition systems. Verification is  the  process  of comparing 

a  transition  system  with  a  system  specification.  System  specifications  usually 
fall into two categories: logical  versus  beha~ioursl  specifications. Logical specifi- 

cations describe  properties  that  the  system is supposed  to  satisfy, e.g.  deadlock 
freedom, mutual exclusion, liveness  properties,  etc. Temporal and Modal Logics 

are  popular tools for expressing such properties.  A behavioural specification, on 
the other hand, usually takes the form of another transition system describing 
the system behaviour  at a more abstract level. Verification then boils down  to 

comparing  two  transitions systems  (an abstract  and  a concrete  one)  w.r.t, a given equivalence or preorder  relation. 

In the last couple of years, a plethora of algorithms have been proposed for verify- 
ing transition systems. Most of these algorithms were developed for very specific 
correctness  problems. The  goal of this paper  is to provide  a  uniform framework 

(in casu Nested  Boolean Equation Systems), and associated efficient algorithms, 
for tackling general correctness problems.  Specific  correctness  problems, be  it of 

a  logical or  a  behavioural nature,  can then  be  handled in two steps: 

1.  In a first step the correctness problem at hand is translated into an equivalent (Nested)  Boolean Equation System E, 

2.  The  second  step  consists  of  solving  E,  i.e.,  computing  the  (appropriate) 

extremal solution of E. 

The  paper  is structured  as follows:  Section  2  introduces  the  notion of (Nested) Boolean Equation System. Section 3 illustrates, by means of an example, how to 

translate behavioural process relations into (Nested)  Boolean Equation Systems. Section 4 (5) contains an efficient algorithm for computing the extremal solutions 
of a  (Nested)  Boolean Equation System. Both  algorithms are  local in that  they 
focus on a  result variable and construct a  stable and complete search space that only contains variables that are necessary to compute the semantics of the result 

variable. Furthermore, unlike global techniques, the proposed  algorithms do not prerequire  the  construction and storage  of the  complete equation system before 
verification. Due to space  limitations, proofs have been left out in this abridged version. 

305 
2  B o o l e a n   E q u a t i o n   S y s t e m s  
This  section  defines  the  syntax  and  semantics  of  (Nested)  Boolean  Equation 

Systems.  The  syntax  is  parameterized  with  respect  to  a  (countable)  set  X  of 
boolean  variables.  The  semantics  are  defined  with  respect  to  an  environment 
mapping  variables  into  booleans  (Boo1  --  {0,  1}). 

2.1  B o o l e a n   E q u a t i o n   S y s t e m s  
The  basis  of  Boolean  Equation  Systems  are  Boolean  Formulas,  which  m a y   be 
defined  by  the  following abstract  syntax 

@  ::=  ~  (  t t   i  z  I  @v@  I  @A@ 
where z ranges over X. Let var(O) _c x be the set of variables occurring in 0. 
For a Formula  O  and  an environment  8 : X  ---* Bool, define the boolean  value 

[O] 8 by structural induction on 0 as follows: [ff] 0 -  0, [tt] 0 -  I, [z] 0 --" 0(z), 
[01  V 02] O  --  max{J01 ] O, [02] 0},  and  [01  ^  02] 0  -- min{[Oz] O, [02] 0}. 
A  Boolean Equation System  (bes for short)is of the form { 

=1  =  r 

Z~  --  0n 
where  the  zl  are  distinct  variables,  and  the  r  are  Boolean  Formulas.  The  set  of 
left  hand  side  variables  of a  bes  E  is  denoted  by  lv(E).  For  z  e  lv(E),  we  use 

E ( z )   to  denote  the  right  hand  side  of E  having  z  as  its  lee  hand  side.  L e t / v ( E )  
denote  the  set  of free  variables  of E,  i.e.  Iv( E)  --  (u=ez,,(~)var(E(z)))  \  Iv(E). 
Semantically,  a  bes  E  acts  as  a  mutually recursive  definition  for its left hand  side 
variables.  Assume  an  environment  0: X --~ Boo1  for  interpreting  free  variables  of 

E.  A  function  p  : lv(E)  --* Bool  is  a  solution  of E  in  context  O iff 

Vz  e  Iv(E)  :  p(z)  :  ~E(z)~  O[p] 
where  O[p] denotes  0  'updated'  by  p.1  Let  [El  0  denote  the  set  of  solutions  of 
the  bes  E  in  environment  0.  For  the  correctness  checking  of transition  systems, 

the  eztremal  solutions  of  E  w.r.t.  _C play  a  central  role,  where  E  is  the  partial 
order  obtained  by  pointwise  extension  of the  natural  ordering  0  <  1  on  boolean 
constants. 2  As  right  hand  sides  of E  are  monotone  w.r.t.  E  (i.e.  0  E  0'  implies 

[r  0  <  [O] 0'),  it  follows from  the  well-known  Knaster-Tarski  fix-point  theorem 
[10]  that  E  has  a  unique  least  as  well  as  a  unique  greatest  solution  w . r . t . E .  
Hence  for  a  bes  E  define: 

[/~E] 0 -  The  least  element  of  [El  0  w.r.t.  _ 

[vE] 0 -- The greatest element of [El 0  w.r.t.  E 

1  For  0: I  ---* Bool  and  f: Y  -~  Bool  with  Y  C  X,  define  O[f] as  the  environment  0' such  that  0'(z) ---- f (z)  if z  E  Y,  and  0'(z) =  0(z)  otherwise. 

For  any  f,g:  D  --* Bool define  f  C: g  r  Vd E D: f(d)  <_ g(d) 

306 
2.2  N es te d  Boolean  Equation  Systems 
A  Nested  Boolean  Equation  System  (nbes  for short)  is  of the  form 

Ela2E2 
where  as  E  {p, v}  and  E1  and  E2  are  Boolean  Equation  Systems.  For technical 
reasons  we  shall  assume  that  the  left  hand  side  variables  of  E1  and  E2  are 
disjoint,  i.e.,  l~(E~) n  l~(E2)  =  $.  This  condition  can  always  be  satisfied  by  an 
appropriate  renaming  of variables. 

Semantically, a  nbes  Ela2E2  can  be  seen  as  the  equation  system  E1  where  the variables  of Iv(E2)  are  defined  in  terms  of lv(E~)  through  an  extremal fix-point 

construction  a2E2.  More formally, a  function Pl  : Iv(E1)  --* Boo1 is a  solution of 
a  nbes  Ela2E2  in  context  8  iff the  following holds: 

Vz  E  lv(E1):  pl(z)  =  [E l (z) ] 0[p2][pl],  where  P2 =  ~a2E2] 0[pl] 
Let  IN] 0  denote  the  set  of solutions  of the  nbes  N  in  environment  8.  Again  it 
follows from  the  Knaster-Tarski  fix-point  theorem  [10]  that  a  N  has  a  unique least  as 

well as  a  unique  9reatest  solution  w.r.t.  _=. Hence for  a  nbes  N  define: 

[/zN] 0  -  The  least  solution  of ~N] 0  w.r.t.  E 

[vN~ 0 "-- The  greatest  solution  of IN] 8  w.r.t.  C_ 

o f   special  interest  are  the  'alternating'  fix-points  pE~vE~  and  vElpE~.  The 
other  cases  are  not  very interesting,  as  they  can  be  reduced  to  single fix-points. 

3  R e p r e s e n t i n g   C o r r e c t n e s s   P r o b l e m s  
This  section  illustrates,  by  means  of  an  example,  how  to  encode  specific  pro- 

cess  correctness  problems  into  boolean  equation  systems.  As  an  example  we 
take  a  weak behavioural equivalence, in  casu branching bisimulation  [11]. Exam- 
ples  of strong  behavioural  relations  can  be  found  in  [8],  and  for  an  encoding  of 

(Mternation-free)  logical specifications  into  boolean  equations  we  refer  to  [12]. 

Fix a  transition  system  T  -  (S, Act, -4),  where  8  is  the  set  of states,  Act  is  the 
set  of visible  actions  ( r  ~  Act),  and  --* C_ S  x  (ACt  O  {r})  x  8  is  the  transition 
relation.  We  shall  write  p  --, q  instead  of (p, a, q) E ---'. 

D e f i n i t i o n  [11] A  branehin 9  bisimulation on T  is a symmetric relation R  C_ S *  
such  that  whenever  pRq  and  p  -~ f  then  either 

-  a = r a n d p ' R q   or 

T  * -  there  exist  ql, q'  such  that  q--,  ql  -~  q'  with  pRql  and  p'Rq'. 

307 
Define  ~  "-  { (p, q) I pRq  for some  branching  relation  R  }. 
The  defining  conditions  of branching  bisimulations  can  be  rephrased  in  terms  of 
a  nbes  N ~   "-- E l s E 2 ,   where  Iv(E,)  "-  {A,B,  Cl, C2}  x  S  x  S,  and  Iv(E~)  - 

{D, E } x   --~  xS,  and  right  hand  sides  of E ,   and  E2  are  defined  by 

E, ((A, p,q)) 
E, (   (B, p, q)) E,(  (C,,p,  q) ) 

E,(  (C2, p, q) ) 
E2( (D, (p, a , p'), q) ) E~( (E,  (v, ~, p'), q) ) 

--  (B,p,q)  A  (B,q,p) --  (Cl,p,  q)  A  (02, p, q) 
- - / ~ , :   v.lv ,  (  (A, p', q)  V  (D,  (p, r, p'), q)  ) --" A.r162  : p_~p, (D,(p,a,p'),q) 
"-- (E,(p,a,p'),q)  V  V r   ,_~q, (D,(p,a,p'),q') --" (A,p, 

q) A  V ,, :  ,_%r ( A,p',  q') 

As  ~b  is  defined  as  the  largest  branching  bisimulation,  the  following correspon- 
dence  exists  between  ~b  and  N ~   : Vp, q  6  8:  p  ~,~  q  iff [vN~b~ ( (A, p, q) ) =  1. 

4  L o c a l   C o r r e c t n e s s   C h e c k i n g   f o r   B E S  
This  section  presents  a  local  algorithm  So l ve   for  computing  [/~E]  ($),  where  E 
is  a  closed  bes  (i.e.  fv(E)  =  0),  and  $  6  lv(E)  is  the  variable  of interest.  (As  E 
is  closed,  [/~E] 0 does  not  depend  on  0,  and  hence  we  simply write  [/~E]  instead of  [~E]  0.) 

Recall  that  the  global  algorithms  of  [1,3,5]  are  all  based  on  classical  fix-point 
approximation:  Initially all  variables are  set  to  0  (in  case  of a  least  solution)  and 
then  variables  are  recomputed  and  updated  until  all  variables  are  'stable'.  The 
local  algorithm  Sol ve  can  be  seen  as  a  refinement  of  these  global  algorithms: 
Instead  of  a  priori  stabilizing  all variables,  So l ve   aims  at  constructing  only  a subset 

of variables  (called  the  search-space)  that  is  both  stable  and  complete  in 
the  sense  that  values  of variables  belonging  to  the  search  space  do  not  depend 
upon  values  of variables  outside  the  search  space. 
In  order  to  compute  ~gE]  ($),  the  following data-structures  are  used  by  Solve: 

-  a  variable S  C_ Iv(E)  for  keeping  track  of the  current  search  space, 
-  for  any  z  6  S  there  is  an  attribute  Val(z)  denoting  the  current  value  of z. 

Solve  is  built  around  the  following invariant  I,  stating  that  the  least  solution  of 

E  is  approximated  from below.  (,91b denotes  the  set  {z  6  S :   Val(z)  =  b}) 

I  ~  v~ e Sl~ : [/~E] (m) ----  I 
At  the  heart  of  S ol v e  are  rules  Update  and  Ezpand.  Rule  Update  takes  care 
of  the  usual  updating  of  variables  whereas  rule  Ezpand  deals  with  the  expan- 
sion  of the  search  space.  Both  rules  have  a  pre-condition  part  and  a  code part. 
The  precondition  must  be  satisfied  in  order  for  the  rule  to  be  applicable.  An 

applicable  rule  is  executed  by  executing  the  statements  listed  in  its  code  part. 

308 
Algorithm Solve  proceeds  by  repeatedly  applying  Update  and  Ezpand.  If both 
rules  are  applicable,  then  the  choice  which  one  to  execute  is  irrelevant,  at  least 
theoretically.  When  no  rule  is applicable  any longer,  Sol ve   terminates.  We then 

have that  the  Va/-attributes  equal  [ pE]   on  8. 

R o u t i n e   Solve 
i n p u t   : a  closed  bes  E,  and  a  variable  ~. fi9 Iv(E) 
o u t p u t :   [DE] ($) 
m e t h o d   : S  := (~}  VaZ(~) := O 

[ Update  D g,pa~d ] ,  
r e t u r n   Val( $ ) 

N o t a t i o n   For  a  Formula  r  we  shall  use  (~b} to  denote  the  value  of  r  when 
evaluated  in  an  ancompletely  specified  environment  7r  where  ~(z)  =  Val(z)  if 

z  fi9  S  and  ~(z)  is  undefined  if  z  r  ,9.  As  only  variables  from  ,.q  do  have  a 
value  specified  in  this  partial  environment,  (r  may  also  be  undefined.  We  use 
the  symbol  ?  to  denote  undefinedness.  For  example  assume  that  ,9  =  ~zt, z2} 
with  Val(z,)  =  0  and  Val(z2)  =  1.  Then  (zt  A z3)  =  0  and  (z2  V zs}  =  1  but {,1 

v  ~}  =  {~  ^  ~ )   =  {~}  =  7. 

Rule  Update  governs  the  usual  updating  of variables:  If  (E(z)}  =  1  for  some 
variable  z  fi9 SIo , then  Val(z)  can  be  set  to  t. 

R u l e   Update 
p r e  3,  fi9 s l 0 :   ( E ( , ) )   = ,  

c o d e  

select some  fi9 fi9 ,S]O:  (E(z)}  =  * 

Val(,) := t 

Rule  Ezpand  deals  with  the  expansion  of  the  search  space:  If  (E(z)} =  ?  for 
some  z  fi9 S[0,  then,  in  order  to  further  investigate  z,  the  search  space  has  to  be 
expanded  by  adding  a  variable  y  occurring  in  E ( z )   that  is  not  already  in  S. 

R u l e   Ezpand 
p r e  

3~  fi9 Sl0:  (E(,)}  =  ? c o d e  

select  some  z  fi9 S l 0 :   (E(=)) --  ? 
select  some  y  fi9 var (E(z ))   :  y  r  8 s  :=  s  u  { ~ }   Vat(y)  :=  0 

F a c t   4.1  Assertion  I  is  an  invariant  of Solve. 

309 
Fact  4.2  (pre(Ezpand)A pre(Update))  =:~  (Vz  E Sl0:  IrE]  (=)= 0) 
T h e o r e m   4.3  (Correctness)  Algorithm  S ol v e  is  partially  correct. 
The  time  complexity of S ol v e  is  stated  in  terms  of the  size  IEI of E,  defined  as 

IEI  -  ~-']~ffiezv(E)[E(z)l,  where  the  size  [r  of a  Formula  r  is  defined  as  follows: [tt[ 

-  [  fl  -  [zl  -  1,  and  [r  v  r  -  [r  A r  --  ]r  +  1 +  [r 

T h e o r em   4.4  ( C o m p l e x i t y )   Using additional data-structures,  algorithm So l ve  
can  be  implemented  to run  in  time  O( IEI ). 

The  complexity result  of theorem 4.4 concerns  ~orst-coze behaviour,  yielding  an 

upper-bound  on  the  running  time.  For  global  algorithms  such  an  upper-bound 
m ay  be  realistic,  but  for local algorithms  it  often  is not.  The  goal of a  local  algo- 

rithm  is  precisely  to  compute  only  information  that  is  really  needed.  Of  course 
one  can  always  (artificially)  construct  systems  that  require  the  complete  least 
solution  [/~E]  to  be  computed  in  order  to  decide  the  value  of  one  single  com- 
ponent  [pE] (~).  These  worst-case  scenario's,  however,  are  believed  to  be  rare 
in  practice  (otherwise  local  techniques  would  not  make  much  sense  in  the  first place). 

Below we discuss  some additional  speed-ups  aiming at  a  further  reduction 
of the  average  running  time.  Note  however  that  these  speed-ups  do  not  improve 
upon  the  worst-case  behaviour  (on  the  contrary). 

Using  direct-access  structures,  the  initialization  phase  of S ol v e  will  have  to  visit 
every  variable once  and  hence  will always take  time  proportional  to  [lv(E)[.  The 

main  loop  of Solve,  on  the  other  hand,  takes  time  proportional  to  *ze.c[E(z)l, 

where  S  is  the  value  of S  upon  termination.  Hence  if [,~[ <<  [lv(E)[  initialization 
time  becomes  dominant.  As  in  [1]  this  costly  initialization  can  be  avoided  by 
implementing  S  as  a  balanced  binary  search  tree.  Initializing  this  tree  can  be 
done  in  constant  time.  However,  executing  a  primitive operation  now  takes  time 

O(log(IS[)),  yielding  an  additional  log([Iv(E)[)  factor  in  the  complexity  result. 
It  is  clearly  advisable  to  keep  the  size  IS[  of  the  search  space  as  small  as  pos- 
sible.  Hence  in  case  both  rules  are  applicable,  an  implementation  will  probably 
give  rule  Update priority  over  Ezpand.  Using  rules  Update and  Ezpand  as  they 
stand,  the  search  space  S  can  only grow.  Once  added,  a  variable stays  in  ,~ until 

S ol v e  terminates,  even  if it  is  no  longer  useful  as  far  as  computing  ~[#E~ (~)  is 
concerned.  However,  useless  variables  ma y  cause  a  further  (useless)  expansion 
of  S  and  hence  have  a  cumulative  negative  effect  on  the  running  time.  There- 
fore  additional  reduction  rules  for  removing  useless  variables  can  be  added  to 

Solve.  Removing  variables  from  S  leaves  assertion  I  invariant,  and  hence  does 
not  cause  additional  correctness  problems.  Hence  a  reduction  heuristic  should 
only  decide  when  and  which  variables  ought  to  be  removed.  An  easy  to  imple- 

ment,  yet  effective  reduction  rule  goes  as  follows:  Upon  setting  Val(z)  to  1,  all 
variables  from  SI0  that  were  added  to  S  because  of  z,  are  removed  from  S,  as 

those  variables  may  now  have  become  useless.  Combining  this  heuristic  with  a 
depth-first  strategy  for  search  space  expansion  yields  an  algorithm  that  is  close 

310 
to [s]. 
Finally,  the  selection  of variable  1/in  rule  Ezpand  should  be  done  carefully.  For 
example  if E ( z )   =  zl  V (z2  A zs)  and  ,9 N {zl,  z2, zs}  :  r  then  z I  is  a  more 

'interesting'  candidate  for  search  space  expansion  than  z2  or  zs. 

5  Lo c al   C o r r e c t n e s s   C h e c k i n g   for  N e s t e d   B E S  
This  section  presents  a  local algorithm A l t S o l v e   for computing the  'alternating' 
fix-point  [ p N ]   (~),  where  N  =  EluE2  is  a  closed  nbes  (i.e.  fv(E1)  U fv(E2)  C lv(E1)Ulv(E2)), 

and  ~. E  Iv(E1) is the  variable of interest.  (As  N  is closed,  [pN] 0 
does  not  depend  on  0,  and  hence  we  simply write  [p N]   instead  of  {pN] 0.) 

Algorithm A l t S o l v e   is roughly obtained  by 'merging' two single bea-algorithms, 
one for pE1  and  one for uE2.  Special care must be taken to deal with  the fact that 

uE2  is  nested  within  El.  The  following data-structures  are  used  by  Al t So l v e:  

-  a  variable  `91  C  Iv(El)  and  a  variable  ,52  C_ lv(E2)  for  keeping  track  of the 

current  search space  ,9 --" `91 U `92, 
-  for  any  z  E  ,9  there  is  an  attribute  Val(z)  denoting  the  current  value  of z. 

The  meaning  of the  Va/-attributes  is  formalized  by  assertions  I1  and  I2,  which 
will  be  kept  invariant  by  Al t S ol ve :  

(/1  ~  VI~ESllI:  [~t_/3~](z)=J.)  (I2  a,  VzE,9210: (~,E4Cz)=0) 
where S+lb denotes the set {z E ,9~: Val(z) =  b}, and (uE2} denotes the greatest 
solution of E2 when evaluated in an u~compleLely specified environment w, where 

7r(z)  :  Val(z)  if  z  E  81  and  w(z)  =  ?  if  z  ~  $1.  As  only  variables  from  $1  do 
have  a  value  specified  in  this  partial  environment  7r,  some  components  of (rE2} 
m a y  also  be  undefined. 3 

Initially  ,91  =  {~},  ,92  -  r  and  VaI(f~) =  0.  For  each  bes  Ei  (i=1,2)  there  is  an 
associated  computation  rule  Updstei  and  an  expansion  rule  Ezpsad i.  Algorithm 

A l t S o l v e   proceeds by repeatedly  applying  Updatel/ EZpg~d I /  Updste2/ Ezps~d 2 
until  no rule  is applicable any  longer.  We then  have that  the  Vs/-attributes  agree 
with  [ p N ]   on  ,91. 

R o u t i n e   AltSolve 
i n p u t   : a  closed  nbes  N  =  ElVE2,  and  a  variable  ~  E/ v(E1)  
o u t p u t :   {pN]  (f~) 

m e t h o d   : 

S 1 :: {~}  V(~/(~) :--- 0  a2 :: [ update~  0 Ezpandl  !  Update2  ~ Ezpa-d2]* 

r e t u r n   Val( ~ ) 
a  Formally  (uE2)  is  defined  as  follows:  Let  0  =  A~.  if  y  E  Sx  then  Val(~) else  O, and  let  0'  ---- A~.  if  y  E  ,St  then  Val(y) else  1.  Then  for  any  z  E  l~(E~)  define 

(vE2)(z)  as  follows:  If  ([vE~]O)(z) =  ([~E2]0t)(z)  then  (~E2)(z)  =  ([vE2]O)(z) else ("~4(~)=  ?. 

311 
Rules  Updatel/EzpaUdl/Update2/Ezpaud  2 are  listed  below.  As  in section  4,  (r 
denotes  the  value of ~b when  evaluated in  an  uneompletely  specified environment 

x where 7c(z) =  Val(z) if z C  ( ,91 U 82 ) and x(z) :  ? if z r ( ,91 u `92 ). 

Rule  Update~ 
p r e  

3~  c  s21~  :  {~2(~))  =  o c o d e  

select  some  z  E  ,9211:  (E2(z))  --  0 Val(z)  :=  0 

Rule Ezpar*d 2 p r e  
code 

select  some  z  C 8211:  (E2(z))  =  ? 
select  some  y  e  var(E2(z))  :  y  r  ( S 1 U $2 ) 
i f y E l v ( E 1 )   t h e n   Sl  :=  ,91U {y)  V a l (y ): - -O f i  

if y  E  lv(E~)  t h e n   82  : :   ,92 U { y )  Val(y)  : :   1  fi 

R u l e   Ezpand 1 p r e  

3z  C 81[0:  (El(z ))  :  ? 
code 

select  some  z  C $1]0:  (El(z ))  =  ? select  some  ~  C  , ~ r ( E l ( ~ ) )   :  ~  r  ( S l   U  S2  ) 

i f y E l v ( E 1 )   t h e n S l : = S 1 0 ( y )   V a l ( y ) : = O f i  
i f y E l v ( Z 2 )   t h e n 8 2   := ,q2 U ( y )   Val(y)  :=  l  fi 

R u l e   Update 1 
p r e  

1 . 3 z   e  Sxl 0:  (El (~))  =  1 
2.  p r e( E ~ p ~ 2 )   ^  pre(Vpd~te2) 
c o d e  

select  some  ~  C  SilO:  {E l (z ))   --  1 ra/(z)  :=  1 

R e s t o r e  

Rules  Update2/Ezpand 2 are  essentially  the  duals  (for greatest  solutions)  of rules Update/Ezpaud 

discussed  in  section  4.  Rule  Ezpand 1  is  essentially  a  copy  of 

312 
rule  Ezpaz~d.  Rules  Updagea/Ezpanda/Ezpand  1 are  easily  seen  to  preserve  the 

invariance of assertions/1  and  12.  The  interesting  rule  is  Updage 1.  Compared  to Update, 

rule  Update 1 had to be modified (extended)  in order to take into account 
the  nesting  of rE2  within  El.  More  precisely  the  following two  extensions  were 

necessary  in  order  for  Updage I  to  preserve  the  invariance  o f / 1   and  12: 

(1)  An  additional  pre-condition  pre(Ezpa~d2)  A pre(Update2) 

(2)  An  additional  code  fragment  R e s t o r e  

Technically (1)  is  needed  in order  to  guarantee  that  Update 1 leaves I1  invariant. Informally  this  can  be  seen  as  follows:  Assertion  11  states  that  variables  from 
fi9 91  approximate  their  least  fix-point  value  from  below.  In  order  not  to  break 

11,  rule  Update 1 must  be  prevented  from using 8a-variables  that  are  potentially 
too  'big'.  If,  for  example,  l/el(z)  =  1  for  some  z  E  82  but  (/~Ea}(z)  =  0  (hence 
variable  z  is  not  yet  stable),  then  this  1-value of variable  z  must  be  masked  for 
rule  Update 1. I.e.,  l/el(z)  may not  be  used  as a  trigger for setting  variables of ~91 

to  1.  The  extra  pre-condition  (1)  precisely states  that  rule  Update 1 may only be 
applied  if all  variables  from  ,92  are  'stable',  ensuring  that  these  variables  have 

already  reached  their  greatest  fix-point  values  in  the  (partial)  context  provided 
by  the  $1  variables,  irrespective  of values  of variables  outside  $1.  Hence  when 
,92  is  stable,  no  variable  from  82  has  a  value  that  is  potentially too  big  (this  is 
formally captured  by fact  5.2,  see  further). 

The  rationale  for  (2)  is  the  following: Upon  setting  Pal(z)  to  1  in rule  Updatex, 
the  (partial)  context  in  which  the  inner  greatest  fix-point  yEa  has  to  be  evalu- 
ated,  is  changed.  As  a  result  components  of (pEa)  may change  and  hence  asser- 

tion  Is  risks  to  be  violated.  The  role of R e s t o r e   is precisely to  restore/2.  Below we  list  some  possible  implementations  for Rest ore. 

-  The  easiest  way  to  restore  12  is  by  re-initializing  ,9a.  I.e. 

(1)  R e s t o r e   ~  Sa  :=  {~ 
-  Note that  brutely re-initializing $2 just  to restore I2 may look like an overkill. 

Furthermore  all  previously  computed  ~v]/?2]-results  that  are  still  valid,  are 
irrevocably  lost  and  hence  have  to  be  computed  anew  if  needed  later  on. 

Schema  (1)  can  be  refined  by  observing  that  variables  from  ,92  that  are  1 
can  never  be  responsible  for  violating  Is.  Hence  it  suffices  to  remove  only 
variables  from  Sa  that  are  0: 

(2)  Restore  --  $2 :----$21 i 
-  Next  note  that  not  every y  G Sa]0  has  to  be  removed:  If  Val(y)  was  already 0  when  z  was  added  to  e l ,   then  Val(y)  is  'independent'  of  Val(z).  Hence 

variable  y  can  impossibly violate I2  when  Val(z)  is  set  to  1.  Hence: 

(3)  Restore  --  :=  S  I1  U  :  <  (S,  :=  S,  U{ ,} ) }  

313 
where  (Val(y)  :=  0)  <  (St  :=  `ga U  {z})  means  that  Val(y) was  set  to 
0 before z  was added  to St. This condition can easily be checked,  e.g. by 
numbering  variables: A  variable from `91 obtains a number  (higher the all 
previous numbers)  when it is added to ,91, and a variable from ,92 obtains a 
number  when  it is set to 0. 

-  As  a further refinement  note that not all variables from ,92 that were set 

to 0 after z was added to ,91 need be removed:  Only those variables y that 
actually  relied  upon  Val(z)  being  0  in  order  to  set  Val(y)  to  0.  In  other 
words,  y  must  be  removed from 82  only if  Val(z)  (=  0)  has  actually served, 
either  directly  or  indirectly,  as  a  trigger  in  setting  Val(y)  to  0.  To  find  out 
whether  this  has  indeed  be  the  case  we  introduce  an  additional  attribute Trig(y) 

for every y  e  ,9210. The goal of Trig(y)  is to keep track of all variables 
occurring  in  E2(y)  that  together  acted  as  triggers in  setting  Val(y)  to  0.  To 
appropriately  set  these  Trig-attributes,  rule  Update 2  must  be  extended  by inserting  the  following statement 

Trig(z)  :=  {y  E  E2(z)  :  y  E  (,91  I.J ,92  )  and  Val(y) =  0} 
right before the statement  Val(z)  :=  0. Using these additional  Trig-attributes 
we  obtain  the  following fine-grained  schema  for  Re sto re:  

R  :=  {=} 
w hi l e  R  ~  0  d o 

select  s o m e y E R   R : = R \ { y }  
f o r e a c h   z  E  $210  :  y  E  Trig(z)  d o  (4)  R e s t o r e   ----  Trig(z )  :=  Trig(z ) \  {y} 

b :---- IE2(z)]  (Av.  if v  e  Trig(z)  then  0  else  1) 
if b ~s 0  t h e n  $2:=$2\{z}  R : = R U { z }  

-  The  price  to  pay  for  the  fine  granularity  of schema  (4)  are  additional  Trig- 

attributes.  Yet  another schema  (5)  is the  following one: To avoid the  (costly) 

Trig-attributes  of schema  (4),  we  use  a  boolean  attribute  Used(z)  for  every 
z  C `gt[0. Initially, i.e.  when  z  is  added  to  81,  Used(z)  is  set  to  false.  When- 
ever  Val(z)  acts  as  a  trigger  for setting  a  variable  of 82  to  0,  Used(z)  is  set 

to  true.  Now  when  Val(z)  is set  to  1,  we consult  Used(z).  If  Used(z)  is  still 
false  then  32  can  stay  as  is.  If,  however,  Used(z)  is  true,  then  we  can  apply 
one  of the  schema's  (1), (2)  or  (3).  This  approach  is  less  subtle  than  schema 

(4)  but  correspondingly  requires  less  storage  space. 

Fact  5.1  Assertions  11 and 12 are invariants of AltSolve. 

F ac t   5.2  (pre(Ezpand2)  Apre(Update2) )  ~  (Vz  E  `92[1 :  (yE2)(z)  ---- 1) 
F ac t   5.3  ( h   Apre(Ezpandl)  Apre(Updatet))  z==> (Vz  E  S t l 0 :   ~/~N l  (z)  =  0) 

314 
T h e o r e m   5.4  ( C o r r e c t n e s s )   Algorithm AltS olve   is  partially  correct. 

For the time complexity, note that rule Updste~ is executed  at most  [lv(E~)l 
times, as every variable of Iv(El) can change value at most once. Hence  left 

hand  side  variables  of the  inner  bes  E2  axe  re-initialized at  most  II~(E1)[  times. The  following theorem  can  be  proven. 

T h e o r e m   5.5  ( C o m p l e x i t y )   Algorithm AltS olve  can be  implemented to run 
in  time  O(  JEll  +  [I~(E1)[.IE21 ). 

Note that theorem 5.5 is valid regardless which of the presented schema's is used 
for implementing Restore. However, average running time might be reduced sub- 

stantially by using for instance schema (4) or (5) instead of the naive schema 

(1). Additional search-space-reduction heuristics can also be incorporated into 
algorithm A1tSolve. Removing variables from 82 does leave assertions 11 and 

12 invariant and hence causes no additional correctness problems. Reducing 81 
is slightly more  complicated. Again  the reason is that, upon  removing  vari- 
ables from 81, the context in which the inner block rE2 has to be evaluated, is 
changed. As a result (rE2) may  change and hence assertion/2 might be violated. 

Procedure Restore can be used here too in order to restore/2. 

6  D i s c u s s i o n   a n d   R e l a t e d   W o r k  

Related  work on  local correctness  checking for boolean  equation  systems can  be found  in  [1,8] (in  [1]  the  notion  of boolean  graphs  is  used).  Larsen  [8]  gives  a 
quadratic  algorithm for  alternation-free  equation  systems.  The  linear  algorithm 
in  [1] is similar in spirit  to Solve.  Both  aim at  constructing  a  complete and sta- 

ble  search  space.  The  Andersen  algorithm is  inherently sequential  as  it  is  based 
on  a  depth-first  traversal  of  the  boolean  graph.  Solve,  on  the  other  hand,  is 

not  restricted  to  depth-first  search.  Rule  Ezpand  can  be  implemented such  that search  space  expansion  follows a  depth-first  pattern,  or  a  breadth-first  pattern, 

etc.  Solve  even  seems  well-suited  to  be  implemented  on  parallel  architectures, 
thereby  potentially  further  reducing  the  running  time.  A  local  algorithm  for equation  systems  of  alternation-depth  2  is  contained  in  [2], where  essentially 

schema  (1)  is  used  to  implement Restore. Although Al tS o lv e  focusses on equation systems having an alternation depth  of 

2, the ideas underlying AltSo lve  easily extend to higher alternation depths.  Con- 
sider for example an  equation  system t h E 1 . . ,   cr,~En of depth  n  (i.e., cr~ ~  Cr~+l). 
The  algorithm for  computing  ~ l E l . . . c r n E , ~ ]   (~)  would  then  contain  a  compu- 

tation  rule  Update i  and  an  expansion  rule  Ezpa~zd i  for  every  1  <  i  <  n.  Rule Update~  may  only  be  executed  on  condition  that  all  inner  blocks  Ei +l...En  

are  stable.  Whenever  a  variable  of  lv(Ei)  changes  value,  variables  of the  inner blocks  Ej  (for  i  <  j  <  n)  must  be  reinitialized.  Actually,  it  sufilces  to  only 
reinitialize variables  belonging to  inner  blocks Ej  of opposite  type  (i.e.  ~j  ~  ~i). Instead  of  re-initializing  inner  blocks,  one  could  also  try  to  extend  the  more 

315 
subtle  Res t o re - s ch em a   (4)  towards  n-ary  blocks.  It  is  however  at  first  sight  not 
clear  how  this  can  be  done.  We  claim that  in  this  way a  localized  version  of the 
global  iterative  algorithm  discussed  in  [6]  is  obtained,  having  the  same  worst- 
case  time complexity as  the  latter  one,  i.e.,  polynomial in  ~ l < i < n   IEil  (and  only 
exponential  in  n).  As  far  as  we  know,  polynomial  time  local-a]-gorithms for  ar- 

bitrary  alternation-depths  have  not  been  reported  in  the  literature,  except  for 

[15]  (and  an  informal  sketch  in  [2]).  Xinxin's  algorithm  is  rather  intricate  and 
complicated  compared  to  the  above  sketched  extension  of Al t S o l v e .   The  local 
algorithms  in  [4,9,14]  are  all  based  on  fix-point  induction  techniques  and  have 
time  complexities  exponential  in  the  number  of variables,  even  when  applied  to 
alternation-free  equation  systems.  The  improvements  proposed  by  Cleaveland 

[4]  do  not  remove this  exponential  behaviour. 

A c k n o w l e d g e m e n t s .   I  would  like to  thank  K.G.  Larsen  for sending  me a  copy 
of Xinxin's  PhD  thesis  and  for  pointing  me  to  Andersen's  PhD  thesis.  Thanks 

also  to  H.R.  Andersen  for  sending  me  a  copy  of his  PhD  thesis. 

R e f e r e n c e s  

1.  Andersen,  H. R.:  Model Checking  and Boolean Graphs, ESOP'92,  LNCS  582,  1992. 2.  Andersen,  H.  R.: 

Verification  of Temporal  Properties of Concurrent Systems, PhD thesis,  Aarhus  University,  DAAMI PB-445,  1993. 

3.  Arnold,  A.,  Crubil]e,  P.:  A  linear algorithm to solve flzed-points equations on tran- sition  systems,  Information  Processing  Letters,  vol.29,  57-66,  1988. 
4.  Cleaveland,  R.:  Tableau-Based  Model  Checking  in  the  Propositional Mu-Calculus, Acta  Informatica,  1990. 

5.  Cleaveland,  R.,  Steffen,  B.:  A  Linear-Time  Model  Checking  Algorithm  for  the Alternation-Free Modal  Mu-Caleulus,  CAV'91, LNCS  575,  1991. 
6.  Cleaveland,  R.,  Klein,  M.,  Steffen,  B.:  Faster Model  Checking  for  the  Modal  Mu- Calculus,  CAV'92, Forthcoming. 

7.  Emerson,  E.A.,  Lei,  C.-L.:  E~cient  model  checking  in  fragments  of  the  proposi- 

tional #-calculus,  LICS,  267-278,  1986. 8.  Larsen,  K.G.: 

Efficient  local correctness  checking,  CAV'92, Forthcoming. 9.  Stirling,  C.,  Walker,  D.:  Local  model  checking  in  the  modal  mu-calculus,  TCS, 

October  1991, see  also  LNCS  351,  369-383,  CAAP  1989. 10.  Tarski,  A.: 

A  Lattice-Theoretical Fixpoint  Theorem  and  its  Applications,  Pacific Journal  of Mathematics,  Vol.  5,  1955. 

11.  van  Glabbeek,  R.J.,  Weijland,  W.P.:  Branching  time  and  abstraction  in  bisimula- 

tion  semantics  (extended abjtract),  in  Information  Processing  89,  North-Holland, 1989. 

12.  Vergauwen,  B.,  Lewi,  J.:  A  linear  algorithm  for  solving  fixed points  equations  on 

transition  systems,  CAAP'92,  LNCS  581. 13.  Vergauwen, B., Lewi, J.:  A  Linear Local Model Checking Algorithm for  CTL,  CON- 

CUR'93,  LNCS  715. 14.  Winskel,  G.: 

A  note  on  model checking  the  modal v-calculus,  ICALP,  LNCS  372, 1989,  see  also TCS  83,  1991. 

15.  Xinxin,  L.:  Specification  and Decomposition in  Concurrency,  PhD  thesis,  Aalborg University,  1992. R  92-2005. 