

Region-Based Shape Analysis with Tracked Locations

Brian Hackett and Radu RuginaComputer Science Department

Cornell UniversityIthaca, NY 14853
{bwh6,rugina}@cs.cornell.edu

ABSTRACT
This paper proposes a novel approach to shape analysis: using localreasoning about individual heap locations instead of global reasoning about entire heap abstractions. We present an inter-proceduralshape analysis algorithm for languages with destructive updates.
The key feature is a novel memory abstraction that differs fromtraditional abstractions in two ways. First, we build the shape abstraction and analysis on top of a pointer analysis. Second, wedecompose the shape abstraction into a set of independent configurations, each of which characterizes one single heap location. Ourapproach: 1) leads to simpler algorithm specifications, because of
local reasoning about the single location; 2) leads to efficient algo-rithms, because of the smaller granularity of the abstraction; and
3) makes it easier to develop context-sensitive, demand-driven, andincremental shape analyses.

We also show that the analysis can be used to enable the staticdetection of memory errors in programs with explicit deallocation.
We have built a prototype tool that detects memory leaks and ac-cesses through dangling pointers in C programs. The experiments
indicate that the analysis is sufficiently precise to detect errors withlow false positive rates; and is sufficiently lightweight to scale to
larger programs. For a set of three popular C programs, the toolhas analyzed about 70K lines of code in less than 2 minutes and
has produced 97 warnings, 38 of which were actual errors.

Categories and Subject Descriptors
F.3.2 [Logics and Meanings of Programs]: Semantics of Pro-gramming Languages--Program Analysis; D.2.4 [Software Engineering]: Software/Program Verification; D.3.4 [ProgrammingLanguages]: Compilers--Memory Management

General Terms
Algorithms, Languages, Verification

Keywords
Shape analysis, static error detection, memory leaks, memory man-agement

Permission to make digital or hard copies of all or part of this work forpersonal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copiesbear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specificpermission and/or a fee.
POPL'05, January 12-14, 2005, Long Beach, California, USA.Copyright 2005 ACM 1-58113-830-X/05/0001 ...$5.00.

1. INTRODUCTION

Dynamic data structures are fundamental to virtually all pro-gramming languages. To check or enforce the correctness of programs that manipulate such structures, the compiler must automat-ically extract invariants that describe their shapes; for instance, that
heap cells are not shared, i.e., not referenced by more than oneother memory location. This invariant provides critical information
to check high-level properties, for instance that a program builds atree or an acyclic list; or to check low-level safety properties, for
instance that there are no accesses through dangling pointers. Forimperative programs with destructive updates, the task of identifying shape invariants is difficult because destructive operations tem-porarily invalidate them. Examples include even simple operations,
such as inserting or removing elements from a list. The challengeis to show that the invariants are restored as the operations finish.

There has been significant research in the area of shape analysisin the past decades, and numerous shape analysis algorithms have
been proposed [34]. At the heart of each algorithm stands a sophis-ticated heap abstraction that captures enough information to show
that invariants are being preserved. Examples of heap abstractionsinclude matrices of path expressions and other reachability matrices [18, 17, 11], shape graphs [29, 21], and, more recently, three-valued logic structures [31]; all of these characterize the entire heap
at once. Although shape analyses have been successful at verify-ing complex heap manipulations, they have had limited success at
being practical for larger programs. We believe that their mono-lithic, heavyweight abstraction is the main reason for their lack of
scalability.This paper presents an inter-procedural shape analysis algorithm
based on a novel memory abstraction. The main idea of this paper isto break down the entire shape abstraction into smaller components
and analyze those components separately. As shown in Figure 1,we propose a decomposition of the memory abstraction along two
directions:*

Vertical decomposition: First, we build the fine-grained shapeabstraction and analysis on top of a points-to analysis that provides a coarse-grained partition of the memory (both heap andstack) into regions, and identifies points-to relations between regions;*
Horizontal decomposition: Second, we decompose the shapeabstraction itself into individual configurations; each configuration characterizes the state of one single heap location, calledthe tracked location. A configuration includes reference counts
from each region, and indicates whether certain program expres-sions reference the tracked location or not. The set of all configurations provides the entire shape abstraction; however, config-urations are independent and can be analyzed separately. This is
the key property that enables local reasoning.

. . .
independent configurations
ShapeAbstraction

AbstractionRegion

Config. Config.  Config. 

n

Points-toInformation
Vertical

decomposition

Horizontal Decomposition

1 2

Figure 1: Decomposition of the memory abstraction
The vertical decomposition frees the shape analysis of the burdenof reasoning about aliases in unrelated program structures. Further, the horizontal decomposition into independent configurationsprovides a range of advantages. First, it enables local reasoning
about the single tracked location, as opposed to global reasoningabout the entire heap. This makes the analysis simpler and more
modular. Second, the finer level of abstraction granularity reducesthe amount of work required by the analysis: efficient worklist algorithms can process individual configurations rather than entireabstractions. Third, it does not require keeping multiple abstractions of the entire heap at each point [30], nor any complex mech-anisms to merge entire abstractions for a more compact representation [29]. The decomposition into configurations automaticallyyields a compact representation that is able to model many concrete heaps. Fourth, it makes it easier to formulate inter-proceduralcontext-sensitive analyses where procedure contexts are individual
configurations. Fifth, it makes it easy to build on-demand and in-cremental shape analysis algorithms. Minor modifications allow
the algorithm to explore from only a few selected allocation sites,giving a complete shape abstraction for all cells created at those
sites, and to reuse previous results when new allocation sites arebeing explored.

We also present extensions of the analysis that enable the staticdetection of memory errors in languages with explicit deallocation.
Our algorithm can identify memory leaks and accesses to deallo-cated data through dangling pointers. We have built a prototype
system for C programs that implements the ideas in this paper andis aimed at detecting memory errors. Our experiments show that
local reasoning leads to scalable implementations; that it can cor-rectly model shape for standard list manipulations; and that it can
enable the detection of memory errors with low false positive rates.This paper makes the following contributions:

* Memory Abstraction: It proposes a novel memory abstrac-tion that builds the precise shape abstraction on top of a region points-to abstraction; it further decomposes the shape ab-straction into independent configurations that describe individual heap locations;*
Analysis Algorithm and Applications: It gives a precise spec-ification of an inter-procedural, context-sensitive analysis algorithm for this abstraction; and shows how to use the analysisresults to detect memory errors;

* On-demand and Incremental Shape Analysis: It shows thatour approach can be applied to the demand-driven and incremental computation of shapes;

* Theoretical Framework: It presents the analysis algorithm ina formal setting and shows that the key parts of the algorithm are

sound;*
Experimental Results: It presents experimental results col-lected from a prototype implementation of the proposed analysis

for C programs.
The rest of the paper is organized as follows. Section 2 presentsan example. Section 3 introduces a simple language, and Sections 4

and 5 describe the algorithm in the context of this simple language.Next, Section 6 presents extensions to the algorithm. Section 7
discusses limitations. We present experimental results in Section 8,discuss related work in Section 9, and conclude in Section 10.

2. EXAMPLE

We use the example from Figure 2 to illustrate the key features ofour analysis. This example is written in C and shows a procedure

splice that takes two argument lists x and y, splices x into y,and returns the resulting list. The code assumes that input list

x isnot longer than
y. The goal of shape analysis is to statically verifythat, if the input lists

x and y are disjoint and acyclic, then the listreturned by
splice is acyclic.The execution of splice works as follows. First, it stores a pointer

to the second list into a local variable z. Then, the program usesa loop to traverse the two lists with parameters

x and y. At eachiteration, it sets a pointer from the first list into the second, and viceversa, using a temporary variable t. When the traversal reaches theend of list

x, it terminates and the procedure returns the list pointedto by
z.

2.1 Memory Abstraction

Figure 3 shows two possible concrete stores that can occur dur-ing the execution of

splice. The one on the left is a possibleconcrete store at the beginning of the procedure, where

x and ypoint to acyclic lists; and the store on the right is the corresponding

memory state when the loop terminates. Boxes labeled with x, y,
z, and t represent the memory locations of those variables. The re-maining unlabeled boxes are heap cells and represent list elements.

Figure 4 presents the memory abstraction that our analysis usesfor these two concrete stores. The left part of this figure shows the
region component of the abstraction, which consists of a points-to graph of regions. Each region models a set of memory locations; and different regions model disjoint sets of locations. Forthis program, our analysis uses a separate region to model the location of each variable1: X, Y, Z, and T are the regions containingvariables

x, y, z, and t, respectively. Region L models all list el-ements. The points-to graph Figure 4 shows the points-to relations

between abstract regions for the whole procedure, as given by aflow-insensitive pointer analysis. Hence, this graph applies to both
the input and output abstractions discussed here.The right part of Figure 4 shows the shape component for each
of the concrete stores. Each abstraction consists of a set of con-figurations: the input abstraction has 3 configurations and the output abstraction has 4. Each configuration characterizes the state ofthe tracked location and consist of: a) reference counts from each
region to the tracked location, shown in superscripts; b) programexpressions that definitely reference the tracked location (hit expressions); and c) program expressions that definitely do not (missexpressions). For instance, configuration (T

1 L1, {t}, ;) shows

that the tracked location has one incoming reference from region T,

1Although not the case in this example, it may happen that multiple
variables get placed into the same region.

1: typedef struct list {
2: struct list *n;
3: int data;
4: } List;
5:
6: List *splice(List *x, List *y) {
7: List *t = NULL;
8: List *z = y;
9: while(x != NULL) {
10: t = x;
11: x = t->n;
12: t->n = y->n;
13: y->n = t;
14: y = y->n->n;
15: }
16: return z;
17: }

Figure 2: Example program: splicing lists

one incoming reference from region L, and is referenced by t, butany expression originating from L (i.e., next pointers) may either
reference it or fail to reference it. Although we could have usedricher sets of miss expressions, these abstractions are sufficient for
our algorithm to prove the shape property.These abstractions are complete: the set of all configurations in
each abstraction provides a characterization of the entire heap. In-deed, if the tracked location is any of the five heap cells, there is a
configuration that characterizes it. But although their sum collec-tively describes the entire heap, configurations are independent: the
state described by any particular configuration is not related to theother configurations; it characterizes one heap location and has no
knowledge about the state of the rest of the heap (beyond what isgiven by the points-to graph). This is the key property that enables
local reasoning.
2.2 Analysis of Splice

Figure 5 shows the analysis result that our algorithm computesat each point in the program. This shape abstraction builds on the

region points-to abstraction from the previous section. Boxes in thefigure represent individual configurations; each row represents the
entire heap abstraction at a program point; and edges correlate thestate of the tracked location before and after each statement. Therefore, each path shows how the state of the tracked location changesduring program execution. For readability, we omit wrap-around
edges that connect configurations from the end to the beginning ofthe loop. Also, we omit individual variables from hit and miss sets,
and show just the field accesses expressions. We use the abbrevia-tions: tnj

t->n and ynj y->n, and indicate miss expressions us-ing overlines. Our algorithm efficiently computes this result using

a worklist algorithm that processes individual configurations (i.e.,individual nodes), rather full heap abstractions (i.e., entire rows).

The top row shows three configurations, Y1, L1, and X1, thatdescribe the memory for any input where

x and y point to acycliclists. The bottom row consists of configurations Z

1 and L1, and

shows that at the end of the procedure the returned value z points toan acyclic list. Hence, the analysis successfully verifies the desired

shape property.We discuss the analysis of several configurations to illustrate
how the analysis performs local reasoning. Consider the configura-tion Y

1Z1 before the statement at line 11, x=t->n. The compiler

inspects this assignment and tries to determine whether or not theexpressions in the left- and right-hand side reference the tracked loExample concrete input Corresponding output
y
x
t

z

y

x
t

z

Figure 3: Example concrete memories
Region Shape ComponentPoints-to Configurations Configurations
Component for input memory for output memory

T
X

Y

Z L

n (X1, {x}, ;)

(Y1, {y}, ;)(L

1, ;, ;)

(Z1, {z}, ;)(T

1 L1, {t}, ;)

(Y1 L1, {y}, ;)(L

1, ;, ;)

Figure 4: Memory abstraction
cation: if the right side references the location, the assignment mayadd a new reference to it; and if the left side points to the tracked location, the assignment may remove a reference to it. For x=t->n,the analysis determines that

x represents a location in region X, and
t->n is a location in region L, as indicated by the points-to graph.But the reference counts in the current configuration show that the

tracked location has no references from regions X or L; hence, itconcludes that neither

x, nor t->n reference the tracked locationand this assignment doesn't affect its reference counts.

Consider now the configuration L1 at the same program point,before line 11. The compiler can use the same judgment as above to
determine that x does not reference the tracked location. However,it is not able to determine whether or not

t->n references it. Atthis point, the compiler bifurcates the current configuration into two

configurations where this fact is precisely known: one where t->nreferences the location and one where it doesn't. In each case, it
adds t->n to the corresponding hit or miss set, and analyzes theassignment. The resulting two configurations L

1 and X1L1 after

line 11 are the successors of the analyzed configuration L1.Keeping track of hit and miss sets provides invaluable information to the analysis. Consider configuration L1 before statement
t->n=y->n. The analysis of this statement yields a configurationL

2, where the tracked location has two incoming references from

L and violates the desired shape property. However, the analysisidentifies that the reference

y->n is being copied, so it adds y->nto the hit set of configuration L

2. At the next assignment, y->n=t,

the analysis identifies that the same expression y->n is being over-written. The presence of

y->n in the hit set enables the analysis toaccurately decrease the reference count from L back to 1.

2.3 Cyclic and Shared Inputs

Analyzing the behavior of splice for cyclic or shared inputlists provides key insights about why the local reasoning about the

single location works. The left part of Figure 6 shows an inputstore where the list pointed to by

y contains a cycle; the right partshows the resulting memory after running

splice with this input.

8: z = y;
9: while (x != NULL)
10: t = x;
11: x = t->n;
12: t->n = y->n;

13: y->n = t;
14: y = y->n->n;
16: return z;

Y1
Y1Z1
Y1Z1
Y1Z1
Y1Z1

Y1Z1
Y1Z1

Z1
Z1

Z1
Z1
Z1

Z1
Z1

X1
X1
X1
X1T1

T1

T1
T1L1yn

T1L1

T1L1

L2tn yn
Y1T1L1

L1
L1
L1
L1
L1tn

L1tn yn
L1yn
L1
L1

Y1L1
Y1L1
Y1L1tn

Y1L1tn yn
Y1L1yn
Y1L1

Y1T1L1
Y1L2tn yn

X1L1tn
X1L1tn yn X1

X1
X1

X1Y1L1tn
X1Y1L1tn yn X1Y1

X1Y1

Loop

Figure 5: Shape analysis results for splice. Boxes represent configurations and edges show how the state of the tracked locationchanges during the execution. We only show field access expressions in the hit and miss sets. We use the abbreviations: tnj

t->nand ynj
y->n, and we indicate miss expressions using overlines. For readability, back edges from configurations at the end of theloop to the corresponding configurations at the beginning of the loop are omitted.

A closer look at the input structure reveals that the cycle is causedby the presence of one shared cell with two incoming references,
the shaded cell. If we inspect the output structure we see that it isalso a cyclic list. The interesting fact is not that

splice yields acyclic output given a cyclic input; but rather that the shaded cell that

causes the input cycle is exactly the same cell that causes the cyclein the output. Therefore, reasoning about cycles requires reasoning
just about this particular cell. All of the other cells in this structurebehave as in the acyclic case.

To build the abstraction for the cyclic input from Figure 6, wecan use the previous abstraction, and augment it with one additional
configuration L2 to describe the cell in question. The analysis ofthe abstraction for the cyclic input will yield a configuration graph
similar to the one from Figure 5, but augmented with additionalpaths that originate at the L

2 configuration. These paths describe

the state of the shared cell through the program. One can examinethe input-output relationships in the result graph, and identify that

the shared cell in the input (L2) may remain shared, but all of thenon-shared cells in the input (X

1, Y1, and L1) will remain nonshared in the output.In fact, the analysis of the cyclic case can reuse all of the analysis

result from the acyclic case. This is possible because the analysisof each configuration in Figure 5 reasons only about one location,
and makes no assumption about the presence or absence of cyclesin the rest of the structure. Hence, those results directly apply to
cyclic inputs; they characterize the "acyclic portion" of the cyclicinput. Similar situations arise for inputs that have shared sublists,
or inputs where one list is a sublist of the other.This discussion brings us to the inter-procedural analysis, the
main obstacle in building scalable analyses. The example showsthat our abstraction allows us to efficiently build an inter-procedural
context-sensitive analysis, where the analysis of each calling con-text can reuse results from other contexts. In our example, the analCyclic input Corresponding output
y
x
z t

z
x

y t

Figure 6: Example cyclic memory
ysis of splice for a cyclic context can reuse the result from anacyclic context, and do little additional work. And if the cyclic
context is being analyzed first, the result for the acyclic one is al-ready available. This is possible because we can break down the
entire heap context into finer-grain contexts that are just individualconfigurations.

3. A SIMPLE LANGUAGE

To formalize the description of the algorithm, we use the simplelanguage shown in Figure 7. This is a typeless C-like imperative

language with procedures, dynamic allocation, and explicit deallo-cation. A program prog maps each procedure to a pair containing
its formal parameters and its body. The only possible values arepointers to memory locations and null pointers. Dynamic allocations create structures that contain one memory location for eachfield. There is a distinguished first field

f1 in each structure; dy-namic allocations return a pointer to the first field in the newly allocated structure. The language supports pointers to variables andpointers into the middle of structures. An expression

e.f requires
e to be an l-value representing the first field of a structure; then
e.f is the f field of that structure. A dereference expression *e alprograms: prog 2 Prog = P ! (V n * S)procedures:

p 2 Pstatements:
s 2 S, s ::= e0  e1|

e  malloc | free(e)| call

p(e1, .., en) | s0 ; s1| if
(e) s0 else s1 | while (e) sexpressions:
e 2 E, e ::= null | x | &e | * e | e.fvariables:
x 2 Vfields:
f 2 F = {f1, . . . , fm}

Figure 7: Source language
ways represents the memory location pointed to by e (not the wholestructure when

e points to a structure). C expressions of the form
e->f are represented in our language as (*e).f. Deallocationstatements free all of the locations in a structure and yield dangling

pointers.We formally model concrete stores that can arise during program
execution using a set of memory locations L that contains the stacklocations for variables, and all of the heap locations created during
program execution. Let V be the set of variables in the program. Aconcrete store is a triple

oe = (oev, oel, oef ), consisting of:

Variable map: oev : V ! LLocation map:

oel : L * (L + {null})Field map:
oef : (L * F ) * L

The map oev assigns a location to each variable. The partial map
oel models points-to relations between locations. We require thatrange

(oev) ` dom(oel). The set range(oev) represents stack-allocatedmemory locations. The set

Loe = dom(oel) - range(oev) representsthe currently allocated heap locations. A stack or heap location

lcontains a dangling pointer if
oel(l) 62 dom(oel) [ {null}. Finally,the partial map
oef captures the organization of fields in allocatedstructures. For a location

l 2 L that represents the first field in aheap structure,
oel(l, f) represents the f field of that structure. Werequire that all locations in the domain and range of

oef be allocated.The Appendix describes the formal semantics of the language using a relation he, oei !l l that evaluates expression e to its l-value;a relation h

e, oei !v v that evaluates e to its r-value; a relationh
s, oei !s oe0 for statements. In this paper, we refer to the l-valueof an expression

e as the location of e, and to the r-value of e as thevalue of e.

We formulate the proposed analysis algorithm in the context ofthis language. The overall algorithm first performs a region analysis, and then runs the shape analysis. The following two sectionsdescribe each of these analyses in turn.

4. REGION ANALYSIS

The goal of region analysis is to provide a partitioning of thememory into disjoint regions, and to identify points-to relations between regions. In general, this can be achieved using any pointeranalysis algorithm; our shape analysis is independent of the particular pointer analysis being used. However, we use a flow-insensitiveand context-sensitive pointer analysis similar to [24] and [10]. Such
algorithms seem a good match for our problem because of two rea-sons. First, they are efficient in practice, due to flow-insensitivity.
Second, they are precise enough to distinguish between differentheap structures allocated at the same site, due to context-sensitivity.
Using such an algorithm, the analysis result is a points-to graph foreach procedure; nodes in these graphs represent memory regions,

and edges model points-to relations between regions. Most impor-tant in our system is to characterize the computed region result, thus
describing the interface between region and shape analysis. Givena program, a region abstraction consists of the following:

* for each procedure p, a set of regions Rp that models the loca-tions that

p may access;*

for each procedure f, a region abstract store: aep = (aepv, aepr, aepf ),where

aepv : V ! Rp maps variables to their regions; the partialmap
aepr : Rp * Rp models points-to relations between regions;and
aepf : (Rp * F ) * Rp maps pairs of base regions and fieldsto field regions;

* for each call site cs, with caller p and callee q, a one-to-onemapping

ucs : Rq ! Rp that maps all (parameter) regions in qto actual regions in

p.

A region abstraction is sound if regions describe disjoint sets ofmemory locations, and points-to relations in the abstraction accurately describe points-to relations in the concrete heap. We give aformal definition of soundness in Section 5.3. Key to the algorithm
is that regions are disjoint, so the subsequent shape analysis cansafely conclude that an update in one region will not change the
values of locations in other regions.We briefly sketch the flow-insensitive and context-sensitive analysis that computes the region points-to abstraction. First, the algo-rithm performs an intra-procedural, unification-based analysis [32]
to build a points-to graph for each function. Then, it performs aninter-procedural analysis and propagates the aliasing information
between different functions at each call site. The algorithm uses atwo-phase approach similar to [24]: a bottom-up pass through the
functions in the call graph propagates the aliasing information fromcallees to callers; and, a top-down phase propagates the information
from callers to callees.Note that the region partitioning that other kinds of pointer analyses produce could be modeled in a similar way. For a context-insensitive pointer analysis, each call site mapping

ucs is the iden-tity function. And in the case of a flow-sensitive approach, the

analysis result is not just one abstract store ae per function, but a setof abstract stores, one for each program point.

5. SHAPE ANALYSIS

This section presents the shape analysis algorithm in detail. Wefirst present the shape abstraction and then give the intra- and interprocedural algorithms.
5.1 Shape Abstraction

The role of the shape abstraction is to make the points-to infor-mation more accurate. Roughly speaking, the region abstraction

provides "may" points-to relations between memory locations, andthe shape abstraction augments it with "must" points-to information about each heap cell.The shape abstraction is based on the notion of configurations.
Each configuration abstracts the state of one individual memorylocation, the tracked location. The full heap abstraction consists
of a finite set of configurations, such that each concrete memorylocation can be modeled by one configuration in the set. Each configuration keeps track of: reference counts from each region to thetracked location; expressions that definitely reference the tracked
location (hit expressions); and expressions that definitely don't ref-erence the location (miss expressions).

Formally, we describe configurations using an index domain Ifor counting references, and a secondary domain

H for hit and missexpressions. A configuration is then a pair of an index and a secondary value. If R is the set of regions in the currently analyzed

function and Ep is the finite set of program expressions, then thedomains are:

Index values: i 2 I = R ! {0, . . . , k, 1}Secondary values:

h 2 H = P(Ep) * P(Ep)Configurations:

c 2 C = I * H

Each index value i gives the reference counts for each region. Webound the reference counts to a fixed value

k, to ensure that theabstraction is finite. For each region
r 2 dom(i), the number i(r)is the number of references to the tracked location from region

r:if
i(r) 2 0..k, then the reference count is exactly i(r); otherwise,if

i(r) = 1, the reference count is k + 1 or greater. In practice,we found a low value

k = 2 to be precise enough for all of theprograms that we experimented with. We emphasize that

k is themaximum reference count from each region; however, there can be

many more references to the tracked object, as long as they comefrom different regions. Finally, each secondary value

h 2 H is apair
h = (e+, e-), where e+ is the hit set and e- is the miss set.The full shape abstraction consists of a set of configurations, with

at most one configuration for each index value. In other words, theabstraction is a partial map from index values to secondary values.
We represent it as a total function that maps the undefined indicesto a bottom value ?:

Shape abstraction: a 2 A = I ! (H [ {?})
We define a lattice domain over the abstract domain, as follows.The bottom element is

a? = *i.?, meaning that no configurationis possible. The top element is

a? = *i.(;, ;), meaning that anyindex is feasible and, for each index, any expression can either reference or fail to reference the tracked location. Given a1, a2 2 A,their join

a1 t a2 is:

(a1 t a2)(i) = \Gamma \Delta  \Theta 

a1(i) if i 62 dom(a2)
a2(i) if i 62 dom(a1)
a1(i) t a2(i) if i 2 dom(a1) " dom(a2)

where (e+1 , e-1 ) t (e+2 , e-2 ) = (e+1 " e+2 , e-1 " e-2 )and ? t

(e+, e-) = (e+, e-) t ? = (e+, e-)

The merge operator t is overloaded and applies to both A and H [{?}; one can infer which operator is being used from its context.

We denote by v the partial order that corresponds to t.
5.2 Intra-Procedural Analysis

We present the dataflow equations, the transfer functions for as-signments, malloc, and free, and then give formal results.

5.2.1 Dataflow Equations

We formulate the analysis of each function in the program as adataflow analysis that computes a shape abstraction

a 2 A at eachprogram point in the function. The algorithm differs from standard

approaches in two ways. First, it uses a system of dataflow equa-tions and a corresponding worklist algorithm that operate at the
granularity of individual configurations, rather than entire heap ab-stractions (i.e., sets of configurations). Second, the dataflow information is being initialized not only at the entry point in the control-flow, but also at each allocation site, where the analysis produces a
new configuration for the newly created memory location.Let

Sasgn be the set of assignments in the program, and Salloc `
Sasgn the set of allocation assignments. For each assignment s 2
Sasgn, we define two program points: *s is the program point be-fore

s and s* is the program point after s. Let Sentry ` Sasgn bethe set of assignments that occur at the beginning of the currently

analyzed function (i.e., assignments reachable from the function

For all s 2 Sasgn, sa 2 Salloc, se 2 Sentry, i 2 I :

[JOIN] Res(*s) i = \Lambda  s02pred(s) Res(s0*) i
[TRANSF] Res(s*) i = \Lambda  i02I([[s]](ae, (i0, Res(*s) i0))) i
[ALLOC] Res(sa*) ia w ha, where [[sa]]gen(ae) = (ia, ha)
[ENTRY] Res(*se) i w ao i

Figure 8: Intra-procedural dataflow equations.

entry point without going through other assignments), and let predand succ map assignments to their predecessor or successor assignments in the control flow (these can be easily computed from thesyntactic structure of control statements).

We model the analysis of individual assignments using transferfunctions that operate at the level of individual configurations. The
transfer function [[s]] of a statement s 2 Sasgn takes the currentregion abstract store

ae and a configuration c 2 C before the state-ment to produce the set of possible configurations after the statement: [[s]](ae, c) 2 A. Furthermore, for each allocation s 2 Salloc,there is a new configuration

[[s]]gen(ae) 2 C being generated.The result of the analysis is a function Res that maps each program point to the shape abstraction at that point. Figure 8 showsthe dataflow equations that describe Res. In this figure,

ae is the re-gion store for the currently analyzed function and
a0 2 A is theboundary dataflow information at the function entry point. Equations [JOIN], [TRANSF], and [ENTRY] are standard dataflow equa-tions, but are being expressed such that they expose individual configurations and their dependencies. Equation [ALLOC] indicatesthat the analysis always generates a configuration for the new location, regardless of the abstraction before the allocation statement.This formulation allows us to build an efficient worklist algorithm for solving the dataflow equations. Instead of computingtransfer functions for entire heap abstractions when the information at a program point has changed, we only need to recomputeit for those indices whose secondary values have changed. Rather
than being entire program statements, worklist elements are state-ments paired with indices. Using a worklist with this finer level of
granularity serves to decrease the amount of work required to findthe least fixed point.

The worklist algorithm is shown in Figure 9. Lines 1-14 performthe initialization: they set the value of Res at entry points (lines 4-7)
and at allocation sites (lines 8-14), and initialize it to a? at all otherprogram points (lines 2-3). The algorithm also initializes the worklist, at lines 1, 7, and 14. Then, it processes the worklist using theloop between lines 16-22. At each iteration, it removes a statement
and an index from the worklist, and applies the transfer functionof the statement for that particular index. Finally, the algorithm
updates the information for all successors, but only for the indiceswhose secondary values have changed (lines 19-21). Then, it adds
the corresponding pair of successor statement and index value tothe worklist, at line 22.

5.2.2 Decision and Stability Functions

To simplify the formal definition of transfer functions, we in-troduce several evaluation functions for expressions. First, we use

a location evaluation function L[[e]] that evaluates an expression eto the region that holds the location of

e. The function is not de-fined for expressions that do not represent l-values (&

e and null).

WORKLIST(DataflowInfo a0)1

W = ;2 for each

s 2 Sasgn3 Res
(*s) = Res(s*) = a?4 for each

se 2 Sentry5 Res
(*se) t = a06 for each

i such that Res(*se)i has changed7
W = W [ {(s, i)}8 for each

sa 2 Salloc9 let
(ia, ha) = [[sa]]gen(ae)10 Res

(sa*)ia t = ha11 for each

i such that Res(sa*)ia has changed12 for each

s 2 succ(sa)13 Res
(*s)i t = Res(sa*)i14
W = W [ {(s, i)}15

16 while (W is not empty)17 remove some

(s, i) from W18 Res
(s*) t = [[s]](ae, (i, Res(*s)i))19 for each

i0 such that Res(s*)i0 has changed20 for each

s0 2 succ(s)21 Res
(*s0)i0 t = Res(s*)i022
W = W [ {(s0, i0)}

Figure 9: Intra-procedural worklist algorithm.
If ae = (aev, aer, aef), then:

L[[x]]ae = aev(x)L

[[*e]]ae = aer(L[[e]]ae)L
[[e.f]]ae = aef (L[[e]]ae, f)

Second, we define a decision evaluation function D[[e]] that takesa store

ae and a configuration c, uses this information to deter-mine whether

e references the location that c tracks: D[[e]](ae, c) 2{
+, -, ?}. The evaluation returns "+" is e references the trackedlocation, "-" if it doesn't, and "

?" if there is insufficient informa-tion to make a decision:

D[[e]](ae, (i, (e+, e-))) = \Gamma 

\Gamma \Gamma \Delta 
\Gamma \Gamma \Theta  -

if e 2 e- . i(L[[e]]ae) = 0.

e = null . e = &x
+ if e 2 e+
? otherwise

(the condition i(L[[e]]ae) = 0 in the miss case is a shorthand for"

e 6= null ^ e 6= &e0 ^ i(L[[e]]ae) = 0")Finally, we define two stability evaluation functions to determine

if writing into a region affects the location or the value of an expres-sion. The location stability function S

[[e]]l takes an abstract storeand a region, and determines whether the location of

e is stable withrespect to updates in that region: S
[[e]]l(ae, r) 2 {true, false}:

S[[x]]l(ae, r) = trueS

[[*e]]l(ae, r) = S[[e]]l(ae, r) ^ L[[e]]ae 6= rS
[[e.f]]l(ae, r) = S[[e]]l(ae, r)

The value stability function S[[e]]v indicates whether the value of eis stable with respect to updates in

r. Value stability implies loca-tion stability, but not vice-versa:

S[[null]]v(ae, r) = trueS

[[x]]v(ae, r) = ae(x) 6= rS
[[&e]]v(ae, r) = S[[e]]l(ae, r)S

[[*e]]v(ae, r) = S[[e]]v(ae, r) ^ L[[*e]]ae 6= rS
[[e.f]]v(ae, r) = S[[e]]l(ae, r) ^ L[[e.f]]ae 6= r

PROPERTY 1 (STABILITY). Given a sound abstract store ae,an assignment

e0  e1 such that L[[e0]](ae) = r, a concrete state oebefore the assignment and a concrete state

oe0 after the assignment,then:

* for any expression e, if S[[e]]v(ae, r) then e evaluates to the samevalue in stores

oe and oe0;*

if S[[e0]]l(ae, r) then e0 evaluates in store oe0 to the value that e1evaluates in store

oe;*

if S[[e1]]l(ae, r) then e1 evaluates to the same value in stores oeand

oe0.

We illustrate the importance of stability with an example. Con-sider two variables:

x in region rx and y in region ry. Assumethat the tracked location is being referenced by

y, that the trackedlocation does not have a self reference, and that the program executes the statements x = &x; *x = y. Although we assign y to *xand

y is a hit expression, *x will not hit the tracked location afterthis code fragment. The reason is that *

x does not represent thesame memory location before and after the statement; the update

has caused *x to have different l-values. Our analysis captures thisfact by identifying that expression *

x is not location-stable with re-spect to updates in region
rx. In general, if the left-hand side of anassignment is not location-stable, it is not safe to add it to the hit

(or miss) set, even if the right-hand side hits (or misses) the trackedlocation.

5.2.3 Analysis of Assignments: e0  e1

The analysis of assignments plays the central role in the intra-procedural analysis. Given a configuration

c = (i, h) before theassignment, the goal is to compute all of the resulting configurations after the assignment. Given our language syntax, this formof assignment models many particular cases, such as nullifications
(x = null), copy assignments (x = y), load assignments (x = *yor

x = y.d), store assignments (*x = y or x.d = y), address-of assignments (

x = &y), as well as assignments that involvemore complex expressions. Our formulation compactly expresses

the analysis of all these statements in a single, unified framework.Figure 10 shows the algorithm. The analysis must determine
whether or not the expressions e0 and e1 reference the tracked lo-cation. For this, it invokes the decision function D

[[*]] on e0 and
e1. For each of the two expressions, if the decision function can-not precisely determine if they hit or miss the tracked location, it

bifurcates the analysis in two directions: one where the expressiondefinitely references the tracked location, and one where it definitely doesn't. The algorithm adds e0 and e1 to the correspondinghit or miss set and analyzes each case using the auxiliary function
assign; it then merges the outcomes of these cases.The function assign is shown Figure 11 and represents the core
of the algorithm. It computes the result configurations when thereferencing relations of

e0 and e1 to the tracked location are pre-cisely known, and are given by the boolean parameters

b0 and b1,respectively. The algorithm works as follows. First, it evaluates

the region r that holds the location being updated, using L[[e0]].Then, it updates the reference count from

r, between lines 2-8. If
e0 references the location, but e1 doesn't, it decrements the count;if

e1 references the location, but e0 doesn't, it increments it; andif none or both reference it, the count remains unchanged. Special

care must be taken to handle infinite reference counts; in particular,decrementing infinite counts yields two possible values, 1 and

k.The result is a set
Si that contains either one or two indices with theupdated reference count(s) for

r. Note that the analysis can safelypreserve reference counts from all regions other than

r, becauseregions model disjoint sets of memory locations.

[[eo  e1]](ae, (i, (e+, e-))) :

case (D[[e0]](ae, (i, (e+, e-))), D[[e1]](ae, (i, (e+, e-)))) of
(v0 2 {-, +}, v1 2 {-, +}) )

assign(e0, e1, ae, i, e+, e-, v0 = +, v1 = +)

(?, v1 2 {+, -}) )

assign(e0, e1, ae, i, e+ [ {e0}, e-, true, v1 = +) t
assign(e0, e1, ae, i, e+, e- [ {e0}, false, v1 = +)

(v0 2 {-, +}, ?) )

assign(e0, e1, ae, i, e+ [ {e1}, e-, v0 = +, true) t
assign(e0, e1, ae, i, e+, e- [ {e1}, v0 = +, false)

(?, ?) )

assign(e0, e1, ae, i, e+ [ {e0, e1}, e-, true, true) tassign

(e0, e1, ae, i, e+ [ {e0}, e- [ {e1}, true, false) t
assign(e0, e1, ae, i, e+ [ {e1}, e- [ {e0}, false, true) t
assign(e0, e1, ae, i, e+, e- [ {e0, e1}, false, false)

Figure 10: Transfer function for assignments [[e0  e1]].

Next, the analysis derives new hit and miss sets, using the com-putation between lines 10-20. First, at lines 10 and 11, the analysis
filters out expressions whose referencing relations to the trackedlocation no longer hold after the update. For instance, the filtered
set e-n includes from e- only those expressions e that meet one ofthe following two conditions:

* S[[e]]v(ae, r): the value of e is stable with respect to the updatedregion

r. In that case, e has the same value before and after theassignment, so it remains in

e-;* S

[[e]]l(ae, r) ^ ~b1: the location of e is stable with respect to
r and the assigned value misses the tracked location (i.e., b1 =false). Hence, the location of

e is the same before and afterthe assignment, but its value may or may not change. If the

value doesn't change, e will not reference the tracked locationafter the assignment because it didn't before (

e 2 e-). If thevalue changes, the location gets overwritten with a value that

still doesn't reference the tracked location (as indicated by b1 =false). Hence, the analysis can conclude that in either case

e willnot reference the tracked location and can safely keep
e in e-n .

At lines 13 and 14, the analysis tries to add the left-hand sideexpression

e0 to the hit or miss set. It uses a similar reasoning asabove to determine that

e0 is a hit (or miss) expression only if itis location-stable and the written value hits (or misses) the tracked

location. At lines 16-18, the analysis derives new expressions in
e+n and e-n by substituting occurrences of *e1 with *e0 in expres-sions that do not contain address-of subexpressions. The set

E0p inthis figure represents all program expression that don't contain the

address-of operator. Once again, substitutions are safe only whencertain stability conditions are met, in this case that

e0 and e1 areboth location-stable.

At line 20, the analysis discards from the miss set all those ex-pressions whose referencing relations can be inferred by the decision function using region information alone. This allows the anal-ysis to keep smaller miss sets without losing precision. At the end,
assign produces one configuration for each index in Si. We use thefollowing notation: if

S is a set of indices and h a secondary value,

then (S, h) = *i 2 I . if (i 2 S) then h else ?.

assign(e0, e1, ae, i, e+, e-, b0, b1) :

1 r = L[[e0]](ae)
2 if (b0 ^ ~b1) then
3 if (i(r) <= k) then Si = { i[r 7! i(r) - 1] }
4 else Si = { i[r 7! k], i[r 7! 1] }
5 else if (~b0 ^ b1) then
6 if (i(r) < k) then Si = { i[r 7! i(r) + 1] }
7 else Si = { i[r 7! 1] }
8 else Si = { i }
9
10 e+n = {e 2 e+ | S[[e]]v(ae, r) . (S[[e]]l(ae, r) ^ b1)}
11 e-n = {e 2 e- | S[[e]]v(ae, r) . (S[[e]]l(ae, r) ^ ~b1)}
12
13 if (S[[e0]]l(ae, r) ^ b1) then e+n [ = {e0}
14 if (S[[e0]]l(ae, r) ^ ~b1) then e-n [ = {e0}
15
16 if (S[[e0]]l(ae, r) ^ S[[e1]]l(ae, r)) then
17 e+n [ = ( e+n [*e0/*e1] " E0p )
18 e-n [ = ( e-n [*e0/*e1] " E0p )
19
20 e-n = {e 2 e-n | 8i0 2 Si . i0(L[[e]]ae) = 0}
21

22 return (Si, (e+n , e-n ))

Figure 11: Helper function assign.

Note that bifurcation can produce up to four cases and each casemay yield up to two configurations. However, there can be at
most three resulting configurations after each assignment, since wemerge configurations with the same index, and the reference count
from the updated region can only increase by one, decrease by one,or remain unchanged. In the example from Section 2 the analysis of each statement and configuration produces either one or twoconfigurations.

Finally, transfer functions map configurations with a secondaryvalue of ? to bottom abstractions

a?. The same is true for all ofthe other transfer functions in the algorithm.

5.2.4 Analysis of Malloc and Free

Figure 12 shows the analysis of dynamic allocation and deallo-cation statements. The transfer function

[[e  malloc]] works asfollows. First, the effect of the allocation is equivalent to that of a

nullification [[e  null]] because the tracked location is guaranteedto be distinct from the fresh location returned by malloc (even if it
happens to be allocated at the same site). Second, since the con-tents of the fresh location are not initialized, its fields become miss
expressions provided that e is location-stable.The generating function

[[e  malloc]]gen yields a configuration
(i, c) for the newly created location such that the index i recordsa reference count of 1 from the region of

e and 0 from all otherregions. The secondary value
h records e as a hit expression, andadds field expressions to the miss set if

e is stable.Finally, the analysis models the transfer function for deallocation

statements [[free(e)]] as a sequence of assignments that nullify eachfield of the deallocated structure. This ensures that the analysis
counts references only from valid, allocated locations.

5.2.5 Conditional Branches

The analysis extracts useful information from test conditions inif and while statements. On the branch where the tested expression

[[e  malloc]](ae, c) :

a = [[e  null]](ae, c)if

(S[[e]]l(ae, L[[e]](ae))) then

e-n = {(*e).f | f 2 F } " Ep
a = {(i, (e+, e- [ e-n )) | a i = (e+, e-)}return

a

[[e  malloc]]gen(ae) :

r = L[[e]](ae)
i = *r0 . if (r0 = r) then 1 else 0
e- = {(*e).f | f 2 F } " Epif

(S[[e]]l(ae, r)) then h = {{e}, e-}else

h = {;, ;}return
(i, h)

[[free(e)]](ae, c) :

a = [[t  *e]](ae, c) (t fresh)
a = t{i2I|ai6=?}[[t.f1  null]](ae, (i, ai))
. . .
a = t{i2I|ai6=?}[[t.fm  null]](ae, (i, ai))
a = t{i2I|ai6=?}[[t  null]](ae, (i, ai))return

a

Figure 12: Analysis of malloc and free.

e is null, the analysis determines that e misses the tracked location.To take advantage of this information, the analysis invokes the decision function D[[e]](ae, c). If the returned value is "?", then theanalysis adds

e to the miss set e-; if the returned value is "+", thenthe configuration is inconsistent with the actual state of the program

and the analysis reduces the secondary value to ?.The latter case occurs in the example from Section 2, where the
condition x != null allows the analysis to filter out the config-uration X

1 after the while loop.

5.3 Formal Framework

This section summarizes the formal results for the intra-proceduralanalysis. The proofs for all of the theorems below are available in

a companion technical report [12]. The first two theorems providecorrectness and termination guarantees for the worklist algorithm.

THEOREM 1 (WORKLIST CORRECTNESS). If transfer func-tions map each configuration with ? secondary value to

a?, thenthe worklist algorithm from Figure 9 yields the least fixed point of

the system of dataflow equations from Figure 8.

THEOREM 2 (MONOTONICITY). The transfer functions [[s]]for assignments, malloc, and free are monotonic in the secondary

value: if h v h0, then [[s]](ae, (i, h)) v [[s]](ae, (i, h0)) for all s, i, ae.

COROLLARY 1 (TERMINATION). The worklist algorithm fromFigure 9 is guaranteed to terminate.

We next give soundness conditions and results. Given an abstractstore

ae = (aev, aer, aef) and a concrete store oe = (oev, oel, oef ), wesay that a region partial map

ff : L * R is (oe, ae)-consistent if:range
(ff) ` dom(aer); ff(oev(x)) = aev(x), 8x 2 V ; aer(ff(l)) =
ff(oel(l)); and aef(ff(l), f) = ff(oef (l, f)) for all the locations l andfields

f where ff and oe are defined. The definitions below givesoundness conditions for our abstractions. We denote by |

S|k thecardinality of a set
S if it is less or equal to k, and 1 otherwise.

DEFINITION 1 (REGION ABSTRACTION SOUNDNESS). A re-gion abstraction, consisting of abstract stores for procedures and

mappings for call sites, is sound if for each activation of each pro-cedure

p there exists a region mapping ffp : L * Rp such that:*

p accesses only locations in dom(ffp);*
for each concrete store oe that occurs during the execution of p,
ffp is (oe, aep)-consistent;*

for each call site cs in p that invokes q, if oep is the store before(or after) the call and

oeq is the store at the entry (or exit) of q,then
ffp(l) = ucs(ffq(l)), 8l 2 Loeq " dom(ffq).

DEFINITION 2 (SHAPE ABSTRACTION SOUNDNESS). Let aebe a sound region store for an activation of procedure

p, and let ffbe the corresponding region mapping for that activation of

p. Let Rbe the regions of
p, and oe a concrete store during the execution of p.Denote by
Lv = {l|(l, f) 2 domf (oe)}"dom(ff) the set of of validfirst-field locations. Then

c = (i, (e+, e-)) safely approximates
l 2 Lv, written c ssoe,ae l, if:* 8

r 2 R . i(r) = | {l0 | ff(l0) = r ^ oe(l0) = l} |k* 8
e 2 e+ . he, oei !v v ) v = l* 8
e 2 e- . he, oei !v v ) v 6= l

A shape abstraction a 2 A safely approximates oe, written a ssae oe,if : 8

l 2 Lv . 9i 2 I . (i, ai) ssoe,ae l.

The soundness theorem states that shape analysis is sound aslong as the underlying region abstraction is sound.

THEOREM 3 (ANALYSIS SOUNDNESS). Let s be a statementin procedure

p. Consider two concrete stores oe and oe0, a soundregion store
ae for p, and a shape abstraction a 2 A. If hs, oei ! oe0and
a ssae oe, then:* \Lambda 

i2I[[s]](ae, (i, ai)) ssae oe0, if s is not a malloc; and*
([[s]]gen(ae) t \Lambda  i2I[[s]](ae, (i, ai))) ssae oe0, if s is a malloc.

5.4 Inter-Procedural Analysis

We formulate the inter-procedural algorithm as a context-sensitiveanalysis that distinguishes between different calling contexts of the

same procedure. Again, we take advantage of our abstraction anddefine procedure contexts to be individual configurations, not entire
heap abstractions.The result for an input configuration context is a set of corresponding output configurations at the end of the procedure. If weconsider a graph model (such as the one in Figure 5) that describes
how the state of the tracked location changes during execution, wecan express the input-ouput relationships for procedure contexts
as reachability relations: the outputs are those exit configurationsthat are reachable from the input configuration (the input context).
However, we do not need to build the configuration graph explic-itly; instead, we tag configurations with the entry index that they
originated from. This separates out configurations that originatedfrom different entries, allowing the analysis to quickly determine
both the output configurations for a given input, and the input con-figuration for a given output. Formally, we extend the index domain
in the analysis with the index at entry:

Index values: (ic, ie) 2 Ip = I * I
The entry index ie has no bearing on the intra-procedural trans-fer functions - they simply preserve this value, and operate on the

current index ic.The analysis at procedure calls must account for the assignment
of actuals to formals and for the change of analysis domain be-tween the caller and the callee. For this, the analysis uses two

For all se 2 Sentry, sc 2 Scall, i 2 Ip :

[IN] :Res

(*se)i w \Lambda 

i0 2 Iptgt
(sc) = fn(se)

([[sc]]in(ae, usc, (i0, Res(*sc)i0)))i

[OUT]Res(s

c*)i = \Lambda 

i0,i002Ip([[s

c]]out(ae, usc ,(i0, Res(*sc)i0),

(i00, Res(sx*)i00)))i
where sx = exit(tgt(sc))

Figure 13: Additional inter-procedural dataflow equations.

WORKLIST(DataflowInfo a0)15

...16 while

(W is not empty)17 remove some

(s, i) from W18 if
s 2 Scall then19 let

se = entry(tgt(s)), sx = exit(tgt(s))20 Res

(*se) t = [[s]]in(ae, us, Res(*s, i))21 for each

i0 s.th. Res(*se)i0 has changed22
W [ = {(se, i0)}23 for each

i0 s.th. Res(sx*)i0 6= ?24 Res
(s*) t =25
[[s]]out(ae, us, Res(*s, i), Res(*sx, i0))26 else if
s 2 Sexit then27 for
sc, i0 s.th. tgt(sc) = fn(s), Res(*sc)i0 6= ?28 Res

(sc*) t =29
[[sc]]out(ae, usc , Res(*sc, i0), Res(*s, i))30 else

31 Res(s*) t = [[s]](ae, Res(*s, i))32
33 for each s0, i0 s.th. Res(s0*)i0 has changed34 for

s00 2 succ(s0)35 Res

(*s00)i0 t = Res(s0*)i036
W [ = {(s00, i0)}

Figure 14: Inter-procedural worklist algorithm

transfer functions: an input function [[s]]in(ae, us, c) 2 A whichtakes a caller configuration

c (before the call) and produces the setof configurations at the entry point in the callee; and an output function [[s]]out(ae, us, c, c0) 2 A which takes an exit configuration c0 atthe end of the procedure, along with the caller configuration

c thatidentifies the calling context, to produce a set of caller configurations after the call. Both functions require the region store ae for thecurrent procedure and the region mapping

us at the call site wherethe information must be propagated.

We express the inter-procedural analysis using a set of dataflowequations that augments the intra-procedural equations from Figure 8 with the two additional equations from Figure 13. We usethe following notations: fn

(s) 2 P is the procedure that state-ment
s belongs to; tgt(sc) 2 P is the target procedure of a callstatement

sc; Scall is the set of call sites in the program; andentry
(p) 2 Sentry and exit(p) 2 Sexit are the entry and exitstatements of procedure

p, respectively. Equation [IN] performsthe transfer from the caller to the callee; and [O

UT] transfers theanalysis back to the caller. Figure 14 shows the main loop of the

inter-procedural worklist algorithm; the remainder of the algorithmis unchanged. The algorithm propagates output configurations to
the callers when it encounters new exit configurations in the callee,or when it discovers new input contexts in the caller.

[[call q(e1, .., en)]]in(ae, u, (i, h)) :

a = [[p1  e1]] . . . [[pn  en]](ae, {(i, h)})return \Lambda 

{i | a i6=?} Sin(ae, u, (i, a i))

where Sin(ae, u, ((ic, ie), (e+, e-))) :

e+q = {e 2 e+ | 8r 2 range(u) . S[[e]]v(ae, r))}
e-q = {e 2 e- | 8r 2 range(u) . S[[e]]v(ae, r))}
ieq = *r 2 Rq . ic(u r)return

((ieq, ieq), (e+ - e+q , e- - e-q ))

[[call q(e1, .., en)]]out(ae, u, ((ic, ie), h), ((icx, iex), hx)) :let

sc = call q(e1, .., en)if
[[sc]]in(ae, u, ((ic, ie), h))(iex, iex) = ? thenreturn

*i.?let
(e+, e-) = hlet
(e+x , e-x ) = hx
e+q = {e 2 e+ | 8r 2 range(u) . S[[e]]v(ae, r))}
e-q = {e 2 e- | 8r 2 range(u) . S[[e]]v(ae, r))}
icq = *r 2 Rq . if (r 62 range(u)) then ic(r)else

icx(u-1(r))return
((icq, ie), (e+x [ e+q , e-x [ e-q ))

Figure 15: Inter-procedural transfer functions.

Figure 15 shows the input and output transfer functions. Theentry transfer function accomplishes two things. First, it performs
the assignments of actual to formal arguments, which may gener-ate new references to the tracked location. Second, it adjusts the
regions of existing references according to the call site map u. Ref-erences whose regions are not in the range of

u are not visible bythe callee and are discarded by the slicing function

Sin. The exittransfer function performs the reversed tasks. First, it accounts for

context-sensitivity using the if statement at the beginning: it checksif the exit configuration in the caller originates from the input context ((ic, ie), h) before the call. If so, it restores the hit and missexpressions discarded at entry and adjusts the region counts.

6. EXTENSIONS

We present two extensions: incremental computation of shapes,and detection of memory errors.

6.1 On-Demand and Incremental Analyses

The goal of a demand-driven analysis is to analyze a selectedset of dynamic structures in the program, created at a one or a few

allocation sites. In our framework, this can be achieved with mini-mal effort: we just apply the dataflow equation [A

LLOC] from Fig-ure 8 to the selected allocation sites. The effect is that the dataflow

information gets seeded just at those sites, and the worklist algo-rithm will automatically propagate that information through the
program. In particular, the inter-procedural analysis will propagateshape information from procedures that contain these allocations
out to their callers.Our analysis framework also enables the incremental computation of shapes. To explore new allocation sites, we seed thedataflow information at the new sites, initialize the worklist to contain successors of those allocations, and then run the worklist algo-rithm. Key to the incremental computation is that our abstraction
based on configurations allows the analysis to reuse results frompreviously analyzed allocation sites. This is possible both at the

intra-procedural level, when the new configurations match exist-ing configurations at particular program points; and at the interprocedural level, when new calling contexts match existing con-texts.

6.2 Memory Error Detection

We extend our analysis algorithm to enable the static detection ofmemory errors such as memory accessed through dangling pointers, memory leaks, or multiple frees. To detect such errors, weenrich the index with a flag indicating whether the tracked cell has
been freed:

Index values: if 2 If = {true, false} * I
Since this information is in the index, for any configuration weknow precisely whether or not the cell has been freed. Most of

the transfer functions leave this flag unchanged; and since mergingconfigurations does not combine different index values (as before),
there is no merging of flags. Only two more changes are requiredin the analysis. First, after the initial allocation this flag is false:

[[e  malloc]]genf (ae) = ((false, ia), ha)
Second, we must change the transfer function for free statements,since the allocation state of the tracked cell may change at these

points. We express the modified transfer function for free usingthe original one, which preserves the allocation flag, and using the
decision function to determine whether the freed location is the onebeing tracked or not:

[[free(e)]]f (ae, ((f, i), h)) = case (D[[e]](ae, c)) of"-" )

[[free(e)]] (ae, ((f, i), h))"
+" ) [[free(e)]] (ae, ((true, i), h))"

? " ) [[free(e)]] (ae, ((f, i), h)) t

[[free(e)]] (ae, ((true, i), h))

With these additions, the analysis can proceed to detect errors.To identify memory leaks, it checks if there are no incoming references to a cell, but the cell was never freed. While a configurationwith no incoming references means there are no pointers to the cell
from regions that are in scope, this does not mean that functionsfurther up the call stack do not still have pointers to the cell. To
be sure that none of these functions have pointers to the trackedcell, the cell must not have been allocated at entry to the function.
We classify memory leaks as configurations ((false, *r.0), h) thatare not reachable from the boundary configurations in

a0. How-ever, leak detection suffers from the standard problem of reference

counting, that it cannot detect leaked cycles.To detect double frees, the analysis performs the following check.
For any statement s = free(e), if ((true, i), h) 2 Res(*s) andD

[[e]](ae, (i, h)) 6= "-", a possible double free has occurred. Andto identify accesses to deallocated memory the analysis checks the

following. For any statement s, define Es as the set of expressionsthat are dereferenced by

s: {e | *e appears in s}. If ((true, i), h) 2Res
(*s) and D[[e]](ae, (i, h)) 6= "-" for any e 2 Es, a possible ref-erence to deallocated memory has occurred.

7. LIMITATIONS

The analysis algorithm presented in this paper has the followinglimitations:

* Spurious configurations. The analysis may generate spuriousconfigurations, but still determine the correct final shape in

spite of this imprecision. In the example from Figure 5, con-figurations Y

1T1L1 and X1Y1L1 are spurious. Ruling such

cases requires more complex decision functions D[[*]].

* Complex structural invariants. For manipulations of linkedstructures with complex invariants, our algorithm may not

identify the correct shape. For example, our algorithm can-not determine that shapes are preserved for operations on
doubly-linked lists, because our configurations cannot recordthe doubly-linked list invariant.

* Robustness. The analysis may not identify the correct shapewhen the same program is written in a different manner. In

the example program from Section 2, if we replace state-ment

x=t->n with x=x->n, the algorithm will not verifythe shape property. This is because the analysis does not

know that x=t at that point, and cannot add t->n to the hitor miss set. To address this issue, the analysis needs expression equality information.

* Worst-case exponential blowup. Similar to most of the exist-ing shape abstractions, the size of our abstraction is exponential in the worst case. In practice, we have seen cases wherea blowup in the number of configuration occurs, but only because of the imprecision in the analysis, e.g., for traversals ofdoubly-linked lists with multiple pointers.

However, we believe that these are limitations of the current al-gorithm, but not of the framework with local reasoning. We anticipate these issues can be addressed by extending the abstraction andthe algorithm, while still reasoning about one single location. For
instance, the decision function could be improved to rule out spuri-ous configurations; an expression equality analysis could be added
as an underlying analysis in the vertical decomposition to addressthe robustness issue; and configurations could be extended with
reachability information and structural invariants about the trackedlocation. We chose to keep the algorithm in this paper simpler and
cleaner to emphasize the concept and to make it amenable to for-mal presentation. These issues will be the subject of future work.

8. RESULTS

We have implemented all of the algorithms presented in the pa-per, including the points-to analysis, shape analysis, and extensions

for detecting memory errors, using the SUIF Compiler infrastruc-ture [1]. We have extended the analysis to handle various C constructs, such as arrays, pointer arithmetic, casts, unions, and others.The points-to analysis makes the usual assumptions, e.g., that array
accesses and pointer arithmetic do not violate the array or structurebounds. Our shape analysis is guaranteed to be sound as long as the
underlying region abstraction computed by the points-to analysis issound. We have tested our prototype implementation on several
small examples and on a few larger C programs. To experimentwith the demand-driven and incremental approach, our system analyzes one allocation site at a time, reusing existing results as newsites are explored. The experiments were conducted on a 1.2GHz
Athlon machine with 256MB of memory, running Linux RedHat 9.
8.1 Core List Manipulations

We have tested the analysis on the following programs that ma-nipulate singly-linked lists:

* insert : inserts an element into a list;*

delete : deletes an element from a list;*
splice : list splicing program from Section 2;*
reverse : iterative list reversal program from [8];*
quicksort : recursive quicksort program from [5];*
insertion sort : iterative insertion sort.

The analysis has successfully determined that all of these pro-grams preserve acyclic list shape. It has also determined that none
of the programs leak memory or access deallocated memory. Theanalysis took less than 1 second for these programs altogether.

8.2 Experience on Larger Programs

We have also used the analysis to detect memory leaks in por-tions of three popular C programs: OpenSSH, OpenSSL, and BinUtils. The results of these experiments are shown in Figure 16. Intotal, we analyzed 184 dynamic allocation sites in about 70 KLOC,
taking less than two minutes. This produced 97 warnings, 38 ofwhich were actual memory leaks (a few warnings were for double
frees and accesses to deallocated memory, all of which were false).Hence, more than one warning out of three was an actual error.
Given that the tool uses sound analysis techniques, we view this asa low rate of false positives.

The error reporting is based on error traces. An error trace repre-sents an execution trace through the program that leads to an error.
The tool produces these traces by following the program executionbackwards through the configuration graph, from the error point
to the allocation site; we find the traces to be extremely helpful inidentifying whether a warning is legitimate. Furthermore, the tool
clusters error traces on a per-region basis: all of traces in one clus-ter refer to errors about locations in the same region. The tool then
reports one warning per cluster. We find this clustering techniquevery useful in identifying distinct bugs, since all of the errors in
one cluster essentially refer to the same programming error. Forour programs, the majority of clusters have a single trace; a few
clusters have less than 10 traces; and one cluster has more than 100error traces.

As mentioned above, all of the detected errors were memoryleaks. Most of them were caused as functions failed to clean up
local resources on abnormal return paths. For instance, some func-tions in SSH do not reclaim memory when a connection fails. In
a few cases, however, functions failed to release resources on allreturn paths.

The examination of false warnings indicated that they were dueto several sources of imprecision. Many of the errors were due
to lack of path information that could have been used to rule outthe error trace. For instance, we are unable to track the correlation between the references to the tracked cell and the values ofvarious error codes in the program. False warnings were also due
to the context-insensitive treatment of global variables in pointeranalysis. For instance, one of the programs stores references to
several buffers (stdin, stout, and stderr) into global variables. Sincethese references are being passed as the same argument to a function, pointer analysis merges them together. This imprecision in thepointer analysis then impacts the precision of shape analysis. The
above-mentioned cluster with more than 100 error traces was dueto this kind of imprecision.

The tool was most affected when the analysis could not accu-rately identify shapes, as in the case of doubly-linked lists or for
heap manipulations where it lacked variable equality information,as mentioned in Section 7. This lead to a blowup in the number of
feasible configurations and the analysis failed to complete in suchcases. However, we are able to isolate these situations using incremental analysis: we explored one allocation site at a time andintroduced a cutoff for the amount of exploration to be performed
from any given allocation site (by limiting the size of the work-list). Figure 16 indicates that the analysis did not complete for 3
allocation sites in SSL and 10 sites in Binutils due to this kind ofimprecision. They represent about 10% of the allocation sites in
these programs.

Program OpenSSH OpenSSL BinUtils
Size (LOC) 18.6 K 25.6 K 24.4 K
Alloc. Sites 41 31 125Analyzed 41 28 115

Total Time (sec) 45s 22s 44sRegion Analysis 16s 13s 6s
Shape Analysis 29s 9s 38sReported 26 13 58
Real bugs 10 4 24

Figure 16: Results for Larger Programs

Overall, we consider that these results are encouraging. Theysuggest that the local reasoning approach to shape analysis is both
sufficiently lightweight to scale to larger programs, and sufficientlyprecise to yield a low rate of false warnings.

9. RELATED WORK

There has been significant work in the past decade in the areaof shape analysis [34]. Early approaches to shape analysis have

proposed the use of path matrices and other matrices that captureheap reachability information [18, 17, 11]. In particular, Ghiya and
Hendren [11] present an inter-procedural shape analysis that usesboolean matrices to identify trees, dags, or cyclic graphs. Their
implemented system has been successful at analyzing programs ofup to 3 KLOC.

Sagiv et. al. present an abstract interpretation that uses shapegraphs to model heap structures [29]. They introduce materialization and summarization as key techniques for the precise compu-tation of shapes. Role analysis [21] uses shape graph abstractions
to check program specifications for heap shapes and heap effects.Experiments have not been presented for these analyses.

In subsequent work, Sagiv et. al. have proposed a parametricshape analysis framework based on 3-valued logic [31]. They encode shape graphs as 3-valued structures and use a focus opera-tion to accurately compute shapes when the analysis encounters
unknown (1/2) logic values. Our bifurcation technique is similarto their focus operation, but applies to a different analysis abstraction. The 3-valued logic approach has been implemented in theTVLA system [23] and has been successful at verifying correctness
and safety properties for complex heap manipulations [22, 8, 35].Work on inter-procedural analysis in TVLA has explored modeling
the program stack using 3-valued structures [28] and expressing thefunction input-output relations for individual heap cells [20]. These
analyses seem expensive in practice; for instance, the analysis of arecursive procedure that deletes an element from a list takes more
than 200 seconds [20].Yahav and Ramalingam [36] have proposed heterogeneous heap
abstractions as a means of speeding up analyses in TVLA. Theirframework constructs a heap abstraction that models different parts
of the heap with different degrees of precision, and keeps preciseinformation just for the relevant portion of the heap. In contrast,
our approach is homogeneous, precisely abstracts the entire heap,but models each heap location separately. Their approach enabled
TVLA to analyze programs of up to 1.3 KLOC.Reynolds, O'Hearn, and others propose Separation logic [27,
26] and BI (the logic of Bunched Implications) [19] as extensionsof Hoare logic that permit reasoning about mutable linked structures. They provide features (such as the separating conjunctionand implication, or the frame rule) that make it easier to express
correctness proofs for pointer-based programs. Compared to static

analyses, these logics provide techniques for verifying program cor-rectness; analyses, on the other hand, provide techniques for automatically inferring points-to properties. A significant challenge forstatic analysis is the automatic synthesis of loop invariants. Generally speaking, inferring points-to properties is more difficult thanverifying them. Therefore, although separation logic works well
for correctness proofs with local reasoning, it is not clear whetheran analysis can use local reasoning alone. In our system, we push
global reasoning down to the pointer analysis component; and thatenables us to use local reasoning at the shape analysis level. Furthermore, we use a finite shape abstraction that localizes the rea-soning to one single heap location.

Demand-driven and incremental algorithm have been proposedin the area of pointer analysis. Heintze and Tardieu [16] describe a
technique to answer aliasing queries by exploring the minimal setof points-to constraints that yields the desired answer. Vivien and
Rinard [33] present an incremental points-to analysis that graduallyexplores more code to refine the points-to information. Our notion
of demand-driven and incremental analysis is different - it refers tothe number of explored allocation sites.

Heine and Lam present Clouseau [15], a static leak detector toolfor C and C++ programs. They use a notion of pointer ownership
to describe the references responsible for freeing heap cells, andformulate the analysis as an ownership constraint system. Their
approach is able to detect leaks and double frees, but cannot de-tect accesses through dangling pointers. Intuitively, that is because
their system tracks owning pointers (and doesn't have informationabout targets of non-owning pointers), while ours tracks memory
locations and their allocation state. The experiments indicate thatour shape analysis approach yields more precise results than the
pointer ownership approach. In particular, Clouseau reports a largenumber of warnings when the program places pointers in aggregate
structures, or when it manipulates multi-level pointers.Das et. al. present ESP [6], a path-sensitive tool for verifying
state machine properties. ESP uses property simulation, a tech-nique that captures path information but avoids the exponential cost
of a full path-sensitive analysis. We borrow from ESP the notionof index values in the abstraction to model critical information that
the analysis must not merge at join points. However, ESP is de-signed to analyze temporal properties for non-recursive structures,
not shapes in recursive heap structures. DeLine and Fahndrich pro-pose Vault [7], an extension of C where programmers can specify
resource management protocols that a compiler can enforce. Thesystem can ensure, for instance, that the program doesn't leak resources. But it cannot precisely track unbounded numbers of re-sources such as those that arise in recursive structures.

The SLAM Project [2, 3] uses predicate abstraction refinementalong with model checking techniques to check temporal safety
properties of C programs. Necula et al. propose CCured [25], aan analysis and transformation system for C programs that uses
type inference to identify type-safe pointers, and instrument the re-maining pointers with run-time checks. However, CCured does not
address the memory deallocation problem and uses a garbage col-lector instead.

Other existing error-detection tools, such as Metal [9] and Pre-fix[4], use unsound techniques to limit the number of false positives
or to avoid fixed-point computations.Finally, dynamic memory error detection tools such as Purify [13]
or SWAT [14] instrument the program to detect errors at run-time.They test only one run of the program and may miss errors that are
not exposed in that run; in particular, they may miss errors in rarelyexecuted code fragments.

10. CONCLUSIONS

We have presented a new approach to shape analysis where thecompiler uses local reasoning about the state of one single heap

location, as opposed to global reasoning about entire heap abstrac-tions. We have showed that this approach makes it easier to develop
efficient intra-procedural analysis algorithms, context-sensitive inter-procedural algorithms, demand-driven and incremental analyses,
and can enable the detection of memory errors with low false pos-itive rates. We believe that the proposed approach brings shape
analysis a step closer to being successful for real-world programs.

11. REFERENCES[1] S. Amarasinghe, J. Anderson, M. Lam, and C. Tseng. The SUIF

compiler for scalable parallel machines. In Proceedings of the EighthSIAM Conference on Parallel Processing for Scientific Computing,

San Francisco, CA, February 1995.
[2] T. Ball, R. Majumdar, T. Millstein, and S. Rajamani. Automaticpredicate abstraction of C programs. In Proceedings of the SIGPLAN

'01 Conference on Program Language Design and Implementation,Snowbird, UT, June 2001.
[3] T. Ball and S. Rajamani. The SLAM project: Debugging systemsoftware via static analysis. In Proceedings of the 29th Annual ACM

Symposium on the Principles of Programming Languages, Portland,OR, January 2002.
[4] W. Bush, J. Pincus, and D. Sielaff. A static analyzer for findingdynamic programming errors. Software - Practice and Experience,

30(7):775-802, August 2000.
[5] S. Chong and R. Rugina. Static analysis of accessed regions inrecursive data structures. In Proceedings of the 10th International

Static Analysis Symposium, San Diego, CA, June 2003.
[6] M. Das, S. Lerner, and M. Seigle. ESP: Path-sensitive programverification in polynomial time. In Proceedings of the SIGPLAN '02

Conference on Program Language Design and Implementation,Berlin, Germany, June 2002.
[7] R. DeLine and M. Fahndrich. Enforcing high-level protocols inlow-level software. In Proceedings of the SIGPLAN '01 Conference

on Program Language Design and Implementation, Snowbird, UT,June 2001.
[8] N. Dor, M. Rodeh, and M. Sagiv. Checking cleanness in linked lists.In Proceedings of the 7th International Static Analysis Symposium,

Santa Barbara, CA, July 2000.
[9] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking system rulesusing system-specific, programmer-written compiler extensions. In

Proceedings of the SIGPLAN '02 Conference on Program LanguageDesign and Implementation, Berlin, Germany, June 2002.
[10] M. Fahndrich, J. Rehof, and M. Das. Scalable context-sensitive flowanalysis using instantiation constraints. In Proceedings of the

SIGPLAN '00 Conference on Program Language Design andImplementation, Vancouver, Canada, June 2000.
[11] R. Ghiya and L. Hendren. Is is a tree, a DAG or a cyclic graph? ashape analysis for heap-directed pointers in C. In Proceedings of the

23rd Annual ACM Symposium on the Principles of ProgrammingLanguages, St. Petersburg Beach, FL, January 1996.
[12] B. Hackett and R. Rugina. Region-based shape analysis with trackedlocations. Technical Report TR2004-1968, Cornell University,

October 2004.
[13] R. Hastings and B. Joyce. Purify: Fast detection of memory leaks andaccess errors. In Proceedings of the 1992 Winter Usenix Conference,

January 1992.
[14] M. Hauswirth and T. Chilimbi. Low-overhead memory leak detectionusing adaptive statistical profiling. In Proceedings of the 11th

International Conference on Architectural Support for ProgrammingLanguages and Operating Systems, Boston, MA, October 2004.
[15] D. Heine and M. Lam. A practical flow-sensitive andcontext-sensitive C and C++ memory leak detector. In Proceedings of

the SIGPLAN '03 Conference on Program Language Design andImplementation, San Diego, CA, June 2003.
[16] N. Heintze and O. Tardieu. Demand-driven pointer analysis. InProceedings of the SIGPLAN '01 Conference on Program Language

Design and Implementation, Snowbird, UT, June 2001.

[17] L. Hendren, J. Hummel, and A. Nicolau. A general data dependencetest for dynamic, pointer-based data structures. In Proceedings of the

SIGPLAN '94 Conference on Program Language Design andImplementation, Orlando, FL, June 1994.
[18] L. Hendren and A. Nicolau. Parallelizing programs with recursivedata structures. IEEE Transactions on Parallel and Distributed

Systems, 1(1):35-47, January 1990.
[19] S. Ishtiaq and P. O'Hearn. BI as an assertion language for mutabledata structures. In Proceedings of the 28th Annual ACM Symposium

on the Principles of Programming Languages, London, UK, January2001.
[20] B. Jeannet, A. Loginov, T. Reps, and M. Sagiv. A relational approachto interprocedural shape analysis. In Proceedings of the 11th

International Static Analysis Symposium, Verona, Italy, August 2004.
[21] V. Kuncak, P. Lam, and M. Rinard. Role analysis. In Proceedings ofthe 29th Annual ACM Symposium on the Principles of Programming

Languages, Portland, OR, January 2002.
[22] T. Lev-ami, T. Reps, M. Sagiv, and R. Wilhelm. Putting staticanalysis to work for verification: A case study. In 2000 International

Symposium on Software Testing and Analysis, August 2000.
[23] T. Lev-Ami and M. Sagiv. TVLA: A system for implementing staticanalyses. In Proceedings of the 7th International Static Analysis

Symposium, Santa Barbara, CA, July 2000.
[24] D. Liang and M.J. Harrold. Efficient points-to analysis forwhole-program analysis. In Proceedings of the ACM SIGSOFT '99

Symposium on the Foundations of Software Engineering,Toulouse,France, September 1999.
[25] G. Necula, S. McPeak, and W. Weimer. CCured: type-saferetrofitting of legacy code. In Proceedings of the 29th Annual ACM

Symposium on the Principles of Programming Languages, Portland,OR, January 2002.
[26] P. O'Hearn, H. Yang, and J. Reynolds. Separation and informationhiding. In Proceedings of the 31th Annual ACM Symposium on the

Principles of Programming Languages, Venice, Italy, January 2004.
[27] J. Reynolds. Separation logic: A logic for shared mutable datastructures. In Proceedings of the Seventeenth Annual IEEE

Symposium on Logic in Computer Science, Copenhagen, Denmark,July 2002.
[28] N. Rinetzky and M. Sagiv. Interprocedural shape analysis forrecursive programs. In Proceedings of the 2001 International

Conference on Compiler Construction, Genova, Italy, April 2001.
[29] M. Sagiv, T. Reps, and R. Wilhelm. Solving shape-analysis problemsin languages with destructive updating. ACM Transactions on

Programming Languages and Systems, 20(1):1-50, January 1998.
[30] M. Sagiv, T. Reps, and R. Wilhelm. Parametric shape analysis via3-valued logic. In Proceedings of the 26th Annual ACM Symposium

on the Principles of Programming Languages, San Antonio, TX,January 1999.
[31] M. Sagiv, T. Reps, and R. Wilhelm. Parametric shape analysis via3-valued logic. ACM Transactions on Programming Languages and

Systems, 24(3), May 2002.
[32] Bjarne Steensgaard. Points-to analysis in almost linear time. InProceedings of the 23rd Annual ACM Symposium on the Principles

of Programming Languages, St. Petersburg Beach, FL, January 1996.
[33] F. Vivien and M. Rinard. Incrementalized pointer and escapeanalysis. In Proceedings of the SIGPLAN '01 Conference on Program

Language Design and Implementation, Snowbird, UT, June 2001.
[34] R. Wilhelm, M. Sagiv, and T. Reps. Shape analysis. In Proceedingsof the 2000 International Conference on Compiler Construction,

Berlin, Germany, April 2000.
[35] E. Yahav. Verifying safety properties of concurrent Java programsusing 3-valued logic. In Proceedings of the 28th Annual ACM

Symposium on the Principles of Programming Languages, London,UK, January 2001.
[36] E. Yahav and G. Ramalingam. Verifying safety properties usingseparation and heterogeneous abstractions. In Proceedings of the

SIGPLAN '04 Conference on Program Language Design andImplementation, Washington, DC, June 2004.

APPENDIX
A. LANGUAGE SEMANTICS

The operational semantics of the simple language from Figure 7uses the following semantic domains:

locations: l 2 Lvalues:

v 2 L [ {null}stores:
oe = (oev, oel, oef ) 2 (V ! L)*

(L * (L [ {null}))*
((L * F ) * L)

The following rules describe the evaluation of expressions. Re-lation h

e, oei !l l evaluates e in store oe to the location l of e;and relation h

e, oei !v v evaluates e in store oe to the value vof
e. Given a concrete store oe = (oev, oel, oef ), we use the nota-tions: dom

v(oe) = dom(oev), doml(oe) = dom(oel), and domf (oe) =dom
(oef). The evaluation rules are as follows.

x 2 domv(oe)h
x, oei !l oe(x) h

e, oei !l l 2 doml(oe) oe(l) = l0h*

e, oei !l l0

he, oei !l l (l, f) 2 domf (oe)h

e.f, oei !l oe(l, f) h

e, oei !l l 2 doml(oe)h

e, oei !v oe(l)

he, oei !l lh
&e, oei !v l hnull, oei !v null

The evaluation relation for statements hs, oei !s oe0 indicatesthat the execution of statement

s in input store oe produces the store
oe0. The evaluation rules are as follows:h

e, oei !l l 2 doml(oe) {lf }f2F fresh
oe0 = oe[l 7! lf1][lf 7! null]f2F [(lf1 , f) 7! lf ]f2Fh

e  malloc, oei !s oe0

he, oei !v l 8f 2 F : (l, f) 2 domf (oe)
oe0 = (oe - {(l, f) 7! }f2F ) - {oe(l, f) 7! }f2Fh

free(e), oei !s oe0

he0, oei !l l 2 doml(oe) he1, oei !v vh

e0  e1, oei !s oe[l 7! u]

prog(f) = ((x1, .., xn), s) 8i = 1..n : hei, oei !v vih

s, oe[oe(xi) 7! vi]i=1..ni !s oe0h

call p(e1, .., en), oei !s oe0

hs0, oei !s oe00 hs1, oe00i !s oe0h

s0 ; s1, oei !s oe0

he, oei !v v = null hs0, oei !s oe0h

if (e) s0 else s1, oei !s oe0

he, oei !v v 6= null hs1, oei !s oe0h

if (e) s0 else s1, oei !s oe0

he, oei !v v = nullh
while (e) s, oei !s oe

he, oei !v v 6= nullh

s, oei !s oe00hwhile

(e) s, oe00i !s oe0h

while (e) s, oei !s oe0