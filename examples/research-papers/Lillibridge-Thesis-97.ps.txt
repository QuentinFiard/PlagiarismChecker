

Translucent Sums: A Foundation for

Higher-Order Module Systems

Mark Lillibridge

May, 1997
CMU-CS-97-122

School of Computer Science

Carnegie Mellon University

Pittsburgh, PA 15213

Submitted in partial fulfillment of the requirements

for the degree of Doctor of Philosophy.

Thesis Committee:
Robert Harper, Chair

Peter Lee
John Reynolds
Luca Cardelli, DEC SRC

Copyright cfl1997 Mark Lillibridge
This research was sponsored by the Air Force Materiel Command (AFMC) and the Defense Advanced Research Projects Agency (DARPA) under contract number, F19628-95-C-0050. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding
any copyright notation thereon.

The views and conclusions contained in this document are those of the author and should not be
interpreted as representing the official policies or endorsements, either expressed or implied, of the U.S.
Government.

Keywords: type theory, modularity, abstraction, sharing, functional programming,
lambda calculus, Standard ML, modules and interfaces, packages, first-class modules,
abstract data types.

Abstract
The ease of understanding, maintaining, and developing a large program depends crucially on how it is divided up into modules. The possible ways a program can be divided
are constrained by the available modular programming facilities ("module system") of
the programming language being used. Experience with the Standard-ML module system has shown the usefulness of functions mapping modules to modules and modules
with module subcomponents. For example, functions over modules permit abstract data
types (ADTs) to be parameterized by other ADTs, and submodules permit modules to
be organized hierarchically. Module systems with such facilities are called higher-order,
by analogy with higher-order functions.

Previous higher-order module systems can be classified as either opaque or transparent.
Opaque systems totally obscure information about the identity of type components of
modules, often resulting in overly abstract types. This loss of type identities precludes
most interesting uses of higher-order features. Transparent systems, on the other hand,
completely reveal type identities by inspecting module implementations, which subverts
data abstraction and prevents separate compilation.

In this dissertation, I describe a novel approach that avoids these problems based
on a new type-theoretic concept, the translucent sum. A translucent sum is a kind of
weak sum whose type can optionally specify the identity of its type components. Under
my approach type identities are not determined by inspecting module implementations,
permitting separate compilation. By default, module operations reveal the connections
between the types in their input and output modules. However, these connections can be
obscured using type coercion. This controlled visibility permits data abstraction where
desired without limiting the uses of higher-order features. My approach also allows
modules to be treated as first-class values, a potentially valuable feature.

In order to lay out the groundwork for my new approach to designing higher-order
module systems and to demonstrate its utility, I develop in complete detail a kernel
system using my approach. I establish formally the theoretical properties of the system,
including soundness even in the presence of side effects. I also show how the system may
be effectively type checked.

iv

To Donna Jean

vvi
Contents
Acknowledgements xiii
I Context 1
1 Introduction 3

1.1 Overview : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 3
1.2 Module Systems : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 4
1.3 Benefits of Higher-Order Module Systems : : : : : : : : : : : : : : : : : : 6
1.4 Example: B-Trees : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 8

2 Previous Approaches 11

2.1 The Opaque Approach : : : : : : : : : : : : : : : : : : : : : : : : : : : : 11
2.2 The Transparent Approach : : : : : : : : : : : : : : : : : : : : : : : : : : 13
2.3 Summary : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 15

3 My Approach 17

3.1 Module and Functor Boundaries : : : : : : : : : : : : : : : : : : : : : : : 17
3.2 Default Interfaces : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 18
3.3 Subtyping : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 19
3.4 The B-Tree Example : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 19
3.5 The Recipe : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 21
3.6 Translucent Sums : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 21
3.7 First-Class Values : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 22
3.8 Linking : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 23
3.9 Type-Sharing Specifications : : : : : : : : : : : : : : : : : : : : : : : : : 27
3.10 Summary : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 28

4 Technical Machinery 29

4.1 Dot Notation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 29

vii

viii CONTENTS

4.2 Creation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 31
4.3 Equality : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 33
4.4 Subtyping : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 35
4.5 The Phase Distinction : : : : : : : : : : : : : : : : : : : : : : : : : : : : 38
4.6 Selection and Application : : : : : : : : : : : : : : : : : : : : : : : : : : 40
4.7 The EVALUE rules : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 44

II The Kernel System 49
5 Overview 51

5.1 Higher Kinds : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 52
5.2 Previous Work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 54
5.3 Extended Interface Matching : : : : : : : : : : : : : : : : : : : : : : : : : 55
5.4 Unnamed Binary Sums : : : : : : : : : : : : : : : : : : : : : : : : : : : : 55
5.5 Reified Constructors : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 57
5.6 Rules and Restrictions : : : : : : : : : : : : : : : : : : : : : : : : : : : : 59
5.7 Notation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 60
5.8 System Summary : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 60

5.8.1 Module Constructs : : : : : : : : : : : : : : : : : : : : : : : : : : 62
5.8.2 References and Recursive Types : : : : : : : : : : : : : : : : : : : 63
5.8.3 Semantics : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 64
5.9 On the Nature of the Proofs : : : : : : : : : : : : : : : : : : : : : : : : : 64
5.10 Organization : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 65

6 Types: Setup 69

6.1 Kinds and Constructors : : : : : : : : : : : : : : : : : : : : : : : : : : : 69
6.2 Proof Strategy : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 72
6.3 The Type Rules : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 75
6.4 Place Lookup : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 78
6.5 Basic Propositions : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 81
6.6 Tagging : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 83
6.7 The Tagged System : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 85
6.8 Basic Tagged Propositions : : : : : : : : : : : : : : : : : : : : : : : : : : 87

7 Types: Confluence 93

7.1 Rewriting : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 93
7.2 The Proof Method : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 94
7.3 The Rewrite Relation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 96
7.4 Argument Kind Erasure : : : : : : : : : : : : : : : : : : : : : : : : : : : 102

CONTENTS ix

7.5 Kind Preservation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 107
7.6 Subject Reduction : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 115
7.7 Confluence : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 124
7.8 Equality : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 125

8 Types: Canonicalization 131

8.1 Normal Forms : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 131
8.2 The Method : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 133
8.3 fij-Normalization : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 135
8.4 Canonical Form : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 144
8.5 Assignment Reduction : : : : : : : : : : : : : : : : : : : : : : : : : : : : 148
8.6 Decidability : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 150

9 Types: Summary 163

9.1 Tag Removal : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 163
9.2 Stamping : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 167
9.3 System Correspondence : : : : : : : : : : : : : : : : : : : : : : : : : : : 173
9.4 Converted Results : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 177
9.5 Semi-Canonical Types : : : : : : : : : : : : : : : : : : : : : : : : : : : : 181
9.6 Strengthening : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 185
9.7 Alternatives : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 187

10 Subtyping 189

10.1 One-Step Subtyping : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 190
10.2 The Subtyping Relation : : : : : : : : : : : : : : : : : : : : : : : : : : : 192
10.3 Shapes : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 193
10.4 Replacement by a Subtype : : : : : : : : : : : : : : : : : : : : : : : : : : 197
10.5 A Semi-Decision Procedure : : : : : : : : : : : : : : : : : : : : : : : : : : 203
10.6 The Simple Type System : : : : : : : : : : : : : : : : : : : : : : : : : : : 207
10.7 Encoding Simple Judgments : : : : : : : : : : : : : : : : : : : : : : : : : 212
10.8 Problem Reduction : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 216
10.9 Undecidability : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 225

11 Soundness 233

11.1 The Terms : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 233
11.2 Self Validity : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 237
11.3 Self and Subtyping : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 241
11.4 Runtime States : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 249
11.5 Properties of Values : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 256
11.6 Value Substitution : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 260

x CONTENTS

11.7 Evaluation : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 266
12 Type Checking 275

12.1 Type-Checking Difficulties : : : : : : : : : : : : : : : : : : : : : : : : : : 275
12.2 The Inference System : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 276
12.3 Semi-Decidability : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 280

III Conclusions 285
13 Extensions 287

13.1 N-Ary Named Fields : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 287
13.2 Extended Interface Matching : : : : : : : : : : : : : : : : : : : : : : : : : 289
13.3 Transparent Value Declarations : : : : : : : : : : : : : : : : : : : : : : : 292
13.4 Kind Components : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 296
13.5 Recursion : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 297
13.6 Better Type Inference : : : : : : : : : : : : : : : : : : : : : : : : : : : : 300
13.7 Elaborations : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 300

13.7.1 SML-like Elaborations : : : : : : : : : : : : : : : : : : : : : : : : 301
13.7.2 Translucent-Sum Syntax : : : : : : : : : : : : : : : : : : : : : : : 301
13.7.3 Open and Include : : : : : : : : : : : : : : : : : : : : : : : : : : : 302
13.7.4 Leroy's With Notation : : : : : : : : : : : : : : : : : : : : : : : : 303
13.7.5 Separate Compilation : : : : : : : : : : : : : : : : : : : : : : : : : 304
13.8 Reformulations : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 304

14 Related Work 309

14.1 First-Order Module Systems : : : : : : : : : : : : : : : : : : : : : : : : : 309
14.2 Previous Higher-Order Module Systems : : : : : : : : : : : : : : : : : : : 310

14.2.1 Modula-3 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 311
14.2.2 Mesa and Cedar : : : : : : : : : : : : : : : : : : : : : : : : : : : : 312
14.2.3 Standard ML : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 312
14.2.4 Experimental Designs : : : : : : : : : : : : : : : : : : : : : : : : : 314
14.3 Manifest Types : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 315
14.4 Modules as Second-Class Values : : : : : : : : : : : : : : : : : : : : : : : 315
14.5 Other Follow-On Work : : : : : : : : : : : : : : : : : : : : : : : : : : : : 320

15 Conclusions 323

15.1 Contributions : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 323

15.1.1 Better Higher-Order Module Systems : : : : : : : : : : : : : : : : 323
15.1.2 Feasibility of My Approach : : : : : : : : : : : : : : : : : : : : : 324

15.1.3 Technical Contributions : : : : : : : : : : : : : : : : : : : : : : : 325
15.2 Future work : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 326

A Collected Kernel System Rules 327

A.1 The Kind and Constructor Level : : : : : : : : : : : : : : : : : : : : : : 327
A.2 The Term Level : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 333

Bibliography 337

xixii
Acknowledgements
I have many people to thank for helping me complete this dissertation. First, and foremost, of course, is my advisor, Robert Harper. I blame his unwavering high standards
for the overall quality of this work. Not content to ensure the technical quality, he also
encouraged me to write as clearly as possible; his recommendation of Lyn Dupre'e's book
Bugs in Writing was particularly helpful in this regard. I have learned a great deal from
Bob over the years and will miss the long technical arguments I had with him.

I also owe a large debt to the other members of my thesis committee: Peter Lee, John
Reynolds, and Luca Cardelli. They provided invaluable advice in a timely fashion. I
particularly want to thank them for letting me put off writing the introduction until the
very end. John Reynolds also deserves special mention for acting as my advisor during
my first year at CMU.

In addition to the people I have already mentioned, I have benefited from technical
discussions over the years with Mark Leone, Dave MacQueen, Greg Morrisett, Frank
Pfenning, Benjamin Pierce, Chris Stone, Doug Tygar, Dave Tarditi, and the rest of the
Pop and Fox groups at CMU. I want to thank Dana Scott for his key role in assembling
the strong group of programming-language researchers at CMU. I would also like to thank
Cleah Schlueter and Sharon Burks for providing non-technical help on more occasions
than I can count.

Thanks go to Andrew Appel, Olivier Danvy, Andrew Gordon, Nick Haines, Rustan
Leino, Xavier Leroy, Brian Milnes, John Mitchell, and Mads Tofte for providing feedback
on drafts of this work. I would like to thank the National Science Foundation (NSF) for
funding me for my first three years of graduate school via a fellowship. My new boss,
Roy Levin, at DEC SRC also deserves thanks for forcing me to work on finishing my
dissertation full time at SRC; without this motivation, I am certain the process of finishing my dissertation would have dragged on far longer due to the abundant distractions
available at SRC.

One of the most important influences on the quality of a graduate student's daily
life is his or her officemates. Fortunately, I have been blessed with a series of great
officemates: Eka Ginting, Mark Leone, Tom Kang, Darryl Kindred, Bill Niehaus, Lu Qi,
and John Greiner (honorary). Eka and Tom deserve special mention for their unflagging

xiii

efforts to distract me from my dissertation, and indeed, work of any kind. In the process,
Eka managed to teach me a lot about business, which I hope to put to good use someday.

Working on a Ph.D. dissertation can be a extremely frustrating and stressful experience. My primary stress release while working on my dissertation was to go ballroom
or swing dancing. Accordingly, I would like to thank the Carnegie Mellon University
Ballroom Dance Club and the Edgewood Club swing community for providing me the
opportunity to dance up a storm. My friends Donna Jean Kaiser, Cheryl Pope, Jim
Reich, and James Rauen also helped keep me sane during this trying period. Finally, I
would like to thank my family for everything they have done for me over the years.

Mark Lillibridge,
April 24, 1997

xiv
Part I
Context

1

Chapter 1
Introduction

1.1 Overview
Many programming languages have a collection of facilities for building modular programs. These collections of facilities, called module systems, play an important role
in programming languages, especially with regard to programming-in-the-large. This
dissertation concerns a new approach to designing module systems for statically-typed
programming languages. The approach promises a substantially more powerful module
system than those built with previous approaches, while at the same time eliminating
the problems associated with the previous approaches.

Traditional module systems, such as the one provided by Modula-2 [56], are first-order,
allowing only trivial manipulations of modules. Some newer programming languages provide higher-order module systems. Higher-order module systems, unlike first-order ones,
permit the non-trivial manipulation of modules within the language. In particular, they
at least permit functions mapping modules to modules and may provide other higherorder features such as modules containing modules as subcomponents and modules as
first-class values. Experience with the Standard-ML module system has shown the usefulness of functions mapping modules to modules and modules with module subcomponents.
For example, functions over modules permit abstract data types (ADTs) to be parameterized by other ADTs, and submodules permit modules to be organized hierarchically.
Modules as first-class values is also likely to be useful because it permits choosing ADT
implementations at runtime.

Previous higher-order module systems can be classified as either opaque or transparent.
Opaque systems totally obscure information about the identity of type components of
modules, often resulting in overly abstract types. This loss of type identities precludes
most interesting uses of higher-order features. Transparent systems, on the other hand,
completely reveal type identities by inspecting module implementations, which subverts

3

4 CHAPTER 1. INTRODUCTION
data abstraction and prevents separate compilation. Unlike opaque systems, transparent
systems cannot support modules as first-class values. My thesis is as follows:

By basing a module system on a new type-theoretic concept, namely a new
kind of weak sum whose type can contain both transparent and opaque type
declarations called a translucent sum, it is possible to obtain a higher-order
module system with the advantages of both the opaque and the transparent
approaches, but none of their disadvantages.

In order to demonstrate this thesis, I design a new programming language with a
higher-order module system based on translucent sums. The language I have created is
a kernel system that contains only the features relevant to module system design; considerable extension would be required to make it into a real programming language. The
design of this kernel system and the proofs required to establish formally its properties
form the core of this dissertation. Included are a proof of the system's soundness and
effective procedures for type checking its programs.

This dissertation is divided into three parts. The first part introduces the problem
and provides the needed background on module systems (this chapter), explains the
previous approaches to designing higher-order module systems (Chapter 2), and describes
my approach using translucent sums (Chapters 3 and 4). The second part, comprising
Chapters 5 to 12, is devoted to the kernel system and its associated proofs. An overview
of this part can be found in Chapter 5; descriptions of this part's other chapters can
be found in Section 5.10. Finally, the third part discusses possible extensions to the
kernel system (Chapter 13), explains related work (Chapter 14), and summarizes this
dissertation's results (Chapter 15).

1.2 Module Systems
A module binds a set of values and types to names. For example, we might have

M = module

val x = 3;
val y = true;
type T = int;
end;

This code creates a new module with three components, called x, y, and T. The components x and y are value components that are bound to the values 3 and true respectively;
the component T, by contrast, is a type component that is bound to the type int. Once
this module is created, it is then bound to the name M; this binding will allow us to

1.2. MODULE SYSTEMS 5
refer to the new modules' components as M.x, M.y, and M.T later on. Although in this
example, we named our new module, this is not required. Sometimes, for example, we
may want to create a new module then immediately apply a function to it; naming the
new module serves no purpose in that case.

Because I am dealing with statically typed languages, modules will have "types",
called interfaces. For example, the module M matches the following interface:

M : interface

val x:int;
val y:bool;
type T;
end;

This interface specifies that M has two value components, x with type int and y with type
bool, and one type component, T.1 The relationship between modules and interfaces is
many-to-many: Many modules may match the same interface and a given module may
match many interfaces.

A programming language's collection of facilities for building modular programs is
its module system. I classify module systems into two types, depending on what sort of
facilities they have. First-order module systems have only the trivial module facilities
discussed so far: module creation, module naming, and module-component extraction
(M.x). Most traditional module systems are of this type. Examples include Ada [52],
CLU [36], C [29], C++ [53], and Modula-2 [56].

Higher-order module systems, by contrast, have non-trivial module manipulation facilities. I shall be concerned in this dissertation primarily with three such facilities:
functors, submodules, and modules as first-class values. Functors are functions mapping
modules to modules. For example, we might define a rectangle ADT parameterized by a
point ADT using a functor:

MkRect = functor(p:POINT):RECT

module

type T = p.T * p.T;
...
end;

The advantage of doing this is that we can create several rectangle ADTs from the same
code using different point ADTs. For example, if we have point ADTs CartPoint and
PolarPoint, we can create a rectangle ADT based on Cartesian points with CartRect

1In my kernel system I deal with a more complicated version of modules that assigns "types", called
kinds, to types; I have simplified things here.

6 CHAPTER 1. INTRODUCTION
= MkRect(CartPoint) and a rectangle ADT based on polar points with PolarRect =
MkRect(PolarPoint).

Submodules are modules contained as components within other modules; they allow
packaging up a series of modules into a single unit. For example, if we had several
search-tree modules, we could package them up into a single module:

SearchTree = module

mod Binary = BinarySearchTree;
mod RedBlack = RedBlackSearchTree;
mod BTree = BTree;
end;

SearchTree, in turn, could be included as part of a larger library algorithms module.
By organizing modules in this way, a hierarchical namespace can be obtained; such
namespaces are easier for programmers to deal with than flat namespaces. Because
most module systems do not consider modules to be ordinary values, a different keyword
(mod) is needed in general here to specify that these are module components, not value
components.

Modules as first-class values refers to the ability to treat modules as if they were
ordinary values of the programming language. This means that anything that can be
done with a ordinary value can be done with a module. Thus, in languages with modules
as first-class values, modules can be passed to or returned by functions, stored in variables,
or selected using conditional statements. In such languages, the mod keyword is just
syntactic sugar for the val keyword.

One useful way to use this facility is to select the most efficient implementation for
an ADT at runtime. For example, the best implementation for a dictionary depends on
the number of items it will contain; the following code sets Dictionary at runtime to
use an implementation that is efficient for n items:

Dictionary = if n!20 then LinkedList else HashTable;

1.3 Benefits of Higher-Order Module Systems
Higher-order module systems offer many benefits over first-order module systems. I have
already mentioned some benefits (the ability to parameterize with respect to ADTs, the
ability to have a hierarchical namespace, and the ability to choose ADT implementations
at runtime), but the greatest benefit of higher-order module systems is that they allow
programs to be organized better. Program organization is crucial to ensuring that large
programs are easy to develop, understand, and maintain.

The most well-known programming language with a higher-order module system is
Standard ML (SML) [21]. SML provides functors and submodules, but treats modules as

1.3. BENEFITS OF HIGHER-ORDER MODULE SYSTEMS 7

normal: mobile: local:

TCP
TCP MOBILE-IP TCP

IP IP glue
ETH ETH ETH
DEV DEV DEV

Figure 1.1: TCP/IP protocol organization
second-class values. The extensive experience of the SML community with functors and
submodules has established their value as program-organization tools. Modules as firstclass values shows promise as a valuable addition to module system toolkits, but since
this facility has never been implemented together with the other higher-order facilities,
experience about its value is lacking.

It is hard to find good examples of why better organization matters: Any small
section of a program can usually be rewritten so that it no longer uses higher-order
module system features at the cost of making the rest of the program more complicated.
Nonetheless, I am now going to present two examples that I feel convey some of the flavor
of how higher-order modules systems are used in practice.

My first example comes from Carnegie Mellon's Fox Project's implementation of the
TCP/IP protocol suite, the FoxNet [6, 5, 4], in SML. The TCP/IP protocol suite is
organized modularly in the form of a protocol stack (see Figure 1.1). The leftmost stack
in this figure shows the organization of normal TCP/IP. Normal TCP/IP is built on
a base device driver protocol (DEV), upon which additional protocol layers (ETH, IP,
and TCP in turn) are placed. Each of the additional protocol layers takes in the lower
level protocol implemented by the underlying stack and produces a new protocol with
additional functionality. For example, the IP layer adds the ability to route between
different nets.

What is particularly nice about this organization is that the protocol interfaces of
the layers are (mostly) identical, allowing protocol layers to be mixed and matched in
order to generate many kinds of functionality. For example, the middle stack in Figure 1.1
represents a configuration for mobile TCP/IP, where in an extra protocol layer, MOBILEIP, has been added between the TCP and IP layers in order to provide an extra layer of
indirection between virtual and physical IP addresses; mobile TCP/IP allows computers
to move around physically without losing connections.

Alternatively, the rightmost stack in the figure represents a configuration for local
TCP/IP, where the IP layer has been dropped. Because the resulting protocol lacks

8 CHAPTER 1. INTRODUCTION
any inter-net routing ability, it can be used only between hosts on the same local net;
however, it will be faster for this purpose because it does less processing and uses smaller
packets. (A small glue layer, labeled glue, is necessary between the TCP and ETH layers
because the protocol interfaces these layers use are slightly different in practice.)

By using functors, FoxNet is able to directly capture this modular organization. Idealized code for doing this might look like the following:

DEV : PROTOCOL = module ... end;

ETH = functor (lower:PROTOCOL):PROTOCOL

module ... end;
...

Here, the base device layer DEV is implemented as a normal module matching the PROTOCOL interface and the other layers are implemented as functors mapping a PROTOCOL
to a PROTOCOL. Using this code, the normal and local TCP/IP protocol stacks could
then be built up by applying the reverent layer functors in the correct order:

Normal = TCP(IP(ETH(DEV)));
Local = TCP(Glue(ETH(DEV)));

In a language with modules as first-class values, we could choose which of these protocol
stacks to use at runtime for maximum efficiency:

P = if on local net() then Local else Normal;
Note that the resulting implementation is completely type safe and does not require
any runtime type checks. A similar-looking object-oriented programming (OOP) program could be written where protocols and packets are objects. (Each protocol contains
a packet type, which is the type of packets belonging to that protocol.). The resulting program would be much slower though because it would require frequent runtime
type checks. (Higher-level-protocol packets have extra fields not present in lower-level-
protocol packets; runtime type checks must be done before those fields can be accessed
because first-order module systems cannot statically distinguish between the different
packet types.)

1.4 Example: B-Trees
My second example involves an ordered dictionary implementation. I have chosen this
example carefully and will be using it throughout the first part of my dissertation because
it illustrates well the differences between the various approaches to building higher-order
module systems.

1.4. EXAMPLE: B-TREES 9

An ordered dictionary is a dictionary whose entries are ordered by an ordering on its
keys. The classic example of an ordered dictionary is the white pages telephone directory:
You can look up phone numbers by name as well as examine entries in alphabetical order.

It order to define the notion of an ordered dictionary, it is first necessary to define
the notion of an ordered type:

ORDERED = interface type T;

val cmp: T*T -? int;
end;

Here, I have defined an ordered type to be a module containing a type T2, the type in
question, together with a comparison function cmp that compares two values of type T,
returning an integer that indicates how they compare. (That is, cmp(x,y)!0 if x ! y,
cmp(x,y)=0 if x = y, and cmp(x,y)?0 if x ? y.)

Using this definition, the notion of an ordered dictionary ADT can then be defined:

ORDERED DICTIONARY =

interface

mod Key:ORDERED;
type elem;
type T;

val new: unit -? T;
val define: T * Key.T * elem -? unit;
val first: T -? Key.T * elem;
...
end;

Here, Key is the ordered type of keys, elem is the type of the elements looked up, and
T is the type of ordered dictionaries managed by the ADT. The functions new, define,
first, and so on, are the operations on ordered dictionaries. For example, new() creates
a new empty ordered dictionary (the type unit contains only one value, denoted ()),
define(d,k,e) adds the binding of key k to element e to the ordered dictionary d, and
first(d) either returns the first binding in the dictionary or raises the exception fail.

An example implementation of an ordered dictionary ADT might then be obtained
using B-Trees as follows:

2By convention, the primary type of a module is called T.

10 CHAPTER 1. INTRODUCTION

MkBTree =

functor (K:ORDERED, E:interface type T; end)

:ORDERED DICTIONARY
module

mod Key = K;
type elem = E.T;
type T = btree(Key.T,elem);

fun new() = ...
fun define(dict:T, key:Key.T, value:elem) = ...
...
end;

I have parameterized the implementation with respect to which ordered type to use for
keys (K) and which type to use for elements (E.T).3 The implementation first makes
copies of the key and element information so that future clients will have access to
this information; second, establishes the representation type it will use, which I have
abbreviated here as btree(Key.T,elem) so that I can refer to it later easily; and, finally,
third, it provides code for each of the required ordered dictionary operations (not shown).

Because the behavior of MkBTree varies depending on which approach to designing
higher-order module systems is being used, I shall defer further discussion of MkBTree
until I have described the approaches in more detail.

3For technical reasons, it is necessary to wrap up the element type in a module in order to pass it to
a functor; this fact is not important here.

Chapter 2
Previous Approaches
In order to motivate my approach to designing higher-order module systems, I shall now
describe the previous approaches to designing higher-order module systems. The previous
approaches can be classified as either "opaque" or "transparent", depending on how they
treat module and functor boundaries.

2.1 The Opaque Approach
Under the opaque approach, module and functor boundaries are opaque, allowing no
information about the identity of type components to pass through. This is exactly what
we want when we build an ADT. For example, consider the following definition of an
integer stack ADT:

IntStack = module

type T = ref(list(int));
fun new() = new [];
fun push(s:T, e:int) = ...
...
end;

The identity of the integer stack type (T) is visible inside the module, allowing us to
implement its operations using the appropriate primitives on its representation type, but
its identity is obscured outside the module: IntStack.T is an abstract type. Thus, the
user of this ADT will be able to create and manipulate integer stacks using code like
IntStack.pop(IntStack.push(IntStack.new(), 3)), which returns 3, but will not be
able to depend in any way on which representation it uses.

Examples of programming languages which take this approach are John Mitchell and
Gordon Plotkin's SOL [43] and Luca Cardelli's Quest [10]. This approach provides data

11

12 CHAPTER 2. PREVIOUS APPROACHES
abstraction at the module level, as we have just seen. It also allows separate compilation,
the ability to type check and compile individual module implementations using only the
interfaces of the modules they reference, because modules depend only on interfaces, not
on implementations. This approach is also compatible with modules as first-class values
because it makes no assumptions about type-component identities.

Unfortunately, because this approach obscures the identity of all type components,
it precludes most interesting uses of higher-order features. Consider the B-Tree example
I introduced in Section 1.4. Suppose we try to use it to create a telephone directory. To
keep things simple, let us use the type string as both the key and element type. We can
build an ordered type "string, ordered alphabetically" by wrapping up string with the
appropriate string comparison operator:

StringOrd = module

type T = string;
type cmp = ...;
end;

A simple functor application then suffices to create an ordered dictionary using this
ordered type for keys and string's for elements:

D = MkBTree(StringOrd, module type T=string; end);
As a test of our new ADT, we can try creating a new telephone directory and then adding
an entry to it:

directory = D.new();

D.define(directory, "John Smith", "123-4567");
Unfortunately, the second line above fails to type check under the opaque approach. The
reason is that D.define has the type

D:T \Lambda  D:Key:T \Lambda  D:elem \Gamma  ? unit
which specifies that D.define's second and third arguments are of type D.Key.T and
D.elem respectively; because the opaque approach treats all type components abstractly
outside their module of definition, these two types are not compatible with string,
the type of the passed second and third arguments. This problem renders the B-Tree
implementation unusable under the opaque approach.

The problem with this example is an instance of a more general problem: There is
no way in the opaque approach to build modules "containing" other types; we can only
build modules containing unrelated new types (e.g., StringOrd.T 6= string). Hence,

2.2. THE TRANSPARENT APPROACH 13
modules cannot export type abbreviations; for example, we cannot make Complex.T be
an abbreviation for the type Real*Real. Also, we cannot extend ADTs by adding a
few new operations to an existing ADT.1 Another consequence is that many of the more
useful idioms using higher-order features are inexpressible. Indeed, David MacQueen
argued in a 1986 paper [37] that this problem is severe enough that the opaque approach
should be abandoned in favor of a transparent one.

2.2 The Transparent Approach
Unlike in the opaque approach, under the transparent approach, module and functor
boundaries are transparent, allowing all information about the identities of type components to pass through them; the transparent approach does this by inspecting module
implementations to determine the actual identity of type components. For example,
consider again the IntStack example:

IntStack = module

type T = ref(list(int));
fun new() = new [];
fun push(s:T, e:int) = ...
...
end;

This time, the identity of the integer stack type is visible both inside and outside of the
module: We know that IntStack.T = ref(list(int)) and can thus manipulate integer
stacks using reference and list primitives. The identity of IntStack.T is computed by
substituting in its implementation and then reducing the resulting expression:

IntStack.T =
(module type T=ref(list(int)); ... end).T =
ref(list(int))

Examples of programming languages that take this approach are David MacQueen's
DL [37]; Robert Harper and John Mitchell's XML [41]; and Robert Harper, John Mitchell,
and Eugenio Moggi's *ML [22]. As we have just seen, the transparent approach does not
provide data abstraction at the module level. It is possible, however, to obtain a more
limited kind of data abstraction, which I call closed abstraction, under the transparent
approach.

1For example, we cannot create a new module ExtendedString from a built-in String ADT module
by first copying the String type and operations then adding a few new operations, and have extended
strings be interchangeable with the built-in strings.

14 CHAPTER 2. PREVIOUS APPROACHES

Closed abstraction is abstraction limited to a specific closed scope. For example,
we might have an abstract-in construct that allows us to hold our integer-stack module
abstract in a particular piece of code (M below):

INTSTACK = interface

type T;
val new : unit -? T;
...
end;

abstract IntStack:INTSTACK = module

type T = ref(list(int));
fun new() = new [];

...
end
in

M
end;

Here IntStack is held abstract inside M ; that is, only the information available in the
interface given for it (INTSTACK) is visible inside M . Thus, the fact that IntStack.T is
a type is visible but not the fact that IntStack.T is equal to ref(list(int)). Because
IntStack is only visible in M , this construct provides only closed abstraction.

The abstract-in construct can be desugared in the transparent approach into a functor
application:

(functor (IntStack:INTSTACK) M )

(module

type T = ref(list(int));
fun new() = new [];
...
end);

Because in general it is not possible to determine the code for functor arguments at
compile time, the transparent-system type checker checks M using only the information
available in interface for IntStack, giving the desired behavior.

By contrast, in open abstraction, which is provided by my approach and the opaque
approach but not by the transparent approach, the scope of the abstraction is not limited
to a single existing scope. For example, using an open-abstraction construct (denoted by
abs here), we might have the following code:

2.3. SUMMARY 15

S = module

abs IntStack:INTSTACK = module

type T = ref(list(int));
fun new() = new [];
...
end;
...
end
...

Here our integer-stack module is held abstract both inside the module S (under the name
IntStack) and outside the module S (under the name S.IntStack). If S is at the top
level of a program then the later scope may include modules complied separately from S
at a later time. Closed abstraction cannot handle such modules because it requires that
all code that uses an ADT be available at the time the ADT is written. Because of this
important limitation, I do not consider systems that support only closed abstraction to
provide abstraction at the module level. Note that under the opaque approach abs is
just a synonym for mod because abstraction is automatic.

Because the transparent approach requires access to the implementations of all the
modules a module refers to in order to compile that module (in order to determine the
identities of type components from those modules), it cannot provide separate compilation. Also, the transparent approach is incompatible with treating modules as first-values
because there is no way to determine the actual identity of a type when it depends on
information available only at runtime.2

However, the transparent approach does allow modules to "contain" other types.
This fact allows most of the interesting use of higher-order features to be used under
the transparent approach. For example, if we try and build a telephone directory using
MkBTree like we did before (see Section 2.1), no type errors occur this time because
under the transparent approach, D.define has the type btree(string,string) * string
* string -? unit. Accordingly, the resulting telephone dictionary is fully usable, but
its implementation is exposed (note the first argument's type), which is undesirable from
the point of view of information hiding.

2.3 Summary
Summarizing, there are two main previous approaches to designing higher-order module
systems, the opaque approach and the transparent approach. The opaque approach has

2More precisely, unsoundness results from this combination in the presence of side effects; the unsoundness example in Section 4.5 shows this fact because it is well typed under the transparent approach
extended with first-class modules but causes a type error at runtime.

16 CHAPTER 2. PREVIOUS APPROACHES
the following advantages:

ffl Provides module-level data abstraction
ffl Supports separate compilation
ffl Compatible with modules as first-class values
Its disadvantages include the absence of all of the following:

ffl Modules can "contain" other types
ffl Modules may export type abbreviations
ffl Many of the more useful higher-order idioms work
The transparent approach, on the other hand, has the opposite advantages and disadvantages; it lacks the opaque approach's advantages but it removes the opaque approach's
disadvantages. Both approaches' set of disadvantages are serious enough to result in their
each building unsatisfactory module systems.

Chapter 3
My Approach
In this chapter I introduce the basic ideas of my approach to designing higher-order
module systems, contrast my approach with the previous ones, and explore my approach's
abilities. In the next chapter (Chapter 4), I explain in more detail the technical machinery
behind my approach.

3.1 Module and Functor Boundaries
Under my approach, which I call the translucent approach, module and functor boundaries are "translucent," being opaque in some places and transparent elsewhere. Where
the boundaries are opaque is controlled by the programmer using interfaces. Each boundary has an associated interface, which specifies which type component's identity information can be seen through the boundary.

In order to allow this specification, interfaces in my approach are extended to allow
specifying the identity of type components. For example, the following interface for a
hash table ADT specifies the type identity of the element type (elem) but not that of
hash tables (T):

HashTable : interface type elem = int;

type T;
...
end

Using this ability, the programmer specifies boundary properties by giving, in the interface associated with a boundary, the type identities of only those components she wishes
the boundary to be transparent to; all other type components will be treated opaquely.
Thus, in the HashTable example above, the boundary will be transparent for the elem
component and opaque for the T component.

17

18 CHAPTER 3. MY APPROACH

Because the programmer is required to provide the actual type identity of transparentlytreated type components in the interface (the type checker checks that the type identities
provided in the interface are correct when the interface is assigned to a module), the type
checker does not need to inspect the implementation of modules to determine the identity
of their type components; it can just believe the module's interface. This fact means that
modules depend on only the interfaces of other modules; my approach is thus able to
support separate compilation without any trouble.

3.2 Default Interfaces
If the programmer does not supply an interface for a simple module (module ... end),
then the type checker infers a fully transparent interface by inspecting the module's
implementation. For example, under my approach, StringOrd, which we bound to the
result of evaluating module type T = string; type cmp = ...; end, would have been
assigned the following interface:

interface type T = string; val cmp: T*T -? int; end
If we compare this interface to the original opaque ORDERED interface (repeated below),
we see that the new interface differs only in the addition of the type identity T=string:

interface type T; val cmp: T*T -? int; end
By using a shorthand notation due to Xavier Leroy [31], we can take advantage of this
fact to express the new interface as ORDERED with T=string. Leroy's with notation is
a purely syntactic shorthand that expresses the result of adding information about type
identities to an existing interface. A discussion of exactly how the with notation works
can be found in Subsection 13.7.4.

The situation for non-simple module expressions without interfaces is more complicated, particularly because modules under my approach are treated as first-class values.
Briefly, by the use of some type rules, an interface that is as transparent as possible given
soundness and reasonable compile-time-information constraints1 is inferred. I shall give
an example of how this can occur later in Section 3.7. Code that does not involve using
modules as first-class values, higher-order functors (functors that take or return other
functors as arguments), or type coercions will be given a fully transparent interface [34].
This category includes the majority of code written in SML.

1In particular, the type checker makes no attempt to determine the run-time branching of conditionals,
instead assuming that they could branch either way at any time.

3.3. SUBTYPING 19
3.3 Subtyping
Subtyping in my system permits forgetting type identities; for example, ORDERED with
T=int is a subtype of ORDERED. This fact means that the programmer can use type
coercions (M !: interface ... end) to increase opacity where and when desired. For
example, the following code creates an initially transparent HashTable module then
makes opaque just the T type component:

HashTable = (module type elem = int;

type T = (string*elem) array;
...
end
!: interface type elem = int;

type T;
...
end);

This technique provides module-level data abstraction under my approach.

Thus, in summary, under the translucent approach, the default is full transparency;
opacity results either from using modules in a first-class manner (to prevent unsoundness)
or from using an explicit type coercion (to obtain data abstraction).

3.4 The B-Tree Example
To get a feel for how translucency works, let us consider again the B-Tree example from
Section 1.4. What happens if we try to build a telephone directory using MkBTree under
the translucent approach? If we examine the original code for MkBTree (partially copied
below), we see that it assigns the interface ORDERED DICTIONARY to the result of applying
MkBTree:

MkBTree =

functor (K:ORDERED, E:interface type T; end)

:ORDERED DICTIONARY
module

mod Key = K;
type elem = E.T;
type T = btree(Key.T,elem);
...
end;

20 CHAPTER 3. MY APPROACH

Because ORDERED DICTIONARY is completely opaque (it specifies no type identities),
this means that MkBTree's boundary under the translucent approach will be completely
opaque as well; consequently, MkBTree will act the same as it did under the opaque
approach: If we try to build a telephone directory like we did before in Section 2.1,
abstract operation-argument types will result in type errors that prevent us from using
the resulting telephone directory.

What happens if we remove the explicit result interface (:ORDERED DIRECTORY) from
the MkBTree code? In that case, the type checker will infer the following totallytransparent result interface:

ORDERED DICTIONARY with Key.T = K.T

with elem = E.T
with T = btree(K.T,E.T)

(Note that the body of the MkBTree functor is a simple module.)

With this interface, MkBTree's boundary will be completely transparent; consequently,
this version of MkBTree will act the same as the old version of MkBTree did under the
transparent approach: If we try to build a telephone directory, the resulting dictionary
will be fully usable, but its implementation will be exposed to the user.

Both versions of MkBTree are unsatisfactory; what we really need is for Key.T and
elem to be transparent (so that the resulting dictionary will be usable) and for T to be
opaque (so that MkBTree's implementation is hidden). We can achieve this by assigning
the following translucent interface as the return interface for MkBTree:

ORDERED DICTIONARY with Key.T = K.T

with elem = E.T

This interface gives MkBTree a translucent boundary that is transparent for the Key.T
and elem type components but opaque for the T type component.

What happens if we try and create a telephone directory using this new version of
MkBTree as before (code repeated below)?

D = MkBTree(StringOrd, module type T=string; end);

directory = D.new();
D.define(directory, "John Smith", "123-4567");
Because of the translucent boundary, D.define will have the type D.T * string * string
-? unit, where D.T is an abstract type. Accordingly, there is no problem using the
resulting telephone directory and the implementation of MkBTree is hidden as desired.
Note that only my approach is thus able to handle the B-Tree example in a satisfactory
manner.

3.5. THE RECIPE 21
3.5 The Recipe
My approach is based on type theory and the *-calculus. In it, modules are a particular
sort of value and interfaces are a particular sort of type. This choice yields a simple and
uniform design.

My "recipe" for building translucent higher-module systems is as follows:

ffl Start with a base *-calculus (to model the core language); I use Girard's F! [15] in

my Kernel system

ffl Add translucent sums (to module modules)
ffl Add dependent functions (to model functors); dependent functions are needed because the result type of a functor can depend on its argument

ffl Add a notion of subtyping (to model implementation-interface matching)
The key component here is the new type theoretical construct I call a translucent
sum; the other components of the recipe are, with the exception of one minor change to
the behavior of dependent functions (see the next chapter), standard components drawn
from the extensive type-theory literature.

Indeed, variations of this recipe can be used to build opaque or transparent higherorder module systems: To get an opaque system, for example, weak sums (also called
existentials) with the dot notation elimination form (discussed in the next chapter) should
be substituted for translucent sums in the recipe. To get a transparent system, on the
other hand, strong sums should be substituted instead. It will also be necessary in the
transparent case to stratify the system, separating modules, functors, and their "types"
from ordinary terms and types; this stratification ensures soundness at the cost of making
modules and functors second-class values.

For both of these variations, in order to handle submodules, dependent sums should
either be added in addition or their functionality should be merged into the weak or
opaque sum construct. (Translucent sums already include the functionality of dependent
sums.)

3.6 Translucent Sums
Translucent sums are weak sums with the dot elimination form that have been enriched
in the following ways:

ffl The ability to give equational information about type components has been added
ffl Type equality has been modified to take this equational information into account

22 CHAPTER 3. MY APPROACH

ffl They have been generalized to:

- have any number of components
- have named components
- allow dependencies on previous (value) components

ffl Subtyping has been modified to allow

- forgetting equational information about type components
- reordering components
- dropping components

The last two subtyping changes are to allow more flexible matching of module implementations to interfaces. This ability is very useful in practice because it allows modules
to be combined in more flexible ways. In particular, it allows passing a module with extra
or differently ordered components than a functor's argument interface requires to that
functor without having to manually write a coercion function to extract only the required
components. The reordering ability also frees programmers of the need to remember the
exact order of an interface's components.

I shall discuss translucent sums in more detail in the next chapter.

3.7 First-Class Values
Like weak sums, on which translucent sums are based, translucent sums are ordinary
values. This fact has a number of consequences. First, because modules are translucent
sums, modules under my approach are first-class values. Second, because of this fact,
modules may be nested inside other modules as value components (i.e., using the val
keyword); my approach thus supports submodules without needing to handle submodule
components specially.

Third, because having modules as first-class values means that any function can
take or return modules, functors are simply ordinary (dependent) functions; accordingly,
functors in my approach are also just ordinary values. Finally, fourth, because functions
in *-calculi are higher-order (they can take and return functions) and functors are just
ordinary functions, my approach supports higher-order functors.

The recipe I have described builds a module system where modules are first-class
values. It is possible to alter the recipe (see Section 13.8) to build instead a translucent
higher-order module system where modules are second-class values. Such an approach
would yield a system with the same abilities as the approach I am describing here except

3.8. LINKING 23
that it would not be possible to choose ADT implementations at runtime. The resulting
system, however, would require substantially less complicated proofs.

Code using modules as first-class values may automatically lose type identity information in order to avoid unsoundness. Consider again, for example, the code to select a
dictionary at runtime based on the number of items needed:

Dictionary = if n!20 then LinkedList else HashTable;
Suppose the programmer gave fully transparent interfaces to LinkedList, say DICTIONARY with T=list(...), and HashTable, say DICTIONARY with T = array(...). Because the type checker does not know what n's value will be at runtime, it cannot safely
determine Dictionary.T's type identity. Accordingly, it must be conservative and assign Dictionary the more opaque interface DICTIONARY, which makes Dictionary.T
abstract.

No special type rules are needed to implement this behavior: Because the type rule for
if-then-else requires the then and else branches to have the same type and LinkedList
and HashTable have different types, the type checker is forced to use subsumption to
coerce both branches to a common supertype; all such types make Dictionary.T opaque.
It is because of this ability to make types abstract when they cannot be determined at
compile-time that my approach is able to treat modules as first-class values without
risking unsoundness.

3.8 Linking
One advantage of a programming language with a higher-order module system based on
type theory is that the process of separate compilation, including linking, can be described
in the language without any need for additional constructs or type rules. The basic idea
here is to describe separate compilation as a preprocessing stage that automatically
converts files containing code with references to other modules into closed functors by
using the files containing the interfaces for the referenced modules. The closed functors
can then be compiled completely independently of any other files. The linker must then
automatically generate code to apply the compiled functors generated by the compiler
to each other in the correct order at runtime.

In order to give you a favor for how this process might work, I am now going to
describe a very simple separate-compilation system. In this system, the implementation
code for modules named M is placed in the file M .m while the interface for module M
(only one interface per module is allowed in this system) is placed in the file M .i; this
naming convention allows the preprocessor to find the interfaces of referenced modules.

Interface and implementation files in this system may optionally start with an import
declaration. Only modules listed in a file's import declaration, if any, may be referenced

24 CHAPTER 3. MY APPROACH

File contents of "String.i":

interface

type T;
val empty : T;
...
end;

File contents of "String.m":

module

type T = array(char);
val empty = ...
...
end;

Figure 3.1: Code for the String module
from that file. If a module's interface file includes an import declaration, then it's implementation file must include an import declaration which starts with the same list of
modules imported in the module's interface file.

For an example program, consider Figures 3.1 and 3.2. Figure 3.1 contains the interface and implementation files for a module String that implements a string type from
character arrays. Figure 3.2 contains the interface and implementation files for a module
Hash, which implements an integer hash-table ADT keyed on strings using an associative
list ADT. The modules String and Assoc (not shown) have no import declarations because they do not need to refer to any other modules. The Hash interface imports String
(in order to use the type String.T), while the Hash implementation imports Assoc as
well (in order to use the String and Assoc operations to implement hash tables).

The transform of Hash into a closed functor results in the code of Figure 3.3. This
transform can be performed completely mechanically: the list of functor arguments comes
from the implementation's import list, the interfaces from the appropriate interface files,
and the functor body from the module's implementation file. Note that no references to
external modules remain: The references to String.T, Assoc.T, and so on, refer to the
MkHash functor's arguments, not to the external modules of the same name. Also note
that checking that Hash's implementation satisfies its publicly declared interface will be
done automatically when the transformed code is compiled; the matching relation here is
just subtyping on interfaces, avoiding the need for a separate set of rules. The transforms
of String and Assoc (not shown) are much simpler since they import nothing.

When this program is linked together, the linker automatically generates the series

3.8. LINKING 25

File contents of "Hash.i":

import String;

interface

type T;
val new : unit -? T;
val lookup : T * String.T -? int;
...
end;

File contents of "Hash.m":

import String, Assoc;

module

type T = Assoc.T(int)
fun new() = ...
fun lookup(table:T, key:String.T) = ...;
...
end;

Figure 3.2: Code for the Hash module

26 CHAPTER 3. MY APPROACH

MkHash =

functor (String: interface

type T;
val empty : T;
...
end,
Assoc: interface ... end)

: interface

type T;
val new : unit -? T;
val lookup : T * String.T -? int;
...
end
module

type T = Assoc.T(int);
fun new() = ...
fun lookup(table:T, key:String.T) = ...;
...
end;

Figure 3.3: Code for the transformed Hash module

String = MkString();
Assoc = MkAssoc();
Hash = MkHash(String, Assoc);

Figure 3.4: Code to combine the closed functors

3.9. TYPE-SHARING SPECIFICATIONS 27
of functor applications shown in Figure 3.4 to combine the closed functors together into
a complete program. Determining what order to link the closed functors in is somewhat
tricky because of dependencies between modules. In the simple system I am describing,
the order is determined by first building a directed graph, whose nodes are the modules
and whose edges represent dependencies between modules: An arrow is drawn from M
to N iff M imports N or M appears before N in any import list. (The second part gives
the programmer some control over the order of module initialization; this control can be
important when side effects are involved.) Second, the graph is checked for cycles; it is
an error, aborting linking, if any cycles are found. Otherwise, third, a topological sort is
done to find a ordering that respects all the dependencies.

At runtime, this series of applications is done as the effect of the program. In a more
realistic example, there would be a Main module, executed last, whose application would
perform the desired computation. Note that if functors are used in the original program,
then the transformed code will involve higher-order functors.

3.9 Type-Sharing Specifications
Standard ML has a feature that is sometimes useful called type sharing, which is used in
interfaces to require that (sub)-component types are equal. To see an example of where
this feature might be useful, imagine that we had a number of different ordered-dictionary
implementations that we wished to test to make sure they worked correctly. One easy
test we could do is to write a functor that takes in two ordered dictionaries and performs
random operations on the two dictionaries in parallel; if their answers differ, then at least
one of them must be incorrect.

In order to make this functor work, we are going to need to require that the two
ordered dictionaries we are passed have the same key and element types. (Otherwise,
we will not be able to perform the same operations on both ordered dictionaries.) This
requirement can be expressed in SML by using type-sharing specifications:

functor RandomTest(structure x:ORDERED DICTIONARY;

structure y:ORDERED DICTIONARY;
...

sharing type x.Key.T = y.Key.T
sharing type x.elem = y.elem
) = ...

(SML syntax is slightly different from my notation.)

This SML code can be translated into my approach by using a series of with expressions to set the required-equal type components equal to each other:

28 CHAPTER 3. MY APPROACH

RandomTest =

functor (x:ORDERED DICTIONARY,

y:ORDERED DICTIONARY

with Key.T = x.Key.T
with elem = x.elem,
...)
...

This basic idea -- picking the type in an specified equivalence class with maximal scope
and then setting the other types in that class equal to it using with statements -- can
used to translate any type-sharing specification from SML into my approach.

3.10 Summary
Summarizing, under my approach the identity of type components start out fully visible;
this visibility can later be obscured either automatically when modules are used in a firstclass manner in order to ensure soundness, or manually when the programmer inserts
a type coercion in order to produce abstraction. This controlled visibility permits data
abstraction where desired and modules as first-class values without limiting the uses of
higher-order features that depend on modules "containing" other types. My approach
also supports separate compilation because modules depend only on interfaces.

Since my approach gives the programmer control over the degree of visibility, she
can choose opacity or transparency as needed, getting the best of both worlds. Indeed,
because translucency permits the programmer to mix opacity and transparency in the
same module (e.g., the interface for HashTable), new uses of higher-order features become possible (e.g., the B-Tree example). My approach also provides a number of other
benefits:

ffl Functors are first-class
ffl Higher-order functors are provided
ffl Type-sharing specifications can be encoded
ffl Modules may export type abbreviations
ffl Linking and separate compilation can be described in the resulting programming

language

ffl The resulting system has a simple and uniform type theory

Chapter 4
Technical Machinery
Now that I've described the basic ideas of my approach, I shall introduce in this chapter
the technical machinery behind my approach. In particular, I shall explain the syntax and
rules for translucent sums in some detail, describe how the various rules interact to obtain
desirable properties such as decidable type equality, and motivate some restrictions in
the rules. This chapter is intended to serve as an introduction to the machinery worked
out in complete detail in the next part of this dissertation; accordingly, I ignore here a
number of uninteresting minor technical issues such as the need for side conditions on
many rules in order to avoid variable capture and duplicate field names.

4.1 Dot Notation
Traditionally, in order to make use of the contents of a weak-sum value (also called an
existential value), a programmer must first open it. If the term M 1 evaluates to a weak
sum of type interface type T; val v:A; end, then it may be opened for use in M 2 by
writing open M 1 as U,x in M 2 end. During M 2's execution, U will be bound to the
type component of the weak sum and x will be bound to its value component, which will
have type [U=T]A. The type rule for open requires that M 2's type does not refer to U;
this requirement is necessary to avoid unsoundness. (Because weak sums are first-class
values, U may be bound to different types at runtime, making it unsafe to refer to it by
a single static name outside the scope of the open statement.)

Having to write out an open statement each time you want to use a weak sum can be
inconvenient; in a 1990 paper [11], Luca Cardelli and Xavier Leroy introduced a shortcut
they called the dot notation. The basic idea is to allow the programmer to directly
write x.T for the type component of and x.v for the value component of the weak sum
denoted by the variable x. These direct references are then translated away by placing
open statements next to the bindings of the weak sums and by substituting the names

29

30 CHAPTER 4. TECHNICAL MACHINERY
of the opened components for the direct references.

For example, consider the following piece of code:

let x = M 1 in

x.v.1(*s::x:T: true)
end

This code translates into the following piece of code:

let x = M 1 in

open x as x T,x v in

x v.1(*s:x T: true)
end
end

By using a more complicated translation, Cardelli and Leroy showed, among other
things, that their dot notation could be extended from working on just variables to
working on any (sub)-component of a variable as well. Under that extension, if x.y.z,
the y.z sub-component of the variable x, is a weak sum, then its type component could be
referred to directly as x.y.z.T. The extension does not compromise soundness because
the (sub)-components of variables are essentially just another kind of variable.

I have chosen to build the dot notation into translucent sums directly instead of
requiring it to be first translated away or not providing it. In their paper, Cardelli and
Leroy do not deal with dependent sums or functions; it seems unlikely that the dot
notation can be translated into open statements in the presence of these features, both of
which are present in my system. Thus, the dot notation in my system should be regarded
as an independent feature and not an abbreviation for the use of open. As I shall explain
in Section 4.5, my approach is able to support the dot notation on a somewhat larger
class of terms than variables and their (sub)-components.

4.2. CREATION 31
4.2 Creation
For the this chapter, I shall use the following syntax:

Simple Modules S ::= module B1; \Delta  \Delta  \Delta  Bn; end (n * 0)
Interfaces I ::= interface D1; \Delta  \Delta  \Delta  Dn; end (n * 0)
Bindings B ::= val x=M j type ff=A
Declarations D ::= val x:A j type ff=A j type ff
Terms M ::= x j S j M:x j functor (x:A) M j

M 1 M 2 j ...
Types A ::= ff j I j FUNCTOR (x:A):A0 j

M:ff j ...

Assignments \Gamma  ::= D1; \Delta  \Delta  \Delta  Dn (n * 0)
Here, the metavariable ff ranges over type variables and the metavariable x ranges over
term variables. I have omitted the syntax for constructs other than translucent sums
and dependent functions because it will not be needed; likewise, I have simplified the
presentation of translucent sums here by using only one name per field rather than the
pair of names -- one for internal access and one for external access -- that are required
for technical reasons (see Section 13.1). In the next chapter I shall introduce a more
concise, precise, and formal notation for my system.

In order to type check a simple module, we type check each of its bindings under
the preceding bindings, if any, and the current assignment (assignments describe the
variables from the rest of the program currently in scope):

8i 2 [1::n]: \Gamma ; D1; \Delta  \Delta  \Delta  ; Di\Gamma 1 ` Bi : Di
\Gamma  ` module B1; \Delta  \Delta  \Delta  ; Bn; end : interface D1; \Delta  \Delta  \Delta  ; Dn; end (I-SIMPLE)

The resulting type for the module is an interface type listing the "types" of the module's bindings. The "type" of a binding is a declaration; the following rules associate
declarations with bindings:

\Gamma  ` M : A
\Gamma  ` val x=M : val x:A (I-VAL)

\Gamma  ` A valid
\Gamma  ` type ff=A : type ff=A (I-TYPE)

Here \Gamma  ` M : A denotes that term M has type A under assignment \Gamma  and \Gamma  ` A valid
denotes that A is a valid type under \Gamma . Note that the rules assign transparent declarations

32 CHAPTER 4. TECHNICAL MACHINERY
(type ff=A) rather than opaque declarations (type ff) to type bindings. This behavior
implements the default interface policy for simple modules (full transparency) that I
described in Section 3.2.

As an example, these rules assign module type ff=int; val a=2; val b=a+2; end
the type interface type ff=int; val a:int; val b:int; end under \Gamma . Note that
because we type check successive bindings in the scope of the previous ones, fields can
refer to earlier fields. In the above example, the b field was able to refer to the a field
because it was type checked under the assignment \Gamma ;type ff=int;val x:int. Earlier type
fields such as ff may also be referred to in later fields.

Later fields may also refer to (sub)-components of earlier fields. For example, the
following module is well typed:

module val P=module

type T=int;
val x=3;
end;
type U=P.T;
val y=P.x;
end

Note the use of the dot notation here to refer directly to the type P.T. The rule for
determining when such a reference is valid is (roughly) as follows:

\Gamma  ` M : interface \Gamma 1; type ff; \Gamma 2; end

\Gamma  ` M :ff valid (V-DOT)

That is to say, if M denotes a translucent sum with an ff type field1 under \Gamma , then
M :ff denotes a type. This rule is in fact too general; I shall explain why and how the
set of terms that this rule applies to needs to be restricted in Section 4.5. I shall defer
discussion of how M :x is typed until Section 4.6.

The ability to refer to earlier fields also exists in interfaces:

8i 2 [1::n]: \Gamma ; D1; \Delta  \Delta  \Delta  ; Di\Gamma 1 ` Di valid

\Gamma  ` interface D1; \Delta  \Delta  \Delta  ; Dn; end valid (V-INTER)

Thus, interfaces like interface type ff; val x:ff; end are valid.

All of the rules for dependent functions (functors) are standard except for the typing
rule for application, which I shall explain in Section 4.6. For example, the rule for type

1Note that a transparent declaration for ff in M 's interface can always be turned into an opaque
declaration for ff by using subsumption on M to forget the identity of ff.

4.3. EQUALITY 33
checking functors is as follows:

\Gamma ; x:A ` M : A0
\Gamma  ` functor (x:A) M : FUNCTOR (x:A):A0 (I-FUNC)

Note that the result type of a functor (A0) can depend on its argument (x).

4.3 Equality
Type equality in my system is structural (i.e.., component-wise) except for equations
derived from the information about type identities found in translucent sums and from
reductions involving functions on types (not discussed in the first part of this dissertation;
see Section 5.1). In particular, two interfaces are equal if their corresponding declarations
are equal:

8i 2 [1::n]: \Gamma ; D1; \Delta  \Delta  \Delta  ; Di\Gamma 1 ` Di = D0i
\Gamma  ` interface D1; \Delta  \Delta  \Delta  ; Dn; end = interface D01; \Delta  \Delta  \Delta  ; D0n; end (E-INTER)

Two declarations are equal if they are of the same sort, declare the same variable, and
contain equal types:

\Gamma  ` A = A0

\Gamma  ` val x:A = val x:A0 (E-VAL)

\Gamma  ` type ff = type ff (E-TYPE-O)

\Gamma  ` A = A0
\Gamma  ` (type ff=A) = (type ff=A0) (E-TYPE-T)

Note that equality does not permit the reordering of translucent-sum fields.

The information about type identities contained in translucent sums leads to equations in two ways. First, whenever a transparent declaration occurs in an assignment, it
gives rise to an equation involving its type variable:

\Gamma ; type ff=A; \Gamma 0 ` ff = A (ABBREV)
Because the components of translucent sums (and functors) are compared for equality
under an assignment extended with the previous declarations, if any, this rule give rise
to equations like the following:

interface type ff=int; val x:ff; end =
interface type ff=int; val x:int; end

34 CHAPTER 4. TECHNICAL MACHINERY

Second, declarations of translucent sums containing transparent declarations, either
directly or in a sub-component, also give rise to equations:

FV(A) " fields(\Gamma 1) = ;
\Gamma  ` M : interface \Gamma 1; type ff=A; \Gamma 2; end

\Gamma  ` M :ff = A (ABBREV

0)

As with the previous rule involving the dot notation, V-DOT, this rule is too general; a
similar restriction to the set of terms it applies to will need to be made.

I use FV(A) to denote the free variables of A and fields(\Gamma ) to denote the fields declared
in \Gamma . Thus, the first precondition of the ABBREV0 rule expresses the requirement that the
type ff is equal to (A) does not depend on any earlier fields in M 's type; this precondition
is needed to prevent variable capture.

Such dependencies can be classified as either essential or inessential. A dependency
is inessential if it can be removed by the use of the equality rules alone; otherwise, it
is essential. Dependencies on transparently-defined fields are inessential: they can be
removed by using the ABBREV or the ABBREV0 rule as appropriate to replace the field
name with its declared identity. (The typing rules prohibit fields from depending on
themselves.) Dependencies on opaquely defined fields, on the other hand, are usually
essential.

As an example, in the following interface type the z field depends essentially on the
ff field but only inessentially on the fi field:

interface

type ff;
type fi = int;
val z: FUNCTOR (s:ff):fi;
end

The difference between essential and inessential dependencies is important because several
type rules in my system require all dependencies between certain fields to be removed
before they can be applied.

Like the ABBREV rule, the ABBREV0 rule also gives rise to equations on interfaces
when combined with the component-wise equality rules. For example, we have that

interface

val x: interface type T=int; end;
type U = x.T;
end

is equal to

4.4. SUBTYPING 35

interface

val x: interface type T=int; end;
type U = int;
end

4.4 Subtyping
Subtyping in my system is structural modulo equality -- equal types are always subtypes
of each other -- except for forgetting information about type-component identities and
the reordering and dropping of translucent-sum fields. The component-wise subtyping
rule for translucent sums says that two interfaces are subtypes if their corresponding
declarations are "subtypes":

8i 2 [1::n]: \Gamma ; D1; \Delta  \Delta  \Delta  ; Di\Gamma 1 ` Di ^ D0i

\Gamma  ` interface D01; \Delta  \Delta  \Delta  ; D0n; end valid
\Gamma  ` interface D1; \Delta  \Delta  \Delta  ; Dn; end ^ interface D01; \Delta  \Delta  \Delta  ; D0n; end (S-INTER)

One declaration is a structural "subtype" of another if it is of the same sort and
declares the same variable either to be a subtype of the other declaration's declared
type (value-declaration case) or to be equal to the same type(s) modulo equality (typedeclaration case):

\Gamma  ` A ^ A0

\Gamma  ` val x:A ^ val x:A0 (S-VAL)

\Gamma  ` type ff ^ type ff (S-TYPE-O)

\Gamma  ` A = A0
\Gamma  ` (type ff=A) ^ (type ff=A0) (S-TYPE-T)

Note that it is not safe to replace a transparent type declaration with one that declares
the field name to be equal to a subtype of the original type because type fields can be
used in contravariant positions; types in such positions can in general only be replaced
safely with supertypes.

The forgetting of type-identity information is implemented by a non-structural rule
for declaration "subtyping":

\Gamma  ` A valid
\Gamma  ` (type ff=A) ^ (type ff) (S-TYPE-F)

36 CHAPTER 4. TECHNICAL MACHINERY

Some examples of subtyping using these rules are as follows:
(a) interface type T=int; val x:int; end

^ interface type T=int; val x:T; end
^ interface type T; val x:T; end

(b) interface type T; type U=T; end

^ interface type T; type U; end

Here in (a), we first created an inessential dependency of the x field on T using equality
then converted it into an essential dependency by using forgetting to make T an opaque
field. In (b), by contrast, we broke an essential dependency of the U field on T by forgetting
that U was equal to T. Subtyping, thus, unlike equality, can be used to break or create
essential dependencies.

Note that before a field's type-identity information can be forgotten, it may be necessary to remove some dependencies on that field in order to ensure that the resulting type
is valid as required by the second precondition of rule S-INTER. (Such dependencies can
always be removed by substituting the type the field is declared equal to for the field
name everywhere.) Consider the following valid interface:

interface

type S = interface type T; end;
val M:S;
val N:S;
val x:M.T;
end

We cannot directly forget S's identity because the resulting type is invalid:

interface

type S;
val M:S;
val N:S;
val x:M.T;
end

(Here, M.T is an invalid type because M, being of a (now) abstract type, cannot be shown
to be a translucent sum.)

However, we can forget S's identity if we first replace the occurrence of S in M's type
with the interface it is currently defined equal to, resulting in the following type:

4.4. SUBTYPING 37

interface

type S;
val M : interface type T; end;
val N:S;
val x:M.T;
end

In addition to the component-wise subtyping rule for interfaces, there are additional
non-structural rules that permit the reordering and dropping of translucent-sum fields.
Because it is unclear how the rules that implement this behavior should be formulated
(see Section 13.2), I shall just give a very rough description of their behavior here: Fields
in interfaces may be dropped if no other fields (essentially) depend on them. A field
may be moved to the right past other fields if they do not depend (essentially) on the
moving field. Some variants of these rules allow a field to be moved to the right past
fields that depend essentially on the moving field under some conditions. See Section 13.2
for details.

Consider, for example, the following interface:

interface type a; type b=int; val c:b; val d:a; end
Here, the c and d fields could be dropped directly and the b field could be dropped after
the dependency on it by the c field had been broken by using equality. The a field, by
contrast, cannot be dropped unless the d field is dropped first because the d field depends
on it essentially. The a field could be moved right past the b and c fields but not past
the d field. Likewise, the b field could be moved right past the c and d fields only if the
dependency by c on b was first broken.

Note that, like the rule for ordinary non-dependent functions, the subtyping rule for
functor types is contravariant:

\Gamma  ` A2 ^ A1 \Gamma ; x:A2 ` A01 ^ A02
\Gamma  ` FUNCTOR (x:A1):A01 ^ FUNCTOR (x:A2):A02 (S-FUNC)

Here, the direction of subtyping on the functor argument types (Ai) is reversed from
that on the overall types. This fact means that subtyping can be used to "remember" the
type-identity information of variables declared in contravariant positions. This ability
provides another way for dependencies to be broken:

FUNCTOR (x:interface type T; end):x.T
^ FUNCTOR (x:interface type T=int; end):x.T
^ FUNCTOR (x:interface type T=int; end):int

Here, remembering followed by equality was used to break the essential dependency of
the result type on the argument x.

38 CHAPTER 4. TECHNICAL MACHINERY
4.5 The Phase Distinction
One desirable property of a programming language is that it have a phase distinction [22].
A programming language is said to have a phase distinction if programs in it can be
type checked without evaluating general program expressions (terms). Programming
languages without a phase distinction are hard to compile efficiently; in the presence of
side effects, their semantics are also unclear. (What does it mean for a program's type
to be "if today is Monday then int else bool"?)

Surprisingly, my system has a phase distinction in spite of allowing modules as firstclass values. The only difficult part to ensuring a phase distinction for my system is
figuring out how to handle equality on types containing terms. In particular, how should
equations like the following be checked?

M:ff = N:ff
The naive method is to simply evaluate M and N , read off the types of their ff type components from the resulting values, and then compare the types using equality. However,
since M and N may be arbitrary terms, this rules out having a phase distinction.

My answer is to restrict the set of terms that may occur in types to an extended
set of "values" I call extended values. The set of extended values consists of the usual
call-by-value values (denoted by the metavariable V ) extended with term variables and
selections on extended values:

Definition 4.5.1 (Syntax)

Extended Values * ::= x j V j *:y

I choose this set because it allows referring to any previous type component (including
nested cases like x.y.ff) and is closed under substitution of a call-by-value value for a
term variable, making defining the call-by-value semantics of function application much
easier. Note that type coercions of the form V !:A are not considered call-by-value values
because they can be reduced further to V . If they were added to the set of extended
values, then the identity of types like (module type T=int; end !: interface type
T; end).T becomes problematic because in order for abstraction to work properly, this
type should not even be equal to itself, let alone be equal to int.

This restriction, which I call the extended-value restriction, is implemented both
syntactically, by replacing M :ff in the grammar for types with *:ff, and via the type
rules, by replacing M by * in the rules V-DOT and ABBREV0. The restriction makes
computing the identity of a type component like *:ff easy: The only operation that
needs to be performed is selection, which never produces side effects and cannot cause
non-termination.

4.5. THE PHASE DISTINCTION 39

The computing of type identities for *:ff's is done in my system by the ABBREV0
rule combined with the rules for typing simple modules and selections. These rules give
rise to equations like the following:

(module type T=int; val x=3; end).T = int
(module type T=int; type U=T*bool; end).U = int*bool
(module val x = module type T=int; end; end.x).T = int

Using these equations, any valid type in my system can be converted using equality into
an equal type that contains terms of only the form x:y1:y2 \Delta  \Delta  \Delta  :yn, n * 0. I shall call such
terms places. (The valid-type requirement here is to rule out cases with invalid selections
like (*x:int: 3):ff.) Once the need for evaluating terms has been removed, it is easy to
establish a phase distinction.

Note that the remaining terms are of the form that Cardelli and Leroy showed how
to convert into open statements (see Section 4.1); this fact indicates that my extension
of the dot notation to extended values is conservative because *:ff's can be regarded as
just syntactic sugar for a type using only the unextended dot notation.

One consequence of the extended-value restriction is that my system is limited to callby-value: Call-by-name requires the ability to substitute general terms for term variables
in terms, which in turn requires the ability to substitute general terms for term variables
in types because terms may contain types; however, substituting general terms into types
results in types containing general terms in violation of the restriction.

Attempting to relax the extended-value restriction in order to get around this limitation gives unsoundness in the presence of side effects. To see this, consider the following
example, where the alternate function alternates between returning true and false
(alternate uses side effects internally):

IntPkg = module type T = int;

val v = 3;
val f = negate;
end;

BoolPkg = module type T = bool;

val v = true;
val f = not;
end;

40 CHAPTER 4. TECHNICAL MACHINERY

Apply = functor (Pkg: interface type T;

val v:T;
val f:FUNCTOR (x:T):T;
end)
begin

Pkg.f(Pkg.v);
true;
end;

Apply(if alternate() then IntPkg else BoolPkg)
This code is well typed in my system2 and safe under call-by-value because Apply under
call-by-value applies the function f to the value v from the same package. However, if we
evaluate this code under call-by-name, we evaluate Apply's argument twice resulting in a
type error because we end up evaluating either IntPkg.f(BoolPkg.v) = negate(true)
or BoolPkg.f(IntPkg.v) = not(3). A similar runtime type error occurs if we first
fi-reduce or inline the call to Apply, then evaluate using call-by-value. Because the fiexpansion would type check if the extended-value restriction were relaxed, this example
shows that such a relaxation is unsound in the presence of effects.

4.6 Selection and Application
Another consequence of the extended-value restriction is that the traditional elimination
rules3 for dependent sums and functions cannot be used because they require the ability
to substitute general terms into types:

\Gamma  ` M : interface val x:A1; val y:A2; end

\Gamma  ` M :x : A1 (I-TRAD-S1)

\Gamma  ` M : interface val x:A1; val y:A2; end

\Gamma  ` M :y : [M :x=x]A2 (I-TRAD-S2)

\Gamma  ` M 1 : FUNCTOR (x:A):A0 \Gamma  ` M 2 : A

\Gamma  ` M 1 M 2 : [M 2=x]A0 (I-TRAD-F)

2I have used an imperative version of Apply here, which executes Pkg.f(Pkg.v) solely for its side
effects, in order to avoid a restriction on functor applications that I discuss in the next section.

3Elimination rules for a construct handle type checking that construct's elimination form(s), in this

case selection for dependent sums and application for dependent functions.

4.6. SELECTION AND APPLICATION 41

Here, I have simplified things by only giving the case for binary dependent sums and
have used [M =x]A to denote the substitution of the term M for the term variable x in
the type A in a variable capture avoiding way.

In order to avoid this problem, I limit my selection and application rules to the
non-dependent cases, which do not require term substitution to handle:

\Gamma  ` * : interface \Gamma 1; type ff; \Gamma 2; end

\Gamma  ` *:ff valid (V-DOT)

FV(A) " fields(\Gamma 1) = ;
\Gamma  ` * : interface \Gamma 1; type ff=A; \Gamma 2; end

\Gamma  ` *:ff = A (ABBREV

0)

FV(A) " fields(\Gamma 1) = ;
\Gamma  ` M : interface \Gamma 1; val x:A; \Gamma 2; end

\Gamma  ` M :x : A (I-SELECT)

\Gamma  ` M 2 : A
\Gamma  ` M 1 : FUNCTOR (x:A):A0 x 62 FV(A0)

\Gamma  ` M 1 M 2 : A0 (I-APP)

When can these rules be applied if we assume that all of their preconditions except the
no-dependency one(s) are met? Clearly, the V-DOT rule can always be applied because
opaque declarations cannot depend on anything. Less obviously, if M can be given a
fully-defined transparent type -- a type that declares all of M 's type (sub)-components
transparently -- that also satisfies the traditional preconditions then the I-SELECT rule
can be applied to M and, furthermore, if M is an extended value, then the ABBREV0
rule can be applied to it as well. This fact holds because all dependencies within and on a
fully-defined transparent type must be inessential and hence breakable via subsumption;
moreover, this breaking can be done without invalidating the traditional preconditions.

The case for the I-APP rule is similar but the reasoning is more complicated. Here,
it is the argument M 2 that needs to be given a fully-defined transparent type in order
for the rule to apply. For the traditional preconditions to hold, this type must be a
subtype of M 1's domain type. Given these two conditions, the I-APP rule can always
be applied: first use subtyping to specialize the functor M 1's domain type to the fullydefined transparent type for M 2; second, use equality to break all dependencies by the
functor result type (A0) on the functor argument (x), which will now all be inessential;
and third, apply the I-APP rule to the resulting non-dependent function type.

As an example, consider type checking the application of a functional version of Apply
(FApply, defined below) to IntPkg (defined in the previous section).

42 CHAPTER 4. TECHNICAL MACHINERY

FApply = functor (Pkg: interface type T;

val v:T;
val f:FUNCTOR (x:T):T;
end)
Pkg.f(Pkg.v);

FApply and IntPkg have the following types:

IntPkg : interface type T=int;

val v:int;
val f:FUNCTOR (x:int):int;
end

FApply : FUNCTOR (Pkg: interface

type T;
val v:T;
val f:FUNCTOR (x:T):T;
end):Pkg.T

Note that IntPkg's type is a fully-defined transparent subtype of FApply's domain type
(use equality to replace occurrences of int with T then forget the type identity of T) so
the functor application will be well typed if we can remove the dependency on Pkg by
FApply's result type.

By using subtyping via subsumption, we can specialize FApply's domain type to
IntPkg's type:

FApply : FUNCTOR (Pkg: interface

type T=int;
val v:int;
val f:FUNCTOR (x:int):int;
end):Pkg.T

Next, we can use equality via subsumption to replace all occurrences of Pkg.T in FApply's
result type by int; this step breaks the dependency on FApply's domain type by its result
type:

FApply : FUNCTOR (Pkg: interface

type T=int;
val v:int;
val f:FUNCTOR (x:int):int;
end):int

4.6. SELECTION AND APPLICATION 43
Finally, we can apply the resulting non-dependent version of FApply to IntPkg using
I-APP to get that FApply(IntPkg) has type int. Note that we cannot type FApply(IntPkg) by first using subsumption to coerce M 2's type to that of FApply's domain
type and then using I-APP because once the information about IntPkg.T is lost there is
no way to break the dependency on Pkg.T by FApply's result type.

Because any term that does not denote a translucent sum will have a fully-defined
transparent type (because it will have no type (sub)-components), the above result means
that the application of a functor to any such term will never fail due to the no-dependency
precondition. Thus, functors act like standard dependent functions when applied to
anything other than a translucent sum.

There are two special cases worthy of note where translucent-sum expressions can
always be given fully-defined transparent types. The first such case is translucent sums
that contain no type (sub)-components. Such translucent sums are essentially ordinary
records; their types are always fully-defined transparent types with no dependencies
between fields because they contain no type (sub)-components, which could be depended
on.

The second case concerns translucent-sum extended values; in the next section I shall
introduce two rules I call the EVALUE rules, which allow a fully-defined transparent type
to be given to any extended value without losing any information about its fields. This
ability means that *:ff, *:x, and F (*) will always type check if * has an ff type field,
* has an x type field, or * is a member of F 's domain type, respectively. Because the
ABBREV0 rule is restricted to working on only extended values, this fact means that the
no-dependency restriction does not in fact restrict the occasions when the ABBREV0 rule
can be applied. Note also that module names (e.g., IntPkg or SearchTree.Binary) are
special cases of extended values; hence, selection of and application to a named module
cannot fail due to the no-dependency restriction.

What about the remaining cases where the no-dependency restriction cannot be met?
By the process of elimination, these are cases where we are computing a new module
(rather than referring to a previously computed module by name), which contains at
least one type component that is depended on by the resulting type and whose identity
the type checker does not know. Recall that unknown type components can only occur
when the programmer either uses modules in a first-class manner or uses a type coercion
to intentionally forget the identity of a type component.

These remaining cases need to be blocked in order to avoid unsoundness. The intuition
behind this fact is that in these cases the result type of the expression in question contains
a type that we have no name for; because we have no name for that type, we cannot
be sure that it does not vary at runtime, leading to possible unsoundness. (Because
my system uses call-by-value, type names must denote a constant type in each of their
dynamic scopes.) As an example, consider the following unsafe code:

44 CHAPTER 4. TECHNICAL MACHINERY

(if alternate() then IntPkg else BoolPkg).f(

(if alternate() then IntPkg else BoolPkg).v)

This is the fi-reduction of the unsoundness example from Section 4.5. Note that it
would be well typed if we removed the no-dependency restriction on selection and used
the traditional selection rules for dependent sums. This example can be j-expanded to
produce an similar unsoundness example for functor application:

SelectF = functor (Pkg: interface type T;

val v:T;
val f:FUNCTOR (x:T):T;
end)
Pkg.f;

SelectV = functor (Pkg: interface type T;

val v:T;
val f:FUNCTOR (x:T):T;
end)
Pkg.v;

SelectF(if alternate() then IntPkg else BoolPkg)(

SelectV(if alternate() then IntPkg else BoolPkg))

Note that this example does not violate the no-dependency restriction on selection because selection is applied only to module names and that both SelectF and SelectV are
well typed even in the presence of the no-dependency restriction.

4.7 The EVALUE rules
Suppose the current assignment contains the following declaration:

val P : interface type T; val x:T; end
What types can we give to the expression P under this assignment? Because we have
a name, P, for the translucent-sum expression we are trying to type, we have a name
for the contents of its T field, namely P.T. This suggests that we can give P the type
interface type T=P.T; val x:P.T; end, which is a subtype of the declared type for
P.

This technique of giving a more expressive type to translucent sums when we have a
name for their type components can be generalized to work on arbitrary translucent-sum
extended values. The name in this case is simply *.T where * is the extended value in

4.7. THE EVALUE RULES 45
question. The technique cannot be extended to general terms because of the extendedvalue restriction (M .T is not in general a valid type in my system). The following two
typing rules implement this technique:

\Gamma  ` * : interface \Gamma 1; type ff; \Gamma 2; end
\Gamma  ` * : interface \Gamma 1; type ff=*.ff; \Gamma 2; end (EVALUE-T)

\Gamma  ` *:x : A0
\Gamma  ` * : interface \Gamma 1; val x:A; \Gamma 2; end
\Gamma  ` * : interface \Gamma 1; val x':A; \Gamma 2; end (EVALUE-V)

(The EVALUE-V rule is used in cases of nested translucent sums to apply the technique
recursively.)

We can give any extended value * a transparent type using these rules by repeating the
following sequence of steps as many times as possible: first, find the leftmost type (sub)-
component in *'s current type that is not declared transparently, call it C. Second, use
equality (via subsumption) to break all dependencies on earlier type (sub)-components
in *'s type. (We can do this breaking because all earlier type (sub)-components must
be declared transparently by step one.) Third, use the EVALUE rules to convert the C
field from an opaque declaration to a transparent one. (Step two here is necessary to
ensure that the selection in the EVALUE-V rule does not fail due to the no-dependency
restriction.) Note that equality (via subsumption) may be needed before applying the
EVALUE rules in order to rewrite *'s type into the form interface ... end.

If *'s original type was fully-defined (it declares all its type (sub)-components), then
the resulting type will be a fully-defined transparent type. A fully-defined type can be
found for * by simply type checking * without reordering or dropping fields from * and
its (sub)-components. This procedure can always be done if * is well typed (adding extra
information does not make well-typed terms ill-typed). Thus, we can give a fully-defined
transparent type to any well-typed extended value using the EVALUE rules.

As an example, consider giving a fully-defined transparent type to the extended value
x under an assignment that contains the following declaration:

val x:interface type T; val y:interface type U; type V=T; end; end
The extended value x goes through the following types as we give it a transparent type:

interface type T; val y:interface type U; type V=T; end; end
interface type T=x.T; val y:interface type U; type V=T; end; end
interface type T=x.T; val y:interface type U; type V=x.T; end; end
interface type T=x.T; val y:interface type U=x.y.U;

type V=x.T; end; end

46 CHAPTER 4. TECHNICAL MACHINERY

In addition to their interactions with the elimination rules, the EVALUE rules are
important because they prevent the identity of opaquely-defined type (sub)-components
from being lost when the (sub)-components are given a new name. Without these rules,
an abstract type and its copy would be considered different abstract types. Consider, for
example, the following code fragment:

M = module type T=int; type U=int; type V=bool; end

!: interface type T; type U=T; type V=bool; end;

N = M;
O = module val X=N; end;
Using the EVALUE rules we can give the following transparent types to these module
names:

M : interface type T=M.T; type U=M.T; type V=bool; end

N : interface type T=M.T; type U=M.T; type V=bool; end
O : interface

val X : interface type T = M.T;

type U = M.T;
type V = bool;
end;
end

Accordingly, we can infer that M.T = M.U = N.T = N.U = O.X.T = O.X.U and that
M.V = N.V = O.X.V = bool, but not that M.T = int. These equations mean that M,
N, and O.X are interchangeable. Without the EVALUE rules we would only be able to
infer that M.T = M.U, N.T = N.U, O.X.T = O.X.U, and M.V = N.V = O.X.V = bool; M,
N, and O.X are not interchangeable in that case because they do not contain equivalent
T components.

Note that the EVALUE rules, the elimination rules for selection and application, and
the ABBREV rules working in concert are able to propagate all the needed information
about the identity of type (sub)-components solely through types; no term (even just
a value) ever needs to be substituted during type checking. This machinery is what
allows my system to support separate compilation: All the information necessary for
type checking can be placed in a module's type (interface); there is no need to have the
code of a supplier module so that it may be substituted.

One way to show the power of this machinery is to show that all the information
available from substituting an extended value * for x can also be made available by

4.7. THE EVALUE RULES 47
giving x an appropriate type A possessed by * (i.e., a fully-defined transparent type as
discussed earlier). This claim can be formalized as the following proposition: If * is a
well-typed extended value under \Gamma  then there exists a type A such that A is a minimal
type for * under \Gamma  and for all types A0 such that \Gamma ; [*=x]\Gamma 0 ` [*=x]A0 valid, we have that
\Gamma ; x:A; \Gamma 0 ` [*=x]A0 = A0. The type A is a transparent minimal type for M under \Gamma  if
for all types A0 such that \Gamma  ` M : A0, we have that \Gamma  ` A ^ A0. I prove a version of this
proposition in Sections 11.5 and 11.6 (see especially Theorem 11.5.10 and Lemma 11.6.10)
for my kernel system.

This proposition can be used to show that the following versions of the traditional
elimination rules, which have been restricted to extended values, can be derived in my
system:

\Gamma  ` * : interface val x:A1; val y:A2; end

\Gamma  ` *:y : [*:x=x]A2 (I-TRAD-S2')

\Gamma  ` M : FUNCTOR (x:A):A0 \Gamma  ` * : A

\Gamma  ` M * : [*=x]A0 (I-TRAD-F')

(For simplicity, I again show only the binary sum case here.)

I shall just sketch the proof of the first rule here: Let * have the type interface val x:A1; val y:A2; end under \Gamma . By applying the proposition, we can get a
transparent minimal type for *:x, call it A01. By EVALUE-V then, * must also have the
type interface val x:A01; val y:A2; end under \Gamma . By the second part of the proposition then, this type is equal to interface val x:A01; val y:[*:x=x]A2; end. Note that
the y field of this type cannot depend on the x field because it contains no x's (* cannot
contain x because of (unshown) side conditions required to prevent variable capture). Accordingly, we can apply equality (via subsumption) to give * this type, then I-SELECT
to show that *:y has the desired type [*:x=x]A2.

Thus, for selection from and application to extended values, my elimination rules are
equivalent to the traditional ones. A similar result can be shown for the other special
cases (non-translucent-sum values and translucent sums without type (sub)-components)
mentioned before in Section 4.6. My rules differ in the remaining cases in that they
refuse to allow some operations that the traditional rules permit in order to prevent
unsoundness in the presence of modules as first-class values and to avoid the need for
substituting general terms so as to be able to support separate compilation.

48 CHAPTER 4. TECHNICAL MACHINERY

Part II
The Kernel System

49

Chapter 5
Overview
In order to demonstrate my approach, I now present a calculus based on the idea of
translucent sums. I omit features that add only surface complexity without making the
development more interesting (e.g., syntactic sugar or array types) in order to simplify
the presentation. The system I describe is thus a kernel system, rather than a full
programming language. Nonetheless, I believe that it contains all the important elements
needed in a programming language with higher-order modules. I include both recursive
types (allowing for non-terminating programs) and references (allowing for imperative
programming) to demonstrate that translucent sums are compatible with effects.

I make a number of other simplifications so that the kernel system proofs are as
simple as possible without losing any results. These simplifications include the fact that
translucent-sum expressions in kernel-system types are limited to places (x:y1 \Delta  \Delta  \Delta  :yn,
n * 0) and the factoring of translucent sums into two simpler constructs, a standard
dependent sum and a new construct called a reified constructor (see Section 5.5 for
details). The more complicated system I described in the first part of this dissertation
can be recovered from the kernel system by adding a pre-processing elaboration stage. I
choose to move the problem of reordering and dropping translucent-sum components to
this elaboration stage. I do this both to simplify the system and because there is some
uncertainly about what the best choice of subtyping rules is for handling component
reordering (see Section 13.2).

In addition to giving the syntax, the typing rules, and the semantics for the system,
I also give formal proofs of all the important properties for a programming language. In
particular, I prove that type checking modulo subtyping is decidable and that the system
is sound. Unfortunately, subtyping, and hence full type checking, is only semi-decidable;
this is unlikely to cause problems in practice though (see Section 10.9). I cover more
exotic modules features such as parameterized interfaces and value sharing as well as
some design alternatives briefly in a later chapter on possible extensions.

51

52 CHAPTER 5. OVERVIEW
5.1 Higher Kinds
I have omitted any mention of functions on types from the first part of this dissertation in
order to keep the discussion simple. Such functions are necessary to handle concepts like
list and reference types: Statically-typed programming languages have not one list type,
but rather a family of list types parametrized by the type of the elements their members
may contain. Thus, an integer list may contain only integers and so on. Because of this
parametrization, list types are most naturally introduced by making list a primitive
function taking a type (the type of the list's elements) and returning a type (the resulting
list type.) Thus, list(int) would denote a list of int's and list(bool) would denote
a list of bool's.

Both types and functions from types to types are instances of a more general notion of
constructors. Constructors are generalized types that may take any number of arguments.
Types (e.g., int) are constructors that take zero arguments, while functions mapping a
type to a type (e.g., list) are constructors taking one type argument. Constructors in
my kernel system may also take multiple arguments through currying: For example, we
might have a constructor hash table that takes two arguments, namely the type of keys
and the type of elements to use. Such a table with string keys and int elements would
have type hash table(string)(int).

Constructors are distinct from terms, forming a separate level of my kernel system.
In order to do type checking, it is necessary to distinguish among the different sorts
of constructors based on how they may be applied. This distinguishing can be done
by introducing a third level of kinds, which classify constructors in the same way that
types classify terms. The simplest kind is type, which classifies completely applied
constructors. Only such constructors may be used to classify terms; all other constructors
must first be applied to suitable arguments before they can be used to classify terms. I
shall refer to only constructors of kind type as types.

The remaining kinds, called higher kinds, are of the form K 1)K2, where K1 and
K2 denote kinds. Such kinds classify constructors that map constructors of kind K 1 to
constructors of kind K 2. Thus, list will have kind type)type and hash table will
have kind type)(type)type).

It is useful to allow programmers to define new constructors in terms of old ones. For
example, a programmer might want to define dictionaries to be hash tables with string
keys:

constr dictionary = *ff::type: hash table(string)(ff);
This declaration introduces a new constructor, dictionary, of kind type)type. The
intent is that dictionary(A) should equal hash table(string)(A) for all types A.

My system supports this ability by allowing such constructors (*ff::K : A), defining

5.1. HIGHER KINDS 53
their equality in terms of substitution:

(*ff::K: A) A0 = [A0=ff]A (BETA)

*ff::K: A ff = A; where ff 62 FV(A) (ETA)
These rules allow equations such as the following to be derived:

(*ff::type: hash table(string)(ff))(int) = hash table(string)(int)
*ff::type: list(ff) = list

In essence, what is going on here is that the constructor and kind levels in my system
constitute a simply-typed lambda calculus with constructors taking the part of simplytyped terms and kinds taking the part of their types. Constructors are equal if when considered as simply-typed terms they evaluate via fij-reduction to the same "value". Like
functions in the simply-typed lambda calculus, constructors can be higher-order, taking
and returning non-type constructors as arguments; for example, *ff::type)type: ff(int)
is a valid constructor of kind (type)type))type. Similarly, partially applied constructors can also be manipulated. For example, the programmer could equivalently have
declared the following:

constr dictionary = hash table(string);
My constructor level is thus quite flexible. Actual programming languages tend to
have more restricted constructor levels in order to simplify the programming model for
the programmer. For example, it is common to allow constructors to take only types as
arguments. However, these restrictions do not yield any real simplification in the system
proofs: All of the significant complexities introduced by having a constructor level occur
even if only user-defined functions from types to types are allowed. Accordingly, I saw
no good reason to make any restrictions.

In a system with constructors, the natural thing to do is to allow translucent sums
to contain constructor components instead of type components. I do this in my kernel
system, allowing translucent sums like

54 CHAPTER 5. OVERVIEW

Dict = module

constr dictionary = hash table(string);
val empty = ...;
...
end
!: interface

constr dictionary :: type)type;
val empty : 8ff. dictionary(ff);
...
end

Here the programmer creates an abstract data constructor, a generalization of an ADT.
Dict.dictionary is abstract constructor of kind type)type; the fact that the programmer used hash tables to implement dictionaries will be hidden outside this module because
of the type coercion. If the coercion had been omitted, then Dict would have been given a
transparent type containing the declaration constr dictionary = hash table(string),
causing Dict.dictionary to be an abbreviation for hash table(string).

Note that we now need to specify the kind of constructors in opaque declarations but
not in transparent ones. This fact is because the kind of a given constructor is easily
inferred. Because types occur so often, it is useful to allow the type keyword to be used
as syntactic sugar for a constr declaration with kind type. Aside from this change,
there is no other change to translucent sums or their behavior. The system translucent
sums are embedded in changes greatly, however, due to the enriched behavior of equality,
which now works on constructors of all kinds not just types, and subtyping.

5.2 Previous Work
I described a much earlier version of this work in a previous paper with Robert Harper
[20]. Aside from minor notational differences, there are only two changes between the
system described in that paper and the one I have described up to this point. The first
change is that I have moved the handling of reordering translucent-sum fields from the
definition of term equivalence (translucent sums whose fields could be reordered without
changing any dependencies were considered equivalent) to the subtyping rules. This
change simplifies the equality relation and makes the basic kernel system easier to adapt
to an implementation that prohibits reordering and allows dropping fields only from the
end of a translucent sum; such implementations can be very efficient because subsumption
under those conditions can be implemented as a no-op.

The second change concerns the definition of extended values. Originally, I had defined them by adding term variables and the selection operation to the grammar for
call-by-value values. Because the call-by-value value definition is recursive, this resulted

5.3. EXTENDED INTERFACE MATCHING 55
in extended values including additional terms over the current definition like module val x=z; val y=module val a=3; end.a; end. These terms did not provide any
real benefit and complicate the explanation of how equality on types containing terms is
handled.

5.3 Extended Interface Matching
I arrived at the kernel system by making a number of simplifications to the system I
have described so far. I am now going to discuss each of these simplifications in turn,
describing a series of increasingly simple systems, ending with the actual kernel system.

One simplification I made was to treat extended interface matching (reordering and
dropping module fields using subsumption) as an extension, rather than building it into
the kernel system directly. The intent is that this ability be provided by a separate preprocessing phase that elaborates an extended version of the kernel language with implicit
extended interface matching into the kernel system by inserting coercion functions where
necessary.

For example, if the input program at some point used implicit subsumption to convert the term M 's type from interface val x:int; val y:bool; end to interface val
y:bool; val x:int; end, then the elaborator would insert an application of the following function to M at that point:

functor (m:interface val x:int; val y:bool; end)

module val y=m.y; val x=m.x; end

Note that no coercions would be required if only equality or forgetting had been used.

In essence, this is just treating where and how to insert field-manipulation coercions
as a form of type inference to be performed by the elaborator. This decision allows
the kernel system and its proofs to be simplified greatly. Note that showing soundness
for the extended system reduces to just verifying that the output of the elaborator is
always well typed in the kernel system, given a soundness proof for the kernel system.
Another advantage of this choice is that it avoids hardwiring a particular set of subtyping
rules into the kernel system; this is probably wise given that there is some uncertainly
about what the best choice of subtyping rules is for handling component reordering (see
Section 13.2) and the difficulty of changing the kernel-system proofs.

5.4 Unnamed Binary Sums
Without the ability to reorder or drop module fields using subsumption, there is no good
reason in a kernel system to have labeled fields or n-ary (as opposed to binary) sums, so

56 CHAPTER 5. OVERVIEW
I have eliminated those features as well (see Section 13.1 for how they might be added
back as an extension). Thus, code like

M = module val x=3; val y=4; val z=y+1; end;

N = module constr T=int; end;
sum:N.t = M.x + M.y + M.z;
must first be translated to use only binary unnamed sums before it can be expressed in
the kernel system. For example, the above code could be translated as

M = module

val x=3;
val module

val y=4;
val module val z=y+1; val 0; end;
end;
end;

N = module constr T=int; val 0; end;
sum:N.1 = M.1 + M.2.1 + M.2.2.1;
Here I am using the notation module val x=M 1; val M 2; end to denote a binary
unnamed module with two value components, the first equal to M 1 and the second equal
to M 2. These components can be selected only by number (i.e., M :1 or M :2). The
syntax includes an internal name (x) for the first component that allows it to be referred
to in M 2 (e.g., see the y and z fields above). This name is not in scope anywhere else
and cannot be used to select the first component from outside the module. It thus acts
like a local variable and can be ff-varied as desired. Either or both components can be
replaced by constructor components with the obvious syntax.

As a further simplification, I have removed the internal naming described above from
simple-module expressions, yielding module creation constructs like module val M 1;
val M 2; end. I did this because internal naming in simple-module expressions can be
desugared into the use of a let statement, which in turn can be desugared to a function
application:

module val x=M 1; val M 2; end

,! let x=M 1 in module val x; val M 2; end end
,! (functor (x:A) module val x; val M 2; end) M 1

5.5. REIFIED CONSTRUCTORS 57
where M 1 has type A. The case where the first component is a constructor is even simpler
because the let statement in that case can be reduced using simple substitution:

module constr ff=A1; val M 2; end

,! let constr ff=A1 in module constr ff; val M 2; end end
,! module constr A1; val [A1=ff]M 2; end
Accordingly, internal naming is not essential in simple-module expressions. I have
thus removed it in order to simplify the operational semantics of the kernel system by
avoiding the need to include the following reduction step:

module val x=V 1; val M 2; end

,! module val V 1; val [V 1=x]M 2; end
Note that internal naming is still present and needed in interfaces because not all
dependencies can be broken. Consider, for example, the following interfaces for unnamed
binary sums:

interface constr T::type; val list(T); end

interface

val M:interface constr T::type; constr ::type; end;
constr FUNCTOR (x:M.T):M.U;
end

5.5 Reified Constructors
As a further simplification, I have factored the unlabeled binary translucent sums of the
previous section into two simpler constructs, a standard dependent sum and a new construct called a reified constructor. A standard dependent sum (module M 1; M 2; end
: interface x:A1; A2; end) is a binary unlabeled module that contains only value
components. Only the fact that the type of its second component may depend on its
first component distinguishes it from an ordinary pair.

In order to encode translucent sums using standard dependent sums, it is necessary
to have some way of encoding constructor components as value components. Reified
constructors provide a way to do this encoding. They allow taking a constructor A
and reifying it into a term, !A?. The resulting reified-constructor term is an ordinary
value, which can be manipulated in any of the usual ways. The constructor contained

58 CHAPTER 5. OVERVIEW
in a reified-constructor extended value * can be extracted by writing *!. Constructor
extraction (\Gamma !) is limited to extended values because of the extended-value restriction.

Reified constructors can be given either opaque (!K?) or transparent
(!=A::K?) types; K here specifies the kind of the constructor the reified-constructor
term contains. Similarly to the translucent-sum case, *! will be equal to A if * has the
transparent type !=A::K?. Essentially, a reified constructor is just a degenerate form of
translucent sum that contains exactly one unlabeled constructor field. The behavior and
type rules of standard dependent sums and reified constructors are what you would expect
from applying the original translucent-sum rules to translucent sums restricted either
to have only two unlabeled value components or one unlabeled constructor component
respectively.

Any unlabeled binary translucent sum can be easily encoded into one standard dependent sum and zero to two reified constructors where each constructor field in the
original translucent sum is represented using a reified constructor. Some representative
examples follow:

module val M 1; val M 2; end :
interface val x:A1; val A2; end

,! module M 1; M 2; end :

interface x:A1; A2; end

module val M 1; constr A2; end :
interface val x:A1; constr ::K2; end

,! module M 1; !A2?; end :

interface x:A1; !K2?; end

module constr A1; val M 2; end :
interface constr ff=A1; val A2; end

,! module !A1?; M 2; end :

interface x:!=A1::K1?; [x!=ff]A2; end

module constr A1; constr A2; end :
interface constr ff::K1; constr A2; end

,! module !A1?; !A2?; end :

interface x:!K1?; [x!=ff]!=A2::K2?; end

Note that we no longer need to allow transparent declarations (constr ff=A) in assignments because they are not needed to type check dependent sums or reified constructors
and because their presence in assignments can be encoded away via a similar encoding.

5.6. RULES AND RESTRICTIONS 59

This factoring simplifies the system in two main ways. First, it avoids the need to
discriminate on the sort of fields a translucent sum has. If the field sorts matter, then
there are four distinct cases that may need to be considered under the original system; if
the transparency/opacity of a constructor component matters as well, then the number
rises to nine cases. (E.g., the need to give four different sample encodings above.) In the
factored system, only one case of sums and possibly two cases of reified constructors ever
need to be considered.

Second, it eliminates the redundancy in the original system of having two separate
ways of specifying a constructor abbreviation: directly via a constructor field (e.g., constr ff=A in an assignment \Gamma ) and indirectly via a constructor field of a translucent sum.
Because of this redundancy, for example, the original system I described needed two rules
to handle equality for constructor abbreviations (ABBREV and ABBREV0) whereas the
kernel system needs only one. In the kernel system, constructor abbreviations are specified only indirectly via a reified constructor. The original formulation is likely to be
preferred for an actual programming language because it probably produces a slightly
more efficient implementation in practice (see Section 13.1).

5.6 Rules and Restrictions
As another simplification, I changed where the EVALUE rules can be applied. Originally,
they could be used at any point in a proof, so long as the term being typed was an
extended value. However, it is not hard to see that any such proof can be normalized
so that the EVALUE rules are only used immediately after a term variable has been
introduced on that variable and its (sub)-components. (The EVALUE rules are not
needed to give fully-defined transparent minimal types to the other extended values.)
Because such proofs are easier to reason about, I have restricted the application of the
EVALUE rules to places (term variables and their (sub)-components) so that only such
normalized proofs can be constructed. This restriction has no effect on what terms can
be given what types.

I have also further restricted what term expressions are allowed in constructors so
that only places (x:i1 \Delta  \Delta  \Delta  :in) may occur in constructors. In the system I described in
the first part of this dissertation, arbitrary extended values could appear in constructors.
However, in that system any valid constructor containing extended values could be replaced with an equal valid constructor that contains only places. Because the equality of
two constructors that contain only places need never involve constructors that contain
terms other than places (this can be shown via a confluence argument), the ability to
have constructors containing arbitrary extended values was really useful only as a way
of explaining how substitution of values for term variables in constructors works.

In the kernel system, value substitution is instead handled directly via a special

60 CHAPTER 5. OVERVIEW
notion of substitution (see Section 11.6) that does any selections needed to reduce values
to places at substitution time. For example, the following holds using this notion of
substitution:

[module !A1?; !A2?; end/x]x.2! = A2
This restriction to places allows a more specialized method (see Section 6.4) to be
used to determine the identity and kind of a constructor extraction, breaking the dependency in the first part's system on the subtyping and well-formed term judgments by the
constructor validity and equality judgments. (These dependencies are caused by the VDOT and ABBREV0 rules, which require typing the term * -- possibly using subtyping
-- in order to decide if *:ff is valid or what it is equal to.) Removing these dependencies
greatly simplifies the proofs.

I have also introduced a new self function similar to Leroy's strengthening operation
(see Sections 11.1 and 14.3 for details), which captures the effect on a place's type of
applying a series of EVALUE rules in a row. More precisely, if starting from the fact
that \Gamma  ` x:i1 \Delta  \Delta  \Delta  :in : A we can derive the type A0 for x:i1 \Delta  \Delta  \Delta  :in using just the EVALUE
and I-SELECT rules, then we can get a type equal to A0 under \Gamma  by applying the function
[self=x:i1 \Delta  \Delta  \Delta  :in] to a type equal to A under \Gamma . The introduction of self allowed me to
further normalize the proofs by replacing the EVALUE rules by a single application of
the self function when term variables are introduced.

5.7 Notation

Because of the great volume of the proofs, I shall use a more concise, mathematical,
and traditional notation to describe the actual kernel system. Figure 5.1 contains a
translation key from the notation I have used before this point into the corresponding
kernel-system notation. In addition to the notation shown in this figure, the kernel system
has two primitive constructors (rec and ref) and five primitive functions (roll, unroll,
new, get, and set). These provide the functionality of recursive types and references
(mutable cells) and are described in the next section.

5.8 System Summary
In this section I provide a mostly self-contained quick overview of my kernel system.
Complete details will be provided in later chapters as I consider each part of the system
in turn.

My kernel system is based on Girard's F! [15] in much the same way that many systems are based on the second-order lambda calculus (F2). That is to say, my system can

5.8. SYSTEM SUMMARY 61

Dependent Sums: module M 1; M 2; end (M 1; M 2)

interface x:A1; A2; end \Sigma x:A1: A2
M .i M :i

Reified Constructors: !A? !A?

!K? !K?
!=A::K? !=A::K?
x:i1 \Delta  \Delta  \Delta  :in! x:i1 \Delta  \Delta  \Delta  :in!

Functors: functor (x:A) M *x:A: M

FUNCTOR (x:A) A0 \Pi x:A: A0
M 1 M 2 M 1 M 2

Type Coercions: M !:A M !:A
Constructors: *ff::K: A *ff::K: A

A1(A2) A1 A2

Kinds: type \Omega 

K1)K2 K1)K2

Declarations: val x:A x:A

constr ff::K ff::K

Assignments: D1; : : : ; Dn ffl; D1; : : : ; Dn

Figure 5.1: The translation into kernel-system notation

62 CHAPTER 5. OVERVIEW
be (roughly) thought of as being obtained from F! by adding more powerful constructs
(dependent functions, dependent sums, reified constructors, references, and recursive
types) and a notion of subtyping and then removing the old constructs (quantification1
(8), weak sums (9), and non-dependent functions (!)) superseded by the new ones.
Subtyping interacts with the rest of the calculus via implicit subsumption. Bounded
quantification is not supported.

Like F!, my system is divided into three levels: terms, (type) constructors, and
kinds. Kinds classify constructors, and a subset of constructors, called types, having
kind \Omega  classify terms. The kind level is necessary because the constructor level contains
functions on constructors. Example: the constructor *ff::\Omega : ref ff has kind \Omega )\Omega  and
when applied to type int yields ref int. There is no separate module system level; all
terms including dependent sums, dependent functions, and reified constructors are firstclass.

5.8.1 Module Constructs
Grouping in my system is handled by (binary unlabeled) dependent sums. Dependentsum terms are written (M 1; M 2) with corresponding type \Sigma x:A: A0. As the form of their
type indicates, the type of their second component may depend on the value of their first
component. Ordinary pairs are a degenerate form of dependent sums where there is no
dependency. The elimination forms are M :1 for the first component of M and M :2 for
the second component of M .

Functional abstraction is handled in my system by dependent functions, denoted by
*x:A: M with corresponding type \Pi x:A: A0. The result type of an application (M 1 M 2)
may depend on the value of the argument (M 2). Ordinary functions are a degenerate
form of dependent functions where there is no dependency.

The ability to include constructor components in a module with optional identity
information is handled by reified constructors. Reified constructors allow packing up a
constructor A of kind K into a term, written !A?. This term has both a transparent
type, !=A::K?, with information on the identity of its constructor component, and an
opaque type, !K?, with no such information. The opaque type is a supertype of the
transparent one, allowing the component information to be forgotten later.

Because terms in constructors are limited to places, the elimination form for reified
constructors is syntactically limited to places. If x:i1:i2 \Delta  \Delta  \Delta  :in (n * 0) denotes a reified
constructor, then x:i1:i2 \Delta  \Delta  \Delta  :in! denotes the constructor it contains. If x:i1:i2 \Delta  \Delta  \Delta  :in has
type !=A::K? under assignment \Gamma  then the equation x:i1:i2 \Delta  \Delta  \Delta  :in! = A will hold under
\Gamma .

1Quantification is derivable from dependent functions and reified constructors. See Section 5.8.1 for
details.

5.8. SYSTEM SUMMARY 63

Quantification is a derived form in my system, resulting from a combination of reified
constructors and dependent functions. The quantified term \Lambda ff::K:M , which denotes the
term M parametrized by a constructor of kind K named ff, can be regarded as standing
for *x:!K ?: [x!=ff]M , where x is not free in M , and the instantiation M [A], which
denotes instantiating the quantified term M with the constructor A, can be regarded as
standing for M !A?.

Aside from the exceptions already mentioned (forgetting component information, constructor abbreviations), the equality and subtyping rules are standard. The programmer
can use an explicit coercion (written M !:A) where desired to force a term M to be
coerced to a supertype A. Coercions in the kernel system have no semantic effect; their
only effect is to discard type information. Coercions may have semantic effects in extensions however. Also present is the machinery (a EVALUE-like rule, restrictions in
the elimination rules for dependent sums and products) needed to properly propagate
information about constructor components solely through the type level.2

5.8.2 References and Recursive Types
SML-like references are provided by three built-in primitives: new, get, and set. If M
is a term that denotes a value of type A then new !A? M returns a new reference with
initial value M . The resulting reference has type ref A. Given a term M that denotes
a reference containing values of type A, get !A? M returns the current value of that
reference. Finally, given a term M 1 that denotes a reference containing values of type A
and a term M 2 denoting a value of type A, set !A? M 1 M 2 sets the reference's value to
be M 2 then returns that value.

Recursive types are implemented by means of an isomorphism between rec A and
A (rec A) mediated by two primitives roll and unroll (here A is of kind \Omega )\Omega ). roll !A?
maps terms of type A (rec A) to terms of type rec A and unroll !A? does the opposite.
Semantically, for properly typed V 1 and V 2's, unroll !A? (roll !A? V 1) = V 1 and
roll !A? (unroll !A? V 2) = V 2. As an example of the use of recursive types, I have
sketched in Figure 5.2 an implementation of integer lists written in SML-like pseudo-code
(rather than kernel-system notation) using some simple extensions to the kernel system.

In the example, the term fg denotes the only value of the type unit and the type
A1 + A2 denotes a disjoint union type; the disjoint union's values are inLeft(V 1) and
inRight(V 2) where V 1 is of type A1 and V 2 is of type A2. The disjoint union destructors
are asLeft and asRight; they raise the exception fail if their argument is of the wrong
sort. The function isLeft checks to see if its argument is of the left sort. I have
omitted "type information", such as applications to !intIter?, that type inference
might supply. (My system does not have a unit type, disjoint union's, exceptions, or

2The discussion of this machinery, how it works, and why it is needed, can be found in Chapter 4.

64 CHAPTER 5. OVERVIEW

(*

* Set things up so that intList ,= unit + (int, intList)
* via roll and unroll:
*)
constr intIter = *ff::\Omega . unit + (int, ff);
type intList = rec intIter;

val nil = roll (inLeft fg) ;
fun cons(x:int, y:intList) = roll (inRight (x, y));

fun hd(x:intList) = (asRight(unroll x)).1;
fun tl(x:intList) = (asRight(unroll x)).2;

fun isNil(x:intList) = isLeft(unroll x);

Figure 5.2: Implementing integer lists with recursive types
extensive type inference; I am using them here only for illustrative purposes.)
5.8.3 Semantics
Evaluation proceeds in a deterministic manner from left to right in a call-by-value manner.
Evaluation does not proceed under quantifications because quantification translates into
a lambda abstraction. My system differs in this regard from SML which does evaluate
under quantifications. See [19] for a discussion of the differences between these two
interpretations of quantifications and why this choice seems to be preferable. In the
terminology of that paper, my system implements the standard call-by-value semantics
for F! extended with the obvious implementations of references and recursive types.
Note that non-termination is a possible result of evaluation because of the inclusion of
recursive types. (E.g., recursive types can be used to implement a fixed point operator.)

5.9 On the Nature of the Proofs
Even after all the simplifications I have implemented, my kernel system is still a large and
complicated system when compared with the sort of systems that are usually analyzed
formally. For example, the system has 48 type rules using 8 auxiliary functions, 10 ways
of building constructors, 13 ways of building terms, and 8 evaluation rules. There are also
a number of dependencies in the system not possessed by simpler systems: constructors

5.10. ORGANIZATION 65
can depend on term variables, the validity of constructors and the equality of constructors
judgments are mutually recursive, and the equality of two constructors depends on the
assignment under which they are compared.

These dependencies greatly increase the difficulty level of the needed proofs. For
example, they prevent using any of the standard methods for establishing normalization
or confluence of constructors. Novel methods or extensions to existing methods must be
invented to handle them.

Mutually dependent definitions also reduce the modularity of the proofs. It is not
possible, for example, to separate the results about the validity of constructors from those
about the equality of constructors. Indeed, the intertwined proofs of those results take
up four full chapters! The choices of proof methods for the various parts are also highly
interdependent: Proof methods in order to work well often require that the type system
be structured in certain ways; unfortunately, these requirements often conflict, preventing
proof methods for different parts of the system from being chosen independently.

These facts make the process of designing and proving correct the kernel system
resemble that of solving an NP-complete problem: There are many choice points and
the complexity and sheer size of the problem prevent effective lookahead, resulting in
extensive guess work and backtracking until a solution is found. Many times I discovered
only after months of work that a particular proof method was unusable and had to be
discarded because of a subtle interaction with another part of the system.

Like what often happens when solving real NP problems, time limits have prevented
me from finding an optimal solution. There was simply no time to try each choice to
see which is best; many of my choices are accordingly just the first choice I tried that
worked. Better choices almost certainly exist. I have briefly summarized at the major
choice points which alternatives I considered, why I tried the ones I did, and why many
of them failed to work. Space limitations and the complexity of the interactions between
many choices prevent me from giving more details. I have also included speculations on
which choices seem better based on hindsight. It is my hope that these will benefit future
designers of systems like this one.

5.10 Organization
I have split up the description of my system and the accompanying proofs into four major
sections: constructor validity and equality, subtyping, soundness, and type checking. To
improve the presentation, I delay introducing parts of the system until they are needed.
For example, terms are not discussed until the section on soundness. For the reader's
convenience, Appendix A contains a complete copy of all the system definitions together
in one place. Briefly, the material covered in each of the chapters devoted to the kernel
system is as follows.

66 CHAPTER 5. OVERVIEW

Chapters 6 to 9 cover constructor validity and equality as a unit. Chapter 6 introduces
the kind and constructor levels of the system and gives the rules for the valid constructor
and equality judgments. It also introduces an alternative formulation called the tagged
system where term variables in types are tagged with their assigned type. These tags
allow the equality of tagged constructors to be decided independently of the assignment
they are being compared under. Chapters 7 and 8 prove the needed results about the
more tractable tagged system which are then transferred back to the original system in
Chapter 9.

In Chapter 7, I use fairly standard methods to introduce a rewriting relation on
constructors for the tagged system and show that it is confluent, that it preserves typing,
and that it implements equality.3 Because rewriting also preserves the outer shape of a
constructor (roughly, is it a function type?, a sum type?, etc.), I am also able to establish
results about what sort of outer shapes two equal constructors can have as well as show
that equal constructors of the same outer shape must have equal subcomponents under
the appropriate assignments. One consequence, for example, is that function types can
never be equal to sum types.

In Chapter 8, I give an algorithm for deciding if a constructor in the tagged system
is valid. In the process of validity checking, the algorithm reduces the constructor using
the previously introduced rewrite relation. If the constructor is found to be valid, the
algorithm returns a normal form for that constructor. Using this algorithm, I show that
all the judgments of the tagged system are decidable and that normal forms for valid
constructors are computable.

In Chapter 9, I show how to translate judgment derivations back and forth between
the two systems using notions of tag removal and stamping. I then translate the results
from the previous two chapters on the tagged system to the original system. This translation shows, for example, that the original valid constructor and equality judgments are
decidable. The translation of the normal form results is somewhat tricky and is handled
by what amounts to an abstract data type: The definition of the untagged normal form
property uses the tagged system; however, I provide sufficient theorems so that later uses
of the property need not use the the tagged system results directly.

Chapter 10 introduces the subtyping relation. Much of the chapter is devoted to
proving that judgments may be weakened by replacing a type in the assignment with a
subtype of the original type. I also establish results about the shape and sub-components
of subtypes. Using these results, I prove correct a semi-decision procedure for subtyping.
I show that one cannot do better by proving that subtyping is undecidable.

Chapter 11 introduces the term level and lays out the kernel system's semantics. The
weakening by a subtype result from the previous chapter is extended to the well-typed

3By implements equality, I mean that the reflexive, symmetric, and transitive closure of the rewriting
relation is the same as the equality relation modulo the validity of the argument constructors.

5.10. ORGANIZATION 67
term judgment with some difficulty due to the self function . Using this result, I show
that the system is sound -- evaluation is deterministic, does not become stuck, and
preserves typing.

Finally, Chapter 12 discusses type checking. To make the problem more tractable, I
remove some of the built-in type inference in the system. In particular, some coercions
must now be indicated explicitly by the programmer instead of being automatically
inferred. I show that the restricted well-typed term judgment is semi-decidable (decidable
modulo subtyping) by proving correct a decision procedure.

68 CHAPTER 5. OVERVIEW
Chapter 6
Types: Setup
Beginning in this chapter, and continuing for the next three chapters, I discuss the
kind and constructor levels of my kernel system, including the notions of constructor
validity and constructor equality, but omitting the notion of subtyping which I discuss
in Chapter 10. In particular, I establish the major results about these notions, namely
decidability and the results about how constructors behave under equality. I also establish
numerous minor results such as strengthening that are needed for later proofs.

6.1 Kinds and Constructors
Definition 6.1.1 (Syntax for the constructor and kind levels)

Kinds K ::= \Omega  j K)K0
Constructors A ::= ff j \Pi x:A: A0 j \Sigma x:A: A0 j *ff::K: A j A A0 j

!K? j !=A::K? j xae! j rec j ref
Paths ae ::= ffl j ae:1 j ae:2

Assignments \Gamma  ::= ffl j \Gamma ; D
Declarations D ::= ff::K j x:A

Here, the metavariable ff ranges over constructor variables and the metavariable x
ranges over term variables. The kind \Omega  denotes the kind of constructors that classify
terms (i.e., types). The empty path is denoted by ffl and the empty assignment by ffl. For
convenience, I shall sometimes omit them in non-empty paths and assignments, writing,
for example, :1 for ffl:1 and ff::K for ffl; ff::K. I shall refer to xae's as places and to xae!'s as
constructor extractions.

69

70 CHAPTER 6. TYPES: SETUP

Objects of the kernel system are considered equivalent if they differ only by ffconversion; the only exception is that assignments with no redeclared variables are never
considered equivalent to assignments with redeclared variables. This exception allows
the valid assignment judgment to require that valid assignments never redeclare variables, simplifying the system. Scoping is as expected and we have the obvious notions
of free constructor variables (FCV(\Gamma )), free term variables (FTV(\Gamma )), and constructor
substitution ([A=ff]\Gamma ) on constructors, declarations, and assignments:

Definition 6.1.2 (Free constructor variables)

FCV(ff) = fffg
FCV(*ff::K: A) = FCV(A) \Gamma  fffg
FCV(\Pi x:A1: A2) = FCV(A1) [ FCV(A2)
FCV(\Sigma x:A1: A2) = FCV(A1) [ FCV(A2)

FCV(A1 A2) = FCV(A1) [ FCV(A2)
FCV(!=A::K?) = FCV(A)

FCV(!K?) = ;

FCV(xae!) = ;
FCV(rec) = ;

FCV(ref) = ;

FCV(ff::K) = ;

FCV(x:A) = FCV(A)

FCV(ffl) = ;
FCV(\Gamma ; D) = FCV(\Gamma ) [ FCV(D)

6.1. KINDS AND CONSTRUCTORS 71
Definition 6.1.3 (Free term variables)

FTV(xae!) = fxg
FTV(\Pi x:A1: A2) = FTV(A1) [ (FTV(A2) \Gamma  fxg)
FTV(\Sigma x:A1: A2) = FTV(A1) [ (FTV(A2) \Gamma  fxg)

FTV(*ff::K: A) = FTV(A)

FTV(A1 A2) = FTV(A1) [ FTV(A2)
FTV(!=A::K?) = FTV(A)

FTV(ff) = ;
FTV(!K?) = ;

FTV(rec) = ;

FTV(ref) = ;

FTV(ff::K) = ;

FTV(x:A) = FTV(A)

FTV(ffl) = ;
FTV(\Gamma ; D) = FTV(\Gamma ) [ FTV(D)

Definition 6.1.4 (Constructor substitution)

[A=ff]ff = A
[A=ff]ff0 = ff0 (ff 6= ff0)
[A=ff]*ff0::K: A0 = *ff0::K : [A=ff]A0 (ff0 6= ff; ff0 62 FCV(A))
[A=ff]\Pi x:A1: A2 = \Pi x:[A=ff]A1: [A=ff]A2 (x 62 FTV(A))

[A=ff]\Sigma x:A1: A2 = \Sigma x:[A=ff]A1: [A=ff]A2 (x 62 FTV(A))

[A=ff](A1 A2) = [A=ff]A1 [A=ff]A2
[A=ff]!=A0::K? = !=[A=ff]A0::K ?

[A=ff]!K? = !K?

[A=ff]xae! = xae!
[A=ff]rec = rec

[A=ff]ref = ref

[A=ff](ff0::K) = ff0::K

[A=ff](x:A0) = x:[A=ff]A0

[A=ff]ffl = ffl
[A=ff](\Gamma ; D) = ([A=ff]\Gamma ); [A=ff]D

Because paths and assignments are lists, it is useful from time to time to have a
notation for appending them. I shall use ae1ae2 to denote ae2 appended to ae1 and \Gamma 1; \Gamma 2 to
denote \Gamma 2 appended to \Gamma 1. Assignments can also be regarded usefully as partial functions:

72 CHAPTER 6. TYPES: SETUP
Definition 6.1.5 (Assignment regarded as a partial function)

dom(ffl) = ;
dom(\Gamma ; x:A) = dom(\Gamma ) [ fxg
dom(\Gamma ; ff::K ) = dom(\Gamma ) [ fffg

(\Gamma 1; x:A; \Gamma 2)(x) = A (x 62 dom(\Gamma 1))
With the exception of subtyping, which shall be discussed later, there are four judgments at the kind and constructor levels:

Definition 6.1.6 (Judgments)

` \Gamma  valid valid assignment

\Gamma  ` A :: K valid constructor
\Gamma  ` A = A0 :: K equal constructors

\Gamma  ` xae ) A place lookup
All of these judgments are defined mutually recursively. For example, the valid assignment judgment checks that each constructor appearing in a valid assignment is valid
under the immediately preceding part of that assignment. Place lookup is an auxiliary
judgment used by the valid and equal constructor judgments.

The kind of the constructor xae! and what it is equal to depend on the type of the
term xae. For example, if xae has type !=A::K? then xae denotes a reified constructor
containing a constructor of kind K that is known to be equal to A so xae! has kind K
and is equal to A. The place lookup judgment is used to determine the type of terms of
this form. If \Gamma  ` xae ) A then xae has type A under assignment \Gamma .

Rather than being defined directly in terms of the well-formed term judgment, which
assigns types to terms, the place lookup judgment is defined using a highly specialized
copy of the machinery needed to determine a term's type. This copying and specialization
allows the valid and equal constructor judgments to not depend on the subtyping or wellformed term judgments, greatly simplifying the system.

I shall present the details of these four judgments shortly, but first I need to discuss
my overall proof strategy so the organization of the rules will make sense.

6.2 Proof Strategy
The key result that needs to be established about the valid and equal constructor judgments is the existence of a confluent rewriting relation that implements equality and

6.2. PROOF STRATEGY 73
under which all valid constructors have normal forms. This result allows the equality of
two valid constructors to be easily tested by simply normalizing both constructors then
testing them to see if they are the same modulo ff-conversion. More generally, the same
procedure can also be used to determine constructively if a given valid constructor is
equal to any valid constructor of a certain shape. This ability is needed in order to show
constructor validity checking decidable.

Unfortunately, because the equality of two constructors in my system depends on
the assignment under which they are compared (e.g., under x:!=A::\Omega ?, x! = A), the
standard methods for establishing confluence cannot be used. After extensive searching, I
have found only two approaches that seem promising. Both are based on the well-known
idea of showing confluence via a rewriting relation which has the diamond property.

A rewriting relation has the diamond property if for any A that rewrites to A1 and
to A2, each in a single step, we can find an A0 such that A1 and A2 both rewrite to A0
in a single step. Confluence follows immediately from this property via a simple "fill-inthe-grid" proof (see Section 7.2 for details). In order to use this proof method effectively,
the rewriting relation must be simple. By simple, I mean roughly that a single step of
the rewriting relation must do only a small amount of work on each sub-constructor. If
the rewriting relation is not simple then proving the diamond property is no easier than
proving confluence directly.

The simple property is not easy to arrange in the presence of reified constructors. In
particular, the obvious rule for rewriting x! is as follows. (I am ignoring paths throughout
this section to simplify the discussion.)

\Gamma (x) !\Lambda \Gamma  !=A::K ?

x! !\Gamma  A (OBVIOUS)

Note that this rule can do an arbitrary amount of work (!\Lambda  denotes the transitive closure
of !) in a single step and is thus not simple.

Each of my two possible approaches handles the problem of how to obtain a simple
rewriting relation in a different way. In the assignment approach, assignments are rewritten in parallel with constructors. The rule for rewriting x! can then deal with only the
last step of rewriting the type of x:

\Gamma (x) !\Gamma  !=A::K ?

x! !\Gamma  A (ASSIGN)

The main rule for rewriting assignments is as follows:

\Gamma  ! \Gamma 0 A !\Gamma 0 A0

\Gamma ; x:A ! \Gamma 0; x:A0 (STAGED)

74 CHAPTER 6. TYPES: SETUP

Note that A is rewritten using \Gamma 0 rather than \Gamma ; this is necessary to obtain the diamond
property. Under this approach A and A0 will be equal under \Gamma  iff \Gamma ; x:A and \Gamma ; x:A0
(x 62 dom(\Gamma )) have a common reduct.

The Tagging approach, on the other hand, introduces a separate tagged system where
term variables are tagged with their type (written xA). This allows x's type to be
rewritten in a series of steps before x! is reduced:

A1 ! A2
xA

1 ! ! xA2 !

(TAG)

A ! !=A0::K?

xA! ! A0 (REDUCE)

The type rules of the tagged system require that if xA occurs in a constructor valid
under \Gamma  then \Gamma (x) is equal to A under \Gamma . This requirement ensures that the tags are
consistent with the assignment. In essence, where the assignment approach reduces x's
type in place (in the assignment), the tagging approach reduces a local copy of x's type.

The tagging approach has the advantage that its rewriting relation does not depend
on the assignment. This fact greatly simplifies its confluence and normalization proofs.
However, once proved, the results on the tagged system must be carefully transfered
back to the original untagged system because tagging is incompatible with subtyping.
(Subtyping alters assignments, replacing types with subtypes or supertypes; there is no
good way to maintain the consistency of the tags with the assignment in this case.) This
transfer can be accomplished by transforming derivations between the two systems using
tag removal and stamping (replacing x by x\Gamma (x) where \Gamma  is the current assignment).

It is not at all obvious which of these two approaches is better. The tagging approach
seems to have simpler proofs but is more verbose (two systems instead of one) and requires
extra work to transfer the results. Given the information I had at the time, I chose to
go with the tagging approach. In hindsight, it is not clear that this was the best choice.
I discuss further, using the benefit of hindsight, this and other decisions in Section 9.7.

Summarizing, my basic proof strategy for Chapters 6 to 9 is to do the following:

ffl Describe the original (untagged) system
ffl Describe the corresponding tagged system
ffl Describe a rewriting relation that implements tagged equality
ffl Prove the rewriting relation confluent via the diamond property
ffl Show normalization and the other desired results for the tagged system
ffl Transfer the results back to the original system

6.3. THE TYPE RULES 75
Note that in order to make the transfer and equality implementation proofs easy, I
have designed the two systems and the rewrite relation to mirror each other as much as
possible.

6.3 The Type Rules
The rules for the (untagged) judgments we are considering are given below. Aside from
the rules dealing with reified constructors (C-OPAQ, C-TRANS, C-EXT-O, C-EXT-T, ETRANS, and E-ABBREV) and place lookup (P-INIT and P-MOVE), they are standard.
I shall defer discussion of the place lookup rules and the defining of the selection function
(S(A; xae; ae0)) until the next section.

Definition 6.3.1 (Assignment Formation Rules)

` ffl valid (EMPTY)

` \Gamma  valid ff 62 dom(\Gamma )

` \Gamma ; ff::K valid (DECL-C)

\Gamma  ` A :: \Omega  x 62 dom(\Gamma )

` \Gamma ; x:A valid (DECL-T)

Definition 6.3.2 (Constructor Formation Rules)

` \Gamma  valid ff::K 2 \Gamma 

\Gamma  ` ff :: K (C-VAR)

\Gamma ; x:A ` A0 :: \Omega 
\Gamma  ` \Pi x:A: A0 :: \Omega  (C-DFUN)

\Gamma ; x:A ` A0 :: \Omega 
\Gamma  ` \Sigma x:A: A0 :: \Omega  (C-DSUM)

\Gamma ; ff::K ` A :: K0
\Gamma  ` *ff::K: A :: K)K 0 (C-LAM)

\Gamma  ` A1 :: K2)K \Gamma  ` A2 :: K2

\Gamma  ` A1 A2 :: K (C-APP)

` \Gamma  valid
\Gamma  ` !K? :: \Omega  (C-OPAQ)

76 CHAPTER 6. TYPES: SETUP

\Gamma  ` A :: K
\Gamma  ` !=A::K? :: \Omega  (C-TRANS)

\Gamma  ` xae ) !K?

\Gamma  ` xae! :: K (C-EXT-O)

\Gamma  ` xae ) !=A::K?

\Gamma  ` xae! :: K (C-EXT-T)

` \Gamma  valid
\Gamma  ` rec :: (\Omega )\Omega ))\Omega  (C-REC)

` \Gamma  valid
\Gamma  ` ref :: \Omega )\Omega  (C-REF)

Definition 6.3.3 (Constructor Equality Rules)

\Gamma  ` A :: K
\Gamma  ` A = A :: K (E-REFL)

\Gamma  ` A0 = A :: K
\Gamma  ` A = A0 :: K (E-SYM)

\Gamma  ` A = A0 :: K \Gamma  ` A0 = A00 :: K

\Gamma  ` A = A00 :: K (E-TRAN)

\Gamma  ` A1 = A01 :: \Omega 
\Gamma ; x:A1 ` A2 = A02 :: \Omega 
\Gamma  ` \Pi x:A1: A2 = \Pi x:A01: A02 :: \Omega  (E-DFUN)

\Gamma  ` A1 = A01 :: \Omega 
\Gamma ; x:A1 ` A2 = A02 :: \Omega 
\Gamma  ` \Sigma x:A1: A2 = \Sigma x:A01: A02 :: \Omega  (E-DSUM)

\Gamma ; ff::K ` A = A0 :: K0
\Gamma  ` *ff::K: A = *ff::K: A0 :: K )K0 (E-LAM)

\Gamma  ` A2 = A02 :: K
\Gamma  ` A1 = A01 :: K)K 0
\Gamma  ` A1 A2 = A01 A02 :: K0 (E-APP)

6.3. THE TYPE RULES 77

\Gamma  ` A = A0 :: K
\Gamma  ` !=A::K? = !=A0::K? :: \Omega  (E-TRANS)

\Gamma ; ff::K ` A :: K0 \Gamma  ` A0 :: K
\Gamma  ` (*ff::K: A) A0 = [A0=ff]A :: K0 (E-BETA)

\Gamma  ` A :: K)K0 ff 62 FCV(A)

\Gamma  ` *ff::K : A ff = A :: K)K 0 (E-ETA)

\Gamma  ` xae! :: K \Gamma  ` xae ) A \Gamma  ` A = !=A0::K0? :: \Omega 

\Gamma  ` xae! = A0 :: K (E-ABBREV)

Definition 6.3.4 (Place Lookup Rules)

` \Gamma  valid x:A 2 \Gamma 

\Gamma  ` x ) A (P-INIT)

\Gamma  ` xae ) A \Gamma  ` A = A0 :: \Omega  A00 = S(A0; xae; ae0)

\Gamma  ` xaeae0 ) A00 (P-MOVE)

I have designed these rules and those of all the other judgments I shall discuss later
so that the following structural property holds: all the sub-components of a judgment
are either valid or well-typed as appropriate. For example, if \Gamma  ` A1 = A2 :: K then it
will be true that ` \Gamma  valid, \Gamma  ` A1 :: K, and \Gamma  ` A2 :: K. This result is immediate for
assignments:

Lemma 6.3.5 (Structural property)

1. A derivation of ` \Gamma ; D valid contains ` \Gamma  valid as a sub-derivation.
2. A derivation of \Gamma  ` A :: K contains ` \Gamma  valid as a sub-derivation.
3. A derivation of \Gamma  ` A1 = A2 :: K contains ` \Gamma  valid as a sub-derivation.
4. A derivation of \Gamma  ` xae ) A contains ` \Gamma  valid as a sub-derivation.
Proof: By simultaneous structural induction on the typing derivations. 2

The fact that ` \Gamma  valid is actually a sub-derivation is useful when using proof by induction
on typing derivations. Note that because valid assignments are required not to redeclare
variables, this result means that in rules such as C-DFUN we must have that x 62 dom(\Gamma ).

78 CHAPTER 6. TYPES: SETUP

The structural property is much harder to establish for constructors and terms and
is proved much later. This fact results from a design choice: I could have added extra
conditions to the rules that would have made those results immediate as well. However,
this choice would have just pushed the work involved elsewhere; it is not possible, for
example, to avoid proving that fi-reduction on constructors preserves validity. I did not
have time to explore the full consequences of adding such conditions; it is possible that
a careful choice could lead to a somewhat simpler proof.

The C-OPAQ and C-TRANS rules check the validity of reified constructor types in
a straightforward manner. The validity of occurrences of constructor extractions are
checked by the C-EXT-O and C-EXT-T rules. A constructor extraction xae! has kind K
only if the place xae points to a reified constructor of kind K. There are two separate
rules because the place lookup judgment does not incorporate a notion of subsumption;
this fact means that the cases where xae has types !K? and !=A::K? must be handled separately. (If place lookup handled subsumption, only C-EXT-O would be needed
because !=A::K? is a subtype of !K?.)

The E-ABBREV rule handles equality for xae!. I chose a version of this rule that does
not require that the kind of the constructor extracted from xae (K 0) matches the kind
assigned originally to xae! (K). Later on in the proof, I establish that these two kinds must
be the same because equality preserves kind information for constructor components.
(E.g., if \Gamma  ` !=A::K? = !=A0::K0? :: \Omega  then K = K0.) The extra equality step on the
type of xae before it is used is there to mirror the relevant rewriting rule (R-ABBREV,
defined in Section 7.3).

Alternatively, I could have chosen a version of the rule that requires the two kinds to be
the same; for example, I could have removed the \Gamma  ` xae! :: K precondition and replaced
K0 by K. It would still be necessary to prove that the actual extracted constructor has
the right kind; the point where it would have to be proved would change however. In
hindsight, this change seems unlikely to have much effect on the complexity of the proofs.
Because of this fact and the fact that the alternative version is simpler and more elegant,
I think it would have been a better choice.

6.4 Place Lookup
As I discussed earlier, the place lookup judgment is used to determine the type of terms
of the form xae (i.e., places) that appear in constructors; the place lookup judgment is
specialized for this purpose and does not handle subsumption. Because subtyping in my
system only forgets information about constructor components, it cannot change what
kind xae! is or what it is equal to; this fact means that place lookup can safely disregard
subsumption, replacing it with the more limited ability to allow a term's type to be
replaced by an equal type.

6.4. PLACE LOOKUP 79

If we consider just the typing rules that apply to terms of the form xae, replacing
subsumption as discussed above and using old-style extended-value rules, we might have
something like the following:

` \Gamma  valid x:A 2 \Gamma 

\Gamma  ` x : A (VAR)

\Gamma  ` xae : A \Gamma  ` A = A0 :: \Omega 

\Gamma  ` xae : A0 (EQ)

\Gamma  ` xae : \Sigma x0:A1: A2

\Gamma  ` xae:1 : A1 (FST)

\Gamma  ` xae : \Sigma x0:A1: A2 x0 62 FTV(A2)

\Gamma  ` xae:2 : A2 (SND)

\Gamma  ` xae : !K?
\Gamma  ` xae : !=xae::K? (RC-VAL)

\Gamma  ` xae : \Sigma x0:A1: A2 \Gamma  ` xae:1 : A01

\Gamma  ` xae : \Sigma x0:A01: A2 (FST-VAL)

\Gamma  ` xae : \Sigma x0:A1: A2 \Gamma  ` xae:2 : A02

\Gamma  ` xae : \Sigma x0:A1: A02 (SND-VAL)

(The FST-VAL and SND-VAL rules are used to recursively apply the RC-VAL rule to
the sub-components of dependent sums.)

By taking advantage of the fact that places may appear in constructors, we can
improve on these rules by replacing SND with a simpler rule:

\Gamma  ` xae : \Sigma x0:A1: A2
\Gamma  ` xae:2 : [xae:1=x0]A2 (SND2)

Here [xae:1=x0] denotes the place substitution where xae:1 is substituted for x0 (defined
below on places, constructors, declarations, and assignments). In essence, SND2 is just
the standard elimination rule for dependent sums limited to xae's. It can be derived from
the SND, EQ, RC-VAL, FST-VAL, and SND-VAL rules (see Section 4.7).

80 CHAPTER 6. TYPES: SETUP
Definition 6.4.1 (Place substitution)

[xae=x0]x0ae0 = xaeae0
[xae=x0]x00ae00 = x00ae00 (x0 6= x00)

[xae=x0](x00ae00!) = ([xae=x0]x00ae00)!
[xae=x0]\Pi x00:A1: A2 = \Pi x00:[xae=x0]A1: [xae=x0]A2 (x00 6= x; x00 6= x0)
[xae=x0]\Sigma x00:A1: A2 = \Sigma x00:[xae=x0]A1: [xae=x0]A2 (x00 6= x; x00 6= x0)

[xae=x0]*ff::K: A = *ff::K: [xae=x0]A

[xae=x0](A1 A2) = [xae=x0]A1 [xae=x0]A2
[xae=x0]!=A0::K? = !=[xae=x0]A0::K?

[xae=x0]ff = ff
[xae=x0]!K ? = !K?

[xae=x0]rec = rec

[xae=x0]ref = ref

[xae=x0](ff::K) = ff::K

[xae=x0](x00:A) = x00:[xae=x0]A

[xae=x0]ffl = ffl
[xae=x0](\Gamma ; D) = ([xae=x0]\Gamma ); [xae=x0]D

After we replace SND with SND2, the VAL rules are no longer needed and can be
discarded: While the VAL rules do allow more types to be derived for xae, they do not
allow more kinds or equations for xae! to be derived. (For example, if x:!\Omega ?, we can
derive x:!=x!::\Omega ? using RC-VAL resulting in x! = x!, a redundant equation given EREFL.)

By introducing a selection function (S(A; xae; ae0)), we can combine the FST and SND2
rules into a more general rule:

\Gamma  ` xae : A A0 = S(A; xae; ae0)

\Gamma  ` xaeae0 : A0 (MOVE)

Definition 6.4.2 (Selection)

S(A; xae; ffl) = A
S(\Sigma x0:A1: A2; xae; :1ae0) = S(A1; xae:1; ae0)
S(\Sigma x0:A1: A2; xae; :2ae0) = S([xae:1=x0]A2; xae:2; ae0)

6.5. BASIC PROPOSITIONS 81
The selection function S(A; xae; ae0) computes the type (if any) for xaeae0 that can be inferred from \Gamma  ` xae : A using just the FST and SND2 rules. It does this computation by
descending into the type A according to the path ae0: at each step, if the next component
of ae0 is :1, it selects the first component (if any) of A, and if the next component is .2, it
selects the second component (if any) of A. Because the second component can depend
on the first component, when selecting the second component the selection function must
replace the internal name for the first component (e.g., x0 in \Sigma x0:A1: A2) with its external
name xae:1, where xae is the external name for A. In order that the selection function can
do this replacement, it is passed A's external name as its second argument.

Thus, if ae0 is set to :1 or to :2, then MOVE is the same as FST or SND2 respectively.
In the general case, one application of MOVE is equivalent to a series of FST and SND2
applications.

The place lookup judgment implements this improved version of the rules: the PINIT rule implements VAR and the P-MOVE rule implements EQ followed by MOVE. I
designed the place lookup judgment to closely mirror the relevant rewriting rules (R-EXT
and R-ABBREV, Section 7.3); in particular, xae's type is obtained by alternating the use
of equality (to get the type into the right form) and the selection function (to get the
type of a subcomponent).

An alternative design I considered was to use a more restrictive rule that only permitted the use of equality once followed by the use of selection once. Given confluence
and its associated results, it can be shown that this design is functionally equivalent to
the one I used: both lead to the same types for xae's. Unfortunately, under the alternate
design this equivalence is required to prove confluence; a mutual dependency thus results
in the proofs which prevents this design from working.

6.5 Basic Propositions
In this section, I prove a number of miscellaneous basic propositions for use later on.
Included are some propositions on the properties of the basic operators (substitution,
selection, and the domain function), as well as a series of propositions showing that all
term and constructor variables in judgments are bound.

Lemma 6.5.1 [xae=x0]x00ae0ae00 = ([xae=x0]x00ae0)ae00.
Lemma 6.5.2 if S(A; xae; :iae0) or S(S(A; xae; :i); xae:i; ae0) exists then

S(A; xae; :iae0) = S(S(A; xae; :i); xae:i; ae0)
Proof: By inspection of the definition of selection. 2

82 CHAPTER 6. TYPES: SETUP
Lemma 6.5.3 If S(A; xae1; ae2ae3) exists then

S(A; xae1; ae2ae3) = S(S(A; xae1; ae2); xae1ae2; ae3)
Proof: By structural induction on ae2. The non-basis case is as follows:

S(A; xae1; :iaeae3)
= S(S(A; xae1; :i); xae1:i; aeae3) (Lemma 6.5.2)
= S(S(S(A; xae1; :i); xae1:i; ae); xae1:iae; ae3) (induction hypothesis)
= S(S(A; xae1; :iae); xae1:iae; ae3) (Lemma 6.5.2)

2

Lemma 6.5.4 (Assignment properties)

1. dom(\Gamma ; \Gamma 0) = dom(\Gamma ) [ dom(\Gamma 0)
2. If x:A 2 \Gamma  then x 2 dom(\Gamma ), FCV(A) ` FCV(\Gamma ), and FTV(A) ` FTV(\Gamma ).

Lemma 6.5.5 (Free term variables)

1. FTV([A0=ff]A) ` FTV(A) [ FTV(A0)
2. FTV([xae=x0]A) ` fxg [ (FTV(A) \Gamma  fx0g)
3. If S(A; xae; ae0) exists then FTV(S(A; xae; ae0)) ` fxg [ FTV(A).

Theorem 6.5.6 (Scoping of term variables)

1. If \Gamma  ` xae ) A then x 2 dom(\Gamma ):
2. If \Gamma  ` A :: K then FTV(A) ` dom(\Gamma ).
3. If \Gamma  ` A1 = A2 :: K then 8i: FTV(Ai) ` dom(\Gamma ).
4. If \Gamma  ` xae ) A then FTV(A) ` dom(\Gamma ).

Proof: Proved sequentially by structural induction on the typing derivations, using
Lemmas 6.5.5 and 6.3.5 as needed. 2

6.6. TAGGING 83
Corollary 6.5.7

1. If ` \Gamma  valid then FTV(\Gamma ) ` dom(\Gamma ).
2. If ` \Gamma ; x:A valid then x 62 FTV(\Gamma ).

Proof: The first part is proved using structural induction on the typing derivations,
using Theorem 6.5.6 as needed. The second part follows almost immediately from the
first part and the rule DECL-T. 2

Theorem 6.5.8 (Scoping of constructor variables)

1. If \Gamma  ` A :: K then FCV(A) ` dom(\Gamma ).
2. If ` \Gamma  valid then FCV(\Gamma ) ` dom(\Gamma ).

Proof: Proved sequentially using structural induction on the derivations applying
Lemma 6.3.5 as needed. 2

Corollary 6.5.9 If ` \Gamma ; ff::K valid then ff 62 FCV(\Gamma ).
Lemma 6.5.10 If ` \Gamma 1; \Gamma 2 valid then dom(\Gamma 1) " dom(\Gamma 2) = ;.
Proof: Inspection of the typing rules for assignments combined with the results from
Lemma 6.3.5 reveal that valid assignments never redeclare variables. 2

6.6 Tagging
In the next section I introduce the tagged system which differs from the (untagged) kernel
system by having tagged places in constructors and by having slightly different operators
and type rules. Throughout these proofs, I shall be dealing with a number of different
systems. I shall use the same notation for each system whenever possible. Thus, A shall
denote a constructor in each system rather than A denoting an untagged constructor, B
a tagged one, C an erased tagged one, and so on. This convention makes it easy to deal
with systems that differ only slightly from each other; it also means that there are fewer
syntactic categories that need to be remembered.

84 CHAPTER 6. TYPES: SETUP

Which system is meant shall either be clear from context or be explicitly stated (e.g.,
"... a tagged constructor A ..."). Because notation occurs most frequently in propositions
and definitions, I shall use a special notation to specify what system the variables in a
proposition or definition are from. The variables' system shall be indicated by placing its
name in square brackets at the beginning of the proposition or definition; if no system is
indicated, then the variables are from the original kernel system. In the rare cases where
variables from multiple systems are needed, the system name shall be replaced with the
word "mixed" and the system of each variable shall be explicitly stated. The system of
the operators and judgments shall be clear from context.

Lemma [Tagged] 6.6.1 (Notation Example)
If ` \Gamma  valid then ` \Gamma \Psi  valid.

Here, the variables' system is the tagged system so \Gamma  is an assignment from the tagged
system. Because tag removal (\Gamma \Psi , defined later in Section 9.1) is an operator that
converts objects to the untagged system, \Gamma \Psi  must be an assignment from the untagged
system, the first judgment must be a tagged one, and the second one must be an untagged
one. The lemma thus states that a valid tagged assignment may be converted to a
valid untagged assignment by tag removal. I shall prove this result later as part of
Theorem 9.3.1.

I originally added tags by replacing xae! in the definition of constructor syntax with
xAae!. I also had to alter place substitution so that it replaces a term variable with a
tagged place:

[xAae=x0]x0A0ae0 = xAaeae0

This change was necessary so that the place substitution function would have a type that
it could use as a tag for x. (The type of x is not computable from the type of x0 or xae
due to missing information.) I made a similar change to the selection function.

Although I was able to work out much of the proof using this definition, I eventually
ran into a fatal problem with proving confluence. The problem arises from the fact that
under this definition the place substitution operator "replaces" one tag with another one
(e.g., A for A0 in the previous equation). If the constructor being rewritten is valid,
this replacement will result in a constructor that has a common reduct with the original
one. However, it may take many steps to reach the common reduct. This fact allows a
counterexample to the diamond property to be constructed.

Consider the constructor xA:2! where A = \Sigma x0:A9: !=x0A

0 !::\Omega ?, A0 = !=ff::\Omega ?,and A

9 is such that it rewrites to A0, but does not rewrite to !=A0::K? for any K or A0
in less than nine steps. Starting from this constructor, in a single step we could extract

the constructor ff from the sub-constructor x0A

0 ! or we could extract the constructorfrom x

A:2! yielding [xA:1=x

0](x0A

0 !) = xA:1!. Thus, in one step we can reach both of the

6.7. THE TAGGED SYSTEM 85
following:

x\Sigma x0:A

9: !=ff::\Omega ?:2! x\Sigma x0:A9: !=x0A

0

!::\Omega ?:1!

The only way to make these two constructors converge again by rewriting is by reducing
both of them to ff. Unfortunately, because of the way A9 was constructed, this reduction
will take at least nine steps because A9 needs to be reduced to !=A0::K? for some K
and A0 before the second constructor as a whole can be reduced. Thus, the original
constructor is a counterexample to the diamond property because we can take one step
away from it in two different ways yet be unable to rejoin within one step.

I solved this problem by switching to floating tags. Whereas, before, tags had to be
placed immediately after the term variable (i.e., xAae!), with floating tags the tag may
be placed anywhere in the path following the term variable (i.e., xaeAae0!). The type
indicated by a floating tag is that of the preceding place. Thus, if \Gamma  ` xaeAae0! :: K then
\Gamma  ` xae ) A. This change means that the place substitution operator no longer needs to
do tag "replacement" or substitute tagged places because it can continue to use the same
tag as before, just in a possibly new location:

[xae=x0](x00ae0Aae00!) = ([xae=x0]x00ae0)[xae=x0]Aae00!

6.7 The Tagged System
Except as noted in this section, the tagged system is identical to the untagged one.
The only change in syntax is to replace xae! in the definition of constructors with xaeAae0!.
Constructor extractions in the tagged system are accordingly xaeAae0!'s. I shall call xaeAae0's
tagged places, reserving the term place to always refer to xae's.

The operator definitions have to be changed slightly to deal with the changed syntax:

Definition [Tagged] 6.7.1 (Operator changes)

FCV(xaeAae0!) = FCV(A)
FTV(xaeAae0!) = FTV(A) [ fxg

[A=ff]xaeA0ae0! = xae[A=ff]A0ae0!
[xae=x0](x00ae0Aae00!) = ([xae=x0]x00ae0)[xae=x0]Aae00!
The operators remain defined as before for all other inputs.

The C-EXT-O, C-EXT-T, and E-ABBREV rules are replaced by the following new
rules:

86 CHAPTER 6. TYPES: SETUP
Definition [Tagged] 6.7.2 (Rule changes)

\Gamma  ` xaeae0 ) !K? \Gamma  ` xae ) A

\Gamma  ` xaeAae0! :: K (C-EXT-O2)

\Gamma  ` xaeae0 ) !=A0::K? \Gamma  ` xae ) A

\Gamma  ` xaeAae0! :: K (C-EXT-T2)

\Gamma  ` xaeA

1ae

0ae00! :: K

\Gamma  ` A1 = A :: \Omega  A2 = S(A; xae; ae0)

\Gamma  ` xaeA

1ae

0ae00! = xaeae0A

2ae

00! :: K (E-EXT2)

\Gamma  ` xaeA! :: K \Gamma  ` A = !=A0::K0? :: \Omega 

\Gamma  ` xaeA! = A0 :: K (E-ABBREV2)

These tagged rules are designed similarly to the untagged rules so that they possess the
same structural property. C-EXT-O2 and C-EXT-T2 are essentially the same as C-EXTO and C-EXT-T respectively except that I added an extra precondition (\Gamma  ` xae ) A)
to ensure that the tag (A) assigned to xae is consistent with \Gamma .

E-ABBREV2 and the new E-EXT-2 rule are designed to mirror closely the relevant
rewriting rules:

A1 ! A A2 = S(A; xae; ae0)

xaeA

1 ae

0ae00! ! xaeae0A

2ae

00! (R-EXT)

A ! !=A0::K0?

xaeA! ! A0 (R-ABBREV)

(R-EXT is used both to rewrite the tag in place and to move it to the right while RABBREV is used to perform the extraction once the tag has been reduced to a !=A0::K?
type; see Section 7.3 for more.)

The effect of the old E-ABBREV rule must be gotten by using repeated applications
of E-EXT-2 followed by an application of E-ABBREV2 (connected using E-TRAN);
more applications are needed because the tagged system, aside from E-TRAN, has only
simple equality rules, which can only do a small amount of work each time they are
applied. Like E-ABBREV, E-ABBREV2 also does not require that the kind of the
constructor extracted from a constructor extraction match the kind assigned originally
to that constructor extraction.

6.8. BASIC TAGGED PROPOSITIONS 87
6.8 Basic Tagged Propositions
In this section, I prove a number of miscellaneous basic propositions about the tagged
system for use later on. Most of these propositions are tagged versions of those I proved
previously for the untagged system in Section 6.5. This duplication is necessary because
these propositions are needed in order to prove that results can be transfered back and
forth between the two systems (see Sections 9.1-9.3). I shall point out the new propositions as I come to them.

Lemma [Tagged] 6.8.1 If S(A; xae1; ae2ae3) exists then

S(A; xae1; ae2ae3) = S(S(A; xae1; ae2); xae1ae2; ae3)
Proof: Exactly the same as the untagged version (Lemma 6.5.3). 2

Lemma [Tagged] 6.8.2 (Assignment properties)

1. dom(\Gamma ; \Gamma 0) = dom(\Gamma ) [ dom(\Gamma 0)
2. If x:A 2 \Gamma  then x 2 dom(\Gamma ), FCV(A) ` FCV(\Gamma ), and FTV(A) ` FTV(\Gamma ).

Lemma [Tagged] 6.8.3 (Structural property)

1. A derivation of ` \Gamma ; D valid contains ` \Gamma  valid as a sub-derivation.
2. A derivation of \Gamma  ` A :: K contains ` \Gamma  valid as a sub-derivation.
3. A derivation of \Gamma  ` xae ) A contains ` \Gamma  valid as a sub-derivation.
4. A derivation of \Gamma  ` A1 = A2 :: K contains ` \Gamma  valid as a sub-derivation.

Proof: By simultaneous structural induction on the typing derivations. 2

Lemma [Tagged] 6.8.4 (Free term variables)

1. FTV([A0=ff]A) ` FTV(A) [ FTV(A0)
2. FTV([xae=x0]A) ` fxg [ (FTV(A) \Gamma  fx0g)

88 CHAPTER 6. TYPES: SETUP

3. If S(A; xae; ae0) exists then FTV(S(A; xae; ae0)) ` fxg [ FTV(A).
Theorem [Tagged] 6.8.5 (Scoping of term variables)

1. If ` \Gamma  valid then FTV(\Gamma ) ` dom(\Gamma ).
2. If \Gamma  ` A :: K then FTV(A) ` dom(\Gamma ).
3. If \Gamma  ` xae ) A then x 2 dom(\Gamma ) and FTV(A) ` dom(\Gamma ).
4. If \Gamma  ` A1 = A2 :: K then 8i: FTV(Ai) ` dom(\Gamma ).
Proof: Proved by simultaneous structural induction on the derivations applying Lemmas 6.8.3 and 6.5.5 as needed. Sample cases:

DECL-T: Given ` \Gamma ; x:A valid derived via rule DECL-T from \Gamma  ` A :: \Omega  and x 62 dom(\Gamma ).

By Lemma 6.8.3, ` \Gamma  valid. Applying the induction hypothesis then gives us that
FTV(A) ` dom(\Gamma ) and FTV(\Gamma ) ` dom(\Gamma ). Since FTV(\Gamma ; x:A) = FTV(\Gamma ) [
FTV(A) and dom(\Gamma ; x:A) = dom(\Gamma )[fxg, this means that FTV(\Gamma ; x:A) ` dom(\Gamma )
` dom(\Gamma ; x:A).

C-DFUN: Given \Gamma  ` \Pi x:A: A0 :: \Omega  derived via rule C-DFUN from \Gamma ; x:A ` A0 :: \Omega . By

Lemma 6.8.3, ` \Gamma ; x:A valid ) \Gamma  ` A :: \Omega  (DECL-T). Applying the induction hypothesis then gives us that FTV(A) ` dom(\Gamma ) and FTV(A0) ` dom(\Gamma ; x:A) =
dom(\Gamma ) [ fxg ) (FTV(A0) \Gamma  fxg) ` dom(\Gamma ). Hence, FTV(\Pi x:A: A0) = FTV(A) [
(FTV(A0) \Gamma  fxg) ` dom(\Gamma ).

P-INIT: Given \Gamma  ` x ) A derived via rule P-INIT from ` \Gamma  valid and x:A 2 \Gamma . Applying

the induction hypothesis gives us that FTV(\Gamma ) ` dom(\Gamma ). By Lemma 6.8.2, x 2
dom(\Gamma ) and FTV(A) ` FTV(\Gamma ) ` dom(\Gamma ).

E-BETA: Given \Gamma  ` (*ff::K: A) A0 = [A0=ff]A :: K0 derived via rule E-BETA from

\Gamma ; ff::K ` A :: K0 and \Gamma  ` A0 :: K. Applying the induction hypothesis gives us that
FTV(A0) ` dom(\Gamma ) and FTV(A) ` dom(\Gamma ; ff::K) = dom(\Gamma ) [ fffg ) FTV(A) `
dom(\Gamma ) (ff is not a term variable). By Lemma 6.8.4, FTV([A0=ff]A) ` FTV(A) [
FTV(A0) ` dom(\Gamma ). Finally, FTV((*ff::K: A) A0) = FTV(A)[FTV(A0) ` dom(\Gamma ).

E-EXT2: Given \Gamma  ` xaeA

1 ae

0ae00! = xaeae0A

2 ae

00! :: K derived via rule E-EXT2 from

\Gamma  ` xaeA

1ae

0ae00! :: K, \Gamma  ` A1 = A :: \Omega , and S(A; xae; ae0) = A2. Applying the induction hypothesis gives us that FTV(xaeA

1ae

0ae00!) = fxg [ FTV(A1) ` dom(\Gamma )

and FTV(A) ` dom(\Gamma ). By Lemma 6.8.4, FTV(A2) = FTV(S(A; xae; ae0)) `
fxg [ FTV(A) ` dom(\Gamma ). Finally, FTV(xaeae0A

2 ae

00!) = fxg [ FTV(A2) ` dom(\Gamma ).

6.8. BASIC TAGGED PROPOSITIONS 89

2
For the untagged system, I needed to show only that all constructor variables in
valid assignment and constructor judgments are bound. I shall need this result for all
four judgments in the tagged case. Accordingly, I have extended the relevant theorem
(Theorem 6.8.7 here) and added the following new lemma to help handle the equality
judgment case:

Lemma [Tagged] 6.8.6 (Free constructor variables)

1. FCV([A0=ff]A) ` FCV(A0) [ (FCV(A) \Gamma  fffg)
2. FCV([xae=x0]A) = FCV(A)
3. If S(A; xae; ae0) exists then FCV(S(A; xae; ae0)) ` FCV(A).

Theorem [Tagged] 6.8.7 (Scoping of constructor variables)

1. If \Gamma  ` A :: K then FCV(A) ` dom(\Gamma ).
2. If \Gamma  ` xae ) A then FCV(A) ` dom(\Gamma ).
3. If \Gamma  ` A1 = A2 :: K then FCV(A1) ` dom(\Gamma ) and FCV(A2) ` dom(\Gamma ).

Proof: Proved by simultaneous structural induction on the derivations applying Lemmas 6.8.3 and 6.8.6 as needed. Sample cases:

C-DSUM: Applying Lemma 6.8.3 to the given \Gamma ; x:A ` A0 :: \Omega , gives us that \Gamma  ` A :: \Omega . Applying the induction hypothesis twice, we have that FCV(A) ` dom(\Gamma ) and that
FCV(A0) ` dom(\Gamma ; x:A) = dom(\Gamma ) [ fxg. Since x is not a constructor variable,
we more precisely have FCV(A0) ` dom(\Gamma ). Thus, FCV(\Sigma x:A: A0) = FCV(A) [
FCV(A0) ` dom(\Gamma ).

P-INIT: Repeated use of Lemma 6.3.5 shows that ` \Gamma 0; x:A valid for some prefix \Gamma 0 of \Gamma .

Hence, by DECL-T, \Gamma 0 ` A :: \Omega . Applying the induction hypothesis, then gives us
that FCV(A) ` dom(\Gamma 0). By Lemma 6.8.2, we have that dom(\Gamma 0) ` dom(\Gamma ) so
that FCV(A) ` dom(\Gamma ).

P-MOVE: By applying the induction hypothesis, we have that FCV(A0) ` dom(\Gamma ). By

Lemma 6.8.6, FCV(A00) = FCV(S(A0; xae; ae0)) ' FCV(A0) ' dom(\Gamma ).

90 CHAPTER 6. TYPES: SETUP
E-BETA: As in the C-DSUM case, applying Lemma 6.8.3 and the induction hypothesis, gives

us that FCV(A0) ` dom(\Gamma ) and FCV(A) ` dom(\Gamma ) [ fffg ) (FCV(A) \Gamma  fffg) `
dom(\Gamma ). By Lemma 6.8.6, FCV([A0=ff]A) ` FCV(A0)[(FCV(A) \Gamma fffg) ` dom(\Gamma ).
By the definition of FCV(\Gamma ), we also have that FCV((*ff::K: A) A0) = (FCV(A) \Gamma 
fffg) [ FCV(A0) ` dom(\Gamma ).

2

Theorem [Tagged] 6.8.8

1. If ` \Gamma  valid then FCV(\Gamma ) ` dom(\Gamma ).
2. If ` \Gamma ; ff::K valid then ff 62 FCV(\Gamma ).
Proof: The first part is proved by structural induction on the derivation using Theorem 6.8.7 and Lemma 6.8.3 as needed. The second part follows almost immediately from
the first part and rule DECL-C. 2

Lemma [Tagged] 6.8.9 If ` \Gamma 1; \Gamma 2 valid then dom(\Gamma 1) " dom(\Gamma 2) = ;.
Proof: Inspection of the typing rules for assignments combined with the results from
Lemma 6.8.3 reveal that valid assignments never redeclare variables. 2

The last two theorems are new. The first one shows that tagged judgments may be
weakened by adding extra declarations to their assignment. The second one establishes
some consequences of the fact that valid assignments never redeclare variables.

Theorem [Tagged] 6.8.10 (Weakening)

Suppose ` \Gamma ; \Gamma 0 valid and dom(\Gamma 0) " dom(\Gamma 00) = ;. Then:

1. If ` \Gamma ; \Gamma 00 valid then ` \Gamma ; \Gamma 0; \Gamma 00 valid.
2. If \Gamma ; \Gamma 00 ` A :: K then \Gamma ; \Gamma 0; \Gamma 00 ` A :: K.
3. If \Gamma ; \Gamma 00 ` xae ) A then \Gamma ; \Gamma 0; \Gamma 00 ` xae ) A.
4. If \Gamma ; \Gamma 00 ` A1 = A2 :: K then \Gamma ; \Gamma 0; \Gamma 00 ` A1 = A2 :: K.
Proof: By simultaneous structural induction on the length of the derivations involving
\Gamma ; \Gamma 00. 2

6.8. BASIC TAGGED PROPOSITIONS 91
Lemma [Tagged] 6.8.11 (Valid assignment properties)

Suppose ` \Gamma  valid. Then:

1. If ff::K 2 \Gamma  and ff::K 0 2 \Gamma  then K = K0.
2. If x:A 2 \Gamma  then \Gamma (x) = A.
3. If x 2 dom(\Gamma ) then \Gamma  ` \Gamma (x) :: \Omega .

Proof: Inspection of the typing rules for assignments combined with the results from
Lemma 6.8.3 reveal that valid assignments never redeclare variables. The last part requires weakening plus repeated use of Lemma 6.8.3. 2

92 CHAPTER 6. TYPES: SETUP
Chapter 7
Types: Confluence
In this chapter, I introduce a rewriting relation for the tagged system and show that
it is confluent and that it implements equality correctly. These results will be essential
to producing a decision procedure for equality (needed for type checking) and proving
soundness. I shall discuss the existence of normal forms under this relation and the
decidability of the tagged judgments in the next chapter. All constructors, assignments,
etc., in this chapter are tagged.

7.1 Rewriting
I shall write A1 !R A2 to denote that A1 rewrites under relation R to A2 in one step. If
R is omitted, the standard rewriting relation of the system under consideration is meant.
I shall use reduce as a synonym for rewrite, particularly when referring to rewriting steps
(reductions) and to the results of rewriting steps (reducts). Some other useful definitions
are as follows:

Definition [Tagged] 7.1.1 (Irreflexive rewriting) A !1R A0 iff A !R A0 and A 6=
A0.

Definition [Tagged] 7.1.2 (Multiple step rewriting) A !\Lambda R A0 iff A and A0 are related by the reflexive and transitive closure of !R.

Definition [Tagged] 7.1.3 (One or more step rewriting) A !+R A0 iff A and A0
are related by the transitive closure of !R.

Definition [Tagged] 7.1.4 (Conversion) A ssR A0 iff A and A0 are related by the
reflexive, symmetric, and transitive closure of !R.

93

94 CHAPTER 7. TYPES: CONFLUENCE
Definition [Tagged] 7.1.5 (Bi-directional rewriting) A *)R A0 iff A !R A0 or
A0 !R A.

Definition [Tagged] 7.1.6 (Common reduct) A1 #\Lambda R A2 iff 9A such that A1 !\Lambda R A
and A2 !\Lambda R A.

7.2 The Proof Method
As I have discussed previously, equality in the tagged system does not depend on the
assignment (modulo validity); this fact means that relatively standard methods can be
used to prove confluence. I shall use the well known method of proving confluence by
constructing a rewriting relation that possesses the diamond property:

Definition [Tagged] 7.2.1 (Diamond property)

!R possesses the diamond property iff for all A, A1, and A2 such that A !R A1 and
A !R A2 then 9A3 such that A1 !R A3 and A2 !R A3. This can be summarized by the
following diagram, the form of which I shall use as a shorthand in proofs:

A

A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi R

@@

@@RR

.....

.....

..RR

.....
.....
..\Psi R

Confluence of the rewriting relation follows directly from this property:
Theorem [Tagged] 7.2.2 (Confluence)

Suppose ! possesses the diamond property. Then, if A !\Lambda  A1 and A !\Lambda  A2 then 9A0
such that A1 !\Lambda  A0 and A2 !\Lambda  A0.

Proof: (Idea) Suppose A rewrites to A1 in 2 steps and rewrites to A2 in 3 steps. By
using the diamond property repeatedly, we can "fill in the grid" to find an A0 that both
A1 and A2 rewrite to to as shown below:

7.2. THE PROOF METHOD 95

A

A3 A4
A1 A6 A5

A7 A8 A2

A9 A10

A0

\Gamma \Gamma 
\Gamma \Gamma \Psi 

\Gamma \Gamma 
\Gamma \Gamma \Psi 

.....
.....
..\Psi 

.....
.....
..\Psi 

.....
.....
..\Psi 

.....
.....
..\Psi 

.....
.....
..\Psi 

.....
.....
..\Psi 

@@

@@R

@@

@@R

@@

@@R

.....

.....

..R

.....

.....

..R

.....

.....

..R

.....

.....

..R

.....

.....

..R

.....

.....

..R

By using this method we can find an A0 that both A1 and A2 rewrite to regardless of
exactly how many steps it takes A to rewrite to A1 or to A2. (A !\Lambda  A0 implies that A
rewrites to A0 in a finite number of steps by the definition of transitive closure.) 2

Because my system allows both fi- and j-reductions, it only possesses confluence if
attention is restricted to valid constructors. To see this fact, consider the following critical
pair involving fi and j:

*ff::K: (*ff0::K0: !\Omega ?) ff

*ff::K: !\Omega ? *ff0::K0: !\Omega ?

\Gamma \Gamma 
\Gamma \Gamma \Psi 

fi @@

@R
j

In order for us to have confluence, we must have that K = K 0 (both reducts are in normal
form). This equation will be true if *ff::K: (*ff0::K0: !\Omega ?) ff is a valid constructor. If
it is not a valid constructor, however, then K may not equal K 0 and confluence fails.
This critical pair is the only point where we need to know we are dealing with valid
constructors in order to show confluence; removing j-reduction from the system, for
example, would allow proving confluence for arbitrary constructors.

This situation is normally handled by first proving that rewriting preserves the validity of constructors (i.e., subject reduction for constructors) and then proving a version of

96 CHAPTER 7. TYPES: CONFLUENCE
Theorem 7.2.2 to which has been added the precondition that \Gamma  ` A :: K. This method
cannot be used here directly because in the presence of reified constructors proving subject reduction for constructors requires some form of confluence.

As an example, suppose we had x:!=A0::K 0? ` x!=A::K?! :: K0. Subject reduction
then requires that x!=A::K ?!'s reduct (A via extraction) have kind K0; since A has
kind K, we must have that K = K 0. Inspection of the relevant typing rules shows that
we have x:!=A0::K0? ` !=A::K? = !=A0::K0? :: \Omega  which implies that !=A::K? ss
!=A0::K0? because the rewriting relation implements equality. Showing that K = K 0
from this fact requires some form of confluence in order to handle the possibility of
fi-expansions.

I shall use a technique due to Herman Geuvers [14] to handle this problem. The idea
is to introduce a notion of erasure (\Gamma ffi) which removes the kinds of constructor variables
in constructor functions but not the kinds in reified constructor's types:

(*ff::K: A)ffi = *ff: Affi

!=A::K?ffi = !=Affi::K?

Because the resulting erased constructors do not have kinds attached to constructorfunction arguments, the problematic fij-critical pair is not a problem for erased constructors. This fact means that confluence can be proved for arbitrary erased constructors;
subject reduction is not required.

This confluence result can then be used to prove subject reduction. In the previous
example we would first show that !=A::K? ss !=A0::K 0? implies that !=A::K?ffi ss
!=A0::K0?ffi ) !=Affi::K? ss !=A0ffi::K0?. By confluence on erased constructors, we
then have that there exists an erased constructor B such that !=Affi::K? !\Lambda  B and
!=A0ffi::K0? !\Lambda  B. Because !=A1::K1? always rewrites to a constructor of form
!=A2::K1? for some A2, we must have that K = K0 in the example as required.

Once subject reduction has been proved, confluence for the unerased constructors can
be established using the normal method.

7.3 The Rewrite Relation
The rules for the rewriting relation are as follows:
Definition [Tagged] 7.3.1 (Rewrite relation)

A ! A (R-REFL)

A1 ! A01 A2 ! A02
\Pi x:A1: A2 ! \Pi x:A01: A02 (R-DFUN)

7.3. THE REWRITE RELATION 97

A1 ! A01 A2 ! A02
\Sigma x:A1: A2 ! \Sigma x:A01: A02 (R-DSUM)

A ! A0
*ff::K: A ! *ff::K: A0 (R-LAM)

A1 ! A01 A2 ! A02

A1 A2 ! A01 A02 (R-APP)

A ! A0
!=A::K? ! !=A0::K? (R-TRANS)

A1 ! A A2 = S(A; xae; ae0)

xaeA

1ae

0ae00! ! xaeae0A

2ae

00! (R-EXT)

A1 ! A01 A2 ! A02
(*ff::K: A1) A2 ! [A02=ff]A01 (R-BETA)

A ! A0 ff 62 FCV(A)

*ff::K: A ff ! A0 (R-ETA)

A ! !=A0::K0?

xaeA! ! A0 (R-ABBREV)

These rules constitute a parallel rewriting relation. A parallel rewriting relation is one in
which a single reduction step on A can rewrite all of A's sub-constructors by one reduction
step in parallel. For example, the R-BETA rule allows A1 and A2 to be rewritten in
parallel with the fi-reduction. Non-parallel rewriting relations often require multiple
steps to accomplish the same reduction (e.g., one step for each sub-component followed
by one step for the fi-reduction).

Being able to do parallel reductions in a single step is crucial to proving the diamond
property. For example, if (*ff::K: A1) A2 rewrites in one step to (*ff::K: A1) A02 (via
A2 ! A02) and to [A2=ff]A1, we need to be able to show that [A2=ff]A1 ! [A02=ff]A1. This
reduction requires in a single step that we be able to rewrite in parallel A2 to A02 at each
of the points in A1 where ff occurs. Only a parallel rewriting relation can provide this
ability.

The R-EXT and R-ABBREV rules handle rewriting constructor extractions. The
R-EXT rule handles both rewriting the tag and moving it to the right in the path. The
existence of the tag allows xae's type to be computed by a series of small steps (e.g.,
R-EXT only reduces the tag a single step at a time), resulting in a simple rewriting
relation.

98 CHAPTER 7. TYPES: CONFLUENCE

R-EXT permits moving the tag an arbitrary amount (ae0) to the right in a single step,
so long as the tag has the right form (i.e., S(A; xae; ae0) exists). In retrospect, I think it
would have been better to only allow moving the tag by a single :i at a time; the ability
to move multiple steps to the right at once only makes the system more complicated.

In order to extract a constructor then, we repeatedly use R-EXT to reduce the tag;
whenever the tag is a sum type, we also move the tag to the right. Eventually, if the
constructor extraction is valid, we will end up with xae!K?! or xae!=A::K?! for some K
and A. The first constructor is in normal form and represents the opaque case. The
second constructor represents the transparent case; it can be reduced using R-ABBREV
to A in a single step.

It will sometimes be useful to consider just the fij or extraction (denoted by fl)
components of the rewriting relation:

Definition [Tagged] 7.3.2 (fij-reduction)
A1 !fij A2 iff A1 ! A2 can be derived without ever using the R-ABBREV rule or the
R-EXT rule with ae0 6= ffl.

Definition [Tagged] 7.3.3 (fl-reduction)
A1 !fl A2 iff A1 ! A2 can be derived without ever using the R-BETA or R-ETA rules.

Here I show that equal constructors can be converted to each other. This result is
the first part of proving that the rewriting relation implements equality. The second part
(valid constructors that have a common reduct are equal) requires confluence and will
be proved later.

Theorem [Tagged] 7.3.4 If \Gamma  ` A = A0 :: K then 9A0; A1; : : : ; An, n * 0, such that:

1. A = A0
2. A0 = An
3. Ai *) Ai+1 for 0 ^ i ! n

Proof: By structural induction on the derivation of \Gamma  ` A = A0 :: K. Example cases:
SYM: Apply the induction hypothesis. Since bi-directional rewriting is symmetric, reversing the sequence of types obtained from the induction hypothesis then yields
the desired sequence.

TRAN: Apply the induction hypothesis twice then place the two resulting sequences side

by side.

7.3. THE REWRITE RELATION 99
DFUN: Apply the induction hypothesis twice getting sequences A00; : : : ; A0m from

\Gamma  ` A00 = A0m :: \Omega  and A000; : : : ; A00r from \Gamma ; x:A00 ` A000 = A00r :: \Omega . The desired sequence is then \Pi x:A00: A000; : : : ; \Pi x:A00: A00r ; \Pi x:A01: A00r ; : : : ; \Pi x:A0m: A00r . R-DFUN and
R-REFL are used to connect them with bi-directional rewriting.

BETA: Let n = 1. A0 ! A1 via R-BETA and R-REFL.

EXT2: Applying the induction hypothesis gives the sequence A00; : : : ; A0m from

\Gamma  ` A1 = A :: \Omega . The desired sequence is then xaeA0

0ae

0ae00!, : : : , xaeA0

m ae

0ae0!, xaeae0A

2 ae

00!.

R-EXT plus R-REFL are used to connect them with bi-directional rewriting.

ABBREV2: Applying the induction hypothesis gives the sequence A00; : : : ; A0m from

\Gamma  ` A = !=A0::K0? :: \Omega . The desired sequence is then xaeA0

0!, : : : , xaeA

0
m!, A

0. REXT plus R-ABBREV and R-REFL are used to connect them with bi-directional
rewriting.

2

Corollary [Tagged] 7.3.5 (Partial correctness I)

If \Gamma  ` A = A0 :: K then A ss A0.

Proof: Apply Theorem 7.3.4 then use the fact that conversion is the transitive closure
of bi-directional rewriting. 2

The rest of this section is devoted to proving the basic properties I shall need about
the rewriting relation. First I show that rewriting never introduces new variables; this
result is needed to prove the diamond property.

Theorem [Tagged] 7.3.6 (Reduct variables) If A ! A0 then
FCV(A0) ` FCV(A) and FTV(A0) ` FTV(A).

Proof: By structural induction on the derivation of A ! A0, using Lemmas 6.8.6 and
6.8.4. 2

Second, I show that except for constructor functions, applications, and extractions,
rewriting preserves the shape of constructors and acts in a component-wise manner.
This result, when combined with confluence and the fact that the rewriting relation
implements equality, will establish the needed properties of equality (e.g., equality acts
in a component-wise manner).

Lemma [Tagged] 7.3.7 (Shape preservation)

100 CHAPTER 7. TYPES: CONFLUENCE

1. If A ! A0 and either A = ff, A = rec, A = ref, A = !K?, or A = xae!K?! then

A = A0.

2. If \Sigma x:A1: A2 ! A0 then 9A01; A02 such that A0 = \Sigma x:A01: A02, A1 ! A01, and A2 ! A02.
3. If \Pi x:A1: A2 ! A0 then 9A01; A02 such that A0 = \Pi x:A01: A02, A1 ! A01, and A2 ! A02.
4. If !=A1::K? ! A0 then 9A01 such that A0 = !=A01::K?, and A1 ! A01.
5. If ref A1 ! A0 then 9A01 such that A0 = ref A01, and A1 ! A01.
6. If rec A1 ! A0 then 9A01 such that A0 = rec A01, and A1 ! A01.

Proof: Proved sequentially (the case for !K? is needed to prove the case for xae!K?!)
by casing on the possible rewriting rules used and using R-REFL as needed. 2

Finally, I establish the consequences of having a parallel rewriting relation for use in
proving the diamond property:

Lemma [Tagged] 7.3.8 If A2 ! A02 then [A2=ff]A1 ! [A02=ff]A1.
Lemma [Tagged] 7.3.9 (Substitution for non-free variables)

1. If ff 62 FCV(A) then [A0=ff]A = A.
2. If x0 62 FTV(A) then [xae=x0]A = A.
3. If ff 62 FCV(\Gamma ) then [A0=ff]\Gamma  = \Gamma .
4. If x0 62 FTV(\Gamma ) then [xae=x0]\Gamma  = \Gamma .

Proof: Proved sequentially using structural induction on A and \Gamma . 2

Lemma [Tagged] 7.3.10 (Iterated substitutions I)

1. If ff 6= ff0 and ff0 62 FCV(A) then

[A=ff]([A1=ff0]A2) = [[A=ff]A1=ff0]([A=ff]A2)

2. [xae=x0]([A=ff]A0) = [[xae=x0]A=ff]([xae=x0]A0)

7.3. THE REWRITE RELATION 101

3. If S(A0; xae; ae0) exists then

[A=ff]S(A0; xae; ae0) = S([A=ff]A0; xae; ae0)

Proof: Proved sequentially using structural induction on A2, A0, and ae0 respectively
using Lemmas 7.3.9, 6.8.6, and 6.8.4 as needed. 2

Theorem [Tagged] 7.3.11 (Parallelism I) If A1 ! A01 and A2 ! A02 then [A2=ff]A1 !
[A02=ff]A01.

Proof: By structural induction on the derivation of A1 ! A01 using Lemmas 6.8.6 and
7.3.6 as needed. Lemma 7.3.8 handles the R-REFL case; lemma 7.3.10 is needed for the
R-BETA and R-EXT cases. 2

Lemma [Tagged] 7.3.12 (Iterated substitutions II)

1. If x01 6= x02 and x02 6= x1 then

[x1ae1=x01]([x2ae2=x02]A) = [[x1ae1=x01]x2ae2=x02]([x1ae1=x01]A)

2. If S(A; x00ae0; ae00) exists then

[xae=x0]S(A; x00ae0; ae00) = S([xae=x0]A; [xae=x0]x00ae0; ae00)

Proof: Proved sequentially by structural induction on A and ae00 respectively. 2

Theorem [Tagged] 7.3.13 (Parallelism II) If A ! A0 then

1. [xae=x0]A ! [xae=x0]A0
2. If S(A; xae; ae0) exists then S(A; xae; ae0) ! S(A0; xae; ae0).

Proof: Proved sequentially by structural induction on the derivation of A ! A0 and
ae0 respectively using Lemma 6.8.6 as needed. Lemma 7.3.10 handles the R-BETA case;
lemma 7.3.12 handles the R-EXT case. Lemma 7.3.7 is needed for part 2. 2

102 CHAPTER 7. TYPES: CONFLUENCE
7.4 Argument Kind Erasure
The erasure function which transforms constructors from the tagged system into the
erased system is as follows:

Definition [Tagged] 7.4.1 (Argument kind erasure)

(*ff::K: A)ffi = *ff: Affi

(\Pi x:A1: A2)ffi = \Pi x:Affi1: Affi2

(\Sigma x:A1: A2)ffi = \Sigma x:Affi1: Affi2

(A1 A2)ffi = Affi1 Affi2
!=A::K?ffi = !=Affi::K?

xaeAae0!ffi = xaeAffiae0!

ffffi = ff
recffi = rec

refffi = ref
!K ?ffi = !K?

The erased system is obtained by taking the tagged system without type rules and replacing *ff::K: A in the definition of constructors with *ff: A. The operators and rewriting
relation are modified in the obvious ways:

Definition [Erased] 7.4.2 (Operator changes)

FCV(*ff: A) = FCV(A) \Gamma  fffg

FTV(*ff: A) = FCV(A)
[A=ff]*ff0: A0 = *ff0: [A=ff]A0 (ff0 6= ff; ff0 62 FCV(A))
[xae=x0]*ff: A = *ff: [xae=x0]A
Definition [Erased] 7.4.3 (Rule changes)

A ! A0
*ff: A ! *ff: A0 (R-LAM3)

A1 ! A01 A2 ! A02
(*ff: A1) A2 ! [A02=ff]A01 (R-BETA3)

A ! A0 ff 62 FCV(A)

*ff: A ff ! A0 (R-ETA3)

7.4. ARGUMENT KIND ERASURE 103
(These rules replace R-LAM, R-BETA, and R-ETA.)

I shall need to show many of the same properties for the rewriting relation of the erased
system as I did for the tagged rewriting relation in order to prove confluence for the erased
system. Rather than duplicate work, I shall relate the two systems using erasure and
an unerasure function then transfer the needed results from the tagged system. First
though, I shall need some results about how erasure interacts with the other operators:

Lemma [Tagged] 7.4.4

1. FCV(Affi) = FCV(A)
2. FTV(Affi) = FTV(A)

Lemma [Tagged] 7.4.5

1. ([A2=ff]A1)ffi = [Affi2=ff](Affi1)
2. ([xae=x0]A)ffi = [xae=x0](Affi)
3. If S(A; xae; ae0) exists then S(A; xae; ae0)ffi = S(Affi; xae; ae0).

Proof: Proved sequentially by structural induction on A, A, and ae0 respectively. Examples:

([A=ff]*ff0::K: A0)ffi = (*ff0::K: [A=ff]A0)ffi = *ff0: ([A=ff]A0)ffi
= *ff0: [Affi=ff](A0ffi) = [Affi=ff]*ff0: (A0ffi) = [Affi=ff]((*ff0::K: A0)ffi)

([xae=x0]*ff0::K: A0)ffi = (*ff0::K: [xae=x0]A0)ffi = *ff0: ([xae=x0]A0)ffi
= *ff0: [xae=x0](A0ffi) = [xae=x0]*ff0: (A0ffi) = [xae=x0]((*ff0::K: A0)ffi)

S(\Sigma x0:A1: A2; xae; :2ae0)ffi = S([xae:1=x0]A2; xae:2; ae0)ffi = S(([xae:1=x0]A2)ffi; xae:2; ae0)
= S([xae:1=x0](Affi2); xae:2; ae0) = S(\Sigma x0:Affi1: Affi2; xae; :2ae0) = S((\Sigma x0:A1: A2)ffi; xae; :2ae0)

Where ff0 6= ff and ff0 62 FCV(A) = FCV(Affi) by Lemma 7.4.4. 2

Lemma [Tagged] 7.4.6 If A1 ! A2 then Affi1 ! Affi2.
Proof: By structural induction on the derivation of A1 ! A2. 2

104 CHAPTER 7. TYPES: CONFLUENCE
Corollary [Tagged] 7.4.7 If A1 ss A2 then Affi1 ss Affi2.
Proof: Proved by structural induction on the length of the conversion using Lemma 7.4.6
to convert from tagged-system rewriting steps to erased-system rewriting steps. 2

The unerasure function is defined as follows:
Definition [Erased] 7.4.8 (Argument kind unerasure)

*ff: A = *ff::\Omega : A

\Pi x:A1: A2 = \Pi x:A1: A2
\Sigma x:A1: A2 = \Sigma x:A1: A2

A1 A2 = A1 A2
!=A::K? = !=A::K?

xaeAae0! = xaeAae0!

ff = ff
rec = rec

ref = ref
!K? = !K?

It simply inserts \Omega  as the kind of each argument. This insertion will not in general
produce valid constructors, but it suffices to give the needed properties; note in particular
Lemma 7.4.12 below:

Lemma [Erased] 7.4.9 (A)ffi = A
Corollary [Erased] 7.4.10

1. FCV(A) = FCV(A)
2. FTV(A) = FTV(A)

Proof: Substitute A for A in Lemma 7.4.4 then apply Lemma 7.4.9. 2

Lemma [Erased] 7.4.11 If S(A; xae; ae0) exists then S(A; xae; ae0) exists.
Lemma [Erased] 7.4.12 If A1 ! A2 then A1 ! A2.

7.4. ARGUMENT KIND ERASURE 105
Proof: By structural induction on the derivation of A1 ! A2. 2

Using these results about erasure and unerasure, the needed theorems and lemmas
can be transfered from the tagged to the erased system:

Lemma [Erased] 7.4.13 If S(A; xae1; ae2ae3) exists then

S(A; xae1; ae2ae3) = S(S(A; xae1; ae2); xae1ae2; ae3)
Proof:

S(A; xae1; ae2ae3) exists (given)
) S(A; xae1; ae2ae3) exists (Lemma 7.4.11)
) S(A; xae1; ae2ae3) = S(S(A; xae1; ae2); xae1ae2; ae3) (Lemma 6.8.1)
) S(A; xae1; ae2ae3)ffi = S(S(A; xae1; ae2); xae1ae2; ae3)ffi (erase both sides)
) S(Affi; xae1; ae2ae3) = S(S(Affi; xae1; ae2); xae1ae2; ae3) (Lemma 7.4.5)
) S(A; xae1; ae2ae3) = S(S(A; xae1; ae2); xae1ae2; ae3) (Lemma 7.4.9)

2

Theorem [Erased] 7.4.14 (Reduct variables) If A1 ! A2 then FCV(A2) ` FCV(A1)
and FTV(A2) ` FTV(A1).

Proof: The constructor variable case is as follows:

A1 ! A2 (given)
) A1 ! A2 (Lemma 7.4.12)
) FCV(A2) ` FCV(A1) (Theorem 7.3.6)
) FCV(A2) ` FCV(A1) (Corollary 7.4.10)
The term variable case is similar. 2

Lemma [Erased] 7.4.15 (Shape preservation)

1. ff ! A implies that A = ff.
2. !K? ! A implies that A = !K?.
3. !=A1::K? ! A implies that A has form !=A2::K? for some A2 where A1 ! A2.

106 CHAPTER 7. TYPES: CONFLUENCE
Proof: All are proved the same way. Example case:

!=A1::K? ! A (given)
) !=A1::K? ! A (Lemma 7.4.12)
) 9A3 such that A = !=A3::K? (Lemma 7.3.7)
) (A)ffi = !=Affi3::K? (erase both sides)
) A = !=Affi3::K? (Lemma 7.4.9)

2

Lemma [Erased] 7.4.16 (Substitution for non-free variables)

1. If ff 62 FCV(A) then [A0=ff]A = A.
2. If x0 62 FTV(A) then [xae=x0]A = A.
Proof: All are proved the same way. Example case:

ff 62 FCV(A) (given)
) ff 62 FCV(A) (Corollary 7.4.10)

) [A0=ff]A = A. (Lemma 7.3.9)
) ([A0=ff]A)ffi = Affi. (erase both sides)
) [A0

ffi=ff]Affi = Affi. (Lemma 7.4.5)

) [A0=ff]A = A. (Lemma 7.4.9)

2

Theorem [Erased] 7.4.17 (Parallelism I and II) If A1 ! A01 and A2 ! A02 then

1. [A2=ff]A1 ! [A02=ff]A01

2. [xae=x0]A1 ! [xae=x0]A01
3. If S(A1; xae; ae0) exists then S(A1; xae; ae0) ! S(A01; xae; ae0).
Proof: All are proved the same way. Example case:

A1 ! A01 and A2 ! A02 (given)
) A1 ! A01 and A2 ! A02 (Lemma 7.4.12)
) [A2=ff]A1 ! [A02=ff]A01 (Theorem 7.3.11)
) ([A2=ff]A1)ffi ! ([A02=ff]A01)ffi (Lemma 7.4.6)
) [A2ffi=ff](A1ffi) ! [A02

ffi=ff](A0

1

ffi) (Lemma 7.4.5)

) [A2=ff]A1 ! [A02=ff]A01 (Lemma 7.4.9)

7.5. KIND PRESERVATION 107

2

7.5 Kind Preservation
In this section I prove confluence for the erased system by first proving the diamond
property. I then use this result to show that conversion in the erased system preserves the
kinds of reified constructors and whether or not reified constructors' types are transparent
or opaque. This kind preservation result is required to prove subject reduction; see the
next section for details.

Theorem [Erased] 7.5.1 (Diamond property)

If A ! A1 and A ! A2 then 9A3 such that A1 ! A3 and A2 ! A3.

Proof: By structural induction on A with case analysis on what rewriting rules were
used. Without loss of generality (WLOG), we may assume that the derivation for A ! A1
uses the same or an earlier rule (earlier here being defined as occuring first in definition 7.3.1) than the A ! A2 derivation.

An extension of the diagram notation used in defining the diamond property (Definition 7.2.1) is used to present the subproofs. Rule names next to an arrow indicate
that that rewriting step used that particular rule. The symbols \Delta  and \Psi  represent arbitrary reduction steps. Multiple occurrences of one of these symbols in the same subproof
represent the same reduction step. Solid arrows represent givens while dotted arrows
are constructed according to the symbol attached to them. (IH) stands for a use of the
induction hypothesis and (lemma name) stands for an application of the named lemma.

The forms of the constructors in the diagrams are determined by the requirements of
the rules being considered and the shape preservation lemma (Lemma 7.4.15). The cases
are as follows:

1. REFL vs. any rule

A

A A2

A2

\Gamma \Gamma 
\Gamma \Gamma \Psi 
REFL @@

@@R
\Delta 

....

....

....R\Delta 

.....
.....
..\Psi  REFL

108 CHAPTER 7. TYPES: CONFLUENCE

2. DFUN vs. DFUN

\Pi x:A: A0

\Pi x:A1: A01 \Pi x:A2: A02

\Pi x:A3: A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 
DFUN @@

@@R
DFUN

.....

.....

.RDFUN

.....
.....
.\Psi  DFUN

Via: A

A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

A0
A01 A02

A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

....

..R(IH)

.....
....
..\Psi  (IH)

3. DSUM vs. DSUM

\Sigma x:A: A0

\Sigma x:A1: A01 \Sigma x:A2: A02

\Sigma x:A3: A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 
DSUM @@

@@R
DSUM

.....

.....

.RDSUM

.....
.....
.\Psi  DSUM

Via: A

A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

A0
A01 A02

A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

....

..R(IH)

.....
....
..\Psi  (IH)

4. LAM3 vs. LAM3

7.5. KIND PRESERVATION 109

*ff: A

*ff: A1 *ff: A2

*ff: A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 
LAM3 @@

@@R
LAM3

.....

.....

..RLAM3

.....
.....
..\Psi  LAM3

A
A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

5. LAM3;(REFL or APP) (R) vs. ETA3 (ff 62 FCV(A))

*ff: A ff

*ff: A1 ff A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

R @@

@@R
ETA3

.....

.....

..RETA3

.....
.....
..\Psi  \Delta 

A
A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  \Delta  (IH)

Here, ff 62 FCV(A1) by the reduct variables lemma (Lemma 7.4.14).

6. LAM3;BETA3 (R) vs. ETA3 (WLOG ff 6= ff0; ff 62 FCV(A))

*ff: (*ff0: A) ff

*ff: [ff=ff0]A1 A2

A3

\Gamma \Gamma 
\Gamma \Psi 

R @@

@@R
ETA3

....

....

...R\Psi 

.....
.....
..\Psi  \Delta 

*ff0: A
*ff0: A1 A2

A3

.....
.....
..\Psi 

LAM3 @@

@@R

.....

.....

..R\Psi  (IH)

.....
.....
..\Psi  \Delta  (IH)

Here, *ff0: A ! *ff0: A1 follows via the R-LAM3 rule from the given (not shown)
A ! A1. Since ff 62 FCV(A1) by the reduct variables lemma, *ff0: A1 = *ff: [ff=ff0]A1
(two constructors are considered the same if they are related by ff-conversion).

110 CHAPTER 7. TYPES: CONFLUENCE

7. APP vs. APP

A A0

A1 A01 A2 A02

A3 A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 
APP @@

@@R

APP

.....

.....

.RAPP

.....
.....
.\Psi  APP

Via: A

A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

A0
A01 A02

A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

....

....

...R(IH)

....
....
...\Psi  (IH)

8. APP;(REFL or LAM3) (R) vs. BETA3

(*ff: A) A0

(*ff: A1) A01 [A02=ff]A2

[A03=ff]A3

\Gamma \Gamma 
\Gamma \Psi 

R @@

@R

BETA3

.....

.....

.RBETA3

.....
.....
.\Psi  (parallelism I)

Via: A

A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

A0
A01 A02

A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

....

.....

..R(IH)

....
.....

..\Psi  (IH)

7.5. KIND PRESERVATION 111

9. APP;ETA3 (R) vs. BETA3 (ff 62 FCV(A))

(*ff: A ff) A0

A1 A01 [A02=ff]A2

[A03=ff]A3

\Gamma \Gamma 
\Gamma \Psi 

R @@

@R

BETA3

.....

.....

.R(parallelism I)

.....
.....
.\Psi  (parallelism I)

Via: A ff

A1 ff A2

A3

....
....
....\Psi APP

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

A0
A01 A02

A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

....

....

...R(IH)

....
....
...\Psi  (IH)

Here, A ff ! A1 ff follows via the R-APP and R-REFL rules from the given (not
shown) A ! A1. Applying parallelism I to A01 ! A03 and A1 ff ! A3 yields
[A01=ff](A1 ff) = A1 A01 ! [A03=ff]A3. ([A01=ff]A1 = A1 by Lemma 7.4.16 since
ff 62 FCV(A1) by the reduct variables lemma.)

10. TRANS vs. TRANS

!=A::K?

!=A1::K? !=A2::K?

!=A3::K?

\Gamma \Gamma 
\Gamma \Gamma \Psi 
TRANS @

@@

@R

TRANS

.....

.....

..RTRANS

.....
.....
..\Psi  TRANS

A
A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

11. EXT vs. EXT

112 CHAPTER 7. TYPES: CONFLUENCE

xae1Aae2ae3ae4!

xae1ae2A0

1 ae3ae4! xae1ae2ae3A

00
2 ae4!

xae1ae2ae3A00

3 ae4!

\Gamma \Gamma 
\Gamma \Psi 
EXT @@

@R
EXT

.....

.....

REXT

.....
.....
\Psi  EXT

A
A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

Where A01 = S(A1; xae1; ae2) and A002 = S(A2; xae1; ae2ae3). By parallelism II, we have
that A03 = S(A3; xae1; ae2) and A003 = S(A3; xae1; ae2ae3) exist with A01 ! A03 and
A002 ! A003. By Lemma 7.4.13,

A003 = S(A3; xae1; ae2ae3) = S(S(A3; xae1; ae2); xae1ae2; ae3) = S(A03; xae1ae2; ae3)

12. EXT vs. ABBREV

xaeA!

xaeA

1 ! A2

A3

\Gamma \Gamma 
\Gamma \Psi 
EXT @@

@R

ABBREV

.....

.....

.RABBREV

.....
.....
..\Psi  (shape)

A
A1 !=A2::K?

!=A3::K?

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

13. BETA3 vs. BETA3

(*ff: A) A0
[A01=ff]A1 [A02=ff]A2

[A03=ff]A3

\Gamma \Gamma 
\Gamma \Psi 

BETA3 @

@@R

BETA3

.....

.....

.R(parallelism I)

.....
.....
.\Psi  (parallelism I)

7.5. KIND PRESERVATION 113

Via: A

A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

A0
A01 A02

A03

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

....

....

...R(IH)

....
....
...\Psi  (IH)

14. ETA3 vs. ETA3 (ff 62 FCV(A))

*ff: A ff

A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 
ETA3 @@

@@R
ETA3

.....

.....

..R\Psi 

.....
.....
..\Psi  \Delta 

A
A1 A2

A3

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R\Psi  (IH)

.....
.....
..\Psi  \Delta  (IH)

15. ABBREV vs. ABBREV

xaeA!

A1 A2

A3

\Gamma \Gamma 
\Gamma \Psi 

ABBREV @

@@RABBREV

.....

.....

..R(shape)

.....
.....
..\Psi  (shape)

A
!=A1::K? !=A2::K?

!=A3::K?

\Gamma \Gamma 
\Gamma \Gamma \Psi 

@@

@@R

.....

.....

..R(IH)

.....
.....
..\Psi  (IH)

2
Theorem [Erased] 7.5.2 (Confluence)

If A !\Lambda  A1 and A !\Lambda  A2 then 9A0 such that A1 !\Lambda  A0 and A2 !\Lambda  A0.

Proof: Same as that of Theorem 7.2.2. 2

114 CHAPTER 7. TYPES: CONFLUENCE
Theorem [Erased] 7.5.3 (Church-Rosser)

If A1 ss A2 then A1 #\Lambda  A2.

Proof: (Idea) A1 ss A2 means that one can get from A1 to A2 via a finite alternating
series of first rewriting then rewriting backwards. Without loss of generality, we can
assume the series starts with rewriting and ends with rewriting. (This is because we
can always rewrite (backwards) a term to itself via the R-REFL rule.) We can then use
confluence to "fill in the bottom half of the gird" like we did for the previous theorem.
Example:

A1 A6 A5

A7 A8 A2

A9 A10

A0

\Gamma \Gamma 
\Gamma \Gamma \Psi \Lambda 

\Gamma \Gamma 
\Gamma \Gamma \Psi \Lambda 
.....
.....
..\Psi \Lambda 

.....
.....
..\Psi \Lambda 

.....
.....
..\Psi \Lambda 

@@

@@R\Lambda 
@@

@@R\Lambda 

.....

.....

..R\Lambda 

@@

@@R\Lambda 

.....

.....

..R\Lambda 

.....

.....

..R\Lambda 

The result we want follows by the transitivity of !\Lambda . 2

Lemma [Erased] 7.5.4 (Kind Preservation)

1. If !=A::K? ss !=A0::K0? then K = K 0.
2. !=A::K ? ss !K0? is impossible.

Proof: Applying Theorem 7.5.3 shows that the two sides of each conversion have a
common reduct. Repeated application of Lemma 7.4.15 places requirements on the form
the common reduct can have. In the first case, the common reduct must be a transparent
type whose kind is the same as both K and K0. Hence, K must equal K 0. In the second
case, the conversion is impossible because it would require the common reduct to be both
a transparent and an opaque type at the same time. 2

7.6. SUBJECT REDUCTION 115
7.6 Sub ject Reduction
In this section I prove subject reduction for constructors. Because I have not yet shown
that all sub-constructors of a constructor are valid (in particular, tags are not yet shown
to be valid), I have to do this via a series of steps. First I prove the propositions needed
to show that fi- or j-reducing an entire valid constructor with no reduction of any subconstructors results in a valid constructor:

Lemma [Tagged] 7.6.1 (Substitutions on assignments)

Let ` be a place or constructor substitution. Then:

1. dom(`\Gamma ) = dom(\Gamma )

2. `(\Gamma 1; \Gamma 2) = (`\Gamma 1); (`\Gamma 2)
3. If ff::K 2 \Gamma  then ff::K 2 `\Gamma .
4. If x:A 2 \Gamma  then x:(`A) 2 `\Gamma .
Proof: The first two parts are shown by structural induction on \Gamma  and \Gamma 2 respectively.
For the last two parts, first show by structural induction that:

`(ffl; D1; : : : ; Dn) = `ffl; `D1; : : : ; `Dn
The desired results then follow from this plus the facts that `(ff::K) = ff::K and
`(x:A) = x:(`A). 2

Theorem [Tagged] 7.6.2 (Validity of constructor substitution)

Suppose \Gamma  ` A :: K. Then:

1. If ` \Gamma ; ff::K; \Gamma 0 valid then ` \Gamma ; [A=ff]\Gamma 0 valid.

2. If \Gamma ; ff::K; \Gamma 0 ` A0 :: K0 then \Gamma ; [A=ff]\Gamma 0 ` [A=ff]A0 :: K0.
3. If \Gamma ; ff::K; \Gamma 0 ` xae ) A0 then \Gamma ; [A=ff]\Gamma 0 ` xae ) [A=ff]A0.
4. If \Gamma ; ff::K; \Gamma 0 ` A1 = A2 :: K0 then \Gamma ; [A=ff]\Gamma 0 ` [A=ff]A1 = [A=ff]A2 :: K0.
Proof: By simultaneous structural induction on the derivations. Example cases:
DECL-T: Given ` \Gamma ; ff::K; \Gamma 00; x:A0 valid derived via rule DECL-T from

\Gamma ; ff::K; \Gamma 00 ` A0 :: \Omega  and x 62 dom(\Gamma ; ff::K; \Gamma 00). By the induction hypothesis, we
have that \Gamma ; [A=ff]\Gamma 00 ` [A=ff]A0 :: \Omega . By Lemma 6.8.2, dom(\Gamma ; ff::K; \Gamma 00) = dom(\Gamma )[
fffg[dom(\Gamma 00) so we have that x 62 dom(\Gamma ) and x 62 dom(\Gamma 00). Since by Lemma 7.6.1,
dom([A=ff]\Gamma 00) = dom(\Gamma 00), we have that x 62 dom(\Gamma ; [A=ff]\Gamma 00). Hence, by rule
DECL-T, we have that ` \Gamma ; [A=ff]\Gamma 00; x:A0 valid.

116 CHAPTER 7. TYPES: CONFLUENCE
C-VAR I: Given \Gamma ; ff::K; \Gamma 0 ` ff :: K0 derived via rule C-VAR from ` \Gamma ; ff::K; \Gamma 0 valid and

ff::K0 2 \Gamma ; ff::K ; \Gamma 0. By Lemma 6.8.11, K = K0. By the induction hypothesis,
we have that ` \Gamma ; [A=ff]\Gamma 0 valid. By weakening (Theorem 6.8.10), we have that
\Gamma ; [A=ff]\Gamma 0 ` A :: K ) \Gamma ; [A=ff]\Gamma 0 ` [A=ff]ff :: K0.

C-VAR II: Given \Gamma ; ff::K; \Gamma 0 ` ff0 :: K0, ff 6= ff0, derived via rule C-VAR from

` \Gamma ; ff::K; \Gamma 0 valid and ff0::K0 2 \Gamma ; ff::K; \Gamma 0. By Lemma 7.6.1, ff0::K0 2 \Gamma ; [A=ff]\Gamma 0.
By the induction hypothesis, we have that ` \Gamma ; [A=ff]\Gamma 0 valid. Hence, by rule CVAR and the fact that [A=ff]ff0 = ff0,
\Gamma ; [A=ff]\Gamma 0 ` [A=ff]ff0 :: K0.

P-INIT: Given \Gamma ; ff::K; \Gamma 0 ` x ) A0 derived via rule P-INIT from ` \Gamma ; ff::K; \Gamma 0 valid and

x:A0 2 \Gamma ; ff::K; \Gamma 0. Applying the induction hypothesis gives us that ` \Gamma ; [A=ff]\Gamma 0 valid.
By Lemma 7.6.1, x:[A=ff]A0 2 [A=ff]\Gamma ; [A=ff]\Gamma 0. By repeated use of Lemma 6.8.3,
we have that ` \Gamma ; ff::K valid ) ff 62 FCV(\Gamma ) (Theorem 6.8.8) ) [A=ff]\Gamma  = \Gamma 
(Lemma 7.3.9) ) x:[A=ff]A0 2 \Gamma ; [A=ff]\Gamma 0. From these results, the desired result
follows via the P-INIT rule.

P-MOVE: Given \Gamma ; ff::K; \Gamma 0 ` xaeae0 ) A3 derived via rule P-MOVE from

\Gamma ; ff::K; \Gamma 0 ` xae ) A1, \Gamma ; ff::K; \Gamma 0 ` A1 = A2 :: \Omega , and A3 = S(A2; xae; ae0). Applying the induction hypothesis gives us that \Gamma ; [A=ff]\Gamma 0 ` xae ) [A=ff]A1 and
\Gamma ; [A=ff]\Gamma 0 ` [A=ff]A1 = [A=ff]A2 :: \Omega . By Lemma 7.3.10, [A=ff]A3 =
[A=ff]S(A2; xae; ae0) = S([A=ff]A2; xae; ae0). From these results, the desired result follows via the P-MOVE rule.

E-ETA: Given \Gamma ; ff::K; \Gamma 0 ` *ff0::K0: A0 ff0 = A0 :: K0)K00 derived via rule E-ETA from

\Gamma ; ff::K; \Gamma 0 ` A0 :: K0)K00 and ff0 62 FCV(A0). WLOG, assume ff0 6= ff and ff0 62
FCV(A). By the induction hypothesis, we have that \Gamma ; [A=ff]\Gamma 0 ` [A=ff]A0 :: K0)K00.
By Lemma 6.8.6, FCV([A=ff]A0) ` FCV(A)[(FCV(A0)\Gamma fffg) ) ff0 62 FCV([A=ff]A0).
The desired result follows via the E-ETA rule.

2

Lemma [Tagged] 7.6.3 (Kind inhabitation) If ` \Gamma  valid and K is any kind then 9A
such that \Gamma  ` A :: K.

Proof: Define K as: \Omega  = !\Omega ?

K1)K2 = *ff::K1: K2
Then show by structural induction on K that \Gamma  ` K :: K. 2

7.6. SUBJECT REDUCTION 117
Corollary [Tagged] 7.6.4 (Strengthening)

If \Gamma ; ff::K ` A :: K 0 and ff 62 FCV(A) then \Gamma  ` A :: K 0.

Proof: By Lemma 6.8.3, ` \Gamma  valid. Apply Lemma 7.6.3 to K to get K such that
\Gamma  ` K :: K . Then apply Theorem 7.6.2 with \Gamma  = \Gamma , \Gamma 0 = ffl, A = K , K = K , and
K0 = K0 to get \Gamma  ` [K=ff]A :: K 0. Since ff 62 FCV(A), we have that [K=ff]A = A by
Lemma 7.3.9. This gives us the desired result. 2

Second, I use these results and the previous section's kind preservation result to prove
that equal constructors are valid constructors. (This result is needed to show that place
lookup produces valid constructors and hence tags of valid constructors are valid.)

Lemma [Tagged] 7.6.5 If \Gamma  ` xaeAae0! :: K then

1. \Gamma  ` xae ) A is a sub-derivation.
2. \Gamma  ` xaeae0 ) A0 where A0 has either the form !K? or the form !=A00::K? for some

A00

Proof: By inspection of the only two rules (C-EXT-O2 and C-EXT-T2) capable of
deriving \Gamma  ` xaeAae0! :: K. 2

Lemma [Mixed] 7.6.6 If \Gamma  ` xae ) A, where ae = :i1: \Delta  \Delta  \Delta  :in, (n * 0) then 9B0; B00; B1; B01;
: : : ; Bn such that:

1. B0 = \Gamma (x)ffi
2. B0j ss Bj (0 ^ j ! n)
3. Bj+1 = S(B0j; x:i1 \Delta  \Delta  \Delta  :ij; :ij+1) (0 ^ j ! n)
4. Bn ss Affi
(Here A's are tagged constructors and B's are erased constructors.)

Proof: By structural induction on the derivation of \Gamma  ` xae ) A. The base case is
handled using Theorem 6.8.11 to show that x:A 2 \Gamma  ) A = \Gamma (x) and the fact that conversion is reflexive by definition. The inductive case is handled using Corollary 7.3.5 and
Corollary 7.4.7 (to turn the equality judgment into an erased conversion), Lemmas 7.4.5
and 7.4.13 (to turn multiple-step path selections into erased staged single-step selections),
and the properties of conversion (to turn a possibly empty series of conversions into a
single one). 2

118 CHAPTER 7. TYPES: CONFLUENCE
Lemma [Erased] 7.6.7 If A ss A0 and both S(A; xae; ae0) and S(A0; xae; ae0) exist then
S(A; xae; ae0) ss S(A0; xae; ae0).

Proof: By Theorem 7.5.3, A and A0 have a common reduct. By repeated use of parallelism II (theorem 7.4.17), this means that S(A; xae; ae0) and S(A0; xae; ae0) have a common
reduct; hence they convert. 2

Theorem [Tagged] 7.6.8 If \Gamma  ` xae ) A1 and \Gamma  ` xae ) A2 then Affi1 ss Affi2.
Proof: First apply Lemma 7.6.6 to both \Gamma  ` xae ) A1 and \Gamma  ` xae ) A2 then apply
Lemma 7.6.7 as many times as needed. 2

Theorem [Tagged] 7.6.9 (Replacement with an equal type)

Suppose \Gamma  ` A1 = A2 :: \Omega  and \Gamma  ` A2 :: \Omega . Then:

1. If ` \Gamma ; x:A1; \Gamma 0 valid then ` \Gamma ; x:A2; \Gamma 0 valid.
2. If \Gamma ; x:A1; \Gamma 0 ` A :: K then \Gamma ; x:A2; \Gamma 0 ` A :: K.
3. If \Gamma ; x:A1; \Gamma 0 ` x0ae ) A then \Gamma ; x:A2; \Gamma 0 ` x0ae ) A.
4. If \Gamma ; x:A1; \Gamma 0 ` A = A0 :: K then \Gamma ; x:A2; \Gamma 0 ` A = A0 :: K.
Proof: By simultaneous structural induction on the derivations. Interesting cases:
DECL-T I: Given ` \Gamma ; x:A1 valid derived via DECL-T from \Gamma  ` A1 :: \Omega  and x 62 dom(\Gamma ).

The desired result, ` \Gamma ; x:A2 valid follows immediately from the precondition that
\Gamma  ` A2 :: \Omega  via the DECL-T rule.

P-INIT I: Given \Gamma ; x:A1; \Gamma 0 ` x ) A derived via rule P-INIT from ` \Gamma ; x:A1; \Gamma 0 valid and

x:A 2 (\Gamma ; x:A1; \Gamma 0). By applying the induction hypothesis, we have that
` \Gamma ; x:A2; \Gamma 0 valid. By rule P-INIT then, \Gamma ; x:A2; \Gamma 0 ` x ) A2. By applying weakening to the equality precondition (theorem 6.8.10), we have that
\Gamma ; x:A2; \Gamma 0 ` A1 = A2 :: \Omega . Then, by applying E-SYM, we have that
\Gamma ; x:A2; \Gamma 0 ` A2 = A1 :: \Omega . By lemma 6.8.11, we have that A = A1. Thus, by
P-MOVE, we have that \Gamma ; x:A2; \Gamma 0 ` x ) A.

2

Theorem [Tagged] 7.6.10 (Validity of equal constructors)

If \Gamma  ` A1 = A2 :: K then \Gamma  ` A1 :: K and \Gamma  ` A2 :: K.

7.6. SUBJECT REDUCTION 119
Proof: By structural induction on the typing derivation. Example cases:
E-DFUN: Given \Gamma  ` \Pi x:A1: A2 = \Pi x:A01: A02 :: \Omega  derived via rule E-DFUN from

\Gamma  ` A1 = A01 :: \Omega  and \Gamma ; x:A1 ` A2 = A02 :: \Omega . Applying the induction hypothesis
gives us that \Gamma  ` A01 :: \Omega , \Gamma ; x:A1 ` A2 :: \Omega , and \Gamma ; x:A1 ` A02 :: \Omega . Applying Theorem 7.6.9, we get that \Gamma ; x:A01 ` A02 :: \Omega . Applying rule C-DFUN twice then gives
us the desired results.

E-BETA: Given \Gamma  ` (*ff::K: A) A0 = [A0=ff]A :: K0 derived via rule E-BETA from

\Gamma ; ff::K ` A :: K0 and \Gamma  ` A0 :: K. By using rules C-LAM and C-APP, we have
that \Gamma  ` (*ff::K: A) A0 :: K0. By Theorem 7.6.2, \Gamma  ` [A0=ff]A :: K0.

E-ETA: Given \Gamma  ` *ff::K: A ff = A :: K)K 0, ff 62 FCV(\Gamma ) (WLOG), derived via rule EETA from \Gamma  ` A :: K)K0 and ff 62 FCV(A). By Lemma 6.8.3, ` \Gamma  valid. Hence,
by rules C-VAR and DECL-C, \Gamma ; ff::K ` ff :: K. By weakening (Theorem 6.8.10),
\Gamma ; ff::K ` A :: K)K0. Hence, by rules C-APP and C-LAM, \Gamma  ` *ff::K: A ff :: K)K0.

E-EXT2: Given \Gamma  ` xaeA

1 ae

0ae00! = xaeae0A

2 ae

00! :: K derived via rule E-EXT2 from

\Gamma  ` xaeA

1ae

0ae00! :: K, \Gamma  ` A1 = A :: \Omega , and S(A; xae; ae0) = A2. By Lemma 7.6.5,

we have that \Gamma  ` xae ) A1 and \Gamma  ` xaeae0ae00 ) A0 where A0 has either the form
!K? or the form !=A00::K? for some A00. By P-MOVE then, \Gamma  ` xaeae0 ) A2.
Thus, by C-EXT-O2 or C-EXT-T2 (depending on the form of A00), we have that
\Gamma  ` xaeae0A

2ae

00! :: K.

E-ABBREV2: Given \Gamma  ` xaeA! = A0 :: K derived via rule E-ABBREV2 from \Gamma  ` xaeA! :: K and

\Gamma  ` A = !=A0::K0? :: \Omega . Applying the induction hypothesis gives us that
\Gamma  ` !=A0::K0? :: \Omega  and hence (only rule C-TRANS can apply) that \Gamma  ` A0 :: K0.
By Lemma 7.6.5, we have that \Gamma  ` xae ) A and \Gamma  ` xae ) A00 where A00 has either the form !K? or the form !=A000::K? for some A000. By rule P-MOVE,
\Gamma  ` xae ) !=A0::K0?. By Theorem 7.6.8, this implies that !=A0ffi::K0? ss A00ffi
where A00ffi is either !K? or !=A000ffi::K?. By Lemma 7.5.4, this implies that
K = K0.

2

The following theorem, which will be needed for deciding constructor validity, also
follows from the kind preservation results:

Theorem [Tagged] 7.6.11 (Uniqueness of constructor kind)

If \Gamma  ` A :: K1 and \Gamma  ` A :: K2 then K1 = K2.

Proof: By structural induction on A. Example cases:

120 CHAPTER 7. TYPES: CONFLUENCE

Var: Here A = ff. The only applicable rule is C-VAR so we must have that ff::K 1 2 \Gamma 

and ff::K2 2 \Gamma . By Lemma 6.8.3 and Theorem 6.8.11, K 1 = K2.

Lam: Here A = *ff::K: A0. The only applicable rule is C-LAM. Applying the induction

hypothesis, gives us that \Gamma ; ff::K ` A0 :: K 0 for exactly one K0. Hence, by C-LAM,
K1 = K2 = K)K0.

Ext: Here A = xaeA0ae0!. By Lemma 7.6.5, \Gamma  ` xaeae0 ) A1 and \Gamma  ` xaeae0 ) A2 where the

Ai's each have either the form !Ki? or the form !=A0i::Ki? for some A0i. By
Theorem 7.6.8, Affi1 ss Affi2. Hence, by kind preservation (Lemma 7.5.4), K1 = K2.

2
Third, I show that selection as used in place lookup results in valid constructors:

Theorem [Tagged] 7.6.12 (Validity of place substitution)

Suppose \Gamma  ` xae ) A0. Then:

1. If ` \Gamma ; x0:A0; \Gamma 0 valid then ` \Gamma ; [xae=x0]\Gamma 0 valid.
2. If \Gamma ; x0:A0; \Gamma 0 ` A :: K then \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]A :: K.
3. If \Gamma ; x0:A0; \Gamma 0 ` x00ae00 ) A then \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]x00ae00 ) [xae=x0]A.
4. If \Gamma ; x0:A0; \Gamma 0 ` A1 = A2 :: K then \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]A1 = [xae=x0]A2 :: K.

Proof: By simultaneous structural induction on the typing derivations. Example cases:
DECL-T I: Given ` \Gamma ; x0:A0; \Gamma 0; x00:A valid derived via rule DECL-T from

\Gamma ; x0:A0; \Gamma 0 ` A :: \Omega  and x00 62 dom(\Gamma ; x0:A0; \Gamma 0) = dom(\Gamma ) [ fx0g [ dom(\Gamma 0) by
Lemma 6.8.2. By Theorem 6.8.3, ` \Gamma ; x0:A0; \Gamma 0 valid. Applying the induction hypothesis then gives us that \Gamma ; x0:A0; \Gamma 0 ` A :: \Omega  and
\Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]A :: \Omega . Since by Lemma 7.6.1, dom([xae=x0]\Gamma 0) = dom(\Gamma 0), we
have that x00 62 dom(\Gamma ; [xae=x0]\Gamma 0). Thus, by DECL-T, we have that
` \Gamma ; [xae=x0]\Gamma 0; x00:[xae=x0]A valid.

C-VAR: Given \Gamma ; x0:A0; \Gamma 0 ` ff :: K derived via C-VAR from ` \Gamma ; x0:A0; \Gamma 0 valid and ff::K 2

(\Gamma ; x0:A0; \Gamma 0). Applying the induction hypothesis gives us that ` \Gamma ; [xae=x0]\Gamma 0 valid.
By Lemma 7.6.1, we have that ff::K 2 \Gamma ; [xae=x0]\Gamma 0. The desired result then follows
via the C-VAR rule.

7.6. SUBJECT REDUCTION 121
C-EXT-O2: Given \Gamma ; x0:A0; \Gamma 0 ` x00ae0Aae00! :: K derived via C-EXT-O2 from

\Gamma ; x0:A0; \Gamma 0 ` x00ae0ae00 ) !K? and \Gamma ; x0:A0; \Gamma 0 ` x00ae0 ) A. Applying the induction
hypothesis gives us that \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]x00ae0ae00 ) !K? and
\Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]x00ae0 ) [xae=x0]A. The desired result then follows via the CEXT-O2 rule since [xae=x0]x00ae0Aae00! = ([xae=x0]x00ae0)[xae=x0]Aae00! and [xae=x0]x00ae0ae00 =

([xae=x0]x00ae0)ae00 by Lemma 6.5.1.

P-INIT I: Given \Gamma ; x0:A0; \Gamma 0 ` x0 ) A derived via rule P-INIT from ` \Gamma ; x0:A0; \Gamma 0 valid and

x0:A 2 (\Gamma ; x0:A0; \Gamma 0). By repeated use of Lemma 6.8.3, we have that ` \Gamma ; x0:A0 valid
) \Gamma  ` A0 :: \Omega  and x0 62 dom(\Gamma ) (DECL-T). By Theorem 6.8.5, FTV(A0) ` dom(\Gamma )
) x0 62 FTV(A0) ) [xae=x0]A0 = A0 (Theorem 7.3.9). By Lemma 6.8.11, A = A0.
Applying the induction hypothesis gives us that ` \Gamma ; [xae=x0]\Gamma 0 valid. By applying
weakening (Theorem 6.8.10) to the precondition, we get that \Gamma ; [xae=x0]\Gamma 0 ` xae ) A0.
Hence, \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]x0 ) [xae=x0]A. as desired.

P-INIT II: Given \Gamma ; x0:A0; \Gamma 0 ` x00 ) A, x00 6= x0, derived via rule P-INIT from

` \Gamma ; x0:A0; \Gamma 0 valid and x00:A 2 (\Gamma ; x0:A0; \Gamma 0). Applying the induction hypothesis
gives us that ` \Gamma ; [xae=x0]\Gamma 0 valid. By Lemma 7.6.1, x00:[xae=x0]A 2
([xae=x0]\Gamma ; x0:[xae=x0]A0; [xae=x0]\Gamma 0). By repeated use of Lemma 6.8.3, we have that
` \Gamma ; x0:A0 valid and ` \Gamma  valid ) x0 62 dom(\Gamma ) (DECL-T). By Theorem 6.8.5, FTV(\Gamma )
` dom(\Gamma ) ) x0 62 FTV(\Gamma ) ) [xae=x0]\Gamma  = \Gamma  (Theorem 7.3.9). Hence, x00:[xae=x0]A 2
\Gamma ; [xae=x0]\Gamma 0. The desired result then follows via the P-INIT rule.

E-BETA: By use of the induction hypothesis plus Lemma 7.3.10.

E-ETA: By use of the induction hypothesis plus Lemma 6.8.6.
E-EXT2: Given \Gamma ; x0:A0; \Gamma 0 ` x00ae0A

1ae

00ae000! = x00ae0ae00A

2ae

000! :: K derived via rule E-EXT2 from

\Gamma ; x0:A0; \Gamma 0 ` x00ae0A

1ae

00ae000! :: K, \Gamma ; x0:A0; \Gamma 0 ` A1 = A :: \Omega , and S(A; x00ae0; ae00) = A2.

Applying the induction hypothesis gives us that
\Gamma ; [xae=x0]\Gamma 0 ` ([xae=x0]x00ae0)[xae=x0]A

1 ae

00ae000! :: K and

\Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]A1 = [xae=x0]A :: \Omega . By Lemma 7.3.12, [xae=x0]A2 =
[xae=x0]S(A; x00ae0; ae00) = S([xae=x0]A; [xae=x0]x00ae0; ae00). The desired result then follows
via the E-EXT2 rule.

2

Theorem [Tagged] 7.6.13 (Validity of selection)

Suppose \Gamma  ` xae ) A, \Gamma  ` A :: \Omega , and S(A; xae; ae0) = A0. Then

1. \Gamma  ` A0 :: \Omega 

122 CHAPTER 7. TYPES: CONFLUENCE

2. \Gamma  ` xaeae0 ) A0
Proof: By structural induction on ae0:
Base: Given \Gamma  ` xae ) A, \Gamma  ` A :: \Omega , and S(A; xae; ffl) = A0 = A (ae0 = ffl). The desired

results follow from this immediately.

Fst: Given \Gamma  ` xae ) A, \Gamma  ` A :: \Omega , and S(A; xae; ae0:1) = A0. By Lemma 6.8.1,

S(A; xae; ae0:1) = S(S(A; xae; ae0); xaeae0; :1). Let A00 = S(A; xae; ae0). Since S(A00; xaeae0; :1)
exists and equals A0, A00 must have form \Sigma x0:A0: A2 for some A2. Applying the induction hypothesis gives us that \Gamma  ` xaeae0 ) A00 and \Gamma  ` \Sigma x0:A0: A2 :: \Omega  ) \Gamma  ` A0 :: \Omega 
(C-DSUM). By E-REFL, \Gamma  ` A00 = A00 :: \Omega , so by P-MOVE we have \Gamma  ` xaeae0:1 ) A0.

Snd: Given \Gamma  ` xae ) A, \Gamma  ` A :: \Omega , and S(A; xae; ae0:2) = A0. By Lemma 6.8.1,

S(A; xae; ae0:2) = S(S(A; xae; ae0); xaeae0; :2). Let A00 = S(A; xae; ae0). Since S(A00; xaeae0; :2)
exists and equals A0, A00 must have form \Sigma x0:A1: A2 for some A1 and A2 where
[xaeae0:1=x0]A2 = A0. Applying the induction hypothesis gives us that \Gamma  ` xaeae0 ) A00
and \Gamma  ` \Sigma x0:A1: A2 :: \Omega  ) \Gamma  ` A1 :: \Omega  and \Gamma ; x0:A1 ` A2 :: \Omega  (C-DSUM). By EREFL, \Gamma  ` A00 = A00 :: \Omega  and \Gamma  ` A1 = A1 :: \Omega , so by P-MOVE we have
\Gamma  ` xaeae0:1 ) A1 and \Gamma  ` xaeae0:2 ) A0. By Theorem 7.6.12, we have that
\Gamma  ` [xaeae0:1=x0]A2 :: \Omega .

2

Fourth, I show from this result and the validity of equals result that the result of
looking up a place is valid and hence that tags of valid constructors are valid:

Theorem [Tagged] 7.6.14 (Validity of looked up places)

If \Gamma  ` xae ) A then \Gamma  ` A :: \Omega .

Proof: By structural induction on the typing derivation:
P-INIT: Given \Gamma  ` x ) A derived via rule P-INIT from ` \Gamma  valid and x:A 2 \Gamma . By

Lemma 6.8.11, \Gamma  ` A :: \Omega .

P-MOVE: Given \Gamma  ` xaeae0 ) A00 derived via rule P-MOVE from \Gamma  ` xae ) A,

\Gamma  ` A = A0 :: \Omega , and S(A0; xae; ae0) = A00. By Theorem 7.6.10, \Gamma  ` A0 :: \Omega . By PMOVE, \Gamma  ` xae ) A0. Hence, by Theorem 7.6.13, \Gamma  ` A00 :: \Omega .

2

Theorem [Tagged] 7.6.15 (Validity of tags)

If \Gamma  ` xaeAae0! :: K then \Gamma  ` A :: \Omega .

7.6. SUBJECT REDUCTION 123
Proof: By Lemma 7.6.5, \Gamma  ` xae ) A. By Theorem 7.6.14, \Gamma  ` A :: \Omega . 2

Finally, I use the previous results to show subject reduction:
Theorem [Tagged] 7.6.16 (Partial correctness II)

If \Gamma  ` A :: K and A ! A0 then \Gamma  ` A = A0 :: K .

Proof: By structural induction on the derivation of A ! A0. Example cases:
R-DFUN: Given \Pi x:A1: A2 ! \Pi x:A01: A02 derived via rule R-DFUN from A1 ! A01 and

A2 ! A02 as well as \Gamma  ` \Pi x:A1: A2 :: \Omega  ) \Gamma  ` A1 :: \Omega  and \Gamma ; x:A1 ` A2 :: \Omega  (CDFUN). Applying the induction hypothesis gives us that \Gamma  ` A1 = A01 :: \Omega  and
\Gamma ; x:A1 ` A2 = A02 :: \Omega . Hence, by E-DFUN, \Gamma  ` \Pi x:A1: A2 = \Pi x:A01: A02 :: \Omega .

R-EXT: Given xaeA

1 ae

0ae00! ! xaeae0A

2ae

00! derived via rule R-EXT from A1 ! A and S(A; xae; ae0) =

A2 as well as \Gamma  ` xaeA

1 ae

0ae00! :: K. By Theorem 7.6.15, \Gamma  ` A1 :: \Omega . Applying the

induction hypothesis then gives us that \Gamma  ` A1 = A :: \Omega . The desired result then
follows via the E-EXT2 rule.

R-BETA: Given (*ff::K: A1) A2 ! [A02=ff]A01 derived via rule R-BETA from A1 ! A01 and

A2 ! A02 as well as \Gamma  ` (*ff::K: A1) A2 :: K0 ) \Gamma  ` *ff::K : A1 :: K)K0 and
\Gamma  ` A2 :: K (C-APP) ) \Gamma ; ff::K ` A1 :: K0 (C-LAM). Applying the induction hypothesis then gives us that \Gamma ; ff::K ` A1 = A01 :: K0 and \Gamma  ` A2 = A02 :: K. Hence
by E-LAM and E-APP, \Gamma  ` (*ff::K: A1) A2 = (*ff::K: A01) A02 :: K0. By Theorem 7.6.10,
\Gamma ; ff::K ` A01 :: K0 and \Gamma  ` A02 :: K. The desired result then follows via the E-BETA
and E-TRAN rules.

R-ETA: Given *ff::K: A ff ! A0 derived via rule R-ETA from A ! A0 and ff 62 FCV(A) as

well as \Gamma  ` *ff::K: A ff :: K)K 0 ) \Gamma ; ff::K ` A ff :: K0 (C-LAM)
) \Gamma ; ff::K ` A :: K)K0 (C-APP). By Corollary 7.6.4, \Gamma  ` A :: K)K0. The desired result then follows via the E-ETA rule.

R-ABBREV: Given xaeA! ! A0 derived via rule R-ABBREV from A ! !=A0::K0? as well as

\Gamma  ` xaeA! :: K. By Theorem 7.6.15, \Gamma  ` A :: \Omega . Applying the induction hypothesis
then gives us that \Gamma  ` A = !=A0::K0? :: \Omega . The desired result then follows via the
E-ABBREV2 rule.

2

Corollary [Tagged] 7.6.17 (Subject reduction)

If \Gamma  ` A :: K and A ! A0 then \Gamma  ` A0 :: K.

Proof: By Theorem 7.6.16, \Gamma  ` A = A0 :: K . By Theorem 7.6.10, \Gamma  ` A0 :: K. 2

124 CHAPTER 7. TYPES: CONFLUENCE
7.7 Confluence
A constructor context C is a constructor with a single hole, written []:

Contexts C ::= [] j \Pi x:C: A j \Pi x:A: C j \Sigma x:C: A j \Sigma x:A: C j *ff::K: C j

C A j A C j !=C::K? j xaeC ae0!

The hole in C may be filled by a constructor A, written C[A], by replacing the hole
with A, incurring capture of free variables in A that are bound at the occurrence of the
hole. For example, if C = *ff::\Omega : \Sigma x:!=ff::\Omega ?: [] , and A = x!=ff::\Omega ?!, then C[A] =
*ff::\Omega : \Sigma x:!=ff::\Omega ?: x!=ff::\Omega ?!. The variables that are bound at the hole of a context
are said to be exposed (to capture) by that context. I shall write ECV(C) for the exposed
constructor variables and ETV(C) for the exposed term variables of a context.

Type checking is compositional in the sense that if a constructor is valid, then so are
all its sub-constructors:

Lemma [Tagged] 7.7.1 (Decomposition)

Suppose that \Gamma  ` C[A] :: K such that ETV(C)"dom(\Gamma ) = ; and ECV(C)"dom(\Gamma ) = ;.1
Then there exists \Gamma 0 and K0 such that:

ffl dom(\Gamma 0) = ECV(C) [ ETV(C)
ffl \Gamma ; \Gamma 0 ` A :: K0

Proof: By structural induction on C. Example cases:
DFUN I: Given C = \Pi x:[]: A2, \Gamma  ` \Pi x:A: A2 :: \Omega , ETV(C) = ;"dom(\Gamma ) = ;, and ECV(C) =

; " dom(\Gamma ) = ; ) ECV(C) [ ETV(C) = ; and \Gamma  ` A :: \Omega  (C-DFUN). Thus, it
suffices to let \Gamma 0 = ffl and K0 = \Omega .

DFUN II: Given C = \Pi x:A1: [], \Gamma  ` \Pi x:A1: A :: \Omega , ETV(C) = fxg " dom(\Gamma ) = ;, and

ECV(C) = ; " dom(\Gamma ) = ;. ) x 62 dom(\Gamma ) and ECV(C) [ ETV(C) = fxg
and \Gamma ; x:A1 ` A :: \Omega  (C-DFUN). Thus, it suffices to let \Gamma 0 = ffl; x:A1 and K0 = \Omega .

EXT: Given C = xae[]ae0!, \Gamma  ` xaeAae0! :: K, ETV(C) = ; " dom(\Gamma ) = ;, and ECV(C) =

; " dom(\Gamma ) = ; ) ECV(C) [ ETV(C) = ;. By Theorem 7.6.15, \Gamma  ` A :: \Omega . Thus,
it suffices to let \Gamma 0 = ffl and K0 = \Omega .

2

1The conditions on the exposed variables can always be satisfied by alpha-renaming C[A]
appropriately.

7.8. EQUALITY 125
Theorem [Tagged] 7.7.2 (Diamond property)

If \Gamma  ` A :: K, A ! A1, and A ! A2 then 9A3 such that A1 ! A3 and A2 ! A3.

Proof: The proof is very similar to that of that for the erased system (Theorem 7.5.1),
with the tagged rather than erased versions of the various lemmas and theorems being
used. Lemma 7.7.1 is used to establish the validity of the various sub-constructors so
that the induction hypothesis can be applied. Only one case requires different handling
because of the presence of kind labels in lambdas:

ffl LAM;BETA (R) vs. ETA (WLOG ff 6= ff0; ff 62 FCV(A))

*ff::K: (*ff0::K0: A) ff

*ff::K: [ff=ff0]A1 A2

A3

\Gamma \Gamma 
\Gamma \Psi 

R @@

@@R
ETA

....

....

...R\Psi 

.....
.....
..\Psi  \Delta 

*ff0::K0: A
*ff0::K0: A1 A2

A3

.....
.....
..\Psi 
LAM @@

@@R

.....

.....

..R\Psi  (IH)

.....
.....
..\Psi  \Delta  (IH)

Here, *ff0::K0: A ! *ff0::K0: A1 follows via the R-LAM rule from the given (not
shown) A ! A1. We are given that \Gamma  ` *ff::K: (*ff0::K0: A) ff :: K)K00 )
\Gamma ; ff::K ` (*ff0::K0: A) ff :: K00 (C-LAM) ) \Gamma ; ff::K ` *ff0::K0: A :: K)K00 (C-APP
and C-VAR) ) K = K0 (C-LAM). Since ff 62 FCV(A1) (by the reduct variables
lemma), *ff0::K0: A1 = *ff0::K: A1 = *ff::K: [ff=ff0]A1 (two constructors are considered the same if they are related by ff-conversion).

2

Corollary [Tagged] 7.7.3 (Confluence)
If \Gamma  ` A :: K, A !\Lambda  A1, and A !\Lambda  A2 then 9A3 such that A1 !\Lambda  A3 and A2 !\Lambda  A3.

Proof: Same proof as for the erased version (Theorem 7.5.2) except that the tagged
rather than erased version of the diamond property is used and subject reduction (Corollary 7.6.17) is used to establish the validity precondition of the diamond property for the
tagged system. 2

7.8 Equality
Now that I have confluence, I can complete the proof that the rewriting relation implements equality:

126 CHAPTER 7. TYPES: CONFLUENCE
Lemma [Tagged] 7.8.1 If \Gamma  ` xaeAae0! :: K and \Gamma  ` A = A0 :: \Omega  then
\Gamma  ` xaeA0ae0! :: K.

Proof: By Lemma 7.6.5, \Gamma  ` xae ) A and \Gamma  ` xaeae0 ) A0 where A0 has either the form
!K? or the form !=A00::K? for some A00. By P-MOVE, \Gamma  ` xae ) A0. Hence by CEXT-O2 or C-EXT-T2, depending on the form of A00, the desired result follows. 2

Theorem [Tagged] 7.8.2 If \Gamma  ` A = A0 :: K then 9A0; A1; : : : ; An, n * 0, such that:

1. A = A0
2. A0 = An
3. \Gamma  ` Ai = Ai+1 :: K for 0 ^ i ! n
4. Ai *) Ai+1 for 0 ^ i ! n
Proof: By structural induction on the typing derivation. Example cases:
SYM: Apply the induction hypothesis then use the E-SYM rule repeatedly to reverse all

the equality judgments. Since bi-directional rewriting is symmetric, reversing the
sequence of types obtained from the induction hypothesis then yields the desired
sequence.

TRAN: Apply the induction hypothesis twice then place the two resulting sequences side

by side so that A0 is in the middle.

DFUN: Apply the induction hypothesis twice getting sequences A00; : : : ; A0m from

\Gamma  ` A00 = A0m :: \Omega  and A000; : : : ; A00r from \Gamma ; x:A00 ` A000 = A00r :: \Omega . By Theorem 7.6.10,
\Gamma  ` A0i :: \Omega  for 0 ^ i ^ m and \Gamma ; x:A00 ` A00r :: \Omega . Hence, by E-REFL, \Gamma  ` A00 = A00 :: \Omega 
and \Gamma ; x:A00 ` A00r = A00r :: \Omega . By repeated use of the replacement with an equal type
theorem (Theorem 7.6.9) then, \Gamma ; x:A0i ` A00r = A00r :: \Omega  for 0 ^ i ! m. The desired
sequence is then \Pi x:A00: A000; : : : ; \Pi x:A00: A00r ; \Pi x:A01: A00r ; : : : ; \Pi x:A0m: A00r . E-DFUN is
used connect them with equality judgments and R-DFUN and R-REFL to connect
them with bi-directional rewriting.

BETA: Let n = 1. A0 ! A1 via R-BETA and R-REFL.

EXT2: Applying the induction hypothesis gives the sequence A00; : : : ; A0m from \Gamma  ` A1 = A :: \Omega .

By Lemma 7.8.1, \Gamma  ` xaeA0

i ae

0ae00! :: K for 0 ^ i ^ m. The desired sequence is then

xaeA0

0 ae

0ae00!, : : : , xaeA0

mae

0ae0!, xaeae0A

2ae

00!. E-EXT2 is used connect them with equality

judgments and R-EXT2 plus R-REFL to connect them with bi-directional rewriting.

7.8. EQUALITY 127
ABBREV2: Applying the induction hypothesis gives the sequence A00; : : : ; A0m from

\Gamma  ` A = !=A0::K0? :: \Omega . By Lemma 7.8.1, \Gamma  ` xaeA0

i ! :: K for 0 ^ i ^ m. Thedesired sequence is then xae

A

0

0!, : : : , xaeA

0
m !, A

0. E-EXT2 plus E-ABBREV2 and EREFL are used connect them with equality judgments and R-EXT plus R-ABBREV
and R-REFL to connect them with bi-directional rewriting.

2

Theorem [Tagged] 7.8.3 (Church-Rosser)

If n * 0, \Gamma  ` Ai :: K for 0 ^ i ^ n, and Ai *) Ai+1 for 0 ^ i ! n then A0 #\Lambda  An.

Proof: Same basic proof as for the erased version (Theorem 7.5.3) except that the
tagged rather than erased version of confluence is used and subject reduction (Corollary 7.6.17) is used to establish the validity precondition for tagged confluence. 2

Corollary [Tagged] 7.8.4 (Partial Correctness III)

If \Gamma  ` A = A0 :: K then A #\Lambda  A0.

Proof: Apply Theorem 7.8.2 followed by Theorem 7.8.3. 2

Theorem [Tagged] 7.8.5 (Full correctness)

\Gamma  ` A1 = A2 :: K iff all of the following:

1. \Gamma  ` A1 :: K
2. \Gamma  ` A2 :: K
3. A1 #\Lambda  A2

Proof: The forward direction is handled by validity of equals (Theorem 7.6.10) and
Corollary 7.8.4. The backwards direction is handled by repeated use of Theorem 7.6.16
and Theorem 7.6.10 followed by repeated use of E-TRAN, E-SYM, and E-REFL. 2

An immediate corollary of this result is strengthening (removal of unreferenced declarations from an assignment) for equality:

Corollary [Tagged] 7.8.6 (Strengthening)

If \Gamma 1; x:A; \Gamma 2 ` A1 = A2 :: K, \Gamma 1; \Gamma 2 ` A1 :: K, and \Gamma 1; \Gamma 2 ` A2 :: K then
\Gamma 1; \Gamma 2 ` A1 = A2 :: K.

128 CHAPTER 7. TYPES: CONFLUENCE
Proof: Follows immediately from Theorem 7.8.5. 2

Combining the equality implementation result with shape preservation
(Lemma 7.3.7) gives two important results about the properties of equality:

Lemma [Tagged] 7.8.7 (Equality of forms)

Suppose \Gamma  ` A1 = A2 :: K and A2 has neither the form A02 A002, A02 62 fref; recg, the form
xae1A0

1 ae2!, nor the form *ff::K: A

01. Then

1. If A1 has one of the forms ff, !K?, rec, or ref then A1 = A2.
2. If A1 has the form \Pi x:A01: A001 then A2 has the form \Pi x:A02: A002.
3. If A1 has the form \Sigma x:A01: A001 then A2 has the form \Sigma x:A02: A002.
4. If A1 has the form !=A01::K? then A2 has the form !=A02::K?.
5. If A1 has the form ref A01 then A2 has the form ref A02.
6. If A1 has the form rec A01 then A2 has the form rec A02.
Proof: By Theorem 7.8.5, A1 #\Lambda  A2 ) 9A such that A1 !\Lambda  A and A2 !\Lambda  A. By
Lemma 7.3.7, A must have the same form as A1. Moreover, by the same lemma, since
all remaining forms possible for A2 are preserved by rewriting, this means that A2 can
only have the same form as A (and hence, A1). 2

Lemma [Tagged] 7.8.8 (Component-wise equality)

1. If \Gamma  ` \Pi x:A1: A2 = \Pi x:A01: A02 :: \Omega , x 62 dom(\Gamma ), then

\Gamma  ` A1 = A01 :: \Omega  and \Gamma ; x:A1 ` A2 = A02 :: \Omega .

2. If \Gamma  ` \Sigma x:A1: A2 = \Sigma x:A01: A02 :: \Omega , x 62 dom(\Gamma ), then

\Gamma  ` A1 = A01 :: \Omega  and \Gamma ; x:A1 ` A2 = A02 :: \Omega .

3. If \Gamma  ` !K? = !K0? :: \Omega  then K = K0.
4. If \Gamma  ` !=A::K? = !=A0::K0? :: \Omega  then

K = K0 and \Gamma  ` A = A0 :: K.

5. If \Gamma  ` ref A = ref A0 :: \Omega  then \Gamma  ` A = A0 :: \Omega .
6. If \Gamma  ` rec A = rec A0 :: \Omega  then \Gamma  ` A = A0 :: \Omega )\Omega .

7.8. EQUALITY 129
Proof: The proofs of each part are similar; we give here only the proof for part
one: Given \Gamma  ` \Pi x:A1: A2 = \Pi x:A01: A02 :: \Omega . By Theorem 7.8.5, \Pi x:A1: A2 #\Lambda  \Pi x:A01: A02,
\Gamma  ` \Pi x:A1: A2 :: \Omega , and \Gamma  ` \Pi x:A01: A02 :: \Omega  ) \Gamma ; x:A1 ` A2 :: \Omega  and \Gamma ; x:A01 ` A02 :: \Omega , (CDFUN) and 9A00 such that \Pi x:A1: A2 !\Lambda  A00 and \Pi x:A01: A02 !\Lambda  A00 ) \Gamma  ` A1 :: \Omega 
and \Gamma  ` A01 :: \Omega  (Theorem 6.8.3 and DECL-T). Hence, by shape preservation (Lemma 7.3.7),
9A001; A002 such that A00 = \Pi x:A001: A002, A1 !\Lambda  A001, A01 !\Lambda  A001, A2 !\Lambda  A002, and A02 !\Lambda  A002. By
Theorem 7.8.5 and Corollary 7.6.17 then, \Gamma  ` A1 = A01 :: \Omega , \Gamma ; x:A1 ` A2 = A002 :: \Omega , and
\Gamma ; x:A01 ` A02 = A002 :: \Omega  ) \Gamma ; x:A1 ` A02 = A002 :: \Omega  (Theorem 7.6.9) ) \Gamma ; x:A1 ` A2 = A02 :: \Omega 
(E-TRAN). 2

130 CHAPTER 7. TYPES: CONFLUENCE
Chapter 8
Types: Canonicalization
In this chapter, I show how to compute normal forms for valid tagged constructors and
how to decide all tagged judgments. These results, once transfered back to the original
untagged system (see the next chapter), will be crucial in proving the (semi)-decidability
of subtyping (and hence type checking in general). All constructors, assignments, etc.,
in this chapter are tagged unless stated otherwise.

8.1 Normal Forms
Definition [Tagged] 8.1.1 (Normal form)
A is in normal form for rewriting relation R (often written R-normal form or just normal
form if the rewriting relation is the full one) iff 6 9A0: A !1R A0.

If A !\Lambda R A0 and A0 is in R-normal form, then A0 is said to be a R-normal form for A
and A is said to be R-normalizing. If all reduction sequences starting from A using !1R
eventually lead to a R-normal form, then A is said to be strongly R-normalizing:

Definition [Tagged] 8.1.2 (Strong normalization)
A is strongly normalizing under R-reduction iff there are no infinite reduction sequences
starting from A using !1R (i.e., A !1R A1 !1R A2 !1R A3 : : :).

(I am using !1R instead of !R here to rule out steps, such as that generated by R-REFL,
which leave the constructor unchanged.)

One advantage of normal forms is that they allow checking for a common reduct to
be reduced to an easier check for identity (modulo ff-conversion):

Lemma [Tagged] 8.1.3 If A1 and A2 are both in normal form then A1 #\Lambda  A2 iff A1 =
A2.

131

132 CHAPTER 8. TYPES: CANONICALIZATION
Proof: By the definition of a common reduct, A1 #\Lambda  A2 iff 9A. A1 !\Lambda  A and A2 !\Lambda  A.
Since Ai is in normal form, Ai !\Lambda  A0i implies that Ai = A0i. Hence, A1 #\Lambda  A2 iff 9A.
A1 = A and A2 = A ) A1 #\Lambda  A2 iff A1 = A2. 2

This fact when combined with the implementing equality result from the previous chapter
means that I can check that \Gamma  ` A1 = A1 :: K by checking that 8i: \Gamma  ` Ai :: K and that
A1 and A2 have the same normal form.

Another similar advantage of normal forms is that they make searching for constructors equal to a given constructor but with a certain form easy. For example, suppose we
wanted to know if A under \Gamma  is equal to a constructor of the form !=A1::K? for some
K and A1, given \Gamma  ` A :: \Omega  and A0 a normal form for A. We can reason as follows:

Assume such a constructor exists. Then, by the implementing equality result, A0 #\Lambda 
!=A1::K? ) !=A1::K? !\Lambda  A0 since A0 is in normal form ) A0 must have the form
!=A01::K? for some A01 since rewriting preserves this shape (see Lemma 7.3.7). Thus,
we have that A0 itself must have the form in question iff such an equal constructor
exists. Note that this new condition can be checked by a simple inspection and that the
inspection provides an example of such an equal constructor.

Because my rewriting relation allows only fij- and fl-reductions, a constructor is in
normal form iff it is in both fij- and fl-normal form:

Lemma [Tagged] 8.1.4 If A !1 A0 then 9A00 such that either A !1fij A00 or A !1fl A00.
Proof: By structural induction on the derivation of A !1 A0. Example cases:
APP: Given A1 A2 !1 A01 A02 derived via rule R-APP from A1 ! A01 and A2 ! A02. Since

A1 A2 6= A01 A02, we must have Ai !1 A0i for some i in f1; 2g. Applying the induction
hypothesis gives us that 9A00i such that either Ai !1fij A00i or Ai !1fl A00i . The desired
result follows by R-APP and R-REFL. (A00 is either A1 A002 or A001 A2.)

EXT I: Given xaeA

1ae

0ae00! !1 xaeae0A

2 ae

00!, ae0 6= ffl, derived via rule R-EXT from A1 ! A01 and

S(A01; xae; ae0) = A2. If A1 = A01 then xaeA

1ae

0ae00! !1fl xaeae0A

2ae

00! via R-EXT and RREFL and we are done. Otherwise, A1 !1 A01. Applying the induction hypothesis
gives us that 9A001 such that either A1 !1fij A001 or A1 !1fl A001. By R-EXT then,
either xaeA

1ae

0ae00! !1fij xaeA00

1 ae

0ae00! or xaeA

1 ae

0ae00! !1fl xaeA00

1 ae

0ae00!.

ABBREV: Given xaeA

1! !

1 A01 derived via rule R-ABBREV from A1 ! !=A01::K0?. If

A1 = !=A01::K0? then xaeA

1 ! !

1fl A01 via R-ABBREV and R-REFL so we are

done. Otherwise, A1 !1 !=A01::K0?. Applying the induction hypothesis gives us
that 9A001 such that either A1 !1fij A001 or A1 !1fl A001. Hence, by R-EXT, either
xaeA

1 ! !

1fl xaeA00

1 ! or xaeA1! !

1fij xaeA00

1 !.

8.2. THE METHOD 133

2

Corollary [Tagged] 8.1.5 If A is in both fij-normal form and fl-normal form then A
is in normal form.

Proof: Assume not. Then 9A0: A !1 A0. Hence, by Lemma 8.1.4, 9A00 such that either
A !1fij A00 or A !1fl A00. But this is impossible because A is in both fij-normal form and
fl-normal form. 2

8.2 The Method
As with F!, invalid constructors in my system may not be normalizing. For example,
if W = *ff::\Omega : (ff ff) (ff ff) then W W is not normalizing because we can apply the step
W W !fij (W W ) (W W ) to sub-constructors of it forever. Thus, in general normalization of a constructor in my system will require that the constructor be valid.

In F!, which has only fi- and j-reductions, valid constructors are strongly normalizing.
This result can be proved by encoding F!'s kind and constructor levels into the type
and term levels of the simply-typed lambda calculus (*!) and then using the fact that
*! is known to be strongly normalizing for well-typed terms. The same method (see
Section 8.3) can be used to prove that valid constructors in the tagged system are strongly
fij-normalizing. Handling normalization for the full rewriting relation is more difficult.

It is not possible in the tagged system to first check that a constructor is valid and then
normalize it by reducing it until it can no longer be reduced any further. The reason
is that validity checking requires checking equality on sub-constructors which in turn
requires normalizing sub-constructors. Accordingly, it is necessary to interleave the tasks
of checking a constructor's validity and computing its normal form in a single algorithm
that returns a normal form only when the constructor is valid. Because constructors can
have at most one kind (Theorem 7.6.11), the algorithm can also return the constructor's
kind when it is valid.

Such an algorithm can be defined inductively over (\Gamma ; A) pairs (\Gamma  is needed to check
variable references). For example, to handle the case where A = \Sigma ff:A1: A2, ff 62 dom(\Gamma ),
we can first call ourselves recursively on (\Gamma ; A1) and ((\Gamma ; ff:A1); A2). If A1 or A2 are
found to be invalid or to have kinds other than \Omega , \Sigma ff:A1: A2 must be invalid as well.
Otherwise, the desired normal form is \Sigma ff:A01: A02 (\Sigma ff:A01: A02 is in normal form iff A01 and
A02 are) and the kind of A is \Omega .

There are two problematic cases. The first one is constructor extraction where A =
xaeA

1 ae

0!. We need to check that \Gamma  ` xae ) A1 and search for a kind K and constructor

A2 in normal form such that either \Gamma  ` xaeae0 ) !K? or \Gamma  ` xaeae0 ) !=A2::K?. Only

134 CHAPTER 8. TYPES: CANONICALIZATION
if both the check and the search succeed is A valid; in that case A will have kind K and
normal form xaeae0!K?! (if \Gamma  ` xaeae0 ) !K?) or A2 (otherwise).

By combining the properties of normal forms with parallelism II (Theorem 7.3.13), it
can be shown that if A0 is a normal form for \Gamma (x) then \Gamma  ` xae ) A0 iff S(A0; x; ae) exists
and \Gamma  ` A0 = S(A0; x; ae) :: \Omega . This result allows handling the above questions, as well
as place lookup judgments in general, via questions about equality that can be handled
using the methods of the previous section.

The second problematic case is constructor application where A = A1 A2. We can
first call ourselves recursively on (\Gamma ; A1) and (\Gamma ; A2). A has kind K (and hence is valid)
iff A1 has kind K0)K and A2 has kind K0 for some K0. This condition is easily checked;
finding a normal form for A when it is valid is more difficult. The recursive calls will
have given us a normal form for A1 (call it A01) and a normal form for A2 (call it A02).
Hence, A !\Lambda  A01 A02 by R-APP.

Unfortunately, while A01 A02 is in fl-normal form, it is not necessarily in fij-normal
form (e.g., consider (*ff::\Omega : ff) !\Omega ?). At this point, we do know that A01 A02 is a valid
constructor so we could repeatedly fij-reduce it to a fij-normal form. (This process must
terminate since valid constructors are strongly fij-normalizing.) It is not immediately
clear, however, if this procedure works in general because the fij-reductions might enable
new fl-reductions, resulting in a constructor not in fl-normal form.

For example, fi-reducing the following constructor enables an fl-reduction:

(*ff::\Omega )\Omega : xff !=!\Omega ?::\Omega ?!) *ff0::\Omega : ff0
This and other such examples are not valid constructors however (the constructor extraction is invalid because ff !=!\Omega ?::\Omega ? cannot be shown equal to any reified constructor
type) which suggests that there may be some special property of these constructors that
rules out the enabling of new fl-reductions by fij-reductions.

This intuition is in fact correct and can be seen by looking again at discussion of
the first problematic case. Notice that we introduce constructor extractions of only the
form xae!K?!. I shall call a constructor that contains constructor extractions of only this
form, a constructor in fl-final form. Such constructors must trivially be in fl-normal form.
More interestingly, this property is stable under fij-reductions because the constructor
extractions contain no free constructor variables, which could be substituted for by the
fij-reductions.

Thus, if we knew that A01 and A02 were in fl-final form, we could safely just fijnormalize their application and return the result as a normal form for A. In order to get
A01 and A02 in fl-final form, we need to show that our algorithm returns not just normal
forms but normal forms in fl-final form (canonical forms). This result can be established
by using the obvious stronger induction hypothesis when proving the algorithm correct.

8.3. fij-NORMALIZATION 135
8.3 fij-Normalization
In this section I prove that valid constructors are strongly fij-normalizing and give an
algorithm, using this result, that fij-normalizes valid constructors. I prove the result by
encoding kinds and constructors into *!'s type and term levels respectively and then
taking advantage of *!'s strong normalization property.

The syntax for the *! system is quite simple:

Definition [*!] 8.3.1 (Syntax)

Types A ::= \Omega  j A!A0

Terms M ::= x j \Psi A j *x:A: M j M M 0
Assignments \Gamma  ::= ffl j \Gamma ; x:A
Here, the metavariable x ranges over term variables and \Psi A denotes an uninterpreted
constant of type A. (I have included the constants solely to make the encoding simpler;
a more complicated proof can be constructed without them.)

The usual conventions apply and we have the usual operators:

Definition [*!] 8.3.2 (Free term variables)

FTV(x) = fxg
FTV(\Psi A) = ;
FTV(*x:A: M ) = FTV(M ) \Gamma  fxg

FTV(M 1 M 2) = FTV(M 1) [ FTV(M 2)

Definition [*!] 8.3.3 (Term substitution)

[M =x]x = M
[M =x]x0 = x0 (x 6= x0)

[M =x]\Psi A = \Psi A
[M =x]*x0:A: M 0 = *x0:A: [M =x]M 0 (x0 6= x; x0 62 FTV(M ))

[M =x](M 1 M 2) = [M =x]M 1 [M =x]M 2

Definition [*!] 8.3.4 (Assignment regarded as a partial function)

dom(ffl) = ;
dom(\Gamma ; x:A) = dom(\Gamma ) [ fxg

(\Gamma 1; x:A; \Gamma 2)(x) = A (x 62 dom(\Gamma 1))

136 CHAPTER 8. TYPES: CANONICALIZATION

The system has only two judgments, which have simple rules:
Definition [*!] 8.3.5 (Judgments)

` \Gamma  valid valid assignment
\Gamma  ` M : A well-typed term

Definition [*!] 8.3.6 (Assignment Formation Rules)

` ffl valid (L-EMPTY)

` \Gamma  valid x 62 dom(\Gamma )

` \Gamma ; x:A valid (L-EXTEND)

Definition [*!] 8.3.7 (Term Formation Rules)

` \Gamma  valid x:A 2 \Gamma 

\Gamma  ` x : A (L-VAR)

` \Gamma  valid
\Gamma  ` \Psi A : A (L-CON)

\Gamma ; x:A ` M : A0
\Gamma  ` *x::A: M : A!A0 (L-LAM)

\Gamma  ` M 1 : A2!A \Gamma  ` M 2 : A2

\Gamma  ` M 1 M 2 : A (L-APP)

The rewriting relation for *! is defined on terms rather than types and permits both
fi- and j-reductions. Its rules are as follows:

Definition [*!] 8.3.8 (Rewrite relation)

M ! M 0
*x:A: M ! *x:A: M 0 (LR-LAM)

M 1 ! M 01
M 1 M 2 ! M 01 M 2 (LR-LEFT)

M 2 ! M 02
M 1 M 2 ! M 1 M 02 (LR-RIGHT)

8.3. fij-NORMALIZATION 137

(*x:A: M 1) M 2 ! [M 2=x]M 1 (LR-BETA)

x 62 FTV(M )
*x:A: M x ! M (LR-ETA)

One of the classic results for *! (see, for example, Barendregt [2]) is that all welltyped terms are strongly normalizing:

Theorem [*!] 8.3.9 (Strong normalization)

If \Gamma  ` M : A then there are no infinite reduction sequences starting from A using !
(i.e., A ! A1 ! A2 ! A3 : : :).

The encoding I will be using is follows. It encodes kinds as *!-types, constructor
variables as *!-term variables, assignments as *!-assignments, and constructors as *!-
terms. The encoding of constructors takes the constructor's assignment as an extra
argument so that it can determine the kind of constructor extractions; this information
is necessary to ensure that the encoding maps valid constructors to well-typed terms.

Definition [Tagged] 8.3.10 (The *!-encoding)

\Omega ? = \Omega 
(K1)K2)? = K?1!K?2

ffl? = ffl
(\Gamma ; ff::K )? = \Gamma ?; ff?:K?

(\Gamma ; x:A)? = \Gamma ?

ff?\Gamma  = ff?
(*ff::K: A)?\Gamma  = *ff?:K?: A?\Gamma ;ff::K (ff 62 dom(\Gamma ))

(A1 A2)?\Gamma  = A?\Gamma 1 A?\Gamma 2

(\Pi x:A1: A2)?\Gamma  = \Psi \Omega !\Omega !\Omega  A?\Gamma 1 A?\Gamma ;x:A

12 (x 62 dom(\Gamma ))

(\Sigma x:A1: A2)?\Gamma  = \Psi \Omega !\Omega !\Omega  A?\Gamma 1 A?\Gamma ;x:A

12 (x 62 dom(\Gamma ))

!K??\Gamma  = \Psi \Omega 
!=A::K??\Gamma  = \Psi K?!\Omega  A?\Gamma 

xaeAae0!?\Gamma  = \Psi \Omega !K? A?\Gamma  where \Gamma  ` xaeAae0! :: K

rec?\Gamma  = \Psi (\Omega !\Omega )!\Omega 

ref?\Gamma  = \Psi \Omega !\Omega 

138 CHAPTER 8. TYPES: CANONICALIZATION
(The mapping from constructor variables to *! term variables is not shown; any bijective
mapping is sufficient.)

The basic idea of the encoding is to map variables, functions, and applications to *!-
terms of the corresponding sort; all other sorts of constructors are mapped to constants or
applications of constants to the encodings of the constructor's component constructors.
This mapping allows any fij-reduction between two constructors to be mirrored on the
corresponding *!-terms. Note that the encoding of constructors is well defined when
restricted to valid constructors:

Lemma [Tagged] 8.3.11 (Existence)

If \Gamma  ` A :: K then A?\Gamma  exists and is uniquely defined (modulo ff-conversion).

Proof: The only case which could cause A?\Gamma  to be undefined or multiply defined is if a
sub-constructor of A of the form xaeA0ae0! is either not well-formed or has multiple kinds.
However, this is not possible: by decomposition (Lemma 7.7.1), all such sub-constructors
must be well-formed and by Lemma 7.6.11, they each have only one kind. 2

The encoding possesses two key properties. The first is that it maps valid assignments
to *! valid assignments and constructors to *! well-typed terms:

Lemma [Tagged] 8.3.12

1. If ` \Gamma  valid then ` \Gamma ? valid.
2. If \Gamma  ` A :: K then \Gamma ? ` A?\Gamma  : K?.
Proof: Proved sequentially by structural induction on \Gamma  and A respectively. Example
cases:

DECL-C: Given ` \Gamma ; ff::K valid derived via rule DECL-C from ` \Gamma  valid and ff 62 dom(\Gamma ).

Applying the induction hypothesis gives us that ` \Gamma ? valid. Inspection of the encoding reveals that ff0 2 dom(\Gamma ) iff ff0? 2 dom(\Gamma ?) ) ff? 62 dom(\Gamma ?). Hence, by
L-EXTEND, ` \Gamma ?; ff?:K? valid
) ` (\Gamma ; ff::K)? valid.

C-DFUN: Given \Gamma  ` \Pi x:A1: A2 :: \Omega , x 62 dom(\Gamma ), derived via rule C-DFUN from \Gamma ; x:A1 ` A2 :: \Omega 

) \Gamma  ` A1 :: \Omega  and ` \Gamma  valid (Theorem 6.8.3). By part one, ` \Gamma ? valid. Applying

the induction hypothesis gives us that \Gamma ? ` A?\Gamma 1 : \Omega  and \Gamma ? ` A?\Gamma ;x:A

12 : \Omega . Hence,

by rules L-CON and L-APP, \Gamma ? ` \Psi \Omega !\Omega !\Omega  A?\Gamma 1 A?\Gamma ;x:A

12 : \Omega  )

\Gamma ? ` (\Pi x:A1: A2)?\Gamma  : \Omega ?.

8.3. fij-NORMALIZATION 139
C-LAM: Given \Gamma  ` *ff::K: A :: K)K 0, ff 62 dom(\Gamma ), derived via rule C-LAM from

\Gamma ; ff::K ` A :: K0. Applying the induction hypothesis gives us that

\Gamma ?; ff?:K? ` A?\Gamma ;ff::K : K0? ) \Gamma ? ` *ff?:K?: A?\Gamma ;ff::K : K?!K0? (L-LAM)
) \Gamma ? ` (*ff::K: A)?\Gamma  : (K)K0)?.

C-EXT-T2: Given \Gamma  ` xaeAae0! :: K ) ` \Gamma  valid (Theorem 6.8.3) ) ` \Gamma ? valid (part one). By

Theorem 7.6.15, \Gamma  ` A :: \Omega . Applying the induction hypothesis gives us that

\Gamma ? ` A?\Gamma  : \Omega . Hence, by rules L-CON and L-APP, \Gamma ? ` \Psi \Omega !K? A?\Gamma  : K? )
\Gamma ? ` xaeAae0!?\Gamma  : K?.

2

The second key property of the encoding is that two constructors related by a fijreduction are still related by a reduction after they are encoded as *!-terms; moreover,
irreflexive rewriting steps are mirrored by one or more *! rewriting steps. (The later
part is needed to ensure that mapping an infinite reduction sequence of irreflexive steps
into *! generates an infinite reduction sequence.)

Lemma [Tagged] 8.3.13 If A?\Gamma  exists then FTV(A?\Gamma ) = FCV(A)?.
Lemma [Tagged] 8.3.14 (Encoding properties)

1. If \Gamma 1; \Gamma 3 ` A :: K, ` \Gamma 1; \Gamma 2 valid, and dom(\Gamma 2) " dom(\Gamma 3) = ; then

A?\Gamma 1;\Gamma 2;\Gamma 3 = A?\Gamma 1;\Gamma 3.

2. If \Gamma 1 ` A1 :: K and \Gamma 1; ff::K; \Gamma 2 ` A2 :: K0 then

[A?\Gamma 

11 =ff?](A?\Gamma 1;ff::K;\Gamma 22 ) = ([A1=ff]A2)?\Gamma 1;[A1=ff]\Gamma 2

Proof: Proved sequentially using structural induction on A and A2. Part one requires
the use of weakening (Theorem 6.8.10). Part two requires the use of part one, Theorem 7.6.2, and Lemma 6.8.3. 2

Lemma [Tagged] 8.3.15 (Mirroring) Suppose \Gamma  ` A1 :: K. Then:

1. If A1 !1fij A2 then A?\Gamma 1 !+ A?\Gamma 2 .
2. If A1 !fij A2 then A?\Gamma 1 !\Lambda  A?\Gamma 2 .

140 CHAPTER 8. TYPES: CANONICALIZATION
Proof: Note that the second part follows immediately from the first part plus the fact
that !\Lambda  is reflexive; it will accordingly be used recursively in the proof of the first part.

The proof of part one proceeds by structural induction on the derivation of A1 !1fij A2.

By Lemma 8.3.12 and subject reduction (Corollary 7.6.17), A?\Gamma 1 and A?\Gamma 2 exist. Example
cases:

R-DFUN: Given \Gamma  ` \Pi x:A1: A2 :: \Omega  and \Pi x:A1: A2 !1fij \Pi x:A01: A02, x 62 dom(\Gamma ), derived via

rule R-DFUN from A1 !fij A01 and A2 !fij A02 ) \Gamma  ` A1 :: \Omega  and \Gamma ; x:A1 ` A2 :: \Omega 
(Theorem 6.8.3), and A1 !1fij A01 or A2 !1fij A02.

Applying the induction hypothesis gives us that A?\Gamma 1 !+ A0?\Gamma 1 and
A?\Gamma ;x:A

12 !\Lambda  A0?\Gamma ;x:A

0
12 or that A?\Gamma 1 !\Lambda  A0?\Gamma 1 and A?\Gamma ;x:A12 !+ A0?\Gamma ;x:A

0
12

) A?\Gamma 1 A?\Gamma ;x:A

12 !+ A0?\Gamma 1 A?\Gamma ;x:A12 !\Lambda  A0?\Gamma 1 A0?\Gamma ;x:A

0
12 or A?\Gamma 1 A?\Gamma ;x:A12 !\Lambda 

A0?\Gamma 1 A?\Gamma ;x:A

12 !+ A0?\Gamma 1 A0?\Gamma ;x:A

0
12 (repeated use of LR-LEFT followed by LR-RIGHT)

) A?\Gamma 1 A?\Gamma ;x:A

12 !+ A0?\Gamma 1 A0?\Gamma ;x:A

0
12

) \Psi \Omega !\Omega !\Omega  A?\Gamma 1 A?\Gamma ;x:A

12 !+ \Psi \Omega !\Omega !\Omega  A0?\Gamma 1 A0?\Gamma ;x:A

0
12 (L-RIGHT)

) (\Pi x:A1: A2)?\Gamma  !+ (\Pi x:A01: A02)?\Gamma 
R-BETA: Given \Gamma  ` (*ff::K: A1) A2 :: K0 and (*ff::K: A1) A2 !1fij [A02=ff]A01, ff 62 dom(\Gamma ),

derived via rule R-BETA from A1 !fij A01 and A2 !fij A02 ) \Gamma  ` A2 :: K and
\Gamma ; ff::K ` A1 :: K0 (C-APP and C-LAM).

Applying the induction hypothesis gives us that A?\Gamma ;ff::K1 !\Lambda  A01?\Gamma ;ff::K and
A?\Gamma 2 !\Lambda  A02?\Gamma . Hence, ((*ff::K: A1) A2)?\Gamma  = (*ff?:K ?: A?\Gamma ;ff::K1 ) A?\Gamma 2
!\Lambda  (*ff?:K?: A0?\Gamma ;ff::K1 ) A0?\Gamma 2 ! [A0?\Gamma 2 =ff](A0?\Gamma ;ff::K1 ) = ([A02=ff]A01)?\Gamma  (the last by
Lemma 8.3.14).

R-ETA: Given \Gamma  ` *ff::K: A ff :: K)K 0 and *ff::K: A ff !1fij A0, ff 62 dom(\Gamma ), derived via

rule R-ETA from A !fij A0 and ff 62 FCV(A)

) \Gamma ; ff::K ` A :: K)K0 (C-LAM and C-APP) ) \Gamma  ` A :: K)K 0 (Corollary 7.6.4).
Applying the induction hypothesis then gives us that A?\Gamma  !\Lambda  A0?\Gamma . By Lemma 8.3.13,
ff? 62 FTV(A?\Gamma ). Hence, (*ff::K: A ff)?\Gamma  = *ff?:K?: A?\Gamma ;ff::K ff = *ff?:K?: A?\Gamma  ff !
A?\Gamma  !\Lambda  A0?\Gamma  (the second equality is by Lemma 8.3.14).

2

Using these two properties of the encoding, a proof of strong fij-normalization for
valid constructors is easily constructed:

8.3. fij-NORMALIZATION 141
Theorem [Tagged] 8.3.16 (Strong fij-normalization)

If \Gamma  ` A :: K then A is strongly normalizing under fij-reduction.

Proof: By Lemma 8.3.12, \Gamma ? ` A?\Gamma  : K?. Suppose A is not strongly normalizing under
fij-reduction. Then there exists an infinite fij-reduction sequence starting from A, say
A !1fij A1 !1fij A2 !1fij A3 : : :. Hence by repeated use of Lemma 8.3.15 and subject

reduction (Corollary 7.6.17), A?\Gamma  !+ A?\Gamma 1 !+ A?\Gamma 2 !+ A?\Gamma 3 : : : ) A?\Gamma  is not strongly
normalizing in *!. But this contradicts Theorem 8.3.9, so we must have that A is
strongly normalizing under fij-reduction as desired. 2

In Figure 8.1, I give the code for an algorithm to fij-normalize valid constructors based
on this result. I have written the algorithm in functional pseudo-code. My version of
pseudo-code allows raising and handling the single exception fail. Functions written in it
can thus return a value, raise fail, or loop forever (functions can be defined recursively).
Patterns in case expressions are matched sequentially in the order written, stopping
with the first match; if no match is found, fail is raised. I allow guard conditions
on the variables involved in a pattern in order to handle equivalence via ff-conversion.
Attempting to evaluate an undefined selection (e.g., S(!K ?; x; :1)) or an undefined
assignment lookup (i.e., \Gamma (x) for x 62 dom(\Gamma )) also results in fail being raised. I shall
be using this notation throughout the dissertation.

The algorithm is composed of two procedures, RO and BR. RO is a reduction
procedure, reducing its argument constructor by one fij-step. I have constructed RO
so that it will only return its constructor unchanged if it is in fij-normal form. BR
is the actual fij-normalizing procedure; it just applies RO iteratively to its argument
until it stops changing. Theorem 8.3.16 ensures that BR always terminates on valid
constructors. The correctness proofs for these algorithms are as follows:

Lemma [Tagged] 8.3.17 (Properties of RO algorithm I)

1. RO(A) always returns
2. A !fij RO(A)
Proof: The first part follows from the fact that all recursive calls to RO are on smaller
constructors and there are no points where fail can be raised. The second part is proved
by structural induction on A. Example cases:

Lam: Here A = *ff::K: A1. Applying the induction hypothesis gives us that A1 !fij

RO(A1). By R-LAM then, *ff::K: A1 !fij *ff::K: RO(A1). If A1 = A0 ff, ff 62
FCV(A0) then *ff::K: A1 !fij A0 via R-ETA and R-REFL. Hence, by inspection of
RO, regardless of which path is taken, A !fij RO(A).

142 CHAPTER 8. TYPES: CANONICALIZATION
RO(A) = case A of

*ff::K: A1: let A01 = RO(A1) in

if A1 6= A01 then

return(*ff::K : A01)
else

case A1 of
(A0 ff), ff 62 FCV(A0): return(A0)

A0: return(*ff::K: A1)
end

A1 A2: let A01 = RO(A1);

A02 = RO(A2) in

if A1 A2 6= A01 A02 then

return(A01 A02)
else

case A1 of

*ff::K: A0: return([A2=ff]A0)

A0: return(A1 A2)

\Pi x:A1: A2: return(\Pi x:RO(A1): RO(A2))

\Sigma x:A1: A2: return(\Sigma x:RO(A1): RO(A2))
!=A0::K?: return(!=RO(A0)::K?)

xaeA0ae0!: return(xaeRO(A0)ae0!)

A0: return(A0)

BR(A) = let A0 = RO(A) in

if A = A0 then

return(A)
else

return(BR(A0))

Figure 8.1: fi-reducing a term

8.3. fij-NORMALIZATION 143
App: Here A = A1 A2. Applying the induction hypothesis gives us that A1 !fij RO(A1)

and A2 !fij RO(A2). By R-APP then, A1 A2 !fij RO(A1) RO(A2). If A1 =
*ff::K: A0 then A1 A2 !fij [A2=ff]A0 via R-BETA and R-REFL. Hence, by inspection of RO, regardless of which path is taken, A !fij RO(A).

2

Lemma [Tagged] 8.3.18 (Properties of RO algorithm II)

If A = RO(A) then A is in fij-normal form.

Proof: We prove the contrapositive (if 9A0: A !1fij A0 then A 6= RO(A)) by structural
induction on A. Example cases:

Lam: Given *ff::K: A1 !1fij A0. Inspecting the rewriting rules shows that this implies

that one of the following is true:

ffl A1 !1fij A01 for some A01

) A1 6= RO(A1) (induction hypothesis)
) RO(*ff::K: A1) = *ff::K: RO(A1) 6= *ff::K: A1

ffl A1 is in fij-normal form and is equal to A0 ff, ff 62 FCV(A0).

) A1 = RO(A1) (Lemma 8.3.17 plus definition of normal form)
) RO(*ff::K: A1) = A0 6= *ff::K: A1 = *ff::K: A0 ff

App: Given A1 A2 !1fij A0. Inspecting the rewriting rules shows that this implies that

one of the following is true:

ffl Ai !1fij A0i for some A0i, i 2 f1; 2g

) Ai 6= RO(Ai) (induction hypothesis)
) A1 A2 6= RO(A1) RO(A2)
) RO(A1 A2) = RO(A1) RO(A2) 6= A1 A2

ffl A1 is in fij-normal form and has the form *ff::K: A00, A2 is also in fij-normal

form, and A0 = [A2=ff]A00.
) A1 A2 = RO(A1) RO(A2) (Lemma 8.3.17 plus definition of normal form)
) RO(A1 A2) = [A2=ff]A00 = A0
) A 6= A0 = RO(A) (definition of !1fij)

2

Corollary [Tagged] 8.3.19 (Properties of BR algorithm)

If \Gamma  ` A :: K then

144 CHAPTER 8. TYPES: CANONICALIZATION

1. BR(A) always returns
2. A !\Lambda fij BR(A)
3. BR(A) is in fij-normal form.
Proof: Inspection of the BR procedure reveals that: when called with A, it recurses on
RO(A), then RO(RO(A)) = RO2(A), then RO3(A), : : :, then ROn(A) where 0 ^ n ^ 1
and ROi(A) 6= ROi+1(A) for 0 ^ i ! n. If BR(A) returns then it returns ROn(A),
n ! 1, and ROn(A) = ROn+1(A).

By Lemma 8.3.17, A !1fij RO(A) !1fij RO2(A) : : : !1fij ROn(A). By Theorem 8.3.16
then, n must be finite. (Otherwise, A is not strongly normalizing under fij-reduction.)
That BR(A) always returns then follows since RO is known to always return by Lemma 8.3.17
and the above argument shows that BR calls itself only a finite number of times. From
the transitivity of !\Lambda fij, we have that A !\Lambda fij ROn(A) ) A !\Lambda fij BR(A). Finally, by
Lemma 8.3.18, BR(A) = ROn(A) is in fij-normal form. 2

8.4 Canonical Form
In this section I define fl-final and canonical form and prove some useful properties about
them. I start out with fl-final form:

Definition [Tagged] 8.4.1 (fl-final form)
A is in fl-final form iff A = C[xaeA0ae0!] implies that ae0 = ffl and A0 = !K? for some K.

Lemma [Tagged] 8.4.2 If A is in fl-final form then A is in fl-normal form.
Proof: Suppose A !fl A0. We can show by structural induction on the derivation that
A = A0 (example cases below). Hence, A is in fl-normal form.

EXT: Given xaeA

1 ae

0ae00! !fl xaeae0A

2ae

00! derived via rule R-EXT from A1 !fl A01 and

S(A01; xae; ae0) = A2. By the definition of fl-final form, ae0 = ae00 = ffl and A1 is in
fl-final form ) A01 = A2. Applying the inductive hypothesis gives us that A1 = A01
) xaeA

1 ae

0ae00! = xaeae0A

2 ae

00!.

ABBREV: Given xaeA

1! !fl A

01 derived via rule R-ABBREV from A1 !fl !=A01::K0?. By

the definition of fl-final form, A1 = !K? for some K. By shape preservation
(Lemma 7.3.7), !K? ! !=A01::K0? is impossible. Hence this case can't occur.

2

8.4. CANONICAL FORM 145
Lemma [Tagged] 8.4.3 If A1 and A2 are in fl-final form then [A2=ff]A1 is in fl-final
form.

Proof: By structural induction on A1. Example cases:
Var I: Here A1 = ff ) [A2=ff]A1 = A2.

Ext: Here A1 = xae!K?! ) [A2=ff]A1 = A1, which is in fl-final form.

2

Lemma [Tagged] 8.4.4 If A is in fl-final form and A !fij A0 then A0 is in fl-final
form.

Proof: By structural induction on the derivation of A !fij A0. Example cases:
R-BETA: Given (*ff::K: A1) A2 !fij [A02=ff]A01 derived via rule R-BETA from A1 !fij A01

and A2 !fij A02. By the definition of fl-final form, A1 and A2 are in fl-final form.
Applying the induction hypothesis gives us that A01 and A02 are in fl-final form.
Hence, by Lemma 8.4.3, [A02=ff]A01 is in fl-final form.

R-ETA: Given *ff::K: A ff !fij A0 derived via rule R-ETA from A !fij A0 and ff 62 FCV(A).

By the definition of fl-final form, A is in fl-final form. Applying the induction
hypothesis gives us that A0 is in fl-final form.

R-EXT: Given xaeA

1 ae

0ae00! !fij xaeae0A

2ae

00!, ae0 = ffl, derived via rule R-EXT from A1 !fij A01

and S(A01; xae; ae0) = A2 ) A01 = A2. By the definition of fl-final form, ae00 = ffl and
A1 = !K? for some K. By Lemma 7.3.7, A2 = !K? ) A = A0.

2

Here I define canonical form and show how new constructors in canonical form can
be created from existing constructors in canonical form:

Definition [Tagged] 8.4.5 (Canonical form)
A is in canonical form iff A is in both fij-normal form and fl-final form.

Lemma [Tagged] 8.4.6 Suppose A is in canonical form. Then:

1. [xae=x0]A is in canonical form.
2. If S(A; xae; ae0) exists then S(A; xae; ae0) is in canonical form.

146 CHAPTER 8. TYPES: CANONICALIZATION
Proof: Proved sequentially by structural induction on A and ae0 respectively. 2

Lemma [Tagged] 8.4.7

1. If \Gamma ; ff::K ` A :: K0 and A is in canonical form then BR(*ff::K: A) returns A0 such

that *ff::K : A !\Lambda  A0 and A0 is in canonical form.

2. If \Gamma  ` A1 :: K2)K, \Gamma  ` A2 :: K 2, and A1 and A2 are in canonical form then

BR(A1 A2) returns A0 such that A1 A2 !\Lambda  A0 and A0 is in canonical form.

Proof: The proof is similar for both parts; we give only the proof of the first part here:

By C-LAM, \Gamma  ` *ff::K: A :: K)K0. By the definition of canonical form, A is in flfinal form ) *ff::K: A is in fl-final form (by defn.). By Corollary 8.3.19, BR(*ff::K: A)
always terminates, *ff::K: A !\Lambda fij BR(*ff::K: A), and BR(*ff::K: A) is in fij-normal
form. By Lemma 8.4.4, BR(*ff::K: A) is in fl-final form ) BR(*ff::K: A) is in canonical
form (by defn.). 2

Because canonical forms are normal forms, they are reducts of all constructors they
are equal to. Since reducing a constructor preserves many properties about it (e.g.,
possession of certain outer shapes), this fact means that if a canonical form is equal
to a constructor with certain properties then that canonical form must also have those
properties:

Lemma [Tagged] 8.4.8 If A is in canonical form then A is in normal form.
Proof: By Lemma 8.4.2, A is in fl-normal form. Hence, by Corollary 8.1.5, A is in
normal form. 2

Lemma [Tagged] 8.4.9 If \Gamma  ` A1 = A2 :: K and A2 is in canonical form then A1 !\Lambda 
A2.

Proof: By Lemma 8.4.8, A2 is in normal form. By Theorem 7.8.5, A1 #\Lambda  A2 )
9A. A1 !\Lambda  A and A2 !\Lambda  A. By the definition of normal form, A = A2. Hence,
A1 !\Lambda  A2. 2

Lemma [Tagged] 8.4.10 (Shape Pullback)

Suppose \Gamma  ` A1 = A2 :: K and A1 is in canonical form. Then:

8.4. CANONICAL FORM 147

1. If A2 = ff, A2 = ref, A2 = rec, or A2 = !K? then A1 = A2.
2. If A2 = \Pi x:A02: A002 then 9A01; A001: A1 = \Pi x:A01: A001.
3. If A2 = \Sigma x:A02: A002 then 9A01; A001: A1 = \Sigma x:A01: A001.
4. If A2 = !=A02::K? then 9A01: A1 = !=A01::K?.
5. If A2 = ref A02 then 9A01: A1 = ref A01.
6. If A2 = rec A02 then 9A01: A1 = rec A01.
Proof: By Lemma 8.4.9 and E-REFL, A2 !\Lambda  A1. The desired results then follow from
Lemma 7.3.7. 2

Corollary [Tagged] 8.4.11 (Canonical Strengthening)

If \Gamma 1; x:A; \Gamma 2 ` A1 = A2 :: K, A1 is in canonical form, and \Gamma 1; \Gamma 2 ` A2 :: K then
\Gamma 1; \Gamma 2 ` A1 = A2 :: K.

Proof: By E-SYM and Lemma 8.4.9, A2 !\Lambda  A1 ) \Gamma 1; \Gamma 2 ` A1 :: K (Corollary 7.6.17)
) \Gamma 1; \Gamma 2 ` A1 = A2 :: K (Corollary 7.8.6). 2

By a similar argument using Parallelism II (Theorem 7.3.13), we can "pull back"
selections through equality to a canonical form; by doing this repeatedly, we can reduce
place lookup using an assignment in canonical form to checking equality:

Lemma [Tagged] 8.4.12 (Pullback)

If A is in canonical form, \Gamma  ` A = A0 :: \Omega , and \Gamma  ` S(A0; xae; ae0) :: \Omega  then
\Gamma  ` S(A; xae; ae0) = S(A0; xae; ae0) :: \Omega .

Proof: By E-SYM and Lemma 8.4.9, A0 !\Lambda  A ) S(A0; xae; ae0) !\Lambda  S(A; xae; ae0) (Theorem 7.3.13) ) \Gamma  ` S(A; xae; ae0) :: \Omega  (Corollary 7.6.17)
) \Gamma  ` S(A; xae; ae0) = S(A0; xae; ae0) :: \Omega  (Theorem 7.8.5). 2

Lemma [Tagged] 8.4.13 If \Gamma (x) is in canonical form and \Gamma  ` xae ) A then
\Gamma  ` A = S(\Gamma (x); x; ae) :: \Omega  and S(\Gamma (x); x; ae) is in canonical form.

Proof: By structural induction on the derivation of \Gamma  ` xae ) A. Example cases:
P-INIT: Given \Gamma  ` x ) A (ae = ffl) derived via rule P-INIT from ` \Gamma  valid and x:A 2 \Gamma 

) S(\Gamma (x); x; ae) = \Gamma (x). By Lemma 6.8.11, \Gamma (x) = A and \Gamma  ` A :: \Omega . Hence, by
E-REFL, \Gamma  ` A = S(\Gamma (x); x; ae) :: \Omega .

148 CHAPTER 8. TYPES: CANONICALIZATION
P-MOVE: Given \Gamma  ` xaeae0 ) A derived via rule P-MOVE from \Gamma  ` xae ) A0,

\Gamma  ` A0 = A00 :: \Omega , and S(A00; xae; ae0) = A. Applying the induction hypothesis then
gives us that \Gamma  ` A0 = S(\Gamma (x); x; ae) :: \Omega  and S(\Gamma (x); x; ae) is in canonical form )
\Gamma  ` S(\Gamma (x); x; ae) = A00 :: \Omega  (E-TRAN and E-SYM). By Theorem 7.6.14, \Gamma  ` A :: \Omega .
Hence, by Lemma 8.4.12, \Gamma  ` S(S(\Gamma (x); x; ae); xae; ae0) = A :: \Omega 
) \Gamma  ` A = S(\Gamma (x); x; aeae0) :: \Omega  (Lemma 6.8.1 and E-SYM) By Lemma 8.4.6,
S(\Gamma (x); x; aeae0) is in canonical form.

2

8.5 Assignment Reduction
For efficiency reasons, the normalization and validity checking algorithm I give only
reduces the assignment once rather than reducing parts of it each time they are needed.
In order to do this, I shall need to extend the notions of reduction and canonical form to
assignments:

Definition [Tagged] 8.5.1 (Reduction of assignments) Reduction can be extended
to assignments as follows:

ffl ! ffl (R-EMPTY)

\Gamma  ! \Gamma 0
\Gamma ; ff::K ! \Gamma 0; ff::K (R-DECL-C)

\Gamma  ! \Gamma 0 A ! A0

\Gamma ; x:A ! \Gamma 0; x:A0 (R-DECL-T)

Definition [Tagged] 8.5.2 (Canonical form for assignments)
\Gamma  is in canonical form iff 8x:A 2 \Gamma : A is in canonical form.

I shall need that reducing the assignments in judgments leaves the judgments' truth
values unchanged and that reduction on assignments preserves assignment validity:

Lemma [Tagged] 8.5.3

1. If \Gamma 1; \Gamma 2 ! \Gamma 0 then 9\Gamma 01; \Gamma 02 such that \Gamma 0 = \Gamma 01; \Gamma 02, \Gamma 1 ! \Gamma 01, and \Gamma 2 ! \Gamma 02.
2. If \Gamma 0 ! \Gamma 1; \Gamma 2 then 9\Gamma 01; \Gamma 02 such that \Gamma 0 = \Gamma 01; \Gamma 02, \Gamma 01 ! \Gamma 1, and \Gamma 02 ! \Gamma 2.

8.5. ASSIGNMENT REDUCTION 149
Proof: By structural induction on \Gamma 2. 2

Lemma [Tagged] 8.5.4 Suppose \Gamma  *) \Gamma 0. Then:

1. dom(\Gamma ) = dom(\Gamma 0)

2. If ff::K 2 \Gamma  then ff::K 2 \Gamma 0.
Lemma [Tagged] 8.5.5 (Reduction and assignments)

Suppose ` \Gamma  valid, ` \Gamma 0 valid, and \Gamma  ! \Gamma 0. Then:

1. ` \Gamma ; D valid iff ` \Gamma 0; D valid.

2. \Gamma  ` A :: K iff \Gamma 0 ` A :: K.
3. \Gamma  ` xae ) A iff \Gamma 0 ` xae ) A.
4. \Gamma  ` A1 = A2 :: K iff \Gamma 0 ` A1 = A2 :: K .
Proof: We prove an equivalent version of the lemma where the rewriting precondition
is instead that \Gamma  *) \Gamma 0 and the results are that the judgments involving \Gamma  imply the
judgments involving \Gamma 0. We prove this by simultaneous structural induction on the
derivations. Interesting cases:

DECL-T: Given ` \Gamma ; x:A valid derived via rule DECL-T from \Gamma  ` A :: \Omega  and x 62 dom(\Gamma ).

Applying the induction hypothesis gives us that \Gamma 0 ` A :: \Omega  By Lemma 8.5.4, dom(\Gamma ) =
dom(\Gamma 0) ) x 62 dom(\Gamma 0). Hence, by DECL-T, ` \Gamma 0; x:A valid.

C-VAR: Given \Gamma  ` ff :: K derived via rule C-VAR from ` \Gamma  valid and ff::K 2 \Gamma  ) ff::K 2 \Gamma 0

(Lemma 8.5.4) ) \Gamma 0 ` ff :: K (C-VAR).

C-DFUN: Given \Gamma  ` \Pi x:A: A0 :: \Omega  derived via rule C-DFUN from \Gamma ; x:A ` A0 :: \Omega 

) ` \Gamma ; x:A valid (Theorem 6.8.3). Applying the induction hypothesis gives us
that ` \Gamma 0; x:A valid. By R-DECL-T and R-REFL, \Gamma ; x:A *) \Gamma 0; x:A. Applying
the induction hypothesis again gives us that \Gamma 0; x:A ` A0 :: \Omega  ) \Gamma 0 ` \Pi x:A: A0 :: \Omega 
(C-DFUN).

P-INIT: Given \Gamma  ` x ) A derived via rule P-INIT from ` \Gamma  valid and x:A 2 \Gamma  ) 9\Gamma 1; \Gamma 2:

\Gamma  = (\Gamma 1; x:A; \Gamma 2). ) ` \Gamma 1; x:A valid and ` \Gamma 1 valid are sub-derivations of \Gamma  ` x ) A
(Theorem 6.8.3) ) \Gamma 1 ` A :: \Omega  is a sub-derivation of \Gamma  ` x ) A (DECL-T). By
Lemma 8.5.3 and R-DECL-T, 9\Gamma 01; A0; \Gamma 02 such that \Gamma 0 = \Gamma 01; x:A0; \Gamma 02, \Gamma 1 *) \Gamma 01, and
A *) A0. ) ` \Gamma 01 valid (Theorem 6.8.3).

Applying the induction hypothesis gives us that \Gamma 01 ` A :: \Omega  ) \Gamma 0 ` A :: \Omega  (Theorem 6.8.10). By P-INIT, \Gamma 0 ` x ) A0. By Lemma 6.8.11, \Gamma 0 ` A0 :: \Omega . Hence, by
Theorem 7.8.5, \Gamma 0 ` A0 = A :: \Omega  ) \Gamma 0 ` x ) A (P-MOVE).

150 CHAPTER 8. TYPES: CANONICALIZATION

2

Theorem [Tagged] 8.5.6 (Subject reduction for assignments)

If ` \Gamma  valid and \Gamma  ! \Gamma 0 then ` \Gamma 0 valid.

Proof: By structural induction on the derivation of ` \Gamma  valid. The interesting case is
as follows:

DECL-T: Given ` \Gamma ; x:A valid derived via rule DECL-T from \Gamma  ` A :: \Omega  and x 62 dom(\Gamma ) as

well as \Gamma ; x:A ! \Gamma 0; x:A0 derived via rule R-DECL-T from \Gamma  ! \Gamma 0 and A ! A0
) ` \Gamma  valid (Theorem 6.8.3). Applying the induction hypothesis gives us that
` \Gamma 0 valid. By Lemma 8.5.5, \Gamma 0 ` A :: \Omega . By subject reduction (Corollary 7.6.17),
\Gamma 0 ` A0 :: \Omega . By Lemma 8.5.4, dom(\Gamma ) = dom(\Gamma 0) ) x 62 dom(\Gamma 0). Hence, by
DECL-T, ` \Gamma 0; x:A0 valid.

2

8.6 Decidability
In this section I give and prove correct algorithms for use in deciding all the tagged
judgments. For each judgment, I give an algorithm that decides that judgment given
certain preconditions about its arguments (e.g., the assignment is already normalized in
constructor validity case). Later on I give versions based on the original algorithms that
have no preconditions. This organization allows extra work such as repeatedly reducing
assignments to be avoided.

In Figure 8.2, I give the code for the algorithms for the equal constructors (EC 0)
and place lookup (P L0) judgments. EC0 takes as input two pairs, each containing one
constructor in canonical form and the kind of that constructor relative to an (unpassed)
assignment \Gamma . If the two constructors are equal under \Gamma  then EC0 returns their kind.
Otherwise, it raises fail. Because the constructors are in normal form, it can do this
just by comparing them and their kinds.

Lemma [Tagged] 8.6.1 (Properties of EC 0 algorithm)

1. EC0((A1; K1); (A2; K2)) always terminates.
2. If \Gamma  ` A1 :: K1, \Gamma  ` A2 :: K2, and A1 and A2 are in canonical form then

EC0((A1; K1); (A2; K2)) returns K iff \Gamma  ` A1 = A2 :: K.

8.6. DECIDABILITY 151
EC0((A1; K1); (A2; K2)) = if K1 = K2 and A1 = A2 then

return(K1)
else

raise fail

P L0(\Gamma ; xae; A) = EC0((S(\Gamma (x); x; ae); \Omega ); (A; \Omega ))
V T 0(\Gamma ; A) = case V C0(\Gamma ; A) of (A0; \Omega ): return(A0)

Figure 8.2: Determining the equality and place lookup judgments
Proof: The first part follows from inspection of the EC0 procedure. The second part is
proved as follows:

By Lemma 8.4.8, A1 and A2 are in normal form. Hence, by Lemma 8.1.3, A1 #\Lambda  A2
iff A1 = A2.

)) By inspection of the EC0 procedure, EC0((A1; K1); (A2; K2)) returns K implies

that K = K 1 = K2 and A1 = A2 ) A1 #\Lambda  A2. Hence, by Theorem 7.8.5,
\Gamma  ` A1 = A2 :: K .

() By Theorem 7.6.10, \Gamma  ` A1 :: K and \Gamma  ` A2 :: K. By Theorem 7.6.11, K1 = K 2 =

K. By Theorem 7.8.5, A1 #\Lambda  A2 ) A1 = A2
) EC0((A1; K1); (A2; K2)) returns K .

2

If \Gamma  ` A :: \Omega  and \Gamma  and A are both in canonical form, then P L0(\Gamma ; xae; A) returns
iff \Gamma  ` xae ) A. It does this by using Lemma 8.4.13 to reduce place lookup to equality
checking and then using EC0 to decide the resulting equality question.

Lemma [Tagged] 8.6.2 (Properties of P L0 algorithm)

1. P L0(\Gamma ; xae; A) always terminates.
2. If \Gamma  ` A :: \Omega  and \Gamma  and A in canonical form then P L0(\Gamma ; xae; A) returns iff \Gamma  ` xae ) A.

Proof: The first part follows from inspection of the P L0 procedure plus Lemma 8.6.1.
The second part is proved as follows:

152 CHAPTER 8. TYPES: CANONICALIZATION

)) By inspection of the P L0 algorithm, P L0(\Gamma ; xae; A) returns implies that

EC0((S(\Gamma (x); x; ae); \Omega ); (A; \Omega )) returns ) \Gamma (x) and S(\Gamma (x); x; ae) exist ) x 2 dom(\Gamma ).
By inspection of the EC0 algorithm, we also have that S(\Gamma (x); x; ae) = A. By
Lemma 6.8.3, ` \Gamma  valid. By Theorem 6.8.11, \Gamma  ` \Gamma (x) :: \Omega . By P-INIT then,
\Gamma  ` x ) \Gamma (x). By P-MOVE and E-REFL then, \Gamma  ` xae ) S(\Gamma (x); x; ae). Hence,
\Gamma  ` xae ) A.

() By Theorem 6.8.5, x 2 dom(\Gamma ) ) \Gamma (x) exists. By the definition of canonical form,

\Gamma (x) is in canonical form. Hence, by Lemma 8.4.13, \Gamma  ` A = S(\Gamma (x); x; ae) :: \Omega 
and S(\Gamma (x); x; ae) is in canonical form. By Theorem 7.6.10, \Gamma  ` S(\Gamma (x); x; ae) :: \Omega .
By Lemma 8.6.1 then, EC0((S(\Gamma (x); x; ae); \Omega ); (A; \Omega )) returns \Omega  ) P L0(\Gamma ; xae; A)
returns.

2
Also in Figure 8.2 is the code for an algorithm for checking type validity (V T 0). It
is defined using the algorithm for checking general constructor validity (V C 0), the code
for which may be found in Figure 8.3. These algorithms are mutually recursive and
differ mainly in their return behavior. Both take as arguments a valid assignment in
canonical form and a constructor. They check the validity of the constructor under the
given assignment while normalizing the constructor. If the constructor is invalid or, in
the case of V T 0, has kind other than \Omega , then fail is raised. Otherwise, a canonical
form for the constructor is returned; V C0 returns the constructor's kind under the given
assignment as well in a pair with the canonical form. These algorithms implement the
ideas discussed in Section 8.2.

Lemma [Tagged] 8.6.3 (Properties of V C0 and V T 0 algorithms I)

If ` \Gamma  valid and \Gamma  is in canonical form then:

1. V T 0(\Gamma ; A) and V C0(\Gamma ; A) alway terminate.
2. If V T 0(\Gamma ; A) returns A0 then \Gamma  ` A :: \Omega , A !\Lambda  A0, and A0 is in canonical form.
3. If V C0(\Gamma ; A) returns (A0; K) then \Gamma  ` A :: K, A !\Lambda  A0, and A0 is in canonical

form.

Proof: All parts are proved simultaneously by induction on the procedure call in
question under the following metric:

jV T 0(\Gamma ; A)j = 2jAj + 1
jV C0(\Gamma ; A)j = 2jAj

8.6. DECIDABILITY 153
V C0(\Gamma ,A) = case A of

ff: case \Gamma  of

(\Gamma 1; ff::K ; \Gamma 2), ff 62 dom(\Gamma 1): return(ff; K)
\Pi x:A1: A2, x 62 dom(\Gamma ): let A01 = V T 0(\Gamma ; A1) in

return(\Pi x:A01: V T 0((\Gamma ; x:A01); A2); \Omega )
end
\Sigma x:A1: A2, x 62 dom(\Gamma ): let A01 = V T 0(\Gamma ; A1) in

return(\Sigma x:A01: V T 0((\Gamma ; x:A01); A2); \Omega )
end
*ff::K: A, ff 62 dom(\Gamma ): let (A0; K0) = V C0((\Gamma ; ff::K); A) in

return(BR(*ff::K: A0); K)K0)
end
A1 A2: let (A01; K01) = V C0(\Gamma ; A1)

(A02; K02) = V C0(\Gamma ; A2)
(K)K0) = K01 in

if K = K 02 then

return(BR(A01 A02); K0)
else

raise fail
end
!=A::K?: let (A0; K0) = V C0(\Gamma ; A) in

if K = K0 then

return(!=A0::K?; \Omega )
else

raise fail
xae1Aae2!: let A0 = S(\Gamma (x); x; ae1ae2) in

P L0(\Gamma ; xae1; V T 0(\Gamma ; A));
case A0 of

!K?: return(xae1ae2!K?!; K)
!=A00::K?: return(A00; K)
end
!K?: return(!K?; \Omega )

rec: return(rec; (\Omega )\Omega ))\Omega )

ref: return(ref; \Omega )\Omega )

Figure 8.3: Determining the validity of a constructor

154 CHAPTER 8. TYPES: CANONICALIZATION
where jAj is any reasonable metric on constructors such that if A0 is a proper subconstructor of A then 0 ^ jA0j ! jAj. (That is to say, V T 0 may call V C0 with the same
constructor and V C0 may call either procedure with a strictly smaller constructor.)

The parts involving V T 0 follow from the parts about V C0 plus inspection of the V T 0
procedure. The interesting cases for V C 0 are as follows. Unless otherwise indicated,
termination follows by inspection of the relevant code.

Var: Here A = ff. By inspection, if we return, we return (ff; K ) where ff::K 2 \Gamma  )

\Gamma  ` ff :: K (C-VAR). By R-REFL, ff !\Lambda  ff. By the definition of canonical form, ff
is in canonical form.

Dfun: Here A = \Pi x:A1: A2, x 62 dom(\Gamma ). By the induction hypothesis, V T 0(\Gamma ; A1) terminates; if it returns A01 then \Gamma  ` A1 :: \Omega , A1 !\Lambda  A01, and A01 is in canonical form
) \Gamma ; x:A01 is in canonical form (by defn.) and \Pi x:A1: A2 !\Lambda  \Pi x:A01: A2 (R-DFUN
and R-REFL).

Assume it returns. By repeated use of subject reduction (Corollary 7.6.17), \Gamma  ` A01 :: \Omega 
) ` \Gamma ; x:A01 valid (DECL-T). By Theorem 7.8.5, \Gamma  ` A01 = A1 :: \Omega . Applying the
induction hypothesis again gives us that V T 0((\Gamma ; x:A01); A2) terminates; if it returns
A02 then \Gamma ; x:A01 ` A2 :: \Omega , A2 !\Lambda  A02, and A02 is in canonical form ) \Pi x:A01: A02 is
in canonical form (by defn.) and \Pi x:A01: A2 !\Lambda  \Pi x:A01: A02 (R-DFUN and R-REFL)
) \Pi x:A1: A2 !\Lambda  \Pi x:A01: A02 (transitivity).

Assume it returns. By Theorem 7.6.9, \Gamma ; x:A1 ` A2 :: \Omega  ) \Gamma  ` \Pi x:A1: A2 :: \Omega  (CDFUN). Thus, by inspection of the relevant code in V C0, we must terminate and
moreover, if we return, we return (\Pi x:A01: A02; \Omega ) which has the needed properties.

Lam: Here A = *ff::K: A1, ff 62 dom(\Gamma ). By DECL-C, ` \Gamma ; ff::K valid. By the definition of canonical form, \Gamma ; ff::K is in canonical form. By the induction hypothesis
then, V C0((\Gamma ; ff::K); A1) terminates; if it returns (A01; K0) then \Gamma ; ff::K ` A1 :: K0,
A1 !\Lambda  A01, and A01 is in canonical form ) \Gamma  ` *ff::K: A1 :: K)K0 (C-LAM) and
*ff::K: A1 !\Lambda  *ff::K: A01 (R-LAM).

Assume it returns. By repeated use of subject reduction (Corollary 7.6.17),
\Gamma ; ff::K ` A01 :: K0, By Lemma 8.4.7, BR(*ff::K: A01) returns A0 such that *ff::K: A01
!\Lambda  A0 and A0 is in canonical form ) *ff::K: A1 !\Lambda  A0 (transitivity). Thus, by
inspection of the relevant code in V C 0, we must terminate and moreover, if we
return, we return (A0; K)K0) which has the needed properties.

App: Here A = A1 A2. By the induction hypothesis, V C0(\Gamma ; A1) terminates; if it returns

(A01; K01) then \Gamma  ` A1 :: K01, A1 !\Lambda  A01, and A01 is in canonical form and V C0(\Gamma ; A2)
terminates; if it returns (A02; K02) then \Gamma  ` A2 :: K02, A2 !\Lambda  A02, and A02 is in canonical form ) A1 A2 !\Lambda  A01 A02 (R-APP).

8.6. DECIDABILITY 155

Assume they both return. Then, by repeated use of subject reduction (Corollary 7.6.17), \Gamma  ` A01 :: K01 and \Gamma  ` A02 :: K 02.

Assume 9K; K0 such that K01 = K)K0 and K02 = K . Then, by C-APP,
\Gamma  ` A1 A2 :: K0. By Lemma 8.4.7, BR(A01 A02) returns A0 such that A01 A02 !\Lambda  A0
and A0 is in canonical form ) A1 A2 !\Lambda  A0 (transitivity). Thus, by inspection of
the relevant code in V C0, we must terminate and moreover, if we return, we return
(A0; K0) which has the needed properties.

Trans: Here A = !=A1::K?. By the induction hypothesis, V C 0(\Gamma ; A1) terminates; if it

returns (A01; K01) then \Gamma  ` A1 :: K01, A1 !\Lambda  A01, and A01 is in canonical form )
\Gamma  ` !=A1::K01? :: \Omega  (C-TRANS), !=A1::K01? !\Lambda  !=A01::K01? (R-TRANS), and
!=A01::K01? is in canonical form (by defn.).

Assume it returns and K01 = K . Then we return (!=A01::K?; \Omega ) which has the
needed properties. Otherwise, by inspection of the relevant code, we must terminate
by failing.

Ext: Here A = xaeA

1 ae

0!. By Lemma 8.6.2 and the induction hypothesis, P L0(\Gamma ; xae1;

V T 0(\Gamma ; A)) always terminates ) we always terminate in this case.
If we are going to return, then A0 = S(\Gamma (x); x; ae1ae2) must exist. By Lemma 8.4.6
and the fact that \Gamma  is in canonical form, A0 is in canonical form. By Theorem 6.8.11,
\Gamma  ` \Gamma (x) :: \Omega . By P-INIT then, \Gamma  ` x ) \Gamma (x). By P-MOVE and E-REFL then,
\Gamma  ` xae1ae2 ) A0 Hence, by Theorem 7.6.14, \Gamma  ` A0 :: \Omega .

There are 2 cases where we return:

ffl Here 9K: A0 = !K? ) \Gamma  ` xae1ae2!K?! :: K (C-EXT-O2). Since we return

(xae1ae2!K?!; K) for this case, the needed properties are satisfied.

ffl Here 9A00; K: A0 = !=A00::K ? ) A00 is in canonical form (by defn.) and

\Gamma  ` A00 :: K (C-TRANS). Since we return (A00; K) for this case, the needed
properties are satisfied.

Rec: Here A = rec. By C-REC, \Gamma  ` rec :: (\Omega )\Omega ))\Omega . By R-REFL, rec !\Lambda  rec. By

the definition of canonical form, rec is in canonical form. Inspection of the relevant
code shows that V C0(\Gamma ; rec) always returns
(rec; (\Omega )\Omega ))\Omega ).

2

Lemma [Tagged] 8.6.4 (Properties of V C0 and V T 0 algorithms II)

If \Gamma  is in canonical form then:

156 CHAPTER 8. TYPES: CANONICALIZATION

1. If \Gamma  ` A :: \Omega  then V T 0(\Gamma ; A) returns.
2. If \Gamma  ` A :: K then 9A0: V C0(\Gamma ; A) returns (A0; K).

Proof: Both parts are proved simultaneously by induction on the procedure call in
question using the same metric as in the previous lemma. The first part follows easily from
induction using the second part and inspection of the definition of V T 0. The interesting
cases for the second part are as follows:

C-VAR: Given \Gamma  ` ff :: K derived via rule C-VAR from ` \Gamma  valid and ff::K 2 \Gamma  ) 9\Gamma 1; \Gamma 2:

\Gamma  = (\Gamma 1; ff::K ; \Gamma 2), ff 62 dom(\Gamma 1) ) V C0(\Gamma ; ff) returns (ff; K).

C-DFUN: Given \Gamma  ` \Pi x:A1: A2 :: \Omega , x 62 dom(\Gamma ), derived via rule C-DFUN from \Gamma ; x:A1 ` A2 :: \Omega 

) \Gamma  ` A1 :: \Omega  (Theorem 6.8.3). Applying the induction hypothesis gives us that
V T 0(\Gamma ; A1) returns. By Lemma 8.6.3, A1 !\Lambda  V T 0(\Gamma ; A1) and V T 0(\Gamma ; A1) is in
canonical form ) \Gamma ; x:V T 0(\Gamma ; A1) is in canonical form (by defn.). By subject reduction (Corollary 7.6.17), \Gamma  ` V T 0(\Gamma ; A1) :: \Omega . By Theorem 7.8.5 then,
\Gamma  ` A1 = V T 0(\Gamma ; A1) :: \Omega . Hence, by Theorem 7.6.9, \Gamma ; x:V T 0(\Gamma ; A1) ` A2 :: \Omega . Applying the induction hypothesis again gives us that V T 0((\Gamma ; x:V T 0(\Gamma ; A1)); A2) returns. Hence, by inspection, V C0(\Gamma ; \Pi x:A1: A2) returns with a pair whose second
element is \Omega  as required.

C-LAM: Given \Gamma  ` *ff::K: A :: K)K 0, ff 62 dom(\Gamma ), derived via rule C-LAM from

\Gamma ; ff::K ` A :: K0 ) ` \Gamma ; ff::K valid (Theorem 6.8.3). By the definition of canonical form, \Gamma ; ff::K is in canonical form. Applying the induction hypothesis then
gives us that 9A0: V C0((\Gamma ; ff::K ); A) returns (A0; K0). By Lemma 8.6.3 and subject reduction (Corollary 7.6.17), \Gamma ; ff::K ` A0 :: K0 ) \Gamma  ` *ff::K : A0 :: K)K0 (CLAM) ) BR(*ff::K: A0) returns (Lemma 8.3.19). Hence, by inspection of V C0,
V C0(\Gamma ; *ff::K: A) returns with a pair whose second element is K)K 0 as required.

C-EXT-O2: Given \Gamma  ` xae1Aae2! :: K derived via rule C-EXT-O2 from \Gamma  ` xae1ae2 ) !K? and

\Gamma  ` xae1 ) A. By Theorem 7.6.15, \Gamma  ` A :: \Omega . Applying the induction hypothesis gives us that V T 0(\Gamma ; A) returns. By Lemma 8.6.3 and Theorem 6.8.3, A !\Lambda 
V T 0(\Gamma ; A) and V T 0(\Gamma ; A) is in canonical form. By subject reduction (Corollary 7.6.17),
\Gamma  ` V T 0(\Gamma ; A) :: \Omega . By Theorem 7.8.5, \Gamma  ` A = V T 0(\Gamma ; A) :: \Omega  ) \Gamma  ` xae1 ) V T 0(\Gamma ; A)
(P-MOVE). Hence, by Lemma 8.6.2, P L0(\Gamma ; xae1; V T 0(\Gamma ; A)) returns.

By Theorem 6.8.5, x 2 dom(\Gamma ) ) \Gamma (x) is in canonical form (by defn.) Hence, by
Lemma 8.4.13, \Gamma  ` !K? = S(\Gamma (x); x; ae1ae2) :: \Omega  and S(\Gamma (x); x; ae1ae2) is in canonical
form ) !K? !\Lambda  S(\Gamma (x); x; ae1ae2) (Lemma 8.4.9) ) S(\Gamma (x); x; ae1ae2) = !K?
(Lemma 7.3.7). Hence, by inspection we see that in this case V C 0(\Gamma ; xae1Aae2!)
returns a pair whose second element is K as required.

8.6. DECIDABILITY 157
V A0(\Gamma ) = case \Gamma  of

ffl: return(ffl)
\Gamma 0; ff::K: if ff 2 dom(\Gamma 0) then

raise fail
else

return(V A0(\Gamma 0),ff::K)

\Gamma 0; x:A: let \Gamma 00 = V A0(\Gamma 0) in

if x 2 dom(\Gamma 0) then

raise fail
else

return(\Gamma 00,x:V T 0(\Gamma 00,A))
end

Figure 8.4: Determining the validity of an assignment

2
Figure 8.4 contains the code for the valid assignment judgment algorithm (V A0). It
takes as an argument an assignment and returns a canonical form for that assignment if
it is valid. Otherwise, it raises fail. The code is quite simple and uses V T 0.

Lemma [Tagged] 8.6.5 (Properties of V A0 algorithm I)

1. V A0(\Gamma ) always terminates.
2. If V A0(\Gamma ) returns \Gamma 0 then ` \Gamma  valid, \Gamma  !\Lambda  \Gamma 0, and \Gamma 0 is in canonical form.
Proof: By structural induction on \Gamma . Example case:
DECL-T: Here \Gamma  = \Gamma 0; x:A. Applying the induction hypothesis gives us that V A0(\Gamma 0) always

terminates and that if V A0(\Gamma 0) returns \Gamma 00 then ` \Gamma 0 valid, \Gamma 0 !\Lambda  \Gamma 00, and \Gamma 00 is in
canonical form.

Assume we return \Gamma 00 and x 62 dom(\Gamma 0). By Theorem 8.5.6, ` \Gamma 00 valid. Hence,
by Lemma 8.6.3, V T 0(\Gamma 00; A) always terminates and if V T 0(\Gamma 00; A) returns A0 then
\Gamma 00 ` A :: \Omega , A !\Lambda  A0, and A0 is in canonical form.

158 CHAPTER 8. TYPES: CANONICALIZATION

Assume V T 0(\Gamma 00; A) returns A0. Hence, by R-DECL-T, \Gamma 0; x:A !\Lambda  \Gamma 00; x:A0. By
the definition of canonical form, \Gamma 00; x:A0 is in canonical form. By Lemma 8.5.5,
\Gamma 0 ` A :: \Omega  ) ` \Gamma 0; x:A valid.

Thus, by inspection of the relevant code in V A0, we must terminate and moreover,
if we return, we return \Gamma 00; x:A0 which has the needed properties.

2

Lemma [Tagged] 8.6.6 (Properties of V A0 algorithm II)

If ` \Gamma  valid then V A0(\Gamma ) returns.

Proof: By structural induction on the typing derivation. Example case:
DECL-T: Given ` \Gamma 0; x:A valid derived via rule DECL-T from \Gamma 0 ` A :: \Omega  and x 62 dom(\Gamma 0)

) ` \Gamma 0 valid (Theorem 6.8.3). Applying the induction hypothesis gives us that
V A0(\Gamma 0) returns some assignment, call it \Gamma 00. By Lemma 8.6.5, \Gamma 0 !\Lambda  \Gamma 00 and \Gamma 00 is
in canonical form ) ` \Gamma 00 valid (Theorem 8.5.6) ) \Gamma 00 ` A :: \Omega  (Lemma 8.5.5) )
V T 0(\Gamma 00; A) always returns (Lemma 8.6.4). Hence, by inspection of V A0, we always
return.

2
By combining V A0 and V C0, I can decide constructor validity without any preconditions:

Lemma [Tagged] 8.6.7

1. If V A0(\Gamma ) returns then ` V A0(\Gamma ) valid.
2. V T 0(V A0(\Gamma ); A) and V C0(V A0(\Gamma ); A) always terminate.
3. \Gamma  ` A :: \Omega  iff V T 0(V A0(\Gamma ); A) returns.
4. \Gamma  ` A :: K iff 9A0: V C0(V A0(\Gamma ); A) returns (A0; K).

Proof: Part one follows from Lemma 8.6.5 and Theorem 8.5.6. Part two follows from
part one, Lemma 8.6.5, and Lemma 8.6.3. The proofs of parts three and four are similar.
We give just the proof of part four here:

8.6. DECIDABILITY 159

V A(\Gamma ) = V A0(\Gamma )
V C(\Gamma ; A) = V C0(V A0(\Gamma ); A):2
P L(\Gamma ; xae; A) = P L0(V A0(\Gamma ); xae; V T 0(V A0(\Gamma ); A))
EC(\Gamma ; A1; A2) = EC0(V C0(V A0(\Gamma ); A1); V C0(V A0(\Gamma ); A2))

Figure 8.5: Procedures for deciding judgments
): Given V C0(V A0(\Gamma ); A) returns (A0; K) ) V A0(\Gamma ) returns. Hence, by Lemma 8.6.5,

` V A0(\Gamma ) valid, \Gamma  !\Lambda  V A0(\Gamma ), and and V A0(\Gamma ) is in canonical form. By part one,
` V A0(\Gamma ) valid. By Lemma 8.6.3 then, V A0(\Gamma ) ` A :: K. Hence, by Lemma 8.5.5,
\Gamma  ` A :: K.

(: Given \Gamma  ` A :: K ) ` \Gamma  valid (Theorem 6.8.3) ) V A0(\Gamma ) returns (Lemma 8.6.6).

Hence, by Lemma 8.6.5, ` V A0(\Gamma ) valid, \Gamma  !\Lambda  V A0(\Gamma ), and and V A0(\Gamma ) is in canonical form. By part one, ` V A0(\Gamma ) valid. Thus, by Lemma 8.5.5, V A0(\Gamma ) ` A :: K.
Hence, by Lemma 8.6.4, 9A0: V C0(V A0(\Gamma ); A) returns (A0; K).

2

Using this technique, I have defined a set of algorithms for deciding each of the
judgments without any preconditions in Figure 8.5.

Lemma [Tagged] 8.6.8 (Deciding judgments I)

1. V A(\Gamma ), V C(\Gamma ; A), P L(\Gamma ; xae; A), and EC(\Gamma ; A1; A2) always terminate.
2. V A(\Gamma ) returns iff ` \Gamma  valid.
3. V C(\Gamma ; A) returns K iff \Gamma  ` A :: K.
4. P L(\Gamma ; xae; A) returns iff \Gamma  ` xae ) A.

Proof: By Lemma 8.6.5, V A0(\Gamma ) always terminates ) V A(\Gamma ) always terminates. By
Lemmas 8.6.5 and 8.6.6, V A0(\Gamma ) returns iff ` \Gamma  valid ) V A(\Gamma ) returns iff ` \Gamma  valid.
The termination of V C(\Gamma ; A) and the fact that V C(\Gamma ; A) returns K iff \Gamma  ` A :: K follow from inspection of the definition of V C(\Gamma ; A) and Lemma 8.6.7. The termination of
P L(\Gamma ; xae; A) and EC(\Gamma ; A1; A2) follows from the termination of V A0(\Gamma ) (Lemma 8.6.5),
the termination of V T 0(V A0(\Gamma ); A) and V C0(V A0(\Gamma ); A) (Lemma 8.6.7), and Lemmas 8.6.2
and 8.6.1. The proof of the last part is as follows:

160 CHAPTER 8. TYPES: CANONICALIZATION

): Given P L(\Gamma ; xae; A) returns ) 9A0: V T 0(V A(\Gamma ); A) returns A0 ) V A0(\Gamma ) returns.

Hence, by Lemma 8.6.3, V A0(\Gamma ) ` A :: \Omega , A !\Lambda  A0, and A0 is in canonical form.
By subject reduction (Corollary 7.6.17), V A0(\Gamma ) ` A0 :: \Omega . Hence, by Lemma 8.6.2,
V A0(\Gamma ) ` xae ) A0. By Theorem 7.8.5, V A0(\Gamma ) ` A0 = A :: \Omega  ) V A0(\Gamma ) ` xae ) A
(P-MOVE). By Lemma 8.6.5, Lemma 8.6.7, and Lemma 8.5.5, \Gamma  ` xae ) A.

(: Given \Gamma  ` xae ) A ) \Gamma  ` A :: \Omega  (Theorem 7.6.14) ) 9A0: V T 0(V A(\Gamma ); A) returns

A0 ) V A0(\Gamma ) returns. Hence, by Lemma 8.6.3, V A0(\Gamma ) ` A :: \Omega , A !\Lambda  A0, and
A0 is in canonical form. By subject reduction (Corollary 7.6.17), V A0(\Gamma ) ` A0 :: \Omega .
By Lemma 8.6.5, Lemma 8.6.7, and Lemma 8.5.5, V A0(\Gamma ) ` xae ) A. By Theorem 7.8.5, V A0(\Gamma ) ` A = A0 :: \Omega  ) V A0(\Gamma ) ` xae ) A0 (P-MOVE). Hence, by
Lemma 8.6.2, P L0(V A0(\Gamma ); xae; V T 0(V A0(\Gamma ); A)) returns ) P L(\Gamma ; xae; A) returns.

2

Lemma [Tagged] 8.6.9 (Deciding judgments II)

EC(\Gamma ; A1; A2) returns K iff \Gamma  ` A1 = A2 :: K .

Proof:

): Given EC(\Gamma ; A1; A2) returns K ) 9A01; A02; K1; K2 such that V C0(V A0(\Gamma ); A1) returns (A01; K1) and V C0(V A0(\Gamma ); A2) returns (A02; K2). By Lemma 8.6.7, \Gamma  ` A1 :: K1
and \Gamma  ` A2 :: K2. By Lemma 8.6.3, A1 !\Lambda  A01, A2 !\Lambda  A02, and A01 and A02
are in canonical form. By subject reduction (Corollary 7.6.17), \Gamma  ` A01 :: K1 and
\Gamma  ` A02 :: K2. Hence, by Lemma 8.6.1, \Gamma  ` A01 = A02 :: K ) \Gamma  ` A01 :: K and
\Gamma  ` A02 :: K (Theorem 6.8.3) ) K = K1 = K2 (Theorem 7.6.11). By Theorem 7.8.5, \Gamma  ` A1 = A01 :: K and \Gamma  ` A2 = A02 :: K. Hence, by E-TRAN and ESYM, \Gamma  ` A1 = A2 :: K.

(: Given \Gamma  ` A1 = A2 :: K ) \Gamma  ` A1 :: K and \Gamma  ` A2 :: K (Theorem 6.8.3) ) 9A01; A02

such that V C0(V A0(\Gamma ); A1) returns (A01; K) and V C0(V A0(\Gamma ); A2) returns (A02; K)
(Lemma 8.6.7) By Lemma 8.6.7, Lemma 8.6.5, and Corollary 7.6.17, \Gamma  ` A01 :: K,
\Gamma  ` A02 :: K, and A01 and A02 are in canonical form. Hence, by Lemma 8.6.1,
EC0(V C0(V A0(\Gamma ); A1); V C0(V A0(\Gamma ); A2)) returns K ) EC(\Gamma ; A1; A2) returns K.

2

The consequences of these algorithms can be summed up in three propositions:
Corollary [Tagged] 8.6.10 (Decidability of judgments)

The following judgments are decidable:

8.6. DECIDABILITY 161

1. ` \Gamma  valid
2. \Gamma  ` A :: K
3. \Gamma  ` xae ) A
4. \Gamma  ` A = A0 :: K

Corollary [Tagged] 8.6.11 (Kind Inference)

A recursive algorithm A exists such that

1. If \Gamma  ` A :: K then A(\Gamma ; A) returns K.
2. If :9K: \Gamma  ` A :: K then A(\Gamma ; A) raises fail

Proof: Let A(\Gamma ; A) = V C(\Gamma ; A). The desired result then follows immediately from
Lemma 8.6.8. 2

Theorem [Tagged] 8.6.12 (Computability of canonical types)

If \Gamma  ` A :: \Omega  then a constructor A0 is recursively computable such that
\Gamma  ` A = A0 :: \Omega  and A0 is in canonical form.

Proof: By Lemma 8.6.7, V T 0(V A0(\Gamma ); A) always returns. By Lemma 8.6.3, A !\Lambda 
V T 0(V A0(\Gamma ); A) and V T 0(V A0(\Gamma ); A) is in canonical form. By Corollary 7.6.17,
\Gamma  ` V T 0(V A0(\Gamma ); A) :: \Omega . By Theorem 7.8.5, \Gamma  ` A = V T 0(V A0(\Gamma ); A) :: \Omega . 2

162 CHAPTER 8. TYPES: CANONICALIZATION
Chapter 9
Types: Summary
In this chapter I transfer the results of the previous two chapters on the tagged system to
the original untagged system. I do this by introducing two transforms I call tag removal
and stamping. Tag removal (\Gamma \Psi ) transforms objects from the tagged to the untagged

system by removing tags (e.g., xaeAae0!\Psi  = xaeae0!). Stamping (\Gamma \Phi \Gamma ) transforms in the
opposite direction by adding tags:

xae!\Phi \Gamma  = x\Gamma (x)ae!
The tag to be added is obtained from the current assignment. Using these two transforms, I shall show how to transform judgment derivations between the two systems.
Transferring the results between systems is then straightforward.

This chapter is the last of the four chapters devoted to the constructor validity and
equality judgments. In the remaining chapters about the kernel system, I shall discuss
subtyping, soundness, and type checking terms respectively.

9.1 Tag Removal
In this section I introduce the tag removal transform and prove the needed properties
about it. Tag removal can be applied to tagged constructors, declarations, assignments,
and judgments, resulting in untagged objects of the same sort. Its definition is straightforward:

163

164 CHAPTER 9. TYPES: SUMMARY
Definition [Tagged] 9.1.1 (Tag removal)

ff\Psi  = ff
rec\Psi  = rec

ref\Psi  = ref
!K?\Psi  = !K?
(\Pi x:A1: A2)\Psi  = \Pi x:A\Psi 1 : A\Psi 2

(\Sigma x:A1: A2)\Psi  = \Sigma x:A\Psi 1 : A\Psi 2

(*ff::K: A)\Psi  = *ff::K: A\Psi 

(A1 A2)\Psi  = A\Psi 1 A\Psi 2
!=A::K?\Psi  = !=A\Psi ::K?

xaeAae0!\Psi  = xaeae0!

(ff::K)\Psi  = ff::K

(x:A)\Psi  = x:A\Psi 

ffl\Psi  = ffl
(\Gamma ; D)\Psi  = \Gamma \Psi ; D\Psi 

(` \Gamma  valid)\Psi  = ` \Gamma \Psi  valid
(\Gamma  ` A :: K)\Psi  = \Gamma \Psi  ` A\Psi  :: K
(\Gamma  ` xae ) A)\Psi  = \Gamma \Psi  ` xae ) A\Psi 
(\Gamma  ` A1 = A2 :: K)\Psi  = \Gamma \Psi  ` A\Psi 1 = A\Psi 2 :: K

Tag removal interacts with the other operators in the expected ways:
Lemma [Tagged] 9.1.2

1. FCV(A\Psi ) ` FCV(A)
2. FTV(A\Psi ) ` FTV(A)
Lemma [Tagged] 9.1.3 (Properties of tag removal)

1. ([A2=ff]A1)\Psi  = [A\Psi 2 =ff](A\Psi 1 )
2. ([xae=x0]A)\Psi  = [xae=x0](A\Psi )
3. If S(A; xae; ae0) exists then S(A; xae; ae0)\Psi  = S(A\Psi ; xae; ae0).
4. dom(\Gamma ) = dom(\Gamma \Psi )

9.1. TAG REMOVAL 165

5. If D 2 \Gamma  then D\Psi  2 \Gamma \Psi 
Proof: Proved sequentially by structural induction on A1, A, ae0, \Gamma , and \Gamma  respectively.
Examples:

([A=ff]*ff0::K: A0)\Psi  = (*ff0::K: [A=ff]A0)\Psi  = *ff0::K: ([A=ff]A0)\Psi 
= *ff0::K: [A\Psi =ff](A0\Psi ) = [A\Psi =ff]*ff0::K: (A0\Psi ) = [A\Psi =ff]((*ff0::K: A0)\Psi )

([A2=ff]xaeA

1ae

0!)\Psi  = (xae

[A2=ff]A1 ae

0!)\Psi  = xaeae0! = [A\Psi 2 =ff]xaeae0!

= [A\Psi 2 =ff](xaeA

1 ae

0!)\Psi 

([xae=x0]x00ae0Aae00!)\Psi  = (([xae=x0]x00ae0)[xae=x0]Aae00)\Psi  = ([xae=x0]x00ae0)ae00
= [xae=x0]x00ae0ae00 = [xae=x0](x00ae0Aae00)\Psi 

S(\Sigma x0:A1: A2; xae; :2ae0)\Psi  = S([xae:1=x0]A2; xae:2; ae0)\Psi  =
S(([xae:1=x0]A2)\Psi ; xae:2; ae0) = S([xae:1=x0](A\Psi 2 ); xae:2; ae0) =
S(\Sigma x0:A\Psi 1 : A\Psi 2 ; xae; :2ae0) = S((\Sigma x0:A1: A2)\Psi ; xae; :2ae0)

dom(\Gamma ; x:A) = dom(\Gamma ) [ dom(x:A) = dom(\Gamma ) [ fxg = dom(\Gamma \Psi ) [ fxg
= dom(\Gamma \Psi ) [ dom(x:A\Psi ) = dom(\Gamma \Psi ; (x:A)\Psi ) = dom((\Gamma ; x:A)\Psi )

D 2 \Gamma  ) \Gamma  = ffl; D1; : : : ; Dm; D; Dm+1; : : : ; Dn
) \Gamma \Psi  = ffl; D\Psi 1 ; : : : ; D\Psi m; D\Psi ; D\Psi m+1; : : : ; D\Psi n ) D\Psi  2 \Gamma \Psi 

Where ff0 6= ff, ff0 62 FCV(A) ' FCV(A\Psi ) by Lemma 9.1.2, and ([xae=x0]x00ae0)ae00 =
[xae=x0]x00ae0ae00 by Lemma 6.5.1. 2

Lemma [Tagged] 9.1.4 If S(A\Psi ; xae; ae0) exists then S(A; xae; ae0) exists.
Proof: By structural induction on ae0. 2

Lemma [Tagged] 9.1.5 (\Gamma ; \Gamma 0)\Psi  = \Gamma \Psi ; \Gamma 0\Psi 

If a tagged constructor extraction xaeAae0! has kind K under \Gamma  (\Gamma  ` xaeAae0! :: K), then
it will always be equal to a constructor extraction involving the same place, but with a
tag of \Gamma (x) next to x (i.e., x\Gamma (x)aeae0!). This equality allows the stamping transform to
assign tags of this sort to all constructor extractions.

Lemma [Tagged] 9.1.6 If \Gamma  ` xae ) A and \Gamma  ` xaeae0 ) A0 where A0 has either the form
!K? or the form !=A00::K? for some A00 then \Gamma  ` x\Gamma (x)aeae0! = xaeAae0! :: K.

166 CHAPTER 9. TYPES: SUMMARY
Proof: By structural induction on the derivation of \Gamma  ` xae ) A:
P-INIT: Given \Gamma  ` x ) A (ae = ffl) derived via rule P-INIT from ` \Gamma  valid and x:A 2 \Gamma . By

C-EXT-O2 or C-EXT-T2 (depending on the form of A00), \Gamma  ` x\Gamma (x)aeae0! :: K. By

Lemma 6.8.11, \Gamma (x) = A. By E-REFL then, \Gamma  ` x\Gamma (x)aeae0! = xaeAae0! :: K.

P-MOVE: Given \Gamma  ` xaeae00 ) A derived via rule P-MOVE from \Gamma  ` xae ) A1,

\Gamma  ` A1 = A2 :: \Omega , and S(A2; xae; ae00) = A. Applying the induction hypothesis gives
us that \Gamma  ` x\Gamma (x)aeae00ae0! = xaeA

1 ae

00ae0! :: K. By E-EXT2, \Gamma  ` xaeA

1ae

00ae0! = xaeae00Aae0! :: K.

The desired result then follows by E-TRAN.

2

Applying the equality twice followed by E-TRAN to two different valid tagged constructor extractions involving the same place shows that the two constructor extractions
must be equal regardless of what or where their tags are:

Corollary [Tagged] 9.1.7 If \Gamma  ` xaeA

1ae

0ae00 :: K and \Gamma  ` xaeae0A

2ae

00 :: K then

\Gamma  ` xaeA

1ae

0ae00 = xaeae0A

2 ae

00 :: K.

Proof: Apply Lemma 7.6.5 then Lemma 9.1.6 for each of the two givens then apply
E-TRAN and E-SYM. 2

This result can be usefully generalized to show that two valid tagged constructors
that differ only in their tags' values or locations must be equal:

Theorem [Tagged] 9.1.8 If \Gamma  ` A1 :: K, \Gamma  ` A2 :: K, and A\Psi 1 = A\Psi 2 then
\Gamma  ` A1 = A2 :: K.

Proof: By structural induction on A\Psi 1 . Example cases:

Var: Here A\Psi 1 = A\Psi 2 = ff ) A1 = A2 = ff (inspection of the definition of tag removal)

) \Gamma  ` A1 = A2 :: K (E-REFL).

DFun: Here A\Psi 1 = A\Psi 2 = \Pi x:B1: B2 for some untagged constructors B1 and B2, \Gamma  ` A1 :: K,

and \Gamma  ` A2 :: K ) A1 = \Pi x:A11: A12 and A2 = \Pi x:A21: A22 for some A11, A12,
A21, and A22 where A\Psi 11 = A\Psi 21 = B1 and A\Psi 12 = A\Psi 22 = B2 (inspection of the definition of tag removal) ) K = \Omega , \Gamma  ` A11 :: \Omega , \Gamma  ` A21 :: \Omega , \Gamma ; x:A11 ` A12 :: \Omega ,
and \Gamma ; x:A21 ` A22 :: \Omega  (C-DFUN). Applying the induction hypothesis gives us that
\Gamma  ` A11 = A21 :: \Omega  ) \Gamma ; x:A11 ` A22 :: \Omega  (Theorem 7.6.9). Applying the induction
hypothesis again then gives us that \Gamma ; x:A11 ` A12 = A22 :: \Omega  ) \Gamma  ` A1 = A2 :: K
(E-DFUN).

9.2. STAMPING 167

Ext: Here A\Psi 1 = A\Psi 2 = xae!, \Gamma  ` A1 :: K, and \Gamma  ` A2 :: K ) A1 = xae1A0

1ae2ae3! andA

2 = xae1ae2A0

2ae3! where ae1ae2ae3 = ae for some A

01 and A02

) \Gamma  ` xae1A0

1ae2ae3! :: K, and \Gamma  ` xae1ae2A

0
2ae3! :: K ) \Gamma  ` A1 = A2 :: K(Corollary 9.1.7).

2

9.2 Stamping
In this section I introduce the stamping transform and prove the needed properties about
it. Stamping can be applied to (untagged) constructors, declarations, assignments, and
judgments, resulting in tagged objects of the same sort. The stamping of constructors and
declarations takes the stamped version of the current assignment as an extra argument
so that the transform can lookup term variables' types for use as tags. The definition of
stamping is as follows:

168 CHAPTER 9. TYPES: SUMMARY
Definition 9.2.1 (Stamping)

ff\Phi \Gamma  = ff
rec\Phi \Gamma  = rec

ref\Phi \Gamma  = ref
!K?\Phi \Gamma  = !K?

(\Pi x:A1: A2)\Phi \Gamma  = \Pi x:A\Phi \Gamma 1 : A\Phi \Gamma ;x:A

\Phi \Gamma 
12 (x 62 dom(\Gamma ) [ FTV(\Gamma ))

(\Sigma x:A1: A2)\Phi \Gamma  = \Sigma x:A\Phi \Gamma 1 : A\Phi \Gamma ;x:A

\Phi \Gamma 
12 (x 62 dom(\Gamma ) [ FTV(\Gamma ))

(*ff::K: A)\Phi \Gamma  = *ff::K: A\Phi \Gamma ;ff::K (ff 62 dom(\Gamma ) [ FCV(\Gamma ))

(A1 A2)\Phi \Gamma  = A\Phi \Gamma 1 A\Phi \Gamma 2
!=A::K?\Phi \Gamma  = !=A\Phi \Gamma ::K?

xae!\Phi \Gamma  = x\Gamma (x)ae!

(ff::K)\Phi \Gamma  = ff::K

(x:A)\Phi \Gamma  = x:A\Phi \Gamma 

ffl\Phi  = ffl
(\Gamma ; D)\Phi  = \Gamma \Phi ; D\Phi \Gamma 

\Phi 

(` \Gamma  valid)\Phi  = ` \Gamma \Phi  valid
(\Gamma  ` A :: K)\Phi  = \Gamma \Phi  ` A\Phi \Gamma 

\Phi  :: K

(\Gamma  ` xae ) A)\Phi  = \Gamma \Phi  ` xae ) A\Phi \Gamma 

\Phi 

(\Gamma  ` A1 = A2 :: K)\Phi  = \Gamma \Phi  ` A\Phi \Gamma 

\Phi 

1 = A

\Phi \Gamma 

\Phi 

2 :: K

Stamping is not always defined. In particular, xae!\Phi \Gamma  is only defined if x 2 dom(\Gamma ).
Stamping is defined, however, for the components of judgments. This result will be
sufficient to translate results between the systems.

Theorem [Mixed] 9.2.2 (Existence of stamping)

1. If FTV(A) ` dom(\Gamma 0) then A\Phi \Gamma 

0 exists.

2. If \Gamma \Phi  exists then dom(\Gamma \Phi ) = dom(\Gamma ).
3. If ` \Gamma  valid then \Gamma \Phi  exists.

9.2. STAMPING 169

4. If \Gamma  ` A :: K then A\Phi \Gamma 

\Phi  exists.

5. If \Gamma  ` xae ) A then A\Phi \Gamma 

\Phi  exists.

6. If \Gamma  ` A1 = A2 :: K then A\Phi \Gamma 

\Phi 

i exist.

(Here \Gamma 0 is a tagged assignment; all other variables are untagged.)

Proof: The first two parts are proved by structural induction on A and \Gamma  respectively.
Then the last four parts are proved by simultaneous structural induction on the typing
derivations. In the last three parts, Lemma 6.3.5 plus part three via the induction hypothesis shows that \Gamma \Phi  exists. Lemma 6.5.6 plus parts one and two then shows that

A\Phi \Gamma 

\Phi  or A\Phi \Gamma \Phi 

i exists. 2

Stamping and tag removal are partial inverses in the sense that stamping followed
by tag removal leaves untagged objects unchanged. The reverse operation (tag removal
followed by stamping) does change the tagged objects, altering their tags' values and locations. If the original object was a valid tagged constructor then the resulting constructor
will at least be equal under the equality relation to the original (Theorem 9.1.8).

Lemma [Mixed] 9.2.3 (Cancellation of stamping)

1. If A\Phi \Gamma 

0 exists then (A\Phi \Gamma 0 )\Psi  = A.

2. If \Gamma \Phi  exists then (\Gamma \Phi )\Psi  = \Gamma .
3. If the judgment J\Phi  exists then (J\Phi )\Psi  = J .
(Here \Gamma 0 is a tagged assignment; all other variables are untagged.)
Proof: Proved sequentially using structural induction on A, \Gamma , and J respectively. 2

The interactions between stamping and the other operators are more complicated
than in the tag removal case because of the need to take the assignment into account,
the need to worry about when stamping is defined, and the need to keep track of where
the tags are. In many cases the operators can be related only by using the equality
relation.

For example, when trying to relate place substitution and stamping, we can reason
as follows:

[xae=x0](x0!\Phi \Gamma ;x

0:A0;\Gamma 0) ? ([xae=x0]x0!)\Phi \Gamma ;[xae=x0]\Gamma 0

, [xae=x0](x0A0!) ? xae!\Phi \Gamma ;[xae=x

0]\Gamma 0

, xaeA0! ? x(\Gamma ;[xae=x0]\Gamma 0)(x)ae!

170 CHAPTER 9. TYPES: SUMMARY
The two sides are clearly not the same because their tags are in different locations.
Under appropriate conditions, however, they will be equal under the equality relation
(Theorem 9.2.6, below).

Lemma [Mixed] 9.2.4 (Properties of stamping I)

1. If A\Phi \Gamma 1;\Gamma 3 exists and dom(\Gamma 2) " dom(\Gamma 3) = ; then A\Phi \Gamma 1;\Gamma 2;\Gamma 3 = A\Phi \Gamma 1;\Gamma 3.
2. If \Gamma \Phi  exists and D 2 \Gamma  then D\Phi \Gamma 

\Phi  2 \Gamma \Phi 

3. If FTV(A1) ` dom(\Gamma 1), ff 62 FCV(\Gamma 1), and FTV(A2) ` dom(\Gamma 1; ff::K; \Gamma 2) then

[A\Phi \Gamma 11 =ff]A\Phi \Gamma 

1;ff::K;\Gamma 22 = ([A1=ff]A2)\Phi \Gamma 1;[A

\Phi \Gamma 1

1 =ff]\Gamma 2 .

(Here the \Gamma i's are tagged assignments; all other variables are untagged.)
Proof: Proved sequentially using structural induction on A, \Gamma , and A2 respectively,
using Lemmas 7.6.1 and 7.3.9. 2

Lemma [Mixed] 9.2.5 If \Gamma ; x:A0; \Gamma 0 ` B\Phi \Gamma ;x:A

0;\Gamma 0 :: K and \Gamma  ` A0 = A00 :: \Omega  then

\Gamma ; x:A0; \Gamma 0 ` B\Phi \Gamma ;x:A

0;\Gamma 0 = B\Phi \Gamma ;x:A00;\Gamma 0 :: K.

(Here B's are untagged constructors; all other variables are tagged.)
Proof: By structural induction on B. Example cases:

Var: Since ff\Phi \Gamma ;x:A

0;\Gamma 0 = ff = ff\Phi \Gamma ;x:A00;\Gamma 0 , applying E-REFL gives the desired result.

Dfun: Let \Gamma 00 = \Gamma ; x:A0; \Gamma 0 and \Gamma 000 = \Gamma ; x:A00; \Gamma 0.

Given \Gamma 00 ` \Pi x0:B\Phi \Gamma 

00: B0\Phi \Gamma 00;x0:B\Phi \Gamma 00 :: \Omega , x0 62 dom(\Gamma 0) [ FTV(\Gamma 00) [ FTV(\Gamma 000),

derived via rule C-DFUN from \Gamma 00; x0:B\Phi \Gamma 

00 ` B0\Phi \Gamma 00;x0:B\Phi \Gamma 00 :: \Omega 

) ` \Gamma 00; x0:B\Phi \Gamma 

00 valid (Lemma 6.8.3) ) \Gamma 00 ` B\Phi \Gamma 00 :: \Omega  (DECL-T). Applying the

induction hypothesis gives us that \Gamma 00 ` B\Phi \Gamma 

00 = B\Phi \Gamma 000 :: \Omega  and

\Gamma 00; x0:B\Phi \Gamma 

00 ` B0\Phi \Gamma 00;x0:B\Phi \Gamma 00 = B0\Phi \Gamma 000;x0:B\Phi \Gamma 00 :: \Omega . By Theorem 7.6.10 and 7.6.9,

\Gamma 000; x0:B\Phi \Gamma 

00 ` B0\Phi \Gamma 000;x0:B\Phi \Gamma 00 :: \Omega  and \Gamma 000 ` B\Phi \Gamma 00 = B\Phi \Gamma 000 :: \Omega . Hence, applying

the induction hypothesis again gives us that
\Gamma 000; x0:B\Phi \Gamma 

00 ` B0\Phi \Gamma 000;x0:B\Phi \Gamma 00 = B0\Phi \Gamma 000;x0:B\Phi \Gamma 000 :: \Omega .

Applying Theorem 7.6.10 and 7.6.9 again gives us that
\Gamma 00; x0:B\Phi \Gamma 

00 ` B0\Phi \Gamma 000;x0:B\Phi \Gamma 00 = B0\Phi \Gamma 000;x0:B\Phi \Gamma 000 :: \Omega 

9.2. STAMPING 171

) \Gamma 00; x0:B\Phi \Gamma 

00 ` B0\Phi \Gamma 00;x0:B\Phi \Gamma 00 = B0\Phi \Gamma 000;x0:B\Phi \Gamma 000 :: \Omega  (E-TRAN).

Hence, by E-DFUN,
\Gamma 00 ` \Pi x0:B\Phi \Gamma 

00: B0\Phi \Gamma 00;x0:B\Phi \Gamma 00 = \Pi x0:B\Phi \Gamma 000: B0\Phi \Gamma 000;x0:B\Phi \Gamma 000 :: \Omega 

) \Gamma 00 ` (\Pi x0:B: B0)\Phi \Gamma 

00 = (\Pi x0:B: B0)\Phi \Gamma 000 :: \Omega .

Ext I: Let \Gamma 00 = \Gamma ; x:A0; \Gamma 0 and \Gamma 000 = \Gamma ; x:A00; \Gamma 0. Given \Gamma 00 ` x0\Gamma 00(x0)ae! :: K derived via

rule C-EXT-O2 from \Gamma 00 ` x0ae ) !K? and \Gamma 00 ` x0 ) \Gamma 00(x0). By weakening (Theorem 6.8.10), \Gamma 00 ` A0 = A00 :: \Omega . By Lemma 6.8.11 and E-REFL, 8x00 2 dom(\Gamma 00):
\Gamma 00 ` \Gamma 00(x0) = \Gamma 00(x0) :: \Omega . Hence, \Gamma 00 ` \Gamma 00(x0) = \Gamma 000(x0) :: \Omega . Thus, by E-EXT2,

\Gamma 00 ` x0\Gamma 00(x0)ae! = x0\Gamma 000(x0)ae! :: K ) \Gamma 00 ` (x0ae!)\Phi \Gamma 

00 = (x0ae!)\Phi \Gamma 000 :: K.

2

Theorem [Mixed] 9.2.6 If \Gamma  ` xae ) A0 and \Gamma ; x0:A0; \Gamma 0 ` B\Phi \Gamma ;x

0:A0;\Gamma 0 :: K then

\Gamma ; [xae=x0]\Gamma 0 ` [xae=x0](B\Phi \Gamma ;x

0:A0;\Gamma 0) = ([xae=x0]B)\Phi \Gamma ;[xae=x0]\Gamma 0 :: K.

(Here B's are untagged constructors; all other variables are tagged.)

Proof: By structural induction on B. Example cases:

Var: By Theorem 7.6.12, \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]ff\Phi \Gamma ;x

0:A0;\Gamma 0 :: K. Since ff\Phi \Gamma 00 = ff and

[xae=x0]ff = ff, by E-REFL we have the desired result.

Dfun: Let \Gamma 00 = \Gamma ; x0:A0; \Gamma 0, ` = [xae=x0], and \Gamma 000 = \Gamma ; `\Gamma 0. We are given that

\Gamma 00 ` (\Pi x00:B1: B2)\Phi \Gamma 

00 :: K where x00 62 dom(\Gamma 00) [ FTV(\Gamma 00) [ FTV(\Gamma 000) [ fx; x0g )

\Gamma 00 ` \Pi x00:B\Phi \Gamma 

00

1 : B

\Phi \Gamma 

00;x00:B\Phi \Gamma 00

12 :: K

) \Gamma 00; x00:B\Phi \Gamma 

00

1 ` B

\Phi \Gamma 

00;x00:B\Phi \Gamma 00

12 :: K (C-DFUN) ) ` \Gamma 00; x00:B\Phi \Gamma 

00

1 valid (Lemma 6.8.3)

) \Gamma 00 ` B\Phi \Gamma 

00

1 :: \Omega  (DECL-T). Applying the induction hypothesis then gives us that

\Gamma 000 ` `B\Phi \Gamma 

00

1 = (`B1)\Phi \Gamma 

000 :: K and

\Gamma 000; x00:`B\Phi \Gamma 

00

1 ` `B

\Phi \Gamma 

00;x00:B\Phi \Gamma 00

12 = (`B2)\Phi \Gamma 

000;x00:`B\Phi \Gamma 00

1 :: K.

By Lemma 9.2.5,

\Gamma 000; x00:`B\Phi \Gamma 

00

1 ` (`B2)\Phi \Gamma 

000;x00:`B\Phi \Gamma 00

1 = (`B2)\Phi \Gamma 

000;x00:(`B

1)\Phi \Gamma 

000

:: K

) \Gamma 000; x00:`B\Phi \Gamma 

00

1 ` `B

\Phi \Gamma 

00;x00:B\Phi \Gamma 00

12 = (`B2)\Phi \Gamma 

000;x00:(`B

1)\Phi \Gamma 

000

:: K

(E-TRAN). Hence, by E-DFUN,

\Gamma 000 ` \Pi x00:`B\Phi \Gamma 

00

1 : `B

\Phi \Gamma 

00;x00:B\Phi \Gamma 00

12 = \Pi x00:(`B1)\Phi \Gamma 

000 : (`B

2)\Phi \Gamma 

000;x00:(`B

1)\Phi \Gamma 

000

:: K

172 CHAPTER 9. TYPES: SUMMARY

) \Gamma 000 ` `\Pi x00:B\Phi \Gamma 

00

1 : B

\Phi \Gamma 

00;x00:B\Phi \Gamma 00

12 = (\Pi x00:`B1: `B2)\Phi \Gamma 

000 :: K

) \Gamma 000 ` `(\Pi x00:B1: B2)\Phi \Gamma 

00 = (`\Pi x00:B

1: B2)\Phi \Gamma 

000 :: K

Ext I: Let \Gamma 00 = \Gamma ; x0:A0; \Gamma 0, ` = [xae=x0], and \Gamma 000 = \Gamma ; `\Gamma 0. We are given that

\Gamma 00 ` (x0ae0!)\Phi \Gamma 

00 :: K . By Theorem 7.6.12, \Gamma 000 ` `(x0ae0!\Phi \Gamma 00) :: K ) \Gamma 000 ` xae

`A

0ae0! :: K.

By Lemmas 7.6.5 and 9.1.6, \Gamma 000 ` x\Gamma 000(x)aeae0! = xae`A0 ae0! :: K

) \Gamma 000 ` (`x0ae0!)\Phi \Gamma 

000 = `(x0ae0!\Phi \Gamma 00) :: K. The desired result follows from E-SYM.

Ext II: Let \Gamma 00 = \Gamma ; x0:A0; \Gamma 0, ` = [xae=x0], and \Gamma 000 = \Gamma ; `\Gamma 0. We are given that

\Gamma 00 ` (x00ae0!)\Phi \Gamma 

00 :: K, x00 6= x0. By Theorem 7.6.12, \Gamma 000 ` `(x00ae0!\Phi \Gamma 00) :: K

) \Gamma 000 ` x00`\Gamma 00(x00)ae0! :: K. By repeated use of Lemma 6.3.5, ` \Gamma ; x0:A0 valid )
x0 62 dom(\Gamma ) (DECL-T) ) x0 62 FTV(\Gamma ) (Theorem 6.8.5) ) `\Gamma  = \Gamma  (Lemma 7.3.9)
) `\Gamma 00(x00) = (`\Gamma 00)(x00) = (`(\Gamma ; x0:A0; \Gamma 0))(x00) = (`\Gamma ; x0:`A0; `\Gamma 0)(x00) = (\Gamma ; `\Gamma 0)(x00)
= \Gamma 000(x00). Hence, by E-REFL, \Gamma 000 ` x00`\Gamma 00(x00)ae0! = x00\Gamma 000(x00)ae0! :: K

) \Gamma 000 ` `(x00ae0!\Phi \Gamma 

00) = (`x00ae0!)\Phi \Gamma 000 :: K.

2

Lemma [Mixed] 9.2.7 (Properties of stamping II)

If \Gamma  ` xae ) B\Phi \Gamma  and S(B; xae; ae0)\Phi \Gamma  exists then \Gamma  ` xaeae0 ) S(B; xae; ae0)\Phi \Gamma .
(Here B's are untagged constructors; all other variables are tagged.)

Proof: By structural induction on ae0:
Empty: Since ae0 = ffl for this case, the desired result is the first precondition.

Fst: Here ae0 = :1ae00 and B = \Sigma x0:B1: B2. By Lemma 6.5.3, S(B; xae; :1ae00) =

S(S(B; xae; :1); xae:1; ae00) = S(B1; xae:1; ae00). Hence, by Lemmas 9.1.4

and 9.2.3, S(B\Phi \Gamma ; xae; :1) exists. By Theorems 7.6.15 and 7.6.13,
\Gamma  ` xae:1 ) S(B\Phi \Gamma ; xae; :1) ) \Gamma  ` xae:1 ) B\Phi \Gamma 1 . Applying the induction hypothesis
gives us that \Gamma  ` xaeae:100 ) S(B1; xae:1; ae00)\Phi \Gamma  ) \Gamma  ` xaeae:100 ) S(B; xae; ae:100)\Phi \Gamma .

Snd: Here ae0 = :2ae00 and B = \Sigma x0:B1: B2. By Lemma 6.5.3, S(B; xae; :2ae00) =

S(S(B; xae; :2); xae:2; ae00) = S(([xae:1=x0]B2); xae:2; ae00). Hence, by Lemmas 9.1.4

and 9.2.3, S(B\Phi \Gamma ; xae; :2) exists. By Theorem 7.6.15, \Gamma  ` (\Sigma x0:B1: B2)\Phi \Gamma  :: \Omega 

) \Gamma ; x0:B\Phi \Gamma 1 ` B\Phi \Gamma ;x

0:B\Phi \Gamma 

12 :: \Omega  (Lemma 6.8.3 and DECL-T). By Theorem 7.6.13,

\Gamma  ` xae:2 ) S(B\Phi \Gamma ; xae; :2)

9.3. SYSTEM CORRESPONDENCE 173

) \Gamma  ` xae:2 ) [xae:1=x0]B\Phi \Gamma ;x

0:B\Phi \Gamma 

12 . By Theorem 9.2.6,

\Gamma  ` [xae:1=x0]B\Phi \Gamma ;x

0:B\Phi \Gamma 

12 = ([xae:1=x0]B2)\Phi \Gamma  :: \Omega . Hence, by P-MOVE,

\Gamma  ` xae:2 ) ([xae:1=x0]B2)\Phi \Gamma . Applying the induction hypothesis gives us that
\Gamma  ` xaeae:200 ) S([xae:1=x0]B2; xae:2; ae00)\Phi \Gamma  ) \Gamma  ` xaeae:200 ) S(B; xae; :2ae00)\Phi \Gamma .

2

Relating stamping and the append operator for assignments requires defining a notion
of extended stamping for assignments. Extended stamping (\Gamma 0\Phi \Gamma ) takes an additional
argument that represents the result of stamping the preceding assignment. The desired
result is then Lemma 9.2.9 below:

Definition [Mixed] 9.2.8 (Extended Stamping)

ffl\Phi \Gamma  = ffl
(\Gamma 0; D)\Phi \Gamma  = \Gamma 0\Phi \Gamma ; D\Phi \Gamma ;\Gamma 

0\Phi \Gamma 

(\Gamma  is a tagged assignment; everything else is from the untagged system.)
Lemma 9.2.9 (\Gamma ; \Gamma 0)\Phi  = \Gamma \Phi ; \Gamma 0\Phi \Gamma 

\Phi 

Lemma [Mixed] 9.2.10 If \Gamma \Phi \Gamma 

0 exists then dom(\Gamma \Phi \Gamma 0) = dom(\Gamma ).

(Here \Gamma  is untagged while the \Gamma 0 is tagged.)

Lemma [Mixed] 9.2.11 Suppose dom(\Gamma 2) " (dom(\Gamma 3) [ dom(\Gamma )) = ;. Then if \Gamma \Phi \Gamma 

1;\Gamma 3

exists, \Gamma \Phi \Gamma 1;\Gamma 2;\Gamma 3 = \Gamma \Phi \Gamma 1;\Gamma 3.
(Here the \Gamma  is a tagged assignment; all other variables are untagged.)

Proof: By structural induction on \Gamma  using Lemmas 9.2.4, 6.8.9, and 6.8.2 for the base
case. 2

9.3 System Correspondence
In this section I show that tag removal can be used to transform tagged judgment derivations into derivations of the corresponding untagged judgments and that stamping can be
used to transform untagged judgment derivations into derivations of the corresponding
tagged judgments. These results mean that the original judgment J is true iff the tagged
judgment J\Phi  exists and is true.

174 CHAPTER 9. TYPES: SUMMARY
Theorem [Tagged] 9.3.1 (System correspondence I)

1. If ` \Gamma  valid then (` \Gamma  valid)\Psi .
2. If \Gamma  ` A :: K then (\Gamma  ` A :: K)\Psi .
3. If \Gamma  ` xae ) A then (\Gamma  ` xae ) A)\Psi .
4. If \Gamma  ` A1 = A2 :: K then (\Gamma  ` A1 = A2 :: K)\Psi .

Proof: By simultaneous structural induction on the length of the typing derivations,
using lemma 9.1.3 as needed. Example cases:

DECL-T: Given ` \Gamma ; x:A valid derived via rule DECL-T from \Gamma  ` A :: \Omega  and x 62 dom(\Gamma ).

Applying the induction hypothesis gives us that \Gamma \Psi  ` A\Psi  :: \Omega . By Lemma 9.1.3, x 62
dom(\Gamma \Psi ) so by rule DECL-T, we have that ` \Gamma \Psi ; x:A\Psi  valid ) (` \Gamma ; x:A valid)\Psi .

C-EXT-T2: Given \Gamma  ` xaeAae0! :: K derived via rule C-EXT-T2 from \Gamma  ` xaeae0 ) !=A0::K? and

\Gamma  ` xae ) A. Applying the induction hypothesis gives us that
\Gamma \Psi  ` xaeae0 ) !=A0\Psi ::K?. Hence, by C-EXT-T, \Gamma \Psi  ` xaeae0! :: K ) (\Gamma  ` xaeAae0! :: K)\Psi .

P-INIT: Given \Gamma  ` x ) A derived via rule P-INIT from ` \Gamma  valid and x:A 2 \Gamma . Applying

the induction hypothesis gives us that ` \Gamma \Psi  valid. By Lemma 9.1.3, x:A\Psi  2 \Gamma \Psi .
Hence, by P-INIT, \Gamma \Psi  ` x ) A\Psi  ) (\Gamma  ` x ) A)\Psi .

E-BETA: Given \Gamma  ` (*ff::K: A) A0 = [A0=ff]A :: K0 derived via rule E-BETA from

\Gamma ; ff::K ` A :: K0 and \Gamma  ` A0 :: K. Applying the induction hypothesis gives us
that \Gamma \Psi ; ff::K ` A\Psi  :: K0 and \Gamma \Psi  ` A0\Psi  :: K. Since [A0\Psi =ff]A\Psi  = ([A0=ff]A)\Psi  by
Lemma 9.1.3, by rule E-BETA we have that \Gamma \Psi  ` ((*ff::K: A) A0)\Psi  = ([A0=ff]A)\Psi  :: K0
) (\Gamma  ` (*ff::K: A) A0 = [A0=ff]A :: K0)\Psi .

E-EXT2: Given \Gamma  ` xaeA

1 ae

0ae00! = xaeae0A

2 ae

00! :: K derived via rule E-EXT2 from

\Gamma  ` xaeA

1ae

0ae00! :: K, \Gamma  ` A1 = A :: \Omega , and S(A; xae; ae0) = A2. Applying the induction hypothesis gives us that \Gamma \Psi  ` xaeae0ae00! :: K. Hence, by E-REFL,
\Gamma \Psi  ` xaeae0ae00! = xaeae0ae00! :: K ) (\Gamma  ` xaeA

1ae

0ae00! = xaeae0A

2ae

00! :: K)\Psi .

E-ABBREV2: Given \Gamma  ` xaeA! = A0 :: K derived via rule E-ABBREV2 from \Gamma  ` xaeA! :: K and

\Gamma  ` A = !=A0::K0? :: \Omega . By Lemma 7.6.5, \Gamma  ` xae ) A is a sub-derivation of
\Gamma  ` xaeA! :: K. Applying the induction hypothesis then gives us that \Gamma \Psi  ` xae! :: K,
\Gamma \Psi  ` xae ) A\Psi , and \Gamma \Psi  ` A\Psi  = !=A0\Psi ::K0? :: \Omega . Hence, by E-ABBREV,
\Gamma \Psi  ` xae! = A0\Psi  :: K ) (\Gamma  ` xaeA! = A0 :: K)\Psi .

9.3. SYSTEM CORRESPONDENCE 175

2

Theorem 9.3.2 (System correspondence II)

1. If ` \Gamma  valid then (` \Gamma  valid)\Phi .
2. If \Gamma  ` A :: K then (\Gamma  ` A :: K)\Phi .
3. If \Gamma  ` xae ) A then (\Gamma  ` xae ) A)\Phi .
4. If \Gamma  ` A1 = A2 :: K then (\Gamma  ` A1 = A2 :: K)\Phi .
Proof: By simultaneous structural induction on the derivations. Existence of the various
stamped items is shown using Theorem 9.2.2. Example cases:

DECL-T: Given ` \Gamma ; x:A valid derived via rule DECL-T from \Gamma  ` A :: \Omega  and x 62 dom(\Gamma ).

Applying the induction hypothesis gives us that \Gamma \Phi  ` A\Phi \Gamma 

\Phi  :: \Omega . By Theorem 9.2.2,

dom(\Gamma ) = dom(\Gamma \Phi ) ) x 62 dom(\Gamma \Phi ). Hence, by DECL-T, ` \Gamma \Phi ; x:A\Phi \Gamma 

\Phi  valid )

` (\Gamma ; x:A)\Phi  valid.
C-DFUN: Given \Gamma  ` \Pi x:A: A0 :: \Omega  derived via rule C-DFUN from \Gamma ; x:A ` A0 :: \Omega . Applying

the induction hypothesis gives us that \Gamma \Phi ; x:A\Phi \Gamma 

\Phi  ` A0\Phi \Gamma \Phi ;x:A\Phi \Gamma 

\Phi 

:: \Omega 

) \Gamma \Phi  ` \Pi x:A\Phi \Gamma 

\Phi  : A0\Phi \Gamma \Phi ;x:A\Phi \Gamma 

\Phi 

:: \Omega  (C-DFUN) ) \Gamma \Phi  ` (\Pi x:A: A0)\Phi \Gamma 

\Phi  :: \Omega .

C-EXT-T: Given \Gamma  ` xae! :: K derived from \Gamma  ` xae ) !=A::K?. Applying the induction hypothesis gives us that \Gamma \Phi  ` xae ) !=A\Phi \Gamma 

\Phi  ::K?. By Theorem 6.8.3, ` \Gamma \Phi  valid.

By Theorem 6.8.5, x 2 dom(\Gamma \Phi ). Hence, by P-INIT, \Gamma \Phi  ` x ) \Gamma \Phi (x). By C-EXTT2 then, \Gamma \Phi  ` x\Gamma \Phi (x)ae! :: K ) \Gamma \Phi  ` (xae!)\Phi \Gamma 

\Phi  :: K.

P-INIT: Given \Gamma  ` x ) A derived via rule P-INIT from ` \Gamma  valid and x:A 2 \Gamma . Applying

the induction hypothesis gives us that ` \Gamma \Phi  valid. By Lemma 9.2.4, x:A\Phi \Gamma 

\Phi  2 \Gamma \Phi .

Hence, by P-INIT, \Gamma \Phi  ` x ) A\Phi \Gamma 

\Phi .

P-MOVE: Given \Gamma  ` xaeae0 ) A00 derived via rule P-MOVE from \Gamma  ` xae ) A,

\Gamma  ` A = A0 :: \Omega , and S(A0; xae; ae0) = A00. Applying the induction hypothesis gives

us that \Gamma \Phi  ` xae ) A\Phi \Gamma 

\Phi  and \Gamma \Phi  ` A\Phi \Gamma \Phi  = A0\Phi \Gamma \Phi  :: \Omega  ) \Gamma \Phi  ` xae ) A0\Phi \Gamma \Phi  (PMOVE). By Theorem 9.2.2, A00\Phi \Gamma 

\Phi  = S(A0; xae; ae0)\Phi \Gamma \Phi  exists. Hence, by Theorem 9.2.7, \Gamma \Phi  ` xaeae0 ) A00\Phi \Gamma 

\Phi  .

176 CHAPTER 9. TYPES: SUMMARY
E-BETA: Given \Gamma  ` (*ff::K: A) A0 = [A0=ff]A :: K0 derived via rule E-BETA from

\Gamma ; ff::K ` A :: K0 and \Gamma  ` A0 :: K ) FTV(A) ` dom(\Gamma ; ff::K) and
FTV(A0) ` dom(\Gamma ) (Theorem 6.5.6). By Theorems 6.3.5 and 6.5.9, ff 62 FCV(\Gamma ).

Hence, by Theorem 9.2.4, [A0\Phi \Gamma =ff]A\Phi \Gamma ;ff::K = ([A0=ff]A)\Phi \Gamma . Applying the induction hypothesis gives us that \Gamma \Phi ; ff::K ` A\Phi \Gamma 

\Phi ;ff::K :: K0 and \Gamma \Phi  ` A0\Phi \Gamma \Phi  :: K

) \Gamma \Phi  ` (*ff::K: A\Phi \Gamma 

\Phi ;ff::K )A0\Phi \Gamma \Phi  = [A0\Phi \Gamma \Phi =ff](A\Phi \Gamma \Phi ;ff::K ) :: K0

(E-BETA) ) \Gamma \Phi  ` ((*ff::K: A) A0)\Phi \Gamma 

\Phi  = ([A0=ff]A)\Phi \Gamma \Phi  :: K0.

E-ETA: Given \Gamma  ` *ff::K: A ff = A :: K)K 0, ff 62 dom(\Gamma ), derived via rule E-ETA from

\Gamma  ` A :: K)K0 and ff 62 FCV(A). Applying the induction hypothesis gives us that

\Gamma \Phi  ` A\Phi \Gamma 

\Phi  :: K )K0. By Theorem 9.2.2, dom(\Gamma ) = dom(\Gamma \Phi ) ) ff 62 dom(\Gamma \Phi ).

By Theorem 6.8.7, FCV(A\Phi \Gamma 

\Phi ) ` dom(\Gamma \Phi ) ) ff 62 FCV(A\Phi \Gamma \Phi  ). By Lemma 9.2.4,

A\Phi \Gamma 

\Phi  = A\Phi \Gamma \Phi ;ff::K . Hence, by E-ETA, \Gamma \Phi  ` *ff::K: A\Phi \Gamma \Phi ;ff::K ff = A\Phi \Gamma \Phi  :: K)K0

) \Gamma \Phi  ` (*ff::K: A ff)\Phi \Gamma 

\Phi  = A\Phi \Gamma \Phi  :: K)K0

E-ABBREV: Given \Gamma  ` xae! = A0 :: K derived via rule E-ABBREV from \Gamma  ` xae! :: K, \Gamma  ` xae ) A,

and \Gamma  ` A = !=A0::K0? :: \Omega . Applying the induction hypothesis gives us that

\Gamma \Phi  ` x\Gamma \Phi (x)ae! :: K, \Gamma \Phi  ` xae ) A\Phi \Gamma 

\Phi , and \Gamma \Phi  ` A\Phi \Gamma \Phi  = !=A0\Phi \Gamma \Phi ::K0? :: \Omega . By

Lemmas 7.6.5 and 9.1.6, \Gamma \Phi  ` x\Gamma \Phi (x)ae! = xaeA

\Phi \Gamma 

\Phi  ! :: K. By Theorem 7.6.10 and

E-ABBREV2, \Gamma \Phi  ` xaeA

\Phi \Gamma 

\Phi  ! = A0\Phi \Gamma 

\Phi  :: K. The desired result then follows via

E-TRAN.

2

Theorem 9.3.3 (System correspondence III)

1. ` \Gamma  valid iff ` \Gamma \Phi  valid.
2. \Gamma  ` A :: K iff \Gamma \Phi  ` A\Phi \Gamma 

\Phi  :: K.

3. \Gamma  ` xae ) A iff \Gamma \Phi  ` xae ) A\Phi \Gamma 

\Phi .

4. \Gamma  ` A1 = A2 :: K iff \Gamma \Phi  ` A\Phi \Gamma 

\Phi 

1 = A

\Phi \Gamma 

\Phi 

2 :: K.

Proof: Follows from the two previous system correspondence theorems and the cancellation of stamping lemma. 2

9.4. CONVERTED RESULTS 177
9.4 Converted Results
In this section I use the results of the previous three sections to transfer many results
for the tagged system, which were proved in the previous three chapters, to the original
untagged system. The following results come from Chapter 6:

Theorem 9.4.1 (Weakening)

Suppose ` \Gamma ; \Gamma 0 valid and dom(\Gamma 0) " dom(\Gamma 00) = ;. Then:

1. If ` \Gamma ; \Gamma 00 valid then ` \Gamma ; \Gamma 0; \Gamma 00 valid.
2. If \Gamma ; \Gamma 00 ` A :: K then \Gamma ; \Gamma 0; \Gamma 00 ` A :: K.
3. If \Gamma ; \Gamma 00 ` xae ) A then \Gamma ; \Gamma 0; \Gamma 00 ` xae ) A.
4. If \Gamma ; \Gamma 00 ` A1 = A2 :: K then \Gamma ; \Gamma 0; \Gamma 00 ` A1 = A2 :: K.
Proof: The proof of each part is similar. I give here only the proof for part one. Given
` \Gamma ; \Gamma 0 valid and ` \Gamma ; \Gamma 00 valid ) ` (\Gamma ; \Gamma 0)\Phi  valid and ` (\Gamma ; \Gamma 00)\Phi  valid (Theorem 9.3.3)

) ` \Gamma \Phi ; \Gamma 0\Phi \Gamma 

\Phi  valid and ` \Gamma \Phi ; \Gamma 00\Phi \Gamma \Phi  valid (Lemma 9.2.9) ) dom(\Gamma 0\Phi \Gamma \Phi ) = dom(\Gamma 0)

and dom(\Gamma 00\Phi \Gamma 

\Phi  ) = dom(\Gamma 00) (Lemma 9.2.10) ) dom(\Gamma 0\Phi \Gamma \Phi  ) " dom(\Gamma 00\Phi \Gamma \Phi ) = ; )

` \Gamma \Phi ; \Gamma 0\Phi \Gamma 

\Phi ; \Gamma 00\Phi \Gamma \Phi  valid (Theorem 6.8.10) ) ` (\Gamma \Phi ; \Gamma 0\Phi \Gamma \Phi ; \Gamma 00\Phi \Gamma \Phi )\Psi  valid (Theorem 9.3.1)

) ` (\Gamma \Phi )\Psi ; (\Gamma 0\Phi \Gamma 

\Phi )\Psi ; (\Gamma 00\Phi \Gamma \Phi )\Psi  valid (Lemma 9.1.5)

) ` \Gamma ; \Gamma 0; \Gamma 00 valid (Lemma 9.2.3) 2

Lemma 9.4.2 (Valid assignment properties)

Suppose ` \Gamma  valid. Then:

1. If ff::K 2 \Gamma  and ff::K 0 2 \Gamma  then K = K0.
2. If x:A 2 \Gamma  then \Gamma (x) = A.
3. If x 2 dom(\Gamma ) then \Gamma  ` \Gamma (x) :: \Omega .
Proof: Inspection of the typing rules for assignments combined with the results from
Lemma 6.8.3 reveal that valid assignments never redeclare variables. The last part requires weakening (Theorem 9.4.1) plus repeated use of Lemma 6.3.5. 2

The next set of results are from Chapter 7:
Theorem 9.4.3 (Validity of equal constructors)

If \Gamma  ` A1 = A2 :: K then \Gamma  ` A1 :: K and \Gamma  ` A2 :: K.

178 CHAPTER 9. TYPES: SUMMARY
Theorem 9.4.4 (Validity of looked up places)

If \Gamma  ` xae ) A then \Gamma  ` A :: \Omega .

Theorem 9.4.5 (Uniqueness of constructor kind)

If \Gamma  ` A :: K1 and \Gamma  ` A :: K2 then K1 = K2.

Proof: By Theorems 7.6.11 and 9.3.3. 2

Theorem 9.4.6 (Replacement by an equal type)

Suppose \Gamma  ` A1 = A2 :: \Omega . Then:

1. If ` \Gamma ; x:A1; \Gamma 0 valid then ` \Gamma ; x:A2; \Gamma 0 valid.
2. If \Gamma ; x:A1; \Gamma 0 ` A :: K then \Gamma ; x:A2; \Gamma 0 ` A :: K.
3. If \Gamma ; x:A1; \Gamma 0 ` x0ae ) A then \Gamma ; x:A2; \Gamma 0 ` x0ae ) A.
4. If \Gamma ; x:A1; \Gamma 0 ` A = A0 :: K then \Gamma ; x:A2; \Gamma 0 ` A = A0 :: K.

Proof: By Theorem 9.4.3, \Gamma  ` A2 :: \Omega . Convert to the tagged system via stamping
(Theorem 9.3.3 and Lemma 9.2.9), then apply the tagged version of the theorem (Theorem 7.6.9), then return to the original system via tag removal and cancellation (Theorem 9.3.1, Lemma 9.2.3, Lemma 9.1.3, and Lemma 9.1.5). 2

Theorem 9.4.7 (Validity of place substitution)

Suppose \Gamma  ` xae ) A0. Then:

1. If ` \Gamma ; x0:A0; \Gamma 0 valid then ` \Gamma ; [xae=x0]\Gamma 0 valid.
2. If \Gamma ; x0:A0; \Gamma 0 ` A :: K then \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]A :: K.
3. If \Gamma ; x0:A0; \Gamma 0 ` x00ae00 ) A then \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]x00ae00 ) [xae=x0]A.
4. If \Gamma ; x0:A0; \Gamma 0 ` A1 = A2 :: K then \Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]A1 = [xae=x0]A2 :: K.

Proof: Convert to the tagged system via stamping (Theorem 9.3.3 and Lemma 9.2.9),
then apply the tagged version of the theorem (Theorem 7.6.12), then return to the original system via tag removal and cancellation (Theorem 9.3.1, Lemma 9.2.3, Lemma 9.1.3,
and Lemma 9.1.5). 2

9.4. CONVERTED RESULTS 179
Theorem 9.4.8 (Strengthening)

If \Gamma 1; x:A; \Gamma 2 ` A1 = A2 :: K, \Gamma 1; \Gamma 2 ` A1 :: K, and \Gamma 1; \Gamma 2 ` A2 :: K then
\Gamma 1; \Gamma 2 ` A1 = A2 :: K.

Proof: Convert to the tagged system via stamping (Theorem 9.3.3 and Lemma 9.2.9),
observe that \Gamma \Phi (\Gamma 

1;x:A)\Phi 2 = \Gamma \Phi \Gamma 

\Phi 
12 and A\Phi (\Gamma 1;x:A;\Gamma 2)\Phi i = A\Phi (\Gamma 1;\Gamma 2)\Phi i (Lemmas 9.2.10,

6.8.9, 6.8.3, 9.2.11, and 9.2.4), then apply the tagged version of the lemma (Lemma 7.8.6),
then return to the original system via tag removal and cancellation (Theorem 9.3.1 and
Lemma 9.2.3). 2

Lemma 9.4.9 (Equality of forms)

Suppose \Gamma  ` A1 = A2 :: K and A2 has neither the form A02 A002, A02 62 fref; recg, the form
xae!, nor the form *ff::K: A01. Then

1. If A1 has one of the forms ff, !K?, rec, or ref then A1 = A2.
2. If A1 has the form \Pi x:A01: A001 then A2 has the form \Pi x:A02: A002.
3. If A1 has the form \Sigma x:A01: A001 then A2 has the form \Sigma x:A02: A002.
4. If A1 has the form !=A01::K? then A2 has the form !=A02::K?.
5. If A1 has the form ref A01 then A2 has the form ref A02.
6. If A1 has the form rec A01 then A2 has the form rec A02.

Proof: Convert to the tagged system via stamping (Theorem 9.3.3), then apply the
tagged version of the lemma (Lemma 7.8.7), then return to the original system via tag
removal and cancellation (Theorem 9.3.1 and Lemma 9.2.3). Note that both stamping
and tag removal preserve forms. 2

Lemma 9.4.10 (Component-wise equality)

1. If \Gamma  ` \Pi x:A1: A2 = \Pi x:A01: A02 :: \Omega , x 62 dom(\Gamma ), then

\Gamma  ` A1 = A01 :: \Omega  and \Gamma ; x:A1 ` A2 = A02 :: \Omega .

2. If \Gamma  ` \Sigma x:A1: A2 = \Sigma x:A01: A02 :: \Omega , x 62 dom(\Gamma ), then

\Gamma  ` A1 = A01 :: \Omega  and \Gamma ; x:A1 ` A2 = A02 :: \Omega .

3. If \Gamma  ` !K? = !K0? :: \Omega  then K = K0.

180 CHAPTER 9. TYPES: SUMMARY

4. If \Gamma  ` !=A::K? = !=A0::K0? :: \Omega  then

K = K0 and \Gamma  ` A = A0 :: K.

5. If \Gamma  ` ref A = ref A0 :: \Omega  then \Gamma  ` A = A0 :: \Omega .
6. If \Gamma  ` rec A = rec A0 :: \Omega  then \Gamma  ` A = A0 :: \Omega )\Omega .

Proof: Convert to the tagged system via stamping (Theorems 9.3.3 and 9.2.2), then
apply the tagged version of the lemma (Lemma 7.8.8), then return to the original system
via tag removal and cancellation (Theorem 9.3.1 and Lemma 9.2.3). 2

Finally, these results are from Chapter 8:

Theorem 9.4.11 (Decidability of judgments)

The following judgments are decidable:

1. ` \Gamma  valid
2. \Gamma  ` A :: K
3. \Gamma  ` xae ) A
4. \Gamma  ` A = A0 :: K

Proof: Follows from Theorem 9.3.3, Corollary 8.6.10, and the fact that the stamping
process always terminates. The later is proved by structural induction on the item being
stamped. 2

Corollary 9.4.12 (Kind Inference) A recursive algorithm A exists such that

1. If \Gamma  ` A :: K then A(\Gamma ; A) returns K.
2. If :9K: \Gamma  ` A :: K then A(\Gamma ; A) raises fail

Proof: Follows from Theorem 9.3.3, Corollary 8.6.11, and the fact that the stamping
process always terminates. The later is proved by structural induction on the item being
stamped. 2

9.5. SEMI-CANONICAL TYPES 181
9.5 Semi-Canonical Types
In this section I transfer the useful results about tagged constructors in canonical form
from Chapter 8 to the original untagged system. I shall do this by introducing semicanonical types, an untagged analogue of types in canonical form. A type is a semicanonical type (roughly) if it is the result of removing the tags from a valid tagged type
in canonical form:

Definition 9.5.1 (Semi-canonical Types)
A is a semi-canonical type under assignment \Gamma  (A 2 C\Gamma ) iff there exists a tagged constructor B such that:

1. B\Psi  = A
2. \Gamma \Phi  ` B :: \Omega 
3. B is in canonical form

Note that unlike in the tagged case, the notion of a semi-canonical type is relative to
an assignment. For example, x! is a semi-canonical type under x:!\Omega ? but not under
x:!=!\Omega ?::\Omega ?. This reflects the fact that equality (and hence any related notion of
rewriting) depends on the assignment in the untagged system but not in the tagged
system.

Some properties about semi-canonical types follow immediately from the definition.
Note that stamping a semi-canonical type does not necessarily yield a canonical type
because stamping does not in general attach the right tags.

Lemma 9.5.2 (Semi-canonical properties)

If A 2 C\Gamma  then

1. \Gamma  ` A :: \Omega 
2. \Gamma \Phi  ` B = A\Phi \Gamma 

\Phi  :: \Omega 

where B is the tagged constructor from the definition of A 2 C\Gamma .
Proof: By the definition of A 2 C\Gamma , B\Psi  = A and \Gamma \Phi  ` B :: \Omega . By Theorem 9.3.1 and
Lemma 9.2.3, \Gamma  ` B\Psi  :: \Omega  ) \Gamma  ` A :: \Omega  ) \Gamma \Phi  ` A\Phi \Gamma 

\Phi  :: \Omega  (Theorem 9.3.3). Hence, by

Theorem 9.1.8 and Lemma 9.2.3, \Gamma \Phi  ` B = A\Phi \Gamma 

\Phi  :: \Omega .

2

In order to keep the proofs modular, I shall treat the definition of semi-canonical
types like an abstract data type; that is, I shall provide sufficient propositions about

182 CHAPTER 9. TYPES: SUMMARY
semi-canonical types in this section so that it will not be necessary to refer to the tagged
system or the details of this definition again after this chapter.

The following two lemmas formalize the fact that semi-canonical sums are built from
semi-canonical components. The equivalent statements for the tagged system involving
canonical forms follow immediately from the definition of canonical form.

Lemma 9.5.3 If \Sigma x:A1: A2 2 C\Gamma , x 62 dom(\Gamma ) then A1 2 C\Gamma  and A2 2 C\Gamma ;x:A

1 .

Proof: By the definition of \Sigma x:A1: A2 2 C\Gamma , there exists a tagged constructor B such
that B\Psi  = \Sigma x:A1: A2, \Gamma \Phi  ` B :: \Omega , and B is in canonical form ) B = \Sigma x:B1: B2 for
some tagged constructors B1 and B2 such that B\Psi 1 = A1 and B\Psi 2 = A2 (inspection of the
definition of tag removal) ) \Gamma \Phi  ` B1 :: \Omega  and \Gamma \Phi ; x:B1 ` B2 :: \Omega  (C-DSUM and Theorem 9.2.2) By inspection of the definition of canonical form, B1 and B2 must also in
canonical form because they are sub-constructors of a canonical constructor ) A1 2 C\Gamma .

By Lemma 9.5.2, \Gamma  ` \Sigma x:A1: A2 :: \Omega  ) \Gamma  ` A1 :: \Omega  (C-DSUM) ) \Gamma \Phi  ` A\Phi \Gamma 

\Phi 

1 :: \Omega  (Theorem 9.3.3) ) \Gamma \Phi  ` A\Phi \Gamma 

\Phi 

1 = B1 :: \Omega  (Theorem 9.1.8 and Lemma 9.2.3)

) \Gamma \Phi ; x:A\Phi \Gamma 

\Phi 

1 ` B2 :: \Omega  (Theorem 9.4.6) ) (\Gamma ; x:A1)\Phi  ` B2 :: \Omega  ) A2 2 C\Gamma ;x:A1 . 2

Lemma 9.5.4 If A1 2 C\Gamma , A2 2 C\Gamma ;x:A

1, x 62 dom(\Gamma ), then \Sigma x:A1: A2 2 C\Gamma .

Proof: By the definition of semi-canonical types, 9 tagged constructors B1 and B2
such that B\Psi 1 = A1, B\Psi 2 = A2, \Gamma \Phi  ` B1 :: \Omega , \Gamma \Phi ; x:A\Phi \Gamma 

\Phi 

1 ` B2 :: \Omega , and B1 and B2are in canonical form ) \Sigma x:B
1: B2 is in canonical form (definition of canonical form),

(\Sigma x:B1: B2)\Psi  = \Sigma x:A1: A2, and \Gamma \Phi  ` A\Phi \Gamma 

\Phi 

1 :: \Omega  (DECL-T and Lemma 6.3.5)

) \Gamma \Phi  ` A\Phi \Gamma 

\Phi 

1 = B1 :: \Omega  (Theorem 9.1.8) ) \Gamma 

\Phi ; x:B1 ` B2 :: \Omega , (Theorem 7.6.9 and Theorem 7.6.10) ) \Gamma \Phi  ` \Sigma x:B1: B2 :: \Omega  (C-DSUM) ) \Sigma x:A1: A2 2 C\Gamma . 2

The following lemma allows weakening the assignment a semi-canonical type is relative
to:

Lemma 9.5.5 (Weakening)

If A 2 C\Gamma 

1;\Gamma 3, ` \Gamma 1; \Gamma 2 valid, and dom(\Gamma 2) " dom(\Gamma 3) = ; then A 2 C\Gamma 1;\Gamma 2;\Gamma 3.

Proof: By the definition of A 2 C\Gamma 

1;\Gamma 3, 9B such that B

\Psi  = A, \Gamma \Phi 1 ; \Gamma \Phi \Gamma 

\Phi 
13 ` B :: \Omega ,

and B is in canonical form. By Theorem 9.3.3 and Lemma 9.2.9, ` \Gamma \Phi 1 ; \Gamma \Phi \Gamma 

\Phi 
12 valid

) \Gamma \Phi ; \Gamma \Phi \Gamma 

\Phi 
12 ; \Gamma \Phi \Gamma 

\Phi 
13 ` B :: \Omega  (Lemma 9.2.10 and Theorem 6.8.10). By Lemma 9.2.11,

9.5. SEMI-CANONICAL TYPES 183
\Gamma \Phi \Gamma 

\Phi 
13 = \Gamma \Phi \Gamma 

\Phi 
1 ;\Gamma 

\Phi \Gamma 

\Phi 

1
23 ) (\Gamma 1; \Gamma 2; \Gamma 3)\Phi  ` B :: \Omega  ) A 2 C\Gamma 

1;\Gamma 2;\Gamma 3 (by definition). 2

The following propositions are transfered from Sections 8.4 and 8.6 using the results
from Sections 9.1 to 9.3:

Lemma 9.5.6 If A 2 C\Gamma , \Gamma  ` xae ) A, and S(A; xae; ae0) exists then
S(A; xae; ae0) 2 C\Gamma .

Proof: By the definition of A 2 C\Gamma , there exists a tagged constructor B such that
B\Psi  = A, \Gamma \Phi  ` B :: \Omega , and B is in canonical form. By Lemma 9.1.4, S(B; xae; ae0) exists. By Theorem 9.3.3, \Gamma \Phi  ` xae ) A\Phi \Gamma 

\Phi  ) \Gamma \Phi  ` xae ) B (P-MOVE, E-SYM, and

Lemma 9.5.2) ) \Gamma \Phi  ` S(B; xae; ae0) :: \Omega  (Theorems 7.6.13 and7.6.14). By Lemma 9.1.3,
S(B; xae; ae0)\Psi  = S(B\Psi ; xae; ae0) = S(A; xae; ae0). By Lemma 8.4.6, S(B; xae; ae0) is in canonical form. Hence, S(A; xae; ae0) 2 C\Gamma . 2

Lemma 9.5.7 (Shape Pullback)

Suppose \Gamma  ` A1 = A2 :: \Omega  and A1 2 C\Gamma . Then:

1. If A2 = ff, A2 = ref, A2 = rec, or A2 = !K? then A1 = A2.
2. If A2 = \Pi x:A02: A002 then 9A01; A001: A1 = \Pi x:A01: A001.
3. If A2 = \Sigma x:A02: A002 then 9A01; A001: A1 = \Sigma x:A01: A001.
4. If A2 = !=A02::K? then 9A01: A1 = !=A01::K?.
5. If A2 = ref A02 then 9A01: A1 = ref A01.
6. If A2 = rec A02 then 9A01: A1 = rec A01.

Proof: By Theorem 9.3.3, \Gamma \Phi  ` A\Phi \Gamma 

\Phi 

1 = A

\Phi \Gamma 

\Phi 

2 :: \Omega . By the definition of A1 2 C\Gamma ,there exists a tagged constructor B such that B\Psi  = A

1 and B is in canonical form. By

Lemma 9.5.2, \Gamma \Phi  ` B = A\Phi \Gamma 

\Phi 

1 :: \Omega  ) \Gamma 

\Phi  ` B = A\Phi \Gamma 

\Phi 

2 :: \Omega  (E-TRAN). The desired re-sults follows from Lemma 8.4.10 and the fact that the form of a constructor is unaffected

by stamping and tag removal. 2

Lemma 9.5.8 (Pullback)

If A 2 C\Gamma , \Gamma  ` A = A0 :: \Omega , \Gamma  ` xae ) A0, and S(A0; xae; ae0) exists then
\Gamma  ` S(A; xae; ae0) = S(A0; xae; ae0) :: \Omega .

184 CHAPTER 9. TYPES: SUMMARY
Proof: By Theorem 9.3.3, \Gamma \Phi  ` A\Phi \Gamma 

\Phi  = A0\Phi \Gamma \Phi  :: \Omega  and \Gamma \Phi  ` xae ) A0\Phi \Gamma \Phi . By Lemmas 9.1.4 and 9.2.3, S(A0\Phi \Gamma 

\Phi ; xae; ae0) exists. Hence by Theorems 7.6.13 and7.6.14,

\Gamma \Phi  ` S(A0\Phi \Gamma 

\Phi ; xae; ae0) :: \Omega . By the definition of A 2 C

\Gamma , there exists a tagged constructorB such that B\Psi  = A, \Gamma \Phi  ` B :: \Omega , and B is in canonical form. Hence, by Lemma 9.5.2,

\Gamma \Phi  ` B = A\Phi \Gamma 

\Phi  :: \Omega  ) \Gamma \Phi  ` B = A0\Phi \Gamma \Phi  :: \Omega  (E-TRAN). Hence by Lemma 8.4.12,

\Gamma \Phi  ` S(B; xae; ae0) = S(A0\Phi \Gamma 

\Phi  ; xae; ae0) :: \Omega  ) \Gamma  ` S(B\Psi ; xae; ae0) = S(A0; xae; ae0) :: \Omega  (Theorem 9.3.1 and Lemma 9.2.3) ) \Gamma  ` S(A; xae; ae0) = S(A0; xae; ae0) :: \Omega . 2

Lemma 9.5.9 If \Gamma 1; x:A1; \Gamma 2 ` xae ) A and A1 2 C\Gamma 

1 then\Gamma 

1; x:A1; \Gamma 2 ` A = S(A1; x; ae) :: \Omega  and S(A1; x; ae) 2 C\Gamma 1;x:A1;\Gamma 2 .

Proof: Let \Gamma  = \Gamma 1; x:A1; \Gamma 2. By Theorem 9.3.3 and Lemma 9.2.9,
\Gamma \Phi 1 ; x:A\Phi \Gamma 

\Phi 
11 ; \Gamma \Phi (\Gamma 1;x:A1)\Phi 2 ` xae ) A\Phi \Gamma 

\Phi . By the definition of A

1 2 C\Gamma 1 and Lemma 9.5.2,

9B: B\Psi  = A1, B in canonical form, and \Gamma \Phi 1 ` B = A\Phi \Gamma 

\Phi 
11 :: \Omega 

) \Gamma \Phi 1 ; x:B; \Gamma \Phi (\Gamma 

1;x:A1)\Phi 2 ` xae ) A\Phi \Gamma 

\Phi  (Theorems 7.6.9 and 7.6.10).

Hence, by Lemmas 6.8.11 and 8.4.13, \Gamma \Phi 1 ; x:B; \Gamma \Phi (\Gamma 

1;x:A1)\Phi 2 ` A\Phi \Gamma 

\Phi  = S(B; x; ae) :: \Omega 

and S(B; x; ae) is in canonical form ) \Gamma \Phi  ` A\Phi \Gamma 

\Phi  = S(B; x; ae) :: \Omega  (Theorems 7.6.9

and 7.6.10) ) \Gamma \Phi  ` S(B; x; ae) :: \Omega  (Theorem 7.6.10) ) S(A1; x; ae) 2 C\Gamma  (definition
of a semi-canonical type and Lemma 9.1.3). By Theorem 9.3.1, Lemma 9.1.3, and
Lemma 9.2.3, \Gamma  ` A = S(A1; x; ae) :: \Omega . 2

Theorem 9.5.10 (Computability of semi-canonical types) If \Gamma  ` A :: \Omega  then a constructor A0 is (recursively) computable such that \Gamma  ` A = A0 :: \Omega  and A0 2 C\Gamma .

Proof: By Theorem 9.3.3, \Gamma \Phi  ` A\Phi \Gamma 

\Phi  :: \Omega . By Theorem 8.6.12, we can compute a

tagged constructor B such that \Gamma \Phi  ` A\Phi \Gamma 

\Phi  = B :: \Omega  and B is in canonical form )

\Gamma \Phi  ` B :: \Omega  (Theorem 6.3.5) and \Gamma  ` A = B\Psi  :: \Omega  (Theorem 9.3.1 and Lemma 9.2.3)
) B\Psi  2 C\Gamma . (Note that tag removal is computable; this is easily proved by structural
induction on the item undergoing tag removal.) 2

The last two lemmas of this section formalize when x! is in semi-canonical form and
that semi-canonical types for a given type under a given assignment are unique:

Lemma 9.5.11 If \Gamma  ` x! :: \Omega  and \Gamma (x) = !\Omega ? then x! 2 C\Gamma .

9.6. STRENGTHENING 185
Proof: By Lemma 9.2.4, (x:!\Omega ?)\Phi \Gamma 

\Phi  2 \Gamma \Phi  ) \Gamma \Phi (x) = !\Omega ? (Lemma 6.3.5, Theorem 9.3.3, and Lemma 9.4.2) ) \Gamma \Phi  ` x!\Omega ?! :: \Omega  (Theorem 9.3.3). By the definition
of canonical form, x!\Omega ?! is in canonical form ) x! 2 C\Gamma  (definition of semi-canonical
types). 2

Lemma 9.5.12 If A1 2 C\Gamma , A2 2 C\Gamma , and \Gamma  ` A1 = A2 :: \Omega  then A1 = A2.
Proof: By the definition of Ai 2 C\Gamma , 9Bi such that B\Psi i = A, \Gamma \Phi  ` Bi :: \Omega , and
Bi is in canonical form ) \Gamma \Phi  ` Bi = A\Phi \Gamma 

\Phi 

i :: \Omega  (Lemma 9.5.2). By Theorem 9.3.3,

\Gamma \Phi  ` A\Phi \Gamma 

\Phi 

1 = A

\Phi \Gamma 

\Phi 

2 :: \Omega  ) \Gamma 

\Phi  ` B1 = B2 :: \Omega  (E-SYM and E-TRAN) ) B1 #\Lambda  B2 (Theorem 7.8.5) ) B1 = B2 (Lemma 8.1.3 and the definition of canonical form) ) B\Psi 1 = B\Psi 2
) A1 = A2 2

9.6 Strengthening
In this section I use the results about semi-canonical types to prove strengthening (removal of unreferenced declarations from an assignment) for the valid assignment, valid
constructor, and equal constructor judgments. I previously showed strengthening by
removing constructor declarations (Theorem 7.6.2 and Corollary 7.6.4); here I show
strengthening by removing term variable declarations:

Theorem 9.6.1 (Strengthening) Suppose x 62 FTV(\Gamma 0) [ FTV(A). Then:

1. If ` \Gamma ; x:A0; \Gamma 0 valid then ` \Gamma ; \Gamma 0 valid.
2. If \Gamma ; x:A0; \Gamma 0 ` A :: K then \Gamma ; \Gamma 0 ` A :: K.

Proof: By simultaneous structural induction on the typing derivations. The only
interesting cases are:

C-EXT-O: Given \Gamma ; x:A0; \Gamma 0 ` x0ae! :: K, x0 6= x, derived via rule C-EXT-O from

\Gamma ; x:A0; \Gamma 0 ` x0ae ) !K?.

Casing on the order of x and x0 in \Gamma ; x:A0; \Gamma 0 (Theorem 6.5.6 and
Lemma 9.4.2):

- x occurs first:

9\Gamma 2; \Gamma 02: \Gamma 2; x0:A1; \Gamma 2 = \Gamma 0 where A1 = (\Gamma ; x:A0; \Gamma 0)(x0).
Let \Gamma 1 = \Gamma ; x:A0; \Gamma 2, \Gamma 01 = \Gamma 02, \Gamma 0 = \Gamma ; \Gamma 2, and \Gamma 00 = \Gamma 02.

186 CHAPTER 9. TYPES: SUMMARY

- x0 occurs first:

9\Gamma 2; \Gamma 02: \Gamma 2; x0:A1; \Gamma 02 = \Gamma  where A1 = (\Gamma ; x:A0; \Gamma 0)(x0).
Let \Gamma 1 = \Gamma 2, \Gamma 01 = \Gamma 02; x:A0; \Gamma 0, \Gamma 0 = \Gamma 2 and \Gamma 00 = \Gamma 02; \Gamma 0.

Either way, \Gamma 1; x0:A1; \Gamma 01 = \Gamma ; x:A0; \Gamma 0 and \Gamma 0; x0:A1; \Gamma 00 = \Gamma ; \Gamma 0
) ` \Gamma ; x:A0; \Gamma 0 valid, ` \Gamma 1 valid, and \Gamma 1 ` A1 :: \Omega  are sub-derivations of the given
derivation (repeated use of Lemma 6.3.5 and DECL-T).

) ` \Gamma ; \Gamma 0 valid and \Gamma 0 ` A1 :: \Omega  (induction hypothesis)
By Theorem 9.5.10, 9A2: \Gamma 0 ` A1 = A2 :: \Omega  and A2 2 C\Gamma 

0

) \Gamma 1 ` A1 = A2 :: \Omega  and A2 2 C\Gamma 

1 (Lemma 6.5.10, Theorem 9.4.1, and Lemma 9.5.5)

) \Gamma 1; x0:A2; \Gamma 01 ` x0ae ) !K? (Theorem 9.4.6)

By Lemma 9.5.9 then, \Gamma 1; x0:A2; \Gamma 01 ` !K? = S(A2; x0; ae) :: \Omega  and
S(A2; x0; ae) 2 C\Gamma 

1;x0:A2;\Gamma 

0

1 ) S(A2; x

0; ae) has form !K? (E-SYM and Lemma 9.5.7).

By P-INIT, \Gamma ; \Gamma 0 ` x0 ) A1 ) \Gamma ; \Gamma 0 ` x0ae ) S(A2; x0; ae) (Theorem 9.4.1 and PMOVE) ) \Gamma ; \Gamma 0 ` x0ae ) !K? ) \Gamma ; \Gamma 0 ` x0ae! :: K (C-EXT-O).

C-EXT-T: Handled the same as the C-EXT-O case except that the form in question is !=A00::K?.

2

Corollary 9.6.2 (Strengthening)

Suppose x 62 FTV(\Gamma 0) [ FTV(A1) [ FTV(A2). Then, if \Gamma ; x:A0; \Gamma 0 ` A1 = A2 :: K, then
\Gamma ; \Gamma 0 ` A1 = A2 :: K.

Proof: By Theorems 9.4.3 and 9.6.1, \Gamma ; \Gamma 0 ` Ai :: K. The desired result then follows
from Theorem 9.4.8. 2

A useful corollary is that replacing a type with an equal semi-canonical type never
introduces new free term variables:

Corollary 9.6.3 (Non-Free Variable Pullback)

If \Gamma ; x:A ` A1 = A2 :: \Omega , A1 2 C\Gamma ;x:A, x 62 FTV(A2) then x 62 FTV(A1).

Proof: By Theorem 9.4.3, \Gamma ; x:A ` A2 :: \Omega  ) \Gamma  ` A2 :: \Omega  (Theorem 9.6.1) and ` \Gamma ; x:A valid
(Lemma 6.3.5) ) x 62 dom(\Gamma ) (DECL-T). By Theorem 9.3.3,

\Gamma \Phi ; x:A\Phi \Gamma 

\Phi  ` A\Phi \Gamma \Phi ;x:A\Phi \Gamma 

\Phi 

1 = A

\Phi \Gamma 

\Phi ;x:A\Phi \Gamma 

\Phi 

2 :: \Omega  and \Gamma 

\Phi  ` A\Phi \Gamma 

\Phi 

2 :: \Omega 

) \Gamma \Phi ; x:A\Phi \Gamma 

\Phi  ` A\Phi \Gamma \Phi ;x:A\Phi \Gamma 

\Phi 

1 = A

\Phi \Gamma 

\Phi 

2 :: \Omega  (inspection of the definition of stamping).

9.7. ALTERNATIVES 187
By the definition of A1 2 C\Gamma ;x:A, there exists a tagged constructor B such that: B\Psi  =
A1, \Gamma \Phi ; x:A\Phi \Gamma 

\Phi  ` B :: \Omega , and B is in canonical form ) \Gamma \Phi ; x:A\Phi \Gamma \Phi  ` B = A\Phi \Gamma \Phi 

2 :: \Omega 

(Lemma 9.5.2 and E-TRAN) ) \Gamma \Phi  ` B = A\Phi \Gamma 

\Phi 

2 :: \Omega  (Corollary 8.4.11) ) \Gamma  ` A1 = A2 :: \Omega (Theorem 9.3.1 and Lemma 9.2.3) ) \Gamma  ` A
1 :: \Omega  (Theorem 9.4.3) ) FTV(A1) ` dom(\Gamma )
(Theorem 6.5.6) ) x 62 FTV(A1). 2

9.7 Alternatives
I have now finished the part of the proofs devoted to constructor validity and equality.
Once I was able to reach this point in the proofs, I did not have to make any more
changes in this part of the system. I had to do considerable backtracking in the later
parts of the proofs, but I never had to back up past this point again.

Accordingly, this is a good point to stop and consider alternative formulations of the
system. The following suggestions are what I would try if I were to start the system and
proofs over again from scratch. Be warned that these are highly speculative ideas and
that although they are based on my experience, it is quite possible that they may be
found to be unusable only after months of work.

I think the biggest source of complexity in the proofs is the mutual dependency
between the valid constructor and equal constructor judgments. I suggest that this cycle
be broken by dropping the current requirement that equations may involve only valid
constructors. Let equal constructors under \Gamma  be defined as two constructors that have
the same kind under \Gamma  and that are convertible via a rewriting relation on (possibly
invalid) constructors. Under an assignment approach (cf. Section 6.2), this might result
in the following rule for equality:

\Gamma  ` A1 :: K \Gamma  ` A2 :: K
\Gamma ; x:A1 ss \Gamma ; x:A2 x 62 dom(\Gamma )

\Gamma  ` A1 = A2 :: K (EQUAL)

(Note that assignments as well as constructors have to be converted under the assignment
approach because rewriting depends on the current assignment.)

The conversion relation can then be defined directly using a rewriting relation without
any reference to the valid or equal constructor judgments. By adding the following rule,
the rewriting relation can be made confluent on (possibly invalid) constructors even in
the presence of both fi and j:

A !\Gamma ;ff::\Omega  A0
*ff::K: A !\Gamma  *ff::\Omega : A0 (ARG-KIND)

188 CHAPTER 9. TYPES: SUMMARY

This addition avoids the need to use erasure or subject reduction in order to prove confluence while preserving all the needed properties of the equality relation. This approach
also avoids the need to prove that the rewriting relation implements a separately defined
equality relation.

Ideally then, the rewriting relation could be introduced first. Only after its properties
had been proved (confluence, kind preservation, shape preservation, etc.), the valid constructor and equal constructor judgments could be introduced. This arrangement would
allow breaking up the first part of the proof into two mostly separate parts.

The ARG-KIND rule does complicate normalization somewhat. Subject reduction
will only hold if the ARG-KIND rule is excluded. This means that normalization will
have to proceed in two steps: First, normalize as before under the rewriting relation
modulo the ARG-KIND rule. Second, use ARG-KIND to change all argument kinds to
\Omega . This last step cannot enable any new reductions so we will have a normal form.

I believe the approach sketched above should be substantially simpler than the one I
used. I suggest the use of the assignment approach rather than the tagged one because
in retrospect it seems simpler.

Chapter 10
Subtyping
In this chapter I introduce the subtyping relation (\Gamma  ` A ^ A0) and prove the major
results about it: subtypes' shapes are related, judgments may be weakened by replacing
types in assignments by subtypes, subtyping acts in a component-wise manner, a semidecision procedure for deciding subtyping exists, and subtyping is undecidable. The
replacement by a subtype result will be crucial in proving soundness for the kernel system
in the next chapter because it shows that values of a subtype can be substituted where
values of a supertype are expected.

The replacement by a subtype result is hard to prove, however. One problem is that
proving it directly requires knowing that subtyping acts in a component-wise manner;
unfortunately, proving that subtyping acts in a component-wise manner requires the
replacement by a subtype result in order to handle transitivity,1 resulting in a cycle.

I shall avoid this problem by introducing a one-step subtyping relation
(\Gamma  ` A ! A0). The one-step subtyping relation is quite simple and only allows information
about constructor components to be forgotten. It has no transitivity rule and does not
allow rewriting via equality of constructors, thus avoiding the equality transitivity rule as
well. Because of the lack of transitivity rules, it can be proved to act in a component-wise
manner without using a replacement result. The lack of equality also simplifies relating
the shapes of one-step subtypes.

The full subtyping relation can be constructed from the one-step subtyping relation
and equality by defining A to be a subtype of A0 under \Gamma  iff you can get from A to A0 by a
series of applications of equality and one-step subtyping under \Gamma . For example, we might
have \Gamma  ` A ^ A0 by \Gamma  ` A = A1 :: \Omega , \Gamma  ` A1 ! A2, \Gamma  ` A2 = A3 :: \Omega , and \Gamma  ` A3 ! A0.

Using this definition of subtyping, the replacement by a subtype result can be proved
as follows: First, prove that types in assignments can be replaced by one-step subtypes
using the fact that one-step subtyping acts in a component-wise manner. Second, combine

1This fact can be seen in the use of Theorem 10.4.7 in the second to last step of Lemma 10.5.1.

189

190 CHAPTER 10. SUBTYPING
that result with the replacement by an equal type result (Theorem 9.4.6) to prove the
desired result. (The key idea for the second part is that you can always replace a type
by a subtype by means of a sequence of replacements by equal and one-step subtypes;
the sequence needed can be determined from the subtyping derivation.)

10.1 One-Step Subtyping
The rules for the one-step subtyping relation follow. Note that aside from the O-FORGET
rule, the rules act either in a component-wise manner or leave the constructor unchanged.

Definition 10.1.1 (One-Step Subtyping Rules)

\Gamma  ` A :: \Omega 
\Gamma  ` A ! A (O-REFL)

\Gamma  ` A01 ! A1
\Gamma ; x:A01 ` A2 ! A02 \Gamma ; x:A1 ` A2 :: \Omega 

\Gamma  ` \Pi x:A1: A2 ! \Pi x:A01: A02 (O-DFUN)

\Gamma  ` A1 ! A01
\Gamma ; x:A1 ` A2 ! A02 \Gamma ; x:A01 ` A02 :: \Omega 

\Gamma  ` \Sigma x:A1: A2 ! \Sigma x:A01: A02 (O-DSUM)

\Gamma  ` A :: K
\Gamma  ` !=A::K? ! !K ? (O-FORGET)

The usual propositions on judgments also hold for one-step subtyping:
Lemma 10.1.2 (Validity of one-step subtypes)

If \Gamma  ` A ! A0 then \Gamma  ` A :: \Omega  and \Gamma  ` A0 :: \Omega .

Theorem 10.1.3 (Weakening)

Suppose ` \Gamma ; \Gamma 0 valid and dom(\Gamma 0) " dom(\Gamma 00) = ;. Then if \Gamma ; \Gamma 00 ` A1 ! A2 then
\Gamma ; \Gamma 0; \Gamma 00 ` A1 ! A2.

Proof: By structural induction on the derivation of \Gamma ; \Gamma 00 ` A1 ! A2, using Theorem 9.4.1 as needed. 2

Lemma 10.1.4 (Strengthening)

Suppose x 62 FTV(\Gamma 0) [ FTV(A1) [ FTV(A2). Then, if \Gamma ; x:A0; \Gamma 0 ` A1 ! A2, then
\Gamma ; \Gamma 0 ` A1 ! A2.

10.1. ONE-STEP SUBTYPING 191
Proof: By structural induction on the derivation using Theorem 9.6.1 as needed. 2

Lemma 10.1.5 (Validity of place substitution)

Suppose \Gamma  ` xae ) A0. Then, if \Gamma ; x0:A0; \Gamma 0 ` A1 ! A2 then
\Gamma ; [xae=x0]\Gamma 0 ` [xae=x0]A1 ! [xae=x0]A2.

Proof: Proved by structural induction on the derivation of \Gamma ; x0:A0; \Gamma 0 ` A1 ! A2 using
Theorem 9.4.7 as needed. 2

Lemma 10.1.6 (Replacement with an equal type)

Suppose \Gamma  ` A1 = A2 :: \Omega . Then, if \Gamma ; x:A1; \Gamma 0 ` A ! A0 then \Gamma ; x:A2; \Gamma 0 ` A ! A0.

Proof: Proved by structural induction on the derivation of \Gamma ; x:A1; \Gamma 0 ` A ! A0 using
Theorem 9.4.6 as needed. 2

Because one-step subtyping lacks any transitivity rules, it can easily be shown to act
in a component-wise manner:

Lemma 10.1.7 (Component-wise one-step subtyping)

1. If \Gamma  ` \Pi x:A1: A2 ! \Pi x:A01: A02, x 62 dom(\Gamma ), then

\Gamma  ` A01 ! A1 and \Gamma ; x:A01 ` A2 ! A02.

2. If \Gamma  ` \Sigma x:A1: A2 ! \Sigma x:A01: A02, x 62 dom(\Gamma ), then

\Gamma  ` A1 ! A01 and \Gamma ; x:A1 ` A2 ! A02.

Proof: Proved by structural induction on the derivations. The O-DFUN and O-DSUM
cases are immediate. The only other possible case is O-REFL which is handled by
Lemma 10.1.2 and C-DFUN/C-DSUM (to establish the validity of A1 and A2) followed
by O-REFL. 2

Using this result, I can prove that (single-step) selections can be pulled back across
one-step subtyping:

Lemma 10.1.8 (Pullback)

If \Gamma  ` xae ) A1 and \Gamma  ` A1 ! \Sigma x0:A02: A002 then \Gamma  ` S(A1; xae; :i) ! S(\Sigma x0:A02: A002; xae; :i).

192 CHAPTER 10. SUBTYPING
Proof: WLOG, let x0 62 dom(\Gamma ). Inspection of the rules for one-step subtyping
shows that \Gamma  ` A1 ! \Sigma x0:A02: A002 must have been derived using either O-REFL or ODSUM. Either way, WLOG, A1 must have the form \Sigma x0:A01: A001 for some A01 and A001 )
\Gamma  ` A01 ! A02 and \Gamma ; x0:A01 ` A001 ! A002 (Lemma 10.1.7) and S(A1; xae; :1) = A01 exists )
\Gamma  ` S(A1; xae; :1) ! S(\Sigma x0:A02: A002; xae; :1).

By Theorem 9.4.4, E-REFL, and P-MOVE, \Gamma  ` xae:1 ) A01
) \Gamma  ` [xae:1=x0]A001 ! [xae:1=x0]A002 (Lemma 10.1.5)
) \Gamma  ` S(A1; xae; :2) ! S(\Sigma x0:A02: A002; xae; :2).
Thus, \Gamma  ` S(A1; xae; :i) ! S(\Sigma x0:A02: A002; xae; :i). 2

10.2 The Subtyping Relation
The rules for the full subtyping relation are as follows:
Definition 10.2.1 (Subtyping Rules)

\Gamma  ` A = A0 :: \Omega 

\Gamma  ` A ^ A0 (S-EQ)

\Gamma  ` A ! A0
\Gamma  ` A ^ A0 (S-ONE)

\Gamma  ` A ^ A0 \Gamma  ` A0 ^ A00

\Gamma  ` A ^ A00 (S-TRAN)

Again, the usual propositions on judgments hold:
Lemma 10.2.2 (Validity of subtypes)

If \Gamma  ` A ^ A0 then \Gamma  ` A :: \Omega  and \Gamma  ` A0 :: \Omega .

Theorem 10.2.3 (Weakening)

Suppose ` \Gamma ; \Gamma 0 valid and dom(\Gamma 0) " dom(\Gamma 00) = ;. Then if \Gamma ; \Gamma 00 ` A1 ^ A2 then
\Gamma ; \Gamma 0; \Gamma 00 ` A1 ^ A2.

Proof: By structural induction on the derivation of \Gamma ; \Gamma 00 ` A1 ^ A2, using Theorems 9.4.1 and 10.1.3 as needed. 2

Theorem 10.2.4 (Strengthening)

Suppose x 62 FTV(\Gamma 0) [ FTV(A1) [ FTV(A2). Then, if \Gamma ; x:A0; \Gamma 0 ` A1 ^ A2, then
\Gamma ; \Gamma 0 ` A1 ^ A2.

10.3. SHAPES 193
Proof: By structural induction on the derivation using Lemma 10.1.4 and Corollary 9.6.2 as needed. 2

Lemma 10.2.5 (Replacement with an equal type)

Suppose \Gamma  ` A1 = A2 :: \Omega . Then, if \Gamma ; x:A1; \Gamma 0 ` A ^ A0 then \Gamma ; x:A2; \Gamma 0 ` A ^ A0.

Proof: Proved by structural induction on the derivation of \Gamma ; x:A1; \Gamma 0 ` A ^ A0 using
Theorem 9.4.6 and Lemma 10.1.6 as needed. 2

10.3 Shapes
In this section I formalize the notion of constructor shapes and establish results about
how the shapes of constructors related by the equality, one-step subtyping, and subtyping
judgments are related. I shall use the following set of shapes to describe the structure of
constructors:

Definition 10.3.1 (Shape syntax)

Shapes O/ ::= ? j * j \Pi  j \Sigma  j * j !K? j !=::K ? j rec j ref j recapp j

refapp

The has-shape function (d\Gamma e) assigns these shapes to constructors in the following manner:

Definition 10.3.2 (Constructor shapes)

dffe = *
d\Pi x:A: A0e = \Pi 

d\Sigma x:A: A0e = \Sigma 
d*ff::K: Ae = *

drec A0e = recapp

dref A0e = refapp

dA A0e = ? (A 62 frec; refg)
d!K?e = !K?
d!=A::K?e = !=::K?

dxae!e = ?
drece = rec

drefe = ref

194 CHAPTER 10. SUBTYPING

I have chosen the set of shapes so that if the ? shape is considered a wildcard, equal
to any other shape, then equal constructors always have equal shapes:

Lemma 10.3.3 (Shapes and equality)

Suppose \Gamma  ` A1 = A2 :: \Omega . Then one of the following is true:

1. dA1e = ?
2. dA2e = ?
3. dA1e = dA2e

Proof: By Theorem 9.4.3, \Gamma  ` A1 :: \Omega  and \Gamma  ` A2 :: \Omega  ) dA1e 6= * and dA2e 6= *
(inspection of the typing rules). The desired result then follows by Lemma 9.4.9. 2

In order to describe how one-step subtyping interacts with shapes, it is useful to
introduce the following ordering relation on shapes, which puts transparent type shapes
before opaque type shapes that contain constructors of the same kind:

Definition 10.3.4 (Ordering of shapes)
We say that O/1 ^ O/2 iff either of the following:

1. O/1 = O/2
2. O/1 = !=::K? and O/2 = !K? for some K

Note that this ordering relation is transitive:
Lemma 10.3.5 (Transitivity)

If O/1 ^ O/2 and O/2 ^ O/3 then O/1 ^ O/3.

The shapes of constructors related by one-step subtyping are related by this ordering:
Lemma 10.3.6 (Shapes and one-step subtyping)

If \Gamma  ` A1 ! A2 then dA1e ^ dA2e.

Proof: Proved by inspection of the one-step subtyping rules. 2

If one-step subtyping is applied to a constructor with the ? shape, it acts as the
identity relation:

Lemma 10.3.7 If \Gamma  ` A1 ! A2 and dA1e = ? or dA2e = ? then:

10.3. SHAPES 195

1. A1 = A2
2. \Gamma  ` A1 = A2 :: \Omega 
3. dA1e = dA2e = ?

Proof: Inspection of the one-step subtyping rules shows that \Gamma  ` A1 ! A2 must be
derived using the O-REFL rule ) A1 = A2 ) \Gamma  ` A1 = A2 :: \Omega  (Theorem 9.4.3 and
E-REFL). 2

When dealing with multiple equalities or one-step subtypings (as is the case when
dealing with the full subtyping relation), it is useful to introduce the concept of a constructor's intrinsic shape under a given assignment (d\Gamma e\Gamma ). The intrinsic shape of a
constructor is the most defined shape it can be put into using equality where ? is considered the least defined shape:

Definition 10.3.8 (Intrinsic constructor shapes)
If \Gamma  ` A :: K then define dAe\Gamma  as follows:

1. If 9A0 such that \Gamma  ` A = A0 :: K, dA0e = O/, and O/ 6= ? then dAe\Gamma  = O/.
2. Otherwise, dAe\Gamma  = ?.

(Note that this definition is well defined because Lemma 10.3.3 and E-TRAN imply that
case one cannot hold for two different shapes.)

When necessary, a type's intrinsic shape under a given assignment may be computed
by first computing an equal semi-canonical type (via Theorem 9.5.10) then determining
the resulting semi-canonical type's shape:

Lemma 10.3.9 If A 2 C\Gamma  then dAe\Gamma  = dAe.
Proof: Suppose not. Then by the definition of intrinsic shape and E-REFL, dAe = ? and
dAe\Gamma  6= ? ) 9A0 such that \Gamma  ` A = A0 :: K, dA0e = dAe\Gamma . By Lemma 9.5.2, \Gamma  ` A :: \Omega .
By Theorems 9.4.5 and 9.4.3, K = \Omega  and \Gamma  ` A0 :: \Omega . ) dA0e 6= * (inspection of typing
rules). By Lemma 9.5.7 then, dAe = dA0e = dAe\Gamma . 2

Equal constructors, of course, have the same intrinsic shape:
Lemma 10.3.10 If \Gamma  ` A1 = A2 :: K then dA1e\Gamma  = dA2e\Gamma .

196 CHAPTER 10. SUBTYPING
Proof: By E-TRAN, A1 and A2 are equal to exactly the same types under \Gamma . Hence,
by the definition of intrinsic constructor shapes, their intrinsic constructor shapes must
be the same. 2

Both forms of subtyping relate types whose intrinsic shapes are related by the introduced ordering on shapes:

Lemma 10.3.11 If \Gamma  ` A1 ! A2 then dA1e\Gamma  ^ dA2e\Gamma .
Proof: Cases:
Case I: dA2e = ?

) A1 = A2 (Lemma 10.3.7) ) dA1e\Gamma  = dA2e\Gamma  ) dA1e\Gamma  ^ dA2e\Gamma .

Case II: dA2e 6= ?

By Lemma 10.3.6, dA1e ^ dA2e ) dA1e 6= ? (? ^ O/ ) O/ = ?) ) dA1e = dA1e\Gamma  and
dA2e = dA2e\Gamma  (Lemma 10.1.2, E-REFL, and the definitions of shape and intrinsic
shape) ) dA1e\Gamma  ^ dA2e\Gamma .

2

Corollary 10.3.12 If \Gamma  ` A1 ^ A2 then dA1e\Gamma  ^ dA2e\Gamma .
Proof: Proved by structural induction on the derivation, using Lemma 10.3.11,
Lemma 10.3.5, and the definition of intrinsic shape as needed. 2

Subtyping collapses to equality when applied to types with certain intrinsic shapes:
Lemma 10.3.13 If \Gamma  ` A1 ! A2, dA1e\Gamma  = dA2e\Gamma , and dA2e\Gamma  62 f\Pi ; \Sigma g then
\Gamma  ` A1 = A2 :: \Omega 

Proof: Lemma 10.3.7 handles the case where dA1e = ? or dA2e = ?, so we can assume
that dA1e 6= ? and dA2e 6= ? ) dA1e = dA1e\Gamma  = dA2e\Gamma  = dA2e (definition of intrinsic
shape) ) \Gamma  ` A1 ! A2 was derived using O-REFL (inspection of the one-step subtyping
rules) ) A1 = A2 ) \Gamma  ` A1 = A2 :: \Omega  (Theorem 9.4.3 and E-REFL). 2

Corollary 10.3.14 If \Gamma  ` A1 ^ A2, dA1e\Gamma  = dA2e\Gamma , and dA2e\Gamma  62 f\Pi ; \Sigma g then
\Gamma  ` A1 = A2 :: \Omega 

10.4. REPLACEMENT BY A SUBTYPE 197
Proof: Inspection of the rules for subtyping shows that a subtyping derivation for
\Gamma  ` A1 ^ A2 can be regarded as a linear sequence of types starting with A1 and ending
with A2 such that adjacent types are related either by equality or one-step subtyping
(under assignment \Gamma ). By Lemma 10.3.11 and the definition of intrinsic shape, it follows that the intrinsic shape with respect to \Gamma  of all the types in the sequence are the
same. Hence, by Lemma 10.3.13 then, we can replace the one-step subtyping steps in
the sequence by equalities. By repeatedly applying E-TRAN then, we get the desired
result. 2

I shall need the following lemma about shapes and one-step subtyping in order to
prove the replacement by a subtype result:

Lemma 10.3.15 (Shape preservation)

Suppose \Gamma  ` A1 ! A2 and \Gamma  ` A2 = A3 :: \Omega . Then:

1. If dA3e = !K? then either \Gamma  ` A1 = A3 :: \Omega  or dA1e = !=::K?.
2. If dA3e = !=::K? then \Gamma  ` A1 = A3 :: \Omega .
Proof: If dA2e = ? then, by Lemma 10.3.7 and E-TRAN, we have that \Gamma  ` A1 = A3 :: \Omega 
and are done. So, assume otherwise ) dA2e = dA3e
(Lemma 10.3.3). By Lemma 10.3.6, dA1e ^ dA2e. There are two cases:

case I: Here dA1e = dA2e ) dA1e 6= ? ) dA1e\Gamma  = dA1e and dA2e\Gamma  = dA2e (Lemma 10.1.2,

E-REFL, and definition of intrinsic shape)
) \Gamma  ` A1 = A2 :: \Omega  (Lemma 10.3.13) ) \Gamma  ` A1 = A3 :: \Omega  (E-TRAN).

case II: Here dA1e = !=::K? and dA3e = dA2e = !K?. We must proving part two here

and are thus done.

2

10.4 Replacement by a Subtype
In this section I prove the key result that if you take a true judgment and replace a type in
its assignment with a subtype, the resulting judgment is also true. As I discussed earlier,
I shall do this by first proving a similar result using the one-step subtyping relation
instead of the full subtyping relation.

The induction hypothesis required for proving this statement is quite tricky; I shall
need a notion of constructor size that decreases when a constructor is replaced by a
selection on that constructor using a non-empty path:

198 CHAPTER 10. SUBTYPING
Definition 10.4.1 (\Sigma -size) If A has form \Sigma x:A1: A2 then bAc = bA1c + bA0c + 1.
Otherwise, bAc = 0.

Lemma 10.4.2 (\Sigma -size properties)

1. bAc * 0
2. b[xae=x0]Ac = bAc
3. If S(A; xae; :i) exists then bS(A; xae; :i)c ! bAc.
4. If S(A; xae; ae0), ae0 6= ffl, exists then bS(A; xae; ae0)c ! bAc.

Proof: Parts one and two are proved by structural induction on A. Part three follows
from parts one and two and the definitions of selection and \Sigma -size. Part four follows from
part three and Lemma 6.5.3. 2

In order to prevent the proof from getting too complicated, I have (partially) pulled
out the following lemma that is used to handle the induction case for the place lookup
judgment. Preconditions one through four of the lemma describe a simplified version of
that case. In particular, the lemma assumes that the selection is by exactly one step (:i);
I shall remove this simplification shortly.

The fifth precondition represents the induction hypothesis of the replacement by a onestep subtype result that we are trying to prove. This precondition allows the lemma to use
the replacement result with smaller (in the \Sigma -size sense) constructors. The lemma says
that under these preconditions, we can either directly lookup the end type (S(A2; xae; :i))
or we can lookup a type (A03) that we can convert via one-step subtyping (\Gamma  ` A03 ! A01)
followed by equality (\Gamma  ` A01 = S(A2; xae; :i) :: \Omega ) to the end type. In the second case, the
one-step supertype \Sigma -size is such that we can use the replacement result with it.

Lemma 10.4.3 (Special pullback lemma I) Suppose:

1. \Gamma  ` xae ) A3
2. \Gamma  ` A3 ! A1
3. \Gamma  ` A1 = A2 :: \Omega 
4. S(A2; xae; :i) exists
5. 8x0; A; A0; A01; A02: If \Gamma ; x0:A ` A01 = A02 :: \Omega , \Gamma  ` A0 ! A, bAc ! bA1c then

\Gamma ; x0:A0 ` A01 = A02 :: \Omega .

10.4. REPLACEMENT BY A SUBTYPE 199
Then one of the following holds:

ffl \Gamma  ` xae:i ) S(A2; xae; :i)
ffl 9A03; A01: \Gamma  ` xae:i ) A03, \Gamma  ` A03 ! A01, bA01c ! bA1c, and

\Gamma  ` A01 = S(A2; xae; :i) :: \Omega 

Proof: Since S(A2; xae; :i) exists, 9x0; A02; A002: A2 = \Sigma x0:A02: A002 and x0 62 dom(\Gamma ) By
Lemma 10.3.3, we have the following cases:

ffl dA1e = ? ) \Gamma  ` A3 = A1 :: \Omega  (Lemma 10.3.7) ) \Gamma  ` A3 = A2 :: \Omega  (E-TRAN) )

\Gamma  ` xae:i ) S(A2; xae; :i) (P-MOVE)

ffl dA1e = \Sigma  ) 9A01; A001: A1 = \Sigma x0:A01: A001 ) \Gamma  ` \Sigma x0:A01: A001 = \Sigma x0:A02: A002 :: \Omega ,

\Gamma  ` S(A3; xae; :1) ! S(\Sigma x0:A01: A001; xae; :1), and
\Gamma  ` S(A3; xae; :2) ! S(\Sigma x0:A01: A001; xae; :2). (Lemma 10.1.8)
) \Gamma  ` A01 = A02 :: \Omega  and \Gamma ; x0:A01 ` A001 = A002 :: \Omega  (Lemma 9.4.10) and
\Gamma  ` S(A3; xae; :1) ! A01 ) \Gamma  ` S(A1; xae; :1) = S(A2; xae; :1) :: \Omega .

By Lemma 10.4.2, bA01c = bS(A1; xae; :1)c ! bA1c and bS(A1; xae; :2)c ! bA1c.
Hence, by precondition number five, \Gamma ; x0:S(A3; xae; :1) ` A001 = A002 :: \Omega .

By Theorem 9.4.4, E-REFL, and P-MOVE, \Gamma  ` xae:1 ) S(A3; xae; :1) and
\Gamma  ` xae:2 ) S(A3; xae; :2) ) \Gamma  ` [xae:1=x0]A001 = [xae:1=x0]A002 :: \Omega  (Lemma 10.1.5) )
\Gamma  ` S(A1; xae; :2) = S(A2; xae; :2) :: \Omega .

Thus, \Gamma  ` xae:i ) S(A3; xae; :i), \Gamma  ` S(A3; xae; :i) ! S(A1; xae; :i),
bS(A1; xae; :i)c ! bA1c, and \Gamma  ` S(A1; xae; :i) = S(A2; xae; :i) :: \Omega .

2

By iterating the previous lemma, we can remove the restriction that the selection be
by only one step (the statement of the lemma is otherwise unchanged):

Lemma 10.4.4 (Special pullback lemma II) Suppose:

1. \Gamma  ` xae ) A3
2. \Gamma  ` A3 ! A1
3. \Gamma  ` A1 = A2 :: \Omega 
4. S(A2; xae; ae0) exists
5. 8x0; A; A0; A01; A02: If \Gamma ; x0:A ` A01 = A02 :: \Omega , \Gamma  ` A0 ! A, bAc ! bA1c then

\Gamma ; x0:A0 ` A01 = A02 :: \Omega .

200 CHAPTER 10. SUBTYPING
Then one of the following holds:

ffl \Gamma  ` xaeae0 ) S(A2; xae; ae0)
ffl 9A03; A01: \Gamma  ` xaeae0 ) A03, \Gamma  ` A03 ! A01, bA01c ! bA1c, and

\Gamma  ` A01 = S(A2; xae; ae0) :: \Omega 

Proof: Proved by induction on the length of ae0. Cases:
Zero: Here ae0 = ffl ) S(A2; xae; ae0) = A2. Let A03 = A3 and A01 = A1 and we are done.
Many: Here ae0 = ae00:i. By Lemma 6.5.3, S(A2; xae; ae00:i) = S(S(A2; xae; ae00); xaeae00; :i).

Hence, by the induction hypothesis, we have two cases:

- Here \Gamma  ` xaeae00 ) S(A2; xae; ae00) ) \Gamma  ` xaeae00:i ) S(A2; xae; ae00:i) (Theorem 9.4.4,

E-REFL, and P-MOVE) ) \Gamma  ` xaeae0 ) S(A2; xae; ae0)

- Here 9A003; A001: \Gamma  ` xaeae00 ) A003, \Gamma  ` A003 ! A001, bA001c ! bA1c, and

\Gamma  ` A001 = S(A2; xae; ae00) :: \Omega . Since bA001c ! bA1c, we can apply
Lemma 10.4.3 to get: 9A03; A01: \Gamma  ` xaeae00:i ) A03, \Gamma  ` A03 ! A01, bA01c ! bA001c,
and \Gamma  ` A01 = S(S(A2; xae; ae00); xaeae00; :i) :: \Omega  ) \Gamma  ` xaeae00:i ) A03, \Gamma  ` A03 ! A01,
bA01c ! bA1c, and \Gamma  ` A01 = S(A2; xaeae00; ae0) :: \Omega 

2

Using the improved version of the lemma, I can now prove the desired replacement
result:

Theorem 10.4.5 (Replacement with a one-step subtype)

If \Gamma  ` A2 ! A1 then:

1. If ` \Gamma ; x:A1; \Gamma 0 valid then ` \Gamma ; x:A2; \Gamma 0 valid.
2. If \Gamma ; x:A1; \Gamma 0 ` A :: K then \Gamma ; x:A2; \Gamma 0 ` A :: K.
3. If \Gamma ; x:A1; \Gamma 0 ` A = A0 :: K then \Gamma ; x:A2; \Gamma 0 ` A = A0 :: K.
4. If \Gamma ; x:A1; \Gamma 0 ` x0ae ) A, x0 6= x, then \Gamma ; x:A2; \Gamma 0 ` x0ae ) A.
5. If \Gamma ; x:A1; \Gamma 0 ` xae ) A then one of:

ffl \Gamma ; x:A2; \Gamma 0 ` xae ) A
ffl 9A02; A01: \Gamma ; x:A2; \Gamma 0 ` xae ) A02, \Gamma ; x:A2; \Gamma 0 ` A02 ! A01,

bA01c ^ bA1c, and \Gamma ; x:A2; \Gamma 0 ` A01 = A :: \Omega 

10.4. REPLACEMENT BY A SUBTYPE 201
Proof: Proved by simultaneous induction on all five parts; the metric used is based
first on bA1c and then on the structure of the derivations of the parts. Thus, we may
recursively call ourselves either with a A1 of smaller \Sigma -size or with the same A1 and a
sub-derivation of the original one. Interesting cases:

C-EXT-O II: Given \Gamma ; x:A1; \Gamma 0 ` xae! :: K derived via C-EXT-O from \Gamma ; x:A1; \Gamma 0 ` xae ) !K ?.

By the induction hypothesis, Theorem 9.4.4, O-REFL, and E-REFL, we have
9A02; A01: \Gamma ; x:A2; \Gamma 0 ` xae ) A02, \Gamma ; x:A2; \Gamma 0 ` A02 ! A01, and
\Gamma ; x:A2; \Gamma 0 ` A01 = !K? :: \Omega  ) \Gamma ; x:A2; \Gamma 0 ` A02 = !K? :: \Omega  or 9A002: A02 = !=A002::K?
(Lemma 10.3.15) ) \Gamma ; x:A2; \Gamma 0 ` xae ) !K? (P-MOVE) or
\Gamma ; x:A2; \Gamma 0 ` xae ) !=A002::K? ) \Gamma ; x:A2; \Gamma 0 ` xae! :: K (C-EXT-O or C-EXT-T).

C-EXT-T II: Given \Gamma ; x:A1; \Gamma 0 ` xae! :: K derived via C-EXT-T from

\Gamma ; x:A1; \Gamma 0 ` xae ) !=A::K? By the induction hypothesis, Theorem 9.4.4, O-REFL,
and E-REFL, we have 9A02; A01: \Gamma ; x:A2; \Gamma 0 ` xae ) A02, \Gamma ; x:A2; \Gamma 0 ` A02 ! A01, and
\Gamma ; x:A2; \Gamma 0 ` A01 = !=A::K? :: \Omega  ) \Gamma ; x:A2; \Gamma 0 ` A02 = !=A::K? :: \Omega 
(Lemma 10.3.15) ) \Gamma ; x:A2; \Gamma 0 ` xae ) !=A::K? (P-MOVE) ) \Gamma ; x:A2; \Gamma 0 ` xae! :: K
(C-EXT-T).

E-ABBREV II: Given \Gamma ; x:A1; \Gamma 0 ` xae! = A0 :: K derived via E-ABBREV from

\Gamma ; x:A1; \Gamma 0 ` xae! :: K, \Gamma ; x:A1; \Gamma 0 ` xae ) A, and
\Gamma ; x:A1; \Gamma 0 ` A = !=A0::K0? :: \Omega  By the induction hypothesis,
Theorem 9.4.4, O-REFL, and E-REFL, we have \Gamma ; x:A2; \Gamma 0 ` xae! :: K,
\Gamma ; x:A2; \Gamma 0 ` A = !=A0::K0? :: \Omega , and 9A02; A01: \Gamma ; x:A2; \Gamma 0 ` xae ) A02,
\Gamma ; x:A2; \Gamma 0 ` A02 ! A01, and \Gamma ; x:A2; \Gamma 0 ` A01 = A :: \Omega 
) \Gamma ; x:A2; \Gamma 0 ` A01 = !=A0::K0? :: \Omega  (E-TRAN)
) \Gamma ; x:A2; \Gamma 0 ` A02 = !=A0::K0? :: \Omega  (Lemma 10.3.15)
) \Gamma ; x:A2; \Gamma 0 ` xae ) A (P-MOVE, E-SYM, and E-TRAN)
) \Gamma ; x:A2; \Gamma 0 ` xae! = A0 :: K (E-ABBREV).

P-INIT I: Given \Gamma ; x:A1; \Gamma 0 ` x0 ) A, x0 6= x, derived via P-INIT from ` \Gamma ; x:A1; \Gamma 0 valid and

x0:A 2 \Gamma ; x:A1; \Gamma 0 ) x0:A 2 \Gamma ; \Gamma 0 and ` \Gamma ; x:A2; \Gamma 0 valid (induction hypothesis) )
x0:A 2 \Gamma ; x:A2; \Gamma 0 ) \Gamma ; x:A2; \Gamma 0 ` x0 ) A (P-INIT).

P-INIT II: Given \Gamma ; x:A1; \Gamma 0 ` x ) A derived via P-INIT from ` \Gamma ; x:A1; \Gamma 0 valid and x:A 2

\Gamma ; x:A1; \Gamma 0 ) ` \Gamma ; x:A2; \Gamma 0 valid (induction hypothesis) and A = A1 (Lemma 9.4.2)
) \Gamma ; x:A2; \Gamma 0 ` x ) A2 (P-INIT) and \Gamma ; x:A2; \Gamma 0 ` A2 ! A1 and \Gamma ; x:A2; \Gamma 0 ` A1 :: \Omega 
(Lemma 10.1.2 and Theorem 9.4.1) ) \Gamma ; x:A2; \Gamma 0 ` A1 = A1 :: \Omega  (E-REFL) Let
A02 = A and A01 = A1 and we are done.

P-MOVE II: Given \Gamma ; x:A1; \Gamma 0 ` xaeae0 ) A00 derived via P-MOVE from \Gamma ; x:A1; \Gamma 0 ` xae ) A,

\Gamma ; x:A1; \Gamma 0 ` A = A0 :: \Omega , and A00 = S(A0; xae; ae0). Applying the induction hypothesis gives us that \Gamma ; x:A2; \Gamma 0 ` A = A0 :: \Omega  and that one of the following cases holds:

202 CHAPTER 10. SUBTYPING

- Here \Gamma ; x:A2; \Gamma 0 ` xae ) A ) \Gamma ; x:A2; \Gamma 0 ` xaeae0 ) A00 (P-MOVE).
- Here 9A002; A001: \Gamma ; x:A2; \Gamma 0 ` xae ) A002, \Gamma ; x:A2; \Gamma 0 ` A002 ! A001,

bA001c ^ bA1c, and \Gamma ; x:A2; \Gamma 0 ` A001 = A :: \Omega  ) \Gamma ; x:A2; \Gamma 0 ` A001 = A0 :: \Omega  (ETRAN). The desired result then follows directly from an application of
Lemma 10.4.4. (Precondition five of the lemma is met by the induction hypothesis since bA001c ^ bA1c.)

2
The result extends immediately to the one-step subtyping relation:

Corollary 10.4.6 (Replacement with a one-step subtype)

If \Gamma  ` A1 ! A2 and \Gamma ; x:A1; \Gamma 0 ` A ! A0 then
\Gamma ; x:A2; \Gamma 0 ` A ! A0.

Proof: By structural induction on the derivation of \Gamma ; x:A1; \Gamma 0 ` A ! A0 using Theorem 10.4.5 as needed. 2

Finally, using these results plus the replacement by an equal type result (Theorem 9.4.6), the desired replacement by a subtype result can be proved:

Theorem 10.4.7 (Replacement with a subtype)

If \Gamma  ` A2 ^ A1 then:

1. If ` \Gamma ; x0:A1; \Gamma 0 valid then ` \Gamma ; x0:A2; \Gamma 0 valid.
2. If \Gamma ; x0:A1; \Gamma 0 ` A :: K then \Gamma ; x0:A2; \Gamma 0 ` A :: K.
3. If \Gamma ; x0:A1; \Gamma 0 ` A = A0 :: K then \Gamma ; x0:A2; \Gamma 0 ` A = A0 :: K .
4. If \Gamma ; x0:A1; \Gamma 0 ` xae ) A, x 6= x0, then \Gamma ; x0:A2; \Gamma 0 ` xae ) A.
5. If \Gamma ; x0:A1; \Gamma 0 ` A ^ A0 then \Gamma ; x0:A2; \Gamma 0 ` A ^ A0.

Proof: Proved simultaneously by structural induction on the derivations. The S-EQ
case is handled by Theorem 9.4.6 and Lemma 10.2.5. The S-ONE case is handled by
Theorem 10.4.5 and Corollary 10.4.6. 2

10.5. A SEMI-DECISION PROCEDURE 203
10.5 A Semi-Decision Procedure
In this section I first prove some results about how subtyping behaves then give and prove
correct a semi-decision procedure for subtyping. The first result I show for subtyping is
that it acts in a component-wise manner:

Lemma 10.5.1 (Component-wise subtyping)

1. If \Gamma  ` \Pi x:A1: A01 ^ \Pi x:A2: A02, x 62 dom(\Gamma ), then

\Gamma  ` A2 ^ A1 and \Gamma ; x:A2 ` A01 ^ A02.

2. If \Gamma  ` \Sigma x:A1: A01 ^ \Sigma x:A2: A02, x 62 dom(\Gamma ), then

\Gamma  ` A1 ^ A2 and \Gamma ; x:A1 ` A01 ^ A02.

Proof: The proof of both parts are similar. I give the proof for only part one here:
Inspection of the rules for subtyping shows that a subtyping derivation for
\Gamma  ` \Pi x:A1: A01 ^ \Pi x:A2: A02 can be regarded as a linear sequence of types starting with
\Pi x:A1: A01 and ending with \Pi x:A2: A02 such that adjacent types are related either by
equality or one-step subtyping (under assignment \Gamma ).

Using Lemma 10.3.7 we can turn one-step subtyping on types with shape ? into
equalities on the same types. By using E-TRAN afterwards, we can collapse adjacent
equalities so that all the remaining types in the sequence have shapes other than ?.

Hence, by Lemma 10.3.11 and the definition of intrinsic shapes, all the types in the
new sequence have shape \Pi  ) 9n * 2: 8i 2 f1 : : : ng: 9Bi; B0i such that

1. A1 = B1 and A01 = B01

2. if i ? 1 then either \Gamma  ` \Pi x:Bi\Gamma 1: B0i\Gamma 1 = \Pi x:Bi: B0i :: \Omega  or

\Gamma  ` \Pi x:Bi\Gamma 1: B0i\Gamma 1 ! \Pi x:Bi: B0i

3. A2 = Bn and A02 = B0n

) 8i 2 f2 : : : ng: (\Gamma  ` Bi\Gamma 1 = Bi :: \Omega  or \Gamma  ` Bi ! Bi\Gamma 1) and (\Gamma ; x:Bi ` B0i\Gamma 1 = B0i :: \Omega 
or \Gamma ; x:Bi ` B0i\Gamma 1 ! B0i) (Lemma 9.4.10 and O-DFUN)

) 8i 2 f1 : : : ng: \Gamma  ` Bn ^ Bi (E-REFL, E-SYM, S-EQ, S-ONE, and S-TRAN applied repeatedly)

) \Gamma  ` A2 ^ A1 and 8i 2 f2 : : : ng: \Gamma ; x:Bn ` B0i\Gamma 1 = B0i :: \Omega  or
\Gamma ; x:Bn ` B0i\Gamma 1 ! B0i (Theorem 10.4.7)

) \Gamma ; x:A2 ` A01 ^ A02 (E-REFL, S-EQ, S-ONE, and S-TRAN applied repeatedly) 2

With the next series of results, I establish that versions of the O-DFUN and ODSUM rules using the full subtyping relation instead of the one-step subtyping relation
are derivable:

204 CHAPTER 10. SUBTYPING
Lemma 10.5.2 Suppose \Gamma  ` A1 ^ A2. Then:

1. If \Gamma  ` \Pi x:A2: A :: \Omega  then \Gamma  ` \Pi x:A2: A ^ \Pi x:A1: A.
2. If \Gamma  ` \Sigma x:A2: A :: \Omega  then \Gamma  ` \Sigma x:A1: A ^ \Sigma x:A2: A.

Proof: The proof of both parts are similar. I give the proof for only part one here:
WLOG, let x 62 dom(\Gamma ). By C-DFUN, \Gamma ; x:A2 ` A :: \Omega . The proof proceeds by structural
induction on the derivation of \Gamma  ` A1 ^ A2:

O-EQ: Given \Gamma  ` A1 = A2 :: \Omega . By E-REFL, \Gamma ; x:A2 ` A = A :: \Omega 

) \Gamma  ` \Pi x:A2: A = \Pi x:A1: A :: \Omega  (E-DFUN) ) \Gamma  ` \Pi x:A2: A ^ \Pi x:A1: A (S-EQ).

O-ONE: Given \Gamma  ` A1 ! A2. By O-REFL, \Gamma ; x:A2 ` A ! A ) \Gamma ; x:A1 ` A ! A (Corollary 10.4.6) ) \Gamma  ` \Pi x:A2: A ! \Pi x:A1: A (O-DFUN)
) \Gamma  ` \Pi x:A2: A ^ \Pi x:A1: A (S-ONE).

O-TRAN: Given \Gamma  ` A1 ^ A0 and \Gamma  ` A0 ^ A2. By the inductive hypothesis,

\Gamma  ` \Pi x:A2: A ^ \Pi x:A0: A ) \Gamma  ` \Pi x:A0: A :: \Omega  (Lemma 10.1.2)
) \Gamma  ` \Pi x:A0: A ^ \Pi x:A1: A (induction hypothesis)
) \Gamma  ` \Pi x:A2: A ^ \Pi x:A1: A (E-TRAN).

2

Lemma 10.5.3 If \Gamma ; x:A ` A1 ^ A2 then:

1. \Gamma  ` \Pi x:A: A1 ^ \Pi x:A: A2
2. \Gamma  ` \Sigma x:A: A1 ^ \Sigma x:A: A2

Proof: The proof of both parts are similar. I give the proof for only part one here: By
Lemma 10.2.2, \Gamma ; x:A ` A1 :: \Omega  ) \Gamma  ` A :: \Omega  (Lemma 6.3.5 and DECL-T). The proof
proceeds by structural induction on the derivation of \Gamma ; x:A ` A1 ^ A2:

O-EQ: Given \Gamma ; x:A ` A1 = A2 :: \Omega  ) \Gamma  ` \Pi x:A: A1 = \Pi x:A: A2 :: \Omega  (E-REFL and E-DFUN)

) \Gamma  ` \Pi x:A: A1 ^ \Pi x:A: A2 (S-EQ).

O-ONE: Given \Gamma ; x:A ` A1 ! A2 ) \Gamma  ` \Pi x:A: A1 ! \Pi x:A: A2 (O-REFL and O-DFUN) )

\Gamma  ` \Pi x:A: A1 ^ \Pi x:A: A2 (S-ONE).

O-TRAN: Given \Gamma ; x:A ` A1 ^ A0 and \Gamma ; x:A ` A0 ^ A2. By the inductive hypothesis,

\Gamma  ` \Pi x:A: A1 ^ \Pi x:A: A0 and \Gamma  ` \Pi x:A: A0 ^ \Pi x:A: A2
) \Gamma  ` \Pi x:A: A1 ^ \Pi x:A: A2 (S-TRAN).

10.5. A SEMI-DECISION PROCEDURE 205

2

Theorem 10.5.4

1. If \Gamma  ` A2 ^ A1, \Gamma ; x:A1 ` A01 :: \Omega , and \Gamma ; x:A2 ` A01 ^ A02 then

\Gamma  ` \Pi x:A1: A01 ^ \Pi x:A2: A02.

2. If \Gamma  ` A1 ^ A2, \Gamma ; x:A2 ` A02 :: \Omega , and \Gamma ; x:A1 ` A01 ^ A02 then

\Gamma  ` \Sigma x:A1: A01 ^ \Sigma x:A2: A02.

Proof: The proof of both parts are similar. I give the proof for only part one
here: By Lemma 10.5.3, \Gamma  ` \Pi x:A2: A01 ^ \Pi x:A2: A02. By C-DFUN, \Gamma  ` \Pi x:A1: A01 :: \Omega  )
\Gamma  ` \Pi x:A1: A01 ^ \Pi x:A2: A01 (Lemma 10.5.2) ) \Gamma  ` \Pi x:A1: A01 ^ \Pi x:A2: A02 (S-TRAN).
2

Using these results and those proved earlier in the chapter, I can reduce the problem
of deciding subtyping on semi-canonical types to either simpler problems (e.g., equality or
shape inspection) or subtyping problems involving sub-components of the original types:

Theorem 10.5.5 Suppose A1 2 C\Gamma  and A2 2 C\Gamma . Then \Gamma  ` A1 ^ A2 iff at least one of
the following:

1. \Gamma  ` A1 = A2 :: \Omega 
2. 9K: bA1c = !=::K? and bA2c = !K?
3. 9x; A01; A001; A02; A002: A1 = \Pi x:A01: A001, A2 = \Pi x:A02: A002, \Gamma  ` A02 ^ A01, and

\Gamma ; x:A02 ` A001 ^ A002.

4. 9x; A01; A001; A02; A002: A1 = \Sigma x:A01: A001, A2 = \Sigma x:A02: A002, \Gamma  ` A01 ^ A02, and

\Gamma ; x:A01 ` A001 ^ A002.

Proof:

() Casing on which choice chosen:

case 1: By S-EQ, we have \Gamma  ` A1 ^ A2.
case 2: By the definition of constructor shapes, 9A01 such that A1 = !=A01::K? and

A2 = !K?. By Lemma 9.5.2, \Gamma  ` A1 :: \Omega  ) \Gamma  ` A01 :: K (C-TRANS) )
\Gamma  ` A1 ! A2 (O-FORGET) ) \Gamma  ` A1 ^ A2 (S-ONE).

case 3: By Lemma 9.5.2, \Gamma  ` A1 :: \Omega . By Theorem 10.5.4 then, \Gamma  ` A1 ^ A2.

206 CHAPTER 10. SUBTYPING
SU T (\Gamma ; A1; A2) = let A01 = CAN (\Gamma ; A1);

A02 = CAN (\Gamma ; A2) in
if EQL(\Gamma ; A01; A02; \Omega ) then

return
else

case (A01; A02) of
(!=A001::K?; !K?): return
(\Pi x:A4: A5; \Pi x:A6: A7): SU T (\Gamma ; A6; A4);

SU T ((\Gamma ; x:A6); A5; A7);
return
(\Sigma x:A4: A5; \Sigma x:A6: A7): SU T (\Gamma ; A4; A6);

SU T ((\Gamma ; x:A4); A5; A7);
return
A: raise fail

Figure 10.1: A semi-decision procedure for subtyping
case 4: By Lemma 9.5.2, \Gamma  ` A2 :: \Omega . By Theorem 10.5.4 then, \Gamma  ` A1 ^ A2.
)) By Lemma 10.3.9, dA1e\Gamma  = dA1e and dA2e\Gamma  = dA2e. By Corollary 10.3.12 then,

dA1e = dA2e or 9K: dA1e = !=::K? and dA2e = !K?. If the later is true,
then we are done (case 2 holds) so assume the former. By Corollary 10.3.14 then,
dA2e\Gamma  2 f\Pi ; \Sigma g or \Gamma  ` A1 = A2 :: \Omega . If the later is true, then we are done (case 1
holds) so assume the former. By Lemma 10.5.1 then, case 3 or 4 holds.

2

This result can be used to construct a semi-decision procedure for subtyping:
Theorem 10.5.6 (Semi-decidability)

The judgment \Gamma  ` A1 ^ A2 is semi-decidable. Non-termination only occurs if the judgment is false.

Proof: Using Theorems 10.5.5, 9.4.3, 9.4.11, and 9.5.10, a semi-recursive procedure is
easily created. An example procedure using the notations of Section 8.3 is contained in
Figure 10.1.

Here, CAN (\Gamma ; A) is an algorithm based on Theorem 9.5.10 that, if \Gamma  ` A :: \Omega  holds,
returns A0 such that A0 2 C\Gamma  and \Gamma  ` A = A0 :: \Omega . Otherwise, it raises fail. EQL(\Gamma ; A1; A2; K),

10.6. THE SIMPLE TYPE SYSTEM 207
based on Theorem 9.4.11, returns true if \Gamma  ` A1 = A2 :: K holds and returns false otherwise.

Inspection plus the theorems mentioned previously suffice to show that:

1. SU T (\Gamma ; A1; A2) returns iff \Gamma  ` A1 ^ A2.
2. SU T (\Gamma ; A1; A2) fails ) :\Gamma  ` A1 ^ A2.

2

10.6 The Simple Type System
In this and the next three sections, I show that the subtyping relation for my system is
undecidable using a slight modification to Benjamin Pierce's proof of the undecidability
of F^ subtyping [51, 50]. In order to make the source of the undecidability clear, I
shall first introduce the simple type system, which has only the minimum constructs and
rules required to produce undecidability; second show that the simple subtyping problem
is easier than the kernel system's subtyping problem; and third show that the simple
subtyping problem is undecidable.

The simple system has only types; there are no constructors of kind other than \Omega .
The methods for building types allow only for binary opaque weak sums (9ff:A), binary
transparent weak sums (9ff=A1:A2), and negative types (:A). Negative types abstract
the idea of contra-variant subtyping: \Gamma  ` :A ^ :A0 iff \Gamma  ` A0 ^ A. In a more realistic
type system, contra-variance would be part of a more complicated construct (e.g., \Pi -
types). The syntax for the simple type system is as follows:

Definition [Simple] 10.6.1 (Syntax)

Types A ::= ff j :A j 9ff:A j 9ff=A1:A2

Assignments \Gamma  ::= ffl j \Gamma ; ff

Here, the metavariable ff ranges over type variables. Equivalence of types, assignments, and other syntactic objects is defined as usual (ff-conversion modulo the assignment exception2), and the definitions of free type variables (FV(A)), type substitution
([A=ff]A0) , and the domain function (dom(\Gamma )) are the obvious ones:

2Namely, assignments with no redeclared variables are never considered equivalent to assignments
with redeclared variables.

208 CHAPTER 10. SUBTYPING
Definition [Simple] 10.6.2 (Free type variables)

FV(ff) = fffg
FV(:A) = FV(A)
FV(9ff:A) = FV(A) \Gamma  fffg
FV(9ff=A1:A2) = FV(A1) [ (FV(A2) \Gamma  fffg)

Definition [Simple] 10.6.3 (Type substitution)

[A=ff]ff = A
[A=ff]ff0 = ff0 (ff 6= ff0)
[A=ff](:A1) = :[A=ff]A1
[A=ff]9ff0:A1 = 9ff0:[A=ff]A1 (ff0 6= ff; ff0 62 FV(A))
[A=ff]9ff0=A1:A2 = 9ff0=[A=ff]A1:[A=ff]A2 (ff0 6= ff; ff0 62 FV(A))

Definition [Simple] 10.6.4 (Domain function)

dom(ffl) = ;
dom(\Gamma ; ff) = dom(\Gamma ) [ fffg

The simple type system has the following judgments:
Definition [Simple] 10.6.5 (Judgments)

` \Gamma  valid valid assignment
\Gamma  ` A valid valid type

\Gamma  ` A = A0 equal types
\Gamma  ` A ^ A0 subtyping relation

The rules for these judgments follow. In order to mirror Pierce's fragment F F^ (see
Section 6.4 of Pierce's thesis [51]) closely, these rules handle transparent definitions (ff=A)
by substitution rather than by adding a transparent definition to the current assignment.
(See, for example, the SUM-T and SU-SUM-T rules.)

Definition [Simple] 10.6.6 (Assignment Formation Rules)

` ffl valid (EMP)

` \Gamma  valid ff 62 dom(\Gamma )

` \Gamma ; ff valid (DCL)

10.6. THE SIMPLE TYPE SYSTEM 209
Definition [Simple] 10.6.7 (Type Formation Rules)

` \Gamma  valid ff 2 dom(\Gamma )

\Gamma  ` ff valid (VAR)

\Gamma  ` A valid
\Gamma  ` :A valid (NEG)

\Gamma ; ff ` A valid
\Gamma  ` 9ff:A valid (SUM-O)

\Gamma  ` A valid \Gamma  ` [A=ff]A0 valid

\Gamma  ` 9ff=A:A0 valid (SUM-T)

Definition [Simple] 10.6.8 (Equality Rules)

\Gamma  ` ff valid

\Gamma  ` ff = ff (EQ-VAR)

\Gamma  ` A1 = A2
\Gamma  ` :A1 = :A2 (EQ-NEG)

\Gamma ; ff ` A = A0
\Gamma  ` 9ff:A = 9ff:A0 (EQ-SUM-O)

\Gamma  ` A1 = A01 \Gamma  ` [A1=ff]A2 = [A1=ff]A02

\Gamma  ` 9ff=A1:A2 = 9ff=A01:A02 (EQ-SUM-T)

Definition [Simple] 10.6.9 (Subtyping Rules)

\Gamma  ` ff valid

\Gamma  ` ff ^ ff (SU-VAR)

\Gamma  ` A2 ^ A1
\Gamma  ` :A1 ^ :A2 (SU-NEG)

\Gamma ; ff ` A ^ A0
\Gamma  ` 9ff:A ^ 9ff:A0 (SU-SUM-O)

\Gamma  ` A1 = A01 \Gamma  ` [A1=ff]A2 ^ [A1=ff]A02

\Gamma  ` 9ff=A1:A2 ^ 9ff=A01:A02 (SU-SUM-T)

210 CHAPTER 10. SUBTYPING

\Gamma  ` A valid
\Gamma ; ff ` A2 valid \Gamma  ` [A=ff]A1 ^ [A=ff]A2

\Gamma  ` 9ff=A:A1 ^ 9ff:A2 (SU-FOR)

Note that all the rules are syntax directed: each shape or pair of shapes has at most
one applicable rule under each relation. Because of this fact, decision procedures can
be constructed directly from the rules. The termination of such procedures is unclear,
however, because the SUM-T, EQ-SUM-T, SU-SUM-T, and SU-FOR rules may increase
the size of the types being dealt with.

The usual propositions on judgments hold:

Lemma [Simple] 10.6.10 (Structural property I)

1. If ` \Gamma ; ff valid then ` \Gamma  valid.
2. If \Gamma  ` A valid then ` \Gamma  valid.

Lemma [Simple] 10.6.11 (Weakening)

Suppose ` \Gamma ; \Gamma 0 valid and dom(\Gamma 0) " dom(\Gamma 00) = ;. Then:

1. If ` \Gamma ; \Gamma 00 valid then ` \Gamma ; \Gamma 0; \Gamma 00 valid.
2. If \Gamma ; \Gamma 00 ` A valid then \Gamma ; \Gamma 0; \Gamma 00 ` A valid.

Proof: By sequential structural induction on the length of the derivations involving
\Gamma ; \Gamma 00. 2

Although the simple-subtyping relation lacks an EQ rule, the next lemma shows that
the following SU-EQ rule is derivable:

\Gamma  ` A1 = A2
\Gamma  ` A1 ^ A2 (SU-EQ)

Lemma [Simple] 10.6.12 If \Gamma  ` A1 = A2 then \Gamma  ` A1 ^ A2 and \Gamma  ` A2 ^ A1.
Proof: Proved by structural induction on the derivation. 2

The following notion of an extended simple-subtyping derivation that permits the use
of SU-EQ will be useful later:

10.6. THE SIMPLE TYPE SYSTEM 211
Definition [Simple] 10.6.13 (Extended derivations)
An extended derivation for \Gamma  ` A1 ^ A2 is a derivation of \Gamma  ` A1 ^ A2 using the normal
simple-subtyping rules plus the SU-EQ rule. The size of an extended derivation is defined
to be the number of SU rules (including SU-EQ) used in the derivation.

Because of Lemma 10.6.12, an extended derivation for \Gamma  ` A1 ^ A2 suffices to prove that
\Gamma  ` A1 ^ A2. Extended derivations will be important because their size as defined above
remains constant under operations such as strengthening and type substitution:

Lemma [Simple] 10.6.14 (Strengthening)

1. If ` \Gamma ; ff; \Gamma 0 valid then ` \Gamma ; \Gamma 0 valid.
2. If \Gamma ; ff; \Gamma 0 ` A valid and ff 62 FV(A) then \Gamma ; \Gamma 0 ` A valid.
3. If \Gamma ; ff; \Gamma 0 ` A1 = A2 and ff 62 FV(A1) [ FV(A2) then \Gamma ; \Gamma 0 ` A1 = A2.
4. If \Gamma ; ff; \Gamma 0 ` A1 ^ A2 by an extended derivation and ff 62 FV(A1) [ FV(A2) then

\Gamma ; \Gamma 0 ` A1 ^ A2 by an extended derivation of equal size.

Proof: Proved sequentially by structural induction on the derivations. 2

Lemma [Simple] 10.6.15 Suppose \Gamma  ` A valid. Then:

1. If \Gamma ; ff; \Gamma 0 ` A1 valid then \Gamma ; ff; \Gamma 0 ` [A=ff]A1 valid.

2. If \Gamma ; ff; \Gamma 0 ` A1 = A2 then \Gamma ; ff; \Gamma 0 ` [A=ff]A1 = [A=ff]A2.
3. If \Gamma ; ff; \Gamma 0 ` A1 ^ A2 by an extended derivation then

\Gamma ; ff; \Gamma 0 ` [A=ff]A1 ^ [A=ff]A2 by an extended derivation of equal size.

Proof: Proved sequentially by structural induction on the derivations involving A1.
Lemma 10.6.11 and Lemma 10.6.10 are used to handle the VAR case. The SU-EQ rule
is used to handle the SU-VAR case in order to keep the resulting derivation the same
size. 2

Corollary [Simple] 10.6.16 (Validity of type substitution)

Suppose \Gamma  ` A valid. Then:

1. If \Gamma ; ff ` A1 = A2 then \Gamma  ` [A=ff]A1 = [A=ff]A2.

2. If \Gamma ; ff ` A1 ^ A2 by an extended derivation then

\Gamma  ` [A=ff]A1 ^ [A=ff]A2 by an extended derivation of equal size.

Proof: Follows immediately from Lemma 10.6.15 and Theorem 10.6.14. 2

212 CHAPTER 10. SUBTYPING
10.7 Encoding Simple Judgments

I shall show that the simple subtyping problem is easier than than the kernel system's subtyping problem by showing that simple subtyping problems can be translated into equivalent kernel-system subtyping problems using the following encoding on simple-system
types, assignments, and judgments. The encoding results in kernel-system constructors,
assignments, and judgments respectively.

Definition [Simple] 10.7.1 (Encoding simple judgments)

ff\Omega  = bff!
(:A)\Omega  = \Pi x:A\Omega : !\Omega ?
(9ff:A1)\Omega  = \Sigma bff:!\Omega ?: A\Omega 1
(9ff=A1:A2)\Omega  = \Sigma bff:!=A\Omega 1 ::\Omega ?: A\Omega 2

ffl\Omega  = ffl
(\Gamma ; ff)\Omega  = \Gamma \Omega ; bff:!\Omega ?

(` \Gamma  valid)\Omega  = ` \Gamma \Omega  valid
(\Gamma  ` A valid)\Omega  = \Gamma \Omega  ` A\Omega  :: \Omega 
(\Gamma  ` A1 = A2)\Omega  = \Gamma \Omega  ` A\Omega 1 = A\Omega 2 :: \Omega 
(\Gamma  ` A1 ^ A2)\Omega  = \Gamma \Omega  ` A\Omega 1 ^ A\Omega 2

Here, b\Gamma  is any bijective mapping from simple type variables to kernel-system term variables.

Encoding type substitution in the simple system results in the substitution in the
kernel system of a constructor for a constructor extraction:

10.7. ENCODING SIMPLE JUDGMENTS 213
Definition 10.7.2 (Constructor substitution for an extraction)

[A=xae!]xae! = A
[A=xae!]x0ae0! = x0ae0! (xae 6= x0ae0)

[A=xae!]ff = ff
[A=xae!]*ff0::K: A0 = *ff0::K: [A=xae!]A0 (ff0 62 FCV(A))
[A=xae!]\Pi x0:A1: A2 = \Pi x0:[A=xae!]A1: [A=xae!]A2 (x0 6= x; x0 62 FTV(A))

[A=xae!]\Sigma x0:A1: A2 = \Sigma x0:[A=xae!]A1: [A=xae!]A2 (x0 6= x; x0 62 FTV(A))

[A=xae!](A1 A2) = [A=xae!]A1 [A=xae!]A2
[A=xae!]!=A0::K? = !=[A=xae!]A0::K?

[A=xae!]!K? = !K?

[A=xae!]rec = rec

[A=xae!]ref = ref

[A=xae!](ff::K) = ff::K

[A=xae!](x0:A0) = x0:[A=xae!]A0

[A=xae!]ffl = ffl
[A=xae!](\Gamma ; D) = ([A=xae!]\Gamma ); [A=xae!]D

Lemma [Simple] 10.7.3 (Encoding properties)

1. dom(\Gamma \Omega ) = ddom(\Gamma )
2. ([A1=ff]A2)\Omega  = [A\Omega 1 =bff!](A\Omega 2 )

Proof: Proved using induction on \Gamma  and A2 respectively. 2

The intrinsic shapes of encoded simple types can be computed using previous results.
Note that encoded variables have intrinsic shape ? because simple assignments do not
have transparent definitions.

Lemma [Simple] 10.7.4 (Shapes of encoded types)

1. If \Gamma \Omega  ` ff\Omega  :: \Omega  then dff\Omega e\Gamma \Omega  = ?.
2. If \Gamma \Omega  ` (:A0)\Omega  :: \Omega  then d(:A0)\Omega e\Gamma \Omega  = \Pi .
3. If \Gamma \Omega  ` (9ff:A1)\Omega  :: \Omega  then d(9ff:A1)\Omega e\Gamma \Omega  = \Sigma .

214 CHAPTER 10. SUBTYPING

4. If \Gamma \Omega  ` (9ff=A1:A2)\Omega  :: \Omega  then d(9ff=A1:A2)\Omega e\Gamma \Omega  = \Sigma .
Proof: For part one, we have \Gamma \Omega  ` ff\Omega  :: \Omega  ) \Gamma \Omega  ` bff! :: \Omega  ) bff 2 dom(\Gamma \Omega ) (Theorem 6.5.6) ) ff 2 dom(\Gamma ) (Lemma 10.7.3) ) bff:!\Omega ? 2 \Gamma \Omega  ) \Gamma \Omega (bff) = !\Omega ? (Lemma 6.3.5
and Lemma 9.4.2) ) bff! 2 C\Gamma \Omega . (Lemma 9.5.11) ) dbff!e\Gamma \Omega  = dbff!e = ? (Lemma 10.3.9).

Parts two to four follow immediately from the definitions of the encoding, intrinsic
shape, and E-REFL. 2

In order to show that simple subtyping problems can be translated into equivalent
kernel-system subtyping problems, I shall need the following series of lemmas relating
substitutions for constructor extractions and transparent definitions (x:!=A::\Omega ?) in the
kernel system:

Lemma 10.7.5 If \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]A0 :: K then
\Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]A0 = A0 :: K .

Proof: Proved by structural induction on A0. Interesting cases:
DFUN: Here \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]\Pi x0:A1: A2 :: \Omega , x0 62 dom(\Gamma ; x:!=A::\Omega ?; \Gamma 0)

) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` \Pi x0:[A=x!]A1: [A=x!]A2 :: \Omega 
) \Gamma ; x:!=A::\Omega ?; \Gamma 0; x0:[A=x!]A1 ` [A=x!]A2 :: \Omega  (C-DFUN)
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]A1 :: \Omega  (Lemma 6.3.5)
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]A1 = A1 :: \Omega  and
\Gamma ; x:!=A::\Omega ?; \Gamma 0; x0:[A=x!]A1 ` [A=x!]A2 = A2 :: \Omega  (induction hypothesis)
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` \Pi x0:[A=x!]A1: [A=x!]A2 = \Pi x0:A1: A2 :: \Omega  (E-DFUN)
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]\Pi x0:A1: A2 = \Pi x0:A1: A2 :: K

EXT I: Here \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]x! :: K ) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` A :: K. By Lemma 6.3.5,

` \Gamma ; x:!=A::\Omega ?; \Gamma 0 valid and ` \Gamma ; x:!=A::\Omega ? valid ) \Gamma  ` !=A::\Omega ? :: \Omega  (DECLT) ) \Gamma  ` A :: \Omega  (C-TRANS) ) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` A :: \Omega  (Theorem 9.4.1) )
K = \Omega  (Theorem 9.4.5). By P-INIT, \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` x ) !=A::\Omega ?
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` x! = A :: \Omega  (C-EXT-T, E-ABBREV, E-REFL, and C-TRANS)
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]x! = x! :: \Omega  (E-SYM)

2

Lemma 10.7.6 If \Gamma  ` A :: \Omega  and \Gamma  ` [A=x!]A0 :: \Omega , x 62 dom(\Gamma ), then
\Gamma ; x:!=A::\Omega ? ` [A=x!]A0 = A0 :: \Omega .

10.7. ENCODING SIMPLE JUDGMENTS 215
Proof: By C-TRANS, \Gamma  ` !=A::\Omega ? :: \Omega . By Lemma 6.3.5, ` \Gamma  valid
) ` \Gamma ; x:!=A::\Omega ? valid (DECL-T) ) \Gamma ; x:!=A::\Omega ? ` [A=x!]A0 :: \Omega  (Theorem 9.4.1)
) \Gamma ; x:!=A::\Omega ? ` [A=x!]A0 = A0 :: \Omega . (Lemma 10.7.5) 2

Lemma 10.7.7 If \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` A0 :: K then
\Gamma ; x:!=A::\Omega ?; \Gamma 0 ` A0 = [A=x!]A0 :: K .

Proof: Proved by structural induction on A0. Interesting cases:
DFUN: Here \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` \Pi x0:A1: A2 :: \Omega , x0 62 dom(\Gamma ; x:!=A::\Omega ?; \Gamma 0)

) \Gamma ; x:!=A::\Omega ?; \Gamma 0; x0:A1 ` A2 :: \Omega  (C-DFUN) ) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` A1 :: \Omega 
(Lemma 6.3.5) ) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` A1 = [A=x!]A1 :: \Omega  and
\Gamma ; x:!=A::\Omega ?; \Gamma 0; x0:A1 ` A2 = [A=x!]A2 :: \Omega  (induction hypothesis)
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` \Pi x0:A1: A2 = \Pi x0:[A=x!]A1: [A=x!]A2 :: \Omega  (E-DFUN)
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` \Pi x0:A1: A2 = [A=x!]\Pi x0:A1: A2 :: \Omega 

EXT I: Here \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` x! :: K ) ` \Gamma ; x:!=A::\Omega ?; \Gamma 0 valid (Lemma 6.3.5) )

\Gamma ; x:!=A::\Omega ?; \Gamma 0 ` x ) !=A::\Omega ? (P-INIT)
) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` x! = A :: \Omega  (C-EXT-T, E-ABBREV, E-REFL, and Theorem 9.4.4) ) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` x! = [A=x!]x! :: \Omega  By Theorem 9.4.5 and Theorem 9.4.3, K = \Omega  ) \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` x! = [A=x!]x! :: K

2

Lemma [Simple] 10.7.8 Suppose \Gamma ; x:!=A::\Omega ?; \Gamma 0 ` A1 ! A2 by a derivation that uses
s applications of the one-step subtyping rules. Then
\Gamma ; x:!=A::\Omega ?; \Gamma 0 ` [A=x!]A1 ! [A=x!]A2 by s applications of the one-step subtyping rules.

Proof: Proved by structural induction on the derivation. Lemmas 10.1.2, 10.7.7,
and Theorem 9.4.3 are used to establish that [A=x!]A1 and [A=x!]A2 are valid under
\Gamma ; x:!=A::\Omega ?; \Gamma 0. Theorem 10.1.6 is needed in addition to handle the O-DFUN and
O-DSUM cases; inspection of its proof shows that it leaves the number of applications of
the one-step subtyping rules unchanged. 2

The previous lemmas when combined with the following lemma, the structural properties, strengthening, weakening, and transitivity, allow converting between the use of transparent definitions and substitutions. For example, given \Gamma  ` A\Omega  :: \Omega  and x 62 dom(\Gamma ), we
can show that \Gamma ; x:!=A\Omega ::\Omega ? ` A\Omega 1 = A\Omega 2 :: \Omega  iff \Gamma  ` [A\Omega =x!](A\Omega 1 ) = [A\Omega =x!](A\Omega 2 ) :: \Omega .

Lemma [Simple] 10.7.9 If bff 62 FTV(A0\Omega ) then bff 62 FTV([A0\Omega =bff!](A\Omega ))

216 CHAPTER 10. SUBTYPING
10.8 Problem Reduction
In this section I show that for any simple judgment J , J holds in the simple system iff
J \Omega  holds in the kernel system. The forward direction is straightforward:

Lemma [Simple] 10.8.1 (Reduction I)

1. If ` \Gamma  valid then ` \Gamma \Omega  valid.
2. If \Gamma  ` A valid then \Gamma \Omega  ` A\Omega  :: \Omega .
3. If \Gamma  ` A1 = A2 then \Gamma \Omega  ` A\Omega 1 = A\Omega 2 :: \Omega .
4. If \Gamma  ` A1 ^ A2 then \Gamma \Omega  ` A\Omega 1 ^ A\Omega 2 .
Proof: Proved by simultaneous induction on the derivations. Interesting cases:
DCL: Here ` \Gamma ; ff valid derived via rule DCL from ` \Gamma  valid and ff 62 dom(\Gamma ) ) bff 62

dom(\Gamma \Omega ) (Lemma 10.7.3). By the induction hypothesis, ` \Gamma \Omega  valid ) \Gamma \Omega  ` !\Omega ? :: \Omega 
(C-OPAQ) ) ` \Gamma \Omega ; bff:!\Omega ? valid (DECL-T) ) ` (\Gamma ; ff)\Omega  valid.

VAR: Here, \Gamma  ` ff valid derived via VAR from ` \Gamma  valid and ff 2 dom(\Gamma ) ) bff:!\Omega ? 2 \Gamma \Omega 

By the induction hypothesis, ` \Gamma \Omega  valid ) \Gamma \Omega  ` bff ) !\Omega ? (P-INIT) ) \Gamma \Omega  ` bff! :: \Omega 
(C-EXT-O) ) \Gamma \Omega  ` ff\Omega  :: \Omega .

SUM-T: Here, \Gamma  ` 9ff=A:A0 valid derived via SUM-T from \Gamma  ` A valid and

\Gamma  ` [A=ff]A0 valid, ff 62 dom(\Gamma ) ) bff 62 dom(\Gamma \Omega ) (Lemma 10.7.3). By applying the
induction hypothesis, \Gamma \Omega  ` A\Omega  :: \Omega  and \Gamma \Omega  ` ([A=ff]A0)\Omega  :: \Omega  ) \Gamma \Omega  ` [A\Omega =bff!](A0\Omega ) :: \Omega 
(Lemma 10.7.3)
) \Gamma \Omega ; bff:!=A\Omega ::\Omega ? ` [A\Omega =bff!](A0\Omega ) = A0\Omega  :: \Omega  (Lemma 10.7.6)
) \Gamma \Omega ; bff:!=A\Omega ::\Omega ? ` A0\Omega  :: \Omega  (Theorem 9.4.3)
) \Gamma \Omega  ` \Sigma bff:!=A\Omega ::\Omega ?: A0\Omega  :: \Omega  (C-DSUM) ) \Gamma \Omega  ` (9ff=A:A0)\Omega  :: \Omega .

EQ-SUM-T: Here, \Gamma  ` 9ff=A1:A2 = 9ff=A01:A02 , ff 62 dom(\Gamma ), derived via EQ-SUM-T from

\Gamma  ` A1 = A01 and \Gamma  ` [A1=ff]A2 = [A1=ff]A02 ) bff 62 dom(\Gamma \Omega ) (Lemma 10.7.3). By
the induction hypothesis, \Gamma \Omega  ` A\Omega 1 = A0\Omega 1 :: \Omega  and
\Gamma \Omega  ` ([A1=ff]A2)\Omega  = ([A1=ff]A02)\Omega  :: \Omega 
) \Gamma \Omega  ` [A\Omega 1 =bff!](A\Omega 2 ) = [A\Omega 1 =bff!](A0\Omega 2 ) :: \Omega  (Lemma 10.7.3)
) \Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` [A\Omega 1 =bff!](A\Omega 2 ) = A\Omega 2 :: \Omega  and
\Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` [A\Omega 1 =bff!](A0\Omega 2 ) = A0\Omega 2 :: \Omega  (Lemmas 9.4.3 and 10.7.6)
) \Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` A\Omega 2 = A0\Omega 2 :: \Omega  (E-SYM and E-TRAN)
) \Gamma \Omega  ` \Sigma bff:!=A\Omega 1 ::\Omega ?: A\Omega 2 = \Sigma bff:!=A0\Omega 1 ::\Omega ?: A0\Omega 2 :: \Omega  (E-TRANS and E-DSUM)
) \Gamma \Omega  ` (9ff=A1:A2)\Omega  = (9ff=A01:A02)\Omega  :: \Omega 

10.8. PROBLEM REDUCTION 217
SU-FOR: Here, \Gamma  ` 9ff=A:A1 ^ 9ff:A2, ff 62 dom(\Gamma ), derived via SU-FOR from \Gamma  ` A valid,

\Gamma ; ff ` A2 valid, and \Gamma  ` [A=ff]A1 ^ [A=ff]A2 ) bff 62 dom(\Gamma \Omega ) (Lemma 10.7.3). By
the induction hypothesis, \Gamma \Omega  ` A\Omega  :: \Omega , \Gamma \Omega ; bff:!\Omega ? ` A\Omega 2 :: \Omega , and
\Gamma \Omega  ` ([A=ff]A1)\Omega  ^ ([A=ff]A2)\Omega  ) \Gamma \Omega  ` [A\Omega =bff!](A\Omega 1 ) ^ [A\Omega =bff!](A\Omega 2 ) (Lemma 10.7.3)
) \Gamma \Omega ; bff:!=A\Omega ::\Omega ? ` [A\Omega =bff!](A\Omega 1 ) = A\Omega 1 :: \Omega  and
\Gamma \Omega ; bff:!=A\Omega ::\Omega ? ` [A\Omega =bff!](A\Omega 2 ) = A\Omega 2 :: \Omega  (Lemmas 10.2.2 and 10.7.6)
) \Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` A\Omega 1 ^ A\Omega 2 (E-SYM, S-EQ, and S-TRAN).

By Lemma 6.3.5, DECL-T, C-TRANS, O-FORGET, S-ONE,
\Gamma \Omega  ` !=A\Omega 1 ::\Omega ? ^ !\Omega ? ) \Gamma \Omega  ` \Sigma bff:!=A\Omega ::\Omega ?: A\Omega 1 ^ \Sigma bff:!\Omega ?: A\Omega 2
(Theorem 10.5.4) ) \Gamma \Omega  ` (9ff=A:A1)\Omega  ^ (9ff:A2)\Omega 

2

The backward direction is harder. To handle the simple validity and equality judgments, the following metric on types is useful:

Definition [Simple] 10.8.2 (Size metric)

jffj = 0
j:Aj = 1 + jAj
j9ff:Aj = 1 + jAj
j9ff=A:A0j = 1 + jAj + j[A=ff]A0j

This definition can be seen to be well defined by noticing that if we extend types so they
may contain integers and define jij = i, we get that j[A1=ff]A2j = j[jA1j=ff]A2j. Note
that under this metric, both A1 and [A1=ff]A2 are smaller than 9ff=A1:A2. This fact will
allow us to recurse on the "natural sub-components" of a simple type.

Using this metric proving the backward direction for the validity judgments is straightforward:

Lemma [Simple] 10.8.3 (Reduction II: validity)

1. If ` \Gamma \Omega  valid then ` \Gamma  valid.
2. If \Gamma \Omega  ` A\Omega  :: \Omega  then \Gamma  ` A valid.
Proof: Proved sequentially by induction on j\Gamma j and jAj respectively. Interesting cases:

Dcl: Here ` (\Gamma ; ff)\Omega  valid ) ` \Gamma \Omega ; bff:!\Omega ? valid ) bff 62 dom(\Gamma \Omega ) and

\Gamma \Omega  ` !\Omega ? :: \Omega  (DECL-T) ) ff 62 dom(\Gamma ) (Lemma 10.7.3) and ` \Gamma \Omega  valid
(Lemma 6.3.5) ) ` \Gamma  valid (induction hypothesis) ) ` \Gamma ; ff valid (DCL).

218 CHAPTER 10. SUBTYPING

Var: Here \Gamma \Omega  ` ff\Omega  :: \Omega  ) \Gamma \Omega  ` bff! :: \Omega  ) \Gamma \Omega  ` bff ) !\Omega ? or \Gamma \Omega  ` bff ) !=A::\Omega ? for

some A (C-EXT-O and C-EXT-T) ) ` \Gamma \Omega  valid (Lemma 6.3.5) and bff 2 dom(\Gamma \Omega )
(Theorem 6.5.6) ) ` \Gamma  valid (induction hypothesis) and ff 2 dom(\Gamma ) (Lemma 10.7.3)
) \Gamma  ` ff valid (VAR).

TSum: Here \Gamma \Omega  ` (9ff=A1:A2)\Omega  :: \Omega , ff 62 dom(\Gamma ) ) \Gamma \Omega  ` \Sigma bff:!=A\Omega 1 ::\Omega ?: A\Omega 2 :: \Omega  and

bff 62 dom(\Gamma \Omega ) (Lemma 10.7.3) ) \Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` A\Omega 2 :: \Omega  (C-DSUM)

) \Gamma \Omega  ` !=A\Omega 1 ::\Omega ? :: \Omega  (Lemma 6.3.5 and DECL-T) and
\Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` A\Omega 2 = [A\Omega 1 =bff!]A\Omega 2 :: \Omega  (Lemma 10.7.7) ) \Gamma \Omega  ` A\Omega 1 :: \Omega  (C-TRANS)
and \Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` [A\Omega 1 =bff!]A\Omega 2 :: \Omega  (Theorem 9.4.3) ) \Gamma \Omega  ` [A\Omega 1 =bff!]A\Omega 2 :: \Omega 
(Theorem 6.5.6, Lemma 10.7.9, and Theorem 9.6.1) ) \Gamma \Omega  ` ([A1=ff]A2)\Omega  :: \Omega 
(Lemma 10.7.3) ) \Gamma  ` A1 valid and \Gamma  ` [A1=ff]A2 valid (induction hypothesis) )
\Gamma  ` 9ff=A1:A2 valid (SUM-T).

2

Because equality in the kernel system between encoded simple types can proceed
via transitivity through constructors which have no analog in the simple system (e.g.,
constructor applications), kernel-system equality derivations cannot be directly converted
into the simple system. Instead, the derivations must converted as we go into a form that
does not use the transitivity rule; this conversion is accomplished by using the results
about how equality acts in a component-wise manner and about how equality relates the
intrinsic shapes of encoded types. The size metric is used to ensure that the conversion
process terminates.

Lemma [Simple] 10.8.4 (Reduction II: equality)

If \Gamma \Omega  ` A\Omega 1 = A\Omega 2 :: \Omega  then \Gamma  ` A1 = A2.

Proof: Proved by induction on jA1j. By Theorem 9.4.3, Lemma 10.7.4, Lemma 10.3.3,
and the definition of intrinsic shapes, we have only the following cases:

Var: Here \Gamma \Omega  ` ff\Omega 1 = ff\Omega 2 :: \Omega  ) \Gamma \Omega  ` cff1! = cff2! :: \Omega  ) \Gamma \Omega  ` cff1! :: \Omega  (Theorem 9.4.3) )

\Gamma  ` ff1 valid (Lemma 10.8.3).

Hence, for i 2 f1; 2g, we have: \Gamma \Omega  ` cffi! :: \Omega  (Theorem 9.4.3) ) cffi 2 dom(\Gamma \Omega )
(Theorem 6.5.6) ) ffi 2 dom(\Gamma ) (Lemma 10.7.3) ) cffi:!\Omega ? 2 \Gamma \Omega  ) \Gamma \Omega (ffi) =
!\Omega ? (Lemma 9.4.2) ) cffi! 2 C\Gamma \Omega  (Lemma 9.5.11) ) cff1! = cff2! (Lemma 9.5.12)
) ff1 = ff2 ) \Gamma  ` ff1 = ff2 (EQ-VAR).

Neg: \Gamma \Omega  ` (:A1)\Omega  = (:A2)\Omega  :: \Omega 

) \Gamma \Omega  ` \Pi x:A\Omega 1 : !\Omega ? = \Pi x:A\Omega 2 : !\Omega ? :: \Omega , x 62 dom(\Gamma \Omega )
) \Gamma \Omega  ` A\Omega 1 = A\Omega 2 :: \Omega  (Lemma 9.4.10) ) \Gamma  ` A1 = A2 (induction hypothesis) )
\Gamma  ` :A1 = :A2 (EQ-NEG).

10.8. PROBLEM REDUCTION 219
OSum: \Gamma \Omega  ` (9ff:A1)\Omega  = (9ff:A2)\Omega  :: \Omega , ff 62 dom(\Gamma )

) \Gamma \Omega  ` \Sigma bff:!\Omega ?: A\Omega 1 = \Sigma bff:!\Omega ?: A\Omega 2 :: \Omega  and bff 62 dom(\Gamma \Omega )
(Lemma 10.7.3) ) \Gamma \Omega ; bff:!\Omega ? ` A\Omega 1 = A\Omega 2 :: \Omega  (Lemma 9.4.10)
) \Gamma ; ff ` A1 = A2 (induction hypothesis) ) \Gamma  ` 9ff:A1 = 9ff:A2 (EQ-SUM-O).

TSum: \Gamma \Omega  ` (9ff=A1:A2)\Omega  = (9ff=A01:A02)\Omega  :: \Omega , ff 62 dom(\Gamma )

) \Gamma \Omega  ` \Sigma bff:!=A\Omega 1 ::\Omega ?: A\Omega 2 = \Sigma bff:!=A0\Omega 1 ::\Omega ?: A0\Omega 2 :: \Omega  and bff 62 \Gamma \Omega  (Lemma 10.7.3)
) \Gamma \Omega  ` !=A\Omega 1 ::\Omega ? = !=A0\Omega 1 ::\Omega ? :: \Omega  and
\Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` A\Omega 2 = A0\Omega 2 :: \Omega  (Lemma 9.4.10) ) \Gamma \Omega  ` A\Omega 1 = A0\Omega 1 :: \Omega 
(Lemma 9.4.10) and \Gamma \Omega ; bff:!=A\Omega 1 ::\Omega ? ` [A\Omega 1 =bff]A\Omega 2 = [A\Omega 1 =bff]A0\Omega 2 :: \Omega 
(Theorem 9.4.3, Lemma 10.7.7, E-SYM, and E-TRAN)
) \Gamma \Omega  ` [A\Omega 1 =bff]A\Omega 2 = [A\Omega 1 =bff]A0\Omega 2 :: \Omega  (Theorem 9.4.3, Theorem 6.5.6,
Lemma 10.7.9, and Theorem 9.6.1)
) \Gamma \Omega  ` ([A1=ff]A2)\Omega  = ([A1=ff]A02)\Omega  :: \Omega  (Lemma 10.7.3) ) \Gamma  ` A1 = A01 and
\Gamma  ` [A1=ff]A2 = [A1=ff]A02 (induction hypothesis)
) \Gamma  ` 9ff=A1:A2 = 9ff=A01:A02 (EQ-SUM-T).

2

Some useful properties about the simple equality and subtyping relations can be
transfered from the kernel system using the results so far:

Theorem [Simple] 10.8.5 (Equality properties)

1. If \Gamma  ` A valid then \Gamma  ` A = A.
2. If \Gamma  ` A1 = A2 then \Gamma  ` A2 = A1.
3. If \Gamma  ` A1 = A2 and \Gamma  ` A2 = A3 then \Gamma  ` A1 = A3.

Proof: Each part is proved the same way: first convert to the kernel system using
Lemma 10.8.1, second apply the relevant kernel rule (E-REFL, E-SYM, and E-TRAN
respectively), and third, transfer the result back to the simple system using Lemma 10.8.3
or Lemma 10.8.4. 2

Corollary [Simple] 10.8.6 (Reflexivity) If \Gamma  ` A valid then \Gamma  ` A ^ A.
Proof: Follows immediately from Theorem 10.8.5 and Lemma 10.6.12. 2

220 CHAPTER 10. SUBTYPING
Theorem [Simple] 10.8.7 (Structural property II)

1. If \Gamma  ` A1 = A2 then \Gamma  ` A1 valid and \Gamma  ` A2 valid.
2. If \Gamma  ` A1 ^ A2 then \Gamma  ` A1 valid and \Gamma  ` A2 valid.

Proof: Proved by first converting to the kernel system using Lemma 10.8.1, second
applying either Theorem 9.4.3 or Lemma 10.2.2, and third, transferring the result back
to the simple system using Lemma 10.8.3. 2

A similar problem to that of the equality judgment case arises with the subtyping
judgment case. Unfortunately, because of the SU-NEG and SU-FOR rules, the simpletype size metric cannot be used to ensure termination here, forcing a different proof
strategy to be used. My solution to this problem involves taking advantage of the fact
that kernel-system subtyping is defined (see Section 10.2) in terms of a series of equality
and one-step subtyping steps joined by transitivity.

I have already shown that kernel-system equality steps can be converted to simple
subtyping steps (Lemmas 10.8.4 and 10.6.12). I shall show next that one-step subtyping
can also be converted to simple subtyping. Because the one-step subtyping relation
lacks any transitivity rule, the proof of this fact is fairly straightforward. By showing
that simple subtyping is transitive, I shall then have that any kernel-system subtyping
judgment derivation can be converted to a simple subtyping judgment derivation by
converting its steps one at a time to simple subtyping and then combining the resulting
steps via transitivity.

Lemma [Simple] 10.8.8 (Reduction II: one-step subtyping)

If \Gamma \Omega  ` A\Omega 1 ! A\Omega 2 then \Gamma  ` A1 ^ A2.

Proof: Proved by induction on the number of applications of the one-step subtyping
rules needed to derive \Gamma \Omega  ` A\Omega 1 ! A\Omega 2 . Interesting cases:

O-REFL: Here \Gamma \Omega  ` A\Omega  ! A\Omega  derived via O-REFL from \Gamma \Omega  ` A\Omega  :: \Omega  ) \Gamma  ` A valid

(Lemma 10.8.3) ) \Gamma  ` A ^ A (Corollary 10.8.6)

O-DFUN: Here \Gamma \Omega  ` (:A1)\Omega  ! (:A2)\Omega  derived via O-DFUN from \Gamma \Omega  ` A\Omega 2 ! A\Omega 1 ) \Gamma  ` A2 ^ A1

(induction hypothesis) ) \Gamma  ` :A1 ^ :A2 (SU-NEG).

O-DSUM I: Here \Gamma \Omega  ` (9ff:A1)\Omega  ! (9ff:A2)\Omega , ff 62 dom(\Gamma ), derived via O-DSUM from

\Gamma \Omega  ` !\Omega ? ! !\Omega ?, \Gamma \Omega ; bff:!\Omega ? ` A\Omega 1 ! A\Omega 2 , and \Gamma \Omega ; bff:!\Omega ? ` A\Omega 2 :: \Omega 
) \Gamma ; ff ` A1 ^ A2 (induction hypothesis) ) \Gamma  ` 9ff:A1 ^ 9ff:A2 (SU-SUM-O).

10.8. PROBLEM REDUCTION 221
O-DSUM II: Here \Gamma \Omega  ` (9ff=A01:A1)\Omega  ! (9ff:A2)\Omega , ff 62 dom(\Gamma ), derived via O-DSUM from

\Gamma \Omega  ` !=A0\Omega 1 ::\Omega ? ! !\Omega ?, \Gamma \Omega ; bff:!=A0\Omega 1 ::\Omega ? ` A\Omega 1 ! A\Omega 2 , and
\Gamma \Omega ; bff:!\Omega ? ` A\Omega 2 :: \Omega  ) \Gamma ; ff ` A2 valid (Lemma 10.8.3) and \Gamma \Omega  ` A0\Omega 1 :: \Omega  (OFORGET) and \Gamma \Omega ; bff:!=A0\Omega 1 ::\Omega ? ` [A0\Omega 1 =bff!]A\Omega 1 ! [A0\Omega 1 =bff!]A\Omega 2
(Lemma 10.7.8) ) \Gamma  ` A01 valid (Lemma 10.8.3) and
\Gamma \Omega  ` ([A01=ff]A1)\Omega  ! ([A01=ff]A2)\Omega  (Lemma 10.1.4 and Lemma 10.7.3).

Since by Lemma 10.7.8 and by inspection of the proof of Lemma 10.1.4,
\Gamma \Omega  ` ([A01=ff]A1)\Omega  ! ([A01=ff]A2)\Omega  uses the same number of applications of the onestep subtyping rules as does \Gamma \Omega ; bff:!=A0\Omega 1 ::\Omega ? ` A\Omega 1 ! A\Omega 2 , a sub-derivation of the
original derivation, we can apply the induction hypothesis to get
\Gamma  ` [A01=ff]A1 ^ [A01=ff]A2 ) \Gamma  ` 9ff=A01:A1 ^ 9ff:A2 (SU-FOR).

O-DSUM III: Here \Gamma \Omega  ` (9ff=A01:A1)\Omega  ! (9ff=A02:A2)\Omega , ff 62 dom(\Gamma ), derived via O-DSUM from

\Gamma \Omega  ` !=A0\Omega 1 ::\Omega ? ! !=A0\Omega 2 ::\Omega ?, \Gamma \Omega ; bff:!=A0\Omega 1 ::\Omega ? ` A\Omega 1 ! A\Omega 2 , and
\Gamma \Omega ; bff:!=A0\Omega 2 ::\Omega ? ` A\Omega 2 :: \Omega  ) A0\Omega 1 = A0\Omega 2 and \Gamma \Omega  ` !=A0\Omega 1 ::\Omega ? :: \Omega  (O-REFL)
and \Gamma \Omega ; bff:!=A0\Omega 1 ::\Omega ? ` [A0\Omega 1 =bff!]A\Omega 1 ! [A0\Omega 1 =bff!]A\Omega 2 (Lemma 10.7.8)
) \Gamma \Omega  ` A0\Omega 1 :: \Omega  (C-TRANS) and \Gamma \Omega  ` ([A01=ff]A1)\Omega  ! ([A01=ff]A2)\Omega 
(Lemma 10.1.4 and Lemma 10.7.3) ) \Gamma \Omega  ` A0\Omega 1 = A0\Omega 2 :: \Omega  (E-REFL) ) \Gamma  ` A01 = A02
(Lemma 10.8.4).

Since by Lemma 10.7.8 and by inspection of the proof of Lemma 10.1.4,
\Gamma \Omega  ` ([A01=ff]A1)\Omega  ! ([A01=ff]A2)\Omega  uses the same number of applications of the onestep subtyping rules as does \Gamma \Omega ; bff:!=A0\Omega 1 ::\Omega ? ` A\Omega 1 ! A\Omega 2 , a sub-derivation of the
original derivation, we can apply the induction hypothesis to get
\Gamma  ` [A01=ff]A1 ^ [A01=ff]A2 ) \Gamma  ` 9ff=A01:A1 ^ 9ff=A02:A2 (SU-SUM-T).

2

In order to prove transitivity for simple subtyping, we shall first need to prove
a lemma that if \Gamma  ` A = A0 and \Gamma  ` [A=ff]A1 ^ [A=ff]A2 by an extended derivation,
then \Gamma  ` [A0=ff]A1 ^ [A0=ff]A2 by an extended derivation of equal size. This result
is needed to handle the case where we have that \Gamma  ` 9ff=A1:A01 ^ 9ff=A2:A02 and
\Gamma  ` 9ff=A2:A02 ^ 9ff=A3:A03, both by extended derivations via the SU-SUM-T rule. By
SU-SUM-T, we also have that \Gamma  ` A1 = A2, \Gamma  ` [A1=ff]A01 ^ [A1=ff]A02 and
\Gamma  ` [A2=ff]A02 ^ [A2=ff]A03. We need to show that \Gamma  ` [A1=ff]A01 ^ [A1=ff]A03 so we can
apply the SU-SUM-T rule to get that \Gamma  ` 9ff=A1:A01 ^ 9ff=A3:A03.

The lemma will allow us to deduce that \Gamma  ` [A1=ff]A02 ^ [A1=ff]A03. The needed result
would then follow from transitivity if available. In order to use transitivity (the induction
hypothesis) here, though, we need to know that we are dealing with a smaller problem.
We can arrange this by inducting on the size of the extended derivations involved and
taking advantage of the fact that extended derivation size is unchanged by this lemma.

222 CHAPTER 10. SUBTYPING
Lemma [Simple] 10.8.9 If \Gamma  ` [A1=ff]A valid and \Gamma  ` A1 = A2 then
\Gamma  ` [A1=ff]A = [A2=ff]A.

Proof: Proved by structural induction on A. 2

Lemma [Simple] 10.8.10 If \Gamma  ` A = A0 and \Gamma  ` [A=ff]A1 = [A=ff]A2 then
\Gamma  ` [A0=ff]A1 = [A0=ff]A2.

Proof: By Theorem 10.8.7, \Gamma  ` [A=ff]A1 valid and \Gamma  ` [A=ff]A2 valid
) \Gamma  ` [A=ff]A1 = [A0=ff]A1 and \Gamma  ` [A=ff]A2 = [A0=ff]A2 (Lemma 10.8.9)
) \Gamma  ` [A0=ff]A1 = [A=ff]A1 (Theorem 10.8.5) ) \Gamma  ` [A0=ff]A1 = [A0=ff]A2 (Theorem 10.8.5).
2

Lemma [Simple] 10.8.11 Suppose \Gamma  ` A1 ^ A2 by an extended derivation of size s.
Then:

1. If \Gamma  ` A0 = A1 then \Gamma  ` A0 ^ A2 by an extended derivation of size s.

2. If \Gamma  ` A2 = A3 then \Gamma  ` A1 ^ A3 by an extended derivation of size s.
3. If A1 = [A=ff]A01, A2 = [A=ff]A02, and \Gamma  ` A = A0 then

\Gamma  ` [A0=ff]A01 ^ [A0=ff]A02 by an extended derivation of size s.

Proof: Proved by simultaneous induction on s, with the proviso that part three may
also call parts one and two with a derivation of the same size. Interesting cases:

SU-NEG 1: Here \Gamma  ` :A0 = :A1 and \Gamma  ` :A1 ^ :A2 via an extended derivation starting with

rule SU-NEG from \Gamma  ` A2 ^ A1 (with extended size s\Gamma 1) ) \Gamma  ` A0 = A1 (EQNEG) ) \Gamma  ` A1 = A0 (Theorem 10.8.5) ) \Gamma  ` A2 ^ A0 (with extended size s\Gamma 1)
(induction via part two) ) \Gamma  ` :A0 ^ :A2 (with extended size s) (SU-NEG).

SU-EQ 1: Here \Gamma  ` A0 = A1 and \Gamma  ` A1 ^ A2 via an extended derivation of size 1 starting

with rule SU-EQ from \Gamma  ` A1 = A2 ) \Gamma  ` A0 = A2 (Theorem 10.8.5) ) \Gamma  ` A0 ^ A2
(with extended size 1) (SU-EQ).

SU-SUM-T 1: Here \Gamma  ` 9ff=A0:A00 = 9ff=A1:A01 and \Gamma  ` 9ff=A1:A01 ^ 9ff=A2:A02 via an extended

derivation starting with rule SU-SUM-T from \Gamma  ` A1 = A2 and
\Gamma  ` [A1=ff]A01 ^ [A1=ff]A02 (with extended size s\Gamma 1) ) \Gamma  ` A0 = A1 and
\Gamma  ` [A0=ff]A00 = [A0=ff]A01 (EQ-SUM-T) ) \Gamma  ` A0 = A2 (Theorem 10.8.5) and
\Gamma  ` [A0=ff]A01 ^ [A0=ff]A02 (with extended size s\Gamma 1) (induction via part three) )
\Gamma  ` [A0=ff]A00 ^ [A0=ff]A02 (with extended size s\Gamma 1) (induction via part one and
Theorem 10.8.5) ) \Gamma  ` 9ff=A0:A00 ^ 9ff=A2:A02 (with extended size s) (SU-SUMT).

10.8. PROBLEM REDUCTION 223
SU-SUM-T 2: Here \Gamma  ` 9ff=A2:A02 = 9ff=A3:A03 and \Gamma  ` 9ff=A1:A01 ^ 9ff=A2:A02 via an extended

derivation starting with rule SU-SUM-T from \Gamma  ` A1 = A2 and
\Gamma  ` [A1=ff]A01 ^ [A1=ff]A02 (with extended size s\Gamma 1) ) \Gamma  ` A2 = A3 and
\Gamma  ` [A2=ff]A02 = [A2=ff]A03 (EQ-SUM-T) \Gamma  ` A1 = A3 (Theorem 10.8.5) and
\Gamma  ` [A1=ff]A02 = [A1=ff]A03 (Lemma 10.8.10) ) \Gamma  ` [A1=ff]A01 ^ [A1=ff]A03 (with extended size s\Gamma 1) (induction via part two)
) \Gamma  ` 9ff=A1:A01 ^ 9ff=A3:A03 (with extended size s) (SU-SUM-T).

SU-FOR 2: Here \Gamma  ` 9ff:A02 = 9ff:A03 and \Gamma  ` 9ff=A1:A01 ^ 9ff:A02 via an extended derivation

starting with rule SU-FOR from \Gamma  ` A1 valid, \Gamma ; ff ` A02 valid, and
\Gamma  ` [A1=ff]A01 ^ [A1=ff]A02 (with extended size s\Gamma 1) ) \Gamma ; ff ` A02 = A03 (EQ-SUMO) ) \Gamma ; ff ` A03 valid (Theorem 10.8.7) and \Gamma  ` [A1=ff]A02 = [A1=ff]A03
(Corollary 10.6.16) ) \Gamma  ` [A1=ff]A01 ^ [A1=ff]A03 (with extended size s\Gamma 1) (induction via part two) ) \Gamma  ` 9ff=A1:A01 ^ 9ff:A03 (with extended size s) (SU-FOR).

PART 3: Here \Gamma  ` A = A0 and \Gamma  ` [A=ff]A01 ^ [A=ff]A02 by an extended derivation of size s )

\Gamma  ` [A=ff]A01 valid and \Gamma  ` [A=ff]A02 valid (Theorem 10.8.7) ) \Gamma  ` [A=ff]A01 = [A0=ff]A01
and \Gamma  ` [A=ff]A02 = [A0=ff]A02 (Lemma 10.8.9) ) \Gamma  ` [A0=ff]A01 = [A=ff]A01 (Theorem 10.8.5) ) \Gamma  ` [A0=ff]A01 ^ [A=ff]A02 (with extended size s) (induction via part
one) ) \Gamma  ` [A0=ff]A01 ^ [A0=ff]A02 (with extended size s) (induction via part two).

2

Theorem [Simple] 10.8.12 (Transitivity)

If \Gamma  ` A1 ^ A2 by an extended derivation and \Gamma  ` A2 ^ A3 by an extended derivation
then \Gamma  ` A1 ^ A3.

Proof: Proved by induction on the sum of the sizes of the two extended derivations.
Interesting cases:

NEG: Here \Gamma  ` :A1 ^ :A2 by an extended derivation via SU-NEG from

\Gamma  ` A2 ^ A1 and \Gamma  ` :A2 ^ :A3 by an extended derivation via SU-NEG from
\Gamma  ` A3 ^ A2 ) \Gamma  ` A3 ^ A1 (induction -- the sum of sizes is unchanged by swapping the derivations) ) \Gamma  ` :A1 ^ :A3 (SU-NEG).

EQ L: Here \Gamma  ` A1 ^ A2 by an extended derivation via SU-EQ from \Gamma  ` A1 = A2 and

\Gamma  ` A2 ^ A3 by an extended derivation ) \Gamma  ` A1 ^ A3 (Lemma 10.8.11).

TSUM: Here \Gamma  ` 9ff=A1:A01 ^ 9ff=A2:A02 by an extended derivation via SU-SUM-T from

\Gamma  ` A1 = A2 and \Gamma  ` [A1=ff]A01 ^ [A1=ff]A02 and
\Gamma  ` 9ff=A2:A02 ^ 9ff=A3:A03 by an extended derivation via SU-SUM-T from

224 CHAPTER 10. SUBTYPING

\Gamma  ` A2 = A3 and \Gamma  ` [A2=ff]A02 ^ [A2=ff]A03 (with extended size s) ) \Gamma  ` A1 = A3
(Theorem 10.8.5) and \Gamma  ` [A1=ff]A02 ^ [A1=ff]A03 (with extended size s)
(Lemma 10.8.11) ) \Gamma  ` [A1=ff]A01 ^ [A1=ff]A03 (induction)
) \Gamma  ` 9ff=A1:A01 ^ 9ff=A3:A03 (SU-SUM-T).

FOR L: Here \Gamma  ` 9ff=A1:A01 ^ 9ff:A02 by an extended derivation via SU-FOR from

\Gamma  ` A1 valid, \Gamma ; ff ` A02 valid, and \Gamma  ` [A1=ff]A01 ^ [A1=ff]A02 and
\Gamma  ` 9ff:A02 ^ 9ff:A03 by an extended derivation via SU-SUM-O from
\Gamma ; ff ` A02 ^ A03 (with extended size s) ) \Gamma ; ff ` A03 valid (Theorem 10.8.7) and
\Gamma  ` [A1=ff]A02 ^ [A1=ff]A03 (with extended size s) (Corollary 10.6.16)
) \Gamma  ` [A1=ff]A01 ^ [A1=ff]A03 (induction) ) \Gamma  ` 9ff=A1:A01 ^ 9ff:A03 (SU-FOR).

2

Lemma [Simple] 10.8.13 (Reduction II: subtyping)

If \Gamma \Omega  ` A\Omega 1 ^ A\Omega 2 then \Gamma  ` A1 ^ A2.

Proof: Proved by structural induction on the derivation. The S-EQ case is handled by
Lemma 10.8.4 and Lemma 10.6.12, the S-ONE case is handled by Lemma 10.8.8, and
the S-TRAN case is handled by Theorem 10.8.12. 2

Thus, I have shown that any simple judgment may be decided by first encoding it as
a kernel-system judgment and then deciding the encoded judgment:

Theorem [Simple] 10.8.14 (Reduction III)

1. ` \Gamma  valid iff ` \Gamma \Omega  valid.
2. \Gamma  ` A valid iff \Gamma \Omega  ` A\Omega  :: \Omega .
3. \Gamma  ` A1 = A2 iff \Gamma \Omega  ` A\Omega 1 = A\Omega 2 :: \Omega .
4. \Gamma  ` A1 ^ A2 iff \Gamma \Omega  ` A\Omega 1 ^ A\Omega 2 .

Proof: Follows immediately from Lemmas 10.8.1, 10.8.3, 10.8.4, and 10.8.13. 2
As consequences of this, the simple validity and equality judgments are decidable and
the simple subtyping problem reduces to the kernel-system subtyping problem. This last
fact means that if the simple subtyping problem is undecidable, then the kernel-system
subtyping problem must be undecidable as well.

10.9. UNDECIDABILITY 225
Corollary [Simple] 10.8.15 (Problem reduction)

1. The ` \Gamma  valid judgment is decidable.
2. The \Gamma  ` A valid judgment is decidable.
3. The \Gamma  ` A1 = A2 judgment is decidable.
4. If the \Gamma  ` A1 ^ A2 judgment is undecidable, then the kernel system subtyping problem is undecidable.

Proof: Follows from Theorem 10.8.14, Theorem 9.4.11, and the fact that the encoding
can be done by an algorithm. 2

10.9 Undecidability
In this section I prove that the simple subtyping problem, and hence the kernel-system
subtyping problem, is undecidable. All judgments in this section are from the simple
system. First, it is worth noting that in the absence of the SU-FOR rule, simple subtyping
is decidable:

Lemma [Simple] 10.9.1

1. If jA1j = jA2j then j[A1=ff]Aj = j[A2=ff]Aj.
2. If \Gamma  ` A1 = A2 then jA1j = jA2j.

Proof: Proved sequentially by induction on A and the derivation of \Gamma  ` A1 = A2 respectively. 2

Theorem [Simple] 10.9.2 (Decidability)
If the SU-FOR rule is removed, then simple subtyping is decidable.

Proof: Inspection of the other SU rules shows that each of them strictly decreases
the following non-negative measure, so the simple syntax-directed procedure always terminates in this case: j\Gamma  ` A1 ^ A2j = jA1j + jA2j. (Lemma 10.9.1 is needed to handle
the SU-SUM-T case; the decidability of the other judgments' procedures is handled by

226 CHAPTER 10. SUBTYPING
Corollary 10.8.15.) 2

Note that use of the SU-FOR rule does not decrease this measure and in fact can
increase it because the type on the right side can grow without limit in the recursive
call. This fact can be used to construct examples that cause the simple syntax-directed
procedure for checking simple subtyping to loop. For example, consider the following
definitions: P (A) = 9ff=A::A (ff 62 FV(A))

Gff(A) = 9ff::A
An example which causes cyclic behavior under the empty assignment is then as follows:

P (Gff(P (ff))) ^ Gff(P (ff))
= 9ff0=Gff(P (ff))::Gff(P (ff)) ^ 9ff0::P (ff0)
) [Gff(P (ff))=ff0](:Gff(P (ff))) ^ [Gff(P (ff))=ff0](:P (ff0))
= :Gff(P (ff)) ^ :P (Gff(P (ff)))
) P (Gff(P (ff))) ^ Gff(P (ff)).

..

Pierce's proof of the undecidability of F^ subtyping has two steps. First, he introduces
a new kind of machine called a row machine and shows that the halting problem for these
machines is undecidable by reducing the two-counter Turing machine halting problem, a
known undecidable problem, to it. Second, he shows that F^ subtyping can be used to
decide rowing machine halting problems.

Row machines come in a variety of positive widths; the syntax for n-width rowing
machines is as follows:

Definition [Rowing] 10.9.3 (Syntax of n-width row machines)

Rows ae ::= ff j *ff1; : : : ; ffn: m j HALT
Machines m ::= !ae1; : : : ; aen?

Here, the metavariable ff ranges over row variables. Equivalence of rows and row machines
is defined as usual (ff-conversion). The definition of free row variables (FV(\Gamma )) and row
substitution ([ae=ff]\Gamma ) on rows and row machines are the obvious ones:

Definition [Rowing] 10.9.4 (Free row variables)

FV(ff) = fffg
FV(*ff1; : : : ; ffn: m) = FV(m) \Gamma  fff1; : : : ; ffng

FV(HALT) = ;

FV(!ae1; : : : ; aen?) = FV(ae1) [ \Delta  \Delta  \Delta  [ FV(aen)

10.9. UNDECIDABILITY 227
Definition [Rowing] 10.9.5 (Row substitution)

[ae=ff]ff = ae
[ae=ff]ff0 = ff0 (ff 6= ff0)
[ae=ff]*ff01; : : : ; ff0n: m = *ff01; : : : ; ff0n: [ae=ff]m (8i: ff0i 6= ff; ff0i 62 FV(ae))

[ae=ff]HALT = HALT

[ae=ff]!ae1; : : : ; aen? = ![ae=ff]ae1; : : : ; [ae=ff]aen?
Row machines of width n are elaborated using the following rewriting relation:
Definition [Rowing] 10.9.6

ae1 = *ff1; : : : ; ffn: m0 m00 = [aen=ffn] : : : [ae1=ff1]m0

!ae1; : : : ; aen? ! m00 (ROW)

Only closed row machines (FV(m) = ;) are elaborated; the rewriting relation preserves
the closed property:

Lemma [Rowing] 10.9.7 If FV(m) = ; and m ! m0 then FV(m0) = ;.
Proof: First show by induction on m that if FV(ae) = ; then FV([ae=ff]m) ` (FV(m) \Gamma 
fffg). The result then follows easily from the definitions of row machine rewriting, free
row variables, and row substitution. 2

The basic idea of row machine elaboration is that a row machine of width n contains
n registers, each of which may contain a row. The row machine !ae1; : : : ; aen? represents
a machine who's first register holds ae1, who's second register holds ae2, and so on. The
first register of a row machine holds its program counter (PC). To move to the next state,
the PC is used as a template to construct the new contents of each of the registers from
the current contents of all of the registers (including the PC). A row machine halts when
its PC becomes HALT:

Definition [Rowing] 10.9.8 The closed n-width row machine m is said to halt iff
9ae2; : : : ; aen: m !\Lambda  !HALT; ae2; : : : ; aen?.

A closed row machine that never halts will run forever:
Lemma [Rowing] 10.9.9

If FV(m) = ; and 8ae2; : : : ; aen: m 6= !HALT; ae2; : : : ; aen? then 9m0: m ! m0.

228 CHAPTER 10. SUBTYPING
Proof: Let m = !ae1; : : : ; aen? ) FV(ae1) = ; (definition of free row variables) and
ae1 6= HALT (given) ) ae1 = *ff1; : : : ; ffn: m00 for some ff1; : : : ; ffn; and m00 ) 9m0: m ! m0
(ROW). 2

More discussion of row machines, including examples, can be found in Section 6.5 of
Pierce's thesis [51]. The elaboration function given there differs slightly from the one here
because it uses simultaneous substitution where I have used iterated substitution; the
definitions can easily be seen to coincide on closed row machines however. In Section 6.8
of his thesis, Pierce proves the following theorem:

Theorem [Rowing] 10.9.10 (Undecidability)

The halting problem for closed row machines is undecidable. (The width may vary from
problem instance to problem instance.)

By making some slight modifications, Pierce's encoding of row machines into F^
subtyping can be turned into an encoding of row machines into simple subtyping. The
following encoding (F(\Gamma )) of width n rows and row machines into simple types is designed
so that a closed n-width row machine m halts iff the simple judgment ffl ` F(m) ^ oe holds
(oe is defined below):

Definition [Rowing] 10.9.11 (Encoding row machines of width n)

oe = 9fi:9ff01: \Delta  \Delta  \Delta  9ff0n::9ff001=ff01: \Delta  \Delta  \Delta  9ff00n=ff0n::fi

F(ff) = ff
F(*ff1; : : : ; ffn: m) = 9ff1: \Delta  \Delta  \Delta  9ffn::F(m)
F(HALT) = 9ff1: \Delta  \Delta  \Delta  9ffn::oe

F(!ae1; : : : ; aen?) = 9fi=oe:9ff01=F(ae1): \Delta  \Delta  \Delta  9ff0n=F(aen)::ff01;

(ffi; ff01; : : : ; ff0ng " FV(!ae1; : : : ; aen?) = ;)

Where jffi; ff01; : : : ; ff0n; ff001; : : : ; ff00ngj = 2n + 1.

The key differences from Pierce's encoding (see Section 6.6 of his thesis) are as follows:
ffl Use of \Gamma  ` 9ff=A:A1 ^ 9ff:A2 instead of 8ff:A2 ^ 8ff^A:A1.
ffl Use of reflexivity to halt computation instead of the FTOP rule. (Compare the

two definitions of F(HALT))

The proof that the encoding is correct is straightforward:

10.9. UNDECIDABILITY 229
Lemma [Rowing] 10.9.12 (Encoding properties)

1. FV(oe) = ;
2. FV(F(ae)) = FV(ae) and FV(F(m)) = FV(m)
3. F([ae0=ff]ae) = [F(ae0)=ff]F(ae) and F([ae0=ff]m) = [F(ae0)=ff]F(m)

Proof: The first part is proved by inspecting the definition of oe. The remaining two
parts are proved by simultaneous induction on ae and m. 2

Lemma [Mixed] 10.9.13 (Encoding validity)

1. ffl ` oe valid
2. If FV(ae) ` dom(\Gamma ) and ` \Gamma  valid then \Gamma  ` F(ae) valid.
3. If FV(m) ` dom(\Gamma ) and ` \Gamma  valid then \Gamma  ` F(m) valid.
(Here \Gamma  is a simple assignment; all other variables are from the row system.)

Proof: The first part is proved by using VAR, NEG, SUM-O, and SUM-T. The remaining parts are proved by simultaneous structural induction on ae and m, using Lemmas 10.9.12 and 10.6.11 as needed. 2

Lemma [Rowing] 10.9.14 If FV(!HALT; ae2; : : : ; aen?) = ; then
ffl ` F(!HALT; ae2; : : : ; aen?) ^ oe.

Proof: By Corollary 10.8.6, NEG, and Lemma 10.9.13, ffl ` :oe ^ :oe
) ffl ` 9ff001=F(HALT):9ff002=F(ae2): \Delta  \Delta  \Delta  9ff00n=F(ae2)::oe ^ 9ff1: \Delta  \Delta  \Delta  9ffn::oe
(Lemma 10.9.12, 10.9.13, SUM-O, SU-FOR, and the given)
) ffl ` 9ff001=F(HALT):9ff002=F(ae2): \Delta  \Delta  \Delta  9ff00n=F(ae2)::oe ^ F(HALT)
) ffl ` :F(HALT) ^ :9ff001=F(HALT):9ff002=F(ae2): \Delta  \Delta  \Delta  9ff00n=F(ae2)::oe (SU-NEG)
) ffl ` 9fi=oe:9ff01=F(HALT):9ff02=F(ae2): \Delta  \Delta  \Delta  9ff0n=F(aen)::ff01 ^
9fi:9ff01: \Delta  \Delta  \Delta  9ff0n::9ff001=ff01: \Delta  \Delta  \Delta  9ff00n=ff0n::fi where jffi; ff01; : : : ; ff0n; ff001; : : : ; ff00ngj = 2n + 1
(Lemma 10.9.12, 10.9.13, SUM-O, SU-FOR, and the given)
) ffl ` F(!HALT; ae2; : : : ; aen?) ^ oe. 2

230 CHAPTER 10. SUBTYPING
Lemma [Rowing] 10.9.15

Suppose m = !ae1; : : : ; aen?, FV(m) = ;, and ae1 6= HALT. Then:

1. If m ! m0 and ffl ` F(m0) ^ oe then ffl ` F(m) ^ oe.
2. If ffl ` F(m) ^ oe then 9m0: m ! m0 and ffl ` F(m0) ^ oe by a smaller derivation.
Proof: By the givens and Lemma 10.9.9, we must have that ae1 = *ff1; : : : ; ffn: m00 for
some ff1; : : : ; ffn, and m00 ) m ! m0 where m0 = [aen=ffn] : : : [ae1=ff1]m00 (ROW). We can
then reason as follows with jffi; ff01; : : : ; ff0n; ff001; : : : ; ff00ngj = 2n + 1:
ffl ` F(m) ^ oe , ffl ` F(!ae1; : : : ; aen?) ^ oe
, ffl ` 9fi=oe:9ff01=F(ae1): \Delta  \Delta  \Delta  9ff0n=F(aen)::ff01 ^
9fi:9ff01: \Delta  \Delta  \Delta  9ff0n::9ff001=ff01: \Delta  \Delta  \Delta  9ff00n=ff0n::fi
, ffl ` 9ff01=F(ae1): \Delta  \Delta  \Delta  9ff0n=F(aen)::ff01 ^ 9ff01: \Delta  \Delta  \Delta  9ff0n::9ff001=ff01: \Delta  \Delta  \Delta  9ff00n=ff0n::oe
(Lemma 10.9.12, 10.9.13, SUM-O, SU-FOR, and the given)
, ffl ` :F(ae1) ^ :9ff001=F(ae1): \Delta  \Delta  \Delta  9ff00n=F(aen)::oe (Lemma 10.9.12, 10.9.13, SUM-O, SUFOR, and the given)
, ffl ` 9ff001=F(ae1): \Delta  \Delta  \Delta  9ff00n=F(aen)::oe ^ F(ae1) (SU-NEG)
, ffl ` 9ff001=F(ae1): \Delta  \Delta  \Delta  9ff00n=F(aen)::oe ^ F(*ff1; : : : ; ffn: m00)
, ffl ` 9ff001=F(ae1): \Delta  \Delta  \Delta  9ff00n=F(aen)::oe ^ 9ff1: \Delta  \Delta  \Delta  9ffn::F(m00)
, ffl ` :oe ^ :[F(aen)=ffn] : : : [F(ae1)=ff1]F(m00) (Lemma 10.9.12, 10.9.13, SUM-O, SU-FOR,
and the given)
, ffl ` [F(aen)=ffn] : : : [F(ae1)=ff1]F(m00) ^ oe (SU-NEG)
, ffl ` F([aen=ffn] : : : [ae1=ff1]m00) ^ oe (Lemma 10.9.12)
, ffl ` F(m0) ^ oe. 2

Theorem [Rowing] 10.9.16 Suppose m is a closed n-width row machine. Then m
halts iff ffl ` F(m) ^ oe.

Proof: The forward direction follows from Lemma 10.9.14, part one of
Lemma 10.9.15, and Lemma 10.9.7. The backward direction follows from part two of
Lemma 10.9.15 and Lemma 10.9.7. 2

The desired undecidability results then follow immediately:
Theorem [Simple] 10.9.17 Simple subtyping is undecidable.
Proof: Follows immediately from Theorem 10.9.16 and Theorem 10.9.10. 2

Corollary 10.9.18 The kernel-system subtyping problem is undecidable.

10.9. UNDECIDABILITY 231
Proof: Follows immediately from Theorem 10.9.17 and Corollary 10.8.15. 2

Is the undecidability of subtyping likely to be a problem in practice? I don't think
there is much chance of it being a problem with human generated code. Consider, for
example, the previous looping example, which is the smallest such example known. Examining it reveals that a type at least as complicated as :Gff(P (ff)) = :9ff::9ff0=ff::ff
is needed to start the loop going.

Translated into SML-like code, using functors to implement negations, this type would
look like the following:

FUNCTOR (s: interface

type T;
FUNCTOR F(s: interface

type U = T;

FUNCTOR G(s: U):RES;
end):RES;
end):RES

where RES is any type. The translated type is quite complicated, involving a functor that
takes an argument containing a functor that takes an argument containing yet another
functor. Types of this sort seem unlikely in practice to arise in human generated code.

Machine generated code is a different matter: it seems plausible that some kind of
automatic encoding of objects, for example, might produce types of this sort. I suggest
that this problem be handled by adding a depth limit to the subtyping procedure so that
it returns an error if it cannot resolve the subtyping question within the specified depth
limit. An initial limit of ten thousand should allow all reasonable programs to be type
checked without problem (I shall show in Chapter 12 that well-typed programs never
produce looping) ; if the programmer is unsure if an error is due to looping or to the
limit, she can increase the limit to a much higher value and recheck the program. If the
program still gives an error, either it really does have a type error, or, alternatively, it
just takes so long to type check that it is unusable in practice.

232 CHAPTER 10. SUBTYPING
Chapter 11
Soundness
I have now finished discussing the kernel-system kind and constructor levels and their
associated proofs. In this chapter, I introduce the term level, define the system's semantics, and prove soundness. I defer the discussion of how to efficiently type check terms
to the next chapter.

11.1 The Terms
The syntax for the term level is as follows:

Definition 11.1.1 (Syntax for the term level)

Terms M ::= x j *x:A: M j M 1 M 2 j (M 1; M 2) j M :1 j M :2 j !A? j

M !:A j roll j unroll j new j get j set

Scoping is as would be expected and the definitions of free constructor variables (FCV(M))
and free term variables (FTV(M )) on terms are the obvious ones:

233

234 CHAPTER 11. SOUNDNESS
Definition 11.1.2 (Free constructor variables)

FCV(x) = ;
FCV(roll) = ;
FCV(unroll) = ;

FCV(new) = ;

FCV(get) = ;

FCV(set) = ;

FCV(M :1) = FCV(M )
FCV(M :2) = FCV(M )
FCV(!A?) = FCV(A)

FCV(*x:A: M ) = FCV(A) [ FCV(M )

FCV(M !:A) = FCV(M ) [ FCV(A)
FCV(M 1 M 2) = FCV(M 1) [ FCV(M 2)
FCV((M 1; M 2)) = FCV(M 1) [ FCV(M 2)

Definition 11.1.3 (Free term variables)

FTV(x) = fxg
FTV(*x:A: M ) = FTV(A) [ (FTV(M ) \Gamma  fxg)

FTV(roll) = ;
FTV(unroll) = ;

FTV(new) = ;

FTV(get) = ;

FTV(set) = ;

FTV(M :1) = FTV(M )
FTV(M :2) = FTV(M )
FTV(!A?) = FTV(A)

FTV(M 1 M 2) = FTV(M 1) [ FTV(M 2)
FTV((M 1; M 2)) = FTV(M 1) [ FTV(M 2)

FTV(M !:A) = FTV(M ) [ FTV(A)

The term level's only judgment is the well-typed term judgment (\Gamma  ` M : A) which
assigns a type (A) to a term (M ) that is well-typed under a assignment (\Gamma ). When
discussing the types of terms, the following abbreviations will be useful:

11.1. THE TERMS 235
Definition 11.1.4 (Arrow types)
The arrow type A!A0 is defined to be equal to \Pi x:A: A0 where x 62 FTV(A0). The arrow
operator (!) is defined to have lower precedence than application (A1A2).

Definition 11.1.5 (Pair types)
The pair type (A; A0) is defined to be equal to \Sigma x:A: A0 where x 62 FTV(A0).

Definition 11.1.6 (Polymorphic types)
The polymorphic type 8ff::K:A is defined to be equal to \Pi x:!K?: [x!=ff]A where x 62
FTV(A).

The rules for the well-typed term judgment follow. The elimination rules for dependent functions (T-APP) and dependent sums (T-SND) are restricted so that they apply
only to terms with non-dependent types. The introduction rule for reified constructors
(T-REIFY) always assigns a transparent type; an opaque type can be obtained instead
by using subsumption afterwards (i.e., use T-REIFY followed by T-SUMP). The rule for
term variables (T-VAR) uses the self function ([self=xae]\Gamma ), discussed below, to get the
effect of a series of EVALUE rules in a row; the advantage of the self function, which is
used only at term-variable introduction time, over separate EVALUE rules, which can be
applied at any time, is that it results in normalized typing derivations, which are easier
to reason about. I discussed how these kind of rules work together to allow information
about constructor components to be propagated solely through the constructor level in
Chapter 4 and Section 5.5.

Definition 11.1.7 (Term Formation Rules)

\Gamma  ` \Gamma (x) = A :: \Omega 

\Gamma  ` x : [self=x]A (T-VAR)

\Gamma ; x:A ` M : A0
\Gamma  ` *x:A: M : \Pi x:A: A0 (T-LAM)

\Gamma  ` M 1 : A2!A \Gamma  ` M 2 : A2

\Gamma  ` M 1 M 2 : A (T-APP)

\Gamma  ` M 1 : A1 \Gamma  ` M 2 : A2

\Gamma  ` (M 1; M 2) : (A1; A2) (T-PAIR)

\Gamma  ` M : \Sigma x:A1: A2

\Gamma  ` M :1 : A1 (T-FST)

236 CHAPTER 11. SOUNDNESS

\Gamma  ` M : (A1; A2)

\Gamma  ` M :2 : A2 (T-SND)

\Gamma  ` A :: K
\Gamma  ` !A? : !=A::K? (T-REIFY)

\Gamma  ` M : A0 \Gamma  ` A0 ^ A

\Gamma  ` M : A (T-SUMP)

\Gamma  ` M : A
\Gamma  ` M !:A : A (T-COERCE)

` \Gamma  valid
\Gamma  ` new : 8ff::\Omega :ff!ref ff (T-NEW)

` \Gamma  valid
\Gamma  ` get : 8ff::\Omega :ref ff!ff (T-GET)

` \Gamma  valid
\Gamma  ` set : 8ff::\Omega :ref ff!(ff!ff) (T-SET)

` \Gamma  valid
\Gamma  ` roll : 8ff::\Omega )\Omega :ff (rec ff)!rec ff (T-ROLL)

` \Gamma  valid
\Gamma  ` unroll : 8ff::\Omega )\Omega :rec ff!ff (rec ff) (T-UNROLL)

The self function is defined below. Given a term xae with type A, [self=xae]A computes
a subtype of A for xae by adding information about the identity of constructor components
to opaque types (!K?) in A. For example,
[self=xae]\Sigma x0:!=ff::\Omega ?: !\Omega ? = \Sigma x0:!=ff::\Omega ?: !=xae:2!::\Omega ?. Note that the self function
leaves transparent types (!=A::K?) unchanged because more useful information about
the identity of their components is already available.

11.2. SELF VALIDITY 237
Definition 11.1.8 (Self function)

[self=xae]!K? = !=xae!::K?
[self=xae]\Sigma x0:A1: A2 = \Sigma x0:[self=xae:1]A1: [self=xae:2]A2; where x 6= x0

[self=xae]ff = ff
[self=xae]\Pi x0:A1: A2 = \Pi x0:A1: A2

[self=xae]*ff::K: A = *ff::K: A

[self=xae]A1 A2 = A1 A2
[self=xae]!=A::K? = !=A::K?

[self=xae]x0ae0! = x0ae0!

[self=xae]rec = rec

[self=xae]ref = ref

The self function does not take into account equality on types; it leaves unchanged
types with shape ?, regardless of their intrinsic shape. For example, [self=x]((*ff::\Omega : ff) !\Omega ?)
= (*ff::\Omega : ff) !\Omega ? even though [self=x]!\Omega ? = !=x!::\Omega ? and
ffl ` (*ff::\Omega : ff) !\Omega ? = !\Omega ? :: \Omega .

The effect of any series of applications of EVALUE-like rules can be gotten by first
using equality to rewrite the type so that only the opaque types you want to alter have
non-? shapes and then applying the self function. For instance, suppose ` \Gamma  valid and
\Gamma (x) = \Sigma x0:!\Omega ?: !\Omega ? and we want to add information to only the second component
of x. By the equality rules, we have that \Gamma  ` \Gamma (x) = \Sigma x0:(*ff::\Omega : ff) !\Omega ?: !\Omega ? :: \Omega . By
the definition of the self function, [self=x]\Sigma x0:(*ff::\Omega : ff) !\Omega ?: !\Omega ? =
\Sigma x0:(*ff::\Omega : ff) !\Omega ?: !=x:2!::\Omega ?. Hence, by T-VAR, we have
\Gamma  ` x : \Sigma x0:(*ff::\Omega : ff) !\Omega ?: !=x:2!::\Omega ? ) \Gamma  ` x : \Sigma x0:!\Omega ?: !=x:2!::\Omega ? (T-SUMP, etc.)
as desired.

11.2 Self Validity
In this section I prove that under suitable conditions the self function produces valid
types. In order to describe when the self function is valid, a notion of cleaving is needed.
The cleave function (\Gamma ;A + ae), defined below, takes as input an assignment \Gamma , a type A
under \Gamma , and a path ae. Treating A like a tree whose branches are named by :1 and :2, it
cleaves apart A following the path ae into three parts: the part of A rooted at ae, call it
A0; the declarations in A that A0 is under (the tree to the left of ae), call it \Gamma 0; and the
remaining part (the tree to the right of ae). The cleave function then returns \Gamma ; \Gamma 0; A0,
discarding the right part of A.

238 CHAPTER 11. SOUNDNESS
Definition 11.2.1 (Cleave function)

\Gamma ;A + ffl = \Gamma ; A

\Gamma ;\Sigma x0:A1: A2 + :1ae = \Gamma ;A1 + ae
\Gamma ;\Sigma x0:A1: A2 + :2ae = (\Gamma ; x0:A1);A2 + ae where x0 62 dom(\Gamma )

Like the selection function, the cleave function can also be done in steps:
Lemma 11.2.2 If \Gamma ;A + ae1ae2 exists then \Gamma ;A + ae1ae2 = \Gamma 2; A2 where \Gamma 2; A2 = \Gamma 1;A1 + ae2
and \Gamma 1; A1 = \Gamma ;A + ae1.

Given a valid assignment, type pair, cleaving results in a new valid assignment, type
pair:

Lemma 11.2.3 (Cleave validity)

If \Gamma  ` A :: \Omega  and \Gamma 0; A0 = \Gamma ;A + ae then \Gamma 0 ` A0 :: \Omega .

The types produced by either cleaving or selecting from the same type A using the
same path are related via a series of place substitutions on the term variables bound in
A:

Lemma 11.2.4 (Shape preservation) d[xae=x0]Ae = dAe
Lemma 11.2.5 (Cleaving vs. selection)

If \Gamma ;A + ae0 or S(A; xae; ae0) exist, then 9 a series of place substitutions, ` = `1 \Delta  \Delta  \Delta  `n, such
that S(A; xae; ae0) = `A0 and dom(`) = dom(\Gamma 0) \Gamma  dom(\Gamma ) where \Gamma 0; A0 = \Gamma ;A + ae0.

Proof: Proved by structural induction on ae0. Cases:
ae0 = ffl: ) \Gamma 0 = \Gamma , A0 = A, and S(A; xae; ae0) = A ) S(A; xae; ae0) = A0 = `A0 and dom(`) =

; = dom(\Gamma 0) \Gamma  dom(\Gamma ) if n = 0.

ae0 = ae00:i: ) \Gamma ;A + ae00 or S(A; xae; ae00) exist (Lemmas 6.5.3 and 11.2.2). Hence, by the induction hypothesis, 9 a series of place substitutions, ` = `1 \Delta  \Delta  \Delta  `n, such that
S(A; xae; ae00) = `A00 and dom(`) = dom(\Gamma 00) \Gamma  dom(\Gamma ) where \Gamma 00; A00 = \Gamma ;A + ae00 )
S((`A00); xaeae00; :i) or \Gamma 00;A00 + :i exist (Lemmas 6.5.3 and 11.2.2) ) d`A00e = dA00e =
\Sigma  (Lemma 11.2.4) ) 9x0; A1; A2: A00 = \Sigma x0:A1: A2 where x 6= x0 and x0 62 dom(\Gamma )
) `A00 = \Sigma x0:`A1: `A2 (WLOG) ) \Gamma 0 = \Gamma 00, A0 = Ai, and S(A; xae; ae0) = `A1 (if
i = 1) or \Gamma 0 = \Gamma 00; x0:A1 and S(A; xae; ae0) = [xaeae00:1=x0](`A2) (if i = 2) (Lemmas 6.5.3
and 11.2.2) ) 9`0: S(A; xae0; ae0) = `0A0 and dom(`0) = dom(\Gamma 0) \Gamma  dom(\Gamma ).

11.2. SELF VALIDITY 239

2
One corollary of this result is that such types must have the same shape:
Corollary 11.2.6 If \Gamma ;A + ae0 or S(A; xae; ae0) exist, then dS(A; x0ae0; ae)e = dA0e where
\Gamma 0; A0 = \Gamma ;A + ae

Proof: Follows directly from Lemmas 11.2.5 and 11.2.4. 2

Another corollary is that if the part of A being selected or cleaved to is not bound by
any term variables declared in A, then the type obtained by selection and cleaving will
be the same:

Lemma 11.2.7 (Substitution for non-free variables)

1. If ff 62 FCV(A) then [A0=ff]A = A.
2. If x0 62 FTV(A) then [xae=x0]A = A.
3. If ff 62 FCV(\Gamma ) then [A0=ff]\Gamma  = \Gamma .
4. If x0 62 FTV(\Gamma ) then [xae=x0]\Gamma  = \Gamma .

Proof: Proved sequentially using structural induction on A and \Gamma . 2

Corollary 11.2.8 If \Gamma  ` A :: \Omega , \Gamma 0; A0 = \Gamma ;A + ae, and \Gamma  ` A0 :: \Omega  then
S(A; xae0; ae) = A0.

Proof: By Lemma 11.2.3, \Gamma 0 ` A0 :: \Omega . By Lemma 11.2.5, 9 a series of place substitutions, ` = `1 \Delta  \Delta  \Delta  `n, such that S(A; xae0; ae) = `A0 and dom(`) = dom(\Gamma 0) \Gamma  dom(\Gamma ). By
inspection of the definition of cleaving, \Gamma 0 = \Gamma ; \Gamma 00 for some \Gamma 00. By Lemmas 6.3.5, 6.5.10,
and 6.5.4, dom(\Gamma ) " dom(\Gamma 00) = ; ) dom(\Gamma 0) \Gamma  dom(\Gamma ) = dom(\Gamma 00). By Theorem 6.5.6,
FTV(A0) ` dom(\Gamma ) ) FTV(A0) " dom(\Gamma 00) = ; ) FTV(A0) " dom(`) = ; ) `A0 = A0
(Lemma 11.2.7) ) S(A; xae0; ae) = A0. 2

If we ignore the question of when the self function produces valid types, it is straightforward to show that the self function produces a subtype of the type it is applied to:

Lemma 11.2.9 If \Gamma  ` A :: \Omega  and \Gamma  ` [self=xae]A :: \Omega  then \Gamma  ` [self=xae]A ^ A.

240 CHAPTER 11. SOUNDNESS
Proof: Proved by structural induction on A. All but the following two cases follow
immediately from O-REFL and S-ONE:

Opaq: Here A = !K? for some K ) [self=xae]A = !=xae!::K ?

) \Gamma  ` [self=xae]A ^ A (C-TRANS, O-FORGET, and S-ONE).

DSum: Here A = \Sigma x0:A1: A2 for some x0, A1, and A2 where x 6= x0 and x0 62 dom(\Gamma )

) [self=xae]A = \Sigma x0:[self=xae:1]A1: [self=xae:2]A2 ) \Gamma  ` A1 :: \Omega , \Gamma ; x0:A1 ` A2 :: \Omega ,
\Gamma  ` [self=xae:1]A1 :: \Omega , and \Gamma ; x0:[self=xae:1]A1 ` [self=xae:2]A2 :: \Omega  (C-DSUM,
Lemma 6.3.5, and DECL-T) ) \Gamma  ` [self=xae:1]A1 ^ A1 and
\Gamma ; x0:[self=xae:1]A1 ` [self=xae:2]A2 ^ A2 (induction hypothesis) )
\Gamma  ` [self=xae]A ^ A. (Theorem 10.5.4)

2

Using these results, I can now show when the self function produces valid types. The
cleave function is needed here because the self function recurses in a cleave-like manner
while, on the other hand, the place lookup judgment, which is needed to ensure the
validity of the inserted names, recurses in a selection-like manner.

Theorem 11.2.10 (Self validity)

If \Gamma  ` xae ) A and \Gamma 0; A0 = \Gamma ;A + ae0 then \Gamma 0 ` [self=xaeae0]A0 :: \Omega .

Proof: Proved by structural induction on A0. Theorem 9.4.4 and Lemma 11.2.3 handle
the cases where dA0e 6= \Sigma  and dA0e 6= !K?. The other cases are:

Opaq: Given A0 = !K? for some K ) [self=xaeae0]A0 = !=xaeae0!::K?. By Lemma 11.2.3,

\Gamma 0 ` A0 :: \Omega  ) ` \Gamma 0 valid (Theorem 6.3.5). By Theorem 9.4.4 and E-REFL,
\Gamma  ` xaeae0 ) S(A0; xae; ae0) ) \Gamma  ` xaeae0 ) !K? (Corollary 11.2.6) ) \Gamma 0 ` xaeae0 ) !K?
(Theorem 9.4.1) ) \Gamma 0 ` xaeae0! :: K (C-EXT-O) ) \Gamma 0 ` !=xaeae0!::K? :: \Omega  (C-TRANS)
) \Gamma 0 ` [self=xaeae0]A0 :: \Omega .

DSum: Given A0 = \Sigma x0:A1: A2 for some x0, A1, and A2 where x 6= x0 and x0 62 dom(\Gamma 0).

By Theorem 9.4.4 and Lemma 11.2.3, \Gamma 0 ` A1 :: \Omega . By the induction hypothesis,
\Gamma 0 ` [self=xaeae0:1]A1 :: \Omega  and \Gamma 0; x0:A1 ` [self=xaeae0:2]A2 :: \Omega .
) \Gamma 0 ` [self=xae:1]A1 ^ A1. (Lemma 11.2.9)
) \Gamma 0; x0:[self=xae:1]A1 ` [self=xaeae0:2]A2 :: \Omega  (Theorem 10.4.7)
) \Gamma 0 ` \Sigma x0:[self=xaeae0:1]A1: [self=xaeae0:2]A2 :: \Omega  (C-DSUM)
) \Gamma 0 ` [self=xaeae0]A0 :: \Omega .

2

11.3. SELF AND SUBTYPING 241
Corollary 11.2.11 If \Gamma  ` xae ) A and \Gamma 0; A0 = \Gamma ;A + ae0 then
\Gamma 0 ` [self=xaeae0]A0 ^ A0.

Proof: By Theorem 9.4.4 and Lemma 11.2.3, \Gamma 0 ` A0 :: \Omega . By Theorem 11.2.10,
\Gamma 0 ` [self=xaeae0]A0 :: \Omega . Hence, by Lemma 11.2.9, \Gamma 0 ` [self=xaeae0]A0 ^ A0. 2

The following lemma, which describes the interaction between subtyping and cleaving,
will be useful in the next section:

Lemma 11.2.12 Suppose \Gamma  ` A1 ^ A2, \Gamma 001; A001 = \Gamma ;A1 + ae, and
\Gamma 002; A002 = \Gamma ;A2 + ae. Then:

1. \Gamma 001 ` A001 ^ A002
2. If \Gamma 002; \Gamma 3 ` A :: K then \Gamma 001; \Gamma 3 ` A :: K.
3. If \Gamma 002; \Gamma 3 ` A ^ A0 then \Gamma 001; \Gamma 3 ` A ^ A0.
Proof: Proved simultaneously by structural induction on ae:
ae = ffl: Here \Gamma  = \Gamma 001 = \Gamma 002 so we are done.
ae = ae0:1: Here 9A4; A5; x0: \Gamma ;A1 + ae0 = \Gamma 01; \Sigma x0:A001: A4 and \Gamma ;A2 + ae0 = \Gamma 02; \Sigma x0:A002: A5, \Gamma 001 =

\Gamma 01, and \Gamma 002 = \Gamma 02, where x0 62 dom(\Gamma 01) [ dom(\Gamma 02) [ fxg. By the induction hypothesis, \Gamma 01 ` \Sigma x0:A001: A4 ^ \Sigma x0:A002: A5 ) \Gamma 01 ` A001 ^ A002 and \Gamma 01; x0:A001 ` A4 ^ A5
(Lemma 10.5.1) ) \Gamma 001 ` A001 ^ A002. Parts two and three follow from the induction
hypothesis.

ae = ae0:2: Here 9A4; A5; x0: \Gamma ;A1 + ae0 = \Gamma 01; \Sigma x0:A4: A001 and \Gamma ;A2 + ae0 = \Gamma 02; \Sigma x0:A5: A002, \Gamma 001 =

\Gamma 01; x0:A4, and \Gamma 002 = \Gamma 02; x0:A5, where x0 62 dom(\Gamma 01)[dom(\Gamma 02)[fxg. By the induction
hypothesis, \Gamma 01 ` \Sigma x0:A4: A001 ^ \Sigma x0:A5: A002 ) \Gamma 01 ` A4 ^ A5 and \Gamma 01; x0:A4 ` A001 ^ A002
(Lemma 10.5.1) ) \Gamma 001 ` A001 ^ A002. Parts two and three follow from the induction
hypothesis followed by replacement by a subtype (Theorem 10.4.7).

2

11.3 Self and Subtyping
In this section I establish results about the interaction between the self function and the
subtyping relation that are needed to extended the replacement by a subtype result to
the term level. First, I shall need some minor lemmas relating self to selection and to
cleaving:

242 CHAPTER 11. SOUNDNESS
Lemma 11.3.1 If x 6= x0 then [self=xae][x00ae0=x0]A = [x00ae0=x0][self=xae]A.
Lemma 11.3.2 (Self and selection)

If either S([self=x2ae2]A; x1ae1; ae) or S(A; x1ae1; ae) exists, then
S([self=x2ae2]A; x1ae1; ae) = [self=x2ae2ae]S(A; x1ae1; ae).

Proof: Proved by structural induction on ae using Lemma 11.3.1 as needed. Example
case: S([self=x

2ae2]\Sigma x0:A1: A2; x1ae1; :2ae0) =
S(\Sigma x0:[self=x2ae2:1]A1: [self=x2ae2:2]A2; x1ae1; :2ae0) =

S([x2ae2:1=x0][self=x2ae2:2]A2; x1ae1:2; ae0) =
S([self=x2ae2:2][x2ae2:1=x0]A2; x1ae1:2; ae0) =
[self=x2ae2:2ae0]S([x1ae1:1=x0]A2; x1ae1:2; ae0) =
[self=x2ae2:2ae0]S(\Sigma x0:A1: A2; x1ae1; :2ae0)

(x0 chosen so that x0 6= x2) 2

Lemma 11.3.3 (Self and cleaving)

If \Gamma 0; A0 = \Gamma ;A + ae then 9\Gamma 00: \Gamma ;[self=xae0]A + ae = \Gamma 00; [self=xae0ae]A0.

Proof: Proved by structural induction on ae. 2

I shall also need the following result which shows that an equality on part of a type
can be extended to an equality on the entire type:

Lemma 11.3.4 (Equality back off )

Suppose \Gamma  ` A1 :: \Omega , \Gamma 1; A01 = \Gamma ;A1 + ae0, and \Gamma 1 ` A01 = A02 :: \Omega . Then, 9\Gamma 2; A2 such
that:

1. \Gamma 2; A02 = \Gamma ;A2 + ae0

2. \Gamma  ` A1 = A2 :: \Omega 
Proof: Proved by structural induction on ae0. Cases:
ae0 = ffl: ) \Gamma 1 = \Gamma  and A1 = A01. Let \Gamma 2 = \Gamma  and A2 = A02 and we are done.

ae0 = ae00:i: Here \Gamma 01; \Sigma x0:A3: A4 = \Gamma ;A1 + ae00 for some \Gamma 01, x0, A3, and A4 where x0 6= x and

x0 62 dom(\Gamma 01) (Lemma 11.2.2) ) A01 = Ai+2. By Lemma 11.2.3, \Gamma 01 ` A3 :: \Omega  and
\Gamma 01; x0:A3 ` A4 :: \Omega  ) \Gamma 01 ` A3 = A3 :: \Omega  and
\Gamma 01; x0:A3 ` A4 = A4 :: \Omega  (E-REFL) ) \Gamma 01 ` \Sigma x0:A3: A4 = A5 :: \Omega  where A5 = \Sigma x0:A02: A4
if i = 1 and A5 = \Sigma x:A3: A02 if i = 2.

Hence, by the induction hypothesis, 9\Gamma 0; A2: \Gamma 0; A5 = \Gamma ;A2 + ae00 and \Gamma  ` A1 = A2 :: \Omega 
) 9\Gamma 2: \Gamma ;A2 + ae00:i = \Gamma 2; A02.

11.3. SELF AND SUBTYPING 243

2
The first key result I need is that if x is bound to a semi-canonical type A in \Gamma  (i.e.,
\Gamma  = \Gamma 1; x:A; \Gamma 2 and A 2 C\Gamma 

1 ), then the result of selecting using path ae on A (S(A; x; ae))can also be obtained by means of equality on the type resulting from cleaving A with ae

under the assignment resulting from cleaving \Gamma ; [self=x]A with ae. (See Theorem 11.3.9
below for the formal version of this result.)

In essence, this result says that applying the self function to the declarations binding a
subcomponent of A adds enough information to allow converting back and forth between
the internal and external names for the preceding subcomponents. (Selection converts
internal names to external ones; cleaving leaves names unchanged.) For example, if
A = \Sigma x0:!\Omega ?: x0! and ae = :2, then we will have the following:

\Gamma ; x0:[self=x:1]!\Omega ? ` x0! = x:1! :: \Omega 
The restriction that A be a semi-canonical type is needed here to ensure that sufficient
information is added by self. (Because semi-canonical types have maximally defined
shapes, self applied to them gives the maximal amount of information.) If we gave x0 the
non-semi-canonical type (*ff::\Omega : ff) !\Omega ? instead, the desired equation would not hold.

The proof of this result is quite complicated. First, I show that constructor extractions
involving a component of A can have their names converted if we can use the final
result on subcomponents of the component in question (Lemma 11.3.7). Second, I show
how to extend the first lemma's result from constructor extractions to arbitrary types
(Lemma 11.3.8). And finally, third, I use the previous lemmas to prove the desired result
(Theorem 11.3.9).

The key idea behind the third step is to apply Lemma 11.3.7 each time we cleave off
a declaration so as to convert all references to that component in the type remaining so
they use the component's external name; by using the fact that self produces a subtype
and the replacement by a subtype result, we can connect together the resulting series of
equalities to convert all the references. The recursion involved can be shown to terminate
by showing that all the recursive calls are to lexically preceding paths (defined below) and
that only a finite number of paths are valid for any given A (i.e., S(A; x; ae) exists).

Definition 11.3.5 (Lexical order for paths)
The path ae1 lexically precedes the path ae2 (written ae1 ! ae2) iff one of the following:

1. ae1 = ffl and ae2 6= ffl
2. ae1 = :1ae01 and ae2 = :2ae02
3. ae1 = :iae01, ae2 = :iae02, and ae01 ! ae02

244 CHAPTER 11. SOUNDNESS
Lemma 11.3.6 If \Gamma 1; x:A; \Gamma 2 ` xae! :: K and A 2 C\Gamma 

1 then\Gamma 

1; x:A; \Gamma 2 ` xae ) S(A; x; ae) and dS(A; x; ae)e ^ !K?.

Proof: Inspection of the typing rules reveals that the derivation of
\Gamma 1; x:A; \Gamma 2 ` xae! :: K must be by either the rule C-EXT-O or the rule C-EXT-T )
9A00; K: \Gamma 1; x:A; \Gamma 2 ` xae ) A00 and dA00e ^ !K? ) \Gamma 1; x:A; \Gamma 2 ` A00 = A0 :: \Omega  and A0 2
C\Gamma 

1;x:A;\Gamma 2 where A

0 = S(A; x; ae) (Lemma 9.5.9) ) dA0e = dA00e (Lemma 9.5.7 and ESYM) ) dA0e ^ !K ?. By P-INIT, P-MOVE,
Lemma 6.3.5, Theorem 9.4.4, and E-REFL, \Gamma 1; x:A; \Gamma 2 ` xae ) A0. 2

Lemma 11.3.7 (Name conversion) Suppose:

1. A 2 C\Gamma 

1

2. \Gamma  = \Gamma 1; x:A; \Gamma 2

3. \Gamma 0; A0 = \Gamma ;([self=x]A) + ae1
4. \Gamma 00; A00 = \Gamma 0;A0 + ae2
5. \Gamma 09; A09 = \Gamma ;A + ae1ae2
6. \Gamma 00 ` A09 = S(A; x; ae1ae2) :: \Omega 
7. \Gamma 0; x0:A0; \Gamma 00 ` xae1ae2! :: K
Then \Gamma 0; x0:A0; \Gamma 00 ` xae1ae2! = x0ae2! :: K

Proof: By Lemma 11.2.2, we can let \Gamma 9; A9 = \Gamma ;A + ae1 and have \Gamma 09; A09 = \Gamma 9;A9 + ae2.
By Lemma 11.3.6, 9K: \Gamma 0; x0:A0; \Gamma 00 ` xae ) S(A; x; ae1ae2) and
dS(A; x; ae1ae2)e ^ !K?. Let A0 = S(A; x; ae1ae2). Casing on dA0e:

!K?: Here dA0e = !K? ) A0 = !K? ) A09 = !K? (Corollary 11.2.6) ) S(A9; x0; ae2) =

!K? (Corollary 11.2.6) and A0 = [self=xae1]A9
(Lemma 11.3.3) ) S(A0; x0; ae2) = S([self=xae1]A9; x0; ae2) =
[self=xae1ae2]!K? (Lemma 11.3.2) ) S(A0; x0; ae2) = !=xae1ae2!::K?
) \Gamma 0; x0:A0; \Gamma 00 ` x0ae2 ) !=xae1ae2!::K? (P-INIT, P-MOVE, E-REFL, and Theorem 9.4.4)
) \Gamma 0; x0:A0; \Gamma 00 ` xae1ae2! = x0ae2! :: K (C-EXT-T, E-ABBREV, E-REFL, E-SYM,
Lemma 6.3.5, and Theorem 9.4.4).

11.3. SELF AND SUBTYPING 245
!=::K?: Here dA0e = !=::K? ) dA09e = !=::K? (Corollary 11.2.6) ) 9A2; A3: A0 =

!=A2::K? and A09 = !=A3::K? ) \Gamma 0; x0:A0; \Gamma 00 ` xae1ae2! = A2 :: K (E-ABBREV,
Theorem 9.4.4, and E-REFL) and \Gamma 00 ` A09 = !=A2::K? :: \Omega  ) A00 = [self=xae1ae2]A09
(Lemma 11.3.3) ) A00 = A09 ) \Gamma 00 ` A00 = !=A2::K? :: \Omega .

By Lemma 6.3.5, P-INIT, and Theorem 11.2.10, \Gamma 0 ` A0 :: \Omega 
) 9\Gamma 8; A8: \Gamma 8; !=A2::K? = \Gamma 0;A8 + ae2 and \Gamma 0 ` A0 = A8 :: \Omega  (Lemma 11.3.4) By
Lemma 6.3.5, P-INIT, Theorem 9.4.4, E-REFL, and P-MOVE,
\Gamma 0 ` !=A2::K ? :: \Omega  ) S(A8; x0; ae2) = !=A2::K? (Corollary 11.2.8)

By P-INIT and Lemma 6.3.5, \Gamma 0; x0:A0; \Gamma 00 ` x0 ) A0
) \Gamma 0; x0:A0; \Gamma 00 ` x0ae2 ) S(A8; x0; ae2) (P-MOVE, Theorem 9.4.1, and
Lemma 6.3.5) ) \Gamma 0; x0ae2:A0; \Gamma 00 ` x0ae2 ) !=A2::K?

) \Gamma 0; x0ae2:A0; \Gamma 00 ` x0ae2! = A2 :: K (E-ABBREV, C-EXT-T, Theorem 9.4.4, and
E-REFL).

) \Gamma 0; x0:A0; \Gamma 00 ` xae1ae2! = x0ae2! :: K (E-SYM and E-TRAN).

2

Lemma 11.3.8 (Name conversion)

Suppose for all \Gamma 0 and ae0, if \Gamma ; \Gamma 0 ` xaeae0! :: K then \Gamma ; \Gamma 0 ` xaeae0! = x0ae0! :: K.
Then if \Gamma ; \Gamma 00 ` [xae=x0]A :: K then \Gamma ; \Gamma 00 ` A = [xae=x0]A :: K.

Proof: Proved by structural induction on the derivation of \Gamma ; \Gamma 00 ` [xae=x0]A :: K. The
proof is completely straightforward using E-REFL except for the following case:

C-EXT-? I: Here \Gamma ; \Gamma 00 ` [xae=x0]x0ae0! :: K ) \Gamma ; \Gamma 00 ` xaeae0! :: K

) \Gamma ; \Gamma 0 ` xaeae0! = x0ae0! :: K. (supposition)
) \Gamma ; \Gamma 0 ` x0ae0! = [xae=x0]x0ae0! :: K (E-SYM).

2

Theorem 11.3.9 (Name conversion) Suppose:

1. A 2 C\Gamma 

1

2. \Gamma 0; A0 = \Gamma 1; x:A; \Gamma 2;A + ae

3. \Gamma 0; A0 = \Gamma 1; x:A; \Gamma 2;([self=x]A) + ae
Then \Gamma 0 ` A0 = S(A; x; ae) :: \Omega .

246 CHAPTER 11. SOUNDNESS
Proof: Proved by induction on the lexical order of ae; recursive calls are only permitted
on lexically preceding paths. Note that this measure is well-founded because there are
only a finite number of paths for which \Gamma 1; x:A; \Gamma 2;A + ae exists. Let \Gamma  = \Gamma 1; x:A; \Gamma 2.
Casing on ae:

ae = ffl: ) S(A; x; ae) = A, A0 = A, and \Gamma 0 = \Gamma . By Lemma 9.5.2, Lemma 6.3.5, and

Theorem 9.4.1, \Gamma  ` A :: \Omega . The desired result then follows via E-REFL.

ae = ae0:1: ) 9x0; A2; A02: \Gamma 0; \Sigma x0:A0: A2 = \Gamma ;([self=x]A) + ae0 and

\Gamma 0; \Sigma x0:A0: A02 = \Gamma ;A + ae0 where x0 6= x and x0 62 dom(\Gamma 00)[dom(\Gamma 00) (Lemma 11.2.2).
By Corollary 11.2.6 and Lemma 6.5.3,
9A001; A002: S(A; x; ae0) = \Sigma x:A001: A002 and S(A; x; ae) = A001.

Applying part one of the induction hypothesis on ae0 gives
\Gamma 0 ` \Sigma x0:A0: A02 = S(A; x; ae0) :: \Omega  ) \Gamma 0 ` \Sigma x0:A0: A02 = \Sigma x:A001: A002 :: \Omega 
) \Gamma 0 ` A0 = A001 :: \Omega  (Lemma 9.4.10) ) \Gamma 0 ` A0 = S(A; x; ae) :: \Omega .

ae = ae0:2: ) 9\Gamma 00; x0; A1; A01: \Gamma 00; \Sigma x0:A1: A0 = \Gamma ;([self=x]A) + ae0 and

\Gamma 00; \Sigma x0:A01: A0 = \Gamma ;A + ae0 where x0 6= x and x0 62 dom(\Gamma 00)[dom(\Gamma 00) (Lemma 11.2.2).
By Corollary 11.2.6 and Lemma 6.5.3,
9A001; A002: S(A; x; ae0) = \Sigma x:A001: A002 and S(A; x; ae) = [xae0:1=x0]A002.

Applying part one of the induction hypothesis on ae0 gives
\Gamma 00 ` \Sigma x0:A01: A0 = S(A; x; ae0) :: \Omega  ) \Gamma 00 ` \Sigma x0:A01: A0 = \Sigma x:A001: A002 :: \Omega 
) \Gamma 00; x0:A01 ` A0 = A002 :: \Omega  (Lemma 9.4.10).

By P-INIT, Lemma 6.3.5, and Corollary 11.2.11, \Gamma  ` [self=x]A ^ A ) \Gamma 00 ` A1 ^ A01
(Lemma 11.2.12 and Lemma 11.3.3) ) \Gamma 00; x0:A1 ` A0 = A002 :: \Omega  (Theorem 10.4.7).
By P-INIT, P-MOVE, E-REFL, Lemma 6.3.5, and Theorem 9.4.4,
\Gamma 00; x0:A1 ` [xae0:1=x0]A002 :: \Omega 

By Lemmas 11.3.7, 11.3.6, 11.2.5, 11.3.3, and 11.2.2 combined with the induction
hypothesis on paths starting with ae0:1, we have that if
\Gamma 00; x0:A1; \Gamma 00 ` xae0:1ae2! :: K then \Gamma 00; x0:A1; \Gamma 00 ` xae0:1ae2! = x0ae2! :: K.

Hence by Lemma 11.3.8, \Gamma 00; x0:A1 ` A002 = [xae0:1=x0]A002 :: \Omega 
) \Gamma 00; x0:A1 ` A0 = [xae0=x0]A002 :: \Omega  (E-TRAN) ) \Gamma 0 ` A0 = S(A; x; ae) :: \Omega .

2

The second key result (Corollary 11.3.12, below) is that if x is bound to a semicanonical type A1 in \Gamma , \Gamma  ` A1 ^ A2, and \Gamma  ` [self=x]A2 :: \Omega , then
\Gamma  ` [self=x]A1 ^ [self=x]A2. This result is exactly what is needed to prove the replacement by a subtype result for the term level in the T-VAR case (see the VAR I case of
Theorem 11.4.20).

11.3. SELF AND SUBTYPING 247

The only hard point in the proof is the inductive case where the ae component via
cleaving of A1 is !=A::K ? and of A2 is !K?. In that case, we need to show that
A = xae! under the appropriate assignment, call it \Gamma 0, since [self=xae]A1 = !=A::K? and
[self=xae]A2 = !=xae!::K?. It is easy to show that \Gamma 0 ` xae! = S(A1; x; ae) :: K. The previous key result (Theorem 11.3.9) can then be used to show that \Gamma 0 ` A = S(A1; x; ae) :: K.

Lemma 11.3.10 If \Gamma 0; A0 = \Gamma ;A + ae and A 2 C\Gamma  then A0 2 C\Gamma 0.
Proof: Proved by structural induction on ae using Lemma 9.5.3. 2

Theorem 11.3.11 (Self and subtyping) Suppose:

1. \Gamma  = \Gamma 1; x:A1; \Gamma 2
2. A1 2 C\Gamma 

1

3. \Gamma 0; A01 = \Gamma ;A1 + ae

4. \Gamma 00; A02 = \Gamma ;A2 + ae
5. \Gamma 0; [self=xae]A01 = \Gamma ;[self=x]A1 + ae
6. \Gamma 0 ` A01 ^ A02
7. \Gamma 0 ` [self=xae]A02 :: \Omega 
Then \Gamma 0 ` [self=xae]A01 ^ [self=xae]A02.

Proof: Proved by structural induction on A01. By P-INIT and Lemma 6.3.5, \Gamma  ` x ) A1
) \Gamma  ` [self=x]A1 ^ A1 (Corollary 11.2.11) ) \Gamma 0 ` [self=xae]A01 ^ A01 and \Gamma 0 ` A01 ^ A02
(Lemma 11.2.12) ) \Gamma 0 ` [self=xae]A01 ^ A02.

This handles all the cases for dA02e 62 f\Sigma ; !K?g () [self=xae]A02 = A02). By Lemma 6.3.5,
Theorem 9.5.5, and Lemma 11.3.10, A01 2 C\Gamma 0 ) dA01e\Gamma 0 = dA01e (Lemma 10.3.9) )
dA01e ^ dA02e\Gamma 0 (Lemma 10.3.11). The remaining cases are thus:

case I: dA02e = !K?:

) dA02e\Gamma 0 = !K? (definition of intrinsic shape and E-REFL)
) dA01e ^ !K?. There are two cases:

- dA01e = !K? ) A01 = !K? = A02 ) [self=xae]A01 = [self=xae]A02

) \Gamma 0 ` [self=xae]A01 ^ [self=xae]A02 (O-REFL and S-ONE).

248 CHAPTER 11. SOUNDNESS

- dA01e = !=::K? ) 9A4: A02 = !K? and A01 = !=A4::K? By Theorem 11.3.9, \Gamma 0 ` !=A4::K? = S(A1; x; ae) :: \Omega  ) \Gamma 0 ` xae ) !=A4::K ? (PINIT, Lemma 6.3.5, Theorem 9.4.4, E-REFL, and P-MOVE)
) \Gamma 0 ` xae! = A4 :: K (E-ABBREV, C-EXT-T, Theorem 9.4.4, and E-REFL)
) \Gamma 0 ` !=xae!::K? = !=A4::K? :: \Omega  (E-TRANS)
) \Gamma 0 ` [self=xae]!=A4::K? = [self=xae]!K? :: \Omega  (E-SYM)
) \Gamma 0 ` [self=xae]A01 = [self=xae]A02 :: \Omega . )
\Gamma 0 ` [self=xae]A01 ^ [self=xae]A02 (S-EQ).

case II: dA02e = \Sigma :

) dA02e\Gamma 0 = \Sigma  (definition of intrinsic shape and E-REFL) ) dA01e = \Sigma  )
9x0; A4; A5; A6; A7 such that A01 = \Sigma x0:A4: A5 and A02 = \Sigma x0:A6: A7 where x0 62
dom(\Gamma 0) [ dom(\Gamma 0). By Lemma 10.5.1, \Gamma 0 ` A4 ^ A6 and \Gamma 0; x0:A4 ` A5 ^ A7. By
C-DSUM, DECL-T, and Lemma 6.3.5, \Gamma 0 ` [self=xae:1]A6 :: \Omega  and
\Gamma 0; x0:[self=xae:1]A6 ` [self=xae:2]A7 :: \Omega .

Hence, by Lemmas 11.2.2, 11.3.3, and the induction hypothesis on A4,
\Gamma 0 ` [self=xae:1]A4 ^ [self=xae:1]A6
) \Gamma 0; x0:[self=xae:1]A4 ` [self=xae:2]A7 :: \Omega  (Theorem 10.4.7). Hence, by
Lemmas 11.2.2, 11.3.3, and the induction hypothesis on A5,
\Gamma 0; x0:[self=xae:1]A4 ` [self=xae:2]A5 ^ [self=xae:2]A7 )
\Gamma 0 ` \Sigma x0:[self=xae:1]A4: [self=xae:2]A5 ^ \Sigma x0:[self=xae:1]A6: [self=xae:2]A7
(Theorem 10.5.4) ) \Gamma 0 ` [self=xae]A01 ^ [self=xae]A02.

2

Corollary 11.3.12 (Self and subtyping) Suppose:

1. A1 2 C\Gamma 

1

2. \Gamma 1; x:A1; \Gamma 2 ` A1 ^ A2

3. \Gamma 1; x:A1; \Gamma 2 ` [self=x]A2 :: \Omega 
Then \Gamma 1; x:A1; \Gamma 2 ` [self=x]A1 ^ [self=x]A2.

Proof: Follows immediately from Theorem 11.3.11 with ae = ffl. 2

11.4. RUNTIME STATES 249
11.4 Runtime States
In this section I introduce the semantic system, an extension of the kernel system that
allows tracking the richer runtime states that arise during evaluation. The semantic
system differs only at the term level; it extends the set of kernel system terms with
locations (l) and adds stores (S) which map locations to values (V ). Stores are assigned
store types (\Phi ) which map locations to types. As a technical device to simplify the
semantics, the primitive functions roll, unroll, new, get, and set are replaced in the
semantic system with versions that are either fully uncurried (roll2(\Gamma ; \Gamma )) or curried
only in their last argument (unroll1(\Gamma ), new1(\Gamma ), get1(\Gamma ), and set2(\Gamma ; \Gamma )). The fully
curried versions can be regarded as syntactic sugar for the (partially) uncurried ones:

Definition [Sem] 11.4.1 (Syntactic sugar)

roll = *x:!\Omega )\Omega ?: *x0:x! (rec x!): roll2(x!; x0)
unroll = *x:!\Omega )\Omega ?: unroll1(x!)

new = *x:!\Omega ?: new1(x!)

get = *x:!\Omega ?: get1(x!)

set = *x:!\Omega ?: *x0:ref x!: set2(x!; x0)

Similarly, the new primitives can be defined in terms of the old ones:
Definition [Sem] 11.4.2

roll2(A; M ) = (roll !A?) M

unroll1(A) = unroll !A?

new1(A) = new !A?

get1(A) = get !A?
set2(A; M ) = (set !A?) M

The syntax for the semantic system is the same as for the kernel system except for
the following changes and additions:

250 CHAPTER 11. SOUNDNESS
Definition [Sem] 11.4.3 (Changed syntax)

Terms M ::= x j *x:A: M j M 1 M 2 j (M 1; M 2) j M :1 j M :2 j

!A? j M !:A j l j roll2(A; M ) j
unroll1(A) j new1(A) j get1(A) j set2(A; M )

Values V ::= *x:A: M j (V 1; V 2) j !A? j l j roll2(A; V ) j

unroll1(A) j new1(A) j get1(A) j set2(A; l)

Store types \Phi  ::= ffl j \Phi ; l:A
Stores S ::= ffl j S; l=V

These changes in syntax require the obvious changes in the free term variables and free
constructor variables functions:

Definition [Sem] 11.4.4 (Changes)

FTV(l) = ;
FTV(new1(A)) = FTV(A)

FTV(get1(A)) = FTV(A)
FTV(unroll1(A)) = FTV(A)

FTV(set2(A; M )) = FTV(A) [ FTV(M )
FTV(roll2(A; M )) = FTV(A) [ FTV(M )

FCV(l) = ;
FCV(new1(A)) = FCV(A)

FCV(get1(A)) = FCV(A)
FCV(unroll1(A)) = FCV(A)
FCV(set2(A; M )) = FCV(A) [ FCV(M )
FCV(roll2(A; M )) = FCV(A) [ FCV(M )

Values are a special subset of terms (all V s are M s) that evaluate to themselves. When
a program terminates, the result of its evaluation is always a value. With the exception
of the body of a lambda, all components of values are themselves values. The set of values includes user functions (*x:A: M ), partially applied primitive functions (unroll1(A),
new1(A), get1(A), and set2(A; l)1), pairs of values, reified constructors, locations (the
values of reference types), and rolled values (roll2(A; V ), the values of recursive types).
Term variables, applications, projections, and coercions are never values.

The semantic system has three term-level judgments:

1I choose to make the value syntax reflect the fact that set

2(\Gamma ; \Gamma )'s second argument is always a

location in a well-typed computation result; the complexity of the system is uneffected by this choice.

11.4. RUNTIME STATES 251
Definition [Sem] 11.4.5 (Judgments)

` \Phi  valid valid store type

\Gamma  `\Phi  M : A well-typed term

` S : \Phi  well-typed store
Note that the semantic system's well-typed term judgment takes an additional parameter,
a store type (\Phi ), which is used to determine the types of locations appearing in the term.

Store types are valid if they never redeclare the type of a location and if all types
they assign to locations are valid under the empty assignment:

Definition [Sem] 11.4.6 (Store Type Formation Rules)

` ffl valid (ST-EMPTY)

` \Phi  valid ffl ` A :: \Omega  l 62 dom(\Phi )

` \Phi ; l:A valid (ST-EXTEND)

The rules for the semantic system's well-typed term judgment follow. The LAM, APP,
PAIR, FST, SND, SUMP, and COERCE rules are unchanged from the kernel system
aside from the addition of the extra store-type parameter. The VAR and REIFY rules
have an extra precondition ` \Phi  valid added to ensure that if \Gamma  `\Phi  M : A then ` \Phi  valid
(see Lemma 11.4.12). The NEW, GET, SET, ROLL, and UNROLL rules are modified
to handle the (partially) uncurried versions of the primitive functions. The previous
versions of these rules (using the curried versions) are easily verified to be derived rules
in the semantic system. The SM-LABEL rule is the only completely new rule; it assigns
the type ref \Phi (l) to location l.

Definition [Sem] 11.4.7 (Term Formation Rules)

` \Phi  valid \Gamma  ` \Gamma (x) = A :: \Omega 

\Gamma  `\Phi  x : [self=x]A (SM-VAR)

\Gamma ; x:A `\Phi  M : A0
\Gamma  `\Phi  *x:A: M : \Pi x:A: A0 (SM-LAM)

\Gamma  `\Phi  M 1 : A2!A \Gamma  `\Phi  M 2 : A2

\Gamma  `\Phi  M 1 M 2 : A (SM-APP)

252 CHAPTER 11. SOUNDNESS

\Gamma  `\Phi  M 1 : A1 \Gamma  `\Phi  M 2 : A2

\Gamma  `\Phi  (M 1; M 2) : (A1; A2) (SM-PAIR)

\Gamma  `\Phi  M : \Sigma x:A1: A2

\Gamma  `\Phi  M :1 : A1 (SM-FST)

\Gamma  `\Phi  M : (A1; A2)

\Gamma  `\Phi  M :2 : A2 (SM-SND)

` \Phi  valid \Gamma  ` A :: K

\Gamma  `\Phi  !A? : !=A::K? (SM-REIFY)

\Gamma  `\Phi  M : A0 \Gamma  ` A0 ^ A

\Gamma  `\Phi  M : A (SM-SUMP)

\Gamma  `\Phi  M : A
\Gamma  `\Phi  M !:A : A (SM-COERCE)

` \Gamma  valid ` \Phi  valid l 2 dom(\Phi )

\Gamma  `\Phi  l : ref (\Phi (l)) (SM-LABEL)

` \Phi  valid \Gamma  ` A :: \Omega 
\Gamma  `\Phi  new1(A) : A!ref A (SM-NEW)

` \Phi  valid \Gamma  ` A :: \Omega 
\Gamma  `\Phi  get1(A) : ref A!A (SM-GET)

` \Phi  valid \Gamma  ` A :: \Omega )\Omega 
\Gamma  `\Phi  unroll1(A) : rec A!A (rec A) (SM-UNROLL)

\Gamma  `\Phi  M : ref A
\Gamma  `\Phi  set2(A; M ) : A!A (SM-SET)

\Gamma  `\Phi  M : A (rec A)
\Gamma  `\Phi  roll2(A; M ) : rec A (SM-ROLL)

Because these rules are so similar to the kernel system ones, the proofs for many propositions are essentially the same for both systems. Accordingly, I present each such proposition only once; these results, marked with [(Sem)], hold both in the semantics system
and (once the store types are removed) in the kernel system.

Any well-typed term in the kernel system is also a well-typed term in the semantic
system taking Definition 11.4.1 into account:

11.4. RUNTIME STATES 253
Lemma 11.4.8 If \Gamma  ` M : A then \Gamma  `ffl M : A.
The reverse is also true if we limit ourselves to terms that do not contain locations and
use Definition 11.4.2:

Lemma [Sem] 11.4.9 If \Gamma  `\Phi  M : A and M contains no locations then
\Gamma  ` M : A.

A store S has valid store type \Phi  iff it assigns a unique value V of type \Phi (l) under the
empty assignment and store type \Phi  to each location l mapped by \Phi :

Definition [Sem] 11.4.10 (Store Formation Rules)

` \Phi  valid
jSj = j\Phi j 8l 2 dom(\Phi ): ffl `\Phi  S(l) : \Phi (l)

` S : \Phi  (STORE)

As with assignments, stores and store types can be treated as as partial functions:
Definition [Sem] 11.4.11 (Store (types) regarded as partial functions)

dom(ffl) = ;
dom(\Phi ; l:A) = dom(\Phi ) [ flg

(\Phi 1; l:A; \Phi 2)(l) = A (l 62 dom(\Phi 1))

dom(ffl) = ;
dom(S; l=V ) = dom(S) [ flg

(S1; l=V ; S2)(l) = V (l 62 dom(S1))
Lemma [Sem] 11.4.12 (Store (type) properties)

1. dom(\Phi ; \Phi 0) = dom(\Phi ) [ dom(\Phi 0)
2. dom(S; S0) = dom(S) [ dom(S0)
3. If l:A 2 \Phi  then l 2 dom(\Phi ).
4. If l=V 2 S then l 2 dom(S).

The usual propositions on judgments hold for the semantic and kernel systems' termlevel judgments:

254 CHAPTER 11. SOUNDNESS
Lemma [Sem] 11.4.13 (Structural properties)

1. If ` \Phi  valid and l 2 dom(\Phi ) then ffl ` \Phi (l) :: \Omega .
2. If ` S : \Phi  then ` \Phi  valid.
3. If \Gamma  `\Phi  M : A then ` \Phi  valid.
Lemma [Sem] 11.4.14 (Valid store (type) properties)

Suppose ` \Phi  valid and ` S : \Phi 0. Then:

1. dom(S) = dom(\Phi 0)
2. If l:A 2 \Phi  then \Phi (l) = A.
3. If l=V 2 S then S(l) = V .
Proof: Inspection of the typing rules for store (types) reveal that valid store (types)
never redeclare/rebind labels. Thus, we have that j\Phi 0j = jdom(\Phi 0)j and jSj = jdom(S)j
) dom(S) = dom(\Phi 0) by STORE. 2

Theorem [(Sem)] 11.4.15 (Validity of Term Types)

If \Gamma  `\Phi  M : A then \Gamma  ` A :: \Omega .

Proof: Proved by structural induction on the derivation. Interesting cases:
VAR: Given \Gamma  ` \Gamma (x) = A :: \Omega  ) \Gamma  ` x ) A (Lemma 6.3.5, P-INIT, and P-MOVE) )

\Gamma  ` [self=x]A :: \Omega  (Theorem 11.2.10).

SND: Given \Gamma  `\Phi  M : \Pi x:A1: A2, x 62 FTV(A2) ) \Gamma  ` \Pi x:A1: A2 :: \Omega  (induction hypothesis) ) \Gamma ; x:A1 ` A2 :: \Omega  (C-DSUM) ) \Gamma  ` A2 :: \Omega  (Theorem 9.6.1).

SUMP: Follows immediately from Lemma 10.2.2.
SM-NEW: Using P-INIT, C-EXT-O, C-DFUN, C-REF, and C-APP it is easy to prove that

ffl ` 8ff::\Omega :ff!ref ff :: \Omega  Using weakening (Theorem 9.4.1) then, we get the desired
result: \Gamma  ` 8ff::\Omega :ff!ref ff :: \Omega .

SM-LABEL: Follows immediately from Lemma 11.4.13, Theorem 9.4.1, Lemma 6.3.5, C-REF,

and C-APP.

2

11.4. RUNTIME STATES 255
Lemma [(Sem)] 11.4.16 If \Gamma  `\Phi  M : A then FTV(M ) ` FTV(\Gamma ).
Proof: By structural induction on the derivation using Theorem 6.5.6,
Lemma 6.3.5, Theorem 11.4.15, and Lemma 10.2.2 as needed. 2

Theorem [(Sem)] 11.4.17 (Weakening)

Suppose ` \Gamma ; \Gamma 0 valid and dom(\Gamma 0) " dom(\Gamma 00) = ;. Then if \Gamma ; \Gamma 00 `\Phi  M : A then
\Gamma ; \Gamma 0; \Gamma 00 `\Phi  M : A.

Proof: By structural induction on the derivation of \Gamma ; \Gamma 00 `\Phi  M : A, using Theorem 9.4.1, Theorem 10.2.3, Lemma 6.3.5, and Lemma 9.4.2 as needed. 2

Theorem [Sem] 11.4.18 (Weakening)

Suppose ` \Phi ; \Phi 0 valid. Then if \Gamma  `\Phi  M : A then \Gamma  `\Phi ;\Phi 0 M : A.

Proof: By structural induction on the derivation of \Gamma  `\Phi  M : A. The only interesting
case is SM-LABEL which is handled by the fact that l 2 dom(\Phi ) ) l 2 dom(\Phi ; \Phi 0) and
\Phi (l) = (\Phi ; \Phi 0)(l) (definition of store type as a partial function). 2

Theorem [(Sem)] 11.4.19 (Strengthening)

Suppose x 62 FTV(\Gamma 0) [ FTV(M ) [ FTV(A). Then, if \Gamma ; x:A0; \Gamma 0 `\Phi  M : A, then
\Gamma ; \Gamma 0 `\Phi  M : A.

Proof: By structural induction on the derivation using Theorem 9.6.1, Corollary 9.6.2,
Lemma 10.2.4, Lemma 6.3.5, and Lemma 9.4.2 as needed. 2

Theorem [(Sem)] 11.4.20 (Replacement by a subtype)

If \Gamma  ` A2 ^ A1 and \Gamma ; x:A1; \Gamma 0 `\Phi  M : A then \Gamma ; x:A2; \Gamma 0 `\Phi  M : A.

Proof: By structural induction on the derivation of \Gamma ; x:A1; \Gamma 0 `\Phi  M : A using Theorem 10.4.7 as needed. The only interesting case is as follows:

VAR I: Here \Gamma ; x:A1; \Gamma 0 `\Phi  x : [self=x]A derived via rule T/SM-VAR from

\Gamma ; x:A1; \Gamma 0 ` (\Gamma ; x:A1; \Gamma 0)(x) = A :: \Omega  ) \Gamma ; x:A1; \Gamma 0 ` [self=x]A :: \Omega 
(Theorem 11.4.15) ) \Gamma ; x:A2; \Gamma 0 ` [self=x]A :: \Omega  and
\Gamma ; x:A2; \Gamma 0 ` (\Gamma ; x:A1; \Gamma 0)(x) = A :: \Omega  (Theorem 10.4.7) ) ` \Gamma ; x:A2; \Gamma 0 valid and
\Gamma ; x:A2; \Gamma 0 ` A1 = A :: \Omega  (Lemma 6.3.5 and Theorem 9.4.2)

256 CHAPTER 11. SOUNDNESS

) \Gamma ; x:A2; \Gamma 0 ` A2 ^ A1 (Theorem 10.2.3) ) \Gamma ; x:A2; \Gamma 0 ` A2 ^ A (S-EQ and ETRAN).

By Theorem 9.5.10 and Lemma 10.2.2, 9A02: \Gamma  ` A2 = A02 :: \Omega  and A02 2 C\Gamma  )
\Gamma ; x:A02; \Gamma 0 ` [self=x]A :: \Omega  (Theorem 9.4.6), \Gamma ; x:A02; \Gamma 0 ` A2 ^ A (Theorem 10.2.5),
and \Gamma ; x:A02; \Gamma 0 ` A2 = A02 :: \Omega  (Theorem 10.2.3 and Lemma 6.3.5)
) \Gamma ; x:A02; \Gamma 0 ` A02 ^ A (E-SYM, S-EQ, and S-TRAN). Hence, by Corollary 11.3.12,
\Gamma ; x:A02; \Gamma 0 ` [self=x]A02 ^ [self=x]A.

By T/SM-VAR and Theorem 9.4.6, \Gamma ; x:A2; \Gamma 0 `\Phi  x : [self=x]A02
) \Gamma ; x:A2; \Gamma 0 `\Phi  x : [self=x]A (T/SM-SUMP).

2

11.5 Properties of Values
In this section I establish a number of properties of values that I shall need to prove
soundness. In order to do type inference in the presence of subsumption, it is necessary
to be able to compute minimal types of terms:

Definition [Sem] 11.5.1 A is a minimal type for M under \Gamma  and \Phi 
(A 2 Min\Gamma ;\Phi (M )) iff:

1. \Gamma  `\Phi  M : A
2. If \Gamma  `\Phi  M : A0 then \Gamma  ` A ^ A0.

I shall need the minimal types of the primitive function values in order to determine
the types of their arguments in applications:

Lemma [Sem] 11.5.2 (Minimal types of selected values)

Suppose \Gamma  `\Phi  V : A. Then:

1. If V = !A0? then 9K: !=A0::K? 2 Min\Gamma ;\Phi (V ).
2. If V = l then ref \Phi (l) 2 Min\Gamma ;\Phi (V ).
3. If V = new1(A) then A!ref A 2 Min\Gamma ;\Phi (V ).
4. If V = get1(A) then ref A!A 2 Min\Gamma ;\Phi (V ).
5. If V = set2(A; l) then A!A 2 Min\Gamma ;\Phi (V ).

11.5. PROPERTIES OF VALUES 257

6. If V = roll2(A; V ) then rec A 2 Min\Gamma ;\Phi (V ).
7. If V = unroll1(A) then rec A!A (rec A) 2 Min\Gamma ;\Phi (V ).
Proof: Any derivation of \Gamma  `\Phi  V : A for the above values must consist of an application
of SM-REIFY/SM-LABEL/SM-NEW/SM-GET/SM-SET/SM-ROLL/SM-UNROLL respectively followed by zero or more applications of SM-SUMP. Hence, A must be a
supertype under \Gamma  for the respective listed type by S-TRAN. 2

This information can also be used to compute the intrinsic shapes of values' types:
Lemma [(Sem)] 11.5.3 If \Gamma  `\Phi  M : A and dAe 6= ? then dAe\Gamma  = dAe.
Proof: By Theorem 11.4.15 and E-REFL, \Gamma  ` A = A :: \Omega  ) dAe\Gamma  = dAe (definition
of intrinsic shape). 2

Lemma [Sem] 11.5.4 (Intrinsic shapes of values' types)

Suppose \Gamma  `\Phi  V : A. Then:

1. If V = !A0? then 9K: !=::K? ^ dAe\Gamma .

2. If V = l then dAe\Gamma  = refapp.
3. If V = roll2(A; V ) then dAe\Gamma  = recapp.
4. If V = new1(A), get1(A), set2(A; l), or unroll1(A) then dAe\Gamma  = \Pi .
5. If V = *x:A0: V 0 then dAe\Gamma  = \Pi .
6. If V = (V 1; V 2) then dAe\Gamma  = \Sigma .
Proof: For parts 1-4, Lemma 11.5.2, provides a minimal type A0 for V under \Gamma  such that
dA0e 6= ? ) dA0e\Gamma  = dA0e (Lemma 11.5.3 and definition of minimal type) and \Gamma  ` A0 ^ A
(definition of minimal type) ) dA0e ^ dAe\Gamma  (Corollary 10.3.12) ) 9K: !=::K? ^ dAe\Gamma 
for part 1 and dA0e = dAe\Gamma  for parts 2-4.

For parts 5/6, any derivation of \Gamma  `\Phi  V : A for the values in question must consist
of an application of SM-LAM/SM-PAIR respectively followed by zero or more applications of SM-SUMP. Hence, A must be a supertype under \Gamma  of a dependent function/pair
type by S-TRAN ) A's intrinsic shape under \Gamma  must be \Pi /\Sigma  (Corollary 10.3.12 and
Lemma 11.5.3). 2

Before I describe the last property of values I shall need, I first need to introduce
some definitions. A transparent constructor is one that contains no direct components
(i.e., the result of a cleaving operation) of the form !K? for some K:

258 CHAPTER 11. SOUNDNESS
Definition 11.5.5 (Transparent constructors)
A constructor A is a transparent constructor iff either:

1. 8K: dAe 62 f\Sigma ; !K?g
2. 9A1; A2: A = \Sigma x:A1: A2 and both A1 and A2 are themselves transparent constructors.

Because the self function only adds information to direct components of the form !K ?,
the self function leaves transparent constructors unchanged:

Lemma 11.5.6 If A is a transparent constructor then [self=xae]A = A.

A disconnected constructor is one in which no direct component refers back to a
previous component:

Definition 11.5.7 (Disconnected constructors)
A constructor A is a disconnected constructor iff either:

1. dAe 6= \Sigma 
2. 9A1; A2: A = \Sigma x:A1: A2, x 62 FTV(A2), and both A1 and A2 are themselves disconnected constructors.

The property of being a transparent and disconnected constructor is preserved by selection:

Lemma 11.5.8 If A is a transparent and disconnected constructor and
S(A; xae; ae0) exists then S(A; xae; ae0) is a transparent and disconnected constructor.

Proof: Proved by structural induction on ae0. Example case:

Snd: Here ae0 = :2ae00 and A = (A1; A2) ) S(A; xae; :2) = A2 ) S(A; xae; :2ae00) =

S(S(A; xae; :2); xae:2; ae00) = S(A2; xae:2; ae00) (Lemma 6.5.3). By the definitions of
transparent and disconnected constructors, A2 is a transparent and disconnected
constructor. Hence, by the inductive hypothesis, S(A2; xae:2; ae00) is a transparent
and disconnected constructor ) S(A; xae; ae0) is a transparent and disconnected
constructor.

2

The importance of the property of being a transparent disconnected constructor is
that when a term variable has a transparent disconnected semi-canonical type, all paths
involving it are defined transparently rather than opaquely:

11.5. PROPERTIES OF VALUES 259
Lemma [Sem] 11.5.9 If A 2 C\Gamma  and A is a transparent disconnected constructor then
\Gamma ; x:A; \Gamma 0 ` xae ) !K? is impossible.

Proof: By Lemma 9.5.9 and E-SYM, \Gamma ; x:A; \Gamma 0 ` S(A; x; ae) = !K? :: \Omega  and S(A; x; ae) 2
C\Gamma ;x:A;\Gamma 0 ) S(A; x; ae) = !K? (Lemma 9.5.7) ) S(A; x; ae) is not a transparent constructor. But this this contradicts Lemma 11.5.8, so this is impossible. 2

All values can be assigned such a type as a minimal type:
Theorem [Sem] 11.5.10 If \Gamma  `\Phi  V : A then there exists a type A0 such that:

1. \Gamma  ` A0 ^ A

2. \Gamma  `\Phi  V : A0
3. A0 2 C\Gamma 
4. A0 is a transparent constructor
5. A0 is a disconnected constructor
Proof: Proved by structural induction on V . Cases:
REIFY: Here V = !A1? ) 9K: !=A1::K? 2 Min\Gamma ;\Phi (V ). (Lemma 11.5.2)

) \Gamma  `\Phi  V : !=A1::K? and \Gamma  ` !=A1::K? ^ A (definition of minimal type). By
Theorem 11.4.15 and Theorem 9.5.10, 9A0: \Gamma  ` !=A1::K? = A0 :: \Omega  and A0 2 C\Gamma 
) \Gamma  `\Phi  V : A0 and \Gamma  ` A0 ^ A (S-EQ, S-TRAN, and SM-SUMP) and dA0e =
dA0e\Gamma  = d!=A1::K?e = !=::K? (Lemma 10.3.9 and definition of intrinsic shape)
) A0 is a transparent and disconnected constructor.

PAIR: Here V = (V 1; V 2). WLOG, \Gamma  `\Phi  V : A was derived without using the SM-SUMP

rule ) 9A1; A2: A = (A1; A2), \Gamma  `\Phi  V 1 : A1, and \Gamma  `\Phi  V 2 : A2 (SM-PAIR). Hence,
by the induction hypothesis, 8i 2 f1; 2g: 9A0i: \Gamma  ` A0i ^ Ai, \Gamma  `\Phi  V i : A0i, A0i 2
C\Gamma , and A0i is a transparent and disconnected constructor. Let A0 = \Sigma x:A01: A02,
x 62 FTV(A02) [ dom(\Gamma ) ) A0 is a transparent and disconnected constructor,
\Gamma  `\Phi  (V 1; V 2) : A0 (SM-PAIR and DECL-T), \Gamma ; x:A01 ` A02 ^ A2 and
\Gamma ; x:A1 `\Phi  A2 : \Omega  (Theorem 9.4.1 and DECL-T), and A02 2 C\Gamma ;x:A0

1 (Lemma 9.5.5and DECL-T) ) \Gamma  ` A0 ^ A (Theorem 10.5.4) and A0 2 C

\Gamma  (Lemma 9.5.4).

OTHER: Here V does not have the form !A1? or the form (V 1; V 2). By Theorem 11.4.15

and Theorem 9.5.10, 9A0: \Gamma  ` A = A0 :: \Omega  and A0 2 C\Gamma  ) \Gamma  ` A0 ^ A and \Gamma  ` A ^ A0
(E-SYM and S-EQ) and dA0e\Gamma  = dA0e (Lemma 10.3.9) ) \Gamma  `\Phi  V : A0 (SM-SUMP)
) 8K: dA0e 62 f\Sigma ; !K?g ) A0 is a transparent and disconnected constructor.

2

260 CHAPTER 11. SOUNDNESS
11.6 Value Substitution
In this section I introduce value substitution ([V =x]\Gamma ) which involves substituting values
for term variables in constructors, assignments, and terms. Value substitution is the
analog of constructor substitution in reducing applications at the term level ((*x:A: M ) V
reduces to [V =x]M ). Before I can define value substitution, I shall need some auxiliary
definitions.

The definition of selection can be extended to values:

Definition [Sem] 11.6.1 (Value selection)

V # ffl = V
(V 1; V 2) # :1ae0 = V 1 # ae0
(V 1; V 2) # :2ae0 = V 2 # ae0

Note that the definition is simpler for values because of the lack of internal names for
components. Like selection on constructors, selection on values can also be done in steps:

Lemma 11.6.2 if V # :iae0 or (V # :i) # ae0 exists then

V # :iae0 = (V # :i) # ae0
Proof: By inspection of the definition of value selection. 2

Lemma 11.6.3 If V # ae1ae2 exists then

V # ae1ae2 = (V # ae1) # ae2
Proof: By structural induction on ae1. The non-basis case is as follows:

V # :iaeae2
= (V # :i) # aeae2 (Lemma 6.5.2)
= ((V # :i) # ae) # ae2 (induction hypothesis)
= (V # :iae) # ae2 (Lemma 6.5.2)

2

The type of a value selection by ae on V can be related to V 's type if it is a transparent
disconnected type that can be selected on by ae:

11.6. VALUE SUBSTITUTION 261
Lemma [Sem] 11.6.4 If \Gamma  `\Phi  V : A, A a transparent disconnected constructor, and
S(A; x; ae) exists then \Gamma  `\Phi  (V # ae) : S(A; x; ae).

Proof: Proved by structural induction on ae. Example case:

Snd: Here ae = :2ae0 and A = (A1; A2) ) V has form (V 1; V 2) (Lemma 11.5.4, definition of

intrinsic shape, Theorem 9.4.3, and E-REFL) ) V # :2 = V 2 and S(A; x; :2) = A2
) V # :2ae0 = (V # :2) # ae0 = V 2 # ae0 (Lemma 11.6.3) and S(A; x; :2ae0) =
S(S(A; x; :2); x; ae0) = S(A2; x; ae0) (Lemma 6.5.3). By the definition of a transparent
disconnected constructor, A2 is a transparent disconnected constructor. Inspection
of the typing rules shows that \Gamma  `\Phi  V : A must be derived using SM-PAIR followed
by zero or more occurrences of SM-SUMP ) 9A01; A02: \Gamma  ` (A01; A02) ^ (A1; A2),
\Gamma  `\Phi  V 1 : A01, and \Gamma  `\Phi  V 2 : A02 ) \Gamma ; x:A01 ` A02 ^ A2 for some x such that x 62
FTV(A2) [ FTV(A02) [ dom(\Gamma ) (Lemma 10.5.1) ) \Gamma  ` A02 ^ A2 (Theorem 10.2.4)
) \Gamma  `\Phi  V 2 : A2 (SM-SUMP). Hence, by the induction hypothesis,
\Gamma  `\Phi  (V 2 # ae0) : S(A2; x; ae0) ) \Gamma  `\Phi  (V # ae) : S(A; x; ae).

2

The extraction operator on values is a partial function that converts from reified
constructors to their component constructor:

Definition [Sem] 11.6.5 (Extraction)

!A?! = A
Again, the result of the extraction operator on a value can be related to that value's
type:

Lemma [Sem] 11.6.6 If \Gamma  `\Phi  V : !=A::K ? then \Gamma  ` V ! = A :: K.
Proof: By Lemma 11.5.3, d!=A::K?e\Gamma  = !=::K? ) V has form !A0? for some
A0 (Lemma 11.5.4) ) V ! = A0 and 9K0: \Gamma  ` !=A0::K0? ^ !=A::K? (Lemma 11.5.2
and definition of minimal type) ) K = K0 and \Gamma  ` !=A0::K? = !=A::K? :: \Omega  (Corollary 10.3.14, Lemma 10.2.2, E-REFL, and definition of intrinsic shape) ) \Gamma  ` A0 = A :: K
(Lemma 9.4.10) ) \Gamma  ` V ! = A :: K. 2

These results can be combined to determine the type of a value selection followed by
an extraction:

Theorem [Sem] 11.6.7

If \Gamma  `\Phi  V : A, A a transparent disconnected constructor, A 2 C\Gamma , and
\Gamma ; x:A; \Gamma 0 ` xae ) !=A0::K? then \Gamma ; x:A; \Gamma 0 ` (V # ae)! = A0 :: K.

262 CHAPTER 11. SOUNDNESS
Proof: By Lemma 9.5.9 and E-SYM, \Gamma ; x:A; \Gamma 0 ` S(A; x; ae) = !=A0::K? :: \Omega . By
Lemma 11.6.4 and Theorem 11.4.17, \Gamma ; x:A; \Gamma 0 `\Phi  (V # ae) : S(A; x; ae)
) \Gamma ; x:A; \Gamma 0 `\Phi  (V # ae) : !=A0::K? (S-EQ and SM-SUMP)
) \Gamma ; x:A; \Gamma 0 ` (V # ae)! = A0 :: K (Lemma 11.6.6). 2

Using these definitions, I can define value substitution ([V =x]\Gamma ) on constructors and
assignments; the key idea is to replace xae with (V # ae)!:

Definition [Sem] 11.6.8 (Value substitution on constructors)

[V =x]xae! = (V # ae)!
[V =x]x0ae! = x0ae! (x0 6= x)

[V =x]*ff::K: A = *ff::K: [V =x]A (ff0 62 FCV(V ))
[V =x]\Pi x0:A1: A2 = \Pi x0:[V =x]A1: [V =x]A2 (x0 6= x; x0 62 FTV(V ))
[V =x]\Sigma x0:A1: A2 = \Sigma x0:[V =x]A1: [V =x]A2 (x0 6= x; x0 62 FTV(V ))

[V =x](A1 A2) = [V =x]A1 [V =x]A2
[V =x]!=A0::K? = !=[V =x]A0::K?

[V =x]ff = ff
[V =x]!K? = !K?

[V =x]rec = rec

[V =x]ref = ref

[V =x](ff::K) = ff::K

[V =x](x0:A0) = x0:[V =x]A0

[V =x]ffl = ffl
[V =x](\Gamma ; D) = ([V =x]\Gamma ); [V =x]D

Note that because (V # ae)! is not always defined, value substitution is a partial function.
Lemma [Sem] 11.6.9 (Free variables)

1. If V # ae exists, then FTV(V # ae) ` FTV(V ).
2. If V ! exists, then FTV(V !) = FTV(V ).
3. If [V =x]A exists and x 62 FTV(V ) then x 62 FTV([V =x]A).

11.6. VALUE SUBSTITUTION 263

4. If x 62 FTV(A) then [V =x]A = A.

If x is assigned a transparent disconnected semi-canonical type, then substitution of
a value with that type for x in a constructor results in an equal constructor:

Lemma [Sem] 11.6.10 If \Gamma  `\Phi  V : A, A a transparent disconnected constructor, A 2
C\Gamma , and \Gamma ; x:A; \Gamma 0 ` A0 :: K then \Gamma ; x:A; \Gamma 0 ` A0 = [V =x]A0 :: K.

Proof: Proved by structural induction on the derivation of \Gamma ; x:A; \Gamma 0 ` A0 :: K. Example
cases:

C-DSUM: Here \Gamma ; x:A; \Gamma 0 ` \Sigma x0:A1: A2 :: \Omega , x0 6= x and x0 62 FTV(V ), derived via rule CDSUM from \Gamma ; x:A; \Gamma 0; x0:A1 ` A2 :: \Omega  ) \Gamma ; x:A; \Gamma 0 ` A1 :: \Omega  (DECL-T).

Hence, by the induction hypothesis, \Gamma ; x:A; \Gamma 0 ` A1 = [V =x]A1 :: \Omega  and
\Gamma ; x:A; \Gamma 0; x0:A1 ` A2 = [V =x]A2 :: \Omega 
) \Gamma ; x:A; \Gamma 0 ` \Sigma x0:A1: A2 = \Sigma x0:[V =x]A1: [V =x]A2 :: \Omega  (E-DSUM)
) \Gamma ; x:A; \Gamma 0 ` \Sigma x0:A1: A2 = [V =x](\Sigma x0:A1: A2) :: \Omega 

C-EXT-O I: Here \Gamma ; x:A; \Gamma 0 ` xae! :: K derived via rule C-EXT-O from

\Gamma ; x:A; \Gamma 0 ` xae ) !K ?. But, by Lemma 11.5.9, this is impossible so this case
cannot exist.

C-EXT-T I: Here \Gamma ; x:A; \Gamma 0 ` xae! :: K derived via rule C-EXT-O from

\Gamma ; x:A; \Gamma 0 ` xae ) !=A0::K? ) \Gamma ; x:A; \Gamma 0 ` xae! = A0 :: K (E-ABBREV, E-REFL,
Theorem 9.4.4) and \Gamma ; x:A; \Gamma 0 ` (V # ae)! = A0 :: K. (Theorem 11.6.7)
) \Gamma ; x:A; \Gamma 0 ` xae! = (V # ae)! :: K (E-SYM and E-TRAN)
) \Gamma ; x:A; \Gamma 0 ` xae! = [V =x]xae! :: K

2
Extending value substitution to terms with [V =x]x defined to be V is straightforward:

264 CHAPTER 11. SOUNDNESS
Definition [Sem] 11.6.11 (Value substitution on terms)

[V =x]x = V
[V =x]x0 = x0 (x 6= x0)

[V =x]*x:A: M = *x:[V =x]A: [V =x]M (x0 6= x; x0 62 FTV(V ))
[V =x](M 1 M 2) = [V =x]M 1 [V =x]M 2
[V =x](M 1; M 2) = ([V =x]M 1; [V =x]M 2)

[V =x](M :1) = ([V =x]M ):1
[V =x](M :2) = ([V =x]M ):2

[V =x]!A? = ![V =x]A?
[V =x](M !:A) = ([V =x]M )!:[V =x]A

[V =x]l = l

[V =x]roll2(A; M ) = roll2([V =x]A; [V =x]M )

[V =x]unroll1(A) = unroll1([V =x]A)

[V =x]new1(A) = new1([V =x]A)

[V =x]get1(A) = get1([V =x]A)
[V =x]set2(A; M ) = set2([V =x]A; [V =x]M )

The previous result on the existence and validity of value substitution on constructors
(Lemma 11.6.10) can be extended to value substitution on terms:

Theorem [Sem] 11.6.12 Suppose \Gamma  `\Phi  V : A, A a transparent disconnected constructor, A 2 C\Gamma , and \Gamma ; x:A; \Gamma 0 `\Phi  M : A0 then
\Gamma ; x:A; \Gamma 0 `\Phi  [V =x]M : [V =x]A0.

Proof: Proved by structural induction on the derivation of \Gamma ; x:A; \Gamma 0 `\Phi  M : A0. Note
that because of Theorem 11.4.15, Lemma 11.6.10, S-EQ, and SM-SUMP, a proof of
\Gamma ; x:A; \Gamma 0 `\Phi  [V =x]M : A0 is also sufficient. We prove whichever is most convenient from
case to case. Interesting cases:

SM-VAR I: Here \Gamma ; x:A; \Gamma 0 `\Phi  x : [self=x]A0 derived via rule SM-VAR from ` \Phi  valid and

\Gamma ; x:A; \Gamma 0 ` (\Gamma ; x:A; \Gamma 0)(x) = A0 :: \Omega . By Lemma 6.3.5, Lemma 9.4.2, and P-INIT,
(\Gamma ; x:A; \Gamma 0)(x) = A and \Gamma ; x:A; \Gamma 0 ` x ) A ) \Gamma ; x:A; \Gamma 0 ` A ^ A0 (S-EQ).
By P-INIT, Lemma 6.3.5, Theorem 9.4.4, E-REFL, P-MOVE, and Theorem 11.2.10,
\Gamma ; x:A; \Gamma 0 ` [self=x]A0 :: \Omega . By Lemma 6.3.5, Theorem 11.4.15, Theorem 11.4.17,
and Lemma 9.5.5, \Gamma ; x:A; \Gamma 0 `\Phi  V : A and A 2 C\Gamma ;x:A;\Gamma 0. By Theorem 11.3.11

then, \Gamma ; x:A; \Gamma 0 ` [self=x]A ^ [self=x]A0
) \Gamma ; x:A; \Gamma 0 ` A ^ [self=x]A0 (Lemma 11.5.6) ) \Gamma ; x:A; \Gamma 0 `\Phi  V : [self=x]A0 (SMSUMP) ) \Gamma ; x:A; \Gamma 0 `\Phi  [V =x]x : [self=x]A0

11.6. VALUE SUBSTITUTION 265
SM-VAR II: Here \Gamma ; x:A; \Gamma 0 `\Phi  x0 : [self=x0]A0, x 6= x0, derived via rule SM-VAR

) \Gamma ; x:A; \Gamma 0 `\Phi  [V =x]x0 : [self=x0]A0

SM-LAM: Here \Gamma ; x:A; \Gamma 0 `\Phi  *x0:A0: M : \Pi x0:A0: A00, x0 6= x and x0 62 FTV(V ), derived via

rule SM-LAM from \Gamma ; x:A; \Gamma 0; x0:A0 `\Phi  M : A00
) \Gamma ; x:A; \Gamma 0; x0:A0 `\Phi  [V =x]M : [V =x]A00 (induction hypothesis)
) \Gamma ; x:A; \Gamma 0; x0:[V =x]A0 `\Phi  [V =x]M : [V =x]A00 (S-EQ, Theorem 11.4.20, and
Lemma 11.6.10)
) \Gamma ; x:A; \Gamma 0 `\Phi  *x0:[V =x]A0: [V =x]M : \Pi x0:[V =x]A0: [V =x]A00 (SM-LAM)
) \Gamma ; x:A; \Gamma 0 `\Phi  [V =x]*x0:A0: M : [V =x]\Pi x0:A0: A00

SM-REIFY: Here \Gamma ; x:A; \Gamma 0 `\Phi  !A0? : !=A0::K? derived via rule SM-REIFY from ` \Phi  valid

and \Gamma ; x:A; \Gamma 0 ` A0 :: K ) \Gamma ; x:A; \Gamma 0 ` [V =x]A0 :: K (Lemma 11.6.10 and Theorem 9.4.3)
) \Gamma ; x:A; \Gamma 0 `\Phi  ![V =x]A0? : !=[V =x]A0::K? (SM-REIFY)
) \Gamma ; x:A; \Gamma 0 `\Phi  [V =x]!A0? : [V =x]!=A0::K?

SM-SUMP: Here \Gamma ; x:A; \Gamma 0 `\Phi  M : A0 derived via rule SM-SUMP from

\Gamma ; x:A; \Gamma 0 `\Phi  M : A00 and \Gamma ; x:A; \Gamma 0 ` A00 ^ A0
) \Gamma ; x:A; \Gamma 0 ` [V =x]A00 ^ [V =x]A0 (Lemma 11.6.10), E-SYM, S-EQ, S-TRAN) and
\Gamma ; x:A; \Gamma 0 `\Phi  [V =x]M : [V =x]A00 (induction hypothesis)
) \Gamma ; x:A; \Gamma 0 `\Phi  [V =x]M : [V =x]A0 (SM-SUMP)

2
Because all values have minimal types that are transparent disconnected semi-canonical
types, the previous theorem can be strengthened by dropping the requirements on x's
type:

Corollary [Sem] 11.6.13 (Validity of value substitution)

If \Gamma  `\Phi  V : A and \Gamma ; x:A; \Gamma 0 `\Phi  M : A0 then \Gamma ; [V =x]\Gamma 0 `\Phi  [V =x]M : [V =x]A0.

Proof: By Theorem 11.5.10, 9 a type A00 such that \Gamma  ` A00 ^ A, \Gamma  `\Phi  V : A00, A00 2 C\Gamma ,
and A00 is a transparent disconnected constructor. By Theorem 11.4.20,
\Gamma ; x:A00; \Gamma 0 `\Phi  M : A0 ) \Gamma ; x:A00; \Gamma 0 `\Phi  [V =x]M : [V =x]A0
) \Gamma ; x:A00; [V =x]\Gamma 0 `\Phi  [V =x]M : [V =x]A0 (repeated use of Lemma 6.3.5,
Lemma 11.6.10, and Theorem 9.4.6) ) \Gamma ; [V =x]\Gamma 0 `\Phi  [V =x]M : [V =x]A0
(Lemma 11.6.9 and Theorem 11.4.19). 2

266 CHAPTER 11. SOUNDNESS
11.7 Evaluation
In this section I define how evaluation works then prove soundness for the semantic
system. Except where stated otherwise, all constructors, terms, and so on in this section
are drawn from the semantic system.

Analogous to the constructor context notion I introduced in Section 7.7, a notion of
a term context can be introduced:

T erm Contexts C ::= [] j *x:A: C j C M j M C j (C; M ) j (M ; C) j

C:1 j C:2 j C!:A j roll2(A; C) j set2(A; C)

As before, filling a hole in a term context C with a term M (written C[M ]) can incur the
capture of free variables in M that are bound at the occurrence of the hole in C. For
example, (*x:A: [])[x] = *x:A: x. Again as before, I write ETV(C) for the exposed term
variables of a term context. (Since term contexts never bind constructor variables, there
is no need for a notion of exposed constructor variables of a term context.)

Type checking of terms is compositional in the sense that if a term is well typed, then
so are all its constituent terms:

Lemma [(Sem)] 11.7.1 (Decomposition)

Suppose that \Gamma  `\Phi  C[M ] : A such that ETV(C) " dom(\Gamma ) = ;.2 Then there exists \Gamma 0 and
A0 such that:

ffl dom(\Gamma 0) = ETV(C)
ffl \Gamma ; \Gamma 0 `\Phi  M : A0 by a rule other than T/SM-SUMP
ffl If \Gamma ; \Gamma 0 `\Phi ;\Phi 0 M 0 : A0 then \Gamma  `\Phi ;\Phi 0 C[M 0] : A.

Proof: Proved by structural induction on C using Lemma 11.4.13 and Theorem 11.4.18
as needed. 2

Defining an evaluation strategy requires giving both a set of reductions and a way to
determine which potential reduction (if any) to do next. I shall specify which reduction
to do next by defining syntactically a set of redices (R) representing potential reduction
sites and a subset of term contexts, called evaluation contexts (E). I shall prove that
any closed well-typed term M is either a value or can be expressed as E[R] in exactly
one way.

Evaluation of closed well-typed terms using a compatible valid store (i.e., both the
term and the store were typed using the same store type) is then defined as follows: If

2The condition on the exposed variables can always be satisfied by alpha-renaming C[M]
appropriately.

11.7. EVALUATION 267
M is a value, then it evaluates to itself using any store. Otherwise, if M = E[R], then
M evaluates using S to the result of evaluating E[M 0] using store S0 where R reduces
using S to M 0 while yielding the new store S0.

I shall also prove that reductions of well-typed terms produce well-typed terms. When
combined with the result about expressing well-typed terms in terms of values, redices,
and evaluation contexts, this result will show that my evaluation strategy deterministically chooses which, if any, potential reduction to do next and that it never gets "stuck"
in a state where it is trying to evaluate a non-value that has no potential reduction sites.

Definition [Sem] 11.7.2 (Specification of evaluation order)

Redices R ::= (*x:A: M ) V j (V 1; V 2):1 j (V 1; V 2):2 j V !:A j

new1(A) V j get1(A) l j set2(A; l) V j
unroll1(A) (roll2(A0; V ))
Evaluation Contexts E ::= [] j E M j V E j (E; M ) j (V ; E) j

E:1 j E:2 j E!:A j roll2(A; E) j set2(A; E)

The evaluation order specified here is normal call by value with applications and pairs
having their components evaluated from left to right.

It is straightforward to prove that values do not contain potential reduction sites and
that potential reduction sites do not contain potential reduction sites as proper subterms:

Lemma [Sem] 11.7.3 ETV(E) = ;
Lemma [Sem] 11.7.4 V = E[R] is impossible.
Proof: Proved by contradiction using structural induction on V . By inspecting the
definitions of values and redices, we see that no value is a redice so we must have that
E 6= []. By inspecting the definition of evaluation contexts then, it is easily seen that
E[M ] cannot have the forms *x:A: M 0, !A?, l, new1(A), get1(A), or unroll1(A). Thus,
we need worry about values with only the forms (V 1; V 2), roll2(A; V ), and set2(A; l) )
E[R] = E1[E2[R]] where E1 is one of [] V 2, V 1 [], roll2(A; []), or set2(A; []). ) E2[R] = V j
for j 2 f1; 2g. But, this is impossible by the induction hypothesis so we are done. 2

Lemma [Sem] 11.7.5 If R = E[R0] then R = R0 and E = [].
Proof: Inspection of the definition of redices reveals that if R = E[R0], E 6= [], then
9E1; E2: E[R0] = E1[E2[R]] and E2[R0] is a value. By Lemma 11.7.4, it cannot be the
case that E2[R0] is a value so E must equal [] and hence R = R0. 2

The following lemmas relate the minimal type of a function in an application to the
argument and result types of the application:

268 CHAPTER 11. SOUNDNESS
Lemma [Sem] 11.7.6 If \Gamma  `\Phi  M 1 M 2 : A then 9A1; A2: \Gamma  `\Phi  M 1 : A2!A1,
\Gamma  `\Phi  M 2 : A2, and \Gamma  ` A1 ^ A.

Lemma [Sem] 11.7.7 Suppose \Gamma  `\Phi  M 1 M 2 : A.

1. If \Pi x:A01: A02 2 Min\Gamma ;\Phi (M 1) then \Gamma  `\Phi  M 2 : A01.
2. If A01!A02 2 Min\Gamma ;\Phi (M 1) then \Gamma  ` A02 ^ A.
Proof: By Lemma 11.7.6, 9A1; A2: \Gamma  `\Phi  M 1 : A2!A1, \Gamma  `\Phi  M 2 : A2, and \Gamma  ` A1 ^ A
) \Gamma  ` \Pi x:A01: A02 ^ A2!A1 (part one) or \Gamma  ` A01!A02 ^ A2!A1 (part two) (definition
of minimal type) ) \Gamma  ` A2 ^ A01 (Lemma 10.5.1) ) \Gamma  `\Phi  M 2 : A01 (SM-SUMP).

For part two, by Lemma 10.5.1, \Gamma ; x:A2 ` A02 ^ A1 where x 62 FTV(A02) [ FTV(A1)
) \Gamma  ` A02 ^ A1 (Theorem 10.2.4) ) \Gamma  ` A02 ^ A (S-TRAN). 2

By using these results and the results on the properties of values from Section 11.5,
I can prove that well-typed applications of values are always redices:

Lemma [Sem] 11.7.8 If \Gamma  `\Phi  V 1 V 2 : A then V 1 V 2 is a redice.
Proof: By Lemma 11.7.6, 9A1; A2: \Gamma  `\Phi  V 1 : A2!A1 ) V 1 must have one of the forms:
new1(A), get1(A), set2(A; l), unroll1(A), or *x:A0: V 0 (Lemma 11.5.3 and Lemma 11.5.4).
Example cases:

*x:A0: V 0: Here V 1 V 2 = (*x:A0: V 0) V 2, a redice.

get1(A): Here V 1 V 2 = get1(A) V 2. ) \Gamma  `\Phi  V 2 : ref A (Lemma 11.5.2 and

Lemma 11.7.7) ) V 2 is a label (Lemma 11.5.3 and Lemma 11.5.4) ) V 1 V 2 is a
redice.

unroll1(A): Here V 1 V 2 = unroll1(A) V 2. ) \Gamma  `\Phi  V 2 : rec A (Lemma 11.5.2 and Lemma 11.7.7)

) V 2 has form roll2(A0; V 0) (Lemma 11.5.3 and Lemma 11.5.4) ) V 1 V 2 is a redice.

2
I can now prove the desired theorem about expressing closed well-typed terms in
terms of values, redices, and evaluation contexts:

Theorem [Sem] 11.7.9 (Progress)

If ffl `\Phi  M : A then either M is a value or there exists an unique evaluation context E
and an unique redice R such that M = E[R].

11.7. EVALUATION 269
Proof: Proved by structural induction on M . By Lemma 11.7.4, it suffices to show that
if M is not a value then 9 an unique E and an unique R such that M = E[R]. Since
Lemma 11.7.5 handles the cases where M is a redice, we need only handle here the cases
where M is not a redice. Example remaining cases:

VAR: Here M = x ) ffl `\Phi  x : A which is impossible so this case cannot occur.

FST: Here M = M 0:1, M 0 not a value. By Lemma 11.7.1 and the induction hypothesis then, 9 an unique evaluation context E0 and an unique redice R0 such that
M 0 = E0[R0] ) M can only be constructed from the evaluation context, redice pair
(E0:1)[R0].

PAIR I: Here M = (M 1; M 2), M 1 not a value. By Lemma 11.7.1 and the induction hypothesis, 9 an unique evaluation context E0 and an unique redice R0 such that
M 1 = E0[R0] ) M can only be constructed from the evaluation context, redice
pair ((E0; M 2))[R0].

PAIR II: Here M = (V ; M 0), M 0 not a value. By Lemma 11.7.1 and the induction hypothesis,

9 an unique evaluation context E0 and an unique redice R0 such that M 0 = E0[R0]
) M can only be constructed from the evaluation context, redice pair ((V ; E0))[R0]
(Lemma 11.7.4).

APP I: Here M = M 1 M 2, M 1 not a value. By Lemma 11.7.1 and the induction hypothesis,

9 an unique evaluation context E0 and an unique redice R0 such that M 1 = E0[R0]
) M can only be constructed from the evaluation context, redice pair (E0 M 2)[R0].

APP II: Here M = V M 0, M 0 not a value. By Lemma 11.7.1 and the induction hypothesis,

9 an unique evaluation context E0 and an unique redice R0 such that M 0 = E0[R0]
) M can only be constructed from the evaluation context, redice pair (V E0)[R0]
(Lemma 11.7.4).

APP III: Here M = V 1 V 2, M not a redice. But, this is impossible by Lemma 11.7.8, so this

case cannot happen.

2
The set of reductions for the semantic system follow. Note that the reductions are
defined to act on term, store pairs in order to allow reductions to have side effects on the
store.

270 CHAPTER 11. SOUNDNESS
Definition [Sem] 11.7.10 (Reduction on terms)

E[(*x:A: M ) V ]; S ,! E[[V =x]M ]; S

E[(V 1; V 2):1]; S ,! E[V 1]; S
E[(V 1; V 2):2]; S ,! E[V 2]; S

E[V !:A]; S ,! E[V ]; S

E[unroll1(A) (roll2(A0; V ))]; S ,! E[V ]; S

E[new1(A) V ]; S ,! E[l]; (S; l=V ) (l 62 dom(S))

E[get1(A) l]; S ,! E[S(l)]; S
E[set2(A; l) V ]; S ,! E[V ]; [l = V ]S

The first reduction rule handles the application of user defined functions via value substitution. The second and third rules handle selecting from a pair in the standard manner.
The fourth rule handles coercions by dropping them. Because of the implicit subsumption
rule (SM-SUMP), this action can leave the term's type unchanged.

The fifth rule handles the unroll1(A) function which strips off a roll2(A0; \Gamma ) from
its argument. The remaining three rules handle the primitives dealing with references:
new1(A) extends the store with a new location set to its argument then returns the new
location, get1(A) returns the value of the location specified by its argument in the store,
and set2(A; l) sets the location l in the store to its argument then returns its argument.
The last reduction rule uses the following function to change the store:

Definition [Sem] 11.7.11 (Setting stores)

[l = V ]ffl = ffl
[l = V ](S; l=V 0) = ([l = V ]S); l=V
[l = V ](S; l0=V 0) = ([l = V ]S); l0=V 0 (l0 6= l)

Because I shall show that evaluation chooses which reduction to do next deterministically, these rules mean that evaluation is completely deterministic aside from the choice
of which new location name to use when extending the store. Because evaluation and
typing only compare location identity, this indeterminism cannot otherwise effect the
outcome of evaluation. If a completely deterministic evaluation function was desired,
a notion of equivalence on terms modulo location-name conversion could be defined, or
alternatively, locations could be allocated in some predefined deterministic manner.

Proving that extending and changing stores preserves the well-typedness of the store
is straightforward:

Lemma [Sem] 11.7.12 If ` S : \Phi , ffl `\Phi  V : A, and l 62 dom(S) then
` S; l=V : \Phi ; l:A.

11.7. EVALUATION 271
Proof: Inspection of the definition of (\Phi ; l:A)(l0) shows that it equals A if l0 = l and
\Phi (l0) otherwise. By Lemma 11.4.14, dom(S) = dom(\Phi ) ) l 62 dom(\Phi ). Hence, inspection of the definition of (\Phi ; l:A)(l0) shows that it equals A if l0 = l and \Phi (l0) otherwise. By
STORE, ` \Phi  valid, jSj = j\Phi j, and 8l 2 dom(\Phi ): ffl `\Phi  S(l) : \Phi (l) ) jS; l=V j = j\Phi ; l:Aj,
` \Phi ; l:A valid (Theorem 11.4.15 and ST-EXTEND), and 8l 2 dom(\Phi ; l:A):
ffl `\Phi  (S; l=V )(l0) : (\Phi ; l:A)(l0) ) 8l 2 dom(\Phi ; l:A):
ffl `\Phi ;l:A (S; l=V )(l0) : (\Phi ; l:A)(l0) (Theorem 11.4.18) ) ` S; l=V : \Phi ; l:A

(STORE). 2

Lemma [Sem] 11.7.13 If ` S : \Phi  and ffl `\Phi  V : \Phi (l) then ` [l = V ]S : \Phi .
Proof: Inspection of the definition of [l = V ]S shows that j[l = V ]Sj = jSj and for
l0 2 dom(S), ([l = V ]S)(l0) = V if l0 = l and S(l0) otherwise. By STORE, ` \Phi  valid,
jSj = j\Phi j, and 8l 2 dom(\Phi ): ffl `\Phi  S(l) : \Phi (l) ) 8l 2 dom(\Phi ): ffl `\Phi  ([l = V ]S)(l) : \Phi (l)
) ` [l = V ]S : \Phi  (STORE). 2

The crucial theorem that reduction preserves well-typedness is then as follows:
Theorem [Sem] 11.7.14 (Subject reduction)

Suppose ffl `\Phi  E[R] : A and ` S : \Phi . Then 9M 0; S0; \Phi 0 such that:

1. E[R]; S ,! E[M 0]; S0
2. ` S0 : \Phi ; \Phi 0
3. ffl `\Phi ;\Phi 0 E[M 0] : A

Proof: By Lemma 11.7.1 and Lemma 11.7.3, 9A0: ffl `\Phi  R : A0 by a rule other than SMSUMP and if ffl `\Phi ;\Phi 0 M 0 : A0 then ffl `\Phi ;\Phi 0 E[M 0] : A. ) FTV(A0) = ; (Lemma 11.4.16).
Casing on R:

fi: Here R = (*x:A1: M ) V . ) 9A2: ffl `\Phi  *x:A1: M : A2!A0 and ffl `\Phi  V : A2 (SMAPP) ) 9A00: ffl `\Phi  *x:A1: M : \Pi x:A1: A00 by a rule other than SM-SUMP and
ffl ` \Pi x:A1: A00 ^ A2!A0 (inspection of typing rules)
) ffl; x:A1 `\Phi  M : A00 (SM-LAM), ffl ` A2 ^ A1 and ffl; x:A2 ` A00 ^ A0
(Lemma 10.5.1) ) ffl; x:A2 `\Phi  M : A00 (Theorem 11.4.20)
) ffl; x:A2 `\Phi  M : A0 (SM-SUMP) ) ffl `\Phi  [V =x]M : [V =x]A0
(Corollary 11.6.13) ) ffl `\Phi  [V =x]M : A0 (Lemma 11.6.9). Thus, it suffices to let
M 0 = [V =x]M, S0 = S, and \Phi 0 = ffl.

272 CHAPTER 11. SOUNDNESS

Fst: Here R = (V 1; V 2):1. ) 9x; A2: ffl `\Phi  (V 1; V 2) : \Sigma x:A0: A2 (SM-FST) ) 9A01; A02:

ffl `\Phi  (V 1; V 2) : (A01; A02) by a rule other than SM-SUMP and ffl ` (A01; A02) ^ \Sigma x:A0: A2
(inspection of typing rules) ) ffl `\Phi  V 1 : A01 (SM-PAIR) and ffl ` A01 ^ A0
(Lemma 10.5.1) ) ffl `\Phi  V 1 : A0 (SM-SUMP) Thus, it suffices to let M 0 = V 1,
S0 = S, and \Phi 0 = ffl.

Snd: Here R = (V 1; V 2):2. ) 9A1: ffl `\Phi  (V 1; V 2) : (A1; A0) (SM-SND) ) 9A01; A02:

ffl `\Phi  (V 1; V 2) : (A01; A02) by a rule other than SM-SUMP and
ffl ` (A01; A02) ^ (A1; A0) (inspection of typing rules) ) ffl `\Phi  V 2 : A02 (SM-PAIR) and
ffl; x:A01 ` A02 ^ A0 where x 62 FTV(A02) [ FTV(A0) (Lemma 10.5.1) ) ffl ` A02 ^ A0
(Theorem 10.2.4) ) ffl `\Phi  V 2 : A0 (SM-SUMP) Thus, it suffices to let M 0 = V 2,
S0 = S, and \Phi 0 = ffl.

Coerce: Here R = V !:A0 ) ffl `\Phi  V : A0 (SM-COERCE) ) ffl `\Phi  E[V ] : A. Thus, it suffices

to let M 0 = V , S0 = S, and \Phi 0 = ffl.

New: Here R = new1(A1) V . By Lemmas 11.7.6, 11.5.2, and 11.7.7, ffl `\Phi  V : A1 and

ffl ` ref A1 ^ A0. Let M 0 = l, S0 = S; l=V , and \Phi 0 = ffl; l:A1 where l 62 dom(S). )
` S0 : \Phi ; \Phi 0 (Lemma 11.7.12) ) ffl `\Phi ;\Phi 0 l : ref ((\Phi ; \Phi 0)(l)) (SM-LABEL, EMPTY,

and STORE) ) ffl `\Phi ;\Phi 0 l : ref A1 (STORE and Lemma 11.4.14) ) ffl `\Phi ;\Phi 0 l : A0
(SM-SUMP)

Get: Here R = get1(A1) l. By Lemmas 11.7.6, 11.5.2, and 11.7.7, ffl `\Phi  l : ref A1 and

ffl ` A1 ^ A0 ) 9A01: ffl `\Phi  l : ref A01 via a rule other than SM-SUMP and
ffl ` ref A01 ^ ref A1 (inspection of typing rules) ) A01 = \Phi (l) (SM-LABEL) and
ffl ` ref A01 = ref A1 :: \Omega  (Lemma 10.2.2, E-REFL, and Corollary 10.3.14)
) ffl `\Phi  S(l) : A01 (STORE) and ffl ` A01 = A1 :: \Omega  (Lemma 9.4.10) ) ffl `\Phi  S(l) : A0
(S-EQ, S-TRAN, and SM-SUMP) Thus, it suffices to let M 0 = S(l), S0 = S, and
\Phi 0 = ffl.

Set: Here R = set2(A1; l) V . ) ffl `\Phi  l : ref A1 (SM-SET) ) 9A01: ffl `\Phi  l : ref A01 via

a rule other than SM-SUMP and ffl ` ref A01 ^ ref A1 (inspection of typing rules)
) A01 = \Phi (l) (SM-LABEL) and ffl ` ref A01 = ref A1 :: \Omega  (Lemma 10.2.2, E-REFL,
and Corollary 10.3.14) ) ffl ` \Phi (l) = A1 :: \Omega  (Lemma 9.4.10). By Lemmas 11.7.6,
11.5.2, and 11.7.7, ffl `\Phi  V : A1 and ffl ` A1 ^ A0 ) ffl `\Phi  V : A0 (SM-SUMP) and
ffl `\Phi  V : \Phi (l) (E-SYM, S-EQ, and E-TRAN) ) ` [l = V ]S : \Phi  (Lemma 11.7.13).
Thus, it suffices to let M 0 = V , S0 = [l = V ]S, and \Phi 0 = ffl.

Unroll: Here R = unroll1(A1) (roll2(A2; V )). By Lemmas 11.7.6, 11.5.2, and 11.7.7,

ffl `\Phi  roll2(A2; V ) : rec A1 and ffl ` A1 (rec A1) ^ A0
) ffl `\Phi  roll2(A2; V ) : rec A2 via a rule other than SM-SUMP and

11.7. EVALUATION 273

ffl ` rec A2 ^ rec A1 (inspection of typing rules) ) ffl `\Phi  V : A2 (rec A2) (SM-ROLL)
and ffl ` rec A2 = rec A1 :: \Omega  (Lemma 10.2.2, E-REFL, and Corollary 10.3.14) )
ffl ` A2 = A1 :: \Omega )\Omega  (Lemma 9.4.10).
) ffl ` A2 (rec A2) ^ A1 (rec A1) (C-REC, E-REFL, E-APP, and S-EQ)
) ffl `\Phi  V : A1 (rec A1) (SM-SUMP) ) ffl `\Phi  V : A0 (SM-SUMP). Thus, it suffices
to let M 0 = V , S0 = S, and \Phi 0 = ffl.

2

Thus, I have given a definition of evaluation for the semantic system that is welldefined, deterministic (modulo exact location names), and for which the semantic type
system is sound:

Corollary [Sem] 11.7.15 (Soundness)
Suppose ffl `\Phi  M : A and ` S : \Phi . Then:

1. If M is a value then M evaluates using S only to M .
2. If M is not a value then 9M 0; S0; \Phi 0 such that:

ffl M ; S ,! M 0; S0
ffl If M ; S ,! M 00; S00 then M 0 = M 00 and S0 = S00 (modulo the choice of exact

location names)

ffl ` S0 : \Phi ; \Phi 0 and ffl `\Phi ;\Phi 0 M 0 : A

Proof: Follows from Theorems 11.7.9 and 11.7.14 and the definition of the reduction
rules. 2

274 CHAPTER 11. SOUNDNESS
Chapter 12
Type Checking
In this chapter I consider the problem of type checking the kernel system. After discussing
the difficulties with directly type checking the kernel system, I introduce a more restrictive
type system and show that type checking for it is semi-decidable; in the presence of an
oracle for subtyping, I show that type checking for it is decidable.

12.1 Type-Checking Difficulties
There are three difficulties with type checking the kernel system. The first difficulty is
the question of how to handle the T-VAR rule, which is not syntax directed: The type
checker must decide what type to apply the self function to. By Corollary 11.3.12, it
is always safe to choose a semi-canonical type equal to the variable in question's type:
Any other typing can be obtained from this one by the use of the T-SUMP rule. By
Theorem 9.5.10, such a type is recursively computable. Thus, this difficulty is not a
problem in practice.

The second difficulty is caused by the presence of the T-SUMP rule. Because the
T-SUMP rule allows introducing subtyping anywhere, the type checker must be able
to solve systems of inequalities rather than the usual systems of equalities handled by
unification. Solving such systems is likely to be hard, especially given that even checking
for subtyping between known types is undecidable.

Even worse is the third difficulty: The system does not possess minimal or "principle" types. In particular, the T-APP rule would require computing the minimal
supertype of a given type that is x free (because of the non-dependent type restriction). For example, suppose \Gamma  ` M 2 : A1 and \Gamma  ` *x:A1: (M !:A2) : \Pi x:A1: A2. Then
\Gamma  ` (*x:A1: (M !:A2)) (M 2!:A1) : A iff \Gamma ; x:A1 ` A2 ^ A and x 62 FTV(A).

Such types do not exist in general, however. For example, \Pi x0:!\Omega )\Omega ?: !=x0! (x)::\Omega ?
has two x-free supertypes, \Pi x0:!\Omega )\Omega ?: !\Omega ? and

275

276 CHAPTER 12. TYPE CHECKING
\Pi x0:!=*ff::\Omega : !\Omega ?::\Omega )\Omega ?: !=!\Omega ?::\Omega ?, which are incomparable with each other.
Hence, the kernel system in general does not possess minimal types.

Because of these difficulties, the problem of constructing a type checking procedure
for the full kernel system is very hard. However, as I shall show shortly, by restricting
the type system slightly, a reasonable type checking procedure can be obtained without
losing any of the benefits of the translucent sum approach. Accordingly, I have chosen
to leave the problem of typing checking the full kernel system to future work.

12.2 The Inference System
In this section I introduce the inference system, which is identical to the kernel system
except for having a more restrictive type system. The major restriction is implemented
by the replacement of the T-SUMP and T-COERCE rules by the new rules I-UN and
I-COERCE respectively:

Definition [Inf ] 12.2.1 (Replacement rules I)

\Gamma  ` M : A0 \Gamma  ` A0 = A :: \Omega 

\Gamma  ` M : A (I-UN)

\Gamma  ` M : A0 \Gamma  ` A0 ^ A

\Gamma  ` M !:A : A (I-COERCE)

These rules specify that equality may be used anywhere (I-UN) but subtyping (subsumption) may be used only where and how specified by the programmer (I-COERCE). This
restriction removes the need to handle systems of inequalities.

The inference system is not quite as restrictive as implied by the above rules: there
is one point where enough information exists to make it possible for the type checker
to automatically insert an explicit coercion. This point is at function application time:
because we will have minimal types (in the inference system) for the function and its
argument, we can insert an explicit coercion that specializes the function's type so that
it operates on arguments of the actual argument type. For example, if f has minimal
type \Pi x:A1: A2 and M has minimal type A01, then we can insert an explicit coercion into
the application f M to get (f !:\Pi x:A01: A2) M .

This idea is incorporated into the new I-APP rule below which replaces the old TAPP rule. The new I-VAR rule (also below), which replaces the old T-VAR rule, handles
the difficulty with type checking term variables as described in the previous section. The
CAN function used in the I-VAR rule is used to compute semi-canonical types; it is
defined in the next section (See Lemma 12.3.1).

12.2. THE INFERENCE SYSTEM 277
Definition [Inf ] 12.2.2 (Replacement rules II)

\Gamma  ` M 1 : \Pi x:A0: A1 \Gamma  ` M 2 : A2
\Gamma  ` A2 ^ A0 \Gamma  ` \Pi x:A2: A1 = A2!A :: \Omega 

\Gamma  ` M 1 M 2 : A (I-APP)

` \Gamma  valid x 2 dom(\Gamma )
\Gamma  ` x : [self=x]CAN (\Gamma ; \Gamma (x)) (I-VAR)

These four rule replacements are the only differences between the kernel and inference
systems.

Because the inference system's type system is a restriction of the kernel system's type
system, all well-typed inference system terms are also well-typed in the kernel system:

Lemma [Inf ] 12.2.3 If \Gamma  ` M : A in the inference system then \Gamma  ` M : A in the kernel
system.

Proof: Proved by structural induction on derivation of \Gamma  ` M : A in the inference
system. Interesting cases:

I-VAR: Here, \Gamma  ` x : [self=x]CAN (\Gamma ; \Gamma (x)) derived via rule I-VAR from ` \Gamma  valid and x 2

dom(\Gamma ) ) \Gamma  ` \Gamma (x) :: \Omega  (Lemma 9.4.2) ) CAN (\Gamma ; \Gamma (x)) exists, CAN (\Gamma ; \Gamma (x)) 2
C\Gamma , and \Gamma  ` \Gamma (x) = CAN (\Gamma ; \Gamma (x)) :: \Omega  (Lemma 12.3.1)
) \Gamma  ` x : [self=x]CAN (\Gamma ; \Gamma (x)) in the kernel system (T-VAR).

I-APP: Here, \Gamma  ` M 1 M 2 : A derived via rule I-APP from \Gamma  ` M 1 : \Pi x:A0: A1, \Gamma  ` M 2 : A2,

\Gamma  ` A2 ^ A0, and \Gamma  ` \Pi x:A2: A1 = A2!A :: \Omega  ) \Gamma  ` M 1 : \Pi x:A0: A1 and \Gamma  ` M 2 : A2
in the kernel system (induction hypothesis) and \Gamma  ` \Pi x:A0: A1 ^ \Pi x:A2: A1
(Lemma 10.5.2) ) \Gamma  ` M 1 : A2!A in the kernel system (T-SUMP and S-EQ)
) \Gamma  ` M 1 M 2 : A in the kernel system (T-APP).

2

Note that because of this fact, the inference type system is also sound for the kernelsystem semantics of Chapter 11.

The reverse result does not hold: there are well-typed kernel system terms that cannot
be typed under the inference system. However, all such terms can be typed under the
inference system if we insert explicit coercions where T-SUMP and T-VAR were used in
the kernel system derivation:

Lemma 12.2.4 If \Gamma  ` M : A in the kernel system then 9M 0 such that M and M 0 are
the same if explicit coercions are removed and \Gamma  ` M 0 : A holds in the inference system.

278 CHAPTER 12. TYPE CHECKING
Proof: Proved by structural induction on derivation of \Gamma  ` M : A in the kernel system.
Interesting cases:

T-SUMP: Here \Gamma  ` M : A derived via rule T-SUMP from \Gamma  ` M : A0 and \Gamma  ` A0 ^ A ) 9M 00:

M and M 00 are the same if explicit coercions are removed and \Gamma  ` M 00 : A0 in the
inference system (induction hypothesis) ) \Gamma  ` M 00!:A : A in the inference system
(I-COERCE). Hence, let M 0 = M 00!:A and we are done.

T-VAR: Here, \Gamma  ` x : [self=x]A, where \Gamma  = \Gamma 1; x:A0; \Gamma 2, x 62 dom(\Gamma 1), derived via rule TVAR from \Gamma  ` A0 = A :: \Omega 
) ` \Gamma  valid and \Gamma 1 ` A0 :: \Omega  (Lemma 6.3.5 and DECL-T), \Gamma  ` A0 :: \Omega  (Lemma 6.3.5
and Lemma 9.4.2), and \Gamma  ` [self=x]A :: \Omega  (Theorem 11.4.15)
) CAN (\Gamma 1; A0) exists, CAN (\Gamma 1; A0) 2 C\Gamma 

1, \Gamma 1 ` A0 = CAN (\Gamma 1; A0) :: \Omega ,CAN (\Gamma ; A

0) exists, CAN (\Gamma ; A0) 2 C\Gamma , and \Gamma  ` A0 = CAN (\Gamma ; A0) :: \Omega  (Lemma 12.3.1)

) ` \Gamma 1; x:CAN (\Gamma 1; A0); \Gamma 2 valid, \Gamma 1; x:CAN (\Gamma 1; A0); \Gamma 2 ` [self=x]A :: \Omega , and

\Gamma 1; x:CAN (\Gamma 1; A0); \Gamma 2 ` A0 = A :: \Omega  (Theorem 9.4.6) and CAN (\Gamma 1; A0) 2 C\Gamma 
(Lemma 9.5.5) ) \Gamma 1; x:CAN (\Gamma 1; A0); \Gamma 2 ` A0 = CAN (\Gamma 1; A0) :: \Omega  (Theorem 9.4.1)
) \Gamma 1; x:CAN (\Gamma 1; A0); \Gamma 2 ` CAN (\Gamma 1; A0) ^ A (E-SYM, E-TRAN, and S-EQ) )
\Gamma 1; x:CAN (\Gamma 1; A0); \Gamma 2 ` [self=x]CAN (\Gamma 1; A0) ^ [self=x]A
(Corollary 11.3.12) ) \Gamma  ` [self=x]CAN (\Gamma 1; A0) ^ [self=x]A
(Lemma 10.2.5).

By Theorem 9.4.6, E-SYM, and E-TRAN,
\Gamma  ` CAN (\Gamma 1; A0) = CAN (\Gamma ; A0) :: \Omega  ) CAN (\Gamma 1; A0) = CAN (\Gamma ; A0)
(Lemma 9.5.12) ) \Gamma  ` [self=x]CAN (\Gamma ; A0) ^ [self=x]A.

By I-VAR, \Gamma  ` x : [self=x]CAN (\Gamma ; A0) in the inference system
) \Gamma  ` (x!:[self=x]A) : [self=x]A in the inference system (I-COERCE).

2

Thus, type checking the full kernel system can be viewed as doing type inference to determine how and where to add explicit coercions so that the terms type check in the more
explicit inference system. I have chosen to treat the less explicit kernel system as the
primary system rather than the inference system because of the kernel system's greater elegance and superior properties modulo deciding type checking (e.g., the inference system
does not possess a replacement by a subtype property at the term level).

The requirement that the programmer specify where subsumption should be used
with the exception of specializing function argument types is not likely to be too burdensome. Except when taking advantage of translucent sum abilities (e.g., to get data
abstraction), such specifications are not needed. Normal computation, including polymorphic abstraction and instantiation, does not require extra specifications, thanks to

12.2. THE INFERENCE SYSTEM 279
the I-VAR rule. (Under the I-VAR rule, any application with an argument that has a
transparent semi-canonical type does not require any extra subsumptions to type check;
the only way to get a term that does not have such a type is to use an explicit coercion
to make things opaque.)

Because of the restrictions made, the inference system, unlike the kernel system,
possesses principle types. In particular, all the types possessed by a given term under \Gamma 
are equal under \Gamma :

Corollary [Inf ] 12.2.5 (Validity of Term Types)

If \Gamma  ` M : A then \Gamma  ` A :: \Omega .

Proof: Follows immediately from Lemma 12.2.3 and Theorem 11.4.15. 2

Theorem [Inf ] 12.2.6 (Existence of principle types)

If \Gamma  ` M : A1 and \Gamma  ` M : A2 then \Gamma  ` A1 = A2 :: \Omega .

Proof: Proved by structural induction on M . WLOG, \Gamma  ` M : A1 and
\Gamma  ` M : A2 were derived using rules other than I-UN (E-REFL). By Corollary 12.2.5,
\Gamma  ` A1 :: \Omega  ) \Gamma  ` A1 = A1 :: \Omega  (E-REFL). That takes care of the cases where A1 = A2.
The interesting remaining cases are:

SND: Here M = M 0:2, \Gamma  ` M 0 : (A01; A1), and \Gamma  ` M 0 : (A02; A2)

) \Gamma  ` (A01; A1) = (A02; A2) :: \Omega  (induction hypothesis)
) \Gamma ; x:A01 ` A1 = A2 :: \Omega , x 62 dom(\Gamma ) [ FTV(A1) [ FTV(A2) (Lemma 9.4.10)
) \Gamma  ` A1 = A2 :: \Omega  (Theorem 9.6.1).

APP: Here M = M 1 M 2, \Gamma  ` M 1 : \Pi x:A00: A01, \Gamma  ` M 2 : A02, \Gamma  ` A02 ^ A00,

\Gamma  ` \Pi x:A02: A01 = A02!A1 :: \Omega , \Gamma  ` M 1 : \Pi x:A000: A001, \Gamma  ` M 2 : A002,
\Gamma  ` A002 ^ A000, and \Gamma  ` \Pi x:A002: A001 = A002!A2 :: \Omega  where x 62 dom(\Gamma ) [ FTV(A1) [
FTV(A2) ) \Gamma  ` \Pi x:A00: A01 = \Pi x:A000: A001 :: \Omega , \Gamma  ` A02 = A002 :: \Omega  (induction hypothesis), \Gamma ; x:A02 ` A01 = A1 :: \Omega  and \Gamma ; x:A002 ` A001 = A2 :: \Omega  (Lemma 9.4.10)
) \Gamma ; x:A00 ` A01 = A001 :: \Omega  (Lemma 9.4.10) and
\Gamma ; x:A02 ` A001 = A2 :: \Omega  (Theorem 9.4.6) ) \Gamma ; x:A02 ` A01 = A001 :: \Omega  (Theorem 10.4.7)
) \Gamma ; x:A02 ` A1 = A2 :: \Omega  (E-SYM and E-TRAN)
) \Gamma  ` A1 = A2 :: \Omega  (Theorem 9.6.1).

2

This result means that the type checker can deal with equivalence classes of equal types
rather than individual types; there is no need to determine in advance which representative of the current class to use.

280 CHAPTER 12. TYPE CHECKING
V ALID(\Gamma ) = if ` \Gamma  valid then return else raise fail
KIN D(\Gamma ; A) = if 9K: \Gamma  ` A :: K then return(K) else raise fail
EQU AL(\Gamma ; A1; A2; K) = if \Gamma  ` A1 = A2 :: K then return else raise fail
SU B(\Gamma ; A1; A2) = if \Gamma  ` A1 ^ A2 then return else raise fail or hang

CAN (\Gamma ; A) = If \Gamma  ` A :: \Omega  then

return(A0) such that A0 2 C\Gamma  and \Gamma  ` A = A0 :: \Omega 
else

raise fail

Figure 12.1: Auxiliary procedures for type checking
12.3 Semi-Decidability
In this section I give a procedure that decides the well-typed term judgment for the inference system and show that it is semi-decidable (decidable given an oracle for subtyping).
First, I will need some auxiliary procedures:

Lemma 12.3.1 (Existence of auxiliary procedures)

Procedures exist which have the behavior specified in Figure 12.1. VALID, KIND,
EQUAL, and CAN are algorithms while SUB may fail to return only in the negative
case.

Proof: Follows from Theorem 9.4.11, Corollary 9.4.12, Theorem 10.5.6, and Theorem 9.5.10. 2

The decision procedure is given in Figure 12.2. T Y P E(\Gamma ; M ) computes a valid type
for M under \Gamma  unless M is not a well-typed term under \Gamma , in which case it fails. T Y P E
uses CAN when it is necessary to find an equivalence-class representative having a certain
form. (This method works because semi-canonical types are maximally defined and
have the minimal number of dependencies.) The proof of the correctness of the T Y P E
procedure is straightforward:

Lemma [Inf ] 12.3.2 If T Y P E(\Gamma ; M ) returns A then \Gamma  ` M : A.

12.3. SEMI-DECIDABILITY 281
T Y P E(\Gamma ; M ) = V ALID(\Gamma );

case M of
x: if x 2 dom(\Gamma ) then

return([self=x]CAN (\Gamma ; \Gamma (x)))
else

raise fail
*x:A: M , x 62 dom(\Gamma ): return(\Pi x:A: T Y P E((\Gamma ; x:A); M ))

M 1 M 2: case CAN (\Gamma ; T Y P E(\Gamma ; M 1)) of

\Pi x:A0: A1: SU B(\Gamma ; T Y P E(\Gamma ; M 2); A0);

case CAN (\Gamma ; \Pi x:T Y P E(\Gamma ; M 2): A1) of

A!A0: return(A0)
(M 1; M 2): return((T Y P E(\Gamma ; M 1); T Y P E(\Gamma ; M 2)))

M :1: case CAN (\Gamma ; T Y P E(\Gamma ; M )) of

\Sigma x:A: A0: return(A)
M :2: case CAN (\Gamma ; T Y P E(\Gamma ; M )) of

(A; A0): return(A0)
!A?: !=A::KIN D(\Gamma ; A)?
M !:A: SU B(\Gamma ; T Y P E(\Gamma ; M ); A);

return(A)
new: return(8ff::\Omega :ff!ref ff)

get: return(8ff::\Omega :ref ff!ff)

set: return(8ff::\Omega :ref ff!(ff!ff))
roll: return(8ff::\Omega )\Omega :ff (rec ff)!rec ff)
unroll: return(8ff::\Omega )\Omega :rec ff!ff (rec ff))

T ERM (\Gamma ; M ; A) = EQU AL(\Gamma ; T Y P E(\Gamma ; M ); A; \Omega )

Figure 12.2: Decision procedure for type checking

282 CHAPTER 12. TYPE CHECKING
Proof: Proved by structural induction on M . By inspection of the code for T Y P E,
T Y P E(\Gamma ; M ) returns ) V ALID(\Gamma ) returns ) ` \Gamma  valid (Lemma 12.3.1). Example
cases:

new: Here T Y P E(\Gamma ; new) returns 8ff::\Omega :ff!ref ff. By T-NEW,

\Gamma  ` new : 8ff::\Omega :ff!ref ff.

!A?: Here T Y P E(\Gamma ; !A?) returns !=A::KIN D(\Gamma ; A)? ) KIN D(\Gamma ; A) returns )

\Gamma  ` A :: KIN D(\Gamma ; A) (Lemma 12.3.1)
) \Gamma  ` !A? : !=A::KIN D(\Gamma ; A)? (T-REIFY).

M !:A: Here T Y P E(\Gamma ; M !:A) returns A and SU B(\Gamma ; T Y P E(\Gamma ; M ); A) returns

) T Y P E(\Gamma ; M ) returns and \Gamma  ` T Y P E(\Gamma ; M ) ^ A (Lemma 12.3.1)
) \Gamma  ` M : T Y P E(\Gamma ; M ) (induction hypothesis) ) \Gamma  ` M !:A : A (I-COERCE).

M 1 M 2: Here T Y P E(\Gamma ; M 1 M 2) returns A0 where 9x0; A0; A1:

CAN (\Gamma ; T Y P E(\Gamma ; M 1)) = \Pi x:A0: A1, SU B(\Gamma ; T Y P E(\Gamma ; M 2); A0) returns,
CAN (\Gamma ; \Pi x:T Y P E(\Gamma ; M 2): A1) = A!A0, and x 62 dom(\Gamma ) [ FTV(A0)

) \Gamma  ` T Y P E(\Gamma ; M 2) ^ A0, \Gamma  ` T Y P E(\Gamma ; M 1) = \Pi x:A0: A1 :: \Omega ,
\Gamma  ` \Pi x:T Y P E(\Gamma ; M 2): A1 = A!A0 :: \Omega  (Lemma 12.3.1), T Y P E(\Gamma ; M 1) returns,
and T Y P E(\Gamma ; M 2) returns

) \Gamma  ` M 1 : T Y P E(\Gamma ; M 1), \Gamma  ` M 2 : T Y P E(\Gamma ; M 2) (induction hypothesis),
\Gamma  ` T Y P E(\Gamma ; M 2) = A :: \Omega , and \Gamma ; x:T Y P E(\Gamma ; M 2) ` A1 = A0 :: \Omega  (Lemma 9.4.10)
) \Gamma  ` M 1 : \Pi x:A0: A1 (I-UN) and
\Gamma  ` \Pi x:T Y P E(\Gamma ; M 2): A1 = T Y P E(\Gamma ; M 2)!A0 :: \Omega  (Theorem 9.4.3, E-REFL, and
E-DFUN) ) \Gamma  ` M 1 M 2 : A0 (I-APP).

2

Lemma [Inf ] 12.3.3 If \Gamma  ` M : A then T Y P E(\Gamma ; M ) returns.
Proof: Proved by structural induction on \Gamma  ` M : A. By Corollary 12.2.5, \Gamma  ` A :: \Omega 
) ` \Gamma  valid (Lemma 6.3.5) ) V ALID(\Gamma ) returns (Lemma 12.3.1). Example cases:

I-VAR: Here \Gamma  ` x : [self=x]CAN (\Gamma ; \Gamma (x)) derived via rule I-VAR from ` \Gamma  valid and x 2

dom(\Gamma ) ) T Y P E(\Gamma ; x) returns.

T-REIFY: Here \Gamma  ` !A? : !=A::K ? derived via rule T-REIFY from \Gamma  ` A :: K ) KIN D(\Gamma ; A)

returns K (Lemma 12.3.1) ) T Y P E(\Gamma ; !A?) returns (inspection of TYPE code).

12.3. SEMI-DECIDABILITY 283
I-COERCE: Here \Gamma  ` M !:A : A derived via rule I-COERCE from \Gamma  ` M : A0 and \Gamma  ` A0 ^ A

) T Y P E(\Gamma ; M ) returns (induction hypothesis)
) \Gamma  ` M : T Y P E(\Gamma ; M ) (Lemma 12.3.2) ) \Gamma  ` T Y P E(\Gamma ; M ) = A0 :: \Omega  (Theorem 12.2.6) ) \Gamma  ` T Y P E(\Gamma ; M ) ^ A (S-EQ and S-TRAN)
) SU B(\Gamma ; T Y P E(\Gamma ; M ); A) returns (Lemma 12.3.1) ) T Y P E(\Gamma ; M !:A) returns
(inspection of TYPE code).

I-SND: Here \Gamma  ` M :2 : A2 derived via rule T-SND from \Gamma  ` M : (A1; A2)

) T Y P E(\Gamma ; M ) returns (induction hypothesis) ) \Gamma  ` M : T Y P E(\Gamma ; M )
(Lemma 12.3.2) ) \Gamma  ` T Y P E(\Gamma ; M ) :: \Omega  (Corollary 12.2.5) and
\Gamma  ` T Y P E(\Gamma ; M ) = (A1; A2) :: \Omega  (Theorem 12.2.6)

) CAN (\Gamma ; T Y P E(\Gamma ; M )) returns A0 such that A0 2 C\Gamma  and
\Gamma  ` T Y P E(\Gamma ; M ) = A0 :: \Omega  (Lemma 12.3.1) ) \Gamma  ` (A1; A2) = A0 :: \Omega  (E-SYM and
E-TRAN)

) 9x; A01; A02: A0 = \Sigma x:A01: A02 and x 62 dom(\Gamma ) [ FTV(A2) (Lemma 9.5.7)
) \Gamma ; A01: ` A02 = A2 :: \Omega  (Lemma 9.4.10 and E-SYM) and A02 2 C\Gamma ;x:A0

1 (Lemma 9.5.3)

) x 62 FTV(A02) (Corollary 9.6.3) ) A0 = (A01; A02) ) T Y P E(\Gamma ; M :2) returns A02
(inspection of TYPE).

I-APP: Here \Gamma  ` M 1 M 2 : A0 derived via rule I-APP from \Gamma  ` M 1 : \Pi x:A0: A1, \Gamma  ` M 2 : A2,

\Gamma  ` A2 ^ A0 and \Gamma  ` \Pi x:A2: A1 = A2!A0 :: \Omega  where x 62 dom(\Gamma ) [ FTV(A0) )
T Y P E(\Gamma ; M 1) and T Y P E(\Gamma ; M 2) return (induction hypothesis) and
\Gamma ; x:A2 ` A1 = A0 :: \Omega  (Lemma 9.4.10) ) \Gamma  ` M 1 : T Y P E(\Gamma ; M 1) and
\Gamma  ` M 2 : T Y P E(\Gamma ; M 2) (Lemma 12.3.2) ) \Gamma  ` T Y P E(\Gamma ; M 1) :: \Omega  (Corollary 12.2.5),
\Gamma  ` \Pi x:A0: A1 = T Y P E(\Gamma ; M 1) :: \Omega , and \Gamma  ` A2 = T Y P E(\Gamma ; M 2) :: \Omega 
(Theorem 12.2.6)

) \Gamma ; x:T Y P E(\Gamma ; M 2) ` A1 = A0 :: \Omega  (Theorem 9.4.6) and
CAN (\Gamma ; T Y P E(\Gamma ; M 1)) returns A00 such that A00 2 C\Gamma  and
\Gamma  ` T Y P E(\Gamma ; M 1) = A00 :: \Omega  (Lemma 12.3.1) ) \Gamma  ` A00 = \Pi x:A0: A1 :: \Omega  (E-SYM
and E-TRAN)

) 9A00; A01: A00 = \Pi x:A00: A01 (Lemma 9.5.7 and E-SYM)
) \Gamma  ` A00 = A0 :: \Omega , \Gamma ; x:A00 ` A01 = A1 :: \Omega , (Lemma 9.4.10) and
\Gamma ; x:A00 ` A01 :: \Omega  (Theorem 9.4.3 and C-DFUN) ) \Gamma  ` T Y P E(\Gamma ; M 2) ^ A00 (ESYM, S-EQ, and S-TRAN) ) SU B(\Gamma ; T Y P E(\Gamma ; M 2); A00) returns
(Lemma 12.3.1), \Gamma ; x:T Y P E(\Gamma ; M 2) ` A01 :: \Omega , and \Gamma ; x:T Y P E(\Gamma ; M 2) ` A1 = A01 :: \Omega 
(Theorem 10.4.7) ) \Gamma  ` \Pi x:T Y P E(\Gamma ; M 2): A01 :: \Omega  (C-DFUN) and
\Gamma ; x:T Y P E(\Gamma ; M 2) ` A01 = A0 :: \Omega  (E-TRAN)

284 CHAPTER 12. TYPE CHECKING

) CAN (\Gamma ; \Pi x:T Y P E(\Gamma ; M 2): A01) returns A000 such that A000 2 C\Gamma  and
\Gamma  ` \Pi x:T Y P E(\Gamma ; M 2): A01 = A000 :: \Omega  (Lemma 12.3.1)

) 9A08; A09: A000 = \Pi x:A08: A09 (Lemma 9.5.7)
) \Gamma  ` A08 = T Y P E(\Gamma ; M 2) :: \Omega , \Gamma ; x:T Y P E(\Gamma ; M 2) ` A09 = A01 :: \Omega 
(Lemma 9.4.10) and A09 2 C\Gamma ;x:A0

8 (Lemma 9.5.3)) \Gamma ; x:T Y P E(\Gamma ; M

2) ` A09 = A0 :: \Omega  (E-TRAN)
) \Gamma ; x:A08 ` A09 = A0 :: \Omega  (Theorem 9.4.6) ) x 62 FTV(A09) (Corollary 9.6.3) )

A000 = A08!A09 ) T Y P E(\Gamma ; M 1 M 2) returns A09 (inspection of TYPE).

2

Moreover, if we had an oracle for the SU B procedure, then the T Y P E procedure
would always terminate:

Lemma [Inf ] 12.3.4 If the SU B procedure in T Y P E is replaced by an oracle for subtyping which never hangs then T Y P E(\Gamma ; M ) always terminates.

Proof: By Lemma 12.3.1, V ALID, CAN , and KIN D always terminate. Since all
recursive calls to T Y P E are on proper sub-terms of the original term, T Y P E(\Gamma ; M ) can
only fail to terminate if a call to SU B fails to terminate. 2

Thus, because of these results and the fact that the inference system has principle types (Theorem 12.2.6), the inference system's well-typed term judgment is semidecidable (decidable given an oracle for subtyping):

Theorem [Inf ] 12.3.5 (Semi-decidability)

The judgment \Gamma  ` M : A is semi-decidable. Non-termination only occurs if the judgment
is false. If an oracle is provided for subtyping then the judgment becomes decidable.

Proof: Claim: T ERM (\Gamma ; M ; A) returns iff \Gamma  ` M : A:

)) Here T ERM (\Gamma ; M ; A) returns ) T Y P E(\Gamma ; M ) returns and

\Gamma  ` T Y P E(\Gamma ; M ) = A :: \Omega  (Lemma 12.3.1) ) \Gamma  ` M : T Y P E(\Gamma ; M )
(Lemma 12.3.2) ) \Gamma  ` M : A (I-UN)

() Here \Gamma  ` M : A ) T Y P E(\Gamma ; M ) returns (Lemma 12.3.3)

) \Gamma  ` M : T Y P E(\Gamma ; M ) (Lemma 12.3.2) ) \Gamma  ` T Y P E(\Gamma ; M ) = A :: \Omega 
(Theorem 12.2.6) ) EQU AL(\Gamma ; T Y P E(\Gamma ; M ); A; \Omega ) (Lemma 12.3.1)
) T ERM (\Gamma ; M ; A) returns

Hence, the judgment is semi-decidable, with non-termination only occuring if the judgment is false. By Lemmas 12.3.4 and 12.3.1, T ERM always terminates if an oracle is used
for subtyping ) the judgment is decidable in the presence of an oracle for subtyping. 2

Part III
Conclusions

285

Chapter 13
Extensions
In this chapter I discuss briefly a number of possible extensions to the basic kernel system.
Some of them are straightforward while others will likely require extensive future research.

13.1 N-Ary Named Fields
One extension needed to make the kernel system a more realistic programming language
is the ability to have translucent sums with any number of named fields. This extension
would allow us to create translucent sum terms like module a=3; x=5; y=7; end with
type interface a:int; x:int; y:int; end. Without this ability, we would have to use
a more cumbersome term like (3; (5; 7)) with type (int; (int; int)); we would also have
to remember when accessing fields that .a corresponds to :1, .x to :2:1, and .y to :2:2.
This requirement unnecessarily burdens the programmer's memory and makes adding or
removing fields later difficult.

Because translucent sums are dependent sums, there must be a way for the types of
components to refer to previous fields. Naively, one might expect that the field names
could be reused for this purpose. This idea does not work because of a conflict between
the requirements on external and internal names: Internal names must be free to ff-vary
under substitution, fi-reduction, and other operators while external names must remain
fixed (otherwise, the set of legal field names which can be selected on changes).

A simple solution is just to have separate external and internal names for each field.
As an example, with internal names denoted in parentheses, we might have the following
type:

interface

T(ff):!type?;
S(S):!= interface T(fi):!type?; x(x):fi!-?ff!; end ::type?;
end

287

288 CHAPTER 13. EXTENSIONS
Note that in the absence of separate names there would be no way to express the fact that
the x field's type depends on the types of both the first and second T fields. The scope
of internal names is the remaining fields of the translucent sum type; external names are
never in scope. In order to simplify the system and catch programmer errors, duplicate
external names in a translucent sum should be prohibited.

I expect that different internal and external names will seldom be needed in practice.
Accordingly, a useful abbreviation is to allow the internal name to be omitted when
it is the same as the external one. Translucent sum terms in the kernel system, for
simplicity, do not contain internal bindings and thus do not need internal names. This
ability is easy added, however, using syntactic sugar. For example, the internal bindings
in module x(a)=2; y=a+a; end can be removed by rewriting the term to let val a=2;
val y=a+a; in module x=a; y=y; end.

Because of the way I factored translucent sums in the kernel system, they contain
only values directly; constructors can be contained only indirectly via the use of a reified
constructor. This factoring could either be hidden from the programmer by syntactic
sugar or removed entirely; the result would be translucent sums that (appear) to have
both constructor and value components. The previous example type would then be as
follows:

interface

constr T(ff)::type;
constr S = interface constr T(fi)::type; val x:fi-?ff; end;
end

Here constructor fields are indicated by the keyword constr and value fields by the
keyword val; opaquely defined constructor fields like T just list the kind of the field while
transparently defined constructor fields like S give the constructor they are defined equal
to (the kind can be inferred). Note that because ff and fi are types here, constructor
extractions (\Gamma !) are no longer needed. Since most constructors are types, it is convenient
to allow the type keyword to be used as syntactic sugar for a constr declaration of kind
type (e.g., type T(ff); or type U = int;).

Although the factored version is simpler theoretically, it may be less efficient in practice. Consider an implementation that wishes to save memory by omitting constructor
fields (the kernel system semantics do not require any type information at runtime). This
optimization is easily done in the non-factored version because the two sorts of fields are
syntactically distinguished.

In the factored version, on the other hand, it is impossible in general to tell what
sort of field we are dealing with. In particular, a field's sort may depend on whether
or not a free type variable whose identity is not known at compile time is equal to
a reified constructor type. Because traditional representation methods require that a
type's representation be invariant under type substitution, this optimization requires

13.2. EXTENDED INTERFACE MATCHING 289
non-traditional representation methods in the factored case. New representation methods
using intensional polymorphism [23, 44] may allow this optimization, but probably not
without some runtime and compiler-complexity cost.

What notions of equality and subtyping are appropriate for n-ary named translucent
sums? One approach is to just extend the kernel system rules in the obvious way. Using
a factored version, this approach might look as follows:

` \Gamma  valid
\Gamma  ` fg = fg :: \Omega  (E-BASE)

\Gamma  ` A = A0 :: \Omega 
\Gamma ; x:A ` fF g = fF 0g :: \Omega  n 62 fields(F )

\Gamma  ` fn(x):A; F g = fn(x):A0; F 0g :: \Omega  (E-FIELD)

` \Gamma  valid
\Gamma  ` fg ^ fg (S-BASE)

\Gamma  ` A ^ A0 \Gamma ; x:A0 ` fF 0g :: \Omega 
\Gamma ; x:A ` fF g ^ fF 0g n 62 fields(F )

\Gamma  ` fn(x):A; F g ^ fn(x):A0; F 0g (S-FIELD)

Here, F and F 0 represent possibly empty lists of fields; fields(F ) is the set of field names
defined in F . I am using f and g instead of interface and end for conciseness. Notice
that these rules only allow translucent sums with the same field names in the same order
to be equal to or subtypes of each other.

13.2 Extended Interface Matching
Another approach is to provide what I call extended interface matching, the ability to
reorder or drop fields using subtyping. This ability is very useful in practice because it
allows modules to be combined in more flexible ways. For example, using the dropping
ability, a programmer could pass a module with more features than required to a functor
without having to manually write a coercion function to extract only the required fields.
Likewise, the reordering ability frees programmers of the need to remember the exact
order of the fields of an interface.

Adding the following rule to the rules of the previous section permits subtyping to
drop fields at the end of a translucent sum:

\Gamma  ` fF g :: \Omega 
\Gamma  ` fF g ^ fg (DROP-END)

290 CHAPTER 13. EXTENSIONS

Dropping fields at the end is always safe because the fields that remain cannot depend
on the fields being dropped. In order to drop fields in the middle, we must check that
none of the later fields depend on the fields being dropped:

x 62 FTV(F 0)
\Gamma ; x:A ` fF g ^ fF 0g n 62 fields(F )

\Gamma  ` fn(x):A; F g ^ fF 0g (DROP-ANY)

What rules to use for reordering fields is problematic. In the original formulation of
the kernel system [20], rules equivalent to the following rule were used:

x1 62 FTV(A2) x2 62 FTV(A1)
\Gamma  ` fn1(x1):A1; n2(x2):A2; F g :: \Omega 
\Gamma  ` fn1(x1):A1; n2(x2):A2; F g ^ fn2(x2):A2; n1(x1):A1; F g (SWAP)

This rule allows adjacent fields be swapped if the later field does not refer to the earlier
one.

I have since discovered a problem with this rule: It does not treat nested translucent sums the same as it does the equivalent flattened version. For example, under the
assignment ffl; fi::\Omega , we have that

fxa:!\Omega ?; xb:fi; y:!=*ff::\Omega )\Omega : ff xa!::(\Omega )\Omega ))\Omega ?;g
^ fxa:!\Omega ?; y:!=*ff::\Omega )\Omega : ff xa!::(\Omega )\Omega ))\Omega ?; xb:fi;g
= fxa:!\Omega ?; y:!=*ff::\Omega )\Omega : ff xa!::(\Omega )\Omega ))\Omega ?; xb:y! (*ff::\Omega : fi);g
^ fxa:!\Omega ?; y:!(\Omega )\Omega ))\Omega ?; xb:y! (*ff::\Omega : fi);g
^ fy:!(\Omega )\Omega ))\Omega ?; xa:!\Omega ?; xb:y! (*ff::\Omega : fi);g

The subtyping fails to hold though, if we combine xa and xb together in a single sum
nested inside the outer sum:

fx:fa:!\Omega ?; b:fi;g; y:!=*ff::\Omega )\Omega : ff x:a!::(\Omega )\Omega ))\Omega ?;g
^ fx:fa:!\Omega ?; b:fi;g; y:!(\Omega )\Omega ))\Omega ?;g
^ fy:!(\Omega )\Omega ))\Omega ?; x:fa:!\Omega ?; b:fi;g;g
6^ fy:!(\Omega )\Omega ))\Omega ?; x:fa:!\Omega ?; b:y! (*ff::\Omega : fi);g;g

(We are forced here to forget the information about y's identity in order to swap the x
and y fields -- swapping requires removing the dependency on x. Unfortunately, we need
this information after the swap is done in order to relate b's type to y.)

I find this behavior counterintuitive. We could make subtyping treat nested and
flattened sums the same by adding flattening rules so that, for example,

fF1; x:fa:A1; b:A2;g;F2g ^ fF3; x:fa:A01; b:A02;g;F4g

13.2. EXTENDED INTERFACE MATCHING 291
holds if

fF1; xa:A1;xb:[xa=a]A2;[xa=x:a][xb=x:b]F 2g ^

fF3; xa:A01;xb:[xb=b]A02;[xa=x:a][xb=x:b]F 4g

provided no variable capture or field duplication occurs. In the more general case, the x
field on the right-hand side might have fewer subfields in a different order or might not
exist at all.

The decision problem for these rules (both with and without flattening) appears to be
quite difficult; it is hard to see how the need to guess intermediate types can be avoided.
(E.g., what type should we coerce a field to before we swap it with the preceding field?)

An alternative way of handling reordering can be obtained by imagining translating
the system with reordering and dropping of fields into the system of the previous section by inserting coercion functions into the code whenever subsumption occurs. Thus,
for example, if subsumption was used to swap the fields of a translucent sum with
type fx:A1; y:A2;g resulting in the type fy:A02; x:A01;g, the following function of type
fx:A1; y:A2;g!fy:A02; x:A01;g would be inserted1:

*r:fx:A1; y:A2;g: (fy=r:y; x=r:x; g!:fy:A02; x:A01;g)
To make this insertion work, the subtyping rules must ensure that this function is always
well typed in the previous section's system whenever they allow fx:A1; y:A2;g to be a
subtype of fy:A02; x:A01;g.

By examining the type rules of the target system, it can be seen that the following
rule is the most general rule possible for this case:

\Gamma  ` fy(x2):A02; x(x1):A01;g :: \Omega 
\Gamma ; x1:A1; x2:A2 ` [self=x1]A1 ^ A01
\Gamma ; x1:A1; x2:A2 ` [self=x2]A2 ^ A02
\Gamma  ` fx(x1):A1; y(x2):A2;g ^ fy(x2):A02; x(x1):A01;g (TWO-FLIP)

The original SWAP rule can be derived from this rule. However, unlike the original rule,
this rule treats nested and flattened translucent sums the same. The example that we
needed extra flattening rules to handle before can be done using just the new TWO-FLIP
rule: Under the assignment ffl; fi::\Omega ; x:fa:!\Omega ?; b:fi;g; y:!=*ff::\Omega )\Omega : ff x:a!::(\Omega )\Omega ))\Omega ?,

1To simplify the discussion, I am assuming here that no reordering or dropping of subfields is needed
on the contents of the x and y fields. In the general case it may be necessary to insert additional coercion
functions before r:y and r:x in order to handle this.

292 CHAPTER 13. EXTENSIONS
we have that

[self=x]fa:!\Omega ?; b:fi;g =
fa:!=x:a!::\Omega ?; b:fi;g =
fa:!=x:a!::\Omega ?; b:(*ff::\Omega : fi) x:a!;g =
fa:!=x:a!::\Omega ?; b:(*ff::\Omega )\Omega : ff x:a!) (*ff::\Omega : fi);g =
fa:!=x:a!::\Omega ?; b:y! (*ff::\Omega : fi);g ^
fa:!\Omega ?; b:y! (*ff::\Omega : fi);g

and [self=y]!=*ff::\Omega )\Omega : ff x:a!::(\Omega )\Omega ))\Omega ? =

!=*ff::\Omega )\Omega : ff x:a!::(\Omega )\Omega ))\Omega ? ^
!(\Omega )\Omega ))\Omega ?

Thus, TWO-FLIP handles the nested translucent sum example.

Because neither of these abilities (to derive SWAP and to handle nesting properly)
require the use of the self function, a simpler and less powerful rule could be substituted
for TWO-FLIP without losing either of these abilities:

\Gamma  ` fy(x2):A02; x(x1):A01;g :: \Omega 

\Gamma ; x1:A1; x2:A2 ` A1 ^ A01
\Gamma ; x1:A1; x2:A2 ` A2 ^ A02
\Gamma  ` fx(x1):A1; y(x2):A2;g ^ fy(x2):A02; x(x1):A01;g (SIMPLER)

The most important difference between these rules is that TWO-FLIP, unlike SIMPLER, allows the swapping of fields that must contain identical constructors. For example, only under TWO-FLIP is fx:!\Omega ?; y:!=x!::\Omega ?;g a subtype of fy:!\Omega ?; x:!=y!::\Omega ?;g.
The use of the self function is crucial here:

x:!\Omega ?; y:!=x!::\Omega ? ` [self=x]!\Omega ? = !=x!::\Omega ? = !=y!::\Omega ?
It is unclear how important this ability is in practice however.

The analysis based on the translation idea can be extended to deal with reordering and
dropping an arbitrary number of fields at the one time, producing generalized versions of
TWO-FLIP and SIMPLER. Xavier Leroy's system [31] (see Section 14.3) appears to be
using a generalized variant of SIMPLER. The decision problem for these rules (TWOFLIP, SIMPLER, and generalizations thereof) does not seem to be much more difficult
than the current kernel-system subtyping problem.

13.3 Transparent Value Declarations
Translucent-sum types as I have described them so far allow opaque constructor declarations, transparent constructor declarations, and opaque value declarations. By analogy

13.3. TRANSPARENT VALUE DECLARATIONS 293
with opaque and transparent constructor declarations, we could consider adding transparent value declarations (TVDs for short) as well. A transparent value declaration would
specify the existence of a value component with a given type those contents is equal to
a specified term. As an example, consider the following type with TVDs:

interface

val x:int = 3;
val X:interface type T; type S; val n:int; end;
val Y:interface type T; type S; val n:int; end = X;
end

If M is a module declared to have this interface, then we can infer that M.x = 3 and M.X =
M.Y; hence we can also infer that M.X.T = M.Y.T, M.X.S = M.Y.S, and M.X.n = M.Y.n.

There are three reasons why we might want to extend translucent sums to allow transparent value declarations. First, TVDs support inlining; for example, when compiling a
module that uses module M, the compiler can use the fact that M.x = 3 to replace references to M.x with 3. (This ability is, of course, more useful when M.x is a complicated
function.)

Second, TVDs allow value sharing, the ability to express the fact that two modules
refer to the same value. This ability may be useful when it is important that two modules
constructed independently use a common piece of code. See [37] for some good examples
of where value sharing is useful.

Third, TVDs allow module sharing (also called structure sharing); module sharing
permits equating all the components of two modules with a single equation (e.g., M.X =
M.Y) which would otherwise require possibly exponentially many equations equating all
the individual components of the modules. Module sharing is thus a useful abbreviation
mechanism.

What terms should we allow TVDs to declare value components' contents to be equal
to? In order to be able to express value or module sharing, we will need to allow places
(xae's). Since subject reduction (desirable for soundness) requires that the set of types
be closed under value substitution, we must then also allow values and projections from
values, resulting in extended values:

Definition 13.3.1 (Syntax)

Extended Values * ::= x j V j *:n

If we are concerned with only inlining, then allowing only values may suffice.

Either of these choices has the drawback that it greatly increases the complexity of
the system: types may contain values which may contain arbitrary terms because of
functional values so that the type-validity judgment must then depend on the full valid
term and subtyping judgments. An actual programming language could restrict the set

294 CHAPTER 13. EXTENSIONS
of legal terms in TVDs further to simplify type inference but this restriction would not
change the underlying theory or its difficulty.

If we allow arbitrary terms in TVDs, then unsoundness results. Consider the following example using rnd(), a pseudo-random number generator (implemented using a
reference):

constr S = interface type T; val v:T; val f:T!T; end;

val M1:S = module type T=int;

val v=3; val f = *x:int. -x; end;
val M2:S = module type T=bool;

val v=true; val f = *x:bool. not x; end;

val F = *x:int. if x % 2 = 1 then M1 else M2;
val X = module x=F(rnd()); y=F(rnd()); end !:

interface x:S=F(rnd()); y:S=F(rnd()); end;

If we allow arbitrary terms in TVDs, this example will type check, allowing us to conclude
that X.x = X.y and hence that X.x.T = X.y.T; the call X.x.f(X.y.v) will thus type
check but produce a runtime type error half the time.

If more terms than the extended values are desired in TVDs, one sound approach is
to formulate a notion of value-like terms whose evaluation does not produce side-effects
or depend on the store. Robert Harper and Chris Stone have taken this approach in
recent work [24], introducing a separate judgment which they use to determine which
terms are value like.

What notation of equality is appropriate for extended values (or value-like terms)?
Clearly, at an absolute minimum, we need equivalent extended values (i.e., ff-convertible)
to be equal. For consistency, it would be nice to also allow constructors to convert using
the existing constructor equality relation, but this ability is not strictly necessary. The
extended-value equality must also take into account any TVDs in the context, allowing
places with TVDs to be replaced by the extended value that they are declared equal to.
Because of the presence of projections in extended values, it will also be necessary to
handle projection (e.g., fx=3; y=4;g.x = 3).

I see no need for including additional equalities, except possibly to handle applications
if value-like terms are allowed; in that case, the implications for the decidability of valuelike term equality will have to be considered carefully. No purpose seems to be served by
allowing functions that are functionally equivalent to be equal, particularly given that
such functions may differ in terms of efficiency.

Because translucent sums can contain constructors, equations on translucent sum
values can also imply equations on constructors (e.g., M.X.T = M.Y.T in the first TVDs

13.3. TRANSPARENT VALUE DECLARATIONS 295
example). These inferences can be handled by adding the following rules for constructor
equality (assuming a factored formulation of translucent sums):

\Gamma  ` *1 = *2 : !K?

\Gamma  ` *1! = *2! :: K (E-VAL-O)

\Gamma  ` *1 = *2 : !=A::K?

\Gamma  ` *1! = *2! :: K (E-VAL-T)

\Gamma  ` A = A0 :: K
\Gamma  ` !A?! = A0 :: K (E-TVD)
Note that constructor extractions in constructors are now of the form *! rather than the
old xae!; this change simplifies things because the value substitution operator no longer
needs to handle projections or extraction -- it can just substitute the value for the term
variable and let the extended-value equality handle the projections and extractions.

Under the factored approach, transparent reified constructor types (!=A::K?) are
unnecessary after TVDs have been added: we can replace occurrences of val x:!=A::K?
by val x:!K?=!A? in interfaces while preserving the equation x! = A. Accordingly,
under those circumstances, we could switch from the current kernel-system (translucent)
reified constructors, which have both transparent and opaque types, to opaque reified
constructors, which have only opaque types. This change would simplify the system and
avoid the redundancy of having two different ways to specify a transparent constructor
definition.

Just as the notion of reified constructors allowed translucent sums to be factored into
simpler primitives in the kernel system, a notion of singleton types would allow factoring
translucent sums with TVDs into simpler primitives. A singleton type ((=*)A) is a type
that may contain only a single sort of extended values:

\Gamma  ` * : A \Gamma  ` * = *0 : A

\Gamma  ` * : (=*0)A (ST-INTRO)

Singleton types are subtypes of the appropriate non-singleton type:

\Gamma  ` (=*)A :: \Omega 
\Gamma  ` (=*)A ^ A (SI-SUB)

What equality rules singleton types should obey is not completely clear, depending in
part on the choice of what they can specify their members are equal to. Likely equality
rules include: \Gamma  ` A = A0 :: \Omega  \Gamma  ` * = *0 : A

\Gamma  ` (=*)A = (=*0)A0 :: \Omega  (SIE-COMP)

296 CHAPTER 13. EXTENSIONS

\Gamma  ` (=*)\Sigma x:A1: A2 :: \Omega  x 62 FTV(*)
\Gamma  ` (=*)\Sigma x:A1: A2 = \Sigma x:(=*:1)A1: (=*:2)A2 :: \Omega  (SIE-DSUM)

Note that these rules allow simplifying the self function to [self=*]A = (=*)A. A
rule similar to E-ABBREV allows making use of the knowledge about the identity of a
singleton type's members:

\Gamma  ` xae ) (=*)A

\Gamma  ` xae = * :: A (SI-ABBREV)

If singleton types are introduced, then transparent value declarations (val x:A =
*) can be replaced by opaque value declarations using singleton types (val x:(=*)A).
Opaque reified constructors can then be used to handle opaque constructor declarations
(val x:!K?) and transparent constructor declarations (val x:(=!A?)!K?). Thus,
by using these encodings, translucent sums with TVDs can be factored into simpler
components: dependent sums, singleton types, and opaque reified constructors.

13.4 Kind Components
Another possible extension is to allow translucent sums to contain kinds. For example, we might allow translucent sum types like interface kind K1; kind K2=type;
constr T1::K1; constr T2::K2; val x:T2; end (unfactored) or interface K1:!!??;
K2:!!=type??; T1:!K1!?; T2:!K2!?; x:T2!; end (factored) where !!?? and !!=type??
denote reified-kind types.

Reified kinds are similar to reified constructors, but package up kinds instead of
constructors. The transparent type !!=K?? is the type of reified kinds containing the
kind K (!!K??), while the opaque type !!?? is the type of all reified kinds, regardless
of what kind they contain. If xae has a reified kind type under \Gamma , then the kind extraction
xae! is a valid kind under \Gamma . If xae has type !!=K?? under \Gamma  then xae! and K are equal
kinds under \Gamma . The type !!=K?? is a subtype of the type !!?? under any \Gamma  for which
K is a valid kind.

Both versions of this extension require adding notions of what a valid kind is and
of which kinds are equal. Both notions depend on the types of the term variables in
the assignment and on the equality of types judgment. This fact is likely to greatly
complicate the proof theory of the extended system.

There are at least two plausible reasons to allow kind components in translucent
sums. The first is based on the concept of a module as being "a chunk of namespace".
If a language allows kinds to be named for abbreviation or mnemonic purposes, then it
should, according to this view of what a module is, also allow kind definitions in modules.

13.5. RECURSION 297
This decision avoids the need to have different syntax for modules and let statements
(including any interactive top level).

The second reason is that allowing translucent sums to contain kinds introduces kind
polymorphism (the ability to abstract over kinds) to the language as a derived form in
much the same way that normal translucent sums allow constructor polymorphism. In
particular, \Lambda ^: M would stand for *x:!!??: [x!=^]M , x 62 FTV(M ), and M K would
stand for M !!K??.) Kind polymorphism is derivable only at the term level; *^: A
is not a derivable form. Kind polymorphism may be useful in combination with singleton kinds (defined in Section 13.8, below) to give more expressive types to higher-order
functors. I discuss this further in Section 14.4.

13.5 Recursion
The kernel system provides the needed primitives to implement recursion but does not
directly provide a way to build recursive functions. A real programming language should
provide at least a fixed-point operator (fix), and preferably some kind of let-rec statement.

Fixed point operators can easily be implemented in the kernel system using recursive
types; see Figure 13.1 for an example implementation of fix in SML-like syntax that can
be used to produce recursive functions of type \Pi x:A: A0. Alternate implementations of
fix are also possible using references instead of recursive types.

Note that this implementation of fix will work for any dependent function type, not
just arrow types. Unfortunately, however, there is no way in the kernel system to abstract
over just dependent function types so multiple copies of the implementation using different types may be needed to cover all the ways fix is used in a given program. It is possible,
though, to handle all the non-dependent function types using a single implementation by
abstracting separately over the argument and return types:

f ix : 8ff::\Omega : 8fi::\Omega : ((ff!fi)!(ff!fi))!(ff!fi)
One approach to the problem of needing multiple copies of fix is to simply make fix
a built-in primitive with a special typing rule that allows it to work on any dependent
function type:

Definition 13.5.1 (Fix Typing Rule)

\Gamma  ` \Pi x:A: A0 :: \Omega 
\Gamma  ` fix : ((\Pi x:A: A0)!(\Pi x:A: A0))!(\Pi x:A: A0) (T-FIX)

Another approach is to introduce parametric interfaces (*x:A: A0 :: A)K), which are
functions at the constructor level that map values to constructors. Parametric interfaces

298 CHAPTER 13. EXTENSIONS

type target type = \Pi x:A: A0;
type fix type = (target type!target type)!target type;
(*

* Set things up so that we can pass a rolled up
* version of fix1 to fix1 as its first argument:
*)
type fix1 iter = *ff::\Omega : ff!fix type;

val fix1 roll = roll !fix iter?;
val fix1 unroll = unroll !fix iter?;

(*

* fix1 is like fix except that it takes a rolled
* up copy of itself as an extra argument:
*)
fun fix1 (rolled fix1:rec fix1 iter) (f:target type) =

f (*x:A: (fix1 unroll rolled fix1) rolled fix1 f x);

val fix = fix1 (fix1 roll fix1);

Figure 13.1: A sample fixed-point operator implementation

13.5. RECURSION 299
allow abstracting over dependent function types by first abstracting away the argument
type (a normal type), and then second, abstracting away the result type modulo the
argument (a parametric interface):

fix : 8ff::\Omega : 8fi::ff)\Omega : ((\Pi x:ff: fi x)!\Pi x:ff: fi x)!\Pi x:ff: fi x
Parametric interfaces (often called parametric signatures when they are available only
at the level of modules) are also likely to be useful for describing the types of modules;
for example, they allow abstracting over a module that several components of another
module depend on. This ability is most likely to be useful if value sharing is allowed.
(If a module depends only on the type components of another module, then we could
alternatively abstract over each type component in turn, giving the same effect at the
cost of more effort.)

Adding parametric interfaces would definitely complicate the kernel system (e.g.,
kinds would then depend on constructors and hence term variables). How best to go
about adding parametric interfaces and what the full consequences of adding them would
be are open questions.

Because the kernel system provides recursive types and existentials (a degenerate
form of translucent sums), it might seem natural to try and encode objects from objectoriented programming languages into the kernel system. Unfortunately, this idea does not
work in practice because the kernel-system subtyping rules do not take all the properties
of recursive types into account. For example, the following desirable inequality does not
hold in the kernel system:

rec *ff::\Omega : fx:int; y:int; self :ff;g ^ rec *ff::\Omega : fx:int; self :ff;g
It is likely that additional subtyping rules could be added to remedy this problem but
the effect those rules would have on the semi-decidability of subtyping and type checking
is unclear.

Given a fixed point operator, let-rec statements can be elaborated into uses of fix and
non-recursive let statements. Some programming languages (e.g., CLU) allow modules
to be defined recursively in terms of each other. This feature is difficult to provide in a
translucent sums framework for several reasons.

One problem is that recursive module definitions allow defining types recursively. This
ability is different from the existing kernel-system recursive-type mechanism because it
provides a true equality rather than just an isomorphism. For example, if we could define
type T=T!T, then T = T!T would be derivable under suitable assignments; however,
the similar equation rec *ff::\Omega : ff!ff = (rec *ff::\Omega : ff!ff)!(rec *ff::\Omega : ff!ff) does not
hold. Permitting types to be defined recursively is a problem because it makes the type
system completely undecidable. The following recursive definition defines a fixed point
operator at the constructor level:

type Y = *f ::(\Omega )\Omega ))(\Omega )\Omega ): f *ff::\Omega : Y f ff

300 CHAPTER 13. EXTENSIONS
Using this combinator, any computation problem (including does Turing machine M
halt?) can be encoded into a type-validity question.

If the possibility of defining types recursively is disallowed, this problem can be gotten
around by staging module computation so that we first compute just the type components
of each module non-recursively then compute the remaining components recursively. Unfortunately, however, there is no way in general to automatically perform this staging:
because first-class translucent sums combine types and values in a single object, the
computations of the type and value components can be arbitrarily interweaved.

More generally, it is possible to have n-stage module computations where the components defined in stage i depend only on type components from stages 0 to i\Gamma 1 and on
value components from stages 0 to i. This idea raises additional problems for automation
because the data flow information needed to arrange this staging automatically is not
available from just the module interfaces. (Requiring access to the source code of the
referenced modules would break separate compilation.)

Thus, in summary, programmers can manually define modules recursively in terms
of each other in the kernel system so long as no type components are defined in terms
of themselves. A full automatic solution to the problem of handling module recursion is
unlikely, but it seems possible that a simple automatable partial solution could be found
that handles most of the uses of recursive modules.

13.6 Better Type Inference
The kernel system is explicitly typed, requiring the programmer to specify explicitly
the type of function arguments, what constructors a polymorphic object should be instantiated to, when and how a term should be polymorphically abstracted over, and,
for the inference system, when and how to use subsumption. It seems likely that some
kind of type reconstruction algorithm could be found which would reduce the amount of
information required.

One possible approach is to try and modify Frank Pfenning's type reconstruction
algorithm for F! [48, 49] to work for the kernel system. The idea would be to require the
programmer to provide all constructors involving translucent sums, dependent functions,
or reified constructors. The reconstruction algorithm would then not have to infer these
sorts of constructors.

13.7 Elaborations
A number of useful extensions are more naturally added as features that elaborate during an elaboration stage down to the core language. For example, a simple let state13.7. ELABORATIONS 301
ment, let x:A = M 1 in M 2 end, could be elaborated into the kernel-system expression (*x:A: M 2) M 1. Elaboration often incorporates a degree of type inference as well.
For example, we could make supplying a type for M 1 in let statements optional; since the
kernel inference system possesses principle types (see Chapter 12), supplying this type is
easy for the elaborator to do.

13.7.1 SML-like Elaborations
The language Standard ML (SML) [21] possesses many elaborations that would make
useful extensions to the kernel system. These include complex let statements that allow
sequential, parallel, recursive, and local bindings; a special syntax for function bindings (e.g., fun inc(x:int) = x+1 rather than val rec inc = *x:int: x+1); tuples as
sugar for records (translucent sums) with numbered fields (e.g., (int, bool) stands for
f1:int; 2:bool;g); datatypes2; and pattern matching. The SML syntax for datatypes
and pattern matching will need to be extended though in order to handle polymorphic
constructors such as the list cons operator, which require instantiation to an explicit type
before they can be used.

Using these SML-like elaborations, we can write code like the following polymorphic
function which swaps the components of a homogeneous length-two tuple:

fun swap(!T::type?, (x:T, y:T)) = (y, x);
Because type variables are declared so frequently, it is helpful to introduce an abbreviation
'T to stand for !T::type?:

fun swap(`T, (x:T, y:T)) = (y, x);
The curried version of this function would look like

fun swap `T (x:T, y:T) = (y, x);
Using this definition, swap !int? (1,2) evaluates to (2,1). For an actual programming
language, we would probably wish to replace the !A? notation for reified constructors
with some other syntax so that we can make use of the ! and ? symbols to denote the
relational operators.

13.7.2 Translucent-Sum Syntax
Translucent sums are used in two main ways in the kernel system: they are used as recordlike temporary objects that are created and passed around in the process of computation

2While datatypes were originally built into SML, recent reformulations of the language [24] treat
them as elaborations in terms of simpler constructs: recursive types, tuples, one-ofs, and patterns.

302 CHAPTER 13. EXTENSIONS
and they are used as module-like permanent objects that contain chunks of program
namespace. These uses are sufficiently different that they would benefit from different
syntax. For record-like use, a light, concise syntax similar to that of records is desirable.
When you are creating translucent sums every other line, fx=3; y=4;g is far preferable
to module val x=3; val y=4; end.

For module-like use, on the other hand, a heavier syntax that stands out is appropriate: Modules are an important part of program structure and should be easily
visible to a reader, not buried in a mess of symbols. Another important reason for
using heavier syntax is that it allows incorporating SML's complex binding forms in
the syntax: We can regard module bindings end as an elaboration for let bindings
in fx1=x1; x2=x2; : : :; xn=xn;g end where x1, x2, : : :, xn are the names bound in
bindings in the order that they are bound.3

For example, module val x=2; val y=x+2; end would elaborate to let val x=2;
val y=x+2; in fx=x; y=y;g end. A slight extension of the SML binding syntax will
be needed here to allow for optionally different external and internal names. As an example, module val x(tmp)=2; val y=x+tmp; end might elaborate to let val tmp=2;
val y=x+tmp; in fx=tmp; y=y;g end. Multiple bindings using the same external name
should be disallowed. Corresponding forms of syntax are useful at the type level (e.g.,
fx:int;g vs. interface val x:int; end).

13.7.3 Open and Include
A useful additional form of binding is the open binding form (open M ), which makes
each component of a selected module available under its external name. (Pascal's with
statement [26] provides a similar form of binding for records.) The elaboration of
open M depends on M 's principle type.4 For example, if M has principle type fx:int;
y:bool;g, then let open M in M 0 end will elaborate to let local m=M in val x=m.x
and val y=m.y; end in M 0 end.

In combination with the previous module syntax, the open binding form allows
for easy module extension. For example, module val x=3; open M; end creates a
module identical to M except for an added initial x field equal to 3. If a similar ability is desired for interfaces, the SML include feature can be provided as well. (interface val x:int; include fy:int; z:int;g; end elaborates to interface x:int;
y:int; z:int; end.)

3I am assuming in this section that the record-like syntax does not include any binding; if it provides
sequential binding, then a slightly more complicated encoding using different external and internal names
will have to be used here to avoid capture.

4The principle type is used to ensure that all of M 's components are made available. If a non-principle

type was used, it might be missing components because of subsumption.

13.7. ELABORATIONS 303
13.7.4 Leroy's With Notation
An important abbreviation feature when dealing with translucent sum types is some
version of Leroy's with notation [31]. Leroy's with notation is used to add information about the contents of a translucent sums' constructor components to its interface. For example, if S is a valid type that is equal to the semi-canonical type interface type x; type y; end, then S with x=int denotes the interface type x=int;
type y; end. It is an error to attempt to redefine what a component is equal to (e.g.,
S with x=int with x=int is erroneous).

Choosing the right scoping rules for with expressions is somewhat tricky. We would
like S with y=x to denote interface type x; type y=x; end, but what should S with
x=y denote? Possibilities include interface type x=y; type y; end (here x is declared
equal to an x bound outside), an error (because the inner y is not in scope for the
declaration of x), interface type x; type y=x; end (this interfaces makes the x and
y components equal), and interface type y; type x=y; end (this type is a subtype of
S under some forms of extended matching; see Section 13.2 for details). Also problematic
is the question of how to use with notation to set S's y component equal to an x bound
outside without incurring capture by S's x component.

One solution is to alter with expressions so that they reference module components
using a name supplied by the programmer. For example, S with (it) it.y = it.x
would denote the old S with y=x while S with (it) it.y=x would denote setting the
y component equal to an x bound outside of S. In order to keep things simple and to
catch as many programmer errors as possible, I recommend declaring references to nonpreceding components as errors. Thus, S with (it) it.x = it.y would be erroneous.

This change to the with notation solves the scoping problems at the cost of a more
verbose notation. A reasonable alternative might be to provide both forms, with the
original with notation as an abbreviation for the new one: S with n=A would stand
for S with (it) it.n=[it:x=x][it:y=y]A, where it 62 FTV(A). Most of the time the
shorter version could be used, but when necessary (to avoid capture) or to make things
clearer, the longer version could be used.

Note that S with z=int is illegal, even if z exists outside: the with notation is only
allowed to add information to its argument type, not to the surrounding context. We
can extend the with notation to handle nested modules though, by allowing with to
add information about subcomponents. For example, interface type r; val s:S; end
with (it) it.s.y = it.s.x-?it.r would be defined equal to interface type r; val
s:S with (s) s.y = s.x-?r; end, which in turn is equal to interface type r; val
s:interface type x; type y=x-?r; end; end.

I recommend against trying to implement the SML sharing-type construct because
of its complicated non-local effects: interface type T sharing type x=y; end can
set x and y, which are bound somewhere outside this type, to be equal to each other.

304 CHAPTER 13. EXTENSIONS
The clearer with construct can be used for all the same purposes that the sharing-type
construct is used for in SML, abet requiring a bit more thought to use in some cases.

13.7.5 Separate Compilation
Another important extension that can be added by elaboration is separate compilation.
This addition requires that the compiler automatically convert files containing code with
references to other modules into closed functors using the files containing the interfaces
for the referenced modules. Some kind of convention needs to be established so that the
compiler can find the files containing the appropriate interfaces. The linker then must
automatically generate code to apply the compiled functors generated by the compiler
to each other in the correct order at runtime. There are many possible ways of setting
up this sort of system; I gave an example of one way in Section 3.8.

13.8 Reformulations
Finally, I want to discuss briefly two possible reformulations of my kernel system. The
first reformulation involves using singleton kinds as an alternative way of capturing the
notion of transparent constructor declarations. Singleton kinds are due independently to
Robert Harper [16] and Xavier Leroy [31]. A singleton kind is composed of a base kind
and a constructor of that kind; in order for a constructor to belong to a singleton kind,
it must belong to the singleton kind's base kind and be equal to the singleton kind's
constructor. A singleton kind thus describes a single equivalence class of constructors.
Singleton kinds are similar to singleton types, but involve the kind and constructor levels
rather than the type and term levels.

I shall describe briefly one formulation of singleton kinds here. To simplify things,
I shall restrict base kinds (B) syntactically so that they do not include singleton kinds
(=A::B):

Definition 13.8.1 (Extended kind level syntax)

Base Kinds B ::= \Omega  j B)B0
Kinds K ::= \Omega  j =A::B j K)K0

This restriction avoids the need to handle singleton kinds of the form =A::(=A0::K).

Adding singleton kinds requires allowing kinds to contain constructors; because constructors are not always valid (because their use of type and term variables may differ
from what the assignment says is legal), this change means that an additional judgment
for establishing kind validity (\Gamma  ` K valid) must be added:

13.8. REFORMULATIONS 305
Definition 13.8.2 (Valid Kind Rules)

` \Gamma  valid
\Gamma  ` \Omega  valid (KV-TYPE)

\Gamma  ` K1 valid \Gamma  ` K2 valid

\Gamma  ` K1)K2 valid (KV-FUN)

\Gamma  ` A :: B
\Gamma  ` =A::B valid (KV-SINGLE)

The other judgments must then be altered to ensure that all kinds in valid judgments are
themselves valid. This change increases the difficulty of proving things about the system
because it makes the kind level dependent on the constructor and term levels.

Because the equality relation on constructors is not syntactic identity, an equal kind
judgment (\Gamma  ` K 1 = K2) must also be introduced:

Definition 13.8.3 (Kind Equality Rules)

` \Gamma  valid
\Gamma  ` \Omega  = \Omega  (KE-TYPE)

\Gamma  ` K1 = K01 \Gamma  ` K2 = K02

\Gamma  ` K1)K2 = K01)K02 (KE-FUN)

\Gamma  ` A = A0 :: B
\Gamma  ` (=A::B) = (=A0::B) (KE-SINGLE)

The constructor equality judgment then needs to be modified to allow for different but
equal kinds. For example, the E-LAM rule becomes

\Gamma  ` K1 = K2
\Gamma ; ff::K1 ` A1 = A2 :: K0
\Gamma  ` *ff::K1: A1 = *ff::K2: A2 :: K1)K0 (E-LAM-K)

It is also necessary to add a rule to handle checking constructor equality at singleton
kinds: \Gamma  ` A

1 = A2 :: B \Gamma  ` A1 = A :: B

\Gamma  ` A1 = A2 :: (=A::B) (E-SINGLE)

In order to allow subtyping to forget the information about constructor identity contained in singleton kinds, it is necessary to introduce a subkinding judgment (\Gamma  ` K ^ K 0)
that allows singleton kinds to be converted to their base kinds:

306 CHAPTER 13. EXTENSIONS
Definition 13.8.4 (Subkinding Rules)

` \Gamma  valid
\Gamma  ` \Omega  ^ \Omega  (KS-TYPE)

\Gamma  ` K01 ^ K1 \Gamma  ` K2 ^ K02

\Gamma  ` K1)K2 ^ K01)K02 (KS-FUN)

\Gamma  ` A = A0 :: B
\Gamma  ` =A::B ^ =A0::B (KS-SINGLE)

\Gamma  ` =A::B valid

\Gamma  ` =A::B ^ B (KS-FORGET)

The subtyping and one-step subtyping judgments are then modified to allow for subkinding. For example, the following rule needs to be added:

\Gamma  ` K1 ^ K2
\Gamma  ` !K1? ! !K2? (O-REIFY)

Subkinding also interacts with the constructor validity judgment by means of a subsumption rule:

\Gamma  ` A :: K0 \Gamma  ` K0 ^ K

\Gamma  ` A :: K (C-SUMP)

The rules for introducing and using singleton kinds are then as follows:

\Gamma  ` A = A0 :: B
\Gamma  ` A :: (=A0::B) (K-INTRO)

\Gamma  ` A :: (=A0::B)

\Gamma  ` A = A0 :: B (K-ABBREV)

The effect of a transparent constructor declaration (constr T=A) can then be gotten
by writing constr T::(=A::B), where B is the base kind of A. Subsumption can be used
as before to forget T's identity. This ability means that we could either switch to simpler
opaque reified constructors (like the case with singleton types in Section 13.3) or to a
simpler version of translucent sums with only opaque constructor and value declarations.

Thus, in summary, the first possible reformulation of the kernel system is to use
singleton kinds rather than transparent reified constructor types to express transparent
constructor definitions. While this change would result in a more orthogonal system

13.8. REFORMULATIONS 307
since the concepts of transparent constructor definitions and reified constructors would
be split into separate primitives, the accompanying increase in complexity (e.g., compare
the above rules to the only rules needed for transparent reified constructors: C-EXT-T,
E-TRANS, E-ABBREV, and O-FORGET) seems too high to be worth paying. This
tradeoff may change, however, if features like bounded polymorphism, which can be
implemented using power kinds [9], are added to the language.

The second possible reformulation of the kernel system is to reformulate the system so
that modules are second class instead of first class. This change would involve introducing
separate module and interface levels; translucent sums and dependent functions would
live on the module level while their "types" would live on the interface level. Because
modules would no longer be terms and interfaces would no longer be types, translucent
sums would need to be extended with three new kinds of declarations: opaque interface declarations, transparent interface declarations, and opaque module declarations.
This extension would allow for modules like module type T=int; val x=3; inter
S=IO INTERFACE; mod s=IO MODULE end and interfaces like interface type O; type
T=int; val x:T; inter I; inter S=IO INTERFACE; mod s:S end.

Either a non-factored version of translucent sums could be used (see Section 13.1) or
opaque reified values, translucent reified constructors, and translucent reified interfaces
could be introduced on the module level. These would allow packaging up a value, a
constructor, or an interface as a module, possibly with information about its contents
in its interface if it packages a constructor or an interface. They would thus allow
opaque value, transparent and opaque constructor, and transparent and opaque interface
declarations to be expressed using only opaque module declarations.

Separate record, non-dependent function, and polymorphic abstraction constructs
would need to be introduced at the term level to handle the previous non-module uses of
translucent sums and dependent functions. The subtyping relation on constructors would
no longer be needed, but new notions of equality and subtyping for interfaces would have
to be introduced. (Forgetting of information would occur only at the interface level.)

Unless additional constructs were added at the interface level (e.g., parametric interfaces or functions mapping interfaces to interfaces), these relations would be relatively
simple because there is no analog to fij-reduction on the interface level, only an analog
of fl-reduction. The subtyping relation for interfaces would still be undecidable, however,
for the same reasons that the kernel system's subtyping relation is undecidable. (The
proof in Sections 10.6 to 10.9 can be adapted to this case.)

An even simpler system can be obtained by disallowing opaque or transparent interface declarations (and hence fl-reductions); this change makes interface equality completely structural: equality cannot change the shape of interfaces. It thus greatly simplifies place lookup as well as many other parts of the system. It particular, it is likely
that type checking decidable is decidable for this system. Xavier Leroy's manifest-types
system [31] (see Section 14.3) takes this approach. It is unclear, though, how problematic

308 CHAPTER 13. EXTENSIONS
the lack of transparent interface definitions is from the programmer's viewpoint.

Either way, I expect the resulting system to be far easier to prove things about in spite
of the likely larger number of rules and constructs. Because there are no conditionals
at the module level, types at runtime will not be able to depend on runtime values in
a second-class module system; this fact means that additional typings can be assigned
to such programs that would be unsound in the presence of first-class modules. One
extension that permits such typings is Xavier Leroy's applicative functors [32]. (See
further discussion in Section 14.4.) The utility of such extensions should be investigated
for any second-class module system.

Chapter 14

Related Work
In this chapter I discuss work related to the work contained in this dissertation.
14.1 First-Order Module Systems
How does the module system I built relate to first-order module systems? The answer is
that languages like Modula-2 [56], which have first-order module systems, basically implement the first-order fragment of a second-class version of my module system. (By the
first-order fragment, I mean here the fragment that results from syntactically disallowing
the use of functors and submodules.)

These languages allow translucent interfaces (interfaces that may contain both opaque
and transparent type declarations), and propagate type-identity information across module boundaries similarly to my translucent approach. In particular, the only information
available about a module's type component is that provided by the module's interface.
Their type systems are extremely simple compared to my kernel system because they do
not need to deal with issues like how to compute the interface of a functor application
or how to rewrite an interface into a form that can be used.

For efficiency reasons, most of these languages only allow reference (aka pointer) types
plus possibly some other types with single-machine-word representations like integers to
be held abstract. This decision allows polymorphic code to treat abstract-type values
uniformly since they all occupy a single machine word, while still allowing non-abstracttype values to have multiple-word representations. By contrast, most implementations
of Standard ML, which does not have this restriction, are less efficient because they
represent all values as single machine words. This choice allows polymorphic code to
work uniformly as before on any type, but requires types that need more than one word
of storage to be represented as a pointer to data in the heap. This extra level of indirection
slows down Standard ML and uses more space.

309

310 CHAPTER 14. RELATED WORK

The restriction on what types can be held abstract is implemented by requiring that
type components declared opaquely in interfaces must contain types that may be held
abstract. This restriction could be added to my kernel system by modifying the OFORGET subtyping rule so that it requires that the type being forgotten can be held
abstract:

\Gamma  ` A :: \Omega  \Gamma  ` A sword

\Gamma  ` !=A::\Omega ? ! !\Omega ? (O-FORGET')

Here, \Gamma  ` A sword is a new judgment that denotes that A's values fit in a single machine
word. I have limited this rule to types because none of these languages allow opaque
higher-kinds. It would not be difficult, however, to extend this rule to allow holding
abstract constructors that when fully applied always produce a type that fits in a single
machine word.

Ada [52] handles the problem of how to implement abstraction in an efficient manner differently: Instead of restricting what types may be held abstract, it replaces
opaque type declarations with private type declarations. A private type declaration
for ff (type ff privately is A) declares privately that ff is equal to A. This information about ff's identity is not visible to the programmer: ff is an abstract type that is
unequal to A, preventing the programmer from taking advantage of the fact that ff must
be equal to A at runtime. The information is visible to the compiler, however, allowing
it to generate non-polymorphic -- and hence efficient -- code.

The main drawback of using private rather than opaque type declarations to implement abstraction is that they increase the amount of recompilation that needs to be done
when modules are changed: With private type declarations, if the programmer changes
the representation type of an ADT, all the client modules that use that ADT will have
to be recompiled because their code depends on the ADT's representation type. No
recompilation of client modules is required with opaque type declarations because the
generated code in that case is polymorphic in the ADT's representation type.

Aside from the extra recompilation incurred, using private instead of opaque type
declarations works fine in a first-order module system. Attempting to build a higherorder module system without opaque type declarations, however, leads to problems; I
shall explain why in Section 14.2.2 where I cover Mesa and Cedar, which have only
transparent and a weak form of private type declarations.

14.2 Previous Higher-Order Module Systems
In addition to the work I have already mentioned in Chapter 2, there are several other
previous (proposed) programming languages with module systems that permit non-trivial
manipulations of modules.

14.2. PREVIOUS HIGHER-ORDER MODULE SYSTEMS 311
14.2.1 Modula-3
Modula-3 [45] provides a functor-like construct called a generic module. A Modula-3
generic module is a module parametrized by a series of interface names. Such a module
can be instantiated by binding its formal interface parameters to the names of actual
interfaces. Instantiation is essentially equivalent to making a textual copy of the body of
the generic module with the formals replaced by the actual names; each such instantiation
results in new machine code, unlike functor applications in my system.

Moreover, only actual instantiations are type checked; the generic module itself cannot
be type checked because no information is available for its formals. Generic modules thus
act as untyped macros. This fact means that we lose the benefits of static typing and
separate compilation whenever we use Modula-3's higher-order module-system features.
Also, because instantiation can be done only at compile time, generic modules must
be second-class values. These drawbacks make for a highly-unsatisfactory higher-order
module system.

Modula-3's method of handling abstraction differs from all other higher-order module systems I am aware of. Modula-3 has two separate sorts of types, which I call
transparently-defined types and revealed types. Transparently-defined types are defined
using transparent type declarations and act the same as in my system. Revealed types,
by contrast, are abstract by default unless information about their identity is available
in the current scope.

While most higher-order module systems use a model where information about type
identities flows locally from place to place, starting from the implementation and occasionally getting restricted along the way, Modula-3 uses a model where identity information for revealed types can be given anywhere using a reveal declaration; global
restrictions ensure that the information revealed is self consistent and that the full information about a revealed type is revealed in exactly one place. By placing the full
revelation for an ADT's type in its implementation module, the programmer can thus
ensure that no client module has access to the full representation information. Note that
because of the need for global checks, this approach cannot type check modules using
only the interfaces they reference; it is thus incompatible with separate compilation.

Unlike my system, Modula-3 supports partial abstraction: The programmer can
choose to reveal only that an ADT's representation type is a subtype of some type
A. This feature can be used in combination with Modula-3's object-oriented features to
implement private (in the sense of C++) fields in objects. It can also be used to give two
interfaces to an ADT, one for normal users that hides implementation details and one for
experts that reveals a more complicated and powerful interface; this is done by revealing
a smaller subtype in the expert interface than in the normal one. Partial abstraction
seems to be useful only when combined with objects.

The obvious way to add partial abstraction to my system would be to add partially312 CHAPTER 14. RELATED WORK
opaque type declarations (type ff !: A). Forgetting would then allow converting from
transparent to partially-opaque to even more opaque to fully-opaque type declarations.
Partially-opaque type declarations in assignments would induce subtyping inequalities in
the same way that transparent type declarations induce equalities in the current system.
The subtyping procedure would need to be revised to handle the resulting inequalities.

14.2.2 Mesa and Cedar
The programming languages Mesa [40, 13] and its successor Cedar [30, 54, 55, 3] fall outside my opaque verses transparent classification of higher-order module systems. These
languages are unusual in that they require interfaces to fully specify the identity of all
type components; it is impossible in these languages to refrain from committing to what
type(s) a module will contain. Types in these languages are thus really contained in
interfaces (as type abbreviations) rather than in modules since two modules with type
components containing different types can never have the same interface.

Accordingly, most of the interesting uses of higher-order features are inexpressible
in these languages. For example, functors are much less useful when they cannot take
modules containing types as inputs1; the B-Tree example (see Section 1.4) is completely
inexpressible in these languages, for example. Also, these languages do not provide (real)
data abstraction.2

Because modules depend only on interfaces (all the needed type information is required to be available in the interfaces), these languages support separate compilation
and could, potentially, support modules as first-class values. Modules as first-class values
are fairly useless, however, if modules cannot contain types, because it is not possible in
that case to choose between different ADT implementations at runtime.

14.2.3 Standard ML
Experience with the programming language Standard ML (SML) [21] has provided much
of the motivation for work on higher-order module systems; SML was the first widely
available real programming language with a higher-order module system. SML has a
(mostly) transparent module system that provides modules, submodules, and first-order
functors at a separate module level. This stratification of module-like constructs from
ordinary terms limits modules to being second-class values in SML.

1Caveat: It is possible to get around this problem somewhat by using the System Modeller (a module
configuration language for Cedar)'s ability to treat any module as a Modula-3-like generic module
parameterized by the names of its input and output interfaces; however, this "solution" has the same
flaws as using generic modules (see Section 14.2.1).

2A very weak form of data abstraction -- any module can violate the abstraction by simply declaring

that it wishes to do so -- is available via a weak form of private type declaration.

14.2. PREVIOUS HIGHER-ORDER MODULE SYSTEMS 313

SML has the transparent approach's advantages and disadvantages as described in
Section 2.2 with one exception mentioned below. Unlike in a pure transparent approach,
though, datatype expressions (a core-level data-structure mechanism) and module expressions in SML are generative: Each time they are evaluated, they give rise to a new
instance with a unique identity. This generativity is implemented in the SML type system by means of a complicated, non-declarative, and hard to reason about mechanism
that uses stamps.

The generativity of datatype expressions is present to ensure that types generated
with abstype expressions are abstract: A datatype expression creates at the same time
a new type different from any other and a set of (de)-constructors for constructing and
de-constructing values of that type; an abstype expression can be thought of as sugar for
first declaring a datatype, second, defining some operators using the new datatype, and
third, hiding the datatype's (de)-constructors. This procedure results in a type whose
values can be manipulated only using the previously-defined operations.3

Although intended as a core-level abstraction mechanism, it is possible, though somewhat awkward, to get data abstraction at the module level by either using an abstype
expression directly, or more flexibly, by using a datatype for the representation type of
the ADT then using a type coercion to forget all the (de)-constructors of the datatype
outside of the ADT module. SML, thus, unlike other transparent module systems, has
the advantage of providing a form of module-level data abstraction.

The generativity of modules is only important for structure-sharing specifications,
an SML feature similar to type-sharing specifications that allows requiring that two
submodules of a module are identical (see Section 13.3 for discussion of how structuresharing specifications might be added to my system); because of the generativity of
modules, the test for module identity is not whether or not two modules contain the
same components, but whether or not they were created from the same evaluation step.
Structure-sharing specifications are not considered to be very useful and recent proposals
for new versions of SML [24, 47] suggest dropping them from the language.

In addition to structure-sharing specifications, SML allows type-sharing specifications
(see Section 3.9). SML allows type-sharing specifications to refer only to type names, not
arbitrary type expressions. This restriction prevents SML from giving fully transparent
interfaces in many cases. The lack of fully transparent interfaces, in turn, prevents SML
from providing separate compilation: It is not possible in general to give an interface for
a module that captures all the information the type checker can obtain from inspecting
that module's implementation directly; hence there are legal SML programs that cannot
be divided into module-sized pieces that type check separately.

3Caveat: Abstype and the given desugaring differ on their treatment of equality: abstypes never
admit equality, while the desugaring's result type admits equality iff the underlying datatype does. This
difference cannot be removed because SML does not provide any way to hide automatically-generated
equality functions.

314 CHAPTER 14. RELATED WORK

The New Jersey implementation of SML (SML/NJ, version 0.93) [1] extends SML
in a number of ways. In particular, it adds to the SML module system the ability to
have higher-order functors, although in a way that depends on SML having modules
as second-class values (see Section 14.4), and a way to make selected modules' boundaries opaque, the abstraction binding. Note that because abstraction bindings can only
make a boundary completely opaque, they cannot be used to solve the B-Tree example
or similar problems. SML/NJ also adds additional software support for incremental recompilation [18], which partially makes up for SML/NJ's lack of separate compilation
by reducing the number of unneeded recompilations required. It is still not possible to
compile without implementations of all referenced modules though.

14.2.4 Experimental Designs
Burstall and Lampson's experimental language Pebble [8] is an early transparent design;
unlike later transparent work, it has modules as first-class values. It avoids unsoundness
only because of a lack of effects; Burstall and Lampson suggested that side effects could
be added to Pebble by first extending Pebble's type system to distinguish expressions
that might cause effects from those that could not, and then, second, restricting types
to expressions that could not cause effects. Pebble has no phase distinction and its type
checking problem is undecidable. These problems have lead later researchers to consider
the transparent approach incompatible with modules as first-class values.

Mitchell, et al. [42] consider an extension of the SML module system with firstclass modules as a means of supporting certain object-oriented programming idioms.
Their paper is primarily concerned with illustrating an interesting language design rather
than with the type-theoretic underpinnings of such a language, though a brief sketch is
provided.

Their system is particularly interesting, because like mine, their system displays a
forced loss of typing information when using modules in conditionals and other primitives.
In that system, types are divided into two universes, U1, the universe of "normal" types
like int and bool!int, and U2, the universe of module types. The loss in their system is
caused by the need to apply an implicit coercion from a strong sum (which belongs to
U2) to a weak sum (which belongs to U1) because primitives operate only on terms with
types in U1. This coercion causes a total loss of typing information. My system is more
flexible than this because it only loses just enough information to ensure soundness.

Russell [7] and Poly [39] both seem likely to have some relationship with my system,
but a detailed comparison seems difficult in the absence of a type-theoretical analysis of
these languages (see [25] for an early attempt).

14.3. MANIFEST TYPES 315
14.3 Manifest Types
The most directly relevant work to mine is Xavier Leroy's work on manifest types [31].
This work, done independently, uses similar ideas but differs most fundamentally from
mine in that his system treats modules as second-class values. This choice greatly simplifies the theoretical complexity of his system and holds out the possibility of a decidable
type system if named interfaces are prohibited. (Section 13.8 discusses these matters in
more detail.)

His system also differs from mine in that his system is based on Damas-Milner style
polymorphism [12] and is implicitly typed, while my kernel system is based on Girard's
F! and is explicitly typed. He has not yet provided either a proof of soundness or a
provably-correct type-checking procedure4 for his system.

The two systems also differ due to slightly different type machinery arranged in different ways. For example, Leroy independently invented an operation he calls strengthening
(written A=xae in my notation) which corresponds to the self function in my system. In
Leroy's original formations of manifest types [31, 32], A=xae computes essentially the same
type as my [self=xae]A except for transparent types: My self function leaves transparent
types unchanged ([self=xae]!=A::K? = !=A::K?), while Leroy's original strengthening operation replaces the information already in the transparent type with information
about the name of the type (!=A::K?=xae = !=xae!::K?). In more recent formations
of manifest types [33, 34], Leroy has switched to a version of strengthening that treats
transparent types in the same way as my self function.

Another technical difference is that Leroy combines external and internal names for
modules into a single identifier (written xi where x is the external name and i the internal
one). Leroy's system requires the user to supply only the external name for an identifier,
generating the internal name automatically using stamps: Each time an external name
is bound, it is assigned a fresh internal identifier name; external-name references are
assigned the internal name from the innermost binding of that external name in scope.
This design decision is problematic, however, because it makes it impossible for the user
to refer to outer components shadowed by an inner component with the same external
name (e.g., the example in Section 13.1).

14.4 Modules as Second-Class Values
Since the initial publication of my work on translucent sums [20] and Leroy's work on
manifest types [31], followup work has begun to appear in the literature. A sizeable

4He did give a type checking procedure and a "proof" of its correctness in his paper [31], but both
were later discovered to be flawed.

316 CHAPTER 14. RELATED WORK

I = interface type T; end;
Apply =

functor (F:FUNCTOR(x:I):I, A:I)

F(A);

Int = module type T=int; end;
Bool = module type T=bool; end;

Id = functor (x:I) x;
ConstInt = functor (x:I) Int;

Figure 14.1: Leroy's paradigmatic higher-order functor example
portion of this new work concerns the expressiveness of such systems (translucent module
systems) when modules are second-class values.

Leroy showed in a recent paper [34] that translucent module systems capable (possibly
via extension) of supporting modules as first-class values can express most (unextended)
SML programs5 so long as SML type ascriptions (M : A) are translated to coercion
functors in the obvious way. (The translation is necessary because SML type ascriptions
can drop or reorder components but not forget type information.)

This result, however, does not extend to SML/NJ because the proof breaks down
in the presence of higher-order functors. To see where the problem arises, consider
Figure 14.1, an example due to Leroy [32]. Here we have defined an interface I for
modules that contain a type T and then defined a higher-order functor Apply that takes
a functor (F) mapping I's to I's and an I (A), and returns the result of applying F to
A. The rest of the example is composed of a number of sample modules and functors for
use in testing Apply.

In SML/NJ (assuming the appropriate syntactical translation) and other transparent module systems with higher-order functors, Apply behaves in what MacQueen and
Tofte [38] call a fully-transparent manner: That is, the type checker knows everything
that could be learned from actually executing the functor application(s). In particular,
it knows the following:

Apply(Id; Bool):T = bool
Apply(ConstInt; Bool):T = int

5Leroy's proof does not cover SML code that uses structure sharing or partially-applied higher-order
constructors.

14.4. MODULES AS SECOND-CLASS VALUES 317

SML/NJ is able to infer these type identities because it type checks functor applications by essentially executing them while ignoring any value components. Such execution
must terminate because there are no conditionals or looping mechanisms at the module
level in SML/NJ. By actually executing functor-application expressions, SML/NJ can
figure out the exact identity of the resulting type components. Note, however, that
SML/NJ's ability to do this type-identity computation depends crucially on its knowledge of the exact definition of the functors involved; because this information cannot be
encoded in their types in SML/NJ, many uses of Apply will not type check in SML/NJ
if separately compiled.

In my system and Leroy's original version of manifest types, by contrast, Apply(F,A).T
is always an abstract type, regardless of what F and A are: Apply gets assigned the type

FUNCTOR (F:FUNCTOR (x:I):I, A:I):I
because F(A) is not an extended value. Functors in these systems are thus not fully
transparent in the sense of [38].

This behavior should not be too surprising, however, for the case where modules are
first-class values: There is in general no reasonable way to completely evaluate functor
applications at type-checking time when they may involve conditionals, recursion, and
the computation of arbitrary values. Even approximations of fully-transparent behavior,
such as Leroy's applicative functors (described later in this section), that assume that
types do not depend on runtime values are unsound in the presence of first-class modules.
It may be possible to incorporate such approximations in a system with first-class modules
by distinguishing (via the type system) those functors that do not use modules in a firstclass manner; unsoundness would then be avoided by using the approximation only on
expressions involving those functors.

It is possible, however, to specialize Apply so that it can handle some of the Apply
test cases correctly at the cost of excluding others. For example, we could define the
following specialized versions of Apply:

ApplyId =

functor (F:FUNCTOR(x:I) :I with T=x.T, A:I)

F(A);

ApplyConstInt =

functor (F:FUNCTOR(x:I) :I with T=int, A:I)

F(A);

318 CHAPTER 14. RELATED WORK
Then, under the two translucent systems, we would have that

ApplyId(Id; Int):T = int
ApplyId(Id; Bool):T = bool
ApplyConstInt(ConstInt; Int):T = int
ApplyConstInt(ConstInt; Bool):T = int

However, ApplyId(ConstInt,Int) and ApplyConstInt(Id,Int) fail to type check.

Xavier Leroy has suggested that it may be possible to some degree to use extra
parameterization by possibly-singleton kinds (see Sections 13.4 and 13.8) to produce
more flexible versions of Apply [35]. For example, the following version can act either
like Apply if it is given the kind type as its first argument or like ApplyConstInt if it is
given the singleton kind =int::type as its first argument:

FlexApply =

functor (K:KIND, F:FUNCTOR(x:I) :I with T::K, A:I)

F(A);

Here, I with T::K is intended to denote interface constr T::K; end by analogy with
the usual with notation. FlexApply cannot be made to act like ApplyId though (x.T is
not in scope outside of FlexApply). It is possible that FlexApply could be made still
more flexible by introducing kinds that depend on term variables but this approach seems
to be far more trouble than it is worth.

If modules are restricted to second-class values, the translucent approach can be extended to handle the Apply example in the same way that SML/NJ does. Leroy's work
on applicative functors [32] demonstrates one way to accomplish this. Under this approach, functor applications are assumed to never generate new constructors: Any result
constructor (sub)-component of a functor is assumed to be a (deterministic) function
of the constructors contained in that functor's arguments. Thus, if A = B and F(A).T
is valid then F(A).T must equal F(B).T. This assumption is true in SML/NJ because
SML/NJ has no way to choose a module (and hence its constructors) at runtime.

Leroy noticed that under this assumption he could safely allow the following set of
terms in constructors:

Extended Names , ::= x j ,:y j ,1(,)2
Note that because of the assumption and the fact that we are using call-by-value, the
expression ,:ff must denote a constant constructor during each of its dynamic scopes.

Using this extension to the set of terms legal in constructors, we can give Apply the
following type:

FUNCTOR (F:FUNCTOR (x:I):I, A:I):I with T=F(A).T

14.4. MODULES AS SECOND-CLASS VALUES 319
(Leroy's EVALUE-like rules give F(A) the type I with T=F(A).T in this system.) To
handle type checking Apply(Id,Bool) then, for example, we would first specialize further
Apply's type as follows:

FUNCTOR (F:FUNCTOR (x:I):I, A:I):I with T=F(A).T

FUNCTOR (F:FUNCTOR (x:I):I with T=x.T, A:I)

:I with T=F(A).T

FUNCTOR (F:FUNCTOR (x:I):I with T=x.T, A:I)

:I with T=A.T

The final specialized type is same type as the original translucent systems gave to ApplyId. Accordingly, it can be used to show that

Apply(Id; Int):T = int
Apply(Id; Bool):T = bool

If we wished to type check Apply(ConstInt,Bool).T instead, we would have instead
specialized Apply to the type of ApplyConstInt:

FUNCTOR (F:FUNCTOR (x:I):I with T=int, A:I)

:I with T=int

This method is in fact general and can be used to handle all uses of Apply possible in
SML/NJ.

Leroy's applicative-functor system is thus more fully transparent than either of my
and Leroy's original translucent module systems. Because of the applicative-functor
system's underlying assumptions, functors in that system cannot produce new abstract
types each time they are applied to the same argument. However, this slight loss of
abstractive power over the original systems is unlikely to be problematic in practice.

Leroy's applicative-functor system is not fully transparent, however. Consider the
following more complicated functor:

ApplyList =

functor (F:FUNCTOR(x:I):I, A:I)

F(module type T=list(A.T); end);

Because ApplyList's functor body is not an extended name, ApplyList can only be
given the opaque type

FUNCTOR (F:FUNCTOR (x:I):I, A:I) :I

320 CHAPTER 14. RELATED WORK
Accordingly, ApplyList(Id,Int).T is abstract in this system rather than equal to list(int)
as required by full transparency.

In principle it should be possible to build a system with a rich enough type system so
that both separate compilation and full transparency can be achieved at the same time.
Because separate compilation requires that all information needed for type checking the
uses of a functor be expressible in that functor's interface, this goal will require functor
interfaces to (optionally) contain an idealized copy of the code for the functor whose
behavior they specify. I expect such a system to be highly complicated and hard to
reason about. MacQueen and Tofte [38] have begun to explore how a system with full
transparency might be built.

There thus appears to be a tradeoff in higher-order module systems with second-class
modules between system simplicity and the degree of full transparency provided. Unfortunately, there is as yet no consensus on the value of full transparency to programmers
because of insufficient experience with higher-order functors.

14.5 Other Follow-On Work
Feeling that the type theory of translucent module systems is unnecessarily complicated,
Mark Jones has recently proposed an alternative approach to handling higher-order module systems [27]. He observes that programs written in a SML-like module system without
abstraction or generativity can be translated into a system with no modules or functors
but with (ordinary) records, functions, and universal polymorphism (8ff:A). The translation works by lifting type definitions within a module to the top level, in a manner
similar to *-lifting (see his paper for details). He believes that abstraction can be provided separately, possibly via (opaque) existentials. He thus suggests that we can do
away with modules containing type components entirely, and just program directly in
the translation's target system.

I do not consider his proposed solution satisfactory for three reasons. First, his transform does not respect extended-interface matching: Dropping a type component from
a module does not produce a module whose type is a supertype of the original module's type. Second, his suggested style of programming forces the programmer to place
the type definitions and procedure definitions of a single "module" far apart, violating
the modularity percept that related definitions should be bundled together. Third, and
most crucially, he is mistaken in his belief that abstraction can be separated from where
types are defined: Abstraction via existentials requires that abstract types be defined in
the same place as the operations that implement them while his transformation requires
separating type definitions from the code that uses them; thus, his transformation and
abstraction via existentials are incompatible.

My work has already begun to be used in the design of new programming languages.

14.5. OTHER FOLLOW-ON WORK 321
In [46], John Ophel investigates how a small language with first-class modules based on
translucent sums might be defined and what the consequences of such a language might
be. In [24], Robert Harper and Chris Stone give a type-theoretic semantics for a new
version of SML, SML 1996, using an typed intermediate language with translucent sums.

While SML 1996 is essentially a slightly better tuned and simplified version of the
original SML, work is underway to build a successor language to SML, currently called
ML2000, that will be substantially more powerful than the current SML implementations [17]. ML2000's module system is based on my work on translucent sums. It treats
modules as second-class values in order to keep the type system simple; I feel that this
was a wise choice, given that ML2000's type system also has to deal with object oriented
features, a known source of complexity [47].

322 CHAPTER 14. RELATED WORK
Chapter 15
Conclusions
In this, the final chapter, I sum up the contributions of my dissertation and discuss
possible future work.

15.1 Contributions
This dissertation makes a number of contributions. I divide them up here according to
the area they contribute in.

15.1.1 Better Higher-Order Module Systems
I began this dissertation work with the following thesis:

By basing a module system on a new type-theoretic concept, namely a new
kind of weak sum that can contain both transparent and opaque type definitions called a translucent sum, it is possible to obtain a higher-order module system with the advantages of both the opaque and the transparent approaches, but none of their disadvantages.

I believe I have by now firmly established this thesis. In chapter 3, I showed how my
approach using translucent sums provides the advantages of the opaque approach, namely

ffl (Open) data abstraction is provided at the module level.
ffl Separate compilation is supported.
ffl Modules are first-class values.
as well as the advantages of the transparent approach, namely

323

324 CHAPTER 15. CONCLUSIONS

ffl Modules can "contain" other types.
ffl Modules may export type abbreviations.
Moreover, my approach provides the following additional advantages not available in
either of the two previous approaches:

ffl All of the higher-order idioms work.
ffl Transparency and opacity can be mixed, even in the same module.
My approach also offers the following advantages:

ffl User-defined higher-order constructors are available.
ffl Functors are first-class.
ffl Higher-order functors are provided.
ffl Type-sharing specifications can be encoded.
ffl Linking and separate compilation can be described in the resulting programming

language.

ffl The resulting system has a simple and uniform type theory.
My approach thus represents a major step forward in the design of higher-order
module systems over previous approaches, providing the first truly satisfactory higherorder module system. This is the single biggest contribution of my dissertation.

15.1.2 Feasibility of My Approach
In order to show that these advantages are actually realizable in practice, I need to
show that my approach is feasible. I have done this by creating a complete working
system using my approach -- the kernel system -- and proving that it has the necessary
properties. In particular, I have shown the following:

ffl How to arrange the system and its associated proofs so they are tractable
ffl The system's soundness even in the presence of side effects
ffl How to do type checking effectively by giving:

- a recursive algorithm for constructor and assignment validity
- a recursive algorithm for constructor equality

15.1. CONTRIBUTIONS 325

- a semi-decision procedure for subtyping
- a proof that type checking is decidable, given an oracle for subtyping
- a semi-decision procedure for type checking
- an argument that the semi-decidability of type checking is not likely to be

problem in practice

All of these represent contributions of my dissertation; the first item above is particularly
important because of the complexity of systems providing translucent sums. I expect that
this dissertation, especially the section on recommended improvements (Section 9.7), will
prove invaluable to future designers of systems with translucent sums. In additional to
being useful as a starting point for building extended systems, my kernel system is likely
to be useful as a reduction target because of these proven properties; for example, I
expect that the soundness of Xavier Leroy's system [31] can be established in this way
far more easily than if it was proved directly.

The negative results about soundness under certain extensions, the decidability of
subtyping (and hence type checking), and the existence of principle types if implicit
subsumption is permitted are also contributions of my dissertation. Similarly to the case
with the full kernel system, I expect that the simple system (see Section 10.6) will be
useful in proving subtyping in other systems with translucent sums undecidable.

15.1.3 Technical Contributions
My dissertation also contains a number of more technical contributions. The most obvious
of these are a large number of properties about the kernel system's type system that are
useful in reasoning about the kernel system. For example, I have shown that in the kernel
system all of the following operations preserve judgment validity:

ffl weakening (adding extra declarations to assignments)
ffl strengthening (removing unreferenced declarations from assignments)
ffl replacing a type in an assignment by a subtype
ffl subject reduction on constructors
Several of the techniques I used to make the proofs more tractable are also noteworthy:
ffl Specializing the well-typed term judgment to places so that the constructor validity

and equality judgments do not depend on term validity or subtyping judgments

ffl Using the self function to normalize typing derivations

326 CHAPTER 15. CONCLUSIONS

ffl Defining subtyping as a series of equality and one-step subtyping steps
ffl Factoring translucent sums into dependent sums plus reified constructors
ffl Introducing a separate tagged system to remove the dependency of rewriting (and

hence equality) on assignments

The first three of these techniques are tied fairly closely to systems involving translucent
sums. However, the fourth technique, factoring, could be used to simplify any system
with modules or sums that allow fields to contain either terms or types, and the fifth
technique, the use of a tagged system, could be applied usefully in any system where the
rewriting of constructors depends on the assignment.

15.2 Future work
One obvious piece of future work would be to construct a prototype based on the kernel
system, but with a more programmer-friendly interface. Ideally, some form of type inference would be devised for the prototype so as to reduce the amount of type information
that would need to be given by the programmer. The prototype would be especially
useful in evaluating the value of having modules as first-class values; exploration with
the prototype might well lead to the discovery of useful new higher-order-module idioms.

The two extensions to the kernel system that I think are the most interesting to pursue
are adding reordering via an elaboration stage (this will require determining the proper
reordering rule(s) for subtyping), and adding transparent value declarations to permit
inlining. I also think that it is worth investigating the relationship between first-class
modules and objects in more detail.

Appendix A
Collected Kernel System Rules

A.1 The Kind and Constructor Level
Definition A.1.1 (Syntax for the constructor and kind levels)

Kinds K ::= \Omega  j K)K0
Constructors A ::= ff j \Pi x:A: A0 j \Sigma x:A: A0 j *ff::K: A j A A0 j

!K? j !=A::K? j xae! j rec j ref
Paths ae ::= ffl j ae:1 j ae:2

Assignments \Gamma  ::= ffl j \Gamma ; D
Declarations D ::= ff::K j x:A

327

328 APPENDIX A. COLLECTED KERNEL SYSTEM RULES
Definition A.1.2 (Free constructor variables)

FCV(ff) = fffg
FCV(*ff::K: A) = FCV(A) \Gamma  fffg
FCV(\Pi x:A1: A2) = FCV(A1) [ FCV(A2)
FCV(\Sigma x:A1: A2) = FCV(A1) [ FCV(A2)

FCV(A1 A2) = FCV(A1) [ FCV(A2)
FCV(!=A::K?) = FCV(A)

FCV(!K?) = ;

FCV(xae!) = ;
FCV(rec) = ;

FCV(ref) = ;

FCV(ff::K) = ;

FCV(x:A) = FCV(A)

FCV(ffl) = ;
FCV(\Gamma ; D) = FCV(\Gamma ) [ FCV(D)

Definition A.1.3 (Free term variables)

FTV(xae!) = fxg
FTV(\Pi x:A1: A2) = FTV(A1) [ (FTV(A2) \Gamma  fxg)
FTV(\Sigma x:A1: A2) = FTV(A1) [ (FTV(A2) \Gamma  fxg)

FTV(*ff::K: A) = FTV(A)

FTV(A1 A2) = FTV(A1) [ FTV(A2)
FTV(!=A::K?) = FTV(A)

FTV(ff) = ;
FTV(!K?) = ;

FTV(rec) = ;

FTV(ref) = ;

FTV(ff::K) = ;

FTV(x:A) = FTV(A)

FTV(ffl) = ;
FTV(\Gamma ; D) = FTV(\Gamma ) [ FTV(D)

A.1. THE KIND AND CONSTRUCTOR LEVEL 329
Definition A.1.4 (Constructor substitution)

[A=ff]ff = A
[A=ff]ff0 = ff0 (ff 6= ff0)
[A=ff]*ff0::K: A0 = *ff0::K : [A=ff]A0 (ff0 6= ff; ff0 62 FCV(A))
[A=ff]\Pi x:A1: A2 = \Pi x:[A=ff]A1: [A=ff]A2 (x 62 FTV(A))

[A=ff]\Sigma x:A1: A2 = \Sigma x:[A=ff]A1: [A=ff]A2 (x 62 FTV(A))

[A=ff](A1 A2) = [A=ff]A1 [A=ff]A2
[A=ff]!=A0::K? = !=[A=ff]A0::K ?

[A=ff]!K? = !K?

[A=ff]xae! = xae!
[A=ff]rec = rec

[A=ff]ref = ref

[A=ff](ff0::K) = ff0::K

[A=ff](x:A0) = x:[A=ff]A0

[A=ff]ffl = ffl
[A=ff](\Gamma ; D) = ([A=ff]\Gamma ); [A=ff]D

Definition A.1.5 (Place substitution)

[xae=x0]x0ae0 = xaeae0
[xae=x0]x00ae00 = x00ae00 (x0 6= x00)

[xae=x0](x00ae00!) = ([xae=x0]x00ae00)!
[xae=x0]\Pi x00:A1: A2 = \Pi x00:[xae=x0]A1: [xae=x0]A2 (x00 6= x; x00 6= x0)
[xae=x0]\Sigma x00:A1: A2 = \Sigma x00:[xae=x0]A1: [xae=x0]A2 (x00 6= x; x00 6= x0)

[xae=x0]*ff::K: A = *ff::K: [xae=x0]A

[xae=x0](A1 A2) = [xae=x0]A1 [xae=x0]A2
[xae=x0]!=A0::K? = !=[xae=x0]A0::K?

[xae=x0]ff = ff
[xae=x0]!K ? = !K?

[xae=x0]rec = rec

[xae=x0]ref = ref

[xae=x0](ff::K) = ff::K

[xae=x0](x00:A) = x00:[xae=x0]A

[xae=x0]ffl = ffl
[xae=x0](\Gamma ; D) = ([xae=x0]\Gamma ); [xae=x0]D

330 APPENDIX A. COLLECTED KERNEL SYSTEM RULES
Definition A.1.6 (Selection)

S(A; xae; ffl) = A

S(\Sigma x0:A1: A2; xae; :1ae0) = S(A1; xae:1; ae0)
S(\Sigma x0:A1: A2; xae; :2ae0) = S([xae:1=x0]A2; xae:2; ae0)

Definition A.1.7 (Assignment regarded as a partial function)

dom(ffl) = ;
dom(\Gamma ; x:A) = dom(\Gamma ) [ fxg
dom(\Gamma ; ff::K ) = dom(\Gamma ) [ fffg

(\Gamma 1; x:A; \Gamma 2)(x) = A (x 62 dom(\Gamma 1))
Definition A.1.8 (Arrow types)
The arrow type A!A0 is defined to be equal to \Pi x:A: A0 where x 62 FTV(A0). The arrow
operator (!) is defined to have lower precedence than application (A1A2).

Definition A.1.9 (Pair types)
The pair type (A; A0) is defined to be equal to \Sigma x:A: A0 where x 62 FTV(A0).

Definition A.1.10 (Polymorphic types)
The polymorphic type 8ff::K:A is defined to be equal to \Pi x:!K?: [x!=ff]A where x 62
FTV(A).

Definition A.1.11 (Judgments)

` \Gamma  valid valid assignment

\Gamma  ` A :: K valid constructor
\Gamma  ` A = A0 :: K equal constructors

\Gamma  ` A ^ A0 subtype relation

\Gamma  ` xae ) A place lookup

\Gamma  ` A ! A0 one-step subtype relation

Definition A.1.12 (Assignment Formation Rules)

` ffl valid (EMPTY)

` \Gamma  valid ff 62 dom(\Gamma )

` \Gamma ; ff::K valid (DECL-C)

A.1. THE KIND AND CONSTRUCTOR LEVEL 331

\Gamma  ` A :: \Omega  x 62 dom(\Gamma )

` \Gamma ; x:A valid (DECL-T)

Definition A.1.13 (Constructor Formation Rules)

` \Gamma  valid ff::K 2 \Gamma 

\Gamma  ` ff :: K (C-VAR)

\Gamma ; x:A ` A0 :: \Omega 
\Gamma  ` \Pi x:A: A0 :: \Omega  (C-DFUN)

\Gamma ; x:A ` A0 :: \Omega 
\Gamma  ` \Sigma x:A: A0 :: \Omega  (C-DSUM)

\Gamma ; ff::K ` A :: K0
\Gamma  ` *ff::K: A :: K)K 0 (C-LAM)

\Gamma  ` A1 :: K2)K \Gamma  ` A2 :: K2

\Gamma  ` A1 A2 :: K (C-APP)

` \Gamma  valid
\Gamma  ` !K? :: \Omega  (C-OPAQ)

\Gamma  ` A :: K
\Gamma  ` !=A::K? :: \Omega  (C-TRANS)

\Gamma  ` xae ) !K?

\Gamma  ` xae! :: K (C-EXT-O)

\Gamma  ` xae ) !=A::K?

\Gamma  ` xae! :: K (C-EXT-T)

` \Gamma  valid
\Gamma  ` rec :: (\Omega )\Omega ))\Omega  (C-REC)

` \Gamma  valid
\Gamma  ` ref :: \Omega )\Omega  (C-REF)

332 APPENDIX A. COLLECTED KERNEL SYSTEM RULES
Definition A.1.14 (Constructor Equality Rules)

\Gamma  ` A :: K
\Gamma  ` A = A :: K (E-REFL)

\Gamma  ` A0 = A :: K
\Gamma  ` A = A0 :: K (E-SYM)

\Gamma  ` A = A0 :: K \Gamma  ` A0 = A00 :: K

\Gamma  ` A = A00 :: K (E-TRAN)

\Gamma  ` A1 = A01 :: \Omega 
\Gamma ; x:A1 ` A2 = A02 :: \Omega 
\Gamma  ` \Pi x:A1: A2 = \Pi x:A01: A02 :: \Omega  (E-DFUN)

\Gamma  ` A1 = A01 :: \Omega 
\Gamma ; x:A1 ` A2 = A02 :: \Omega 
\Gamma  ` \Sigma x:A1: A2 = \Sigma x:A01: A02 :: \Omega  (E-DSUM)

\Gamma ; ff::K ` A = A0 :: K0
\Gamma  ` *ff::K: A = *ff::K: A0 :: K )K0 (E-LAM)

\Gamma  ` A2 = A02 :: K
\Gamma  ` A1 = A01 :: K)K 0
\Gamma  ` A1 A2 = A01 A02 :: K0 (E-APP)

\Gamma  ` A = A0 :: K
\Gamma  ` !=A::K? = !=A0::K? :: \Omega  (E-TRANS)

\Gamma ; ff::K ` A :: K0 \Gamma  ` A0 :: K
\Gamma  ` (*ff::K: A) A0 = [A0=ff]A :: K0 (E-BETA)

\Gamma  ` A :: K)K0 ff 62 FCV(A)

\Gamma  ` *ff::K : A ff = A :: K)K 0 (E-ETA)

\Gamma  ` xae! :: K \Gamma  ` xae ) A \Gamma  ` A = !=A0::K0? :: \Omega 

\Gamma  ` xae! = A0 :: K (E-ABBREV)

Definition A.1.15 (Place Lookup Rules)

` \Gamma  valid x:A 2 \Gamma 

\Gamma  ` x ) A (P-INIT)

A.2. THE TERM LEVEL 333

\Gamma  ` xae ) A \Gamma  ` A = A0 :: \Omega  A00 = S(A0; xae; ae0)

\Gamma  ` xaeae0 ) A00 (P-MOVE)

Definition A.1.16 (Subtyping Rules)

\Gamma  ` A = A0 :: \Omega 

\Gamma  ` A ^ A0 (S-EQ)

\Gamma  ` A ! A0
\Gamma  ` A ^ A0 (S-ONE)

\Gamma  ` A ^ A0 \Gamma  ` A0 ^ A00

\Gamma  ` A ^ A00 (S-TRAN)

Definition A.1.17 (One-Step Subtyping Rules)

\Gamma  ` A :: \Omega 
\Gamma  ` A ! A (O-REFL)

\Gamma  ` A01 ! A1
\Gamma ; x:A01 ` A2 ! A02 \Gamma ; x:A1 ` A2 :: \Omega 

\Gamma  ` \Pi x:A1: A2 ! \Pi x:A01: A02 (O-DFUN)

\Gamma  ` A1 ! A01
\Gamma ; x:A1 ` A2 ! A02 \Gamma ; x:A01 ` A02 :: \Omega 

\Gamma  ` \Sigma x:A1: A2 ! \Sigma x:A01: A02 (O-DSUM)

\Gamma  ` A :: K
\Gamma  ` !=A::K? ! !K ? (O-FORGET)

A.2 The Term Level
Definition A.2.1 (Syntax for the term level)

Terms M ::= x j *x:A: M j M 1 M 2 j (M 1; M 2) j M :1 j M :2 j !A? j

M !:A j roll j unroll j new j get j set

334 APPENDIX A. COLLECTED KERNEL SYSTEM RULES
Definition A.2.2 (Free constructor variables)

FCV(x) = ;
FCV(roll) = ;
FCV(unroll) = ;

FCV(new) = ;

FCV(get) = ;

FCV(set) = ;

FCV(M :1) = FCV(M )
FCV(M :2) = FCV(M )
FCV(!A?) = FCV(A)

FCV(*x:A: M ) = FCV(A) [ FCV(M )

FCV(M !:A) = FCV(M ) [ FCV(A)
FCV(M 1 M 2) = FCV(M 1) [ FCV(M 2)
FCV((M 1; M 2)) = FCV(M 1) [ FCV(M 2)

Definition A.2.3 (Free term variables)

FTV(x) = fxg
FTV(*x:A: M ) = FTV(A) [ (FTV(M ) \Gamma  fxg)

FTV(roll) = ;
FTV(unroll) = ;

FTV(new) = ;

FTV(get) = ;

FTV(set) = ;

FTV(M :1) = FTV(M )
FTV(M :2) = FTV(M )
FTV(!A?) = FTV(A)

FTV(M 1 M 2) = FTV(M 1) [ FTV(M 2)
FTV((M 1; M 2)) = FTV(M 1) [ FTV(M 2)

FTV(M !:A) = FTV(M ) [ FTV(A)

Definition A.2.4 (Judgments)

\Gamma  ` M : A well-typed term

A.2. THE TERM LEVEL 335
Definition A.2.5 (Term Formation Rules)

\Gamma  ` \Gamma (x) = A :: \Omega 

\Gamma  ` x : [self=x]A (T-VAR)

\Gamma ; x:A ` M : A0
\Gamma  ` *x:A: M : \Pi x:A: A0 (T-LAM)

\Gamma  ` M 1 : A2!A \Gamma  ` M 2 : A2

\Gamma  ` M 1 M 2 : A (T-APP)

\Gamma  ` M 1 : A1 \Gamma  ` M 2 : A2

\Gamma  ` (M 1; M 2) : (A1; A2) (T-PAIR)

\Gamma  ` M : \Sigma x:A1: A2

\Gamma  ` M :1 : A1 (T-FST)

\Gamma  ` M : (A1; A2)

\Gamma  ` M :2 : A2 (T-SND)

\Gamma  ` A :: K
\Gamma  ` !A? : !=A::K? (T-REIFY)

\Gamma  ` M : A0 \Gamma  ` A0 ^ A

\Gamma  ` M : A (T-SUMP)

\Gamma  ` M : A
\Gamma  ` M !:A : A (T-COERCE)

` \Gamma  valid
\Gamma  ` new : 8ff::\Omega :ff!ref ff (T-NEW)

` \Gamma  valid
\Gamma  ` get : 8ff::\Omega :ref ff!ff (T-GET)

` \Gamma  valid
\Gamma  ` set : 8ff::\Omega :ref ff!(ff!ff) (T-SET)

` \Gamma  valid
\Gamma  ` roll : 8ff::\Omega )\Omega :ff (rec ff)!rec ff (T-ROLL)

` \Gamma  valid
\Gamma  ` unroll : 8ff::\Omega )\Omega :rec ff!ff (rec ff) (T-UNROLL)

336 APPENDIX A. COLLECTED KERNEL SYSTEM RULES
Definition A.2.6 (Self function)

[self=xae]!K? = !=xae!::K?
[self=xae]\Sigma x0:A1: A2 = \Sigma x0:[self=xae:1]A1: [self=xae:2]A2; where x 6= x0

[self=xae]ff = ff
[self=xae]\Pi x0:A1: A2 = \Pi x0:A1: A2

[self=xae]*ff::K: A = *ff::K: A

[self=xae]A1 A2 = A1 A2
[self=xae]!=A::K? = !=A::K?

[self=xae]x0ae0! = x0ae0!

[self=xae]rec = rec

[self=xae]ref = ref

Bibliography

[1] Andrew W. Appel and David B. MacQueen. Standard ML of New Jersey. In

J. Maluszynski and M. Wirsing, editors, Third Int'l Symp. on Prog. Lang. Implementation and Logic Programming, pages 1-13, New York, August 1991. SpringerVerlag.

[2] Henk P. Barendregt. The Lambda Calculus: Its Syntax and Semantics, volume 103

of Studies in Logic and the Foundations of Mathematics. North-Holland, revised
edition, 1984.

[3] Richard J. Beach. Experience with the Cedar programming environment for computer graphics research. Technical Report CSL-84-6, Xerox Corporation, Palo Alto,
July 1985.

[4] Edoardo Biagioni. A structured TCP in Standard ML. In Sigcomm '94, London,

England, August/September 1994.

[5] Edoardo Biagioni, Robert Harper, and Peter Lee. Standard ML signatures for a

protocol stack. Technical Report CMU-CS-93-170, School of Computer Science,
Carnegie Mellon University, Pittsburgh, PA, July 1993. (Also published as Fox
Memorandum CMU-CS-FOX-93-01).

[6] Edoardo Biagioni, Robert Harper, Peter Lee, and Brian G. Milnes. Signatures for a

network protocol stack: A systems application of Standard ML. In ACM Conference
on LISP and Functional Programming, Orlando, Florida, June 1994.

[7] Hans-J"urgen B"ohm, Alan Demers, and James Donahue. An informal description of

Russell. Technical Report 80-430, Computer Science Department, Cornell University, Ithaca, New York, 1980.

[8] Rod Burstall and Butler Lampson. A kernel language for abstract data types and

modules. In Kahn et al. [28], pages 1-50.

337

338 BIBLIOGRAPHY

[9] Luca Cardelli. Structural subtyping and the notion of power type. In Fifteenth ACM

Symposium on Principles of Programming Languages, San Diego, California, 1988.
ACM.

[10] Luca Cardelli. Typeful programming. Technical Report 45, DEC Systems Research

Center, 1989.

[11] Luca Cardelli and Xavier Leroy. Abstract types and the dot notation. Technical

Report 56, DEC Systems Research Center, Palo Alto, CA, March 1990.

[12] Luis Damas and Robin Milner. Principal type schemes for functional programs. In

Ninth ACM Symposium on Principles of Programming Languages, pages 207-212,
1982.

[13] Charles M. Geschke, James H. Morris Jr., and Edwin H. Satterthwaite. Early experience with Mesa. Technical Report CSL-76-6, Xerox Corporation, Palo Alto,
October 1976.

[14] Herman Geuvers. The Church-Rosser property for fij-reduuction in typed *-calculi.

In Seventh Symposium on Logic in Computer Science, pages 453-460, Santa Cruz,
California, June 1992.

[15] Jean-Yves Girard. Interpr'etation Fonctionnelle et 'Elimination des Coupures dans

l'Arithm'etique d'Ordre Sup'erieure. PhD thesis, Universit'e Paris VII, 1972.

[16] Robert Harper. Personal communication, 1993.
[17] Robert Harper. A propsoal for ML2000 (draft of december 16, 1994). (Unpublished),

December 1994.

[18] Robert Harper, Peter Lee, Frank Pfenning, and Eugene Rollins. Incremental recompilation for Standard ML of New Jersey. Technical Report CMU-CS-94-116, School
of Computer Science, Carnegie Mellon University, Pittsburgh, PA, February 1994.
(Also published as Fox Memorandum CMU-CS-FOX-94-02; to appear Workshop
on ML, Orlando, FL, June, 1994.).

[19] Robert Harper and Mark Lillibridge. Explicit polymorphism and CPS conversion. In

Twentieth ACM Symposium on Principles of Programming Languages, pages 206-
219, Charleston, SC, January 1993. ACM, ACM.

[20] Robert Harper and Mark Lillibridge. A type-theoretic approach to higher-order modules with sharing. In Twenty-first ACM Symposium on Principles of Programming
Languages, pages 123-137, Portland, OR, January 1994.

BIBLIOGRAPHY 339
[21] Robert Harper, Robin Milner, and Mads Tofte. The definition of Standard ML

(version 3). Technical Report ECS-LFCS-89-81, Laboratory for the Foundations of
Computer Science, Edinburgh University, May 1989.

[22] Robert Harper, John C. Mitchell, and Eugenio Moggi. Higher-order modules and the

phase distinction. In Seventeenth ACM Symposium on Principles of Programming
Languages, San Francisco, CA, January 1990.

[23] Robert Harper and Greg Morrisett. Compiling polymorphism using intensional type

analysis. In Twenty-second ACM Symposium on Principles of Programming Languages, pages 130-141, San Francisco, CA, January 1995.

[24] Robert Harper and Chris Stone. A type-theoretic account of Standard ML 1996

(version 2). Technical Report CMU-CS-96-136R, Carnegie Mellon University, Pittsburgh, PA, 1996.

[25] James G. Hook. Understanding Russell: A first attempt. In Kahn et al. [28], pages

69-85.

[26] K. Jensen. Pascal User Manual and Report. Springer-Verlag, 1978. (2nd edition).
[27] Mark P. Jones. Using parameterized signatures to express modular structure. In

Twenty-Third ACM Symposium on Principles of Programming Languages, pages
21-24, St. Petersburg Beach, FL, January 1996. ACM Press.

[28] Gilles Kahn, David MacQueen, and Gordon Plotkin, editors. Semantics of Data

Types, volume 173 of Lecture Notes in Computer Science. Springer-Verlag, June
1984.

[29] Brian W. Kernighan and Dennis M. Ritchie. The C Programming Language.

Prentice-hall, Inc., 1978.

[30] Butler W. Lampson. A description of the Cedar language: A Cedar language reference manual. Technical Report CSL-83-15, Xerox Corporation, Palo Alto, December
1983.

[31] Xavier Leroy. Manifest types, modules, and separate compilation. In Proceedings of

the Twenty-first Annual ACM Symposium on Principles of Programming Languages,
Portland, pages 109-122. ACM, January 1994.

[32] Xavier Leroy. Applicative functors and fully transparent higher-order modules. In

Conference Record of POPL '95: ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 142-153, San Francisco, CA, January 1995.

340 BIBLIOGRAPHY
[33] Xavier Leroy. A modular module system. Research report 2866, INRIA, April 1996.
[34] Xavier Leroy. A syntactic theory of type generativity and sharing. Journal of

Functional Programming, 6(5):667-698, 1996.

[35] Mark Lillibridge, Zhong Shao, and Robert Harper. Minutes of the ML2000 meeting

at Portland, Oregon on January 16, 1994. Unpublished, 1994.

[36] Barbara Liskov, Russell Atkinson, et al. CLU Reference Manual, volume 114 of

Lecture Notes in Computer Science. Springer-Verlag, 1981.

[37] David MacQueen. Using dependent types to express modular structure. In Thirteenth ACM Symposium on Principles of Programming Languages, 1986.

[38] David B. MacQueen and Mads Tofte. A semantics for higher-order functors. In

D. Sannella, editor, Programming Languages and Systems -- ESOP '94, volume 788
of Lecture Notes in Computer Science, pages 409-423. Springer-Verlag, 1994.

[39] David C. J. Matthews. POLY report. Technical Report 28, Computer Laboratory,

University of Cambridge, 1982.

[40] James G. Mitchell, William Maybury, and Richard Sweet. Mesa language manual.

Technical Report CSL-78-1, Xerox Corporation, Palo Alto, February 1978.

[41] John Mitchell and Robert Harper. The essence of ML. In Fifteenth ACM Symposium

on Principles of Programming Languages, San Diego, California, January 1988.

[42] John Mitchell, Sigurd Meldal, and Neel Madhav. An extension of Standard ML modules with subtyping and inheritance. In Eighteenth ACM Symposium on Principles
of Programming Languages, January 1991.

[43] John C. Mitchell and Gordon Plotkin. Abstract types have existential type. In

Twelfth ACM Symposium on Principles of Programming Languages, 1985.

[44] John Gregory Morrisett. Compiling with Types. PhD thesis, School of Computer

Science, Carnegie Mellon University, Pittsburgh, PA, December 1995. (Available as
Carnegie Mellon University School of Computer Science technical report CMU-CS-
95-226.).

[45] Greg Nelson, editor. Systems Programming with Modula-3. Prentice-Hall, Englewood

Cliffs, NJ, 1991.

[46] John Ophel. A polymorphic language with first-class modules. Australian Computer

Science Communications, 17(1):422-430, February 1995.

BIBLIOGRAPHY 341
[47] Amit Patel and Chris Stone. Minutes of the ML2000 meeting at King's Beach, CA.

(Unpublished), August 1996.

[48] Frank Pfenning. Partial polymorphic type inference and higher-order unification.

In Proceedings of the 1988 ACM Conference on Lisp and Functional Programming,
pages 153-163, Snowbird, Utah, July 1988. ACM Press.

[49] Frank Pfenning and Peter Lee. LEAP: A language with eval and polymorphism.

In TAPSOFT '89, Proceedings of the International Joint Conference on Theory and
Practice in Software Development, Barcelona, Spain, pages 345-359. Springer-Verlag
LNCS 352, March 1989.

[50] Benjamin Pierce. Bounded quantification is undecidable. In Proceedings of the

Nineteenth Annual ACM Symposium on Principles of Programming Languages, Albuquerque. ACM, January 1992.

[51] Benjamin C. Pierce. Programming with Intersection Types and Bounded Polymorphism. PhD thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, December 1991.

[52] I. C. Pyle. The Ada Programming Language. Prentice-Hall International, 1981.
[53] Bjarne Stroustrup. The C++ Programming Language. Addison-Wesley Publishing

Company, 1987.

[54] Daniel C. Swinehart, Polle T. Zellweger, Richard J. Beach, and Robert B. Hagmann.

A structural view of the Cedar programming environment. Technical Report CSL86-1, Xerox Corporation, Palo Alto, June 1986.

[55] Warren Teitelman. The Cedar programming environment: A midterm report and

examination. Technical Report CSL-83-11, Xerox Corporation, Palo Alto, June
1984.

[56] Niklaus Wirth. Programming in Modula-2. Texts and Monographs in Computer

Science. Springer-Verlag, 1983.