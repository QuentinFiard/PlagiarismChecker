

Stream Fusion
From Lists to Streams to Nothing at All

Duncan Coutts1 Roman Leshchinskiy2 Don Stewart2

1 Programming Tools Group 2 Computer Science & Engineering

Oxford University Computing Laboratory University of New South Wales

duncan.coutts@comlab.ox.ac.uk {rl,dons}@cse.unsw.edu.au

Abstract
This paper presents an automatic deforestation system, stream fu-sion, based on equational transformations, that fuses a wider range

of functions than existing short-cut fusion systems. In particular,stream fusion is able to fuse zips, left folds and functions over
nested lists, including list comprehensions. A distinguishing fea-ture of the framework is its simplicity: by transforming list functions to expose their structure, intermediate values are eliminatedby general purpose compiler optimisations.

We have reimplemented the Haskell standard List library on topof our framework, providing stream fusion for Haskell lists. By allowing a wider range of functions to fuse, we see an increase in thenumber of occurrences of fusion in typical Haskell programs. We
present benchmarks documenting time and space improvements.
Categories and Subject Descriptors D.1.1 [Programming Tech-niques]: Applicative (Functional) Programming; D.3.4 [Programming Languages]: Optimization
General Terms Languages, Algorithms
Keywords Deforestation, program optimisation, program trans-formation, program fusion, functional programming

1. Introduction
Lists are the primary data structure of functional programming. Inlazy languages, such as Haskell, lists also serve in place of traditional control structures. It has long been recognised that com-posing list functions to build programs in this style has advantages
for clarity and modularity, but that it incurs some runtime penalty,as functions allocate intermediate values to communicate results.
Fusion (or deforestation) attempts to remove the overhead of pro-gramming in this style by combining adjacent transformations on
structures to eliminate intermediate values.Consider this simple function which uses a number of intermediate lists:

f :: Int ! Int
f n = sum [ k d^ m | k A~ [1..n], m A~ [1..k] ]

Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citationon the first page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior specific permission and/or a fee.
ICFP'07, October 1-3, 2007, Freiburg, Germany.Copyright (C) 2007 ACM 978-1-59593-815-2/07/0010. . . $5.00.

No previously implemented short-cut fusion system eliminates allthe lists in this example. The fusion system presented in this paper
does. With this system, the Glasgow Haskell Compiler (The GHCTeam 2007) applies all the fusion transformations and is able to
generate an efficient "worker" function f 0 that uses only unboxedintegers (

Int#) and runs in constant space:

f 0 :: Int# ! Int#
f 0 n =

let go :: Int# ! Int# ! Int#

go z k =

case k > n of

False ! case 1 > k of

False ! to (z + k) k (k + 1) 2
True ! go z (k + 1)True ! z

to :: Int# ! Int# ! Int# ! Int# ! Int#
to z k k0 m =

case m > k of

False ! to (z + (k d^ m)) k k0 (m + 1)
True ! go z k0in go 0 1

Stream fusion takes a simple three step approach:

1. Convert recursive structures into non-recursive co-structures;
2. Eliminate superfluous conversions between structures and co-structures;

3. Finally, use general optimisations to fuse the co-structure code.

By transforming pipelines of recursive list functions into non-recursive ones, code becomes easier to optimise, producing better
results. The ability to fuse all common list functions allows the pro-grammer to write in an elegant declarative style, and still produce
excellent low level code. We can finally write the code we want tobe able to write without sacrificing performance!

1.1 Short-cut fusion
The example program is a typical high-level composition of listproducers, transformers and consumers. However, extensive optimisations are required to transform programs written in this styleinto efficient low-level code. In particular, naive compilation will
produce a number of intermediate data structures, resulting in poorperformance. We would like to have the compiler remove these
intermediate structures automatically. This problem, deforesta-tion (Wadler 1990), has been studied extensively (Meijer et al.
1991; Gill et al. 1993; Takano and Meijer 1995; Gill 1996; Huet al. 1996; Chitil 1999; Johann 2001; Svenningsson 2002; Gibbons
2004). To illustrate how our approach builds on previous work onshort-cut fusion, we review the main approaches.

build/foldr The most practically successful list fusion system todate is the build/foldr system (Gill et al. 1993). It uses two combinators, foldr and build, and a single fusion rule to eliminate adjacentoccurrences of the combinators. Fusible functions must be written
in terms of these two combinators. A range of standard list func-tions, and list comprehensions, can be expressed and effectively
fused in this way.There are some notable exceptions that cannot be effectively
fused under build/foldr: left folds (foldl) (functions such as sumthat consume a list using an accumulating parameter), and zips
(functions that consume multiple lists in parallel).
destroy/unfoldr A more recent proposal (Svenningsson 2002)based on unfolds rather than folds addresses these specific shortcomings. However, as proposed, it does not cover functions thathandle nested lists (such as

concatMap) or list comprehensions,and there are inefficiencies fusing

r'lter-like functions, which mustbe defined recursively.

stream fusion Recently, we proposed a new fusion framework foroperations on strict arrays (Coutts et al. 2007). While the performance improvements demonstrated for arrays are significant, thisprevious work describes fusion for only relatively simple operations: maps, filters and folds. It does not address concatenations,functions on nested lists, or zips.

In this paper we extend stream fusion to fill in the missing pieces.Our main contributions are:

* an implementation of stream fusion for lists (Section 2);

* extension of stream fusion to zips, concats, appends (Section 3)and functions on nested lists (Section 4);

* a translation scheme for stream fusion of list comprehensions(Section 5);

* an account of the compiler optimisations required to remove

intermediate structures produced by fusion, including functionson nested lists (Section 7);

* an implementation of stream fusion using compiler rewrite rulesand concrete results from a complete implementation of the

Haskell list library (Section 8).
2. Streams
The intuition behind build/foldr fusion is to view lists as sequencesrepresented by data structures, and to fuse functions that work

directly on the natural structure of that data. The destroy/unfoldrand stream fusion systems take the opposite approach. They convert
operations over the list data structure to instead work over the dualof the list: its unfolding or co-structure.

In contrast to destroy/unfoldr, stream fusion uses an explicit rep-resentation of the sequence co-structure: the

Stream type. Separatefunctions,
stream and unstream, are used to convert between listsand streams.

2.1 Converting lists to streams
The first step in order to fuse list functions with stream fusion isto convert a function on list structures to a function on stream costructures (and back again) using stream and unstream combina-tors. The function map, for example, is simply specified as:

map :: (a ! b) ! [a] ! [b]
map f = unstream c' maps f c' stream

which composes a map function over streams, with stream conver-sion to and from lists.

While the natural operation over a list data structure is a fold,the natural operation over a stream co-structure is an unfold. The
Stream type encapsulates an unfold, wrapping an initial state anda stepper function for producing elements. It is defined as:

data Stream a = 9s. Stream (s ! Step a s) s
data Step a s = Done|

Yield a s|
Skip s

Note that the type of the stream state is existentially quantifiedand does not appear in the result type: the stream state is encapsulated. The Stream data constructor itself is similar to the standardHaskell list function unfoldr (Gibbons and Jones 1998),

Stream :: 8s a. (s ! Step a s) ! s ! Stream a
unfoldr :: 8s a. (s ! Maybe (a, s)) ! s ! [a]

Writing functions over streams themselves is relatively straight-forward. map, for example, simply applies its function argument to

each yielded stream element, when the stepper is called:

maps :: (a ! b) ! Stream a ! Stream b
maps f (Stream next0 s0) = Stream next s0

where

next s = case next0 s of

Done ! Done
Skip s0 ! Skip s0
Yield x s0 ! Yield (f x ) s0

The stream function can be defined directly as a stream whoseelements are those of the corresponding list. It uses the list itself as

the stream state. It is of course non-recursive yielding each elementof the list as it is unfolded:

stream :: [a] ! Stream a
stream xs0 = Stream next xs0

where

next [ ] = Done
next (x : xs) = Yield x xs

The unstream function unfolds the stream and builds a liststructure. Unfolding a stream to produce a list is achieved by

repeatedly calling the stepper function of the stream, to yield thestream's elements.

unstream :: Stream a ! [a]
unstream (Stream next0 s0) = unfold s0

where

unfold s = case next0 s of

Done ! [ ]
Skip s0 ! unfold s0
Yield x s0 ! x : unfold s0

In contrast to unfoldr, the Stream stepper function has oneother alternative, it can

Skip, producing a new state but yielding nonew value in the sequence. This is not necessary for the semantics

but as we shall show later, is crucial for the implementation. Inparticular it is what allows all stepper functions to be non-recursive.

2.2 Eliminating conversions
Writing list functions using compositions of stream and unstreamis clearly inefficient: each function must first construct a new

Stream, and when it is done, unfold the stream back to a list.This is evident in the definition of map from the previous section. Instead of consuming and constructing a list once: streamconsumes a list, allocating Step constructors; map

s consumes andallocates more Step constructors; finally, unstream consumes the

Step constructors and allocates new list nodes. However, if wecompose two functions implemented via streams:

map f c' map g =

unstream c' maps f c' stream c' unstream c' maps g c' stream

we immediately see an opportunity to eliminate the intermediatelist conversions!

Assuming stream c' unstream as the identity on streams, weobtain the rewrite rule:

hstream/unstream fusioni 8 s . stream (unstream s) 7! s

The Glasgow Haskell Compiler supports programmer-definedrewrite rules (Peyton Jones et al. 2001), applied by the compiler
during compilation. We can specify the stream fusion rule as partof the list library source code -- without changing the compiler.
When the compiler applies this rule to our example, it yields:

unstream c' maps f c' maps g c' stream

Our pipeline of list transformers has now been transformed intoa pipeline of stream transformers. Externally, the pipeline still consumes and produces lists, just as the direct list implementationof

map c' map does. However, internally the maps f c' maps gpipeline is the composition of (simple, non-recursive) stream functions.It is interesting to note that the

stream/unstream rule is notreally a classical fusion rule at all. It only eliminates the list allocations that were introduced in converting operations to work overstreams.

2.3 Fusing co-structures
Having converted the functions over list structures into functionsover stream co-structures, the question now is how to optimise

away intermediate Step constructors produced by composed func-tions on streams.

The key trick is that all stream producers are non-recursive.
Once list functions have been transformed to compositions ofnon-recursive stepper functions, there is an opportunity for real

fusion: the compiler can relatively easily eliminate intermediate
Step constructors produced by the non-recursive steppers, usingexisting general purpose optimisations. We describe this process in

detail in Section 7.

3. Writing stream combinators
Figure 1 shows the definitions of several standard algorithms onflat streams which we use throughout the paper. For the most part,

these definitions are essentially the same as those presented in ourprevious work (Coutts et al. 2007). In the following, we discuss
some of the combinators and highlight the principles underlyingtheir implementation.

No recursion: filter Similarly to maps, the stepper function for
r'lters is non-recursive which is crucial for producing efficientfused code. In the case of

r'lters, however, a non-recursive imple-mentation is only possible by introducing

Skip in place of elementsthat are removed from the stream -- the only alternative is to recursively consume elements from the input stream until we find onethat satisfies the predicate (as is the case for the

r'lter function inthe destroy/unfoldr system). As we are able to avoid this recursion,

we maintain trivial control flow for streams, and thus never have tosee through fixed points to optimise, yielding better code.

Consuming streams: fold The only place where recursion is al-lowed is when we consume a stream to produce a different type.
The canonical examples of this are foldrs and foldls which are de-fined in Figure 1. To understand this it is helpful to see compositions of stream functions simply as descriptions of pipelines whichon their own do nothing. They require a recursive function at the
end of the pipeline to unroll sequence elements, to actually con-struct a concrete value.

Recursion is thus only involved in repeatedly pulling values outof the stream. Each step in the pipeline itself requires no recursion.
Of course because of the possibility that a single step might skip itmay take many steps to actually yield a value.

Complex stream states: append Many operations on streams en-code complex control flow by using non-trivial state types. One

r'lters :: (a ! Bool) ! Stream a ! Stream a
r'lters p (Stream next0 s0) = Stream next s0

where

next s = case next0 s of

Done ! Done
Skip s0 ! Skip s0
Yield x s0 | p x ! Yield x s0|

otherwise ! Skip s0

returns :: a ! Stream a
returns x = Stream next True

where

next True = Yield x False
next False = Done

enumFromTos :: Enum a ) a ! a ! Stream a
enumFromTos l h = Stream next l

where

next n |n > h = Done|

otherwise = Yield n (succ n)

foldrs :: (a ! b ! b) ! b ! Stream a ! b
foldrs f z (Stream next s0) = go s0

where

go s = case next s of

Done ! z
Skip s0 ! go s0
Yield x s0 ! f x (go s0)

foldls :: (b ! a ! b) ! b ! Stream a ! b
foldls f z (Stream next s0) = go z s0

where

go z s = case next s of

Done ! z
Skip s0 ! go z s0
Yield x s0 ! go (f z x ) s0

appends :: Stream a ! Stream a ! Stream a
appends (Stream nexta sa0) (Stream nextb sb0) =

Stream next (Left sa0)

where

next (Left sa ) =

case nexta sa of

Done ! Skip (Right sb0)
Skip s0a ! Skip (Left s0a)
Yield x s0a ! Yield x (Left s0a)
next (Right sb) =

case nextb sb of

Done ! Done
Skip s0b ! Skip (Right s0b)

Yield x s0b ! Yield x (Right s0b)

zips :: Stream a ! Stream b ! Stream (a, b)
zips (Stream nexta sa0) (Stream nextb sb0) =

Stream next (sa0, sb0, Nothing)

where

next (sa, sb, Nothing) =

case nexta sa of

Done ! Done
Skip s0a ! Skip (s0a, sb, Nothing)
Yield a s0a ! Skip (s0a, sb, Just a)
next (s0a, sb, Just a) =

case nextb sb of

Done ! Done
Skip s0b ! Skip (s0a, s0b, Just a)
Yield b s0b ! Yield (a, b) (s0a, s0b, Nothing)

Figure 1: Flat stream combinators

concatMaps :: (a ! Stream b) ! Stream a ! Stream b
concatMaps f (Stream nexta sa0) = Stream next (sa0, Nothing)

where

next (sa, Nothing) =

case nexta sa of

Done ! Done
Skip s0a ! Skip (s0a, Nothing)
Yield a s0a ! Skip (s0a, Just (f a))
next (sa, Just (Stream nextb sb)) =

case nextb sb of

Done ! Skip (sa, Nothing)
Skip s0b ! Skip (sa, Just (Stream nextb s0b))
Yield b s0b ! Yield b (sa, Just (Stream nextb s0b))

Figure 2: Definition of concatMaps on streams

example is appends which produces a single stream by concate-nating two independent streams, with possibly different state types.
The state of the new stream necessarily contains the states of thetwo component streams.

To implement concatenation we notice that at any moment weneed only the state of the first stream, or the state of the second. The
next function for append thus operates in two modes, either yield-ing elements from the first stream, or elements from the second.

The two modes can then be encoded as a sum type, Either sa sb,tagging which mode the stepper is in: either yielding the first
stream, or yielding the second. The modes are thus representedas

Left sa or Right sb and there is one clause of next for each.When we get to the end of the first stream we have to switch modes

so that we can start yielding elements from the second stream.This is another example where it is convenient to use

Skip. In-stead of immediately having to yield the first element of the second

stream (which is impossible anyway since the second stream mayskip) we can just transition into a new state where we will be able
to do so. The rule of thumb is in each step to do one thing and onething only.

What is happening here of course is that we are using stateto encode control flow. This is the pattern used for all the more
complex stream functions. Section 7.1 explains how code in thisstyle is optimised.

Consuming multiple streams: zip Functions that consume mul-tiple stream in parallel, such as

zips, also require non-trivial state.Unsurprisingly the definition of

zips on streams is quite similar tothe equivalent definition in the destroy/unfoldr system. The main

difference is that the stream version has to cope with streams thatproduce

Skips, which complicates matters slightly. In particular, itmeans that the we must cope with a situation where we have an

element from the first stream but cannot immediately (i.e., non-recursively) obtain an element from the second one.

So rather than trying to extract an element from one stream, thenfrom another in a single step, we must pull from the first stream,
store the element in the state and then move into a new state wherewe attempt to pull a value from the second stream. Once the second
stream has yielded a value, we can return the pair. In each call ofthe

next function we pull from at most one stream. Again we seethat in any single step we can do only one thing.

4. Functions on nested streams
The last major class of list functions that we need to be able tofuse are ones that deal with nested lists. The canonical example is

concatMap, but this class also includes all the list comprehensions.In terms of control structures, these functions represent nested
recursion and nested loops.

T J [E | ] K = return ET J

[E | B, Q] K = guard B (T J [ E | Q ] K)T J
[E | P A~ L, Q] K = let f P = True

f = False
g P = T J [ E | Q ] K
h x = guard (f x) (g x)
in concatMap h LT J
[E | let decls, Q] K = let decls in T J [ E | Q ] K

Figure 3: Translation scheme for list comprehensions

The ordinary list concatMap function has the type:
concatMap :: (a ! [b]) ! [a] ! [b]
For each element of its input list it applies a function which givesanother list and it concatenates all these lists together. To define a

list concatMap that is fusible with its input and output list, andwith the function that yields a list, we will need a stream-based
concatMaps with the type:

concatMaps :: (a ! Stream b) ! Stream a ! Stream b

To get back the list version we compose concatMaps withstream and unstream and compose the function argument f with

stream:

concatMap f = unstream . concatMaps (stream . f ) . stream

To convert a use of list concatMap to stream form we need afusible list consumer c and fusible list producers p and f . For c,

p and f to be fusible means that they must be defined in termsof stream or unstream and appropriate stream consumers and
producers cs, ps and fs:

c = cs . stream
p = unstream . ps
f = unstream . fs

We now compose them, expanding their definitions to re-veal the stream and unstream conversions, and then apply the

stream/unstream fusion rule three times:

c c' concatMap f c' p
= cs c' streamc'

unstream c' concatMaps (stream c' f ) c' streamc'
unstream c' ps
= cs c' concatMaps (stream c' f ) c' ps
= cs c' concatMaps (stream c' unstream c' fs) c' ps
= cs c' concatMaps fs c' ps

Actually defining concatMaps on streams is somewhat tricky.We need to get an element

a from the outer stream, then f a givesus a new inner stream. We must drain this stream before moving

onto the next outer a element.There are thus two modes: one where we are trying to obtain an
element from the outer stream; and another mode in which we havethe current inner stream and are pulling elements from it. We can
represent these two modes with the state type:

(sa, Maybe (Stream b))
where sa is the state type of the outer stream. The full concatMapsdefinition is given in Figure 2.

5. List comprehensions
List comprehensions provide a very concise way of expressingoperations that select and combine lists. It is important to fuse them

to help achieve our goal of efficiently compiling elegant, declarativeprograms. Recall our introductory example:

f n = sum [ k d^ m | k A~ [1..n], m A~ [1..k] ]

There are two aspects to fusion of list comprehensions. One isfusing with list generators. Obviously this is only possible when
the generator expression is itself fusible. The other aspect is elimi-nating any intermediate lists used internally in the comprehension,
and allowing the comprehension to be fused with a fusible list con-sumer.

The build/foldr system tackles this second aspect directly byusing a translation of comprehensions into uses of

build and
foldr that, by construction, uses no intermediate lists. Furthermore,by using

foldr to consume the list generators it allows fusion theretoo.

Obviously the build/foldr translation, employing build, is notsuitable for streams. The other commonly used translation (Wadler
1987) directly generates recursive list functions. For streams weeither need a translation directly into a single stream (potentially
with a very complex state and stepper function) or a translation intofusible primitives. We opt for the second approach which makes the
translation itself simpler but leaves us with the issue of ensuringthat the expression we build really does fuse.

We use a translation very similar to the translation given in theHaskell language specification (Peyton Jones et al. 2003). However,
there are a couple of important differences. The first change isto always translate into list combinators, rather than concrete list
syntax. This allows us to delay expansion of these functions anduse compiler rewrite rules to turn them into their stream-fusible
counterparts.The second change is to modify the translation so that conditionals do not get in the way of fusion. The Haskell'98 translationsfor expressions and generators are:

T J [E | B, Q] K = if B then T J [ E | Q ] K else [ ]T J

[E | P A~ L, Q] K = let ok P = T J [ E | Q ] K

ok = [ ]in concatMap ok L

Note that for the generator case, P can be any pattern and as suchpattern match failure is a possibility. This is why the

ok functionhas a catch-all clause.

We cannot use this translation directly because in both cases theresulting list is selected on the basis of a test. We cannot directly
fuse when the stream producer is not statically known, as is the casewhen we must make a dynamic choice between two streams. The
solution is to push the dynamic choice inside the stream. We usethe function

guard:

guard :: Bool ! [a] ! [a]
guard True xs = xs
guard False xs = [ ]

This function is quite trivial, but by using a named combinatorrather than primitive syntax it enables us to rewrite to a stream

fusible implementation:

guards :: Bool ! Stream a ! Stream a
guards b (Stream next0 s0) = Stream next (b, s0)

where

next (False, ) = Done
next (True, s) = case next0 s of

Done ! Done
Skip s0 ! Skip (True,s0)
Yield x s0 ! Yield x (True,s0)

The full translation is given in Figure 3. We can use guarddirectly for the case of filter expressions. For generators we build a

function that uses guard with a predicate based on the generator'spattern.

We can now use this translation on our example. For the sakeof brevity we omit the guard functions which are trivial in this
example since both generator patterns are simple variables.

T J [k d^ m | k A~ [1..n], m A~ [1..k] ] K
= concatMap (y" k !

concatMap (y" m !

return (k d^ m))
(enumFromTo 1 k))
(enumFromTo 1 n)

Next we inline all the list functions to reveal the stream versionswrapped in

stream / unstream and we apply the fusion rule threetimes:

= unstream (concatMaps (y" k ! stream (

unstream (concatMaps (y" m ! stream (

unstream (returns (k d^ m))))
(stream (unstream (enumFromTos 1 k))))))
(stream (unstream (enumFromTos 1 n))))

= unstream (concatMaps (y" k !

concatMaps (y" m !

returns (k d^ m))
(enumFromTos 1 k))
(enumFromTos 1 n))

Finally, to get our full original example we apply sums (which isjust

foldls (+) 0) and repeat the inline and fuse procedure one moretime. This gives us a term with no lists left; the entire structure has

been converted to stream form.

= sums (concatMaps (y" k !

concatMaps (y" m !

returns (k d^ m))
(enumFromTos 1 k))
(enumFromTos 1 n))

6. Correctness
Every fusion framework should come with a rigorous correctnessproof. Unfortunately, many do not and ours is not an exception.

This might seem surprising at first, as we introduce only one rathersimple rewrite rule:

8 s. stream (unstream s) 7! s

Should it not be easy to show that applying this rule does notchange the semantics of a program or, conversely, construct an example where the semantics is changed? In fact, a counterexampleis easily found for the system presented in this paper: with

s =?,we have:

stream (unstream ?) = Stream next ? 6= ?

Depending on how we define equivalence on streams, othercounterexamples can be derived. In the rest of this section we

discuss possible approaches to retaining semantic soundness ofstream fusion.

6.1 Strictness of streams
The above counter-example is particularly unfortunate as it impliesthat we can turn terminating programs into non-terminating ones.

In our implementation, we circumvent this problem by not export-ing the

Stream data type and ensuring that we never construct bot-tom streams within our library. Effectively, this means that we treat

Stream as an unlifted type, even though Haskell does not provideus with the means of saying so explicitly.1

Avoiding the creation of bottom streams is, in fact, fairly easy. Itboils down to the requirement that all stream-constructing functions
be non-strict in all arguments except those of type Stream whichwe can presume not to be bottom. This is always possible, as the

1 Launchbury and Paterson (1996) discuss how unlifted types can be integrated into a lazy language.

arguments can be evaluated in the stepper function. For instance,the combinator

guard defined in the previous section is lazy in thecondition. The latter is not inspected until the stepper function has

been called for the first time.In fact, we can easily change our framework such that the
rewrite rule removes bottoms instead of introducing them. For this,it is sufficient to make stream strict in its argument. Then, we
have stream (unstream ?) = ?. However, now we can derivea different counterexample:

stream (unstream (Stream ? s)) = ? 6= Stream ? s

This is much less problematic, though, as it only means that weturn some non-terminating programs into terminating ones. Unfortunately, with this definition of stream it becomes much harder toimplement standard Haskell list functions such that they have the
desired semantics. The Haskell 98 Report (Peyton Jones et al. 2003)requires that

take 0 xs = [ ], i.e., take must be lazy in its secondargument. In our library,

take is implemented as:

take :: Int ! [a] ! [a]
take n xs = unstream (takes n (stream xs))

takes :: Int ! Stream a ! Stream a
takes n (Stream next s) = Stream next0 (n, s)

where

next0 (0, s) = Done
next0 (n,s) = case next s of

Done ! Done
Skip s0 ! Skip (n, s0)
Yield x s0 ! Yield x (n a, 1,s0)

Note that since takes is strict in the stream argument, streammust be lazy if

take is to have the required semantics. An alterna-tive would be to make

takes lazy in the stream:

takes n s = Stream next0 (n, s)

where

next0 (0, s) = Done
next0 (n,Stream next s) =case next s of

Done ! Done
Skip s0 ! Skip (n, Stream next s0)
Yield x s0 ! Yield x (n a, 1, Stream next s0)

Here, we embed the entire argument stream in the seed ofthe newly constructed stream, thus ensuring that it is only evaluated when necessary. Unfortunately, such code is currently lessamenable to being fully optimised by GHC. Indeed, efficiency was
why we preferred the less safe fusion framework presented in thispaper to the one outlined here. We do hope, however, that improvements to GHC's optimiser will allow us to experiment with alter-natives in the future.

6.2 Equivalence of streams
Even in the absence of diverging computations, it is not entirelytrivial to define a useful equivalence relation on streams. This is

mainly due to the fact that a single list can be modeled by infinitelymany streams. Even if we restrict ourselves to streams producing
different sequences of Step values, there is still no one-to-onecorrespondence -- two streams representing the same list can differ
in the number and positions of Skip values they produce. Thissuggests that equivalence on streams should be defined modulo
Skip values. In fact, this is a requirement we place on all stream-processing functions: their semantics should not be affected by the
presence or absence of Skip values.
6.3 Testing
Although we do not have a formal proof of correctness of ourframework, we have tested it quite extensively. It is easy to introduce subtle strictness bugs when writing list functions, either directly on lists or on streams. Fortunately we have a precise specifi-cation in the form of the Haskell'98 report. Comparative testing on
total values is relatively straightforward, but to test strictness prop-erties however we need to test on partial values. We were inspired
by the approach in StrictCheck (Chitil 2006) of checking strict-ness properties by generating all partial values up to a certain finite
depth. However, to be able to generate partial values at higher or-der type we adapted SmallCheck (Runciman 2006) to generate all
partial rather than total values up to any given depth. We used thisand the Chasing Bottoms library (Danielsson and Jansson 2004) to
compare our implementations against the Haskell'98 specificationand against the standard library used by many Haskell implementations.This identified a number of subtle bugs in our implementation
and a handful of cases where we can argue that the specificationis unnecessarily strict. We also identified cases where the standard
library differs from the specification. The tests document the strict-ness properties of list combinators and give us confidence that the
stream versions do, in fact, have the desired strictness.

7. Compiling stream code
Ultimately, a fusion framework should eliminate temporary datastructures. Stream fusion by itself does not, however, reduce allocation - it merely replaces intermediate lists by intermediate Stepvalues. Moreover, when a stream is consumed, additional allocations are necessary to maintain its seed throughout the loop. Forinstance,

append allocates an Either node in each iteration.This behaviour is quite similar to programs produced by destroy/unfoldr and like the latter, our approach relies on subsequentcompiler optimisation passes to eliminate these intermediate values. Since we consider more involved list operations than Sven-ningsson (2002), in particular nested ones, we necessarily require
more involved optimisation techniques than the ones discussedin that work. Still, these techniques are generally useful and not
specifically tailored to programs produced by our fusion frame-work. In this section, we identify the key optimisations necessary
to produce good code for stream-based programs and explain whythey are sufficient to replace streams by nothing at all.

7.1 Flat pipelines
Let us begin with a simple example: sum (xs ++ ys). Our fusionframework rewrites this to:

foldls (+) 0 (appends (stream xs) (stream ys))
Inlining the definitions of the stream combinators, we get

let nextstream xs =

case xs of

[ ] ! Done
x : xs0 ! Yield x xs0
nextappend (Left xs) =

case nextstream xs of

Done ! Skip (Right ys)
Skip xs0 ! Skip (Left xs0)
Yield x xs0 ! Yield x (Left xs0)

nextappend (Right ys) =

case nextstream ys of

Done ! Done
Skip ys0 ! Skip (Right ys0)
Yield y ys0 ! Yield y (Right ys0)

go z s =

case nextappend s of

Done ! z
Skip s0 ! go z s0
Yield x s0 ! go (z + x) s0
in go 0 (Left xs)

Here, nextstream and nextappend are the stepper functions of thecorresponding stream combinators and

go the stream consumer of
foldls.While this loop is rather inefficient, it can be easily optimised

using entirely standard techniques such as those described by Pey-ton Jones and Santos (1998). By inlining next

stream into the firstbranch of next
append , we get a nested case distinction:

nextappend (Left xs) =

case

case xs of

[ ] ! Done
x : xs0 ! Yield x xs0of

Done ! Skip (Right ys)
Skip xs0 ! Skip (Left xs0)
Yield x xs0 ! Yield x (Left xs0)

This term are easily improved by applying the case-of-case trans-formation which pushes the outer case into the alternatives of the

inner case:

nextappend (Left xs) =

case xs of

[ ] ! case Done of

Done ! Skip (Right ys)
Skip xs0 ! Skip (Left xs0)
Yield x xs0 ! Yield x (Left xs0)

x : xs0 ! case Yield x xs0 of

Done ! Skip (Right ys)
Skip xs0 ! Skip (Left xs0)
Yield x xs0 ! Yield x (Left xs0)

This code trivially rewrites to:

nextappend (Left xs) = case xs of

[ ] ! Skip (Right ys)
x : xs0 ! Yield x (Left xs0)

The Right branch of nextappend is simplified in a similar man-ner, resulting in

nextappend (Right ys) = case ys of

[ ] ! Done
y : ys0 ! Yield y (Right ys0)

Note how by inlining, applying the case-of-case transforma-tion and then simplifying we have eliminated the construction (in

nextstream ) and inspection (in nextappend) of one Step value per it-eration. The good news is that these techniques are an integral part
of GHC's optimiser and are applied to our programs automatically.Indeed, the optimiser then inlines next

append into the body of goand reapplies the transformations described above to produce:

let go z (Left xs) = case xs of

[ ] ! go z (Right ys)
x : xs0 ! go (z + x) (Left xs0)
go z (Right ys) = case ys of

[ ] ! z
y : ys0 ! go (z + y) (Right ys0)
in go 0 (Left xs)

While this loop does not use any intermediate Step values,it still allocates Left and Right for maintaining the loop state.

Eliminating these requires more sophisticated techniques than wehave used so far. Fortunately, constructor specialisation (Peyton
Jones 2007), an optimisation which has been implemented in GHCfor some time, does precisely this. It analyses the shapes of the
arguments in recursive calls to go and produces two specialisedversions of the function, go

1 and go2, which satisfy the followingequivalences:

8 z xs. go z (Left xs) = go1 z xs8

z ys. go z (Right ys) = go2 z ys

The compiler then replaces calls to go by calls to a specialisedversion whenever possible. The definitions of the two specialisations are obtained by expanding go once in each of the above twoequations and simplifying, which ultimately results in the following program:

let go1 z xs = case xs of

[ ] ! go2 z ys
x : xs0 ! go1 (z + x) xs0go
2 z ys = case ys of[ ] ! z

y : ys0 ! go2 (z + y) ys0in go
1 0 xs

Note that the original version of go is no longer needed. Theloop has effectively been split in two parts -- one for each of

the two concatenated lists. Indeed, this result is the best we couldhave hoped for. Not only have all intermediate data structures been
eliminated, the loop has also been specialised for the algorithm athand.

By now, it becomes obvious that in order to compile stream pro-grams to efficient code, all stream combinators must be inlined and
subsequently specialised. Arguably, this is a weakness of our ap-proach, as this sometimes results in excessive code duplication and
a significant increase in the size of the generated binary. However,as discussed in Section 8, our experiments suggest that this increase
is almost always negligible.
7.2 Nested computations
So far, we have only considered the steps necessary to optimisefused pipelines of flat operations on lists. For nested operations

such as concatMap, the story is more complicated. Nevertheless, itis crucial that such operations are optimised well. Indeed, even our
introductory example uses concatMap under the hood as describedin Section 5.

Although a detailed explanation of how GHC derives the effi-cient loop presented in the introduction would take up too much
space, we can investigate a less complex example which, neverthe-less, demonstrates the basic principles underlying the simplification
of nested stream programs. In the following, we consider the simplelist comprehension

sum [m d^ m | m A~ [1..n]]. After desugaringand stream fusion, the term is transformed to (we omit the trivial

guard):

foldls (+) 0 (concatMaps (y"m. returns (m d^ m))

(enumFromTos 1 n))

After inlining the definitions of the stream functions, we arriveat the following loop (next

enum, nextcm and nextret are the stepperfunctions of enumFromTo

s, concatMaps and returns, respec-tively, as defined in Figures 1 and 2 ):

let nextenum i | i > n = Done|

otherwise = Yield i (i + 1)

nextconcatMap (i, Nothing) =

case nextenum i of

Done ! Done
Skip i0 ! Skip (i0, Nothing)
Yield x i0 ! let nextret True = Yield (x d^ x) False

nextret False = Donein

Skip (i0, Just (Stream nextret True))
nextconcatMap (i, Just (Stream next s)) =

case next s of

Done ! Skip (i, Nothing)
Skip s0 ! Skip (i, Just (Stream next s0))
Yield y s0 ! Yield y (i, Just (Stream next s0))

go z s = case nextconcatMap s of

Done ! z
Skip s0 ! go z s0
Yield x s0 ! go (z + x) s0
in go 0 (1, Nothing)

As before, we now inline nextenum and nextconcatMap into thebody of go and repeatedly apply the case-of-case transformation.
Ultimately, this produces the following loop:

let go z (i, Nothing) | i > n = z|

otherwise =
let nextret True = Yield (i d^ i) False

nextret False = Donein

go z (i + 1, Just (Stream nextret True))
go z (i, Just (Stream next s)) =

case next s of

Done ! go z (i, Nothing)
Skip s0 ! go z (i, Just (Stream next s0))
Yield x s0 ! go (z + x) (i, Just (Stream next s0))
in go 0 (1, Nothing)

Now we again employ constructor specialisation to split go intotwo mutually recursive functions go

1 and go2 such that8

z i. go z (i, Nothing) = go1 z i8
z i next s. go z (i, Just (Stream next s)) = go2 z i next s

The second specialisation is interesting in that it involves an exis-tential component -- the state of the stream. Thus, go

2 must havea polymorphic type which, however, is easily deduced by the compiler. After simplifying and rewriting calls to go, we arrive at thefollowing code:

let go1 z i | i > n = z|

otherwise =
let nextret True = Yield (i d^ i) False

nextret False = Donein

go2 z (i + 1) nextret True
go2 z i next s = case next s of

Done ! go1 z i
Skip s0 ! go2 z i next s0
Yield x s0 ! go2 (z + x ) i next s0in go
1 0 1

The loop has now been split into two mutually recursive func-tions. The first,

go1, computes the next element i of the enumer-ation
[1..n] and then passes it to go2 which computes the productand adds it to the accumulator

z. However, the nested structure ofthe original loop obscures this simple algorithm. In particular, the

stepper function nextret of the stream produced by returns has tobe passed from

go1, where it is defined, to go2, where it is used. Ifwe are to produce efficient code, we must remove this indirection

and allow nextret to be inlined in the body of go2. In the following,we consider two approaches to solving this problem: static argument transformation and specialisation on partial applications.
Static argument transformation It is easy to see that next and iare static in the definition of go

2, i.e., they do not change betweeniterations. An optimising compiler can take advantage of this fact

and eliminate the unnecessary arguments:

go2 z i next s =

let go02 z s = case next s of

Done ! go1 z i
Skip s0 ! go02 z s0
Yield x s0 ! go02 (z + x) s0
in go02 z s

With this definition, go2 can be inlined in the body of go1. Subse-quent simplification binds

next to nextret and allows the latter tobe inlined in
go02:

go1 z i | i > n = z|

otherwise =
let go02 z True = go02 (z + i d^ i) False

go02 z False = go1 z (i + 1)
in
go02 z True

The above can now be easily rewritten to the optimal loop:

go1 z i | i > n = z|

otherwise = go1 (z + i d^ i) (i + 1)

Note how the original nested loop has been transformed intoa flat one. This is only possible because in this particular example, the function argument of concatMap was not itself recursive.More complex nesting structures, in particular nested list comprehensions, are translated into nested loops if the static argumenttransformation is employed. For instance, our introductory example
would be compiled to

let go1 z k | k > n = z|

otherwise =
let go2 z m | m > k = go1 z (k + 1)|

otherwise = go2 (z + k d^ m) (m + 1)in go
2 z 1in go
1 0 1

Specialisation An alternative approach to optimising the programis to lift the definition of

nextret out of the body of go1 accordingto the algorithm of Johnsson (1985):

nextret i True = Yield (i d^ i) False
nextret i False = Done

go1 z i | i > n = z|

otherwise = go2 z (i + 1) (nextret i) True

Now, we can once more specialise go2 for this call; but this time,in addition to constructors we also specialise on the partial application of the now free function nextret , producing a go3 such that:

8 z i j . go2 z j (nextret i) True = go3 z j i
After expanding go2 once in the above equation, we arrive at thefollowing unoptimised definition of

go3:

go3 z j i = case nextret i True of

Done ! go1 z j
Skip s0 ! go2 z j (nextret i) s0
Yield x s0 ! go2 (z + x) j (nextret i) s0

Note that the stepper function is now statically known and canbe inlined which allows all case distinctions to be subsequently

eliminated, leading to a quite simple definition:

go3 z j i = go2 (z + (i d^ i)) j (nextret i) False
The above call gives rise to yet another specialisation of go2:

8 z i j . go2 z j (nextret i) False = go4 z j i
Again, we rewrite go4 by inlining nextret and simplifying, ulti-mately producing:

go1 z i | i > n = z|

otherwise = go3 z (i + 1) i
go3 z j i = go4 (z + (i d^ i)) j i
go4 z j i = go1 z j

This is trivially rewritten to exactly the same code as has beenproduced by the static argument transformation:

go1 z i| i > n = z|

otherwise = go1 (z + i d^ i) (i + 1)

This convergence of the two optimisation techniques is, how-ever, only due to the simplicity of our example. For the more deeply

nested program from the introduction, specialisation would pro-duce two mutually recursive functions:

go1 z k | k > n = z|

otherwise = go2 z k (k + 1) 1

go2 z k k0 m| m > k = go1 z k0|

otherwise = go2 (z + k d^ m) k k0 (m + 1)

This is essentially the code of f 0 from the introduction; theonly difference is that GHC's optimiser has unrolled

go2 once andunboxed all loop variables. This demonstrates the differences between the two approaches nicely. The static argument transforma-tion translates nested computations into nested recursive functions.
Specialisation on partial applications, on the other hand, producesflat loops with several mutually recursive functions. The state of
such a loop is maintained in explicit arguments.Unfortunately, GHC currently supports neither of the two approaches -- it only specialises on constructors but not on partialapplications of free functions and does not perform the static argument transformation. Although we have extended GHC's optimiserwith both techniques, our implementation is quite fragile and does
not always produce the desired results. Indeed, missed optimisa-tions are at least partly responsible for many of the performance
problems discussed in Section 8. At this point, the implementationmust be considered merely a proof of concept. We are, however,
hopeful that GHC will be able to robustly optimise stream-basedprograms in the near future.

8. Results
We have implemented the entire Haskell standard List library, in-cluding enumerations and list comprehensions, on top of our stream

fusion framework. Stream fusion is implemented via equationaltransformations embedded as rewrite rules in the library source
code. We compare time, space, code size and fusion opportuni-ties for programs in the nofib benchmark suite (Partain 1992),
when compared to the existing build/foldr system. To ensure afair comparison, both frameworks have been benchmarked with
our extensions to GHC's optimiser (cf. Section 7) enabled. For thebuild/foldr framework, these extensions do not significantly affect
the running time and allocation behaviour, usually improving themslightly, and without them, nested

concatMap's under stream fu-sion risk not being optimised.

8.1 Time
Figure 4 presents the relative speedups for Haskell programs fromthe nofib suite, when compared to the existing build/foldr system.

On average, there is a 3% improvement when using stream fusion,with 6 of the test programs more than 15% faster, and one, the `integer' benchmark, more than 50% faster. One program, `paraffins',ran 24% slower, due to remnant

Stream data constructors not stat-ically removed by the compiler.

In general we can divide the results into three classes of pro-grams:

1. those for which there is plenty of opportunity for fusion whichis under-exploited by build/foldr;
2. programs for which there is little fusion or for which the fusionis in a form handled by build/foldr;
3. and thirdly, programs such as `paraffins' with deeply nestedlist computations and comprehensions which overtax our extensions to GHC's optimiser.
For the first class or programs, those using critical left folds andzip, stream fusion can be a big win. 10% (and sometimes much

more) improvement is not uncommon. This corresponds to around15% of programs tested.

In the second case, the majority of programs covered, there iseither little available fusion, or the fusion is in the form of right
folds, and list comprehensions, already well handled by build/foldr.Only small improvements can be expected here.

Finally, the third class, corresponds to some 5% of programstested. These programs have available fusion, but in deeply nested
form, which can lead to Step constructors left behind by limitations

in current GHC optimisations, rather than being removed statically.These programs currently will run dramatically, and obviously,
worse.For large multi-module programs, the results are less clear, with
just as many programs speeding up as slowing down. We find thatfor larger programs, GHC has a tendency to miss optimisation opportunities for stream fusible functions across module boundaries,which is the subject of further investigation.

8.2 Space
Figure 5 presents the relative reduction in total heap allocationsfor stream fusion programs compared to the existing build/foldr

system. The results can again be divided into the same three classesas for the time benchmarks: those with under-exploited fusion
opportunities, those for which build/foldr already does a good job,and those for which

Step artifacts are not statically eliminated bythe compiler.

For programs which correctly fuse, in the first class, with newfusion opportunities found by stream fusion, there can be dramatic
reductions in allocations (up to 30%). Currently, this is the minor-ity of programs. The majority of programs have modest reductions,
with an average decrease in allocations of 4.4%. Two programshave far worse allocation performance, however, due to missed opportunities to remove Step constructors in nested code. For large,multi-module programs, we find a small increase in allocations, for
similar reasons as for the time benchmarks.
8.3 Fusion opportunities
In Figure 6 we compare the number of fusion sites identified withstream fusion, compared to that with build/foldr. In the majority of

cases, more fusion sites are identified, corresponding to new fusionopportunities with zips and left folds. Similar results are seen when
compiling GHC itself, with around 1500 build/foldr fusion sitesidentified by the compiler, and more than 3000 found under stream
fusion.
8.4 Code size
Total compiled binary size was measured, and we find that forsingle module programs, code size increases by a negligible 2.5%

on average. For multi-module programs, code size increases by11%. 5% of programs increased by more than 25% in size, again
due to unremoved specialised functions and Step constructors.

9. Further work
9.1 Improved optimisations
The main direction for future work on stream fusion is to improvefurther the compiler optimisations required to remove

Step constructorsstatically, as described in Section 7.

Another possible approach to reliably fusing nested uses of
concatMap is to define a restricted version of it which assumesthat the inner stream is constructed in a uniform way, i.e., using the

same stepper function and the same function to construct initialinner-stream states in every iteration of the outer stream. This
situation corresponds closely to the forms that we expect to be ableto optimise with the static argument transformation.

The aim would be to have a rule that matches the common situ-ation where this restricted

concatMap can be used. Unfortunatelysuch rules cannot be expressed in the current GHC rules language.

A more powerful rule matcher would allow us to write somethinglike:

concatMap (y" x ! unstream (Stream nextJxK sJxK))
=concatMap0 (y" y ! nextJyK) (y" y ! sJyK)

-30
-20
-10

 0
 10
 20
 30

binarytrees

nsieve

partialsums

pidigitsspectralsumcolbernouilli

digits-of-e1integrate

queens

loop

digits-of-e2

exp3-8

gen-regexps

paraffins

rfib

wheelsieve1wheelsieve2

x2n1jl-rsaru-listansiboyer

fibheapsinteger

k-nucleotidemandelbrot

nbody

regex-dnareverse

sortingmeteorcalendarcichellicircsimclausify

constraintscryptarithm1fannkuch

primes

perfectsqs

eliza

Percentage speedup

Figure 4: Percentage improvement in running time compared to build/foldr fusion

-30
-20
-10

 0
 10
 20
 30

binarytrees

nsieve

partialsums

pidigitsspectralsumcolbernouilli

digits-of-e1integrate

queens

loop

digits-of-e2

exp3-8

gen-regexps

paraffins

rfib

wheelsieve1wheelsieve2

x2n1jl-rsaru-listansiboyer

fibheapsinteger

k-nucleotidemandelbrot

nbody

regex-dnareverse

sortingmeteorcalendarcichellicircsimclausify

constraintscryptarithm1fannkuch

primes

perfectsqs

eliza

Percentage reduction in allocations

Figure 5: Percent reduction in allocations compared to build/foldr fusion

-15
-10

-5

 0
 5
 10
 15
 20
 25
 30

binarytrees

nsieve

partialsums

pidigitsspectralsumcolbernouilli

digits-of-e1integrate

queens

loop

digits-of-e2

exp3-8

gen-regexps

paraffins

rfib

wheelsieve1wheelsieve2

x2n1jl-rsaru-listansiboyer

fibheapsinteger

k-nucleotidemandelbrot

nbody

regex-dnareverse

sortingmeteorcalendarcichellicircsimclausify

constraintscryptarithm1fannkuch

primes

perfectsqs

eliza

Improvement in found fusion sites

Figure 6: New fusion opportunities found when compared to build/foldr

Here, T Jx K matches a term T abstracted over free occurrencesof the variable

x . In the right hand side the same syntax indicatessubstitution.

The key point is that the stepper function of the inner stream isstatically known in

concatMap0. This is a much more favourablesituation compared to embedding the entire inner stream in the seed

of concatMap. Indeed, extending GHC's rule matching capabil-ities in this direction might be easier than robustly implementing
the optimisations outlined in Section 7.

9.2 Fusing general recursive definitions
Writing stream stepper functions is not always easy. The represen-tation of control flow as state makes them appear somewhat inside

out. One technique we found useful when translating Haskell listfunctions into stream fusible versions was to first transform the list
version to very low level Haskell. From this form, where the pre-cise control flow is clear, there is a fairly direct translation into a
stream version.For example here is a list function written in a very low level
style using three mutually tail-recursive functions. Each one hasonly simple patterns on the left hand side and on the right hand
side: an empty list; a call; or a cons and a call.

intersperse :: a ! [a] ! [a]
intersperse sep xs0 = init xs0

where

init xs = case xs of

[ ] ! [ ]
(x : xs) ! go x xs

go x xs = x : to xs
to xs = case xs of

[ ] ! [ ]
(x : xs) ! sep : go x xs

We can translate this to an equivalent function on streams bymaking a data type with one constructor per function. Each constructor holds the arguments to that function except that argumentsof type list are replaced by the stream state type. In the body of each
function, case analysis on lists is replaced by calling next0 on thestream state. Consing an element onto the result is replaced by uses
of Yield . Calls are replaced by Skips with the appropriate statedata constructor:

data State a s = Init s | Go a s | To s
intersperses :: a ! Stream a ! Stream a
intersperses sep (Stream next0 s0) = Stream next (Init s0)

where

next (Init s) = case next0 s of

Done ! Done
Skip s0 ! Skip (Init s0)
Yield x s0 ! Skip (Go x s0)

next (Go x s) = Yield x (To s)
next (To s) = case next0 s of

Done ! Done
Skip s0 ! Skip (To s0)
Yield x s0 ! Yield sep (Go x s0)

It would be interesting to investigate the precise restrictions onthe form which can be translated in this way and whether it can

be automated. This might provide a practical way to fuse generalrecursive definitions over lists: by checking if the list function can
be translated to the restricted form and then translating into a streamversion. There is some precedent for this approach: Launchbury
and Sheard (1995) show that in many common cases it is possible totransform general recursive definitions on lists into a form suitable
for use with ordinary build/foldr short-cut fusion.

9.3 Fusing more general algebraic data types
It seems straightforward to define a co-structure for any sum-of-products data structure. Consider for example a binary tree type

with information in both the leaves and interior nodes:

data Tree a b = Leaf a | Fork b (Tree a b) (Tree a b)
The corresponding co-structure would be:

data Streama b = 9s. Stream (s ! Step a b s) s
data Step a b s = Leafs a | Forks b s s | Skip s

Of course other short-cut fusion systems can also be generalisedin this way but in practice they are not because it requires defining a

new infrastructure for each new data structure that we wish to fuse.Automation would be required to make this practical. This problem
is somewhat dependent on the ability to generate stream style codefrom ordinary recursive definitions.

10. Conclusion
It is possible, via stream fusion, to automatically fuse a completerange of list functions, beyond that of previous short-cut fusion

techniques. In particular, it is possible to fuse left and right folds,zips, concats and nested lists, including list comprehensions. For
the first time, details are provided for the range of general purposeoptimisations required to generate efficient code for unfoldr-based
short-cut fusion.Stream fusion is certainly practical, with a full scale implementation for Haskell lists being implemented, utilising library-basedrewrite rules for fusion. Our results indicate there is a greater opportunity for fusion, than under the existing build/foldr system, andalso show moderate improvements in space and time performance.
Further improvements in the specific compiler optimisations re-quired to remove fusion artifacts statically.

The source code for the stream fusion List library, and modifiedstandard Haskell library and compiler, are available online.2

Acknowledgments We are indebted to Simon Peyton Jones forclarifying and extending GHC's optimiser, which greatly assisted
this effort. We are also grateful to Manuel Chakravarty and SpencerJanssen for feedback on drafts and to the four anonymous referees
for their invaluable comments.
References
Olaf Chitil. Type inference builds a short cut to deforestation. InICFP '99: Proceedings of the fourth ACM SIGPLAN International Conference on Functional programming, pages 249-260,New York, NY, USA, 1999. ACM Press.

Olaf Chitil. Promoting non-strict programming. In Draft Pro-ceedings of the 18th International Symposium on Implementation and Application of Functional Languages, IFL 2006, pages512-516, Budapest, Hungary, September 2006. Eotvos Lorand
University. URL http://www.cs.kent.ac.uk/pubs/2006/
2477.

Duncan Coutts, Don Stewart, and Roman Leshchinskiy. Rewrit-ing Haskell strings. In Practical Aspects of Declarative Languages 8th International Symposium, PADL 2007, pages 50-64.Springer-Verlag, January 2007.

Nils Anders Danielsson and Patrik Jansson. Chasing bottoms, acase study in program verification in the presence of partial

and infinite values. In Dexter Kozen, editor, Proceedings ofthe 7th International Conference on Mathematics of Program
Construction, MPC 2004, volume 3125 of LNCS, pages 85-109.Springer-Verlag, July 2004.

2 This material can be found on the website accompanying this paper at
http://www.cse.unsw.edu.au/~dons/papers/CLS07.html.

Jeremy Gibbons. Streaming representation-changers. In D. Kozen,editor, Mathematics of Program Construction, pages 142-168.

Springer-Verlag, 2004. LNCS 523.
Jeremy Gibbons and Geraint Jones. The under-appreciated unfold.In ICFP '98: Proceedings of the third ACM SIGPLAN International Conference on Functional programming, pages 273-279,New York, NY, USA, 1998. ACM Press.
Andrew Gill. Cheap Deforestation for Non-strict Functional Lan-guages. PhD thesis, University of Glasgow, January 1996.
Andrew Gill, John Launchbury, and Simon Peyton Jones. A shortcut to deforestation. In Conference on Functional Programming

Languages and Computer Architecture, pages 223-232, June1993.

Zhenjiang Hu, Hideya Iwasaki, and Masato Takeichi. Derivingstructural hylomorphisms from recursive definitions. In Proceedings 1st ACM SIGPLAN International Conference on Func-tional Programming, volume 31(6), pages 73-82. ACM Press,
New York, 1996.
Patricia Johann. Short cut fusion: Proved and improved. In SAIG2001: Proceedings of the Second International Workshop on Semantics, Applications, and Implementation of Program Genera-tion, pages 47-71, London, UK, 2001. Springer-Verlag.
Thomas Johnsson. Lambda lifting: transforming programs to recur-sive equations. In Functional programming languages and computer architecture. Proc. of a conference (Nancy, France, Sept.1985), New York, NY, USA, 1985. Springer-Verlag Inc.

John Launchbury and Ross Paterson. Parametricity and unboxingwith unpointed types. In European Symposium on Programming, pages 204-218, 1996.
John Launchbury and Tim Sheard. Warm fusion: deriving build-catas from recursive definitions. In FPCA '95: Proceedings of

the seventh international conference on Functional program-ming languages and computer architecture, pages 314-323,
New York, NY, USA, 1995. ACM Press.
Erik Meijer, Maarten Fokkinga, and Ross Paterson. Functionalprogramming with bananas, lenses, envelopes and barbed wire.

In J. Hughes, editor, Proceedings 5th ACM Conf. on Func-tional Programming Languages and Computer Architecture,
FPCA'91, Cambridge, MA, USA, 26-30 Aug 1991, volume 523,pages 124-144. Springer-Verlag, Berlin, 1991.
Will Partain. The nofib benchmark suite of Haskell programs. InFunctional Programming, pages 195-202, 1992.
Simon Peyton Jones. Constructor Specialisation for Haskell Pro-grams, 2007. Submitted for publication.
Simon Peyton Jones and Andr'e L. M. Santos. A transformation-based optimiser for Haskell. Sci. Comput. Program., 32(1-3):

3-47, 1998. ISSN 0167-6423.
Simon Peyton Jones, Andrew Tolmach, and Tony Hoare. Playingby the rules: rewriting as a practical optimisation technique in

GHC. In Ralf Hinze, editor, 2001 Haskell Workshop. ACMSIGPLAN, September 2001.

Simon Peyton Jones et al. The Haskell 98 language and libraries:The revised report. Journal of Functional Programming, 13(1):

0-255, Jan 2003. http://www.haskell.org/definition/.
Colin Runciman. SmallCheck 0.2: another lightweight testinglibrary in Haskell.

http://article.gmane.org/gmane.
comp.lang.haskell.general/14461, 2006.

Josef Svenningsson. Shortcut fusion for accumulating parameters& zip-like functions. In ICFP '02: Proceedings of the seventh

ACM SIGPLAN International Conference on Functional pro-gramming, pages 124-132, New York, NY, USA, 2002. ACM
Press.

Akihiko Takano and Erik Meijer. Shortcut deforestation in calcu-lational form. In Conf. Record 7th ACM SIGPLAN/SIGARCH

Int. Conf. on Functional Programming Languages and Com-puter Architecture, FPCA'95, pages 306-313. ACM Press, New
York, 1995.
The GHC Team. The Glasgow Haskell Compiler (GHC). http:

//haskell.org/ghc, 2007.

Philip Wadler. List comprehensions. In Simon Peyton Jones, ed-itor, The implementation of functional programming languages.

Prentice Hall, 1987. Chapter 15.
Philip Wadler. Deforestation: transforming programs to eliminatetrees. Theoretical Computer Science, (Special issue of selected

papers from 2nd European Symposium on Programming), 73(2):231-248, 1990.