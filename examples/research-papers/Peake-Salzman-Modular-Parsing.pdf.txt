

Support  for  odular  Parsing  in  Software  Reengiueering 

Ian  Peake, Eric  Salzman Centre  for  Software  Maintenance 
School  of  Information  Technology The  University  of  Queensland 4072 

AUSTRALIA Phone:  +  617  3365  2097 
Fax:  -i- 617  3365  1428 {  peaki  I eric  }@it.uq.edu.au 

Abstract 
As  reengineering increasingly contributes to  software engineering,  so  can  software  engineering  principles 
contribute to cost-effective reengineering tool development. The cost  of  modelling  languages motivates support for 
modular parsers  which  can,  like  program  modules, be assembled cheaply from  smaller, tested components. We 
describe a  scheme which  achieves this  by  extending the expressive and jlexible  combinator parsing  scheme using 

object-oriented constructs (class inheritance and dynamic method dispatch). Related  schemes either  do  not  filly 
support code sharing or sacrifice flexibility.  The scheme has been implemented in a prototype reengineering environment 

and successfilly  tested on  grammars such as Modula-2. Generation time for  extensions is  linear in  the size of the 
extension. Run time peeormance is potentially as bad as for general parsing  algorithms but  can  be  linear  (10  times 
slower than LALR for  Modula-2) after optimization. 

1.  Introduction 

The need to support modular language implementations -  that is, where components (of a language implementation) 
can be defined,  compiled  and tested  separately,  then integrated -  has been widely recognised. 

As Koskimies has observed, although modularisation is most commonly  seen in  a traditional  language front  end 
implementation where lexical  analyser, parser, linker  etc. are separate loosely  coupled modules, there is  another 
important form  of modularity. This is "...according to the natural units  of  the language itself,"  -  splitting,  e.g.,  a 
grammar into logically cohesive units such as "expressions" or "database statements." Because language models are as 

much "targets" as they are "tools"  of software engineering, the benefits of  this  approach fulfil  software engineering 

objectives. Module  size can be more closely  managed; modules match natural concepts thus supporting cohesion 
and coupling;  and modules embodying important  syntax constructs can be reused in the production of new languages 

[IhI. Increasingly  there is  a trend  toward  incorporating 
principles  from  programming into  language design and implementation [3], including reusability  and modularity 

1151, originally proposed in language extensibility literature [22][25]  originating in the sixties and seventies. There are 
several applications and tools which support various forms of modular language definition [5] [7] [S] [16] [26] [27]. 

The need for such support in software reengineering is readily apparent: 
l  Models for  languages such as COBOL  are central to translation projects, requiring person months to develop, 

test or extend, so support for their reuse is highly desira- ble. However COBOL,  like  several other mainstream 
languages, has several independent implementations [23], each with  slightly different syntax and semantics, 

so modifying  a copy of  an existing grammar might be necessary before it  can be used in a new situation, 
l  The  emergence of  4GLs  has resulted  in  hybrid  or "embedded"  languages, integrating  the  syntax  and 

semantics of, for example, C and SQL. Defining syntax for such a language necessarily involves new syntax at 
the connection between two pre-existing syntaxes (i.e.: SQL as C expressions or C expressions within  SQL). 
Implementation would  require copying  and merging syntax descriptions of SQL and C. 
The software engineering problem to be solved is that of the "version  fork"  resulting  from  having  copied code to 
create slightly different language models. Later changes to 

O-8186-7840-2/97  $10.00  0  1997  IEEE  58 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 

common behaviour  may in  general have to be manually propagated to all "derived'  grammars, increasing the risk of 
introducing unnecessary errors. Ideally language implementers should be able to specify 
derived language models in  terms of a base grammar and a summary of  changes. Then, any compiled resources (i.e.: 

object code) of  one language model should be reusable by the compiler when creating resources for derived language 
models. In other words, object code should behave in  ways sympathetic  to modular  language specifications  (which 
emphasise distinctions)  rather than language denotations which may include large amounts of redundancy. 

Figure 1 illustrates the goal by depicting specifications (horizontal  lines and arrows), which  either fully  specify a 
language (LO) or specify a language relative to another (Ll). 

Figure  1.  Language  specifications  vs. language  denotations 
Ellipses  represent derived resources (LO's outlined,  Ll's shaded). Our goal  is  to  achieve an implementation  of Ll 

which,  in  terms  of  the  diagram,  only  creates  derived resources not in the intersection of LO and Ll's  ellipses. 

We use the term extend to refer to the way  a language model extension reuses the specification or implementation 
of another base language model. The goal does not  allow  the possibility  of  a language 
model specified in  terms of more than one other model, but as seen by the examples represents a sufficiently interesting 

goal which may be useful in achieving more general ones. We focus  on parser  specification  and reuse,  which 
constitutes  a  large  portion  of  the  language  tool implementation  effort  [4][6].  So the narrowed goal is  to 

create parsers whose code can be reused as though they were modules.  Hence we use the terms "grammar"  and 
"language model"  as synonyms. For  the purposes of  this paper we do not consider issues of parse tree construction, 
so regarding the behaviour or denotation of some compiled grammar as its recognisor. 

Ideally,  any extension to support modularity  should be maximally orthogonal to existing parser technology, That is, 
it should integrate with any existing parsing scheme without compromising  any  of  that  scheme's  advantages.  For 
reengineering,  expressiveness  and  efficient  parser 

generation are arguably more important than of parse time efficiency. 

Expressiveness is  important  since both  the ability  to create rapid  prototypes  and maintainability  determine 
productivity  in  the reengineering  tool  building  domain rather than parse time efficiency: it  is suboptimal to require 

grammars to be, e.g., LL,  LR  or unambiguous  since this involves more work  to transform  an otherwise executable 
language  specification  into  a (perhaps  less  elegantly expressed) compilable grammar. 

Efficient  parser  generation  is  important  since  (i)  a grammar  will  likely  be  recompiled  frequently  in  a 
prototyping  environment; and, (ii)  the cost of recompiling very large grammars (a likely  occurrence in industrial scale 
projects) is nontrivial even when using an established parser generator such as Refine's parser generation system Dialect 

vol. Parse time  performance  is  less important  since  the 
primary  concern is  the development and maintenance of models for  large complex  languages. Although  software 

reengineering and related disciplines  are often  concerned with  deployment into large scale applications, overall costs 

are often  dominated  by  development,  maintenance  and reuse [21. 

Our  scheme builds  on  combinator  parsing,  which satisfies the criteria above as follows: 
l  expressiveness:  any  context  free  (even  ambiguous) grammar is supported (initially  with the exception of left 

recursion but see later); 
l  flexibility:  the basic scheme can be extended e.g. to sup- port  semantic actions, increase efficiency  or explicitly 

support expression hierarchies [123 (However we are not necessarily claiming that these facilities  are all compati- 
ble with this scheme or each other); 
l  compile time efficiency: creation of top down parsers is typically  cheaper than LR  style parsers; 

l  run time efficiency: The apparent equivalence of combi- nator parsing and chart parsing obtained through optimi- 

sations  such  as memoing  [17]  suggests polynomial worst case parse time complexity. Nearly linear run time 
performance  is  likewise  possible  through  techniques such as the removal of routine ambiguity from "normal" 

grammars, the use of pragmas [13],  and backtracking related optimisations [21]. 
Parsers for  specific  grammars  are implemented  as collections  of  function  definitions.  Through  the use of  a 
hierarchy of  "parseable input streams" (corresponding to a hierarchy of language descriptions) combined with  generic 

functions  and methods for  nonterminals  and productions, parser  code  (in  compiled  form)  is  available  to 
implementation of any derived language model. Several  alternative  schemes providing  support  for 

modular  grammars have been proposed  and developed. 

59 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 

Existing  schemes either  do not  retain  the  flexibility  and succinctness  of  definition  of  an  approach  such  as 

combinator  parsing  or  do not  fully  support  object  code sharing across multiple  language models as required by the 

examples, We defer detailed comparisons until  the section on related work, below, 

The technology presented in this paper is being used as part of an extended version of Software Refinery (called the 
Language  extension  Work  Bench  -  "LXWB"  [18])  to implement  language  tools  for,  e.g.,  preprocessors, 

translators and design recovery tools. 

2.  Source  language 

The parsing scheme presented in  this paper works  for BNF  style  context  free  grammars  consisting  of  a set of 
productions and a set of starting symbols. The scheme is (by design)  closely  related  to  Reasoning  Systems'  Dialect 

parser generator (see the section on related work below). Extra  clauses are required  to  identify  grammars  by 

(unique) name, and (optionally)  specify importation  from another grammar by name: 

grmmar GrIdmel 

(extend  Gname2) 

(Braces denote optionality.) A  dependant grammar GY  which 

extends  a grammar GX  implicitly  includes  all  productions  in  GX,  including 

productions  reused by  GX  from  other grammars (that  is, transitive  extension chains are permitted).  The dependant 

grammar may selectively exclude any nonterminal ("NT") (and its associated productions) 

excluding  NT 

or any single production by specifying the rule in full: 
excluding  NT  ->  I1  .  In 

It  is  an error  for  an excluding  clause to  refer  to nonexistent  nonterminals  or  productions  in  the  base 

grammar. Every  grammar  must  explicitly  define  its  own  start 
symbols. Grammars containing references to nonterminals which 
are neither explicitly  or implicitly  defined (and therefore to nonterminals which have been excluded) are undefined. No 
grammar may extend  another grammar in such a way that it  transitively depends upon itself. 

3.  Infrastructure 

The scheme is based on combinator parsing and several features  found  in  object  oriented  and  functional  (or 

applicative) languages. We present the scheme using both Refine and Allegro  Common LISP, reflecting  the fact that 
our prototype  has been built  using both.  The combinator parsing  library  is presented  in  Refine.  Parser functions 
corresponding to user defined nonterminals are expressed in Common LISP. 

3.1  Software  refinery. 

Software  Refinery  1191 [201 is  a reengineering  tool development environment built  on Allegro  Common LISP, 
which  includes  the  programming  language  Refine. Lexically,  Refine  has an Algal-like  flavour  and is  case- 

insensitive. Refine functions with  signatures of the form 

function  refine-fn  (varl:  typel,  . .  .)  :  result-type .  . 
are accessible to LISP code as functions of the form 

(defun  refine-fn  (varl  var2)  . ..) 
and, conversely,  LISP  functions  of  the second form  are accessible as Refine functions of the first form. 

Refine is  statically  typed and provides  some complex types such as seq  (sequence) and set,  implemented  as 
LISP lists. The type tuple  is also implemented as a LISP list. Refine has a class system which  does not transparently 

interact with  Common LISP's  CLOS  (see below).  Refine also does not directly support laziness or method overriding, 

so  these  features  must  be  accessed  via  functions implemented in LISP. 

3.2  Combinator  parsing. 

Combinator parsing is an elegant parser implementation scheme which  can handle  all  ambiguous  context  free 
grammars  not  containing  left  recursion.  The  scheme involves user defined functions to parse language primitives 

such as tokens, supported by higher order "glue"  functions to combine primitive parsers into more complex parsers. 

Our  initial  implementation  of  the combinator  parser library  does not differ  substantially from  that described by 
Hutton  [Hutton92],  although we actually use opaque types instead of the  Refine seq  type for pstream  and parser. 

The type of a parser function (expressed in Refine) is: 
type  parser  =  map  (pstream,  seq  (parse-result)) 

This type describes functions mapping from values of a class  pstream  to  a list  of  objects  of  class  parse- 

result.  We  assume that  pstream  handles  lexical analysis  and therefore  represents  a sequence of  tokens 

60 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 

(strings). 

type  pstream  =  seq  (string) 

`Ibe definition of the  parse-result  type is 
type  parse-result  =  tuple  (user-object,  pstream) 

that is, two components: a value representing the object successfully parsed 

(user-object  denotes the type of all user  created  objects),  and the  remaining  unconsumed 

portion of the token stream. A simple example of a parser  is a function p-begin 
behaving as follows : 

p-begin  (["begin',..)) ==> 

I  <"begin",  I..)>  ] 
p-begin  (..) ==> 

[I 
That is, the function  returns a sequence containing a tuple representing the appropriate parse result if  its input  starts 

with  the  "begin"  token,  and  the  empty  sequence otherwise. 

"High  level"  parser combinators combine parsers  to create new 

parsers,  achieving the effect of both simple BNF  style operators such as e.g. concatenation 

("then") and alternation  ("orelse")  as well  as EBNF  operators 

such as the Kleene star ("many"). For  example, because in  this implementation  parsers 
return lists of possible parses, the alternation combinator is implemented  simply  as the  list  concatenation  of  the 

application of all parser alternatives to the input stream: 

function  ORELSE  (altl:  parser,  alt2:  parser):  parser  = lambda  (s:  pstream) 

concat  (altl  (ps),  alt2  (ps)) 

3.3  Common  LISP. 

Although  combinator parsers are traditionally  defined for  functional  languages  which  have  lazy  evaluation 
strategies, it  is possible to implement the strategy in  LISP using demand driven evaluation of function  arguments and 
lexically  scoped closures. Demand driven  evaluation of  a function F's argument A  is achieved by wrapping the actual 
parameter expression as a parameterless first class function. At the first point in the definition of F where A is required, it 

is passed as an argument to apply. The Common LISP  Object System (CLOS) is a library 

of  object  oriented  programming  facilities,  including  the generic  function  facility.  Generics  are  declared  with 
signatures  stipulating  the  classes of  their  parameters. Generics may be instantiated  with  method declarations, 
each of which is a function  with  a signature specifying the subclasses of the corresponding generic parameter's class 

for  which  it  applies.  For  every  application  of  a (unary) generic  function  to  its  argument, CLOS  determines  and 
applies the effective method -  the method whose parameter class most closely match the actual parameter's class. 

4.  Implementation  scheme 

The translation scheme: (i)  is presented as a scheme for implementing  BNF  style production  alternatives as parse 
combinators  (section  4.1);  (ii)  is  extended  to  handle scenarios where a nonterminal's parse method may include 
new syntax (section 4.2);  and (iii)  is  further  extended to handle scenarios where syntax may be excluded (section 
4.3). Finally,  the issue of ensuring that names used in parse functions do not collide is addressed in section 4.4. 

In what follows  we make use of the example grammars in Figure 2. Case is not significant, 

grammar  GA 

start-symbols  Item 

item  -t  item-a 
item  ->  item-b 
item-a  ->  "A" 
item-b  ->  `Bl" 

grammar  GB 

extend  GA 

start-symbols  item 
item  ->  item-c 
item-c  ->  'C' 

item-b  ->  "B2" 
Figure  2.  Simple  grammars  GA  and  GB 

4.1  Basic scheme 

For  every  nonterminal  there  must  be  an associated generic function of type parser.  E.g., for  item-b  in GA 
above this would be: 

;  parse  an  item-b  from  the  front  of  a  pstream (defgeneric  p-item-b  (pstream)) 

Each of GA's nonterminal generics must be instantiated with  methods to call  all  associated productions.  E.g.,  for 
item-b: 

;  apply  the  parser  for  all  item-b's  productions ;  to  the  pstream  s 
(defmethod  p-item-b  (pstream  s) (funcall  (orelse  ('p-item-b-ga-1)  ('p-item-b-ga-2)) 

S) ) 
And  hence the references to p-i  tern-b-ga-  1  and p- 

item-b-ga-2: 

(defun  p-item-b-w-1  @stream  s) ;  consumes  a  'Bl'  from  the  pstream  s 

61 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 

(defun  p-item-b-ga-2  (pstream  s) ;  consume  a  "B2"  from  the  pstream  s 

The names for each production's parse function must be unique within  all  nonterminals in  all  grammars, hence the 
inclusion of "ga" in the names above, Figure  3 illustrates  the use  of  LISP  generics  and 
methods to implement p - i  t em according to the scheme so far. In  all  following  diagrams: Ellipses  represent generic 

functions, rectangles represent functions (or methods, with arrows pointing to the instantiated generic) and dashed lines 
represent calls to functions. Quoted text within  rectangular boxes represents a token which  would be expected at that 
point in the input for the recogniser to succeed. 

,t I  1 
(p-item-a)  ,(' F. -.'  `I,, (p-iJem-b) :* 

Figure  3.  Example  of  a  simple  parse-function Implementation 

4.2  Using method  overriding  to  allow  extension 

Consider the grammar GB  which  extends  GA.  In GB, the syntax definition  of  item  is  extended to include 
i  tern-  c.  Thus, "A"  is legal in both GA  and GB, while "C" is legal only in GB. Below we outline the implementation of 
parser functions for GB. 

Distinguishing  Input  Streams. First  we  need  to distinguish between "parsing in  GA"  and "parsing in GB". 
When any pstream  is  created it  must be created as an instance  of  some  subclass  of  ps  tream  uniquely 
corresponding to its  grammar. Classes corresponding to extensions must be subclasses of their bases. So two new 

subclasses of ps  tream  are required: 

(clefclass GA-pscream (pstream)) (defclass  GB-pstream  (GA-pstream)) 

From now  on, methods created specifically  for  some grammar G must  only  be applicable  to  the appropriate 
pstream  subclass associated with  G. For example, we need to retrospectively specify that methods created for GA 
have  parameters  of  class  GA-pstream  instead  of ps 

tream: 

(defmethod  p-item  (GA-pstream  s)  ) 

Providing  fanout  functions  to  allow  reuse of  gram- mar  alternatives.  To  implement  GB,  two  extra 
productions must be recognised. Consider 

item  ->  item-c 
The method for parsing i  tern in GA cannot be changed, or GA  will  behave differently  when "parsing in GA".  Instead 

p-i  tern must be re instantiated so as to override the pre- existing p-i 

tern  applicable to GA-ps  treams. This requires a further refinement to the scheme: for 

every NT  create afunout  function  (uniquely  named as a function of its NT  and grammar). For i  tern in GA this is 

(defun  p-item-GA-f  (s) call  the  generics  for  p-item-a  and  p-item-b 

; 
Ordinarily,  the method for  a particular  NT  (e.g., p- it  em) simply  calls the fanout function  corresponding its 

NT. 

(defmethod  p-item  (GA-pstream  s) (p-item-GA-f  9)) 

When a new method for the same NT is introduced in an extending  LM,  the  new  method  uses  the  "orels  e" 
combinator to call the fanout for both the base grammar, and a new fanout for the NT in its own grammar. Thus, p-  i  t em 
for GB would be implemented as 

(defmethod  p-item  (gb-pstream  s) (funcall  (orelse  'p-item-ga-f  'p-item-gb-f)  s)) 

where  p-i  tern-gb-  f  is  an  ordinary  function implementing the parser which calls the generic for  item- 
C.  Implementing 

is  itself  straightforward since there is no overlap with existing productions in GA. 
Figure  4 illustrates  the objects  created in  order  to implement GA  according to the extended scheme. (In  this 
diagram there are some entities which are functions rather than methods, and hence do not have attached upward solid 
arrows since they do not instantiate anything.) Figure 5 illustrates the new objects created to implement 
GB, and how they link  to the existing objects (shaded area). 
4.3  Exclusion  of syntax  in  extensions 

Let GB be as before, with the additional clause 
excluding  item-b 
meaning that use of i  tern-b  is not valid in GB. The implementation  scheme already provides for  this 

possibility:  instantiate the i  tern-  b  generic in  GB  so that 

62 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 

.-  .) 
&tern-a)  &em-b)  & 

Figure  4:  Implementation  of  grammar  GA using  fanout  functions 

Figure  6.  Using  production  generics  and method  overriding  to  exclude  productions 

:  p-item-c ..`W 

: + 

"c" 
Figure  5.  Example  of  using  fanout  functions and  method  overriding  to  implement 

production  addition 
the new method does not  call  any fanout functions,  but rather calls a "null  parser" (which always fails by returning 

an empty set of possible parses.) GB might alternatively contain the production 

excluding  item-b  ->  'B2" 

meaning that the specific  production  is  invalid.  This requires  that  each production  have its  own production 

generic: 

(defgeneric  p-item-b-gb-1  (gb-pstream)) 

(As stated earlier, the name of the generic function must be unique. Ideally the name should correspond uniquely to 

the  production's  RHS  in  order  to  best  satisfy  the requirement  that  a base language  model  need not  be 
examined by other models.) The production generic is instantiated by a new method 
whenever some language model excludes the production. The implementation  of  the exclusion  example above is 
illustrated in Figure 6. 

4.4  Parse function  namespace management 

Since  there  are several  grammar  implementations coexisting within  one LISP  world,  it  is important that no 
unexpected behaviour occur as a result of  function  name 

collisions  arising from  coincidental name sharing between language models. But the scheme precludes this possibility: 
Nonterminal generic function names cannot collide because the  inheritance  hierarchy  partitions  the  name  space 

correctly:  even if  two completely unrelated grammars GX and GY  define nonterminals with  the same name, the two 

separate instantiations are completely independent by virtue of LISP's  method overriding.  Fanout functions  are again 
unique by  virtue  of  their  naming  scheme (note that the naming scheme used here is fallible  unless grammar names 

are restricted from containing hyphens "-"),  so there is no danger of name collisions between them. 

5.  Related  work  in  modular  parsing 
5.1  Object  oriented  precedence grammars. 

An  implementation strategy devised by  Bloesch et al. [5]  based  on  an object  oriented  implementation  of 
precedence grammars supports sharing of generated parser code. 

The  scheme efficiently  compiles  expression  style grammars but requires a worst case O(n2) transformation to 
handle empty free, deterministic context free grammars. We believe the need for this transformation makes the scheme 

unsuitable for preprocessing grammar modules in isolation. Bloesch described a scheme similar  to ours based on 
recursive descent parsing but  the apparent difficulties  of using recursive descent led to its rejection. 

5.2  Dialect. 

Software Refinery includes a language modelling suite called Dialect  [20]. In Dialect  a grammar may optionally 
name another grammar as its  base. The meaning of  the grammar is then determined relative to the base grammar. 

63 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 

Dialect  generates  parsers  for  some grammar  G  by calculating  its  denoted  grammar  G'  (calculating  any 
changes necessitated if  G is  an extension), then compiling G' using GNU Bison, an LALR(l)  parser generator. 

The advantage of using a preprocessor like  this is that off-the-shelf  parser  technology  can  be  reused  by 
augmenting  an  existing  generator  with  a  simple preprocessor. 

The major disadvantage is that G will  be recompiled in space and time  as a function  of  G',  the denoted grammar, 
Even  small  changes  to  a base  level  language  model necessitate regeneration of  all  dependant language models 

before their behaviour reflects the changes. 

5.3  Lazy  incremental  generation  of  parsers. 

Heering  et a2 [ 1 l]  propose  a tool,  IPG,  which  lazily generates a state table driven  (LALR)  parser and critique 
several  other  possible  methods  for  incremental  parser generation. We have not determined whether theirs or any 
other LALR  based strategy can be modified  to allow  for code sharing. 

5.4  Modular  recursive  descent parsing. 

Koskimies  [16]  developed a parser generation scheme based on specifying modular LL(1)  grammars as collections 
of interdependent Modula-2  modules. Each nonterminal is implemented as a separate function  in  a recursive descent 
parser, A  "start  tree"  is constructed lazily  at parse time  to cache the FIRST  and FOLLOW  sets required in recursive 

descent parsing. Our approach differs  from  Koskimies in  two important 
respects: first,  by  making  use of  combinator  parsing,  no other  special  apparatus is  required  to  support  top  down 
parsing, and secondly, by  making  use of dynamic method dispatch, code sharing is more readily achieved. 

Koskimies'  approach satisfies the first part of the "true sharability"  criterion  because each syntax component is  a 
separately  compilable  module  and  the  dependencies between  productions  are implemented  as inter-module 
dependencies. Consider again our example grammars GA and GB. To implement GA,  each NT  is declared in  its own 
module, and GA is (presumably) defined as a module which imports the modules for  I  tern,,  I  tern-A  and I  tern-B.  To 

implement GB, a (new) module is required for  Item  which must not collide  with  the previous module for  It  em (how 
easy this is in Modula-2 obviously depends on the particular compiler  in  use).  GB  itself  is  implemented  as a module 

which  imports  all  GA's  modules, substituting  the revised version of  Item.  Thus parser code can be shared, however 
object code for  each module must be copied and re-linked whenever it is used in  a new language instance. 

5.5  Extended  chart  parsing. 

While  enrichments  such  as  memoing  and modularisation are being made to top down parsers, there is 
some justification  in  asking  whether  anything  new  is achieved that  has not  already  been  achieved  with  chart 
parsers  [lo].  For  example  Wegbreit  [25]  for  example showed  how  dynamically  extensible  parsing  could  be 

implemented using Earley's algorithm  [9].  Several authors including  Johnson [14]  and Norvig  [17] have remarked on 

the correspondence of chart parsing to strategies involving memoing and (simulated) concurrency [24]. 

We take the position  of  that given such an equivalence, suitable top down parsers are by  no means inferior  since 
they achieve similar  results to chart parsers with  economy of specification and flexibility. 

6.  Evaluation  /  conclusions 
6.1  Modularity. 

The  work  presented  here  satisfies  the  modularity requirement inasmuch as it  supports true sharing of  object 
code. A  grammar  may  extend  no more  than one other grammar, although there is  apparently no reason why  the 
scheme could not be extended to allow such (see below). 
6.2  Expressiveness / abstractness. 

Since the scheme is  based on combinator  parsing,  it admits many enhancements available  to  that regime. For 
example,  although  the scheme presented here  does not construct parse trees, combinator parsers readily support the 

attachment of semantic actions to parser functions. The elegance with  which  the existing  scheme admits 
enrichment demonstrates the feasibility  not only of building a fully  featured  implementation  for  conventional  parser 
specifications, but also extending specification languages to make the modular paradigm for  grammar implementation a 
practical reality. One drawback of the existing scheme is that grammars 

containing  left  recursive definitions  are not  acceptable, a widely  documented deficiency with  the combinator parsing 

scheme as used above -  and with  most top  down parsing schemes  [l].  The  traditional  solution,  removing  left 
recursion prior  to parser generation is suboptimal, because although left recursion may be removed from  each module 

specification,  unexpected  left  recursion  may  occur  as modules  are combined.  Alternative  combinator  parsing 
schemes  based  on  continuation  passing  such  as that described by Johnson [14] do not suffer from  this problem. 
Initial  efforts in  merging our scheme with  Johnson's have 

64 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 

yielded promising results. Our scheme does not easily  admit the use of LR  style 
precedence rules to eliminate  routine  ambiguity  from  e.g. expression hierarchies, however there has been some work 

to create special combinators for expressions which may be applicable [12]. We have not investigated whether these can 
be admitted into our scheme. 

6.3  Compile  time  and  run  time  performance. 

Although  still  a prototype, the scheme has been used to generate parsers for  several grammars, including  a pre- 
existing grammar for Modula-2. Compile time performance of  the parser generation has not  been isolated  from  other 

superstructure in  the prototype but is observably faster than Software Refinery's  Dialect  subsystem when compiling 
small extensions to large base models. After  implementing memoing of fanout functions and lexical analyser calls and 
removing ambiguity  in  expressions, run time performance was of  the order  of  10 times  slower  than  the equivalent 

Dialect generated LALR  parser but arguably acceptable for prototyping purposes. 

As  with  all  general  parsing  strategies,  run  time performance  is  compromised  both  by  the possibility  of 
ambiguous grammars (we expect parsers in  the worst case to have a run  time  complexity  of  O(n3) in  the size of  the 
input) and by the overhead of allowing for the possibility  of ambiguous  grammars  even  when  grammars  are  not 

ambiguous; some optimisations  to address the latter  are possible 1213. 

6.4  Significance. 

As mentioned above in  the section on chart parsing, the novelty  of this work  is twofold:  the use of  object oriented 
notation  and combinator  parser  notation  to  succinctly express powerful,  general,  composite  parsers;  and the 
possibility  of  capitalising  on  further  developments  in combinator parsing which might allow the reuse of efficient 

(i.e.: linear parse time performance) parsers by  "plugging in"  extensions without the need for further parser generation 
or compilation. The  scheme could  be therefore  be used  to  support 

abstract specification  and prototyping  of  truly  modular grammars in  fields  where large scale prototype  language 
models  are vital,  such as constructing  translation  tools, CASE tools and even compilers. 

Tangentially, the usefulness of  object oriented method instantiation  for  this  application  could  be regarded as a 
reason for investigating method dispatch implementations. 

7.  Future  work 
7.1  Prototyping  and  validation 

The  scheme presented here is  one of  several parser generation  schemes integrated  into  a protype  called  the 
Language extension Work Bench (LXWB)  [18]. As  mentioned  in  the  evaluation  section  above, 

investigation  of combinator parsing schemes for handling routine ambiguity is also needed. 

The use of  fanout  functions  is slightly  unsatisfactory since base grammars which  are also extensions must create 
fanout  functions  for  whatever  NTs  they  propagate  to downstream  extensions.  A  more  appropriate  technique 
might be to use the CLOS call-next-method  facility. Further work  in  applying  this  scheme to new and pre- 

existing  extension hierarchies,  is  needed to  validate  the usefulness of the modularity paradigm and the applicability 

of this scheme in practice. Further  work  in  integrating  alternative  combinator 
parsing strategies with  our scheme would both increase the viability  of  the scheme described here to be used in  real 
language  model  implementations  and demonstrate  the flexibility  of these schemes. 

7.2  Extending  concepts of  grammar  extension  and modularity. 

Wildman  [27]  showed  the  desirability  of  grammar composition  (versus extension);  some key  composition 
operations could  be implemented  elegantly  based on the current scheme. For example, the current scheme allows a 

grammar to use at most one other grammar. Proper support for  the second example in  the introduction  (4GL)  requires 
that  multiple  grammars  be  used.  Provided  existing constraints  are satistied,  multiple  grammar use could  be 

added by means of CLOS's multiple inheritance scheme. To be  consistent  with  existing  semantics,  rules  must  be 
introduced  for  resolving  name conflicts  where the same nonterminal names have different meaning in base models. 

Implementing the representative input class for: 
grammar GZ extend  GX,  GY 

would require the declaration: 

(defclass  GZ-pstream  (GX-pstream  GY-pstrem)) 

GZ would be constructed by  implicitly  including  all  of GX's and GY's productions, except where productions were 

explicitly  excluded. Methods instantiated for gz-ps  tream would  then  override  methods  instantiated  for  gx- 

pstream  and gy-pstream. 

65 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 

Acknowledgements 

Ian Peake's contribution to this work was sponsored by an Australian Postgraduate Award and a scholarship from 
the  Australian  Defence  Science  and  Technology Organisation. 

References 

Ul 

PI 

131 

141 
VI 
[61 
[71 
Fl 

[91 
[lOI 

[111 

U21 

A.  Aho,  R.  Sethi,  and  J. Ullman.  Compilers:  principles, 

techniques  and  tools.  Addison-Wesley,  Reading,  1986. 

P. Bailes,  M.  Chilvers,  and  I.  Peake.  A  generic,  knowl- 
edge-based,  re-engineering  architecture.  In  Proceedings 
6th International  Workshop  on CASE, pages 190-198,  Sin- 
gapore,  1993. IEEE. 

P. Bailes,  T.  Chorvat,  and I.  Peake. A  formal  basis  for  the 
perception  of  programming  as a language  design  activity. In  Proceedings  of  the  6th  International  Conference  on 

Computing  and Information,  volume  1 of  Journal  of  Com- puting  and Information,  pages 1279-1294,  Trent  Universi- 
ty,  1994. 
A.  Berglas  and J. Harrison.  Evaluation  of  the ITOC  Infor- mation  System  Design  Recovery  Tool.  In  Proceedings  of 

the  Workshop  on  Program  Comprehension,  Dearborn, 
Michigan,  USA,  1997. to  appear. 

A.  Bloesch  and T.  Halpin.  An  object-oriented  approach  to extensible  parsing.  In  16th  Australian  Computer  Science 

Conference,  volume  B,  pages 345-351,  Feb.  1993. 
P. T.  Breuer  and .I. P. Bowen.  A  PREttier  compiler-compil- er:  generating  higher-order  parsers  in  C.  Software  - Prac- 

tice  andExperience,  25(11):1263-1297,  Nov.  1995. 
L.  Cardelli,  F.  Matthes,  and  M.  Abadi.  Extensible  syntax with  lexical  scoping.  Research Report  121, Digital  Systems 

Research Centre,  Palo  Alto,  California,  Feb.  1994. 
J. R.  Cordy  and  C.  D.  Halpern.  TXL:  a rapid  prototyping system for  programming  language  dialects.  In  Proceedings 

IEEE  International  Conference  on  Computer  Languages, Miami,  Nov.  1988. 

J. Earley.  An  efficient  context-free  parsing  algorithm. Communications  of the ACM,  26(l),  Jan. 1983. 

S. L.  Graham  M.  A.  Harrison,  and W.  L.  Ruzzo.  An  Im- 
proved  Context-Free  Recognizer.  ACM  Trans.  Prog.  Lang. Syst., 2(3):415-462,  July  1980. 

.I. Heering,  P. Klint,  and J. Rekers.  Incremental  generation of  parsers.  IEEE  Transactions  on  Software  Engineering, 

16(12):1344-1351,  Dec.  1990. 
S. Hill.  Combinators  for  parsing  expressions.  Functional 
Programming,  6(3):445-463,  May  1996. 

[I31 
Cl41 
u51 

U61 

u71 
iI81 
u91 
WI 
1211 

[221 
[231 
WI 
v51 
WI 

r271 

G. Hutton  and  E. Meijer.  Monadic  Parser  Combinators. 
Technical  Report NO'ITCS-TR-96-4,  Department  of  Com- puter  Science,  University  of  Nottingham,  1996. 

M.  Johnson.  Memoization  in  Top-Down  Parsing.  Compu- 

tational  Linguistics,  21(3):405-417,  1995.  Discussion  Pa- 
per. 

S. Kamin  and E. Golin.  Report  of  a workshop  on future  di- 
rections  in programming  languages  and compilers.  Techni- cal report,  University  of Illinois,  1994. NSF  CCR-9304990. 

K.  Koskimies.  Lazy  recursive-descent  parsing  for  modular language  implementation.  Software-Practice  and  Experi- 

ence, 20:749-772,199O. 
P. Norvig.  Techniques  for  automatic  memoization  with  ap- plications  to  context-free  parsing.  Computational  Linguis- 

tics,  17(1):91-98,  1991. 
I.  Peake.  User's  guide  to  the  language  extension  work 
bench version  1. Technical  Report  387,  School  of Infonna- tion  Technology,  University  of  Queensland,  1996. 

Reasoning  Systems,  Palo  Alto,  California.  Refine  user's 
guidefor  Refine  version  3.0  on Sun computers,  1990. 

Reasoning  Systems,  Inc.,  Palo  Alto,  California.  Dialect  us- 
er's  guide for  Dialect  version  1.0,  1990. 

N.  Rojemo.  Garbage  collection  and  memory  eflciency  in lazyfunctional  languages.  PhD  thesis,  Chalmers  Universi- 

ty  of  Technology,  1995. 
T.  Standish.  Extensibility  in  programming  language  de- sign. In Proceedings  ofAFIPS  Conference,  pages 287-290, 

Ahaheim,  1975. 
N.  Stern  and R. A.  Stern.  The  Wiley  COBOL  syntax  refer- 
ence  guide:  with  IBM  and  VAX  enhancements.  Wiley, 

1994. 

D.  S. Warren.  Memoing  for  logic  programs.  Communica- tions 

of  the ACM,  35(3):93-l  11, Mar.  1992. 

B.  Wegbreit.  Studies  in  extensible  programming  languag- es. Garland  Publishing,  London,  1980. 

D.  Weise  and D.  Crew.  Programmable  syntaxmacros.  SIG- PLAN  Notices,  28(6):1X--165,  1993.  (Proceedings  of 
ACM  SIGPLAN  `93  Conference  on  Programming  Lan- 

guage Design  and Implementation). 

L.  Wildman  and  I.  Hayes.  Composing  grammar  transfor- mations  to  construct  a specification  of  a parser. Australian 

Computer  Science  Communications,  17(1):556-562,1995. 

66 
Proceedings of the 8th International Workshop on Software Technology and Engineering Practice (STEP '97)0-8186-7840/97 $10.00 (C) 1997 IEEE 