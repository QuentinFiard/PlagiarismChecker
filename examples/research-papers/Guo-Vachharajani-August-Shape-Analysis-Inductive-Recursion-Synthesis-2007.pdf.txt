

Shape Analysis with Inductive Recursion Synthesis

Bolei Guo Neil Vachharajani David I. AugustDepartment of Computer Science
Princeton University {bguo,nvachhar,august}@princeton.edu

Abstract
Separation logic with recursively defined predicates allows for con-cise yet precise description of the shapes of data structures. However, most uses of separation logic for program analysis rely onpre-defined recursive predicates, limiting the class of programs analyzable to those that manipulate only a priori data structures. Thispaper describes a general algorithm based on inductive program
synthesis that automatically infers recursive shape invariants, yield-ing a shape analysis based on separation logic that can be applied
to any program.A key strength of separation logic is that it facilitates, via explicit expression of structural separation, local reasoning aboutheap where the effects of altering one part of a data structure are
analyzed in isolation from the rest. The interaction between localreasoning and the global invariants given by recursive predicates is
a difficult area, especially in the presence of complex internal shar-ing in the data structures. Existing approaches, using logic rules
specifically designed for the list predicate to unfold and fold linked-lists, again require a priori knowledge about the shapes of the data
structures and do not easily generalize to more complex data struc-tures. We introduce a notion of "truncation points" in a recursive
predicate, which gives rise to generic algorithms for unfolding andfolding arbitrary data structures.

Categories and Subject Descriptors F.3.1 [Logics and Meaningsof Programs]: Specifying and Verifying and Reasoning about Programs; F.3.2 [Logics and Meanings of Programs]: Semantics ofProgramming Languages--Program analysis

General Terms Languages, Theory
Keywords Shape analysis, separation logic, loop invariant infer-ence, inductive recursion synthesis, artificial intelligence

1. Introduction
Shape analysis aims at an accurate description of the programheap layout, which can enable aggressive optimizations, program

verification, and program understanding tools. With the prevalentuse of dynamic memory allocation, a heap abstraction must have
some way of describing infinite number of concrete heaps with afinite representation. Among such techniques are summary node [1]
which groups elements of potentially unbounded data structuresinto a finite number of abstract heap nodes, and k-limiting [2] which
only distinguishes elements of a linked data structure up to depth
k. In both cases, the approximation of memory states leads to

Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citationon the first page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior specific permission and/or a fee.
PLDI'07 June 11-13, 2007, San Diego, California, USA.Copyright cfl 2007 ACM 978-1-59593-633-2/07/0006.. . $5.00.

loss of information about the shapes of recursive data structures.Inductively defined predicates such as those used in separation
logic [3] allow for concise yet precise description of recursivedata structures. For example, an acyclic linked-list is captured by
list(x) .= (x = null ^ emp) . (x ! ff * list(ff)). Althoughexpressive, a problem with these predicates is that it is difficult to
infer them from the program. As a result, current uses of separationlogic usually have a handful of pre-defined predicates hardwired
into the logic and are limited to program verification where thelogic engine is supplied with user specifications that a predicate
holds at certain program point. In the case of linked-lists, logic rulescan be designed to recognize certain patterns in the logic formulae
and rewrite them to synthesize the list predicate. Two analyses oflist-processing programs are proposed [4, 5], both containing a rule
that says if x points to y and y points to z then there is a list segmentbetween

x and z. It is difficult to generalize this to arbitrary datastructures. Lee et al. propose a grammar-based shape analysis [6]

that automatically discovers grammars which can be translated torecursive predicates. However, their grammars can have only one
explicit parameter, limiting the class of data structures describable.We propose a shape analysis that performs inductive recursion synthesis to automatically infer arbitrary recursive predicates,effectively reverse-engineering the data types in the program.
This technique leverages an existing method in artificial intelli-gence called inductive program synthesis, originally developed for
constructing recursive logic programs from sample input/outputpairs [7, 8]. It allows the analysis to extract a loop invariant from a
constant number of symbolically executed loop iterations. Sound-ness is guaranteed by verifying that the invariant derives itself over
the loop body. If so, then it allows the analysis to converge overthe loop and proceed, but unlike many widening operations used to
reach fixed points, there is no approximation involved and henceno loss of precision. Otherwise, the analysis will halt and report
failure. This technique can infer any data type with a tree-likebackbone and some other pointer fields that point in the backbone, possibly producing dags and cycles. This gives our analysisthe same descriptive power as the Pointer Assertion Logic [9].
However, in their framework shape invariants are already given bynon-traditional data type declarations and the logic engine relies on
user specifications including procedure pre- and post-conditions,and loop invariants. our analysis starts with zero knowledge and
infers everything, the data types, the procedure summaries, and theloop invariants from scratch. Inductive recursion synthesis is also
used to converge over recursive procedures.Another difficulty in using recursive predicates lies in the fact
that while they express global properties that hold over entiredata structures, most programs perform many local alterations (insertions, deletions, rotations, etc.) to the data structures and re-establish global properties afterwards. Ideally, the analysis should
be able to zoom in on a small part of a data structure, reason aboutit ignoring the rest, and then zoom back out. The spatial conjunction operator of separation logic is designed to facilitate this kindof local reasoning via explicit expression of structure separation

and aliasing. However, for data structures with complex internalsharing, isolating a sub-structure separate from the rest is difficult.
In [4, 5], logic rules tailored to the list predicate can unfold a listto expose a list element and fold it back. But, again, this does not
easily generalize to other data structures. To enable smooth transi-tioning between local reasoning and global invariants, we introduce
the notion of "truncation points" in a recursive predicate, whichhelps the analysis to cut corners out of a data structure. Generic
algorithms based on truncation points are then designed to unfoldand fold arbitrary recursive data structures.

The shape analysis presented in this paper is interprocedural.Like the analysis by Gotsman et al. [10], at each procedure entry, it
extracts the region of heap accessed by the procedure, called localheap, from the rest of the heap and, upon return, re-incorporates
this updated local heap using the Frame rule of separation logic.Cutpoints [11], the nodes that separate the local heap from the
frame, are preserved so that upon return the callee's effects canbe properly propagated to the caller. In the presence of recursive
procedures, the number of cutpoints can be infinite. [10] boundsthe number of cutpoints at the cost of potential precision loss. In our
case, inductive recursion synthesis allows cutpoints to be describedinductively in the entry/exit invariants of recursive procedures,
hence there is no need to bound them.Our goal is to handle real-life C programs like those in the SPEC
benchmarks, whose data structures are complex and cannot be eas-ily taken apart into independent pieces. We will use as a running example the benchmark 181.mcf from SPEC2000, which builds andmanipulates a left-child right-sibling tree with two kinds of backward links - a parent link and a left-sibling link. As shown in Fig-ure 1, there is a great degree of internal sharing which makes both
inferring its shape and reasoning about its shape challenging. Ad-ditionally, many applications perform their own memory management using arrays. To model this correctly, our analysis tracks alias-ing that arises from pointer arithmetic. Finally, the algorithm performs a pre-pass including a fast pointer analysis and program slic-ing to preserve only code that may affect the result of shape analysis. This effectively reduces the overhead of being flow-sensitive onrealistic programs, which is important because flow-sensitivity allows strong updates, key to shape analysis. This also reduces noisesthat may confuse the inductive recursion synthesis algorithm.

child

parent sib

sib prev

fi2

fi1

h0

h

Figure 1. A specimen of the tree used in 181.mcf
In summary, the contributions of this work are:

* An algorithm for inferring recursive shape invariants based on

inductive program synthesis.*

A general algorithm for unrolling and rolling back arbitraryrecursive data structures, even those with internal sharing.

* Techniques to handle real-life applications.

Section 2 defines the abstract semantics. Section 3 describesinductive recursion synthesis, and Section 4 presents the algorithm

for unrolling and rolling recursive predicates. Section 5 describesthe implementation of our analysis. Preliminary test results are
reported in Section 6. Section 7 discusses related work and finally,Section 8 concludes.

2. Abstract States and Abstract OperationalSemantics

Labels l 2 LabelGlobals

g 2 GlobalRegisters
r 2 RegExprs
e ::= null | g | rInsts
s ::= r = e | r = malloc() | free(r) | r = f(~x) |

[r1] = r2 | r1 = [r2] | goto l | if c goto lBranch Conds
c ::= r1 = r2 | r1 6= r2

Vars ff 2 V arRecursion vars

A 2 RecHeap names
h ::= g | ff | h.nSymbolic vals
v ::= null | h | h + nPure assertions
P ::= v1 = v2 | v1 6= v2Heap assertions
H ::= h1.n ! h2 | A(h1, ..., hn[; h01, ..., h0m])Register values
\Pi  ::= ff | \Pi , r = vHeap formulae
\Sigma  ::= emp | H | \Sigma  * \Sigma Pure formulae
\Phi  ::= P | \Phi  ^ \Phi States
S ::= \Pi  | \Sigma  | \Phi Predicate defs
\Theta  ::= ff | \Theta , A .= P . \Sigma Proc summaries
\Gamma  ::= ff | \Gamma , (f, \Pi entry|\Sigma entry|\Phi entry, \Pi exit|\Sigma exit|\Phi exit)

Table 1. Target Language and Abstract States

The target language of our analysis is an assembly like low-level intermediate language used by our optimizing C compiler.
The syntax of the language is shown in Table 1. Globals are namesof heap locations allocated for global variables. Our analysis also
handles instructions such as r1 = r2 * n and r1 = r2 + n, whichperform pointer arithmetic. For simplicity of presentation, they are
not included in the discussion here. Detailed treatment of arrays andpointer arithmetic is based on the low-level pointer analysis by Guo
et al. [12]. The symbolic values computed in this analysis containoffset information. Indistinguishable array elements are collapsed
into one element.The rest of this section describes the abstract representation
of states and an abstract operational semantics of the instructionstailored to the unstructured control flow of machine-level code.

2.1 Abstract States
An abstract state \Pi  | \Sigma  | \Phi  consists of a mapping \Pi  fromregisters to their symbolic values, a separation logic formula

\Sigma that is the conjunction of a finite number of atomic heap assertions,

and a pure formula \Phi  that records true branch conditions alongthe execution paths with which the state is associated and also
records aliasing between pointer arithmetic and heap names. Twoglobal environments are maintained:

\Theta  for recording the definitionsof recursive predicates and
\Gamma  for tabulating procedure summaries.Table 1 gives the definition of the state.

Unlike the "symbolic heaps" defined in [13], which use pro-gram variables (the high-level counterpart of registers) to name
heap locations and record alias relationships between program vari-ables, our analysis takes the "points-to" approach, assigning unique
names to heap locations and recording the target of each registerexplicitly. Aside from the benefit that there is no need for "rearrangement" rules which set the pre-state in a suitable form bygoing through the alias pairs, this facilitates the inductive recursion
synthesis algorithm. As will be explained in Section 3, the access-path- like heap names encode important patterns of spatial relationships between heap locations that can be recognized and thengeneralized via inductive reasoning. The heap names can be simply
thought of as logic variables with long names.Recursive predicates are parameterized so that they are expressive enough to describe data structures with internal sharing viabackward links. The first parameter represents the top of the data
structure and the rest represent the targets of backward links. Forexample, the left-child right-sibling tree with parent and left-sibling

links from 181.mcf can be written as:

mcf tree(x1, x2, x3) .= (x1 = null ^ emp) .

(x1.parent ! x2 * x1.child ! ff * mcf tree(ff, x1, null) *

x1.sib prev ! x3 * x2.sib ! fi * mcf tree(fi, x2, x1)).

An instance of such a tree where the root h has null parentand sib prev links is described by instantiating the predicate:

mcf tree(h, null, null).We also introduce a new type of recursive predicates called
truncated recursive predicates, A(h1, ..., hn; h01, ..., h0m) where nis the arity of

A. This is designed for handling modifications toa data structure when the analysis needs to isolate relevant parts

of the data structure so as to reason about the modifications in alocalized fashion. The second set of parameters {

h01, ..., h0m} is ofvariable length and is what we call the set of truncation points in

the data structure rooted at h1. This predicate is syntactic sugar for
(*i=1..m9fii,1, ..., fii,n-1.A(h0i, fii,1, ..., fii,n-1))-*A(h1, ..., hn)(both the iterated spatial conjunction operator and the "magic

wand" operator -* are defined in [3]). It identifies a heap that,when combined with

m heaps rooted at h01, ..., h0m on each ofwhich
A holds, yields a heap rooted at h1 on which A holds. Inother words, this is the data structure reachable from

h1, with allsub-graphs rooted at
h01, ..., h0m cut out from it. Because the pred-icates are "precise" [14] in that each unambiguously identifies a

piece of heap, when A(h1, ..., hn) holds on the combined piece ofheap, it must go through all the nodes in it. Hence it is impossible
to have a situation where the truncation points do not truncate thedata structure at all, ensuring the correctness of our definition. The
definition also specifies that the sub-graphs are mutually disjoint,i.e. no truncation point can be in the sub-graph of another truncation point. This invariant is crucial for unrolling predicates asit constrains the number of possible outcomes (details are in Section 4). In Figure 1, suppose that at some program point, there is apointer to an interior node

h0 of the tree, then the heap is describedas mcf tree
(h, null, null; h0) * mcf tree(h0, fi1, fi2). By the defini-tion of mcf tree, we know that the dangling points

fi1 and fi2 of theheap mcf tree
(h0, fi1, fi2) are backward links and therefore residein the other half of the heap.

A linked-list fragment between x and y can be described bylist
(x; y), which looks similar to the "list segment" predicatelist
(x, y) .= (x = y ^ emp) . (x ! ff * list(ff, y)) defined in[15]. However, this predicate is defined by specifying a path by

which y is reached from x and is therefore hard to generalize tomore complex data structures, whereas we avoid this complication entirely by working not from the top of the data structure, butfrom the bottom, and hiding the reaching path information with the
"magic wand". Not only is our approach completely general andcapable of handling messy backward links, it is also more flexible
by allowing a variable number of truncation points. This is impor-tant because unlike lists, other data structures may have more than
one end. The ability to model this comes in handy, for example,when cutting and grafting sub-trees.

Let JK\Pi ,\Phi  be a function that evaluates each expression e to aheap name or null.J

nullK\Pi ,\Phi  = null JgK\Pi ,\Phi  = gJ

rK\Pi ,\Phi  = 8><>:

h0 if \Pi (r) = h + n and \Phi  records the alias h + n = h0
ff if \Pi (r) = h + n and \Phi  records no alias of h + n,

ff is a fresh variable
\Pi (r) otherwise

The partial order v over the set of abstract states is defined asfollows:

\Pi 1 | \Sigma 1 | \Phi 1 v \Pi 2 | \Sigma 2 | \Phi 2 if there exists amapping

f between the heap names in the two states such that (i)for each
r 2 Domain(\Pi 1), if JrK\Pi 1,\Phi 1 = null, then JrK\Pi 2,\Phi 2 = null;otherwise

f(JrK\Pi 1,\Phi 1) = JrK\Pi 2,\Phi 2, and (ii) for each atomic H in

\Sigma 1, f#(H) is in \Sigma 2, f# replaces each h appearing in H with f(h),and (iii) for each atomic

P in \Phi 1, f##(P ) is in \Phi 2, f## replacess each
h in P with f(h). Obviously there could be infinitely increasinglychains of abstract states. Termination of the analysis is achieved via

inductive recursion synthesis.
2.2 Abstract Operational Semantics
We give the abstract operational semantics for the target languagein the style of L

c, a compositional logic for control flow [16], withsome modifications. Most noticeably, our logic rules are written

for forward analysis while those in [16] are for backward analysis.The judgment we use is:

\Psi , F ` \Psi 0. F is a set of programfragments
l(s)l0, with label l identifying the entry of instruction
s and l0 identifying the exit. \Psi  and \Psi 0 are sets of labeled states:
\Psi  = {l1 : S1, ..., ln : Sn}, \Psi 0 = {l01 : S01, ..., l0m : S0m}.Labels

l1, ..., ln are where the control flow may enter F and labels
l01, ..., l0m are where it may leave F . The judgment is read as: if for
i = 1..n, the state at entry li is Si, and the execution of F does notget stuck, then for

j = 1..m, the state at exit l0j is S0j.Table 2 lists the operational rules that transform entry states of a

program fragment to exit states. It includes one rule for each primi-tive instruction, composition rules

COMBINE, DISCHARGEand
WEAKEN for combining individual instructions, and therule

UNFOLD for unrolling a recursive predicate to reveal apoints-to fact. Note, the rules shown in the table perform strong

updates to the abstract state. In the case of aliasing due to arrayelements collapsed into a single heap element, the analysis would
have to use an alternate set of rules which perform weak updates.In the rule

MALLOC, ff.? !? simply registers ff as anallocated heap node whose content is unknown.

MUTATE invokes an important sub-routine rearrange names,shown in Figure 2, to encode access-path info in heap names. The
recursion synthesis algorithm relies on this to identify the basicstructure of a recursion. rearrange names assumes that the current
heap satisfies h1.n ! h2 and that v is to be written to h1.n. Theappropriate name for

v is determined based on its form:

* If it is a simple variable, then we assign h1.n as its new name.If the old content stored in field

n of h1 has already claimedthis name, then the old content is renamed to a fresh variable.

* If it is a heap name plus an offset, then it points to the middle of

a structure, most likely an array element. As in the first case,
h1.n is assigned as its new name. Additionally, the analysisrecords in

\Phi  that the pointer arithmetic aliases with h1.n sothat if later the location is visited via pointer arithmetic instead

of access path, the analysis will recognize it as well.*
Otherwise, v points to a heap location that has already beenlinked to a parent, and no special action is necessary.

The intuition behind this is: While a heap location may be reach-able via multiple access paths (one data structure may contain cross
pointers to another data structure; or, within a single data structure,a node may be internally shared in the presence of dags and cycles),
the algorithm chooses the access path that reveals the acyclic back-bone of the recursive data structure to which the location belongs.
Our heuristic is to inherit the access path of first location it is linkedto, taking advantage of the fact that such a link is usually created
when adding a new expansion to a recursive data structure.The rule

PROC CALL is the same as the one given in [10].It exploits the Frame rule by breaking the heap at a call site into

the "local heap" accessed by the callee and a frame. oe is a map-ping between the formal parameters and the actuals, and between
the return value and destination register of the call instruction.
PROC CALL is understood as follows: If there exists in \Gamma  arecorded summary of the callee,

(f, \Pi entry | \Sigma entry | \Phi entry, \Pi exit |

rearrange names(h1, n, h2, v)if

v = a thenif

h2 = h1.n thenreplace

h2 everywhere with a fresh variablereplace
v everywhere with h1.nreturn
h1.nelse

if v = h + n thenif

h2 = h1.n thenreplace

h2 everywhere with a fresh variablerecord alias h

h + n, h1.nireturn
h1.nreturn
v

Figure 2. Algorithm of rearrange names

\Sigma exit | \Phi exit), and the current heap \Sigma  can be separated into disjointpieces

oe(\Sigma entry) and R, then the heap after the call instruction is aconjunction of

oe(\Sigma exit) and R; and r is assigned the return valuetranslated by
oe (ret is special register for holding return values).Since we are not concerned with bounding the number of cutpoints,

they are simply treated as dangling points from the frame.The rule responsible for termination of the analysis is normalize. There are two kinds of normalization operations. From a sub-heap, synthesis infers a recursive description that is guaranteed to
be more general. fold reduces the size of the state by folding sur-rounding heap nodes into a recursive predicate.

3. Inferring Recursive Predicates
This section describes the algorithm for automatically inferring re-cursive predicates. It enables the analysis to arrive at loop invariants

without introducing unnecessary approximation. Loop invariant in-ference proceeds in the following steps:

1. Symbolically execute the loop body up to a fixed number oftimes (2 suffices in the experimentation).
2. If the analysis does not converge over the loop at this point, theninvoke inductive recursion synthesis, which returns a hypothesized loop invariant.
3. Verify the soundness of the loop invariant by assuming that itholds on loop entry and checking that for each control flow

path in the loop, if \Sigma 0 is the heap at the end of the path, thenfold

\Theta (\Sigma 0) = \Sigma invariant. If the analysis diverges, then halt andreport failure.

4. Otherwise, the loop invariant is valid. By the algorithm ofrecursion synthesis, the states associated with the loop entry

in the initial number of iterations must be derivable from theinvariant by unrolling it. Hence they are eliminated using the
WEAKEN rule.
3.1 The Inductive Recursion Synthesis Algorithm
Inductive program synthesis, the problem of automatic synthesisof recursive programs from input/output samples, studied in AI research, resembles loop invariant inference in the sense that the in-put/output samples are provided by finite executions of the loop
and the invariant can be seen as a highly abstracted encoding ofthe loop. The approach introduced by Summers [7] consists of two
steps. First, the input/output samples are rewritten as finite pro-gram traces, then a recurrence relation is identified by inspecting
the traces. In our case, the program trace is readily available asthe heap formula after execution of the loop, with crucial information encoded in the logic variable names by rearrange names inSection 2. The logic formula is translated into a term, the form of
inputs on which the recurrence detection algorithm operates, usingthe domain knowledge about heap semantics. Such global inspection of states is only conducted when converging over loops. Therest of the analysis updates states locally.
3.1.1 Translating Heap Formulae into Terms
The set of terms is defined in Figure 3. A term can be viewed as atree where each symbol is a node.

Terms t ::= x variables|

c constants|
f(t1, .., .tn) functions

Figure 3. Set of Terms

The idea is to map each heap location to a term that describesthe data structure reachable from it, referred to as a "heap" term.
We start by assigning a function symbol to each logic operator, *
for spatial conjunctions, n! for points-to assertions with n beingthe field, and the predicate name for predicate instantiations. As

the heap locations are interconnected with each other, naturallysome terms will be sub-trees of other terms. While the heap may
contain dags and cycles, the term tree structure must remain acyclic(consistent with the fact that the backbones of inductive definitions
are acyclic). To achieve this, each heap location is also associatedwith a "name" term. For all appearances of a heap location on
the right hand side of a points-to assertion, only one will result inthe corresponding heap term being linked as a sub-tree of the left
hand side. All others are translated into name terms by the rewritefunction

[], cutting the points-to link in a sense.

[null] = NULL [g] = g [ff] = ff [h.n] = n([h]).

The translation process maintains a mapping fl from heap locationsto heap terms.

[] is overloaded to translate heap formulae to terms.

[A(h1, ..., hn[; h01, ..., h0m])] = fl(h1) =

A([h1], ..., [hn][; [h01]..., [h0m]))
[h.n1 ! h1 * ... * h.nr ! hr] = fl(h) =

*(n1! ([h], get term(h, h1)), ..., nr! ([h], get term(h, hr))),

get term(h1, h2) = j fl(h2) if h2 = h1.n[h2] otherwise

In a depth-first traversal of the abstract heap, every predicate in-stantiation is translated into the heap term of the first parameter; all
points-to assertions with the same location on the left hand side aretranslated together into the heap term of that location. The choice
between a heap term and a name term for the right hand side isguided by the access paths encoded in the names of the heap locations. The final result is a forest of top-level term trees and becauseof the heuristic adopted in rearrange names, each of these trees
roughly corresponds to a different data structure in the program.Figure 4(a) contains a loop from 181.mcf that builds the leftchild right-sibling tree with backward links. nodes is an array oftree nodes. All new tree nodes are subsequently requested from it.
Figure 4(b) shows the term tree after two iterations of the loop.Each * term represents a distinct node in the data structure, whose
name is given in the parenthesis next to it. For each field n in the
node, the corresponding * term contains n! term whose left sub-term is the name of the source location and the right sub-term is

either the name of the target location or the * term representingthe target location. In the latter case, the expansion of the data
structure is continued from below the * term. In the former case, thedata structure reachable from the target location will be expanded
along some other access path reaching that target. The term inFigure 4(b) completely captures the effect of the loop on heap at
this execution point and presents it in such a way that exposes theunderlying recursive pattern to the recurrence detection algorithm.

{l : \Pi  | \Sigma  | \Phi }, {l (r = e) l0} ` {l0 : \Pi [r = JeK\Pi ,\Phi ] | \Sigma  | \Phi } ASSIGN
{l : \Pi  | \Sigma  | \Phi }, {l (r = malloc()) l0} ` {l0 : \Pi [r = ff] | \Sigma  * ff.? !? | \Phi } , ff fresh MALLOC
{l : \Pi , r = h | \Sigma  * H(h) | \Phi }, {l (free(r)) l0} ` {l0 : \Pi , r = h | \Sigma  | \Phi } , H(h) ::= h.n ! h

0 | A(h, ...) FREE

{l : \Pi , r1 = h1 + n | \Sigma  * h1.n ! h2 | \Phi }, {l (r2 = [r1]) l0} `{

l0 : \Pi , r1 = h1 + n [r2 = h2] | \Sigma  * h1.n ! h2 | \Phi }

LOOKUP

h02 = rearrange names(h1, n, h2, v){
l : \Pi , r1 = h1 + n, r2 = v | \Sigma  * h1.n ! h2 | \Phi }, {l ([r1] = r2) l0} `{

l0 : \Pi , r1 = h1 + n, r2 = h02 | \Sigma  * h1.n ! h02 | \Phi }

MUTATE

{l : S}, {l (goto l1) l0} ` {l1 : S} JUMP {l : S}, {l (if c goto l1) l0} ` filter(c)(l1 : S) [ filter(~c)(l0 : S)} BRANCH

\Gamma  ` (f, \Pi entry | \Sigma entry | \Phi entry, \Pi exit | \Sigma exit | \Phi exit) \Sigma  |= oe(\Sigma entry) * R
{l : \Pi  | \Sigma  | \Phi }, {l (r = f(~x)) l0} ` {l0 : \Pi [r = oe(\Pi exit(ret))] | oe(\Sigma exit) * R | \Phi } PROC CALL

unfold\Theta (l : S, h), F ` \Psi 0{

l : S}, F ` \Psi 0 UNFOLD

\Psi 1, F1 ` \Psi 01 \Psi 2, F2 ` \Psi 02
\Psi 1 [ \Psi 2, F1 [ F2 ` \Psi 01 [ \Psi 02 COMBINE

\Psi  [ {l : S}, F ` \Psi 0 [ {l : S}

\Psi , F ` \Psi 0 [ {l : S} DISCHARGE

\Psi , F ` \Psi 02 \Psi 02 ) \Psi 01

\Psi , F ` \Psi 01 WEAKEN

\Psi 1 ' \Psi 2
\Psi 1 ) \Psi 2 superset

\Sigma 0  \Sigma 
\Psi  [ {l : \Pi  | \Sigma  | \Phi } ) \Psi  [ {l : \Pi  | \Sigma 0 | \Phi } normalize

recursion synthesis(\Sigma 1) = A(h1, ..., hn[; ff1, ..., ffm])

\Sigma  * \Sigma 1  \Sigma  * A(h1, ..., hn[; ff1, ..., ffm]) synthesis

fold\Theta (\Sigma 1) = A(h1, ..., hn[; ff1, ..., ffm])
\Sigma  * \Sigma 1  \Sigma  * A(h1, ..., hn[; ff1, ..., ffm]) fold

filter(r1 = r2)(l : \Pi  | \Sigma  | \Phi ) = j {l : \Pi  | \Sigma  | \Phi  ^ Jr1K\Pi ,\Phi  = Jr2K\Pi ,\Phi } if \Phi  0 Jr1K\Pi ,\Phi  6= Jr2K\Pi ,\Phi ff otherwise
filter(r1 6= r2)(l : \Pi  | \Sigma  | \Phi ) = j {l : \Pi  | \Sigma  | \Phi  ^ Jr1K\Pi ,\Phi  6= Jr2K\Pi ,\Phi } if \Phi  0 Jr1K\Pi ,\Phi  = Jr2K\Pi ,\Phi ff otherwise

Table 2. Abstract Operational Semantics

nodes = malloc(MAX_NODES);
root = nodes;
node = nodes+1;
root->parent = null;
s1: root->child = node;

root->sib = null;
root->sib_prev = null;

for (...) {

node->parent = root;
node->child = null;
s2: node->sib = node+1;
s3: node->sib_prev = node-1;

node++;
}

(a) Code

child
h *

*

*child
h

child

NULL

child

NULL
parent sib

*

(h)

(h.child) h NULL h NULL

sib sib_prev

(h.child.sib)

(h.child.sib.sib)

parent

hchild
h

child

h

sib

child

h

sib_prev

NULL

sib
child

h

child

h

sib
child

h

sib
child

h

sib_prev

NULLsib
child

h

h NULL

parent

(b) Term tree

g(x1, x2, x3) = *(

parent! (x1, x2), child! (x1, g),

sib! (x1, g), sib prev! (x1, x3))

g(x1, x2, x3) = *(

parent! (x1, x2),

child! (x1, g(child(x1), x1, NULL)),

sib! (x1, g(sib(x1), x2, x1)),
sib prev! (x1, x3))

(c) Recurrence

Figure 4. A loop in 181.mcf that builds its tree

This cannot be achieved by ordinary separation logic formulaewithout the enhancement of access-path-based heap names or the
domain-specific translation into terms.
3.1.2 Recurrence Detection
For convergence over loops, the recurrence detection algorithm isapplied to each top-level term (a loop may touch multiple data

structures). The algorithm we build on is by Schmid [8]. The high-level intuition is that if there is a recurrence relation that explains
a term, then the term can be obtained from the recurrence relation

by unfolding the recursion body up to a finite length. So a term canbe folded into a recursion by finding a segmentation of the term
corresponding to the unfolding points, together with parametersubstitution rules. As pointed out by Summers [7], this can be
viewed as the converse of using fixed points to give the semanticsof a recursive function. The algorithm proceeds in three steps:

1. Search for a valid segmentation of the input term. This can bequite complex as the recurrence relation can be of arbitrary

form, not just simple linear recursions such as linked-lists. In

Figure 4(b), bold lines cutting across tree edges segment theterm such that the target node of each edge cut is an unfolding
point. Three unfolding points are NULL nodes, which corre-spond to the base case of the recursion (modifications are made
to Schmid's algorithm to determine when NULL nodes are notunfolding points). The unfolding point h.child.sib.sib is where
the symbolic execution of the loop and hence the expansion ofthe term tree stop. An unfolding point like this is a single * term
with no children. We refer to them as the "un-expanded" nodes.
The basic algorithm for finding a valid segmentation is givenin Figure 5. Formally, it searches for the set R of recursion

points - places in the recurrence body where it invokes itself.The unfolding points in the term can be derived by repeated unrolling of the recurrence at its recursion points. In Figure 4(b),the recursion points coincide with the top two unfolding points,
closest to the root of the tree. The other four are results of un-rolling twice starting at the recursion point on the left. To ensure
that the algorithm returns the minimal recurrence relation thatexplains the input term, the search for the next recursion point
proceeds from left to right and from top to bottom, backtrackingwhen R does not induce a valid segmentation. Validity of segmentation is checked by first computing a skeleton tskel of thehypothetical recurrence body. t

skel is the minimal term tree thatcontains all paths in t leading to the recursion points, with the

recursion points replaced by a special symbol 0. All other pathsare replaced by fresh variables at the highest points. R induces
a valid segmentation if for each unfolding point u derived fromR, the relation t

skel <= u holds. <= is defined inductively as*

0 <= t0 if t0 contains NULL or un-expanded nodes,*
x <= t0 if t0 does not contain NULL or un-expanded nodes,*
f(t1, ..., tn) <= f(t01, ..., t0n) if ti <= t0i for i = 1..n.

find valid segmentation(t)
R = {} // The set of recursion points
x = leftmost child of twhile

x 6= null doif is potential recursion point

(x, t) then
R += xif is valid segmentation

(R, t) then
x = next pos right(x)continue

else

R -= x
x = leftmost child of x, if any or next pos right(x)return the set of unfolding points induced by

R

is potential recursion point(x, t)return

x is a NULL node . (x has the same symbol as t ^
x contains NULL or un-expanded nodes in its term tree)

is valid segmentation(R, t)
tskel = the minimal pattern of t reaching all nodes in Rreturn 8 unfolding point

u.tskel <= u

next pos right(x)if

x has no parent thenreturn null

if x has a right sibling y thenreturn

yreturn next pos right

(parent of x)

Figure 5. Algorithm to find valid segmentations
2. Compute the body of the recurrence, which is the maximal over-lapping portion of all segments. This is done by anti-unifying

(u) the segments:*

f(t1, ..., tn) u f0(t01, ..., t0m) = '(f(t1, ..., tn), f0(t01, ..., t0m)),*
f(t1, ..., tn) u f(t01, ..., t0n) = f(t1 u t01, ..., tn u t0n).

' is a one-to-one mapping between pairs of terms and variableswhich guarantees that identical sub-term pairs are replaced by

the same variable throughout the whole term.
3. Find parameter substitutions. The sub-terms where the seg-ments differ are instantiations of the parameters in the recurrence. Parameter substitutions are computed by identifying reg-ularities in these terms. In our case, the parameters are precisely those terms translated from the names of heap locations.The access- paths, now encoded in the prefix form, provide the
excellent opportunity for identifying interrelationships betweenthe parameters. We define the notion of positions in a term tree
t: (i) * is the position of the root (ii) if the node at position u,denoted as

t|u, is a function, then its i-th child has position u.i.Within each segment s, let fi

s,xj,r denote the sub-term that isthe instantiation of parameter x

j at recursion point r. The sub-stitution term for parameter x
j recursion point r is computed assub(x
j, r, *).

sub(xj, r, u) =8>><

>>:

xk if is recurrent(xj, xk, r, u)
f(sub(xj, r, u.1), ..., if 8 segment s, fis,xj,r|u = f(...)

sub(xj, r, u.n)) with arity(f) = n,

is recurrent(xj, xk, r, u) =8

successive segments s and s0, fis0,xj,r|u = fis,xk,r|*.

sub is defined by structural induction on term trees. The leafsof the substitution term are parameter variables. They are determined through comparison of successive segment pairs inis recurrent to see if a general pattern emerges. For an internal
position u in the substitution term, it must hold that the cor-responding parameter instantiations in all segments share the
same function node at u.
For the term in Figure 4(b), the recurrence body is shown inFigure 4(c) on the top, and the final recurrence relation with parameter substitutions is shown at the bottom, which translates tothe predicate mcf tree

(x1, x2, x3) defined in Section 2.

3.2 What Recursion Synthesis Can and Cannot Do
The complete algorithm given in [8] handles the case where therecursion does not start at the root of the term tree, which happens when a recursive data structure is conjoined with some extradata. It can handle mutual recursions and nested recursions, which
allows the analysis to support nested data structures, e.g. trees oflinked-lists. It can also handle interdependencies between parameter instantiations and incomplete program traces. We believe thealgorithm is powerful enough to decipher most recursive data types.
However, our technique relies on the loop that constructs the datastructure to reveal the data structure's recursive backbone. It will
fail, for example, if the code reads a table that specifies the datastructure or copies a data structure by keeping a map between pointers in the original and those in the duplicate.

4. Local Reasoning under Global Invariants
This section discusses two functions used by the symbolic execu-tion rules, unfold

\Theta (l:S, h) and fold\Theta (\Sigma ). They concern reasoningabout local changes to recursive data structures described by global

shape invariants, yielding a general algorithm for unfolding andfolding recursive predicates.

unfold\Theta  takes a state S and a heap location h located either atthe root of a recursive data structure or at the bottom sitting between
the data structure and a truncation point, unrolls the predicatedescribing the data structure so that

S contains explicit points-toassertions with
h on the left hand side. It returns a set of statesbecause case analysis is needed in the presence of truncation points.

Peeling the data structure from the top is conceptually easy, sim-ply replace the recursive predicate with its inductive definition, substituting arguments passed to the predicate for parameters in thedefinition. Complication arises when the predicate contains truncation points. We do not know their exact positions relative to theroot. They could be sitting right below the root, in which case they

alias with the newly exposed targets of h, or they could be fartherway from

h so that they become the truncation points in the sub datastructures below

h. Because spatial conjunction does not allow im-plicit aliasing, we have to enumerate all possible scenarios of relative positioning between h and the truncation points, constrained bythe invariant that the sub data structures rooted at truncation points
are mutually disjoint. Let n be the number of recursion points (Sec-tion 3.1.2) in the definition of the recursive predicate and

m be thenumber of truncation points in the predicate. The total number of

possibilities is exponential in n*m. However, n is a small constant(1 for linked-lists, 2 for binary trees),

m is also small because localupdates only involve a few nodes and once done, the global invariant is restored and these truncation points are eliminated by fold\Theta .Consider the heap: mcf tree

(h, null, null; ff) * mcf tree(ff, fi1, fi2).Unfolding
h yields four heaps:

* h.parent ! null * h.child ! ff * mcf tree(ff, h, null) *

h.sib prev ! null * h.sib ! fi4 * mcf tree(fi4, null, h)*

h.parent ! null * h.child ! fi3 * mcf tree(fi3, h, null) *
h.sib prev ! null * h.sib ! ff * mcf tree(ff, null, h)*

h.parent ! null * h.child ! fi3 * mcf tree(fi3, h, null; ff) *
h.sib prev ! null * h.sib ! fi4 * mcf tree(fi4, null, h)*

h.parent ! null * h.child ! fi3 * mcf tree(fi3, h, null) *
h.sib prev ! null * h.sib ! fi4 * mcf tree(fi4, null, h; ff)

Unrolling a recursive predicate from the bottom up makes ha new truncation point, causing some old truncation points to be

removed to maintain mutual-disjointness of truncation points. Let
T be the set of the original truncation points that point to h. Again,we do not know the exact access path from

h to a t 2 T , so casesplitting is required as well. In this case the link from

t to h alsolimits the possible places where
t may alias with a node under
h, according to the definition of the recursive predicate. Consideragain the heap mcf tree

(h, null, null; ff) * mcf tree(ff, fi1, fi2). Tounroll
fi2, because the link ff ! fi2 is a sib prev link, by definitionof mcf tree,

ff must be the target of the sib link originating from
fi2. Hence after unrolling fi2, we have mcf tree(h, null, null; fi2) *
fi2.parent ! fi1*fi2.child ! fi3*mcf tree(fi3, fi2, null)*fi2.sib !
ff * fi2.sib prev ! fi4 * mcf tree(ff, fi1, fi2). If we were to consider
ff as the target of the child link of fi2, then ff would be describedas mcf tree

(ff, fi2, null), which is inconsistent with its descriptionbefore the unrolling. Similar inconsistency also arises if we do

not consider ff as any target of fi2. Our algorithm checks eachcombination to rule out inconsistencies. In the case of unrolling
fi1, there are two possibilities, either ff is the child of fi1 or it is atruncation point in the child sub-tree of

fi1.Figure 6 contains the algorithm that determines all possible

spatial relationships between an unfolded node h, associated witha recursive predicate

A, and a set of truncation points T . Eachpossibility is represented by a function

ss that maps every t in
T to either r or r, where r is one of the recursion points in thedefinition of

A. r means the t is located at the recursion pointand
r means that t is further below r. The algorithm assumes thatneighboring recursive elements in the data structure are one pointer

traversal away. This assumption can be removed by generalizingthe algorithm. Details are omitted due to space constraint.

The case analysis performed in unfold\Theta  closely mimics the waya programmer may reason informally about local updates - "If it
is the case that x points y, then ...", but it does so exhaustivelyto ensure correctness. In comparison, folding a heap formula is
straightforward because we do not need to worry about accidentallycreating implicit aliasing, hence no case analysis is needed. It
cleans up unused truncation points left behind by unfold\Theta  in anattempt to incorporate cut-out pieces of the original data structure
back into it, thereby restoring the global invariant. fold\Theta  takes a

valid possibilities = {}for all

ss doif 8
r, 9t.ss(t) = r ) @t0.t0 6= t ^ ss(t) = r or r thenok

= truefor all

t 2 T doif 9 backward link

t.n ! h thenlet
xj be the parameter in A's definition s.t. x1.n ! xjlet
r be the recursion point s.t. ss(t) = r or rif
ss(t) = r thenif the recursive call at

r substitutes x1 for xj thencontinue

elseif the recursive call at

r substitutes x1 for some xk ^9r0
.the recursive call at r0 substitutes xk for xj thencontinue

ok = falsebreak
if ok thenvalid possibilities +=

ss

Figure 6. Algorithm for case analysis in unfold\Theta 

heap, looks for locations not pointed to by any live register, andtries to merge it into a neighboring data structure. Like unfold

\Theta ,it also works from two directions, starting either with locations

sitting directly atop a recursive data structure and working its wayupwards, or with truncation points and working its way downwards.

It achieves similar effect of the rewrite rules for list in [4, 5],
p ! k * list(k, q)  list(p, q) and list(p, k) * k ! q list

(p, q). However, we handle arbitrary predicates by crawling theabstract heap such that each time, instead of a single heap cell, a

whole chunk of heap fitting the definition of the recursive predicate(including backward links) are absorbed.

To illustrate unfolding and folding, we will again turn to181.mcf. Figure 7 contains a code fragment which cuts a sub-tree
from under its parent and connects it to a new parent. At entry l0,
q and t are two truncation points in the mcf tree whose root is R.The parent link of

t points to p. The code fragment removes thesub-tree rooted at
t from under p, moving the right sibling of t,if any, towards the left to be the new child of

p. t is added as thechild of
q, shifting the old child of q, if any, toward the right. Theheap formulae associated with each program label are listed in Table 3. For each label, parts of the heap formulae that are differentfrom the previous label are underlined. The unfold and fold actions
taken at each step are also listed. Formula \Sigma 1,2 corresponds to thecase where the branch at

l1 is not taken. We omit subsequent for-mulae derived from it. They are similar to those listed here. The

same is done for \Sigma 3,2. The registers that are live at the end of thiscode fragment are

t and q. In the last step, we fold all other nodesback into the tree. The final heap

\Sigma 6,2, where t.sib points to null, issubsumed by
\Sigma 6,1 (based on the definition of v in Section 2.1).

l0:

if (t->sib)

t->sib->sib_prev = t->sib_prev;
l1:

if (t->sib_prev)

t->sib_prev->sib = t->sib;
else

p->child = t->sib;
l2:

t->parent = q;
t->sib = q->child;
l3:

if (t->sib)

t->sib->sib_prev = t;
l4:

q->child = t;
t->sib_prev = 0;
l5:

Figure 7. Local modification to a tree in 181.mcf

\Sigma 0:
l0 mcf tree

(r, null, null; q, t) * mcf tree(q, fi1, fi2)*
t.parent ! p * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! ff1 * t.sib ! ff3 * mcf tree(ff3, p, t)

\Sigma 1,1: Unfold ff3 \Sigma 1,2:
l1

mcf tree(r, null, null; q, t) * mcf tree(q, fi1, fi2)*
t.parent ! p * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! ff1 * t.sib ! ff3*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*

ff3.sib prev ! ff1 * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

mcf tree(r, null, null; q, t) * mcf tree(q, fi1, fi2)*
t.parent ! p * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! ff1 * t.sib ! null

\Sigma 2,1: Unfold ff1 \Sigma 2,2: Unfold p
l2

mcf tree(r, null, null; q, ff1) * mcf tree(q, fi1, fi2)*
ff1.parent ! p * ff1.child ! ff7 * mcf tree(ff7, ff1, null)*
ff1.sib prev ! ff6 * ff1.sib ! ff3*
t.parent ! p * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! ff1 * t.sib ! ff3*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*
ff3.sib prev ! ff1 * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

mcf tree(r, null, null; q, p) * mcf tree(q, fi1, fi2)*
p.parent ! ff8 * p.child ! ff3*
p.sib prev ! ff9 * p.sib ! ff10 * mcf tree(ff10, ff8, p)*
t.parent ! p * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! null * t.sib ! ff3*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*
ff3.sib prev ! null * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

\Sigma 3,1: Unfold q \Sigma 3,2: Unfold q

l3

mcf tree(r, null, null; q, ff1)*
q.parent ! fi1 * q.child ! fi3 * mcf tree(fi3, q, null)*

q.sib prev ! fi2 * q.sib ! fi4 * mcf tree(fi4, fi1, q)*
ff1.parent ! p * ff1.child ! ff7 * mcf tree(ff7, ff1, null)*
ff1.sib prev ! ff6 * ff1.sib ! ff3*
t.parent ! q * t.child ! ff2 * mcf tree(ff2, t, null)*

t.sib prev ! ff1 * t.sib ! fi3*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*
ff3.sib prev ! ff1 * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

mcf tree(r, null, null; q, p)*
q.parent ! fi1 * q.child ! fi3 * mcf tree(fi3, q, null)*

q.sib prev ! fi2 * q.sib ! fi4 * mcf tree(fi4, fi1, q)*
p.parent ! ff8 * p.child ! ff3*
p.sib prev ! ff9 * p.sib ! ff10 * mcf tree(ff10, ff8, p)*
t.parent ! q * t.child ! ff2 * mcf tree(ff2, t, null)*

t.sib prev ! null * t.sib ! fi3*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*
ff3.sib prev ! null * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

\Sigma 4,1: Unfold fi3 \Sigma 4,2:

l4

mcf tree(r, null, null; q, ff1)*
q.parent ! fi1 * q.child ! fi3*
q.sib prev ! fi2 * q.sib ! fi4 * mcf tree(fi4, fi1, q)*
fi3.parent ! q * fi3.child ! fi5 * mcf tree(fi5, fi3, null)*

fi3.sib prev ! t * fi3.sib ! fi6 * mcf tree(fi6, q, fi3)*
ff1.parent ! p * ff1.child ! ff7 * mcf tree(ff7, ff1, null)*
ff1.sib prev ! ff6 * ff1.sib ! ff3*
t.parent ! q * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! ff1 * t.sib ! fi3*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*
ff3.sib prev ! ff1 * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

mcf tree(r, null, null; q, ff1)*
q.parent ! fi1 * q.child ! null*
q.sib prev ! fi2 * q.sib ! fi4 * mcf tree(fi4, fi1, q)*
ff1.parent ! p * ff1.child ! ff7 * mcf tree(ff7, ff1, null)*
ff1.sib prev ! ff6 * ff1.sib ! ff3*
t.parent ! q * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! ff1 * t.sib ! null*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*
ff3.sib prev ! ff1 * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

\Sigma 5,1: \Sigma 5,2:

l5

mcf tree(r, null, null; q, ff1)*
q.parent ! fi1 * q.child ! t*
q.sib prev ! fi2 * q.sib ! fi4 * mcf tree(fi4, fi1, q)*
fi3.parent ! q * fi3.child ! fi5 * mcf tree(fi5, fi3, null)*
fi3.sib prev ! t * fi3.sib ! fi6 * mcf tree(fi6, q, fi3)*
ff1.parent ! p * ff1.child ! ff7 * mcf tree(ff7, ff1, null)*
ff1.sib prev ! ff6 * ff1.sib ! ff3*
t.parent ! q * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! null * t.sib ! fi3*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*
ff3.sib prev ! ff1 * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

mcf tree(r, null, null; q, ff1)*
q.parent ! fi1 * q.child ! t*
q.sib prev ! fi2 * q.sib ! fi4 * mcf tree(fi4, fi1, q)*
ff1.parent ! p * ff1.child ! ff7 * mcf tree(ff7, ff1, null)*
ff1.sib prev ! ff6 * ff1.sib ! ff3*
t.parent ! q * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! null * t.sib ! null*
ff3.parent ! p * ff3.child ! ff4 * mcf tree(ff4, ff3, null)*
ff3.sib prev ! ff1 * ff3.sib ! ff5 * mcf tree(ff5, p, ff3)

\Sigma 6,1: Fold ff1, ff3, fi3 \Sigma 6,2: Fold ff1, ff3
fold

mcf tree(r, null, null; q)*
q.parent ! fi1 * q.child ! t*
q.sib prev ! fi2 * q.sib ! fi4 * mcf tree(fi4, fi1, q)*
t.parent ! q * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! null * t.sib ! fi3 * mcf tree(fi3, q, t)

mcf tree(r, null, null; q)*
q.parent ! fi1 * q.child ! t*
q.sib prev ! fi2 * q.sib ! fi4 * mcf tree(fi4, fi1, q)*
t.parent ! q * t.child ! ff2 * mcf tree(ff2, t, null)*
t.sib prev ! null * t.sib ! null

Table 3. Intermediate states of a tree update in 181.mcf

5. The Analysis
This section puts various pieces of the analysis together.

5.1 Code Pruning
Our interprocedural shape analysis includes a pre-pass in whicha simple pointer analysis is performed to identify recursive data

structures present in the program, and code that has no effect onthe shape properties of these data structures is pruned away.

Because this shape analysis targets low-level code with notype information, a pointer analysis similar to Steensgaard's analysis [17] is used to roughly infer the high-level type of each pointer.This eliminates the need for shape analysis to track non-pointer
data fields. These fields do not exhibit interesting recursive patternsand may confuse recursion synthesis. An inferred pointer type represents a set of runtime locations, e.g. the "next" field in all nodesof a linked-list. Our pointer analysis determines an inferred type
for each load/store instruction, which over-approximates the set oflocations the instruction accesses. Recursive types are identified as
those associated with load instructions involved in traversing recur-sive data structures. These loads share the property that the destination register is used to compute the load address, a recurrence thatis easily detected by computing strongly-connected components of
the reaching-definition graph.Code pruning is achieved by the following program slicing algorithm: It starts with an empty set of instructions and a set of trackedtypes initialized to the set of recursive types identified above. For
each store to a tracked type, all instructions (including branchesand possibly crossing procedure boundaries) that contribute to the
computation of either the store address or the value to be storedare added. New pointer types that need to be tracked will be identified in the process, causing more instructions to be added. Whenthe algorithm terminates, only instructions that may affect updates
to recursive pointer fields are preserved. This step is essential formanaging large benchmarks.

5.2 Interprocedural Analysis
As in [10] and [18], at each procedure entry, the analysis splitsthe state into a local heap and a frame, and sends the local heap,

consisting of heap regions reachable from the actual parameters andthe globals used in the procedure and all its callees, as the pre-state
of the procedure (although any other splitting is sound). Cutpointsare preserved by telling the algorithm fold

` not to fold them away.Our implementation adapts the tabulation algorithm in [18] which

records procedure summaries for re-use under equivalent callingcontexts. It is modified to perform inductive recursion synthesis,

shown in Figure 8. In the interprocedural control flow graph, eachcall site is represented by a call node and a return node. Each
procedure has an entry node and an exit node. The algorithm keepsa worklist of triples h

n, Sentry, Si, each saying that state S holdsright before node
n given that Sentry holds on entry of the procedurecontaining
n. If n is a call node, the local heap of the callee is firstextracted from

S and the triple is registered as a calling contextassociated with the callee and this local heap. If no summary of the

callee exists for this local heap, then it is pushed onto the worklisttogether with the callee's entry node. Upon popping the callee's
exit node off the worklist, the updated local heap is propagated toall calling contexts registered with the callee to be re-combined
into the frames. All other nodes are handled by transform(n !
n0, S), which updates state S according to the semantics of n.For memory efficiency, we do not keep around intermediate states,

state duplication only occurs at split points of control flow and forrecording procedure summaries and loop invariants.

5.2.1 Handling Recursive Procedures
Just like loops, recursive procedures are handled by symbolic ex-ecution along sample execution paths, then followed by inductive

recursion synthesis. The control flow graph of a recursive proce-dure contains two kinds of loop back edges, one for recursive calls
and one for recursive returns. Recursion synthesis is applied forboth to infer the entry and exit invariants respectively. The choice
of sample execution paths does not affect soundness as the inferredprocedure entry/exit invariants are verified to see that they can derive themselves. We choose those paths that are good representativeof the runtime behavior of the recursive procedures and are hence
likely to yield valid invariants. On entry of a strongly-connected-component (SCC) in the call graph (representing mutually recursive procedures), the analysis follows an execution path that enterseach procedure in the SCC at least twice. At each branch instruction reaching recursive calls, the analysis only propagates statesto one branch target. The selection is performed by the subroutine transform in Figure 8, which returns NULL for the non-takenbranch. If all procedures in the SCC have been visited at least twice,
the target that does not lead to recursive calls is taken to ensure ter-mination; otherwise, the other target is taken. If both targets lead
to recursive calls, we favor the one leading to procedures that havenot been visited twice yet. When checking the invariants of each
procedure, all execution paths are taken into account.

worklist = {hentrymain, S0, S0i}while worklist is not empty do

remove hn, Sentry, Si from worklistif

n is a call node then
Slocal = extract(S, callee)contexts

(hcallee, Slocali) += hn, Sentry, Siif summary

(hcallee, Slocali) 6= ff thenfor all
Sexit 2 summary(hcallee, Slocali) doworklist += h

nreturn, Sentry, combine(Sexit, S)ielse

worklist += hentrycallee, Slocal, Slocaliif callee is recursive then

latest entry statecallee = Slocalelse if
n is an exit node thenif callee is recursive then

latest exit statecallee = Sif caller is not in the callgraph SCC of callee then

for all procedure p in callee's SCC dorecursion synthesis

(latest entry statecallee)recursion synthesis
(latest exit statecallee)for all procedure
p in callee's SCC doif
!invariants valid(p) thenhalt

summary(hcallee, Sentryi) += Sfor all h

ncall, Se, Sci 2 contexts(hcallee, Sentryi) doworklist += h

nreturn, Se, combine(S, Sc)ielse

for all control flow edge n ! n0 do

S0 = transform(n ! n0, S)if

n ! n0 is a back edge of loop l thenif analysis converges or

l has not iterated twice thenworklist += h
n0, Sentry, S0ielse

recursion synthesis(S0)if

!invariants valid(l) thenhalt

elseworklist += h

n0, Sentry, S0i

Figure 8. The Interprocedural Algorithm

6. Experiment Results
This analysis has been implemented in our C compiler. Prelimi-nary experiment results are reported in Table 4. Time was taken

on a 3GHz P4 with 512KB cache and 2GB memory. In additionto 181.mcf which uses iterative algorithm to build and to traverse

its data structure, we tested on four Olden benchmarks which userecursive procedures. The 2nd column lists the recursive data structures used in the benchmarks. Our analysis is able to infer andmaintain precise shape predicates that describe these data structures. For the most part, the shape analysis phase (last column)takes less time than the pre-pass (4th and 5th columns), demonstrating the effectiveness of code pruning.

Benchmark Data Type # Insts Analysis Time (s)Pointer Slicing Shape
181.mcf mcf tree 2158 0.59 0.22 0.55treeadd binary tree 162 0.09 0.02 0.05
bisort binary tree 423 0.16 0.05 0.38perimeter quaternary tree 624 0.20 0.06 0.10

w/ parent linkspower lists 1054 0.37 0.07 0.06

Table 4. Experiment results

7. Related Work
Recently there have been many interesting works in applying sep-aration logic to program analysis, not just verification. Berdine et

al. describe a form of symbolic execution that, for certain typesof preconditions, generates post-conditions by updating the preconditions in-place [13]. It does not by itself yield a suitable ab-stract domain due to lack of guarantee for convergence. Two analyses of list- processing programs [4, 5] use rewrite rules tailoredto the list predicate to reduce logic formulae and thereby arrive at
fixed points. Both analyses are intraprocedural. An interproceduralanalysis is given in [10], limited to pre-defined predicates as well.
[19] studies pointer arithmetic in an abstract domain where eachlist node is a multiword.

Most similar to our work, Lee et al.'s grammar-based analy-sis [6] can also discover recursive predicates automatically. But
since their grammar only allows one explicit argument, it cannothandle data structures with multiple backward links such as the
mcf tree and it cannot handle multiple pointers to the interior ofa data structure. We support arbitrary number of parameters and
can handle dags in some cases while they cannot.In [20], inductive learning is also used to find instrumentation
predicates. Their technique, based on successive refinement givenpositive and negative examples, is different from recursion synthesis. Although in principle their predicates can describe complexdata structures, the inference of such recursive predicates is not
evaluated in their experimentation.

8. Conclusion and Future Work
This paper presented an interprocedural shape analysis based onseparation logic. With two powerful techniques, inductive recursion

synthesis and generic recursion unrolling/rolling based on trunca-tion points, the analysis is able to take separation logic based program analysis beyond simplistic data structures. For future work,we would like more results on the conditions under which the recursion synthesis algorithm would fail. Though we do not expectit to fail often in practice, when it does, a more elegant recovery
scheme than halting is desirable. Potential solutions include a spe-cial predicate that says all pointers to a particular data structure may
alias and prompting the user for further information.

References

[1] D. R. Chase, M. Wegman, and F. K. Zadeck, "Analysis of pointers andstructures," in Proceedings of the ACM SIGPLAN '90 Conference on

Programming Language Design and Implementation, pp. 296-310,June 1990.

[2] N. D. Jones and S. S. Muchnick, "Flow analysis and optimizationof Lisp-like structures," in Program Flow Analysis: Theory and

Applications (S. S. Muchnick and N. D. Jones, eds.), pp. 102-131,Englewood Cliffs, NJ: Prentice-Hall, 1981.

[3] J. Reynolds, "Separation logic: A logic for shared mutable datastructures," in Proceedings of the 7th Annual IEEE Symposium on

Logic in Computer Science, July 2002.
[4] D. Distefano, P. W. O'Hearn, and H. Yang, "A local shape analysisbased on separation logic," in Lecture Notes in Computer Science,

vol. 3920, pp. 287-302, Springer-Verlag, 2006.
[5] S. Magill, A. Nanevski, E. Clarke, and P. Lee, "Inferring invariants inseparation logic for imperative list-processing programs," in Workshop

on Semantics, Program Analysis, and Computing Environments forMemory Management (SPACE), January 2006.

[6] O. Lee, H. Yang, and K. Yi, "Automatic verification of pointerprograms using grammar-based shape analysis," in Prceedings of

the 2005 European Symposium on Programming (ESOP), 2005.
[7] P. Summers, "A methodology for Lisp program construction fromexamples," Journal ACM, vol. 24(1), pp. 162-175, 1977.

[8] U. Schmid, Inductive synthesis of functional programs. Berlin,Germany: Springer-Verlag, 2003.
[9] A. Mffller and Schwartzbach, "The pointer assertion logic engine," inProceedings of the ACM SIGPLAN 2001 Conference on Programming

Language Design and Implementation, pp. 221-231, 2001.
[10] A. Gotsman, J. Berdine, and B. Cook, "Interprocedural shapeanalysis with separated heap abstractions," in Proceedings of the

13th International Static Analysis Symposium (SAS), August 2006.
[11] N. Rinetzky, J., Bauer, T. Reps, M. Sagiv, and R. Wilhelm, "A seman-tics for procedure local heaps and its abstractions," in Proceedings of

the 32nd ACM Symposium on Principles of Programming Languages,pp. 296-309, January 2005.

[12] B. Guo, M. J. Bridges, S. Triantafyllis, G. Ottoni, E. Raman, andD. I. August, "Practical and accurate low-level pointer analysis," in

Proceedings of the 3rd International Symposium on Code Generationand Optimization, March 2005.

[13] J. Berdine, C. Calcagno, and P. W. O'Hearn, "Symbolic execution withseparation logic," in Lecture Notes in Computer Science, vol. 3780,

pp. 52-68, Springer-Verlag, 2005.
[14] P. W. O'Hearn, H. Yang, and J. Reynolds, "Separation and informationhiding," in Proceedings of the 31st ACM symposium on Principles of

Programming Languages, pp. 268-280, January 2004.
[15] J. Berdine, C. Calcagno, and P. W. O'Hearn, "A decidable fragmentof separation logic," in Lecture Notes in Computer Science, vol. 3328,

pp. 97-109, Springer-Verlag, 2004.
[16] G. Tan and A. W. Appel, "A compositional logic for control flow," inLecture Notes in Computer Science, vol. 3855, pp. 80-94, SpringerVerlag, 2006.
[17] B. Steensgaard, "Points-to analysis by type inference in programswith structures and unions," in Lecture Notes in Computer Science,

1060, pp. 136-150, Springer-Verlag, 1996.
[18] N. Rinetzky, M. Sagiv, and E. Yahav, "Interprocedural shape analysisfor cutpoint-free programs," Tech. Rep. 26, Tel Aviv University,

November 2004.
[19] C. Calcagno, D. Distefano, P. W. O'Hearn, and H. Yang, "Beyongreachability: Shape abstraction in the presence of pointer arithmeetic,"

in Lecture Notes in Computer Science, vol. 4134, pp. 182-203,Springer-Verlag, 2006.

[20] A. Loginov, T. Reps, and M. Sagiv, "Abstraction refinement via induc-tive learning," in Proceedings of the 17th International Conference on

Computer Aided Verification, pp. 519-533, 2005.