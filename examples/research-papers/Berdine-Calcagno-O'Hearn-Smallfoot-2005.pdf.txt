

In: FMCO 2005, LNCS 4111, pp. 115-137. 1

Smallfoot: Modular Automatic Assertion

Checking with Separation Logic

Josh Berdine1, Cristiano Calcagno2, and Peter W. O'Hearn3

1 Microsoft Research
2 Imperial College, London
3 Queen Mary, University of London

Abstract. Separation logic is a program logic for reasoning about programs that manipulate pointer data structures. We describe Smallfoot, a
tool for checking certain lightweight separation logic specifications. The
assertions describe the shapes of data structures rather than their detailed contents, and this allows reasoning to be fully automatic. The
presentation in the paper is tutorial in style. We illustrate what the tool
can do via examples which are oriented toward novel aspects of separation logic, namely: avoidance of frame axioms (which say what a procedure does not change); embracement of "dirty" features such as memory
disposal and address arithmetic; information hiding in the presence of
pointers; and modular reasoning about concurrent programs.

1 Introduction
Separation logic is a program logic geared toward specifying and verifying proper-ties of dynamically-allocated linked data structures [35], which has lead to much
simpler by-hand specifications and program proofs than previous formalisms.Specifications in separation logic are "small", in that a specification of a program component concentrates on the resources relevant to its correct operation(its "footprint"), not mentioning the resources of other components at all [32].
In this paper we describe Smallfoot, an experimental tool for checking certainseparation logic specifications.

The aim of the tool was simple: we wanted to see whether the simplicityof the by-hand proofs in separation logic could be transferred to an automatic
setting. Smallfoot uses lightweight assertions that describe the shapes of datastructures rather than their detailed contents; this restriction allows the reasoning to be fully automatic. The input language allows first-order procedureswith reference and value parameters, essentially as in [17], together with operations for allocating, deallocating, mutating and reading heap cells. Smallfootrequires pre- and post-conditions for the procedures, and loop invariants. It also
supports annotations for concurrency, following a concurrent extension of sepa-ration logic [31, 11].

In [5] we defined the symbolic execution mechanism and proof procedure thatlie at the heart of Smallfoot, but we did not there show how they could be used
to prove programs. The purpose of this paper is the opposite: to show what the

tool can do, without exposing its innards. We proceed in a tutorial style. Wedescribe in an informal way how the proof rules of [32, 35, 31] are used in the
tool, in conjunction with the execution mechanism, but we do not give a fullyformal description or a repeat of the techniques of [5]. For a full understanding
of exactly how Smallfoot works familiarity with [32, 35, 31, 5] is essential. But wehave tried to make the presentation relatively self-contained, and we hope that
many of the main points can be gleaned from our examples and the discussionsurrounding them.

We begin in the next section by introducing Smallfoot with three examples.The purpose of this work is to explore separation logic's modularity in an automatic setting, and that is the subject of all three examples. We will discusssome of the features of Smallfoot as we go through the examples, and highlight
some of the issues for automation that guided its design. A description of theinput language and some central points in the verification condition mechanism
is then given in Sections 3 and 4. Several further examples are given in Section5, and we conclude with a discussion of related and future work.

We stress that Smallfoot is limited in various ways. Its input language hasbeen designed to match the theoretical work on separation logic, rather than an
existing widely-used language; our purpose was to experiment with the logic,rather than to produce a mature end-user tool. Beyond the basic primitives of
separation logic, Smallfoot at this point includes several hardwired predicates forsingly-, doubly-, and xor-linked lists, and for trees, but not (yet) a mechanism
for arbitrary inductive definitions of data structures. We included xor lists justto illustrate how reachability does not feature in separation logic; we have not
incorporated more general address arithmetic. Smallfoot cannot handle all of themore advanced algorithms that have been the subject of by-hand proofs in separation logic, particularly graph algorithms [40, 6, 7]. Further, it does not havespecifications for full functional correctness. Extensions in some of these directions would necessitate abandoning the automatic aspect, relying on interactiveproof. Those are areas for further work.

2 Smallfoot in Three Nutshells
We begin with a warning: you should suspend thinking about the global heapwhen reading separation logic specifications, otherwise the logic can seem counterintuitive. Rather than global heaps you can think of heaplets, portions ofheap. An assertion talks about a heaplet rather than the global heap, and a spec
[P ] C [Q] says that if C is given a heaplet satisfying P then it will never try toaccess heap outside of

P (other than cells allocated during execution) and it willdeliver a heaplet satisfying

Q if it terminates. (Of course, this has implicationsfor how
C acts on the global heap.) This heaplet reading may seem a simplepoint, but we have found that separation logic's "local way of thinking" can lead

to confusions, which arise from reverting to thinking in terms of the global heap.So we will return to this point several times below.

2

2.1 Local Specifications and Framing
Consider a procedure for disposing a tree:

disp_tree(p) [tree(p)] {

local i,j;
if (p = nil) {} else {i := p\Delta l

; j := p\Delta r; disp_tree(i); disp_tree(j); dispose(p); }
} [emp]

This is the expected procedure that walks a tree, recursively disposing left andright subtrees and then the root pointer. It uses a representation of tree nodes

with left and right fields, and the empty tree is represented by nil.This Smallfoot program includes a precondition and postcondition, corresponding to a partial correctness specification:

[tree(p)] disp_tree(p) [emp]
(We use square instead of curly brackets, despite treating partial correctness, tomaintain consistency with Smallfoot's concrete syntax.) This is an example of

the small specifications supported by separation logic: it talks only about theportion of heap relevant to the correct operation of the procedure. In particular,
tree(p) describes a heaplet where p points to a tree, and where there are no junkcells, cells not in the tree. This "no junk cells" part is necessary to be able to
conclude emp, that the heaplet on termination is empty.Smallfoot discovers a proof of this program by symbolic execution. The proof
in the else branch corresponds to the proof steps:

[(p7!l: x, r: y) * tree(x) * tree(y)]i := p\Delta l

; j := p\Delta r;
[(p7!l: i, r: j) * tree(i) * tree(j)]

disp_tree(i);
[(p7!l: i, r: j) * tree(j)]

disp_tree(j);
[p7!l: i, r: j]

dispose(p);
[emp]

After we enter the else branch we know that p6=nil so that, by unrolling, p is anallocated node that points to left and right subtrees occupying separate storage.

Then the roots of the two subtrees are loaded into i and j. Notice how thenext proof steps follow operational intuition. The first recursive call removes the
left subtree, the second call removes the right subtree, and the final instructionremoves the root pointer

p. The occurrences of the separating conjunction * inthese assertions ensure that the structures described, the two subtrees and root

pointer, occupy separate memory, as is necessary if an operation that removesone of them is not to affect one of the others. This verification is carried out
using the specification of disp_tree as an assumption, as in the usual treatmentof recursive procedures in Hoare logic [17].

3

In the if branch we use an implication tree(p) ^ p=nil ) emp, which relies onthe "no junk" character of the

tree predicate.The assertions in this proof use very little of separation logic; they are all of

the form \Pi  ^ \Sigma  where \Pi  is a pure boolean condition and \Sigma  is a *-combinationof heap predicates. All of the assertions in Smallfoot are of this special form
(together with conditionals over them), and this enables a symbolic executionmechanism where *-conjuncts are updated in-place.

There is a hidden part in the proof outline just given: in the two procedurecalls the preconditions at the call sites do not match the preconditions for the
overall specification of disp_tree. For example, for the second call the assertionat the call site is (

p7!l: i, r: j)*tree(j) while the procedure spec would suggest thatthe precondition should just be

tree(j) (after renaming of the parameter). Thisis where the local way of thinking comes in. The specification of

disp_tree saysthat a heaplet satisfying
tree(j) is transformed into one satisfying emp. The inputheaplet need not be the whole heap, we can effect this transformation on a heaplet that lives inside a larger heap, and then slot the result into that larger heap.In separation logic, this pulling out and slotting in is described using the
* connective. Generally, a heaplet h satisfies P * Q if it can be split into twodisjoint heaplets

hP and hQ that satisfy P and Q. The above narrative for the call
disp_tree(j) tells us to take (p7!l: i, r: j)*tree(j), pull out the heaplet description
tree(j), transform it to emp, and slot that back in, obtaining (p7!l: i, r: j) * emp.Then, we can use an identity

P * emp , P .Separation logic has an inference rule (the frame rule)

[P ] C [Q]
[R * P ] C [R * Q]

(where C doesn't assign to R's free variables) which lets us do "pull out, performlocal surgery, slot in" in a proof. To automatically generate proofs using this rule,

which was implicitly applied in the steps in the proof for the else branch above,we need a way to infer frame axioms. If we are given an assertion at a call site
and a procedure precondition, we must find the leftover part (which lets us dothe "pull out" step). Often, this leftover part can be found by simple pattern
matching, as is the case in the disp_tree example, but there are other cases wherepattern matching will not do. Technically, Smallfoot uses a method of extracting
frame axioms from incomplete proofs in a proof theory for entailments [5].

2.2 Processes that Mind Their Own Business
Concurrent separation logic [31] has the following rule for parallel composition:

[P ] C [Q] [P 0] C0 [Q0]

[P * P 0] C k C0 [Q * Q0]

where C does not change variables free in P 0, C0, Q0, and vice versa. The ideaof this rule is that the specifications [

P ] C [Q] and [P 0] C0 [Q0] describe all theresources that
C and C0 might access, that they mind their own business; so,

4

if we know that the resources are separate in the precondition, then we canreason about the concurrent processes independently. A simple example of this
is a parallel composition of two heap alterations on different cells, where the *in the precondition guarantees that

x and y are not aliases:

[x7!c: 3 * y7!c: 3]
[x7!c: 3]
x\Delta c := 4
[x7!c: 4]

flflflflflflfl [y7!c: 3]

y\Delta c := 5
[y7!c: 5]
[x7!c: 4 * y7!c: 5]

The local thinking is exercised more strongly in concurrent than in sequentialseparation logic. A points-to fact

x7!c: 3 describes a heaplet with a single cell
x that is a record with a c field whose value is 3. As far as the left process isconcerned, reasoning is carried out for a heaplet with a single cell, its heaplet,

and similarly for the right. In the global heap, though, it is not the case thatthere is only one cell; there are at least two! The two views, local and more
global, are reconciled by the form of the concurrency rule.To apply the concurrency rule automatically we need a way to get our hands
on the preconditions of the constituent processes. We could do this in severalways, such as by requiring an annotation with each k, or by introducing a "named
process" concept which requires a precondition but no postcondition. We settledon requiring the constituents of a k to be procedure calls; because procedures
come with pre/post specs we can use their preconditions when applying theconcurrency rule. The postconditions are not strictly necessary for automating
the concurrency rule. We made this choice just to avoid multiplying annotationforms. A Smallfoot program corresponding to the above example, but where we
create the two separate cells, is:

upd(x,y) [x7!] {x\Delta c := y;} [x7!c: y]
main() {x :=

new(); y := new(); x\Delta c := 3; y\Delta c := 3;
upd(x,4) k upd(y,5);
} [x7!c: 4 * y7!c: 5]

In the precondition of upd the assertion x7! indicates that x points to something.It denotes a singleton heaplet in which

x is the only allocated or defined cell.The postcondition describes a singleton heaplet where the

c field of location xhas
y as its contents.When a pre- or post-condition is left out, as the pre for

main is in this program,it defaults to
emp. Also, Smallfoot accepts a collection of procedures as input,one optionally "main".

In contrast, when we change the main program to

main() {x :=

new(); x\Delta c := 3; y := x;
upd(x,4) k upd(y,4);
} [y=x ^ x7!c: 4]

5

then Smallfoot flags an error; since x and y are aliases, there is no way to splitthe heap into two parts, giving one symbolic cell to each of the constituent
processes. In general, if a Smallfoot program has a race -- where two processesmay attempt to access the same cell at the same time -- then an error is reported.
(More precisely, any such attempted parallel accesses must be wrapped in criticalsections which specify atomicity assumptions for accesses.)

Our description of how the proof is found for sequential disp_tree is almostthe same for a parallel variant, which Smallfoot proves using the concurrency
rule:

par_disp_tree(p) [tree(p)] {

local i,j;
if (p = nil ) {} else {i := p\Delta l

; j := p\Delta r;
par_disp_tree(i) k par_disp_tree(j);
dispose(p); }
} [emp]

The reader's reaction to disp_tree and par_disp_tree might be: aren't theyrather trivial? Well, yes, and that is part of the point. For contrast, consider
par_disp_tree in the rely/guarantee formalism [21, 27], which is rightly cele-brated for providing compositional reasoning about concurrency. In addition to
a precondition and a postcondition saying that the nodes in the tree are deallo-cated, we would have to formalize two additional assertions:

Rely No other process touches my tree tree(p); and
Guarantee I do not touch any storage outside my tree.

Although compositional, as this example demonstrates the relies and guaranteescan be rather global, and can complicate specifications even in simple examples

when no interference is present. The Smallfoot specification for this procedureis certainly simpler.

2.3 Process Interaction and Heaplet Transfer
Process interaction in Smallfoot is done with conditional critical regions (ccrs)[18]. The programming model is based on "resources"

r and ccr statements
with r when(B) {C}. ccrs for common resource r must be executed with mutualexclusion, and each has a guard which must hold before execution.

Data abstractions can be protected with ccrs by wrapping critical regionsaround code that accesses a data structure. A more daring form of concurrency
is when several processes access the same piece of state outside of critical sec-tions [31]. In separation logic it is possible to show that daring programming
idioms are used consistently. An example is a pointer-transferring buffer: in-stead of copying a (perhaps large) portion of data from one process to another,
a pointer to the data is sent. Typically, the sending and receiving processes accessthe pointer without synchronization.

6

A toy version of this scenario is the following code snippet using buffer op-erations

put and get:

x := new();
put(x); flfl

get(y;);
dispose(y);

This creates a new pointer in the left process and then places it in the buffer.The right process then reads out the pointer and disposes it. We would typically

want to fill the pointer contents in the left process before sending it, and to dosomething with those contents in the right. The point is that to reason about
the dispose in the right process we must know that y is not dangling after we dothe

get operation. It is useful to use the intuition of "permission to access" todescribe this [9, 8]: the permission to access the pointer moves from the first to the

second process along with the pointer value. Further, when permission transfersit must disappear from the left process or else we could mistakenly justify a
further dispose(x) in the left process, after the put. In conjunction with the
dispose(y) in the right process that would disastrously lead to a double-disposalthat we must rule out.

This is where the local way of thinking helps. An assertion at a programpoint describes a heaplet, which represents a local permission to access, instead
of a global heap. put(x) will have precondition x7! and postcondition emp, theidea being that the heaplet for

x flows out of the left process and into the buffer.The
emp postcondition ensures that, even if the value of x remains unchanged,the local knowledge that

x is not dangling (the permission) is given up, thuspreventing further disposal. At this point the global heap is not empty, but the

heaplet/permission for the left process is. get(y;) will have precondition empand postcondition

y7!, connoting that the heaplet (the permission) materializesin the second process.

A Smallfoot program encoding this scenario is:

resource buf (c) [if c=nil then emp else c7!]
init() { c := nil; }
put(x) [x7!] { with buf when(c=nil) { c := x; } } [emp]
get(y;) [emp] { with buf when(c6=nil) { y := c; c := nil; } } [y7!]
putter() { x := new(); put(x); putter(); }
getter() { get(y;); /* use y */ dispose(y); getter(); }
main() { putter() k getter(); }

In the ccr model resource names are used to determine units of mutualexclusion. Different

ccrs with r when(B) {C} for the same resource name rcannot overlap in their executions. A

ccr can proceed with its body C only whenits boolean condition B holds. A resource declaration indicates some private

variables associated with the resource (in this case c) and an invariant thatdescribes its internal state.

7

When we have resource declarations as here an init procedure is needed forinitialization; when we do not have a resource declaration, the initialization can
be omitted. The init procedure is run before main; it's job is to set up the statethat is protected by the named resource, by establishing the resource invariant.

In this code the omitted preconditions and postconditions are all (by default)
emp, except the post of init which is (by default) the resource invariant (theassertion in the resource declaration). The

put and get operations are encodedusing little critical regions. The resource buf has an invariant which describes

its heaplet: it says that if c=nil then the buffer has no permission, else it holdspermission to access

c. The put operation can fire only when c=nil, and sobecause of the invariant we will know at that point that buf's heaplet is

emp.The assignment
c:= x changes the buf state so that the only way for the invariantto be true is if
c7!; the permission to access the pointer (at this point denoted byboth
c and x) flows into the buffer. Furthermore, the put operation cannot have
x7! as its postcondition because separation is maintained between the resourceinvariant and the heaplet assertions for the two processes. A similar narrative can

be given about how get effects a transfer from the buffer to the getter process.In fact, the annotations in this code are more than is strictly needed. If we
were to inline put and get, then Smallfoot would verify the resulting code. Weseparated out these operations only to display what their specifications are.

What makes this all work is an inference rule

[(P * Rr) ^ B] C [Q * Rr]
[P ] with r when(B) {C} [Q]

where Rr is an invariant formula associated with resource r. This rule is used toverify the

put and get procedures, and the concurrency rule is then used for thecomposition of

putter and getter. Even though the program loops, the fact thatit gets past Smallfoot ensures that no pointer is ever disposed twice (without

an intervening allocation), that there is no race condition, and that the resourceinvariant is true when not in the middle of a critical section.

Besides the separation between resource and process enforced using *, thisrule (which stems originally from [18]) is wonderfully modular: the precondition
and postcondition P and Q of a ccr do not mention the invariant Rr at all. Thisallows reasoning about processes in isolation, even in the presence of interaction.

3 The Input Language
3.1 Annotated Programs
A Smallfoot program consists of sets of resource declarations

resource r(~xr)Rr
where ~xr and Rr are resource r's protected variables and invariant; and proceduredeclarations

f(~p ; ~v)[Pf ] Cf [Qf ]

8

where procedure f's parameters ~p are passed by reference and ~v by value, andassertions

Pf and Qf are f's pre- and post-conditions. In this formal descriptionthe preconditions and postconditions have to be included, but we repeat that

in the tool if a pre or post is left out then it is emp by default. Assertions aredescribed later; commands are generated by:

E ::= x | nil | c | E xor E
B ::= E=E | E6=E

S ::= x:= E | x:= E\Delta t | E\Delta t:= E | x:= new() | dispose(E)
C ::= S | C ; C | if(B) {C} else {C} | while(B) [I] {C}|

f (~x ; ~E) | f (~x ; ~E) k f(~x ; ~E) | with r when(B) {C}

There is the additional evident constraint on a program that in any procedurecall

f(~y ; ~E) or region with r when(B) {C} the variable f /r must be defined in aprocedure/resource declaration.

Smallfoot programs are subject to certain variable restrictions, which areneeded for the soundness of Hoare logic rules; for example, that variable aliasing
and concurrent races for variables (not heap cells) are ruled out. These conditionsare, in general, complex and unmemorable; they may be found in [4].

3.2 Assertions and Specifications
The assertions are *-combinations of heap predicates and ^-combinations ofpure boolean facts, together with conditionals over these. Conditionals are used

rather than disjunctions because they preserve the "preciseness" property thatis needed for soundness of concurrent separation logic [11]. The heap predicates
include the points-to relation, the tree predicate, a predicate for singly-linked listsegments and one for xor-linked lists. (We also have conventional doubly-linked
lists in Smallfoot, but do not include any examples for them in this paper.)

P, Q, R, I ::= \Pi  ^ \Sigma  | if B then P else P H ::= E7!ae | tree(E) | ls(E, E)

\Pi  ::= B1 ^ * * * ^ Bn | true | false | xlseg(E, E, E, E)

\Sigma  ::= H1 * * * * * Hn | emp ae ::= t1: E1, . . . , tn: En

The model assumes a finite collection Fields (from which the ti are drawn),and disjoint sets Loc of locations and Values of non-addressable values, with
nil 2 Values. We then set:

Heaps def= Loc fin* (Fields ! Values [ Loc)

Stacks def= Variables ! Values [ Loc
In this heap model a location maps to a record of values. The formula E7!ae canmention any number of fields in

ae, and the values of the remaining fields areimplicitly existentially quantified.

9

For s 2 Stacks, h 2 Heaps, the key clauses in the satisfaction relation forassertions are as follows:
s ffl E=F

defiff JEKs = JF Ks

s ffl E6=F

defiff JEKs 6= JF Ks

s ffl \Pi 0 ^ \Pi 1

defiff s ffl \Pi 

0 and s ffl \Pi 1

s, h ffl E07!t1: E1, . . . , tk: Ek

defiff h = [JE

0Ks\Delta r] where r(ti) = JEiKs for i 2 1..k

s, h ffl emp

defiff h = ?

s, h ffl \Sigma 0 * \Sigma 1

defiff 9h

0, h1. h = h0*h1 and s, h0 ffl \Sigma 0 and s, h1 ffl \Sigma 1

s, h ffl \Pi  ^ \Sigma 

defiff s ffl \Pi  and s, h ffl \Sigma 

For pure assertions \Pi  we do not need the heap component in the satisfactionrelation.

h = h0*h1 indicates that the domains of h0 and h1 are disjoint, andthat
h is their graph union. The semantics JEKs 2 Values of expressions is asexpected. We will not provide semantic definitions of the predicates for trees and

lists now, but give inductive characterizations of them later.Each command

C determines a relation:J

CK: (Stacks * Heaps) ! (Stacks * Heaps) [ {fault}
The fault output occurs when a command attempts to dereference a danglingpointer. For example,

x\Delta tl:= y produces a fault when applied to state s, h, where
s(x) is not a location in the domain of h. We will not give a formal definition ofJ

CK; when considering concurrency it is especially intricate [11]. The interpreta-tion of Hoare triples is:

[P ] C [Q] holds if, whenever given a state satisfying P , C will not pro-duce a fault and, if it terminates, will deliver a state satisfying

Q. Moremathematically:
s, h ffl P ^ (s, h)JCKoe =) oe 6= fault ^ oe ffl Q

This interpretation guarantees that C can only access heap which is guaranteedto exist by

P . For, if C were to alter heap outside of an assertion P , then itwould fault when that heap was deleted, and that would falsify [

P ] C [Q].

4 Verification Condition Generation
Smallfoot chops an annotated program into Hoare triples for certain symbolicinstructions, that are then decided using the symbolic execution mechanism

of [5]. Execution reduces these triples to entailments P ` Q. These entailmentsare usually called verification conditions; we will use the same terminology for
the output of the chopping phase, before the execution phase.

4.1 Verification Conditions
A verification condition is a triple [P ] SI [Q] where SI is a "symbolic instruction":

SI ::= ffl | S | [P ] jsr~x [Q] | if B then SI else SI | SI ; SI

10

A symbolic instruction is a piece of loop-free sequential code where all procedurecalls have been instantiated to

jsr instructions of the form [P ] jsr~x [Q]. This formplays a central role in Smallfoot. We use it not only to handle procedure calls,

but also for concurrency and for entry to and exit from a critical region.

Semantically, [P ] jsr~x [Q] is a "generic command" in the sense of [38]. It isthe greatest relation satisfying the pre- and post-condition, and subject to the

constraint that only the variables in ~x are modified. An adaptation of genericcommands which requires the relation to agree on local and pull out/slot in
interpretations of triples, can be found in [33].

Overall, what the execution mechanism does for [P ] SI [Q] is start with P andrun over statements in SI generating postconditions. For each postcondition

P 0thus obtained, it checks an entailment
P 0 ` Q using a terminating proof theory.
We will not give a detailed description of the symbolic execution mechanism,referring to [5] for the details. (We remark that the presentation there does not

include conditional assertions if B then P else Q, but these are easily dealt with.)Instead, we will describe how the mechanism works in a particular case, in the
else branch of the disp_tree program.

When we take that branch we have to establish a triple

[p6=nil ^ tree(p)] C [emp]
where C is the command in the else branch, with procedure calls instantiatedto

jsr instructions. Applying the tree unroll rule yields

[p6=nil ^ (p7!l: i0, r: j0) * tree(i0) * tree(j0)] C [emp]
for fresh variables i0 and j0. After the first two assignment statements in C weare left with:

[p6=nil ^ (p7!l: i, r: j) * tree(i) * tree(j)]
([tree(i)] jsr [emp]) ;([tree(j)] jsr [emp]) ; dispose(p) [emp]

To apply [tree(i)] jsr [emp] we have to find a frame axiom, using the frame rulefrom earlier, and it is just (

p7!l: i, r: j) * tree(j). Similarly, in the next step weobtain
p7!l: i, r: j as the frame axiom, and finally we dispose p. (Frame infer-ence is not always so easy; for example,

ccr examples later require a certainamount of logical reasoning beyond pattern matching.) This leaves us with an

easy entailment:

p6=nil ^ emp ` emp

4.2 VCGen
For each procedure declaration f (~p ; ~v)[P ] C [Q] we generate a set of verificationconditions

vcg(f, [P ] C [Q]). The formal definition can be found in [4], and herewe illustrate how it applies to the

par_disp_tree and heaplet transfer examplespresented in Sections 2.2 and 2.3.

11

Recall the specification of par_disp_tree: [tree(p)] par_disp_tree(p) [emp]. Sofor a call

par_disp_tree(i), vcg considers a single generic command:

[tree(i)] jsr [emp]
which indicates that the net effect of calling par_disp_tree on i is to con-sume a

tree starting from i, produce no heap, and modify no (nonlocal) vari-ables in the process. Using this straight-line command, and the similar one for

the call par_disp_tree(j), the net effect of the recursive parallel function calls
par_disp_tree(i) k par_disp_tree(j) is to consume trees starting at i and j,produce no heap, and modify no variables. This is the core of the verification

condition of par_disp_tree, and is expressed by the straight-line command:

[tree(i) * tree(j)] jsr [emp]
With this, the whole body of par_disp_tree is expressed by a conditional com-mand, and so

par_disp_tree's single vc is obtained by tacking on the pre- andpost-conditions:

[tree(p)]
if p=0 then ffl else i := p\Delta l ; j := p\Delta r ;([tree(i) * tree(j)] jsr [emp]) ; dispose(p)

[emp]

This vc is then discharged by symbolic execution, which propagates the precon-dition forward through the command and then checks (for each branch of the
execution) that the computed postcondition entails the specified one.

For the heaplet transfer example, the init procedure must establish the re-source invariant from precondition

emp, yielding vc:

[emp] jsr [if c=nil then emp else c7!]
For brevity, if we inline put and get in putter and getter:

putter() [emp] {

local x;x :=

new();
with buf when(c=nil) {c := x

; }
putter();
} [emp]

getter() [emp] {

local y;
with buf when(c6=nil) {y := c

; c := nil; }
dispose(y);
getter();
} [emp]

The crux of the vcs of these functions is the straight-line command whichexpresses the

ccr commands. For getter this is:

[emp] jsr [(if c=nil then emp else c7!) ^ c6=nil] ;
y:= c ; c:= nil
[if c=nil then emp else c7!] jsrc [emp]

12

The generic commands for ccr entry and exit act as resource transformers.Recalling that the resource invariant for buf is (

if c=nil then emp else c7!), theinitial generic command expresses that upon entry into the

ccr, the guard holdsand resource invariant is made available to the body. Notice how the invariant

is obtained starting from emp as a precondition, "materializing" inside the ccras it were. Then the body runs, and the final generic command expresses that
the body must reestablish the resource invariant prior to exiting the ccr.The

ccr in putter works similarly, but illustrates resource transfer on exit:

[emp] jsr [(if c=nil then emp else c7!) ^ c=nil] ;
c:= x
[if c=nil then emp else c7!] jsrc [emp]

The use of emp in the postcondition, considering that x6=nil since x will havejust been allocated, effectively deletes the invariant

c7! from consideration, andthe cell pointed-to by
c will not be accessible to the code following the ccr.The
vcs for putter and getter are then:

[emp]

x:= new();
[emp]

jsr
[(if c=nil then emp else c7!) ^ c=nil];
c:= x;
[if c=nil then emp else c7!] jsrc [emp];
[emp] jsr [emp]
[emp]

[emp]

[emp]

jsr
[(if c=nil then emp else c7!) ^ c6=nil];
y:= c;
c:= nil;
[if c=nil then emp else c7!] jsrc [emp];
dispose(y);
[emp] jsr [emp]
[emp]

Note that, as usual, when verifying a recursive procedure, the procedure's spec-ification is assumed. Here, this means that each recursive call is replaced by a

generic command with the procedure's pre- and post-conditions.The main command is then a parallel function call:

putter(); flfl getter();
which gives the additional verification condition:

[emp] ([emp] jsr [emp]) [emp]
Note that in both of these examples, no analysis of potential interleavingsof the executions of parallel commands is needed. Given the resource invariants,

the concurrent separation logic treatment of ccrs allows us to just verify a fewtriples for simple sequential commands.

5 Further Examples
5.1 More on Trees
The specification of disp_tree does not use *, even though the proof does. Anexample that uses * in its spec is:

13

copy_tree(q;p) [tree(p)] {

local i,j,i',j';
if (p = nil ) { q := p; }
else {i := p\Delta l

; j := p\Delta r;
copy_tree(i';i); copy_tree(j';j);q :=

new(); q\Delta l := i'; q\Delta r := j'; }
} [tree(q) * tree(p)]

The tree predicate that we use is not sensitive to the contents of the tree, onlythe fact that it is a tree. So, if in

copy_tree the final two steps were

q\Delta l := j'; q\Delta r := i';
then we would actually have an algorithm for rotating the tree, though it wouldsatisfy the same spec. If, on the other hand, we mistakenly point back into the

old tree

q\Delta l := i; q\Delta r := j;
then an error is reported; we do not have separation on termination.The tree predicate that we have used here is one that satisfies

tree(E) () (E=nil ^ emp) . (9x, y. (E7!l: x, r: y) * tree(x) * tree(y))
where x and y are fresh. The use of the * between E7!l: x, r: y and the twosubtrees ensures that there are no cycles, the * between the subtrees ensures

that there is no sharing (it is not a dag), and the use of emp in the base caseensures that there are no cells in a memory satisfying

tree(E) other than thosein the tree. The fact that the specification does not mention any data field is

what makes this a shape specification, insensitive to the particular data.This definition of

tree(E) is not something that the user of Smallfoot sees; itis outside the fragment used by the tool (it has a quantifier). Reasoning inside

the tool essentially uses rolling and unrolling of this definition. For instance, theproof step where we entered the else branch uses an entailment

p6=nil ^ tree(p) ` 9x, y. (p7!l: x, r: y) * tree(x) * tree(y)
together with stripping the existential (generating fresh variables) when theright-hand side is subsequently used as a precondition.

5.2 Linked Lists
We now give an example, using lists, that cannot be handled using simple(un)rolling of an inductive definition. We work with linked lists that use field tl

for the next element. The predicate for linked-list segments is the least satisfyingthe following specification.

ls(E, F ) () (E=F ^ emp) . (E6=F ^ 9y.E7!tl: y * ls(y, F ))

14

A complete linked list is one that satisfies ls(E, nil).Consider the following Smallfoot program, where the pre and post use complete lists only, but the loop invariant requires a genuine segment ls(x, t). (Onewould use genuine segments in pres and posts for, e.g., queues.):

append_list(x;y) [ls(x, nil) * ls(y, nil)] {

if (x = nil ) { x := y; }
else {t := x

; u := t\Delta tl;
while (u 6=nil) [ls(x, t) * t7!tl: u * ls(u, nil)] {t := u

; u := t\Delta tl; }t\Delta tl := y

; }
} [ls(x, nil)]

The most subtle part of reasoning in this example comes in the last step,which involves a triple

[ls(x, t) * t7!tl: nil * ls(y, nil)] t\Delta tl := y; [ls(x, nil)]
We use a symbolic execution axiom

[A * x7!f: y] x\Delta f:= z [A * x7!f : z]
to alter the precondition in-place, and then we use the rule of consequence withthe entailment

ls(x, t) * t7!tl: y * ls(y, nil) ` ls(x, nil)
of the postcondition. This entailment does not itself follow from simple unrollingof the definition of list segments, but is proven in the proof theory used within

Smallfoot by applying the inductive definition to conclude ls(t, nil) from t7!tl: y *
ls(y, nil), and then applying a rule that encodes the axiom

ls(E1, E2) * ls(E2, nil) ` ls(E1, nil)
It is this axiom that does not follow at once from list rolling and unrolling; inthe metatheory it would require a proof by induction.

Generally, for each hardwired inductive predicate Smallfoot uses a collectionof such rules that are consequences of induction, but that can be formulated
in a way that does not require enumeration of inductive hypotheses. The prooftheory we have obtained in this manner is complete as well as terminating for
entailments involving lists and trees [5].This ability to prove inductive properties is one of the characteristics which
sets this approach apart from Alias Types [39] and its descendants. Alias Typesincludes coercions to roll and unroll inductive types, but (as far as we understand) consequences of induction must be witnessed by loops.A final comment on this example. In the loop invariant we did not include a
*-conjunct ls(y, nil), which would indicate that the loop preserves the listness of
y. The reason we did not include this is that y's list is outside the footprint ofthe loop; Smallfoot discovers it as a frame axiom.

15

5.3 Information Hiding
The following describes a toy memory manager, which maintains binary conscells in a free list. When the list is empty, the

alloc(x;) operation calls new ina way similar to how
malloc() might call a system routine sbrk() to requestadditional memory.

resource mm (f ) [ls(f, nil)]
init() { f := nil; }
alloc(x;) [emp] {

with mm when(true) {

if(f = nil ) { x := new(); } else { x := f; f := x\Delta tl; } }
} [x7!]

dealloc(y) [y7!] { with mm when(true) { y\Delta tl := f; f := y; } } [emp]
The use of ccrs provides mutual exclusion, so that several calls to allocor
dealloc in different process will not interfere. The real point of the exam-ple, though, is information hiding. Because of the modularity of the

ccr rule,the interface specifications for
alloc and dealloc do not mention the free listat all. Furthermore, the specification of

dealloc forces permission to access adeallocated cell to be given up, and this is essential to prevent incorrect usage.

For example, the little main program

main() { alloc(z;); dealloc(z); z\Delta tl := z; }
is flagged as an error by Smallfoot, because the precondition to z\Delta tl := z will be
emp; we must know that z points to something to do a dereference, this programwould tie a cycle in the free list.

However, the reason that this program is ruled out is not just because theinvariant it violated, it is because the cell

z (now in the free list) cannot betouched at all after
dealloc(z). For example, if we were to replace z\Delta tl := z byz\Delta tl :=
nil then the free list would not be corrupted in the global state, but theexample still would not pass Smallfoot; it breaks abstraction by dereferencing a

cross-boundary pointer, into the free list abstraction.The effect of this information hiding can be seen more strongly by replacing
the occurrences of new and dispose in the pointer-transferring buffer with callsto the homegrown memory manager.

putter() { alloc(x;); put(x); putter(); }
getter() { get(y;); /* use y */ dealloc(y); getter(); }
If we replace the putter and getter procedures from Section 2.3 with these,include joint initialization of the two resources

init() { f := nil; c := nil; }
and leave everything else the same, then the code verifies. If we did not use the
ccr rule to hide resource invariants, we would have to "thread" the free list

16

through the buffer code, forcing us to alter the specifications of put and get byincluding

ls(f, nil) in their preconditions and postconditions.

5.4 XOR-deqs
For our final example we consider deqs - double-ended queues - implementedusing an xor-linked list. Recall that an xor-linked list is a compact representation

of doubly-linked lists where, instead of using separate fields to store previousand next nodes, their bitwise exclusive or is stored in one field [23]. Besides their
entertainment value, using xor lists here demonstrates how Smallfoot does notdepend on reachability. The fact that the separation logic triple [

P ] C [Q] assertsthat execution of
C in states described by P will not access any other locations(except possibly locations newly allocated by

C) does not depend on whetherother such locations are reachable or not. We will also allow concurrent access

to the deq, though that aspect is of secondary importance for the example.The following predicate describes xor-linked list segments:

xlseg(E1, F1, E2, F2)

defiff (E

1=F1 ^ E2=F2 ^ emp).

(E16=F1 ^ E26=F2 ^ 9x. (E17!l: (E2 xor x)) * xlseg(x, F1, E1, F2))

In reading this definition it helps to think of a picture:

E2

xor

F1F2E1
xorxor

The basic idea is that a resource will own the deq represented as an xorlist, while processes accessing the two ends will hold dummy nodes back and
front which will be used for putting elements in the deq. Operations for gettingfrom the

deq will release nodes into the calling processes. The resource declara-tion and invariant are as follows; additionally, an initialization is needed (code

omitted) which sets up the pictured postcondition.

resource xdeq(n,p) [front=p ^ back=n ^ xlseg(f, n, p, b)]
init() { ... } [(front7!l: prev xor f) * (back7!l: next xor b)]

In this invariant it helps to consider the picture above: heaps cells correspondingto the nodes

n and p (and hence front and back) are not held in the deq, butrather are pointers into the processes that hold them as dummy nodes.

There are four procedures for accessing the deq: in Table 1 we show the codefor putting on the back and getting from the front, and the specifications only
for the other two (their code is similar).What the

getf procedure does is dispose the dummy node front it currentlyhas, replacing it with the first node

f that is in the deq. This is done by an

17

Table 1 xor -linked deq accessors

getf(x;) [front7!l: prev xor f] {

local t, old f;t := front\Delta l

;old f := prev

xor t;
dispose(front);prev := front

;
/* split new dummy link

off front */
with xdeq when(old f 6=n) {t := f\Delta l

;f := t
xor p;p := old f

;front := p

;
}x := front\Delta d

;
} [front7!l: prev xor f]

getb(x;) [back7!l: next xor b] {

...
} [back7!l: next xor b]

putb(x) [back7!l: next xor b] {

local t, new n, old p;
/* allocate new dummy link */new n :=

new();new n\Delta l := next

xor back;
/* store datum in previous dummy,

link to new dummy */back\Delta d := x

;t := back\Delta l
;old b := t
xor next;back\Delta l := new n

xor old b;
/* move previous dummy link

into deq */
with xdeq when(p6=back) {b := back

;n := new n

;back := n
;
}
} [back7!l: next xor b]

putf(x) [front7!l: prev xor f] {

...
} [front7!l: prev xor f]

ownership transfer, within a critical region, similar to what was done in thepointer-transferring buffer in Section 2.3. Note that, although front7!

l: prev xor fis true at the beginning and end of the procedure, it is false at intermediate

points. Similarly, the putb procedure stores a new item in the d field of itsdummy node back, and then effects an ownership transfer where this node gets
swallowed into the deq data structure. The crucial point is that the accesses
x:= front\Delta d and back\Delta d:= x of the data fields occur outside of critical sections.It is this that allows these accesses to be done in parallel.

[Aside: There is one limitation of Smallfoot that this example shows: in the
putb procedure we include a test (p6=back) which happens to be true in anyexecution. This condition is an additional annotation that Smallfoot needs to

verify the code. The difficulty is that two processes may be allocating nodesconcurrently, and the allocated nodes will indeed be different, but our current
assertions do not allow us to say so, locally. We say "current" because if wechange the memory model to allow "existence permissions" [7, 8] then it is possible to do away with the extra annotation in a by-hand proof; we have not,though, incorporated existence permissions into Smallfoot as of yet.]

To show these procedures working, we set up two parallel processes procf and
procb which nondeterministically choose whether to do a put or get operation on

18

the two ends of the deq. (The nondet keyword was not in the formal grammarfor Smallfoot before, but it is in the tool and is implemented by talking both
branches of a conditional in symbolic execution.)

procf(x) [front7!l: prev xor f] {

if(nondet) {

getf(x;); /* use x */ }
else {

/* produce an x */ putf(x); }
procf(x);
} [false]

procb(x) [back7!l: next xor b] {

if(nondet) {

getb(x;); /* use x */ }
else {

/* produce an x */ putb(x); }
procb(x);
} [false]

main() procf(42) k procb(13);
Smallfoot verifies the resulting program using a terminating proof theory forfacts about xor lists. It involves basic identities for xor, together with adaptations

of the rules in [5] for list segments. Again, this example could not be verifiedwithout consequences of induction that go beyond rolling and unrolling of an
inductive definition, and Smallfoot uses several such for xor lists, akin to theaxiom described in Section 5.2.

This is a variant of classic algorithms which allow concurrent access to twoends of a queue. As usual, we could allow multiple processes at each end of the
queue by using mutexes to rule out concurrent accesses from the same end.

6 Conclusions and Related Work
Before discussing related work we mention some of Smallfoot's limitations.First, even when a program's preconditions and postconditions can be expressed using Smallfoot assertions, we will not be able to verify it if its (loopand resource) invariants cannot be expressed. An example of this is Parkinson
and Bornat's proof [34] of the non-blocking stack of Michael [26]. (Parkinson hasverified a different non-blocking algorithm which is included amongst the examples on our web pages, but we are unable to express the invariant for Michael'salgorithm.)

Incidentally, although Brookes has shown that concurrent separation logicrules out races [11], this should not be taken to mean that it cannot be used on
programs that are normally considered racy. Generally, one can use little ccrsto explicitly notate statements that are considered atomic, or one could use some
other notation (e.g., "atomic") with the same proof methodology, and that iswhat Parkinson and Bornat have done in [34].

Second, Smallfoot uses a strict separation model, which does not allow shar-ing of read access. As a consequence it cannot handle, e.g., a readers and writers
program, which is proven in [8] using a less strict "counting permissions" modelof separation logic. Adding permission accounting is on our to-do list.

Third, it would be straightforward to include inductive definitions, if wewere content to just roll and unroll them. However, then very many interesting

19

programs would not verify. Several examples in this paper involving linked listsrequired properties to be proven at both ends, and these would not be verifiable
using rolling and unrolling alone. A direction for future research is to find a classof inductive definitions and to classify consequences of induction that can be
included in a terminating proof theory.

The most closely related works to Smallfoot are the Pointer Assertion LogicEngine [28] and Alias Types [39] and its relatives (e.g. [13, 9]). PALE is stronger

than Smallfoot in the range of predicates it considers, based on graph types.The state of development of Smallfoot is more directly comparable to the first
version of PALE [20], which was for linked lists only, and we hope to encom-passes some graph structures in the future. Conversely, PALE does not check
frame conditions on recursive calls, and this (intentionally) leads to unsound-ness, whereas the treatment of framing is a focus of Smallfoot. Also, PALE does
not deal with concurrency. Early on in the Smallfoot development we consideredwhether we could translate a fragment of separation logic into the fragment of
monadic second-order logic that PALE is based on. For some specific assertionsit is possible but we were unable to find a general scheme. The decidability of
fragments of monadic second-order logic is brittle, and can be broken by addingfeatures. Most importantly, we were unable to see how to give a compositional
interpretation of *.

With regard to Alias Types, there are many similarities. Most importantly,both approaches use a substructural logic or type theory for heaps. We believe it

is fair to say that the annotation burden in Smallfoot is considerably less than inAlias Types, owing mainly to inference of frame axioms. Alias Types were aimed
at intermediate languages, so that is not a criticism of them. Another differenceis that Alias Types use a range of inductive predicates, while we only use several
specific predicates. However, our proof theory uses strong and sometimes com-plete inductive properties, such as are needed when working at both ends of a
linked list.

The shape analysis of Sagiv, Reps and Wilhelm [37] provides a powerful ver-ification technique for heaps. The biggest problem with the approach is that it

is non-modular, in that an update to a single abstract heap cell can necessitatechanging the whole abstract heap (some steps to build in modularity have been
taken in [36]). We considered whether we could use ideas from shape analy-sis within a single procedure, and leverage *'s modularity for interprocedural
and concurrent analysis. Again, we had great difficulty dealing with * composi-tionally, and further difficulties with the

dispose instruction. But investigationscontinue; if this direction worked out it would give us access to a much wider

range of abstractions (using "canonical abstraction" [37]).

We are often asked: why did you not just give a deep (semantic) embeddingof separation logic in a predicate logic, and then use a general theorem prover,

instead of constructing your own proof method? The short answer is that thedeep embedding leads to nested quantifiers in the interpretation of *, and this
is an impediment to automation; attempts so far along these lines have provento be highly non-automatic. Of course it would be valuable to construct a deep

20

embedding and develop a range of tactics and make use of general purposeprovers, but that is for separate work.

Work on ESC and Spec# has resulted in important advances on modularheap verification [16, 3]. Ideas of ownership and inclusion have been used to
classify objects, and give a way of avoiding frame axioms, intuitively related towork on ownership types and semantics [12, 1]. Methods based on fixed ownership structures have been described (e.g., [25, 14]), but fixed structures areinflexible, e.g., having difficulty dealing with ownership transfer examples (like
our pointer-transferring buffer or memory manager), except possibly under dra-conian restrictions (such as unique-pointer restrictions). A recent emphasis has
been on using ownership assertions that refer to auxiliary fields that may be al-tered, and this leads to added flexibility [2, 24], including transfer. New schemes
are being invented to extend the basic idea, such as a "friends" concept that letsinvariants reach across hierarchical ownership domain [30]. We refer to David
Naumann's survey paper for a fuller account of and further references to re-search in this area [29].

In contrast, separation logic does not require a hierarchical ownership struc-ture to ensure locality or encapsulation. Assertions just describe heaplets, portions of state, and an assertion encapsulates all of the state that a command isallowed to change. Still, there appear to be some similarities between the ownership assertion approaches and the reasons for why separation logic works mod-ularly [41, 33]; there seem to be, in particular, remarkably similar intuitions underlying a recent ownership-invariant system for concurrency [19] and concurrentseparation logic [31]. A careful comparison of their models could be worthwhile.

Modular reasoning about concurrent programs has also received much atten-tion, often based on the fundamental work of Jones, Misra and Chandy [21, 27].
Our remarks at the end of Section 2.2 apply also in any comparison betweenSmallfoot and tools based on rely/guarantee (e.g. [15]). Our remarks should not
be taken to be an ultimate argument for separation logic over rely/guarantee,and it would be interesting to attempt to marry their strong points (easy treatment of independence, powerful treatment of dependence). We should add thatthe criticisms we made echo comments made by Jones himself [22].

Smallfoot is written in OCaml, and all of the examples in this paper verifiedin a few milliseconds on an ordinary laptop. We have not included a timing
table or other experimental results, because for the small examples we haveconsidered the interpretation of such results would be questionable, except that
if the verifications had taken minutes or hours and not milliseconds then thatwould have been a negative indication. The source code for the current version of
Smallfoot (v0.1), together with the examples from this paper and several others,is available for download from the address given in reference [4].

Acknowledgments. Thanks to Matthew Parkinson, who wrote lots of littleprograms that tested the tool and pointed out a number of bugs. All three authors were partially supported by the EPSRC. During Berdine's stay at CarnegieMellon University during 2003, his research was sponsored by National Science
Foundation Grant CCR-0204242.

21

References

1. A. Banerjee and D.A. Naumann. Ownership confinement ensures representation

independence for object-oriented programs. Journal of the ACM, 52(6):894-960,
2005. Preliminary version in POPL'02.
2. M. Barnett, R. DeLine, M. Fahndrich, K.R.M. Leino, and W. Schulte. Verification

of object-oriented programs with invariants. Journal of Object Technology, 3(6):27-
56, 2004.
3. M. Barnett, K.R.M. Leino, and W. Schulte. The Spec# programming system: An

overview. In CASSIS'04 post-proceedings, 2004.
4. J. Berdine, C. Calcagno, and P.W. O'Hearn. Verification condition generation and

variable conditions in Smallfoot. Available from
http://www.dcs.qmul.ac.uk/research/logic/theory/projects/smallfoot/index.html.
5. J. Berdine, C. Calcagno, and P.W. O'Hearn. Symbolic execution with separation

logic. In 3rd APLAS , pages 52-68, 2005.
6. L. Birkedal, N. Torp-Smith, and J.C. Reynolds. Local reasoning about a copying

garbage collector. In 31st POPL, pages 220-231, 2004.
7. R. Bornat, C. Calcagno, and P. O'Hearn. Local reasoning, separation, and aliasing.

Presented at 2nd SPACE Workshop, 2004.
8. R. Bornat, C. Calcagno, P. O'Hearn, and M. Parkinson. Permission accounting in

separation logic. 32nd POPL, 59-70, 2005.
9. J. Boyland. Checking interference with fractional permissions. In 10th SAS, pages

55-72, 2003.
10. P. Brinch-Hansen, editor. The Origin of Concurrent Programming. SpringerVerlag, 2002.
11. S.D. Brookes. A semantics for concurrent separation logic. Theoretical Computer

Science, to appear. Preliminary version in CONCUR'04, 2006.
12. D. Clarke, J. Noble, and J. Potter. Simple ownership types for object containment.

In 15th ECOOP, pages 53-76, 2001.
13. R. DeLine and M. F"ahndrich. Enforcing high-level protocols in low-level software.

In 8th PLDI, pages 59-69, 2001.
14. W. Dietl and P. M"uller. Universes: Lightweight ownership for JML. Journal of

Object Technology, 2006.
15. C. Flanagan, S.N. Freund, and S. Qadeer. Thread-modular verification for sharedmemory programs. In 11th ESOP, pages 262-277, 2002.
16. C. Flanagan, K.R.M. Leino, M. Lillibridge, G. Nelson, J.B. Saxe, and R. Stata.

Extended static checking for Java. In 9th PLDI, pages 234 - 245, 2002.
17. C.A.R. Hoare. Procedures and parameters: An axiomatic approach. In E. Engeler, editor, Symposium on the Semantics of Algorithmic Languages, volume 188
of Lecture Notes in Mathematics, pages 102-116. Springer-Verlag, 1971.
18. C.A.R. Hoare. Towards a theory of parallel programming. In Operating Systems

Techniques, Acad. Press, pages 61-71. Reprinted in [10], 1972.
19. B. Jacobs, K.R.M. Leino, F. Piessens, and W. Schulte. Safe concurrency for aggregate objects with invariants. In 3rd SEFM, 2005.
20. J. Jenson, M. Jorgensen, N. Klarkund, and M. Schwartzback. Automatic verification of pointer programs using monadic second-order logic. In 4th PLDI, pages
225-236, 1997.
21. C.B. Jones. Specification and design of (parallel) programs. IFIP Conf., 1983.
22. C.B. Jones. Wanted: A compositional approach to concurrency. In A. McIver and

C. Morgan, editors, Programming Methodology, pages 1-15, 2003. Springer-Verlag.

22

23. D.E. Knuth. The Art of Computer Programming, Volume I: Fundamental Algorithms. Addison Wesley, 2nd edition, 1973.
24. K.R.M. Leino and P. M"uller. Object invariants in dynamic contexts. In 18th

ECOOP, pages 491-516, 2004.
25. K.R.M. Leino, A. Poetzsch-Heffter, and Y. Zhou. Using data groups to specify and

check side effects. In 9th PLDI, pages 246 - 257, 2002.
26. M.M. Michael. Hazard pointers: Safe memory reclamation for lock-free objects.

IEEE TPDS, 15(6):491-504, 2004.
27. J. Misra and K.M. Chandy. Proofs of networks of processes. IEEE Trans. Software

Eng., 7(4):417-426, 1981.
28. A. M"oller and M.I. Schwartzbach. The pointer assertion logic engine. In 8th PLDI,

pages 221-231, 2001.
29. D.A. Naumann. Assertion-based encapsulation, invariants and simulations. In 3rd

FMCO, pages 251-273, 2005.
30. D.A. Naumann and M. Barnett. Friends need a bit more: Maintaining invariants

over shared state. In 7th MPC, pages 54-84, 2004.
31. P.W. O'Hearn. Resources, concurrency and local reasoning. Theoretical Computer

Science, to appear. Preliminary version in CONCUR'04, 2006.
32. P.W. O'Hearn, J.C. Reynolds, and H. Yang. Local reasoning about programs that

alter data structures. In 15th CSL. pages 1-19, 2001.
33. P.W. O'Hearn, H. Yang, and J.C. Reynolds. Separation and information hiding.

In 31st POPL, pages 268-280, 2004.
34. M. Parkinson and R. Bornat. Exploiting linearisability in program logic. Draft

paper, 2005.
35. J.C. Reynolds. Separation logic: A logic for shared mutable data structures. In

17th LICS, pages 55-74.
36. N. Rinetzky, J. Bauer, T. Reps, M. Sagiv, and R. Wilhelm. A semantics for

procedure local heaps and its abstractions. In 32nd POPL, pages 296-309, 2005.
37. M. Sagiv, T. Reps, and R. Wilhelm. Parametric shape analysis via 3-valued logic.

ACM TOPLAS, 24(3):217-298, 2002.
38. J. Schwarz. Generic commands--A tool for partial correctness formalisms. The

Computer Journal, 20(2):151-155, 1977.
39. D. Walker and J.G. Morrisett. Alias types for recursive data structures. In 3rd

Types in Compilation Workshop, pages 177-206, 2001.
40. H. Yang. An example of local reasoning in BI pointer logic: the Schorr-Waite graph

marking algorithm. Presented at 1st SPACE Workshop, 2001.
41. H. Yang and P.W. O'Hearn. A semantic basis for local reasoning. In 5th FOSSACS,

pages 402-416, 2002.

23