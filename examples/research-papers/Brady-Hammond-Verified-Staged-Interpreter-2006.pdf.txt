

A Verified Staged Interpreter is a Verified Compiler

Multi-stage Programming with Dependent Types

Edwin Brady Kevin Hammond
School of Computer Science, University of St Andrews, St Andrews, Scotland.

Email: eb,kh@dcs.st-and.ac.uk

Abstract
Dependent types and multi-stage programming have both beenused, separately, in programming language design and implementation. Each technique has its own advantages -- with dependenttypes, we can verify aspects of interpreters and compilers such as
type safety and stack invariants. Multi-stage programming, on theother hand, can give the implementor access to underlying compiler technology; a staged interpreter is a translator. In this paper,we investigate the combination of these techniques. We implement
an interpreter for a simply typed lambda calculus, using dependenttypes to guarantee correctness properties by construction. We give
explicit proofs of these correctness properties, then add staging an-notations to generate a translator from the interpreter. In this way,
we have constructed a verified compiler from a verified staged in-terpreter. We illustrate the application of the technique by considering a simple staged interpreter that provides guarantees for somesimple resource bound properties, as might be found in a domain
specific language for real-time embedded systems.
Categories and Subject Descriptors D.3.4 [Programming Languages]: Processors -- Interpreters, Compilers, Translator writ-ing systems and compiler generators; D.2.4 [

Software Engineer-ing]: Software/Program Verification -- Correctness proofs, Formal

methods
General Terms Languages, Theory, Verification
Keywords Dependent types, Multi-stage programming, Partialevaluation, Domain Specific Language Implementation, Resource
aware programming, Functional programming

1. Introduction
Multi-stage programming supports separation of concerns in com-piler writing, by allowing automatic program generation to proceed
in a series of stages. Each stage captures some new aspect of theproblem space that is then reflected in subsequent stages through
the program that is generated. A primary advantage of the approachis that it supports the construction of domain specific notations in
a nested fashion [11]. Here, each stage allows the encapsulation of

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior specific permission and/or a fee.

GPCE'06 October 22-26, 2006, Portland, Oregon, USA.
Copyright c\Theta  2006 ACM 1-59593-237-2/06/0010. . . $5.00.

domain knowledge in a precise way, and programmers may work atdifferent levels (corresponding to stages) according to their degree
of specialisation. For example, in the domain of real-time embed-ded systems which we are investigating, the first stage might be a
restricted notation that guaranteed bounded time and space usage,and be used by the applications programmer; the subsequent stage
might be used to define these restricted notations in terms of theunderlying meta-programming system, and be used by the domain
expert; and the final stage would correspond to the generation ofexecutable code, and be used by the compiler writer.

A major problem with this approach arises in ensuring that gen-erated programs conform to the properties required by the (meta)-
programmer. This problem has been explored in outline by Taha,Sheard and Pa^sal'ic amongst others [28, 31, 30], who have produced systems that are capable of correctly preserving type infor-mation across stages. While this is a valuable contribution in reducing runtime type errors for generated programs, these approachesrestrict the expressivity of their type systems. This approach is valuable in allowing the automatic verification of types, but verificationof more complex properties will generally require more complex
proof structures than can be supported by such frameworks. Forexample, the calculation of bounds on the resources used by a generated program may be essential in a real-time embedded systemssetting; previous work (e.g. [34, 20]) uses multi-stage programming
to generate resource correct programs, but is limited to specific re-source correctness properties. We are thus motivated to consider
how arbitrary proofs may be embedded within multi-stage pro-grams in a homogeneous framework, in order to allow automatic
verification of required program properties for domain specific lan-guages implemented using a multi-stage approach.

1.1 Overview of our Approach
Types give a program meaning; dependent type systems, in which
types may be predicated on values, allow us to give a more pre-cise type to a program and therefore to be more confident that it

has the intended meaning. In this paper, we consider how the sepa-rate techniques of multi-stage programming and dependently typed
programming can be combined in order to implement an efficientand correct implementation of a functional programming language.

We use dependent types to implement a well-typed interpreter,following and extending the ideas of Augustsson and Carlsson [4].
We are able to show by construction that the interpreter returns avalue of the correct type and correctly evaluates well-typed terms
-- we take types as the prior notion representing a specification,and use the typechecker to guarantee that our program respects this
specification. Dependent types ensure, by static checking, that theinterpreter cannot be executed on badly formed or ill-typed code.

111

Thus dependent types provide static guarantees of certain desiredcorrectness properties.
We further consider the use of staging annotations [32] to controlthe execution order of the interpreter. Staging annotations allow
code generation to be deferred until run-time, when some inputsare known. This means that we can specialise our interpreter for
specific object progams -- staging the interpreter yields a translatorfrom the object language to the meta-language [14]. From here it
is a small step to generating a compiler for the object language(for example using offshoring -- passing the translated code to an
external compiler [13]). The combination of dependent types andmulti-stage programming therefore gives us a method for building
verified compilers, for at least some required properties.

t ::= \Theta i (type universes)--

x (variable)--
(x : t) \Theta  t (function space)--
\Lambda x :t. t (abstraction)--
t t (application)-- let

x \Lambda \Theta  t : t in t (let binding)

Figure 1. The core language, TT

\Gamma  \Xi  valid
\Gamma  \Xi  \Theta n : \Theta n+1 Type

(x : S) \Pi  \Gamma 

\Gamma  \Xi  x : S Var

(x : S \Lambda \Theta  s) \Pi  \Gamma 

\Gamma  \Xi  x : S Val

\Gamma  \Xi  f : (x : S) \Theta  T \Gamma  \Xi  s : S

\Gamma  \Xi  f s : T [s/x] App

\Gamma ; x : S \Xi  e : T \Gamma  \Xi  (x : S ) \Theta  T : \Theta n

\Gamma  \Xi  \Lambda x :S.e : (x : S ) \Theta  T Lam

\Gamma ; x : S \Xi  T : \Theta n \Gamma  \Xi  S : \Theta n

\Gamma  \Xi  (x : S) \Theta  T : \Theta n Forall

\Gamma  \Xi  e1 : S \Gamma ; x \Lambda \Theta  e1 : S \Xi  e2 : T
\Gamma  \Xi  S : \Theta n \Gamma ; x \Lambda \Theta  e1 : S \Xi  T : \Theta n

\Gamma  \Xi  let x : S \Lambda \Theta  e1 in e2 : T [e1/x] Let

\Gamma  \Xi  x : A \Gamma  \Xi  A\Theta  : \Theta n \Gamma  \Xi  A \Sigma  A\Theta 

\Gamma  \Xi  x : A\Theta  Conv

Figure 2. Typing rules for TT
1.2 The Core Type Theory, TT
Our implementation language (meta-language) is a strongly nor-malising dependent type theory with inductive families [12], similar to Luo's UTT [22] or the Calculus of Inductive Constructions inC

OQ [9]. This language, which we call TT, is an enriched lambdacalculus, with the usual properties of subject reduction, Church

Rosser, and uniqueness of types up to conversion. The strong nor-malisation property (i.e. that evaluation always terminates) is guaranteed by allowing only primitive recursion over strictly positiveinductive datatypes. The syntax of this language is given in Figure 1, and its typing rules in Figure 2. We may also abbreviate thefunction space

(x : S) \Theta  T by S \Theta  T if x is not free in T .

In TT, there is a hierarchy of type universes, \Theta i, where \Theta 0 is thetype of types, and

\Theta n : \Theta n+1. We leave universe levels implicit,since they can be inferred by the machine [17]. The key typing rules

which set this type system apart from more traditional simply- orpolymorphically-typed

\Lambda -calculi are the App and Conv rules: Appis the rule for applying dependent functions (note

x may be freein
T , so s may be substituted in the type of the application); and
Conv is the conversion rule -- two terms are convertible by the\Sigma  relation if they have a common redex. Checking convertibility

requires evaluation at compile-time, hence strong normalisation isa requirement for decidable typechecking.

For clarity of presentation, we will use the higher level EPIGRAMnotation [25], which elaborates to

TT. A more detailed presentationof E
PIGRAM can be found in [24]; TT and its compilation schemeare detailed in [6].

1.3 Programming with Inductive Families
Inductive families are simultaneously-defined collections of alge-braic data types which can be indexed over values as well as types.
For example, we will define a "lists with length" (or vector) typebelow. We first, however, need to declare a type of natural numbers
to represent such lengths:

data N : \Theta  where 0 : N n : Ns n : N
Addition and multiplication can be easily defined by primitive re-cursion. We can now declare vectors as follows:

Vect A n definesan inductive family of lists indexed over
A, the type of vector ele-ments, and also over
n, the vector length. Note that, by construc-tion,
\Xi  only targets vectors of length zero, and x::xs only targetsvectors of length greater than zero:

data A : \Theta  n : NVect A n : \Theta  where \Xi  : Vect A 0

x : A xs : Vect A kx::xs : Vect A (s k)

Note that A and k are implicit arguments to the infix constructor
:: -- their types can be inferred from the type of Vect. When thetype includes explicit length information in this way, it follows that

any type-correct function over values in that type must expressthe invariant properties of the length. For example, we can write
a bounds-safe list lookup function that gives a static guarantee thata value is never projected from an empty list. In order to do do this,
we define a datatype of finite sets, which can be used to representnumbers with an upper bound:

data n : NFin n : \Theta 
where f0 : Fin (s n) i : Fin nfs i : Fin (s n)

Note that there are no elements of Fin 0 -- this would be a finite setwith zero elements. The type of

lookup below expresses staticallythat the bound of the index and the size of the list are the same, so

there can be no run-time error:

let i : Fin n xs : Vect A nlookup i xs : A

lookup i xs \Upsilon  elim i \Upsilon  case xs

lookup f0 (x :: ys) \Lambda \Theta  x
lookup (fs j ) (x :: ys) \Lambda \Theta  lookup j ys

112

The elim and case notation invoke the primitive recursion andcase analysis operators respectively on

i and xs. Termination isguaranteed since these operators are the only means to inspect

data. Unlike a simply typed language, we do not need to giveerror handling cases: the typechecker verifies that the empty vector
cannot be a legal input. We can see this by observing that neitherconstructor of

Fin targets the type Fin 0, therefore no well-typedapplication of
lookup could accept a Vect A 0.

1.4 Types for Specification
By giving additional static information about the lookup func-tion, we obtain a stronger guarantee of its behaviour from the typechecker. The definition itself, however, is written in the usual way-- indeed, it is more concise since there is no need for error checking. When writing the type, we are really writing a specification.Then, in writing the program, we are at the same time providing a
proof that the implementation meets this specification.
While we accept that such methods may not become widespreadfor general purpose programming in the short term, there are many

important applications domains where guarantees of correctnessare vital or desirable. Our own area of interest is resource-bounded
safety-critical systems [16]; we aim to use the techniques wepresent in this paper to implement a verified compiler for a resource
aware functional language. We will return to this in Section 5.

1.5 Theorem Proving
The dependent type system of TT also allows properties to be ex-pressed directly. For example, the following heterogeneous definition of equality, due to McBride [23], is built in to TT:

a : A b : Ba = b : \Theta  A : \Theta  a : Arefl a : a = a

This definition introduces an infix type constructor, =, parametrisedover two types; we can declare equality between any two types, but
can only construct an instance of equality between two definition-ally equal values in the same type. For example,

refl (s 0) is aninstance of a proof that
s 0 = s 0. Furthermore, since equality is anordinary datatype just like N and

Vect, we can also write programsby case analysis on instances of equality, such as the program below. This can be viewed as a proof that s respects equality:

let p : n = mresp s p : (s n) = (s m)

resp s p \Upsilon  case p

resp s (refl n) \Lambda \Theta  refl (s n)

We can also represent more complex properties, including logicalrelations:

data x, y : Nx<=y : \Theta  where leO : 0<=y p : x<=yleS p : s x<=s y
Note that x and y can be left implicit, as their types (and even theirvalues) can be inferred from the type of the relation. For example,
leS (leS leO) could represent a proof of s (s 0) <= s (s (s (s 0)). Aswith equality, given a proof, we can write programs by recursion
over the proof. For example, we can write a safe subtraction func-tion (i.e. the result is guaranteed to be non-negative) by primitive
recursion over the proof that the second argument is less than orequal to the first:

let n, m : N p : m <= nminus n m p : N

minus n m p \Upsilon  elim p

minus n 0 (leO n) \Lambda \Theta  n
minus (s n) (s m) (leS p) \Lambda \Theta  minus n m p

The values for the arguments n and m are determined by theindices of

leO and leS; no case analysis on the numbers themselvesis required. The Curry-Howard isomorphism [10, 18] describes this

correspondence between proofs and programs.
The lack of a phase distinction between types and values meansthat we can write proofs like this

directly over programs; there isno need to duplicate values at the kind level. While it has been

claimed elsewhere [8] that this implies that types cannot be erasedat run-time, in fact, we are able to maintain type erasure by instead
establishing a distinction between compile-time and run-time val-ues using techniques from [6], and erasing those needed at compiletime only.

1.6 Implementation
An implementation of the staged interpreter we develop in thispaper, along with an implementation of

TT, is available from
http://www.dcs.st-and.ac.uk/\Lambda eb/STLC/.

2. A Dependently Typed Interpreter
Dependent types can be used to good effect in the implementationof programming languages. One demonstration of this is Augustsson and Carlsson's well-typed interpreter in Cayenne [4, 3]. Thisinterpreter implements the language given below:

e ::= \Lambda a : T . e \Lambda -abstraction--

e e application--
a variable--
e op e binary operator--
n number--
b boolean value--
if e then e else e boolean choice--
primrec e e e primitive recursion

op ::= + -- * --<--=-->-- and -- or

T ::= N Natural numbers--

Bool Booleans--
t \Theta  t Function type

This is a simply typed \Lambda -calculus with booleans and natural num-bers. We call this language

\Lambda AC; our implementation augments Au-gustsson and Carlsson's with a primitive recursion operator for natural numbers, primrec and if . . . then . . . else expressions.
The typing rules for this language are given in Figure 3, withcontext validity defined as follows:

\Xi  valid

\Gamma  \Xi  valid
\Gamma , a : T \Xi  valid

a : T \Pi  \Gamma , a : T a : T \Pi  \Gamma a : T \Pi  \Gamma , b : S
The interpreter we present here uses inductive families to repre-sent well-typedness and synchronisation of type and value environments. By using inductive families, we can express explicit rela-tionships between data structures, just like the relationship between

113

\Gamma  \Xi  n : N \Gamma  \Xi  b : Bool
a : t \Pi  \Gamma  \Xi  a : t

\Gamma , a : s \Xi  e : t
\Gamma  \Xi  \Lambda a : s. e : s \Theta  t

\Gamma  \Xi  e1 : s \Theta  t \Gamma  \Xi  e2 : s\Gamma  \Xi  e

1 e2 : t

\Gamma  \Xi  e1 : N \Gamma  \Xi  e2 : N op \Pi  -+ -- *""

\Gamma  \Xi  e1 op e2 : N

\Gamma  \Xi  e1 : N \Gamma  \Xi  e2 : N op \Pi  -<--=-->""

\Gamma  \Xi  e1 op e2 : Bool

\Gamma  \Xi  e1 : Bool \Gamma  \Xi  e2 : Bool op \Pi  -and -- or""

\Gamma  \Xi  e1 op e2 : Bool

\Gamma  \Xi  x : Bool t : a f : a

\Gamma  \Xi  if x then t else f : a

\Gamma  \Xi  x : N z : a s : N \Theta  a \Theta  a\Gamma  \Xi  primrec x z s : a

Figure 3. Typing rules for \Lambda AC
a Vect and its length. In particular, the types we use express the re-lationship between values and their type and context membership.
This means that, without having to prove any theorems, we havestatic guarantees that evaluation preserves type, and that context
lookup will always succeed. Later, we will also see that we can rep-resent raw (untyped) terms and implement typechecking in such a
way as to guarantee that any well-typed term it produces is of theof the correct type. i.e. we can show soundness of the typechecking
algorithm, by the types alone.

2.1 Representation
We have specified context validity, context membership and thetyping rules in relation to contexts. We would now like to choose
a representation for \Lambda AC terms in the meta-language which reflectsthis specification as directly as possible and ensures that only welltyped expressions can be built. In a traditional language some lossof information is inevitable here, but with inductive families we can
specify in the type the relationships between these concepts.
We begin with a representation of types. These types can be reifiedinto meta-language types with the

interpTy function, since thedependent type system allows us to compute types:

data Ty : \Theta  where TyNat : Ty

TyBool : Ty

s, t : Ty
Arrow s t : Ty

let t : TyinterpTy t : \Theta 

interpTy t \Upsilon  elim t

interpTy TyNat \Lambda \Theta  N
interpTy TyBool \Lambda \Theta  Bool
interpTy (Arrow s t) \Lambda \Theta  interpTy s \Theta  interpTy t

We represent type environments (\Gamma ) as vectors of types, and mem-bership of a type environment as a relation:

let n : NEnv n : \Theta  Env n \Lambda \Theta  Vect Ty n
data G : Env n i : Fin n t : TyVar G i t : \Theta 
where top : Var (s::G) f0 s v : Var G i tpop v : Var (s::G) (fs i) t

Variables are de Bruijn indexed, and represented by an element ofa finite set. Using finite sets gives an explicit bound on the index
which means that the variable can never refer to a value out of thescope given by the type environment. We can also view

top and popas zero and successor constructors of a natural number representing

a de Bruijn index.
If we read Var G i t as G \Xi  i : t, its intended meaning, then wesee a direct correspondence with the earlier definition of context

membership.
The Expr family, which represents expressions in the object lan-guage, is shown below. It is indexed over the type environment

in which it will be evaluated, and the type of value it represents.Therefore any well-typed instance of

Expr must be a representationof a well-typed term; this is a static guarantee. There is no need

to supply a well-typing predicate along with an expression as inprevious work [4, 30], since there is no way to construct ill-typed
values:

data G : Env n A : TyExpr G A : \Theta 
where k : Nenat k : Expr G TyNat

b : Boolebool b : Expr G TyBool

v : Var G i tevar v : Expr G t
f : Expr G (Arrow s t) a : Expr G s

eapp f a : Expr G t

e : Expr (s::G) t
elam e : Expr G (Arrow s t)

op : interpTy A \Theta  interpTy B \Theta  interpTy C

a : Expr G A b : Expr G B

eop op a b : Expr G C

x : Expr G Bool t, f : Expr G A

eif x t f : Expr G A

x : Expr G N z : Expr G A
s : Expr G (N \Theta  A \Theta  A)

eprimrec x z s : Expr G A

Again, if we read the declaration x : Expr G T with its intendedmeaning,

G \Xi  x : T , then we can read the typing rules directlyfrom the
Expr type declaration. The only minor exception is the
eop constructor, which permits a more generic implementation ofbinary operators. Thus any correctly constructed (i.e. well-typed)

instance of an Expr must be a representation of a well-typed termin

\Lambda AC.

As an example, the factorial function could be defined by primitiverecursion as follows:

fact = \Lambda x :N. primrec x 1 (\Lambda k :N. \Lambda ih :N. (k + 1) * ih)
The representation of this as an Expr is:

114

let x : Expr G T ve : ValEnv Ginterp x ve : interpTy T

interp x ve \Upsilon  elim x

interp (enat k) ve \Lambda \Theta  k
interp (ebool b) ve \Lambda \Theta  b
interp (evar v) ve \Lambda \Theta  envLookup v ve
interp (eapp f a) ve \Lambda \Theta  (interp f ve) (interp a ve)
interp (elams e) ve \Lambda \Theta  \Lambda a : interpTy s. interp e (extend a ve)
interp (eop op a b) ve \Lambda \Theta  op (interp a ve) (interp b ve)
interp (eif x t f ) ve \Lambda \Theta  runif (interp x ve) (interp t ve) (interp f ve)
interp (eprimrec x z s) ve \Lambda \Theta  primrec (interp x ve) (interp z ve) (interp s ve)

let x : Bool t, f : Arunif x t f : A

runif x t f \Upsilon  case x

runif true t f \Lambda \Theta  t
runif false t f \Lambda \Theta  f

let n : N z : A s : N \Theta  A \Theta  Aprimrec n z s : A

primrec n z s \Upsilon  elim n

primrec 0 z s \Lambda \Theta  z
primrec (s k) z s \Lambda \Theta  s k (primrec k z s)

Figure 4. The interpreter
fact = elam(eprimrec top (enat (s 0))

(elam (elam

(eop mult (eop plus

(evar (pop top)) (enat (s 0))) (evar top)))))

The interpreter has a value environment in which to look up thevalues of variables. Since variables in the environment may have
different types, using a Vect is not appropriate. Instead, we definea type which synchronises the value environment with the type
environment; each value in the value environment gets its type fromthe corresponding entry in the type environment. The declaration of
the value environment and a lookup function are as follows:

data G : Env nValEnv G : \Theta  where empty : ValEnv \Xi 

t : interpTy T r : ValEnv G

extend t r : ValEnv (T ::G)

let v : Var G i T ve : ValEnv GenvLookup v ve : interpTy T

envLookup v ve \Upsilon  elim v

envLookup top (extend t r) \Lambda \Theta  t
envLookup (pop v) (extend t r) \Lambda \Theta  envLookup v r

The type environment helps to ensure that we can only representwell-typed terms. The value environment is used with the interpreter to ensure that any value we project out of the environmenthas the correct type. The invariants on

envLookup guarantee thatwe can never project a non-existent value out of the environment. It

is not possible to project a value from the empty environment; suchan operation would be ill-typed. This means that there is no need
for any error checking in the interpreter; we know by constructionthat all possible inputs are well-typed and that the output will be of
the correct type.
2.2 The Interpreter
The implementation of the interpreter is shown in Figure 4. interpis written by structural recursion over the input expression

x. It re-turns a semantic representation, as a
TT term, of the input. So,for example, the interpretation of a
\Lambda -abstraction (elam) is a TTfunction which implements that
\Lambda -abstraction. Interpretation of anapplication then simply applies the function to the interpretation of

its argument. Note that in the case for elam, we use the implicit ar-gument

s to establish the input type of the function. This approachis similar to normalisation by evaluation [5] in that we construct

a semantic representation of the term to be interpreted. It is also a
tagless interpreter; i.e., there is no need to tag the return value withits type, since the the type is known from the index of the input.

Evaluating the fact function defined above gives, as expected, the
meta-level implementation of factorial by primitive recursion1:

fact = \Lambda x :N.primrecx (s0)(\Lambda k, ih :N.mult(plusk (s0))ih)

3. Dependent Types and Staging
In [33], Taha states that "a staged interpreter is a translator". Hisidea is to defer code generation for staged fragments until run-time;
in the case of an interpreter, the program generates a meta-languageimplementation of the object program, eliminating the interpretation overhead. In this section, we apply Taha's staging techniqueto the

TT language and show how we can modify our dependentlytyped interpreter to take advantage of staging annotations. A major

advantage over Taha's approach is that dependent types allow usto maintain the compile-time correctness guarantees of Section 2
automatically. It follows that, by construction, our object programsare well-typed, well-scoped and terminating.

3.1 Extensions to TT
To add staging constructs to TT, we begin by extending it withthe notion of levels. Level 0 is the run-time execution level; higher
levels contain deferred code. We index the typing judgment withthe level

n, i.e. \Gamma  \Xi n x : A states that x has type A at level n. Weextend
TT with the following expression forms:

e ::= . . .-- '

e (Quoted term) -- \Omega eff (Code type)--
!e (Evaluate term) -- fie (Escape term)

A, 'e quotes an expression e, deferring its execution until the next

stage. This lifts the expression from level n to level n + 1

1 In fact primrec, mult and plus are also unfolded, but we omit these
details for clarity.

115

A, \Omega eff is the "code" type of a quoted term.
A, !e evaluates a quoted expression e. Since this executes code, it

is only valid at level 0, where e has no free variables.A, fi

e splices (escapes) a quoted term into a lower level. Thismoves an expression from level

n + 1 to level n; n cannot belevel 0, since this would imply execution.

The typing rules are given in Figure 5. These typing rules addition-ally ensure staging correctness -- in particular, a value bound in
a later stage cannot be used in an earlier stage. To guarantee this,context entries are annotated with the level where they are bound
and checked at the point of use, with updated Var and Val rules,and code can only be executed if it has no free variables. This is
a more restrictive solution than strictly necessary -- we could forexample use environment classifiers [35] to ensure that all free variables have an originating environment -- but is sufficient for manyprograms including those we present in this paper.

\Gamma  \Xi n+1 e : A
\Gamma  \Xi n 'e : \Omega Aff Quote \Gamma  \Xi 

n A : \Theta \Gamma  \Xi 

n \Omega Aff : \Theta  Code\Xi 

0 e : \Omega Aff
\Gamma  \Xi 0!e : A Eval

\Gamma  \Xi n e : \Omega Aff
\Gamma  \Xi n+1fie : A Escape

x :n S \Pi  \Gamma  n <= m

\Gamma  \Xi m x : S Var

x \Lambda \Theta  s :n S \Pi  \Gamma  n <= m

\Gamma  \Xi m x : S Val

Figure 5. Typing rules for staging constructs
The two basic notions of equivalence are:

\Xi  e : A\Gamma  \Xi !('e) \Sigma  e \Gamma  \Xi  e : A\Gamma  \Xi fi('e) \Sigma  e

The distinction between the escape and evaluation constructs is thatescape must be enclosed by quotation brackets and evaluation applies only to closed terms -- the purpose of escape is to allow re-duction inside a code building context. Extending an implementation of TT with these constructs is fairly straightforward; the oneaspect needing care is conversion of quoted terms:

\Gamma  \Xi  x, y : A \Gamma  \Xi  x \Sigma  y

\Gamma  \Xi  'x \Sigma  'y

This rule states that quoted terms are definitionally equal if the val-ues they quote are definitionally equal. An implementation of conversion which simply compares normal forms would not implementthis rule correctly, so should be extended accordingly.

3.2 Example -- power
A classic example of the benefit of multi-stage programming is the
power function, which returns the nth power of m. We can definethis as follows:

let n, m : Npower n m : N

power n m \Upsilon  elim n

power 0 m \Lambda \Theta  s 0
power (s k) m \Lambda \Theta  m * (power k m)

This is a generic power function, in that it can be used to compute avalue raised to any non-negative exponent. However, there is a price
to pay for genericity; if the function is often used with the samevalue of

n, our program still has to perform the work associatedwith this input on every application.

We could, at compile time, create specialised instances of thisfunction for commonly used inputs, e.g.:

power2 \Lambda \Theta  power (s (s 0))
power4 \Lambda \Theta  power (s (s (s (s 0))))

These can be partially evaluated at compile-time, but this requiresknowing in advance what the specialised inputs are. What if we do
not know until run-time? We do not have a way, in the languagewithout staging annotations, of partially evaluating at run-time to
create these specialised instances on dynamic data.
Staging annotations, combined with run-time code generation, giveus a method for creating these specialised instances dynamically:

let n : N m : \Omega Nffpower\Theta  n m : \Omega Nff

power\Theta  n m \Upsilon  elim n

power\Theta  0 m \Lambda \Theta  '(s 0)
power\Theta  (s k) m \Lambda \Theta  '(fim * fi(power\Theta  k m))

Now, reading an input at run-time, we dynamically generate aspecialised

power function; for example, with the input s (s 0):

power\Theta  (s (s 0)) = \Lambda m :\Omega Nff. '(m * m * (s 0))
We run such generated code with the ! construct. For example,
power2 can now be defined as follows:

power2 = !('\Lambda m :N. fi(power\Theta  (s (s 0)) 'm))
The ! construct compiles and executes its argument; at run-time,this will generate code for a specialised power of two function.
This behaves in the same way as our earlier unstaged definitionof

power2 but with the partial evaluation deferred until run-time.

Although this is a somewhat artificial example, it illustrates thedifference between specialising functions at compile-time and runtime. This staging technique has greater benefit where we have alarge, commonly used structure which is nevertheless not known
until run-time -- for example, a syntax tree for a program which isto be interpreted.

3.3 A Staged Interpreter
Partial evaluation of an object program yields a representation ofthe program in the meta-language; effectively this is a translated
version of the object program. If we can defer this partial evalua-tion until run-time, then we do not need to know the object program
until run-time. This allows us to remove the interpretation overheadand thus generate a translator for the object language. In the previous section, we saw that staging a program allowed us to deferpartial evaluation of the

power function until run-time. We willnow consider how to apply this technique to the interpreter of Section 2.2. Figure 6 gives a staged version of the interpreter. The basicdefinition is as before, but with staging annotations added to denote
where code generation should be deferred until run-time. Note thatthere are no staging annotations on the call to

envLookup. Thisis because we would also like to partially evaluate this function

-- thus projection of variables from the value environment is done

116

let x : Expr G T ve : ValEnv Ginterp x ve : \Omega interpTy T ff

interp x ve \Upsilon  elim x

interp (enat k) ve \Lambda \Theta  'k
interp (ebool b) ve \Lambda \Theta  'b
interp (evar v) ve \Lambda \Theta  envLookup v ve
interp (eapp f a) ve \Lambda \Theta  '(fi(interp f ve) fi(interp a ve))
interp (elams e) ve \Lambda \Theta  '(\Lambda a : interpTy s. fi(interp e (extend a ve)))
interp (eop op a b) ve \Lambda \Theta  '(op fi(interp a ve) fi(interp b ve))
interp (eif x t f ) ve \Lambda \Theta  '(runif fi(interp x ve) fi(interp t ve) fi(interp f ve))
interp (eprimrec x z s) ve \Lambda \Theta  '(primrec fi(interp x ve) fi(interp z ve) fi(interp s ve))

let n : N t, f : Arunif n t f : A

runif n t f \Upsilon  case n

runif true t f \Lambda \Theta  t
runif false t f \Lambda \Theta  f

let n : N z : A s : N \Theta  A \Theta  Aprimrec n z s : A

primrec n z s \Upsilon  elim n

primrec 0 z s \Lambda \Theta  z
primrec (s k) z s \Lambda \Theta  s k (primrec k z s)

Figure 6. The staged interpreter
only once. We stage envLookup as follows, storing code in thevalue environment:

data G : Env nValEnv G : \Theta  where empty : ValEnv \Xi 

t : \Omega interpTy T ff r : ValEnv G

extend t r : ValEnv (T ::G)

let v : Var G i T ve : ValEnv GenvLookup v ve : \Omega interpTy T ff

envLookup v ve \Upsilon  elim v

envLookup top (extend t r) \Lambda \Theta  t
envLookup (pop v) (extend t r) \Lambda \Theta  envLookup v r

Evaluation of the fact function gives a quoted representation of themeta-level implementation of factorial, with

primrec, mult and
plus not inlined:

fact = '(\Lambda x :N.primrecx(s0)(\Lambda k, ih :N.mult(plusk(s0))ih))
We have now deferred the partial evaluation until run-time -- ratherthan incurring interpretation overhead each time we wish to run
this object language function, there is now a single compilationoverhead, with code generated for the quoted function at run-time.

4. A Verified Compiler
Our choice of data type for the object language means that the im-plementation of the interpreter is simultaneously a proof of the desired properties. By using full-spectrum dependent types, we havea guarantee that input to the interpreter is well-scoped and welltyped, and that the output will be the correct type. Our represen-tation of the object language, in particular the invariants which it
satisfies, means that we know the properties that the interpretersatisfies by construction rather than by post-hoc theorem proving.
Staging lets us take this a step further -- from the representation ofthe object language and the staging of the interpreter, we generate
a correct compiler, by construction.
In this section, we will give some desired properties of our stagedinterpreter, and give explicit proofs of these properties. The principal advantage of our method for compiler construction is that theseproofs are extremely simple -- the use of inductive families and our

choice of invariants on these families means that the properties inwhich we are interested are already checked by the (meta-language)
typechecker.

data n : NRaw n : \Theta 
where k : Nrnat k : Raw n b : Boolrbool b : Raw n

i : Fin nrvar i : Raw n f , a : Raw nrapp f a : Raw n

e : Raw (s n)
rlam e : Raw n

op : interpTy A \Theta  interpTy B \Theta  interpTy C

a, b : Raw n

rop op a b : Raw n

x, t, f : Raw n
rif x t f : Raw n

x, z, s : Raw n
rprimrec x z s : Raw n

data G : Env n r : Raw n T : TyChecked G r T : \Theta 

where e : Expr G Tok e : Checked G r T error : Checked G r T
let G : Env n r : Raw n T : Tycheck G r T : Checked G r T

Figure 7. Checking Raw Terms
Let us first complete our prototype implementation with a datatypefor raw terms (we assume the existence of a parser which generates
these well-scoped terms) and a typechecker. The check function(declared in Figure 7) takes a raw term and its intended type and
returns a Checked structure, which either contains a well-typedterm, or an error. We omit the definition of

check; its structurefollows that of the typechecker example in [25].

To begin, let us define a correspondence between the definition of
\Lambda AC and our representation, Raw, Ty and Expr.

117

Definition 1 (Representation). If \Gamma  \Xi  t : T then:

A, \Theta \Gamma \Lambda  is the representation of the context (with n entries) as an

Env n

A, \Theta T \Lambda  is the representation of the type as a Ty.
A, \Theta t\Lambda  is the representation of the term as an Expr \Theta \Gamma \Lambda  \Theta T \Lambda .
A, RAW(t) is the representation of the term as raw syntax, Raw n.

Since dependent types encode many correctness properties directlywithin the program, the substantial part of any compiler correctness
proof is in checking that the implementation faithfully models thesemantics. We can show that our representation is a complete and
faithful representation of \Lambda AC by its correspondence with the typingrules.

Lemma 2 (Soundness of representation). If e : Expr \Theta \Gamma \Lambda  \Theta T \Lambda ,then there is a term

t such that \Theta t\Lambda  = e and \Gamma  \Xi  t : T .

Proof. Each constructor of Expr directly corresponds to a typingrule (Figure 3), by reading

x : Expr G T as G \Xi  x : T .

Lemma 3 (Completeness of representation). If \Gamma  \Xi  t : T , then
there is a term e : Expr \Theta \Gamma \Lambda  \Theta T \Lambda , such that \Theta t\Lambda  = e.

Proof. Each typing rule (Figure 3), directly corresponds to a con-structor of

Expr by reading x : Expr G T as G \Xi  x : T .

For the correctness of our implementation, we verify that the type-checker is a sound and complete implementation of the typing
rules, and that evaluation preserves type.
Theorem 4 (Soundness of typechecking function). If
check \Theta \Gamma \Lambda  RAW(t) \Theta T \Lambda  \Theta  ok e then \Gamma  \Xi  t : T , where
e : Expr \Theta \Gamma \Lambda  \Theta T \Lambda .

Proof. By the type of the Checked view, and the check function,no

e can be constructed which does not have the type Expr\Theta \Gamma \Lambda \Theta T \Lambda .Then

\Gamma  \Xi  t : T by Lemma 2.

Although we can show soundness using types alone, completenessrequires some extra work, involving the details of the

check func-tion.

Theorem 5 (Completeness of typechecking function). If
\Gamma  \Xi  t : T then check \Theta \Gamma \Lambda  RAW(t) \Theta T \Lambda  \Theta  ok e, where
e : Expr \Theta \Gamma \Lambda  \Theta T \Lambda .

Proof Sketch. By Lemma 3, there exists a term e : Expr \Theta \Gamma \Lambda  \Theta T \Lambda .The totality of the

check function ensures that it will produceeither a term
ok e, where e represents a term of the correct type(by Theorem 4), or

error.

To show that check produces a well-typed term where it exists, wedefine a forgetful map operation --

e--, where e : Expr G T , andshow by induction over --
e-- that check G --e-- T \Theta  ok e.

Theorem 6 (Subject Reduction). If interp s ve \Theta  t and
s : Expr G T then t : T .

Proof. The return type of interp ensures that the meta-level valuereturned has the type required by its representation. By typechecking in TT, s : Expr G T ensures that t : T . Furthermore, since
interp is total, evaluation will always return a value.

In addition, because the implementation language is strongly nor-malising (i.e., evaluation always terminates with a constructor
headed value), we know that variable lookup will always suc-ceed, and the interpreter will always terminate correctly. Therefore, for any object program, the interpreter will always produce ameta-level representation of that program. We have verified these
properties for the unstaged implementation -- since the stagingannotations guarantee that types are preserved between stages, and
these properties are shown by the program's type, we can be surethat these correctness properties are preserved after staging the interpreter. By verifying the properties for the interpreter, and addingstaging annotations, we have verified the properties for the resulting compiler.
4.1 Termination and Side Effects
Since we have used a strongly normalising language to implementa staged interpreter for

\Lambda AC, we can be sure of strong propertiessuch as termination of
\Lambda AC. For many domain specific languages,guaranteed termination is important. For example Hume [16] is

separated into two layers, a co-ordination layer which directs theflow of data, and a computation layer which processes data. If we
desire strong static guarantees about programs in the computationlayer, we may also require computations to be total.

From our perspective, the primary benefits of a strongly terminatinglanguage, in which fl is not a value, are that proofs are total and
typechecking is decidable. In a full-spectrum dependently typedlanguage, where values can appear in types and vice versa, the
termination property is essential for decidability of typechecking.Furthermore, without it, it is possible to construct a proof of any
proposition by creating a non-terminating function bottom =
bottom, which can have any type we like.

As far as proofs and typechecking are concerned, totality is vital.However, the resulting limitation is that our programs must also not

possess side-effects, such as I/O, since these effects could appearin types. This precludes the implementation of a Turing complete
language in TT as it stands. Meta-D [30] avoids this problem byrestricting the type language. We prefer not to make the same restrictions since a key part of our method is that proofs are easilyexpressible within the source language. Our proposed solution to
this problem is as for I/O in Haskell, treating partiality as a monad.In collaboration with Capretta, Altenkirch [1] and Uustalu [36] are
developing such a method for introducing partiality into a depen-dently typed language without losing decidable typechecking, and
this work transfers neatly to our setting.

5. Dependent Types for Resource Analysis
We have previously considered the use of dependent types to pro-vide static guarantees of resource properties for functional programs [7]. The idea is to predicate each user-defined type on anatural number, representing the size of values in that type; each
function then returns both a value and its size plus a proof that thesize satisfies a given predicate. This is represented by the following
Size type:

data A : N \Theta  \Theta  P : (n : N) \Theta  A n \Theta  \Theta Size A P : \Theta 
where val : A n p : P n valsize val p : Size A P
For example, we can implement a size-safe list append functionby predicating a

List type on a natural number, and implementing
append as follows:

118

data A : N \Theta  \Theta List

S A : N \Theta  \Theta 

where nil

S : ListS A 0

x : A xn xs : ListS A xsncons

S x xs : ListS A (s xsn)

let xs : ListS A xsn ys : ListS A ysnappend xs ys : Size List

S A (\Lambda n :N. \Lambda v :ListS A n.n = xsn + ysn)

append nilS ys \Lambda \Theta  size ys (refl ysn)
append (consS x xs) ys\Lambda \Theta  let

(size val p) = append xs ys in

size (consS x val ) (resp s p)

We have not yet considered in detail how to execute these programs.It is important when constructing a resource analysis that the cost
proofs do not interfere with the actual program execution costs,otherwise the costs will no longer be valid! While the techniques
of [6] will mitigate this problem, they will not completely removethis dynamic cost information. A further (potentially error-prone)
pass is required in the implementation in order to translate Sizestructures into simple values. A staged interpreter for a resourceaware functional language would, however, allow us to remove thecost information in a principled way.

The verified interpreter presented above can now be extended toinclude size properties as well as type properties. To do this, we
extend the type environment to include size variables as well as
\Lambda -bound variables, as shown in Figure 8. Since type environ-ments now contain size information, we can embed size properties in types and proofs of those properties within programs, asrequired. We are continuing to develop this idea for a full size
aware language, using staging to generate TT code for executionvia Hume [16].

data vn, vs : NTyEnv v

n vs : \Theta 

where empty : TyEnv 0 0

G : TyEnv vn vs
sizeExtend G : TyEnv vn (s vs)

t : Ty vs G : TyEnv vn vs
typeExtend t G : TyEnv (s vn) vs

Figure 8. Type environments with size variables
6. Related Work
Our work brings together the related areas of dependently typedprogramming [2] and multi-stage programming [32], building
on the idea of a tagless staged interpreter [30, 29]. One impor-tant difference in our work is the use of

full-spectrum dependent
types [26]; there is no syntactic distinction between types andterms. An advantage of this is that it becomes easier to express

properties of a program in the type, without the need to duplicatevalues at the kind level. We do not need to maintain a

phase dis-tinction between types and values; instead, we maintain a phase

distinction between compile-time and run-time values using tech-niques originally developed in Brady's PhD thesis [6].

Furthermore, our language does not have effects such as non-termination. This is important if we want our programs to have verifiable static guarantees; non-termination (via a fixpoint combinator

with type (P : \Theta ) \Theta  (P \Theta  P) \Theta  P) introduces an incon-sistency into our programs which means that proofs of properties
in the program can no longer be trusted. Further examples of pro-gramming in this way, including the rationale, are presented in [2].
By adding staging annotations to a logically sound type theory weaim to implement compilers with verifiable static guarantees.

Our approach to verification is to annotate data structures with theirinvariants. Another possibility with a dependent type system is to
pair a program with a proof of its specification. This is the approachtaken by Leroy [21], who is developing and certifying a compiler
in COQ. Hutton and Wright [19] also discuss compiler correctness,but providing an external proof of the required properties. McKinna and Wright [27] use EPIGRAM to give an explicit proof ofcompiler correctness in the implementation language. These methods concentrate on the back-end; our approach, assuming a correctcompiler for the meta-language, allows us to concentrate on the semantics of the object language.
We have not yet addressed the implementation techniques requiredof our multi-stage language. Our current prototype implementation

is based on normalisation by evaluation [5]. The MetaOCaml com-piler implements the

! (eval) construct by linking the compiler inwith the executable and representing code as an abstract syntax

tree2. A more practical implementation technique may be to ex-ploit the relationship with Gr'egoire and Leroy's compiled strong
reduction [15] -- one way of understanding staging annotations isthat they direct when to reduce under binders. Gr'egoire and Leroy's
technique, in which they extend run-time values with a representation of free variables, may provide an efficient method for con-structing code at run-time.

7. Conclusions and Further Work
This paper has investigated the construction of verified compilersfor domain specific languages using a combination of dependent
types and multi-stage programming. While the use of dependenttypes to expose software properties means that some initial work
must be done in order to properly express these properties in thetypes, there is a significant benefit in improving the ease of subsequent verification, and in providing support for automation. More-over, once constructed, a single dependently typed framework may
be reused in either a general or domain specific manner.
We have taken great care to annotate the representation of theinterpreter data structures in such a way as to guarantee that an

implementation of the interpreter is both total and preserves thetype. The payoffs are that the implementation is straightforward,
no error checking is required, and that the typechecker guaranteesthe properties we specify. The rationale behind working so hard
to choose the right representation is that data is static and code isdynamic -- if we choose to annotate the static construct with more
information, we do less work dynamically. This greatly simplifiesprogram verification -- the only work we have to do is to show that
the data structure we use accurately models the requirements.
This paper has considered only fairly simple properties. In a realdomain specific language, such as our Hume target [16], we will

need to express both more complex invariants and more complexproperties than the simple size metrics used here. in such a setting,
full spectrum dependent types will be invaluable in allowing us toexpress the relationship between the language and its properties
precisely. Such properties might include: guaranteed termination;time, space and power usage for some implementation; or the
correctness of specific program transformations. Adding staging
2 Walid Taha, pers. comm.

119

annotations to such a domain specific interpreter will give a meta-language implementation, without explicit proofs, but preserving
the guarantees in the interpreter's type.
While partial evaluation of a strongly normalising program canyield a semantic representation of an object program in the meta

language without any need for adding staging annotations, we doget an important further benefit from adding these annotations --
namely, that we obtain a machine code representation of the objectprogram, in addition to the

meta-language code provided by partialevaluation. By combining the two techniques of dependently typed

programming and multi-stage programming, we can implement anefficient compiler for a resource aware functional language with
strong static guarantees.

Acknowledgements
This work is generously supported by EPSRC grant EP/C001346/1and by EU Framework VI IST-510255 (EmBounded). We would
like to thank Walid Taha and James McKinna, and the anonymousreferees for their helpful comments.

References

[1] T. Altenkirch. Stop thinking about bottoms when writing programs,2006. Talk at BCTCS 2006.

[2] T. Altenkirch, C. McBride, and J. McKinna. Why dependent types

matter. http://www.cs.nott.ac.uk/\Lambda txa/publ/ydtm.pdf,
2005. Draft.

[3] L. Augustsson. Cayenne - a language with dependent types. In Proc.

1998 International Conf. on Functional Programming (ICFP '98),
pages 239-250, 1998.

[4] L. Augustsson and M. Carlsson. An exercise in dependent

types: A well-typed interpreter. http://www.cs.chalmers.se/\Lambda 

augustss/cayenne/, 1999.

[5] U. Berger and H. Schwichtenberg. An inverse of the evaluation

functional for typed \Theta -calculus. In R. Vemuri, editor, Proc. 1991
IEEE Symp. on Logic in Comp. Sci., pages 203-211, 1991.

[6] E. Brady. Practical Implementation of a Dependently Typed

Functional Programming Language. PhD thesis, University ofDurham, 2005.

[7] E. Brady and K. Hammond. A dependently typed framework for

static analysis of program execution costs. In Proc. Implementation
of Functional Languages (IFL 2005). Springer, 2006.

[8] L. Cardelli. Phase distinctions in type theory. Manuscript, 1988.
[9] Coq Development Team. The Coq proof assistant -- reference

manual. http://coq.inria.fr/, 2001.

[10] H. B. Curry and R. Feys. Combinatory Logic, volume 1. North

Holland, 1958.

[11] K. Czarnecki, J. O'Donnell, J. Striegnitz, and W. Taha. DSLimplementation in MetaOCaml, Template Haskell, and C++. In

Domain Specific Program Genearation 2004, volume 3016 of LNCS.
Springer, 2004.

[12] P. Dybjer. Inductive families. Formal Aspects of Computing,

6(4):440-465, 1994.

[13] J. Eckhardt, R. Kaibachev, E. Pa^sal'ic, K. Swadi, and W. Taha.Implicitly heterogeneous multi-stage programming. In

Proc. 2005
Conf. on Generative Programming and Component Engineering
(GPCE 2005), volume 3676 of LNCS. Springer, 2005.

[14] Y. Futamura. Partial evaluation of computation process - an approachto a compiler-compiler.

Higher-Order and Symbolic Computation,
12(4), 1999. Reprinted from Systems * Computers * Controls 2(5),
1971.

[15] B. Gr'egoire and X. Leroy. A compiled implementation of strong

reduction. In Proc. 2002 International Conf. on Functional
Programming (ICFP 2002), pages 235-246, 2002.

[16] K. Hammond and G. Michaelson. Hume: a Domain-Specific

Language for Real-Time Embedded Systems. In Proc. Conf.
Generative Programming and Component Engineering (GPCE '03),
Lecture Notes in Computer Science. Springer-Verlag, 2003.

[17] R. Harper and R. Pollack. Type checking with universes. Theoretical

Computer Science, 89(1):107-136, 1991.

[18] W. A. Howard. The formulae-as-types notion of construction. InJ. P. Seldin and J. R. Hindley, editors,

To H.B.Curry: Essays on
combinatory logic, lambda calculus and formalism. Academic Press,
1980. A reprint of an unpublished manuscript from 1969.

[19] G. Hutton and J. Wright. Compiling exceptions correctly. In

Mathematics of Program Construction, volume 3125 of LNCS.
Springer, 2004.

[20] O. Kiselyov, K. Swahi, and W. Taha. A methodology for generating

verified combinatorial circuits. In Fourth International Conference
on Embedded Software, pages 249-258. ACM, 2004.

[21] X. Leroy. Formal certification of a compiler back-end. In Principles

of Programming Languages 2006, pages 42-54. ACM Press, 2006.

[22] Z. Luo. Computation and Reasoning - A Type Theory for Computer

Science. Intl. Series of Monographs on Comp. Sci. OUP, 1994.

[23] C. McBride. Dependently Typed Functional Programs and their

proofs. PhD thesis, University of Edinburgh, May 2000.

[24] C. McBride. Epigram: Practical programming with dependent types.

Lecture Notes, International Summer School on Advanced Functional
Programming, 2004.

[25] C. McBride and J. McKinna. The view from the left. Journal of

Functional Programming, 14(1):69-111, 2004.

[26] J. McKinna. Why dependent types matter. In Proc. ACM Symp.

on Principles of Programming Languages (POPL 2006), pages 1-1,
2006.

[27] J. McKinna and J. Wright. A type-correct, stack-safe, provablycorrect expression compiler in Epigram.

Journal of Functional
Programming, 2006. To appear.

[28] MetaOCaml: A compiled, type-safe multi-stage programming

language. Available online from http://www.cs.rice.edu/\Lambda 

taha/MetaOCaml/, 2001.

[29] E. Pa^sal'ic. The Role of Type-Equality in Meta-programming. PhD

thesis, OGI School of Science and Engineering, 2004.

[30] E. Pa^sal'ic, W. Taha, and T. Sheard. Tagless staged interpreters for

typed languages. In Proc. 2002 International Conf. on Functional
Programming (ICFP 2002). ACM, 2002.

[31] T. Sheard and S. Peyton-Jones. Template meta-programming for

haskell. In Proc. 2002 ACM Haskell workshop, pages 1-16, 2002.

[32] W. Taha. Multi-stage Programming: Its Theory and Applications.

PhD thesis, Oregon Graduate Inst. of Science and Technology, 1999.

[33] W. Taha. A gentle introduction to multi-stage programming,2003. Available from

http://www.cs.rice.edu/\Lambda taha/
publications/journal/dspg04a.pdf.

[34] W. Taha, S. Ellner, and H. Xi. Generating heap-bounded programs in

a functional setting. In Third International Conference on Embedded
Software, volume 2855 of LNCS. Springer, 2003.

[35] W. Taha and M. F. Nielsen. Environment classifiers. In Proc. ACM

Symp. on Principles of Programming Languages (POPL 2003), pages
26-37, 2003.

[36] T. Uustalu. Partiality is an effect, 2004. Talk at Dagstuhl workshop

on Dependently Typed Progamming.

120