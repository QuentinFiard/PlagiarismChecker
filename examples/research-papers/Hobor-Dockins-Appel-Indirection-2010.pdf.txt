

A Theory of Indirection via Approximation
Aquinas Hobor *#
National University of Singapore

hobor@comp.nus.edu.sg

Robert Dockins#
Princeton University
rdockins@cs.princeton.edu

Andrew W. Appel #

Princeton University
appel@princeton.edu

Abstract
Building semantic models that account for various kinds of indirectreference has traditionally been a difficult problem. Indirect reference can appear in many guises, such as heap pointers, higher-orderfunctions, object references, and shared-memory mutexes.

We give a general method to construct models containing indi-rect reference by presenting a "theory of indirection". Our method
can be applied in a wide variety of settings and uses only simple,elementary mathematics. In addition to various forms of indirect
reference, the resulting models support powerful features such asimpredicative quantification and equirecursion; moreover they are
compatible with the kind of powerful substructural accounting re-quired to model (higher-order) separation logic. In contrast to previous work, our model is easy to apply to new settings and has asimple axiomatization, which is complete in the sense that all models of it are isomorphic. Our proofs are machine-checked in Coq.
Categories and Subject Descriptors D.3.1 [PROGRAMMINGLANGUAGES]: Formal Definitions and Theory -- Semantics;

F.3.1 [LOGICS AND MEANINGS OF PROGRAMS]: Specifyingand Verifying and Reasoning about Programs -- Logics of programs; F.4.1 [MATHEMATICAL LOGIC AND FORMAL LAN-GUAGES]: Mathematical Logic -- Mechanical theorem proving

General Terms Languages, Theory, Verification
Keywords Indirection theory, Step-indexed models

1. Introduction
A recurring problem in the semantics of programming languages isfinding semantic models for systems with indirect reference. Indirection via pointers gives us mutable records; indirection via lockscan be used for shared storage; indirection via code pointers gives
us complex patterns of computation and recursion. Models for pro-gram logics for these systems need to associate invariants (or assertions, or types) with addresses in the store; and yet invariants arepredicates on the store. Tying this "knot" has been difficult, especially for program logics that support abstraction (impredicativity).
* Supported by a Lee Kuan Yew Postdoctoral Fellowship.

# Supported in part by NSF awards CNS-0627650 and CNS-0910448, and
AFOSR award FA9550-09-1-0138.

Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citationon the first page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior specific permission and/or a fee.
POPL'10, January 17-23, 2010, Madrid, Spain.Copyright cfl 2010 ACM 978-1-60558-479-9/10/01.. . $10.00

Consider general references in the polymorphic *-calculus.Here is a flawed semantic model of types for this calculus:

value j loc of address + num of N + . . .

type j (memtype * value) ! T
memtype ss address * type (1)

Values are a tagged disjoint union, with the tag loc indicatinga memory address. T is some notion of truth values (e.g., the

propositions of the metalogic or a boolean algebra) and a naturalinterpretation of the type

A ! T is the characteristic function for aset of
A. We write ss to mean "we wish we could define things thisway" and

A * B to indicate a finite partial function from A to B.The typing judgment has the form

 ` v : o/, where  isa memory typing (
memtype), v is a value, and o/ is a type; thesemantic model for the typing judgment is

 ` v : o/ j o/(, v).Memory typings are partial functions from addresses to types. The

motivation for this attempt is that the type "ref o/" can use thememory typing to show that the reference's location has type

o/:

ref o/ j *(, v). 9a. v = loc(a) ^ (a) = o/.
That is, a value v has type ref o/ if it is an address a, and accordingto the memory typing

, the memory cell at location a has type o/.Unfortunately, this series of definitions is not well-founded:

type contains a contravariant occurrence of memtype, which inturn contains an occurrence of

type. A standard diagonalizationproves that no solution to these equations exists in set theory.

A recent approach to tackle this problem is to employ stratifi-cation, yielding a well-founded definition of an appropriate semantic model [AAV03, Ahm04, AMRV07]. A key strength of thesemodels is that they can express general (impredicative) quantified
types even though they are stratified. Unfortunately, these modelshave a disturbing tendency to "leak" into any proofs utilizing them,
making modularization difficult, obscuring their essential features,needlessly limiting their power, and contributing to unpleasant tedium. Also, all of these models are specialized to the problem ofmutable references, and even for the expert it can be daunting to
modify the techniques to apply to other domains.Hobor et al. applied these techniques to Hoare logics, developing a model for a concurrent separation logic (CSL) with first-class locks and threads [HAZ08]. This model was extremely complex to construct because the substructural accounting was woventhroughout the stratification. It was also complex to use, exposing
more than fifty axioms.Even then, the axiom set was incomplete:from time to time the CSL soundness proof required the statement
and proof of additional properties (which were provable from themodel). Like the mutable reference models, Hobor et al.'s model
was a solution to a specific problem, and could not be applied toother problems--not even to other concurrent separation logics.

We present a single solution, indirection theory, that can handlethese domains as well as numerous others. Our model is characterized by just two axioms, an order of magnitude better than the sim-plest of the previous solutions. The axioms are equational, orthog1

onal, and complete, and have greater expressive power and cleanermodularity. The modularity enables a graceful extension for substructural accounting that does not need to thread the accountingthrough the stratification. Moreover, the axioms provide greater insight into the model by directly exposing the approximation at theheart of the stratification technique.

As we show in $2, a key observation is that many domains canbe described by the pseudoequation:

K ss F ((K * O) ! T), (2)
where F (X) is a covariant functor, O is some arbitrary set of"other" data and

K is the object that we wish to construct. Theearlier cardinality argument guarantees we cannot construct

K (inset theory), but indirection theory lets us approximate it:

K _ N * F ((K * O) ! T) (3)
Here X _ Y means the "small" type X is related to the "big" type
Y by two functions: squash : Y ! X and unsquash : X ! Y .The

squash function "packs" an element y of the big type Y into anelement of the small type

X, applying an approximation when thestructure of
y is too complex to fit into X. The unsquash functionreverses the process, "unpacking" an element of

X into an elementof
Y ; since Y is bigger than X, unsquash is lossless.The

squash and unsquash functions form a section-retractionpair, meaning that

squash ffi unsquash : X ! X is the identityfunction and
unsquash ffi squash : Y ! Y is an approximationfunction. Thus

X _ Y is almost an isomorphism, and informallyone can read
X _ Y as "X is approximately Y". With equation(3), indirection theory says that left hand side of pseudoequation

(2) is approximately equal to a pair of a natural number and theright hand side of pseudoequation (2).

Contributions.

$2 We show numerous examples containing indirect reference andshow how they can be characterized with a covariant functor.

$3 We present the two axioms of indirection theory.$

4 We show how to apply the axioms to two of the examples.$
5 We explore some implications of indirection theory.$
6 We induce an impredicative logic from indirection theory.$
7 We combine indirection theory and substructural accounting.$
8 We show a simple way to construct the model once and for all,avoiding the need for application-specific models.

$9 We prove that the axioms of indirection theory completelycharacterize our model (that is, all models are isomorphic).

Our proofs are completely machine-checked. The Coq imple-mentation of the axioms of indirection theory from $3, the logics
and constructions from $6 and $7, the model construction from $8,the uniqueness proof from $9, and the worked example of using
indirection theory to prove the type soundness of the polymorphic
*-calculus with references from $2.1, are available at:

http://msl.cs.princeton.edu/

2. Applications for indirection theory
Here we examine a selection of examples involving indirect refer-ence. In each case intuition leads to an impossible model that we

can approximate with indirection theory. We do not explain the ex-amples in great detail, and refer interested readers to the original
papers, which explain the full motivation and original models. Ineach case, constructing the original model was a difficult task.

2.1 General references in the *-calculus
Ahmed et al. constructed the first model of a type system for thepolymorphic

*-calculus with general references [AAV03]. Follow-ing (1), we want a solution to the pseudoequation

memtype ss address * ((memtype * value) ! T),
which falls neatly into the pattern of pseudoequation (2) with

F (X) j address * X

O j value.

By equation (3), indirection theory constructs the approximation

memtype _ N * (address * ((memtype * value) ! T)),
and by folding the definition of type (from eqn. 1) we reach

memtype _ N * (address * type).
This model is sufficient to define a powerful type system for thepolymorphic

*-calculus with mutable references. In $4.1, we willshow how to construct the types

nat and ref o/.

2.2 General references in von Neumann machines
Modeling a type system with general references for von Neumannmachines was solved first by Ahmed [Ahm04], and then later in

a more sophisticated way by Appel et al. [AMRV07]. The key isthat whereas in the

*-calculus types are based on sets of values, ona von Neumann machine types are based on sets of register banks.

Here is the intuition for a von Neumann machine with 32-bit integermemory addressing and

m 32-bit integer registers:

rbank j int32* m-2. . . *int32

type j (memtype * rbank) ! T
memtype ss int32 * type.

The intuition is thus very similar to the *-calculus case. We set

F (X) j int32 * X

O j rbank,

and indirection theory constructs the approximation

memtype _ N * (int32 * type).
In the *-calculus, the memory maps addresses to values, and valuesare the

O used in constructing the model for types. In the vonNeumann machine, the memory maps 32-bit integer addresses to

32-bit integer values; however, O is not a single 32-bit integer butinstead a register bank of

m 32-bit integers. This minor mismatchmakes the type
ref o/ slightly harder to define in the von Neumanncase, but does not cause any fundamental difficulties.

2.3 Object references
Hrit,cu and Schwinghammer modeled general references in thesetting of Abadi and Cardelli's object calculus [HS08]. The object

calculus setting introduces a number of new issues: object creation,method updates, and bounded subtyping. To model the storage of
methods in the heap, Hrit,cu and Schwinghammer would like tobuild the following impossible model:

type j (heaptype * value) ! T
heaptype ss address * type.

Again applying our recipe, we choose F and O as

F (X) j address * X

O j value,

which yields the approximate model

heaptype _ N * (address * type).

2

Pleasingly, the normal complications of objects do not appear inthe construction of the semantic model. Objects, subtyping and
quantification are all dealt with on top of the same simple modelof memory/heap typings used for general references.

2.4 Substructural state
Ahmed et al. used substructural state to model the uniqueness typesfound in languages such as Clean, Cyclone, and TAL [AFM05].

Here the intuitive model has two changes:

quals j {U, R, A, L}
type j (memtype * quals * value) ! T
memtype ss address * quals * type.

The quals indicate substructural restrictions: U indicates unre-stricted data,

R indicates relevant, A indicates affine, and L in-dicates linear. This model differs from the previous two by putting

quals in both contravariant and covariant positions. We can set

F (X) j address * (quals * X)
O j quals * value,

and use indirection theory to construct the approximation

memtype _ N * (address * (quals * type)).

2.5 Embedding semantic assertions in program syntax
Consider a Hoare logic for a language with function pointers andan assert statement. The predicate

f : {P }{Q} means that f isthe address of a function with precondition

P and postcondition Q.The statement assert
(P ) means that logical assertion P holds atthe current program point. This assert is much more powerful than

a traditional assert because it takes an assertion in the logic insteadof a program expression; i.e.,

P need not be computable.1There are two ways to represent assertions

P :

* A syntax for assertions, with an associated interpretation;

* A semantic predicate of the metalogic (e.g., CiC).

We choose to use semantic assertions because they give additionalflexibility and save quite a bit of effort. With syntactic assertions,

the syntax of assertions must be fixed at the same time as the syntaxof the language. However, it is not until one is writing programs
(well after the syntax of the language is fixed) that one knowswhich assertions will be required. With semantic assertions, one
can enrich the assertion language at any time by simply defining itsmeaning in the metalogic. This "late binding" allows users of the
programming language to define entire type disciplines or programlogics, should they wish. Moreover, by using semantic assertions
we get to reuse the binding structure of the metalogic for free,which relieves us of the burden of encoding binding structure for
quantifiers using de Bruijn indices or some other technique.In a conventional semantics of Hoare logic with function pointers, f : {P }{Q} is defined as "f is a function with body b such that{

P } b {Q}" [Sch06, AB07]. This means that assertions are predi-cates over program syntax. This is simple if assertions are not also

embedded in syntax, but if they are then one desires the following:

predicate j (program * memory * . . .) ! T
syntax j assert of predicate +assign

of ident * expr + . . .
program ss address * syntax.

Here the Hoare logic assertions (predicate) judge the program,the memory, and other unspecified objects (e.g., local variables).

The program is used to check function-pointer assertions. Program
1 It is not that we intend to build a machine that can compute whether some
arbitrary assertion P holds; it is that we can use P to reason statically aboutthe program, and then erase to an executable program.

syntax is a tagged disjoint sum and includes the assert statementas well as numerous others (e.g., assignment, function call, loops).
The program is a partial function from addresses to syntax. We set

F (X) j address * (assert of X + . . .)
O j memory * . . . ,

and use indirection theory to construct the approximation

program _ N * (address * syntax).
This model for assertions has not been presented previously;the conventional presentation of embeddable assertions requires

syntactic predicates. Modifying the techniques of Ahmed et al.[AAV03, Ahm04], Appel et al. [AMRV07], etc. to build a model
for this situation appears intimidating.The reason directly stratifying over syntax seems difficult is not
an issue of theoretical power but rather one of proof engineering.The stratification in those models needs to be built through program
syntax, which greatly increases the number of tedious details in theconstruction. The key innovation that makes constructing the model
easy in our approach is the introduction of the functor F , whichabstracts away the boring "plumbing".

2.6 Concurrent separation logic with first-class locks
Concurrent Separation Logic (CSL) is a novel way to reason aboutconcurrent programs [O'H07]. However, originally it had several

limitations, most importantly a lack of first-class locks (locks thatcan be created/destroyed dynamically). Hobor et al. and Gotsman
et al. independently extended CSL to handle first-class locks aswell as a number of other features [HAZ08, GBC

+07].

The key idea in CSL is that acquiring a lock allows a threadaccess to additional resources (memory), and releasing a lock relinquishes said resources. The "shape" of the resources acquired orrelinquished is described by a predicate of separation logic. Firstclass locks are challenging to model because the resource invariantof one lock can describe the binding of a resource invariant to another lock. The intuitive model for this contains a circularity:

res j VAL of value + LK of (share * bool * pred)
pred j (heap * locals) ! T
heap ss address * res

Heaplets (heap) are partial functions mapping locations to re-sources (

res): either regular data (VAL) or locks (LK). Regulardata locations contain values. Since multiple threads can each own

part of a lock, each lock is associated with a share, which trackshow much of the lock is controlled. Locks also have a boolean,
which is true if this thread holds the lock; and a predicate (pred)specifying the lock's resource invariant. We set

F (X) j address*(VAL of value +LK of (share *bool *X))

O j locals,

and then can use indirection theory to construct the approximation

heap _ N * (address * res).
This example is particularly interesting because the resource mapsplay dual roles: not only do resource maps allow us to solve the

indirect reference problems arising from first-class locks, but theyalso give us a way to define a separation logic. In $4.2 we will show
how to define the points-to and is-a-lock assertions, and in $6 and$7 will develop the rest of a higher-order separation logic.

Inversion. In reasoning about resources one wants to do inversion(case analysis) on the

res type; in reasoning about syntax ($2.5),one wants to do inversion on

syntax. Indirection theory supportsfull inversion, unlike our previous models [HAZ08, Hob08].

3

2.7 Industrial-strength CSL model for Concurrent C minor
Indirection theory is not only mathematically elegant, but alsocapable of constructing significantly more complicated models than

the previous examples. We have used indirection theory to build amodel for CSL for Concurrent C minor, a dialect of C with dynamic
locks, function pointers, first-class threads, pointer arithmetic, byteand word addressability, and sophisticated sequential control flow
[Ler06, HAZ08, Hob08]. Required features included:

* First-class function pointer specifications that can relate func-tion pre- and postconditions and arguments/return values.

* Language independence, i.e., assertions are not predicates overprogram syntax. This is (therefore) a different treatment of the

Hoare triple than sketched in $2.5; see [Hob08, Ch. 10].*
First-class locks (i.e., the resource invariant of a lock can referto other locks, function pointers, etc.).

* Impredicative universal and existential quantification (to enablegeneral polymorphic lock pointers, etc.).

* Equirecursive invariants (to describe list data structures, etc.).

* Semantic assertions embeddable in program syntax.

* Support for a stack pointer, and both local and global variables.

* Substructural accounting to model separating conjunction, using the sophisticated share models of Dockins et al. [DHA09].*

Byte addressability, along with a requirement that the four bytesof a word-sized lock must not get separated.

Thus, the model requires a significant superset of the featuresprovided by the models in $2.5 and $2.6. Hobor et al. developed the
first model that combined all these elements, but it was extremelycomplicated [HAZ08]; later Hobor presented a partially simplified
model, which took dozens of pages to explain [Hob08]. Indirectiontheory can define the model much more easily.

kind j VAL + LK + FUN + CT + RES
pred j (rmap * mem * locals * sp * gmap) ! T
preds j \Sigma (A : Type). list (A ! pred)
res j NO + YES of (kind * share * preds)
wf rm : (address ! res) ! T j

*. 8a, ss, P. (a) = YES(LK, ss, P ) ) `(a mod 4 = 0) ^
(a + 1) = (a + 2) = (a + 3) = YES(CT, ss, (unit, nil))'
rmap ss \Sigma ( : address ! res). wf rm()

For further explanation see Hobor et al. [HAZ08, Hob08]. Thefunction

wf rm enforces alignment for locks. The point is thatindirection theory handles this model just like previous examples:

rmap _ N * (\Sigma ( : address ! res). wf rm()).
2.8 Applications using indirection theory
In each of these applications, F is covariant (and the circular pseu-doequation on

K is contravariant). The point is that it is possibleto think of finding all the instances of

X "inside" the data structureand performing some operation on each of them. In $10 we discuss

extensions to indirection theory, including to bivariant functors.Most of the applications presented above have been previously
solved with a step-indexing model (either on paper or machine-checked). What is new here is the discovery of a uniform pattern
into which each of the above examples fit.We have used indirection theory to prove the type soundness
of the polymorphic *-calculus with references (from $2.1) in Coq.The proofs took approximately one week to develop.

As mentioned in $2.7, we also use indirection theory to mechan-ically prove the soundness of a concurrent separation logic with
first-class locks and threads for Concurrent C minor [Hob08].

3. Axiomatic characterization
Input. Suppose we are given a type O ("other data"), a type T("truth values") with distinguished inhabitant ?, and a covariant

functor F . That is, let Type stand for the types of the metalogic;then equip

F : Type ! Type with a function fmap : (A ! B) !
F (A) ! F (B) that satisfies the following two axioms:2

fmap idA = idF(A) (4)
fmap f ffi fmap g = fmap (f ffi g) (5)

The function fmap can be thought of as a generalization of mapfrom functional languages, which applies a function to all the elements in a list. Thus, fmap(g) should apply g to every X within an
F (X). For example, here is fmap for the case of general referencesin the

*-calculus from $2.1:

fmap j *g. *. g ffi 
Clearly equations (4) and (5) hold for this fmap. The definition of
fmap is normally straightforward when the structure of F is known.

Output. Indirection theory now provides provides the following:

K : Type (6)
pred j K * O ! T (7)
squash : (N * F (pred)) ! K (8)
unsquash : K ! (N * F (pred)) (9)

The definitions of K (also called knot), squash, and unsquash areabstract. A predicate (

pred) is a function in the metalogic from apair of a knot
K and other data O to truth values. As explainedpreviously,
squash and unsquash are coercion functions betweenthe "small" type knot (

K) and the "big" type N * F (pred).To coerce an object from the small type to the big one is lossless,

but to go from big to small requires approximation. Equations (10)and (11) define the approximation used in indirection theory:

level : K ! N j fst ffi unsquash (10)

approxn : pred ! pred j

*p. *(k, o). (p (k, o) level k < n? level k >= n. (11)

The key idea is that knots have levels. A knot with a higher levelis able to "store more information" than a knot with a lower level.
The way to determine the level of a knot is to unsquash it andthen take the first component (equation 10). The

approxn function(equation 11) does the actual approximation by "forgetting" how a

predicate behaves on knots with levels greater than or equal to n.When an approximated predicate is passed a knot of too high level
it just returns the default value ?; if the level is low enough thenthe underlying original predicate is used.

The behavior of squash and unsquash are specified by thefollowing two axioms, which constitute all of indirection theory:

squash (unsquash k) = k (12)
unsquash (squash(n, x)) = (n, fmap approxn x). (13)

Equation (12) guarantees that squash and unsquash form a section-retraction pair, and demonstrate that

unsquash is lossless. In con-trast,
squash is lossy; equation (13) precisely specifies where theinformation is lost. When an

F (pred) is squashed to level n, all ofthe predicates inside it are approximated to level

n.The simplicity of the axioms is a major strength of indirection

theory. The axioms are parametric over F (X), whereas previousmodels exposed numerous axioms specialized to their domains. For

2 Readers familiar with category theory will see the obvious inspiration;
others will find that they do not need category theory to follow this paper.

4

example, Hobor et al.'s model for higher-order CSL for ConcurrentC minor (outlined in $2.7) had more than fifty axioms, all of which
follow from equations (12) and (13) once F (X) is chosen. We viewthis pleasing fact as evidence that the axiomatization is right. In $9
we prove something stronger: the axiomatization is categorical.
Corollaries. There are easy corollaries to the axiomatization of
squash and unsquash. First, equation (12) directly implies that
unsquash is injective and that unsquash ffi squash is idempotent.(These two facts hold of any section-retraction pair.)

Second, any predicate (pred) "pulled out" of an unsquashedknot has already been approximated to the level of the knot:

unsquash k = (n, F ) ) F = fmap approxn F (14)
That is, whenever (n, F ) is the result of an unsquash then Fis unaffected by approximating it to level

n. All the information"above"
n has already been lost, so throwing it away again has noeffect. The proof is straightforward from equations (12) and (13).

Third, a predicate P approximated to level n and then approxi-mated again to level m is equal to

P approximated to min(n, m):

approxnffi approxm = approxmin(n,m) (15)
Proof: directly from the definition of approxn in equation (11).Fourth, if a knot of level

n is first unsquashed and thenre
squashed to a different level m, the predicates in the result havebeen approximated to level

min(m, n):

unsquash k = (n, F ) )
unsquash(squash (m, F )) = (m, F 0) )

F 0 = fmap approxmin(n,m) F (16)

Proof: follows directly from equations (14), (13), (5), and (15).
Implementation. In $8 we give a model to prove the soundnessof indirection theory. We have implemented the soundness proof

as a module in Coq matching the Input and Output signatures; asAppendix A shows, the axiomatization is remarkably concise. Both
signatures are matched opaquely, guaranteeing clean modularity.
Trustworthiness. In $2.8 we explained that both of the examplesfrom $2.1 and $2.7 have been established using machine-checked

indirection theory--i.e., using the interface given in Appendix A.Since the proofs are machine checked in Coq, we have a high
degree of confidence that they do not have mistakes.But perhaps the proofs, while correct, are proofs of the wrong
theorems! How do we know that the approximations we get withindirection theory are powerful enough to prove nontrivial properties? Could the axioms presented above admit a one-point model?We address this question in several parts by examining our type
soundness proof of the polymorphic *-calculus with references.First, we took great care that the definition of safety is entirely
standard: for any reachable state, the machine can take another stepor it has reached a value. That is, the definition of safety does not
refer to approximation or indirection theory. Since we define safetyin the standard way, at the end of the day we know that we have
proved something whose meaning is well-understood.Second, our typing rules (proved as lemmas from our typing
definitions, including those given in $4.1) are entirely standard. It issimple to use the typing rules to type a wide variety of expressions,
including expressions that manipulate the heap in interesting ways,run forever, and so forth. Thus we know that our semantic types are
powerful enough to use with meaningful programs.The combination of these two points mean that the axioms
preclude a one-point model: if our typing judgment were alwaystrue, then we would have a mechanical proof that the polymorphic
*-calculus with references never gets stuck, a contradiction; on theother hand, if our typing judgment were always false then we would

not be able to prove the standard typing rules of the calculus and/orwould be unable to apply our typing rules to any programs.

Finally, as mentioned earlier, in $8 we will present a construc-tion, which the reader can examine to determine if it is reasonable (for example, that it has more than one point). Since in $9 wepresent a proof that all models of the axioms are isomorphic, it is
quite reasonable to think about the axioms and the construction wepresent as two sides of the same coin.

Just as in the polymorphic *-calculus with references example,in the soundness proof for concurrent separation logic for Concurrent C minor (which uses indirection theory), the final result is es-tablished on a concurrent machine with reasonable semantics (although we assume sequential consistency) [Hob08, Ch. 5]; we alsoestablish a usable set of Hoare rules for proving partial correctness
of concurrent programs, and apply them to examples. The combina-tion guarantees that we have demonstrated something meaningful.

Indirection theory is a reformulation of previous step-indexedtechniques. Step-indexed models have also been extensively used
in mechanical type soundness proofs for general references in vonNeumann machines as covered in $2.2. In particular, the FPCC
project [AAR+09] used a step-indexed model to prove the safety ofthe output of the SPARC code emitted by a Standard ML compiler.

4. Using indirection theory
Indirection theory constructs models that support a number ofpowerful--but historically difficult to model--features. Many of

these features, such as impredicative quantification and equirecur-sive predicates, do not depend on the structure of

F (X); in $6 wewill give models for these kinds of features. Here we examine modeling features that do depend on the structure of F (X), focusingon two of the examples presented previously in $2. Applying these
ideas to other F (X) is usually not difficult.
4.1 General references in the *-Calculus
We return to the example of modeling a type system with generalreferences in the polymorphic

*-calculus from $2.1. Set

F (X) j address * X

O j value,

and indirection theory constructs the model

value j loc of address + num of N + . . .

type j (memtype * value) ! T
memtype _ N * (address * type).

Recall that X _ Y implies the existence of the squash/unsquashsection-retraction pair. Substituting

F (X) into equations (8) and(9) demonstrates that in this model
squash/unsquash have the types

squash : (N * (address * type)) ! memtype
unsquash : memtype ! (N * (address * type)).

Thus squash and unsquash provide easy access to the model.The semantics of the typing judgment

k ` v : o/, pronounced"in the context of memory typing
k, value v has type o/," is o/(k, v).It is simple to use this model to define both the basic

type nat aswell as the historically difficult to model
type ref o/. A value v hastype
nat if the value is a num(n) for some n:

nat j *(k, v). 9n. v = num(n). (17)
This is natural, and the definition of ref o/ is only slightly harder.The intuition is that a value

v has type ref o/ if the value is anaddress
a and according to the memory typing , the memory cellat location

a has type o/. That is,

ref o/

?j *(k, v). let (n, ) = unsquash k in

9a. v = loc(a) ^ (a) = o/. (18)

5

The only problem is that since (a) has been extracted from aknot

k of level n, by equation (14) we know that (a) has beenapproximated to level

n--that is,

(a) = approxn (a).
Comparing (a) to o/, which may not have been approximated, istoo strong. Instead we introduce the idea of approximate equality:

P =n Q j approxn P = approxn Q. (19)
That is, two predicates (type in this model) are approximately equalat level

n if they are equal on all knots of level less than n.With approximate equality it is easy to fix equation 18:

ref o/ j *(k, v). let (n, ) = unsquash k in9

a. v = loc(a) ^ (a) =n o/ (20)

This definition for ref o/ is correct and can type general referencesin the polymorphic

*-calculus.3 We will return to this example in$5.1 to show how a memory and a memory typing are related; we

also refer readers interested in more details to the mechanization.
4.2 Concurrent separation logic with first-class locks
Our second example is modeling the assertions of a ConcurrentSeparation Logic with first-class locks from $2.6. We set

F (X) j address*(VAL of value +LK of (share *bool *X))

O j locals,

and indirection theory constructs the model

res j VAL of value + LK of (share * bool * pred)
pred j (heap * locals) ! T
heap _ N * (address * res).

Recall that a share ss tracks how much of a lock is owned sincemultiple threads can each own part of the same lock. Here we will

define the assertions points-to "a 7! v" and is-a-lock "a ss P ".The points-to assertion is standard; is-a-lock has a share

ss thatindicates how much of the lock is controlled and a predicate

P thatis the lock's resource invariant. Both of these assertions depend

on the structure of F (X). In $7 we will show how to define theseparating conjunction and the rest of separation logic applicable
to any F(X) that forms a separation algebra.The intuition for points-to is that if

a points to v (a 7! v), thenthe heaplet
OE contains VAL(v) at location a and nothing else:

a 7! v j *(k, ae). let (n, OE) = unsquash k in

OE(a) = VAL(v) ^ domain(OE) = {a}. (21)

Defining the is-a-lock assertion is equally straightforward if oneuses the notion of approximate equality given in equation (19):

a ss P j *(k, ae). let (n, OE) = unsquash k in9

P 0, b. OE(a) = LK(ss, b, P 0) ^ domain(OE) = {a} ^ P =n P 0. (22)

That is, location a is a lock with share ss and resource invariant Pif the resource map

OE contains a LK(ss, b, P 0) for some boolean band predicate
P 0 at location a, OE is empty everywhere else, and Pis approximately equal to

P 0. We do not restrict b because is-a-lockgives permission to (attempt to) lock the lock, but not to read the

lock value. This definition is sufficient to model first-class locks.

5. Aging the knot
We return to the example of general references in the polymorphic
*-calculus from $2.1 and $4.1 to demonstrate some aspects ofusing indirection theory. All of the definitions we give here except

3 A reader may worry that it would be easy to write the incorrect definition
(18) by mistake. However, in $5.3 we will define a restricted class ofhereditary predicates (

types) which reject (18) but allow (20).

(23), (25)-(28), and (32) are parametric over F (X) and thereforeapplicable to any domain. It is usually not difficult to modify the
domain-specific definitions to other F (X).As in section 4.1, we outline the major aspects of using indirection theory, but do not cover the type soundness proof for the poly-morphic

*-calculus with references in exhaustive detail here. Weencourage readers interested in the nuts and bolts of a full soundness proof to examine the mechanization.
5.1 A multimodal logic
One remaining question is how a memory typing is related to amemory (function from

address ! value). The intuition is thatthe memory typing
k is a valid typing of the memory m (written
k ` m valid) if all the values in m have the type given by k:4

k ` m valid

?j let (n, ) = unsquash k in

8a. k ` m(a) : (a). (23)
Unfortunately, this definition is not quite right. The first problem isthat as the

*-calculus with references steps it allows new memorycells to be allocated, such as during the execution of the expression

new e. To type the new location, the memory typing must grow aswell. But how do we know that our old locations are still well-typed
under the new memory typing? There are several choices; here wefollow the "multimodal" pattern of Dockins et al. [DAH08].

A world w is a pair of knot k and other data o. Given a relation
R : world ! world, define the modal operator \Lambda R as usual:5

\Lambda R o/ j *w. 8w0. wRw0 ) o/(w0). (24)
We call this setting multimodal because we allow several differentrelations

R, depending on which part of the world we want toreason about. Our next task is thus to define a relation that will

let us reason about the extension of the memory typing.Define the relation

E (for Extends) as follows:

(k, o)E(k0, o) j let (n, ) = unsquash k in

let (n0, 0) = unsquash k0 in

n = n0 ^8

a. a 2 dom() ) 0(a) = (a).

(25)

That is, (k, o)E(k0, o0) if k has the same level as k and k0 agreeswith

k everywhere in the domain of k, and is otherwise unre-stricted; we also require

o = o0. Note that E is reflexive and transi-tive. Now define the modal operator """, pronounced "extendedly",

as follows: "

o/ j \Lambda E o/. (26)
Thus, k ` v : " o/ means that k0 ` v : o/ for any k0 that is anextension of

k. With this operator, we can change (23) into:

k ` m valid

?j let (n, ) = unsquash k in

8a. k ` m(a) : "(a). (27)
Since the issue of types being stable under the extension of thememory typing is orthogonal to the action of approximation, we

will not comment further on this issue and instead refer readersinterested in this aspect to the mechanization.

5.2 Applying an extracted predicate to its knot
There is a problem with (27) as well. Notice that " (a) is beingapplied to

k--the very same knot from which  was extracted.

4 Recall that the typing judgment k ` v : o/ is modeled as o/(k, v).
5 Until this point, we have not required any special structure for T other than
the existence of a distinguished element ?. To simplify the presentation,from now on we will assume that T

= Prop, the propositions of themetalogic, and that ? is the proposition False. One could choose some

other T, e.g. any complete Heyting algebra.

6

Corollary (14) implies (a) has been approximated to level n:

(a) = approxn (a)
Thus, in (27), k ` m(a) : "(a) is always k ` m(a) : "?, whichin turn is just

k ` m(a) : ?. This is exactly where we weaken thepseudomodels to achieve a sound definition: predicates cannot say

anything meaningful about the knot whence they came. We mustweaken (27) so that

k is valid if the types in it describe the memoryafter
k has been approximated further:

k ` m valid j let (n, ) = unsquash k in8

a, n0. n > n0 ) squash (n0, ) ` m(a) : "(a) (28)

By equation (16), squash (n0, ) is the same as k except thepredicates inside it have been further approximated to level

n0.We call the process of unsquashing a knot and then resquashing

it to a lower level, causing it to become more approximate, agingthe knot. Since we must do so whenever we wish to use a predicate
that we pull out of a knot, we have developed some useful auxiliarydefinitions. The

age1 function reduces the level of a knot by firstunsquashing and then resquashing at one level lower, if possible:

age1 k j(Some (squash (n, x)) unsquash k = (n+1, x)None unsquash k = (0, x). (29)
The relation A relates k to its aged version and holds o constant:

(k, o) A (k0, o) j age1 k = Some k0. (30)
Note that A is noetherian (i.e., the world can only be aged a finitenumber of times) because the level of

k0 is always decreasingtowards
0. Let A+ denote the irreflexive transitive closure of A.6Now define an operator "

." from predicate to predicate:

.o/ j \Lambda A+ o/. (31)
Pronounced "approximately P ", .P (w) means that P holds on allstrictly more approximate worlds reachable from

w via A+.We can use the
. operator to rephrase equation (28):

k ` m valid j let (n, ) = unsquash k in8

a. k ` m(a) : . "(a). (32)

Equation (32) is pleasing because it is quite close in form to theintuitive but flawed (27), with the added benefit of being correct.7

The key to defining the correct (32) instead of the flawed (27) is toremember a simple rule: to apply a predicate

P to the knot fromwhich it was extracted, one must guard
P with the . operator.

5.3 Hereditary predicates
Let A* denote the reflexive, transitive closure of A, and define themodal operator "\Lambda " as follows:

\Lambda o/ j \Lambda A* o/.
Let P be a predicate and w be a world such that P (w). Supposewe have a (possibly) more approximate world

w0 (i.e., wA*w0).We say that
P is hereditary if P (w0)--that is, once P holds on wthen it will hold on all further approximations of

w:8

w. P (w) ) \Lambda P (w). (33)
Now observe that since A* is reflexive, we always have8

w. \Lambda P (w) ) P (w).

6 Here we follow the strategy of Appel et al. [AMRV07]; what is new is that
we have explicitly built A+ from the operations of indirection theory.
7 The """ and "." operators commute, so the last line of (32) could just as

easily have been written 8a. k ` m(a) : " .(a). For comparison withAppel et al. [AMRV07], their "

." is the same as our ".""; we have found iteasier to reason about these actions separately [DAH08].

Thus we can rephrase (33) very concisely--P is hereditary iff

P = \Lambda P. (34)
Are all predicates hereditary? Unfortunately not: for example,the flawed initial definition for

ref o/ (18) is not. However, it iseasy to define new hereditary predicates using the logical operators

defined in $6. Moreover, the correct definitions for references (20),points-to (21) and is-a-lock (22) are all hereditary. In addition,
applying the . operator makes a predicate hereditary since

.P = \Lambda  . P. (35)
Thus, types pulled out of a valid memory typing (32) are hereditary.

5.4 Finite-step proofs and initial knot construction
In soundness proofs that utilize indirection theory, we usually havesome knot

k, for example modeling the memory typing or a re-source map. One must age this knot whenever the proof needs to

pull a pred P out of k, since the application P (k, o) will alwaysbe ?. For our polymorphic

*-calculus with mutable references, weneed to age at least on memory access, although in the proofs we

choose to age on every step to make the action uniform. For ourConcurrent Separation Logic with first class locks and threads, we
age at function-call, lock-acquire/release, and fork.Since our knots have only a finite level, we can age only a
finite number of times. Therefore, once we have our initial knot,our safety proof is only good for a number of steps equal to the
level of that initial knot. Fortunately, constructing an initial knotof arbitrary level is easy. For example, let us construct a knot (i.e.,
memory typing) of level n for the *-calculus with references.To make it more interesting, suppose the initial memory typing
should have "nat" (equation 17) at location 0 and "ref nat" (equa-tion 20) at location 1. If

 is this partial function, then kinit is:

kinit j squash(n, ).
One strength of indirection theory is that the construction of theinitial knot is much simpler than in previous step-indexed models.

Our proofs are good for any number of steps since it is possible toconstruct an initial knot of any level.

6. Modal/intuitionistic logic
We can use the theory of indirection to construct a possible-worldsmodel of a modal logic in the style of Appel et al.'s "Very Modal

Model" (VMM) [AMRV07]. In fact, we do better: the VMM isalmost a Kripke semantics of intuitionistic logic, but lacks the
important condition that all the proposition symbols are hereditary.To fix this problem, we construct the Kripke model for (propositional) intuitionistic logic, explicitly maintaining the invariant thatpredicates are hereditary. Let

predH be the subset of the predicatesthat are hereditary. We build a Kripke semantics for our logic in the

standard way, with W = K*O, and forcing |=: (W*predH) ! Tis just reversed function application. Then we have:

w |= true j ?
w |= false j ?
w |= p ^ q j w |= p ^ w |= q
w |= p . q j w |= p . w |= q
w |= p ) q j 8w0. wA*w0 ) (w0 |= p) ) (w0 |= q)
w |= 8x : A. P (x) j 8x : A. w |= P (x)
w |= 9x : A. P (x) j 9x : A. w |= P (x),

where the left-hand ^, ., ), 8, 9 are the synthesized operators ofour logic, and the right-hand ^

, ., ), 8, 9 are operators of themetalogic. It is straightforward to verify that these definitions are

hereditary. Note that we directly lift 8 and 9 from the metalogic,

7

which extends the logic into a higher-order logic. The metavariable
A is any type of the metalogic (e.g., A:Type in Coq), so thequantification is fully impredicative:

A = predH works just fine.These definitions form the standard Kripke model of intuitionistic logic, to which we add the modal operators . and \Lambda . In com-parison to the VMM, the \Lambda  operator is now less important, as all
of our logical operators produce hereditary formulae from heredi-tary subformulae; in contrast, the VMM's implication operator did
not do so. However \Lambda  is still useful for coercing an arbitrary pred(which might not be hereditary) into a

predH.We define recursive predicates over contractive operators in the

style of the VMM [AMRV07]. We support full equirecursion andso do not require dummy operational steps to pack and unpack
recursive data. This gives us the power to reason about traditionallydifficult low-level constructs such as compiled function closures.

7. Separation logic
Indirection theory, like previous models of impredicative indirec-tion, is used to reason about higher-order invariants on the contents of state, e.g., mutable references, locks, objects, or functionpointers. On the other hand, Separation Logic is useful for reasoning about the aliasing and noninterference of these resources. Onewants to use both kinds of reasoning simultaneously. Separation
Logic combines much more smoothly with indirection theory thanwith previous models.

We proceed by extending the Kripke semantics of $6 to encom-pass the the connectives of the logic of Bunched Implications (BI).
Our Kripke semantics is similar but not identical to those of Pym[Pym02, Chapter 4] and Restall [Res00, Chapter 11].

We take inspiration from Calcagno et al. [COY07], who definestructures they call separation algebras (SA), which they use as semantic models of separation logic. The main idea is that SAs definea partial operation \Phi  which combines two "disjoint" resources. The
operation \Phi  is used to give semantics to the separating conjunction.A separation algebra (SA) is a tuple h

A, \Phi i where A is a set (or
Type) and \Phi  = is a ternary relation on A satisfying:

x \Phi  y = z1 ) x \Phi  y = z2 ) z1 = z2 (36)

x1 \Phi  y = z ) x2 \Phi  y = z ) x1 = x2 (37)

x \Phi  y = z ) y \Phi  x = z (38)
x \Phi  y = a ) a \Phi  z = b )9

c. y \Phi  z = c ^ x \Phi  c = b (39)

8x. 9u. u \Phi  x = x (40)
a \Phi  a = b ) a = b (41)
This definition of separation algebras is somewhat different fromCalcagno et al.'s. First, our definition uses ternary relations rather

than partial binary operations. Second, Calcagno et al. present amore restrictive version of axiom (40): 9

u. 8x. u \Phi  x = x. Theiraxiom requires that an SA have a unique unit, while axiom (40)

allows different elements of an SA to have different units. Thispermits knots to be considered as SAs; each stratification level will
have its own unit. Third, Calcagno et al. lack axiom (41); this axiomis useful and well-justified, but is unrelated to indirection theory.
We refer the reader to our paper on separation algebras for furtherdiscussion of the advantages of our definition [DHA09].

A bunched-implication indirection model. In $3, we presentedan input signature for indirection theory; one of the elements of
this signature is a covariant functor F (X) in the category of typeswith total functions. Here we instead require that

F be a functorin the category of separation algebras with join homomorphisms

(defined below). This means that F is function between SAs and

its associated fmap function preserves the property of being a joinhomomorphism. If

f is a join homomorphism, then so is fmapf.

Let hA,

A\Phi i and hB, B\Phi i be SAs. We say that a function f : A !

B is a join homomorphism iff, for all x, y, z 2 A

x

A\Phi  y = z ) f(x) B\Phi  f(y) = f(z). (42)

We equip the naturals N with the trivial join relation, i N\Phi  j = kiff
i = j = k. We require that T be equipped with some join

relation, and that ? be an identity for that relation: ? T\Phi  ? = ?.We also require that the type

O of "other data" be equipped witha join relation; if there is no "interesting" separation to be done on

O, then the trivial join relation will suffice.Now we build an SA on "unsquashed" knots. We start by building the SA over K*O ! T by defining the join relation pointwise:

p \Phi  q = r iff 8k o. p (k, o) T\Phi  q (k, o) = r (k, o). (43)
Note that we do not need an SA over K for this definition. Next,we get an SA on

F (K * O ! T) because we required F to be afunctor over SAs. Finally, we get an SA over N *

F (K * O ! T)by joining componentwise (with the trivial SA on N). Verifying the

SA axioms for these constructions is straightforward [DHA09].The SA on knots is defined by simply stating:

k1\Phi k2 = k3 , unsquash k1\Phi unsquash k2 = unsquash k3. (44)

The SA axioms for this construction follow from the fact that
squash ffi unsquash is the identity function (one of the axioms ofindirection theory) and the fact that

unsquash ffi squash is a joinhomomorphism. This follows because

F preserves join homomor-phisms and because
approxn is a join homomorphism, which wededuce from its definition and the fact that ? is an identity element.

Thus we see that the separation algebra on knots is determinedby the SA structure embedded in the functor

F , which allows theuser to specify the interesting part of the SA as input.

An example. Consider the model for first-class locks from $2.6:

F (X) j address*(VAL of value +LK of (share *bool *X))

O j locals.

Given an SA over X, we want to define an SA over F (X). Theintuition here is that we want the partial functions to join pointwise

such that undefined locations join with any defined location, valuelocations join only with undefined locations, and lock locations join
provided that at most one thread holds the lock at a time.Formally, we add an extra (pseudo)element

u to the right-handside of
* to represent unowned locations. Assume we have a joinrelation on shares (see [DHA09]). Define an SA on booleans:

b1

B\Phi  b

2 = b3 iff (b1 && b2 = F) ^ (b1 || b2 = b3).

The join relation of the RHS is the smallest relation such that:

u \Phi  a = a (a)

a \Phi  u = a (b)
s1

S\Phi  s

2 = s3 ) b1

B\Phi  b

2 = b3 ) x1

X\Phi  x

2 = x3)

LK (s1, b1, x1) \Phi  LK (s2, b2, x2) = LK (s3, b3, x3).(c)
In equation (c), the si are required to be nonunit shares.Finally we define the SA over heaplets pointwise on the address:

f \Phi  g = h iff 8`. f(`) \Phi  g(`) = h(`)
This model gives rise to an SA where heaplets must have dis-joint value domains, but where separated heaplets may each have

some share of a lock. The SA over shares keeps track of lock visibil-ity (the ability to compete to acquire the lock) whereas the boolean
value keeps track of whether this thread holds the lock.

8

When defining an SA over O (the local variables), we can eitherchoose to use a trivial SA, or we can choose to define a similar
pointwise SA. The second choice leads to a "variables as resources"[PBC06] style of separation logic, whereas the former choice leads
to a presentation where local variables are not separated.SAs for other models can be built by using various combinations
of products, coproducts, and functions, etc. See Dockins et al. forexamples and explicit constructions of share models [DHA09].

Operators of separation logic. Using the separation algebra overknots we are almost ready to state the Kripke semantics for BI. The
Kripke semantics is defined over pairs K * O, so we lift the SAover

K to pairs, componentwise.

w |= emp j w \Phi  w = w
w |= p * q j 9w1 w2. w1 \Phi  w2 = w ^ w1 |= p ^ w2 |= q
w |= p --* q j 8w0 w1 w2. w A*w0 )

w0 \Phi  w1 = w2 ) w1 |= p ) w2 |= q
In order for these definitions to be valid, we must show that theyare hereditary. The fact that --* is hereditary follows immediately

from the definition. In order to show that emp and * are hereditary,we require the following technical facts about knots:

8k1 k2 k3 k01. k1 \Phi  k2 = k3 ) k1Ak01 )9

k02 k03. k01 \Phi  k02 = k03 ^ k2Ak02 ^ k3Ak03 (45)

8k1 k2 k3 k03. k1 \Phi  k2 = k3 ) k3Ak03 )9

k01 k02. k01 \Phi  k02 = k03 ^ k1Ak01 ^ k2Ak02 (46)
These facts follow easily from the definition of the SA overknots, the definition of

A, and the fact that approxn is a join homo-morphism. Hereditarity for

emp and * then follows by induction onthe transitivity of
A*, using (45) and (46) in the base cases.It is relatively easy to show that these definitions, together with

the definitions from $6, form a model of the logic of BunchedImplications. This is most easily done by proving that the model
satisfies the axioms of a Hilbert system of BI [Pym02, Table 3.1].
8. Model construction
Here we construct a model for the axioms in $3. Indirection theoryis built in the Calculus of Inductive Constructions (CiC) with the

axiom of functional extensionality.8 Our model uses a step-indexingtechnique originally developed by Ahmed et al. [AAV03], but we
have made many improvements and simplifications.Indirection theory is so compact that the definition, construction, and soundness proofs require only 400 lines to implementin Coq. The construction is parameterized over

F (X), making itdirectly applicable to all of the examples given in $2. Moreover,

the construction is more powerful than previous models; for exam-ple, as explained in $2.6, indirection theory supports full inversion
while the previous models of Hobor et al. do not [HAZ08, Hob08].
Use of dependent types. The proofs are tricky to mechanize dueto the dependent types in the indexed-model construction. There are

no dependent types in the axiomatization, so users of indirectiontheory are not burdened with them. This means that indirection
theory can be used (although not, we conjecture, proved sound)in metalogics without dependent types, such as the simple theory
of types (HOL). This is a significant strength of our approach.
Presentation. We elide the handling of the "other" data O whichappears in the axiomatization. Adding it presents no fundamental

difficulties, but it clutters the explanation.
8 We have also developed an axiom-free version by working in the category
of setoids (whose objects are types equipped with an equivalence relationand whose morphisms are equivalence-preserving functions). The proofs

are not much more difficult to carry out, just more difficult to state.

8.1 Tying the knot.
We wish to define a type K that is similar to the pseudodefinition inequation (2), reproduced here (without

O):

K ss F (K ! T).
We proceed by defining an approximation to pred called predn, afinitely stratified type constructor indexed by the natural

n:

predn j (unit n = 0pred

n0 * (F (predn0) ! T) n = n0 + 1. (47)

For all n > 0, P : predn is a pair whose second component P.2 isan approximation to the recursive pseudodefinition (2) and whose

first component P.1 is a simpler approximation P 0 : predn-1.A knot (

K) hides the index with a dependent sum:

K j \Sigma (n : N). F (predn). (48)
That is, a knot is a dependent pair of a natural n and an F withelements of

predn inside. Define the level of a knot k as:|

k| = k.1 that is, |(n, f)| = n. (49)
A knot's level gives how many layers of stratification it contains.Now we can define the type of predicates (

pred):

pred = K ! T. (50)
A pred is an "infinitely stratified" predn that can judge a knotcontaining any amount of stratification.

8.2 Stratification and unstratification.
We define a function stratn : pred ! predn that collapses aninfinitely stratified

pred into a finitely stratified predn:

stratn(P ) = (() n = 0`strat

n0(P ), *f. P (n0, f)' n = n0 + 1.(51)

The stratn function constructs the list structure of predn by recur-sively applying

P to knots of decreasing level. The finitely stratifiedtype
predn is not big enough to store the behavior of P on knots oflevel >=

n, and so that information is thrown away.The
stratn function is a standard feature in step-indexing con-structions [AAV03, AMRV07, Hob08]. A key innovation in our

new construction is the definition of a partial inverse to stratn.9First we define a "floor" operator that given a

P : predn+m con-structs a
P 0 : predn by stripping off the outer m approximations:

bP cmn j (P m = 0bP.1cm0

n m = m0 + 1. (52)

Now observe that for any a, b 2 N,

b > a , 9m. b = a + m + 1. (53)
We now define unstratn : predn ! pred, which takes a finitelystratified

predn and constructs an infinitely stratified pred from it.We use (53) to take cases and apply (52) in a constructive way:

unstratn(P ) = *k. ((bP c

m|k|+1.2) k.2 n = |k|+m+1

? n <= |k|. (54)
When given a knot of level < n, the unstratn function uses thefloor operator to "look up" how to behave. When applied to a knot

k of level >= n, the unstratn function returns ? since the predn Pdoes not contain any way to judge

k.

9 Although the supporting proofs for VMM [AMRV07] contained a similar
inverse, it was not explained in the paper and played only a supporting role.Here we show that

unstrat is actually of central importance.

9

Below we will need the following two technical facts. First, thefloor operation commutes with taking the first projection:

bP cmn+1.1 = bP.1cmn (55)
Proof of (55). By induction on m.
Due to the dependent types, the statement of this lemma and itsproof are somewhat more complicated in the Coq development;
nonetheless, the overall proof idea is straightforward.The second technical lemma specifies what happens when two
similar finitely stratified predicates are restratified at a lower level.b

P1cm1n = bP2cm2n )

(stratnffi unstratn+m1) P1 = (stratnffi unstratn+m2) P2 (56)

If P1 : predn+m1 and P2 : predn+m2 are two finitely stratifiedpredicates that are equal in their first

n layers, then they are equalafter they have gone through
unstratn+j followed by stratn.

Proof of (56). By induction on n. The base case is easy; the induc-tive case follows by the induction hypothesis and (

55).

8.3 Composing stratn and unstratn.
What happens when we compose stratn and unstratn? We takethis in two parts. First we wish to show:

stratnffi unstratn = idpredn (57)
where idff is the identity function on type ff (i.e., idff j *x : ff. x).

Proof of (57). By induction on n. In the base case, the claim fol-lows because

strat0f = () for all f and the unit type has a uniquevalue. In the inductive case, where

n = n0 + 1, after unfolding
stratn0+1 we must show (for arbitrary P and f):

stratn0(unstratn0+1 P ) = P.1 and

unstratn0+1(P ) (n0, f) = P.2 f.

To demonstrate the first equation, first observeb

P c1n0 = bP.1c0n0
so we may rewrite using (56) into stratn0(unstratn0(P.1)) andapply the induction hypothesis. In the second equation, note that

n0 + 1 = |(n0, f)| + 0 + 1,
which means that

unstratn0+1(P )(n0, f) = (bP c0n0+1.2) ((n0, f).2) = P.2 f.
This completes the first part.

For unstratnffi stratn, we cannot do as well since stratn "for-gets" information that

unstratn cannot recover. Give T a flat partialorder by defining v as the minimal relation such that:

x v x reflexivity (58)? v

x pointedness (59)

It is clear that v is antisymmetric. With v we can state three cases:

(unstratnffi stratn) P k v P k 8 |k| (60)

P k v (unstratnffi stratn) P k |k| < n (61)
(unstratnffi stratn) P k v ? |k| >= n (62)

Proof of (60). By induction on n. In the base case n = 0 and
unstrat0(P ) = ? for all P ; the claim follows from (59). In theinductive case

n = n0 + 1. Consider the two subcases of thedefinition of
unstrat. When n <= |k|, unstratn(P ) = ? for all P ,and we are done, again by (59). In the case where

n = |k|+ m +1,

we proceed by subcases on the value of m. If m = 0, then observethat

n0 = |k|, and we have:

unstratn0+1(stratn0+1 P ) k

= (bstratn0+1 P c0|k|+1.2 (k.2)
= (stratn0+1 P ).2 (k.2)
= P (n0, k.2) = P (|k|, k.2) = P k.

Then the claim follows by (58). In the case that m = m0 + 1, then:

unstratn0+1(stratn0+1 P ) k

= (bstratn0+1 P cm0+1|k|+1 .2) (k.2)

= (b(stratn0+1 P ).1cm0|k|+1.2) (k.2)
= (bstratn0 P cm0|k|+1.2) (k.2)
= (unstratn0(stratn0(P )) k

The final line follows n0 = |k| + m0 + 1, which allows us to fold
unstratn0. Now we apply the induction hypothesis.

Proof of (61). By induction on n. In the base case n = 0, and|

k| < 0 yields a contradiction. In the inductive case, we have
n = n0 + 1. Since |k| < n, we must have n = |k| + m + 1for some

m. As before, we inspect the value of m. if m = 0, theclaim follows by (58) and calculation identical to the preceding. If

m = m0+1 then we again perform similar calculation as above andapply the induction hypothesis. We must only verify that |

k| < n0,which follows because
n0 = |k| + m0 + 1.

Proof of (62). Immediate from the definition of unstrat.
Since v is pointed and antisymmetric, (60), (61), and (62) imply:

(unstratnffi stratn) P k = (P k |k| < n? |k| >= n. (63)

8.4 Squashing and unsquashing.
Define squash and unsquash to fmap stratn and unstratn:

squash(n, f) j (n, fmap stratn f) (64)

unsquash(k) j (|k|, fmap unstrat|k| k.2). (65)

Recall from $3 the definitions of level and approxn (without O):

level j fst ffi unsquash (66)

approxn P k j (P k level k < n? level k >= n. (67)
It follows immediately from (64) and (66) that level k = |k|.Applying this equality to (63) and (67) shows:

approxn = unstratn ffi stratn. (68)
We now prove the two axioms of indirection theory. Proof of (12):

squash (unsquash k)

= squash (|k|, fmap unstrat|k| k.2) (65)
= (|k|, fmap strat|k| (fmap unstrat|k| k.2)) (64)
= (|k|, fmap (strat|k| ffi unstrat|k|) k.2)) (5)
= (|k|, fmap idpred|k| k.2) (57)
= (|k|, idF(pred|k|) k.2) (4)
= k (49)

10

The second axiom (13) follows in a similar way:

unsquash (squash (n, f))

= unsquash (n, fmap stratn f) (64)
= (n, fmap unstratn (fmap stratn f)) (65)
= (n, fmap (unstratn ffi stratn) f)) (5)
= (n, fmap approxn f) (68)

This completes the construction.

9. Uniqueness of the model
One remarkable property of the axiomatization given in $3 is thatit is categorical: the axioms determine the model uniquely up to

isomorphism. We prove this by constructing a bijection betweenany two models and prove that the bijection preserves the

squashand
unsquash operations. For simplicity, we will elide the type O.

Input. We assume that we have a single input (F , fmap). We thentake two (possibly different) constructions

A and B. To distinguishthe functions and properties defined on one construction from the

other, we will write, e.g., squashA or squashB.
Informal goal and core proof idea. Our goal is to construct anisomorphism

f : KA ! KB. At first this seems quite easy:

f

?j squash

B ffi unsquashA. (69)

That is, take a kA : KA, unsquash it to get to a common form (oftype N *

F (pred)), and then squash it into an element of type KB.Unfortunately, this approach does not work since

unsquashA pro-duces an element of type N *
F (predA), while squashB requiresan element of type N *
F (predB). We cannot assume that predAis compatible with
predB without begging the question, so (69) isinvalid. Part of what makes the problem tricky is that the types are

isomorphic but need not be equal, so we must build up significantmachinery to coerce the types from one construction to the other.

Formal goal. We want a pair of functions f : KA ! KB and
g : KB ! KA. These functions will be inverses:

f ffi g = idKB (70)

g ffi f = idKA. (71)
Thus, f and g are bijective. To be isomorphisms they must alsobe homomorphisms (preserve

squash and unsquash); for this weintroduce two derived functions,

\Phi  : F (predA) ! F (predB):

\Phi  j fmap (*PB. PB ffi g), (72)
and \Gamma  : F (predB) ! F (predA):

\Gamma  j fmap (*PA. PA ffi f). (73)
Since f and g are inverses, and fmap distributes over functioncomposition (equation 5),

\Phi  and \Gamma  are inverses as well:

\Phi  ffi \Gamma  = idF(predB) (74)

\Gamma  ffi \Phi  = idF(predA). (75)
We can now state that f and g are homomorphisms as follows:

f(squashA(n, A)) = squashB(n, \Phi (A)) (76)

g(squashB(n, B)) = squashA(n, \Gamma (B)) (77)

unsquashB(f(kA)) = (n, \Phi (A))

where (n, A) = unsquashA(kA) (78)

unsquashA(g(kB)) = (n, \Gamma (B))

where (n, B) = unsquashB(kB). (79)

This will complete the proof that A and B are isomorphic.

Proof sketch. The formal details of the proof are quite technical;here we give an informal outline. We have implemented our proof
in Coq and refer readers seeking more detail to the mechanization.We construct

f and g from a sequence of approximations(
f0, g0),. . . ,(fm, gm),. . . . A pair of functions (fi, gi) are inversesand homomorphisms on knots of level <=

i.First we construct
f0 and g0. By equation (14), all of the pred-icates inside knots of level

0 are approximated to level 0--that is,they are all constant functions returning ?. We write ?

ff to meanthe constant function from type ff to ? (i.e., ?
ff j *a : ff. ?). Thefunctions
f0 and g0 simply swap ?KA with ?KB and vice versa:10

f0(kA) j let (n, A) = unsquashA kA in

squashB(n, [PA ) ?KB ] A) (80)
g0(kB) j let (n, B) = unsquashB kB in

squashA(n, [PB ) ?KA] B). (81)

Lemma. (f0, g0) is an isomorphism pair on knots of level 0.Next, given

(fi, gi) we wish to construct the next pair in theseries
(fi+1, gi+1). The trick is that due to the contravariance of
pred, fi+1 is built from gi, and gi+1 is built from fi:

^f(fl)(kA) j let (n, A) = unsquashA kA in

squashB(n, [PA ) PA ffi fl] A) (82)
^g(OE)(kB) j let (n, B) = unsquashB kB in

squashA(n, [PB ) PB ffi OE] B). (83)

Lemma. If (f, g) is isomorphism pair for knots of level <= i, then
( ^f(g), ^g(f)) is an isomorphism pair for knots of level <= i + 1.Now define the function

h that takes n and produces (fn, gn):

h(n) j ((f0, g0) n = 0let (f0, g0) = h(n0) in ( ^f(g0), ^g(f0)) n = n0+1.(84)
The h function works by bouncing back and forth; note that even-numbered

fi have f0 as their base while odd-numbered fi have g0.The
gi are mirrored: even gi use g0 for a base while odd gi use f0.Now we are ready to define

f and g. The idea is that we willlook at the knot
k that we have been given and use the h functionto construct an
fi or gi of the appropriate level:

f(kA) j `(fst ffi h ffi levelA)(kA)'(kA) (85)

g(kB) j `(snd ffi h ffi levelB)(kB)'(kB). (86)
Theorem. (f,g) is an isomorphic pair for knots of any level.
Implications. Categorical axiomatizations are sufficiently un-common that we examine the implications. Most importantly, the

axioms of indirection theory given in $3 are in some sense com-plete: they define a particular class of models in a definitive way.
Moreover, there seems to be little point in developing alternativesto the construction we presented in $8, at least in CiC. We view
these facts as powerful evidence that our axioms are the correctway to characterize current step-indexing models.

10. Extensions of indirection theory
Although many problem domains of interest fall into the simpleform of pseudoequation (2), some problem domains require predicates to appear in negative positions (the left side of arrows). Forexample, the recent result of Ahmed et al., which applies stepindexing to reason about data abstraction [ADR09], requires suchflexibility. We have defined, on paper and in Coq, a straightforward

10 Keeping with our informal style, we will abuse notation by writing
[Pff ) X]  to mean the substitution of the predicates predff in  with
X. Formally this is written fmap (*Pff. X) . Note Pff can appear in X.

11

extension to indirection theory that handles bifunctors, which allowequations containing mixed variance.

In our axiomatization of indirection theory, nonhereditary pred-icates can pop out of the unsquash function. If we make sure to
place \Lambda  in front of any predicate taken from a knot, we avoid thisproblem; but it is not clear that this approach extends to the bifunctor case. Instead, we can do something even more powerful: wehave an alternate axiomatization that guarantees that all predicates
in knots are hereditary. We have a model proved in Coq (and on pa-per), but unfortunately it is not as straightforward to construct. We
hypothesize that this model could be used to mechanize the recentresult of Dreyer et al. [DNRB10].

11. Limitations of indirection theory
Indirection theory is a powerful technique for those problems towhich it applies, but it is worthwhile to examine some limitations.

First, indirection theory only builds solutions for the particularclass of recursive domain equations given by pseudoequation (2).
Although, as seen in $2, the form of this pseudoequation wascarefully chosen to cover many problem domains of interest, it is
manifestly not applicable to equations of other forms (although in$10 we cover some possible extensions).

Second, our insistence on remaining in the simple category ofsets (or types) means that any solution we build must necessarily
involve approximation; as we previously noted, a simple cardinalityargument shows that we cannot obtain isomorphism solutions. We
have found this cost to be quite manageable, especially when man-aged using the framework of the Very Modal Model [AMRV07].

Finally, step-indexing techniques have thus far been appliedonly to questions of safety, partial correctness, and program equivalence. It is unclear how, or if, step indexing approaches can beapplied to questions of liveness and total correctness.

12. Related work
Syntactic methods. There is a long history of using syntacticmethods to handle indirection. Early papers on Hoare logic used

syntactic representations of program text to reason about functioncalls [CO78]. Syntactic accounts of general references have been
studied by Harper [Har94], Harper and Stone [HS97], Wright andFelleisen [WF94], and others. Crary developed TALT, a typed assembly language which had indirection due to both data referencesand code pointers [Cra03].

Defining Hoare-style logics using syntactic methods is a com-mon choice [Sch97, Ohe01, Sch06]. However, even when the
Hoare derivations are syntactic, it is nearly ubiquitous in mechan-ically verified proofs for the assertion language to be purely semantic; that is, assertions are identified with predicates on programstates (perhaps together with other auxiliary data) [Nip02]. In these
applications, indirection helps solve problems of indirect reference,especially if one wishes to embed semantic assertions (or types)
into program syntax or operational semantics.One could instead use a fully syntactic approach, where assertions are also treated as syntax. Using syntactic assertions removesthe need to solve tricky contravariant domain equations. Instead,
one is left with the problem of adequately representing the syntaxand semantics of the assertion logic, a nontrivial problem in its own
right. A logic supporting higher-order quantification is especiallytroublesome to handle in most mechanized proof systems.

Domain theory. Domain theory is an alternate approach to cre-ating semantic models of programming languages [GHK

+03]. Domain theory is primarily concerned with solving recursive domainequations that describe the desired form of the model. Using domain theory, one can construct actual isomorphism solutions toequations such as pseudoequation (2). Indeed, one can construct

models using domain theory for applications where indirection the-ory does not appear well suited (e.g. denotational models of the
untyped *-calculus). The price one pays is that the solution is con-structed in some category of domains rather than in simple sets.

Working in higher categories is especially inconvenient inmechanized higher-order logics. Simply building up the required
theory takes quite a bit of effort. Many attempts have been made tomechanize domain theory [Mil72, MNOS99, Age06], including a
recent effort in Coq by Benton et al. [BKV09]. However, all thesesystems seem to stop short of developing a full suite of domain
theory. For example, we are aware of no mechanization which de-velops as far as the theory of algebraic bounded-complete partial
orders (i.e. Scott domains). Benton et al. have developed one ofonly very few mechanizations that includes an inverse-limit construction, allowing the solution of recursive domain equations. Fur-thermore, once the required base theory is developed, the tedium
of verifying the properties of structured morphisms (e.g, mono-tonicity, continuity, etc.) can still be a major hurdle. Much of the
development effort in HOLCF [MNOS99] was devoted to allevi-ating this pain, and Benton et al. claim that "dealing with all the
structural morphisms is still awkward" in their system [BKV09].
Ultrametric Spaces. Birkedal et al. solve recursive domain equa-tions using certain classes of ultrametric spaces [BST09]. Their approach is similar in spirit to domain theory, where semantic do-mains are built in some higher category, but uses a foundation built
on metric spaces rather than partially ordered sets. Given a suffi-cient basis of analysis and category theory, the metric space setup
seems to afford a nice simplification of similar domain-theoreticresults. To our knowledge, no attempt has yet been made to mechanize this metric space approach.
BI Hyperdoctrines. BI hyperdoctrines are category-theoreticmodels of higher-order bunched implications [BBTS07]. BI hyperdoctrines provide: higher-order logic, the standard BI connec-tives, recursive definitions, and impredicative quantification. But
the published BI-hyperdoctrine model does not appear to supportindirection, i.e. the kinds of settings in $2. The techniques used for
domain-theoretic models of indirection (e.g. Day's construction infunctor categories [Lev02]) could perhaps be applied to BI hyperdoctrines. Like the domain-theoretic methods, methods based onadvanced category theory require a great deal of background in the
field to understand and utilize. Mechanizing models based on BIhyperdoctrines would require considerable effort to build up the
necessary base theory.
Very Modal Model. Appel et al.'s "Very Modal Model" (VMM)provides a way to simplify the handling of step-indexing models by

building a modal logic for reasoning about the indexes [AMRV07].In our current paper we also simplify the application of stepindexed models, so the techniques are superficially similar. How-ever, although indirection theory was designed to dovetail with the
VMM, they are in fact orthogonal and either system can be usedwithout the other. After Appel et al., both Benton and Tabareau
[BT09] and Ahmed et al. [ADR09] constructed modal modelswithout indirection theory. Indeed, it is possible and useful to build
a modal logic even when the setting does not have the contravariantcircularities that motivate the current work [BT09, DAB09]. Moreover, although we build a modal logic on top of indirection theoryin $6, one can easily work directly with the axioms.

In addition, the logic constructed in $6 is superior to the onefrom Appel et al. because it properly recognizes and handles the
heredity condition. The na"ive interpretation of implication foundthere does not preserve heredity. This leads to less elegant reasoning because the operator \Lambda  must be inserted in nonobvious places.Neither do Appel et al. show how to incorporate the substructural
elements required for separation logic, which we do here.

12

Finally, the VMM suffers from the same flaw as other step-indexing models: the construction is hardcoded to a particular domain and is difficult to adapt to other settings. Indirection theory issimpler, more powerful, and applies to a wide variety of domains.

Concurrent separation logic. Both Hobor et al. [HAZ08] andGotsman et al. [GBC

+07] developed formulations of a Concurrent

Separation Logic with first-class locks and threads. Both presen-tations use a semantic model of propositions; however, they take

very different paths to handle the contravariant circularity involvedin modeling lock invariants.

Hobor et al. use a purely semantic method that grew out of theVMM, whereas Gotsman et al. use a syntactic reification of the
logic to handle the contravariance issue. That is, Gotsman et al.associate each occurrence of a concurrent statement (e.g.,

lock,
unlock, etc.) with a static handle (a "lock sort") pointing intoa lookup table of resource invariants. This technique is displeasing

from a mathematical perspective: it is preferable to have a semanticmodel that is independent of syntax. Significantly, the syntactic
reification weakens Gotsman et al.'s model: for example, there isno polymorphism over lock sorts, so it is impossible to specify the
simple function that takes an arbitrary lock and locks it:

Spec : 8x, ss, R. f : {x ss R}{R * x ss R}
Body : f(x) = (lock x).

Instead, Gotsman et al. would have to create one version of thisfunction for each lock sort and then somehow determine which one

to call at a given program point. In contrast, indirection theory canhandle this case easily with impredicative quantification over

R.Finally, the models of Hobor et al. and Gotsman et al. are difficult to understand. Hobor subsequently made some improvementsin mathematical modularity but the model was still much more
complex than the theory of indirection presented here [Hob08].We hope that the formulation of indirection theory as a sectionretraction pair (squash-unsquash) makes life easier for the reader.

13. Conclusion
Indirection theory is a new approach to modeling impredicative in-direction. It is immediately applicable to a wide variety of settings

and has an extremely simple, categorical axiomatization. Indirec-tion theory embeds easily into type theory, and its axiomatization
embeds easily into the simple theory of types (HOL). Finally, itis powerful: we have used indirection theory as the basis for a
machine-checked soundness proof for the Concurrent SeparationLogic for Concurrent C minor described in $2.7.

Acknowledgments. We would like to thank Amal Ahmed, NickBenton, Matthew Parkinson, Andrew Pitts, Peter Sewell, Konrad
Slind, and the anonymous referees for their helpful suggestions onearlier drafts of this paper.

References

[AAR+09] Amal Ahmed, Andrew W. Appel, Christopher D. Richards,Kedar N. Swadi, Gang Tan, and Daniel C. Wang. Semantic

foundations for typed assembly languages. ACM. Trans. onProgramming Languages and Systems, 2009.

[AAV03] Amal Ahmed, Andrew W. Appel, and Roberto Virga. Anindexed model of impredicative polymorphism and mutable references. http://www.cs.princeton.edu/~appel/papers/impred.pdf, January 2003.

[AB07] Andrew W. Appel and Sandrine Blazy. Separation logic forsmall-step C minor. In 20th Int'l Conference on Theorem

Proving in Higher-Order Logics (TPHOLs), pages 5-21, 2007.
[ADR09] Amal Ahmed, Derek Dreyer, and Andreas Rossberg. State-dependent representation independence. In POPL '09: Proc.

36th annual ACM SIGPLAN-SIGACT Symposium on Princi-ples of Programming Languages, pages 340-353, 2009.
[AFM05] Amal Ahmed, Matthew Fluet, and Greg Morrisett. A step-indexed model of substructural state. In ICFP '05: Proceedings of the tenth ACM SIGPLAN International Conference onFunctional programming, pages 78-91, 2005.

[Age06] Sten Agerholm. Domain theory in HOL. In Higher OrderLogic Theorem Proving and Its Applications, LNCS, pages

295-309. Springer, 2006.
[Ahm04] Amal J. Ahmed. Semantics of Types for Mutable State. PhDthesis, Princeton University, Princeton, NJ, November 2004.

Tech Report TR-713-04.
[AMRV07] Andrew W. Appel, Paul-Andre Melli`es, Christopher D.Richards, and Jer^ome Vouillon. A very modal model of a modern, major, general type system. In Proc. 34th Annual ACMSIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL'07), pages 109-122, January 2007.
[BBTS07] Bodil Biering, Lars Birkedal, and Noah Torp-Smith. Bi-hyperdoctrines, higher-order separation logic, and abstraction.

ACM Trans. Program. Lang. Syst., 29(5):24, 2007.
[BKV09] Nick Benton, Andrew Kennedy, and Carsten Varming. Somedomain theory and denotational semantics in coq. In Theorem Proving in Hogher Order Logics, LNCS, pages 115-130.Springer, 2009.

[BST09] Lars Birkedal, Kristian Sto/vring, and Jacob Thamsborg. Thecategory-theoretic solution of recursive metric-space equations. Technical report, 2009. TR-2009-119.
[BT09] Nick Benton and Nicolas Tabareau. Compiling functionaltypes to relational specifications for low level imperative code.

In TLDI '09: Proc. 4th international workshop on Types inlanguage design and implementation, pages 3-14, 2009.

[CO78] Robert Cartwright and Derek Oppen. Unrestricted procedurecalls in Hoare's logic. In POPL '78: Proceedings of the

5th ACM SIGACT-SIGPLAN symposium on Principles of Pro-gramming Languages, pages 131-140, 1978.

[COY07] Cristiano Calcagno, Peter W. O'Hearn, and Hongseok Yang.Local action and abstract separation logic. In LICS '07: Proceedings of the 22nd Annual IEEE Symposium on Logic inComputer Science, pages 366-378, 2007.

[Cra03] Karl Crary. Toward a foundational typed assembly language.In POPL '03: 30th ACM Symp. on Principles of Programming

Languages, pages 198-212, 2003.
[DAB09] Derek Dreyer, Amal Ahmed, and Lars Birkedal. Logical step-indexed logical relations. In Proceedings 24th Annual IEEE

Symposium on Logic in Computer Science (LICS'09), 2009.
[DAH08] Robert Dockins, Andrew W. Appel, and Aquinas Hobor. Multi-modal separation logic for reasoning about operational semantics. In 24th Conference on the Mathematical Foundations ofProgramming Semantics, pages 5-20. Springer ENTCS, 2008.

[DHA09] Robert Dockins, Aquinas Hobor, and Andrew W. Appel. Afresh look at separation algebras and share accounting. In

The 7th Asian Symposium on Programming Languages andSystems. Springer ENTCS, 2009. To appear.

[DNRB10] Derek Dreyer, Georg Neis, Andreas Rossberg, and LarsBirkedal. A relational modal logic for higher-order stateful

adts. In POPL '10: Proc. 37th annual ACM SIGPLAN-SIGACTSymposium on Principles of Programming Languages, 2010.
To appear.
[GBC+07] Alexey Gotsman, Josh Berdine, Byron Cook, Noam Rinetzky,and Mooly Sagiv. Local reasoning for storable locks and

threads. In Proceedings 5th Asian Symposium on ProgrammingLanguages and Systems (APLAS'07), 2007.

[GHK+03] G. Gierz, K. H. Hofmann, K. Kiemel, J. D. Lawson, M. Mis-love, and D. S. Scott. Continuous Lattices and Domains, volume 93 of Encylopedia of Mathematics and its Applications.Cambridge University Press, Cambridge, UK, 2003.

13

[Har94] Robert Harper. A simplified account of polymorphic refer-ences. Information Processing Letters, 51:201-206, 1994.
[HAZ08] Aquinas Hobor, Andrew W. Appel, and Francesco ZappaNardelli. Oracle semantics for concurrent separation logic. In

Proc. European Symp. on Programming (ESOP 2008) (LNCS4960), pages 353-367. Springer, 2008.

[Hob08] Aquinas Hobor. Oracle Semanatics. PhD thesis, PrincetonUniversity, Princeton, NJ, November 2008.

[HS97] Robert Harper and Chris Stone. A type-theoretic inter-pretation of Standard ML. http://foxnet.cs.cmu.edu/papers/

rwh-interpret.ps, 1997.
[HS08] C*at*alin Hrit,cu and Jan Schwinghammer. A step-indexed se-mantics of imperative objects. International Workshop on

Foundations of Object-Oriented Languages (FOOL'08), 2008.
[Ler06] Xavier Leroy. Formal certification of a compiler back-end, or:programming a compiler with a proof assistant. In POPL'06,

pages 42-54, 2006.
[Lev02] Paul Blain Levy. Possible world semantics for general stor-age in call-by-value. In Computer Science Logic, 16th International Workshop, CSL 2002, volume 2471 of LNCS, pages232-246, Edinburgh, Scotland, UK, September 2002. Springer.

[Mil72] Robin Milner. Logic for computable functions: description ofa machine implementation. Technical report, Stanford, CA,

USA, 1972.
[MNOS99] Olaf M"uller, Tobias Nipkow, David von Oheimb, and OskarSlotosch. HOLCF = HOL + LCF. Journal of Functional

Programming, 9:191-223, 1999.
[Nip02] Tobias Nipkow. Hoare logics for recursive procedures and un-bounded nondeterminism. In Computer Science Logic, volume

2471/2002 of LNCS, pages 155-182. Springer, 2002.
[O'H07] Peter W. O'Hearn. Resources, concurrency and local rea-soning. Theoretical Computer Science, 375(1):271-307, May

2007.
[Ohe01] David von Oheimb. Analyzing Java in Isabelle/HOL: Formal-ization, Type Safety and Hoare Logic. PhD thesis, Technische

Universit"at M"unchen, 2001.
[PBC06] Matthew Parkinson, Richard Bornat, and Cristiano Calcagno.Variables as resource in Hoare logics. Proc. of 21st Annual

IEEE Symp. on Logic in Computer Science, 0:137-146, 2006.
[Pym02] David J. Pym. The Semantics and Proof Theory of the Logicof Bunched Implications, volume 26 of Applied Logic Series.

Kluwer Academic Publishers, 2002.
[Res00] Greg Restall. An Introduction to Substructural Logics. Rout-ledge, London, England, 2000.

[Sch97] Thomas Schreiber. Auxiliary variables and recursive proce-dures. In TAPSOFT '97: Proceedings of the 7th International Joint Conference CAAP/FASE on Theory and Practiceof Software Development, pages 697-711, London, UK, 1997.
Springer-Verlag.
[Sch06] Norbert Schirmer. Verification of Sequential Imperative Pro-grams in Isabelle/HOL. PhD thesis, Technische Universit"at

M"unchen, 2006.
[WF94] Andrew K. Wright and Matthias Felleisen. A syntactic ap-proach to type soundness. Information and Computation,

115(1):38-94, 1994.

A. Axiomatization in Coq
Module Type TY FUNCTOR.Parameter F : Type ! Type.

Parameter fmap : forall {A B}, (A ! B) ! F A ! F B.
Axiom fmap id : forall A : Type , fmap (@id A) = @id (F A).Axiom fmap comp : forall A B C (f:B ! C) (g:A ! B),

compose (fmap f) (fmap g) = fmap (compose f g).Parameter T : Type.
Parameter T bot : T.Parameter other : Type.
End TY FUNCTOR.
Module Type KNOT.Declare Module TF:TY FUNCTOR.

Import TF.
Parameter knot : Type.Definition predicate := (knot * other) ! T.

Parameter squash : (nat * F predicate) ! knot.Parameter unsquash : knot ! (nat * F predicate).
Definition level (x:knot) : nat := fst (unsquash x).(* le gt dec n m : forall n m : nat, {n

<= m} + {n > m} *)Definition approx (n:nat) (p:predicate) : predicate :=

fun w ) if le gt dec n (level (fst w)) then T bot else p w.
Axiom squash unsquash :forall x, squash (unsquash x) = x.
Axiom unsquash squash :forall n x0, unsquash (squash (n,x0)) = (n,fmap (approx n) x0).
End KNOT.
Module Knot (TF:TY FUNCTOR) : KNOT with Module TF:=TF.

14