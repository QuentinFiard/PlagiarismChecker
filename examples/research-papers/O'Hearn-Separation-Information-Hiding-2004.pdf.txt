

Separation and Information Hiding
Peter W. O'Hearn

Queen MaryUniversity of London

Hongseok Yang

Seoul NationalUniversity

John C. Reynolds

Carnegie MellonUniversity

Abstract
We investigate proof rules for information hiding, using the recentformalism of separation logic. In essence, we use the separating
conjunction to partition the internal resources of a module fromthose accessed by the module's clients. The use of a logical connective gives rise to a form of dynamic partitioning, where we trackthe transfer of ownership of portions of heap storage between program components. It also enables us to enforce separation in thepresence of mutable data structures with embedded addresses that
may be aliased.

Categories and Subject Descriptors: D.2.4 [Software Engineer-ing]: Program Verification--class invariants; D.3.3 [Programming
Languages]: Language Constructs and Features--modules, pack-ages

General Terms: Languages, Theory, Verification
Keywords: Separation Logic, Modularity, Resource Protection

1 Introduction
Modularity is a key concept which programmers wield in theirstruggle against the complexity of software systems. When a program is divided into conceptually distinct modules or components,each of which owns separate internal resources (such as storage),
the effort required for understanding the program is decomposedinto circumscribed, hopefully manageable, parts. And, if separation is correctly maintained, we can regard the internal resources ofone module as hidden from its clients, which results in a narrowing
of interface between program components. The flipside, of course,is that an ostensibly modular program organization is undermined
when internal resources are accessed from outside a module.
It stands to reason that, when specifying and reasoning about pro-grams, if we can keep track of the separation of resources between

Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citationon the first page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior specific permission and/or a fee.POPL'04, January 14-16, 2004, Venice, Italy.
Copyright 2004 ACM 1-58113-729-X/04/0001 ...$5.00

program components, then the resultant decomposition of the spec-ification and reasoning tasks should confer similar benefits. Unfortunately, most methods for specifying programs either severelyrestrict the programming model, by ruling out common programming features (so as to make the static enforcement of separationfeasible), or they expose the internal resources of a module in its
specification in order to preserve soundness.
Stated more plainly, information hiding should be the bedrock ofmodular reasoning, but it is difficult to support soundly, and this
presents a great challenge for research in program logic.
To see why information hiding in specifications is desirable, sup-pose a program makes use of n different modules. It would be unfortunate if we had to thread descriptions of the internal resourcesof each module through steps when reasoning about the program.
Even worse than the proof burden would be the additional anno-tation burden, if we had to complicate specifications of user procedures by including descriptions of the internal resources of allmodules that might be accessed. A change to a module's internal
representation would necessitate altering the specifications of allother procedures that use it. The resulting breakdown of modularity
would doom any aspiration to scalable specification and reasoning.
Mutable data structures with embedded addresses (pointers) haveproven to be a particularly obstinate obstacle to modularity. The
problem is that it is difficult to keep track of aliases, different copiesof the same address, and so it is difficult to know when there are no
pointers into the internals of a module. The purpose of this paperis to investigate proof rules for information hiding using separation
logic, a recent formalism for reasoning about mutable data struc-tures [36].

Our treatment draws on work of Hoare on proof rules for dataabstraction and for shared-variable concurrency [16, 17, 18]. In
Hoare's approach each distinct module has an associated resourceinvariant, which describes its internal state, and scoping constraints
are used to separate the resources of a module from those of clientprograms. We retain the resource invariants, and add a logical connective, the separating conjunction d^, to provide a more flexibleform of separation.

We begin in the next section by describing the memory model andthe logic of pre- and post-conditions used in this work. We then
describe our proof rules for information hiding, followed by twoexamples, one a simple memory manager module and the other a
queue module. Both examples involve the phenomenon of resourceownership transfer, where the right to access a data structure transfers between a module and its clients. We work through proofs, and

failed proofs, of client code as a way to illustrate the consequencesof the proof rules.
After giving the positive examples we present a counterexample,which shows that our principal new proof rule, the hypothetical
frame rule, is incompatible with the usual Hoare logic rule for con-junction; the new rule is thus unsound in models where commands
denote relations, which validate conjunction. The problem is thatthe very features that allow us to treat ownership transfer lead to
a subtle understanding where "Ownership is in the eye of the As-serter". The remainder of the paper is occupied with a semantic
analysis. This revolves around a notion of "precise" predicates,which are ones that unambiguously identify a portion of state. In
essence, we ask the Asserter to be unambiguous when specifyingwhich resource is owned; when this is the case, we find that our
proof rules are sound.
Familiarity with the basics of separation logic, as presented in [36],would be helpful in reading the paper. We remind the reader in particular that the rules for disposing or dereferencing an address aresuch that it must be known to point to something (not be dangling)
in the precondition for a rule to apply. For example, in the putativetriple {

true}[x] := 7{???}, where the contents of heap address x ismutated to 7, there is no assertion we can use in the postcondition

to get a valid triple, because x might be dangling in a state satisfy-ing the precondition. So, in order to obtain any postcondition for
[x] := 7, the precondition must imply the assertion x 7!-d^true thatx is not dangling.

The local way of thinking encouraged by separation logic [26] isstretched by the approach to information hiding described here. We
have found it useful to use a figurative language of "rights" whenthinking about specifications, where a predicate p at a program
point asserts that "I have the right to dereference the addresses in phere".

1.1 Contextual Remarks
The link between modularity and information hiding was developedin papers of Hoare and Parnas in the early 1970s [16, 17, 28, 29].
Parnas emphasized that poor information distribution amongstcomponents could lead to "almost invisible connections between
supposedly independent modules", and proposed that informationhiding was a way to combat this problem. Hoare suggested using
scoping restrictions to hide a particular kind of information, the in-ternal state of a module, and showed how these restrictions could
be used in concert with invariants to support proof rules that did notneed to reveal the internal data of a module or component. These
ideas influenced many subsequent language constructs and specifi-cation notations.

Most formal approaches to information hiding work by assuminga fixed, a priori, partitioning between program components, usually expressed using scoping restrictions, or typing, or simply usingcartesian product of state spaces. In simple cases fixed partitioning can be used to protect internal resources from outside tamper-ing. But in less simple situations, such as when data is referred
to indirectly via addresses, or when resources dynamically transferbetween program components, correct separation is more difficult
to maintain. Such situations are especially common in low-levelsystems programs whose purpose is to provide flexible, shared access to system resources. They are also common in object-orientedprograms. An unhappy consequence is that modular specification
methods are lacking for widely-used imperative or object-oriented

programming languages, or even for many of the programming pat-terns commonly expressed in them.
The essential point is that fixed partitioning does not cope naturallywith systems whose resource ownership or interconnection structure is changing over time. A good example is a resource manage-ment module, that provides primitives for allocating and deallocating resources, which are held in a local free list. A client programshould not alter the free list, except through the provided primitives; for example, the client should not tie a cycle in the free list.In short, the free list is owned by the manager, and it is (intuitively)
hidden from client programs. However, it is entirely possible for aclient program to hold an alias to an element of the free list, after a
deallocation operation is performed; intuitively, the "ownership" ofa resource transfers from client to module on disposal, even if many
aliases to the resource continue to be held by the client code. In alanguage that supports address arithmetic the potential difficulties
are compounded: the client might intentionally or unintentionallyobtain an address used in an internal representation, just by an arithmetic calculation.
A word of warning on our use of "module" before we continue: Theconcept of module we use is just a grouping of procedures that share
some private state. The sense of "private" will not be determinedstatically, but will be the subject of specifications and proof rules.
This allows us to approach modules where correct protection ofmodule internals would be impossible to determine with a compiletime check in current programming languages. The approach in thispaper might conceivably be used to analyze the information hiding
in a language that provides an explicit module notation, but that isnot our purpose here.

The point is that it is possible to program modules, in the sense ofthe word used by Parnas, whether or not one has a specific module
construct at one's disposal. For example, the pair of malloc() and
free() in C, together with their shared free list, might be consideredas a module, even though their correct usage is not guaranteed by

C's compile-time checking. Indeed, there is no existing program-ming language that correctly enforces information hiding of mutable data structures, largely because of the dynamic partitioningissue mentioned above, and this is an area where logical specifications are needed. We emphasize that the issue is not one of "safe"versus "unsafe" programming languages; for instance, middleware
programs written in garbage-collected, safe languages, often per-form explicit management of certain resources, and there also ownership transfer is essential to information hiding.
Similarly, although we do not consider the features of a full-blownobject-oriented language, our techniques, and certainly our problems, seem to be relevant. Theories of objects have been developedthat account for hiding in a purely functional context (e.g., [30]), but
mutable structures with embedded addresses, or object id's, are fun-damental to object-oriented programming. A thoroughgoing theory
should account for them directly, confronting the problems causedwhen there are potential aliases to the state used within an object.

These contextual remarks do not take into account some recentwork that attempts to address the limitations of fixed partitioning
and the difficulties of treating mutable data structures with embed-ded addresses. We will say more on some of the closely related
work at the end of the paper.

2 The Storage Model
We consider a model where a heap is a finite partial function takingaddresses to values:

H def= Addresses *fin Values
This set has a partial commutative monoid structure, where the unitis the empty function and the partial combining operation

d^ : H c^ H * H
is the union of partial functions with disjoint domains. Moreformally, we say that h

1#h2 holds for heaps h1 and h2 whendom(h
1) " dom(h2) = {}. In that case, h1 d^ h2 denotes the com-bined heap h

1 [ h2. When h1#h2 fails, h1 d^ h2 is undefined. Inparticular, note that if h = h

1 d^ h2 then we must have that h1#h2.The subheap order u* is subset inclusion of partial functions.

We will work with a RAM model, where the addresses are naturalnumbers and the values are integers

Addresses def= {0,1,2,...} Values def= {...,a,1,0,1,...}
The results of this paper go through for other choices for Addressesand

Values, and thus cover a number of other naturally occurringmodels, such as the cons cell model of [36] and the hierarchical

memory model of [1]. Our results also apply to traditional Hoarelogic, where there is no heap, by taking the trivial model where
Addresses is empty (and Values non-empty).
A natural model of separation that is not an instance of the par-tial functions model construction above is the "trees with dangling
pointers" model of [6]; it would be interesting to axiomatize the es-sentials of these separation models, by identifying a subclass of the
partial monoid models of [32].
To interpret variables in the programming language and logic, thestate has an additional component, the "stack", which is a mapping
from variables to values; a state is then a pair consisting of a stackand a heap:

S def= Variables ! Values States def= S c^ H.
We treat predicates semantically in this paper, so a predicate is justa set of states.

Predicates def= P (States)
The powerset of states has the usual boolean algebra structure,where ^ is intersection, . is union, ~ is complement,

true is theset of all states, and
false is the empty set of states. We use p, q, r,sometimes with subscripts and superscripts, to range over predicates. Besides the boolean connectives, we will need the lifting ofd^ from heaps to predicates:

p d^ q def= {(s,h) | 9h0,h1.h = h0 d^ h1, and(s

,h0) 2 p, and (s,h1) 2 q}.

As a function on predicates we have a total map d^ from
Predicates c^ Predicates to Predicates which, to the right of def=,uses the partial map, d^ : H c^H

* H in its definition. This overload-ing of d^ will always be disambiguated by context. d^ has a unit

emp,the set {(s
,[]) | s 2 S} of states whose heap component is empty.It also has an implication adjoint a,d^, though that will play no role

in the present paper. Note that emp is distinct from the empty set
false of states.

We use x 7! E to denote a predicate that consists of all pairs (s,h)where h is a singleton in which x points to the meaning of E:

h(s(x)) = [[E]]s. The points-to relation x 7! E,F for binary conscells is syntactic sugar for (x 7!E) d^ (x + 1 7!F). We will also use
quantifiers and recursive definitions in examples in what should bea clear way.

The syntax for the programming language considered in this paperis given by the following grammar.

E ::= x,y,... | 0 | 1 | E + E | E c^ E | E a, E
B ::= false | B ) B | E = E | E < E
C ::= x := E | x := [E] | [E] := E | x := cons(E,...,E)|

dispose(E) | skip | C;C | if B then C else C|
while B C | letrec k = C,...,k = C in C | k

For simplicity we consider parameterless procedures only. The ex-tension to all first-order procedures raises no new difficulties, but

lengthens the presentation. Higher-order features, on the otherhand, are not straightforward. We assume that all the procedure
identifiers are distinct in any letrec declaration. When proce-dure declarations do not have recursive calls, we write

let k1 =C

1,...,kn = Cn in C to indicate this.

The command x := cons(E1,...,En) allocates n consecutive cells,initializes them with the values of E

1,...,En, and stores the addressof the first cell in x. We could also consider a command for variablelength allocation. The contents of an address E can be read andstored in x by x := [E], or can be modified by [E] := F. The command dispose(E) deallocates the address E. In x := [E], [E] := Fand

dispose(E), the expression E can be an arbitrary arithmeticexpression; so, this language allows address arithmetic.

This inclusion of address arithmetic does not represent a generalcommitment to it on our part, but rather underlines the point that
our methods do not rely on ruling it out. In examples it is oftenclearer to use a field-selection notation rather than arithmetic, and
for this we use the following syntactic sugar:

E.i := F def= [E + i a, 1] := F x := E.i def= x := [E + i a, 1].
Each command denotes a (nondeterministic) state transformer thatfaults when heap storage is accessed illegally, and each expression

determines a (heap independent) function from stacks to values.The semantics will be given in Section 7.

3 Proof System
The form of judgment we use is the sequent

\Gamma  ` {p}C{q}
which states that command C satisfies its Hoare triple, under certainhypotheses. Hypotheses are given by the grammar

\Gamma  ::= e | {p}k{q}[X],\Gamma 
subject to the constraint that no procedure identifier k appears twice.An assumption {p}k{q}[X] requires k to denote a command that

modifies only the variables appearing in set X and that satisfies theindicated triple.

3.1 Proof Rules for Information Hiding
We begin with a special-case, programmer-friendly, proof rule, thatis a consequence of a more fundamental, logician-friendly, rule to
be described later.

Modular Non-Recursive Procedure Declaration Rule

\Gamma  ` {p1 d^ r}C1{q1 d^ r}.

..
\Gamma  ` {pn d^ r}Cn{qn d^ r}
\Gamma ,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] ` {p}C{q}

\Gamma  ` {p d^ r}let k1 = C1,...,kn = Cn in C{q d^ r}

In this rule k1,...kn is a grouping of procedures that share privatestate described by resource invariant r. In a resource management

module, the ki would be operations for allocating and freeing re-sources, and r would describe unallocated resources (perhaps held
in a free list). The rule distinguishes two views of such a module.When reasoning about the client code C, we ignore the invariant
and its area of storage; reasoning is done in the context of interfacespecifications {p

i}ki{qi} that do not mention r. The perspective isdifferent from inside the module; the implementations C

i operateon a larger state than that presented to the client, and verifications

are performed in the presence of the resource invariant. The twoviews, module and client, are tied up in the conclusion of the rule.

The modular procedure rule is subject to variable conditions: werequire a set Y (of "private" variables), and the conditions are

s^ C does not modify variables in r, except through usingk

1,...,kn;s^
Y is disjoint from p, q, C and the context"\Gamma 

,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn]";s^

Ci only modifies variables in Xi,Y .
The idea behind these conditions is that we must be sure that clientcode does not alter variables used within a module, but we must

also allow some overlap in variables to treat various examples. Arigorous formulation of what these conditions mean has been placed
in an appendix at the end of the paper. We will continue to state thenecessary side conditions as we present our proof rules, but there
will be little harm if the reader skates over them, or understandsthem in an intuitive way, while reading the paper. We only stress
that the modifies clauses refer exclusively to the stack, where thenew part of the paper involves the heap, and d^.

It is also possible to consider initialization and finalization code.For instance, if, in addition to the premises of the modular procedure rule, we have \Gamma  ` {p}init{p d^ r} and \Gamma  ` {q d^ r}final{q}, thenwe can obtain

\Gamma  ` {p} init;(let k1 = C1,...,kn = Cn in C); final {q}.
In our examples we will not consider initialization or finalizationsince they present no special logical difficulties.

In the modular procedure rule, the proof of {p}C{q} about theclient in the premises can be used with any resource invariant r. As
a result, this reasoning does not need to be repeated when a modulerepresentation is altered, as long as the alteration continues to satisfy the interface specifications {pi}ki{qi}. This addresses one ofthe points about reasoning that survives local changes discussed in
the Introduction.
However, the choice of invariant r is not specified by programminglanguage syntax

let k1 = C1,...,kn = Cn in C in the modular pro-cedure rule. In this it is similar to the usual partial correctness rule

for while loops, which depends on the choice of a loop invariant.It will be convenient to consider an annotation notation that specifies the invariant, and the interface specifications {pi}ki{qi}, as adirective on how to apply the modular procedure rule; this is by

Interface Specifications{p

1}k1{q1}[X1],...,{pn}kn{qn}[Xn]

Resource Invariant: r

Private Variables: Y
Internal ImplementationsC

1,...,Cn

Table 1. Module Specification Format

analogy with the use of loop invariant annotations as directives to averification condition generator.

We will use the format for module specifications in Table 1. Thisinstructs us to apply the modular procedure rule in a particular way,
to prove

\Gamma ,Interface Specifications ` {p}C{q}
for client code C, and to prove \Gamma  ` {pi d^ r}Ci{qi d^ r} for the bodies.We emphasize that this module format is not officially part of our

programming language or even our logic; however, its role as adirective on how to apply the modular procedure rule in examples
will, we hope, be clear.
The modular procedure rule can be derived from a standard rule forparameterless procedure declarations, and the following more basic
rule.

Hypothetical Frame Rule

\Gamma ,{pi}ki{qi}[Xi](for iu*n) ` {p}C{q}
\Gamma ,{pi d^ r}ki{qi d^ r}[Xi,Y ](for iu*n) ` {p d^ r}C{q d^ r}
wheres^ C does not modify variables in r, except through

using k1,...,kn; ands^
Y is disjoint from p, q, C, and the context"\Gamma 

,{p1}k{q1}[X1],...,{pn}k{qn}[Xn]".

The notation {pi}ki{qi}[X1](for iu*n) in the rule is a shorthand
for {p1}k1{q1}[X1],...,{pn}kn{qn}[Xn], and similarly for {pi d^r}k

i{qi d^ r}[X1,Y ](for iu*n). In examples we will use the modularprocedure rule, but will phrase our theoretical results in terms of

the hypothetical frame rule.
The hypothetical frame rule is so named because of its relation tothe ordinary frame rule from [20, 26]. The hypothetical rule allows
us to place invariants on the hypotheses as well as the conclusionof sequents, whereas the ordinary rule includes invariants on the
conclusion alone. (The ordinary frame rule is thus a special case ofthe hypothetical rule, where n = 0.)

3.2 Other Proof Rules
We have standard Hoare logic rules for various constructs, alongwith the rule of consequence.

\Gamma ,{p}k{q}[X] ` {p}k{q}

p ) p0 \Gamma  ` {p0}C{q0} q0 ) q

\Gamma  ` {p}C{q}

\Gamma  ` {p ^ B}C{p}
\Gamma  ` {p}whileBC{p ^ ~B}

\Gamma  ` {p}C1{q} \Gamma  ` {q}C2{r}

\Gamma  ` {p}C1;C2{r}

\Gamma  ` {p ^ B}C {q} \Gamma  ` {p ^ ~B}C0 {q}

\Gamma  ` {p}ifBthenC elseC0{q}

In addition, we allow for the context \Gamma  to be permuted.
The rule for possibly recursive procedure declarations uses the pro-cedure specifications in proofs of the bodies:

\Gamma ,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] ` {p1}C1{q1}.

..
\Gamma ,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] ` {pn}Cn{qn}

\Gamma ,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] ` {p}C{q}

\Gamma  ` {p}letrec k1 = C1,...,kn = Cn in C{q}

wheres^ C

i only modifies variables in Xi.

In case none of the ki are free in the Cj we can get a simpler rule,where the {p

i}ki{qi}[Xi] hypotheses are omitted from the sequentsfor the C
j. Using let rather than letrec to indicate the case wherea procedure declaration happens to have no recursive instances, we

can derive the modular non-recursive procedure declaration rule ofthe previous section from the hypothetical frame rule and the standard procedure rule just given. We can also derive a modular rulefor recursive declarations.

The ordinary frame rule is

\Gamma  ` {p}C{q}
\Gamma  ` {p d^ r}C{q d^ r}

wheres^ C does not modify any variables in r.

This is a special case of the hypothetical rule, but we state it sep-arately because the ordinary rule will be used without restriction,
while we will place restrictions on the hypothetical rule.
One rule of Hoare logic, which is sometimes not included explicitlyin proof systems, is the conjunction rule.

\Gamma  ` {p}C{q} \Gamma  ` {p0}C{q0}

\Gamma  ` {p ^ p0}C{q ^ q0}

The conjunction rule is often excluded because it is an example ofan admissible rule: one can (usually) prove a metatheorem, which

says that if the premises are derivable then so is the conclusion.However, it is not an example of a derived rule: one cannot construct a generic derivation, in the logic, of the conclusion from thepremises. We will see in Section 6 that the hypothetical frame rule
can affect the admissible status of the conjunction rule.
Finally, we have axioms for the basic commands, where x,m,n areassumed to be distinct variables.

\Gamma  ` {E 7!-}[E] := F {E 7!F}
\Gamma  ` {E 7!-}dispose(E){emp}

\Gamma  ` !x=m^emp?x := cons(E1,...,Ek){x 7!E1[m/x],...,Ek[m/x]}
\Gamma  ` {x = n ^ emp}x := E {x = (E[n/x]) ^ emp}
\Gamma  ` {E 7!n ^ x = m}x := [E]{x = n ^ E[m/x] 7!n}
These axioms describe the effect of each command on only one, orsometimes no, heap cells. Typically, their effects can be extended

using the frame rule: for example, we can infer {(x 7! 3) d^ (y 7!4)}[x] := 7{(x 7! 7) d^ (y 7! 4)} by choosing y 7! 4 as the invariant
in the frame rule.

Interface Specifications{

emp}alloc{x 7!-,-}[x]{x 7!-

,-}free{emp}[]

Resource Invariant: list( f )
Private Variables: f
Internal Implementations

if f = nil then x := cons(-,-) (code for alloc)

else x := f ; f := x.2;

x.2 := f ; f := x; (code for free)

Table 2. Memory Manager Module

4 A Memory Manager
We consider an extended example, of an idealized memory managerthat doles out memory in chunks of size two. The specifications and
code are given in Table 2.
The internal representation of the manager maintains a free list,which is a singly-linked list of binary cons cells. The free list is
pointed to by f , and the predicate list( f ) is the representation in-variant, where

list( f ) def() ( f = nil ^ emp) . (9g. f 7!-,g d^ list(g))
This predicate says that f points to a linked list (and that there areno other cells in storage), but it does not say what elements are in
the head components.
For the implementation of alloc, the manager places into x theaddress of the first element of the free list, if the list is nonempty. In
case the list is empty the manager calls the built-in allocator consto get an extra element. The interaction between

alloc and consis a microscopic idealization of the treatment of
malloc in Section8.7 of [22]. There,
malloc manages a free list but, occasionally, itcalls a system routine

sbrk to request additional memory. Besidesfixed versus variable sized allocation, the main difference is that we

assume that cons always succeeds, while sbrk might fail (return anerror code) if there is no extra memory to be given to

malloc. Weuse this simple manager because to use a more complex one would

not add anything to the points made in this section.
When a user program gives a cell back to the memory manager it isput on the front of the free list; there is no need for interaction with
a system routine here.
The form of the interface specifications are examples of the localway of thinking encouraged by separation logic; they refer to small
pieces of storage. It is important to appreciate the interaction be-tween local and more global perspectives in these assertions. For
example, in the implementation of free in Table 2 the variable xcontains the same address after the operation completes as it did
before, and the address continues to be in the domain of the globalprogram heap. The use of

emp in the postcondition of free doesnot mean that the global heap is now empty, but rather it implies

that the knowledge that x points to something is given up in thepostcondition. We say intuitively that

free transfers ownership tothe manager, where ownership confers the right to dereference.

It is interesting to see how transfer works logically, by consideringa proof outline for the implementation of

free.

{list( f ) d^ (x 7!-,-)}x

.2 := f ;{list( f ) d^ (x 7!-

, f )}{list(x)}

f := x;{list( f )}
{list( f ) d^ emp}
The most important step is the middle application of the rule of con-sequence. At that point we still have the original resource invariant

list( f ) and the knowledge that x points to something, separately.But since the second field of what x points to holds f , we can obtain list(x) as a consequence. It is at this point in the proof that theoriginal free list and the additional element x are bundled together;
the final statement simply lets f refer to this bundled information.
A similar point can be made about how alloc effects a transferfrom the module to the client.

We now give several examples from the client perspective. Eachproof, or attempted proof, is done in the context of the interface
specifications of alloc and free.
The first example is for inserting an element into the middle of alinked list.

{(y 7!a,z) d^ (z 7!c,w)}
alloc;{(y 7!a

,z) d^ (z 7!c,w) d^ (x 7!-,-)}{(y 7!a
,z) d^ (x 7!-,-) d^ (z 7!c,w)}x
.2 := z; x.1 := b;y.2 := x{(y 7!a

,x) d^ (x 7!b,z) d^ (z 7!c,w)}

Here, in the step for alloc we use the interface specification, to-gether with the ordinary frame rule.

If we did not have the modular procedure rule we could still ver-ify this code, by threading the free list through and changing the
interface specification. That is, the interface specifications wouldbecome

{list( f )}alloc{list( f ) d^ x 7!-,-}{list( f ) d^ x 7!-}

free{list( f )}

thus exposing the free list, and the proof would be

{(y 7!a,z) d^ (z 7!c,w) d^ list( f )}
alloc;{(y 7!a

,z) d^ (z 7!c,w) d^ (x 7!-,-) d^ list( f )}{(y 7!a
,z) d^ (x 7!-,-) d^ (z 7!c,w) d^ list( f )}x
.2 := z; x.1 := b;y.2 := x{(y 7!a

,x) d^ (x 7!b,z) d^ (z 7!c,w) d^ list( f )}.

Although technically correct, this inclusion of the free list in theproof of the client is an example of the breakdown of modularity

described in the Introduction.
One might wonder whether this hiding of invariants could beviewed as a simple matter of syntactic sugar, instead of being the
subject of a proof rule. We return to this point in Section 6.
We can similarly reason about deletion from the middle of a linkedlist, but it is more interesting to attempt to delete wrongly.

{(y 7!a,x) d^ (x 7!b,z) d^ (z 7!c,w)}
free;

{(y 7!a,x) d^ (z 7!c,w)}y := x

.2;{???}

This verification cannot be completed, because after doing the freeoperation the client has given up the right to dereference x.
This is a very simple example of the relation between ownershiptransfer and aliasing; after the

free operation x and f are aliasesin the global state, and the incorrect use of the alias by the client

has been rightly precluded by the proof rules. (A more positiveexample of aliasing, which incidentally would not be amenable to
unique-reference disciplines, would be a program to dispose nodesin a graph.)

Similarly, suppose the client tried to corrupt the manager, by sneak-ily tying a cycle in the free list.

{emp}alloc; free; x.2 := x{???}
Once again, there is no assertion we can find to fill in the ???, be-cause after the

free statement the client has given up the right todereference x (
emp will hold at this program point). And, this pro-tection has nothing to do with the fact that knotting the free list contradicts the resource invariant. For, suppose the statement x.2 := xwas replaced by x

.1 := x. Then the final assignment in this sequencewould not contradict the resource invariant, when viewed from the

perspective of the system's global state, because the list( f ) pred-icate is relaxed about what values are in head components. However, from the point of view of the interface specifications, the clienthas given up the right to dereference even the first component of
x. Thus, separation prevents the client from accessing the internalstorage of the module in any way whatsoever.

Finally, it is worth emphasizing that this use of d^ to enforce separa-tion provides protection even in the presence of address arithmetic
which, if used wrongly, can wreak havoc with data abstractions.Suppose the client tries to access some memory address, which
might or might not be in the free list, using [42] := 7. Then, forthis statement to get past the proof rules, the client must have the
right to dereference 42, and therefore 42 cannot be in the free list(by separation). That is, we have two cases

{42 7!- d^ p}[42] := 7; alloc{42 7!7 d^ p d^ x 7!-,-}
and

{p}[42] := 7; {???}alloc{???}
where p does not imply that 42 is in the domain of its heap. In thefirst case the client has used address arithmetic correctly, and the

42 7!- in the precondition ensures that 42 is not one of the cells inthe free list. In the second case the client uses address arithmetic
potentially incorrectly, and the code might indeed corrupt the freelist, but the code is (in the first step) blocked by the proof rules.

5 The Eye of the Asserter
In Table 3 we give a queue module. In the specification we usea predicate listseg(x

,a,y) which says that there is an acyclic linkedlist from x to y has the sequence a in its head components. The variable Q denotes the sequence of values currently held in the queue; itis present in the resource invariant, as well as in the interface specifications. (Technically, we would have to ensure that the variableQ was added to the s component of our semantics.) This exposing
of "abstract" variables is standard in module specifications, as isthe inclusion of assignment statements involving abstract variables

Interface Specifications{Q = a ^ z = n ^ P(z)}

enq{Q = ac'hni ^ emp}[Q]{

Q = hmic'a ^ emp}deq {Q = a ^ z = m ^ P(z)}[Q,z]{
emp}isempty?{(w = (Q = e)) ^ emp}[w]

Resource Invariant: listseg(x,Q,y) d^ (y 7!-,-)
Private Variables: x,y,t
listseg Predicate Definition

listseg(x,a,y) def()
if x = y then (a = [] ^ emp)
elsea,9v,z,a0. (a = hvic'a0 ^ x 7!v,z) d^ P(v)d^

listseg(z,a0,y)c'

Internal Implementations

Q := Qc'hzi; (code for enq)t :=

cons(-,-); y.1 := z; y.2 := t; y := t

Q := cdr(Q); (code for deq)z := x

.1; t := x; x := x.2; dispose(t)

w := (x = y) (code for isempty?)

Table 3. Queue Module, Parametric in P(v)

whose only purpose is to enable the specification to work.
This queue module keeps a sentinel at the end of its internal list,as is indicated by (y 7! -

,-) in the resource invariant. The sentineldoes not hold any value in the queue, but reserves storage for a new

value.
An additional feature of the treatment of queues is the predicateP, which is required to hold for each element of the sequence a.
By instantiating P in various ways we obtain versions of the queuemodule that transfer different amounts of storage.

s^ P(v) = emp: plain values are transferred in and out of thequeue, and no storage is transferred with any of these values;
s^ P(v) = v 7!-,-: binary cons cells, and ownership of the stor-age associated with them, are transferred in and out of the

queue;s^
P(v) = list(v): linked lists, and ownership of the storage as-sociated with them, are transferred in and out of the queue.

To illustrate the difference between these cases, consider the fol-lowing attempted proof steps in client code.

{Q = hnic'a ^ emp}

deq{Q = a ^ z = n ^ P(z)}

z.1 := 42{???}

In case P(v) is either emp or list(v) we cannot fill in ??? because wedo not have the right to dereference z in the precondition of z

.1 :=42. However, if P(v) is v 7! -
,- then we will have this right, and avalid postcondition is (Q = a^z = n^z 7!42

,-). Conversely, if wereplace z
.1 := 42 by code that traverses a linked list then the thirddefinition of P(v) will enable a verification to go through, where the

other two will not.
On the other hand there is no operational distinction between thesethree cases: the queue code just copies values.

The upshot of this discussion is that the idea of ownership transferwe have alluded to is not determined by instructions in the programming language alone. Just what storage is, or is not, transferred de-pends on which definition of P we choose. And this choice depends
on what we want to prove.
This phenomenon, where "Ownership is in the eye of the Asserter",can take some getting used to at first. One might feel ownership
transfer might be made an explicit operation in the programminglanguage. In some cases such a programming practice would be
useful, but the simple fact is that in real programs the amount ofresource transferred is not always determined operationally; rather,
there is an understanding between a module writer, and program-mers of client code. For example, when you call

malloc() youjust receive an address. The implementation of
malloc() doesnot include explicit statements that transfer each of several cells to

its caller, but the caller understands that ownership of several cellscomes with the single address it receives.

6 A Conundrum
In the following 0 is the assertion emp that the heap is empty, and 1says that it has precisely one active cell, say x (so 1 is x 7!-).

Consider the following instance of the hypothetical frame rule,where

true is chosen as the invariant:{

0 . 1}k{0}[] ` {1}k{false}{
(0 . 1) d^ true}k{0 d^ true}[] ` {1 d^ true}k{false d^ true}

The conclusion is definitely false in any sensible semantics of se-quents. For example, if k denotes the do-nothing command,

skip,then the antecedent holds, but the consequent does not.

However, we can derive the sequent in the premise:

{0 . 1}k{0}{

1}k{0} Consequence

{0 . 1}k{0}{

0}k{0} Consequence{
0 d^ 1}k{0 d^ 1} Ordinary Frame{

1}k{1} Consequence{
1 ^ 1}k{1 ^ 0} Conjunction{

1}k{false} Consequence

This shows that we cannot have all of: the usual rule of conse-quence, the ordinary frame rule, the conjunction rule, and the hypothetical frame rule. It also shows that the idea of treating infor-mation hiding as syntactic sugar for proof and specification forms
should be approached with caution: one needs to be careful that in-troduced sugar does not interact badly with expected rules, in a way
that contradicts them.
The counterexample can also be presented as a module, and can beused to show a similar problem with the modular procedure rule.

Given this counterexample, the question is where to place theblame. There are several possibilities.

1. The specification {0 . 1}k{0}. This is an unusual specifica-tion, since in the programming languages we have been using

there is no way to branch on whether the heap is empty.
2. The invariant true. Intuitively, a resource invariant shouldprecisely identify an unambiguous area of storage, that owned

by a module. The invariant list( f ) in the memory manager isunambiguous in this sense, where

true is perhaps not.

3. One of the rules of conjunction, consequence, or the ordinaryframe rule.
We pursue the first two options in the remainder of the paper, bydefining a model of the programming language and investigating a
notion of precise predicate.

7 A Denotational Model
Until now in work on separation logic we have used operationalsemantics, but in this paper we use a denotational semantics. By
using denotational semantics we will be able to reduce the truthof a sequent \Gamma  ` {p}C{q} to the truth of a single semantic triple
{p}[[C]]h{q} where h maps each procedure identifier in \Gamma  to a"greatest" or "most general" relation satisfying it. In the case of
the hypothetical frame rule, we will be able to compare two de-notations of the same command for particular instantiations of the
procedure identifiers, rather than having to quantify over all possi-ble instantiations. Our choice to use denotational semantics here is
entirely pragmatic: The greatest relation is not always definable bya program, but the ability to refer to it leads to significant simplifications in proofs about the semantics.
Recall that a state consists of a pair, of a stack and a heap. A com-mand is interpreted as a binary relation

States $ States [ {fault}
that relates an input state to possible output states, or a special out-put,

fault, which indicates an attempted access of an address notin the domain of the heap. In fact, because we use a fault-avoiding

interpretation of Hoare triples, it would be possible to use the do-main

States ! P (States) [ {fault}
instead. Using the more general domain lets us see clearly that if acommand nondeterministically chooses between

fault and somestate, then the possibility of faulting will mean that the command

is not well specified according to the semantics of triples. This isnot an essential point; the more constrained domain could be used
without affecting any of our results.
This domain of relations is inappropriate for total correctness be-cause it does not include a specific result for non-termination, so
that our semantics will not distinguish a command C from one thatnondeterministically chooses C or divergence.

We will not consider all relations, but rather only those that validatethe locality properties of the (ordinary) frame rule. We say that a
relation c:States $ States [ {fault} is safe at a state (s,h) when~((s

,h)[c]fault). We just list the properties here, and refer thereader to [39] for further explanation of them. The locality properties are:

1. Safety Monotonicity: for all states (s,h) and heaps h1 such thath#h

1, if c is safe at (s,h), it is also safe at (s,h d^ h1).
2. Frame Property: for all states (s,h) and heaps h1 such thath#h

1, if c is safe at (s,h) and (s,h d^ h1)[c](s0,h0), then there isa subheap h0

0 u* h0 such that

h00#h1, h00 d^ h1 = h0, and (s,h)[c](s0,h00).

Commands will be interpreted using the following domain.

The poset LRel of "local relations" is the set of all re-lations c satisfying the safety monotonicity and frame

properties, ordered by subset inclusion.
LEMMA 1. LRel is a chain-complete partial order with a least el-ement. The least element is the empty relation, and the least upper
bound of a chain is given by the union of all the relations in thechain.

The meaning of a command is given in the context of an environ-ment h, that maps procedure identifiers to relations in

LRel.

h 2 ProcIds ! LRel [[C]]h 2 LRel
The semantics of expressions depends only on the stack

[[E]]s 2 Ints [[B]]s 2 {true,false} (where s 2 S).
The valuations are standard and omitted.

Selected valuations for commands are in Table 4. The main pointto note is the treatment of

fault. We have included only the basiccommands and sequential composition. The interpretation of conditionals is as usual, a procedure call applies the environment to thecorresponding variable, and while loops and

letrec receive stan-dard least fixed-point interpretations, which are guaranteed to exist

by Lemma 1.

LEMMA 2. For each command C, [[C]] is well-defined: for all en-vironments h, [[C]]h is in

LRel, and [[C]]h is continuous in h whenenvironments are ordered pointwise.

It is entertaining to see the nondeterminism at work in the semanticsof

cons in this model. In particular, since we are aiming for partialcorrectness, the semantics does not record whether a command terminates or not; for instance, x := 1;y := 1 has the same denotationas a command that nondeterministically picks either x := 1;y := 1
or divergence. Such a nondeterministic command can be expressedin our language as

x := cons(0);dispose(x);y := cons(0);dispose(y);
if (x = y) then (x := 1;y := 1)

else (while (x = x) skip)

The reader may enjoy verifying that this is indeed equivalent tox := 1;y := 1 in the model.

8 Semantics of Sequents
In this section we give a semantics where a sequent

\Gamma  ` {p}C{q}
says that if every specification in \Gamma  is true of an environment, thenso is {p}C{q}.

To interpret sequents we define semantic cousins of the modifiesclauses and Hoare triples. If c 2

LRel is a relation then

s^ modir'es(c,X) holds if and only if whenever y 62 X and(s

,h)[c](s0,h0), we have that s(y) = s0(y).s^ {

p}c{q} holds if and only if for all states (s,h) in p,1. ~((s,h)[c]fault); and

2. if (s,h)[c](s0,h0) then state (s0,h0) is in q.
Now we can define the semantics: A sequent

{p1}k1{q1}[X1]...,{pn}kn{qn}[Xn] ` {p}C{q}
holds if and only if

for (s,h) 2 States and a 2 States [ {fault},

(s,h)[[[x := E]]h]a () a = (s[x 7! [[E]]s],h)
(s,h)[[[x := cons(E1,...,En)]]h]a () 9m. (m,...,m + n a, 1 62 dom(h))^ a,

a = (s[x 7! m],h d^ [m 7! [[E1]]s,...,m + n a, 1 7! [[En]]s])c'(s
,h)[[[x := [E]]]h]a () if [[E]]s 2 dom(h) then a = (s[x 7! h([[E]]s)],h) else a = fault

(s,h)[[[[E] := F]]h]a () if [[E]]s 2 dom(h) then a = (s,h[[[E]]s 7! [[F]]s]) else a = fault
(s,h)[[[dispose(E)]]h]a () if [[E]]s 2 dom(h)

then a = (s,h0) for h0 s.t. h0 d^ ([[E]]s 7! h([[E]]s)) = helse a =

fault

(s,h)[[[C1;C2]]h]a () s,9(s0,h0).(s,h)[[[C1]]h](s0,h0) ^ (s0,h0)[[[C2]]h]at^ . s,(s,h)[[[C1]]h]fault ^ a = faultt^

where fix f gives the least fixed-point of f , and seq(c1,c2), b ; c1;c2 and d1,...,dn are defined as follows:

(s,h)[seq(c1,c2)]a () s,9(s0,h0).(s,h)[c1](s0,h0) ^ (s0,h0)[c2]at^ . s,(s,h)[c1]fault ^ a = faultt^

(s,h)[b ; c1;c2]a () if b(s) = true then (s,h)[c1]a else (s,h)[c2]a(d

1,...,dn) = fix(ld1,...,dn 2 LReln.(F1,...,Fn)) (where Fi = [[Ci]]h[k1 7! d1,...,kn 7! dn])

Table 4. Selected Valuations

for all environments h, if both {pi}h(ki){qi} and
modir'es(h(ki),Xi) hold for all 1 u* i u* n, the triple{p}([[C]]h){q} also holds.

9 Precise Predicates
We know from the counterexample in Section 6 that we must re-strict the hypothetical frame rule in some way, if it is to be used
with the standard semantics. Before describing the restriction, letus retrace some of our steps. We had a situation where ownership
could transfer between a module and a client, which made essentialuse of the dynamic nature of d^. But we had also got to a position
where ownership is determined by what the Asserter asserts, andthis put us in a bind: when the Asserter does not precisely specify
what storage is owned, different splittings can be chosen at differ-ent times using the nondeterministic semantics of d^; this fools the
hypothetical frame rule. It is perhaps fortuitous that the nondeter-minism in d^ has not gotten us into trouble in separation logic before
now. A way out of this problem is to insist that the Asserter pre-cisely nail down the storage that he or she is talking about.

A predicate p is precise if and only if for all states (s,h),there is at most one subheap h

p of h for which (s,hp) 2 p.

Intuitively, this definition says that for each state (s,h), a precisepredicate unambiguously specifies the portion of the heap h that
is relevant to the predicate. Formulae that describe data structuresare often precise. Indeed, the definition might be viewed as a formalization of a point of view stressed by Richard Bornat, that forpractically any data structure one can write a formula or program
that searches through a heap and picks out the relevant cells. Bornatused this idea of reading out the relevant cells in order to express
spatial separation in traditional Hoare logic [4].
An example of a precise predicate is the following one for list seg-ments:

listseg(x,y) def() (x = y ^ emp) .a,

x 6= y ^ 9z. (x 7!z) d^ listseg(z,y)c'

This predicate is true when the heap contains a non-circular linkedlist (and nothing else), which starts from the cell x and ends with

y. Note that because of x 6= y in the second disjunct, the predicate

listseg(x,y) says that if x and y have the same value in a state (s,h),the heap h must be empty. If we had left x 6= y out of the second
disjunct, then listseg(x,y) would not be precise: listseg(x,x) couldbe true of a heap containing a non-empty circular list from x to x
(and nothing else), and also of the empty heap, a proper subheap.For this reason, the list segment predicate in [36] is not precise, if
we wrap it in an existential quantifier over the sequence parameter.
If p is a precise predicate then there can be at most one way to splitany given heap up in such a way as to satisfy p d^ q; the splitting,
if there is one, must give p the unique subheap satisfying it. Thisleads to an important property of precise predicates.

LEMMA 3. A predicate p is precise if and only if p d^ a, distributesover ^:

for all predicates q and r, we have p d^ (q^ r) = (p d^ q) ^(p d^ r).
We also have closure properties of precise predicates.

LEMMA 4. For all precise predicates p and q, all (possibly im-precise) predicates r, and boolean expressions B, all the predicates

p ^ r, p d^ q, and (B ^ p) . (~B ^ q) are precise.

10 Soundness
All of the proof rules from Section 3.2 are sound in the denota-tional model. The main result of the paper concerns the hypothetical frame rule and, by implication, the modular procedure rule.

THEOREM 5.

(a) The hypothetical frame rule is sound for fixed preconditionsp

1,..., pn if and only if p1,..., pn are all precise.

(b) The hypothetical frame rule is sound for a fixed invariant r ifand only if r is precise.

Theorem 5(a) addresses point 1 from Section 6: it rules out theprecondition 0.1 in the conundrum, which is not precise. Theorem
5(b) addresses point 2: it rules out the invariant true, which is notprecise. And this result covers the queue and memory manager
examples, where the preconditions and invariants are all precise.

There are two main concepts used in the proof of the theorem.s^

The greatest relation. We identify the greatest relation fora specification {p}k{q}[X], which is the largest local relation

satisfying it. This allows us to reduce the truth of a sequent,which officially involves quantification over all environments,
to the truth of a single triple for a single environment.s^
Simulation. To show the soundness of the hypothetical framerule we need to connect the meaning of a command in one

context to its meaning in another with an additional invariantand additional modifies sets. We develop a notion of simulation relation between commands to describe this connection.

In the next two subsections we define these concepts and state someof their properties, and then we sketch their relevance in the proof
of the theorem.

10.1 The Greatest Relation
For each specification {p} a, {q}[X], define great(p,q,X)

(s,h)[great(p,q,X)]fault

def() (s,h) 62 p d^ true

(s,h)[great(p,q,X)](s0,h0)

def() (1) s(y) = s0(y) for all variables y 62 X; and

(2) 8hp,h1.(hp d^ h1 = h ^ (s,hp) 2 p)=) 9h0

q.h0q#h1 ^ h0q d^ h1 = h0 ^ (s0,h0q) 2 q

The first equivalence says that great(p,q,X) is safe at (s,h) justwhen p holds in (s

,hp) for some subheap hp of h. The secondequivalence is about state changes. The condition (1) means that

great(p,q,X) can modify only those variables in X. Condition (2)says that

great(p,q,X) demonically chooses a subheap hp of theinitial heap h that satisfies p (i.e., (s

,hp) 2 p), and disposes all cellsin h

p; then, it angelically picks from q a new heap h0q (i.e., (s0,h0q) 2q) and allocates h0

q to get the final heap h0.

LEMMA 6. The relation great(p,q,X) is in LRel, and satis-fies {p} a, {q} and

modir'es(a,,X). Moreover, it is the greatestsuch: for all local relations c in

LRel, we have that {p}c{q} ^
modir'es(c,X) =) c t, great(p,q,X).

The greatest environment for a context \Gamma  is the largest environment,in the pointwise order, satisfying all the procedure specifications in

\Gamma . It maps k to great(p,q,X) when {p}k{q}[X] 2 \Gamma ; otherwise, itmaps k to the top relation

States c^ (States [ {fault}). Greatestenvironments give us a simpler way to interpret sequents and proof

rules. A sequent \Gamma  ` {p}C{q} holds just if the triple {p}([[C]]h){q}holds for the greatest environment h satisfying \Gamma , leading to

PROPOSITION 7. For all predicates p, q, p0 and q0, commands C,and contexts \Gamma  and \Gamma 0, we have the following equivalence: the proof
rule \Gamma  ` {p}C{q}

\Gamma 0 ` {p0}C{q0}
holds if and only if we have {p}[[C]]h{q} =) {p0}[[C]]h0{q0} forthe greatest environments h and h0 that, respectively, satisfy \Gamma  and

\Gamma 0.

10.2 Simulation
Let R : States $ States be a binary relation between states.For c

,c1 in LRel, we say that c1 simulates c upto R, denotedc[
sim(R)]c1, just if the following properties hold:

s^ Generalized Safety Monotonicity: if (s,h)[R](s1,h1), and c issafe at (s

,h), then c1 is safe at (s1,h1).s^

Generalized Frame Property: if (s,h)[R](s1,h1), c is safe at(s

,h), and (s1,h1)[c1](s01,h01), then there is a state (s0,h0) suchthat (s

,h)[c](s0,h0) and (s0,h0)[R](s01,h01).

c[sim(R)]c1 says that for R-related initial states (s,h) and (s1,h1),when we have enough resources at (s

,h) to run c safely, we alsohave enough resources at (s

1,h1) to run c1 safely; and in that case,every state transition from (s

1,h1) in c1 can be tracked by a transi-tion from (s,h) in c.

Suppose r is a predicate. The following relation Rr plays a centralrole in the analysis of the hypothetical frame rule.

(s,h)[Rr](s1,h1) def() s = s1 ^ 9hr.h1 = h d^ hr ^ (s,hr) 2 r
The next result gives us a way to connect hypotheses in the premiseand conclusion of the hypothetical rule, and additionally provides
the characterization of precise predicates that is at the core of The-orem 5.

PROPOSITION 8.

(a) A predicate p is precise if and only if

great(p,q,X)[sim(Rr)]great(p d^ r,q d^ r,X)
holds for for all predicates r and q, and sets X of variables.
(b) A predicate r is precise if and only if

great(p,q,X)[sim(Rr)]great(p d^ r,q d^ r,X)
holds for all predicates p,q and sets X of variables.
The detailed proof of Theorem 5 relies on developing machinerythat allows us to apply this key proposition; this development, and

the proof of the proposition itself, is nontrivial, and will be left tothe full paper. However, the relevance of the proposition can be
seen by considering a special case of the hypothetical frame rule,for the key case of procedure call, and where the modified variables
are held fixed:

{p1}k{q1}[X1] ` {p}k{q}{
p1 d^ r}k{q1 d^ r}[X1] ` {p d^ r}k{q d^ r}

We give a proof of the following proposition about this special case;it is the central step for showing Theorem 5.

PROPOSITION 9.

(a) The above special case of the hypothetical frame rule is soundfor a fixed precondition p

1 if and only if p1 is precise.

(b) The above special case is sound for a fixed invariant r if andonly if r is precise.

Note that the if direction of the proposition is implied by the samedirection of Theorem 5, and that for the only-if direction, the proposition implies the theorem. The proof of this proposition uses alemma that characterizes

sim(Rr) using Hoare triples.

LEMMA 10. Local relations c and c1 are related by sim(Rr) if andonly if for all predicates p

,q, we have

{p}c{q} =) {p d^ r}c1{q d^ r}.

Proof: [of Proposition 9]

Using Proposition 7 and Lemma 10, we can simplify the above spe-cial case of the hypothetical frame rule as follows:

for all predicates p,q,if {p

1}k1{q1}[X1] ` {p}k{q} holds,then {p

1 d^ r}k1{q1 d^ r}[X1] ` {p d^ r}k{q d^ r} holds

() (* Proposition 7)

for all predicates p,q,if {p}

great(p1,q1,X1){q} holds,then {p d^ r}

great(p1 d^ r,q1 d^ r,X1){q d^ r} holds

() (* Lemma 10)

great(p1,q1,X1)[sim(Rr)]great(p1 d^ r,q1 d^ r,X1)

Now, Proposition 8(a) gives (a) of this proposition, and Proposi-tion 8(b) gives (b) of this proposition.

10.3 Supported and Intuitionistic Predicates
There is a relaxation of the notion of precise predicate that can beused to provide further sufficient conditions for soundness. A predicate is supported if, for any stack and heap, the collection of sub-heaps making it true (while holding the stack constant) is empty or
has a least element. A predicate is intuitionistic if it is closed underheap extension.

THEOREM 11. The hypothetical frame rule is sound in the follow-ing cases:

(a) the preconditions p1,..., pn are supported, and the postcon-ditions q

1,...,qn are intuitionistic; or

(b) the resource invariant r is supported, and the postconditionsq

1,...,qn are intuitionistic.
Notice that the first point does not contradict the only if part ofTheorem 5(a), because it mentions postconditions in addition to

preconditions. Likewise, the second point does not contradict The-orem 5(b), because it mentions postconditions as well as the resource invariant. This result about supported predicates would giveus a version of the hypothetical frame rule appropriate when we are
not interested in nailing down definite portions of memory usingassertions, as might be the case in a garbage-collected language.

11 Related and Future Work
As we have emphasized, reliance on fixed resource partitioning hasbeen an obstacle to the development of modular methods of program specification that are applicable to widely used programminglanguages. Because the separating conjunction d^ is a logical connective, which depends on the state, it allows us to describe situa-tions where the partition between a module and its clients changes
over time. For example, with a resource manager module the re-sources transfer back and forth between the module and a client,
as allocation and deallocation operations are performed, but correctoperating relies on separation being maintained at all times.

A different reaction to the limitations of fixed partitioning hasbeen the development of the assume-guarantee method of reasoning
about program components [24, 21]. While this has proven success-ful, we are unsure whether it could be profitably applied to mutable
data structures with embedded pointers. In any case, when parti-tioning can be ensured, be it fixed or dynamic, an invariant-based
methodology leads to pleasantly modular specifications and proofs.

Perhaps the most significant previous work that addresses infor-mation hiding in program logics, and that confronts mutable data
structures, is that of Leino and Nelson [23] (also, [12]). They useabstract variables (like our use of the variable Q in Table 3) to specify modules, and they develop a subtle notion of "modular sound-ness" that identifies situations when clients cannot access the internal representation of a module. This much is similar in spirit towhat we are attempting, but on the technical level we are not at all
sure if there is any relationship between the separating conjunctionand their notion of modular soundness.

The information-hiding problems caused by pointers have been aconcern for a number of years in the object-oriented types community (e.g., [19, 10, 15] ). A focal point of that work has been aconcept of "confinement", which disallows or controls pointers into
data representations. Some confinement systems use techniquessimilar to regions, with control over the number and direction of
pointers across region boundaries.
The advantage of confinement schemes is their use of static typing,or static analysis, to provide algorithmic guarantees of information
hiding properties. Conversely, separation logic is more flexible, notjust because it is based on logic rather than types, but also because
it allows any number of pointers from the outside, requiring onlythat these pointers not be dereferenced without permission. Current
confinement schemes have difficulty with ownership transfer thatinvolves aliasing (because they tend to rely on "unique" pointers),
such as a program that disposes all of the elements in a graph, orwith examples where resource partitioning depends on arithmetic
properties.
Recent work on the semantics of confinement uses heap partition-ing in an essential way [3, 33], thus suggesting the prospect of a
deeper connection between type systems for confinement and log-ics of separation. There is also the possibility of promoting the
heap partitioning operation d^ used in the semantic models to a typeoperator in the source language; an immediate step could even be
attempted to obtain a form of alias types with information hiding[37]. Further unification along these lines could be valuable.

It is striking that many proof systems for object-oriented languageswork by exposing class invariants or other descriptions of internal
states at method call sites (e.g., [13, 34]). Of course, the developersof such systems have rightly been careful, as unsoundness can very
easily result if one incorrectly hides invariants. It seems plausible,however, that taking explicit account of separation or confinement
could lead to an improved logic of objects.
Further afield in aims, but closer in technique, are logics of mo-bile and concurrent processes that have been developed by Cardelli,
Caires and Gordon [9, 5]; related ideas have also been used to studysemi-structured data [8, 7]. Cardelli et. al. use subsets of a commutative monoid, as in the general models of bunched logic [31, 32],but the interaction between logic and program dynamics is very
different to that here. The models of [9, 5] do not satisfy the prop-erties (such as the frame property) that drive our approach to information hiding. Furthermore, although the "pointers from outside"phenomenon certainly occurs in their setting, based as it is on the
p-calculus, they do not use the conjunction d^ (or | in their nota-tion) to control these pointers/names; rather, they employ a form of
new name quantifier, following Gabbay and Pitts [14]. Despite thesurface similarity of logical structure, we do not feel that we fully
understand the relationship between the two approaches.
An intriguing question is if there is a link between the hypothetical frame rule and the data abstraction provided by polymorphictypes. Polymorphic typing can be used to hide the type in a data abstraction [35, 25], but this is not the same thing as hiding dynamicresources. For example, if we hide the type of a reference, polymorphic typing does not guarantee that the reference is not aliased, andaccessible from outside the data abstraction. Still, the hypothetical
frame rule ensures that a proof of client code can be used with any(precise) representation invariant, so there is an obvious intuitive
analogy with polymorphic functions; the client should be paramet-rically polymorphic in the resource invariant. If this analogy can
be made precise it may provide the basis for an approach to datarefinement, and encapsulated components as first-class values, that
accounts for mutable structures and dynamic ownership transfer.
We have stayed in a sequential setup in this paper, but the ideasseem relevant to concurrent programming. Indeed, the treatment
by Hoare in [17] revolves around the concept of spatial separa-tion, and the work here grew out of an attempt to directly adapt
that approach, and its extension by Owicki and Gries [27], to sep-aration logic. In unpublished notes from August 2001, O'Hearn
described proof rules for concurrency using d^ to express heap sepa-ration, and showed program proofs where storage moved from one
process to another. The proof rules were not published, becauseO'Hearn was unable to establish their soundness. Then, in August
2002, Reynolds showed that the rules were unsound if used withoutrestriction, and this lead to our focus on precise assertions. Both
the promise and subtlety of the proof rules had as much to do withinformation hiding as concurrency, and it seemed unwise to attempt
to tackle both at the same time. At the time of Reynolds's discoverywe had already begun work on the hypothetical frame rule, and the
counterexample appears here as the conundrum in Section 6.
Work is underway on the semantics of the concurrent logic, and weare hopeful that a thorough account of the concurrency proof rules
will be forthcoming.
Finally, in this paper we have concentrated on program proving,but there have been striking successes in software model checking [2, 11], which use abstraction to bridge the gap between infi-nite state language models and the finite state models expected by
model checking algorithms; in essence, abstract interpretations arechosen, and sometimes refined, that allow for the synthesis of loop
invariants. We wonder if one might synthesize resource invariantsdescribing heap-sensitive properties as well, and use this to partition the model checking effort. For this to be workable the imme-diate challenge is to devise expressive heap abstractions [38] that
are compatible with an information-hiding rule like the hypotheti-cal frame rule.

Acknowledgements. We have benefitted greatly from discus-sions with Josh Berdine, Richard Bornat and Cristiano Calcagno.
O'Hearn's research was supported by the EPSRC project "Lo-cal Reasoning about State". Reynolds's research was partially
supported by an EPSRC Visiting Fellowship at Queen Mary,University of London, by National Science Foundation Grant
CCR-0204242, and by the Basic Research in Computer Science(http://www.brics.dk/) Centre of the Danish National Research
Foundation. Yang was supported by grant No. R08-2003-000-10370-0 from the Basic Research Program of the Korea Science
& Engineering Foundation. Yang would like to thank EPSRC forsupporting his visit to University of London in 2002, during which
he first got involved in this work.

12 References

[1] A. Ahmed, L. Jia, and D. Walker. Reasoning about hierarchical stor-age. In 18th LICS, 2003.
[2] T. Ball and S. Rajamani. Checking temporal properties of softwarewith boolean programs. Proceedings of the Workshop on Advances in

Verification, 2000.
[3] A. Banerjee and D. Naumann. Representation independence, confine-ment and access control. In 29th POPL, 2002.

[4] R. Bornat. Proving pointer programs in Hoare logic. Mathematics ofProgram Construction, 2000.
[5] L. Cardelli and L Caires. A spatial logic for concurrency. In TACS'01,LNCS 2255:1-37, Springer, 2001.
[6] L. Cardelli, P. Gardner, and G. Ghelli. Querying trees with pointers.Unpublished notes, 2003.
[7] L. Cardelli, P. Gardner, and G. Ghelli. A spatial logic for queryinggraphs. Proceedings of ICALP'02.
[8] L. Cardelli and G. Ghelli. A query language for semistructured databased on the ambient logic. Proceedings of ESOP'01.
[9] L. Cardelli and A. D. Gordon. Anytime, anywhere. Modal logics formobile ambients. In 27th POPL, 2000.
[10] D. Clarke, J. Noble, and J. Potter. Simple ownership types for objectcontainment. ECOOP, LNCS 2072, 2001.
[11] J. Corbett, M. Dwyer, J. Hatcliff, S. Laubach, C. P*as*areanu, Robby,and H. Zheng. Bandera: extracting finite-state models from Java

source code. In International Conference on Software Engineering,pages 439-448, 2000.
[12] K.R.M. Leino D. Detlefs and G. Nelson. Wrestling with rep exposure.Digital SRC Research Report 156, 1998.
[13] F. de Boer. A WP calculus for OO. In FOSSACS, 1999.
[14] M. Gabbay and A. Pitts. A new approach to abstract syntax involvingbinders. In 14th LICS, 1999.

[15] C. Grothoff, J. Palsberg, and J. Vitek. Encapsulating objects withconfined types. OOPSLA, pp241-253, 2001.
[16] C.A.R. Hoare. Proof of correctness of data representations. ActaInformatica 4, 271-281, 1972.
[17] C.A.R. Hoare. Towards a theory of parallel programming. In Hoareand Perrot, editors, Operating Systems Techniques. Academic Press,

1972.
[18] C.A.R. Hoare. Monitors: An operating system structuring concept.C.ACM, 17(10):549-557, October 1974.

[19] J. Hogg, D. Lea, R. Holt, A. Wills, and D. de Champeaux. TheGeneva convention on the treatment of object aliasing. OOPS Messenger, April, 1992.
[20] S. Isthiaq and P.W. O'Hearn. BI as an assertion language for mutabledata structures. In 28th POPL, 2001.

[21] C.B. Jones. Specification and design of (parallel) programs. IFIPConference, 1983.
[22] B. Kernighan and D. Ritchie. The C programming language. PrenticeHall, 1988.
[23] K.R.M. Leino and G. Nelson. Data abstraction and information hid-ing. ACM TOPLAS 24(5): 491-553, 2002.
[24] J. Misra and K.M. Chandy. Proofs of networks of processes. IEEETransactions of Software Engineering, July, 1981.
[25] J.C. Mitchell and G.D. Plotkin. Abstract types have existential type.ACM TOPLAS 10(3):470-502, 1988.
[26] P. O'Hearn, J. Reynolds, and H. Yang. Local reasoning about pro-grams that alter data structures. In Proceedings of Computer Science

Logic, pages 1-19, 2001. LNCS 2142.
[27] S. Owicki and D. Gries. An axiomatic proof technique for parallelprograms I. Acta Informatica, 6:319-340, 1976.

[28] D.L. Parnas. Information distribution aspects of design methodology.IFIP Congress (1) 1971: 339-344, 1972.
[29] D.L. Parnas. On the criteria to be used in decomposing systems intomodules. C.ACM, 15(12):1053-1058, 1972.
[30] B.C. Pierce and D.N. Turner. Simple type-theoretic foundations forobject-oriented programming. Journal of Functional Programming,

4(2):207-247, 1994.

[31] D.J. Pym. The Semantics and Proof Theory of the Logic of BunchedImplications. Kluwer Applied Logic series, 2002.
[32] D.J. Pym, P.W. O'Hearn, and H. Yang. Possible worlds and resources:the semantics of BI. TCS, to appear, 2003.
[33] U. Reddy and H. Yang. Correctness of data representations involvingheap data structures. Proceedings of ESOP, 2003.
[34] B. Reus, M. Wirsing, and R. Hennicker. A Hoare calculus for ver-ifying Java realizations of OCL-constrained design models. FASE

Proceedings, LNCS 2029, pp300-316, 2001.
[35] J.C. Reynolds. Types, abstraction and parametric polymorphism.IFIP Proceedings, pp513-523, 1983.

[36] J.C. Reynolds. Separation logic: a logic for shared mutable data struc-tures. Invited Paper, 17th LICS, 2002.
[37] D. Walker and J.G. Morrisett. Alias types for recursive data structures.In Types in Compilation, pp177-206, 2000.
[38] R. Wilhelm, M. Sagiv, and T. Reps. Shape analysis. In CompilerConstruction, pp1-17, 2000.
[39] H. Yang, and P. O'Hearn. A semantic basis for local reasoning. InProceedings of FOSSACS'02, pp402-416, 2002.

13 Appendix: Variable Conditions
13.1 Side Conditions and Modifies Sets
We now clarify the side conditions for the hypothetical frame rule.To begin with, note that in the rule we are using comma between
the Xi and Y for union of disjoint sets; the form of the rule thereforeassumes that X

i and Y are disjoint.

The disjointness requirement for Y enforces that we do not observethe changes of a variable in Y while reasoning about C; as a result,
reasoning in client code is independent of variables in Y . We give atechnical definition of several variants on a notion of disjointness of
a set of variables X from a set of variables, a command, a predicate,or a context. X is disjoint from a set Y if their variables do not
overlap; X is disjoint from a command C if X does not intersectwith the free variables of C; X is disjoint from predicate r if the
predicate is invariant under changes to values of variables in X; Xis disjoint from context \Gamma  if for all {p}k{q}[Y ] in \Gamma , X is disjoint
from p, q and Y . This defines the second side condition.
The first side condition can be made rigorous with a relativized ver-sion of the usual notion of set of variables modified by a command.
We describe this using a set Modifies(C)(\Gamma ;\Gamma 0) of variables associ-ated with each command, where we split the context into two parts.
The two most important clauses in the definition concern procedurecall.

Modifies(k)(\Gamma ;\Gamma 0) = X, if {p}k{q}[X] 2 \Gamma 
Modifies(k)(\Gamma ;\Gamma 0) = {}, if {p}k{q}[X] 2 \Gamma 0

The upshot is that Modifies(C)(\Gamma ;\Gamma 0) reports those variables modi-fied by C, except that it doesn't count any procedure calls for procedures in \Gamma 0.
For the other commands, the relativized notion of modifies setis defined usual. For a compound command C with immediate
subcommands C1,...,Cn, the set Modifies(C)(\Gamma ;\Gamma 0) is the union[

iModifies(Ci)(\Gamma ;\Gamma 0). Two of the basic commands are as follows:

Modifies(x := E)(\Gamma ;\Gamma 0) = {x} Modifies([x] := E)(\Gamma ;\Gamma 0) = {}
For [x] := E the modifies set is empty because the command altersthe heap but not the stack.

We are now in a position to state the first side condition rigorously:it means

Modifies(C)(\Gamma ; {p1}k1{q1}[X1],...,{pn}kn{qn}[Xn])is disjoint from r.
The modifies conditions for the the ordinary frame and recursiveprocedure rules do not mention the "except through" clause. These
can be formalized by taking \Gamma 0 to be empty in Modifies(C)(\Gamma ;\Gamma 0).
An important point is that the free variables of the resource invari-ant are allowed to overlap with the X

i. This often happens whenusing abstract variables to specify the behaviour of a module, as

exemplified by the treatment of the abstract variable Q in the queuemodule in Table 3.

The complexity of modifies clauses is a general irritation in pro-gram logic, and one might feel that this problem with modifies
clauses could be easily avoided, simply by doing away with assign-ment to variables, so that the heap component is the only part of the
state that changes. While this is easy to do semantically, obtaininga satisfactory program logic is not as straightforward. The most important point is the treatment of abstract variables. For example, inthe queue module the variable q is used in interface specifications
as well as the invariant. If we were to try to place this variable intothe heap then separation would not allow us to have it in both an interface specification and an invariant. If some other approach couldbe developed as an alternative to the changing abstract variables,
that was itself not more complex, then perhaps we could finally doaway with modifies conditions.

In situations where one wants to capture only "structural integrity"properties of data structures, rather than correctness properties, it is
often possible to avoid abstract variables. For example, one some-times wants to ensure, for example, that a data structure has the
correct shape and has no dangling pointers, without giving a com-plete description of the data that is represented. Because abstract
variables are not required (or less often required) in such situationswe might get some way with a logic simpler than the one here, that
does not require modifies clauses.

13.2 On Existentials and Free Variables
In [26, 36] there is an inference rule for introducing existential vari-ables in preconditions and postconditions.

{p}C{q}{9
x.p}C{9x.q} x 62 free(C)

The side condition cannot be stated in the formalism of this paper.For, a procedure specification {p}k{q}[X] identifies the variables,

X, that k might modify, but not those that k might read from.
We can get around this problem by adding a free variable compo-nent to the sequent form, thus having

(Y ) \Gamma  ` {p}C{q}.
This constrains the variables appearing in C and all the proceduresk

i, but not the preconditions and postconditions. This would allowus to describe the existential rule as

(Y ) \Gamma  ` {p}C{q}
(Y ) \Gamma  ` {9x.p}C{9x.q} x 62 Y

Another reasonable approach is to have a distinct class of "logical"variables, that cannot be assigned to in programs. For technical

simplicity, we do not explicitly pursue either of these extensions inthe current paper.