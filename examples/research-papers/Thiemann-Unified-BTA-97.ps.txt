

A Unified Framework for Binding-Time Analysis

Peter Thiemann
Wilhelm-Schickard-Institut, Universit"at T"ubingen, Sand 13, D-72076 T"ubingen,

Germany, E-mail: thiemann@informatik.uni-tuebingen.de

Abstract. Binding-time analysis is a crucial part of offline partial evaluation. It is often specified as a non-standard type system. Many typebased binding-time analyses are reminiscent of simple type systems with
additional features like recursive types. We make this connection explicit
by expressing binding-time analysis with annotated type systems that
separate the concerns of type inference from those of binding-time annotation. The separation enables us to explore a design space for bindingtime analysis by varying the underlying type system and the annotation
strategy independently. The result is a classification of different monovariant binding-time analyses which allows us to compare their relative
power. Due to the systematic approach we uncover some novel analyses.

A partial evaluator separates the computation of a source program into two
or more stages [7, 20]. Using the (static) input of the first stage it transforms a
source program into a specialized residual program. Application of the residual
program to the (dynamic) input of the second stage yields the same answer as
application of the source program to the entire input. The binding time of an
input is the information whether it is static or dynamic.

Binding-time analysis (BTA) is a prepass of a partial evaluator that annotates each expression in the source program with the earliest (static is earlier
than dynamic) time at which it can be evaluated. The actual specializer is a
mere interpreter of annotated programs that executes the static expressions and
generates code for the remaining ones.

Binding-time analyses come in two flavors: A monovariant BTA computes a
single mapping of program points to binding-times, whereas a polyvariant BTA
allows for several such mappings. Both alternatives have their merits. Monovariant BTAs are simple and efficient to implement [4, 14, 15, 18, 20]. However,
in some applications static and dynamic values flow through the same program
points, which forces a monovariant BTA to annotate the program points as dynamic. A polyvariant BTA [5, 6] yields better results in these cases, but is also
considerably more expensive.

In the current work we concentrate on monovariant BTAs for the lambda
calculus as they are used in many partial evaluators [4, 14, 15, 18]. Our analyses achieve some degree of polyvariance because we admit liberal binding-time
coercions and rely on a more precise inclusion-based flow analysis framework.

BTA is often presented as a monolithic analysis which makes it unnecessarily
hard to understand and to reason about [2, 3, 14,18, 21]. Recent work has shown
the possibility to modularize BTA into several stages [4, 12, 13]. All of these

works rely more or less implicitly on using type systems and extending them
with annotations. However, none of the latter works really exploits the potential
of the modularization, namely comparing variants of the analyses with respect
to their accuracy.

We consider a modest staging of BTA in two phases, building on the ideas of
annotated type systems: flow-type analysis and binding-time annotation. Building a BTA on top of a flow-type system has some advantages over approaches
where types and binding times are intermingled [2, 14, 18]. First, it is easier to
implement a modular algorithm. Second, the approach applies to typed and
untyped languages. Third, it clearly separates different concerns: binding-time
propagation and type correctness. By not confusing them, we avoid a problem in
Henglein's type inference algorithm [18], which was discovered by Birkedal and
Welinder [2]. We investigate two variations of flow-type systems, an equational
system and an inclusion-based system which adds subtyping to the equational
system. On top of these, we investigate two binding-time annotation strategies,
a local one and a global one. The essential difference between these two lies in
additional binding-time coercion rules of the local strategy. We also identify an
instance of our framework that is equivalent to Gomard's BTA [14].

We present a modular algorithm for this BTA framework. Its run time ranges
from almost-linear (for the equational system with the global annotation strategy) to exponential (for the inclusion-based system with the local annotation
strategy), relying on well-known algorithms for flow-type analysis [18, 30].

We have compared the relative strengths of the different instantiations of
our algorithm. We can show that the equational and inclusion-based approaches
are equivalent under the global annotation scheme. This is somewhat unexpected
and shows that a simple-minded annotation strategy can throw away information
which is present in the underlying flow-type system. Otherwise, we show that
the local strategy produces strictly better results than the global strategy for
both type systems. Furthermore, the local variant of the inclusion-based system
is strictly better than the local variant of the equational system. Finally, we show
how to improve the results of a local equational BTA by using eta-expansors [11].
Figure 1 gives an overview of our results.

As far as we know, the following issues have not been investigated previously:

- the generic algorithm for BTA based on type automata and annotations,
- the combination of equational flow-typing with a local annotation scheme,
- inclusion-based BTA in a type-based setting, and
- an algorithm to improve the results of BTA using eta-expansors.

1 Basic Framework
For concreteness of our exposition, we have chosen a lambda calculus extended
with numbers, pairs, and conditionals.

e ::= x j *x:e j e@e j 0 j succ e j (e; e) j ss1e j ss2e j if0 e e e

simple typing
global ann., Sec. 2.1

partial typing
local ann., Sec. 2.5

subtyping
global ann., Sec. 3.1

simple typing
local ann., Sec. 2.2

subtyping
local ann., Sec. 3.2

simple typing
expansion
local ann., Sec. 2.4

arrows point towards increasing
precision of the
analysis

Fig. 1. Overview of Results

In the subsequent text, we use let-expressions "let x = e1 in e2" as syntactic
sugar for "(*x:e2)@e1." We assume that each subterm e is identified by a unique
program point ` 2 L which we indicate by superscripting e` where necessary.

We also define an annotated version of the syntax which serves to express the
output of the BTA. fi ranges over binding-time (bt) annotations, for example S

and D. liftfi;fi

0 E denotes a binding-time coercion (from fi to fi

0) for integers.

E ::= x j *fix:E j E@fiE j 0 j succfi E j (E; E)fi j ssfii E j if0fi E E E j liftfi;fi

0 E

We define jEj as the term obtained by dropping all annotations and lifts from
E. E is a completion of e if e = jEj.

We employ a standard type language with ? and ? types denoting the empty
type and the type of all values, which are used in the inclusion-based system.
Types can be recursive without an explicit fixpoint constructor in the language.

o/ ::= ? j ? j int j o/ ! o/ j o/ \Theta  o/

1.1 Type Inference
From an abstract operational view, type inference takes a term as input and
constructs a directed graph, every node of which is annotated by a type constructor, and a mapping M from the set L of program points to the nodes of
the graph. We call this directed graph a type automaton (cf. [29]).

Definition1. A type automaton over a set of program points L is a Moore
machine [19] A = (Q; \Sigma ; X; ffi; lab) where Q is the set of states, \Sigma  = f1; 2; : : :g
is the input alphabet, X is the set of labels, which are type constructors, ffi :
Q \Theta  \Sigma  ! Q is the partial transition function, and lab : Q ! X the labeling
function. For any state OE, the transitions ffi(OE; 1); : : : ; ffi(OE; n) are defined if and
only if lab(OE) is an n-ary type constructor.

The additional mapping M from the set L of program points to Q determines for
each program point ` a subautomaton A(`) with initial state M (`) that describes

the type of the construct at `. Recursive types arise naturally in this framework:
they are type automata that recognize infinite languages.

It is helpful to consider states of the type automaton as type variables and
type inference as a process that refines an initial non-deterministic automaton
by unification until unification fails or the automaton is deterministic.

1.2 Binding-Time Annotation
We relate binding times to states of an automaton by giving a map B : Q !
BT. BT can be the standard domain f0; 1g aka fS; Dg, as well as a multilevel binding-time domain f0; : : : ; Dg where D * 1 is the maximum binding
time [13]. Each map B corresponds to an annotation of the occurrences of type
constructors in the recursive type denoted by the automaton. However, it is often
more convenient to talk about binding-time-annotated types ae.

Definition2 Binding-Time-Annotated Types.

ae ::= ?fi j ?fi j intfi j ae !fi ae j ae \Theta fi ae
Annotated types may also be recursive. We write AEfi = ae in order to peel off
the top-level binding-time annotation.

Not every binding-time annotation is admissible. For example, the annotated
type int0 !D int0 does not make sense because it specifies a dynamic function
where the argument and result are available at time 0, i.e., statically. Clearly,
the same kind of restriction must be imposed on all other type constructors: the
components of a constructed value are not available before the constructor.

Definition3 Well-formedness. Let A = (Q; \Sigma ; X; ffi; lab) be a type automaton and B : Q ! BT a binding-time annotation.

(A; B) is well-formed if for all OE 2 Q: either lab(OE) = ? and D = B(OE), or
8i: OE0 = ffi(OE; i) defined ) B(OE) ^ B(OE0).

Equivalently, we can express the well-formedness criterion as a predicate on
annotated types [12]:

Definition4 Well-formed Types. An annotated type ae is well-formed if wft ae
is derivable from the axioms wft ?D and wft intfi and the rules

wft AEfi11 wft AEfi22 fi ^ fi1 fi ^ fi2

wft AEfi11 !fi AEfi22

wft AEfi11 wft AEfi22 fi ^ fi1 fi ^ fi2

wft AEfi11 \Theta fi AEfi22

Def. 3 provides a set of inequalities that every well-formed annotation must
fulfill. These inequalities give rise to a set of binding-time constraints (BTC)
from a type automaton in the obvious way: Associate a binding-time variable
fiOE with each state OE of the automaton. This variable captures the annotation
fiOE = B(OE). The BTC sets only involve BTCs of the forms:

1. i ^ fi (for 0 ^ i ^ D), 2. fi1 ^ fi2, and 3. fi1 = fi2
where ^ and = are the usual relations over BT ` N.

Definition5. A solution for a set of BTCs is an assignment from binding-time
variables to BT which satisfies all constraints.

Fact. Every set of BTCs has a unique least solution.
Lemma 6. There is an algorithm to compute the least solution for BTC set S
in O(jSj) time.

Proof. First rewrite inequations of the form a ^ fi to equations of the form
fi = a t fi (where t denotes maximum). This takes O(jSj) time and preserves all
solutions. A theorem of Seidl [32, Theorem 10] provides an algorithm to compute
the least solution to such a set of equations over N in O(jSj) time.

1.3 Annotation Strategies
Given a term and its type automaton, we have two choices to perform a bindingtime annotation. One choice is the global strategy that provides a single wellannotation for the entire type automaton. It is similar to what standard algorithms provide [2, 14, 18].

Another choice is the local strategy. For each program point `, it constructs
the subautomaton A(`) of the type automaton. For each of these automata
we have to provide well-annotations, but now we also need to respect phase
constraints that relate the types of "neighboring" program points. These phase
constraints can prescribe binding-time coercions that need to be inserted into the
term to make it well-annotated. Below, we will make this notion more precise.

It is important to observe that every global annotation gives rise to a local
annotation. Given a type automaton A = (Q; : : :) and a global annotation B
we construct the local annotation Be of A(`) = (Q`; : : :) for expression e`. By
construction of the A(`) there is an injective mapping ' : Q` ! Q and we can
define Be by Be := B ffi ', i.e., by restricting B to the set of states of A(`).

2 Equational Binding-Time Analysis

(var) \Gamma fx : o/g ` x : o/ (const) \Gamma  ` 0 : int (succ) \Gamma  ` e : int\Gamma  ` succ e : int

(abs) \Gamma fx : o/

2g ` e : o/1

\Gamma  ` *x:e : o/2 ! o/1 (app)

\Gamma  ` e1 : o/2 ! o/1 \Gamma  ` e2 : o/2

\Gamma  ` e1@e2 : o/1

(pair) \Gamma  ` e

1 : o/1 \Gamma  ` e2 : o/2

\Gamma  ` (e1; e2) : o/1 \Theta  o/2 (proj)

\Gamma  ` e : o/1 \Theta  o/2

\Gamma  ` ssie : o/i

(if) \Gamma  ` e

1 : int \Gamma  ` e2 : o/ \Gamma  ` e3 : o/

\Gamma  ` if0 e1 e2 e3 : o/

Fig. 2. Simple Types

The underlying type system of equational BTA is the system of simple types
with recursion. Figure 2 gives the standard rules.

\Gamma fx : aeg ` x ; x : ae \Gamma  ` 0 ; lift

0;fi 0 : intfi \Gamma  ` e ; E : int

fi

\Gamma  ` succ e ; succfi E : intfi
\Gamma fx : ae2g ` e ; E : ae1 wft ae2 !fi ae1

\Gamma  ` *x:e ; *fix:E : ae2 !fi ae1

\Gamma  ` e1 ; E1 : ae2 !fi ae1 \Gamma  ` e2 ; E2 : ae2

\Gamma  ` e1@e2 ; E1@fiE2 : ae1
\Gamma  ` e1 ; E1 : ae1 \Gamma  ` e2 ; E2 : ae2 wft ae1 \Theta fi ae2

\Gamma  ` (e1; e2) ; (E1; E2)fi : ae1 \Theta fi ae2

\Gamma  ` e ; E : ae1 \Theta fi ae2

\Gamma  ` ssie ; ssfi1 E : aei
\Gamma  ` e1 ; E1 : AEfi1 \Gamma  ` e2 ; E2 : ae \Gamma  ` e3 ; E3 : ae

\Gamma  ` if0 e1 e2 e3 ; if0fi E1 E2 E3 : ae

Fig. 3. Translation Rules for Global Equational BTA

2.1 Global Variant
For the global variant we only need the well-annotatedness constraints, phase
constraints are not necessary.

Definition7 Global Equational Binding-Time Analysis.

- Construct A by type reconstruction for simple types with recursion.
- Build a BTC set from the well-formedness constraints derived from A and

the initial binding times, i.e., bi ^ fixi .
- Solve the BTC set to obtain a minimal well-formed bt annotation of A.

From the construction of the automaton A we know that each expression e`
of the original term is associated to a state OEe = M (`) of A which in turn is
associated with a binding-time annotation fie = B(OEe). Using this association we
can transform a program into a completion as shown in Fig. 3. The judgement
\Gamma  ` e ; E : ae reads "under type assumption \Gamma  term e translates to annotated
term E of well-formed annotated type ae."

2.2 Local Variant
A local BTA associates a local type automaton with each program point and
decorates it with binding-time information. The local automaton Ae for expression e` is the subautomaton of A with initial state M (`). Each of these local
automata Ae has its own binding-time annotation Be : \Phi  ! BT. Obviously,
each of them must be well-formed, according to Def. 3.

Furthermore, we now have to specify phase constraints. This amounts to

having binding-time (bt) coercions ae b; ae0 (read: there is a bt coercion from
ae to ae0, see Fig. 5) in the definition of well-annotatedness. The corresponding
translation rule is:

\Gamma  ` e ; E : ae ae

b
; ae

0

\Gamma  ` e ; hae b; ae

0iE : ae0

where ae ranges over annotated types. A bt coercion enables us to use a static
function in a dynamic context without compromising the staticness of the function. Bt coercions do not change the shape of the underlying type. Figure 4
defines the coercion relation between bt annotated types, which gives rise to the
phase constraints.

ae b; ae fi ^ fi

0

intfi b; intfi

0

ae

0

1

b
; ae1 ae2 b; ae

0

2 fi ^ fi

0 wft ae

1 !fi ae2 wft ae

0

1 !fi

0 ae0

2

ae1 !fi ae2 b; ae

0

1 !

fi0 ae0

2

ae1 b; ae

0

1 ae2

b
; ae

0

2 fi ^ fi

0 wft ae

1 \Theta fi ae2 wft ae

0

1 \Theta fi

0 ae0

2

ae1 \Theta fi ae2

b
; ae

0

1 \Theta fi

0 ae0

2

Fig. 4. Binding-Time Coercion Relation

hae ; aei = *z:z
hintfi ; intfi

0 i = *y:liftfi;fi0 z

hae1 !fi ae2 ; ae

0

1 !fi

0 ae0

2i = *z:*fi

0 x3:hae

2 ; ae

0

2i(z@fihae

0
1 ; ae1ix

3)

hae1 \Theta fi ae2 ; ae

0

1 \Theta 

fi0 ae0

2i = *z:(hae1 ; ae

0
1iss

fi

1 z; hae2 ; ae

0
2iss

fi

2 z)

fi0

Fig. 5. Higher-Order Binding-Time Coercions

Figure 5 shows an implementation of bt coercions (cf. [8-10]). Coercions can
also be defined for sums and some recursive types (e.g., lists).

When generating the phase constraints we refer to the normalized translation rules given in Fig. 6. In all cases where the binding-time annotations must
coincide, we equate the annotations of two automata. Wherever coercions are
allowed, we relate the annotations as prescribed in Fig. 4. Both result in obvious algorithms which traverse two automata simultaneously and generate constraints. The number of constraints is bounded by the product of the number of
states of the automata. Each of these is bounded by the number of states of the
global automaton, which is bounded by the size of the program.

Definition8 Local Equational Binding-Time Analysis.

- Construct A by type reconstruction for simple types with recursion.

\Gamma fx : aeg ` x ; x : ae \Gamma  ` 0 ; 0 : int0 \Gamma  ` e

; E : AEfi

\Gamma  ` succ e ; succfi E : intfi
\Gamma fx : ae2g ` e ; E : ae1
\Gamma  ` *x:e ; *

0x:E : ae

2 !

0 ae

1

\Gamma  ` e1 ; E1 : ae

0

2 !fi ae1 \Gamma  ` e2 ; E2 : ae2 ae2 ; ae

0
2

\Gamma  ` e1@e2 ; E1@fi(hae2 ; ae

0

2iE2) : ae1

\Gamma  ` e1 ; E1 : ae1 \Gamma  ` e2 ; E2 : ae2

\Gamma  ` (e1; e2) ; (E1; E2)

0 : ae

1 \Theta 

0 ae

2

\Gamma  ` e ; E : ae1 \Theta fi ae2

\Gamma  ` ssie ; ssfii E : aei
\Gamma  ` e1 ; E1 : AEfi \Gamma  ` e2 ; E2 : ae2 \Gamma  ` e3 ; E3 : ae3 ae2 ; ae ae3 ; ae

\Gamma  ` if0 e1 e2 e3 ; if0fi E1 (hae2 ; aeiE2) (hae3 ; aeiE3) : ae

Fig. 6. Normalized Translation Rules for Local Equational BTA

- For each subexpression e` of the program build a local automaton Ae as the

subautomaton of A with initial state M (`).
- Build a BTC set from the well-formedness constraints derived from all Ae,

the phase constraints, and the initial binding times, i.e., bi ^ fixi .
- Solve the BTC set giving well-formed binding-time annotations for each Ae.

The binding-time annotations also satisfy the phase constraints.

The complexity of the algorithm is dominated by the cost of generating the
phase constraints. Let s be the size of the program. Flow type inference takes
O(s \Delta  ff(s)) time [18], generating the well-formedness BTCs takes O(s2) time,
generating the phase BTCs takes O(s2) time for each program point resulting
in a total of O(s3). Solving the BTC set is linear in the size of the constraint
set. Hence, the overall time complexity is O(s3).

2.3 Comparison
In this section we compare the power of the global and local variants of equational
BTA. As any global annotation can be considered a local annotation it is clear
that the local variant cannot yield worse results than the global variant (see
Sec. 1.3). The following example term shows that the inclusion is proper:

let f = *z:z in f@((if0 0 f g)@0) (1)
is analyzed with g : intD !D intD, a dynamic function. Such a situation arises,
for example, if g is a dynamic parameter of the goal function. The global annotation scheme translates this term to

letD f = *Dz:z in f@D((if00 0 f g)@D(lift 0)) (2)
where everything except the conditional is dynamic. The specialized term is

let f = *z:z in f@(f@0). (3)
The local annotation scheme translates the same term to

let0 f = *0z:z in f@0((if00 0 (*Dw:f@0w) g)@D(lift 0)) (4)
which specializes to

(*w:w)@0. (5)

Hence, we have the following lemma.

Lemma 9. The local variant of the equational BTA classifies strictly more program points as static than the global variant.

(t-const) \Gamma  ` 0 : ? (t-succ1) \Gamma  ` e : ?\Gamma  ` succ e : ? (t-succ2) \Gamma  ` e : int\Gamma  ` succ e : ?

(t-abs) \Gamma fx : ?g ` e : ?\Gamma  ` *x:e : ? (t-app) \Gamma  ` e

1 : ? \Gamma  ` e2 : ?

\Gamma  ` e1@e2 : ?

(t-pair) \Gamma  ` e

1 : ? \Gamma  ` e2 : ?

\Gamma  ` (e1; e2) : ? (t-proj)

\Gamma  ` e :
\Gamma  ` ssie : ?

(t-if) \Gamma  ` e

1 : ? \Gamma  ` e2 : o/ \Gamma  ` e3 : o/

\Gamma  ` if0 e1 e2 e3 : o/

Fig. 7. Additional Partial Typing Rules

2.4 More Precision
The example from the preceding subsection can be improved by eta-expanding
g before placing the annotations [9]:

let0 f = *0z:z in f@0((if00 0 (*0w:f@0w) (*0w:g@Dw))@0(lift 0))
This completion reduces to 0. Below we sketch an algorithm to produce this
result. First, we need a definition.

Definition10 Eta-Expansors [11].

\Delta o/ = (

*z:z o/ = int
*z:*w:\Delta o/2@(z@(\Delta o/1@w)) o/ = o/1 ! o/2
*z:(ss1(\Delta o/1@z); ss2(\Delta o/2 @z)) o/ = o/1 \Theta  o/2

Definition11 Improved Local Equational Binding-Time Analysis.

- Perform equational flow-type reconstruction.
- For all expressions e appearing as arguments of function calls, branches of

conditionals, or arguments of primitive operations do simultaneously:

ffl Replace e of type o/ = o/1 ! o/2 which is not a lambda expression by

\Delta o/ @e.
ffl Replace e of type o/ = o/1 \Theta  o/2 that is not a pair construction by \Delta o/ @e.
- Continue as in Local Equational Binding-Time Analysis.

2.5 Another Variation of Equational BTA
We can also express Gomard's BTA, which is based on partial types, in our
framework. It adds the type ? to the current system and the rules in Fig. 7. The
motivation behind these rules is the desire to type all terms regardless whether
their execution yields an error or not. Using this system as a basis for a BTA
intends to defer all program parts that are possibly erroneous (have type ?) to
run time. Additionally, Gomard's BTA allows for first-order bt coercions of the

form intfi b; intfi

0 for fi ^ fi0. So we can say that Gomard's BTA consists of

partial (equational) type inference with a local annotation scheme restricted to
first-order bt coercions. Henglein's algorithm [18] performs the entire reconstruction for this system in almost-linear time. Strictly speaking, we are discussing
Mogensen's system [25] because Gomard and Henglein disallow recursive types.

? _t o/ o/ _t o/ o/ _t ? o/

1 _t o/2 o/2 _t o/3

o/1 _t o/3
o/

0

1 _t o/1 o/2 _t o/

0
2

o/1 ! o/2 _t o/

0

1 ! o/

0
2

o/1 _t o/

0

1 o/2 _t o/

0
2

o/1 \Theta  o/2 _t o/

0

1 \Theta  o/

0
2

Fig. 8. Type Coercions

?0 _g ae ae _g ae AED _g ?D ae

1 _g ae2 ae2 _g ae3

ae1 _g ae3
fi ^ fi

0

intfi _g intfi

0 ae

0
1 _g ae1 ae2 _g ae

0
2

ae1 !fi ae2 _g ae

0

1 !fi ae

0
2

ae1 _g ae

0

1 ae2 _g ae

0
2

ae1 \Theta fi ae2 _g ae

0

1 \Theta fi ae

0
2

Fig. 9. Coercion Relation for the Global Variant

3 Inclusion-Based Binding-Time Analysis
Equational flow analysis and BTA ignore the direction in which values flow.
This sometimes deteriorates binding-time annotations because the analysis can
equate program points that never flow together.

Hence, the inclusion-based BTA builds on an extension of the equational
flow-type system with subtyping, ?, and ? types. The resulting system of simple types with recursion and subtyping originates from work by Amadio and
Cardelli [1]. It only adds the subsumption rule to the typing rules of Fig. 2.

(sub) \Gamma  ` e : o/ o/ _

t o/0

\Gamma  ` e : o/

0

The coercion relation for types _t shown in Fig. 8 is standard. Typability for
that system can be decided in polynomial time [17, 29], however type reconstruction requires exponential time [29]. The result of that algorithm is a global
type automaton as in Sec. 2. On top of that automaton, we define our BTA.

As in Sec. 2, there are two ways to add binding-time annotations to the
automaton: the global and the local strategy. For both strategies, we reuse Def. 3
for well-formed binding-time annotations. Only the phase constraints differ.

3.1 Global Variant
In the global setting, we can reuse all annotated translation rules from the equational setting. We only have to define an annotated translation rule for the rule
(sub) of type subsumption. It is based on the coercion relation _g on annotated
types defined in Fig. 9. It leads to the following annotated translation rule.

\Gamma  ` e ; E : ae ae _g ae

0

\Gamma  ` e ; hae b; ae

0iE : ae0

This system has two problems. First, although we can coerce types we cannot
coerce their binding-time annotations (except for type int). Second, the axiom

AED _g ?D means if we want to forget the structure of a type, the binding time
of the whole structure must be dynamic. Taken together, we find that a value
which is used at type ? anywhere in the program is annotated as dynamic in
the whole program, even in places were its type is known. In consequence, we
gain nothing compared to the global equational analysis.

Define aet for an annotated type ae by

AED

t = ?D

int0

t = int0 ae1 !

0 ae2t = ae1t !0 ae2t

ae1 \Theta 0 ae2

t = ae

1t \Theta 0 ae2t.

Lemma 12. Any annotated translation \Gamma  ` e ; E : ae in the global inclusionbased system gives rise to a translation \Delta t; \Gamma t ` e ; E : aet in the global equational system with partial types.

Proof. Induction on the structure of a translation.
Theorem 13. The translations induced by global inclusion-based BTA and by
global equational BTA with partial types are identical.

Proof. Lemma 12 gives us for each inclusion-based translation an equational
translation which achieves the same effect. The other implication is obvious as
each derivation in the system of simple recursive types without subtyping is
trivially also a derivation in the system with subtyping.

?

0 _l ae ae _l ae AED _l ?D ae1 _

l ae

2 ae2 _l ae3

ae1 _l ae3

fi ^ fi

0

intfi _l intfi

0

ae

0

1 _l ae1 ae2 _l ae

0
2 fi ^ fi

0 wft ae

1 !fi ae2 wft ae

0

1 !fi

0 ae0

2

ae1 !fi ae2 _l ae

0

1 !fi

0 ae0

2

ae1 _l ae

0

1 ae2 _l ae

0
2 fi ^ fi

0 wft ae

1 \Theta fi ae2 wft ae

0

1 \Theta fi

0 ae0

2

ae1 \Theta fi ae2 _l ae

0

1 \Theta fi

0 ae0

2

Fig. 10. Combined Type and Binding-Time Coercion Relation

3.2 Local Variant
In the local view, we adopt the position that every subexpression has its own
type automaton and its own annotation. The annotations of neighboring types
are related using bt coercions on top of the type coercions. In fact, the only
change is in the coercion rules for type constructors. Now they can increase
the binding time of the constructed value. Figure 10 defines the combined bt
and type coercion relation _l. The additional power with respect to the global
equational system stems from coercions like ae _l ?D, which coerces a value of
a sensible type to a dynamic type error. In the equational system, the ? type
would have spread its dynamic binding time beyond the cause of the error.

3.3 Comparison of the Inclusion-Based BTAs
In this section we compare the power of the global and local variants of inclusionbased BTA. We have already proved that global inclusion-based BTA is equivalent to global equational BTA (see Theorem 13). Again, in the inclusion-based
framework, any global annotation can be considered a local annotation. Hence, it
is clear that the local variant cannot yield worse results than the global variant.
Our previous example term (1) demonstrates that the inclusion is proper.

let f = *z:z in f@((if0 0 f g)@0). (6)
For the assumption g : ?D the results of global and local equational BTA coincide (cf. (2)):

letD f = *Dz:z in f@D((if00 0 f g)@D(lift 0)) (7)
However, the local inclusion based variant produces (cf. 4)

let0 f = *0z:z in f@0((if00 0 (*Dw:f@0w) g)@D(lift 0)), (8)
where we can perform more reductions statically.

(*w:w)@0 (9)
Hence the following lemma.
Lemma 14. The local inclusion-based BTA produces strictly better results than
its global counterpart.

3.4 Comparison of the Equational and Inclusion-Based BTAs
Finally, we need to compare the local variants of the equational and the inclusionbased frameworks. Every type derivation of the equational system is also a type
derivation of the inclusion-based system, without type coercions. To show that
the inclusion is proper we consider the term

let g = *x:x in let f = *z:g in (f@0)@f@g@0 (10)
The local inclusion-based BTA constructs the completion

let0 g = *0x:x in let0 f = *0z:g in (f@00)@0f@0g@00
which reduces statically to 0. In contrast, the local equational BTA yields

letD g = *Dx:x in let0 f = *0z:g in (f@00)@Df@0g@D0
which reduces statically to

let g = *x:x in g@(g@0)

4 Related Work
Here, we only discuss additional work that has not been discussed in the body
of the paper.

Mogensen [25] was the first one to consider BTA based on recursive types.
His motivation was typing Y in order to unfold fixpoints statically. Gomard's
system assigns type ?D to Y , thus it defers all occurrences of Y to run time.

Palsberg and Schwartzbach [30] compare BTAs based on abstract interpretation (ai) with type-based BTAs. They show that their ai-based approach is
more powerful than Mogensen's approach [25] which is more powerful than Gomard's [14] approach. In view of the current work, the latter is not surprising
because more terms are typable in the presence of recursive types. Due to the
result of Heintze, Palsberg, and O'Keefe [17,29] we conjecture that their ai-based
algorithm is equivalent to the local inclusion-based system presented here.

The ML partial evaluator Pell-Mell [24] employs a BTA based on set-based
analysis [16]. There are significant parallels between set-based analysis and the
simple type system with subtyping and recursion [17]. These parallels again
suggest that the BTA of Pell-Mell is also equivalent to the local inclusion-based
system presented here.

Launchbury [22] considers BTA based on projections. This BTA has parallels
with our equational system, but appears to be more restrictive because it insists
on uniform properties of recursive types.

The present author [34] has considered a BTA augmented with representation
analysis that removes some of the restrictions of the current BTA frameworks
and keeps track of additional information. This work can be recast in the present
framework by including additional layers of annotations.

Solberg, in her PhD thesis [33], gives a general overview of the use of annotated type systems in program analysis. She considers BTA in the style of
Nielson and Nielson [27]. She shows how that particular analysis fits into the
general framework, but does not compare different alternatives for BTA and her
work is not geared towards partial evaluation.

Nielson and Nielson [28] give a systematic description of different multi-level
lambda-calculi using algebraic methods. Their interest lies in the different wellformedness criteria for expressions. In our current work, we are concerned with
combining different type systems with different annotation strategies. The wellformedness criterion of expressions remains fixed.

5 Conclusions
With the exception of the work of Palsberg and Schwartzbach [30], BTAs have
lead fairly separate lives. They could not be compared because they relied on
different frameworks (abstract interpretation, type inference, set-based analysis,
projections, and so on). We have constructed a general BTA framework based
on annotated type systems that allows such comparisons in a clean and simple
way. Beyond that, our systematic approach has identified three novel BTAs.

Acknowledgements Thanks to Olivier Danvy and Dirk Dussart for discussions
on higher-order coercions and type-based program analysis.

References

1. R. M. Amadio and L. Cardelli. Subtyping recursive types. ACM Trans. Prog.

Lang. Syst., 15(4):575-631, 1993.
2. L. Birkedal and M. Welinder. Binding-time analysis for Standard-ML. In

P. Sestoft and H. So/ndergaard, editors, Proc. ACM SIGPLAN Workshop on Partial Evaluation and Semantics-Based Program Manipulation PEPM '94, pages 61-
71, Orlando, Fla., June 1994. ACM.
3. A. Bondorf. Automatic autoprojection of higher order recursive equations. Science

of Programming, 17:3-34, 1991.
4. A. Bondorf and J. Jo/rgensen. Efficient analysis for realistic off-line partial evaluation. Journal of Functional Programming, 3(3):315-346, July 1993.
5. C. Consel. Binding time analysis for higher order untyped functional languages.

In LFP 1990 [23], pages 264-272.
6. C. Consel. Polyvariant binding-time analysis for applicative languages. In

D. Schmidt, editor, Proc. ACM SIGPLAN Symposium on Partial Evaluation and
Semantics-Based Program Manipulation PEPM '93, pages 66-77, Copenhagen,
Denmark, June 1993. ACM Press.
7. C. Consel and O. Danvy. Tutorial notes on partial evaluation. In Proc. 20th Annual ACM Symposium on Principles of Programming Languages, pages 493-501,
Charleston, South Carolina, Jan. 1993. ACM Press.
8. O. Danvy. Type-directed partial evaluation. In Proc. 23rd Annual ACM Symposium on Principles of Programming Languages, pages 242-257, St. Petersburg,
Fla., Jan. 1996. ACM Press.
9. O. Danvy, K. Malmkjaer, and J. Palsberg. The essence of eta-expansion in partial

evaluation. Lisp and Symbolic Computation, 8(3):209-227, July 1995.
10. O. Danvy, K. Malmkjaer, and J. Palsberg. Eta-expansion does The Trick. Technical Report BRICS RS-95-41, Computer Science Dept., Aarhus University, Denmark, Aug. 1995.
11. R. Di Cosmo and D. Kesner. Simulating expansions without expansions. Mathematical Structures in Computer Science, 4:1-48, 1994.
12. D. Dussart, F. Henglein, and C. Mossin. Polymorphic recursion and subtype qualifications: Polymorphic binding-time analysis in polynomial time. In Mycroft [26],
pages 118-136. LNCS 983.
13. R. Gl"uck and J. Jo/rgensen. Fast multi-level binding-time analysis for multiple

program specialization. In PSI '96 [31].
14. C. K. Gomard. Partial type inference for untyped functional programs. In LFP

1990 [23], pages 282-287.
15. C. K. Gomard and N. D. Jones. A partial evaluator for the untyped lambdacalculus. Journal of Functional Programming, 1(1):21-70, Jan. 1991.
16. N. Heintze. Set-based analysis of ML-programs. In Proc. 1994 ACM Conference

on Lisp and Functional Programming, pages 306-317, Orlando, Florida, USA, June
1994. ACM Press.
17. N. Heintze. Control-flow analysis and type systems. In Mycroft [26], pages 189-

206. LNCS 983.

18. F. Henglein. Efficient type inference for higher-order binding-time analysis. In

J. Hughes, editor, Proc. Functional Programming Languages and Computer Architecture 1991, pages 448-472, Cambridge, MA, 1991. Springer-Verlag. LNCS 523.
19. J. E. Hopcroft and J. D. Ullman. Introduction to automata theory, languages and

computation. Addison-Wesley, 1979.
20. N. D. Jones, C. K. Gomard, and P. Sestoft. Partial Evaluation and Automatic

Program Generation. Prentice Hall, 1993.
21. N. D. Jones, P. Sestoft, and H. So/ndergaard. An experiment in partial evaluation:

The generation of a compiler generator. In J.-P. Jouannaud, editor, Rewriting
Techniques and Applications, pages 124-140, Dijon, France, 1985. Springer-Verlag.
LNCS 202.
22. J. Launchbury. Projection Factorisations in Partial Evaluation, volume 1 of Distinguished Dissertations in Computer Science. Cambridge University Press, 1991.
23. Proc. 1990 ACM Conference on Lisp and Functional Programming, Nice, France,

1990. ACM Press.
24. K. Malmkjaer, O. Danvy, and N. Heintze. ML partial evaluation using set-based

analysis. In Record of the ACM-SIGPLAN Workshop on ML and its Applications,
number 2265 in INRIA Research Report, pages 112-119, BP 105, 78153 Le Chesnay
Cedex, France, June 1994.
25. T. AE. Mogensen. Self-applicable partial evaluation for pure lambda calculus. In

C. Consel, editor, Proc. ACM SIGPLAN Workshop on Partial Evaluation and
Semantics-Based Program Manipulation PEPM '92, pages 116-121, San Francisco,
CA, June 1992. Yale University. Report YALEU/DCS/RR-909.
26. A. Mycroft, editor. Proc. International Static Analysis Symposium, SAS'95, Glasgow, Scotland, Sept. 1995. Springer-Verlag. LNCS 983.
27. F. Nielson and H. R. Nielson. Two-Level Functional Languages. Cambridge University Press, 1992.
28. F. Nielson and H. R. Nielson. Multi-level lambda-calculi: an algebraic description.

In O. Danvy, R. Gl"uck, and P. Thiemann, editors, Partial Evaluation, volume 1110
of Lecture Notes in Computer Science, pages 338-354, Dagstuhl, Germany, Feb.
1996. Springer Verlag, Heidelberg.
29. J. Palsberg and P. O'Keefe. A type system equivalent to flow analysis. In

Proc. 22nd Annual ACM Symposium on Principles of Programming Languages,
pages 367-378, San Francisco, CA, Jan. 1995. ACM Press.
30. J. Palsberg and M. I. Schwartzbach. Binding-time analysis: Abstract interpretation versus type inference. In IEEE International Conference on Computer Languages 1994, pages 289-298, Toulouse, France, 1994. IEEE Computer Society Press.
31. PSI-96: Andrei Ershov Second International Memorial Conference, Perspectives of

System Informatics, volume 1181 of Lecture Notes in Computer Science, Novosibirsk, Russia, June 1996. Springer-Verlag.
32. H. Seidl. Least solutions of equations over N . In Proc. International Conference of

Automata, Languages and Programming, ICALP '94, volume 820 of Lecture Notes
in Computer Science, pages 400-411. Springer-Verlag, 1994.
33. K. L. Solberg. Annotated Type Systems for Program Analysis. PhD thesis, Odense

University, Denmark, July 1995. Also technical report DAIMI PB-498, Comp. Sci.
Dept. Aarhus University.
34. P. Thiemann. Towards partial evaluation of full Scheme. In G. Kiczales, editor,

Reflection'96, pages 95-106, San Francisco, CA, USA, Apr. 1996.