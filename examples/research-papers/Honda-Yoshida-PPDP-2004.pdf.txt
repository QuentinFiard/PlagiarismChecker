

A Compositional Logic for Polymorphic Higher-Order Functions

Kohei HondaDepartment of Computer Science
Queen Mary, London
kohei@dcs.qmul.ac.uk

Nobuko YoshidaDepartment of Computing
Imperial College London
yoshida@doc.ic.ac.uk

Abstract
This paper introduces a compositional program logic for higher-order polymorphic functions and standard data types. The logic

enables us to reason about observable properties of polymorphicprograms starting from those of their constituents. Just as types
attached to programs offer information on their composability soas to guarantee basic safety of composite programs, formulae of
the proposed logic attached to programs offer information on theircomposability so as to guarantee fine-grained behavioural properties of polymorphic programs. The central feature of the logic is asystematic usage of names and operations on them, whose origin is
in the logics for typed p-calculi. The paper introduces the programlogic and its proof rules and illustrates their usage by non-trivial
reasoning examples, taking a prototypical call-by-value functionallanguage with impredicative polymorphism and recursive types as
a target language.
Categories and Subject Descriptors: F.3.1 [Specifying and Ver-ifying and Reasoning about Programs]:Assertions, Logics of programs, Specification techniques
General Terms: Language, Theory, Verification

1. Introduction
Types and Assertions. In modern functional programming lan-guages such as ML and Haskell [27, 17, 9], as well as in recent
object-oriented languages [23, 29], types are positioned as a keyelement of abstraction in programming. Types in these languages
offer a basic compositional specification, in the sense that a com-posite program can be assigned a type if, and only if, its constituent
programs can be assigned types and, moreover, the latter are mu-tually consistent with each other following a certain rule (for instance, if we wish to apply N to M, we require M has type a ) band N has type a for some a and b). Once a type is assignable to
a program, we know, for example, it never runs into a constructorerror, and that it would evaluate, if ever, to a value of that type, statically guaranteeing the fundamental safety property of programs.

Permission to make digital or hard copies of all or part of this work forpersonal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copiesbear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specificpermission and/or a fee.
PPDP'04, August 24-26, 2004, Verona, Italy.Copyright 2004 ACM 1-58113-819-9/04/0008 ...$5.00.

Useful as they are, types have basic limitation as specifications,in that they cannot describe (hence cannot guarantee) fine-grained
behavioural properties of programs. A type can indicate, for exam-ple, a given program is a function from natural numbers to natural
numbers: but there is no way to say it is a function which, for exam-ple, transforms an even number to an odd number, or, for that matter, any number to its factorial. A significant merit of treating onlya basic safety property is that a verification of type conformance of
a given program is in many cases computationally feasible. But ifwe wish to certify more general behavioural properties, types alone
cannot serve the purpose.The present work introduces a simple assertional method for
compositional specification of behavioural properties of higher-orderprograms and data types. Assertions are associated with two typed
interface points of a typed program, namely its environment anditself, strictly following type information. Just as types attached to
programs offer information on their composability so as to guaran-tee basic safety of composite programs, formulae attached to programs offer, in the present framework, information on their com-posability so as to guarantee fine-grained behavioural properties of
polymorphic programs. The logical discipline is cleanly stratifiedon the top of a type discipline, extending specifiable properties to
encompass essentially arbitrary observable properties of programs.One of the central elements of the presented program logic is a systematic usage of names and operations on them. This feature comesfrom a theory of logics for typed p-calculi developed in [21], which
is essentially a typed variant of Hennessy-Milner logic [18], andwhich offers a general basis for a family of program logics through
embeddings of the latter in the former. The relationship betweenthe program logics and the process logics is detailed in [22, 21].

Let us briefly illustrate the essence of the proposed assertionalmethod using simple examples.

Basic Ideas. Consider a simple program which computes a doubling function, N def= lx.x + x, with type N)N where N is the typefor natural numbers. The type of N represents an abstract specification of this program, saying that if we apply a value of N, then itreturns (if ever) a value of type N; but if we apply a value of other
types, it guarantees nothing. Thus a function can guarantee a typeof the resulting value only relying on types of its arguments.

We extend the same compositional reasoning to more generalbehavioural properties, using Hoare-style assertions [19, 16]. Take
the same N above; we observe that, if we apply 5 to N, then itreturns 10; more generally if we apply any natural number to N, it
always returns even. And in more detail, it returns the double of anarbitrary argument whenever the latter is well-typed, that is as far
as it is a natural number. Thus this function can guarantee a certainbehaviour by relying on the property of the argument. We wish to

represent these behavioural properties using logical formulae. Todo this, we do not mention N itself in a formula, but rather describe
its properties by naming it as, say, f (any fresh name will do). Thuswe can write

f * 5 = 10 (1)
as a property of N (named as f ). Similarly we can write

8xN.Even( f * x) (2)
where Even(n) is the predicate saying n is even (for example we
can set Even(x) def= 9n.(x = 2 * n)). The operator * is left associa-tive and non-commutative, which is best understood as the application in applicative structures. We can further refine the formula tosay f computes the doubling function. Formulae may be combined
using arbitrary standard logical connectives and quantifiers, just asin Hoare Logic.

Using these formulae (which we let range over A,B,...), thejudgement of the logic has the following shape.

A ` M : f B
which can be read as:

If M, named as f , can rely on A as the behaviour ofan environment, then the function combined with the

environment can guarantee B.
The name f is called anchor, which can be any fresh name not oc-curring in M. An anchor is used for representing the point of operation, hence of specification, of M. Intuitively the above judgementcorresponds to a Hoare triple {A}M{B} where A is about the free
variables of M and B is about f which is the name given to M.This idea - naming functions and programs - naturally comes from
encodings of functions into the p-calculus [26, 28] where functionM is mapped into an agent [[M]]

f equipped with unique name, fto be referred and shared by other agents. Reflecting its processtheoretic origin, the specification method regards programs as in-teractive entities [26] whose specifications are given via interrogating its behaviour one by one. As an example, we can write downthe specification for N as:

T ` N : f 8xN.Even( f * x) (3)
which says that the program N named as f , under the trivial as-sumption

T on its free variables, satisfies 8xN.Even( f *x) (the triv-iality of the assumption is because no free variables occur in M: the

truth T in general indicates the weakest specification allowing anywell-typed behaviour).

Let us present further examples of assertions, starting from asimple assertion for the identity function.

T ` lxN.x :u 8yN. u * y = y. (4)
The judgement says that the given program, when applied to anyargument of type N, will return that same argument as a result.

When this function is applied to the argument, u * y is peeled-offand replaced by a new anchor name m.

T ` (lxN.x)2 :m m = 2 (5)
Let us take a brief look at how we can compositionally derive (5).We first need the predicate for the argument.

` 2 :z z = 2 (6)
which simply says that "2" as a program satisfies, when named asz, the predicate z = 2. We then infer:

(4), (6), (8yN. (u * y = y) ^ z = 2) oe u * z = 2

T ` (lxN.x)2 :m m = 2

In the above derivation (which follows the proof rule for applica-tion, formally discussed in Section 4 later), the predicate in the
conclusion, "m = 2", is obtained by substituting "m" for "u * z"in the conclusion part of the entailment in the antecedent. Note
this entailment is a simple instance of the standard axiom in thepredicate logic with equality, (A(x

,x) ^ x = y) oe A(x,y) (cf. [25,$2.8]). While validity of such entailment is in general incalculable,

it is calculable using simple axioms in this case as well as in manypractical examples. The nature of the above derivation may become
clearer by contrasting it with the corresponding typing derivation.

` lxN.x : N)N ` 2 : N`

(lxN.x)2 : N

Here, instead of calculating validity of entailment, we simply matchthe first N of the function's type N ) N with the argument's type

N, obtaining N. In correspondence with simpler specification, wehave only to use simpler, and essentially mechanical, inference.

Next we consider an example which uses a non-trivial assump-tion on a higher-order variable.

8xN.Even( f * x) ` f 3 + 1 :u Odd(u) (7)
where Odd(n) says n is odd. Using the same environment, we canfurther derive:

8xN.Even( f * x) ` f 3 + f ( f 5) + 1 :u Odd(u) (8)
By using name f , the term which contains multiple f can share thesingle specification in the environment. The derivation of (7) and

(8) starts from the following instance of the axiom for a variable.

8xN.Even( f * x) ` f :m 8xN.Even(m * x) (9)
The specification says that if we assume 8xN.Even( f * x) for theentity which a variable f denotes, then f as a program named as m

satisfies precisely the same property (substituting m for f ). Startingfrom (9), we can easily reach (7) and (8), using the rule for application as well as a similar rule for first-order operations (all of whichare later presented in Section 4).

Let L def= f 3+ f ( f 5)+1 and recall N def= lx.x +x before. We nowconsider the following specification.

T ` let f = N in L :u Odd(u) (10)
The "let" construct has the standard decomposition into abstractionand application, but has a special status in the present context in that

its derivation clearly describes how we can "plug" a specificationof a part into a specification of a whole (just as in the cut rule in the
sequent calculus). The derivation of (10) follows.

(3), (8), 8xN.Even( f * x) oe 8xN.Even( f * x)

T ` let f = N in L :u Odd(u) (11)

Note the third condition in the antecedent is a trivially valid tautol-ogy. In this tautology, the first 8xN

.Even( f * x) is the conclusion of(3) while the second one is the assumption of (8): thus the property

which is guaranteed by N is simply plugged into the assumptionfor L. This derivation may be understood as being analogous to
a composition rule of Hoare Logic, where we infer {A}P1;P2{B}from {A}P

1{C1} and {C2}P2{B} such that C1 oe C2. (11) may alsobe contrasted with the type derivation for the same program.

` N : N)N f : N)N ` L : N`

let f = N in L : N (12)

which has a shape isomorphic to (11). Further examples of asser-tions and derivations are found in later sections.

As we already mentioned, the extensive use of names in thesespecifications and their derivations comes from the underlying pcalculus logic. Cumbersome as they may look, their use allows usto reason about programs and data structures of diverse kinds on a
uniform basis, of which the present paper will focus on purely func-tional ones. Among others we shall treat function types, products,
sums, recursion (in terms and in types), and second-order poly-morphism (both universals and existentials). Here we only show
a simplest example, taking a specification of the universal identity,\Lambda 

X.lxX.x : 8X.X ) X, leaving other examples to Sections 3 and 4.

8X.8xX.(u * [X] * x = x). (13)
The assertion says that the universal identity named as u, when itis applied to any type a and any well-typed argument y of type a,

will return that argument itself as a result.
Summary of Contributions. Some of the possible contributionsof the present paper would be:

* Introduction of an assertional method for specifying prop-erties of polymorphic higher-order programs and data types,

taking a prototypical call-by-value higher-order polymorphiclanguage as an example.

* Compositional proof rules for the proposed assertional method,ensuring total correctness. As far as we know, this is the first

such system for higher-order polymorphic languages.*
Discussions on how the presented method may be used forreasoning about behaviours of programs in higher-order languages and data types, with extensive examples.
It may be worth stressing that the assertional method discussed inthe present paper cleanly extends to call-by-name evaluation, imperative procedures as well as data structures with destructive up-date. Such extensions are detailed in [21].

Related Work. The intersection type disciplines [11, 5, 13, 38]offer one of the most general ways to specify behaviours of programs among various type systems for functions (they are also ap-plied to non-functional calculi recently, cf. [12, 24]). Apart from
the fact that they have mainly been studied for untyped calculi,there are two main differences from the presented framework. First,
specifications in intersection types are based on conjunction andentailment of a specific kind, whereas the logical language in the
present framework allows the full use of standard logical connec-tives. Second, the properties expressible in intersection types are
certain closed sets in the corresponding CPOs, whereas formulaein the presented logic essentially encompass arbitrary observable
properties of programs. This second point also applies to Abram-sky's domain logic [4], which has a close connection with intersection type disciplines, even though the domain logic is richer in typestructures.

Equational logics for the l-calculi have been studied since theclassical work by Curry and Church. LCF [14] augments the standard equational theory of the l-calculus with Scott's fixed pointinduction. The program logics for higher-order functions derived
from process logics differ in that an assertion in the former de-scribes behavioural properties of programs rather than equates them,
allowing specifications with arbitrary degrees of precision, as wellas smoothly extending to non-functional behaviour.

The reasoning methods for polymorphic l-calculi have been stud-ied focusing on the principles of parametricity, either using equational logics [34, 2] or using logical relations [1, 39, 32, 33]. Thepresented method differs in that it offers behavioural specifications

for interface of a program, rather than directly equating/relatingprograms. It should however be noted that, for calculating validity
of entailment, the present method does need to make resort to se-mantic arguments for polymorphic behaviours. This suggests fruitful interplay between the present logical method, on the one hand,and the reasoning principles as developed in, and extending, [34, 2,
39, 32, 33, 1], on the other.Reynolds [35] develops a specification logic for Algol, extending
Hoare Logic with treatment of higher-order procedures. In additionto basic differences in the constructions of formulae and judgement,
the use of the assumption on free variables in the present logic leadsto compositional proof rules, unlike in [35].

Reynolds, O'Hearn, Bornat and their colleagues [36, 37, 30, 8,10] study extensions of Hoare's Logic with an aim to offer an effective reasoning method for low-level operations, including pointers,memory allocation/deallocation, and garbage collection. A central
idea of their approach is to explicitly assume a dynamically allo-cated region of memory cells in the universe of discourse, and reason about them based on a conjunction which at the same time im-plies disjointness of such regions. The present framework is cleanly
extensible to impure higher-order procedures as well as shared datastructures with destructive update [21]. It would be an interesting
subject of study to integrate the methods for low-level reasoning ascultivated through their studies with the present framework.

Finally, as we already noted, the origin of the present work isin the logic for typed p-calculi. [22, 21, 20] discuss in detail the
theory of process logics for sequentially typed processes, togetherwith their relationship to the program logics.

Structure of the Paper. Section 2 reviews the syntax and opera-tional semantics of the polymorphic PCF used in the paper; Section 3 introduces the assertions and its semantics; Section 4 definesthe proof rules; Section 5 shows non-trivial reasoning examples;
Section 6 concludes the paper with further topics. The extensivediscussions on the general framework of the logics, including the
presentation of its imperative and other extensions, the soundnessproofs, detailed comparisons with related work, as well as connections to the corresponding process logics, are found in [20, 21, 22].
2. Call-by-Value Polymorphic PCF
2.1 Syntax and Typing
As a target language, we choose the call-by-value PCF with unit,sums and products, extended with universal and existential secondorder polymorphism as well as recursive types [31, 15, 40]. Apartfrom the treatment of recursive types (which relies on implicit type
conformance for simplicity of associated proof rules), all constructsare standard. Our presentation essentially follows Pierce's recent
textbook [31] (many program examples are also from his book).We first list the grammar of programs, assuming an infinite set of
term variables (sometimes called names) as well as an infinite setof type variables (

X, Y,...). Below let i range over {1,2}.

M ::= () | n | b | x | lxa.M | MN | uxa)b.lya.M|

if M then N1 else N2 | op(~M) | hM1,M2i|
pi(M) | ini(M) | case M of {ini(xaii ).Ni}i2{1,2}|
\Lambda X.M | Mb | pack hb,Mias9X.a|
unpack M ashX,xiin N
V ::= () | n | b | x | lxa.M | ua)b.lya.M| h

V1,V2i | ini(V) | \Lambda X.V | pack hb,V ias9X.a

M,N,... denote general terms (sometimes called programs), while

V,W,... denote values. The grammar uses types (a,b,...) whichare given later. Binding etc. are standard.

fv(M)/ftv(M) denotes aset of free variables/type variables. Bound variables are annotated

by types, though in examples we often omit them. n stands fornon-negative numerals (1,2,...) and b for booleans (t, f). () is unit.
We often use c for constants. op(M0,...,Mn-1) denotes an n-aryarithmetic and boolean operation. Among others we consider the
unary operations succ(M) (the successor) and ~M (the negation)and binary operations M + N, M - N, M * N, M = N (equality of
two numbers), M ^ N and M . N. We use the standard weak call-by-value one-step reduction [15, 40], written M -! M0. We only
list the main rules for universals and existentials.

(\Lambda X.M)b -! M[b/X]
unpack (pack hb,Vias 9X.a)ashX,xiin N -! N[b/X][V /x]

Types, ranged over by a,b,..., are generated from:

a ::= Unit | B | N | a)b | a * b | a + b |

X | 8X.a | 9X.a | uX.a

Again binding is standard. Unit, B and N are called atomic types.The typing judgements have the form \Gamma  ` M : a, where \Gamma  is a base,

which is a finite map from variables to types. Well-typed terms arederived from the rules in Figure 1 (only part of constants and operators are treated, which are easily extended to other cases). All rulesare standard: in the rules for polymorphism, the constructors (type
abstraction and pack) and the destructors (type concretion and un-pack) compensate with each other. In the rule for recursive type
(based on the equi-recursive approach [31]), ss denotes the treeequivalence of two types, which in particular includes the standard
(un)folding, uX.a ss a[uX.a/X]. We often write M\Gamma ;a to denotea typable term M such that we have \Gamma  ` M : a. We shall call the
language PolyPCFv.
2.2 Programming Examples
In the following we explore the expressiveness of PolyPCFv usingsimple programs, which are later used as running examples. As a

simple instance of the universal abstraction, we take the standarduniversal identity.

` \Lambda X.lxX.x : 8X.X ) X. (14)
To use this identity, we instantiate it with a type and feed a value ofthat type:

((\Lambda X.lxX.x)N)2 -! (lxN.x)2 -! 2. (15)
The second example is Church's Polymorphic Booleans.

tru = \Lambda X.lxX.lyX.x fls = \Lambda X.lxX.lyX.y (16)
Each function takes two arguments and returns one of them. Weassign a common type to

tru and fls assuming two arguments havethe same type, but this type may be arbitrary since

tru and fls donot use their arguments except return one of them. Then we can

write boolean operations like not by constructing a new booleanthat uses an existing one to decide which of its arguments to return.

Let Bool def= 8X.X ) X ) X below.

` lb : Bool.\Lambda X.ltX.l f X.b X f t : Bool )Bool (17)
The third example is a type for a list of elements of type a, usingrecursive types.

List(a) def= uY.(Unit + (a * Y)). (18)
The empty list is represented by in1(()), while the list which con-sists of a head M (of type a) and a tail L (of type

List(a)) becomes

[Var] -\Gamma , x:a ` x : a [Unit] -\Gamma  ` () : Unit

[Num] -\Gamma  ` n : N [Bool] -\Gamma  ` b : B

[Succ] \Gamma  ` M : N\Gamma  ` succ(M) : N [Eq] \Gamma  ` M1,2 : N\Gamma  ` M1 = M2 : B
[Abs] \Gamma ,x:a ` M : b\Gamma ,x:a ` lxa.M : a)b [App] \Gamma  ` M : a)b \Gamma  ` N : a\Gamma  ` MN : b

[Rec] \Gamma ,x : a)b ` lya.M : a)b\Gamma  ` uxa)b.lya.M : a)b

[If] \Gamma  ` M : B \Gamma  ` N1,2 : a\Gamma  ` if M thenN1 elseN2 : a
[Inl] \Gamma  ` M : a1\Gamma  ` in1(M) : a1+a2 [Inr] \Gamma  ` M : a2\Gamma  ` in2(M) : a1+a2

[Case] \Gamma  ` M :a1+a2 \Gamma , xi : ai ` Mi :b\Gamma  ` case M of {ini(xi).Mi}i2{1

,2} : b

[Pair] \Gamma  ` Mi : ai (i = 1,2)\Gamma  ` hM1,M2i : a1*a2 [Proj] \Gamma  ` M :a1*a2\Gamma  ` pi(M) : ai (i = 1,2)

[T-Abs] \Gamma  ` M : a X 62 ftv(\Gamma )\Gamma  ` \Lambda X.M : 8X.a [T-App] \Gamma  ` M : 8X.a\Gamma  ` Mb : a[b/X]

[T-Pack] \Gamma  ` M : a[b/X]\Gamma  ` pack hb,Mias9X.a : 9X.a
[T-Unpack] \Gamma  ` M : 9X.a \Gamma  * x:a ` N : b X 62 ftv(\Gamma )[ftv(b)\Gamma  ` unpack M as hX,xiin N : b

[T-Rec] \Gamma  ` M : a a ss b\Gamma  ` M : b
Figure 1: Typing Rules for PolyPCFv

in2(hM,Li), which is of type List(a) by Unit + a * List(a) ss
List(a). A list can be infinite, e.g. ux.in2(h1,xi) is an infinite listof 1 and has type

List(N). In our subsequent discussions we oftentreat lists. For legibility we use the following notations.

[e] def= in1(()), [M :: L] def= in2(hM,Li).
As is well-known, it is often convenient to treat lists generically,i.e. without depending on its types. In such situations, we can use

the polymorphic list type 8X.List(X). A simple example is thegeneric cons function:

\Lambda X.lxX.llList(X).[x :: l]. (19)
A little more complex example is a program which calculates thelength of a list of an arbitrary type.

\Lambda X.u f List(X))N.llList(X).

case l of isNil ) 0 | isCons(x,l0) ) f (l0) + 1 (20)

Above we use "case l of isNil ) M | isCons(x,l0) ) N" whichstands for

case l of{in1(z).M |in2(y).((lxl0.N)p1(y))p2(y)} (z,y fresh)

Yet another example which uses a polymorphic list is a programwhich filters out elements of a list that satisfy a given predicate.

` \Lambda X.l f X)B.filter( f ) : 8X.(X )B))List(X))List(X)(21)
where filter( f ) is the following expressions:

ug.ll.case l of isNil )[e]|

isCons(x,y))if f (x) then [x :: g(y)] else g(y).

We end our brief exploration with a simple use of existential ab-straction. Below we use records, which are in the present case simply a labelled version of products.

pack hN,{new : l().0, inc : lx.x + 1, get : lx.x}i
as 9X.{new : Unit ) X, inc : X ) X, get : X )N} (22)

where l().M is a thunk which formally stands for lxUnit.M withx 62

fv(M). The type represents an abstract data type for a counter,which has three methods: "

new" exports an opaque integer, "inc"increments it, and "
get" turns an opaque value to the correspond-ing non-opaque value.

3. Assertions for PolyPCFv
3.1 Syntax
In this section we introduce formulae and judgement for a programlogic for

PolyPCFv, illustrate them by examples, and present theirsemantics. As in the standard Hoare logic, a specification for a

program can be either about total correctness (where non-trivial as-sertions always guarantee termination) or about partial correctness
(where divergence allows arbitrary specifications). These two, to-gether with a third one which subsumes both, are discussed in detail
in [21]. In the present paper we focus on the logics for total cor-rectness, which allows a most straightforward presentation, both in
syntax and semantics. The presentation places a particular empha-sis on the type-oriented nature of the logic.

Terms and Formulae. A judgement in the present logic uses apair of first-order logical formulae to describe behavioural properties of typed functionals. Formulae are made up from equations onterms and their combinations by standard logical connectives. The
grammar of a language for the total logic for PolyPCFv follows.

e ::= xa | () | n | b | op(e1,..,en) | ?a | e1 * e2

| he1,e2i | pi(e) | ina+bi (e) | e * [b] | hb,ei9X.a
A ::= e1 = e2 | ~A | A1 ^ A2 | A1 . A2 | A1 oe A2| 8

x.A | 9x.A | 8X.A | 9X.A

The first set of expressions (e,e0,...) are called terms, while thesecond ones (A

,B,C .. .) formulae. Terms contain variables, whichwe often call names. They also include constants such as unit (),

natural numbers n and booleans b. op indicates a first-order opera-tion (usually carried over from the target programming language).
?a denotes divergence with type a, which is seldom used in spec-ifications but is needed for semantic completeness. We write e +
for e 6= ?. e1 * e2 is an application of e1 and e2 where * is left as-sociative and non-commutative. Terms also includes the standard
arithmetic operators. The first three terms in the second line areparing, projection and injection, respectively. The last two forms
of terms are a type application for polymorphic universal type andpacking for existential type, respectively. Operationally e * [b] corresponds to Mb, while hb,ei corresponds to a packed pair.

In formulae, logical connectives are used with their standardprecedence/association: e.g. A ^ B oe 8x

.C . D oe E is parsed as(A ^ B) oe (((8x
.C) . D) oe E). A j B denotes A and B are logicallyequivalent. As far as no confusion arises, we use these connectives

both syntactically (i.e. as connectives in formulae in program log-ics) and semantically (i.e. for discussing validity of various kinds).
We also use the truth T (definable as, for example, 1 = 1) and thefalsity

F (which is ~T). T and F also denote boolean values. Thequantifications induce binding, for which we assume the standard

bound name convention. fv(A)/ftv(A) denotes the set of free vari-ables/type variables in A.

Below we define the well-typed expressions and formulae.
Definition 3.1 (well-typedness in terms)

* (), n, b, xa and ?a are well-typed with types Unit, N, B, aand a, respectively.

* e1 * e2 is well-typed with type b if e1,2 are well-typed withtypes a)b and a, respectively.

* ~e is well-typed with type B, if e is well-typed with type B.e

1 + e2 is well-typed with type N if e1,2 are well-typed withtype N. Similarly for

succ, *, -, etc.* h

e1, e2i is well-typed with type a1 *a2 if e1,2 are well-typedwith types a

1,2. p1(e) is well-typed with type a if e is well-typed with type a * b, similarly for p

2(e).*

ina+b1 (e) is well-typed with type a+b if e is well-typed with
type a. Similarly for ina+b2 (e).*
e * [b] is well-typed with type a[b/X] if e is well-typed withtype 8

X.a. hb,ei9X.a is well-typed with type 9X.a if e iswell-typed with type a[b

/X].

A is well-typed if whenever a variable/name occurs twice they ownthe same type and each pair of equated terms have the same type.

Hereafter we only consider well-typed terms and formulae and omittype annotations if no ambiguity arises (or if ambiguity does not
matter).
Judgement. There are two forms of the judgement, one for se-mantic validity and another for syntactic derivability.

A |=M\Gamma ;a :u B, A ` M\Gamma ;a :u B
In both forms of sequents, we assume \Gamma  ` M : a and u 62 fn(\Gamma ). Theprimary names in A are those in

dom(\Gamma ), while the primary nameof B is u. Other names occurring in A and B are auxiliary. Then free

names in A (resp. in B) should be typed under \Gamma  * \Theta  (resp. u : a * \Theta )for a common \Theta , which is a map from the auxiliary names to types.
Each sequent can be read as:

for any closed values of types \Gamma  satisfying A, the resultof substituting them for variables in M leads to the behaviour satisfying B, under an arbitrary interpretationof auxiliary names in A and B.

Later we shall formalise this idea, first by defining semantics forvalidating the first form of sequent and, secondly, by introducing
proof rules for deriving the second form of sequent. The term as-sertion is sometimes used for formulae used in a judgement, as well
as for a judgement itself.
3.2 Examples of Assertions
We first recall several examples from Introduction. First,

Even(y) = 9xN. (yN =2 * x)

is the standard predicate which says y is even, while:

Double(u) = 8nN.(uN)N * n=2 * n)
says that a function u always returns double of the argument, whichis satisfied by, for example, lx

.x + x. The following entailment isvalid with respect to semantics of formulae given later.

Double(u) oe 8yN.Even(uN)N * y).
Next we recall another example from Introduction:

ID(u) def= 8X.8xX.u8X.X)X * [X] * x = x .
This is an assertion for the universal identity \Lambda X.lxX.x, which meansthat the given program, when it is applied to any type a and any

well-typed argument y of type a, will return that argument as a
result. In contrast, IDN(u) def= 8xN.(uN)N * x = x) is an assertionsatisfied by the monomorphic identity lxN

.x. These two assertionsare related in the following way:

9m.(u = m * [N] ^ ID(m)) j IDN(u)
As a simple example of sums and products, let us define A(m) def=9y0z0

.(m = hin1(y0),z0i ^ Even(y0) ^ Odd(z0)). Then we have, forexample, A(h

in1(y),zi) oe Even(y).A list can be encoded into product and sums with recursive types.

Thus we can reason about a list using in1(()) and in2(hM,Li) asencodings of the nil [e] and the cons [M :: L], respectively. However having terms for the list as such in assertions, written [e] (for
in1(())) and [e :: e0] (for in2(he, e0i)), is convenient, especiallywhen we reason about complex programs which process lists. As

an example, using these notations, we can define a derived predi-cate for the well-foundedness (i.e. finiteness) of a list as follows.

Wf (l) j 9nN.Len(l,n).
Len(l,0) j l =[e].
Len(l,n + 1) j 9x,l0.l = [x :: l0] ^ x 6= ? ^ Len(l0,n).

Next, we recall the program cntr in (22) in Section 2.

pack hN,{new : l().0, inc : lx.x + 1, get : lx.x}i
as 9X.{new : Unit ) X, inc : X ) X, get : X )N}

The following is a specification for this program before packing,named as w (we use a labelled projection

l(e)).

9yX,zX.(y = new(w) * () ^ z = inc(w) * y ^ get(w) * z>=1)
A more readable specification may use a notation that combines anapplication and a projection, writing e

.l(e0) for (e.l) * (e0).9

yX,zX.(w.new()=y ^ w.inc(y)= z ^ w.get(z)>=1)
Now we consider the data hiding. Let:

C(u, X) def= 9wa, yX,zX.(u=hX,wi ^ D(w,y,z))
D(w,y,z) def= w.new()=y ^ w.inc(y)=z ^ w.get(z)>=1

We write C(hX,xi, X) for C(u, X)[hX,xi/u]. Then:* 9

X.C(u, X) hides a concrete type of an ADT, giving a speci-fication of the packed program above with anchor u.

* In contrast, C(hX,xi, X) opens an ADT, under which, forexample, l()

.x.get(x.inc(x.new())) with anchor u satisfiesu * () >= 1.

Using these predicates in intermediate steps, we shall later showthe following unpacked program, with anchor u, satisfies u*() >= 1.

unpack cntr as hX,xi in l().x.get(x.inc(x.new()))

3.3 Semantics of Assertions
Below we define semantics of assertions taking a quickest path,using congruence classes of

PolyPCFv (for further discussions onmodels, including those based on typed processes, see [21]). We

use the standard typed congruence. Suppose \Gamma  ` M1,2 : a. Then\Gamma  ` M

1 ,=l M2 : a iff, for each closing C[Mi] of type N, we haveC[M
1] + iff C[M2] + where M + means 9N.M -!* N 6-!.

Model. Let k,k0,... range over the ,=l-congruence classes of typedclosed terms, which we call behaviours. We write ka if k is of type
a. Then for each type a, there is a unique congruent class of thediverging terms, which we write ?a or simply ?. If k 6= ?, we say
k is a total behaviour. A model x is a well-typed finite map from
names to total behaviours. Given ka)b1 and ka2 , k1 * k2 is given asthe congruence class including MN for M 2 k

1 and N 2 k2. Sim-ilarly, given k8X.a and b, k * [b] is given as the congruence class

including Mb for M 2 k. Then given ka[b/X] and b, hb,ki is givenas the congruence class including

pack hN,Mias9X.a for M 2 k.Arithmetic operations etc. are similarly defined.

Satisfaction. Fix auxiliary names and type variables in A. Aninterpretation I maps auxiliary names to both total and non-total
behaviours, as well as type variables to closed types (the formershould be consistent with the latter). Given a model x and an interpretation I , the map [[e]]I*x is defined by induction on e as follows:

* [[c]]I*x = c, [[?]]I*x = ? and [[x]]I*x = (I [ x)(x).

* [[e * e0]]I*x = [[e]]I*x * [[e0]]I*x

* [[e + e0]]I*x = [[e]]I*x + [[e0]]I*x, similarly for others.

* [[he,e0i]]I*x = h[[e]]I*x, [[e0]]I*xi, [[pi(e)]]I*x = pi([[e]]I*x) and

[[ini(e)]]I*x = ini([[e]]I*x).

* [[e * [b]]]I*x = [[e]]I*x * [b] and [[hb,ei]]I*x = hb,[[e]]I*xi
The satisfaction of A by a model x under an interpretation I , writtenx |=I A, is given by induction on the structure of A. We start from:

x |=I e1 = e2 j [[e1]]I*x = [[e2]]I*x
Logical connectives are given the standard (classical) interpretation(below connectives on the right-hand side are about validity):

x |=I A1 ^ A2 j (x |=I A1) ^ (x |=I A2)x |

=I ~A j ~ (x |=I A)x |
=I 8xT .A j 8c 2 T. x |=I*x:c A,x |=I 8

xa.A j 8k 2 [[a]]. x |=I*x:k A,x |
=I 8X.A j 8a. x |=I*x:a A

where, in the second last line, [[a]] denotes the set of all behavioursof type a. The rest is de Morgan duality. We then write k |=I

u A(read: k with anchor u satisfies A under I ) when u : k |=I A (u : k is

a mode which maps u to k). Finally with M closed, M |=Iu A stands
for 9k. (M 2 k ^ k |=Iu A). We also write ~x : ~V |=I A for ~x :~k |=I Awith V

i 2 ki. We can now define:

Definition 3.2 (semantics of assertions) A |= M~x:~b;a :u B iff, under
each well-typed I and for each ~V~b such that ~x :~V |=I A, we have
M[~V /~x] |=Iu B.

Note that, by definition, if we have A |=M :uB for A such that A 6j F,it always holds M +. Also note the validity of A is far from being

effectively calculable since the logic properly extends the standardnumber theory (thus, for example, true formulae in the present logic
are not recursively enumerable). This does not, however, precludethe construction and use of compositional proof rules for the logic,
where the calculation of validity is often reduced to mechanicalinferences. The compositional proof system for valid assertions is
not only important for verifications: it offers a fundamental insighton the nature of each construct of the language. This is the theme
of the next section.
4. Proof Rules for PolyPCFv
This section introduces proofs rules for PolyPCFv including de-rived rules. The shape of each rule naturally follows that of the

corresponding typing rule (except structural rules which only ma-nipulate formulae), making the reasoning principle compositional.
We recall, from Section 3.1, that the main sequent for provabilityhas the form:

A ` M\Gamma ;a :u B
where \Gamma  ` M : a and names in A and B should be well-typed (asspecified in Section 3.1). The well-typedness demands, among others, u never occurs in A, and free variables in \Gamma  never occur in B.We often call A and B the rely formula and the guarantee formula,
respectively. Variables which occur in \Gamma  are the primary names inA, u is the primary name in B while names which occur in A and B
but not in dom(\Gamma ) [ {u} are auxiliary names. These notions play akey role in the consistency of the proof rules.

The proof rules are listed in Figure 2. In each rule, we assumeall assertions are well-typed and a primary name and auxiliary
names are never mixed in sequents in the antecedent. Symbolsi

, j,... exclusively range over auxiliary names. In the following weillustrate each proof rule one by one.

First-Order Rules. We start from the basic rules: [Var] says that,if something can be said about what x denotes in the environment,
then the same thing can be said about x as a term, named as u. Sim-ilarly for [Const] and [Succ]. For arithmetical/boolean operations,
we have, for example:

[Add] A ` M :v B1 A ` N :w B2 (B1 ^ B2) oe B[v + w/u]A ` M + N :u B
Similarly for the equality operator:

[Eq] A ` MN :v1 B1 A ` NN :v2 B2 (B1 ^ B2) oe B[v1=v2/b]A ` M =N :b B
?From these rules one can guess the general form of the proof rulefor an n-ary operator (of which constants and unary/binary operators are special cases), given as [Op] in Figure 2. The rule assumes
op also appears as a term constructor in the logical language.Next we move to the proof rule for the conditional, which says

that, under A, if a boolean term M (named as b) satisfies A0, and Bholds for (1) N

1 under the assumption A0 holds and (2) N2 under theassumption A0 does not hold, then, again under A, surely B holds

for if M then N1 elseN2.

[If] A ` M :b A0 A ^ A0[T/b] ` N1 :u B A ^ A0[F/b] ` N2 :u BA ` if M then N1 else N2 :u B
Note the rule keeps clean symmetry, as in the corresponding rulein Hoare logic. Observe also b 62

fv(A) by the well-formednessof A ` M :

b A0. Another observation is that A ` M :b A0 indicates(as far as A is non-trivial) M terminates. Thus, in a closed term,

the conditional branch can surely be evaluated, reaching one of Ni,which in turn is guaranteed to terminate and satisfies B.

[Var] -A[x/u] ` x :u A [Const] -A[c/u] ` c :u A

[Succ] A ` M :v B[v+1/u]A ` succ(M) :u B
[Op] A ` Mi :mi Bi (1 <= i <= n) (^iBi) oe B[op(m1,..,mn)/u]A ` op(M1,..,Mn) :u B
[If] A ` M :b A0 A ^ A0[T/b] ` N1 :u B A ^ A0[F/b] ` N2 :u BA ` ifM then N1 elseN2 :u B

[Abs] A

-x~i ^ Ax1 `M :m A2 8x~i.(A1 oe A2[u * x/m] ) oe B

A `lx.M :u B

[App] A `M :m B1 A `N :x B2 B1 ^ B2 oe B[m * x/u] ^ m * x+A `MN :u B

[Rec] A ` ly.M :u B(0) A ^ B(i)[x/u] ` ly.M :u B(i + 1)A ` ux.ly.M :u 8i.B(i)

[Consequence] A oe A0 A0 ` M :u B0 B0 oe BA ` M :u B
[Pair] A ` Mi :mi Bi B1 ^ B2 oe B[hm1,m2i/u]A ` hM1,M2i :u B
[Proj1] A ` M :m B[p1(m)/u]A ` p1(M) :u B [In1] A ` M :m B[in1(m)/u]A ` in1(M) :u B

[Case] A ` M :m E A

-~x^ E[ini(xi)/m] ` Ni :u B

A ` case M of {ini(xi).Ni} :u B

[T-Abs] A

-X ` M :m B

A ` \Lambda X.M :u 8X.B[u*[X]/m]

[T-App] A ` M :m 8X.B[m*[X]/u]A ` Mb :u B[b/X]

[T-Pack] A ` M :m B[hX,mi/u][b/X]A ` pack hb,Mias9X.a :u 9X.B
[T-Unpack] A ` M :m 9X.E A

-xX ^ E[hX,xi/m] ` N :u B

A ` unpack M as hX,xiin N :u B

[T-Rec] A0 ` M :m B0 A0 ss A B0 ss BA ` M :m B

Figure 2: Proof Rules for PolyPCFv

Proof Rules for Higher-Order Functions. We now move to threeof the key rules for

PolyPCFv-logic, abstraction, application andrecursion. Below recall Ax indicates the only primary name in A is

x,~i means a (possibly empty) vector of names, while A-x~i says nonames from x~i occur in A.

[Abs] A

-x~i ^ Ax1 `M :m A2 8x~i.(A1 oe A2[u * x/m] ) oe B

A `lx.M :u B
The rule says that, whenever M named as m satisfies A2 relyingon A (which is not about x) and A

1 (which is about x), then lx.Mnamed u has the behaviour such that, whenever u is given x satisfying A1, it returns the result (u * x) which satisfies A2 for m. This

rule can be decomposed into:

[Abs-sub] A ` M :m B, i freshA[i/x] ` lx.M :u B[m * i/u]

[oe] A ^ B ` M

\Gamma ;a :u C, fv(B)"fv(\Gamma )= /0

A ` M\Gamma ;a :u B oe C
However we prefer [Abs] because of their convenience in reasoning.The provability does not differ in the presence of [oe] and [Aux-8]

(which is given later). Next we look at the rule for application.

[App] A `M :m B1 A `N :x B2 B1 ^ B2 oe B[m * x/u] ^ m * x+A `MN :u B
The rule says that, if M, named as m, satisfies B1, and N, namedas x, satisfies B

2, and B1 and B2 say that m applies to x converges(recall m * x+ stands for m * x 6= ?, cf.$ 3.1), then MN named as u

satisfies B whenever B is a consequence of B1 and B2 where, in thelatter, the returned value u is replaced by m * x.

Related to the above two proof rules, it is instructive to examinethe rule for the

let construct.

[Let] A ` M :x A0 A ^ A0 ` N :u BA ` let x = M in N :u B .
The rule can be derived from [Abs] and [App] via the standard translation, let x = M in N def= (lx.N)M. Note x cannot occur in A sincex is an anchor.

Proof Rules for Recursion. Below n is a fresh variable of N-type.

[Rec] A

-x ` ly.M :u B(0) A ^ B(n)[x/u] ` ly.M :u B(n + 1)

A ` ux.ly.M :u 8n.B(n)
Under A, the term satisfies, without assuming anything about x,already B(0) (where B( * ) is a formula with a hole). The term also

satisfies, if we assume B(n) for x in addition to A, B(n + 1). So weexpect it satisfies B(n) for each n. It is also notable that the

letrecconstruct, with the standard operational semantics [15], has a clean

proof rule. Below let V have an arrow type.

[Letrec]

A ` V [y/x] :x E(0)
A ^ E(n)[y/x] ` V[y/x] :x E(n+1)

A ^ 8n.E(n) ` M :u B

A ` letrec x = V in M :u B

Structural Rules. We list the consequence rule and the two asso-ciated rules for auxiliary names (there are other natural structural
rules which we omit).

[Conseq] A oe A0 A0 ` M :u B0 B0 oe BA ` M :u B

[Aux-8 ] A

-i ` M :u B

A ` M :u 8i.B [Aux-9 ] A ` M :u B

-i9
i.A ` M :u B

To put the consequence rule to real use (as well as all other ruleswhich use validity of formulae), we may as well use inference rules

for the underlying semantic structure, in addition to the standardrules for predicate calculus with equality and number theory. Three
basic rules are given as follows:

(ext) 8y.e1 * y = e2 * y oe e1 = e2
(?-*) ? * e = ? e * ? = ?
(?-op) op(e1,..,?,..,en) = ?

All are easily justifiable from the underlying model given in $ 3.3(for further account of such axioms see [21, $ 10]).

Sum and Products. The rules for sum and products in Figure 2should be understood as [Op] and [If]. Note how the introduction of
constructors and destructors in programs is directly reasoned usingthe corresponding constructs (terms) in assertions.

Products and sums are naturally extended to their labelled ver-sions, records and variants. For example, records add the term of
the form {li : ei} and e.l, interpreted as (labelled) products and theirprojection. The proof rules become:

[Record] A ` Mi :mi Bi ^ Bi oe B[{li : mi}/u]A ` {li : Mi} :u B

[Sell] A ` M :m B[m.l/u]A ` M.l :u B
Polymorphism and Recursive Types. Finally we explain the rulesfor the second order polymorphism. [T-Abs] and [T-App] in Figure
2 are similarly explained as [Abs] and [App], respectively. Here wefocus on the packing and unpacking rules for 9.

[T-Pack] A ` M :m B[hX,mi/u][b/X]A ` packhb,Mias 9X.a :u 9X.B
The rule says that, if Ma[b/X], named as m, satisfies B[hb,ma[b/X]i/u],then

pack hb,Mias9X.a named u satisfies 9X.B (we remind thath

b,ea[b/X]i means a packed expression whose type is 9X.a). Notethat we create a packing M of b by replacing a pack of its anchor

name m and X by fresh anchor name u (note the essentially sametechnique is used in the rule for paring, [Pair]).

[T-Unpack] is defined symmetrically as follows.

[T-Unpack] A ` M :m 9X.E A

-xX ^ E[hX,xi/m] ` N :u B

A ` unpack M as hX,xiin N :u B
The rule says that, if M named as m satisfies 9X.E and N namedas n satisfies B with m packed as h

X,xi, then the resulting termsatisfies B. Unpacking is simply handled by an instantiation of a

pack of x and X. Intuitively here hiding is ensured by linking onename in a pack by another name in another pack. In the rule for
recursive types, [T-Rec], A ss A0 denotes, as before, two formulaeare identical except for substituting occurrences of ss-related types.
We can also use the extensionality of operators for e*e0, e*[a], andhe

,e0i and the entailment 8X.A oe A[a/X] and A[a/X] oe 9X.A.

Soundness. We conclude this section with the key property ofthese proof rules, their soundness with respect to the semantics
of assertions. This can be established via embedding into the p-calculus, following three steps:

* We first translate PolyPCFv-terms into the second-order poly-morphic p-calculus preserving types. Then we prove equational full abstraction up to the contextual coungruences, us-ing the method in [6, 7].

* Secondly, we translate PolyPCFv-assertions into those of thesecond-order polymorphic p-calculus. Then we prove the

logical full abstraction of the translation (i.e. a PolyPCFv-formula is valid iff the translation is valid in the corresponding process logic. [21].*
Finally, since the process logic satisfies the soundness [20],
we can prove, for each ~V~b such that ~x :~V |=I A, we have
M[~V /~x] |=Iu B via the translation of terms and formulae [21].

Since the logic for the p-calculus is with much fewer constructs,this gives a transparent proof. The details are found in [21, 20].

Theorem 4.1 (soundness) A ` M :u B implies A |=M :u B.

5. Reasoning Examples
This section illustrates the use of proof rules introduced in the pre-vious section by a few non-trivial reasoning examples. We also

introduce a couple of derived rules which can directly reason high-level data structures.

Universal Identity. We first infer the property of the universalidentity. This is a simplest example to demonstrate how we can use
an algebra of names and type variable and compose specifications.For legibility, we often reuse the anchor name. Recall (14):

` \Lambda X.lxX.x : 8X.X ) X.
for which we infer:

1. T ^ x = l ` x :m m=l (Var)
2. T ` lxX.x :u 8xl.(x = l oe uX)X * x = l) (Abs)
3. T ` lx.x :u 8xX.(uX)X * x = x) (Conseq)
4. T ` \Lambda X.lxX.x :u 8X.8xX.((u8X.X)X * [X]) * x = x) (T-Abs)

The resulting assertion says that \Lambda X.lxX.x is a polymorphic func-tion named as u which takes two arguments, arbitrary type

X andvalue with type
X, and just returns the value as it is. Recall (15).?From the above inference we can infer:

5. T ` (\Lambda X.lxX.x)N :u 8xN.(uN)N * x = x) (T-App)
6. T ` ((\Lambda X.lxX.x)N)3 :u u = 3 (App, Conseq)

Next we infer an assertion with a non-trivial assumption. We startfrom Line 4 in the preceding inference, and infer as follows.

50. T ` (\Lambda X.lxX.x)N :u 8xN.(uN)N * x = x) (T-App)
60. Even(y) ` y + 1 :m Odd(m) (Var,Op,Conseq)
70. Even(y) ` ((\Lambda X.lxX.x)N)(y + 1) :w Odd(w) (App,Conseq)

Line 70 is derived from the following inference.

(8x.u * x = x ^ Odd(m)) oe (u * m = m ^ Odd(m))j

(w = m ^ Odd(m))[u * m/w]

Since (w = m ^ Odd(m)) oe Odd(w), this satisfies the side condi-tion of

(App), (B1 ^ B2) oe B[u * m/w], hence we reach Line 70.

Convention 5.1 In the following inferences we allow free vari-ables of a program to occur in the guarantee formula in a sequent,
with the same semantics as Definition 3.2 except "M[~V /~x] |=Iu B"
in the definition is replaced by "M[~V /~x] |=I*~x:~Vu B". The proof rulesstay precisely the same.

While the strict usage of names as we have been obeying so far doesnot lose generality, the new convention above is useful for making
the reasoning shorter, especially in complex examples.
Church's Polymorphic Booleans. Next recall Church Polymor-phic Booleans whose type is

Bool = 8X.X ) X ) X and the notfunction.

tru = \Lambda X.lxX.lyX.x fls = \Lambda X.lxX.lyX.y`

lb : Bool.\Lambda X.ltX.l f X.b X f t : Bool )Bool

We first infer the property of tru as follows.

1. T ` xX :u u = x (Var)
2. T ` lyX.xX :u 8yX.uX)X * y = x (Abs)
3. T ` lxX.lyX.xX :u 8xX.8yX.uX)X)X * x * y = x (Abs)
4. T ` tru :u 8X.8xX.8yX.uBool * [X] * x * y = x (T-Abs)
The specification exactly represents the polymorphic truth. Simi-larly we can specify

fls by swapping x and y. Let us denote booleanspecification as:

BTru(u) = 8X.8xX.8yX.uBool * [X] * x * y = x

BFls(u) = 8X.8xX.8yX.uBool * [X] * x * y = y

Now we infer the property of not. We define:
BNot(u) = 8b.((BTru(b) oe BFls(u*b)) ^ (BFls(b) oe BTru(u*b)))
which means if it gets the truth, then it returns the false and if itgets the false, then it returns the truth.

1. BTru(b) ` b :m BTru(m) (Var)
2. BTru(b) ` b X :m 8yX.8xX.m * y * x = y (T-App)
3. BTru(b) ` b X y :m 8xX.m * x = y (App)
4. BTru(b) ` b X yx :m m = y (App)
5. BTru(b) ` ly.b X yx :m 8y.m * y = y (Abs)
6. BTru(b) ` lx.ly.b X yx :m 8x.8y.m * x * y = y (Abs)
7. BTru(b) ` lX.lx.ly.b X yx :m BFls(m) (T-Abs)
8. T ` not :u 8b.(BTru(b) oe BFls(u * b)) (Abs)
9. T ` not :u BTru(b) oe BFls(u * b) (Conseq)
Symmetrically we can infer:

T ` not :u BFls(b) oe BTru(u * b)
Now we apply the following derived proof rule to 9 and the above.

[And] A ` M :u Bi (i = 1,2)A ` M :u B1 ^ B2
Noting b is an auxiliary variable, an application of [Aux-8 ] givesus the following desired proof.

T ` not :u BNot(u)
Polymorphic Recursive Function and Lists. Recall the program
filter( f ) which filters a list using a function f : X ) B, given in(21). The following program takes off all occurrences of 0 from a

list of natural numbers using filter( f ).

elimZero def= ((\Lambda X.l f X)B.filter( f ))N)(lxN.x 6= 0).
We can easily see this program does not terminate if an argument isan infinite list. Thus, to prove total correctness, we should specify

that a given list is well-founded and finite, and that each elementterminates. We define this and other related notions as derived
predicates.

Wf (l) j 9nN.Len(l,n).
Len(l, 0) j l = [e].
Len(l,n + 1) j 9x,l0. l =[x :: l0] ^ x 6= ? ^ Len(l0,n).

One of the natural specifications for elimZero is given as:

ElimZero(u) def= 8lList(N). (Wf (l) oe A(u,l) ^ B(u,l)) (23)

where we set:

A(u,l) def= l =[e] oe u * l =[e].
B(u,l) def= l =[x :: y] ^ x 6= ? oe (x 6= 0 oe u * l =[x :: u * y])^(x = 0 oe u * l = u * y).

The predicate ElimZero(u) (on u of type List(N))List(N)) saysthat, assuming an integer list is well-founded, applying the list to u
would result in another integer list which is the same as the originalone except that each 0 in the list is eliminated one by one. Our aim
is to prove:

T ` elimZero :u ElimZero(u). (24)
To derive (24), the key step is to infer the following generic asser-tion for the program

filter( f ).

T ` filter( f ) :u 8l. Filter(u, l, f ) (25)
where Filter(u, l, f ) says u * l is the result of filtering l by f :

Filter(u,l, f ) def= Wf (l) oe A(u, l) ^C(u, l, f ) (26)
where C(u,l, f ) is defined as follows:

l =[x :: y] ^ x 6= ? oe ( f * x = T oe u * l =[x :: u * y])^( f * x =

F oe u * l =u * y).

Once we have (25), we can reach (24) as follows.

1. T ` filter( f ) :u 8l. Filter(u, l, f ) (Assumption)
2. T ` l f .filter( f ) :u 8 f ,l. Filter(u * f ,l, f ) (Abs)
3. T ` \Lambda X.l f .filter( f ) :u 8X.8 f ,l. Filter(u * [X] * f ,l, f ) (T-Abs)
4. T ` (\Lambda X.l f .filter( f ))N :u 8 f , l. Filter(u * f ,l, f ) (T-App)
5. T ` lx.(x 6= 0) : f NonZero( f ) (Var, Num, Eq, Abs)
6. T ` ((\Lambda X.l f .filter( f ))N)(lx.x 6= 0) :u ElimZero(u) (4, 5, App)
In Line 5, NonZero( f ) stands for:

8x.((x = 0 oe f * x = F) ^ (x = n >= 1 oe f * x = T).
Then in Line 6, we calculate the assertions as:

8l. Filter(u * f ,l, f ) ^ NonZero( f ) oe ElimZero(u * f ).
We now derive (25). The derivation is, as usual, divided into thebase case and the induction. For reasoning, we first note the following inductive definition of the filter predicate.

Filter(u,l, f ) j 8nN.(Len(l,n) oe Fil(l, f ,u * l,n))

Fil(l, f ,l0,0) def= l = l0
Fil(l, f ,l0,n+1) def= (l =[e] oe l0 =[e]) ^(l = [x :: y] ^ x 6= ? oe

( f * x = T oe9y0

.(l0 = [x :: y0] ^ Fil(y, f ,y0,n)))^( f * x =

F oe Fil(y, f ,l0,n))

The equivalence with (26) is immediate by induction on the lengthof a list. We also let:

M def= case l of isNil ) [e] | isCons(x, y) ) N
N def= if f (x) then [x :: g(y)] else g(y)

Note filter( f ) def= ug.ll.M. We also use the following abbreviationsfor brevity.

E(n)(u) j 8l.(Len(l,n) oe Fil(l, f ,u * l,n))

[Nil] -A[[e]/u] ` [e] :u A
[Cons] A ` M :m B1 A ` L :l B2 B1^B2 oe B[[m::l]/u]A ` [M :: L] :u B

[List]

A ` M :m E A ^ E[[e]/m] ` N1 :u BA ^ E[[x :: l]

/m] ` N2 :u B
A ` case M of isNil ) N1 | isCons(x,l) ) N2 :u B

Figure 3: Proof Rules for Lists and Case

The base case follows.

1. l = [e] ` l :l0 l0 = [e] (Var)
2. [e] = [e] ` [e] :m m = [e] (Nil)
3. F ` if f (x) then [x :: g(y)] else g(y) :m m = [e] (falsity)
4. l =[e] ` M :m Fil(l, f ,m,0) (1,2,3,List)
5. T ` ll.M :m E(0)(m) (Abs)

In Lines 2 and 4, the derived proof rules for lists in Figure 3 areused where we assume [e] and [e :: e0] are included among the terms
in the logic (which formally stand for in1(()) and in2(he,e0i), re-spectively).

We move to the induction step. Below we use the followingabbreviations:

C(lxyn) def= l =[x :: y] ^ Len(y,n).
G( f xl0yn) def= ( f * x = T oe 9y0.(l0 =[x :: y0] ^ Fil(y, f ,y0,n))) ^

( f * x = F oe Fil(y, f ,l0,n))

A(lxyngT) def= E(n)(g) ^C(lxyn) ^ f * x = T

A(lxyngF) def= E(n)(g) ^C(lxyn) ^ f * x = F

Note G( f xl0ny) is the part of Fil(l, f ,l0,n+1) when the list is non-empty.

1. C(lxyn) ` l :l0 l0 = [x :: y] ^ Len(y,n) (Var)
2. F ` [e] :m E(n + 1)(m) (falsity)
3. T ` f (x) :b f * x = b (Var, Var, App)
4. A(lxyngT) ` g(y) :m f * x = T ^ Fil(y, f ,m,n) (Var, Var, App)
5. A(lxyngT) ` [x::g(y)] :mf * x ^ 9y0

.(m=[x::y0] ^ Fil(y, f ,y0,n)) (Cons)

6. A(lxyngT) ` [x::g(y)] :m G( f xmyn) (Conseq)
7. A(lxyngF) ` g(y) :m f * x = F ^ Fil(l, f ,m,n) (Var, Var, App)
8. A(lxyngF) ` g(y) :m G( f xmyn) (Conseq)
9. E(n)(g)^C(lxyn) ` N:mG( f xmyn) (3,6,8,If)
10. E(n)(g)^C(lxyn) ` M :m G( f xmyn) (1,2,9,List)
11. E(n)(g) ` ll.M :m 8lxy. (C(lxyn) oe G( f xmyn)) (10, Abs)
12. E(n)(g) ` ll.M:mE(n + 1)(m) (Conseq)

In the final line, we observe: 8lxy. (C(lxyn) oe G( f xmyn)) oe8

l. (Len(l,n+1) oe Fil(l, f ,m * l, n+1)) def= E(n + 1)(m). We can

[Object]

A-~yi~ji ^ E~yii ` Mi :mi Bi (8i 2 I)^

i8~yi~ji.(Ei ^ Bi[u.li(~yi)/mi]) oe BA ` {l

i(~yi) : Mi}i2I :u B

[Inv]

A ` M :m B A ` Ni :yi Bi^

iBi oe B[u.l(~yi)/m]

A ` M.l(~N) :u B

Figure 4: Proof Rules for Objects and Invocations

now combine the two conclusions, reaching (25).

1. T ` ll.M :m E(0)(m)
2. E(n)(g) ` ll.M :m E(n + 1)(m)
3. T ` ug.ll.M :m 8n.E(n)(m) (Rec)

We have now arrived at the assertion (25).
Abstract Data Type. The final example is a short inference forpacking and unpacking, using the counter ADT in (22). We consider programs written in a more convenient, object-like notation.
cntr is defined by pack hN, Mias9X.a and M is given as:

M def= hN,{new() : 0, inc(x) : x + 1, get(x) : x}i

a def= {new : e) X, inc : X ) X, get : X )N}.

(note the empty vector e has replaced what was () of Unit-typebefore). The target program is given as follows, writing e

.li(e0)for (e
.li) * (e0):

N def= unpack cntr as hX,xi in l().x.get(x.inc(x.new()))
Observe ` N : Unit )N. The assertion we wish to prove is:

T ` N :u u * () >= 1. (27)
We can reason for the above program using the rules for record andfield selection in Section 4, Page . However the reasoning becomes
much simpler if we use the proof rules which directly correspondto the above notation.1 The proof rules for objects and object invocations are given in Figure 4. In (Object), we assume methodsare indexed by i 2 I, where each method in an object would take a
distinct vector of typed arguments. Note the rule is a simple variantof the abstraction rule (and, dually, (Inv) the application rule).

For the derivation of (27), we use the following abbreviations.

C(u, X) def= 9wa,yX,zX.(u=hX,wi ^ D(w,y,z))
D(w,y,z) def= w.new()=y ^ w.inc(y)=z ^ w.get(z)>=1

Also let C(hX,xi, X) def= C(u, X)[hX,xi/u]. The derivation follows.

1In general, using the proof rules which precisely correspond to
the granularity of a given programming language is essential fortractable reasoning. See [21, $8] for the corresponding derivation

for the same assertion using the rules for record and field selection.

1. T ` M :m m.new()=0 ^ m.inc(0)= 1 ^ m.get(1)=1

(Num, Var, Add, Var, Object)

2. T ` M :m 9yN.zN.(hN, mi = hN,mi ^ D(m,y,z)) (Conseq)
3. T ` pack hN,Mias9X.a :m 9X.C(m, X) (T-Pack)
4. C(hX,xi, X) ` x.new() :m x.new() = m (Inv)
5. C(hX,xi, X) ` x.inc(x.new()) :m9y

.(x.new() = y ^ x.inc(y) = m) (Var, 4, Inv)

6. C(hX,xi, X) ` x.get(x.inc(x.new())) :m m >= 1 (Var, 5, Inv)
7. C(hX,xi, X) ` l().x.get(x.inc(x.new())) :u u * () >= 1 (Abs)
8. T ` N :u u * () >= 1 (3,7,T-Unpack)

?From Line 2 to Line 3, we apply the following logical equivalenceas the condition for [T-Pack].

C(m, X)[hX,xi/u][N/X] j 9yN.zN.(hN, mi = hN,mi ^ D(m,y,z))
6. Conclusion
In this paper we proposed an assertional method for specifyingand reasoning about polymorphic higher-order functions and data

types, together with associated compositional proof rules, and demon-strated their usage using non-trivial reasoning examples for polymorphic programs. A compositional program logic has a funda-mental status in many fields of software engineering, ranging from
the traditional specification and verification, to model checking, toprogram testing, to static and dynamic analyses of programs, and
to certification of mobile code. While being extensively studied forimperative programs, a clean treatment of higher-order computation in the compositional program logics, either for functional pro-gramming languages or procedural/object-oriented ones, may not
have been known so far. We believe the presented framework isone of the promising directions towards this goal.

Although not discussed in this paper for the space sake, the pre-sented method is extensible to diverse forms of typed behaviours,
including behaviours with global and local state, call-by-name eval-uation, user-defined data types and stateful objects, as well as to different notions of correctness including partial correctness. Further,in the total logics, valid logical judgements for a given program
precisely characterise its semantics up to the canonical congruence.These results are discussed in [21]. The use of typed processes as
the underlying semantic domain also enables a uniform treatmentof proof rules and calculation of validity.

The studies on compositional logics for higher-order computa-tion along the line of the present study have however just begun,
and many significant challenges remain before we can reach a com-prehensive theory of logical articulation of complex software behaviours, on the one hand, and a general and effective engineeringframework, on the other. Some of the notable challenges are: development of compositional logics for a fully fledged functionalprogramming language, such as ML [27] and Haskell [17], as well
as those for object-oriented languages (this would involve treat-ment of input/output, exceptions and concurrency); development of
practical notations for assertions as well as for proofs; non-trivialapplications of the developed logics, including their use in integrated development environments, certified mobile code, and for-mally founded version control; and the applications of the derived
program logics beyond standard verification/specification method-ologies. More theoretically, a significant challenge is to obtain an
in-depth understanding of the models of the presented logic and its

ramifications, which may also lead to tractable methods for calcu-lating validity in the logic besides that of number-theoretic facts.
Acknowledgement. The authors thank anonymous referees fortheir useful suggestions. Kohei Honda is partially supported by
EPSRC grant GR/S55545. Nobuko Yoshida is partially supportedby EPSRC grants GR/R33465 and GR/S55538.

References

[1] Abadi, M., ??-closed relations and admissibility, MSCS10(3) (June 2000), 313-320.

[2] Abadi, M., Cardelli, L., Curien, P.-L., Formal ParametricPolymorphism, TCS 121, 1-2, (Dec), 9-58. Elsevier, 1993.
[3] Abadi, M. and Leino, R. A logic for object-orientedprograms. Technical Report SRC-161, Compaq SRC, 1998.
[4] Abramsky, S., Domain Theory in Logical Form, Annuals ofPure and Applied Logic, 51:1-77, 1991.
[5] Barbanera, F., Dezani-Ciancaglini, M. and de'Liguoro, U.,Intersection and Union Types: syntax and semantics. Inf. and

Comp., 119:202-230, 1995.
[6] Berger, M., Honda, K. and Yoshida, N., Sequentiality and thep-Calculus, TLCA01, LNCS 2044, 29-45, Springer, 2001.

[7] Berger, M., Honda, K. and Yoshida, N., Genericity and thep-Calculus, FoSSaCs'03, LNCS 2620, 103-119, Springer,

2003.
[8] Bornat, R., Proving pointer programs in Hoare Logic.Mathematics and Program Construction, 2000.

[9] Caml Home Page, http://caml.inria.fr/.
[10] Calcagno, C., O'Hearn, P. and Bornat, R. Program logic andequivalence in the presence of garbage collection. TCS,

298(3):557-581, 2003.
[11] Coppo, M. and Dezani-Ciancaglini, M. An extension ofbasic functionality theory of lambda-calculus. Notre Dame

J. Formal Log. 21:685-693, 1980.
[12] Damiani,F., Dezani-Ciancaglini, M. and Giannini, P. A filtermodel for mobile processes. MSCS, 9(1):63-101, 1999.

[13] Dunfield, J. and Pfenning, F., Type Assignment forIntersections and Unions in Call-by-Value, FoSSaCs'03,

LNCS 2620, 250-266, Springer, 2003.
[14] Gordon, M., Milner, A. and Wadsworth, C., Edinburgh LCF,LNCS 78, Springer, 1979.

[15] Gunter, C., Semantics of Programming Languages:Structures and Techniques, MIT Press, 1992.
[16] Floyd, W. Assigning meaning to programs. Prc. Symp. inApplied Mathematics. 19:19-32, 1967.
[17] The Haskell home page, http://haskell.org.
[18] Hennessy, M. and Milner, R. Algebraic Laws forNondeterminism and Concurrency. Journal of ACM, 32:1,

pp.137-161, 1985.
[19] Hoare, C.A.R. An axiomatic basis of computerprogramming. CACM, 12:576-580, 1969.

[20] Honda, K., Sequential Process Logics: Soundness Proofs.Typescript, 50pp. November 2003. Available at:

www.dcs.qmul.ac.uk/~kohei/logics.
[21] Honda, K., Process Logic and Duality: Part (1) SequentialProcesses. Typescript, 234pp, March 2004. Available at:

www.dcs.qmul.ac.uk/~kohei/logics.
[22] Honda, K. From Process Logic to Program Logic. A shortversion of Sections 1-3 and 6 in [21]. ICFP'04, ACM, 2004.

[23] Java home page. Sun Microsystems Inc.,http://www.javasoft.com/, 1995.
[24] U. de' Liguoro, Characterizing convergent terms in objectcalculi via intersection types, TLCA'01, LNCS 2044.

Springer, 2001.
[25] Mendelson, E., Introduction to Mathematical Logic (thirdedition). Wadsworth Inc., 1987.

[26] Milner, R., Functions as Processes, MSCS. 2(2):119-141,1992,
[27] Milner, R., Tofte, M. and Harper, R.W, The Definition ofStandard ML, MIT Press, 1990.
[28] Milner, R., Parrow, J. and Walker, D., A Calculus of MobileProcesses, Info. & Comp. 100(1):1-77, 1992.
[29] Microsoft Corporation, .NET Framework Developer's Guide,

http://msdn.microsoft.com, 2003.

[30] O'Hearn, P., Yang, H. and Reynolds, J., Separation andInformation Hiding, POPL'04, 268-280, 2004.

[31] Pierce, B.C., Types and Programming Languages, MITPress, 2002.
[32] Pitts, A.M., Existential Types: Logical Relations andOperational Equivalence, Proceedings ICALP'98, LNCS

1443, 309-326, Springer, 1998.
[33] Pitts, A.M., Parametric Polymorphism and OperationalEquivalence, Mathematical Structures in Computer Science,

2000, 10:321-359.
[34] Plotkin, G. and Abadi, M., A Logic for ParametricPolymorphism, LICS'98, 42-53, IEEE Press, 1998.

[35] Reynolds, J. Idealized Algol and its specification logic. Toolsand Notions for Program Construction, 121-161, CUP.
[36] Reynolds, J. Intuitionistic Reasoning about Shared MutableData Structure, Millennial Perspectives in Computer Science,

2000, Palgrave.
[37] Reynolds, J., Separation logic: a logic for shared mutabledata structures. Invited Paper, LICS 2002.

[38] van Bakel, S., Intersection Type Assignment Systems. TCS,151(2):385-435, 1995.
[39] Wadler, P. Theorems for Free. Functional Programming andComputer Architecture, Adison Wesley, 1989.
[40] Winskel, G. The Formal Semantics of ProgrammingLanguages. MIT Press, 1993.
[41] Yoshida, N., Berger, M. and Honda, K., StrongNormalisation in the p-Calculus, LICS'01, 311-322, IEEE,

2001. A full version in Journal of Info. & Comp., 191 (2004)145-202, Elsevier.