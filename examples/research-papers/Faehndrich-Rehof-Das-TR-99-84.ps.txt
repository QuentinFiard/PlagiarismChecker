

From Polymorphic Subtyping to CFL Reachability:
Context-Sensitive Flow Analysis Using Instantiation

Constraints
Microsoft Research Technical Report MSR-TR-99-84

Manuel F"ahndrich Jakob Rehof Manuvir Das

March 2000

Abstract
We present a novel approach to computing context-sensitive flow of values through procedures and data structures. Our approach combines and extends techniques from two seemingly disparate areas: polymorphic subtyping and interprocedural dataflow analysis based
on context-free language reachability. The resulting technique offers several advantages over
previous approaches: it works directly on higher-order programs, provides demand-driven
interprocedural queries, and improves the asymptotic complexity of a known algorithm
based on polymorphic subtyping from O(n8) to O(n3) for computing all queries. For intraprocedural flow restricted to equivalence classes, our algorithm yields linear inter-procedural
flow queries.

Contents
1 Introduction 3

1.1 Constraint Copying Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.2 A New Method Based on Instantiation Constraints . . . . . . . . . . . . . . . 5
1.3 Situating the Analyses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
1.4 Context-Sensitivity in Higher-Order Programs . . . . . . . . . . . . . . . . . . 8
1.5 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.6 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

2 Flow Polymorphism 15

2.1 A Copy-based System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

2.1.1 Polymorphic Constrained Types . . . . . . . . . . . . . . . . . . . . . 15
2.1.2 Type Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
2.1.3 Flow Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.1.4 Flow Relation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.1.5 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.2 A CFL-based System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

2.2.1 Polymorphic Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.2.2 Type Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.2.3 Flow Graphs and Flow Queries . . . . . . . . . . . . . . . . . . . . . . 21
2.2.4 CFL Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.2.5 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.2.6 Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.2.7 Understanding Self-loops and Improved Algorithm . . . . . . . . . . . 30
2.2.8 Demand-driven Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.3 Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.4 Discussion and Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

2.4.1 Polymorphic Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . 37
2.4.2 Higher-Order Context-Sensitivity . . . . . . . . . . . . . . . . . . . . . 37
2.4.3 Precise Interprocedural Dataflow Analysis . . . . . . . . . . . . . . . . 39
2.4.4 Summarization in Context-Sensitive Analyses . . . . . . . . . . . . . . 40
2.4.5 Constraint Simplification . . . . . . . . . . . . . . . . . . . . . . . . . 40
2.4.6 Other Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

1

3 Flow and Type-Structure Polymorphism 42

3.1 CFL-Based Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

3.1.1 Type Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
3.1.2 Flow Queries in the Presence of Type Polymorphism . . . . . . . . . . 45
3.1.3 Practical Aspects of Constraint Generation . . . . . . . . . . . . . . . 47
3.2 POLYEQ: An Efficient Special Case . . . . . . . . . . . . . . . . . . . . . . . . 48

3.2.1 Type System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.2.2 Flow Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.2.3 Practical Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
3.3 Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

3.3.1 Non-Structural Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . 52
3.3.2 Recursive Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
3.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

4 Conclusions 56
A Soundness Proof 60

A.1 Overview of the proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
A.2 Normal Instantiation Contexts . . . . . . . . . . . . . . . . . . . . . . . . . . 62
A.3 Closure Under Substitution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
A.4 Normal Derivations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
A.5 Existence Of Normal Derivations . . . . . . . . . . . . . . . . . . . . . . . . . 71
A.6 Soundness Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

2

Chapter 1
Introduction
Answering queries of the form "Does any value appearing at program point `1 flow to program point `2" solves many static analysis problems such as finding potential pointer aliases,
determining possible targets of indirect function calls, and delimiting storage escapement.
This article studies efficient techniques to answer such queries in a context-sensitive manner,
i.e., without introducing spurious flow between different calling contexts.

From Types to Flow
We study the flow of program values in terms of flow paths on the type structure of a
program. To make this more concrete, assume that our program p is given such that each
subexpression e is labeled with a label ` as in e`. The queries we can ask of such a system are
all queries of the form "Is there flow from `1 to `2?", where `1 annotates some subexpression
e1 and `2 annotates some subexpression e2 of the entire program expression e. We answer
such queries by looking at the type o/1 and o/2 inferred for expressions e1 and e2. Types in
our system themselves have labels annotating all subcomponents, thus we find that some
label `01 annotates o/1 and some label `02 annotates o/2. We then ask whether there is flow
from `01 to `02 in a type instantiation graph that results from the type inference on p.

The choice of answering flow queries on the type structure of a program is quite natural
since sound type systems compute a conservative approximation of value flow. Without
subtyping nor polymorphism, this view leads to the following symmetric flow relation: If
e1 and e2 have the same type, then there is potentially flow from e1 to e2, and vice versa.
If their types differ, we know there is no flow.

Using standard types for flow leads to rather imprecise results. To improve the precision,
we label type constructors in order to distinguish unrelated occurrences of the same type.
For example, the distinct labeling of the argument and result type in the function type
int`1 ! int`2 indicates that the result is unrelated to the argument.

Another improvement in precision is obtained by treating flow as an asymmetric relation
through the introduction of subtyping. Given a function int`1 ! int`2 and an argument
int`0, standard language semantics state there is flow from the argument to the function
domain, not vice versa. In subtyping, this fact is expressed by requiring that the argument
type is a subtype of the domain type int`0 ^ int`1, which in turn is satisfied if `0 ^ `1.
The flow constraint `0 ^ `1 now expresses that values arising at expressions characterized
by types labeled `0 flow to expressions with types labeled by `1.

3

Precision is further improved by considering a context-sensitive flow analysis based on
polymorphic types. The focus of this article is the interaction between subtyping and
polymorphism.

Contributions
The main contributions of this article are:

ffl A novel algorithm for computing context-sensitive, directional flow information for

higher order typed programs. Our algorithm improves the asymptotic complexity of
the best known algorithm [Mos96] based on polymorphic subtyping from O(n8) to
O(n3).

ffl Our results are founded on a novel analysis of subtyping combined with instantiation (semi-unification) constraints including polymorphic recursion. Instantiation
constraints provide a graph-based interpretation of substitution, and the ensuing formulation of polymorphic subtyping via CFL-reachability leads to demand-driven and
purely graph-based implementation technology for type-based flow analysis.

ffl We transfer results on precise interprocedural dataflow analysis based on CFL-reachability [RHS95] to the setting of type-based analysis, resulting in an algorithm which
works directly on higher order programs with structured data.

ffl We also study the applicability of CFL-reachability for flow computation in the case

where the underlying type structure of programs is itself polymorphic (and not just the
labeling), as e.g., in ML-like languages. We show that no additional approximations
are necessary in this case and that flow queries are still computable in time O(n3).

ffl Our results open the door to new implementation techniques and engineering tradeoffs for flow analyses based on polymorphic subtyping systems. By obviating the need
to simplify and copy systems of subtyping constraints, our technique may circumvent
one of the main scaling inhibitors for such systems.

Many context-sensitive flow analyses based on function summaries (e.g. [CRL99, LH99,
FFA99]) are presented as two phase computations. In phase 0, information is propagated
from the callees (where it originates) to the callers. In phase 1, information is propagated
from callers back to callees. The information in the second step represents summary information for a callee from all contexts. In previous work, this phase distinction does not
encompass first-class functions (or function pointers), because uses of functions do not necessarily coincide with call sites in the presence of first-class functions. Our results show that
the phase distinction generalizes to first-class functions and is present on each individual
flow path, thus enabling fine-grained demand-driven algorithms without the need for two
global phases.

An Example
We now consider a very simple example program to show the principal difference of our work
to previous approaches. We assume here that the underlying types, which arise by erasing all
labels, are monomorphic but the type system is polymorphic over labels. Polymorphism is
introduced at let- and letrec-bindings. Occurrences of let- or letrec-bound symbols are
uniquely identified by indices i, as in f i. Indices i thereby single out individual instantiation

4

sites. Our framework is similar to the one studied in, e.g., [Mos96]. Detailed definitions are
given in Section 1.6.

Our example program e is as follows:

let id = *x:int`1.x`2
in

((idi 0`3)`4 , (idj 1`5)`6)
end

Here, we are interested in tracking the flow of constants 0 and 1 labeled with `3 and `5.

1.1 Constraint Copying Methods
All previous work in polymorphic subtype inference is based on qualified polymorphic types
of the form 8~`:C ) oe, where C is a set of captured subtyping constraints qualifying the type
oe. Since C may contain quantified labels from ~`, such an approach gives rise to copies of
the captured constraints at all instantiation sites for that type. A standard 1 polymorphic
constrained type (see, e.g., [Smi94, TS96, Mos96]) for id is 8`1`2:f`1 ^ `2g ) int`1 ! int`2.
In a copy-based framework, program e is typed by copying the constraint set f`1 ^ `2g
associated with id at each of the instantiation sites idi and idj, yielding the standard
polymorphic typing judgment

f`3 ^ `4; `5 ^ `6g; ; ` e : oe (1.1)
with oe = int`4 \Theta  int`6. Such a typing has four components, from left to right: a set of
subtype (or flow) constraints, a type environment (here empty), a term and a type. From
this typing we conclude that the value 0 (`3) flows to the first component of the resulting
pair (`4), and the value 1 (`5) flows to the second (`6). Polymorphism over labels, here
implemented via constraint copying, keeps the two instantiation sites apart, matching up
a call site (e.g., idi 0`3) with its proper return (`4). A monomorphic analysis, in contrast,
typically predicts, imprecisely, that either value (`3 or `5) flows to either return point (`4 or
`6).

The seeming need to copy subtype constraint sets at every distinct instantiation site has
been identified as a major problem, making it very difficult to scale polymorphic subtyping
to large programs. 2 The problem has generated a significant amount of research, including
work on constraint simplification, which aims at compacting constraint sets before they are
copied [FM89, Cur90, Kae92, Smi94, EST95, Pot96, TS96, FA96, AWP97, Reh97, FF97].
It is unlikely that constraint simplification techniques alone will solve this problem, and
complete simplification is a hard problem itself [Reh98, FF97].

1.2 A New Method Based on Instantiation Constraints
In this article, we tackle the constraint copying problem in a new way. Our starting point is
a new presentation of polymorphic subtyping, based on instantiation constraints, which we

1Function id can be given a most general typing without any subtyping constraints, but we choose the
present typing for illustrative purposes.

2The small size of the constraint set in our toy example is illusory in practice, of course.

5

call POLYFLOWCFL. Instead of constrained types 8~`:C ) oe, POLYFLOWCFL uses standard
quantified types of the form 8~`:oe, which are given meaning in combination with a global set
of constraints. Expression e from the example receives a typing of the formae

`1 _i\Xi  `3; `2 _i+ `4;
`1 _j\Xi  `5; `2 _j+ `6 oe ; f`1 ^ `2g; ; ` e : oe (1.2)

A typing now has five components, from left to right: a set of instantiation constraints
(a.k.a. semi-unification constraints [Hen93]), a set of flow constraints, a type environment
(here empty), a term and a type.

An instantiation constraint ` _ip `0, with p 2 f+; \Xi g, expresses that `0 is an instance
of `, at instantiation site i. The indices i and j serve to keep distinct instantiation sites
apart. The polarities p 2 f+; \Xi g are explained in a moment. The instantiation constraints
of our typing explicitly represent the label substitutions 'i = f`1 7! `3; `2 7! `4g and
'j = f`1 7! `5; `2 7! `6g used at instantiation sites i and j, respectively, to produce instances
of id's type int`1 ! int`2. Here, 'i is represented by the constraints `1 _i\Xi  `3; `2 _i+ `4,

and 'j is represented by `1 _j\Xi  `5; `2 _j+ `6. In a constraint copying framework, 'i and 'j
are applied at sites i and j to copy the subtype constraint set f`1 ^ `2g associated with id,
yielding f`3 ^ `4g and f`5 ^ `6g.

The crucial difference of POLYFLOWCFL to copy-based systems is that

ffl Instead of explicitly representing copies of the original constraint system (f`1 ^ `2g),

only the substitutions necessary to create them are represented. The constraint copies
are thereby implicitly given in terms of the original set (f`1 ^ `2g) and the instantiation constraints.

The flow at all instantiation sites is recoverable in a completely demand-driven fashion
through the combination of flow and instantiation constraints. Suppose that we demand to
know where `3 flows. Drawing flow constraint f`1 ^ `2g as a directed edge from `1 to `2 and
drawing instantiation constraints `1 _i\Xi  `3; `2 _i+ `4 for site i as dotted edges, we recover
the flow from `3 to `4 at instantiation site i by completing the following diagram, the lower
dashed edge representing the "recovered" flow constraint:

`1

_i\Xi fflffl

)) `

2

_i+fflffl

`3 55U . i `4

(1.3)

The diagram gets completed by traveling from `3 along the instantiation edge `1 _i\Xi  `3
in reverse direction, then traveling from `1 to `2 along the direction of flow (i.e., along
`1 ^ `2), and then finally traveling from `2 to `4 along the instantiation edge `2 _i+ `4.
We have thereby recovered the flow that was demanded, using only parts of the constraint
systems needed for this query.

A further advantage of instantiation constraints is that all flow is present in the constraint
sets I and C obtained in a typing judgment for POLYFLOWCFL. Consider for example the
flow of both value 0 (`3) and 1 (`5) to formal parameter x (`1). We recover such flow
similarly to the flow above via `1 _i\Xi  `3 and `1 _j\Xi  `5. To recover such flow in copy-based
systems, the entire typing derivation is required instead of merely the final judgment.

A crucial technical insight of our work is that in order to interpret instantiation constraints as flow constraints, it is necessary to assign them polarities (+ and \Xi ) indicating

6

the direction of flow, in addition to the indices i indicating the instantiation site. A negative
(\Xi ) instantiation edge gets traversed in reverse direction of instantiation, a positive one (+)
gets traversed along the direction of instantiation. Disregarding polarities and interpreting instantiation constraints as bi-directional flow constraints results in a complete loss of
context-sensitivity.

Polarities are assigned to instantiation constraints according to the polarity of the "source
types" of instantiations, in our example the negative, resp. positive, occurrences of `1, resp.
`2, in the type oe = int`1 ! int`2 of id.

CFL-Reachability
Recovering flow through instantiation and flow constraints is best formulated as CFL reachability on a graph formed by flow and instantiation constraints (edges) and labels (nodes).
Provided we reverse instantiation edges with negative polarity and label them with opening parentheses (i, label positive instantiation edges with closing parentheses )i, and flow
edges with d, all flow paths spell words from a particular grammar. For example, the path

`3 (

i\Gamma ! `1 d\Gamma ! `2 )i\Gamma ! spells the word "(

id)i" and corresponds to a matched flow path, becausethe parentheses match up. This formulation rules out spurious flow paths, for instance the

path `3 (

i\Gamma ! `1 d\Gamma ! `2 )j\Gamma ! `6, which corresponds to calling id at instance i, but returning at

instance j.

Matched flow paths bear a close resemblance to the precise interprocedural flow paths of
matching call- and return sequences studied in [RHS95] for the case of first order programs
manipulating atomic data. Our results in the remainder of this article can be seen as a
transfer of flow computation via CFL-reachability to the setting of higher-order and typebased polymorphic systems with structured data.

The transfer of the CFL viewpoint to this setting is non-trivial, because we incorporate
higher-order functions, polymorphic recursion, structured data and arbitrary instantiations
that may not correspond directly to call-return sequences 3.

1.3 Situating the Analyses
Flow analyses compute information about how values flow from one program point to another. There are many variations of flow computations in the literature. The particular form
of flow we are concerned with in this article is characterized by the following flow queries:
"Do values arising at expression e1 flow to the program point characterized by expression
e2?". There is still a wide choice of precisions for such queries. Particular analyses can be
characterized along at least two dimensions: flow-sensitivity and context-sensitivity. Flowsensitivity is a slightly misnamed concept referring to whether or not an analysis considers
the order of destructive updates. Flow-insensitive analyses ignore the order of updates and
are sometimes characterized as considering all interleavings of statements. Flow-sensitive
analyses are better characterized as performing strong updates. Modeling strong updates
requires must alias information. For purely functional languages, flow-sensitivity is of no
concern.

The second dimension--context-sensitivity--characterizes how a flow analysis handles
flow paths involving function bodies. Many distinct flow paths may share program points

3In higher-order programs, a function symbol may occur in contexts that are not call sites

7

within a function body. Context-insensitive analyses do not distinguish flow information
for such program points even if the information arises from different invocation contexts.
Context-sensitive analyses keep flow paths involving distinct invocation contexts apart.

Three other dimensions are of interest to characterize the flow analyses considered in
this article: whether the analysis is summary-based, higher-order, or directional. Whether
a context-sensitive analysis is summary-based or not is a vague concept, but intuitively we
consider a flow analysis summary-based, if the analysis examines each function body only
once, creating a concise description of the function. This description (or a copy thereof)
is employed in different contexts where the function is used. In contrast, non-summarybased approaches perform some degree of reanalysis of a function in new contexts. The
important aspect of summary-based approaches is not the exact space-time tradeoff made
w.r.t. reanalyzing, but the fact that there exists an explicit description of the effects of a
function independently of the analysis algorithm.

We say that an analysis is higher-order, if it works directly on programs with first-class
functions (or function pointers) without the need for an explicit call-graph approximation
computed through other means. A higher-order flow-analysis computes a call-graph approximation as part of the flow computation by computing the flow of function values.

Finally, directional analyses are characterized by having a non-symmetric notion of flow.
Symmetric notions of flow dictate that, whenever there is flow from ` to `0, there is also
flow from `0 to `. Such notions are often very imprecise, but they may have highly efficient
implementations. Monomorphic type systems without subtyping, for example, are symmetric, and type inference in these systems can be implemented by solving equations using fast
union-find methods.

The flow analyses studied in this article are summary-based, higher-order, contextsensitive, and directional but flow-insensitive. As we show in Section 3.2, flow-insensitivity
does not preclude the use of our techniques on imperative programs.

1.4 Context-Sensitivity in Higher-Order Programs
Context sensitivity in first-order programs is defined in terms of valid call-return paths. A
path is valid if the call and return edges associated with particular call sites form a wellparenthesized sequence4 For higher-order programs (function pointers in C) we must first
define what context-sensitivity means for indirect function calls. We explain the contextsensitivity of an analysis in terms of a conceptual copying of function bodies. Consider the
example C program below:

typedef int (*FIP)(int *);

int f(int *p) -...""
int g(int *q) -...""

void foo(int a, int b, int c) -

int ra, rb;
FIP fp = c?fi:gj;

4With each call site i is associated a pair of matching parenthesis (i )i. Well-parenthesised sequences are
those that can be completed by adding parentheses to either end so as to form a completely parenthesised
sequence.

8

int fi1(int *p) -...""
int fi2(int *p) -...""

int gj1(int *q) -...""
int gj2(int *q) -...""

void foo(int a, int b, int c) -

int ra, rb;

if (c) -

ra = fi1(&a);
rb = fi2(&b);
""
else -

ra = gj1(&a);
rb = gj2(&b);
""
""

Figure 1.1: One expansion per function per
call-site

int fi(int *p) -...""
int gj(int *q) -...""

void foo(int a, int b, int c) -

int ra, rb;

if (c) -

ra = fi(&a);
rb = fi(&b);
""
else -

ra = gj(&a);
rb = gj(&b);
""
""

Figure 1.2: One expansion per function occurrence

(1) ra = fp1(&a);
(2) rb = fp2(&b);
""

Function pointer fp is assigned either function f at occurrence i or function g at occurrence
j. Indirect call sites 1 and 2 are using fp. Consider a polymorphic analysis of this program
that treats each indirect call to a particular function independently from other calls. Such
an analysis corresponds to analyzing the expanded program shown in Figure 1.1 monomorphically (not context-sensitive). In this expansion, we have two copies fi1 and fi2 of function
f, one per indirect call site, and similarly for function g. This context-sensitivity is based
on functions reaching individual call-sites. It is expensive, since the number of instances of
a function depends on the number of indirect call sites it flows to.

Another form of context-sensitivity for higher-order programs is adopted in this article.
We only allow one copy of a function per occurrence of a function symbol. In our example,
this form corresponds to analyzing the expanded program in Figure 1.2 monomorphically.
There is one copy of function f corresponding to occurrence i and one copy of function
g corresponding to occurrence j. The same function is called at the two indirect callsites 1 and 2. This form has the advantage that it generates only as many instances of a
function f as there are occurrences of the symbol f in the program. On the other hand,
the use of fewer instances may lead to less precise results. This form of context-sensitivity
corresponds to recursive let-polymorphism [Myc84]. Note that in the first-order case, the
two approaches are identical, since function symbols only occur at call sites. The analogy of
copying functions is only conceptual (and obviously does not apply in the recursive case).

9

1.5 Overview
In Chapter 2 we start with the system POLYFLOW which is a flow type system with recursive polymorphism. Recursive polymorphism is used to achieve context-sensitivity, even in
the case of recursive invocations of functions. Polymorphism in POLYFLOW is restricted to
flow labels. The underlying type structure of the program is monomorphic. In other words,
the underlying type system corresponds to a monomorphic version of the ML-type system.
For this system we show how a known description [Mos96] based on constraint copying and
simplification (POLYFLOWcopy) is equivalent to a system without copying nor simplification
based on instantiation constraints and context-free language reachability queries (POLYFLOWCFL). The advantages of POLYFLOWCFL over POLYFLOWcopy include an asymptotically better algorithm answering individual or all queries in O(n3) instead of O(n8), where
n is the tree size of the type-annotated program (or number of distinct nodes in the type
instantiation graph.) More importantly, the size of the graph generated prior to answering
any queries is linear in n. The graph closure is computable on demand for particular queries
using the techniques presented by Reps et. al. in [RHS95]. Furthermore, we provide insights
into the complexity analysis of CFL-based algorithms through a new CFL algorithm.

Chapter 3 extends the POLYFLOW system to the system POLYTYPE, which is polymorphic in both the flow and the type structure. The underlying typing system of POLYTYPE
(without flow annotations) is exactly the Milner-Mycroft [Myc84] type system. We skip
the copying system and study directly the system POLYTYPECFL based on instantiation
constraints and CFL-reachability. The novel aspect of POLYTYPECFL is its combination of
two CFL-reachability problems, namely the matching of instantiation sites, as well as the
matching of data structure construction and elimination. We show that the two matching
problems form a single matching problem by keeping them synchronized at instantiation
boundaries. This synchronization is possible because we work with a structural subtyping
problem without recursive types. Perhaps surprisingly, the complexity of computing flow for
POLYTYPECFL is no harder than in POLYFLOWCFL: individual or all queries are computable
in time O(n3). The two complexities differ however in how the number of nodes n vary with
the size of the program m. In the worst case for POLYFLOWCFL n is exponential in m,
whereas for POLYTYPECFL, n is doubly exponential in m. In practice it makes more sense
to compare programs where the largest types are roughly the same size, and in that case,
the complexity is also the same. In fact, we expect POLYTYPECFL to have fewer nodes in
practice due to the type polymorphism which avoids expanding types of generic functions.

In Section 3.2 we discuss a special restricted case of POLYTYPE called POLYEQ which is
polymorphic over flow and type variables, but without subtyping. POLYEQ uses equivalence
classes to describe intra-procedural flow. The flow between function instantiations (interprocedural flow) is directed and we show that it is a special case of the CFL-reachability
of POLYFLOWCFL that has a more efficient implementation. Individual flow queries can be
answered in linear time and all queries in quadratic time. We show experimentally that
POLYEQ scales well to large programs.

At the end of Chapter 3 we discuss how to combine our approach with non-structural
subtyping and recursive types. We show restrictions on non-structural subtyping that supposedly guarantee the existence of flow paths with perfectly nesting parentheses. Combining context-sensitivity with recursive types yields two interleaved CFL problems. Reps has
shown this problem to be undecidable [Rep00]. In the type-based formulation, the undecidability manifests in the need to label infinite type with infinitely many distinct labels. In
practice, one uses repetitive labelings using only a finite number of labels, thus yielding a

10

(Expressions) e ::= x j n j (e1, e2) j *x:o/:e j e1 e2 j

let f : o/ = e1 in e2 j f io/ j
letrec f : o/ = e1 in e2 j
if0 e0 then e1 else e2 j e:j
(Types) o/ ::= int j o/ ! o/ j o/ \Theta  o/
(Labelled Types) o/ hsi; oe ::= int` j oe !` oe j oe \Theta ` oe
(Labels) L ::= `
(Label Sequence) s; t ::= ` j s s

Figure 1.3: Definitions

computable approximation of the general case.

Chapters 2 and 3 are concerned with the logical aspects of the flow systems under
study show only how to infer constraints and compute flow queries on the resulting type
instantiation graph. We assume that the underlying type structures are inferred through
other means. It is obvious that such type structures can in fact be inferred via algorithm
W for Hindley-Milner typings or the semi-algorithm of Henglein [Hen93] for Milner-Mycroft
typings. Chapter 4 offers conclusions, and Appendix A provides a proof of soundness for
the flow relation of POLYFLOWCFL.

1.6 Definitions
Throughout this article, we study the simple ML-like language given in Figure 1.3. The
language has constants (integers n), pairs, abstraction, application, let and recursive bindings, conditionals, and pair selection e:j. We distinguish between lambda-bound variables x
and let- or letrec-bound variables f . Uses of let- and letrec-bound variables are annotated
with an instantiation site i as in f i. Furthermore, we assume type annotations on lambda-,
letrec-, and let-bound variables as well as on instances of let- and letrec-bound variables.
Each sub-expression in the source is implicitly labeled, as in e`. However, we omit that
labeling except where it is interesting. Note that letrec-bindings can bind any kind of value.
For instance, mutually recursive functions can be defined by letrec-bindings of a pair of
functions.

We work with unlabeled types o/ and labeled types oe. As a technical device, we use the
notation o/ hsi to denote labeled types with structure o/ . The label sequence s is the labeling
of o/ obtained as a pre-order traversal of its structure. Figure 1.4 makes the relation between
o/ hsi and oe precise. A judgment ` o/ hsi : oe states that type o/ hsi is well-labeled and equal
to oe. When oe is not of interest, we will also write ` o/ hsi wl for such statements. We use
well-labeled types o/ hsi interchangeably with oe.

Positive and Negative Polarity
We say that o/0 has positive polarity in o/ , if 1) o/ = o/0, or 2) o/ = o/1 ! o/2 and either o/0 has
positive polarity in o/2, or o/0 has negative polarity in o/1, or 3) o/ = o/1 \Theta  o/2 and o/0 has positive
polarity in o/1 or o/2.

Similarly, o/0 has negative polarity in o/ , if 1) o/ = o/1 ! o/2 and either o/0 has negative
polarity in o/2 or o/0 has positive polarity in o/1, or 2) o/ = o/1 \Theta  o/2, and o/0 has negative polarity
in o/1 or o/2.

11

` o/ hsi : oe

` inth`i : int`
` o/1hs1i : oe1 ` o/2hs2i : oe2

` o/1 \Theta  o/2h`s1s2i : oe1 \Theta ` oe2

` o/1hs1i : oe1 ` o/2hs2i : oe2

` o/1 ! o/2h`s1s2i : oe1 !` oe2

Figure 1.4: Well-labeling

C ` L ^ L

C; L1 ^ L2 ` L1 ^ L2 [Id]

C ` L ^ L [Refl]
C ` L0 ^ L1 C ` L1 ^ L2

C ` L0 ^ L2 [Trans]

Figure 1.5: Constraint relation

The definition is identical for labeled types oe. A label annotating a a type o/0 with
positive (negative) polarity within oe itself has positive (negative) polarity. We also call a
label with negative polarity within oe an input label, and one with positive polarity an output
label. The set of labels with positive polarity in oe are written oe+ and the set of labels with
negative polarity in oe is written oe\Xi .

Contexts
We assign each subexpression e0 of an expression e a context Q as follows. The context of e1
in an expression let` f = e1 ... is the label ` of the let-expression. The context of e1 in
letrec` f = e1 ... is the label ` of the letrec-expression. In all other cases, the context
of an immediate sub-expression e0 of e is the same as the context of e. The context of the
top-level expression is called the top-level context or `?. When a context is nested within
another context, we call it a sub-context of the latter.

Flow Constraints
A flow constraint set C is a set of constraints of the form L ^ L. Statements of the form
C ` L ^ L0 express that C implies L ^ L0. These statements are governed by the rules in
Figure 1.5. The generalized form C ` C0 abbreviates C ` L ^ L0 for each L ^ L0 in C0.

Structural Subtyping
Subtyping judgments relate two labeled types and have the form C ` oe ^ oe0. In this
article we only consider structural subtyping, i.e., oe and oe0 have the same structure o/ . The

12

C `^ oe ^ oe

C ` `1 ^ `2
C `^ int`1 ^ int`2 [Int]

C `^ oe1 ^ oe01 C `^ oe2 ^ oe02 C ` ` ^ `0

C `^ oe1 \Theta ` oe2 ^ oe01 \Theta `

0 oe0

2 [Pair]

C `^ oe01 ^ oe1 C `^ oe2 ^ oe02 C ` ` ^ `0

C `^ oe1 !` oe2 ^ oe01 !`

0 oe0

2 [Fun]

Figure 1.6: Subtype relation

subtyping is restricted to the labeling as given by the rules in Figure 1.6. As is standard,
the function type constructor is contravariant in the domain.

Substitutions
Substitutions ' map labels to labels. The domain of a substitution ' is the set of labels
on which ' is not the identity. Explicit simultaneous substitutions replacing a for b and c
for d are written [a=b; c=d]. We apply explicit substitutions in postfix form, as in oe[`1=`2],
and named substitutions in prefix form '(oe). Substitutions applied to constraint sets C are
defined naturally.

Instantiation Constraints
An instantiation constraint L _ip L0 states that L instantiates to L0 at site i with polarity p.
We use instantiation constraints to make substitutions at instantiation sites of polymorphic
types explicit. A polarity p is either positive + or negative \Xi . The operator p negates
the polarity of p. Contrary to subtyping systems, instantiation constraints are covariant
in all constructors. We introduce polarities to encode the usual contravariance as an extra
annotation. Sets of instantiation constraints are written I. Figure 1.7 lifts instantiations to
labeled types.

I ` oe _ip oe I ` L _ip L

I; L _ip L0 ` L _ip L0 [Id]

I ` ` _ip `0
I ` int` _ip int`

0 [Int]

I ` ` _ip `0 I ` oe1 _ip oe01 I ` oe2 _ip oe02

I ` oe1 \Theta ` oe2 _ip oe01 \Theta `

0 oe0

2 [Pair]

I ` ` _ip `0 I ` oe1 _ip oe01 I ` oe2 _ip oe02

I ` oe1 !` oe2 _ip oe01 !`

0 oe0

2 [Fun]

Figure 1.7: Instantiation Relation

13

Sets of instantiation constraints I are subject to the well-formedness condition that for
any particular index i and any label L, there exists at most one L0 such that there is a
constraint L _ip L0 in I. A set I of instantiation constraints thus gives rise to a vector of
substitutions \Phi (I), indexed by instantiation site i, where

\Phi i(L) = L0 if L _ip L0 2 I
We use the notation I ` oe _ip oe0 : ' to mean that the instantiation is derivable under
I ` oe _ip oe0, and that '(oe) = oe0. Note that ' only has to agree with \Phi i(I) on the labels
appearing in oe.

14
Chapter 2
Flow Polymorphism
In this Chapter we study POLYFLOW, a simple flow type system with polymorphic flow
variables, but no polymorphism of type structure. We give two presentations of POLYFLOW. We first examine POLYFLOWcopy based on copying constraints at instantiations.
Second, we present the system POLYFLOWCFL based on CFL-reachability. We show that
both systems compute equivalent flow information. The advantage of POLYFLOWCFL is its
asymptotically cheaper running time of O(n3) vs. O(n8) for the POLYFLOWcopy system.

2.1 A Copy-based System
POLYFLOWcopy is similar to the system Mossin studies in his thesis ([Mos96], Chapter 5).
It differs however in the following points.

ffl Mossin's approach can only answers queries of the form "What construction points

flow to any particular program point?", where construction points are lambda, pair,
and constant expressions. It is inherent in his system that the construction points be
identified prior to the analysis. POLYFLOWcopy studied here is slightly more general
in that it allows all queries of the form "Is there flow from program point `1 to `2?".
As a result, we do not require a class of constant labels.

ffl We make instantiation substitutions explicit via instantiation constraints.

2.1.1 Polymorphic Constrained Types
Polymorphic types for POLYFLOWcopy are qualified by a set of constraints, written 8~`:C )
oe. Such a type scheme can be instantiated to oe[~`0=~`] in all contexts where the constraints
C[~`0=~`] hold.

The captured constraints C of a polymorphic constrained type describe the flow paths
between input labels (labels annotating negative occurrences of types) and output labels
(labels annotating positive occurrences of types) in oe. These constraints summarize all flow
between input and output labels of oe.

We use the notation f l(oe) for the set of labels in oe and f l(A) for the set of free labels
in the environment A. We may also use this notation on flow constraints f l(C).

15

2.1.2 Type Rules
Figure 2.1 contains typing rules for deriving judgments of the form Cg; I; C; A `cp e : oe,
where Cg is an accumulation of all flow constraints appearing in the derivation, I is a set
of instantiation constraints, C a set of flow constraints, A a type environment mapping
lambda-bound variables x to labeled types oe, and let- and letrec-bound variables f to type
schemes. The rules are classified into base rules and polymorphic rules. The base rules are
mostly standard. Rule [Lam] uses the type annotation o/ to obtain the labeled type o/ hsi
used in the judgment of the lambda body. Rule [Label] connects the label ` annotating an
expression e` with the label `0 annotating the top-level constructor of the type o/ h`0si of e.
The statement C ` ` = `0 is an abbreviation for the statements C ` ` ^ `0 and C ` `0 ^ `.
Tying the expression label ` to the type label `0 in such a way allows us to ask our flowqueries on the expression labels, but answer them using the constraints used in the type
derivation.

The polymorphic rules involve quantification and instantiation of labels. Rule [Let]
differs from standard let-rules in that the set of constraints C0 required to derive e1's type
is captured in the polymorphic type 8~`:C0 ) oe1. The set of quantified labels ~` contains all
free labels of oe1 and C0 that are not free in A or C. Furthermore, C0 must be a subset of the
collection Cg. Rule [Inst] gives types to occurrences f i of let- and letrec-bound variables.

The polymorphic type 8~`C0 ) oe is instantiated to oe0 via a substitution ' on the quantified
labels ~`. The judgment I ` oe _i+ oe0 : ' requires that the substitution of labels in oe is explicit
as a set of instantiation constraints in I. Recall that this judgment only relates I and ' for
labels actually occurring in oe. Furthermore, we require that the constraints C of the context
imply the constraints '(C0) as expressed by the judgment C ` '(C0). Given the definition
of the relation C ` '(C0), we note that except for trivial and transitive constraints, C must
contain all of the constraints '(C0). This aspect gives rise to the copying of constraints:
the constraints C0 representing the flow paths of the let- or letrec-bound expression are
duplicated at each instance by requiring '(C0) to be part of the constraints C.

Rule [Rec] is used to type letrec-expressions. The first line in the antecedent handles
the proper fixpoint requirements, namely that we derive type oe1 for e1 under constraints C0
and the assumption that f 's type is 8~`C0 ) oe1. As in the [Let] rule, we require that C0 is
a subset of the collection Cg.

Contexts of Labels
We assume that in a derivation of a judgment Cg; I; C; A `cp e : oe, all labels of subexpressions of e are distinct, and that quantified labels of distinct quantified types are
distinct via renaming of bound labels. Recall from Section 1.6 that let- and letrec-bindings
divide the sub-expressions of e into a set of disjoint contexts. We associate each label `
appearing in the derivation with a unique context as follows. The context of ` is the letor letrec-binding where the label is quantified, or the top-level context, if the label is not
bound in any quantified type. Contexts divide the set of labels into equivalence classes [`]
and furthermore, there is a unique constraint set C0 associated with each context, namely
the constraint set C0 captured in the quantified type of a given let- or letrec-binding. We
can thus refer to contexts either via a label (it's context), a let- or letrec-binding, or a
particular constraints set C0 appearing in the derivation. We use the notation C[`] to refer
to the constraint system C0 associated with the same context as `.

To give the reader some intuition about contexts, suppose all let- and letrec-bindings
generalize lambda expressions, and all lambda's are let- or letrec-bound, then contexts

16

Cg; I; C; A `cp e : oe
Base Rules

Cg; I; C; A; x : oe `cp x : oe [Id] Cg; I; C; A `cp n` : int` [Int]

Cg; I; C; A `cp e1 : oe2 !` oe1 Cg; I; C; A `cp e2 : oe2

Cg; I; C; A `cp e1 e2 : oe1 [App]

` o/ hsi : oe Cg; I; C; A; x : oe `cp e : oe0

Cg; I; C; A `cp *`x:o/:e : oe !` oe0 [Lam]

Cg; I; C; A `cp e1 : oe1 Cg; I; C; A `cp e2 : oe2

Cg; I; C; A `cp (e1; e2)` : oe1 \Theta ` oe2 [Pair]

Cg; I; C; A `cp e : oe1 \Theta ` oe2

Cg; I; C; A `cp e:j : oei [Proj j = 1; 2]

Cg; I; C; A `cp e0 : int` Cg; I; C; A `cp e1 : oe Cg; I; C; A `cp e2 : oe

Cg; I; C; A `cp if e0 then e1 else e2 : oe [Cond]

Cg; I; C; A `cp e : oe
C ` oe ^ oe0

Cg; I; C; A `cp e : oe0 [Sub]

Cg; I; C; A `cp e : oe
` o/ h`0si : oe C ` ` = `0

Cg; I; C; A `cp e` : oe [Label]

Polymorphic Rules

Cg; I; C0; A `cp e1 : oe1
Cg; I; C; A; f : 8~`:C0 ) oe1 `cp e2 : oe2
C0 ` Cg ~` ` gen(A; oe1; C0)
Cg; I; C; A `cp let f = e1 in e2 : oe2 [Let]

Cg; I; C0; A; f : 8~`:C0 ) oe1 `cp e1 : oe1
Cg; I; C; A; f : 8~`:C0 ) oe1 `cp e2 : oe2
C0 ` Cg ~` ` gen(A; oe1; C0) ` o/ hsi : oe1

Cg; I; C; A `cp letrec f :o/ = e1 in e2 : oe2 [Rec]

I ` oe _i+ oe0 : ' C ` '(C0) dom ' = ~`

Cg; I; C; A; f : 8~`:C0 ) oe `cp f i : oe0 [Inst]

gen(A; oe; C0) = f l(oe; C0) n f l(A)

Figure 2.1: Copy-Based System POLYFLOWcopy

17%%[ ProductName: GPL Ghostscript ]%%
%%[Page: 1]%%
%%[LastPage]%%


Figure 2.2: Generic flowgraph with five contexts
coincide with lambda bodies.
2.1.3 Flow Graphs
A flow graph G = (I; Cg; L) of a derivation Cg; I : C; A `cp e : oe is formed by the set of
labels L appearing in the derivation together with the set of instantiation edges I and the
collection of flow constraints Cg.

Figure 2.2 shows an example flow graph. Solid edges represent flow constraints, dotted
edges represent instantiation constraints. Large circles group nodes of the same context.
Instantiation edges usually cross contexts, but recursive instantiations may produce instantiation edges within a single context. Flow edges usually stay within a context, but can
cross between a context and one of its sub-contexts. These cross-context flow edges arise
through the use of lambda-bound variables in inner contexts.

Answering a flow query of the form "Is there flow from `1 to `2" requires finding a path
in a flow graph from `1 to `2 involving flow and instantiation edges. In the special case
where `1 and `2 belong to the same context, the query can be answered by inspecting the
flow constraints of the common context C[`1] alone. This property is due to the copying of
the bound constraints at instantiations of quantified types.

The next section makes answering flow queries precise using a simple flow relation.

18

I; Cg `cp `  `

Cg ` `1 ^ `2
I; Cg ` `1 p `2 [Level]

I; `1 _i+ `2; Cg ` `1 + `2 [Out]

I; `1 _i\Xi  `2; Cg ` `2 \Xi  `1 [In]
I; Cg ` `0 p `1 I; Cg ` `1 p `2

I; Cg ` `0 p `2 [Trans]

I; Cg ` `0 + `1 I; Cg ` `1 \Xi  `2

I; Cg `cp `0  `2 [Stage]

Figure 2.3: Flow relation for POLYFLOWcopy

2.1.4 Flow Relation
Given a derivation Cg; I; C; A `cp e : oe, we can answer flow queries pertaining to labels
L(e) of e by considering the constraint sets I and Cg. Figure 2.3 contains a set of rules for
deriving flow judgments of the form I; Cg `cp `1  `2 stating that under constraints I and
Cg, there is flow from label `1 to label `2. We now examine these rules in turn.

Some flow paths only involve flow constraints in Cg. These can be deduced directly from
Cg via rule [Level], i.e., if we can derive Cg ` `1 ^ `2, then we can deduce flow from `1 to
`2.

Note that the rules internally use two auxiliary judgments of the form I; Cg ` `1 + `2
and I; Cg ` `1 \Xi  `2 called positive and negative flow respectively. Rules with an occurrence
of p are actually rule schemes for all rules obtained by selecting + or \Xi  for p.

Rule [Trans] encodes transitivity for both auxiliary relations. The interesting rules are
[In] [Out] and [Stage]. These rules capture that all flow paths take on the form of a positive flow, followed by a negative flow, where positive flow involves flow along positive
instantiation edges and ordinary flow edges, and negative flow involves flow along negative
instantiation edges and ordinary flow edges. The intuition behind the structure of such flow
paths can be gleaned from the special case of a first-order program. In first-order programs,
function instantiation and calls coincide. Negative instantiation edges represent edges from
actual to formal parameters, and positive instantiation edges represent flow of return values
to the call site. Due to the copying of constraints, all matching flow through functions (flow
involving a matched sequence of call-return edges) is explicit as ordinary flow constraints.
The only flow that is not explicit is flow from within a function to some outer context
along return edges (positive flow), and back into a different context along argument edges
(negative flow). It is exactly this flow that is captured by rule [Stage] of the flow relation.

2.1.5 Example
Figure 2.4 contains an example program and flow graph. Function idpair is the identity
on integer pairs. It is instantiated at site i within f, which in turn is instantiated at site

19

let idpair = *x:int \Theta  int.x in
let f = *y:int.idi (a`a,b`b) in
let z = (fj 0).2`z
...

C0 ffl

_i\Xi 
fflffl

++
~~~~

~~~~ ???????

? ffl

_i+
fflffl

\Gamma \Gamma \Gamma \Gamma 

\Gamma \Gamma \Gamma \Gamma  ???????

?

ffl

_i\Xi 
fflffl

**ffl
_i\Xi 
fflffl

44ffl
_i+
fflffl

ffl

_i+
fflffl
C1 ffl ++e c a

. ] [ Y

\Gamma \Gamma \Gamma \Gamma 

\Gamma \Gamma \Gamma \Gamma  ???????

? ffl

_j+
fflffl

\Theta \Theta \Theta \Theta 

\Theta \Theta \Theta \Theta  ??????

??

`a **i g

d b . " Z W U

`b 44U W Y " . b e g iffl

_j+
fflffl

`1

_j+
fflffl
C2 ffl

\Theta \Theta \Theta \Theta 

\Theta \Theta \Theta \Theta  ??????

??

ffl `z

Figure 2.4: POLYFLOWcopy example
j. There are three distinct contexts C0, C1, and C2 corresponding to the body of idpair,
the body of f, and the remainder of the code. The dashed flow edges in C1 arise through
copying of the corresponding edges from C0 at site i. Using the flow relation of Figure 2.3,
we can deduce flow I; Cg `cp `b  `z from b to z, where Cg = C0 [ C1 [ C2. The deduction
uses rule [Level] on the dashed edge starting at `b, giving rise to I; Cg ` `b + `1. Combined
via [Trans] with flow I; Cg ` `1 + `z through [Out] yields I; Cg ` `b + `z. Finally using
[Stage] together with a trivial negative flow I; Cg ` `z \Xi  `z derived from [Level] results in
I; Cg `cp `b  `z.

2.2 A CFL-based System
We now present the system POLYFLOWCFL which computes the same answers to flow queries
as POLYFLOWcopy, but does not involve any constraint copying. POLYFLOWCFL is conceptually simpler than POLYFLOWcopy and also more practical. The best known algorithm for
inferring a type derivation for POLYFLOWcopy has complexity O(n8) [Mos96] and involves
handling multiple constraint systems, their simplification, and copying. POLYFLOWCFL on
the other hand involves only a single flow constraint system. Computing a type derivation
and answering all flow queries can be done in cubic time for POLYFLOWCFL. We prove the
equivalence of flow queries between POLYFLOWcopy and POLYFLOWCFL.

20

2.2.1 Polymorphic Types
POLYFLOWCFL uses polymorphic types of the form 8~`:oe. Only labels are quantified, and
unlike for POLYFLOWcopy, no qualifying constraint systems appear in the polymorphic types.

2.2.2 Type Rules
Judgments for POLYFLOWCFL have the form t; I; C; A `CFL e : oe shown in Figure 2.5. The
base rules change minimally w.r.t. the copy system. The extra t component in the judgment
is a label sequence containing the labels appearing in all *-bound types in the environment
A. The [Lam] rule makes this explicit by concatenating the label sequence s of the new
*-bound type o/ hsi to the current sequence t for the judgment of the body. The labels of
*-bound variables have a special role in flow computations. Due to nesting of let- and letrecbound definitions within lambda expressions, *-bound program variables allow the program
direct access to non-local scopes. Intuitively1, such edges skip some call or return edges that
are manifest as instantiation edges. In this section we are transforming the flow problem
into a CFL-reachability problem by formulating matched call-return flows as a parenthesis
matching problem. Cross-context flow edges make it necessary to add extra instantiation
edges to recover skipped call or return edges. We will explain the exact details of this aspect
of flow paths in more detail later. Suffice it to say here that at let- and letrec-bindings, we
capture the current set of free labels as part of the bindings. For letrec- and let-bound
variables, the environment contains pairs of the polymorphic type and a label sequence:
A; f : (8`i:oe; s). At instantiation points i [Inst], we require instantiations I ` s _i+ s and
I ` s _i\Xi  s which have the effect that for all ` in s, there are constraints ` _i+ ` and ` _i\Xi  `
in I. We will show later how these so-called self-loops enter into the flow computation.

2.2.3 Flow Graphs and Flow Queries
Given a derivation \Delta ; I; C `CFL e : oe, the flow graph G = (I; C; L) is defined by the set of
labels L appearing in the derivation, along with the flow edges C and instantiation edges
I.

The flow relation of POLYFLOWcopy is basically transitivity on the positive and negative
flow relations + and \Xi  involving constraints of Cg. Since we don't copy any constraints
in the POLYFLOWCFL system, there are fewer flow constraints in C than there are in Cg.
As a result, we have to use a larger flow relation to capture exactly the same flow as POLYFLOWcopy. The basic case where POLYFLOWcopy has an explicit flow `01 p `02 not present
in POLYFLOWCFL is in the following situation.

`1

_i\Xi fflfflO/O/
O/ )) `2

_i+fflfflO/O/
O/

`01 55 `02
POLYFLOWcopy generates the edge `01 ^ `02 by copying the constraint `1 ^ `2 at instance i.
In POLYFLOWCFL, the flow from `01 to `02 must be discovered through other means. To do so,
we introduce an auxiliary flow judgment C ` `1 m `2 called matched flow. Matched flow
captures flow paths where instantiation edges form matching pairs, negative instantiation

1The intuition applies to the first-order case.

21

t; I; C; A `CFL e : oe
Base Rules

t; I; C; A; x : oe `CFL x : oe [Id] t; I; C; A `CFL n` : int` [Int]

t; I; C; A `CFL e1 : oe2 !` oe1 t; I; C; A `CFL e2 : oe2

t; I; C; A `CFL e1 e2 : oe1 [App]

` o/ hsi : oe t s; I; C; A; x : oe `CFL e : oe0

t; I; C; A `CFL *`x:o/:e : oe !` oe0 [Lam]

t; I; C; A `CFL e1 : oe1 t; I; C; A `CFL e2 : oe2

t; I; C; A `CFL (e1; e2)` : oe1 \Theta ` oe2 [Pair]

t; I; C; A `CFL e : oe1 \Theta ` oe2

t; I; C; A `CFL e:j : oei [Proj j = 1; 2]

t; I; C; A `CFL e0 : int` t; I; C; A `CFL e1 : oe t; I; C; A `CFL e2 : oe

t; I; C; A `CFL if e0 then e1 else e2 : oe [Cond]

t; I; C; A `CFL e : oe C ` oe ^ oe0

t; I; C; A `CFL e : oe0 [Sub]

t; I; C; A `CFL e : oe
` o/ h`0si : oe C ` ` = `0

t; I; C; A `CFL e` : oe [Label]

Polymorphic Rules

t; I; C; A `CFL e1 : oe1
t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2
~` = gen(A; oe1)

t; I; C; A `CFL let f = e1 in e2 : oe2 [Let]

t; I; C; A; f : (8~`:oe1; t) `CFL e1 : oe1
t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2
~` = gen(A; oe1) ` o/ hsi : oe1

t; I; C; A `CFL letrec f :o/ = e1 in e2 : oe2 [Rec]

I ` oe _i+ oe0 : ' dom ' = ~` I ` s _i+ s I ` s _i\Xi  s

t; I; C; A; f : (8~`:oe; s) `CFL f i : oe0 [Inst]

gen(A; oe) = f l(oe) n f l(A)

Figure 2.5: CFL-Based System POLYFLOWCFL

22

I; C `CFL `  `

C ` `1 ^ `2
I; C ` `1 p `2 [Level]

I; `1 _i+ `2; C ` `1 + `2 [Out]

I; `1 _i\Xi  `2; C ` `2 \Xi  `1 [In]
I; C ` `0 p `1 I; C ` `1 p `2

I; C ` `0 p `2 [Trans]

I ` `1 _i\Xi  `0 I; C ` `1 m `2 I ` `2 _i+ `3

I; C ` `0 p `3 [Match]

I; C ` `0 + `1 I; C ` `1 \Xi  `2

I; C `CFL `0  `2 [Stage]

p = +; \Xi ; m

Figure 2.6: Flow relation for POLYFLOWCFL

edges match up with positive instantiation edges of the same instance. In the above graph,
given that we have a trivially matched flow (involving no instantiation edges) from `1 to
`2, rule [Match] in Figure 2.6 can be used to deduce matched flow from `01 to `02, effectively
deducing the copied constraint.

Note how the polarity on the instantiation edges defines the flow direction w.r.t. the
direction of the instantiation edge. Positive polarity means that flow occurs in the same
direction as the instantiation, whereas negative polarity means that flow occurs in the
opposite direction of the instantiation.

The complete flow relation I; C `CFL `1  `2 defined in Figure 2.6 states that under
constraints I and C, there is flow from label `1 to `2. The rules differ from the ones for
POLYFLOWcopy only in the addition of the auxiliary judgment I; C ` `1 m `2 for matched
flow, and the extra rule [Match]. The sequence of instantiation edges traversed along a
matched flow path form a well-parenthesized sequence, where _i\Xi  matches _i+. Matched
flow avoids spurious flow paths that involve negative and positive instantiation edges from
distinct instantiations. In the first-order case, such paths correspond to spurious flow from
one call site of a function f to another call site of f . In the general case it corresponds to
spurious flow from one instantiation site to another.

The key to formulating flow queries in the POLYFLOW system as a CFL-problem is the
tagging of instantiation edges with polarities. Instantiation constraints have been used previously for computing Milner-Mycroft typings [Hen93], software dependencies [OJ97], and
dimension inference [Rit95]. However, we are not aware of any previous work of propagating
and exploiting polarities on instantiation edges.

23

2.2.4 CFL Formulation
We now formulate flow queries as a context-free language reachability problem (see for
example [MR97]). Given a flow graph G = (I; C; L), construct the graph GCFL with nodes
L, and the following labeled edges:

`1 p\Gamma ! `2
`1 (

i\Gamma ! `2 if `1 _

i+ `2 2 I

`2 n\Gamma ! `1
`2 )

i\Gamma ! `1 if `1 _

i\Xi  `2 2 I

`1 d\Gamma ! `2 if `1 ^ `2 2 C
Edges with labels p (n) correspond to positive (negative) instantiation edges used in the [Out]
([In]) rule of the flow relation. Edges with labels (i and )i correspond to the instantiation
edges used in the [Match] rule.

A flow relation I; C `CFL `1  `2 can be derived via rules of Figure 2.6 if and only if
there exists a path in GCFL where the sequence of labels along the path from `1 to `2 is
accepted by the following grammar with start symbol S:

S  P N
P  M P

j p P
j ffl
N  M N

j n N
j ffl
M  (i M )i

j M M
j d
j ffl

It is easy to see that productions for P accept paths that corresponds to positive flow
I; C ` `1 + `2, productions for N produce negative flow paths, and productions for M
produce matched flow paths.

Note that in practice, the graph GCFL need not explicitly be computed. Instead, the
graph closure can be computed directly on the set of constraints C and I.

2.2.5 Examples
Figure 2.7 shows the same example examined for the POLYFLOWcopy case. The top contains the flow graph G containing flow and instantiation edges. The bottom contains the
corresponding CFL graph GCFL where we omit the d labels on flow edges. The flow path
from b to z now takes the form

`b (

i\Gamma ! ffl d\Gamma ! ffl )i\Gamma ! `1 p\Gamma ! `z

where the flow from `b to `1 forms a matched flow that was explicit as a copied constraint
in POLYFLOWcopy.

24

let idpair = *x:int \Theta  int.x in
let f = *y:int.idi (a`a,b`b) in
let z = (fj 0).2`z
...

ffl

_i\Xi 
fflffl

**
""""""""

"""""""" AAAAAAA

A ffl

_i+
fflffl

""""

""" AAAAAAA

A

ffl

_i\Xi 
fflffl

**ffl
_i\Xi 
fflffl

44ffl
_i+
fflffl

ffl

_i+
fflffl
ffl
""""

""" ???????

ffl

_j+
fflffl

\Gamma \Gamma \Gamma \Gamma 

\Gamma \Gamma \Gamma \Gamma  ??????

?

`a `b ffl

_j+
fflffl

`1

_j+
fflffl
ffl
\Gamma \Gamma \Gamma \Gamma 

\Gamma \Gamma \Gamma \Gamma  ??????

?

ffl `z
Flow graph G

ffl **
""""""""

"""""""" AAAAAAA

A ffl

)i
fifi
p

``

""""

""" AAAAAAAA

ffl **ffl 44ffl

)i
fifi
p

``

ffl

)i
fifi
p

``
ffl

(i

LL

n
RR

""""

""" ??????

? ffl

)j
fifi
p

``

\Gamma \Gamma \Gamma \Gamma 

\Gamma \Gamma \Gamma \Gamma  ??????

?

`a
(i

LL

n
RR

`b
(i

LL

n
RR

ffl

)j
fifi
p

``

`1

)j
fifi
p

``
ffl
\Gamma \Gamma \Gamma \Gamma 

\Gamma \Gamma \Gamma \Gamma  ??????

?

ffl `z
CFL Graph GCFL

Figure 2.7: POLYFLOWCFL example

25

let app = (*f.(*x. f x)`r )`app
in

let id = (*y.y)`id
in

let w = ((appi idj)`

0
r b`b)`w

fflffi flfi\Phi \Psi  \Omega ff! `

app

tttt

tttt

t

JJJJJ
JJJJJ

p

fflffl

fflffi flfi\Phi \Psi  \Omega ff! `

f

\Omega \Omega \Omega 

\Omega \Omega \Omega  55555

5 fflffi flfi\Phi \Psi  \Omega ff! `r

\Omega \Omega \Omega 

\Omega \Omega \Omega 

\Omega 

555
555
5

p
fflffl

fflffi flfi\Phi \Psi  \Omega ff! `

id

\Phi \Phi \Phi \Phi 

\Phi \Phi \Phi  666666

6

p
fflffl

`0

)i
fflffl

`6 88`xff `7

)i
fflffl

`y 99 `3

)j
fflffl

fflffi flfi\Phi \Psi  \Omega ff!
rrrrr

rrrrr LLLLLLLLL

L

fflffi flfi\Phi \Psi  \Omega ff! `

9

\Psi \Psi \Psi \Psi 

\Psi \Psi \Psi  555555

5

n

OO

fflffi flfi\Phi \Psi  \Omega ff! `0

r

\Psi \Psi \Psi 

\Psi \Psi \Psi 

\Psi 

555
555
5 fflffi flfi\Phi \Psi  \Omega ff! `8

\Phi \Phi \Phi \Phi 

\Phi \Phi \Phi  666666

6VV

`1 BB`5

(i

OO

ffl
(i

OO

ffl

fflffl

`2

(j

OO

`4]]
`b

OO

`w

Figure 2.8: Higher-order example (only relevant edges shown)
One advantage of using the type-based approach to flow analysis presented here is that
it deals directly with higher-order programs. Figure 2.8 contains an example. The app
function takes a function f as an argument and returns a function (labeled `r) that in
turn takes a parameter x and applies f to x. The figure shows the flow graph resulting
from applying app at instance i to the identity function id (instance j) and a value b. We
have used boxes around labels annotating function types to make the type structure more
readable. First note that we can determine what functions are called indirectly within app,
by observing what labels flow to `f . There is a path

`id p\Gamma ! `8 ! `9 n\Gamma ! `f
showing that the identity function (labeled `id ) flows to `f . The flow edges connecting the
types labeled by `8 and `9 arise from the subtype relation between the instance of id (the
argument) and the domain of the instance of app. The reversed edge `1 ^ `2 arises through
contra-variance of the subtype relation for function domains.

Edge `x ^ `0 represents the argument passing of x to f within app, and similarly, `6 ^ `7

26

represents the flow of the result of this application to the result of the function labeled `r.
The flow path connecting b with w is then as follows:

`b ! ffl (

i\Gamma ! `x ! `0 )i\Gamma ! `1 ! `2 (j\Gamma ! `y ! `3 )j\Gamma ! `4 ! `5 (i\Gamma ! `6 ! `7 )j\Gamma ! ffl ! `w

Observe how the path enters app through instance i and then emerges back along the edge
`0 )

i\Gamma ! `1. The polarity of this edge was determined to be positive, because the polarity of

the argument type `f within the type of app is itself negative. The path then traverses id
on instance j and reenters app at instance i through `5 (

i\Gamma ! `6 before finally emerging along

the edge `7 )

i\Gamma ! ffl. The example shows that in the higher-order case, the traversal of an

instantiation edge does not correspond directly to an argument passing or return step as in
the first-order case. In this example the path traverses app twice through instance i.

2.2.6 Algorithm
We now show how to compute flow queries for an expression e whose size without type
annotations is m, and whose type-annotated size is n. This section gives an algorithm with
time complexity O(n3) for computing individual or all queries. Note that in the worst case,
the size n is exponentially larger than m, although n will typically be close to m in practice.

Constraint Derivation
The type rules in Figure 2.5 can be used directly as constraint inference rules. As is standard
for inference systems, the use of the subsumption rule [Sub] can be restricted to the argument
derivation in [App], the branches in [Cond], and the binding in [Rec]. Constraints are
inferred at rules [Inst] and [Sub] by using the rules of Figures 1.7 and 1.5 in reverse, i.e.,
to obtain the conclusion, we need to generate the constraints required by the antecedents.
To guarantee the well-formedness of instantiation constraints, the rule presented in [Hen93]
must be applied whenever possible:

` _ip `1 ^ ` _ip0 `2 ) `1 = `2 (F1)
This process produces a flow constraint set C of size O(n), and an instantiation constraint
set of size O(mn). The m factor in the size of I is a direct result of the extra instantiation
constraints added on free labels at rule [Inst]. Without these, we would generate only O(n)
instantiation constraints. We show in Section 2.2.7 how to generate only O(n) constraints
and thus obtain a linear sized graph on which to answer flow queries. This space reduction
is of practical importance for the demand-driven algorithm we present in Section 2.2.8.

Constraint generation can be implemented in time proportional to the number of derived
constraints. The only non-obvious steps are in rules [Let] and [Rec], where we avoid using
gen(A; oe1) to find the quantifiable labels. This problem is solved with an extra subsumption
step on oe1 ^ oe01 guaranteeing that all labels in oe01 are fresh. Binding this type in place of
oe1 allows instantiation of all labels occurring in oe01 at all instances. This step also obviates
the need to ever apply rule (F1).

Answering Flow Queries via CFL Reachability
After constraint derivation we produce the graph GCFL according to the description given
earlier. This graph has O(n) nodes (the set of labels in the typed program), and O(mn)

27

S  P N
P  M P

j p P
j ffl
N  M N

j n N
j ffl
Ki  M )i

M  (i Ki

j M M
j d
j ffl

Figure 2.9: Grammar for CFL queries.
edges. We follow [MR97] and normalize the grammar for the CFL problem such that the
right hand sides of productions contain at most two symbols (terminals or non-terminals),
resulting in the grammar shown in Figure 2.9. This grammar has m terminals (i; )i and m
non-terminals Ki, since the number of distinct instantiations i is linear in the program size
and independent of the type size.

Figure 2.10 shows a generic CFL-algorithm that computes all derivable paths in time
O(en + un2 + bn3), where e is the number of epsilon productions, u is the number of distinct
unary grammar productions of the form A  B, and b is the number of distinct binary
grammar productions of the form A  B C. Applied to our particular CFL problem
(grammar of Figure 2.9) where e = 3, u = 1, and b = O(m), we obtain an initial complexity
of O(mn3) for computing all pairs reachability. We will further tighten the complexity to
O(n3) by exploiting the particular structure of constraints generated by POLYFLOWCFL.

On termination, the algorithm produces a graph G0 containing all possible edges labeled
by non-terminals of the grammar. To answer a query for flow from `1 to `2 we simply inspect
G0 for the presence of an S-edge from `1 to `2.

The algorithm of Figure 2.10 uses a work list W and adds edges to the result graph G0.
For each node ` and each production r of the form A  B C of the grammar, we use two
sets pred r(`) and succr(`) containing the predecessors of ` reachable via an edge labeled B,
and the successors of ` reachable via an edge labeled C.

The algorithm assumes that given an edge labeled B, we can index through B the rules
r that apply in the for-loops without looking at rules that don't apply.

We argue the complexity of the algorithm as follows: The number of steps needed to
add all edges for epsilon-productions is en. Now consider the statement labeled (2) in the
algorithm. For a fixed unary rule r and node `1, this statement is executed at most n times,
since the test at (1) guarantees that we see each edge at most once. There are u rules and n
nodes `1, thus the overall number of executions of statement (2) is un2 times. Next consider
the statement labeled (3) in the algorithm dealing with productions of the form A  B C.
For a particular node `2 and particular binary production r, this statement is executed at
most n2 times, because there are at most n distinct predecessors in pred r(`2) and n distinct
successors in succr(`2) that can be paired up. The test at (1) guarantees that we never add
a node twice to a bucket pred r or succr. Since there are b distinct productions and n distinct

28

W = edges of GCFL
G0 = ;

for each production A  ffl and node `, add ` A\Gamma ! ` to W
while W not empty

remove edge e = `1 B\Gamma ! `2 from W
(1) if e not in G0 do

add e to G0
for each rule r of the form A  B

(2) add `1 A\Gamma ! `2 to W

for each rule r of the form A  B C do

add `1 to pred r(`2)
for each `3 in succr(`2)

(3) add `1 A\Gamma ! `3 to W

end
end

for each rule r of the form A  C B do

add `2 to succr(`1)
for each `0 in pred r(`1)

(4) add `0 A\Gamma ! `2 to W

end
end
endif
end

Figure 2.10: CFL algorithm
nodes `2, we obtain the bound O(bn3). The argument for productions of the form A  C B
is analogous. The overall complexity bound of the algorithm is thus O(en + un2 + bn3).

This bound is more precise than the bound of the algorithm presented in [MR97] which
has worst case complexity2 O(j\Sigma j3n3). It assumes that the grammar can have j\Sigma j3 binary
productions and only gives complexity for this case. For this case, our bound is consistent
with the bound in [MR97]. But in practice, grammars are smaller and our algorithm attains
better bounds in those cases.

Cubic Algorithm
The complexity bound of the general algorithm can be tightened by considering u and b to
be the average number of grammar rules that apply at any particular node. In that case
it doesn't matter what the number of overall distinct grammar rules are. The complexity
is solely determined by the average number of rules that apply at each node. The overall
complexity improves in the case where u and b are constant at each node, but the productions
are drawn from a non-constant set of distinct productions (in our case, there are O(m)

2\Sigma  is the set of terminals and non-terminals used.

29

distinct productions).

As an example consider the family of O(m) productions of the form M  (i Ki. If we
can bound the average number of edges labeled (i on all nodes in our initial flow graph by
a constant, then on average only a constant number of productions of the form M  (i Ki
apply at any node. This hinges on the fact that the algorithm does not add any new edges
labeled with terminals (i.

If we discount the instantiation self-loops of the form `

_ip\Gamma \Gamma ! ` added through rule [Inst]

for the moment, we obtain the desired bounds on b. On average at any label, only a constant
number of productions apply. However, the number of self-loops added through rule [Inst]
is O(m) per label in the worst case. Fortunately, the complexity analysis for general binary
rules given above can be tightened in the case of self-loops. Consider rule M  (i Ki, when
applied to a self-loop. The situation is as follows:

`(i $$ `0

Kioo

For a fixed ` and fixed i, the number of times this rule triggers is at most n, since there are at
most n labels `0 connected to ` via an edge Ki. Since there are at most m such self-loops on
` and n distinct labels `, the number of executions of line 3 in the CFL algorithm involving
self-loops is bounded by O(mn2). The same argument applies to Ki  M )i. This analysis
leads to:

Theorem 2.1 Given I, C, `, `0. Deciding whether I; C `CFL `  `0 can be done in time
O(n3). Moreover, the entire flow relation derivable from I and C can be computed in time
O(n3).

This result improves the best known algorithm, given by Mossin [Mos96], from O(n8) to
O(n3). The gain is realized by avoiding repeated copies and simplifications of constraint
sets, and also by avoiding iterating the inference to obtain fixpoints for the polymorphic
recursive type schemes.

2.2.7 Understanding Self-loops and Improved Algorithm
We now show variations of the constraint derivation and the CFL-algorithm such that the
initial set of constraints I generated is of size O(n) instead of O(mn). Recall that through
rule [Inst], our constraint derivation phase generates up to O(m) distinct instantiation selfloops of the form `

_ip\Gamma \Gamma ! ` for up to O(n) distinct labels ` annotating types of *-bound

variables. Consequently, there are up to O(n) nodes that need to consider rules of the form
M  (i Ki for up to O(m) distinct i. Thus the average number of rules that may apply per
node is still O(m). To reduce the average to a constant, we need to understand why these
self-loops are needed in the first place.

It is interesting to note that these self-loops ` _i ` were used by Henglein [Hen93] merely
as a convenient way of enforcing monomorphism of *-bound variables. In POLYFLOWCFL,
self-loops are necessary to recover all flow paths and thus for proving soundness of flow.

Example
Figure 2.11 shows an example where self-loops are present. The example contains a letbinding of a function f within the scope of the *-bound parameter x of g. The body of f

30

let g = *x:int`x.

let f = *y:int`y .x
in

if0 x then (fi 0`0)`2 else (fj 1`1)`3
in

(gh 4`4)`5

!

\Upsilon \Upsilon \Upsilon \Upsilon 

\Upsilon \Upsilon \Upsilon  777777

7

`4

(h
fflffl

`5
!`g
\Phi \Phi \Phi 

\Phi \Phi \Phi  666666

6

)h
OO

`x(i '' (jww
''

ffl

)h
OO

!`f
\Phi \Phi \Phi 

\Phi \Phi \Phi  444444

4

)i

""

)j

O/O/
`y ffl

)i~~

)j


!
\Omega \Omega \Omega 

\Omega \Omega \Omega  44444

4 !

\Upsilon \Upsilon \Upsilon \Upsilon 

\Upsilon \Upsilon \Upsilon  777777

7

`0

(i

@@

`2@A BC

RR
`1
(j

..

`3

PP

Figure 2.11: Self-loop example (p and n edges not shown)
refers directly to x by returning it. Within g, we apply two instances of f at sites i and j.
Finally, g is applied at site h. In this example, there is obviously flow from label `4 to `5,
since g acts as the identity function.

The corresponding CFL-graph in Figure 2.11 contains two paths exhibiting the flow from
`4 to `5. The two distinct paths correspond to the two branches of the if-expression, and
thus to two distinct applications of f , one at i, the other at j. Each path uses one of the
two self-loops on `x, namely the one corresponding to the particular instance of f used in
the remainder of the path.

`4 (

h\Gamma ! `x (i\Gamma ! `x ! ffl )i\Gamma ! `2 ! ffl )h\Gamma ! `5

`4 (

h\Gamma ! `x (j\Gamma ! `x ! ffl )j\Gamma ! `3 ! ffl )h\Gamma ! `5

31

The self-loops are necessary to balance the result edges ffl )

i\Gamma ! `2 or ffl )j\Gamma ! `3 from the

body of f to the instantiation sites i and j. If we think about the closure-converted version
of this program, we would explicitly pass x as a parameter to f . It is this parameter path
that is skipped by referring to free *-bound variables like x and the self-loops essentially
simulate the extra parameter passing.

Level Based Inference
In general, this situation occurs whenever we have a let- or letrec-binding f referring to a
*-bound variable x from an outer scope and a use of f :

*x : oe. ...

... let f = ...x...

in
... f i
...

The self-loops on labels ` in oe annotating the type of a *-bound variable will have instance
labels i for all instances of any let- or letrec-bindings within the lambda body itself. To
determine the self-loops on a label ` annotating a lambda with scope r, it is thus sufficient
to determine the binding scope q of any instances i within r. If q is a sub-scope of r,
then ` acquires a self-loop for instance i. In fact, it is sufficient to determine the relative
syntactic level of *-, let-, and letrec-bindings instead of the actual scopes. The syntactic
level is determined as follows. For a let- or letrec-expression of f occurring at level k, its
sub-expressions e1 and e2 occur at level k + 1 and the binding f occurs at level k. The
following example shows that variables of lambda-bindings occurring within a letrec (or let)
binding have a strictly higher level k +1 than the letrec bound variable f with level k. Thus,
no self-loops for labels on x or y are created at instances i or j in this example.

letrec fk = *xk+1. ... f ik ...
in

*yk+1. ... f jk ...

In the case where the let-binding is nested within a lambda-expression, the binding level of
f is equal or higher to the binding level k of the lambda bound variable. Thus any instance
i of f will generate loops on labels of x.

*xk.

let fk = ...
in

... f ik ...

These observations can be exploited by introducing summary self-loop edges of the form
` s

r\Gamma ! ` for each label ` annotating the type of a lambda-bound variable at level r. Such a

summary self-loop stands for the set of edges with labels (i and )i where i is an instance of
a binding of level q * r occurring in the scope of the lambda generating ` s

r\Gamma ! `.

The new rules are shown in Figure 2.12. Judgments no longer contain the sequence of
free labels t, but are now indexed by the syntactic level k: I; C; A `CFLk e : oe. Furthermore,
the environment A maps let- and letrec-bound names to a quantified type paired with the
binding level of the name (see rules [Let] and [Rec]). At instantiation of f i with binding

32

level q, we require the instantiation constraints oe _i;q+ oe0 to be annotated with the binding
level q.

Level Based Queries
In the CFL-graph GCFL, we label the instantiation edges with (qi or )qi . Furthermore, for
each label ` annotating the type of a lambda-bound variable at level k, we add a single

summary self-loop ` s

k\Gamma ! ` to G

CFL3. GCFL now contains O(n) nodes and O(n) initial edges
where n is the tree size of the type-annotated program. The number of summary self-loops

is bounded by the number of labels or O(n).

We rewrite the grammar for the CFL-problem as follows. Since, a summary self-loop sk
on ` replaces the set of self-loops with labels (qi and )qi where i is an instance of a binding

of level q * k occurring in the scope of the lambda generating ` s

k\Gamma ! `, we need a family of

grammar rules of the form

M  sk M )qi q * k

and

M  (qi M sk q * k

which are normalized by introducing the families of auxiliary non-terminals Lq and Rq.

Rq  M )qi

Lq  (qi M

M  sk Rq q * k

j Lq sk q * k

The full grammar is shown in Figure 2.13. Note that we still have no more than O(m)
terminals and non-terminals, since the binding level k of a terminal depends directly on the
instance i. But we draw our productions from a family of m2 distinct productions.

We now have on average a constant number of edges labeled with terminals in our graph
and the average number of distinct rules that apply per node is constant, except for nodes `
with summary self-loops sk, since they need to consider the family of rules M  sk Rq (and
M  Lq sk) for all q such that q * k. But it is still the case that for a fixed ` and q, the
number of applications of this rule is bounded by O(n), since at most n distinct labels `0 are
connected to ` via an edge labeled Rq. Even though we reduced the number of initial edges
to O(n), the CFL-algorithm of Figure 2.10 would require O(m) sets O/r at a label ` with
summary self-loop k, one for each rule with q * k. Overall, that leads to O(mn) such sets.
We can modify the algorithm to use only O(n) such sets, by noting that at any particular
label ` where the family of rules M  sk Rq with q * k applies, the set O/r of all these
rules can be shared, because it doesn't matter which particular level q is used to trigger the
rule. This optimization depends on the fact that there are no other rules involving Rq on
the right-hand side. The same reasoning applies to the family M  Lq sk.

To summarize, the introduction of summary self-loops reduces the size of the initial
constraint graph from O(mn) to O(n) and further allows the CFL-algorithm to use only
constant number of pred r and succr sets per node on average.

3One can distinguish positive and negative self-loops that match up only with a negative (positive)
instantiation edge. Positively occurring labels only require negative self-loops, negatively occurring labels
only require positive self-loops. We chose to elide this detail here.

33

I; C; A `CFLk e : oe
Base Rules

I; C; A; x : oe `CFLk x : oe [Id]

I; C; A `CFLk n` : int` [Int]
I; C; A `CFLk e1 : oe2 !` oe1 I; C; A `CFLk e2 : oe2

I; C; A `CFLk e1 e2 : oe1 [App]

` o/ hsi : oe t s; I; C; A; x : oe `CFLk e : oe0

I; C; A `CFLk *`x:o/:e : oe !` oe0 [Lam]

I; C; A `CFLk e1 : oe1 I; C; A `CFLk e2 : oe2

I; C; A `CFLk (e1; e2)` : oe1 \Theta ` oe2 [Pair]

I; C; A `CFLk e : oe1 \Theta ` oe2

I; C; A `CFLk e:j : oei [Proj j = 1; 2]

I; C; A `CFLk e0 : int` I; C; A `CFLk e1 : oe I; C; A `CFLk e2 : oe

I; C; A `CFLk if e0 then e1 else e2 : oe [Cond]

I; C; A `CFLk e : oe C ` oe ^ oe0

I; C; A `CFLk e : oe0 [Sub]

I; C; A `CFLk e : oe
` o/ h`0si : oe C ` ` = `0

I; C; A `CFLk e` : oe [Label]

Polymorphic Rules

I; C; A `CFLk+1 e1 : oe1 ~` = gen(A; oe1)
I; C; A; f : (8~`:oe1; k) `CFLk+1 e2 : oe2

I; C; A `CFLk let f = e1 in e2 : oe2 [Let]

I; C; A; f : (8~`:oe1; k) `CFLk+1 e1 : oe1 ~` = gen(A; oe1)
I; C; A; f : (8~`:oe1; k) `CFLk+1 e2 : oe2

I; C; A `CFLk letrec f = e1 in e2 : oe2 [Rec]

I ` oe _i;q+ oe0 : ' dom ' = ~`

I; C; A; f : (8~`:oe; q) `CFLk f i : oe0 [Inst]

gen(A; oe) = f l(oe) n f l(A)

Figure 2.12: POLYFLOWCFL with levels

34

S  P N
P  M P

j p P
j ffl
N  M N

j n N
j ffl
Ki  M )qi

M  (qi Ki

j M M
j d
j ffl
j sk Rq q * k
j Lq sk q * k
Rq  M )qi

Lq  (qi M

Figure 2.13: Grammar for summary self-loops

Levels instead of Scopes
By construction, the set of flow paths recognized by the new formulation contains at least
all the flow paths of the original formulation. On the other hand, we use only syntactic
levels to decide which summary self-loops could pair up with some instance i instead of
actual scopes. It thus appears that a self-loop of a label `1 on a lambda-bound variable y at

level p may match up with any instantiation edge `2 )

q
i\Gamma ! `3 with a binding level q greater or

equal to p, even though the instance i does not appear in the scope of *y (see Figure 2.14).
But for such a situation to arise, there must be an edge `1 R

q\Gamma \Gamma ! `

3 which in turn requires a
matched path connecting label `1 with the instantiation edge )qi at label `2. Such a matched

path must go through an outer lambda *x at level k ^ p with label `0, where *x contains
both *y and the instantiation i in its scope (refer to Figure 2.14). The label `0 will have a
self-loop that can properly match up with the instantiation edge )qi producing a direct edge

`0 M\Gamma ! `3. Thus by transitivity of M -edges the matched path from `1 to `0 combined with
the path from `0 to `3 gives rise to the edge `1 M\Gamma ! `3, without the need for the self-loop at
`1.

Thus even though the edge from `1 to `3 in Figure 2.14 may erroneously be added by
applying the rule M  sp Rq, the same edge can be added by rule M  M M on path
`1 ! `0 ! `3, without using the self-loop sp.

The idea of using levels in the type derivation to avoid carrying the set of free type
variables around appears standard in implementations of Hindley-Milner style type systems.
Pessaux provides a nice description of the equivalence of level-based and non-level based
inference of polymorphic types in his thesis ([Pes00], Chapter 8).

35

`2

)qi

AEAE*x `
0sk &&

M

33gggggggg
ggggggggg
ggggggggg
gg R

q

--c b b a a ` ` . ^ ^ ] ] " " [

M

11 `3

*y `1

sp

XX

M

eeKKKKK

KKKKK

KKKKK

KKKKK

KKK

Rq

99

\Upsilon  \Xi 

\Delta  ""

z w

t

M

DD

k ^ p ^ q
Figure 2.14: Matching self-loops with instantiations of different scopes
2.2.8 Demand-driven Algorithm
We now sketch a demand-driven CFL-closure algorithm using the ideas of [RHS95]. The
grammar of Figure 2.13 is modified by deleting all epsilon productions and introducing an
extra non-terminal T for trigger edges. The trigger has the same function as start edges
in [RHS95]. Figure 2.15 shows the resulting grammar for a backward demand algorithm
(which requires a modification of the rules involving Lq). Given a label `, we ask for all

labels that can potentially flow to `. We seed the algorithm with a trigger-edge ` T\Gamma ! ` and
an edge ` N\Gamma ! `. Furthermore, we use three extra rules in the CFL algorithm:

Given Add
`1 )

i\Gamma ! ffl T\Gamma ! ffl `1 T\Gamma ! `1 D1

`1 s

k\Gamma ! ffl T\Gamma ! ffl `

1

T\Gamma ! `1 D3

`1 N\Gamma ! ffl `1 P\Gamma ! `1 D3
Rules D1 and D2 add a trigger edge across an instantiation or self-loop edge allowing the
closure to proceed. Rule D3 adds a P edge to any node with an outgoing N edge, allowing
the derivation of S paths. When no more new edges can be added to the graph closure, the
query answer is the set of labels `0 connected to ` with an S-edge.

2.3 Soundness
Soundness of our flow relation I; C `CFL `1  `2 is non-obvious and requires proof, which
can be found in Appendix A. The presence of polymorphic recursion is a complicating
factor, and it renders the proof non-trivial. The proof essentially consists in showing that,
for every derivation in POLYFLOWCFL, there exists a derivation in POLYFLOWcopy such that
our notion of flow is a safe approximation of the flow defined by the copy-based system (in
fact, our notion of flow is equivalent, in terms of precision). The system POLYFLOWcopy is
similar to a standard copy-based system studied by Mossin for which soundness has been
established [Mos96]).

36

S  P N
P  T P

j p P
N  T N

j n N
Ki  T )qi

M  (qi Ki

j d
j sk Rq q * k
j (qi Lk q * k
Rq  T )qi

Lk  T sk

T  M T

Figure 2.15: Grammar for demand-driven algorithm

A technical core in our proof consists in showing that the CFL-based flow relation can
recover all substitutions on constraint systems used in the copy-based derivation. Since
soundness has been established for copy-based systems by Mossin [Mos96], soundness of our
notion of flow follows.

The soundness theorem states that for every derivation of POLYFLOWCFL, there exists
a derivation in POLYFLOWcopy containing no more flow than the flow present in the POLYFLOWCFL derivation. The proof is given in Appendix A.

Theorem 2.2 (Soundness) For every judgment

t; I; C; A `CFL e : oe
derivable in POLYFLOWCFL there exists a judgment

C0; I0; C0; A0 `cp e : oe
derivable in POLYFLOWcopy such that, for all labels ` and `0 occurring in e one has

I0; C0 `cp `  `0 ) I; C `CFL `  `0

2.4 Discussion and Related Work
2.4.1 Polymorphic Subtyping
Our work owes much to Mossin's work on flow analysis based on structural polymorphic
subtyping systems [Mos96]. In particular, we build on the soundness proof provided there
for POLYFLOWcopy, and use the same idea of introducing formal joins of labels to proof
soundness or POLYFLOWCFL with respect to POLYFLOWcopy.

2.4.2 Higher-Order Context-Sensitivity
Type-polymorphic analyses are context-sensitive in the type abstraction graph of a program,
not in the actual function call-graph as is standard in first-order precise inter-procedural

37

letrec P = *a.*b.

if0 a then

let b1 = c^`c in

let a1 = (a - b1)`a1 in
let q = Pj a1 b1 in

let b2 = q.2`b2 in
q
else p
in

let main = *x. Pi x 0`0

ffl
\Delta \Delta \Delta \Delta 

\Delta \Delta \Delta \Delta  ???????

?

`a1

(j
flfl
n

jj

`b1mm

(j
flfl
n

jj

ffl ffl ** `b2
ffl
""""

"""" ???????

? `c

..@@@

@@@@

ffl

\Theta \Theta \Theta \Theta 

\Theta \Theta \Theta \Theta  ??????

??

`a 55

..

`b 55ffl

)i
fifi
p

``

)j

LL

p
RR

`1

)i
fifi
p

``

)j

LL

p
RR

`x
(i

LL

n
RR

`0
(i

LL

n
RR

ffl ffl
Figure 2.16: Example from [RHS95] (some edges omitted)

analyses (see discussion in Section 1.4). In the case where type abstraction and value
abstraction coincide (first-order programs), type-polymorphic context-sensitivity coincides
with the standard call-graph context-sensitivity. In the higher-order case, calls to lambdabound functions are monomorphic within the body of the lambda. However, in many
cases, context sensitivity is recovered by the fact that the higher-order function itself is
polymorphic. Consider:

let f = *p.*x. ... p x ...
in

let a = f g ... let b = f h ...
...

Even though the call p x within the body of f is monomorphic, the applications f g and
f h are fully polymorphic, since f's type is polymorphic. Thus there is no spurious flow
between the parameters and results of g and h as might be expected.

38

2.4.3 Precise Interprocedural Dataflow Analysis
In [RHS95], Reps et. al. show how to solve a class of distributive interprocedural dataflow
problems (called IFDS problems) precisely, i.e., restricted to valid call-return paths. Our
POLYFLOWCFL analysis is not directly comparable to the IFDS framework. They differ in
at least the following points.

1. The IFDS problem is formulated for first-order programs only, whereas POLYFLOWCFL

deals directly with higher-order programs.

2. The IFDS problem does not deal with data structures (no data-flow facts are derived

for data structure components), whereas POLYFLOWCFL handles data structures directly.

3. On the other hand, the IFDS framework is flow-sensitive, i.e., there is an implicit store

and data flow facts express information about the store at a particular program point.
In contrast, our analysis is flow-insensitive, i.e., there is no concept of a store that is
updated.

For POLYFLOWCFL to deal with imperative languages, two avenues exist. Either POLYFLOWCFL handles imperative features the way ML's type system handles references, namely
by treating them in a flow-insensitive way, i.e., all updates to a particular abstract location are accumulated. Alternatively, the program is transformed into an interprocedural
SSA form. POLYFLOWCFL applied to the SSA transformed program yields flow-sensitive
information. Thus the problem in computing flow-sensitive information is not in the flow
computation per se, but in obtaining a suitable interprocedural SSA representation of the
program--a difficult task since it requires aliasing information in the presence of pointers
and data structures.

Focusing more on the similarities, we can state that instead of deriving a subset of jDj
data-flow facts at each program point, POLYFLOWCFL derives a single global set of jDj2
data flow facts, namely the reachability relation between labels. Alternatively, we can view
each label ` occurring in the program expression e as a program point. Then the set of data
flow facts derived for point ` is the set of reachable labels Li for each label `i appearing in
the type labeled by `. However, the analogy does not express the fact that the paths in the
exploded supergraph of [RHS95] carry only a single bit, namely true or false, whereas our
paths carry sets of labels. There is thus a further distinction in what paths represent.

Figure 2.16 shows an SSA translation of the running example in [RHS95] into our language and the resulting type instantiation graph. Pairs are used to return the current values
of the two SSA transformed variables x and y. Instead of read statements for x and y, we
assume x to be a parameter to main, and we introduce a constant c for the read result
assigned to y. Furthermore, we use 0 at label `0 to represent the uninitialized value, and
in order to model how uninitialized values propagate, we assume that the subtraction operation adds flow constraints from both arguments to the result. The question posed by
Reps is whether b can be uninitialized after the recursive call to P at j. In our translation,
the question is: Can `0 flow to `b2 ? In order to answer this question, P has to be treated
polymorphically in the second argument b, saying that P returns it's second argument or c.
One path connecting `0 with `b2 is

`0 (

i\Gamma ! `b \Gamma ! `1 )j\Gamma ! ffl ! `b

2

39

but it is invalid, since (i does not match )j. The other three paths are not accepted by
the grammar either. Thus, there is no flow from `0 to `b2 and we can conclude that b2 is
initialized on all paths.

2.4.4 Summarization in Context-Sensitive Analyses
Many context-sensitive flow analyses based on function summaries (e.g. [CRL99, LH99,
FFA99]) are presented as two phase computations. In phase 1, information is propagated
from the callees (where it originates) to the callers. In POLYFLOWCFL, this information
is captured as positive flow P . In phase 2, information is propagated from callers back to
callees. The information in the second step represents summary information for a callee
from all contexts. In our formulation, this final information is captured as P N or S-flow.
Our results show that this phase distinction is present on each individual flow path. As a
result, it is not necessary to compute two global phases. Instead, we can use demand-driven
algorithms. In the global 2-phase approach, it is easy to use demand-driven algorithms for
phase 2 only. However, in that case, the information gathered in phase 1 already has size
O(n2) in the worst case.

Mossin's formulation of POLYFLOW is also a 2-phase algorithm ([Mos96], pages 90,91).
His formulation relies crucially on the fact that the types include a set of polymorphic
flow constraints that are copied on instantiation, including constraints of the form L ^ `,
where L is a set of label constants. Type inference constitutes phase 1, after which flow
information is present for the top-level function in the form of constraints involving constant
labels. In phase 2, this information is propagated back into polymorphic functions using
the reverse of substitutions performed during type inference. This step corresponds directly
to our use of n-edges. Again, this approach does not yield a demand-driven algorithm and
the information present after phase 1 has worst case size O(n2).

We are not aware of any context-sensitive analysis computing summary information for
every point in the program that deals directly with higher-order programs while generating
only O(n) instances.

Context-sensitive analyses based on reanalyzing function bodies in different contexts
do not have the problem of computing summary information without destroying contextsensitivity, since they enumerate each distinct context and can accumulate information at
the same time. However, these analyses are typically exponential and use an arbitrary limit
on the number of contexts being distinguished (e.g. [JW95, NN97]).

2.4.5 Constraint Simplification
Program analyses based on polymorphic subtyping depend crucially on constraint simplification in order to be at all practical [FM88, FA96, Pot96, Mos96, FF97, Pot98]. In the
particular case of Mossin's algorithm for inferring derivations of POLYFLOWcopy, the constraint set C is simplified before forming the quantified type 8~`:C ) oe. Without this
simplification, the constraint sets can grow exponentially in n due to the copying. In the
case of polymorphic recursion, simplification is absolutely crucial to obtain a fixpoint for the
polymorphic constrained type. The simplification consists in retaining only those constraints
in C that involve free labels, or labels occurring in oe, while retaining all flow implied by C.
This reduces to removing intermediate labels, while adding enough transitive constraints.

Since POLYFLOWCFL does not copy constraint systems, it automatically avoids the exponential blowup. The correspondence is yet closer, since 1) instantiation constraints only

40

relate labels appearing in oe and its instance, and 2) the transitive rule [Trans] together
with rule [Match] in the flow relation `CFL derive the simplified constraints directly that are
copied in POLYFLOWcopy. Interestingly, the fixpoint computation for polymorphic recursive functions is avoided altogether. It appears indirectly in the CFL algorithm where the
fixpoint is computed for the set of non-terminal edges that can be added to the graph.

CFL-based approaches do not obviate all constraint simplification. For example, Ssimplification [FM88] may be useful in obtaining smaller polymorphic types (i.e., fewer
distinct labels) and thus fewer instantiation constraints. Furthermore, the computation
of the CFL-closure may benefit from techniques such as online cycle elimination on M edges [FFSA98].

2.4.6 Other Related Work
Henglein's work on semi-unification and polymorphic recursion [Hen93] provides the logical
foundation for our work. Dussart, Henglein and Mossin [DHM95a] present an algorithm for
binding time analysis using polymorphic recursion with subtyping constraints, which uses
constraint copying.

The unpublished work [DHM95b] formulates [DHM95a] purely in terms of semi-unification.
However, it does not not make the connection to CFL-reachability and does not address the
computation of flow information. We believe our formulation of POLYFLOWCFL is the first
analysis combining instantiation (semi-unification) constraints and directional flow edges.
In addition, we extend instantiation constraints with polarities and provide them with a
flow interpretation.

Our work is also related to the closure analysis for ML by Heintze and McAllester
[HM97]. The system they study corresponds to a type-based flow analysis with subtyping
but without polymorphism. Such a system has also been studied by Mossin [Mos96]. The
lack of polymorphism and context-sensitivity results in simple graph reachability queries
answerable in linear time. Our approach degrades gracefully into a non-context sensitive
setting. Given GCFL, individual queries can be answered in linear time by ignoring the
matching problem and treating all edges as unlabeled flow edges.

41

Chapter 3
Flow and Type-Structure
Polymorphism

In this chapter we extend the flow analysis of Chapter 2 with polymorphism over type
structure. We extend the definitions from Figure 1.3 as shown in Figure 3.1. The language
of types now contains type variables ff. Type annotation on let- and letrec-bindings take
the form 8ffi:o/. Labeled types oe are extended to type variables, where type variables are
annotated with a special kind of label h called a hole-label. Label sequences thus contain
both ordinary labels ` and hole-labels hff, where the hole-labels are tagged with the type
variable that they annotate in the type.

The well-labeling logic of Figure 1.4 is extended with the rule

` ffhhffi : ffh
and similarly, the subtype relation from Figure 1.6 is extended with the following rule.

C ` h1 ^ h2
C `^ ffh1 ^ ffh2 [Var]

In the same vein, we extend the instantiation relation of Figure 1.7 to type variables:

I ` h _ip L I ` ff _ip o/

I ` ffh _ip o/ hL si [Var]

(Expressions) e ::= x j n j (e1, e2) j *x:o/:e j e1 e2 j

let f : 8~ff:o/ = e1 in e2 j f io/ j
letrec f : 8~ff:o/ = e1 in e2 j
if0 e0 then e1 else e2 j e:i
(Types) o/ ::= int j o/ ! o/ j o/ \Theta  o/ j ff
(Labelled Types) o/ hsi; oe ::= int` j oe !` oe j oe \Theta ` oe j ffh
(Labels) L ::= ` j h
(Label Sequence) s; t ::= ` j hff j s s

Figure 3.1: Definitions

42

Note that we now have instantiation constraints on type variables of the form ff _ip o/ .

Substitutions ' now have three components: 'jff maps type variables ff to unlabeled
types o/ , 'j` maps ordinary labels ` to ordinary labels `0, and 'jh maps hole labels to label
sequences s. The domain of a substitution ' is the set of type variables and labels on which
' is not the identity. We say that a substitution ' is well-formed for a particular type
oe = o/ hsi, if the result oe0 of the substitution is well-labeled, i.e. ` '(o/ )h'(s)i : oe0. In other
words, for all ff 2 o/ and for all hff 2 s, we have ` '(ff)h'(hff)i : wl, i.e., the structure
substitution of a type variable ff and the sequence substitutions of all hole labels tagged
with ff yield well-labeled types.

The notation o/hsi enables us to capture the substitution of multiple occurrences of type
variable ff at hff1 ; hff2 ; : : : with a single new structure o/ , while labeling the occurrences of o/
at hff1 ; hff2 ; : : : differently. For example: the substitution [int \Theta  int=ff][`1`2`3=hff1 ][`4`5`6=hff2 ]
applied to type ffh1 !`0 ffh2 yields

int`2 \Theta `1 int`3 !`0 int`5 \Theta `4 int`6

3.1 CFL-Based Approach
We skip the copy-based approach and directly show how to extend the CFL-based approach
of POLYFLOWCFL to POLYTYPECFL.

Polymorphic types
Polymorphic types are now written 8ffi`ihi:o/ hsi, with quantified variables ffi and quantified
labels `i, hi. A quantified type is said to be well-labeled (written ` 8ffi`ihi:o/hsi wl), if for all
ffi, all hole-variables hffk 2 s are among the quantified labels hi. In other words, hole-labels
annotating occurrences of quantified variables ff must themselves be quantified. We use the
notation

A type o/ 0hs0i is an instance of a polymorphic type 8~ff~`~h:o/ hsi, written 8~ff~`~h:o/hsi _ o/ 0hs0i,
if there exists a substitution ' over the quantified variables, such that '(o/ ) = o/ 0, '(s) = s0,
and ` o/ 0hs0i wl.

The set of free hole labels of types and environments are written f h(oe) and f h(A).

3.1.1 Type Rules
Figure 3.2 shows the rules for the type polymorphic flow system. The base rules are identical to the rules for POLYFLOWCFL in Figure 2.12. The polymorphic rules now quantify
over type variables and instantiate them to types at instantiations. Note that we use the
annotations of the underlying structural polymorphic types at [Let] and [LetRec]. Finding
a polymorphic typing derivation for the underlying structural types can be done using algorithm W , provided that polymorphic types in the letrec case are given through some other
means (programmer, or semi-decidable procedure [Hen93]).

For completeness, the type rules are presented with the level optimization and summary
self-loops discussed in Section 2.2.7. In the remainder of this chapter however, we will
elide summary self-loops and level annotations on instantiation constraints, since they are
orthogonal to the issues discussed here.

43

I; C; A `ptk e : oe
Base Rules

I; C; A; x : oe `ptk x : oe [Id] I; C; A `ptk n` : int` [Int]

I; C; A `ptk e1 : oe2 !` oe1 I; C; A `ptk e2 : oe2

I; C; A `ptk e1 e2 : oe1 [App]

` o/ hsi : oe t s; I; C; A; x : oe `ptk e : oe0

I; C; A `ptk *`x:o/:e : oe !` oe0 [Lam]

I; C; A `ptk e1 : oe1 I; C; A `ptk e2 : oe2

I; C; A `ptk (e1; e2)` : oe1 \Theta ` oe2 [Pair]

I; C; A `ptk e : oe1 \Theta ` oe2

I; C; A `ptk e:i : oei [Proj i = 1; 2]

I; C; A `cp e0 : int` I; C; A `cp e1 : oe I; C; A `cp e2 : oe

I; C; A `cp if e0 then e1 else e2 : oe [Cond]

I; C; A `ptk e : oe C ` oe ^ oe0

I; C; A `ptk e : oe0 [Sub]

I; C; A `ptk e : oe
` o/ h`0si : oe C ` ` = `0

I; C; A `ptk e` : oe [Label]
Polymorphic Rules

I; C0; A `ptk+1 e1 : oe1
I; C; A; f : (8~ff~`~h:oe1; k) `ptk+1 e2 : oe2
C ` C0 ~` = gen`(A; oe1) ~h = genh(A; oe1)
` o/ hsi : oe1 ` 8~ff~`~h:oe1 wl

I; C; A `ptk let f : 8~ff:o/ = e1 in e2 : oe2 [Let]

I; C; A; f : (8~ff~`~h:oe1; k) `ptk+1 e1 : oe1
I; C; A; f : (8~ff~`~h:oe1; k) `ptk+1 e2 : oe2
C ` C0 ~` = gen`(A; oe1) ~h = genh(A; oe1)
` o/ hsi : oe1 ` 8~ff~`~h:oe1 wl

I; C; A `ptk letrec f : 8~ff:o/ = e1 in e2 : oe2 [Rec]

I ` oe _i;q+ oe0 : ' dom ' = ~ff; ~`; ~h

I; C; A; f : (8~ff~`~h:oe; q) `ptk f i : oe0 [Inst]

gen`(A; oe) = f l(oe) n f l(A)
genh(A; oe) = f h(oe) n f h(A)

Figure 3.2: POLYTYPECFL

44

let id = *x:ff. x in
let f = *y:fi. idi (a`a, idk y`y )`p in
let z = (fj b`b).2`z
...

hff1 ,, hff2

)k
xx

p
--

)i
fifi
p

```
p

(i

LL

n
RR

\Theta 1

""""

"""" \Theta 2

????

????

`1

)j
flfl
p

jj

\Theta 1
\Gamma \Gamma \Gamma \Gamma 

\Gamma \Gamma \Gamma \Gamma  \Theta 2??????

??

`a ffl `y

(k

XX

n
""

ffl

)j
fifi
p

``

`2

)j
flfl
p

jj
`3
\Theta 1""""""

""

\Theta 2 @@@@

@@@@

`b

(j

MM

n
QQ

ffl `z
Figure 3.3: Type-polymorphic example
3.1.2 Flow Queries in the Presence of Type Polymorphism
Consider the example of Figure 3.3, which involves the application of the polymorphic
identity function id with type 8ffh1h2:ffh1 ! ffh2 . We are again interested in the flow
from b to z. But whereas in earlier examples (e.g., Figure 2.7) there existed a CFL path
from `b to `z involving only instantiation and flow constraints, the flow paths in the type
polymorphic case of Figure 3.3 involve traversing constructor edges, i.e., edges linking the
pair type constructors with its right sub-component. We view constructor edges as a pair
of directed edges, one from parent to child, and the other from child to parent. The child to
parent edge is labeled with an open parenthesis indexed by the parent type constructor and
the child index. For example, the edge from `a to the pair type labeled `p is labeled [\Theta 1.
Similarly, parent to child edges are labeled with closing parenthesis, in our example ]\Theta 1. To
avoid clutter in our graphs, we do not draw both edges and simply annotate the undirected
edge with the constructor/index label (here \Theta 1).

The flow from b to z is exposed by the following path, which is accepted by the grammar
in Figure 3.4:

`b

(j\Gamma ! `

y

(k\Gamma ! h

1 ! h2

)k\Gamma !-- -z "" ffl [\Theta 2\Gamma \Gamma ! ffl (i\Gamma ! h

1 ! h2

)i\Gamma !-- -z "" `

1

]\Theta 2\Gamma \Gamma !-- -z "" `

2

)j\Gamma !-- -z "" `

z

There are only two new productions w.r.t. the grammar for POLYFLOWCFL, namely M 
[ci M ]ci and M  [ci M ]ci . The first new production enables matching up edges from the

45

S  P N
P  M P

j p P
j ffl
N  M N

j n N
j ffl
M  (i M )i

j [ci M ]ci ci covariant in c
j [ci M ]ci ci contravariant in c
j M M
j d
j ffl

Figure 3.4: Extended grammar for constructor matching

ith child of a type constructors c with the edge from c to its ith child whenever the ith child
of a constructor has the same variance as the constructor itself. The second production
handles the contravariant case. The non-terminal M stands for reversed M paths. We
choose to express these paths externally from the grammar by an extra rule

if `1 M\Gamma ! `2 is an edge in G0, then `2 M\Gamma ! `1 is also an edge in G0. (RevM)
It is possible to express reversed M -paths directly in the grammar, but we have to introduce reverse edges for all terminals involved in M productions and write corresponding
productions for M as follows:

M  )i M (i

j M M
j d

In general, constructor and instantiation matching are independent and give rise to an
interleaved CFL problem. Deciding whether there is a single path accepted by both CFL
problems is undecidable [Rep00]. Fortunately, we can prove for our particular flow analysis
that there always exists a flow path with properly nested parentheses of both kinds, resulting
in a single CFL problem. Consider for example the alternative path in Figure 3.3 formed
by

`b

(j\Gamma ! `

y

(k\Gamma ! h

1 ! h2

)k\Gamma ! ffl [\Theta 2\Gamma \Gamma ! ffl (i\Gamma ! h

1 ! h2

)i\Gamma ! `

1

)j\Gamma ! `

3

]\Theta 2\Gamma \Gamma ! `

z

This path differs from our earlier path in the last two edges traversed. Instead of traversing
the edge `1

]\Theta 2\Gamma \Gamma ! `

2 followed by `2

)j\Gamma ! z, we take `

1

)j\Gamma ! `

3 followed by `3

]\Theta 2\Gamma \Gamma ! z. The second

path matches what happens operationally, namely that we return the pair from function f
along the edge `1

)j\Gamma ! `

3 and then select the second component of the pair. However, on this

path, the constructor and instantiation parentheses are not properly nested, since [\Theta 2 does

not match up with )j.

If we interpret the first flow path operationally, we see that we select the second component of the pair within function f prior to returning it in order to properly nest [\Theta 2 and
]\Theta 2 within (j and )j. The reason we can always do this is that we work with a structural

46

subtyping system, where subsumption steps oe1 ^ oe2 always require that the type structure
of oe1 and oe2 are the same. This results in the following property:

Lemma 3.1 If there is matched flow C ` `1 m `2 from label `1 to `2 and `1 annotates o/1
and `2 annotates o/2, then o/1 = o/2.

Although we do not have a direct soundness proof for the POLYTYPE system, we believe that at least for the case where type polymorphism is restricted to non-recursive MLpolymorphism, the proof of soundness can be reduced to the proof of POLYFLOW by examining the monomorphic type expansion. A proof of the recursive polymorphic case is left
as future work.

3.1.3 Practical Aspects of Constraint Generation
Given the family of extra grammar productions M  [ci M ]ci and M  [ci M ]ci, it
is no longer necessary for the subtype relation C ` oe ^ oe0 to relate labels at all levels
of oe and oe0, since these relations can be derived indirectly as CFL-reachability via the
extra productions. This is an important aspect in practice, for it allows us to derive yet
fewer constraints when generating the initial type instantiation graph. Taking this idea
to its logical extreme suggests that we also delay the downward closure of instantiation
constraints. Instead of relating every label in oe _i+ oe0 via an instantiation constraint, we
only relate the labels of the top-level constructor in oe and oe0. The remaining relations can
be recovered through this one and the extra grammar productions spelled out below (and
similarly for p and n edges):

)i  [ci )i ]ci ci covariant in c
(i  [ci )i ]ci ci contravariant in c
(i  [ci (i ]ci ci covariant in c
)i  [ci (i ]ci ci contravariant in c

Figure 3.5 illustrates the application of the first two rules to a function type constructor.
The original instantiation edge `0 )

i\Gamma ! `0

0 gives rise to the two edges `2

)i\Gamma ! `0

2 and `01

(i\Gamma ! `

1.

Recall that given a program of size m, the number n of distinct labels and constraints

generated in the type-monomorphic case is exponential in m in the worst case. The reason
for the exponential difference is that the unlabeled type structure can be represented as a
DAG with size O(m), whereas the labeled type structure is a tree of the same shape, because
shared type structures are labeled independently.

If we delay the downward closure of subtyping and instantiation steps during constraint
generation as outlined above and generate labels on types only on demand, the number of
distinct labels, flow, and instantiation edges is bounded by O(m).

In the type-polymorphic case, the size of the unlabeled type graph can itself be exponential in m, and the labeled type graph is then doubly-exponential in m. However, experience
with ML typing has shown that in practice this situation does not arise. In any case, using
the delayed strategy for flow and instantiation constraints, we still generate only O(m) edges
and labels. Of course, any query of the system may potentially involve closing the graph,
and thus generating the exponential or doubly exponential number of labels and edges in
the worst case. In practice we expect the demand-driven queries to explore only small parts
of the labeled structure.

47

fflffi flfi\Phi \Psi  \Omega ff! `

0

zzzz

zzzz DDDDDDD

D

)i
fifi

`1 `2

)i
fifi

$

#

!

O/

AE
oe
ae

fflffi flfi\Phi \Psi  \Omega ff! `0

0

----

---- CCCCCCC

C

)i

LL

`01
(i

LL

$
#
!
O/AE

oe

ae

`02
Figure 3.5: Graphical illustration of extra productions
We haven't sketched how the demand-driven strategy decides what labels to quantify
over. The trick is to choose a derivation where we can quantify over every label in the
quantified type by using the same trick used in the proof of the soundness theorem, namely
that we use a subsumption step in the let and letrec rules to freshen the labels of oe1. This
guarantees that any label in oe1 can be instantiated to a fresh label at all instances.

Such a demand-driven scheme can be implemented by using two data structures with
the following signatures:

T : L ! o/
M : L ! N ! L

Structure T is a map from labels to types. For this map to exist, we require that each
label annotate a unique type. The second map M is used to traverse the labeled type
structure. Given a label `1 and a child index k, M ` k produces the label annotating the
kth child position of the labeled type annotated by `1. Initially, the two maps are empty. As
constraint derivation proceeds, the mappings T and M are extended necessary. The original
size of T and M will be O(m). During CFL-closure for a particular query, the maps M and
T are consulted and further extended as necessary.

3.2 POLYEQ: An Efficient Special Case
Context-sensitivity based on Hindley-Milner style polymorphic type inference is in wide
spread use due to its good practical running time. The low cost of such inference based
analyses stems from the use of unification to model intra-procedural dependencies of values. Inter-procedural dependencies of values is captured by instantiations of polymorphic
function types, but this information is generally ignored.

Here we view Hindley-Milner style polymorphism as a special case of POLYTYPE with
a number of restrictions that allow for a more efficient flow algorithm. The resulting system
is called POLYEQ and has the following characteristics:

ffl The type system does not admit the subsumption rule [Sub], thus there are no flow

constraints C.

48

ffl Each polymorphic type variable ff has a single unique hole label hff used at every

occurrence of ff.

ffl Individual all sources--one sink flow queries can be answered in time O(n) in the size

of the type instantiation graph.

In the absence of subtyping, the flow of values within an instantiation context is entirely
modeled by equivalence classes. The flow of values between different instantiation contexts
is characterized by instantiation edges, which are directed.

3.2.1 Type System
As described above, the type system of POLYEQ differs from POLYTYPE only in the omission of the [Sub] rule, along with the restriction that if two hole variables hff1 and hff2 are
associated with the same type variable ff, then hff1 = hff2 . We thus do not restate the rules
here.

3.2.2 Flow Computation
The computation of flow queries on GCFL degenerates from a CFL-reachability problem to
an RE-reachability problem (regular expression). To obtain the form of the RE-reachability
problem, consider the grammar in Figure 3.4. We reproduce the productions for nonterminal M representing matched flow below:

M  (i M )i

j [ci M ]ci ci covariant in c
j [ci M ]ci ci contravariant in c
j M M
j d
j ffl

Since we have no directed edges, the production M  d can be omitted. We now show by
induction on the grammar reductions that the only M -edges produced by this grammar for a
graph GCFL are self-loops. The base case for the epsilon production is trivial. Next, consider
the production M  [ci M ]ci. By induction, the M in the right-hand side represents a selfloop on a label `. Thus the edges labeled by [ci and ]ci arise from the same constructor edge
rooted at ` and form a loop. The M -edge produced is a self-loop on the other end-point of
this loop, namely the ith child of `. The case for M  [ci M]ci is analogous. The transitivity
rule M  M M is trivial. Finally, consider M  (iM )i. Recall that this rule encodes the
following situation of instantiation constraints

`1

_i\Xi fflfflO/O/
O/ `2

_i+fflfflO/O/
O/

`01 M 55 `02
where we have `1 m `2. By induction, we have `1 = `2. Since instantiation edges represent
substitutions, we must have `01 = `02. Thus the added M -edge on `01 forms a self-loop.

49

Test program Code lines AST nodes Ave. deref size Analysis time (secs)

Mono Poly Mono Poly Flow

compress 1,904 2,234 7 3 0.5 0.6 10.7%
li 7,602 23,379 282.1 185.2 1.8 40.9 93.2%
m88ksim 19,412 65,967 107.3 11.6 4.6 11.5 42.8%
ijpeg 31,215 79,486 37.9 11.1 7.0 44.8 80.7%
go 29,919 109,134 51.3 16.6 4.7 9.9 38.1%
perl 26,871 116,490 51.1 21.1 7.6 16.4 39.8%
vortex 67,211 200,107 1661.3 61.9 17.3 161.3 79.5%
gcc 205,406 604,100 429.5 91.8 42.3 179.5 64.7%

Table 3.1: Raw measurement data: Lines of code and AST node count. Average sizes of
points-to sets at static dereference points, and running time in seconds.

Given that M only derives empty strings, we can simplify the grammar considerably to

S  P N
P  p P

j ffl
N  n N

j ffl

This grammar only accepts sequences formed by the regular expression p\Lambda n\Lambda . We call such
paths P N -paths. P N -path reachability can be computed in O(n) time for a graph of size n
(n nodes, O(n) edges) for all sources--one sink, or all sinks--one source queries. Computing
all queries takes O(n2) time.

3.2.3 Practical Applications
Given the restrictions on POLYEQ, derivations become equivalent to their underlying HindleyMilner or Milner-Mycroft type derivation. There is a one-to-one mapping between type
nodes and labels. Thus, labels need no longer be explicitly represented. All that is needed
are the instantiation constraints corresponding to the substitutions on the type structure at
instantiation sites. This opens up the possibility of retrofitting the above flow analysis onto
existing type analyses based on Hindley-Milner style polymorphism.

As a practical application, we use POLYEQ to compute points-to information and function pointer information for the C programming language. To show that our techniques
scale to large programs we present numbers for an implementation of the described type
inference and flow algorithms. We show the precision improvements gained over a monomorphic version in the context of points-to analysis. The monomorphic version corresponds to
Steensgaard's analysis [Ste96].1

We analyze a range of C programs from the SPEC benchmark suite. The raw numbers
are given in Table 3.1. All experiments were run on a Dell Precision 610 with 512MB
of memory. To measure the precision of the points-to analysis, we count points-to set
sizes at static pointer dereference points only (direct accesses to arrays are not counted as
dereferences).

1Library function stubs are treated polymorphically, no conditional unification is used.

50%%[ ProductName: GPL Ghostscript ]%%


0
20
40
60
80
100

compress

li

m88ksim ijpeg

go perl vortex gcc

Benchmark
Normalizeddereferencesetsize

Monomorphic Polymorphic%%[Page: 1]%%
%%[LastPage]%%


Figure 3.6: Reductions of points-to sizes%%[ ProductName: GPL Ghostscript ]%%


0
500
1000
1500
2000

compress

li

m88ksim ijpeg

go perl vortex gcc

Benchmark

Analysistime(uspernode)

Monomorphic Instantiationoverhead Flowstepoverhead%%[Page: 1]%%
%%[LastPage]%%


Figure 3.7: Running times%%[ ProductName: GPL Ghostscript ]%%


0
6
12
18

compress

li

m88ksim ijpeg

go perl vortex gcc

Benchmark

Multipleof#Nodes Monomorphic

#Nodes:Polymorphic #Instantiationedges%%[Page: 1]%%
%%[LastPage]%%

Figure 3.8: Space overhead

Figure 3.6 shows the reductions in the average points-to set size obtained through polymorphism. The most dramatic reduction is obtained for Vortex, where the average points-to
set size drops from 1661 to 62. Even for GCC, we get almost a factor of 5 reduction in the
average points-to set size.

Figure 3.7 gives the running time of the monomorphic and the polymorphic analyses.
We give the time per abstract syntaxt tree node to show the scaling behavior. The running
time is broken down into monomorphic running time, time for computing the polymorphic
type instantiation graph (in excess of the monomorphic time), and the time to compute
the flow result. The numbers show that the polymorphic type instantiation graph can be
computed with little overhead over a monomorphic analysis. The time to compute the flow
information however is a substantial fraction of the analysis time. Fortunately, the absolute
times are small (! 3mins for gcc). The flow computation is currently implemented as a
forward-only flow, where each symbol is propagated along all P N -paths. We believe this
naive implementation can be improved substantially.

Finally, Figure 3.8 shows the space consumption of the polymorphic analysis as a factor
of the space consumption of the monomorphic analysis. The space is broken down into
type nodes and instantiation edges. The space overhead of polymorphism is substantial and
currently the main inhibitor to scaling the analysis to very large programs. We are able
to construct the final type instantiation graph for MS Word (2.1MLoc) within 512MB of
memory, but exceed memory during the flow computation. Finding ways to further reduce
the memory consumption is part of future work.

51

let pair = *y:int. (a`a, y`y )`p in
let z = (pairi b`b).2`z
...

`p **
\Theta 1

\Delta \Delta \Delta \Delta 

\Delta \Delta \Delta \Delta  \Theta 2======

= h

fi
2

)i
flfl
p

jj
`a `y

`1
\Theta 1

~~~~

~~~~ \Theta 2@@@@@@@

@

`b

(i

MM

n
QQ

`2 `z
Figure 3.9: Non-structural subtyping example
3.3 Extensions
3.3.1 Non-Structural Subtyping
So far, we have assumed that all subtyping steps are structural. Non-structural subtyping
allows subtyping judgments of the form oe1 ^ oe2, where oe1 and oe2 do not necessarily have
the same structure. An example of such a system is the type system based on set constraints
presented in [AW92]. Non-structural subtyping can lead to the problem that although there
is a path between two labels, every path contains interleaved matchings of instantiations
and constructor labels.

Consider the non-structural case depicted in Figure 3.9 for a simpler example than the
one in Figure 3.3. Non-structural subtyping can give the type 8`yfih2:int`y ! fih2 to pair,
along with a non-structural subtyping side constraint int`a \Theta `p int`y ^ fih2 . At instance i,
fih2 instantiates to the pair int`2 \Theta `1 int`z . In order to find flow from b to z, we are forced
to take the path with interleaved parentheses

`b (

i\Gamma ! `y [\Theta 2\Gamma \Gamma ! `p ! h

2

)i\Gamma ! `

1

]\Theta 2\Gamma \Gamma ! `

z

As the example shows, non-structural subtyping cannot be allowed arbitrarily, but it is
still possible to mix structural and non-structural subtyping as long as we can guarantee
that if there is an interleaved path from `1 to `2 with matched instantiation and constructor
labels, then there also exists a path with perfectly nested matchings of instantiation and
constructor labels. The condition for such nested matchings to exist is simple.

Conjecture 3.2 In the presence of non-structural subtyping, flow paths with perfect nesting
of instantiation edges and constructor edges exist as long as the type structure of any type
annotated with a quantified label ` is fully expanded to the underlying Milner-Mycroft type
structure.

This requirement is weaker than the one of Lemma 3.1. It guarantees only that if there
is matched flow `0 m ` or ` m `0, and ` is a quantified label (i.e., it appear to the left

52

of some instantiation constraint), then the type structure annotated by ` is as concrete as
the type structure annotated by `0. We also make the implicit assumption that no label
annotates two structurally distinct types.

Our formulation of the type rules [Let] and [Letrec] already require the quantified type
oe1 to be as expanded as the underlying Milner-Mycroft type o/ . It is thus already admissible
in our type system to use non-structural subtyping steps in the subsumption rule [Sub].

One can relax the structural requirements on types even further by observing that nested
matchings need only exist on paths connecting input with output labels. Consider again
Figure 3.9 and the flow path from `a to `2:

`a

[\Theta 1\Gamma \Gamma ! `

p ! hfi2

p\Gamma ! `

1

]\Theta 1\Gamma \Gamma ! `

2

Here we have an interleaving of p-edges and constructor edges. Such an interleaving is
however not a problem, since p (or n) edges do not enter into matched flow. It is possible
to recognize such paths using the extra grammar rules below:

S  P [ci S ]ci N
P  [ci P ]ci
N  [ci N ]ci

The minimal expansion of the type structure needed for the program in Figure 3.9 is therefore
as follows:

`p **

\Theta 1

\Delta \Delta \Delta \Delta 

\Delta \Delta \Delta \Delta  \Theta 2======

= h

fi
2

\Theta 2

???
???
?

)i
flfl
p

jj
`a `y `0

)i
flfl
p

jj
`1
\Theta 1

~~~~

~~~~ \Theta 2@@@@@@@

@

`b

(i

MM

n
QQ

`2 `z
Note that the pair type structure at hfi2 only expands the right component. The left component does not need expansion. We capture these weaker requirements for existence of
perfectly nested paths as follows.

Conjecture 3.3 (Partial Labeling) In the presence of non-structural subtyping, flow paths
with perfect nesting of instantiation and constructor edges exist if for every input label `1
and output label `2 of the fully annotated polymorphic type 8~`:o/ hsi such that there is matched
flow from `1 to `2, the actual type used in the type instantiation graph must be expanded to
contain at least `1 and `2.

The restriction to input and output labels makes clear that we only care about paths that
may involve matched instantiation edges. Paths that involve p and n edges are handled
by the extra grammar rules shown above. The view put forth here is that non-structural
subtyping is a way of dealing with partially labeled types.

The advantage of using some non-structural subtyping steps in a derivation lies in that it
may substantially reduce the size of the resulting type instantiation graph and the number
of flow and instantiation edges.

53

3.3.2 Recursive Types
Recursive types describe regular infinite tree structures. Such structures have finite representations, for example as _-types of the form _ff:o/ , where ff may occur in o/ . Such a
_-type encodes the equation ff = o/ . Extra fold/unfold type rules describe the equivalence of
infinite types with distinct representations. The standard rule for unfolding recursive types
in non-annotated type systems is simply:

A ` e : _ff:o/
A ` e : o/ [_ff:o/ =ff]

Viewed in the world of labeled types, recursive types give rise to infinite labeled types, where
each node in the infinite tree may be labeled by a distinct label. Recursive types are only
of interest in the presence of recursive functions that manipulate such infinite structures.
Without recursive functions, any program can only inspect a finite prefix of these infinite
trees, and therefore an explicit labeling is possible. This view is consistent with the view
put forth in the previous section on non-structural subtyping. Even though the underlying
type structure is fixed and possibly infinite, we deal with only partially labeled types.

In the presence of recursive functions, programs can build and inspect recursive data
structures up to unbounded depth. In general, the partial labeling requirement put forth
in Conjecture 3.3 leads to infinitely labeled types. For example, let list = _ff:int \Theta  ff be a
type for integer lists and let nil : list be the empty list value. The program

letrec double = *l.

if isNil l then nil
else

(l.1, (l.1, double l.2))

takes an input list l and produces an output list where elements 2i and 2i + 1 are equal to
element i of the input list. If we view the input type and the output type as infinite labeled
trees, we see that there is matched flow from the input type to the output type at arbitrary
depth.

As a result, it is not possible to expand the type structure only finitely and still obtain
a perfectly nested matching problem. There seem to be two alternatives. First, expand the
type structure as little as desired and deal directly with the interleaved matching problem.
As stated earlier, the general interleaved matching problem is undecidable [Rep00]. The
second alternative is to use a regular labeling of the infinite tree structure, where labels
reused infinitely many times. Using the same label to annotate multiple type nodes at
different depths of a recursive type introduces spurious flow between these type nodes. In
practice, this approach is the most natural one to use. The underlying type structure already
provides regular finite representations for the underlying infinite types in form of _-types.
We can translate those representations into regular labeled _-types as follows. Given _ff:o/ ,
let the regular labeled type _ff:o/ hsi be such that there exists a unique hole label hff in s
labeling all occurrences of the bound variable ff. Any unfolding of the regular labeled type
is obtained via the following rule.

C; A ` e : _ff:o/ hsi
'(hff) = s '(L) = L L 6= hff

C; A ` e : o/ [_ff:o/ =ff]h'(s)i (Unfold)

The substitution ' expands the hole variable hff into the label sequence s. Since s contains
hff itself, this expansion mirrors the type structure expansion o/ [_ff:o/ =ff].

54

When approximating infinite labeled types with regular labeled types, the number and
placement of fold/unfold steps in the program can have an influence on the precision. Minimizing the number of occurrences of fold/unfold steps through other means (e.g., tagging
optimization [Hen92]) might be beneficial.

3.4 Related Work
Mossin briefly touches upon the subject of flow analyses in the presence of polymorphic
type structure [Mos96]. Expressed in our formulation, e considers only two distinct hole
variables hff+ and hff\Xi  for each polymorphic type variable ff, where the first is used to annotate
positive occurrences of ff, and the second for negative occurrences of ff. Such an approach
approximates the flow of values by assuming that all input occurrences of a type variable ff
flow to all output occurrences of ff. For a function such as

twice : 8ff:(ff ! ff) ! ff ! ff
where twice f a = f (f a), the treatment he proposes yields strictly less precise flow
than our approach in POLYTYPE:

In [Rep00], Reps provides an elegant proof for the undecidability of flow queries in the
presence of interleaved call-return and constructor matchings. His presentation reduces
a variation of the post-correspondence problem to a flow query. His result provides an
excellent foundation for understanding the flow problems arising through the interaction of
polymorphic subtyping and recursive types.

The extension of CFL-based flow analysis to type polymorphism is also related to work by
O'Callahan and Jackson [OJ97]. They use polymorphic type inference for software analysis
of C programs. They define a symmetric compatibility relation between values based on
the instantiations of type variables. Their system is closest to POLYEQ. Our directed flow
relation of POLYEQ is a strengthening of their symmetric compatibility relation, providing
strictly better information at no extra cost.

55

Chapter 4
Conclusions
We presented a novel approach to computing context-sensitive flow of values through procedures and data structures. Our results are founded on a novel analysis of polymorphic
subtyping, as a combination of instantiation (or semi-unification) constraints and subtyping
constraints, and it includes polymorphic recursion.

The main contributions of this article are:

ffl A novel algorithm for computing context-sensitive, directional flow information for

higher order typed programs. Our algorithm improves the asymptotic complexity of a
known algorithm based on subtyping from O(n8) to O(n3). For intra-procedural flow
restricted to equivalence classes, our algorithm yields linear time inter-procedural flow
queries.

ffl Our algorithm is demand driven. We prove that context sensitive flow can be computed

by CFL (Context Free Language) reachability in polymorphic subtyping systems. This
result leads to a characterization of individual, valid context sensitive flow paths, and
it allows us to answer single flow queries on demand. The initial constraint graph is
linear in the size of the program.

ffl We transfer results on precise interprocedural dataflow analysis based on CFL reachability [RHS95] to the setting of type based analysis, resulting in an algorithm which
works directly on higher order programs with structured data.

ffl Our results open the door to new implementation techniques for flow analyses based on

polymorphic subtyping systems. By obviating the need to multiply copies of subtyping
constraints, our technique may circumvent one of the main scaling inhibitors for such
systems.

56

Bibliography
[AW92] A. Aiken and E. Wimmers. Solving systems of set constraints. In Proceedings

of the 7th Annual IEEE Symposium on Logic in Computer Science (LICS'92),
pages 329-340. IEEE Computer Society Press, June 1992.

[AWP97] A. Aiken, E. Wimmers, and J. Palsberg. Optimal representations of polymorphic

types with subtyping. In Proceedings of the International Symposium on Theoretical Aspects of Computer Science, pages 47-76. Springer Verlag, September
1997.

[CRL99] Ramkrishna Chatterjee, Barbara G. Ryder, and William A. Landi. Relevant

context inference. In Conference Record of the 26th Annual ACM SIGPLANSIGACT Symposium on Principles of Programming Languages, January 1999.

[Cur90] Pavel Curtis. Constrained quantification in polymorphic type analysis. Technical

Report CSL-90-1, February 1990.

[DHM95a] Dirk Dussart, Fritz Henglein, and Christian Mossin. Polymorphic recursion

and subtype qualifications: Polymorphic binding-time analysis in polynomial
time. In Alan Mycroft, editor, Proc. 2nd Int'l Static Analysis Symposium (SAS),
Glasgow, Scotland, volume 983 of Lecture Notes in Computer Science, pages
118-135. Springer-Verlag, September 1995.

[DHM95b] Dirk Dussart, Fritz Henglein, and Christian Mossin. Polymorphic recursion and

subtype qualifications: Polymorphic binding-time analysis in polynomial time.
Unpublished draft, May 1995.

[EST95] Jonathan Eifrig, Scott Smith, and Valery Trifonov. Sound polymorphic type

inference for objects. In Proceedings of the 10th annual Conference on ObjectOriented Programming Systems, Languages and Applications, volume 30:10 of
ACM SIGPLAN Notices, October 1995.

[FA96] Manuel F"ahndrich and Alex Aiken. Making set-constraint based program analyses scale. In First Workshop on Set Constraints at CP'96, Cambridge, MA,
August 1996. Available as Technical Report CSD-TR-96-917, University of California at Berkeley.

[FF97] Cormac Flanagan and Matthias Felleisen. Componential set-based analysis. In

PLDI'97 [PLD97], pages 235-248.

57

[FFA99] Jeffrey S. Foster, Manuel Fahndrich, and Alexander Aiken. Polymorphic versus

monomorphic points-to analysis. Technical Report ???, UC Berkeley, November
1999.

[FFSA98] M. F"ahndrich, J. Foster, Z. Su, and A. Aiken. Partial online cycle elimination

in inclusion constraint graphs. In Proceedings of the 1998 ACM SIGPLAN Conference on Programming Language Design and Implementation, number 33:5 in
SIGPLAN notices, pages 85-96, June 1998.

[FM88] Y. Fuh and P. Mishra. Type inference with subtypes. In Proceedings of the 1988

European Symposium on Programming, pages 94-114, 1988.

[FM89] Y. Fuh and P. Mishra. Polymorphic subtype inference: Closing the theorypractice gap. In Proc. Int'l J't Conf. on Theory and Practice of Software Development, pages 167-183, March 1989.

[Hen92] F. Henglein. Global tagging optimization by type inference. In LFP'92 [LFP92],

pages 205-215.

[Hen93] Fritz Henglein. Type inference with polymorphic recursion. ACM Transactions

on Programming Languages and Systems, 15(2):253-289, 1993.

[HM97] Nevin Heintze and David McAllester. Linear-time subtransitive control flow

analysis. In PLDI'97 [PLD97], pages 261-272.

[JW95] Suresh Jagannathan and Andrew Wright. Effective flow analysis for avoiding

run-time checks. In Proceedings of the 2nd International Static Analysis Symposium, volume 983 of Lecture Notes in Computer Science, pages 207-224. Springer
Verlag, September 1995.

[Kae92] S. Kaes. Type inference in the presence of overloading, subtyping and recursive

types. In LFP'92 [LFP92].

[LFP92] Proceedings of the 1992 ACM Conference on Lisp and Functional Programming,

June 1992.

[LH99] Donglin Liang and Mary Jean Harrold. Efficient points-to analysis for wholeprogram analysis. In Proceedings of the 7th European Software Engineering Conference and the 7th ACM SIGSOFT Symposium on the Foundations of Software
Engineering, September 1999.

[Mos96] Christian Mossin. Flow Analysis of Typed Higher-Order Programs. PhD thesis,

DIKU, Department of Computer Science, University of Copenhagen, 1996.

[MR97] David Melski and Thomas Reps. Interconvertibility of set constraints and

context-free language reachability. In Proceedings of the ACM SIGPLAN
Symposium on Partial Evaluation and Semantics-Based Program Manipulation
(PEPM-97), volume 32, 12 of ACM SIGPLAN Notices, pages 74-89. ACM Press,
June 1997.

[Myc84] A. Mycroft. Polymorphic type schemes and recursive definitions. In Proceedings

of the 6th International Symposium on Programming, pages 217-228, 1984.

58

[NN97] Flemming Nielson and Hanne Riis Nielson. Infinitary control flow analysis: a

collecting semantics for closure analysis. In POPL'97 [POP97], pages 332-345.

[OJ97] Robert O'Callahan and Daniel Jackson. Lackwit: A program understanding tool

based on type inference. In International Conference on Software Engineering,
May 1997.

[Pes00] Fran,cois Pessaux. D'etection Statique d'Exceptions non Rattrap'ee en Objective

CAML. PhD thesis, Universit'e Pierre & Marie Curie, Paris 6, 2000. in french.

[PLD97] Proceedings of the 1997 ACM SIGPLAN Conference on Programming Language

Design and Implementation, number 32:6 in SIGPLAN notices, June 1997.

[POP97] Conference Record of the 24th Annual ACM SIGPLAN-SIGACT Symposium on

Principles of Programming Languages, January 1997.

[Pot96] Fran,cois Pottier. Simplifying subtyping constraints. In Proceedings of the SIGPLAN '96 International Conference on Functional Programming (ICFP '96),
number 31:6 in SIGPLAN notices, pages 122-133, May 1996.

[Pot98] Franois Pottier. Type Inference in the Presence of Subtyping: From Theory to

Practice. PhD thesis, Universit'e Paris VII, July 1998.

[Reh97] J. Rehof. Minimal typings in atomic subtyping. In POPL'97 [POP97].
[Reh98] J. Rehof. The Complexity of Simple Subtyping Systems. PhD thesis, Dept. of

Computer Science, University of Copenhagen, Denmark, April 1998.

[Rep00] Thomas Reps. Undecidability of context-sensitive data-dependence analysis.

Transactions on Programming Languages and Systems, 2000. to appear.

[RHS95] Thomas Reps, Susan Horwitz, and Mooly Sagiv. Precise interprocedural

dataflow analysis via graph reachability. In Conference record of POPL '95,
22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages: papers presented at the Symposium: San Francisco, California, January
22-25, 1995, pages 49-61, 1995.

[Rit95] M. Rittri. Deriving dimensions under polymorphic recursion. In Proceedings of

the Conference on Functional Programming Languages and Computer Architecture, pages 147-159. ACM Press, June 1995.

[Smi94] Geoffrey S. Smith. Principal type schemes for functional programs with overloading and subtyping. Science of Computer Programming, 23(2-3):197-226,
December 1994.

[Ste96] Bjarne Steensgaard. Points-to analysis in almost linear time. In Conference

Record of the 23rd Annual ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages, pages 32-41, January 1996.

[TS96] Valery Trifonov and Scott Smith. Subtyping constrained types. In Proceedings of

the 3rd International Static Analysis Symposium, volume 1145 of Lecture Notes
in Computer Science, pages 349-365. Springer Verlag, September 1996.

59

Appendix A
Soundness Proof
We prove soundness of the system POLYFLOWCFL. We will do so by proving the system
sound relative to POLYFLOWcopy; since soundness has been established for a system sufficiently similar to POLYFLOWcopy in [Mos96], the soundness of POLYFLOWCFL follows from
the soundness results of [Mos96].

A.1 Overview of the proof
The flow relation for a program e determined by a typing t; I; C; A `CFL e : oe in POLYFLOWCFL is defined by the CFL-reachability relation I; C ` `  `0 on the labels appearing
in e. As we have seen, a central motivation for this relation is to rule out spurious flow
paths, thereby gaining precision in the flow analysis. From the point of view of soundness,
however, the problem is to ascertain that the flow relation does not rule out too many
paths, so that any flow that could be realized during any possible execution of the program
is accounted for. Hence, to prove soundness, we need to show that CFL-reachability is a safe
approximation (overestimates) the real flow of the program. We will do this by showing that
the flow relation safely approximates the flow relation defined by the system POLYFLOWcopy,
which is sufficiently close to the system studied by Mossin for which soundness has already
been established [Mos96]. In fact, we believe that the copy-based systems and the CFLbased system are equivalent with respect to precision, but we shall only be concerned with
soundness here.

Technically, the proof consists in showing that, for every derivation in POLYFLOWCFL,
there exists a derivation in POLYFLOWcopy such that the CFL-based flow relation defined by
the derivation in POLYFLOWcopy is a safe approximation of the flow defined by the derivation
in the copy-based system. A technical core in the proof is to show that our notion of CFLbased flow can recover all substitutions on constraint systems used in some copy-based
derivation. Suppose that we have a POLYFLOWCFL derivation of t; I; C; A `CFL e : oe. We
wish to show that there exists a derivation Cg0; I0; C0; A0 `cp e : oe0 in POLYFLOWcopy such
that, intuitively, the subtyping relation on the labels in e defined by the latter derivation
is safely approximated by the flow relation derivable from I and C under CFL-reachability.
The intuition why the CFL-based system works is then this, that all flow, which is explicit
in a copy-based system, can be recovered from the flow constraints (C) and the instantiation

60

(Types) o/ ::= int j o/ ! o/ j o/ \Theta  o/
(Labelled Types) o/ hsi; oe ::= int` j oe !` oe j oe \Theta ` oe
(Labels) L ::= ` j Fi `i

Figure A.1: Extended labelled types

constraints (I). As mentioned earlier, the central case we must be able to handle is this:

`1

_i\Xi fflffl

)) `

2

_i+fflffl

`3 55U . i `4

where flow from `3 to `4 is recovered by matched flow under CFL-reachability. This intuition provides the proof idea that we can construct the desired typing derivation of
Cg0; I0; C0; A0 `cp e : oe0 in POLYFLOWcopy from the given derivation of t; I; C; A `CFL e : oe
by closing the set C under matched flow, using the constraints in I and C. Let CI denote
this flow closure of C, i.e., we take CI to be the set of all flow constraints of the form ` ^ `0
where I; C `CFL ` m `0 holds. Then we will show that CI contains all the constraint copies
needed for a derivation in the copy-based system. The technical property needed here is
that, whenever a substitution ' is used at an instantiation site, then one has

CI ` '(CI ) (A.1)
that is, CI is closed under substitutions. This property will render CI applicable in the rule
[Inst] of POLYFLOWcopy.

It turns out that, in order for CI to have this property, one needs to require certain
properties of the derivation of t; I; C; A `CFL e : oe. Such derivations are called normal
derivations in the proof below. However, one can show that normal derivations can be
assumed without loss of generality, because an arbitrary derivation in POLYFLOWCFL can
be normalized.

The strategy of the proof is now the following. We first give a number of technical
definitions, in Section A.2. We then establish the property (A:1) in Section A.3 under certain
assumptions about the elements of the judgement t; I; C; A `CFL e : oe. The central notion
here is that of a normal instantiation context, defined in Section A.2. In Section A.4 we then
show that normal derivations satisfy the assumptions of Section A.3, and in Section A.5 we
show that normal derivations can always be obtained. Section A.6 concludes the soundness
proof by composing these results.

As a technical device for the soundness proof, we extend our type language and the
subtype logic with formal joins, as shown in Figure A.1 and Figure A.2. Whenever `1; : : : ; `n
is a series of labels, we can form the formal join Fi `i. Such joins are governed by the rules
[LubL] and [LubR] in the extended subtype logic shown in Figure A.2. The extended
language allows us to translate fixpoint types in polymorphic recursive typings of system
POLYFLOWCFL into fixpoint types of system POLYFLOWcopy. A similar method was used
by Mossin in [Mos96] to guarantee the existence of type fixpoints in his system.

61

C `^ oe ^ oe

C ` `1 ^ `2
C `^ int`1 ^ int`2 [Int]

C `^ oe1 ^ oe01 C `^ oe2 ^ oe02 C ` ` ^ `0

C `^ oe1 \Theta ` oe2 ^ oe01 \Theta `

0 oe0

2 [Pair]

C `^ oe01 ^ oe1 C `^ oe2 ^ oe02 C ` ` ^ `0

C `^ oe1 !` oe2 ^ oe01 !`

0 oe0

2 [Fun]

C ` `i ^ `; i = 1 : : : n

C ` Fni=1 `i ^ ` [LubL]

i 2 f1; : : : ; ng
C ` `i ^ Fni=1 `i [LubR]

Figure A.2: Extended subtype relation

A.2 Normal Instantiation Contexts
Definition 1 (Polarized constraint sets) Let C be a set of flow constraints, let oe be a
labelled type and let F ` f l(oe). We say that C is polarized with respect to oe and F , written
C BF oe, iff the following conditions hold for all ` 2 F :

1. whenever C ` ` ^ `0 with ` 6= `0, then ` occurs negatively in oe
2. whenever C ` `0 ^ ` with ` 6= `0, then ` occurs positively in oe
\Lambda 
Definition 2 (Instantiation context) Let C be a set of flow constraints, let I be a set of
instantiation constraints, let A be a set of type assumptions, let oe be a labelled type, and
let ' be a substitution on labels. The tuple of data hC; I; A; oe; 'i is called an instantiation
context. \Lambda 

Definition 3 (CFL closure) Let C be a set of flow constraints and let I be a set of instantiation constraints. We then construct a new set of flow constraints, called the CFL closure
of C with respect to I and denoted CI, defined by

CI = f` ^ `0 j I; C ` ` m `0g
That is, CI is the relation of matched CFL flow, considered as a flow constraint set. Notice
that, by rule [Level] of Figure 2.6, one has C ` CI for all I. \Lambda 

Definition 4 (Extended substitution) Let hC; I; A; oe; 'i be an instantiation context with
dom(') = gen(A; oe). For a label `, define the set of labels L(`; C; I; A; oe) by setting

L(`; C; I; A; oe) = f`0 2 f l(A) [ f l(oe) j CI ` `0 ^ `g

62

We write 'L(`; C; I; A; oe) to denote the set f'(`0) j `0 2 L(`; C; I; A; oe)g. The extended
substitution induced by the instantiation context hC; I; A; oe; 'i is denoted 'hC;I;A;oei. It has
domain dom('hC;I;A;oei) = gen(A; oe; C) and is given by

'hC;I;A;oei(`) = ae '(`) if ` 2 gen(A; oe)F 'L(`; C; I; A; oe) if ` 2 gen(A; oe; C) n gen(A; oe)
\Lambda 
Definition 5 (Normal instantiation context) An instantiation context hC; I; A; oe; 'i is called
a normal instantiation context at index i, if and only if the following conditions hold:

(i) dom ' = gen(A; oe)
(ii) C Bdom ' oe
(iii) I ` oe _i+ oe0 : '

(iv) 8` 2 f l(A): I ` ` _i+ ` and I ` ` _i\Xi  `

(v) Whenever I ` `1 _ip `2 and I ` `3 _jp0 `4 with `1 6= `2 and `3 6= `4, then `2 6= `3
(vi) f l(C) = f l(CI )
\Lambda 

Lemma A.1 If hC; I; A; oe; 'i is a normal instantiation context at index i, then CI Bdom 'oe.
Proof: Consider the first condition for CI Bdom ' oe from Definition 1. Suppose that ` 2
dom ' and CI ` ` ^ `0. We then must show that ` occurs negatively in oe. For this property,
it is sufficient to prove that, whenever I; C `CFL ` m `0 with ` 2 dom ', then ` occurs
negatively in oe. We prove this property by induction on the proof of I; C `CFL ` m `0, by
cases over the last rule used in the proof.

Suppose, for the base case, that the last rule used is

C ` ` ^ `0
I; C ` ` m `0 [Level]

Because hC; I; A; oe; 'i is a normal instantiation context, we have C Bdom ' oe, and so C `
` ^ `0 implies that ` occurs negatively in oe.

Suppose that the last rule used is

I; C ` ` m `1 I; C ` `1 m `0

I; C ` ` m `0 [Trans]

By induction hypothesis, I; C ` ` m `1 implies that ` occurs negatively in oe.

Suppose that the last rule used is

I ` `1 _j\Xi  ` I; C ` `1 m `2 I ` `2 _j+ `0

I; C ` ` m `0 [Match]

Suppose that `1 6= `. Now, we have ` 2 dom ', and therefore (by I ` oe _ip oe0 : ') it must
be the case that I ` ` _ip '(`) with '(`) 6= `. Therefore, since we also have I ` `1 _j\Xi  `, it

63

follows from the assumption that hC; I; A; oe; 'i is a normal instantiation context (condition
(v) of Definition 5) that ` 6= `, a contradiction. Hence, we must reject the assumption that
`1 6= `, so that we now have `1 = `. But then the induction hypothesis applied to the
premise I; C ` `1 m `2 shows that `1 = ` occurs negatively in oe.

There are no other rules applicable to derive I; C `CFL ` m `0, and the proof of the
desired property is complete. Proving the second property of Definition 1 is analogous and
left out. \Lambda 

Lemma A.2 Suppose that hC; I; A; oe; 'i is a normal instantiation context at index i, and
suppose furthermore that `0 and `1 are labels in f l(C) such that one of the following conditions is satisfied for each j = 0; 1:

(c1) `j 2 gen(A; oe), or
(c2) `j 62 gen(A; oe; C)
Then '(`0) ^ '(`1) 2 '(CI ) implies I; C `CFL '(`0) m '(`1).
Proof: Notice that, since `0; `1 2 f l(C), one has that `j 62 gen(A; oe; C) implies `j 2 f l(A).
Also, since '(`0) ^ '(`1) 2 '(CI ), one has `0 ^ `1 2 CI . Finally, because hC; I; A; oe; 'i is
normal, Lemma A.1 yields that CI Bdom ' oe.

Let ` = '(`0) and `0 = '(`1). We proceed by cases, according to the four possible
combinations of the conditions (c1) and (c2).

Case (c2) \Gamma  (c2): `0 62 gen(A; oe; C); `1 62 gen(A; oe; C). Then `0 = `; `1 = `0, and we have
` ^ `0 2 C, from which we get I; C ` ` m `0 by rule [Level].

Case (c1) \Gamma  (c2): `0 2 gen(A; oe); `1 62 gen(A; oe; C). In this case, one has `1 = '(`1) = `0.
Since `0 2 gen(A; oe) with `0 ^ `1 2 CI , it follows from CI Bdom ' oe that `0 occurs negatively
in oe. It then follows from the assumption that hC; I; A; oe; 'i is normal (condition (iii) of
Definition 5), that we have

I ` `0 _i\Xi  ` (A.2)
Since `1 2 f l(C) and `1 62 gen(A; oe; C), it follows that `1 2 f l(A). Therefore, by the
assumption that hC; I; A; oe; 'i is normal (condition (iv) of Definition 5), we have I ` `1 _ip `1
for p = + and p = \Xi . Choosing this relation with p = +, we have I ` `1 _i+ `1. Because
`1 = `0, this yields

I ` `0 _i+ `0 (A.3)
Since `0 ^ `1 2 CI, it follows that we have I; C ` `0 m `1. Because `0 = `1, we therefore
have

I; C ` `0 m `0 (A.4)
Composing (A:2),(A:3) and (A:4) we get I; C ` ` m `0, by rule [Match], as desired.

Case (c2) \Gamma  (c1): `0 62 gen(A; oe; C); `1 2 gen(A; oe). In this case we have `0 = '(`0) = `.
Since `1 2 gen(A; oe) with `0 ^ `1 2 CI , it follows from CI Bdom ' oe that `1 occurs positively
in oe. It then follows from the assumption that hC; I; A; oe; 'i is normal (condition (iii) of
Definition 5), that we have

I ` `1 _i+ `0 (A.5)

64

Since `0 2 f l(C) and `0 62 gen(A; oe; C), it follows that `0 2 f l(A). Therefore, by the
assumption that hC; I; A; oe; 'i is normal (condition (iv) of Definition 5), we have I ` `0 _ip `0
for p = + and p = \Xi . Choosing this relation with p = \Xi , we have I ` `0 _i\Xi  `0. Because
`0 = `, this yields

I ` ` _i\Xi  ` (A.6)
Since `0 ^ `1 2 CI , it follows that we have I; C ` `0 m `1. Because ` = `0, we therefore
have

I; C ` ` m `1 (A.7)
Composing (A:5),(A:6) and (A:7) we get I; C ` ` m `0, by rule [Match], as desired.

Case (c1) \Gamma  (c1): `0 2 gen(A; oe); `1 2 gen(A; oe). Since `0 2 dom ' and `1 2 dom '
with `0 ^ `1 2 CI, it follows from CI Bdom ' oe that `0 occurs negatively in oe and `1 occurs
positively in oe. It then follows from the assumption that hC; I; A; oe; 'i is normal (condition
(iii) of Definition 5), that we have

I ` `0 _i\Xi  ` (A.8)
and

I ` `1 _i+ `0 (A.9)
Since we also have

I; C ` `0 m `1 (A.10)
by `0 ^ `1 2 CI, we can apply rule [Match] to (A:8), (A:9) and (A:10) to get I; C `CFL
` m `0, as desired. \Lambda 

Corollary 1 Suppose that hC; I; A; oe; 'i is a normal instantiation context at index i, and
let `0 and `1 be as stated in Lemma A.2. Then '(CI ) ` '(`0) ^ '(`1) implies I; C `CFL
'(`0) m '(`1).

Proof: By induction on the proof of '(CI ) ` '(`0) ^ '(`1), using Lemma A.2 for the base
case, together with reflexivity and transitivity of the relation m (using rules [Level] and
[Trans] of Figure 2.6) for the inductive cases. \Lambda 

A.3 Closure Under Substitution
Theorem A.3 Let hC; I; A; oe; 'i be a normal instantiation context at index i, and let b' =
'hC;I;A;oei. Then one has

CI ` b'(CI )
Proof: We are to show that whenever L ^ L0 2 b'(CI), then CI ` L ^ L0. So assume,
for arbitrary L; L0 that L ^ L0 2 b'(CI ). Then, for some `0; `1 2 f l(CI ) = f l(C), we have
`0 ^ `1 2 CI and b'(`0) = L and b'(`1) = L0. We can assume `0 6= `1, since otherwise we are
done. For each label `j, j = 0; 1, there are three disjoint cases to consider:

65

(c1) `j 2 gen(A; oe)
(c2) `j 2 gen(A; oe; C) n gen(A; oe)
(c3) `j 62 gen(A; oe; C)
This yields 9 possible cases for `0 and `1. We prove CI ` L ^ L0 by considering each of
these 9 possible cases. Notice that one has gen(A; oe) = dom('), gen(A; oe; C) = dom( b')
and hence gen(A; oe; C) n gen(A; oe) = dom( b') n dom(').

First consider all cases where `0 and `1 are either in gen(A; oe) = dom(') or not in
gen(A; oe; C) = dom( b'). These are just the combinations of the cases (c1) and (c3) above,
and in these cases we have b' = ', and Lemma A.2 gives the conclusion

I; C ` L m L0
in all of these cases. It then follows, by definition of CI , that CI ` L ^ L0 in all these cases.
We therefore only need to consider the remaining 5 combinations of (c1); (c2); (c3) which
are not combinations of (c1) and (c3).

Case (c1) \Gamma  (c2): `0 2 gen(A; oe); `1 2 gen(A; oe; C) n gen(A; oe). In this case we have by
Definition 4 that

L0 = b'(`1) = G 'L(`1; C; I; A; oe) (A.11)
and

L = b'(`0) = '(`0) (A.12)
Since `0 2 gen(A; oe), we have `0 2 f l(oe). Because `0 ^ `1 2 CI , we can conclude `0 2
L(`1; C; I; A; oe), by transitivity of ^. It follows that

'(`0) 2 'L(`1; C; I; A; oe) (A.13)
By (A:13) together with rule [LubR], one has ` '(`0) ^ F L(`1; C; I; A; oe). Using (A:11)
and (A:12), we can conclude ` b'(`0) ^ b'(`1), and hence CI ` L ^ L0 as desired.

Case (c2) \Gamma  (c1): `0 2 gen(A; oe; C) n gen(A; oe). In this case one has

L = b'(`0) = G 'L(`0; C; I; A; oe) (A.14)
and

L0 = b'(`1) = '(`1) (A.15)
Since `1 2 gen(A; oe), one has `1 2 f l(oe). Because `0 ^ `1 2 CI, we have

8`00 2 L(`0; C; I; A; oe): CI ` `00 ^ `1 (A.16)
Now, let `00 be an arbitrary label in L(`0; C; I; A; oe). Since ` is preserved under substitutions,
we can conclude '(CI ) ` '(`00) ^ '(`1) from (A:16). By definition of L(`0; C; I; A; oe), one
has `00 2 f l(A) [ f l(oe), and therefore either `00 2 gen(A; oe) or `00 62 gen(A; oe; C). Moreover,
`1 2 gen(A; oe). Corollary 1 is therefore applicable, and allows us to conclude

8`00 2 L(`0; C; I; A; oe): I; C `CFL '(`00) m '(`1) (A.17)

66

From (A:17) we can conclude that '(`00) ^ '(`1) 2 CI for all `00 2 L(`0; C; I; A; oe). By
rule [LubL] we then get CI ` F 'L(`0; C; I; A; oe) ^ '(`1), hence CI ` L ^ L0 follows from
(A:14) and (A:15), thereby proving the theorem in this case.

Case (c2) \Gamma  (c2): `0 2 gen(A; oe; C) n gen(A; oe); `1 2 gen(A; oe; C) n gen(A; oe). In this
case one has

L = b'(`0) = G 'L(`0; C; I; A; oe) (A.18)
and

L0 = b'(`1) = G 'L(`1; C; I; A; oe) (A.19)

Now, for all `00 2 L(`0; C; I; A; oe) one has CI ` `00 ^ `0. Hence, using `0 ^ `1 2 CI , one has
CI ` `00 ^ `1 for all `00 2 L(`0; C; I; A; oe). It follows that L(`0; C; I; A; oe) ` L(`1; C; I; A; oe),
and therefore we can conclude

'L(`0; C; A; oe) ` 'L(`1; C; A; oe) (A.20)
From (A:20), together with an application of rule [LubR] followed by an application of rule
[LubL], we get

` G 'L(`0; C; I; A; oe) ^ G 'L(`1; C; I; A; oe) (A.21)
But (A:21), (A:18) and (A:19) together show that ` L ^ L0, hence also CI ` L ^ L0, as
desired.

Case (c3) \Gamma  (c2): `0 62 gen(A; oe; C); `1 2 gen(A; oe; C) n gen(A; oe). In this case one has

L = b'(`0) = '(`0) = `0 (A.22)
and

L0 = b'(`1) = G 'L(`1; C; I; A; oe) (A.23)

Notice that, because `0 62 gen(A; oe; C), we must have `0 2 f l(A). Since `0 ^ `1 2 CI , it
follows that `0 2 L(`1; C; I; A; oe), hence '(`0) 2 'L(`1; C; I; A; oe), and therefore ` '(`0) ^F

'L(`1; C; I; A; oe) by rule [LubR]. Using (A:22) and (A:23) we can conclude ` L ^ L0,
hence CI ` L ^ L0, as desired.

Case (c2) \Gamma  (c3): `0 2 gen(A; oe; C) n gen(A; oe); `1 62 gen(A; oe; C). In this case one has

L = b'(`0) = G 'L(`0; C; I; A; oe) (A.24)
and

L0 = b'(`1) = '(`1) = `1 (A.25)
Since `0 ^ `1 2 CI , we have CI ` `00 ^ `1 for all `00 2 L(`0; C; I; A; oe). Since ` is preserved
under substitution, it follows that

8`00 2 L(`0; C; I; A; oe): '(CI ) ` '(`00) ^ '(`1) (A.26)

67

Let `00 be an arbitrary label in L(`0; C; I; A; oe). Then `00 2 f l(A) [ f l(oe) by definition. It
follows that either `00 2 gen(A; oe) or `00 2 gen(A; oe; C)ngen(A; oe). In either case, Corollary 1
is applicable to `00 and `1 because `1 62 gen(A; oe; C). From (A:26), we then conclude from
Corollary 1 that

8`00 2 L(`0; C; I; A; oe): I; C `CFL '(`00) m '(`1) (A.27)
In turn, it follows from (A:27) that '(`00) ^ '(`1) 2 CI for all `00 2 L(`0; C; I; A; oe). By
rule [LubL] we can then conclude that CI ` F 'L(`0; C; I; A; oe) ^ '(`1), thereby showing
CI ` b'(`0) ^ b'(`1) and hence (using (A:25) and (A:26)) we get CI ` L ^ L0, as desired. \Lambda 

A.4 Normal Derivations
Definition 6 (Normal derivation) Let D be a derivation (regarded as a proof tree) in
POLYFLOWCFL. Each application within D of rule [Inst] of the form

I ` oe _i+ oe0 : ' dom ' = ~` I ` s _i+ s I ` s _i\Xi  s

t; I; C; A; f : (8~`:oe; s) `CFL f i : oe0 [Inst]
is uniquely determined by the index i. Moreover, for every let- or letrec-bound variable
f we can assume (by suitably renaming variables) that there is a unique application of rule
[Let] or [Rec], respectively, in which the symbol f gets bound. The second premise of such
a rule application of the form

t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2
is referred to as the binding premise for f within D. The environment A in this rule
application is denoted env (D; f ) (notice that one has ~` = gen(env(D; f ); oe1) in the binding
premise for f ).

The first premise of an application of rule [Let] or [Rec] (that is, the premise which is
not the binding premise) is referred to as the minor premise of the rule application.

An instantiation site within D given by the symbol f i uniquely determines an application of rule [Inst] as shown above. This site determines the set of data I; C; f; oe; '. It
thereby determines the instantiation context hC; I; env (D; f ); oe; 'i, which is called the instantiation context determined by this application of rule [Inst]. We also refer to the context
hC; I; env (D; f ); oe; 'i as the instantiation context determined by index i, and we may denote
it Instcon(D; i).

Let Instcon(D) denote the set of all instantiation contexts determined by applications
of rule [Inst] in D. We say that a derivation D is a normal derivation if and only if every
instantiation context in Instcon(D) is normal (according to Definition 5). \Lambda 

Definition 7 (Translation on type assumptions) Let A be a set of type assumptions, C a
set of flow constraints and I a set of instantiation constraints. For a quantified type of the
form 8~`:oe, we define the qualified type (8~`:oe)hI;C;Ai by setting

(8~`:oe)hI;C;Ai = 8~`0:CI ) oe with ~`0 = gen(A; oe; C)
Let D be a derivation of the judgement

t; I; C; A0 `CFL e : oe
We translate a set of type assumptions A into AD given by

68

;D = ;
(A; x : oe)D = AD; x : oe
(A; f : (8~`:oe; t))D = AD; f : (8~`:oe)hI;C;env(D;f)i
\Lambda 

Definition 8 (Extension of instantiation sets) Let D be a derivation in POLYFLOWCFL
of the judgement t; I; C; A `CFL e : oe. We then define an extended set of instantiation
constraints ID:

ID = I [ f` _i+ 'hC;I;A;oei(`) j hC; A; oe; 'i = Instcon(D; i)g
Here, 'hC;I;A;oei is the extended substitution induced by the instantiation context hC; I; A; oei,
according to Definition 4. \Lambda 

Lemma A.4 (Translation of normal derivations) Suppose that

t; I; C; A `CFL e : oe
is derivable by a normal derivation D in system POLYFLOWCFL. Then the judgement

CI ; ID; CI; AD `cp e : oe
is derivable in system POLYFLOWcopy.
Proof: Let D be a normal derivation in system POLYFLOWCFL of the judgement t; I; C; A `CFL
e : oe. We translate every POLYFLOWCFL-judgement of the form

t0; I0; C0; A0 `CFL e0 : oe0
in D into the POLYFLOWcopy-judgement

CI00 ; ID0 ; CI00 ; AD `cp e0 : oe0
The derivation D thereby translates into a series of judgements, D0, in POLYFLOWcopy. One
can then verify, by induction on the derivation D, that the translated sequence of judgements
D0 constitutes a valid derivation in POLYFLOWcopy. The proof is by cases over the last rule
applied in D. We will do a few illustrative cases:

Suppose that the last rule used in D is [Inst], of the form

I ` oe _i+ oe0 : ' dom ' = ~` I ` s _i+ s I ` s _i\Xi  s

t; I; C; A; f : (8~`:oe; s) `CFL f i : oe0 [Inst]

Let hI; C; A0; '; oei be the instantiation context Instcon(D; i) = hI; C; env (D; f ); '; oei, and
let b' = 'hI;C;A0;';oei. It follows from the premise I ` oe _i+ oe0 : ' together with the definition
of ID (Definition 8) that we have

ID ` oe _i+ oe0 : b' (A.28)

69

Also, since the context hI; C; A0; '; oei is normal by assumption, Theorem A.3 shows that we
have

CI ` b'(CI ) (A.29)
Finally, by definition of AD (Definition 7) we have

(A; f : (8`:oe; s))D = AD; f : 8~`0:CI ) oe (A.30)
with ~`0 = gen(env (A0; f )). It follows from (A:28), (A:29) and (A:30) that the following
application of rule [Inst] is valid in POLYFLOWcopy:

ID ` oe _i+ oe0 : b' CI ` b'(CI) dom b' = ~`0

CI; ID; CI ; AD; f : 8~`0:CI ) oe `cp f i : oe0 [Inst]

and thereby proving the lemma in this case.

Suppose that the last rule used in D is [Sub], of the form

t; I; C; A `CFL e : oe C ` oe ^ oe0

t; I; C; A `CFL e : oe0 [Sub]

By induction, we have CI ; ID; CI ; AD `cp e : oe derivable in POLYFLOWcopy. Since C ` CI,
one has CI ` oe ^ oe0 by C ` oe ^ oe0. Hence, rule [Sub] is applicable in POLYFLOWcopy, and
it yields the conclusion yields CI ; ID; CI; AD `cp e : oe0, thereby proving the lemma in this
case.

Suppose that the last rule used in D is an application of the rule [Let], of the form

t; I; C; A `CFL e1 : oe1 ~` = gen(A; oe1)
t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2

t; I; C; A `CFL let f = e1 in e2 : oe2 [Let]

By induction, we know that

CI ; ID; CI ; AD `cp e1 : oe1
is derivable, and

CI ; ID; CI ; AD; f : 8~`0:CI ) oe1 `cp e2 : oe2
is derivable, with `0 = gen(env (D; f ); oe1). Now, by definition of env(D; f ) (Definition 7) and
AD (Definition 6), we can conclude that A = env (D; f). Moreover, because D is normal,
we have f l(C) = f l(CI ), It follows that we can write ~`0 = gen(A; oe1; C). Therefore, the
following application of the [Let] rule is valid in POLYFLOWcopy:

CI ; ID; CI ; AD `cp e1 : oe1
CI ; ID; CI ; AD; f : 8~`0:CI ) oe1 `cp e2 : oe2
CI ` CI ~`0 ` gen(A; oe1; CI )
CI ; ID; CI ; AD `cp let f = e1 in e2 : oe2 [Let]

thereby proving the lemma in this case.

70

Suppose that the last rule used in D is an application of the rule [Ret], of the form

t; I; C; A; f : (8~`:oe1; t) `CFL e1 : oe1 ~` = gen(A; oe1)
t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2

t; I; C; A `CFL letrec f = e1 in e2 : oe2 [Rec]

By induction, we know that

CI ; ID; CI ; AD; f : 8~`0:CI ) oe1 `cp e1 : oe1
is derivable in POLYFLOWcopy, and

CI ; ID; CI ; AD; f : 8~`0:CI ) oe1 `cp e2 : oe2
is derivable in POLYFLOWcopy, with `0 = gen(env (D; f ); oe1). Now, by definition of env(D; f )
(Definition 7) and AD (Definition 6), we can conclude that A = env (D; f). Moreover, because D is normal, we have f l(C) = fl(CI), It follows that we can write ~`0 = gen(A; oe1; C).
Therefore, the following application of the [Let] rule is valid in POLYFLOWcopy:

CI ; ID; CI; AD; f : 8~`0:CI ) oe1 `cp e1 : oe1
CI ; ID; CI; AD; f : 8~`0:CI ) oe1 `cp e2 : oe2
CI ` CI ~`0 ` gen(A; oe1; CI ) ` o/ hsi : oe1
CI; ID; CI ; AD `cp letrec f :o/ = e1 in e2 : oe2 [Rec]

thereby proving the lemma in this case.

The remaining cases are obvious and are left out. \Lambda 

A.5 Existence Of Normal Derivations
Definition 9 (Label closure) For labeled types oe1; oe2 we define the label closure of the
inequality oe1 ^ oe2, denoted lcl (oe1 ^ oe2), to be the set of flow constraints implied by the
constraint oe1 ^ oe2, as follows:

ffl lcl(int`1 ^ int`2 ) = f`1 ^ `2g
ffl lcl(oe1 \Theta `1 oe2 ^ oe3 \Theta `2 oe4) = f`1 ^ `2g [ lcl(oe1 ^ oe3) [ lcl (oe2 ^ oe4)
ffl lcl(oe1 !`1 oe2 ^ oe3 !`2 oe4) = f`1 ^ `2g [ lcl(oe3 ^ oe1) [ lcl (oe2 ^ oe4)
Notice that one has

lcl (oe1 ^ oe2) ` oe1 ^ oe2
\Lambda 
Lemma A.5 (Existence of normal derivations) For every derivation D of a judgement

t; I; C; A `CFL e : oe
in POLYFLOWCFL there exist C0 and I0 and a normal derivation DN of

t; I0; C0; A `CFL e : oe
such that for all `; `0 in f l(e) one has

I0; C0 ` ` m `0 ) I; C ` ` m `0

71

Proof: The proof is in 3 steps. We first (step I) introduce transformations on derivations,
which transforms a given derivation D into a new derivation DN . We then show (step II)
that the resulting derivation DN is indeed normal. Finally (step III), we show that the
property

I; C ` ` m `0 ) I; C ` ` m `0
holds.

We assume w.l.o.g. that the given derivation D satisfies the folowing binding properties:

ffl Any two program variables bound by distinct let- or letrec-bindings are distinct,

and

ffl Whenever f : (8~`:oe; t) and g : (8~`0:oe0; t0) are two distinct type assumptions occurring

in distinct binding premises (Definition 6) of D, then the labels in ~` and ~`0 are disjoint.

ffl Whenever '1 and '2 are substitutions used at any two applications of rule [Inst] in

D, one has dom '1 " dom '2 = ;.

These properties can always be obtained by renaming let- or letrec-bound bound program
variables and by renaming bound type labels.

Step I. Let a derivation D of the judgement t; I; C; A `CFL e : oe be given in POLYFLOWCFL. To obtain DN from D, we perform local transformations on every application of
rule [Let] and [Rec] in D, as described next.

To describe the transformations of derivations, we need a few technical preliminaries.
For each let- or letrec-bound variable f in D, let TyBind (D; f ) = oe, where oe is the

uniquely determined type such that the binding f : (8~`:oe; t) occurs in a binding premise
within D, and let LabBind (D; f ) denote the set of labels in ~`, where ~` is the vector of labels
bound in that binding premise. Notice that the binding properties assumed for D ensure
that one has

LabBind (D; f ) " LabBind (D; g) = ;
for any f and g occurring in distinct binding premises in D. Fix a let- or letrec-bound variable f in D. Let f be a renaming on LabBind (D; f ), mapping the labels in LabBind (D; f )
to distinct labels which are to be kept fresh throughout DN such that for any substitutions
'1; '2 applied at any instantiation sites in DN , one has:

dom '1 " dom '2 = ; (A.31)
and

dom '1 " ran '2 = ; (A.32)
where we set ran ' = f'(`) j ` 2 dom 'g. Using our assumption that D satisfies the binding
properties mentioned above, it is clear that f can be chosen in such a way that these
conditions are satisfied.

For each oe 2 TyBind (D; f ), let oef = f (oe) and define the constraint set Cf by

Cf = C [ lcl (oe ^ oef )

72

and define the set of instantiations constraints If by

If = ff (`) _ip `0 j ` _ip `0 2 Ig
Transformation of applications of rule [Let]. Consider an untransformed application of
rule [Let] within D of the form

t; I; C; A `CFL e1 : oe1
~` = gen(A; oe1)

t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2
t; I; C; A `CFL let f = e1 in e2 : oe2 [Let]

This application of rule [Let] gets transformed into the following series of judgements:

t; If ; Cf ; A `CFL e1 : oe1 Cf ` oe1 ^ oef1

t; If ; Cf ; A `CFL e1 : oef1 [Sub] J
t; If ; Cf ; A `CFL let f = e1 in e2 : oe2 [Let]

where

J = t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e2 : oe2
and ~`0 = gen(A; oef1 ). This series of judgements enters into a valid subderivation of POLYFLOWCFL. To see this, first consider that we have

t; If ; Cf ; A `CFL e1 : oe1 Cf ` oe1 ^ oef1

t; If ; Cf ; A `CFL e1 : oef1 [Sub]

because lcl (oe1 ^ oef1 ) ` Cf by definition of Cf . Secondly, since by assumption we can derive

t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2
we can also derive

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e2 : oe2
by renaming of bound variables: any instantiation of the type of f used to type e2 in the
derivation of the former judgement can be performed on the type of f in the latter judgement
to type e2 in the same way. It follows that we can apply the [Let] rule as follows:

t; If ; Cf ; A `CFL e1 : oef1 ~`0 = gen(A; oe0)
t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e2 : oe2

t; If ; Cf ; A `CFL let f = e1 in e2 : oe2 [Let]

We can now compose the application of [Sub] with the application of [Let] to obtain a valid
subproof of

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e2 : oe2

73

Transformation of applications of rule [Rec]. Consider an untransformed application of
rule [Rec] within D of the form

t; I; C; A; f : (8~`:oe1; t) `CFL e1 : oe1

~` = gen(A; oe1)

t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2
t; I; C; A `CFL letrec f = e1 in e2 : oe2 [Rec]

This application of [Rec] gets transformed into the following series of judgements:

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e1 : oe1 Cf ` oe1 ^ oef1

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e1 : oef1 [Sub] J

t; If ; Cf ; A `CFL letrec f = e1 in e2 : oe2 [Rec]

where

J = t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e2 : oe2
and ~`0 = gen(A; oef1 ). This series of judgements enters into a valid subderivation of POLYFLOWCFL. To see this, first consider that we have

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e1 : oe1
derivable, because (by assumption) we can derive

t; I; C; A; f : (8~`:oe1; t) `CFL e1 : oe1
The derivability of the former judgement follows from the derivability of the latter by renaming bound variables, as argued previously (in the case of [Let], above). We then have

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e1 : oe1 Cf ` oe1 ^ oef1

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e1 : oef1 [Sub]

because lcl (oe1 ^ oef1 ) ` Cf by definition of Cf . Finally, since by assumption we can derive

t; I; C; A; f : (8~`:oe1; t) `CFL e2 : oe2
we can also derive

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e2 : oe2
by renaming of bound variables. We can then apply the [Rec] rule as follows:

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e0 : oef1 ~`0 = gen(A; oef1 )
t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e2 : oe2

t; If ; Cf ; A `CFL letrec f = e1 in e2 : oe2 [Rec]

We can now compose the application of [Sub] with the application of [Rec] to obtain a valid
subproof of

t; If ; Cf ; A; f : (8~`0:oef1 ; t) `CFL e2 : oe2

74

By repeated application of the two proof transformation we can construct a transformed
derivation D0 of

t; I\Lambda ; C\Lambda ; A `CFL e : oe
Finally, in order to turn D0 into a normal derivation DN , we add the trivial inequality ` ^ `
to C\Lambda  of D0, for every label ` which occurs in I\Lambda  but not in C\Lambda . Let C0 be the resulting
constraint set:

C0 = C\Lambda  [ f` ^ ` j ` 2 f l(I\Lambda ) n f l(C\Lambda )g
Finally, set I0 = I\Lambda . Step II. We now argue that the resulting derivation DN of the judgement

t; I0; C0; A `CFL e : oe
is indeed normal. To do this, let instcon(DN ; i) = hC0; I0; Ai; oe; 'i be an arbitrary instantiation context in Instcon(DN ). We have Ai = env (DN ; f ) and oe = oe(D;f)0 for some f at
instantiation site f i. We must then show the following properties, according to Definition 5:

(i) dom ' = gen(Ai; oe)
(ii) C0 Bdom ' oe
(iii) I0 ` oe _i+ oe0 : '

(iv) 8` 2 f l(Ai): I0 ` ` _i+ ` and I0 ` ` _i\Xi  `

(v) Whenever I0 ` `1 _ip `2 and I0 ` `3 _jp0 `4 with `1 6= `2 and `3 6= `4, then `2 6= `3
(vi) f l(C0) = f l((C0)I

0)

with oe = oe(D;f). We consider each property in turn.

(i) dom ' = gen(A; oe) follows from the rules of POLYFLOWCFL.
(ii) C0 Bdom ' oe follows from the proof transformations on the applications of [Let] and

[Rec]. By these transformations, each such rule is applied with a binding premise for f
having a binding of the form A = Ai; f : (8~`0:oef , where dom ' = gen(Ai; oef ) = ~`0. By
construction of DN , it is the case that C0 contains exactly the set of flow constraints
lcl(oe ^ oef ) where the flow variables in ~`0 are all distinct and occur only in oef . It
follows directly from this property that C0 Bdom ' oef .

(iii) I0 ` oe _i+ oe0 : ' follows from the rules of POLYFLOWCFL, for suitable oe0.

(iv) 8` 2 f l(Ai): I0 ` ` _i+ ` and I0 ` ` _i\Xi  ` follows from the rules of POLYFLOWCFL.

(v) Whenever I0 ` `1 _ip `2 and I0 ` `3 _jp0 `4 with `1 6= `2 and `3 6= `4, then `2 6= `3. This

property follows from (A:32), as follows. If I0 ` `1 _ip `2, then `1 is in the domain of
', provided `1 6= `2. Therefore, `2 is in the range f '. Similarly, if `3 6= `4 then `3 is in
the domain of some substitution '0 used at instantiation site j. Hence, if `2 = `3, then
the label `2 is in the domain of '0. But `2 is also in the range of '. This contradicts
property (A:32) of the construction of DN and is therefore impossible.

75

(vi) f l(C0) = f l((C0)I

0 ) holds by construction of C0 from C\Lambda  above: CFL closure cannot

introduce any variables not already present in the original constraint set or I0. Since
f l(I0) ` f l(C0), the property follows.

Step III. We now show that the property

I0; C0 ` `  `0 ) I; C ` `  `0
holds. But this property is clear from the construction of DN : the set C0 was constructed
from C by addition of inequalities of the form oe ^ oef , where oef arises from oe by renaming
variables, using flow variables that occur nowhere else (in particular, none of these flow
labels occur in the term e). It follows that the constraint set C can be obtained from the
set C0 by identifying flow variables. This operation can only increase the flow among the
labels in e that can be deduced from C in comparison to C0. \Lambda 

A.6 Soundness Theorem
Theorem A.6 (Soundness) For every judgement

t; I; C; A `CFL e : oe
derivable in POLYFLOWCFL there exists a judgement

C0; I0; C0; A0 `cp e : oe
derivable in POLYFLOWcopy such that, for all labels ` and `0 ocurring in e one has

I0; C0 `cp `  `0 ) I; C `CFL `  `0
Proof: By Lemma A.5, there is a judgement

t; I0; C0; A `CFL e : oe
derivable by a normal derivation D in POLYFLOWCFL and such that, for `; `0 2 f l(e) one
has

I0; C0 ` `  `0 ) I; C ` `  `0 (A.33)
By Lemma A.4, the judgement

(C0)I

0; (I0)D; (C0)I0; AD `

cp e : oe

is derivable in POLYFLOWcopy. It is easy to see, from the definition of (I0)D, that (I0)D and
I0 agree on the labels occurring in e. Then one has

(I0)D; (C0)I

0 `

cp `  `0 ) I0; C0 `CFL `  `0 (A.34)

Using (A:33) and (A:34) together, we get

(I0)D; (C0)I

0 `

cp `  `0 ) I; C `CFL `  `0

Taking C0 = (C0)I

0 ; I

0 = (I0)D; A0 = AD then establishes the theorem.

\Lambda 

76