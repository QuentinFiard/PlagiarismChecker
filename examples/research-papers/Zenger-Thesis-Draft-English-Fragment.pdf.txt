

Indexed Types

Christoph Zenger

Contents
1 Indices, Constraints and Types 21.1 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.2 Requirements for an Index System . . . . . . . . . . . . . . . . . 41.3 Some Index Systems . . . . . . . . . . . . . . . . . . . . . . . . . 6

1.3.1 Polynomial Equations . . . . . . . . . . . . . . . . . . . . 61.3.2 Presburger Arithmetic . . . . . . . . . . . . . . . . . . . . 6
1.4 Indexed Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81.5 Type Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.6 The Consequence Relation `A . . . . . . . . . . . . . . . . . . . . 111.7 Structural Equality with * . . . . . . . . . . . . . . . . . . . . . . 13
1.8 Type Schemes and Contexts . . . . . . . . . . . . . . . . . . . . . 13
2 Programming Language and Type Inference 172.1 The Programming Language . . . . . . . . . . . . . . . . . . . . 17

2.2 Type Inference for Indexed Types . . . . . . . . . . . . . . . . . . 202.3 Unification Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 22

2.3.1 Normal Forms . . . . . . . . . . . . . . . . . . . . . . . . 222.3.2 New Instances . . . . . . . . . . . . . . . . . . . . . . . . 23
2.3.3 The Algorithm R . . . . . . . . . . . . . . . . . . . . . . . 242.3.4 The Algorithm

M . . . . . . . . . . . . . . . . . . . . . . 242.3.5 The Transformations T

1 and T2 . . . . . . . . . . . . . . . 252.4 Operational Soundness . . . . . . . . . . . . . . . . . . . . . . . . 27

2.5 Complexity of Type Inference . . . . . . . . . . . . . . . . . . . . 28
3 Conclusion 303.1 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

3.2 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313.3 Challenges of the Future . . . . . . . . . . . . . . . . . . . . . . . 31

1

Chapter 1
Indices, Constraints and
Types

In this chapter we present the formal basics for the description of the typesystem and the inference

In the type inference system of Hindley-Milner [Mil78] the typing problemis transformed into an equivalent unification problem, which can be solved by
Robinson's algorithm [Rob65]. Similarly we generate a unification problem inthe type inference for indexed types. In other words we compute a constraint
which is equivalent to the typing problem and the validity of which has tobe examined afterwards. Such a constraint consist of conditions for type and
term variables. To investigate problems like the equivalence of the typing andconstraint resolution we will introduce and discuss syntax and semantics of
constraints in this chapter.We do not want to fix the index system. Hence we define the requirements
for such an index system and give a few example of such systems afterwards.We will extend index systems in a general way to constraints, that are expressive enough to express typing problems, but are still solvable.The constraints do not have higher order functions or predicates. Therefore
an algebraic approach [Wir90] is sufficient.As opposed to other type systems here we have indices in type constraints.
We will later need another equivalence relation on types distinct from equality,which we will call structural equality. The reason is, that the patterns for function arguments have to be structural of most general type. Because we need tocapture this semantically we have a semantics with two components. The first
component looks at exact equivalence, the second only at structural equivalence.The chapter starts with an example of a type definition, the meaning of
which is described informally. We will afterwards define an index system andgive examples. Then we continue to define indexed types and type constraints
and a consequence relation on type constraints.In the last section we give definitions for further syntactic constructs like

2

type schemes and contexts which are needed for the description of the typesystem in the next chapter.
1.1 Example
Before we formally define index systems, types, and type constraints we willinformally look at an example. We start with a typical definition for a tree in
Haskell or Gofer:

data Tree a =

Leaf a |
Branch (Tree a) (Tree a);

We have a parameter a, which stands for the type of the leaves. A tree is eithera leaf with a componenet of type

a or a node with two subtrees.In a functional language with indexed types we want to support the following

kind of type definition:

data Tree a #n ?b =

Leaf a, n = 1, b |
Branch (Tree a l bl) (Tree a r br),

n = l + r, b = (br and bl and (l = r));

This type has three parameters, a type parameter a and two indices, an integer
n and a Boolean value b. a determines the type of the leaves and b tells us,whether the tree is balanced. The sort of the indices is here indicated by a prefix

# or ?. A syntax with n:Int and b:Bool would also be possible.We are also a little bit lax with the distinction of truth statements and
expressions of sort Bool. We will justify this later. It would be more precise towrite

n = 1, b = true
and

n = l + r,
(b = true) <-> (br = true and bl = true and (l = r))

The meaning of the indices is fixed inductively. The number of leaves ofa leaf is 1, this is described by

n = 1. The number of leaves of a composedtree is given by the sum of the leaves of the left and right subtree. We write

n = l + r. A leaf is always balanced. A composed tree is balanced, if bothsubtrees are balanced and have the same size.

We used an index system here which allows Boolean values and integers asindices. Besides equality some connectives like

+ and and are allowed. In thenext section we give a formal framework for index systems of this kind.

3

1.2 Requirements for an Index System
In an index system we do not yet have types. Only connections between indicescan be given. An index system will be described by a concrete algebra for a
signature. In the following we will define how such algebras and signatureslook like. We could also instead of requiring properties for the algebra require
validity of some inference rules. That would give us more freedom in choosing asemantic. On the other hand we feel that the additional freedom is minor and
the treatment is easier this way.
Definition 1 (Index Signature). A index signature is a tupel (S, Sq, pred, F ),where

S is a set of sorts, Sq a subset of S and pred an element of S. F is a setof sorted function symbols, i.e. every function symbol has argument sorts from

S* and a result sort from S.

Informally S are the sorts which can later be used for term constraints,
Sq are sorts over which we are allowed to quantify and for which we have anequality. Only sorts from

Sq may eventually appear as indices. pred is a specialsort which stands for term constraints.

Definition 2 (\Sigma -Term). Let \Sigma  = (S, Sq, pred, F ) be an index signature and
V an S-indexed set of variables, then T\Sigma ,s(V ) is defined as follows:

x 2 Vs
x 2 T\Sigma ,s(V )

ti 2 T\Sigma ,si(V )
f(t1, . . . , tn) 2 T\Sigma ,s(V ) f : s1 * . . . * sn ! s 2 F

true 2 T\Sigma ,pred(V ) indexfalse 2 T\Sigma ,pred(V )
t1 2 T\Sigma ,pred(V ) t2 2 T\Sigma ,pred(V )

t1 ^ t2 2 T\Sigma ,pred(V )

t1 2 T\Sigma ,pred(V ) t2 2 T\Sigma ,pred(V )

t1 . t2 2 T\Sigma ,pred(V )

t 2 T\Sigma ,pred(V )~

t 2 T\Sigma ,pred(V )

t1 2 T\Sigma ,q(V ) t2 2 T\Sigma ,q(V )

t1 =q t2 2 T\Sigma ,pred(V ) q 2 Sq

t 2 T\Sigma ,pred(V ) ff 2 Vq9

qff.t 2 T\Sigma ,pred(V \ {ff}) q 2 Sq
t 2 T\Sigma ,pred(V ) ff 2 Vq8

qff.t 2 T\Sigma ,pred(V \ {ff}) q 2 Sq

Definition 3 (\Sigma -Term Constraint). A \Sigma -term constraint is a \Sigma -term from
T\Sigma ,pred(V ).

4

Term constraints are constraints which do not yet contain types. Besidesterm constructors of many sorted algebras there are Boolean operators and
quantifiers. Th constant for false statements is labelled indexfalse, because wewill later have another constant false.

We do not distinguish here between terms and formulas as sometimes done[Wir90]. fromulas are just terms of sort

pred. This allows a more homogeneoustreatment in a few places and formulas can be part of a term. Most index

systems, however, will not make use of that.
Definition 4 (\Sigma -Algebra). A \Sigma -algebra is an S-indexed set A together with afunction

Af : As1 *. . .*Asn ! As for each function symbol f : s1*. . .*sn ! s.Furthermore

* Apred = {true, false}

* As 6= ; f"ur s 2 S
This definition is standard for many sorted algebras.Now we have to give the semantics of terms and term constraints in this

algebra. We need environments, which fix the meaning of free variables.
Definition 5 (\Sigma -Environment). A \Sigma -environment ae is an S indexed mapfrom

V to A. We write

ae[a/v](x) = ae a, v = xae(x), sonst
Now we can give the semantics for terms and term constraints. Again thisis standard for many sorted algebra.

Definition 6 (\Sigma -Term Semantics). For a given environment ae and a \Sigma -algebra

A we define:

[[f (t1, . . . , tn)]]A,ae = Af ([[t1]]A,ae, . . . , [[tn]]A,ae)

[[ff]]A,ae = ae(ff)
[[9sff.t]]A,ae = 9as 2 As.[[t]]A,ae[as/ff]
[[8sff.t]]A,ae = 8as 2 As.[[t]]A,ae[as/ff]
[[t1 ^ t2]]A,ae = [[t1]]A,ae ^ [[t2]]A,ae
[[t1 . t2]]A,ae = [[t1]]A,ae . [[t2]]A,ae

[[~t]]A,ae = ~[[t]]A,ae
[[t1 =q t2]]A,ae = ([[t1]]A,ae =Aq [[t2]]A,ae)
[[indexfalse]]A,ae = false

[[true]]A,ae = true

Definition 7 (Consequence Relation). We can now define a consequencerelation `

A with

P `A R if and only if 8ae.([[P ]]A,ae ! [[R]]A,ae)

5

From the definitions of term semantics and the consequence relation it isobvious that we can use classical reasoning for `

A.

Remark 1. For `A classical reasoning rules are valid.

For indexed types we are only interested in systems with a decidable conse-quence relation.

Definition 8 (Index System). An index system is an index signature \Sigma together with a \Sigma -algebra

A, such that `A P for P 2 T\Sigma ,pred(V ) is decidable

Before we come to type constraints we will have a look at a few examples ofindex systems.

1.3 Some Index Systems
When we are designing a functional language with indexed types, we have todecide, which index system we want to use. Here we want to present a few such
systems.

1.3.1 Polynomial Equations
We formulate polynomial equations in the following way as index system.
Example 1 (Polynomial Equations).

constc : poly, for eachc 2 C* :

poly * poly ! poly+ :
poly * poly ! poly- :
poly * poly ! poly
Sq = {poly}
Apoly = C

The decidability of this system is treated in computer algebra [Col75]. Wecannot change the domain to Z, because then we would lose decidability (The
reason is the undecidability of Hilbert's tenth problem [Mat70]). Using R asdomain we can even add comparison operators.

To work over C or R instead of Z may be a problem, because e.g. n > 0 `A
n >= 1 does not hold any more. More importantly predicates like "x odd" areno longer expressible. For this reason we are more interested in the following

system.

1.3.2 Presburger Arithmetic
Definition 9 (Presburger Arithmetic). A formula P is a formula in Pres-burger Arithmetic if it is

* a linear equation,

6

* a linear comparison,

* two formulas in Presburger Arithmetic connected by a logic connective, or

* a quantification over a formula in Presburger Arithmetic.
The domain for variables are integers.

Presburger Arithmetic is quite expressive, but still decidable [Coo72], so itseems an excellent candidate as an index system. For data dependence analysis

strong solvers have been developed [Pug92], [?].Formally we describe Presburger Arithmetic as follows:

Example 2 (Presburger Arithmetik). We have

1 : linear*

n : linear ! linear for each n 2 Z+ :

linear * linear ! linear- :

linear * linear ! linear
< : linear * linear ! pred
Sq = {linear}
Alinear = Z

We can extend Presburger Arithmetic to include a truth sort without losingdecidability. The advantage is, that we can later parametrize types also with

truth values.
Example 3 (Presburger Arithmetic with Truth). We have an additionalsort

bool with

inj : bool ! pred^ :

bool * bool ! bool. :
bool * bool ! bool~ :
bool ! bool
Sq = {linear, bool}
Abool = {true, false}

We can see the decidability by mapping formulas in Presburger arithmeticwith truth to formulas in Presburger arithmetic. For every variable

b of sort
bool we introduce a new variable of sort linear. We describe a mapping repl,that maps expressions of sort

bool to expressions of sort pred.

* repl(b) = (b0 = 0)

* repl(inj(B)) = repl(B)

* repl(9b.A) = 9b0.repl(A)

* repl(8b.A) = 8b0.repl(A)

* repl(A = B) = repl(A) $ repl(B)

7

repl is homomorphic on all other operators (e.g. repl(A^B) = repl(A)^repl(B)).This mapping does not change the semantics of closed constraints.

Here is an example for such a mapping:

repl((b ^ c) = ~d) = ((b0 = 0) ^ (c0 = 0)) $ ~(d0 = 0)
In practice it will be convenient, to mix terms of the sorts pred and bool, aswe did at the beginning of the chapter.

repl(b = (br ^ bl ^ (l = r))) =(

b0 = 0) $ (br0 = 0) ^ (bl0 = 0) ^ (l = r)

Similarly we could introduce finite domains, by using b0 = 0, b0 = 1, . . . ,
b0 = k and (b0 > k . b0 < 0).We could also imagine lists over finite domains [true

, false, true] would becoded as 2*3
2+1*3+2, longer as >. But n = len(l) would be 3n-1 <= l < 3n which

is no longer Presburger arithmetic. In our example we will stick to Presburgerarithmetic with truth.

1.4 Indexed Types
We want to expand the term constraints to type constraints. To this end we haveto formalise types. We assume that type declarations are global for the whole
program. We could assume them to be local [OL96], which has the advantagethat certain program transformations, which need the introduction of new data
types, can be local, whereas here they are global. We choose this way here,because it simplifies the presentation.

Definition 10 (Type Signature). A type signature \Delta  for a given index sig-nature \Sigma  = (

S, Sq, pred, F ) is a set of declarations of the following kind:

data T_ff(_n : _s) = X

i

Di_o/i ( Qi, _fii( _mi : _qi)

The si, qi,j are from Sq, the o/i,j from T\Sigma ,\Delta ,type(_ff [ _fii [ _n [ _mi), and the Qi from
T\Sigma ,pred(_n [ _mi).

The _fii and _mi are the free variables of the _o/i. We note, that only elementsof
Sq are allowed as sorts, those which have equality and quantifiers. Thedefinition of

T\Sigma ,\Delta ,type(V ) follows only now, because it refers to type signatures.This recursion is justified, because the form of the

o/i is not relevant to thedefinition.

Definition 11 ((\Sigma , \Delta )-Type). Let V be an S [{type}-indexed set of variables.Then the set of (\Sigma 

, \Delta )-types T\Sigma ,\Delta ,type(V ) is inductively defined as follows:

ff 2 Vtype
ff 2 T\Sigma ,\Delta ,type(V )

8

ti 2 T\Sigma ,si(V ) o/j 2 T\Sigma ,\Delta ,type(V )

(T_o/ _t) 2 T\Sigma ,\Delta ,type(V ) data T_ff(_n : _s) = . . . 2 \Delta 

o/1 2 T\Sigma ,\Delta ,type(V ) o/2 2 T\Sigma ,\Delta ,type(V )

o/1 ! o/2 2 T\Sigma ,\Delta ,type(V )

The tree declaration at the beginning of the chapter would formally look likethat:

data T a(n : Int)(b : Bool)=

Leaf (Tree a l bl) (Tree a r br)( (

n = 1 ^ b = true)
l, bl, r, br|

Branch (Tree a l bl) (Tree a r br)( (

n = l + r ^ (b = true) , ((br = true) ^ (bl = true) ^ (l = r)),
l, bl, r, br

In practice we will use #i and ?b instead of i : int and b : bool. Additionallywe usually do not mention _

fii and _mi explicitly.To describe the semantics of types we define

Atype:

Definition 12 (Atype). Atype is built inductively from the following rules:

o/1 2 Atype o/2 2 Atype

o/1 ! o/2 2 Atype
o/i 2 Atype ak 2 Ask

T_o/ _a 2 Atype data T _ff(_n : _s) = . . . 2 \Delta 

We will also use o/ for these. Types from Atype, however, do not containvariables.

Now we have to define structural equivalence of types from this set. Intu-itively, two types are structural equivalent if they are equal when we neglect
indices.
Definition 13 (,=). We define a relation ,= on Atype inductively:

o/1 ,= o/ 01 o/2 ,= o/02
o/1 ! o/2 ,= o/ 01 ! o/ 02

o/i ,= o/ 0i
T_o/ _a ,= T_o/ 0_a0

Remark 2. It is easy to see, that ,= is an equivalence.

(Tree Int 5 True) ,= (Tree Int 7 False) holds, but still (Tree Int 5
True) 6= (Tree Int 7 False).For the semantics of types we have to assign also types to the free type

variables. therefore we extend the definition of an environment.
Definition 14 ((\Sigma , \Delta )-Environment). A (\Sigma , \Delta )-environment ae is a S [{

type}-indexed map from V to A. We write ae[a/v] as in \Sigma -environments.

9

Everywhere, where we used \Sigma -environments we can also use (\Sigma , \Delta )-environments with the obvious meaning.
Now we can give the semantics of types. It is fixed by the choice of the indexsystem.

Definition 15 ((\Sigma , \Delta )-Type Semantics).

[[t1 ! t2]]A,ae = [[t1]]A,ae ! [[t2]]A,ae
[[(To/1, . . . , o/k, t1, . . . , tn)]]A,ae = T([[o/1]]A,ae, . . . , [[o/k]]A,ae, [[t1]]A,ae, . . . , [[tn]]A,ae)

[[ff]]A,ae = ae(ff)

1.5 Type Constraints
Now we define type constraints. These are the constraints which are later bythe type inference and decided by the unification.

Definition 16 ((\Sigma , \Delta )-Type Constraint). Let V be an S [ {type}-indexedset of variables. (\Sigma 

, \Delta )-type constraints T\Sigma ,\Delta ,prop(V ) are defined inductively:

t 2 T\Sigma ,pred(V )
inj(t) 2 T\Sigma ,\Delta ,prop(V )

false 2 T\Sigma ,\Delta ,prop(V )
t1 2 T\Sigma ,\Delta ,prop(V ) t2 2 T\Sigma ,\Delta ,prop(V )

t1 ^ t2 2 T\Sigma ,\Delta ,prop(V )

t1 2 T\Sigma ,\Delta ,prop(V ) t2 2 T\Sigma ,pred(V )

t2 ! t1 2 T\Sigma ,\Delta ,prop(V )

t1 2 T\Sigma ,\Delta ,type(V ) t2 2 T\Sigma ,\Delta ,type(V )

t1 =type t2 2 T\Sigma ,\Delta ,prop(V )

t 2 T\Sigma ,\Delta ,prop(V ) ff 2 Vq9

qff.t 2 T\Sigma ,\Delta ,prop(V \ {ff}) q 2 Sq [ {type}
t 2 T\Sigma ,\Delta ,prop(V ) ff 2 Vq8

qff.t 2 T\Sigma ,\Delta ,prop(V \ {ff}) q 2 Sq [ {type}

The function inj is an embedding of term constraints into type constraints.As we see later, term constraints are always structurally true. This leads to the

fact that we do not need to define true, because inj(true) is exactly what wewant. On the other hand inj(indexfalse) and false have a different semantics.

10

We have equality and all quantifiers, but as logical connectives only ^ and !are allowed, where the left side of the implication is limited to term constraints.
More general constraints would significantly complicate the unification if notrender it impossible.

The difficulty with the definition of the type constraint semantics is, that weneed both, the exact semantics as well as the semantics for neglecting indices.
We will give the semantics as a pair of values, where ssi are the projections tothe components. This is a two level semantics in the sense of [

?].

Definition 17 ((\Sigma , \Delta )-Type Constraint Semantics).

[[inj(t)]]A,ae = ([[t]]A,ae, true)

[[false]]A,ae = (false, false)
[[t1 =type t2]]A,ae = ([[t1]]A,ae =Atype [[t2]]A,ae, [[t1]]A,ae ,= [[t2]]A,ae)

[[t1 ^ t2]]A,ae = (ss1([[t1]]A,ae) ^ ss1([[t2]]A,ae), ss2([[t1]]A,ae) ^ ss2([[t2]]A,ae))
[[t2 ! t1]]A,ae = (ss2([[t1]]A,ae) ^ ([[t2]]A,ae ! ss1([[t1]]A,ae)), ss2([[t1]]A,ae))

[[9sff.t]]A,ae = (9as 2 As.ss1([[t]]A,ae[as/ff]), 9as 2 As.ss2([[t]]A,ae[as/ff]))
[[8sff.t]]A,ae = (8as 2 As.ss1([[t]]A,ae[as/ff]), 8as 2 As.ss2([[t]]A,ae[as/ff]))

We note particularly that

[[inj(true)]]A,ae = (true, true)
but

[[inj(indexfalse)]]A,ae = (false, true)
The semantics of P ! C is chosen such that even if P is wrong, C has to bestructurally true for

P ! C to be true. Here a few examples:

[[8m, n.m = n ! Vector ffm = Vector ffn]]A,ae = (true, true)
[[8m, n.m = n + 1 ! Vector ffm = Vector ffn]]A,ae = (false, true)

[[int = bool]]A,ae = (false, false)

1.6 The Consequence Relation `A
For the consequence relation to hold, we require that it holds for both com-ponenets. This is the obvious choice, because we want equivalence in the sense
of the consequence relation to be semantic equivalence.
Definition 18 (Consequence Relation). For a \Sigma -algebra A we define aconsequence relation `

A on T\Sigma ,\Delta ,prop(V ):

C `A C0 if and only if 8ae.8i.(ssi([[C]]A,ae) ! ssi([[C0]]A,ae)).

11

We say

C jA C0 if and only if C `A C0 and C0 `A C.
Usually we will write P instead of inj(P ). This is reasonable because inj ishomomorphic in ^, !, and the quantifiers and inj(

P ) `A inj(R) if and only if
P `A R.Here we collect some basic properties of `

A. P stands form term constraints,

A, B, and C for type constraints.

Proposition 1 (Properties of `A). The following rules are semantically jus-tified:

(taut) C `A C

(^I) C `

A A C `A B

C `A A ^ B (^Er)

C `A A ^ B

C `A A (^El)

C `A A ^ B

C `A B

(! E) C `

A P C `A P ! B

C `A B (! I)

C ^ P `A B
C `A P ! B

(8I) C `

A A

C `A 8ff.A ff 62 fv(C) (8E)

C `A 8ff.A
C `A [a/ff]A

(9I) C `

A [a/ff]A

C `A 9ff.A (9E)

C `A 9ff.A C ^ A `A B

C `A B ff 62 fv(C, B)

(=o/ I1) C `

A o/1 = o/01, o/2 = o/ 02

C `A o/1 ! o/2 = o/ 01 ! o/02 (=o/ E1)

C `A o/1 ! o/2 = o/ 01 ! o/ 02

C `A o/1 = o/ 01, o/2 = o/ 02

(=o/ I2) C `

A _o/ = _o/ 0, _t = _t0

C `A T _o/ _t = _o/ 0_t0 (=o/ E2)

C `A T _o/ _t = _o/0_t0
C `A _o/ = _o/ 0, _t = _t0

(=t ref l) C `A t = t (=o/ ref l) C `A o/ = o/

(=t trans) C `

A t = t0, t0 = t00

C `A t = t00 (=o/ trans)

C `A o/ = o/0, o/0 = o/ 00

C `A o/ = o/ 00

(=t sym) C `

A t = t0

C `A t0 = t (=o/ sym)

C `A o/ = o/ 0
C `A o/ 0 = o/
Proof: See Appendix.

12

1.7 Structural Equality with *
To be able to treat structural equality easily, we define an operator *, whichextracts the structure of types and type constraints. * has a syntactic and a
semantic definition. Of course, we want them to be compatible. Let cs anarbitrary but fixed constant of sort

s.

Definition 19 (*). We introduce an operator* : T\Sigma ,\Delta ,s(V ) ! T\Sigma ,\Delta ,s(V ) f"ur
s 2 {type, prop}:

(t1 ! t2)* = t*1 ! t*2
(To/1, . . . , o/k, t1, . . . , tn)* = T(o/ *1 , . . . , o/ *k , cs1, . . . , csn)

ff* = ff
inj(t)* = true
(t1 =type t2)* = t*1 =type t*2

(C1 ^ C2)* = C*1 ^ C*2

(P ! C)* = C*

(9sff.C)* = 9sff.(C*)
(8sff.C)* = 8sff.(C*)
(9typeff.C)* = 9typeff.(C*)
(8typeff.C)* = 8typeff.(C*)

Now the semantic definition:On {true

, false} * {true, false} we define * as (x, y)* = (y, y). On Atype as

(To/1, . . . , o/k, t1, . . . , tn)* = T(o/ *1 , . . . , o/ *k , Acs1 , . . . , Acsn )

(t1 ! t2)* = t*1 ! t*2

and finally for environments:

ae*(ff) = ae(ff)*
Our goal is [[ *]]ae* = [[ ]]*ae. This holds at least for type equations:
Proposition 2. Es gilt:

[[(o/ = o/ 0)*]]ae* = [[o/ = o/ 0]]*ae.
Proof: See Appendix.

1.8 Type Schemes and Contexts
Finally we introduce a few basic syntactic constructs for the type system. Typeschemes denote parameterized types. We use v to describe subsumption similarly to [OSW98],[?] and others.

13

Definition 20 (Type Schemes). A type scheme is of the form 8 _ff.8_n.C ) oe,where

oe is again a type scheme or a type. _ff are type variables and _n are termvariables, and

C is a type constraint.

8_ff.8_n.C ) 8_ff0.8_n0.C0 ) oe and 8_ff, _ff0.8_n, _n0.C ^ C0 ) oe are consideredequivalent, where _

ff0, _n0 62 fv(C). As consequence every type scheme can bewritten in the form 8_

ff.8_n.C ) o/ .The correctness of a typing a reasonable concept only in the presence of a

context of declarations.
Definition 21 (Context). A context is a sequence of variable declarations(

x1 : oe1, . . . , xn : oen).

the subsumption relation is a generalization of the instance notion inHindley-Milner.

Definition 22 (Subsumption). Let

C00 `A (8_ff.8_n.C ) o/ ) v (8 _fi.8 _m.C0 ) o/0)
if and only if

C00 ^ C `A 9ffi.(ffi = o/ ^ 9 _fi.9 _m.(C0 ^ ffi = o/0))
and

C00 `A (x1 : oe1, . . . , xk : oek) v (x1 : oe01, . . . , xk : oe0k)
if and only if

8i.(C00 `A oei v oe0i).
Remark 3. If _fi and _m are not free in o/ , we have

C00 `A 8_ff.8_n.C ) o/ v 8 _fi.8 _m.C0 ) o/ 0
if and only if

C00 ^ C `A 9 _fi.9 _m.(C0 ^ o/ = o/0).
As an exmaple

fi = Int `A Int ! fi v 8ff.ff ! ff,
as we can see from

fi = Int `A 9ffi.(ffi = Int ! fi ^ 9ff.(ffi = ff ! ff)).
Similarly

fi = Int `A Int ! Int v 8ff.ff ! ff.

14

Jones gives in his thesis [Jon94] a comparable notion on constrained typeschemes

(P | oe) <= (P 0 | oe0).
The definition relies on the notion of a generic instance which is given there.Every type equation

o/ = o/ 0 can be transformed into a set of equations of theform
ffi = o/i. Furthermore constraints may not contain type equations andtherefore

C `A o/ = o/ 0 and `A o/ = o/ 0 are equivalent.If we use our subsumption relation for Jones relation then the following

statements are equivalent.

(P | oe) <= (P 0 | oe0) und `A P ) oe v P 0 ) oe0
C `A oe v oe0 und (C | oe) <= oe0
Whether we introduce (P | oe) and <= or allow constraints at the left side of`

A oe v oe0 is more a matter of taste and emphasis. We see C as a condition for

subsumption and not so much as belonging to the left type scheme. thereforewe prefer to write

C `A oe v oe0.Subsumption is reflexive and transitive:

Proposition 3 (Reflexivity of Subsumption).

C `A oe v oe
Proof: See Appendix.
Proposition 4 (Transitivity of Subsumption). From

C `A oe v oe0
and

C0 `A oe0 v oe00
follows

C ^ C0 `A oe v oe00
Proof: See Appendix.For contexts, that contain constraints, it is sometimes a difference whether
8_ff.8_n.C ) oe has instances under all substitutions for the free variables orwhether we have to put conditions on the substitution. For example (

Int =
ff) ) ff has instances only if (Int = ff). ext(oe) gives us this condition. Thisnotion is sometimes needed for statements, that hold only in restricted form if

ext(oe) 6= true, respectively ext(\Gamma ) 6= true.

15

Definition 23 (ext). We define

ext(8_ff.8_n.C ) oe) = 9 _ff.9_n.(C ^ ext(oe))
ext(o/ ) = true
and

ext(x1 : oe1, . . . , xk : oek) = ext(oe1) ^ . . . ^ ext(oek)
fro contexts.

now we have

ext((Int = ff) ) ff) = (Int = ff).
A type scheme or context is consistent if and only if ext(oe) = true, ext(\Gamma ) = true[OSW98].

16

Chapter 2
Programming Language
and Type Inference

In the last chapter we presented indices and indexed types. Here we will presenta programming language with indexed types and show how to infer the types
for this language. besides we will show the absence of runtime type errors andmake a statement about the complexity of the type inference.

We will first present the rules, which explain to the user, when a programis type correct. In the second step we give a deterministic set of rules which
determines a constraint for each program that is satisfiable if and only if theprogram is typable. In a third step we give an algorithm that decides the
satisfiability of the constraint.To show the absence of runtime type errors we prove subject reduction, that
is a certain set of reductions preserves typability. Using only these reductionsan interpreter can never get into a type error.

The complexity of the type inference is difficult to treat exactly, especiallywhen the index system is variable. Nevertheless we can show that for programs
of a specific form the computational complexity is almost linear in the lengthof the program. This is in contrast to other theorems, that the computational
complexity for ML programs of general form is DEXPTIME-complete [KTU90],[KM89].

2.1 The Programming Language
We start by giving a grammar for the language. We only present the kernelhere. Extensions will be discussed later.

17

E = x|

E1E2|
*x.E|
(let x = E1 in E2)|
(fix x :: P ) o/ in E)|
D|
case F of {Di _yi ) Ei}

An operational semantics will be given will be given in the section on oper-ational soundness. It is straightforward.

Often, three rule systems are used to describe type inference [Jon94],

* a logic system with one introduction and one elimination rule for everytype construction.

* a syntactic system with one rule for every syntactic construct

* an algorithmic system which can be read as an attribute grammar andwhich contains already the unification.

We propose a different procedure here. We have a logic system as usual, butwe give then a deterministic system, that is syntactic as well as algorithmic, but
does not contain unification. Unification is then a seperate third step.We think that the separation of type inference and unification is important,
because type inference and unification can be investigated and extended sepa-rately. As an example it is easier to check, whether unification has to be more
complex, if the fixpoint rule in the type system is changed a little bit. Thisseparation can also be found in a paper by Wand [Wan87].

In an implementation it is of course reasonable to melt these two phasessimilar to the melting of lexical and syntactical analysis in a compiler.
We start with the logical system. We read a judgement C, \Gamma  ` E : oe as "Ifwe have

C and the declarations \Gamma  then E is of type oe".Dabei steht

C eigentlich f"ur eine "Aquivalenzklasse [C]jA von Constraints.The first four rules are the rules of the Hindley-Milner system with an additional constraint, similar to other systems [Sul96], [OSW98].

(var) (x : oe) 2 \Gamma C, \Gamma  ` x : oe

(! E) C, \Gamma  ` E : o/0 ! o/ C, \Gamma  ` F : o/ 0C, \Gamma  ` EF : o/
(! I) C, (\Gamma , x : o/ ) ` E : o/0C, \Gamma  ` *x.E : o/ ! o/0

18

(let) C, \Gamma  ` E : oe C0, (\Gamma , x : oe) ` F : o/C ^ C0, \Gamma  ` (let x = E in F ) : o/
For recursive functions we need a fixpoint operator. Because we want todeclare types here, this operator cannot be introduced as a constant ( as is
possible in Hindley-Milner). Type schemes of declared functions are closed,they have no free type variables.

(f ix) C, (\Gamma , x : oe) ` E : oe C `

A ext(oe)

C, \Gamma  ` (fix x :: P ) o/ in E) : oe ae

_n, _ff = fv(P, o/ )
oe = 8_ff.8_n.P ) o/

the following two rules for introduction and elimination of type schemes cannotbe seperated into two rules [OSW98].

(8 ) I) C ^ C0, \Gamma  ` E : o/C ^ 9_ff.9_n.C0, \Gamma  ` E : 8 _ff.8_n.C0 ) o/ _n, _ff 62 fv(C, \Gamma )
(8 ) E) C, \Gamma  ` E : 8_ff.8_n.C0 ) o/ C `

A [_o/ /_ff][_t/_n]C0

C, \Gamma  ` E : [_o//_ff][_t/_n]o/

The existential rule is used to eliminate variables on the left side. Thisexistential quantification on the left side corresponds logically to a universal

quantification over the whole judgement, which is implicitly given for free vari-ables.

(9I) C, \Gamma  ` E : oe9_ff.9_n.C, \Gamma  ` E : oe _n, _ff 62 fv(\Gamma , oe)
The equality rule expresses, that equal things can replace each other. Equal-ity modulo

C is sufficient.

(=) C, [_o/ /_ff][_t/_n]\Gamma  ` E : [_o/ /_ff][_t/_n]oe C `

A _t = _t0, _o/ = _o/ 0

C, [_o/ 0/_ff][_t0/_n]\Gamma  ` E : [_o/0/_ff][_t0/_n]oe

Now we add introduction and elimination for algebraic data types. Intro-duction is easy:

Qi has to be satisfied to allow the introduction.

(data I) data T_ff_n = Pi Di _o/i ( Qi, _fii _mi C `

A 9 _mi.9_n.Qi

C, \Gamma  ` Di : 8 _mi.8_n.8 _fii.8 _ff.Qi ) (_o/i ! T _ff_n)

The elimination brings something substantially new. In all variants theconditions

Qi may be used, because they were fulfilled at introduction time.

19

the existentially quantified varaibles _fii and _mi may occur in variants, but notin the result.

(data E)

data T_ff_n = Pi Di _o/i ( Qi, _fii _mi(

C ^ `Qi), (\Gamma , _yi : `_o/i) ` Ei : o/
C, \Gamma  ` F : `(T _ff_n)

C, \Gamma  ` case F of {Di _yi ) Ei} : o/ 8!:

` = [ _m0i/ _mi, _n0/_n,_

u/_ff, _*i/ _fii]_
m0i, _*i 62 fv(C, \Gamma , o/ )

We want to make two important statements here. Firstly we can weakenthe judgment by strengthening the condition

C. Secondly, no unstisfiable con-straints may occur on the right side if the left side is satisfiable.

Proposition 5 (Weakening). If C0 `A C and C, \Gamma  ` E : oe are valid, then
C0, \Gamma  ` E : oe holds.

Proof: See Appendix.
Proposition 6 (Consistency). If C, \Gamma  ` E : oe are valid, then C ^ ext(\Gamma ) `Aext(

oe) holds.

Proof: See Appendix.

2.2 Type Inference for Indexed Types
Now we come to the type inference. Here we calculate for a given term withcontext a type constraint

C, which is satisfiable if and only if E is typable in thiscontext. We describe this algorithm in the form of judgements

C, \Gamma  `W E : ffand read the rule system as attribute grammar, where
E and \Gamma  are inheritedattributes and
C and the variable ff are synthesized. this method of reading arule systeme as attribute grammar goes back to R'emy [R'em89].

On the right side we use only variables in order to have all conditions in C.This is important in the fixpoint rule, when

C becomes P ! C.A further advantage is, that besides the right hand side variable and the free

variables of the context no free variables occur in the constraint. WE do not needa gen(\Gamma 

, o/ ) operator. This operator is used in many calculi as 8(fv(o/) \ fv(\Gamma )).o/ .The first three rules are simple. We note in (!

EW ), that instead of9
ff.9fi.(C ^ C0 ^ ff = fi ! ffi) we could have written 9fi.[fi ! ffi/ff](C ^ C0),but this is again more algorithmic than logic.

(varW ) (x : 8_ff.8_n.C ) o/ ) 2 \Gamma 9_ff.9_n.(C ^ ffi = o/), \Gamma  `W x : ffi ffi new
(! IW ) C, (\Gamma , x : ff) `

W E : fi

9ff.9fi.(ffi = ff ! fi ^ C), \Gamma  `W *x.E : ffi ff, ffi new

20

(! EW ) C, \Gamma  `

W E : ff C0, \Gamma  `W F : fi

9ff.9fi.(C ^ C0 ^ ff = fi ! ffi), \Gamma  `W EF : ffi ffi new
In the let-rule, we know that ff is the only free variable and we write 8ff.C ) ff.

(letW )

C, \Gamma  `W E : ff
C0, (\Gamma , x : 8ff.C ) ff) `W F : fi

C0 ^ 9ff.C, \Gamma  `W (let x = E in F ) : fi

In the fixpoint rule the constarint is built of two parts. The first part9_
ff.9_n.(ffi = o/ ^ P ) makes sure, that the resulting type is 8_ff.8_n.P ) o/ , thesecond part 8_

ff.8_n.(P ! 9fl.(C ^ o/ = fl)) makes sure, that the subexpression
E really has type 8_ff.8_n.P ) o/. The second part has in general free variables,because the usage of global variables inside

E poses restrictions on their types.

(f ixW ) C, (\Gamma , x : 8_ff.8_n.P ) o/ ) `

W E : fl

9 _ff.9_n.(ffi = o/ ^ P )^8_

ff.8_n.(P ! 9fl.(C ^ o/ = fl)),\Gamma  `

W (fix x :: P ) o/ in E) : ffi

ae ffi new

_ff, _n = fv(P, o/ )

The (data IW ) rule is quite similar to (varW ).

(data IW ) data T_ff_n = Pi Di _o/i ( Qi, _fii _mi9_ff.9 _fi

i.9_n.9 _mi.(ffi = _o/i ! T _ff_n ^ Qi), \Gamma  `W Di : ffi ffi new

To use the implication with Qi on the left hand side in order to "cancel" thecondition

Qi from the constraint is a decisive idea for the inference of indexedtypes. The idea is, that

Qi ! C is the weakest constraint C0, with C0^Qi `A C.
1

(data EW )

data T _ff_n = Pi Di_o/i ( Qi, _fii _mi
C, \Gamma  `W F : j
Ci, (\Gamma , _yi : _aei) `W Ei : ii9

j.9_ff.9_n.(j = T _ff_n ^ C^8

i.8 _fii.8 _mi.9ii.9_aei.(Qi !(_
aei = _o/i ^ Ci ^ ii = ffi))),\Gamma  `

W case F of {Di _yi ) Ei} : ffi

ffi, _aei new

The quatification 8i is a metanotation and means (8 _fi1. . . .) ^ (8 _fi2. . . .) ^ . . ..Now we make a few statements about this system. We start with showing,
that a more general context \Gamma 0 does not require a stronger constraint than \Gamma and the subsumption condition together.

Proposition 7 (Weakening). If C00 `A \Gamma  v \Gamma 0 and C, \Gamma  `W E : ff are valid,then

C0, \Gamma 0 `W E : ff holds and C00 ^ C `A C0.

1This idea was still missing in the paper [Zen97].

21

Proof: See Appendix.soundness tells us, that `

W never infers a typing, that is not possible in the

logic system. Completeness says, that if we have a typing in the logic system`

W finds a typing which is at least as general as the logic typing.

Theorem 1 (Soundness). If C, \Gamma  `W E : ff is valid then C, \Gamma  ` E : ff holds.
Proof: See Appendix.
Theorem 2 (Completeness). If C, \Gamma  ` E : 8_ff.8_n.C0 ) o/ is valid, then aderivation

C00, \Gamma  `W E : fi exists with C ^ C0 ^ ext(\Gamma ) `A 9fi.(C00 ^ fi = o/).

Proof: See Appendix.

2.3 Unification Algorithm
In this section we present the unification algorithm and state its soundness.Because the algorithm only has to check satisfiablity it is sufficient to look at
closed constraints. We will give a first and a second normal form for closed typeconstraints and then give an algorithm which converts every type constraint in
second normal form. We continue to show that every closed type constraint insecond normal form is equivalent to a closed term constraint. But we assumed
to have a decision procedure for them.

2.3.1 Normal Forms
We start with giving the normal forms. Als erstes beschreiben wir hier dieNormalform von Typconstraints.

Definition 24 (normal forms). A type constraint C is in first normal form,if it is false or of the form

Q.P ^  ^ G,
where Q is a list of quatifiers, P a term constraint,  an idempotent substi-tution [_

o/ /_ff], which we interpret as a set of solved type equations ffi = o/i, G aset of variable equations modulo term constraint

P ! (fii = fi0i). All variables
ffi from dom() must not occur anywhere else in the formula. Furthermore the
o/i in  must never be a single variable.If additionally no type variable is universally quantified and all

ff 2 dom()are free in
C, then C is in second normal form.

The algorithm is subdivided in two transformations T1 and T2. The firstbrings the type constraint in first normal form , the second in second normal

form.

22

It will be a subtask, to disassemble a conditional equation P ! (o/ = o/ 0)into

Q.(o/ 00 = o/ 000) ^ P 0 ^ (Pi ! (ffi = fii)). As an example we disassemble

(m = n) ! (ff = Vector fi n)
into

9fl, k.((ff = Vector fl k) ^ (m = n ! (fi = fl)) ^ (m = n ! n = k)).
This task is done by M. More specifically we first get

9fl, k.((ff = Vector fl k) ^ (m = n ! (Vector fl k = Vector fi n))
The disassembling of the last component is done by R. The generation of thenew type (

Vector fl k)) from (Vector fi n) is done by newinst.We present the algorithms in a "bottom-up" order. We make some statements on the way, which wil give us the decidability of type constraints in theend.

2.3.2 New Instances
We often want to generate a new type o/ 0, which has the same structure as o/ ,but is as general as possible. In

o/ 0 only new variables may occur and no variablemore than once. We achieve this by the following definition.

Definition 25 (newinst). newinst is defined by the following set of rules

(fi, ;, fi) = newinst(ff) new fi
( _fi1, _n1, o/ 01) = newinst(o/1) ( _fi2, _n2, o/ 02) = newinst(o/2)

( _fi1 [ _fi2, _n1 [ _n2, o/ 01 ! o/ 02) = newinst(o/1 ! o/2)

( _fii, _ni, o/ 0i ) = newinst(o/i)
(Si _fii, Si _ni, T _o/ 0_n0) = newinst(T _o/ _t) new _n0

( _fii, _ni, o/0i ) = newinst(o/i)
(Si _fii, Si _ni, [_o/ 0/_ff]) = newinst([_o/ /_ff]) new _n0

The idea of newinst is to disassemble a constraint ff = o/ in a condition
ff = o/0 and a non-structural rest o/ = o/ 0. For example

newinst(Tfi(Listfi)(m + n)m) = (hu1, u2i, h*1, *2i, Tu1(Listu2)*1*2)
the structural part

ff = Tu1(Listu2)*1*2)
and the rest

(o/ = o/ 0) j ((Tfi(Listfi)(m + n)m) = Tu1(Listu2)*1*2)j

fi = u1 = u2 ^ m + n = *1 ^ m = *2

are the components. Now the central statement about newinst.

23

Lemma 1 (newinst). If C* `A  and ( _fi, _n, 0) = newinst() are valid, then
C `A 9 _fi, _n.0 holds.

Proof: See Appendix.

2.3.3 The Algorithm R
R has to disassemble the non-structural rest C of the type constraint into aterm constraint

P and conditional variable equations G. R(C) = (P, G).

Algorithm 1 (R). R takes as input a quantifierfree constraaint C and worksas follows:

* R(C ^ C0) = (P ^ P 0, G ^ G0), where (P, G) = R(C) und (P 0, G0) = R(C0)

* R(P ! C) = (P ! P 00, (Vi(P ^ P 0i ! (ffi = o/i))), where (P 00, (Vi P 0i !(

ffi = o/i))) = R(C)

* R(P ) = (P, true), if P already has the form of a term constraint.

* R(o/1 ! o/2 = o/ 01 ! o/ 02) = (P ^ P 0, G ^ G0), where (P, G) = R(o/1 = o/ 01) and(

P 0, G0) = R(o/2 = o/ 02)

* R(To/1 . . . o/nt1 . . . tk = To/ 01 . . . o/ 0nt01 . . . t0k) = ((Vi Pi) ^ (Vi ti = t0i), (Vi Gi)),wobei (

Pi, Gi) = R(o/i = o/ 0i )

* R(ff = o/ ) = (true, ff = o/ )

* R(o/ = ff) = (true, ff = o/ )
the last two cases only occur as R(ff = fi) auf, if the argument did notcontain structural constraints. We claim, that

R does not change the meaningand that its result ahs a special form.

Proposition 8 (Form and soundness of R). If C is a quantifierfree con-straint, then R(

C) = (P, G) and C jA P ^ G, where P is a term constraint and
G is of the form Vi(Pi ! ffi = o/i).If further

C = 0C0, `A C0* and (0, _fi, _m) = newinst(), then both o/ihave the form of a single variable

fii.

Proof: See Appendix.

2.3.4 The Algorithm M
The algorithm M executes a repetitive part of the normal form algorithm. Froma substiution and a set of conditional type equations it computes a new substitution, a term constraint and a set of conditional variable equations. Newly gener-ated variables are existentially quantified. The resulting constraint is equivalent
to the first.

24

Algorithm 2 (M). let U be a set of type equations and G a set of condtionalequations. We compute

00 = mgu(U *, G*), the most genaral unifier. From thiswe compute ( _
fi, _n, 0) := newinst(00). In a last step (P, G0) = R(0(U ^ G)).Now M(
U, G) is defined as (0, P, G0, _fi, _n). If mgu(U *, G*) fails, M fails also.

Looking at the example before

U = true, G = (m = n) ! (ff = Vector fi n)
The most general unifier is

00 = [(Vector fi n)/ff]
and

(fl, k, [(Vector fl k)/ff]) = newinst(00).
We call R:

(m = n ! n = k, m = n ! fi = fl)= R(

m = n ! (Vector fl k) = (Vector fi n))

For M we also have a form and soundness result:
Proposition 9 (Form and soundness of M). If M(U, G) = (0, P, G0, _fi, _n),then for all

P 0 with _fi, _n 62 fv(P 0)

9 _fi.9_n.(P 0 ! P ) ^ 0 ^ (P 0 ! G0) jA P 0 ! ( ^ G)
holds, where 0G0 = G0 and G0 is of the form Vi Pi ! (ffi = fii). If M fails,then

P 0 ! (U ^ G) jA false.

Proof: See Appendix.

2.3.5 The Transformations T1 and T2
It is left to describe the transformations T1 and T2. We define both of them bya rule system.

T1 is essentially taking out the quantifiers and calling M. T2eliminates universally quantified variables and existentially qunatified variables

from dom() going inside out.
Algorithm 3 (T1). The transformation T1:

T1(P ) = P

T1(C) = Q.P ^  ^ G T1(C0) = Q0.P 0 ^ 0 ^ G0(

00, P 00, G00, _fi, _n) = M( ^ 0, G ^ G0)T

1(C ^ C0) = Q.Q0.9 _fi.9_n.(P ^ P 0 ^ P 00) ^ 00 ^ G00T

1(C) = Q.P ^  ^ G (0, P 00, G00, _fi, _n) = M(, true)T
1(P 0 ! C) = Q.9 _fi.9_n.(P 0 ! (P ^ P 00)) ^ 0 ^ (P 0 ! (G ^ G00))T

1(C) = Q.P ^  ^ GT
1(Q0.C) = Q0.Q.P ^  ^ G
If M fails, T1(C) = false.

25

Proposition 10 (Form and soundness of T1). T1(C) jA C. FurthermoreT

1(C) is in first normal form.

Proof: See Appendix.
Definition 26 (RG). We define RG such that, ffRGff0 holds if and only if
P ! (ff = ff0) occurs in G. Let R*G be the reflexive and transitive hull.

Algorithm 4 (T2). The transformation T2:

T2(C) = Q.P ^ ( ^ ff = o/) ^ G(

0, P 0, G0, _fi, _n) = M([o//ff], ;)T

2(9ff.C) = 9 _fi.9_n.Q.(P ^ P 0) ^ 0 ^ (G ^ G0) ff 62 dom()T

2(C) = Q.P ^  ^ GT
2(9ff.C) = 9ff.Q.P ^  ^ G ff 62 dom()T

2(C) = Q.P ^  ^ GT

2(8ff.C) = false ffR

*Gff0, ff0 2 fv(, 8ff.C)

T2(C) = Q.P ^  ^ (G0 ^ G00)T

2(8ff.C) = Q.P ^  ^ G00 ae

fv(G0) = {ff0 | ffR*Gff0}fv(

G00, , 8ff.C) " fv(G0) = ;T

2(C) = C0T
2(9n.C) = 9n.C0T

2(C) = C0T
2(8n.C) = 8n.C0

C = P ^  ^ GT

2(C) = P ^  ^ G
If M fails, T2(C) = false.

Proposition 11 (Form and Soundness of T2). T2(C) jA C. If C was infirst normal form, then T

2(C) is in second normal form.

Proof: See Appendix.For a closed constraint in normal form, there is no

 and G is irrelevant.

Proposition 12 (Closed Constraints). For a closed type constraint `A Q.P ^
 ^ G is eqivalent to `A Q.P .

Proof: See Appendix.From this we get decidability

Theorem 3 (Unification). For a type constraint C, `A C is decidable.
Proof:Let _

ff and _n be the free type and term variables of C. Then `A C holds if andonly if `

A 8_ff, _n.C holds. This in turn is equivalent to `A T2(T1(8_ff, _n.C)). But

this is either false or equivalent to `A P for a term constraint P , which wasdecidable. So also the validity of

C is decidable.

Corollary 1 (Satisfiability and Validity). Satisfiability and Validity of typeconstraints are decidable.

26

2.4 Operational Soundness
In this section we investigate the soundness of typing, that is the question,whether programs that are called type correct by the inference really cannot
have type errors at runtime.There are in general two ways of proving that. the first way is to define a
denotational semantics. We assign a value to every expression and set of valuesto every type. Then we show, that _

x : _oe ` E : o/ implies [[E]] 2 [[o/ ]] whenever[[
xi]] 2 [[oei]] [Mil78].But the semantics for algebraic data types is a non-trivial issue [Gun92] and

we choose a simpler way here. We will show that subject reduction holds, thatis the type of an expression is preserved under reduction.

[stuck terms are ill-typed]The advantage of the former method that it applies automatically to all
reductions that do not change the meaning of an expression.We consider the following reduction steps:

(*x.E)F ! [F/x]E
(fix f :: oe in E) ! [( fix f :: oe in E)/f]E
(let x = E in F ) ! [E/x]F
case (D _E) of {(D_x) ) E0} ! [ _E/_x]E0

We do not fix the reduction strategy here. Every strategy, which uses onlythese reductions, fulfills subject reduction.
The following lemma is essential for the proof of subject reduction. It isclose to a let-rule, but in the conclusion, there is a substitution instead of the
let and x may occur anywhere in the context. The additional condition in theantecedent comes from weakening.

With \Gamma x we mean the context, which lacks the definition for x, but is identicalto \Gamma  otherwise.
We write !* for the reflexive, transitive, compatible hull of !.
Lemma 2. For _fl, _k 62 fv(C5)

C0, \Gamma x `W F : * C1, \Gamma  `W E : u
C5 ^ C4 `A 9*.(C0 ^ * = o/ ) (x : 8_fl.8_k.C4 ) o/ ) 2 \Gamma 

C2, \Gamma x `W [F/x]E : u

holds and 9*.C0 ^ C5 ^ C1 `A C2.
Proof: See Appendix.We show the subject reduction in the `

W calculus. the validity in ` follows

as a corollary.

Theorem 4.

C, \Gamma  `W F : ff F !* F 0

C0, \Gamma  `W F 0 : ff

27

holds, where C ` C0.
Proof: See Appendix.
Corollary 2 (Subject Reduction).

C, \Gamma  ` F : ff F !* F 0

C ^ ext(\Gamma ), \Gamma  ` F 0 : ff

Proof: See Appendix.We have shown therefore, that with the above mentioned reductions no type

error can happen. The additional condition ext(\Gamma ) does not disturb us, becausewe usually work with contexts for which ext(\Gamma ) = true holds.

2.5 Complexity of Type Inference
It is very difficult to make concise statements about the computational com-plexity, especially when the index system is variant.

In the literature it is shown for ML, that type inference ist DEXPTIME-complete [KM89], [KTU90]. Experience shows however, that it is mostly linear
for practical ML-programs.We show here, that for programs of a specific form (essentially functions
must be of bounded size), the computational complexity for the type inferenceis mostly linear in the size of the program.

Theorem 5 (Complexity). If a functional program X is of the form

let f1 = (fix f1 :: P1 ) o/1 in E1) inlet

f2 = (fix f2 :: P1 ) o/2 in E2) in.

..
let fm = (fix fm :: P1 ) o/m in Em) in
F

\Gamma  a closed context, \Delta  a set of type declarations

|Pi| < b, |o/i| < b, |\Delta |m < b, |Ei| < b, |F | < b, |\Gamma |m < 3 + 4b
and the computational complexity for deciding `A C for |C| < b0 is bounded by
B0(b0), then the computational complexity for the inference of C, \Gamma  ` X : ff isbounded by

B(b)O((|X|+|\Gamma | +|\Delta |) log(|X| +|\Gamma |+ |\Delta |)), that is mostly lkinear inthe size of the program. the size of

C is bounded by B(b) and therefore decidablein
O(1).

The non-linearity stems only from the search for variables in \Gamma  and \Delta . B(b)depends only on

b and not on |X| or |\Delta |. The sizes mentioned here, basicallylexical sizes, are more specifically defined in the appendix. |\Gamma |

m and |\Delta |m denotethe size of the largest component.

28

That the computational complexity for deciding `A C is bounded is imme-diately clear from decidability and the fact, that there exist only finitely many
essentially different constraints of a given size.We have shown, that under natural assumptions, type inference is mostly
linear. Whether it is practical cannot not be concluded from that. Neverthelesswe can conclude that practical test for quite small examples will give reasonable
evidence for the constant and therefore on the practical computational complex-ity. The first results of a prototype implementation give reason to confidence
(The AVL-example in the appendix is checked in a few seconds).

29
Chapter 3
Conclusion
At the end we want to summarize the achievements and look at possible furtherdevelopments. Also we will shortly discuss the implementation.
3.1 Summary
We presented a type system for indexed types. With this type system it is pos-sible to describe many problems with value parameters. We saw examples from
different areas including linear algebra, arrays and data structure invariants.Indexed types are between type systems for theorem provers with dependent
types and classical Hindley-Milner type systems as in ML. We have decidabletype inference, but also the possibility of value parameters. indexed types do
not have the generality of the dependent types of a theorem prover, but formany problems occuring in practical programming, they are very well-suited.
Moreover it is much easier to program here than in a theorem prover, becausether is more automatic inference.

On the technical side we solved the problems that appeared. We ditinguishedconceptually between inference and unification. Many type inference algorithms
use union of constraint sets, which correspond to a logical and. We had toremove constraints from a constraint set and identified implication as the logical
equivalent. P ! C is the weakest constraint, that together with P implies C.Further we solved the difficulty, that anargument pattern always has to have
the most general argument type, by introducing structural equivalence on types.Unification was, because of the additional implications, index conditions,
and quantifiers considerably more complicated. Nevertheless we could give aresolution algorithm.

We proved correctness and completeness of the type inference and unificationand also the operational correctness of the system. The proof for unification is
new, the proofs for soundness and completeness are of course based on proofsfor other systems, but at least the extension to the case-rule is non-trivial.

30

3.2 Implementation
We developed a prototype for a functional language with indexed types. Thelanguage is oriented towards the language Haskell [PHA

+97]. The parser, pattern compilation and generation of typeconstraints are implemented in C, usingthe compiler toolbox Cocktail [GE90]. The unification was written in Pizza

[OW97]. It reduces the type constraint to term constraints in Presburger Arith-metik, that are checked for satisfiability with Omega [Pug92].

3.3 Challenges of the Future
What are the challenges that remain? We divide this in theoretical and practicalproblems.

Practical Problems
We have a prototype of the system. to examine the type system in a widercontext, a more efficient and reliable implementation would be necessary.

Only then we can examine, whether the missing array bound checks reallyresult in an efficiency gain. We also would need an efficient implementation of
array monads.Also a study, which examines the efficiency of programming with indexed
types and the robustness of resulting programs. Do libraries, that are writtenwith indexed types make our lives easier?

Theoretical Problems
The most important problem seems to be, how well indexed types combine withoverloading. Superficially this seems very simple and the following definition

seems natural:

sprod :: Num a => (Vector a n) -> (Vector a n) -> a
However, we cannot necessarily declare matrices as instances of Num, becausemultiplication of general matrices is not necessarily allowed. We would like to

have a type class Mult as

class Mult a where

(*) :: a -> a -> a

and an instance

instance Num a => Mult (Matrix a n n)
The inference of type classes, where class mebership depends on indices, hasto be investigated. Is it easier to integrate type classes [PHA

+97], [Jon94] or

system O [OWW95]? Could we also introduce constructor classes [Jon95]?

31

The second question is, whether we can define explicit quantifiers? Especiallyexistential quantifiers in function results have to be described in new data types.
It seems possible, but the details have to be worked out [OL96].the thrd point of interest is pattern completeness. With indexed types it
is possible that patterns are given, that under the circumstances, can never becalled. As an example in

vihead :: (n > 0) => (Vector Int n) -> Int;
vihead (Vcons x xs) = x;
vihead (Vnil) = 0;

the last line can never be executed. Should we issue a warning or even an errorin such a case? can we extend the type inference in that way?

On the other side, can we detect simple pattern failures like the call (vtail
Vnil) in

vtail :: (Vector a n) -> (Vector a (n - 1))
vtail (Vcons x xs) = xs;

Can we require pattern completeness, that is only those patterns can lack, thatare impossible because of the type? In the example

vtail we would have toeither add a branch for
Vnil or else formulate a stronger condition. The formercould only be achieved by returning an error, because there is no expression of

type (Vector a -1). In that case we would need to strengthen the condition:

vtail :: (n > 0) => (Vector a n) -> (Vector a (n - 1))
vtail (Vcons x xs) = xs;

Would this be an improvement or more a hindrance in practice? Is this inferable?At last we want to mention an extension to imperative languages. the main

problem is the following: In a functional language for every variable, there isexactly one assignment. In an imperative language, however, a variable also has
one type, but there may be multiple assignments for one variable. This leadsto problems, if types differentiate precisely. Some assignments are not possible
any more. Consider the assignment

i: Int' n;
i := i + 1;

This can only be allowed, that indices of types may change. A sensible solutionmight be to reqire them to be fixed only in a static single assignment form. the

second problem is that for indexed types every type of a recursive function hasto be declared. In the imperative world this corresponds to annotating a loop
invariant, but this may, at least in simple cases be implicit.

32

Bibliography
[Col75] G.E. Collins. Quantifier elimination for real closed fields by cylindricalgebraic decomposition. In 2nd GI Conf. on Automata Theory and

Formal Languages, LNCS 33, pages 134-183, Kaiserslautern, 1975.Springer.

[Coo72] D.C. Cooper. Theorem proving in arithmetic with multiplication.In B. Meltzer and D. Mitchie, editors, Machine Intelligence 7, pages

91-99. American Elsevier, New York, 1972.
[GE90] J. Grosch and H. Emmelmann. A tool box for compiler construction.In D. Hammer, editor, Proc of the Third International Workshop on

Compiler Compilers, LNCS 477, pages 106-116, Schwerin, Oct 1990.Springer.

[Gun92] C. Gunter. Semantics of Programming Languages. MIT Press, Cam-bridge, Massachusetts, 1992.
[Jon94] M.P. Jones. Qualified Types: Theory and Practice. PhD thesis,University of Oxford, 1994.
[Jon95] M.P. Jones. A system of constructor classes: overloading and implicithigher-order polymorphism. Journal of Functional Programming,

5(1):1-35, January 1995.
[KM89] P.C. Kanellakis and J.C. Mitchell. Polymorphic unification and MLtyping. In Proc. 16th ACM Symposium on Principles of Programming Languages, pages 105-115, ??, Jan 1989. ACM Press.
[KTU90] A.J. Kfoury, J. Tiuryn, and P. Urzyczyn. ML typability isDEXPTIME-complete. In A. Arnold, editor, Proceedings of the

CAAP, volume 431 of LNCS, Copenhagen, Denmark, May 1990.Springer.

[Mat70] J. Matiyasevic. Diophantine representation of recursively enumerablepredicates. In Proc. of the Second Scandinavian Logic Symposium,

Amsterdam, 1970. North-Holland.

33

[Mil78] R. Milner. A theory of type polymorphism in programming. Journalof Computer and System Sciences, 17:348-375, 1978.
[OL96] M. Odersky and K. L"aufer. Putting type annotations to work. InProc. 23rd ACM Symposium on Principles of Programming Languages, pages 54-67, St.Peteresburg Beach, Florida, Jan 1996. ACMPress.

[OSW98] M. Odersky, M. Sulzmann, and M. Wehr. Type inference with con-strained types. Theory and Practice of Object Systems, 1998. (submitted).
[OW97] M. Odersky and P. Wadler. Pizza into Java: Translating theory intopractice. In Proc. 24rd ACM Symposium on Principles of Programming Languages, pages 146-159, Paris, Jan 1997. ACM Press.
[OWW95] M. Odersky, P. Wadler, and M. Wehr. A second look at overload-ing. In Proc. ACM Conf. on Functional Programming and Computer

Architecture, pages 135-149, June 1995.
[PHA+97] J. Peterson, K. Hammond, L. Augustsson, B. Boutel, W. Bur-ton, J. Fasel, A. Gordon, J. Hughes, P. Hudak, T. Johnsson,

M. Jones, E. Meijer, S. Peyton Jones, A. Reid, and P. Wadler. Re-port on the Programming Language Haskell Version 1.4, April 1997.
http://www.haskell.org.
[Pug92] W. Pugh. The omega test: A fast and practical integer programmingalgorithm for dependency analysis. Communications of the ACM,

35(8):102-114, August 1992.
[R'em89] D. R'emy. Typechecking records and variants in a natural extensionof ML. In Proceedings of the 16th ACM Symposium on Principles of

Programming Languages, Austin, Texas, Jan 1989.
[Rob65] J.A. Robinson. A machine-oriented logic based on the resolutionprinciple. Journal of the ACM, 12(1):23-49, Jan 1965.

[Sul96] M. Sulzmann. Typinferenz mit Constraints (german). Master's the-sis, University of Karlsruhe, Mai 1996.
[Wan87] M. Wand. A simple algorithm and proof for type inference. Funda-menta Informaticae, 10:115-122, 1987.
[Wir90] M. Wirsing. Algebraic specification. In Jan van Leeuwen, editor,Formal Methods and Semantics, Handbook of Theoretical Computer

Science, pages 675-788. Elsevier, 1990.
[Zen97] C. Zenger. Indexed types. Theoretical Computer Science, 187:147-165, 1997.

34