

UNIVERSIT 'E de PARIS-SUD
U.F.R. SCIENTIFIQUE d'ORSAY

TH `ESE
pr'esent'ee pour obtenir

Le GRADE de DOCTEUR en SCIENCES

de l'UNIVERSIT 'E de PARIS XI ORSAY

Sp'ecialit'e : Informatique

par

Sylvain GIRBAL

Sujet :
Optimisation d'applicationsComposition de transformations
de programme : mod`ele et outils

Soutenue le 30 septembre 2005 devant le jury compos'e de :

M. Albert Cohen INRIA Futurs
M. Jacques Raguideau CEA LIST
M. Lawrence Rauchwerger Texas A&M University
M. Tanguy Risset ENS Lyon
M. Pascal Sainrat IRIT
M. Olivier Temam INRIA Futurs

R'esum'e
Les optimisations pr'esentes dans les compilateurs statiques sont de moins en moins adapt'ees
aux comportements des m'ecanismes dynamiques complexes pr'esents dans les architectures modernes. De nombreux ph'enom`enes architecturaux ont lieu simultan'ement, et le compilateur doit
donc effectuer de nombreuses transformations de programmes pour optimiser les applications.

Dans cette th`ese, nous proposons un mod`ele unifi'e capable de repr'esenter les programmes
et l'ensemble des transformations permettant de faciliter la recherche des longues s'equences de
transformations n'ecessaires `a l'optimisation des programmes. Ce mod`ele, bas'e sur une repr'esentation poly'edrique, fait une s'eparation claire entre les diff'erents types d'actions effectu'ees
par les transformations de programme*a : La modification des domaines d'it'erations, de l'ordonnancement, et des acc`es aux donn'ees. Les transformations sont alors des compositions de ces
actions 'el'ementaires, et les s'equences de transformations sont elles-m^emes des compositions de
ces transformations.

Nous avons 'egalement associ'e `a notre repr'esentation un ensemble de r`egles de normalisation
permettant*a : de maintenir une complexit'e de repr'esentation quasi-constante sans en limiter
l'expressivit'e*a ; de simplifier les algorithmes permettant de d'eterminer l'applicabilit'e des transformations*a ; d'h'eriter ces r`egles de normalisation par composition des transformations.

Nous proposons 'egalement une impl'ementation autour des compilateurs Open64 et ORC,
ciblant les architectures IA64, AMD64 et IA32 qui nous a permis d'optimiser le benchmark
swim des SpecFP 2000, obtenant un speedup sup'erieur `a +30% par rapport aux meilleurs
compilateurs commerciaux sur AMD64 et IA32.

Abstract
Static compiler optimizations can hardly cope with the complex run-time behavior and hardware components interplay of modern processor architectures. Multiple architectural phenomena
occur and interact simultaneously, which requires the optimizer to combine multiple program
transformations.

The purpose of this thesis is twofold : (1) to introduce a richer framework which improves
on classical polyhedral representations, as a unified model able to represent the whole transformation set. (2) to facilitate the automatic search for compositions of program transformations
on a simpler, structured search space The key is to clearly separate three types of actions associated with program transformations : modification of iteration domain, of schedule, and of
accesses. Transformation could thus be represented as composition of those basic actions, and
transformation sequences as composition of those transformations.

A set of normalisation rules allow our formalism : (1) to maintain a nearly constant complexity for our formalism without hampering expressivity ; (2) to simplify the algorithm determining the applicability of the transformations ; (3) to inherit those rules when composing
transformations.

We also present the implementation of out framework within the Open64/ORC compiler,
aiming for native IA64, AMD64 and IA32 code generation. This implementation allowed us to
optimize the swim SpecFP 2000 benchmark, obtaining a speedup of more than +30% compared
to best commercial compilers with best compilation flags.

3
Table des mati`eres
1 Introduction 9
I Contexte 13
2 'Etat de l'art 15

2.1 Optimisation source `a source . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
2.2 Optimisation semi-automatique . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
2.3 Compilation adaptative . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.4 Compilation it'erative . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

2.4.1 Pr'esentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.4.2 Travaux sur la compilation it'erative . . . . . . . . . . . . . . . . . . . . . 22
2.4.3 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.5 Optimisations manuelles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

2.5.1 R'esultat exp'erimentaux . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.5.2 M'ethodologie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.5.3 R'esultats d'etaill'es pour quelques benchmarks . . . . . . . . . . . . . . . . 25
2.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

3 Le choix du compilateur 29

3.1 Front-ends . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.2 Repr'esentation interm'ediaire : . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.3 Les phases du compilateur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
3.4 Source `a source . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

II Mod`ele de programmes et techniques de compilation 35
4 Limitations inh'erentes aux repr'esentations syntaxiques 37

4.1 Probl`emes de taille de code et de complexit'e . . . . . . . . . . . . . . . . . . . . . 37
4.2 Probl`eme de reconnaissance de motifs . . . . . . . . . . . . . . . . . . . . . . . . 39
4.3 Probl`eme du comportement "par phase" des compilateurs . . . . . . . . . . . . . 40
4.4 Probl`emes de l'application successive des transformations . . . . . . . . . . . . . 40
4.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

5 Abstraction poly'edrique 43

5.1 Niveau d'abstraction et d'efinitions . . . . . . . . . . . . . . . . . . . . . . . . . . 43

5.1.1 Instructions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

4 TABLE DES MATI`ERES

5.1.2 Nids de boucles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
5.2 Programmes `a Contr^ole Statique . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
5.3 Parties `a Contr^ole Statique (SCoP) . . . . . . . . . . . . . . . . . . . . . . . . . . 46
5.4 D'ecomposition en Parties `a Contr^ole Statique . . . . . . . . . . . . . . . . . . . . 47
5.5 Am'elioration de la couverture des SCoPs . . . . . . . . . . . . . . . . . . . . . . 47
5.6 Analyse de la couverture des SCoPs . . . . . . . . . . . . . . . . . . . . . . . . . 48

5.6.1 R'epartition des SCoPs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
5.6.2 R'epartition des instructions . . . . . . . . . . . . . . . . . . . . . . . . . . 49
5.6.3 R'epartitions des acc`es . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
5.6.4 R'epartitions des performances . . . . . . . . . . . . . . . . . . . . . . . . 53
5.6.5 'Etude des benchmarks r'efractaires . . . . . . . . . . . . . . . . . . . . . . 54
5.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

6 Analyses et transformations poly'edriques 59

6.1 Analyses de d'ependances et de flots de donn'ees . . . . . . . . . . . . . . . . . . . 60

6.1.1 Cas des programmes r'eguliers . . . . . . . . . . . . . . . . . . . . . . . . . 60
6.1.2 Cas des programmes irr'eguliers . . . . . . . . . . . . . . . . . . . . . . . . 63
6.1.3 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
6.2 Expansion de tableaux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
6.3 Algorithmes d'ordonnancement poly'edrique . . . . . . . . . . . . . . . . . . . . . 66

6.3.1 Ordonnancements monodimensionnels . . . . . . . . . . . . . . . . . . . . 66
6.3.2 Ordonnancements multidimensionnels . . . . . . . . . . . . . . . . . . . . 66
6.3.3 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67

7 G'en'eration de code 71

7.1 Strat'egies pour scanner un poly`edre . . . . . . . . . . . . . . . . . . . . . . . . . 71
7.2 Techniques pour scanner plusieurs poly`edres . . . . . . . . . . . . . . . . . . . . . 72
7.3 Notre algorithme de g'en'eration de code : CLooG . . . . . . . . . . . . . . . . . . 74
7.4 Une 'evolution de l'algorithme : URGenT . . . . . . . . . . . . . . . . . . . . . . . 76

7.4.1 Modification des structures de donn'ees . . . . . . . . . . . . . . . . . . . . 76
7.4.2 Diminution du nombre d'op'erations poly'edriques . . . . . . . . . . . . . . 77
7.4.3 Autres optimisations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

III Un Formalisme bas'e sur le Mod`ele Poly'edrique 81
8 Notations 85

8.1 Notations usuelles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
8.2 Glossaire des notations du formalisme . . . . . . . . . . . . . . . . . . . . . . . . 85

9 D'efinitions du formalisme 87

9.1 It'erateurs et dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
9.2 Domaines d'it'erations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88

9.2.1 D'efinition formelle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
9.3 Ordonnancement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92

9.3.1 D'efinition formelle : . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
9.4 Liste des Acc`es . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97

9.4.1 D'efinition formelle : . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
9.5 Vecteur de d'eroulage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

TABLE DES MATI`ERES 5
10 Invariants du formalisme 101

10.1 Invariants d'ordonnancement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
10.2 Invariants de domaine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
10.3 V'erification des invariants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105

10.3.1 Par construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
10.3.2 Par application successive de transformations . . . . . . . . . . . . . . . . 106

11 Transformations de Programme dans le Formalisme 107

11.1 Constructeurs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

11.1.1 Op'erations de calcul matriciel . . . . . . . . . . . . . . . . . . . . . . . . . 108
11.1.2 Op'erations sur les structures . . . . . . . . . . . . . . . . . . . . . . . . . 108
11.1.3 Op'eration d'ordonnancement . . . . . . . . . . . . . . . . . . . . . . . . . 109
11.2 Primitives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111

11.2.1 Transformation unimodulaire g'en'erique . . . . . . . . . . . . . . . . . . . 111
11.2.2 Ajout d'une in'equation au Domaine . . . . . . . . . . . . . . . . . . . . . 112
11.2.3 Ajout d'une variable locale . . . . . . . . . . . . . . . . . . . . . . . . . . 113
11.2.4 Ajout d'une it'erateur (Extension) . . . . . . . . . . . . . . . . . . . . . . 113

12 Listes des transformations de codes usuelles 115

12.1 Fusion de boucle (Loop Merging) . . . . . . . . . . . . . . . . . . . . . . . . . . . 115

12.1.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
12.1.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 116
12.2 Fission de boucle (Loop fission, Loop distribution) . . . . . . . . . . . . . . . . . 116

12.2.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
12.2.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 117
12.3 D'eplacement de blocs de code (Code Motion) . . . . . . . . . . . . . . . . . . . . 118

12.3.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
12.3.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 118
12.4 Permutation de boucles (Loop Interchange) . . . . . . . . . . . . . . . . . . . . . 120

12.4.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
12.4.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 120
12.5 Inversion de boucle (Loop Reversal) . . . . . . . . . . . . . . . . . . . . . . . . . 121

12.5.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
12.5.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 122
12.6 Torsion de boucles (Skewing) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123

12.6.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
12.6.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 124
12.7 'Epluchage d'it'erations (Peeling) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125

12.7.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
12.7.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 125
12.8 'Epluchage du temps (Time Peeling) . . . . . . . . . . . . . . . . . . . . . . . . . 127
12.9 D'ecalage (Shifting) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129

12.9.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
12.9.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 129
12.10D'eroulage complet (Full unroll) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130

12.10.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
12.10.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 130
12.11Strip-mine d'it'erations (sans stride) . . . . . . . . . . . . . . . . . . . . . . . . . . 131

6 TABLE DES MATI`ERES

12.11.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
12.11.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 132
12.12Strip-mine d'it'erations (avec stride) . . . . . . . . . . . . . . . . . . . . . . . . . 132

12.12.1 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 133
12.13Strip-mine temporel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
12.14Privatisation de tableau (Array privatization) . . . . . . . . . . . . . . . . . . . . 135

12.14.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
12.14.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 136
12.15Contraction de tableau (Array contraction) . . . . . . . . . . . . . . . . . . . . . 137

12.15.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
12.15.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 137
12.16S'erialisation de tableau (Array serialization) . . . . . . . . . . . . . . . . . . . . . 138

12.16.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
12.16.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 138
12.17Padding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139

12.17.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
12.17.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 139
12.18Transposition de tableau (Array Transposition) . . . . . . . . . . . . . . . . . . . 140

12.18.1 Repr'esentation syntaxique . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
12.18.2 Repr'esentation dans le formalisme . . . . . . . . . . . . . . . . . . . . . . 140
12.19Ajout d'informations de contexte . . . . . . . . . . . . . . . . . . . . . . . . . . . 141

13 Exemple de composition de transformations dans le formalisme 143

13.1 Repr'esentation de l'exemple dans le formalisme . . . . . . . . . . . . . . . . . . . 144
13.2 Repr'esentation de la s'equence de transformations dans le formalisme . . . . . . . 146
13.3 La s'equence de transformations, 'etape par 'etape . . . . . . . . . . . . . . . . . . 146
13.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149

14 Recherche de s'equences de transformations 151

14.1 Propri'et'es de commutativit'e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151

14.1.1 Commutativit'e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
14.1.2 Confluence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
14.2 Une approche alternative : rechercher les valeurs des matrices . . . . . . . . . . . 153

15 Optimisation de Code : Le SpecFP2000 SWIM 155

15.1 R'esultats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
15.2 M'ethodologie de recherche . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
15.3 La liste des transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158

15.3.1 Les labels du programme source . . . . . . . . . . . . . . . . . . . . . . . 158
15.3.2 Informations de contexte . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
15.3.3 D'eplacement de calc3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
15.3.4 Fusions des boucles calc3, calc1 et calc2 . . . . . . . . . . . . . . . . . . . 159
15.3.5 Unroll-and-jam dans le noyau fusionn'e . . . . . . . . . . . . . . . . . . . . 160

IV Impl'ementation du processus d'optimisation 161
16 Processus de Compilation 163

TABLE DES MATI`ERES 7
17 Quiver : Biblioth`eque de composants 165

17.1 Choix d'impl'ementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
17.2 Structures de donn'ees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166

17.2.1 Les listes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
17.2.2 Les vecteurs et les matrices . . . . . . . . . . . . . . . . . . . . . . . . . . 167
17.2.3 Les arbres . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168

18 WRaP-IT : WHIRL Represented as Polyedra - Interface Tool 171

18.1 Algorithme d'extraction des SCoPs . . . . . . . . . . . . . . . . . . . . . . . . . . 171
18.2 Structures de donn'ees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175

18.2.1 Symboles de la table des symboles . . . . . . . . . . . . . . . . . . . . . . 175
18.2.2 Arbres arithm'etico-logiques . . . . . . . . . . . . . . . . . . . . . . . . . . 176
18.2.3 Acc`es `a des tableaux, des scalaires ou des it'erateurs . . . . . . . . . . . . 177
18.2.4 Conditionnelles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
18.2.5 Instructions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
18.2.6 SCoPs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
18.2.7 Fonctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179

19 URUK : Unified Representation Universal Kernel 181

19.1 Utilisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
19.2 D'eveloppement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
19.3 Structures de donn'ees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185

19.3.1 Les param`etres des transformations . . . . . . . . . . . . . . . . . . . . . 185
19.3.2 Les transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
19.4 Analyseurs lexicaux et syntaxiques . . . . . . . . . . . . . . . . . . . . . . . . . . 188

19.4.1 Expressions arithm'etiques symboliques . . . . . . . . . . . . . . . . . . . . 188
19.4.2 Scripts URUK de s'equences de transformations . . . . . . . . . . . . . . . 189
19.4.3 Fichiers de d'efinition des transformations . . . . . . . . . . . . . . . . . . 190

20 Les g'en'erateurs de code CLooG et URGenT 191

20.1 Cr'eation des poly`edres 'etendus . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
20.2 G'en'eration de WHIRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192

20.2.1 G'en'eration des instructions : 'Elimination des redondances . . . . . . . . . 193
20.2.2 G'en'eration des bornes de boucles . . . . . . . . . . . . . . . . . . . . . . . 194
20.2.3 G'en'eration des conditionnelles . . . . . . . . . . . . . . . . . . . . . . . . 195

21 Conclusion 197

21.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
21.2 Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198

21.2.1 Recherche d'opportunit'es de transformation . . . . . . . . . . . . . . . . . 198
21.2.2 Extension de la notion de labels et instances d'instruction . . . . . . . . . 198
21.2.3 Int'egration dans un processus de compilation it'erative . . . . . . . . . . . 199
21.2.4 Architecture client / serveur . . . . . . . . . . . . . . . . . . . . . . . . . . 200
21.2.5 Support de GCC 4.0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200

8 TABLE DES MATI`ERES
A Support de l'analyse dynamique pour l'optimisation it'erative - DiST : Distribution de simulations 203
A.1 Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
A.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204
A.3 Principes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
A.4 Impl'ementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
A.5 Protocole exp'erimental . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
A.6 Acc'el'eration et Pr'ecision (R'esultats exp'erimentaux) . . . . . . . . . . . . . . . . 215
A.7 La simulation rapide autorise de nouvelles applications . . . . . . . . . . . . . . . 223
A.8 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224

9
Chapitre 1
Introduction

Depuis le d'ebut des ann'ees 1990, l''ecart entre les performances cr^etes affich'ees par les
constructeurs, et les performances soutenues obtenues sur des codes r'eels a subi une croissance
exponentielle : L'augmentation brutale de la complexit'e des processeurs a conduit `a une d'egradation effective du code g'en'er'e par les compilateurs. Ce ph'enom`ene a d'abord touch'e les
processeurs g'en'eralistes, avant d'atteindre les architectures embarqu'ees.

Les cons'equences directes ont 'et'e, d'une part un ralentissement de l''evolution des performances, et d'autre part une forte augmentation des co^uts de conception et de production des
architectures `a hautes performances.

Architectures. Du point de vue de l'architecture, il a 'et'e possible d'observer un nombre croissant de caract'eristiques communes entre les syst`emes embarqu'es et les architectures g'en'eralistes.
Ainsi, les architectures embarqu'ees adoptent des techniques issues de la compilation pour processeurs g'en'eralistes `a hautes performances (parall'elisme entre instructions, syst`emes de hi'erarchie
m'emoire, pr'edicteurs de branchement, ex'ecution sp'eculative, . . .). Et r'eciproquement, du fait
des probl`emes croissants de dissipation thermique, les processeurs g'en'eralistes se tournent vers
des solutions issues du monde de l'embarqu'e (clock gating, voltage scaling, . . .).

Les trois principales directions pour am'eliorer les performances ont 'et'e : (1) une course `a
l'augmentation du parall'elisme d'instruction en multipliant les m'ecanismes permettant d'ex'ecuter simultan'ement un maximum d'instructions ind'ependantes, tout en masquant au mieux les
latences de ces instructions ; (2) la multiplication des m'ecanismes sp'eculatifs, qui permettent de
pr'edire le comportement local des programmes ; (3) la mise en place d'une hi'erarchie m'emoire
complexe permettant d'exploiter au mieux la r'eutilisation des donn'ees dans le temps et dans
l'espace.

Compilateurs. La part de plus en plus importante prise par la sp'eculation dans l'architecture
rend son comportement impr'evisible. L'ex'ecution dans le d'esordre, la pr'ediction de branchement,
la pr'ediction de valeur et les m'ecanismes de caches posent un r'eel probl`eme pour l'optimisation
de code car la compilation classique est limit'ee par des techniques d'analyses statiques qui ne
peuvent mod'eliser ces comportements.

Dans le domaine de l'optimisation de programme, le principal verrou technologique est donc
la limitation de l'analyse statique des compilateurs, peu pr'ecise en pr'esence de composants dynamiques. Pour contourner cet obstacle, il faut se baser sur des techniques d'analyse dynamique,
qui seules peuvent fournir une compr'ehension d'etaill'ee du comportement du programme.

La t^ache incombant aux compilateurs a 'egalement 'evolu'ee avec le rapprochement des architectures g'en'eralistes et embarqu'ees : Dans les ann'ees 1980 et au d'ebut des ann'ees 1990, la

10 1. Introduction
performance du code 'etait la pr'eoccupation principale de l'utilisateur. A la fin des ann'ees 1990,
la taille du code est devenue un 'el'ement d'eterminant du monde de l'embarqu'e `a cause de la faible
capacit'e m'emoire de ces syst`emes, et la r'eduction de la consommation d''energie est 'egalement
devenue une priorit'e. Les mod`eles de co^ut des compilateurs ont donc 'evolu'e pour prendre en
compte ces nouveaux param`etres, parfois par une mod'elisation tr`es rudimentaire (consommation
des hi'erarchies m'emoires).

L'optimisation d'un programme au sein d'un compilateur se fait gr^ace `a l'application successive de transformations sur la repr'esentation du programme. Les meilleurs des compilateurs
actuels n'impl'ementent toutefois qu'un nombre restreint de transformations (entre dix et vingt),
et celles-ci sont appliqu'ees dans un ordre fig'e. La litt'erature quand `a elle, en propose plusieurs
centaines.

Optimisation it'erative. La compilation it'erative est une solution aux probl`emes des limitations de l'analyse statique. Cette derni`ere est alors compl'et'ee par des informations dynamiques
telles que le temps d'ex'ecution (par une simple ex'ecution), ou des informations d'etaill'ees sur le
nombre de hits ou de miss dans les caches de donn'ees (par une simulation ou en recourant `a des
compteurs mat'eriels). Ces informations permettent de mieux comprendre le comportement du
programme, et donc de prendre de meilleures d'ecisions pour l'optimisation.

En poussant cette approche `a l'extr^eme, il est raisonnable de penser qu'en ne recourant qu'`a
des analyses dynamiques pr'ecises (au besoin par simulation), il est possible de comprendre en
d'etail le comportement du programme sur l'architecture, et de guider tr`es pr'ecis'ement le processus de compilation, en choisissant les transformations adapt'ees aux probl`emes de performances
identifi'ees sur l'architecture.

Pour ce faire, il faut toutefois disposer d'un mod`ele unifi'e capable de repr'esenter l'ensemble
des transformations de programme : l'ensemble des transformations disponibles actuellement
dans les compilateurs n'est pas suffisant pour ^etre exploit'e par un tel processus it'eratif. Pour
passer `a l'application syst'ematique de m'ethodes de recherches empiriques, il faut r'esoudre les
probl`emes d'inhomog'en'eit'e au niveau des transformations, de leurs contraintes de composition,
et d'ordre d'application. Ces inhomog'en'eit'es ont en effet un impact tr`es n'egatif sur la structure
et la complexit'e de l'espace de recherche.

Contributions : Dans le cadre de cette th`ese, nous pr'esentons un formalisme unifi'e pour la
repr'esentation de programmes et de transformations de programme, capable de repr'esenter les
longues s'equences de transformations n'ecessaires `a l'optimisation des applications.

Nous avons pris soin de faciliter la recherche de la s'equence optimisante en s'eparant clairement les diff'erentes composantes du formalisme, et en favorisant la repr'esentation des transformations par une composition de t^aches 'el'ementaires sur ces composantes. Plusieurs invariants
permettent 'egalement de normaliser notre formalisme, limitant l'espace de recherche sans limiter
l'expressivit'e du formalisme.

Pour une s'equence de transformations donn'ee, contrairement aux repr'esentations classiques,
la phase de g'en'eration de code n'est appel'ee qu'une seule fois, lorsque toutes les transformations
ont 'et'e appliqu'ees, et non apr`es chaque transformation. Cela permet de maintenir une complexit'e
constante de la taille de la repr'esentation entre les diff'erentes transformations, 'evitant ainsi
de restreindre l'applicabilit'e des transformations suivantes, et de complexifier inutilement la
recherche de nouvelles transformations `a appliquer.

Nous avons 'egalement d'evelopp'e une suite de compilation compl`ete correspondant `a l'impl'ementation de notre formalisme et des transformations de code usuelles. Nous avons pris soin `a
ce que le d'eveloppement de nouvelles transformations au sein de cette application soit le plus

1. Introduction 11
simple possible, en d'efinissant un langage pour la d'efinition de transformations. Cette impl'ementation a permis d'optimiser avec succ`es le benchmark swim des SpecFP2000, au del`a de ce
que les meilleurs compilateurs 'etaient capables de r'ealiser.

Plan : Dans la Partie I nous pr'esenterons l''etat de l'art concernant l'optimisation de programme, et le compilateur que nous avons utilis'e. Dans la Partie II nous pr'esentons les limites
des repr'esentations syntaxiques et une nouvelle abstraction : les parties `a contr^ole statique. Nous
pr'esentons 'egalement les analyses classiques et les techniques d'ordonnancement du mod`ele poly'edrique. Et nous conclurons par une description en d'etail des techniques de g'en'eration de code
dans ce mod`ele. Dans la Partie III nous pr'esenterons en d'etail notre formalisme en expliquant
comment les programmes et les transformations de programme sont repr'esent'ees ; en d'efinissant
un ensemble d'invariants facilitant la recherche de ces transformations ; et en pr'esentant deux
exemples d'optimisations de programme. Enfin, dans la Partie IV nous pr'esenterons l'impl'ementation de notre processus d'optimisation, d'etaillant les choix d'impl'ementation que nous avons
effectu'es pour faciliter `a la fois l'utilisation du processus d'optimisation par des personnes ne
ma^itrisant pas le formalisme, et pour simplifier le d'eveloppement de nouvelles transformations
de programmes pour l'utilisateur expert du formalisme.

12 1. Introduction13

Premi`ere partie

Contexte

15
Chapitre 2

'Etat de l'art

Il existe de nombreuses techniques d'optimisation de programme, dont la plus r'epandue est la
parall'elisation. De nombreux outils et environnements ont donc 'et'e d'evelopp'es pour automatiser
l'extraction du parall'elisme des programmes s'equentiels.

Dans un premier temps, nous pr'esenterons les diff'erents environnements d'optimisation et
de parall'elisation. Dans la section 2.1, nous pr'esenterons les environnements source `a source, et
dans la section 2.2 nous pr'esenterons les environnements semi-automatiques.

Dans un second temps, nous pr'esenterons les diff'erentes techniques de compilation permettant l'optimisation : Dans la section 2.3 nous pr'esenterons l'optimisation adaptative, qui affine
l'ex'ecutable au fur et `a mesure de son ex'ecution. Dans la section 2.4 nous pr'esenterons les techniques utilis'ees dans la compilation it'erative qui produit des binaires interm'ediaires, successivement test'es pour diriger les phases suivantes de la compilation. Enfin, la section 2.5 pr'esentent
des r'esultats de l'optimisation manuelle des SpecFP 2000.

2.1 Optimisation source `a source

Les environnements source `a source effectuent une s'erie d'analyses sur les nids de boucles,
puis substituent des parties de ces nids de boucles par des versions plus facilement parall'elisables.
Cette substitution s'effectue soit directement sur le code source, soit dans une repr'esentation
interm'ediaire interne `a l'outil.

Polaris. Polaris [13] apporte une solution au faible taux de parall'elisation que les compilateurs
Fortran sont capable d'atteindre sur des benchmarks repr'esentatifs des applications r'eelles. Il
s'agit d'un compilateur parall'elisant et optimisant pour Fortran qui propose une s'equence d'analyses et de transformations `a appliquer aux nids de boucle pour extraire d'avantage de parall'elisme.

DO I=1, N
(S1) A(2*I) = ...
(S2) ... = A(2*I)
(S3) ... = A(2*I+1)
(S4) ... = A(I+2*N+1)

Fig. 2.1 - Exemple de code Fortran `a parall'eliser
La Figure 2.1 donne un exemple de source Fortran `a parall'eliser, elle nous servira `a illustrer
les phases d'analyses et de transformations r'ealis'ees par Polaris.

16 2. 'Etat de l'art

Pour parall'eliser une boucle, il ne faut pas que cette derni`ere porte des d'ependances interit'erations. Cette v'erification est r'ealis'ee par la phase d'analyse de d'ependances de Polaris :

- Le test d''egalit'e permet de v'erifier si deux fonctions d'acc`es `a des tableaux sont strictement

identiques. Il permet ici de s'assurer que deux it'erations diff'erentes des instructions S1
n'acc`edent pas `a la m^eme partie du tableau, tout comme deux it'erations des instructions
S1 et S2.
- Le test de PGCD permet de s'assurer du fait que l''egalit'e de deux fonctions d'acc`es poss`ede

une solution enti`ere ou non. Ici l''egalit'e des acc`es des instructions S1 et S3 s'exprime par
l''egalit'e 2 ^ I " 2 ^ I1 ` 1 qui n'a pas de solution enti`ere car le PGCD des coefficients (2)
ne divise par la composante enti`ere (1).
- Enfin le test d'intervalle v'erifie l'intersection d'intervalles d'existence des fonctions d'acc`es

pour r'esoudre ce probl`eme pour des coefficients non constants. Ici cette analyse permet de
v'erifier qu'il n'y a pas de d'ependance inter-it'eration entre les instructions S1 et S4.
La pr'esence dans les boucles de variables scalaires temporaires (uniquement utilis'es pour une
it'eration de la boucle) cr'ee 'egalement des d'ependances inter-it'erations qui inhibent la parall'elisation. La phase de privatisation transforme ces scalaires temporaires en tableaux temporaires
pour 'eliminer cette d'ependance. Cette privatisation est 'etendue aux tableaux (dont le nombre
de dimensions augmente par privatisation).

Les variables d'induction comme J dans la Figure 2.2(a), ne peuvent ^etre 'elimin'ees par privatisation. Ces variables sont caract'eris'ees par une incr'ementation constante `a chaque it'eration
de la boucle, et sont 'elimin'ees par la phase de substitution des variables d'induction : L'acc`es
ArJ s est alors remplac'e par Ar2 * Is.

J=0
DO I=1, N

J=J+2
A[J]= ...

(a) cas simple

J=0
DO I=1, N

J=J+1
S1(J)
DO K=1, I

J=J+1
S2(J)

(b) cas complexe

Fig. 2.2 - Variables d'induction
Polaris est capable de substituer des expressions complexes par des fonctions de plusieurs
it'erateurs englobants. Dans l'exemple de la Figure 2.2(b), les deux instructions sont substitu'ees
par S1pI * pI ' 1q{2q et S2pI * pI ' 1q{2 ` Kq.

Les r'eductions sur les tableaux sont 'egalement tr`es fr'equentes, et cr'eent des d'ependances
inter-it'erations : Il s'agit d'op'erations du style accumulation des valeurs d'un tableau, comme
indiqu'e dans la Figure 2.3.

DO I=1, N

S = S + A[I]

Fig. 2.3 - Op'erations de r'eduction
Polaris est capable d'analyser ce genre de nids de boucle pour d'ecider de la meilleure strat'egie
pour permettre la parall'elisation : Sommes partielles sur des copies de A sur chaque processeur
puis somme de ces sommes partielles, ou utilisation de s'emaphores pour cr'eer des sections critiques.

Toutes ces techniques permettent `a Polaris de trouver la plupart des opportunit'es de parall'elisation dans les codes Fortran de calcul intensif.

2.2. Optimisation semi-automatique 17
SUIF. Le compilateur SUIF [102, 48] parall'elise et optimise automatiquement des programmes
s'equentiels pour les architectures multiprocesseurs `a m'emoire partag'ee. Les deux principales
techniques utilis'ees par ce compilateur sont : La recherche de parall'elisme `a gros grain, et des
optimisations au niveau de la gestion de la m'emoire partag'ee.

La phase de recherche de parall'elisme `a gros grain utilise une s'erie d'analyses pour localiser
les opportunit'es de parall'elisme : Les analyses scalaires regroupent l'analyse de d'ependances,
la privatisation, et la reconnaissance de r'eductions. Les analyses de tableaux utilisent des techniques de programmation lin'eaire pour r'esoudre les probl`emes de d'ependances et permettent la
privatisation et la reconnaissance d'op'erations de r'eduction sur les tableaux. L'analyse interproc'edurale permet, suite `a des substitutions par inlining de fonctions, d'analyser le code expans'e
par les techniques intra-proc'edurales habituelles, et de caract'eriser les appels de fonctions suivant leurs diff'erents contextes, afin de d'eterminer pour chacun d'eux si la fonction doit ^etre
sp'ecialis'ee pour chacun de ces appels.

La phase d'optimisation de la m'emoire cherche `a r'eduire les probl`emes pos'es par les caches
des machines `a m'emoire partag'ees. La r'eduction globale du nombre de d'efaut de cache est
r'ealis'ee d'une part en maximisant les r'eutilisations des donn'ees au sein des m^emes processeurs,
et d'autre part en faisant au maximum travailler chaque processeur sur ces donn'ees contigu"es.

Le processus de parall'elisation est donc le suivant : des optimisations scalaires sont d'abord
appliqu'ees pour augmenter les opportunit'es de parall'elisme (propagation de constantes, d'etection de variables d'induction, privatisation scalaire, . . .). Puis les boucles sont restructur'ees par
des transformations unimodulaires guid'ees par l'analyse des d'ependances, ces transformations
permmettant d'optimiser pour le parall'elisme et la localit'e. Enfin la traducteur SUIF-to-C permet d'obtenir le source C correspondant `a la version optimis'ee.

Petit. Au sein du projet Omega, l'outil d'analyse de d'ependance et de restructuration de
boucles Petit [54, 53] est plus proche de notre travail. Il procure un environnement poly'edrique
unifi'e permettant d'appliquer un vaste choix de transformations de r'eordonnancement. Il partage
'egalement notre vision des transformations au niveau des instructions. C'est un outil de recherche

efficace pour la parall'elisation des noyaux de calculs intensifs.

2.2 Optimisation semi-automatique

Les environnements d'optimisation semi-automatique ne cherchent pas `a parall'eliser automatiquement des programmes s'equentiels, comme la plupart des environnements source `a source,
mais sont guid'es par l'utilisateur. Ce dernier peut alors indiquer quelles parties de code optimiser, forcer les transformations lorsque l'analyseur de d'ependance ne parvient pas `a d'eterminer
s'il y a ou non d'ependance, ou d'evelopper de nouvelles applications dans un environnement
optimisant.

ParaScope. ParaScope [27] est `a la fois un environnement de programmation parall`ele pour
architectures `a m'emoire partag'ee, et un compilateur source `a source interactif pour Fortran. Son
but est de faciliter le d'eveloppement d'applications parall`eles.

Parascope utilise un syst`eme d'analyse de d'ependances hi'erarchiques : quand les test les plus
simples ne sont pas capables de d'eterminer s'il y a d'ependance ou non, des tests plus co^uteux
sont appliqu'es. La Figure 2.4 pr'esente les diff'erents modules de ParaScope.

Le compilateur est divis'e en deux composants distincts : Le program compiler prend en
charge toute la partie inter-proc'edurale, et le module compiler optimise les proc'edures pour la

18 2. 'Etat de l'art

ProgramRepository

AbstractSyntax Tree
DependenceGraph

ProgramCompiler
InterproceduralIssues

ModuleCompiler
ProcedureTailoring

ParaScope

Editor

TransformedFortran

DependenceInformation

Composition

Editor

Fig. 2.4 - Processus de compilation de ParaScope
machine cible. Ces deux composants, via le program repository peuvent acc'eder aux informations
de d'ependances de donn'ees, et `a l'arbre de syntaxe de l'ensemble du programme. Cela permet au
module compiler par exemple de v'erifier si les param`etres des appels de la fonction qu'il optimise
sont constants, ce qui est souvent le cas (Ces param`etres correspondent souvent `a la taille des
structures de donn'ees, et se retrouvent dans les bornes des boucles de la fonction).

Le composition editor permet d'ajouter de nouvelles fonctions `a inclure au programme, et le
ParaScope editor est un 'editeur Fortran qui permet de visualiser et d''editer le code optimis'e en
affichant l'ensemble des d'ependances. Une s'erie de transformations de boucles interactives sont
alors applicables, et les r'esultats apparaissent directement sur le source.

MMAlpha. Deux outils de codesign partagent de nombreuses motivations et technologies
avec notre projet d'optimisation semi-automatique. Le premier d'entre eux, MMAlpha [46] est
un environnement manipulant des programmes 'ecrits dans le langage Alpha [70], et synth'etisant les descriptions VHDL des circuits correspondants. La Figure 2.5 donne un aper,cu de cet
environnement.

Alpha AST

C

VHDL
Parsing

transformations

Parsing
Analyses Parsing

Simulation
Mathematica

Fig. 2.5 - Le syst`eme MMAlpha
MMAlpha est un environnement de transformations poly'edriques utilisant la PolyLib et
Mathematica pour les phases d'analyses, et l'application des transformations de programme. Il
est le premier environnement `a avoir introduit une approche interactive et semi-automatique
dans le cadre des transformations poly'edriques.

L'arbre de syntaxe abstraite (AST) est impl'ement'e sous forme d'une structure symbolique
interne `a Mathematica, et les phases du processus de raffinement du programme sont impl'ement'ees par des manipulations symboliques de cet arbre sous forme de paquetages Mathematica. Les

2.2. Optimisation semi-automatique 19
diff'erentes phases sont les suivantes : la phase d'uniformisation transforme tout d'abord le programme Alpha en un programme Alpha uniforme 'equivalent, dont toutes les d'ependances sont
uniformes ; puis la phase d'ordonnancement associe `a chaque calcul (et donc `a chaque variable
dans le cadre d'un langage fonctionnel `a assignation unique) une date d'ex'ecution logique sous
forme de fonctions du temps multidimensionnelles affines par variable ; la phase de g'en'eration se
d'eroule en deux 'etapes : dans un premier temps la g'en'eration d'une description RTL sous forme
d'un programme Alpha0, puis dans un second temps la structuration de ce programme sous
forme d'un programme AlpHard. Ces deux langages Alpha0 et AlpHard sont des sous-ensembles
du langage Alpha.

La clef de MMALpha est le langage fonctionnel `a assignation unique Alpha, qui permet de
repr'esenter les algorithmes de haut niveau sous forme d''equations r'ecurrentes, et de repr'esenter
les impl'ementations mat'erielles de bas niveau correspondant `a ces algorithmes. La Figure 2.6
repr'esente un filtre FIR, impl'ement'e dans le langage Alpha.

system fir (x: {i | 1<=i<=100} of integer;

H: {n | 0<=n<=9} of integer)
returns (res : {i | 1<=i<=100} of integer);
var

Y : {i,n | 1<=i<=100; -1<=n<=9} of interger
let

Y[i,n] = case

{ | n=-1} : 0[];
{ | 0<=n} : Y[i,n-1] + H[n] * x[i-n];
res[i] = Y[i,9];

Fig. 2.6 - Programme Alpha d'un filtre FIR.
Le langage Alpha est un langage de flot de donn'ees : Il manipule des donn'ees multidimensionnelles, comme H, x et Y dans l'exemple. Ces donn'ees correspondent `a des unions de poly`edres
convexes (contrairement aux langages traditionnels qui manipulent des tableaux rectangulaires),
et les expressions permettent d'exprimer des restrictions de ces domaines pour effectuer les calculs, comme pour Y ri, ns) dans l'exemple.

Ce langage pose toutefois un r'eel probl`eme aux d'eveloppeurs qui ne veulent pas faire l'effort
d'une programmation fonctionnelle, moins intuitive que la programmation it'erative. De plus
l'expressivit'e du langage est restreinte, ce qui ne permet pas d'y impl'ementer tous les algorithmes.

Pico. Le second outil de codesign est PICO [90], qui vise `a automatiser la cr'eation d'acc'el'erateurs mat'eriels non programmables (NPAs). Il s'agit d'une approche plus pragmatique du
codesign, se limitant `a des nids de boucles parfaits dont les bornes sont constantes et les d'ependances uniformes, et produisant des designs VHDL des acc'el'erateurs mat'eriels correspondant `a
ces nids de boucles. La Figure 2.7 pr'esente le fonctionnement de PICO.

L'utilisateur fournit un nid de boucle en C, ainsi que l'ensemble des architectures `a explorer.
Le Spacewalker va trouver le meilleur NPA dans cet espace de recherche en sp'ecifiant le nombre
et la performances des processeurs, ainsi que la bande passante m'emoire au compilateur de NPA.
Ce dernier va, pour ces contraintes, cr'eer un design VHDL correspondant au nid de boucle. Les
informations de performance et de co^ut permettent d''evaluer les diff'erents design g'en'er'es et de
choisir les meilleurs.

La phase d'analyse de d'ependances ne g`ere que des acc`es affines, et commence par transformer
le nid de boucles en code `a assignation unique. L'analyse des d'ependances de flots permet alors
d'ordonnancer les acc`es de mani`ere `a qu'ils puissent ^etre pipelin'es. Les transformations de tiling
et la promotion de registres permettent de r'eduire efficacement le trafic m'emoire, permettant de

20 2. 'Etat de l'art

NPA Compiler

Parallel Loop Nest n~ Hardware
Datawidth

Analysis

FU
Allocation

Modulo
Scheduling

Datapath

Synthesis

Iteration Space n~ Space-Time
Dependence

Analysis Tiling

Iteration
Scheduling

Spacewalker
Loop nest(C)

Hostinterface

code NPA Design

(VHDL)

Explorerange

Perf.

Cost

Fig. 2.7 - Fonctionnement de PICO
contourner le probl`eme de la faible bande passante m'emoire, sans que le surco^ut mat'eriel soit
trop important. Enfin le Modulo scheluder utilisent des techniques de shifting et de modulos
pour distribuer les calculs sur les processeurs.

2.3 Compilation adaptative

C'est souvent le manque de connaissances `a propos des architectures cibles et des jeux de
donn'ees des applications qui limite le nombre des optimisations r'ealisables `a la compilation. La
compilation adaptative pallie ces limitations en retardant certaines d'ecisions jusqu'`a l'ex'ecution
du programme.

La compilation adaptative regroupe des techniques diff'erentes : Plusieurs versions d'une
m^eme partie d'un programme peuvent ^etre g'en'er'ees `a la compilation, l'une de ces versions 'etant
s'electionn'ee `a l'ex'ecution [18, 32]. La param'etrisation permet de g'en'erer un code restructurable
par changement des valeurs des param`etres [47], comme la taille de la tuile pour une version
tuil'ee d'un nid de boucle. Enfin, la compilation dynamique recompile des parties de codes lors
de l'ex'ecution [4, 25, 36, 3].

Voss et Eigenmann [99, 98] ont propos'e ADAPT, un environnement pour le support des
optimisations adaptatives modifiant le flot de contr^ole des parties `a optimiser comme l'indique
la Figure 2.8. Ainsi, dynamiquement, lorsqu'une version exp'erimentale de la section de code
est disponible, elle est ex'ecut'ee `a la place de la version actuelle, et s'il s'av`ere qu'elle est plus
performante, elle remplace cette version actuelle, qui correspond `a la version la plus performante
connue.

Ce mode de fonctionnement permet de sortir compl`etement l'optimiseur du chemin critique
de l'application : Seul un flag est test'e pour savoir si une nouvelle version est disponible. L'optimiseur qui produit les versions exp'erimentales et 'evalue leur performances apr`es ex'ecution
peut 'egalement ^etre ex'ecut'e sur un autre processeur, ou sur une autre machine du r'eseau. Les
heuristiques guidant chacune des optimisations r'ealis'ees par l'optimiseur sont sp'ecifi'ees dans un
langage ad-hoc (AL).

Le principal d'efaut de la compilation adaptative est que le travail d'optimisation est `a refaire
pour chaque nouvelle ex'ecution de l'application, et donc pour chaque jeu de donn'ees, quelque
soit la sensibilit'e de l'application `a la modification des jeux de donn'ees. La compilation it'erative,
elle, `a la fin de son processus d'optimisation produit un binaire final r'eutilisable.

2.4. Compilation it'erative 21

FLOT D'EX'ECUTION OPTIMISEUR

Versionexp'erimentale

pr^ete ?

Meilleure ver-sion connue

Version
exp'erimentale

NON OUI Compilateur

'Evaluateur de

performances

partie
`aoptimiser

Fig. 2.8 - Syst`eme d'optimisation ADAPT
2.4 Compilation it'erative

Les techniques d'optimisations it'eratives sont issues du monde de l'embarqu'e. Elles permettent au prix de temps de compilations bien plus important d'obtenir des programmes optimis'es sp'ecifiquement pour une architecture d'edi'ee.

Nous allons tout d'abord dans la section 2.4.1 pr'esenter les principes de la compilation it'erative. Dans la section 2.4.2 nous pr'esenterons les diff'erents travaux en rapport avec la compilation
it'erative, pour conclure dans la section 2.4.3 par les limitations de cette approche.

2.4.1 Pr'esentation

Lors de la compilation classique (voir Figure 2.9), le compilateur produit directement un
binaire `a partir du fichier source, ne basant son processus d'optimisation que sur des analyses
statiques.

Source Compilateur Binairefinal
Fig. 2.9 - Le processus de compilation classique
Lors de la compilation it'erative (voir Figure 2.10), le compilateur produit, `a chaque 'etape, des
binaires interm'ediaires qui sont test'es. Une analyse dynamique est r'ealis'ee `a partir des r'esultats
de ces tests qui permet de diriger le compilateur pour les 'etapes suivantes de la compilation. Il
est ainsi possible de prendre en compte le comportement du programme sur l'architecture pour
diriger la compilation et le choix des optimisations.

La plus simple des analyses dynamiques consiste `a ex'ecuter le binaire, mesurer son temps

22 2. 'Etat de l'art

Source Compilateur

Binaires
interm'ediaires

Binaire

final

feedback

Fig. 2.10 - Le processus de compilation it'eratif
d'ex'ecutions, et ainsi juger du gain de performance apport'e par les transformations de programme choisies et de leurs param`etres. Une autre solution peut par exemple consister, pour
une s'erie de transformations donn'ees, `a g'en'erer une grande quantit'e de binaires, en faisant varier
les param`etres des transformations, de tous les tester et de conserver celui avec le meilleur temps
d'ex'ecution.

La pr'esence des multiples phases de compilation rend la compilation it'erative beaucoup plus
lente que la compilation classique. Ceci d'autant plus que les analyses dynamiques peuvent ellem^eme ^etre tr`es gourmandes : Au lieu d'ex'ecuter le binaire interm'ediaire, il est par exemple
possible de le simuler au sein d'un compilateur cycle `a cycle pour conna^itre son comportement
exact sur l'architecture. Les temps de compilation passent alors facilement de quelques dizaines
de secondes `a plusieurs heures.

Initialement la compilation it'erative s'appliquait essentiellement au monde de l'embarqu'e.
En effet les architectures embarqu'ees 'evoluent beaucoup moins rapidement que les processeurs
g'en'eralistes, et la compr'ehension de son comportement du point de vue des performances et
de la consommation est importante. Les applications du monde de l'embarqu'e ont 'egalement
une longue dur'ee de vie, car fig'ees au sein du mat'eriel, et peu nombreuses. Le surco^ut de la
compilation it'erative est ainsi facilement amorti par le volume de production.

2.4.2 Travaux sur la compilation it'erative

Dans [14] et [57], O'Boyle et al. ont propos'e d''etendre le spectre de la compilation it'erative
`a la compilation pour processeurs g'en'eralistes, et d''etudier la faisabilit'e de cette technique
pour diff'erents nids de calcul intensif, ainsi que pour diff'erentes architectures. En faisant varier
les param`etres de quelques transformations, ainsi que la taille des donn'ees des programmes, il
ont montr'e que pour chaque programme `a optimiser, les meilleurs transformations d'ependaient
'enorm'ement de l'architecture sous-jacente et de la taille de ces structures. Ainsi, `a chaque fois

que l'architecture est am'elior'ee (comme par une augmentation de la taille des caches) toutes les
phases d'analyses statiques des compilateurs doivent ^etre r'e'ecrites et les programmes recompil'es.

Avec l'approche it'erative, un tr`es grand nombre de valeurs pour les param`etres sont test'es,
et le binaire offrant les meilleurs performances peut ^etre conserv'e. Les auteurs ont utilis'e des
m'ethodes simples d''echantillonnage pour trouver les param`etres correspondantsr'ein au temps
d'ex'ecution minimum, ce minimum 'etant trouv'e en parcourant moins de 10% de l'espace de
recherche, r'ealisant moins de 200 'evaluations. Plus int'eressant encore, il suffit de parcourir moins
de 1.25% de l'espace d'it'eration (soit environ 25 'evaluations) pour trouver des solutions proches
(`a 97% en moyenne) du minimum.

2.5. Optimisations manuelles 23

Plut^ot que de g'en'erer un grand nombre de binaires et de conserver le meilleur, il est plus
int'eressant d'extraire les informations observ'ees lors de l'ex'ecution des binaires interm'ediaires
et de les r'einjecter dans le compilateur qui peut ainsi prendre de nouvelles d'ecisions, cr'eant
ainsi un environnement complet [78, 42] capable d'optimiser des applications enti`eres sur une
architecture arbitraire.

Il est 'egalement possible d'utiliser des mod`eles de co^ut semblables `a ceux pr'esents dans
l'analyse statique, pour diriger l'algorithme parcourant l'espace de recherche correspondant aux
param`etres de quelques transformations sp'ecifiques. Dans [56] les auteurs utilisent des mod`eles
de caches pour s'electionner les facteurs de d'eroulage et les tailles de tuiles optimales pour les
deux transformations de d'eroulage et de tiling.

Il n'en reste pas moins que les espaces de recherche associ'es `a tous ces travaux sont extr^emement restreints du fait qu'ils ne consid`erent que de petits ensembles de quelques transformations,
et qu'ils utilisent des techniques directes (le temps d'ex'ecution principalement) pour 'evaluer le
bien fond'e des transformations. Dans [84], Parello et al. ont montr'e, sur l'exemple de la multiplication de matrices, qu'il 'etait n'ecessaire d'appliquer de longues compositions de transformations
diff'erentes pour obtenir des performances optimales. De plus, il est n'ecessaire d'appliquer certaines transformations de code d'egradant les performances (et qui seraient donc rejet'ees avec
une heuristique bas'ee simplement sur le temps d'ex'ecution) pour cr'eer de nouvelles opportunit'es
de transformations.

Cooper [28] propose gr^ace `a la compilation it'erative d'en finir avec l'ordre fig'e des phases
d'optimisation dans les compilateurs, et de diriger la recherche de la s'equence de transformations
optimale par des fonctions de co^ut externes au compilateur et d'ependant des objectifs (performance, taille de code, consommation). Il montre 'egalement que des techniques de recherche
simples, sans heuristique, sont capables de trouver des solutions satisfaisantes au probl`eme.

2.4.3 Conclusion

Les deux principales limitations de la compilation it'erative sont donc actuellement, d'une part
le manque d'un environnement unifi'e permettant de r'ealiser l'ensemble des transformations de
programmes, ce qui permettrait d'avoir un espace de recherche vraiment cons'equent. Et d'autre
part des crit`eres de choix trop simple pour juger de l'utilit'e des transformations appliqu'ees.

Fursin et al. [68] utilisent l'environnement unifi'e UTF [55] de Kelly et Pugh pour y impl'ementer un processus it'eratif, mais la cible est une nouvelle fois essentiellement des nids de boucles
et de petites applications. Les s'equences de transformations sont 'egalement g'en'eralement assez
courtes (de 2 ou 3 transformations).

Parello et al. [83] proposent que ce soit le comportement de l'architecture qui guide directement le processus d'optimisation en utilisant des simulateurs de processeurs cycles `a cycles pour
simuler les programmes plut^ot que de seulement consid'erer les temps d'ex'ecution. Dans le cadre
de ces travaux les transformations ont 'et'e appliqu'ees manuellement. Dans la section suivante
seront pr'esent'ees en d'etail les s'equences de transformations appliqu'ees.

2.5 Optimisations manuelles

Pour illustrer le fait que de longues s'equences de transformations de programme sont n'ecessaires pour optimiser efficacement les programmes, nous allons vous pr'esenter dans ce chapitre le
travail d'optimisation manuel effectu'e par Parello et. al [83] sur l'ensemble des SpecFP 2000 [95].
L'auteur est parvenu `a obtenir des performances sup'erieures `a celles obtenues par les meilleurs
compilateurs commerciaux pour 9 de ces SpecFP.

24 2. 'Etat de l'art

Apr`es une br`eve pr'esentation des r'esultats dans le Section 2.5.1, nous d'ecrirons bri`evement la
m'ethodologie utilis'ee dans la Section 2.5.2, et 'etudierons plus en d'etail les s'equences de transformations propos'ees pour 5 de ces benchmarks dans la Section 2.5.3 montrant la n'ecessit'e d'avoir
de longues et complexes s'equences de transformations, un ordre non fig'e dans lequel appliquer
ces transformations, et la n'ecessit'e d''egalement consid'erer les s'equences de transformations d'egradant les performances.

2.5.1 R'esultat exp'erimentaux

La Figure 2.11 donne la valeur des diff'erents speed-ups obtenus pour chaque benchmark
par rapport `a la performances base pour l'optimisation manuelle propos'ee dans [83] et les performances peak, qui repr'esentent les meilleurs performances que sont capables d'atteindre les
meilleurs compilateurs commerciaux.

1
2
3

speed-up

swim galgel wupwise applu apsi facerec ammp equake mesa mgrid fma3d art

base peak manuel

Fig. 2.11 - Speed-up obtenus sur 12 benchmarks SpecFP2000
L'architecture utilis'ee pour ces exp'eriences est un Alpha 21264C EV68 (HP AlphaServer
ES45) `a 1GHz (1 processor enabled) avec 8MB de cache L2 et 8GB de m'emoire. Les compilateurs
utilis'es sont les compilateurs Fortran (V5.4) et C (V6.4) de HP. Les options de compilations sont
-arch ev6 -fast -O5 ONESTEP, et le pr'eprocesseur Fortran KAP (v4.3) a 'egalement est utilis'e.

Dans la Section 2.5.3, nous d'etaillerons les s'equences de transformations manuelles propos'ees
pour les 5 premiers benchmarks de la Figure 2.11 qui ont obtenus des speed-ups significatifs.

2.5.2 M'ethodologie

L'approche propos'ee dans [83] utilise une m'ethodologie empirique pour l'optimisation de
programmes complets, en prenant en compte les composants de l'architecture et leurs comportements pendant l'ex'ecution du programme. Pour cela les programmes sont simul'es avec le
simulateur de processeur cycle `a cycle HP EV68, et des informations sont collect'ees `a propos de
la sous utilisation des parties de l'architecture.

Ces informations ont permis de construire empiriquement un arbre de d'ecision associant
anomalies d'etect'ees sur l'architecture pendant l'ex'ecution, et transformations de programmes
`a appliquer pour r'eduire ces anomalies. Alternent donc des phases d'analyses et d'application
manuelles de transformations aux termes de chacune desquelles une 'evaluation de la performance
est effectu'ee en ex'ecutant sur la machine r'eelle.

Ainsi, bien que ce proc'ed'e soit manuel, il n'en est pas moins syst'ematique et it'eratif, et il
permet de construire des s'eries de transformations appliqu'ees `a diff'erents endroits du programme.
Dans la section 2.5.3 nous montrerons sur 5 benchmarks, que ce sont souvent les m^emes r'egions
du programmes qui sont transform'ees, et qu'il s'agit donc bien de compositions de s'equences de
transformations.

2.5. Optimisations manuelles 25
2.5.3 R'esultats d'etaill'es pour quelques benchmarks

Dans cette section, nous allons d'etailler les s'equences de transformations appliqu'ees aux
benchmarks swim, galgel, wupwise, applu et apsi. Pour ces exemples, l'ensemble des fonctions et
des proc'edures ont 'et'e inlin'es par KAP. Nous avons repr'esent'e les s'equences obtenues dans les
Figures 2.12, 2.13, 2.14, 2.15 et 2.16.

Chaque 'etape d'analyse et de transformation est repr'esent'ee par une bo^ite grise, indiquant `a
chaque fois le gain obtenu au niveau du temps d'ex'ecution du benchmark complet. Ces r'esultats
sont donn'es en secondes, et une valeur n'egative signifie une diminution du temps d'ex'ecution,
et donc une am'elioration des performances (Le temps d'ex'ecution de base de chaque benchmark
est donn'e dans sa l'egende). Chaque 'etape de transformation (les bo^ites grises) comportent une
s'eries de transformations repr'esent'ees par les bo^ites blanches.

A1 : -32s

A2 : -30s A3 : -15s

Peeling Shifting
Peeling Shifting Fusion
Peeling Shifting

Array forw.
substitution Padding Tiling

Fig. 2.12 - Optimizing swim (base 204s)
A1:-14s

A2:+24s

A3 :-24s

A4:-5s

A5 :-6s

Interchange

Strip-mining

Strip-mining

Fusion
Fusion
Fusion
Fusion

Scalar
promotion

Instruction

splitting Shifting Fission

Strip-mining

Fusion
Fusion

Shifting Array copypropagation

Strip-mining

Scalar
promotion

Fusion

Fusion

Hoisting Unrolland jam Registerpromotion

Fig. 2.13 - Optimizing galgel (base 171s)

A1 : -19s A2 : -45s A3 : -11s
Fusion Fullunrolling Fullunrolling Arraycontraction Scheduling

Fig. 2.14 - Optimizing wupwise (base 236s)

G : -11s

B2 : -18s
B1 : -4s
Fusion

Instruction

splitting

Privatization

Privatization

Fission Fullunrolling

A : -29s
Full
unrolling

Float. point

reordering

Scalar
promotion

Fig. 2.15 - Optimizing applu (base 214s)
Une forte localit'e des transformations : Dans les Figures 2.12 `a 2.16., les transformations
sont situ'ees sur une m^eme ligne lorsqu'elles s'appliquent aux m^emes r'egions d'un programme.
On constate donc une forte localit'e sur l'endroit o`u sont appliqu'ees les transformations. Par
exemple dans galgel, toutes les optimisations concernent le m^eme nid de boucle, et pour swim
trois nids de boucles sont fusionn'es et c'est le nid de boucles r'esultant qui est optimis'e.

26 2. 'Etat de l'art

G : -27s B2 : -1s B3 : -1s

B1 : -31s

Data
layout

Fission

Privatization
Privatization

Interchange Fission Softwarepipelining

A1 : -3s A2 : -2s A3 : -1s

Fission Peeling Fusion Softwarepipelining

Software
pipelining

C1 : -11s
Privatization

Privatization Interchange

Fission

Fig. 2.16 - Optimizing apsi (base 378s)

On peut donc effectivement parler de compositions de s'equences de transformations. Une
m'ethodologie facilitant la composition de transformations de programme faciliterait donc cette
recherche de s'equence de transformation optimisante.

Des s'equences longues et complexes : Nous avons d'ej`a illustr'e la pr'esence de s'equences
de transformations. On peut 'egalement observer que ces s'equences sont souvent longues et
complexes : Pour galgel, on observe m^eme une composition de 23 transformations de boucles et
de tableaux localis'ees dans le m^eme nid de boucle, pour apsi ce sont trois nids de boucles qui
sont transform'es par 10 transformations pour pouvoir ^etre fusionn'es ensemble, pour applu les 9
transformations s'effectuent `a deux endroits de la m^eme boucle fusionn'ee.

Des d'egradations locales de performances : Certaines 'etapes de transformations, comme
l''etape A2 pour galgel peuvent d'egrader les performances, et ces 'etapes ne sont pas forc'ement
inutiles, car elle peuvent permettre d'appliquer de nouvelles s'equences de transformations qui
jusqu'alors n''etaient pas l'egales, et ces derni`eres apporteront de grosses am'eliorations de performances, couvrant largement la d'egradation.

Pour ce benchmark, les multiples fusions et la promotion scalaire ont tellement rapproch'e
les productions de valeurs de leur consommation, que les latences d'acc`es m'emoire ne sont plus
recouvertes, et que les d'ependances de donn'ees deviennent donc le principal probl`eme. Par
contre, cela permet d'envisager l''etape suivante qui va r'ealiser une sorte de pipeline logiciel, et
ainsi facilement r'egler les probl`emes de latences m'emoires.

Les m'ecanismes de la compilation it'erative pr'esent'es dans la Section 2.4, pour permettre ce
style de transformations, ne devront donc ne pas uniquement utiliser le crit`ere de la performance
(plus sp'ecifiquement le temps d'ex'ecution) pour 'evaluer l'utilit'e de certaines transformations.

Un ordre non fig'e : On remarque 'egalement que l'ordre dans lequel sont appliqu'ees les
transformations n'est absolument pas fig'e. En effet, les transformations ne sont pas toujours
appliqu'ees pour les m^emes raisons : Consid'erons par exemple les transformations de fusion,
fission et interchange. Pour galgel la transformation de permutation de boucle est appliqu'ee
en premier car elle rend l'egale toute la suite d'optimisations. Les transformations de fusions
et de fission sont appliqu'ees apr`es. Pour apsi et applu les fusions et les fissions sont r'ealis'ees
avant la transformation de permutation de boucle (Pour applu la transformation finale de tiling

2.6. Conclusion 27
r'ealise une permutation de boucle. Cette fois la permutation ne sert pas `a rendre l'egale d'autres
transformations, mais `a obtenir une meilleure localit'e des acc`es m'emoire.

Dans le Chapitre 4, nous mettrons en avant que les compilateurs classiques fonctionnent par
phase, et ex'ecutent leur phase d'optimisation dans un ordre fig'e. Ainsi, les transformations de
fusions et de fissions sont souvent r'ealis'ees dans la m^eme phase, tandis que la permutation de
boucle est r'ealis'ee dans une phase diff'erente. Un tel compilateur se prive donc d'un des deux
types d'utilisation de la transformation de permutation de boucle.

Par contre cette restriction est facilement contourn'ee dans le cadre de la compilation it'erative
(voir Section 2.4), le processus de compilation it'eratif appliquant plusieurs fois l'int'egralit'e des
phases pr'esentes dans le compilateur.

Motifs : Les algorithmes une fois impl'ement'es poss`edent souvent des parties de codes extr^emement similaires. Cela se refl`ete lors du processus d'optimisations par la pr'esence de motifs
dans la s'equence des transformations. Dans swim les m^emes transformations sont appliqu'ees
aux trois boucles (peeling et shifting) pour rendre la fusion l'egale. Dans apsi la m^eme s'equence
d'optimisations est appliqu'ee `a deux fonctions extr^emement similaires (B1 et C1).

2.6 Conclusion

Ces optimisations manuelles des SpecFP 2000 ont montr'e d'une part qu'il 'etait possible
d'appliquer de longues compositions de transformations pour am'eliorer la performances des
programmes, et d'autre part qu'une connaissance pr'ecise du comportement de l'architecture
permettait efficacement de diriger un processus de compilation.

La Figure 2.17 r'esume les r'esultats de performance obtenus sur l'ensemble des 12 SpecFP. La
premi`ere colonne de r'esultat indique le speed-up obtenu pour les meilleures options de compilations possibles par rapport aux options de compilation standard (-Obest). La seconde colonne le
speedup obtenu (toujours par rapport `a la compilation standard) par le processus d'optimisation
manuel. Les trois benchmarks mgrid, fma3d, et art qui obtiennent de moins bons r'esultats que
la version peak illustrent la p'enibilit'e d'une recherche manuelle dans l'espace de recherche gigantesque des optimisations de programme. Un outil permettant d'appliquer automatiquement
ou semi-automatiquement les transformations de programmes faciliterait grandement une telle
recherche.

Peak SPEC Opt. Manuelles
swim 1.00 1.61
galgel 1.04 1.39
wupwise 1.20 2.90
applu 1.47 2.18
apsi 1.07 1.23
mesa 1.04 1.42
ammp 1.18 1.40
equake 2.65 3.22
mesa 1.12 1.17
mgrid 1.59 1.45
fma3d 1.32 1.09
art 1.22 1.07

Fig. 2.17 - Speed-up for 12 SPECFP2000 benchmarks

Pour passer d'une technique d'optimisation manuelle `a un processus automatique, il faut, tout

28 2. 'Etat de l'art
comme dans le cas de la compilation it'erative, un environnement unifi'e permettant d'appliquer
l'ensemble des transformations de programme. Les Parties III et IV proposeront le formalisme
et l'impl'ementation correspondant `a un tel environnement bas'e sur le mod`ele poly'edrique.

29

Chapitre 3
Le choix du compilateur

Au d'ebut de la th`ese s'est pos'e la question du choix du compilateur sur lequel nous allions
baser notre environnement d'optimisation. Nous allons dans ce chapitre vous expliquer les raisons
qui nous ont amen'e `a choisir le compilateur Open64.

3.1 Front-ends

Nous nous pla,cons dans le contexte de l'optimisation d'applications de calculs scientifiques.
Ces applications sont la plupart du temps 'ecrite en Fortran (77 ou 90), ou en C (plus rarement
en C++). Nous avons donc rechercher des environnements de compilations sachant traiter ces
diff'erents langages. Open64 poss`ede les front-ends suivants : C, C++, Java (source ou bytecode),
et Fortran (77 ou 90).

3.2 Repr'esentation interm'ediaire :

La repr'esentation interm'ediaire des compilateurs Open64, la WHIRL, a 'et'e introduite par le
compilateur Pro64 de SGI. Elle procure une forme interm'ediaire unique quelque soit le front-end
utilis'e, et donc le langage du programme source de d'epart.

Cela nous permet, dans notre contexte d'optimisations de programmes C, Fortran et Fortran90, de ne r'ealiser le travail d'extraction des informations relatives `a notre formalisme (l'extraction des SCoPs) qu'une seule fois `a partir d'une repr'esentation interm'ediaire unique.

Une propri'et'e importante du compilateur Open64 est d'utiliser la m^eme repr'esentation interm'ediaire lors des diff'erentes phases de la compilation, et ce jusqu'`a l'obtention d'un code trois
adresses qui poss`ede sa propre repr'esentation. En fait la WHIRL poss`ede des niveaux. Plus le
niveau de la WHIRL est 'elev'e, plus sa s'emantique ressemble `a celle des langages de haut niveau,
avec des s'equences de code tr`es courtes, et une description tr`es hi'erarchique. Plus le niveau de
la WHIRL est bas, plus sa s'emantique ressemble `a celle du langage machine, avec de longues
s'equences de code, et une description tr`es aplatie.

Cela a de multiples avantages, par rapport aux compilateurs avec formes interm'ediaires
multiples. Le premier est de r'eduire la perte de s'emantique inh'erente `a chaque changement de
forme. Avec la WHIRL, la plupart des phases d'analyses peuvent ^etre r'ealis'ees sur les hauts
niveaux de la WHIRL (lorsque la s'emantique est la plus forte) et les r'esultats de ces analyses
utilis'es dans des niveaux plus bas. Avec des repr'esentations interm'ediaires dissoci'ees, il n'est
pas toujours facile de retrouver les informations de haut niveau (comme des informations sur les
boucles, leurs bornes, leur nombre d'it'erations) dans les repr'esentations de bas niveaux.

30 3. Le choix du compilateur

Un autre avantage vient du fait que lors du processus d'optimisation, plusieurs optimisations
comme la propagation de constantes, l''elimination de code mort, et certaines phases d'analyses
doivent ^etre r'e-appliqu'ees plusieurs fois `a diff'erents niveaux. Avec une forme interm'ediaire commune, une seule impl'ementation de ces techniques est suffisante, et plus important encore, la
communication entre les phases de compilations est 'egalement beaucoup plus simple vu que
celles-ci travaillent sur la m^eme repr'esentation.

Lors du processus de compilation, le niveau de la WHIRL est successivement abaiss'e, certaines constructions 'etant remplac'ees par d'autres de plus bas niveau. Les constructions de type
if/then/else finissent par exemple par ^etre converties en goto (ou en pr'edicats d'instructions
quand la cible est IA64), et les acc`es aux tableaux eux sont convertis en calculs d'adresses. La
Figure 3.1 d'ecrit les diff'erents niveaux de la WHIRL, et ses abaissements successifs :

CC++ Java

Bcode

F77
F90 Front-ends

Inlining
Very High WHIRL

Call unnesting
High WHIRL Address computation replacement

(Access subscript, record constructs)
Control construct lowering

(if/then/else)Mid WHIRL

Intrinsic call loweringLoad/Store lowering

Low WHIRL

Opcode type mapping
Very Low WHIRL

Code Generation
Machine Code Representation

Fig. 3.1 - Les niveaux de la WHIRL
Nous extrairons les informations permettant de construire notre repr'esentation du niveau
High WHIRL. A ce niveau, les acc`es aux tableaux ne sont pas encore convertis en calculs
d'adresses, et le contr^ole du programme est semblable `a celui du code source. La WHIRL est alors
compos'ee d'un arbre semblable `a l'arbre de syntaxe abstraite du code source, et d'un ensemble
de table de symboles, et d'informations issues des phases d'analyses.

Un autre avantage extr^emement int'eressant de la repr'esentation interm'ediaire d'Open64
est la possibilit'e de sauvegarder la WHIRL dans un fichier ASCII ou un fichier binaire. Cette
repr'esentation ASCII ne peut plus ^etre utilis'ee par le compilateur, mais elle est extr^emement
int'eressante du point de vue du d'eveloppement. Elle a massivement 'et'e utilis'ee pour le d'ebogage
de l'algorithme d'extraction des SCoPs, et celui de g'en'eration de WHIRL. La repr'esentation
binaire est encore plus int'eressante, car elle peut ^etre fournie directement au compilateur, qui
dans ce cas saute l''etape front-end.

3.3. Les phases du compilateur 31

Cela va nous permettre d'extraire la forme interm'ediaire du compilateur Open64, de la modifier en appliquant nos transformations, et de pouvoir librement la r'einjecter dans le compilateur.

3.3 Les phases du compilateur

La compilation au sein des compilateurs est organis'ees en phases d'optimisations successives.
La Figure 3.2 pr'esente les principales phases d'Open64, avec `a droite le niveau de la WHIRL
utilis'e par cette phase :

Pre-Optimization (PreOpt)
Loop Nest Optimizer (LNO)
Scalar Global Optimisation (WOPT)

Code Generation (CG)

High WHIRL
Mid WHIRL
Very Low WHIRL
Fig. 3.2 - Les phases du compilateur Open64
La premi`ere de ces phases (PreOpt) r'ealise tout une s'erie d'analyses utilis'ees par les phases
suivantes (analyse d'aliasing de pointeurs, analyses interproc'edurales, etc.) et prend en charge
la propagation de constante, l''elimination de code mort, la suppression de gotos, et surtout,
la normalisation des boucles en do-loops. Notre formalisme n''etant capable d'optimiser que les
parties `a contr^ole statique du programme (Les nids de boucles dont le contr^ole s'exprime sous
forme d'in'equations affines des it'erateurs englobants, voir Chapitre 5) ces phases de simplification
sont indispensables, car elles permettent de rendre statique de grande parties du programme. La
Figure 3.3 donne plusieurs exemples de normalisations effectu'ees par la phase de pr'e-optimisation
sur des parties de code non-statiques, qui apr`es normalisation, sont devenues statiques.

int foo(int M)

N=100;
for(i=0;i<M*N;i++)

S1

int foo(int M)

for(i=0;i<100*M;i++)

S1

(a) Exemple de propagation de constantes
i=100;
while(i>=0)

A[i] = f(i);
i--;

for(i=0;i<=100;i++)

A[100-i] = f(100-i)

(b) Exemple de promotion en do-loop et de normalisation
x=0;
for(i=0;i<=20;i++)

for(j=0;j<=30;i++)

x=x+2
A[x] = x;

for(i=0;i<=20;i++)

for(j=0;j<=30;i++)

A[2*j + 40*i] = 2*j + 40*i;

(c) Exemple de substitution de variables d'inductions
Fig. 3.3 - Exemples de normalisations utiles pour la staticit'e et l'affinit'e

32 3. Le choix du compilateur

La seconde phase (LNO) du compilateur Open64 est celle correspondant `a l'optimisation
des nids de boucles, comme l'optimisation pour la localit'e et la parall'elisation, la distribution
de boucles, les transformations unimodulaires, la privatisation de tableaux, etc. La troisi`eme
phase (WOPT) prend en charge les optimisations sur une repr'esentation `a assignation unique :
reconnaissance de variable d'induction, 'elimination des redondances, r'eduction de force, etc. La
derni`ere phase de g'en'eration de code (CG) produit le binaire `a partir d'une repr'esentation de
code trois adresses.

Open64 permet, gr^ace `a de nombreuses options de compilation, d'une part de choisir quelles
phases ex'ecuter, et d'autre part de sortir la repr'esentation binaire de la WHIRL apr`es chaque
phase. On peut donc proc'eder comme suit : n'ex'ecuter que jusqu'`a la phase de pr'e-optimisation
comprise et sortir le fichier binaire, `a l'aide d'une s'erie d'outils manipuler ce fichier binaire, puis
fournir ce fichier binaire comme fichier d'entr'ee au compilateur en n'activant que la phase de
g'en'eration (et 'eventuellement la phase WOPT). Nous obtenons alors le processus d'optimisation
pr'esent'e dans la Figure 3.4.

input.c
PreOPT

LNO
WOPT

CG

PreOPT

LNO
WOPT

CG
output.bin

input.N
output.N

our
optimisation

framework

open64 -S -PHASE :p=on :l=off :w=off :c=off input.c open64 -PHASE :p=on :l=off :w=off :c=off output.N

Fig. 3.4 - Processus d'optimisation
Cela permet ainsi de remplacer les phases d'optimisations du compilateur par notre propre
environnement d'optimisation, tout en b'en'eficiant du travail de la phase de pr'e-optimisation qui
a d'ej`a s'epar'e les boucles en deux cat'egories, les do-loops qui correspondent `a des boucles de
type Fortran (Aucune modification de l'it'erateur dans le corps de boucle, stride constant), et
les boucles while qui repr'esentent les autres types de boucles, que notre formalisme ne sait pas
g'erer.

En fait, la phase de PreOpt doit absolument ^etre ex'ecut'ee une seconde fois car elle r'ealise
des analyses n'ecessaires aux phases suivantes (notamment la phase WOPT). Certaines parties
du LNO doivent 'egalement ^etre activ'ees pour que Open64 soit capable de produire un binaire.

3.4 Source `a source

Le compilateur Open64 offre 'egalement la possibilit'e de r'eg'en'erer du source C ou du source
Fortran `a partir de la repr'esentation binaire de la WHIRL. Bien que notre framework ne se situe
absolument pas d'un contexte d'optimisation de code source to source, cela est extr^emement
utile du point de vue du debogage encore une fois. Cela permet de g'en'erer le code apr`es chaque
transformation dans le but de v'erifier que l'impl'ementation de la transformation est correcte.

3.4. Source `a source 33

Les outils de r'eg'en'erations whirl2c et whirl2f fournis avec Open64 sont au stade exp'erimental.
Actuellement certains acc`es aux tableaux et les acc`es aux membres des structures C sont effectu'es
sous forme de calculs d'adresse, et une multitude de typecast, la plupart du temps inutiles, sont
g'en'er'es dans les op'erations arithm'etiques.

Cela ne pose pas de probl`emes particuliers dans le cadre d'une utilisation comme outils de
d'ebogage. Par contre, cela les rend impropres `a ^etre utilis'es dans un environnement source to
source.

Berkeley UPC [20] ont propos'e un outil beaucoup plus robuste capable de r'eg'en'erer du code
C `a partir de la WHIRL. Une 'equipe de Rice University a d'evelopp'e l'outil Open64/SL [22]
capable de r'eg'en'erer du code Fortran 90.

34 3. Le choix du compilateur35

Deuxi`eme partie
Mod`ele de programmes et

techniques de compilation

37
Chapitre 4
Limitations inh'erentes aux
repr'esentations syntaxiques

Au sein des compilateurs actuels, apr`es l'application d'une transformation `a une section du
programme, une nouvelle version du code de cette section est g'en'er'ee, dans la forme interm'ediaire
syntaxique ad'equate (arbre de syntaxe abstraite, code trois adresses, graphe `a assignation unique,
. . .), d'o`u le terme de transformations syntaxiques. Ce comportement se retrouve 'egalement dans
tous les travaux pr'ec'edents sur des infrastructures bas'ees sur des mod`eles `a base de matrices ou
de poly`edres.

Dans ce chapitre, nous allons montrer les diff'erentes limitations inh'erentes `a ces repr'esentations syntaxiques des programmes. La section 4.1 d'etaille le probl`eme de l'accroissement rapide
de la taille du code lors de l'application de longues s'equences de transformations. La section
4.2 pr'esente les probl`emes que pose l'application des transformations pr'ec'edentes pour l'algorithme de reconnaissance de motif qui guide l'application de nouvelles transformations. La
section 4.3 souligne le probl`eme majeur pos'e par le fonctionnement par phase des compilateurs :
l'impossibilit'e de r'ep'eter certaines transformations apr`es que des transformations des phases
ult'erieures aient 'et'e appliqu'ees. Enfin, la section 4.4 montre que produire une nouvelle version
de la repr'esentation `a chaque transformation est 'egalement une limitation, car cela peu rendre
les transformations suivantes ill'egales.

4.1 Probl`emes de taille de code et de complexit'e

La cons'equence directe des mod`eles syntaxiques, est l'accroissement important de la taille du
code et de la complexit'e apr`es l'application de multiples transformations de codes. Consid'erons
l'exemple simple de la Figure 4.1.

for (i=0; i<M; i++)
S1 Z[i] = 0;

for (j=0; j<N; j++)
S2 Z[i] += (A[i][j] + B[j][i]) * X[j];

for (k=0; k<P; k++)

for (l=0; l<Q; l++)
S3 Z[k] += A[k][l] * Y[l];

Fig. 4.1 - Exemple de programme `a optimiser
Pour r'eduire la distance de localit'e du tableau A, il est profitable de fusionner dans un premier
temps les boucles i et k (la nouvelle boucle sera nomm'ee i) et les boucles j et l dans un second

38 4. Limitations inh'erentes aux repr'esentations syntaxiques
temps (la nouvelle boucle sera nomm'ee j). Tuiler les boucles i et j permet ensuite d'exploiter la
localit'e spatiale, ainsi que la localit'e du TLB au niveau du tableau B qui est acc'ed'e par colonne.
Pour r'ealiser toutes ces transformations, les 'etapes suivantes sont n'ecessaires :

- Fusionner les boucles i et k
- Fusionner les boucles j et l
- Fissionner l'instruction Z[i]=0 `a l'ext'erieur de la boucle i,
- Strip-miner la boucle i
- Strip-miner la boucle j
- Permuter les boucles i et jj (la boucle g'en'er'ee via le strip-mine de la boucle j)
Les bornes des boucles i et j 'etant diff'erentes, les 'etapes de fusion et de strip-mining vont
progressivement multiplier le nombre de versions de nids de boucle, chaque version avec une
garde diff'erente. Apr`es toutes ces transformations, le programme contient de multiples instances
de la section de code de la Figure 4.2. Le nombre d'instructions du programme apr`es chaque
'etape est indiqu'e dans la Figure 4.3. La colonne "syntaxique" correspond `a une repr'esentation

syntaxique classique telle qu'on en trouve dans les compilateurs (la taille y est exprim'ee en
nombre de lignes de code source), la colonne "poly'edrique" correspond `a notre formalisme (d'efini
dans la partie III) et la taille y est exprim'ee en nombre de cellules de matrices.

...
if ((M >= P+1) && (N == Q) && (P >= 63))

for (ii=0; ii<P-63; ii+=64)

for (jj=0; jj<Q; jj+=64)

for (i=ii; i<ii+63; i++)

for (j=jj; j<min(Q,jj+63); j++)

Z[i] += (A[i][j] + B[j][i]) * X[j];
Z[i] += A[i][j] * Y[j];
for (ii=P-62; ii<P; ii+=64)

for (jj=0; jj<Q; jj+=64)

for (i=ii; i<P; i++)

for (j=jj; j<min(Q,jj+63); j++)

Z[i] += (A[i][j] + B[j][i]) * X[j];
Z[i] += A[i][j] * Y[j];
for (i=P+1; i<min(ii+63,M); i++)

for (j=jj; j<min(N,jj+63); j++)

Z[i] += (A[i][j] + B[j][i]) * X[j];
for (ii=P+1; ii<M; ii+=64)

for (jj=0; jj<N; jj+=64)

for (i=ii; i<min(ii+63,M); i++)

for (j=jj; j<min(N,jj+63); j++)

Z[i] += (A[i][j] + B[j][i]) * X[j];
...

Fig. 4.2 - Versioning apr`es fusion de la boucle externe

Syntaxique Poly'edrique(#lignes) (#values)
Original code 11 78Outer loop fusion 44

p^4.0q 78 p^1.0qInner loop fusion 132
p^12.0q 78 p^1.0qFission 123
p^11.2q 78 p^1.0qStrip Mine 350
p^31.8q 122 p^1.5qStrip Mine 407
p^37.0q 182 p^2.3qInterchange 455
p^41.4q 182 p^2.3q

Fig. 4.3 - Comparaison de taille entre les repr'esentations

Le code final g'en'er'e `a partir la repr'esentation poly'edrique sera d'une complexit'e similaire,

4.2. Probl`eme de reconnaissance de motifs 39
mais cette complexit'e n'appara^itra pas avant la phase de g'en'eration de code, et donc, n'aura pas
d'incidence sur l'applicabilit'e des transformations. La repr'esentation poly'edrique consiste en un
nombre fix'e de matrices associ'ees `a chaque instruction du programme. Ainsi, la complexit'e de la
repr'esentation ne varie que tr`es peu au fur et `a mesure que des transformations sont appliqu'ees.
Le nombre d'instructions demeure le m^eme jusqu'`a la phase de g'en'eration de code, et seule la
dimension de quelques matrices peut augmenter, comme l'indique la Figure 4.3.

Notez que plus le code est complexe, plus cette diff'erence sera importante : par exemple,
si la seconde boucle 'etait triangulaire (j=0 ;i<i ;j++), alors le nombre de lignes de la version syntaxique serait de 34153 alors que la taille de la repr'esentation poly'edrique demeurerait
inchang'ee (M^eme nombre d'instructions, et m^eme taille de matrices).

4.2 Probl`eme de reconnaissance de motifs

Les compilateurs basent leur recherche d'opportunit'es pour les transformations gr^ace `a des
r`egles de pattern-matching. Cette approche est extr^emement fragile, surtout dans le contexte de
compositions complexes de transformations, car les transformations pr'ec'edentes peuvent d'etruire
les r`egles des transformations qui suivent. Cette faiblesse est confirm'ee par l''evolution historique
des benchmarks SPEC CPU, souvent dirig'ee pour 'eviter les m'ecanismes un peu trop ad hoc mis
en place dans les compilateurs commerciaux [85].

Pour illustrer notre point de vue, nous avons tent'e de r'ealiser les transformations de la
section pr'ec'edente avec comme cible l'Alpha 21364 EV7, en utilsant KAP C(v4.1) [51], l'un
des meilleurs pr'e-processeurs disponible (transformations de boucles et de tableaux en source `a
source). La Figure 4.4 montre les performances obtenues par KAP et pour les diff'erentes 'etapes
de la s'equence de transformations d'ecrite ci-dessus (fusion des boucles externes et internes, puis
tuilage) sur l'exemple de d'epart.

Original KAP Double Fusion Full Sequence
Time (s) 26.00 12.68 19.00 7.38

Fig. 4.4 - Temps d'ex'ecution pour l'exemple de la Figure 4.1

Nous avons montr'e que KAP n'a pu appliquer quasiment aucune des transformations list'ees
car ses motifs de pattern-matching 'etaient la plupart du temps trop limit'es. Bien que n'ayant
pas acc`es au sources de KAP, nous avons proc'ed'e `a de l'ing'enierie inverse en modifiant le source
jusqu'`a ce que KAP soit capable d'appliquer les transformations, les limitations de KAP sont
d'eduites des simplifications n'ecessaires `a l'application des transformations. Dans le chapitre 13,
nous montrerons `a quel point ces limitations sont inexistantes dans notre mod`ele.

La premi`ere 'etape est la fusion des boucles i et k : nous avons constat'e que KAP n'essayait de
fusionner que les nids de boucles parfaits avec des bornes de boucles identiques. Apr`es avoir, `a la
main, chang'e les bornes de boucles et extrait le Z[i]=0, KAP fut capable de fusionner les boucles i
et k. Avec le mod`ele poly'edrique, la fusion est seulement limit'ee par des limitations s'emantiques
comme les d'ependances de donn'ees. Les nids de boucles non parfaits ou les bornes non identiques
ne sont pas une limitation, ou plus exactement, ces limitations artificielles n'apparaissent tout
simplement pas, voir Chapitre 13.

Apr`es la fusion des boucles externes, la seconde 'etape est la fusion des boucles internes j et l.
Ces fusions changent l'ordre dans lequel est valeurs de Z[i] sont calcul'ees et nous avons constat'e
que KAP refuse de faire cette modification (apparemment une autre condition sur le pattern
d'applicabilit'e de la fusion). Apr`es renommage de Z dans la seconde boucle et l'accumulation
des valeurs apr`es les deux boucles, KAP a appliqu'e la seconde fusion.

40 4. Limitations inh'erentes aux repr'esentations syntaxiques

Pour r'esumer, nous avons constat'e que KAP 'etait incapable d'appliquer ces deux transformations `a cause de limitations dans les r`egles de pattern-matching, et que ce genre de limitation
n'existaient pas dans la repr'esentation poly'edrique. Nous avons r'ealis'e des exp'eriences suppl'ementaires sur des compilateurs modernes de restructuration de boucles, comme Intel ICC (IA64)
Open64/ORC (IA64) et nous avons trouv'e des limitations similaires, notamment au niveau des
bornes de boucles.

4.3 Probl`eme du comportement "par phase" des compilateurs

Les compilateurs suivent un ensemble ordonn'e de phases, chaque phase effectuant des analyses et des optimisations d'edi'ees. Cette compilation par phase `a un inconv'enient majeur : il
rend impossible l'application d'une transformation plusieurs fois apr`es que d'autres transformations aient rendu la seconde application possible. De plus, cet ordre fig'e limite les strat'egies
d'optimisation possibles, rendant impossibles certaines s'equences d'optimisations.

Consid'erons encore l'exemple de la Figure 4.1. Comme expliqu'e ci-dessus, KAP fut incapable
du fissionner les instructions Z[i]=0 par lui-m^eme, et l'application du tuilage n'ecessite cette
transformation. La documentation de KAP [51] relate que la fusion et la fission sont effectu'ees
dans la m^eme phase, possiblement plusieurs fois. Ainsi, la fission peut rendre la transformation
de fusion l'egale (bien qu'ici KAP ne parvienne pas `a la faire pour les raisons d'ecrites plus haut).

Par contre, la fission n'est pas identifi'ee comme pouvant rendre le tuilage l'egal, et donc le
compilateur n'essaiera pas de fissionner pour pouvoir tuiler. De plus, m^eme apr`es avoir splitter
les initialisations de Z[i], et fusionner les deux paires de boucles, KAP n'est jamais parvenu `a
tuiler la boucle j, pr'ef'erant favoriser la promotion scalaire et l'unroll-and-jam obtenant ainsi une
performance maximum de 12.35s. Notre s'equence de transformations abaissa le temps d'ex'ecution de 26.00s `a 19.00s avec la fusion et la fission, et l'abaissa jusqu'`a 7.38s avec le tiling.

Donc, KAP souffre d'une strat'egie d'optimisation trop rigide, et l'exemple souligne que pour
obtenir de meilleures performances, il est n'ecessaire de pouvoir composer les transformations de
mani`ere beaucoup plus flexible. Dans le Chapitre 15 nous montrerons que pour un nid de boucle,
en composant jusqu'`a 23 transformations de programmes, nous fument capables de battre les
performances peak des SPEC.

4.4 Probl`emes de l'application successive des transformations

La derni`ere limitation inh'erente aux repr'esentations syntaxiques vient du fait que chaque
transformation est effectu'ee sur la repr'esentation syntaxique issue de l'application de la transformation pr'ec'edente. Ainsi les techniques de r'e-'ecriture, ou les transformations simples qui sont
sens'es faciliter l'application d'une transformation peuvent dans un m^eme temps rendre une autre
transformation (ou la m^eme transformation appliqu'e `a un autre endroit du code) ill'egale.

Illustrons cela sur un exemple simple : le source de la Figure 4.5 repr'esente trois petits nids
de boucles. La fusion de ces trois nids de boucles permet de r'eduire la distance de r'eutilisation
du tableau A pour b'en'eficier d'une meilleure localit'e temporelle. Le r'esultat de cette double
fusion correspond `a la Figure 4.6.

Les compilateurs optimisants qui utilisent des techniques avanc'ees de r'e-'ecriture [97], ainsi
que la plupart des repr'esentations non syntaxiques [77] n'ecessitent de peeler une instruction de
la premi`ere et de la derni`ere boucle pour faire co"incider les bornes de boucles et rendre la fusion
applicable. Mais, c'est ce peeling de la derni`ere instruction de la premi`ere boucle qui rend la

4.5. Conclusion 41

B(1) = 0
do i = 1, 1000
pAq A(i) = A(1) + ...

do i = 1, 999
pBq B(i+1) = A(i) + ...

do i = 1, 1000
pCq C(i) = A(i) + B(i) + ...

Fig. 4.5 - Un code `a fusionner

B(1) = 0
do i = 1, 999

A(i) = A(1) + ...
B(i+1) = A(i) + ...
C(i) = B(i) + ...
A(1000) = A(1) + ...
C(1000) = A(1000) + B(1000) + ...

Fig. 4.6 - Fusion des trois boucles

fusion de la derni`ere boucle ill'egale. La Figure 4.7 correspond au code apr`es ce peeling et la
fusion des deux premi`eres boucles.

B(1) = 0
do i = 1, 999
pAq A(i) = A(1) + ...
pBq B(i+1) = A(i) + ...
pP q A(1000) = A(1) + ...

do i = 1, 1000
pCq C(i) = A(i) + B(i) + ...

Fig. 4.7 - L'instruction 'epluch'ee rend la fusion ill'egale
Les compilateurs n'envisageant la fusion que des boucles cons'ecutives, l'instruction peel'ee
P doit ^etre d'eplac'ee soit avant la premi`ere boucle, soit apr`es la derni`ere boucle. Or ces deux
d'eplacements sont d'esormais ill'egaux `a cause des d'ependances : le d'eplacement avant la premi`ere
boucle est impossible `a cause d'une d'ependance entre l'instruction peel'ee P et l'instruction A.
Et, le d'eplacement apr`es la derni`ere boucle est rendu ill'egal `a cause de l'anti-d'ependance entre
l'instruction P et l'instruction C.

Pour l'exemple de la Figure 4.5, KAP et ICC n'ont pas r'eussi `a fusionner les codes (la
contrainte sur les bornes de boucles identiques est trop forte), et ORC n'a r'eussi que la fusion
partielle correspondant `a la Figure 4.7. Notre processus d'optimisation est capable d'obtenir le
code optimal de la Figure 4.6.

4.5 Conclusion

Dans ce chapitre, nous avons successivement montr'e les diff'erentes limitations inh'erentes `a
une repr'esentation syntaxique des programmes. La n'ecessit'e de composer de longues s'equences
de transformations pour optimiser efficacement les programmes, nous impose donc de travailler
`a niveau d'abstraction sup'erieur.

La construction des compilateurs sous forme d'applications successives d'algorithmes de complexit'e tr`es faible n'a jusqu'`a pr'esent pas permis d'y int'egrer des techniques poly'edriques plus
complexes. Dans le chapitre 15 nous montrerons que les techniques poly'edriques ont un impact
raisonnable sur les temps de compilation, et que des techniques plus complexes peuvent donc
^etre int'egr'ees dans les compilateurs.

Le chapitre suivant pr'esente le niveau d'abstraction auquel nous avons d'ecid'e de travailler,
et l'impact de ce choix sur les codes que nous saurons traiter.

42 4. Limitations inh'erentes aux repr'esentations syntaxiques43
Chapitre 5
Abstraction poly'edrique

Apr`es avoir montr'e dans le chapitre pr'ec'edant les limitations inh'erentes `a une repr'esentation
syntaxique des programmes, nous allons maintenant pr'esenter les diff'erents niveaux d'abstraction
auquel nous avons d'ecid'e de travailler. Nous allons introduire la notion de SCoP (Parties de
Programmes `a Contr^ole Statique) correspondant aux parties de programmes que nous sommes
capables d'abstraire et donc d'optimiser.

Les sections 5.1 et 5.2 d'efinissent les notions de bases permettant d'abstraire la programme
`a optimiser. Les sections 5.3 et 5.4 d'efinissent pr'ecis'ement la notion de SCoPs, et pr'esentent
comment s'effectue la d'ecomposition du programme en SCoPs. Enfin, les sections 5.5 et 5.6
pr'esentent des techniques permettant d'am'eliorer la couverture des SCoPs et fournissent une
analyse d'etaill'ee de cette couverture pour un ensemble de benchmarks repr'esentatifs.

5.1 Niveau d'abstraction et d'efinitions

Les deux composantes `a abstraire sont naturellement la brique de base des codes sources,
l'instruction, et 'egalement les nids de boucles qui repr'esentent les sites habituels de l'optimisation de programme. Dans cette section nous pr'esenterons l'abstraction que nous allons utiliser
pour ces deux composantes, en indiquant la limitation que ces abstractions impliquent sur la
repr'esentativit'e du mod`ele de programme.

5.1.1 Instructions

Une instruction pr'esente dans les code source peut ^etre ex'ecut'ee plusieurs fois au cours
du programme (si l'instruction est dans une boucle par exemple). Chacune des ce ex'ecutions
correspond `a une instance de l'instruction. La Figure 5.1 pr'esente `a gauche une instruction S
situ'ee dans une boucle i, et `a droite plusieurs instances de cette instruction rencontr'ees lorsque
la boucle est ex'ecut'ee.

for (i=2; i<=100; i++)
(S) A[i] = A[i-1] + A[i-2];

...
A[7] = A[6] + A[5];
...
A[22] = A[21] + A[20];
A[23] = A[22] + A[21];
...
A[100] = A[9] + A[98];

Fig. 5.1 - Instruction, et instances d'instruction

44 5. Abstraction poly'edrique

Cette abstraction n'est pas capable de repr'esenter les constructions du C rassemblant plusieurs instructions en une seule, comme ceux `a gauche de la Figure 5.2. Fort heureusement,
dans leur phase de construction de l'arbre de syntaxe abstrait, les compilateurs r'e'ecrivent ces
constructs sous la forme pr'esent'ee `a droite. Ces constructions complexes ne sont donc pas une
limitation sur la repr'esentativit'e de l'abstraction.

A[i++]=B[++j];

j=j+1;
A[i]=B[j];
i=i+1;

Fig. 5.2 - Exemple de construct multi-instructions

5.1.2 Nids de boucles

La clef de l'optimisation des programmes est l'optimisation des nids de boucles associ'ees
aux calculs les plus longs du programme. Les nids de boucles correspondent `a un ensemble de
structures it'eratives englobant un ou plusieurs ensembles d'instructions. La forme g'en'erale d'une
boucle est pr'esent'ee dans la Figure 5.3.

for (i1=L1; i<=U1; i+=S1)

...
for (i2=L2; i<=U2; i+=S2)

...
for (i3=Ln; i<=Un; i+=Sn)

corps de boucle
...
...

Fig. 5.3 - Nid de boucle
Chaque boucle poss`ede un it'erateur ik qui varie de la borne inf'erieure Lk `a la borne sup'erieure
Uk par pas constant de Sk. La profondeur d'une instruction correspond au nombre de boucles
englobant cette instruction. Au niveau le plus interne, le corps de boucle ne contient plus que
des instructions. Une boucle est qualifi'ee de parfaite si seul le corps de boucle contient des
instructions.

Cette abstraction n'est donc pas capable de repr'esenter sous forme de nids de boucles les
"boucles" C de la Figure 5.4, c'est `a dire les compteurs de boucles flottants, les boucles `a pas
non constant, et les boucles modifiant la valeur de leur it'erateur dans le corps de boucle.

while(f>epsilon)

loga = loga + 1;
f = f / 2;

k = 1;
for(int i=0; i<N; i+=k)

A[i]=0;
k++;

bool first = true;
for(int i=0; i<N; i++)

A[i]=0;
if(first)

i=10;
first=false;

Fig. 5.4 - Exemples de codes non repr'esentable sous forme de nids de boucles
De nombreux travaux [1, 7, 8, 104, 64, 33, 6] ont 'etudi'e l'optimisation des nids de boucles
parfaits. Les m'ethodes poly'edriques sont parfaitement adapt'ees pour am'eliorer le parall'elisme
et la localit'e de ce type de boucles. Les s'equences de transformations unimodulaires sont alors
mod'elis'ees simplement sous forme de produits matriciels transformant l'espace d'it'eration.

Toutefois, dans les applications r'eelles (et m^eme dans la majorit'e des noyaux de calculs
intensifs) la plupart nids de boucles ne sont pas parfaits. L'un des noyaux de calculs le plus

5.2. Programmes `a Contr^ole Statique 45
souvent pr'esent dans la litt'erature, pr'esent'e dans la Figure 5.5, le produit matriciel est un bon
exemple de nid de boucle non-parfait.

Ci,j "

My"

k"1

Ai,k ^ Bk,j

for i=1 to n

for j=1 to k

C[i,j] = 0
for l=1 to m

C[i,j] = C[i,j]+A[i,l]]*B[l,j]

Fig. 5.5 - Nid de boucle non-parfait : La multiplication matricielle C " A ^ B
Des techniques ont alors 'et'e propos'ees pour rendre les nids de boucles parfaits, g'en'eralement
par des techniques de distribution de boucles, mais ces transformations des nids de boucles ne
sont pas toujours l'egales du point de vue des d'ependances de donn'ees.

Pingali et al. [59] ont propos'e une approche pour d''etendre les techniques r'eserv'ees aux nids
de boucles parfaits aux nids de boucles non-parfaits, permettant ainsi de transformer directement
ce type de boucles. D'un autre cot'e, Feautrier [41], puis Kelly et Pugh [52, 53] dans l'outil Omega
ont propos'e des techniques puissantes de r'e-ordonnancement des instructions de nids de boucles
complexes.

Le formalisme que nous d'ecrirons dans la chapitre 9 est capable de repr'esenter les nids de
boucles non-parfaits, et pr'esentant une certaine irr'egularit'e (dont les instructions du corps de
boucle sont gard'ees par des conditionnelles).

5.2 Programmes `a Contr^ole Statique

La classe de programme `a contr^ole statique, d'efinie par Feautrier dans [39] dans le contexte
de l'analyse de d'ependance, permet de repr'esenter la majorit'e des noyaux de calcul intensif.
Cette classe de programme correspond aux programmes dont les structures de contr^oles sont :

1. des boucles do-loop dont les bornes s'expriment sous la forme de fonctions affines des

it'erateurs englobants et des param`etres constants du programme (comme la taille des
structures)

2. des conditionnelles if dont les conditions s'expriment elles aussi sous la forme de fonctions

affines des it'erateurs englobants et des param`etres constants.

3. les appels de routines sont tous inlin'es.
Les seules structures de donn'ees autoris'ees sont le scalaire et le tableau, et pour ces derniers les
acc`es aux tableaux doivent 'egalement ^etre affines.

Ces restrictions ont permis `a l'auteur de d'efinir le pr'edicat de s'equencement pour distinguer
une instance particuli`ere d'une instruction, et ainsi de consid'erer les relations de d'ependances
entre instances plut^ot qu'entre instructions. Consid'erons l'exemple de la Figure 5.6 qui calcule
le produit de deux polyn^omes, et plus pr'ecis'ement les d'ependances li'ees au tableau C.

for(k=0;k<=2*N)
(S1) C[k] = 0;

for(i=0;i<=N;i++)

for(j=0;j<=N;j++)
(S2) C[i+j] += A[i]*B[j];

Fig. 5.6 - Produit de deux polyn^omes A et B
Au niveau des instructions, il y a deux d'ependances `a consid'erer : la d'ependance de flot
entre l'instruction S1 et l'instruction S2, et la d'ependance de l'instruction S2 vers elle m^eme

46 5. Abstraction poly'edrique
due `a l'op'erateur d'accumulation +=. Au niveau des instances d'instructions, il est possible
d'obtenir des informations beaucoup plus d'etaill'ees, comme l'instance de l'instruction 'ecriture
source correspondant `a chaque lecture du tableau C. Par exemple, pour retrouver la source
correspondant `a la lecture C[i,j] ne peut ^etre un instance de S1 que si i ` j " 0, et une lecture
de C[i,j] pour une instance de l'instruction S2pi, jq ne peut avoir comme source l'instance
S2pi1, j1q de la m^eme instruction S2 que si i ` j " i1 ` j1.

Cette approche `a plusieurs b'en'efices. Elle permet une conversion facile des programmes
`a contr^ole statique en code `a assignation unique (ne poss'edant plus que des d'ependances du
type lecture apr`es 'ecriture) facilitant grandement l'ordonnancement du programme. Elle permet
'egalement d'avoir une analyse pr'ecise des d'ependances, utile pour trouver des opportunit'es

d'optimisations des acc`es aux tableaux, comme ceux qui seront propos'es dans le Chapitre 11.

5.3 Parties `a Contr^ole Statique (SCoP)

Dans le cadre de l'optimisation de programme dans le contexte d'applications scientifiques
r'eelles, les hypoth`eses faites par la classe des programmes `a contr^ole statique sont toutefois
beaucoup trop strictes : si les noyaux de calcul font la plupart du temps partie de cette classe de
programme, les applications enti`eres contenant ces noyaux de calculs poss`edent dans la grande
majorit'e des cas des parties de programmes `a contr^ole non statique. Par exemple, aucun des
SPECS FP2000 [95] ne fait partie de cette classe.

Nous avons donc d'efini la notion de Parties `a Contr^ole Statique pour pouvoir repr'esenter
un programme comme un ensemble de parties `a contr^ole non statique, et de parties `a contr^ole
statique. Notre formalisme ne prendra en charge que les SCoPs (permettant de les transformer
pour les optimiser) et laissera les parties `a contr^ole non statique inchang'ees.

D'efinition : Au sein d'une fonction, une partie `a contr^ole statique (SCoP) est le nombre maximal d'instructions sans boucles while, o`u les bornes de boucles et les conditionnelles englobantes
sont des fonctions affines compos'ees de constantes symboliques et des it'erateurs englobant. Les
constantes symboliques sont appel'ees les param`etres globaux du SCoP, ainsi que tout invariant
apparaissant dans un des index de tableau du SCoP. Les SCoPs poss'edant au moins une do-loop
sont qualifi'es de riches.

Les SCoPs riches correspondent aux nids de boucles pr'esent'es dans la section 5.1. Ils sont
les candidats id'eaux pour l'optimisation de programme. La Figure 5.7 pr'esente un exemple de
d'ecomposition d'une fonction d'un programme en trois SCoPs, dont deux riches.

Restriction sur les tableaux : Notez que la limitation sur les indices de tableaux introduite
dans la section 5.2 ne concerne plus les SCoPs. Dans le contexte des programmes `a contr^ole
statique, cette restriction 'etait indispensable pour pourvoir calculer de mani`ere exacte l'ensemble
des d'ependances.

Pour l'application de transformations de programme et l'optimisation de programme en g'en'eral, la probl'ematique n'est pas la m^eme : certes, une analyse de d'ependance pr'ecise est utile
pour d'eterminer l'applicabilit'e de la transformation, mais l'analyse statique appliqu'ee conservativement aux acc`es de tableaux non affines peut faire appara^itre des d'ependances de donn'ees en
fait inexistantes. Or, nous voulons absolument garder la possibilit'e pour notre environnement
semi-automatique de transformations de programme, de laisser l'utilisateur expert ignorer ces
d'ependances virtuelles et d'appliquer ses transformations.

5.4. D'ecomposition en Parties `a Contr^ole Statique 47

SCoP d'ecomposition
do i=1, N
......................................................................

S1 SCoP 1, une instruction, non riche
......................................................................

do j=1, i*i
......................................................................

S2 SCoP 2, trois instructions, riche
do k=0, j param`etres globaux: N,i,j

if (j .ge. 2) then it'erateurs: k

S3
S4
......................................................................

do p = 0, 6 SCoP 3, deux instructions, riche

S5 param`etres globaux: N
S6 it'erateurs: p

Fig. 5.7 - Exemple de d'ecomposition en Parties `a Contr^ole Statique
Plus simplement, nous voulons ^etre capable d'appliquer les transformations m^eme si les
informations sur les d'ependances de donn'ees sont incertaines, et plut^ot v'erifier `a posteriori que
les transformations n'ont viol'e aucune d'ependance. Les SCoPs permettent ainsi de repr'esenter
plus de nids de calculs que la classe des programmes `a contr^ole statique [39].

La repr'esentation des instructions dans les SCoPs est d'ecrite en d'etail dans la partie III qui
pr'esente notre formalisme.

5.4 D'ecomposition en Parties `a Contr^ole Statique

La d'ecomposition d'un programme en SCoPs est grandement facilit'ee par le travail du compilateur Open64 [79] et de ses d'eriv'es ORC [80] et EkoPath [21] : au d'ebut du processus de
compilation, le compilateur commence par une phase de simplification et de normalisation des
structures de contr^ole. A la fin de cette phase, les boucles sont normalis'ees et divis'ees en deux
cat'egories distinctes :

- les boucles allant de 0 jusqu'`a une expression avec un pas entier constant. Ces boucles sont

appel'ees do-loop.
- les autres formes de boucles, r'ef'er'ees en tant que boucles while.
Certaines boucles while pr'esentent dans les sources C ou Fortran sont ainsi normalis'ees en doloop quand les bornes enti`eres et le pas peuvent ^etre d'ecouvert statiquement. Open64 prend
'egalement en charge la substitution des formes closes li'ees aux variables d'induction.

L'algorithme d'extraction des SCoPs est pr'esent'e en d'etail dans le Chapitre 18, apr`es la d'efinition notre formalisme. En sortie, cet algorithme renvoie pour chaque fonction du programme
une liste des SCoPs associ'es.

5.5 Am'elioration de la couverture des SCoPs

La couverture des SCoPs pour un programme est une notion tr`es importante, puisque les
SCoPs repr'esentent les parties du programme que nous pouvons optimis'ees. La section 5.6
pr'esentera une analyse d'etaill'ee de la couverture des SCoPs pour diff'erents benchmarks. Cette
section pr'esente comment, gr^ace `a des technique de r'e-'ecriture, il est possible d'am'eliorer la
couverture des SCoPs en transformant des parties de programme `a contr^ole non statique en
SCoPs.

48 5. Abstraction poly'edrique

Les conditionnelles et les bornes de boucles s'expriment parfois avec des appels de fonctions
qui excluent ces boucles et ces conditionnelles des SCoPs. Des techniques r'e-'ecriture permettent
souvent d''eliminer ces appels de fonctions en les rempla,cant par des versions statiques. Ces
r'e-'ecritures "syntaxiques" s'effectuent sur l'arbre de syntaxe correspondant au code source, en
rempla,cant une branche de l'arbre par une branche 'equivalente ne cassant pas la staticit'e du code.
Ces r'e-'ecritures sont effectu'ees avant d'appliquer l'algorithme de reconnaissance des SCoPs. De
nombreuses fonctions intrins`eques du Fortran peuvent ainsi ^etre librement remplac'ees, comme
les fonctions minimum, maximum, division enti`ere et modulo.

Minimum : La pr'esence de minimums dans les bornes sup'erieures de boucles est fr'equente, et
ces minimums peuvent ais'ement ^etre r'e'ecrits comme conjonctions d'in'equations, rendant ainsi
le code statique. Cette r'e-'ecriture est illustr'ee par la Figure 5.8.

for(k=0; k<min(A,B) ; k++)

S1
S2

for(k=0; (k<A) && (k<B) ; k++)

S1
S2

Fig. 5.8 - R'e-'ecriture de minimums dans les bornes sup'erieures

Maximum : Sym'etriquement, certains maximums peuvent eux aussi ^etre replac'e par une
conjonction d'in'equations. La Figure 5.9 illustre cela, malgr'e le fait qu'une description syntaxique
ne soit pas adapt'ee.

for(k=max(A,B) ; k<C ; k++)

S1
S2

for(k>=A && k>=B ; k<C ; k++)

S1
S2

Fig. 5.9 - R'e-'ecriture de maximums dans les bornes inf'erieures
Si la repr'esentation syntaxique de droite semble 'etrange, dans le mod`ele poly'edrique, les deux
bornes peuvent facilement ^etre repr'esent'ees par des conjonctions d'in'equations sur l'it'erateur.

Modulos : Il est 'egalement fr'equent d'avoir des modulos au sein des corps de boucles pour
n'entreprendre certaines actions qu'`a certaines it'erations. Ces modulos peuvent ^etre exprim'es
par projection affine en ajoutant une nouvelle variable locale, libre de toute contrainte. Ainsi,
la conditionnelle pk%4 "" 0q peut facilement ^etre repr'esent'e par tDp|k " 4pu au prix de l'ajout
d'un nouvelle variable locale p libre de toute contrainte.

Il est ainsi possible de consid'erer comme affines certaines expressions contenant des modulos
et des divisions enti`eres en ajoutant des variables locales. Ces techniques ne sont pas encore
implement'ees dans l'algorithme d'extraction des SCoPs d'efini dans le chapitre 15, mais am'elioreraient la couverture en SCoP de nombreux programmes, comme tout ceux qui affichent des
r'esultats interm'ediaires toutes les N it'erations `a l'aide de modulos.

5.6 Analyse de la couverture des SCoPs

Gr^ace `a l'impl'ementation de l'algorithme du Chapitre 18 dans Open64, nous avons 'etudi'e
l'applicabilit'e de notre environnement poly'edrique `a plusieurs benchmarks. Cette 'etude a 'et'e
r'ealis'ee de mani`ere la plus conservative possible, sans inlining et sans les am'eliorations d'ecrites

5.6. Analyse de la couverture des SCoPs 49
dans la section 5.5, pour conna^itre la staticit'e inh'erente des codes sources. Les seuls traitements sur le code source r'ealis'es sont donc ceux pr'esents dans la phase de Pr'e-optimisation du
compilateur Open64 (voir Chapitre 3), c'est-`a-dire principalement la propagation de constante,
l''elimination de code mort, la suppression de goto, et la normalisation des boucles.

Les am'eliorations de la Section 5.5 et surtout l'inlining permettent d'obtenir des SCoPs bien
plus gros et une bien meilleure couverture.

5.6.1 R'epartition des SCoPs

La Figure 5.10 r'esume les r'esultats que nous avons obtenus pour les SpecFP 2000. La colonne
langage indique le langage source du benchmark. La seconde colonne, Fonctions, indique le
nombre de fonctions pr'esentent dans le benchmark (sans inlining). Les colonnes de la section
SCoPs indiquent respectivement le nombre total de SCoPs, le nombres de SCoPs riches (ceux
contenant au moins un nid de boucles) parmi ces SCoPs, et le nombres de SCoPs ayant des
param`etres globaux. La section Param`etres d'etaille le nombre minimum, maximum et moyen
de param`etres pour l'ensemble des SCoPs.

SCoPs Param`etres
Langage Fonctions Tous Riches Param. Min. Max. Moy.

168.wupwise Fortran77 22 161 20 73 0 11 2.5
171.swim Fortran77 6 13 5 10 0 5 2
172.mgrid Fortran77 12 22 10 15 0 6 1.55
173.applu Fortran77 16 91 18 68 0 7 2.57
177.mesa C 44 456 4 71 0 6 0.32
179.art C 26 219 14 96 0 11 1.18
183.equake C 27 177 21 57 0 5 0.58
187.facerec Fortran90 21 92 23 49 0 8 1.88
188.ammp C 63 646 34 275 0 7 0.96
191.fma3d Fortran90 84 289 2 56 0 5 0.36
200.sixtrack Fortran77 136 4980 371 2040 0 17 1.79
301.apsi Fortran77 97 396 88 218 0 18 1.44

Fig. 5.10 - Couverture des parties `a contr^ole statique pour les SpecFP 2000

En accord avec des r'esultats pr'ec'edant utilisant Polaris [35], la couverture en nids de boucles
r'eguliers est grandement d'ependante de la qualit'e des m'ecanismes de propagation de constantes,
de normalisation des boucles et de la d'etection des variables d'induction.

La comparaison de la quatri`eme et de la cinqui`eme colonne indique un pourcentage de SCoPs
riches assez faible parmi les SCoPs, repr'esent'e 'egalement par la Figure 5.11. Il conviendra donc
de s'assurer que les nids de boucles captur'es par les SCoPs sont bien les nids de boucles les plus
volumineux dans lesquels le programme passe le plus de temps. Les quatre derni`eres colonnes
argumentent le besoin de techniques param'etriques pour avoir une couverture du code correcte.

5.6.2 R'epartition des instructions

Pour nous assurer que les nids de boucles les plus importants sont bien captur'es par les
SCoPs, consid'erons la Figure 5.12, qui donne la r'epartition des instructions dans le programme.
La section Instructions de la figure donne respectivement le nombre total d'instructions dans
le programme, le nombre total d'instructions statiques (dans des SCoPs) et le nombre total

50 5. Abstraction poly'edrique

10
20
30
40
50
60
70
80
90

SCoPs
riches
(%)

wupwise swim mgrid applu mesa art equake facerec ammp fma3d sixtrack apsi

Fig. 5.11 - Pourcentage de SCoPs riches

d'instruction dans des SCoPs riches. Les trois colonnes de la section Instructions par SCoP
riche fournissent le nombre minimal, maximal et moyen d'instructions par SCoP riche.

Instructions Instructions par SCoP riche
Toutes Statiques Riches Minimum Maximum Moyenne

168.wupwise 641 641 312 2 80 15.6
171.swim 201 199 138 9 51 27.6
172.mgrid 470 470 430 8 195 43.0
173.applu 1005 993 565 3 114 31.4
177.mesa 1306 1013 56 6 22 14.0
179.art 613 606 104 2 14 7.4
183.equake 756 750 230 1 42 11.0
187.facerec 1354 1296 972 3 265 42.3
188.ammp 2409 2339 503 2 53 14.8
191.fma3d 752 662 11 5 6 5.5
200.sixtrack 26542 23722 8225 2 264 22.2
301.apsi 3473 3383 1828 2 71 20.8

Fig. 5.12 - R'epartition des instructions

La troisi`eme colonne indique qu'en moyenne plus de 95% des instructions sont statiques. La
non-staticit'e est en fait essentiellement due `a des conditionnelles isol'ees, comme celles pr'esentes
dans l'initialisation des programmes `a la lecture des fichiers d'entr'ees, ou encore `a des tests de
valeurs de pointeurs du type "si le pointeur est non nul". La quatri`eme colonne indique qu'une
grande parties des instructions est effectivement situ'ee dans les SCoPs riches, sauf pour les
benchmarks mesa et fma3d. La Figure 5.13 donne une meilleure vision de la couverture des
SCoPs. Ces r'esultats sont bien meilleurs que ceux de la Figure 5.11, et sont en corr'elation avec
le fait que pour les benchmarks de calcul intensif, l'essentiel des instructions sont pr'esentes
dans des boucles. Enfin les trois derni`eres colonnes indiquent que la taille des SCoPs riches est
suffisamment cons'equente pour envisager des optimisations de boucles efficaces.

La Figure 5.14 donne plus de pr'ecisions sur la r'epartitions des SCoPs suivant leur tailles,
indiquant que la plupart des SCoPs avant inlining des fonctions font moins de 100 instructions, avec quelques exceptions. Cela signifie que la plupart des analyses et des transformations
poly'edriques seront possibles, et qu'elles demanderont des ressources et un temps raisonnable.

La Figure 5.15 indique que la profondeur des boucles dans les SCoPs (sans prendre en compte

5.6. Analyse de la couverture des SCoPs 51

10
20
30
40
50
60
70
80
90

Instructions
riches
(%)

wupwise swim mgrid applu mesa art equake facerec ammp fma3d sixtrack apsi

Fig. 5.13 - Pourcentage d'instructions riches

10
20
30
40
50
60
70
80
90
100
110

Nomb
re
des

SCoPs

0-2 3-4 5-8 9-16 17-32 33-64 65-128 129-256 257+

168.wupwise
171.swim
172.mgrid
173.applu
177.mesa
179.art

183.equake
187.facerec
188.ammp

191.fma3d
200.sixtrack
301.apsi

Taille des SCoPs (instructions)
Fig. 5.14 - R'epartition des SCoPs par taille

les 'eventuelles boucles englobantes sans contr^ole statique) est rarement sup'erieure `a 4. De plus,
les boucles tr`es profondes tendent `a contenir tr`es peu d'instructions. Cela donne une estimation
de la bonne scalabilit'e du proc'ed'e et de ces algorithmes exponentiels, comme ceux pr'esents dans
le g'en'erateur de code qui converti le formalisme vers la forme interm'ediaire du compilateur.

5.6.3 R'epartitions des acc`es

Nous avons pris soin, lors de la d'efinition les SCoPs dans la Section 5.3, `a ce que l'affinit'e des
fonctions d'acc`es aux tableaux n'ait pas d'impact sur la d'ecoupage du programme en SCoPs.
Nous avons aussi soulign'e que des fonctions d'acc`es affines 'etaient n'ecessaires pour avoir une
description d'etaill'ee des informations de d'ependances de donn'ees. Il est donc int'eressant de
conna^itre la r'epartition des acc`es affines dans le programme.

Les acc`es aux tableaux pour les diff'erents benchmarks sont repr'esent'es dans la Figure 5.16.
La premi`ere colonne indique le nombre total d'acc`es pour chaque benchmark, la seconde colonne
le nombre d'acc`es affines. La Figure 5.17 repr'esente plus clairement la part des acc`es affines.

Dans la Figure 5.17, on distingue imm'ediatement deux cat'egories de benchmarks : pour
sept benchmarks, la quasi-int'egralit'e de leurs acc`es peuvent ^etre repr'esent'es par des fonctions
affines. Nous serons donc capables pour ces benchmarks d'avoir une analyse des d'ependances de

52 5. Abstraction poly'edrique

1
10
100
1000

Nomb
re
des

SCoPs

1 2 3 4 5 6

168.wupwise
171.swim
172.mgrid
173.applu
177.mesa
179.art

183.equake
187.facerec
188.ammp

191.fma3d
200.sixtrack
301.apsi

Profondeur des SCoPs
Fig. 5.15 - R'epartition des SCoPs riches par profondeur

Acc`es Acc`es
Tous Affines Tous Affine

168.wupwise 111 100 183.equake 489 109
171.swim 195 195 187.facerec 609 597
172.mgrid 182 180 188.ammp 1601 68
173.applu 1434 1434 191.fma3d 123 123
177.mesa 620 11 200.sixtrack 20686 20564
179.art 192 26 301.apsi 1620 1409

Fig. 5.16 - R'epartition des acc`es

donn'ees tr`es d'etaill'ee, ce qui facilitera grandement la recherche d'opportunit'e pour l'application
de transformations.

10
20
30
40
50
60
70
80
90
100

Acc
`es
affines

(%)

wupwise swim mgrid applu mesa art equake facerec ammp fma3d sixtrack apsi

Fig. 5.17 - Pourcentage d'acc`es aux tableaux affines

Pour quatre benchmarks : mesa, art, equake, et ammp, une forte majorit'e des acc`es sont
non-affines. Utiliser des techniques statiques d'analyses de d'ependances serait un frein pour la
recherche d'opportunit'e de transformations pour ces benchmarks. La sous-section 5.6.5 donnera
davantage de d'etails sur ces quatre benchmarks.

5.6. Analyse de la couverture des SCoPs 53
5.6.4 R'epartitions des performances

Nous nous sommes finalement int'eress'e `a la r'epartition des SCoPs par rapport aux performances, en comparant le d'ecoupage du programme en SCoPs par rapport aux informations
de profiling obtenues sur la totalit'e du programme. Les mesures de profiling ont 'et'e r'ealis'ees
par des techniques de sampling en utilisant l'outil oprofile, qui a pond'er'e chaque ligne du code
source par son importance dans le temps d'ex'ecution du programme. Nous avons ensuite, dans
les Figures 5.18 et 5.19, regroup'e au sein des fonctions les parties du codes repr'esentant plus de
2.5% du temps total d'ex'ecution.

Les colonnes Fichier, Fonction et Lignes indiquent la localisation dans le source de la partie
de code consid'er'ee. La colonne %Temps indique le pourcentage du temps d'ex'ecution de la partie
de code par rapport au temps d'ex'ecution total.

La derni`ere colonne, #SCoP indique le nombre de SCoPs n'ecessaires pour repr'esenter cette
partie de code. Lorsqu'un seul SCoP est n'ecessaire, cela signifie qu'un unique SCoP capture la
boucle dont d'epend les performances et que nous pourrons r'ealiser librement tout un ensemble
de transformations. Lorsque plusieurs SCoPs sont n'ecessaires, cela signifie la pr'esence de parties
non statiques dans la boucle responsable de la performance, qui vont nous emp^echer de r'ealiser
certaines transformations (comme le r'eordonnancement entre les instructions situ'ees de part et
d'autre de la partie non statique). Enfin, lorsque la zone responsable des performances est hors
de tout SCoP, cela est not'e ,, et cela signifie que nous pourront r'ealiser aucune optimisation.

Fichier Fonction Lignes %Temps #SCoPs
168.wupwise zaxpy.f zaxpy 11-32 20.6% 2

zcopy.f zcopy 11-24 8.3% 1
zgemm.f zgemm 158-206 3.7% 12
zgemm.f zgemm 236-271 47.5% 7
171.swim swim.f main 116-119 5.6% 1

swim.f calc1 263-269 26.3% 1
swim.f calc2 317-325 36.8% 1
swim.f calc3 399-405 29.2% 1
172.mgrid mgrid.f psinv 152 27.1% 1

mgrid.f resid 192 62.1% 1
mgrid.f rprj3 236 4.3% 1
mgrid.f interp 277-309 3.4% 1
173.applu applu.f blts 563-620 15.5% 1

applu.f buts 663-721 21.8% 1
applu.f jacld 1685-2009 17.3% 1
applu.f jacu 2106-2320 12.6% 1
applu.f rhs 2614-3040 20.2% 1
177.mesa depth.c gl depth test span less 422-440 3.0 3

os mesa.c write color span 730-747 4.9 3
texture.c sample 1d linear 511-570 37.9 6
texture.c apply texture 1978-2082 2.6 2
triangle.c general textured triangle 196-857 34 ,
179.art scanner.c train match 394-502 14.8% 20

scanner.c match 533-616 82.6% 15

Fig. 5.18 - R'epartition des performances (wupwise N~ art)

La plupart des parties de codes sont repr'esentables par un faible nombre de SCoPs. Pour les
programmes Fortran swim, mgrid, applu, et sixtrack le nombre de SCoPs par partie est souvent
1, ce qui indique une tr`es bonne couverture des performances. Les programmes wupwise, mesa,
et apsi poss`edent une couverture un peu moins bonne.

L'isolation des performances est bien moins bonne pour les programmes C art, equake, et
ammp qui utilisent tous l'arithm'etique de pointeurs. Particuli`erement, les d'er'ef'erencements multiples (tableaux dynamiques dans des structs C) et les nombreux typecast pr'esents dans la fonction mm_fv_update du benchmark ammp rendent l'extraction des SCoPs impossible. Comme

54 5. Abstraction poly'edrique
d'ecrit dans les sections pr'ec'edentes, la pr'esence massive de pointeurs dans le programme fma3d
rend le d'ecoupage en SCoP impossible, notamment tous les tests de pointeurs ajout'es par le
compilateur, comme d'ecrit dans la Section 5.6.5.

Fichier Fonction Lignes %Temps #SCoPs
183.equake quake.c main 437-477 99% 4
187.facerec cfftb.f90 passb4 275-310 35.6% 1

fft2d.f90 fft2db 168-178 14.9% 1
gaborRoutines.f90 GaborTrafo 108-129 19.2% 2
graphRoutines.f90 LocalMove 392-412 18.7% 2
graphRoutines.f90 TopCostFct 479-616 8.23% 1
188.ammp atoms.c a m serial 169-177 7.4% 3

rectmm.c mm fv update 560-1120 71.9% ,
vnonbon.c f nonbon 478-507 6.0% 2
191.fma3d fma2.f90 solve 319-577 10.2% ,

fma2.f90 time initialization 3242-3245 4.5% ,
material 11.f90 material 41 1131-1175 14.5% ,
platq.f90 platq internal forces 193-321 8.8% ,
platq.f90 platq mass 402-709 14.9% ,
platq.f90 khplq divergence operator 777-988 6.5% ,
platq.f90 khplq stress divergence 1045-1119 3.9% ,
platq.f90 platq stress integration 1851-2006 11.6% ,
200.sixtrack thin6d.f thin6d 180-186 15.2% 1

thin6d.f thin6d 217-227 3.7% 1
thin6d.f thin6d 230-244 8.9% 3
thin6d.f thin6d 267-285 8.2% 2
thin6d.f thin6d 466-477 6.3% 1
thin6d.f thin6d 561-588 54.8% 1
301.apsi apsi.f dcdtz 1331-1352 4.3% 1

apsi.f dtdtz 1478-1499 4.3% 1
apsi.f dudtz 1663-1686 4.5% 1
apsi.f dvdtz 1803-1831 4.5% 1
apsi.f wcont 1878-1889 7.5% 1
apsi.f trid 3190-3205 5.9% 1
apsi.f smth 3444 3.7% 1
apsi.f radb4 5288-5319 6.6% 2
apsi.f radbg 5456-5584 9.0% 3
apsi.f radf4 5912-5935 3.2% 2
apsi.f radfg 6193-6286 5.1% 2
apsi.f dkzmh 6413-6508 11.4% 8

Fig. 5.19 - R'epartition des performances (equake N~ apsi)

5.6.5 'Etude des benchmarks r'efractaires

Nous allons maintenant revenir sur les benchmarks qui semblent les moins adapt'es `a notre
mod`ele de programmation pour tenter de les caract'eriser. Du point de vue de la r'epartition
des SCoPs et de la r'epartition des instructions, deux benchmarks ne semblent pas du tout
adapt'es : mesa et fma3d qui ont une couverture en instructions riches inf'erieure `a 6%. Trois
benchmarks semblent peu adapt'es : art, equake, et ammp qui poss`edent une couverture inf'erieure
`a 30%. Du point de vue de la r'epartition des acc`es affines, deux benchmarks ne semblent
pas du tout adapt'es : mesa et ammp. Deux autres benchmarks semblent peu adapt'es : art et
equake.

mesa Le benchmark mesa est de loin le benchmarks le moins adapt'es `a notre mod`ele de
programmation, avec moins de 1% de SCoPs riches repr'esentant `a peine 5% des instructions. Il
s'agit en fait d'une bibliot`eque graphique 3D libre 'ecrite en C fonctionnant comme OpenGL. Elle
va donc effectuer le rendu g'eom'etrique d'une figure g'eom'etrique plus ou moins compliqu'ee dont

5.6. Analyse de la couverture des SCoPs 55
les coordonn'ees sont fournies dans le fichier d'entr'ee, pour en sortie fournir une image graphique
au format PNG.

Cette application d'efinit une s'erie de structures servant `a ranger des formes g'eom'etriques
complexes, structures qui sont allou'ees dynamiquement. Cette application fait donc un usage
intensif de pointeurs vers ces structures, mais 'egalement de pointeurs sur les fonctions. Les tableaux servent essentiellement `a cr'eer des collections de ces structures, plus rarement `a stocker
les coordonn'ees ou les composantes des couleurs. Cela explique le faible taux de tableaux `a acc`es
statique de la Figure 5.17 (moins de 2%). Le tr`es faible taux d'instructions `a contr^ole statique
dans les SCoPs riches s'explique par le fait que l'utilisation des structures C sont syst'ematiquement gard'ees par des tests de valeurs sur les pointeurs qui rendent le contenu de la condition
non-statique.

Le principal probl`eme vient donc du fait que mesa n'est pas principalement une application
de calcul intensif mais une API compl`ete capable de g'en'erer des formes g'eom'etriques complexes
pour en effectuer le rendu.

art. Pour art, seulement 15% des instructions sont dans des SCoPs riches, et moins de 15% des
acc`es sont affines. Il s'agit en fait d'un proc'ed'e de reconnaissance de formes et d'objets (comme
les h'elicopt`eres ou les avions) dans les images thermiques infrarouges. L'algorithme de recherche
est bas'e sur des r'eseaux neuronaux d'abord entra^in'es `a reconna^itre ces objets, puis utilis'es sur
d'autres images. Le benchmark prend en entr'ee une s'erie d'image d'entra^inement, et une s'erie
d'images `a scanner. En sortie, est associ'e `a chaque image `a scanner un facteur de confiance sur
la pr'esence des diff'erents objets, et l'image avec le plus fort facteur de confiance est renvoy'ee.

Cette application repr'esente un neurone par une structure C contenant 8 doubles, et manipule
pendant les deux phases de l'algorithme de nombreux pointeurs sur des listes de cette structure.
Plusieurs tableaux mono-dimensionnels de petite taille (g'en'eralement 2) sont 'egalement allou'es
dynamiquement, bien que leur taille soit connue statiquement. Cela explique le nombre relativement faible de tableaux indiqu'e dans la Figure 5.16. L'essentiel des conditionnelles s'effectue par
comparaison sur les valeurs du tableau Y dynamique (allou'e avec un pointeur). Sa taille reste
fixe au cours du programme, mais elle n'est connue qu'apr`es lecture du fichier d'entr'ee. C'est `a
cause de ces conditionnelles que la staticit'e du code est faible (15% des instructions sont dans
des SCoPs riches).

equake. Avec 30% d'instructions riches et 23% d'acc`es affines, equake semble ne pas ^etre
compl`etement adapt'e au mod`ele de programmation. Le benchmark equake simule la propagation
d'ondes sismiques ('elastiques) dans des vall'ees au relief h'et'erog`ene. En entr'ee, l'application prend
des informations topologiques (relief, densit'e des mat'eriaux) sur le terrain, et les caract'eristiques
de l''el'ement sismique `a simuler. En sortie, elle fournit des listes de mouvements constat'es `a
diff'erents points du terrain.

Les terrain est d'ecoup'e en t'etra`edres pour fournir des informations relatives `a sa topologie, et les r'esultats sont des d'eplacements dans un espace `a trois dimensions. Cette application
souffre des m^emes probl`emes que le benchmark art. Sa programmation est d'ailleurs tr`es similaire : structures de donn'ees point'ees (cette fois d'er'ef'erenc'ees plusieurs fois) repr'esent'ees par
des structures C qui expliquent une nouvelle fois la faible proportions d'acc`es affines (23%). La
faible staticit'e du code est cette fois expliqu'ee car la majorit'e des conditionnelles sont des tests
de distances (g'en'eralement `a l''epicentre). Ces conditionnelles sont donc des comparaisons de
valeurs flottantes, et donc non statiques. Elles expliquent la faible proportion de SCoPs riches
(30%).

56 5. Abstraction poly'edrique

Un autre probl`eme relatif `a equake est que plusieurs tableaux statiques sont situ'es dans des
structures (par exemple les coordonn'ees des points importants comme l''epicentre du s'eisme).
L'acc`es `a ces tableaux dans la WHIRL est 'ecrit comme un d'er'ef'erencement `a partir de l'adresse
de la struct, et non pas comme un acc`es `a un tableau (sans calcul d'adresse). Nous le consid'erons
donc `a tort comme non-affine, le prenant pour un tableau dynamique acc'ed'e par pointeur. Il
faudrait utiliser des techniques de r'e-'ecriture pour reconna^itre ces acc`es comme affines.

ammp. Le benchmark ammp poss`ede 20% d'instructions situ'ees dans des SCoPs riches, pour
5% d'acc`es statiques. Ce benchmark r'esout des probl`emes de chimie mol'eculaire, mod'elisant des
mol'ecules complexes. Il r'esout les 'equations de Newton r'egissant le d'eplacement des mol'ecules
dans un liquide, r'epondant `a des r`egles impos'ees par des prot'eines inhibitrices, et calcule l''energie
associ'ee `a la configuration des atomes. En entr'ee est fournie une liste d'atomes, leur configuration
initiales, et les r`egles de d'eplacement associ'ees. En sortie est renvoy'ee la configuration finale des
atomes et l''energie dissip'ee.

Les mol'ecules sont repr'esent'ees par des listes cha^in'ees d'atomes (eux m^emes repr'esent'es
sous forme de grosses structures C de plus de 20 'el'ements). Ces listes sont bien s^ur allou'ees
dynamiquement et manipul'ees pendant tous le programme, ce qui explique le tr`es faible taux
d'acc`es affine (5%). Il y a 'egalement un grand nombre de conditionnelles (environ 235 pour 2400
instructions) qui correspondent `a des comparaisons de distance ou de potentiel, comparaisons
flottantes et donc non statiques.

fma3d. Bien que la totalit'e des acc`es du benchmark fma3d soient affines, moins de 2 % des
instructions sont dans des SCoPs riches, ce qui ne laisse que tr`es peu d'espoir pour l'optimisation de ce programme avec notre mod`ele de programmation. Ce benchmark mod'elise par des
techniques d''el'ements finis les effets d'un choc non-'elastique sur la d'eformation de formes solides
en 3D. En entr'ee sont fournies les informations relatives `a l'impact initial sur la forme en 3D, et
un treillis `a 'el'ements finis `a appliquer `a cette forme. En sortie, sont fournis les d'eplacement de
diff'erents points du treillis au cours du temps.

Tout comme les benchmarks art et equake utilise un grand nombre de structures de donn'ees allou'ees dynamiquement. Toutefois fma3d n'est pas 'ecrit en C, mais en Fortran 90. Or les
pointeurs du Fortran 90 ont un comportement bien particulier : les donn'ees en m'emoire 'etant
syst'ematiquement align'ees sur la taille du mot m'emoire, les deux derniers bits des pointeurs du
Fortran devrait toujours ^etre `a 0. Mais au lieu de cela, ils sont utilis'es pour fournir des informations suppl'ementaires sur le pointeur (comme le fait qu'il a 'et'e allou'e ou non). Au niveau
de l'arbre de syntaxe, et plus particuli`erement du calcul d'adresse, cela introduit des op'erateurs
logiques (AND) pour masquer ces bits d'informations. Ces op'erateurs logiques au milieu d'expressions arithm'etiques ne sont pas compatibles avec notre analyseur d'arbre syntaxique qui
essaye de construire l'expression arithm'etique correspondant `a l'acc`es, et qui marque comme
non valide des parties enti`eres du code.

Il faudrait modifier notre analyseur pour que l'impact des pointeurs Fortran soit du m^eme
ordre que l'impact des pointeurs C. Ce n'est pas une tache facile, car de nombreuses instructions
correspondant `a la manipulation et au test des bits d'informations des pointeurs sont ajout'ees par
le compilateur, sans que ces instructions de test soient pr'esentent dans le programme d'origine.
Cela explique 'egalement pourquoi l'impact des pointeurs est sup'erieur en Fortran.

5.7. Conclusion 57
5.7 Conclusion

La Section 5.6.5 a clairement montr'e que l'utilisation de l'arithm'etique des pointeurs avait
un impact tr`es grand sur la repr'esentativit'e de notre mod`ele de programmation. L'impact est
d'autant plus fort pour les codes Fortran 90, qui stockent des informations additionnelles dans
les pointeurs et doivent manipuler ces derniers pour les r'ecup'erer.

Nous avons toutefois 'egalement montr'e que pour les classes de programmes plus calculatoires,
pr'ef'erant l'utilisation de tableaux aux pointeurs, notre couverture en SCoPs 'etait plut^ot bonne.
Et que l'ensemble des nids de boucles candidats `a l'optimisation 'etait repr'esent'e.

L'inlining de fonctions et les am'eliorations d'ecrites dans la Section 5.5 permettent d'am'eliorer
encore cette couverture. Il est 'egalement possible de permettre `a l'utilisateur de renseigner des
informations de staticit'e pour court-circuiter des parties de l'algorithme : en consid'erant par
exemple un groupe d'instructions comme un macro-bloc statique repr'esent'e par une unique
instruction. Cela permet d'exclure de l'analyse de staticit'e des instructions non repr'esentatives
aux gardes complexes (comme les entr'ees/sorties correspondant aux fonctions de d'eboguage).
De telles techniques permettent d'exclure (dans le cadre des applications sans arithm'etique de
pointeurs) les quelques instructions responsables de la non staticit'e, c'est-`a-dire pour les SpecFP,
essentiellement des affichages de valeurs interm'ediaires des calculs r'ealis'es `a certaines it'erations
des algorithmes.

58 5. Abstraction poly'edrique59
Chapitre 6
Analyses et transformations
poly'edriques

Les phases d'analyse jouent un r^ole crucial au sein des compilateurs, car elles fournissent
les informations n'ecessaires aux phases r'ealisant les optimisations. Les r'esultats de la phase
d'analyse de d'ependances par exemple vont permettre de d'eterminer l'applicabilit'e des transformations r'ealis'ees dans les diff'erentes phases d'optimisation des compilateurs.

Les analyses de d'ependances ont longtemps mod'elis'e les acc`es aux 'el'ements d'un tableau
comme des acc`es au tableau tout entier. Ce genre de mod`ele ne permet d'extraire ni les informations n'ecessaires `a la parall'elisation des nids de boucles acc'edant aux tableaux, ni les informations
de d'ependances n'ecessaires `a la d'etermination de l'applicabilit'e des transformations.

Consid'erons par exemple le code de la Figure 6.1, en consid'erant les d'ependances de donn'ees
au niveau des instructions S1 et S2, aucun r'eordonnancement n'est possible (S2 d'epend de S2
et de S1).

(S1) A[0]=1.432

for(i=1; i<N; i++)
(S2) A[i] = A[0] * X[i]

Fig. 6.1 - Exemple de source `a analyser
Par contre, en consid'erant les instances d'instructions, il est possible de d'eterminer que les
'ecritures en m'emoire r'ealis'ees par les instances de l'instruction S2 se font toutes `a des adresses

diff'erentes, et qu'aucune r'ef'erence m'emoire ne subit `a la fois une lecture et une 'ecriture. Les
diff'erentes instances de l'instruction S2 peuvent donc ^etre r'eordonn'ees librement.

Cette repr'esentation compl`ete pr'esente toutefois un d'efaut majeur li'e `a la taille d'une telle
repr'esentation et au temps n'ecessaire `a sa g'en'eration : il faut ainsi ^etre capable d'indiquer les
d'ependances entre toutes les paires possibles d'instances d'instructions partageant un m^eme acc`es `a un tableau, ce qui n'ecessite 'egalement d'^etre capable d'identifier les r'ef'erences acc'edant
aux m^eme cases m'emoires. Les compilateurs classiques utilisent donc g'en'eralement des repr'esentations partielles et approximatives, ce qui conservativement interdit certaines optimisations
du programme.

Dans la section 6.1, nous r'esumerons les diff'erentes techniques, bas'ees sur la programmation lin'eaire, permettant de recueillir les informations de d'ependances compl`etes dans des programmes r'eguliers, irr'eguliers, et plus particuli`erement pour nos SCoPs. Dans la section 6.2 nous
nous int'eresserons `a la g'en'eralisation de l'expansion scalaire dans le cadre des tableaux, et montrerons l'int'er^et de la repr'esentation poly'edrique pour r'ealiser cette expansion. Dans la section

60 6. Analyses et transformations poly'edriques
6.3 nous pr'esenterons les techniques utilis'ees pour repr'esenter l'ordonnancement des instructions
dans le mod`ele poly'edrique.

6.1 Analyses de d'ependances et de flots de donn'ees

Nous allons maintenant pr'esenter les diff'erentes techniques permettant de recueillir des informations de d'ependances compl`etes. Toutes ces techniques agissent au niveau des instances
d'instruction (voir Section 5.1.1), et font r'ef'erence au vecteur d'it'eration [60] : Chaque instance
d'une instruction de profondeur n, peut ^etre repr'esent'ee par un couple pS, iq correspondant `a
l'instruction et au vecteur d'it'eration associ'e `a l'instance. Les composantes de ce vecteur d'it'eration i P Zn repr'esentent les valeurs des it'erateurs englobants cette instruction pour cette instance
particuli`ere. L'ensemble des vecteurs d'it'eration possibles relatifs `a une instruction forme son
domaine d'it'eration. La Figure 6.2 donne quelques exemples d'instances d'instructions pour un
code source, et la Figure 6.3 donne les domaines d'it'eration correspondants.

for(i=1; i<100; i++)

for(j=1; j<100; j++)

S1(i,j)
S2(i)
S3

(a) Code source

pS1,

"2

3

j

q pS1,

"99

99

j

q pS2,

"760

q pS3, r sq

(b) Instances d'instructions

Fig. 6.2 - Exemples d'instances avec leur vecteur d'it'eration

Domaine de S1 :

! "i

j

j

| 1 d^ i d^ 100, 1 d^ j d^ 100

)

Domaine de S2 :

! "

i

0

| 1 d^ i d^ 100

)

Fig. 6.3 - Exemples de domaines d'it'eration correspondant au source 6.2(a)
L''egalit'e de deux fonctions d'acc`es `a un m^eme tableau A de dimension n peut ^etre repr'esent'e
par un syst`eme de n 'equations, une pour chacune des composantes du tableau. Consid'erons par
exemple le code de la Figure 6.4.

for(i=1; i<N; i++)

for(j=1; j<N; j++)
(S1) A[i-1][j+1] = ...

for(i=1; i<N; i++)

for(j=1; j<N; j++)
(S2) ... = A[i][j]

Fig. 6.4 - Exemple de flot de donn'ees
Une r'eutilisation sur le tableau A entre deux instances pS1,

`i

j

ae

q et pS2,

`i1

j1

ae

q des instructions

S1 et S2 est caract'eris'ee par le syst`eme t i ' 1 " i1 ^ j ` 1 " j1 u.

Il est par contre beaucoup plus difficile pour l'instance d'une lecture donn'ee, de trouver
l'instance de l''ecriture qui correspond `a cette lecture.

6.1.1 Cas des programmes r'eguliers

Feautrier [38, 39] a montr'e que ce probl`eme pouvait ^etre r'esolu par des techniques de la
programmation lin'eraire, et a d'evelopp'e un algorithme trouvant les informations exactes et

6.1. Analyses de d'ependances et de flots de donn'ees 61
compl`etes de d'ependances de flot pour les programmes `a contr^ole statique d'efinis dans la Section
5.2 (les bornes de boucles, les conditionnelles et les fonctions d'acc`es aux tableaux sont des
fonctions affines des it'erateurs englobants).

La fonction d'acc`es `a un tableau M de l'instruction t pour l'instance d'instruction pt, bq peut
^etre 'ecrite sous la forme d'une fonction g du vecteur d'it'eration b, comme l'indique la Figure 6.5

L'objectif est alors de trouver l'instance source de la valeur M rgpbqs pour tout tableau M afin
de conna^itre de fa,con exacte l'ensemble des d'ependances de flot.

for(i=0; i<N; i++)

for(j=0; j<N; j++)

for(k=0; k<N; k++)

... = A[i][k] ...

(a) code source

g

"
""

>>
-

i

j
k

fi
fl

,
,"

" i

k

j

(b) fonction d'acc`es au
tableau A

Fig. 6.5 - Acc`es 'ecrit sous forme d'une fonction du vecteur d'it'eration

Soit S " tpSi, aiq | i P r0, nsu l'ensemble des instances d'instructions Si avec leur vecteur
d'ordonnancement ai produisant une valeur du tableau M . Ces instances d'instruction sont de
la forme "M[f(a)]=. . ." et celle correspondant `a la source de l'acc`es M pgrbsq est la derni`ere des
instances pSi, aiq.

La pr'ec'edence est d'efinie `a l'aide de l'op'erateur "a*" et l'instance "K" est d'efinie comme 'etant
r'ealis'ee avant toute instance (@pt, bq : K a* pt, bq).
La source de l'acc`es M pgrbsq s'exprime alors par les contraintes suivantes :

- l'instance pSi, aiq doit produire la valeur pour M pgpbqq.

f paiq " gpbq
- l'instance pSi, aiq doit pr'ec'eder l'instance pt, bq.

pSi, aiq a* pt, bq
- l'instance pSi, aiq doit ^etre une des instances possibles de Si.

pSi, aiq P S
- l'instance pSi, aiq doit ^etre la derni`ere v'erifiant toutes les conditions ci-dessus.

u 0 ai ^ f puq " gpbq ^ pS, uq a* pt, bq ^ pS, uq P S n~ u ! ai
Plus simplement, en consid'erant que l'op'erateur "max!" renvoie le maximum lexicographique
d'une ensemble de vecteur (Le maximum lexicographique de l'ensemble vide est K).

ai " max !pQSitpbqq
QSitpbq "

!

u | f puq " gpbq ^ pS, uq a* pt, bq ^ pS, uq P S

)

Cela signifie que ce probl`eme s'apparente `a rechercher la solution s P Zn maximale parmi les
solutions v'erifiant un syst`eme d''equations et d'in'equations affines.

Il est 'egalement possible de repr'esenter l'ensemble des sources d'une lecture en fonction du
vecteur d'ordonnancement associ'e `a cette lecture. Feautrier propose de repr'esenter ces r'esultats
sous forme d'arbres de s'election quasi-affines : les quast. Ces arbres donnent la valeur du couple

62 6. Analyses et transformations poly'edriques

(S0) A[0]= 0

for(i=1; i<50; i++)
(S1) A[i]= ...

for(i=51; i<100; i++)
(S2) A[i]= ...

for(i=0; i<100; i++)
(S3) ... = A[i]

quastif
i=0then

(S0,[0])else if

0<i and i<50then

(S1,[i])else if

50<i and i<100then

(S2,[i])else
K

Fig. 6.6 - Exemple de quast repr'esentant les sources de A[i]

pSi, aiq correspondant `a l'instance de l'instruction ayant r'ealis'ee l''ecriture pour une instance
de lecture donn'ee. Ces arbres sont param'etriques et conditionn'es par les valeurs du vecteur
d'ordonnancement correspondant `a l'instance de la lecture. La Figure 6.6 donne un exemple de
quast correspondant `a un acc`es au tableau Aris.

Amarasinghe et al. [71] ont propos'e une approche alternative repr'esentant les informations de
d'ependances compl`etes dans des Last Write Trees, des arbres qui font correspondre une instance
d'une op'eration de lecture avec la derni`ere instance d''ecriture `a la m^eme r'ef'erence m'emoire,
et donne 'egalement des informations de couverture (le fait qu'une op'eration d''ecriture masque
une op'eration d''ecriture pr'ec'edente). Consid'erons par exemple le source de la Figure 6.7(a) o`u
les 'ecritures correspondant aux lectures de la premi`ere it'eration (j " 11) ne sont pas dans le
nid de boucles. Pour les it'erations suivantes, les lectures correspondent aux 'ecritures r'ealis'ees `a
l'it'eration j pr'ec'edente. Cette information est repr'esent'ee sous la forme de l'arbre de la Figure
6.7(b).

...
for(i=11; i<=20; i++)

for(j=11; j<=20; j++)

A[j]=...
...=A[j-1]
...

(a) Exemple de code

K ir, jr ' 1

jr a, 11
F T

(b) Un Last Write Tree
Fig. 6.7 - Exemple de Last Write Trees

L'auteur montre 'egalement que les informations issues de ces arbres sont `a la fois n'ecessaires et suffisantes pour guider la phase d'optimisation r'ealisant la privatisation de tableau,
une transformation tr`es importante pour la parall'elisation des programmes sur des machines
multi-processeurs.

Pugh [86], pour simplifier le probl`eme NP-complet de la programmation lin'eaire, a propos'e
l'Omega Test permettant de d'eterminer s'il existe une solution lin'eaire `a un ensemble arbitraire
d''equations et d'in'equations, en utilisant de nouvelles m'ethodes d''elimination de contraintes
d''egalit'e : des r`egles de normalisation et de r'e'ecriture sont appliqu'ees pour faire appara^itre dans
les 'egalit'es le coefficient 1. Cette 'egalit'e est ensuite substitu'ee dans l'ensemble des autres 'egalit'es
et in'egalit'es, puis 'elimin'ee du syst`eme comme le montre la Figure 6.8.

A la fin de l'algorithme, la premi`ere in'equation 1 d^ 13oe ` 12 d^ 40 se normalise en 0 d^ oe d^ 2
sur les entiers, et la seconde in'equation '50 d^ '5oe ' 3 d^ 50 en '9 d^ oe d^ 10, ce qui nous donne
comme r'esultat final 0 d^ oe d^ 2.

D'une mani`ere g'en'erale, pour d'eterminer si un syst`eme de n in'equations poss`ede des solutions
enti`eres, l'auteur proc`ede `a une s'erie de projection du poly`edre de dimension n form'e par ces
in'equations, dans des espaces de dimensions inf'erieures, cr'eant des ombres du poly`edre dans
lesquelles il cherche les points entiers. Deux ombres sont en fait g'en'er'ees : l'ombre r'eelle, qui

6.1. Analyses de d'ependances et de flots de donn'ees 63

substitution syst`eme `a r'esoudre
7x ` 12y ` 31z " 17
3x ` 5y ` 14z " 7
1 d^ x d^ 40
'50 d^ y d^ 50

x " '8oe ' 4y ' z ' 1

'7oe ' 2y ` 3z " 3
'24oe ' 7y ` 11z " 10
1 d^ '8oe ' 4y ' z ' 1 d^ 40
'50 d^ y d^ 50

y " oe ` 3o/

'3oe ' 2o/ ` z " 1
'31oe ' 21o/ ` 11z " 10
1 d^ '12oe ' 12o/ ' z ' 1 d^ 40
'50 d^ oe ` 3o/ d^ 50

z " 3oe ` 2o/ ` 1

1 " 1
2oe ` o/ ` 1 " 0
1 d^ '15oe ' 14o/ ' 2 d^ 40
'50 d^ oe ` 3o/ d^ 50

o/ " '2oe ' 1

1 " 1
0 " 0
1 d^ 13oe ` 12 d^ 40
'50 d^ '5oe ' 3 d^ 50

Fig. 6.8 - R'esolution par l'Omega Test

correspond effectivement `a l'ombre du poly`edre, et l'ombre sombre du poly`edre, comme l'indique
la Figure 6.9.

Ombre r'eelle
Ombre sombre

Fig. 6.9 - Ombre r'eelle et ombre sombre d'un poly`edre de dimension 2
L'absence de points entiers dans l'ombre r'eelle du poly`edre signifie alors l'absence de points
entiers dans le poly`edre, et la pr'esence de points entiers dans l'ombre sombre du poly`edre signifie
la pr'esence de points entiers dans le poly`edre de d'epart.

Ces techniques ont d'emontr'e qu'elles 'etaient capables de calculer en un temps raisonnable
les informations de d'ependances compl`etes, n'ecessaires `a l'optimisation et `a la parall'elisation
des programmes. Certaines de ces techniques ont m^eme 'et'e 'etendues au cas des programmes
irr'eguliers [106].

6.1.2 Cas des programmes irr'eguliers

La repr'esentation des programmes irr'eguliers aux niveau des acc`es impose g'en'eralement de
sortir du mod`ele poly'edrique. Cette section d'ecrit bri`evement des techniques utilis'ee pour traiter
de tels programmes.

Pugh et Wonnacott [106] ont propos'e d''etendre l'analyse aux programmes irr'eguliers en
repr'esentant les contraintes irr'eguli`eres comme des contraintes lin'eaires avec des termes nonr'eguliers repr'esent'es sous la forme de fonctions non interpr'et'ees. Dans ce cadre, les auteurs ont
d'efini des techniques d'analyse de d'ependances symboliques en utilisant une extension des 'equa64 6. Analyses et transformations poly'edriques
tions de Presburger, et sont arriv'es `a parall'eliser quelques boucles des Perfect Club Benchmarks
avec cette technique.

Collard et al. [24] proposent d''etendre les classes de programmes `a ceux comportant des
while et des constructions en if, then, else qui ne permettent pas `a la compilation de d'eterminer ni le contr^ole, ni le flot de donn'ees. Le concept de source d'efini par Feautrier est alors
'etendu aux ensembles de sources pour le calcul des flots de donn'ees. Les parties irr'eguli`eres sont

pr'esent'ees comme 'etant pr'ediqu'ees par des variables cach'ees, et les r'esultats obtenus sont des
approximations conservatives.

6.1.3 Conclusion

L'ensemble des techniques d'ecrites ci-dessus sont applicables dans le cadre des SCoPs en ce
qui concerne les acc`es affines. Pour les acc`es non affines, il faudrait utiliser des m'ethodes plus
approximatives. Pour l'instant, nous consid'erons les acc`es non-affines aux tableaux comme des
acc`es `a la totalit'e du tableau. La forte proportion d'acc`es affines dans les SCoPs (voir Section
5.6.3) et la faible pr'esence des acc`es non-affines dans les nids de boucles les plus profonds, font
que cette forte approximation n'affecte que peu l'applicabilit'e des transformations des parties
de code `a optimiser.

Enfin nous avons adopt'e un sch'ema totalement diff'erent entre notre phase d'optimisation et
notre phase d'analyse de d'ependances : Plut^ot que de pratiquer une phase d'analyse complexe
au d'ebut de notre processus d'optimisation, et pour chaque transformation de se r'ef'erer `a cette
phase d'analyse pour en v'erifier l'applicabilit'e comme l'indique la Figure 6.10, nous sauvons
l''etat des d'ependances de donn'ees avant d'appliquer une s'erie de transformations, et v'erifions `a
posteriori qu'aucune d'ependance n'a 'et'e viol'ee comme l'indique la Figure 6.11.

Phase
d'analyse

Phase de
transformation

Phase de
transformation

V'erification de l'applicabilit'e

Fig. 6.10 - Sch'ema classique de v'erification des d'ependances
Sauvegarde
d'ependances

Phase de
transformation

Phase de
transformation

V'erification
d'ependances

Recherche de d'ependances viol'ees

Fig. 6.11 - Notre sch'ema de v'erification des d'ependances
Notre algorithme de v'erification des d'ependances `a posteriori a une complexit'e similaire
`a celui d'analyse de d'ependance classique et requiert environ le m^eme nombre de ressources
(celles n'ecessaires au stockage de l'ensemble des d'ependances de donn'ees). L'avantage d'une
telle technique est double : tout d'abord, il permet au processus de compilation de travailler avec
des r'esultats interm'ediaires non valides du point de vue des d'ependances, les transformations
suivantes permettant de r'etablir cette validit'e. Cette propri'et'e est importante dans le contexte
de l'optimisation it'erative et dans celui de la recherche d'une s'equence de transformations.

6.2. Expansion de tableaux 65
6.2 Expansion de tableaux

Nous avons dans la section pr'ec'edente pr'esent'e comment les analyses de d'ependances de
donn'ees 'etaient r'ealis'ees dans le mod`ele poly'edrique, en nous int'eressant plus particuli`erement
aux d'ependances de flot. Ces d'ependances repr'esentent en fait les seules v'eritables d'ependances
du programme. Elles repr'esentent la transmission des r'esultats entre les op'erations composant
le programme.

Les autres types de d'ependances correspondent `a la r'eutilisation de cellules m'emoires, et
peuvent ^etre 'elimin'ees par des techniques d'expansion permettant de traduire le programme en
assignation unique. L'expansion est une 'etape n'ecessaire de la parall'elisation de programmes,
mais une expansion totale du programme n'est toutefois pas concevable du point de vue de
l'espace m'emoire requis. L'extraction des informations compl`etes de flot de donn'ees r'ealis'ee
dans la section pr'ec'edente permettent de r'ealiser ce travail d'expansion.

Feautrier [37] a 'etendu la technique d'expansion scalaire [105] aux tableaux afin d''eliminer les
d'ependances de sortie. L'algorithme est en deux 'etapes : Les 'ecritures sont d'abord transform'ees
soit par renommage dans les cas les plus simples, soit par expansion. Puis les lectures sont
analys'ees et 'eventuellement remplac'ees par des acc`es aux nouveaux tableaux pour reconstruire
le flot de donn'ees. Cet algorithme est r'ealis'e en r'esolvant des syst`emes param'etriques entiers, et
sa complexit'e en moyenne d'epend d'un petit nombre de param`etres. L'espace m'emoire requis
par le programme pour stocker les tableaux apr`es expansion quant `a lui est beaucoup plus
grand (le produit de matrice par exemple, obtient une complexit'e m'emoire en Opn3q), ce qui
est inconcevable pour des programmes manipulant de grandes structures de donn'ees, comme la
plupart des applications scientifiques.

Lefebvre et al. [63, 62], pour r'esoudre le probl`eme de l'espace m'emoire, proposent de r'ealiser
des expansions partielles de tableaux. Les auteurs d'efinissent la notion de dur'ee d'utilit'e d'une
valeur en s'eparant en trois phases la dur'ee de vie d'une variable. La premi`ere phase se situe avant
la premi`ere 'ecriture d'une valeur, et la cellule m'emoire est alors consid'er'ee comme vide. Durant
la seconde phase, la valeur est utilis'ee et la cellule m'emoire est utile. Durant la troisi`eme phase
la valeur n'est plus utilis'ee et la cellule m'emoire devient inutile. Durant les premi`ere et troisi`eme
phases l'espace m'emoire correspondant peut ^etre librement r'eutilis'e. Cette notion permet aux
auteurs de r'ealiser des renommages et des expansions partielles des tableaux rendant possible la
parall'elisation sans explosion de la taille m'emoire.

Barthou et al. [9] ont 'etendu ces techniques aux classes de programme au contr^ole irr'egulier.
Ces programmes poss'edant un flot de contr^ole dynamique, une partie du calcul, notamment
le calcul d'adresse, doit ^etre r'ealis'e `a l'ex'ecution. Dans le cas classique, cela ne permet pas
de trouver statiquement les informations compl`etes sur le flot de donn'ees, et donc de r'ealiser
l'expansion avant l'ex'ecution. Les auteurs proposent de nouvelles techniques d'expansion, et
d'efinissent la notion d'expansion statique. Le principe consiste `a regrouper les 'ecritures `a une
m^eme cellule m'emoire en classes d''ecritures indissociables du point de vue du flot de donn'ees.
L'expansion peut ^etre r'ealis'ee pour cette cellule un nombre de fois 'egal au nombre de classes
identifi'ees.

Cohen [23] 'etend encore ces techniques aux programmes r'ecursifs, red'efinissant l'analyse
de d'ependance et de d'efinitions visibles par instance dans le cadre ces programmes. L'auteur
introduit une nouvelle abstraction pour les d'efinitions visibles : les transductions.

Rajopadhye et al. [101, 87] ont 'egalement 'etudi'e les probl`emes de r'eutilisation m'emoire
apr`es expansion totale, en proposant une technique permettant de construire pour un ordonnancement donn'e, l'allocation m'emoire optimale. L'id'ee consiste `a calculer les allocations m'emoires
par projection de domaines, en s'assurant qu'aucune valeur en vie n'est jamais r'e'ecrite. Leur

66 6. Analyses et transformations poly'edriques
technique de projection a ensuite 'et'e 'etendue aux fonctions d'acc`es `a modulos en g'en'eralisant
les projections en pseudoprojections.

Enfin, Darte et al [29] g'en'eralisent les approches pr'ec'edentes en formalisant le probl`eme par
des r'eseaux critiques entiers pour proposer une allocation m'emoire modulaire inter-tableaux.

6.3 Algorithmes d'ordonnancement poly'edrique
6.3.1 Ordonnancements monodimensionnels

Dans un contexte de parall'elisation de programmes, Feautrier [40] a propos'e une m'ethode
pour construire des ordonnancements affines monodimensionnels `a partir des graphes de flot
de donn'ees construits par l'analyse de d'ependances. Les contraintes de pr'ec'edence sont alors
impos'ees par les d'ependances. Ces ordonnancements sont repr'esent'ees par la fonction d'ordonnancement ` qui associe `a chaque instruction, une date logique d'ex'ecution en fonction de la
valeur du vecteur d'it'eration. La Figure 6.12 pr'esente la plus simple des fonctions d'ordonnancements possibles pour les instructions S1 et S2.

for(i=0; i<=N; i++)
(S1) A[i] = ...

for(j=0; j<=N; j++)
(S2) A[i] = A[i] + ...

`pS1,

"i0

q " 0

`pS2,

"i

j

j

q " j ` 1

Fig. 6.12 - Fonction d'ordonnancement des instructions S1 et S2
Le principal d'efaut de cet ordonnancement affine est qu'il n'est pas toujours possible de
trouver un tel ordonnancement pour un graphe de flot donn'e. Consid'erons par exemple le code
source de la Figure 6.13(a). La fonction d'ordonnancement de S, pr'esent'ee la Figure 6.13(b), ne
d'epend pas que du vecteur d'ordonnancement

`i

j

ae mais aussi du param`etre N correspondant `a la

borne de la boucle i, ce qui pose probl`eme si ce param`etre ne peut ^etre connu statiquement.

for(i=0; i<=N; i++)

for(j=0; j<=i; j++)
(S) a = a + ...

(a) source

`pS,

"i

j

j

q " N ^ i ` j

(b) fonction d'ordonnancement

Fig. 6.13 - Nid de boucles sans ordonnancement lin'eaire possible
Or, la pr'esence de bornes de boucles non connue statiquement est extr^emement fr'equente
dans les codes r'eels. Ces bornes de boucles correspondent la plupart du temps aux dimensions
des structures de donn'ees qui ne sont connues qu'apr`es lecture du jeu de donn'ees de l'application.

6.3.2 Ordonnancements multidimensionnels

Feautrier [41] a 'egalement propos'e de consid'erer des ordonnancements multidimensionnels.
La fonction ` et les dates logiques sont alors des vecteurs, et la notion d'ordre sur ces vecteurs
s'exprime par l'op'erateur d'ordre strict ! :

u ! v dhn~ _

$
&

%

, u0 a* v0
, ^

"

, u0 " v0

, u1..du ! v1..dv

6.3. Algorithmes d'ordonnancement poly'edrique 67
L'auteur recherche alors pour chaque instruction, la fonction d'ordonnancement de dimension
minimale en se basant sur les graphes de flot de donn'ees. Dans le contexte de la parall'elisation
plus les fonctions d'ordonnancement auront un nombre de dimensions faible, plus il sera possible
de parall'eliser.

De mani`ere similaire, Lim et Lam [65, 66] d'efinissent les affine partition mappings comme
des fonctions d'ordonnancement multidimensionnelles, et tentent de maximiser le parall'elisme,
cette fois en minimisant les communications dues aux synchronisations. Un degr'e de parall'elisme
maximum est recherch'e successivement pour un nombre de synchronisations croissant (de z'ero `a
des fonctions exponentielles du nombre d'it'erations) jusqu'`a ce que le parall'elisme soit suffisant
pour occuper l'int'egralit'e des ressources mat'erielles. Les auteurs obtiennent ainsi successivement
des versions avec un meilleur degr'e de parall'elisme, mais des co^uts de synchronisation plus 'elev'es.
La recherche de parall'elisme pour un nombre de synchronisation donn'e s'exprime par la recherche
d'un ordonnancement affine pour chaque partition temporelle.

Bastoul et al. [11] proposent un d'ecoupage du programme en chunks, des r'egions `a forte
localit'e o`u l'essentiel des donn'ees tiennent dans le cache, et recherchent ensuite un ordonnancement affine pour ces chunks qui minimise le trafic m'emoire inter-chunks, c'est-`a-dire le nombre
de lignes `a renouveler dans le cache. Cette approche orient'ee localit'e et faible trafic permet de
minimiser la consommation 'energ'etique importante due au trafic de donn'ees depuis la m'emoire
centrale.

Kelly et Pugh [53] utilisent les space mappings pour repr'esenter la parall'elisation sur les
diff'erents processeurs, et les time mappings pour repr'esenter l'ordonnancement. Ces time mappings sont en fait des bijections permettant `a partir des domaines des instructions de calculer
un nouveau domaine o`u l'ordre lexicographique est respect'e. La modification de ces fonctions
correspond alors directement `a un r'eordonnancement du programme. La Figure 6.14 donne un
exemple de code source (a) avec les domaines d'it'erations associ'es (b) et un exemple de code
transform'e (d) apr`es application d'un time mapping (c).

for(i=1; i<=N; i++)

S1(i)
for(j=1; j<=i-1; j++)

S2(i,j)
S3(i)

(a) code source

S1 : t1 d^ i d^ N u
S2 : t1 d^ i d^ N ^ 1 d^ j d^ M u
S3 : t1 d^ i d^ N u

(b) domaines d'it'eration

T 1 : t ris N~ r0, is u
T 2 : t ri, js N~ r1, j, 0, is u
T 3 : t ri, js N~ r1, i ' 1, 1s u

(c) time mappings

for(i=1; i<=N; i++)

S1(i)
for(j=1; j<=M; j++)

for(i=1; i<=N; i++)

S2(i,j)
S3(i+1)

(d) source transform'e

Fig. 6.14 - Exemple de time mapping
Toutes ces techniques d'ordonnancement malgr'e leur abstractions respectives sont extr^emement co^uteuses, tous ces algorithmes 'etant de complexit'e exponentielle.

6.3.3 Conclusion
Ordonnancement : Dans le cadre de l'optimisation de programme, nous voulons ^etre capables
d'appliquer n'importe quelle transformation sur l'ordonnancement des instructions pour modifier, soit l'ordre des it'erations, soit le s'equencement des instructions dans les nids de boucles.

68 6. Analyses et transformations poly'edriques
Il faut aussi faciliter la composition des transformations pour pouvoir reproduire les longues
s'equences de transformations n'ecessaires `a l'optimisation de programmes.

Pour une instruction de profondeur d, nous utilisons des dates logiques de dimension 2^d`1
qui correspondent directement `a l'emplacement de l'instruction dans l'arbre de syntaxe. Dans
la Figure 6.15, (a) pr'esente un exemple de code source, dont (b) est l'arbre de syntaxe, et (c)
l'ensemble des fonctions d'acc`es associ'ees aux instructions.

for (i=1; i<M; i++)

S1
S2
for (k=1; k<P; k++)

S3
for (l=1; l<Q; l++)

S4
S5

(a) code source

for i S2 for k

S1 S3 for l

S4 S5

0 1 2
0 0 1

0 1

(b) arbre de syntaxe
`pS1, risq "

>>
-0i

0

fi
fl `pS2, rsq "

"10 `

pS3, rksq "

>>
-2k

0

fi
fl

`pS4,

"k

l

j

q "

>>
--
--
--
--
-

2
k

1

l
0

fi
ffi
ffi
ffi
ffi
fl `

pS5,

"k

l

j

q "

>>
--
--
--
--
-

2
k

1

l
1

fi
ffi
ffi
ffi
ffi
fl

(c) fonctions d'ordonnancement
Fig. 6.15 - Fonctions d'ordonnancement de dimension 2 ^ d ` 1

L'ordonnancement relatif au s'equencement des instructions des nids de boucles (l'ordre des
instructions dans les boucles) est alors repr'esent'e par les dimensions paires (en commen,cant `a 0),
tandis que l'ordonnancement relatifs aux it'erations est repr'esent'e par les dimensions impaires.
Les transformations modifiant l'un de ces deux ordonnancement agira sur les dimensions ad-hoc.

Chaque composante de la fonction ` est une fonction affine des it'erateurs et des param`etres
du SCoP, comme les tailles des structures de donn'ees. Il est ainsi facile de repr'esenter des
transformations utilisant ces param`etres. Consid'erons par exemple le code de la Figure 6.16 qui
repr'esente une inversion de boucle sur un seul des instructions d'une boucle : (a) correspond
au code de d'epart et (b) repr'esente ses fonctions d'ordonnancement. Apr`es modification de cet
ordonnancement (c), on obtient `a l'ex'ecution la trace d'ex'ecution (d).

Apr`es l'inversion de boucle, toutes les instructions de S1 sont ex'ecut'ees avant celle de S2,
ce qui ne correspond pas `a l'intuition d'une inversion de boucle sur une seule instruction qui ne
devrait pas changer l'imbrication des instructions S1 et S2. La Figure 6.17 correspond `a cette
version plus intuitive de la transformation. Elle exprime la nouvelle fonction d'ordonnancement
de S1 'egalement avec le param`etre N qui correspond `a la borne sup'erieure de la boucle. Cette
fois, dans la trace d'ex'ecution g'en'er'ee, les instructions S1 et S2 sont bien altern'ees, et l'ordre
d'ex'ecution des instructions de S1 est bien invers'e.

L'ensemble des transformations d'ordonnancement sont d'etaill'ees dans la Partie III d'ecrivant
notre formalisme.

6.3. Algorithmes d'ordonnancement poly'edrique 69

for (i=1; i<=N; i++)

S1(i)
S2(i)

(a) code de d'epart

`pS1, risq "

>>
-0i

0

fi
fl `pS2, risq "

>>
-0i

1

fi
fl

(b) ordonnancement de d'epart

`pS1, risq "

>>
- 0'i

0

fi
fl `pS2, risq "

>>
-0i

1

fi
fl

(c) ordonnancement transform'e

S1(3)
S1(2)
S1(1)
S2(1)
S2(2)
S2(3)

(d) trace d'ex'ecution pour N i 3

Fig. 6.16 - Inversion de boucle non param'etrique sur l'instruction S1

for (i=1; i<=N; i++)

S1(i)
S2(i)

(a) code de d'epart

`pS1, risq "

>>
-0i

0

fi
fl `pS2, risq "

>>
-0i

1

fi
fl

(b) ordonnancement de d'epart

`pS1, risq "

>>
- 0N ' i ` 1

0

fi
fl `pS2, risq "

>>
-0i

1

fi
fl

(c) ordonnancement transform'e

S1(3)
S2(1)
S1(2)
S2(2)
S1(1)
S2(3)

(d) trace d'ex'ecution pour N i 3

Fig. 6.17 - Inversion de boucle param'etrique sur l'instruction S1

Composition de transformations Wolf [103] propose un mod`ele, permettant d'extraire du
parall'elisme et d'optimiser les programmes pour la hi'erarchie m'emoire, guid'e par la notion de
r'eutilisation. Il propose un environnement pour la transformation de boucles combinant les transformations poly'edriques classiques et contraintes d'ordonnancement issues des informations de
d'ependances. Ces contraintes sont exprim'ees sous la forme de vecteurs de d'ependance qui indiquent `a la fois la distance et la direction de la d'ependance, et qui permettent ainsi de d'eterminer
la l'egalit'e des transformations. Si l'auteur met en avant la n'ecessit'e de r'ealiser plusieurs types
de transformations pour optimiser les nids de boucles, il ne s'oriente pas vers la recherche de la
meilleure s'equence de transformations `a appliquer, mais vers la recherche de la meilleure transformation complexe correspondant `a une composition de transformation. Sa mod'elisation n'est
modifi'ee que lorsque que cette transformation complexe et l'egale a 'et'e trouv'ee. Le nombre de
transformations propos'e est 'egalement faible : principalement les transformations unimodulaires
et le tiling.

Notre approche est `a l'oppos'e : nous d'ecomposons au maximum les transformations de programmes en compositions de transformations plus 'el'ementaires, et appliquons ces transformations 'el'ementaires `a notre formalisme. La l'egalit'e est v'erifi'ee a posteriori comme indiqu'e dans
la section pr'ec'edente, ce qui nous laisse une grande libert'e dans le choix des transformations
composant la s'equence optimisante. Nous avons 'egalement fait une s'eparation claire des composantes du formalisme chacune 'etant repr'esent'ee par un ensemble de matrices : les modifications
de l'ordonnancement, des domaines, et des fonctions d'acc`es sont ainsi orthogonales et explicites.
Nous n'avons donc pas d'ordre implicite pour l'ordonnancement des domaines transform'es. Cela
nous permet de repr'esenter l'int'egralit'e des transformations de programme et de faciliter la

70 6. Analyses et transformations poly'edriques
composition.

Par exemple, l'impl'ementation classique de la fusion de boucle inclue la modification des
bornes de boucles (des domaines) et des acc`es aux tableaux, alors qu'ils ne sont que la cons'equence d'une transformation d'ordonnancement. Certaines it'erations peuvent alors ^etre peel'ees,
augmentant `a la fois la taille de la repr'esentation, et rendant plus complexe l'application de
nouvelles transformations. Dans notre repr'esentation d'ecrite dans la partie III, la fusion de
boucle est exclusivement explicit'ee comme une transformation d'ordonnancement qui n'affecte
donc que les fonctions d'ordonnancement des instructions concern'ees. Les modifications des domaines d'it'erations sont trait'ees implicitement, et les 'eventuels peeling sont effectu'es lors de la
g'en'eration du code. La complexit'e de la repr'esentation reste donc exactement la m^eme.

Enfin, comme toute transformation de programme correspond `a une s'erie de transformations
sur les matrices du formalisme, la recherche d'une s'equence de transformations peut s'exprimer
par une recherche de valeurs dans ces matrices. Cette mod'elisation permet donc 'egalement de
trouver de nouvelles compositions de transformations qui n'ont pas encore 'et'e d'evelopp'ees dans
les mod`eles statiques.

71
Chapitre 7
G'en'eration de code

Apr`es l'application d'une s'erie de transformations dans le mod`ele poly'edriques, la derni`ere
'etape consiste `a r'eg'en'erer les structures de boucles imp'eratives `a r'einjecter dans le compilateur

sous forme d'arbres de syntaxe pour qu'il puisse produire le binaire. Cette g'en'eration de code
doit s'appliquer `a chaque SCoP transform'e et a un fort impact sur la qualit'e du code : il faut
absolument 'eviter que des gardes redondantes ou des bornes de boucles trop complexes r'eduisent
l'efficacit'e des transformations appliqu'ees.

Dans les Chapitres 5 et 6, nous avons pr'esent'e un mod`ele de programmation repr'esentant les
instructions des programmes par leur domaines d'it'erations et des fonctions d'ordonnancement.
Dans ce contexte, la phase de g'en'eration de code consiste `a trouver un ensemble de nids de
boucles visitant chaque point entier de chaque poly`edre des domaines une unique fois, et dans
un ordre compatible avec celui impos'e par les fonctions d'ordonnancement.

Dans ce chapitre, les Sections 7.1 et 7.2 pr'esentent les techniques utilis'ees pour scanner
un, puis plusieurs poly`edres. La Section 7.3 pr'esente la m'ethode de g'en'eration que nous avons
utilis'ee, bas'ee sur le travail de Quiller'e et al. [88] et am'elior'ee par Bastoul [10]. La Section 7.4
pr'esente les probl`emes de complexit'e li'es `a cet algorithme, ainsi qu'une nouvelle impl'ementation
tirant partie de notre formalisme pour en r'eduire la complexit'e.

7.1 Strat'egies pour scanner un poly`edre

Au sein du mod`ele poly'edrique, le probl`eme de la g'en'eration de code est directement li'e `a
un probl`eme consistant `a scanner les points entiers des poly`edres.

Ancourt et Irigoin [1] furent les premiers `a proposer une solution bas'ee sur l''elimination
de Fourier-Motzkin [91]. Leur m'ethode 'etait limit'ee, car elle ne pouvait ^etre appliqu'ee qu'`a un
seul poly`edre, et uniquement pour des transformations unimodulaires. L'id'ee de base consistait
`a impl'ementer les fonctions de transformations comme un changement de base des it'erateurs,
puis, pour chaque nouvelle dimension, de projeter le poly`edre sur l'axe pour trouver les bornes
de boucles comme l'indique la Figure 7.1. Le principal inconv'enient de cette m'ethode 'etait la
production de contr^ole redondant qui n'est pas 'elimin'e au fur et `a mesure des projections.

Les travaux suivants sur le g'en'eration de code ont chercher `a 'etendre cette technique, d'abord
pour g'erer les pas de boucles (strides) sup'erieur `a 1 [64, 107], puis `a 'etendre l'applicabilit'e aux
transformations non inversibles [45]. Toutes ces alternatives de la technique de Fourier-Motzkin
ne r'esolvaient pas le probl`eme le plus crucial : la possibilit'e de scanner plusieurs poly`edres du
m^eme code sans provoquer l'explosion des structures de contr^ole.

La qualit'e du code g'en'er'e peut ^etre 'evalu'ee des deux mani`ere suivantes : par la quantit'e

72 7. G'en'eration de code

Poly`edre :
DSom "

$
&

%

1 d^ i d^ n
1 d^ j d^ n
i ` j d^ M

Projections :1

d^ i d^ minpN, M ' 1q
1 d^ j d^ minpN, M ' 1q i

j

N
N

1 N M-1
1
N
M-1

b b b
b b b b
b b b b
b b b b

0 1 2
1
2

M

M
Fig. 7.1 - M'ethode par projection (Fourier-Motzkin)
de contr^ole dupliqu'e dans le code g'en'er'e, ou par la taille du code g'en'er'e, les codes trop longs
pouvant polluer le cache d'instructions.

7.2 Techniques pour scanner plusieurs poly`edres

Le probl`eme consistant `a scanner plusieurs poly`edres pour des parties de code communes fut
d'abord partiellement r'esolu en g'en'erant une boucle parfaitement imbriqu'ee, puis en 'eliminant
seulement partiellement, les gardes redondantes [52]. Une autre technique consiste `a g'en'erer le
code de chaque poly`edre ind'ependamment, puis `a les fusionner [45, 16], mais cette technique
g'en`ere 'enorm'ement de contr^ole redondant, bien que cette redondance soit absebte des codes
avant fusion.

Pour pr'esenter les diff'erentes techniques permettant de scanner les points entiers de plusieurs poly`edres, r'ef'erons nous `a la Figure 7.2, qui repr'esente les instances d'ex'ecution de deux
instructions S1 et S2.

DS1om "

!1

d^ j d^ N, i " 1

)

DS2om "

!1

d^ i d^ N, j " n

)

i

j

N
N

bInstances de S1
bcInstances de S2

b
b
b
b
b

bc bc bc bc bc

0 1 2 3
1
2
3

Fig. 7.2 - Exemple de deux poly`edres `a scanner
La politique la plus simple consiste `a calculer l'enveloppe rectangulaire des deux poly`edres,
puis de scanner chaque point de cette enveloppe en v'erifiant `a l'aide de gardes si une instruction
doit ^etre ex'ecut'e. C'est la technique utilis'ee par le g'en'erateur de code LoopPo [44, 45]. La Figure
7.3 illustre cette technique, et le surco^ut en terme de contr^ole qu'elle engendre : ici, pour OpN q
op'erations, il faut v'erifier OpN 2q points. Le contr^ole correspondant aux bornes de boucles est

7.2. Techniques pour scanner plusieurs poly`edres 73
ainsi dupliqu'e au niveau de chaque point.

i
j

N
N

bInstances de S1
bcInstances de S2

b
b
b
b
b

bc bc bc bc bc

0 1 2 3
1
2
3

do i=1, n

do j=1, n

if (1<=i .and. i<=n .and. j=n)

S1
if (i=1 .and. 1<=j .and. j<=n)

S2

Fig. 7.3 - M'ethode par enveloppe rectangulaire (bounding box)
Une am'elioration de cette technique consiste `a ne prendre que l'enveloppe convexe du poly`edre, comme illustr'e par la Figure 7.4. Le surco^ut li'e au contr^ole est r'eduit, mais n'est toujours

pas satisfaisant, car les gardes se situent toujours au niveau le plus profond. Le code de la Figure
7.4 a 'et'e produit par le g'en'erateur de code d'Omega, CodeGen [52].

i
j

N
N

bInstances de S1
bcInstances de S2

b
b
b
b
b

bc bc bc bc bc

0 1 2 3
1
2
3

do i=1, n

do j=i, n

if (j=n)

S1
if (i=1)

S2

Fig. 7.4 - M'ethode par enveloppe convexe (convex hull)
Quiller'e et al. ont propos'e une technique de g'en'eration r'ecursive capable de g'en'erer un
ensemble de nids de boucles en scannant plusieurs unions de poly`edres [88], et en 'etant capable
de s'eparer ces poly`edres en un ensemble de poly`edres disjoints. La g'en'eration des nids boucles se
fait alors des niveaux des plus externes aux plus internes. La Figure 7.5 illustre cette technique.

i
j

N
N

bInstances de S1
bcInstances de S2

b
b
b
b
b

bc bc bc bc bc

0 1 2 3
1
2
3

if (n=1)

S1(i=1,j=1)
S2(i=1,j=1)
if(n>=2)

do j=1, n-1

S1(i=1)
S1(i=1,j=n)
S2(i=1,j=n)
do i=2, n

S2(j=n)

Fig. 7.5 - M'ethode par s'eparation
Cette derni`ere approche procure actuellement la meilleure solution car elle garantit qu'il
n'y a aucun contr^ole redondant. Par contre, sa principale limitation est li'ee `a la complexit'e de

74 7. G'en'eration de code
l'algorithme, `a l'impossibilit'e de g'en'erer des strides, et `a la difficult'e de traiter des matrices
d'ordonnancement singuli`eres.

La section suivante pr'esente en d'etails une version am'elior'ee de cet algorithme pr'esent'e par
Bastoul dans [10].

7.3 Notre algorithme de g'en'eration de code : CLooG

Le principe de l'algorithme est le suivant : il s'agit d'une g'en'eration r'ecursive du code, `a
partir d'une liste de poly`edres `a scanner. Cette g'en'eration r'ecursive se fait de la dimension la
plus externe `a la dimension la plus interne. Cet algorithme est l'eg`erement diff'erent de celui
pr'esent'e par Quiller'e et al. dans [88]. A chaque 'etape de l'algorithme consiste `a :

1. intersecter chaque poly`edre de la liste avec le contexte correspondant au corps de boucle

actuel (pour ne scanner que la boucle consid'er'ee).

2. projeter les poly`edres obtenus sur la dimension la plus externe, puis de s'eparer chaque

projection en des poly`edres disjoints.

3. trier les poly`edres r'esultats de mani`ere `a ce qu'un poly`edre se retrouve avant un autre si

il doit ^etre scann'e avant ceux qui le suivent pour respecter l'ordre lexicographique.

4. fusionner les poly`edres successifs ayant au moins un un autre niveau de boucle pour g'en'erer

une nouvelle liste et pour g'en'erer r'ecursivement les boucles obtenues en scannant cette
nouvelle liste.

5. et enfin, calculer les strides que la dimension courante impose aux dimension externes.

D'ecrivons cet algorithme sur un exemple non-trivial, en scannant les deux domaines poly'edriques
pr'esent'es dans la Figure 7.6(a). Les deux instructions ont comme vecteur d'it'eration i "

`i

j

ae,

comme variables locales ilv " rks et comme param`etres globaux igp " rns.

- nous calculons d'abord l'intersection avec le contexte, `a ce point il ne faut consid'erer que

les contraintes sur les param`etre globaux. Nous avons suppos'e avoir la contrainte n e^ 6.
- nous projetons le poly`edre sur la premi`ere dimension i, puis nous s'eparons le r'esultat en

poly`edres disjoints. Cela signifie que nous construisons les domaines contenants les points
`a scanner du domaine DS1om seul, des deux domaines DS1om et DS2om, et de DS2om seul, comme
indiqu'e dans la Figure 7.6(b). Ce dernier domaine est vide.
- `a cette 'etape, nous remarquons la pr'esence d'une variable locale qui implique un stride

non unitaire. Nous d'eterminons alors ce stride et mettons `a jour la borne inf'erieure de la
boucle.
- Ensuite, nous g'en'erons le code obtenu en scannant la premi`ere dimension (celui correspondant aux boucles externes).
- il ne reste plus qu'`a r'ecursivement r'ep'eter le processus sur la prochaine dimension (dans cet

exemple, il y a maintenant deux listes `a traiter : une pour chaque boucle externe g'en'er'ee).
Nous intersectons les poly`edres avec le nouveau contexte (qui correspond au domaine des
boucles externes d'ej`a g'en'er'ees), puis projetons les r'esultats sur la dimension externe, pour
s'eparer ces projections en poly`edres disjoints. Cette derni`ere partie est triviale pour la
seconde liste, mais g'en`ere de nouveaux domaines pour la premi`ere liste comme indiqu'e
dans la Figure 7.6(c).
- finalement, nous g'en'erons le code associ'e `a cette nouvelle et derni`ere dimension.
La partie r'eclamant le plus de calcul dans l'algorithme est celle correspondant `a la s'eparation
en poly`edre disjoints. Pour une liste donn'ee de n poly`edres, nous devons calculer DS1om ' DS2om
(La partie du domaine correspondant `a l'instruction S1 seule), DS1om X DS2om (la partie du domaine
correspondant `a la fois `a S1 et `a S2) et DS2om ' DS1om (la partie du domaine correspondant `a

7.3. Notre algorithme de g'en'eration de code : CLooG 75

i
j

N
N

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

b
b
b
b
b
b

b
b
b
b

b
b

0 1 2 3 4 5 6 7
1
2
3
4
5 D

S1om :

$
&

%

1 d^ i d^ N
i " 2k ` 1
1 d^ j d^ N

DS2om :

$
&

%

1 d^ i d^ 6
i " 2k ` 1
1 d^ j d^ N ' i

(a) Domaine initial `a scanner

i
j

N
N

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

b
b
b
b
b
b

b
b
b
b

b
b

S1 et S2 S1

0 1 2 3 4 5 6 7
1
2
3
4
5

do i = 1, 6, 2DS

1om : t1 d^ j d^ N uD

S2om : t1 d^ j d^ N ' iu

do i = 7, N, 2D

S1om : t1 d^ j d^ N u

(b) Projection et s'eparation sur la premi`ere dimension

i
j

N
N

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

bc
bc
bc
bc
bc
bc
bc

b
b
b
b
b
b

b
b
b
b

b
b

0 1 2 3 4 5 6 7
1
2
3
4
5

do i = 1, 6, 2

do j = 1, N-i

S1
S2
do j = N-i+1, N

S1
do i = 7, N, 2

do j = 1, N

S1

(c) Projection et s'eparation sur la seconde dimension
Fig. 7.6 - M'ethode de g'en'eration par s'eparation

l'instruction S2 seule). Puis, il faut r'eit'er'e l'op'eration pour chaque poly`edre issue d'une 'eventuelle
instruction S3 et ainsi de suite. La complexit'e au pire de l'algorithme s'exprime ainsi en Op3nq
op'erations poly'edriques, ces op'erations 'etant elles-m^emes exponentielles. De plus, l'emprunte
m'emoire est tr`es importante du fait que nous devons allouer la m'emoire pour chaque nouveau
domaine issu de la s'eparation.

Impl'ementation : Cet algorithme a 'et'e impl'ement'e par C'edric Bastoul au sein de la biblioth`eque CLooG (Chunky Loop Generator). Il devait `a l'origine servir `a g'en'erer du code C au
sein du logiciel Chunky [11] d'optimisation pour la localit'e. Des pr'ecisions sont fournies sur

76 7. G'en'eration de code
les op'erations poly'edriques r'ealis'ees, et la forme des matrices dans le chapitre 20. CLooG est
capable de g'en'erer un contr^ole efficace pour l'ensemble des SCoPs pr'esents dans les benchmark
SPEC2000 [95], certains de ces SCoPs comportant plus de 1700 instructions.

7.4 Une 'evolution de l'algorithme : URGenT

Cette section pr'esente URGenT, une refonte de CLooG r'ealis'ee en collaboration avec Nicolas Vasilache. Il tire directement parti des propri'et'es du formalisme pr'esent'e dans la Partie III
pour r'eduire le nombre d'op'erations poly'edriques `a effectuer, et poss`ede donc une complexit'e
m'emoire beaucoup plus faible.

7.4.1 Modification des structures de donn'ees

Le probl`eme de la complexit'e m'emoire de CLooG est devenu une s'erieuse limitation avec
les tr`es longues s'equences de transformations. Particuli`erement, la multiplication des transformations de Peeling, de strip-mining, de permutation de boucles, et de d'eroulages a cr'e'e des
SCoPs de plusieurs milliers d'instructions avec des domaines et des fonction d'ordonnancement
complexes. La g'en'eration de ces SCoPs r'eclamait alors quelques gigaoctets de m'emoire.

Pour r'eduire l'emprunte m'emoire du g'en'erateur de code, ses structures de donn'ees sousjacentes ont 'et'e modifi'ees pour favoriser la repr'esentation sous forme de matrices plut^ot que
sous forme de poly`edres (un ensemble de vertices et de rayons). Cette derni`ere repr'esentation
'etant extr^emement gourmande en m'emoire. La conversion en poly`edre ne s'effectue plus qu'au

dernier moment, pour calculer les intersections et les diff'erences via la PolyLib, et le r'esultat de
ces calculs est reconverti sous forme matricielle.

Cette repr'esentation interne sous forme matricielle permet 'egalement de nouvelles optimisations sur les contraintes comme l''elimination gaussienne qui 'etaient impossible `a r'ealiser au
niveau des poly`edres. La Figure 7.7 pr'esente `a gauche une s'erie de contrainte, et `a droite le code
g'en'er'e en prenant en compte ces contraintes : une boucle est g'en'er'ee pour l'it'erateur j, alors
qu'une seule des it'erations de la boucle correspond effectivement `a une instance de l'instruction.
De plus, la contrainte du if 'etant d'ependante de l'it'erateur j, cette garde ne peut ^etre hoist'ee.

$
&

%

i ` j ' 2M ` 1 " 0

' j ` M e^ 0

j ' 1 e^ 0

for(j=1; j<=M ; j++)

if(j == -i +2M - 1)

S

Fig. 7.7 - G'en'eration sans 'elimination gaussienne

La Figure 7.8 pr'esente ces m^emes contraintes apr`es l''elimination gaussienne de la variable j,
et pr'esente sur la droite le code g'en'er'e qui peut ^etre produit `a partir de cette matrice. Il n'y a
plus de boucles, mais juste une instruction gard'ee.

$
&

%

i ` j ' 2M ` 1 " 0
i ' M ` 1 e^ 0
'i ` 2M ' 2 e^ 0

if( M-1 <= i && i <= 2M - 2)

S(j = -i + 2M - 1)

Fig. 7.8 - G'en'eration avec 'elimination gaussienne

7.4. Une 'evolution de l'algorithme : URGenT 77
7.4.2 Diminution du nombre d'op'erations poly'edriques

R'eduire le nombre d'op'erations poly'edriques signifie r'eduire le nombre d'intersection et de
diff'erences r'ealis'ees sur les poly`edres pour l'algorithme pr'esent'e dans la section 7.3.

L'outil CLooG peut ^etre utilis'e pour g'en'erer le code correspondant `a une repr'esentation
poly'edrique g'en'erique (avec les domaines repr'esent'es par des poly`edres, et possiblement des informations partielles sur l'ordonnancement comme celles impos'ees par les d'ependances de donn'ees). Notre formalisme, pr'esent'e dans la Partie III, assure un ordre total sur les instructions
avec des informations d'ordonnancement pr'ecises. Ces propri'et'es d'ordonnancement permettent
de d'eterminer, par une simple inversion de matrice, les r'esultats de certaines op'erations poly'edriques.

L'id'ee consiste `a tirer parti des deux propri'et'es suivantes : `a une profondeur donn'ee, les
domaines des instructions sont souvent, soit identiques (c'est une propri'et'e issue des instructions
situ'ees dans le m^eme nid de boucles dans le code d'epart), ou bien disjoints (c'est une propri'et'e
des codes s'equentiels). V'erifier ces propri'et'es avant d'effectuer les op'erations poly'edriques peut
donc permettre d'en d'eterminer le r'esultat et ainsi obtenir un gain significatif en termes de
performance.

Consid'erons l'exemple simple de la Figure 7.9. La g'en'eration de ce code par CLooG produit
toutes les projections et les intersections des domaines 'etendus des 4 instructions, et ce pour
chacun des niveaux de l'algorithme.

for i

S1
for j

S2
S3
S4

Fig. 7.9 - Code `a g'en'erer
Dans notre formalisme, Section 9.3, nous d'efinissons les vecteurs d'ordonnancement fi qui
permettent d'exprimer l'entrelacement des instructions aux diff'erentes profondeurs des nids de
boucles. Deux invariants du formalisme, pr'esent'es dans le Chapitre 10 assurent des propri'et'es
de s'equentialit'e et de densit'e sur ces vecteurs d'ordonnancement.

Les vecteurs d'ordonnancement correspondant `a l'exemple de la Figure 7.9 sont pr'esent'es
dans la figure 7.10. On d'enote les caract'eristiques suivantes : les vecteurs des instructions S1, S2
et S3 sont identiques `a la profondeur 0 (S1, S2 et S3 sont dans la m^eme boucle i) mais diff`erent
de celui de l'instruction S4. A la profondeur 1, les vecteurs des instructions S1, S2 et S3 diff`ere
indiquant leur entrelacement `a ce niveau.

fiS1 " 00 fiS2 " 01

0

fiS3 " 02 fiS4 " 1

Fig. 7.10 - Vecteurs d'ordonnancement
Au niveau de l'algorithme de projection et de s'eparation pr'esent'e dans la Section 7.3, ces
informations peuvent se traduire par :

- au premier niveau il suffit de consid'erer ensemble que les instructions S1, S2 et S3. Toute

intersection avec le domaine 'etendu de S4 sera forc'ement vide.
- au second niveau, les instructions S1, S2 et S3 peuvent ^etre consid'er'ees s'epar'ement, la

s'eparation 'etant d'ej`a garantie par leur fi1.

78 7. G'en'eration de code
Un g'en'erateur de code sp'ecialis'e pour notre formalisme peut donc, `a l'aide de simple comparaisons de vecteurs, 'eviter grand nombre de calculs poly'edriques correspondant `a des projections,
des intersections et des diff'erences dont le r'esultat serait l'ensemble vide, ou l'un des poly`edres
de d'epart.

Cette technique permet 'egalement de supprimer les informations correspondant aux vecteurs
d'ordonnancement des domaines 'etendus, r'eduisant ainsi le nombre de niveau `a projeter pour
une instruction `a la profondeur d de 2d ` 1 `a d.

Fusion de blocs `a la g'en'eration : `a un niveau donn'e, les instructions d'un nid de boucle sont
souvent caract'eris'ees par des domaines identiques et un ordonnancement purement s'equentiel.
Consid'erons par exemple la Figure 7.11. Les instructions S2, S3, S4 et S5 poss`edent exactement le
m^eme domaine, et leur ordonnancement est purement s'equentiel. La g'en'eration de code peut, au
lieu de consid'erer chacune de ces instructions s'epar'ement (et donc intersecter, projeter, s'eparer
entre eux leur domaines), consid'erer ces 4 instructions comme un bloc atomique pour ces phases
de projections / s'eparations.

for i

S1
for j

S2
S3
S4
S5

Fig. 7.11 - Possibilit'e de g'en'eration par blocs
Pour cela, juste avant la phase de s'eparation, nous introduisons un tri des instructions `a
traiter suivant les valeurs du vecteur d'ordonnancement pour ce niveau, puis ralisons la fusion
des instructions dont les domaines sont identiques en blocs. Ces blocs seront consid'er'es de fa,con
unitaire pour ce qui concerne les phases d'intersections / s'eparations.

Pour les SCoPs fortement transform'es par des shifts diff'erents sur chaque instruction de la
boucle (par exemple en vu de r'ealiser un pipeline logiciel), les instructions des boucles peuvent
perdre cette propri'et'e de "domaines identiques" et cette modification n'optimise pas l'algorithme.
Toutefois l'augmentation de la complexit'e de l'algorithme due au tri est n'egligeable dans ce cas.

7.4.3 Autres optimisations

Les derni`eres optimisations pr'esent'es dans cette section sont des fonctionnalit'es suppl'ementaires apport'ees au g'en'erateur de code. Il ne s'agit pas ici d'optimiser le g'en'erateur de code
lui-m^eme, mais le code produit par le g'en'erateur. Ces impl'ementations ont partiellement 'et'e
implant'ees au sein du g'en'erateur de code URGenT et partiellement au sein de notre outil
d'application des transformation URUK pr'esent'e dans la Chapitre 19.

D'eroulage complet : appliquer le d'eroulage complet au niveau du formalisme signifierait
multiplier la repr'esentation d'une instructions par le nombre de fois que le d'eroulage la duplique.
Pour 'eviter de proc'eder ainsi et maintenir une taille de repr'esentation raisonnable, y compris
dans un contexte de d'eroulage, nous avons associ'e aux instructions un vecteur de d'eroulage qui
indique, pour chaque dimension jusqu'`a la profondeur de l'instruction, si cette derni`ere doit ^etre
d'eroul'ee. Ainsi, le d'eroulage n'est pas r'ealis'e au niveau du formalisme, mais au niveau de la
g'en'eration de code. L'algorithme de d'eroulage est le suivant :

7.4. Une 'evolution de l'algorithme : URGenT 79

Pour un niveau donn'e, si toutes les instructions sont marqu'ees pour ^etre d'eroul'ee `a ce niveau,
le nombre d'occurrence entre la borne inf'erieure et la borne sup'erieure est calcul'ee. Si ce nombre
n'est pas param'etrique, le processus de d'eroulage est enclench'e et la branche correspondant `a
la boucle dans l'arbre de syntaxe est dupliqu'ee ce nombre de fois.

Boucles d'eg'en'er'ees : Plusieurs transformations, comme le d'eroulage ou le strip-mining ont
tendance `a cr'eer des boucles dont les bornes sont calcul'ees avec des divisions enti`eres, et qui
correspondent en fait `a des boucles d'eg'en'er'ees ex'ecut'ees 0 ou 1 fois. Ces boucles peuvent ^etre
transform'ees en simple if. La Figure 7.12 montre un exemple de boucle d'eg'en'er'ee transform'ee
en conditionnelle.

for (i=ceild(N-5, 7);i<=floord(N-1, 7);i++)

S1

if ( (N%7>?) (N%7<?) )

S1

Fig. 7.12 - Exemple de boucle d'eg'en'er'ee
Pour r'ealiser cette transformation, il est n'ecessaire de d'etecter de telles boucles. Cela est
r'ealis'e par r'esolution de probl`emes de programmation lin'eaire en nombres entiers gr^ace `a l'outil
Piplib [38].

Conditionnelles et bornes de boucles sup'erieures : Il est important dans le cadre des
bornes de boucles sup'erieures et des conditionnelles d''eviter au maximum les fonctions cr'eant des
structures de contr^ole plus complexes comme les fonctions min et max, ainsi que les divisions
enti`eres dont l'impl'ementation au sein des langages de programmation ne correspond pas `a la
d'efinition math'ematique.

Consid'erons par exemple les deux contraintes suivantes : 2i<=N et 3i<=M. La conditionnelle correspondante g'en'er'ee par CLooG serait i<=min(N/2,M/3). Nous avons modifi'e cela dans
URGenT pour que ce soit la conjonction (2i<=N && 3i<=M) qui soit g'en'er'ee, et que dans le cas
de pr'esence de divisions dans une expression, l'expression soit int'egralement multipli'ee par le
PPCM des diviseurs. Cela permet lorsqu'il est impossible de g'en'erer une conjonction de supprimer toute division.

80 7. G'en'eration de code81

Troisi`eme partie
Un Formalisme bas'e sur le Mod`ele

Poly'edrique

83
Dans cette partie, nous allons d'efinir notre formalisme permettant de repr'esenter les SCoPs,
les transformations de programmes et les compositions de celles-ci. Nous allons 'egalement pr'esenter les propri'et'es du formalisme permettant d'orienter la recherche de la s'equence de transformations optimisante vers la recherche d'une composition de transformations.

Formalisme et propri'et'es : La base de notre approche consiste `a s'eparer de fa,con claire les
quatre diff'erents types d'actions associ'ees aux transformations de programme : la modification du
domaine d'it'eration (bornes de boucles et pas de boucle), la modification de l'ordonnancement
des instructions, et la modifications des fonctions d'acc`es des tableaux (indices de tableaux,
structures des tableaux) en s'eparant ces composantes au niveau de la repr'esentation. Nous
repr'esentons ainsi, dans le Chapitre 9 chacune de ces composantes par une s'erie de matrices.

La compilation it'erative classique est g'en'eralement utilis'ee pour rechercher les param`etres
optimaux d'une s'equence de transformation fix'ee. Nous voulons 'etendre cette recherche aux
transformations elles-m^emes, l'espace de recherche sera donc gigantesque. Un ensemble d'invariants associ'es au formalisme, sp'ecifi'es dans le chapitre 10, permettent de normaliser notre
repr'esentation, r'eduisant la complexit'e de l'espace de recherche associ'e aux transformations,
sans entraver l'expressivit'e du formalisme.

Transformations et composition : l'effet des transformations de programme dans ce formalisme peut alors s'exprimer par une s'erie d'actions correspondant `a des op'erations matricielles
ind'ependantes sur ces composantes. Cette s'erie d'op'erations peut ^etre d'ecrite comme une composition de transformations plus 'el'ementaires d'ecrites dans le Chapitre 11, facilitant ainsi la
composition des transformations elles-m^emes.

La d'efinition de transformations par composition, facilite 'egalement la v'erification des invariants, les compositions de transformations respectent naturellement ces invariants si les transformations qui les composent les v'erifient. Le Chapitre 12 donne la repr'esentation de l'ensemble
des transformations usuelles dans notre formalisme, la plupart du temps d'efinies comme des
compositions de transformations plus 'el'ementaires, indiquant pour chacune d'elle les extensions
que notre formalisme a permis d'apporter par rapport `a la d'efinition classique des mod`eles
syntaxiques.

Les propri'et'es de commutativit'e et de confluence associ'ees aux transformations dans le Chapitre 14 facilite 'egalement la recherche de compositions et le formalisme permet aussi d'envisager
une approche alternative pour la recherche de compositions de transformations de programme,
en r'esumant cette recherche `a l'essai de diff'erentes valeurs pour les matrices des composantes.

Exemples d'utilisation : nous illustrons par deux exemples l'utilisation de notre formalisme :
le Chapitre 13 pr'esente un exemple concis et complet de l'utilisation du formalisme pour repr'esenter un SCoP, une s'equence de transformations d'eroul'ee 'etape par 'etape, et illustre l'int'er^et
des invariants. Le Chapitre 15, montre que l'impl'ementation de ce formalisme est capable d'optimiser des applications r'eelles en pr'esentant l'optimisation du benchmark swim des SpecFP
2000.

84 85
Chapitre 8
Notations

Dans ce chapitre, nous d'efinissons les notations usuelles utilis'ees par notre formalisme, et
proposons un glossaire des notations d'efinies dans le formalisme. A chaque notation est associ'ee
une r'ef'erence vers la section du formalisme la d'efinissant.

8.1 Notations usuelles
Notations vectorielles

~0d repr'esente le vecteur nul de dimension d. (~02 "

`0

0

ae)

~1d repr'esente le d-i`eme vecteur unit'e de l'espace de dimension d. (~12 "

`0

1

ae)

v1 , v2 repr'esente la concat'enation des vecteurs v1 et v2.
dimpvq repr'esente la dimension du vecteur v.
gcdpvq repr'esente le PGCD des coefficients non nuls du vecteur v.
pref ixpv, lq repr'esente le vecteur correspondant aux l premiers 'el'ements de v.
u D^ v indique que le vecteur u est un pr'efixe du vecteur v. (D` | u " pref ixpv, `q)
u A* v indique que le vecteur u est un pr'efixe strict du vecteur v. (u D^ v ^ u 0 v)
enclosepvq repr'esente le vecteur v priv'e de son dernier 'el'ement.
enclosepv, lq repr'esente le vecteur v priv'e de ses l derniers 'el'ements.

Notations matriciellesId

pdq repr'esente la matrice identit'e de dimension d. (Idp2q "

` 1 0

0 1

ae)

dim rowpM q repr'esente le nombre de lignes de la matrice M .
dim colpM q repr'esente le nombre de colonnes de la matrice M .

8.2 Glossaire des notations du formalisme
It'erateurs et Dimensions Section 9.1i

gp Param`etres globaux du SCoP.iS Vecteur d'it'eration de l'instruction

S.

iSlv Variables locales de l'instruction S.
dgp Nombre de param`etres globaux.
dS Nombre d'it'erateurs de l'instruction S (profondeur de l'instruction S).
dSlv Nombre de variables locales de l'instruction S (pour les divisions et les modulos)

86 8. Notations
Domaines d'it'erations Section 9.2DS

om Domaine d'it'erations de l'instruction S.\Lambda S Ensemble des matrices des domaines de l'instruction S.

Ordonnancement Section 9.3SS

ch Fonction d'ordonnancement associ'ee `a l'instruction S.\Theta S Matrice d'ordonnancement de l'instruction S.

AS Matrice d'ordonnancement des it'erations de l'instruction S.
\Gamma S Matrice d'ordonnancement param'etrique de l'instruction S.
fiS Vecteur d'ordonnancement de l'instruction S.

Acc`es Section 9.4ST Vecteur indiquant les tailles de chaque dimension du tableau T .

LShs Liste des acc`es associ'ee au membre gauche de l'instruction S.R

Shs Liste des acc`es associ'ee au membre droit de l'instruction S.

Invariants Chapitre 10

fimaxpP q Valeur m maximum telle que P ,m soit un fi-pr'efixe d'une instruction du SCoP.

87
Chapitre 9
D'efinitions du formalisme

Nous venons dans le chapitre pr'ec'edent de d'efinir comment nous d'ecomposions le programme
en parties `a contr^ole statique. D'efinissons maintenant le formalisme n'ecessaire `a la repr'esentation
d'un SCoP et des instructions qui le composent.

9.1 It'erateurs et dimensions

Notre formalisme stocke les informations relatives `a chaque instruction d'un SCoP. Commen,cons par d'efinir les vecteurs correspondant aux param`etres d'un SCoP et aux it'erateurs relatifs
`a chaque instruction.

SCoP & Param`etres globaux : Une des parties `a contr^ole statique extraite de l'arbre
de syntaxe du compilateur est une paire pSCoP, igpq, o`u SCoP est un ensemble d'instructions
cons'ecutives -- dans leur repr'esentation poly'edrique -- et igp le vecteur des param`etres globaux
du SCoP. dgp " dimpigpq est le nombre de param`etres globaux.

Profondeur & Vecteur d'it'erations : La profondeur dS d'une instruction S correspond
au nombre de boucles englobant l'instruction S dans le SCoP. Le vecteur d'it'erations iS de
dimension dS de l'instruction S appartenant au SCoP est compos'e des it'erateurs englobant
l'instruction S.

Variables locales : Les variables du vecteur iSlv sont locales `a l'instruction S, et permettent
l''ecriture de modulos et de divisions enti`eres sous forme d''equations affines (Une description
d'etaill'ee sera donn'ee dans la section 9.2). En l'absence de ces modulos / divisions dans le
contr^ole du programme, le vecteur iSlv est vide. dSlv est la dimension du vecteur iSlv.

Exemple : L'exemple ci-dessous illustre sur un SCoP la valeur de ces diff'erents vecteurs et
celles des dimensions correspondantes.

for (i=1; i<M; i++)
(S1) A[i]=0;

for (j=1; j<N; j++)
(S2) A[i] += Z[i][j] * X[j];
(S3) b = Z[i][j] * Z[j][i]

if (k<l)
(S4) c = X[j] * X[P-j]

else
(S5) c = 0

igp "

>>
-

M

N

P

fi
fl

iS1 "

"i0 dS1

" 1

@k P r2, 5s, iSk "

"i

j

j

dSk " 2

@k P r1, 5s, iSklv " rs dSklv " 0

88 9. D'efinitions du formalisme
D'efinition : Une instruction S P SCoP est d'efinie par un quadruplet pDSom, LShs, RShs, SSchq, dont
les quatre composantes sont repr'esent'ees poly'edriquement. DSom est le domaine d'it'erations de
l'instruction S, LShs et RShs les r'ef'erences aux tableaux de S, et SSch est l'ordonnancement affine
de S.

9.2 Domaines d'it'erations

Le domaine d'it'erations d'efinit, pour chaque instruction, l'ensemble des valeurs pouvant
^etre prises `a l'ex'ecution par les it'erateurs de boucles englobants. Dans le cadre des SCoPs, cet

ensemble de valeurs peut ^etre repr'esent'e par un syst`eme d'in'equations affines repr'esentant les
contraintes impos'ees par les bornes des boucles et les conditionnelles englobant l'instruction
consid'er'ee.

L'exemple ci-dessous associe `a chaque instruction du source de gauche, le syst`eme d'in'equations correspondant `a ces contraintes :

for (i=1; i<M; i++)

S1
for (j=1; j<N; j++)

S2
for (k=1; k<P; k++)

for (l=1; l<Q; l++)

S3
S4
if (k<l)

S5
else

S6

DS1om " t i e^ 1, i a* M uD

S2om " t i e^ 1, i a* M, j e^ 1, j a* N uD

S3om " t k e^ 1, k a* P, l e^ 1, l a* Q uD
S4om " t k e^ 1, k a* P, l e^ 1, l a* Q uD
S5om " t k e^ 1, k a* P, l e^ 1, l a* Q, k a* l uD
S5om " t k e^ 1, k a* P, l e^ 1, l a* Q, k e^ l u

Comme les instructions S1 et S2 appartiennent `a la m^eme boucle externe i, leurs domainesD
S1om et DS2om partagent les m^emes contraintes relatives `a cet it'erateur. La profondeur de S2

'etant plus importante que celle de S1, DS2om poss`ede des contraintes suppl'ementaires relatives

`a l'it'erateur j. Les instructions S3 et S4, elles, se situent `a la m^eme profondeur dans le m^eme
corps de boucle, leur domaine DS3om et DS4om sont donc identiques.

Pour chacune des instructions du code, les in'equations des domaines d'it'erations de chaque
instruction forment un poly`edre convexe. Les points entiers situ'es `a l'int'erieur de ce poly`edre
repr'esentent les valeurs possibles prises par les it'erateurs englobants. Par exemple, pour les
quatre instructions S1, S2, S3 et S4 les poly`edres sont les suivants :

Domaine d'it'erations

de S1

i

j

M
N

b b b b b

b b b b b
b b b b b
b b b b b
b b b b b

0 1 2 3
1
2
3

Domaine d'it'erations

de S2

i

j

M
N

b b b b b
0 1 2 3
1
2
3

Domaine d'it'erations

de S3 et S4

k

l

P
Q

b b b b b

b b b b b
b b b b b
b b b b b
b b b b b

0 1 2 3
1
2
3

Les instructions S5 et S6 situ'ees dans les boucles k, l sont 'egalement englob'ees par une
conditionnelle, S5 'etant dans le then et S6 dans le else. Les domaines d'it'erations DS5om et DS6om
sont donc identiques en ce qui concerne les contraintes relatives aux bornes de k et de l, et

9.2. Domaines d'it'erations 89
compl'ementaires par rapport `a la conditionnelle pk a* lq. Les poly`edres correspondant `a leur
domaine d'it'erations sont donc les deux poly`edres triangulaires compl'ementaires suivants :

Domaine d'it'erations

de S5

k

l

P
Q

b b b b

b b b
b b
b

0 1 2 3
1
2
3

Domaine d'it'erations

de S6

k

l

P
Q

b

b b
b b b
b b b b
b b b b b

0 1 2 3
1
2
3

Bornes de boucles 'etendues : dans la section 5.5, nous avions montr'e qu'il 'etait possible,
par des techniques de r'e'ecriture sous forme de conjonctions, de consid'erer qu'une borne inf'erieure
de boucle utilisant la fonction max 'etait affine, ainsi qu'une borne sup'erieure utilisant la fonction
min. Illustrons cela par exemple de domaine sur un tel code :

for (i=max(M,N); i<min(P,Q); i++)

S1
S2 D

S1om " DS2om " t i e^ M, i e^ N, i a* P, i a* Q u

Disjonctions : jusque l`a, les syst`emes correspondant aux domaines d'it'erations sont des
conjonctions d'in'equations affines. S'il est naturel que les contraintes impos'ees par les bornes
de boucles soient des conjonctions du fait qu'elles d'efinissent un intervalle (souvent dense), les
contraintes relatives aux conditionnelles, elles, peuvent facilement introduire des disjonctions.
Consid'erons l'exemple suivant :

if (M>N) || (P>Q)

S1
if (M<=N) && (P<=Q)

S2
else

S3
if (M!=N)

S4

DS1om " t M a, N, u Y t P a, QuD

S2om " t M d^ N, P d^ QuD

S3om " t M a, N, u Y t P a, QuD
S4om " t M a, N, u Y t M a* N u

Les instructions S3 et S4 de l'exemple ci-dessus s'ex'ecutent dans les m^emes conditions (M a,
N ou P a, Q), leurs domaines sont donc identiques et correspondent `a une union de syst`emes
d'in'equations affines. Le domaine de l'instruction S3 situ'e dans le else, est calcul'e en prenant
l'oppos'e de la conditionnelle qui est une conjonction. Le r'esultat est donc une nouvelle fois une
union de syst`emes d'in'equations affines.

Enfin, les 'egalit'es et les in'egalit'es sont elles aussi repr'esent'ees sous la forme d'in'equations. En
effet, l''egalit'e M " N peut tr`es simplement se r'e'ecrire `a l'aide du syst`eme t M d^ N, M e^ N u.
Par contre, l'in'egalit'e se r'e-'ecrit `a l'aide d'une disjonction, comme pour l'instruction S4, o`u
M 0 N se transforme en t M a, N, u Y t M a* N u.

Strides et Modulos : L'utilisation de disjonctions n'est pas toujours la solution la plus
adapt'ee. Consid'erons par exemple une boucle i de N it'erations contenant une instruction S ne
s'ex'ecutant que pour des valeurs paires de i. Il n'est pas raisonnable d''ecrire le domaine de cette
instruction sous la forme d'une union de N {2 syst`emes. Consid'erons l'exemple suivant :

90 9. D'efinitions du formalisme

for (i=1; i<M; i++))

for (j=1; j<M; j++))

S1
for (i=1; i<M; i++))

for (j=1; j<M; j+=2))

S2
for (i=1; i<M; i++))

for (j=1; j<M; j++))

if(j%2==1)

S3

DS1om " t i e^ 1, i a* M, j e^ 1, j a* M uD

S2om " t i e^ 1, i a* M, j e^ 1, j a* M, j mod 2 " 1 uD

S3om " t i e^ 1, i a* M, j e^ 1, j a* M, j mod 2 " 1 u

Les domaines DS2om et DS3om des instructions S2 et S3 sont identiques. Le stride et le modulo
sont donc similaires. Ces domaines ne sont cependant pas des syst`emes affines `a cause du modulo.'

Etudions les poly`edres repr'esentant le domaine des instructions S2 et S3 :

Domaine d'it'erations

de S1

i

j

M
M

b b b b b

b b b b b
b b b b b
b b b b b
b b b b b

0 1 2 3
1
2
3

Domaine d'it'erations

de S2 et S3

i

j

M
M

b b b b b

b b b b b
b b b b b
0 1 2 3
1
2
3

Le poly`edre de droite (celui correspondant au domaine de S2 et S3 est semblable au poly`edre
de gauche, si ce n'est qu'un point sur deux est conserv'e sur la dimension j.

Comme indiqu'e dans la section 9.1, cela peut s'exprimer en ajoutant une dimension k, libre
de toute autre contrainte que j " 2 * k. On obtient alors un poly`edre `a trois dimensions qui,
dans les plans de projection pi, jq, pi, kq et pj, kq ressemble `a :

Domaine d'it'erations

de S2 et S3

i

j

M
M

b b b b b

b b b b b
b b b b b
0 1 2 3
1
2
3

Domaine d'it'erations

de S2 et S3

k

j

M
M

ji

2k

\Gamma 

1

b
b
b
0 1 2 3
1
2
3

9.2.1 D'efinition formelle

Le domaine d'it'erations DSom d'une instruction S P SCoP est une union de poly`edres convexes
d'efinie par un ensemble \Lambda S de matrices \Lambda Sk P Mnk,dS`dSlv`dgp`1pZq telles que :

i P DSom dhn~

$
''
&

''
%

D\Lambda Si P \Lambda S | \Lambda Si "

>>
--
--
-

iS
iSlv
igp

1

fi
ffi
ffi
fl e^ 0

,
//
.

//
-

9.2. Domaines d'it'erations 91

Le nombre nk correspond au nombre de contraintes encod'ees dans la matrice \Lambda Sk , et n'est
pas limit'e. Le vecteur colonne est construit par concat'enation des vecteurs colonnes iS et iSlv
(repr'esentant les it'erateurs et les variables locales de l'instruction S) et du vecteur colonne igp
qui repr'esente les param`etres globaux du SCoP.

Exemple : Illustrons sur un exemple les valeurs prises par ces matrices \Lambda . Le code ci-dessous
illustre les diff'erents cas mis en avant pr'ec'edemment : conditionnelle, minimum et disjonction. Les
'equations et in'equations des domaines ont 'et'e normalis'ees sous la forme comparaison sup'erieure

non-stricte.

for (i=2; i<=in(M,N); i+=2)

S1
S2
for (k=1; k<M; k++)

for (l=1; l<N; l++)

S3
if (k==l)

S4
else

S5

DS1om " t i e^ 1, M e^ i , N e^ i, i e^ 2 * p , 2 * p e^ i uD

S2om " t uD

S3om " t k e^ 1, M ' 1 e^ k, l e^ 1, N ' 1 e^ l uD
S4om " t k e^ 1, M ' 1 e^ k, l e^ 1, N ' 1 e^ l, k e^ l , l e^ k u

DS5om " Y

"

t k e^ 1, M ' 1 e^ k, l e^ 1, N ' 1 e^ l, l e^ k ` 1 u

t k e^ 1, M ' 1 e^ k, l e^ 1, N ' 1 e^ l, k e^ l ` 1 u

*

Les param`etres globaux de ce programme sont igp " rM, N s. Les ensembles de matrices
correspondant `a ces domaines sont les suivants :

\Lambda S1 "

$
''
''
&

''
''
%

i p M N 11 0 0 0

'1
'1 0 1 0 0
'1 2 0 0 11

'2 0 0 '1

,
//
//
.

//
//
-

\Lambda S2 " H

\Lambda S3 "

$
''
''
&

''
''
%

k l M N 11 0 0 0

'1
'1 0 1 0 '10 1 0 0

'10
'1 0 1 '1

,
//
//
.

//
//
-

\Lambda S4 "

$
''
''
''
'&

''
''
''
'%

k l M N 11 0 0 0

'1
'1 0 1 0 '10 1 0 0

'10
'1 0 1 '1
'1 1 0 0 01

'1 0 0 0

,
//
//
//
/.

//
//
//
/-

\Lambda S5 "

$
''
''
'&

''
''
'%

k l M N 11 0 0 0

'1
'1 0 1 0 '10 1 0 0

'10
'1 0 1 '1
'1 1 0 0 '1

,

k l M N 11 0 0 0

'1
'1 0 1 0 '10 1 0 0

'10
'1 0 1 '11
'1 0 0 '1

,
//
//
/.

//
//
/-

En multipliant \Lambda S31 par

^
__
*

k

l
M

1

o/
OEOE
AE, on obtient toutes les in'equations pr'esentent dans DS3om.

Exemple de transformations : Les transformations ne modifiant que les domaines d'it'erations des instructions peut maintenant s'exprimer comme une s'erie d'op'erations sur la matrice
\Lambda . La transformation d''epluchage (Peel) par exemple consistera `a partir d'une instruction S de
cr'eer deux instructions S1 et S2 copies de S, avec l'ajout de la contrainte de peeling pour l'une
d'elle, et de son contraire pour l'autre.

92 9. D'efinitions du formalisme

La transformation de strip-mining (StripMine) est 'egalement principalement une transformation de domaine, mais elle a des aussi des effets cosm'etiques sur les autres composantes du
formalisme du fait de l'ajout du nouvel it'erateur.

Toutes ces transformations sont d'ecrites pr'ecis'ement dans le Chapitre 11.

9.3 Ordonnancement

Avec le domaine d'it'erations de l'instruction S, nous avons d'efini l'ensemble des valeurs
pouvant ^etre prises `a l'ex'ecution par les it'erateurs de boucles englobants, sans d'efinir l'ordre
dans lequel ces valeurs seraient prises.

L'ordonnancement d'efinit l'ordre d'ex'ecution s'equentiel des it'erations de S. Revenons `a
l'exemple de d'epart de la section pr'ec'edente, et aux repr'esentations sous forme de poly`edres
des domaines. Ci-dessous sont repr'esent'es les domaines des instructions S1 et S6.

for (i=1; i<M; i++)

S1
for (j=1; j<N; j++)

S2
for (k=1; k<P; k++)

for (l=1; l<Q; l++)

S3
S4
if (k<l)

S5
else

S6 Domaine d'it'erations

de S3 et S4

k

l

P
Q

b b b b b

b b b b b
b b b b b
b b b b b
b b b b b

0 1 2 3
1
2
3

Domaine d'it'erations

de S6

k

l

P
Q

b

b b
b b b
b b b b
b b b b b

0 1 2 3
1
2
3

Sur le poly`edre correspondant `a l'instruction S, on peut d'ecrire l'ordonnancement des instances de l'instruction S entre elles de la mani`ere suivante :

Ordre d'ex'ecution

de S3 et S4

k

l

P
Q

b b b b b

b b b b b
b b b b b
b b b b b
b b b b b

0 1 2 3
1
2
3

Ordre d'ex'ecution

de S6

k

l

P
Q

b

b b
b b b
b b b b
b b b b b

0 1 2 3
1
2
3

Il s'agit d'indiquer, que pour les instances de l'instruction S3 par exemple, que ces instances
sont ex'ecut'ees par ordre croissant de l puis de k.

Il faut 'egalement fournir les informations permettant de d'efinir l'ordonnancement des instructions entre elles. Pour indiquer par exemple que dans la seconde paire de boucle, les instances
de l'instruction S3 sont avant celles de S4 pour un m^eme vecteur d'ordonnancement i, c'est `a
dire pour une m^eme valeur de la paire pk, lq.

Feautrier [41], puis Kelly et Pugh [53], ont propos'e une mani`ere de repr'esenter l'ordre d'ex'ecution des instances de chaque instruction, capable de g'erer les sections de code correspondant
`a des nids de boucles non-parfaits. Nous utilisons une repr'esentation similaire dans nos SCoPs :
Le principe consiste `a d'efinir une date d'ex'ecution pour chaque instance d'une instruction, cette
date 'etant fonction du vecteur d'it'eration i.

9.3. Ordonnancement 93

Nous utilisons des dates d'ex'ecutions de dimension 2 ^ d ` 1 pour permettre de dissocier l'ordonnancement d^u aux it'erateurs et l'ordonnancement s'equentiel des instructions. Cela permettra
de faciliter grandement le travail du g'en'erateur de code.

Pour chaque instruction, le formalisme d'efinit une fonction multidimensionnelle d'ordonnancement Sch qui caract'erise l'ordonnancement de la mani`ere suivante : l'instance i1 de l'instruction
S1 s'ex'ecute avant l'instance i2 de l'instruction S2 si et seulement si

SS1ch pi1q ! SS3ch pi2q
Les dimensions de la fonction Sch entrelacent ordonnancement sur les it'erations (qui servent `a
indiquer par exemple que S3pk " 5, l " 2q s'ex'ecute apr`es S3pk " 5, l " 1q), et ordonnancement
s'equentiel (qui servent `a indiquer par exemple que S3pk " 2, l " 2q s'ex'ecute avant S4pk "
2, l " 2q).

La premi`ere dimension correspond `a l'ordre s'equentiel pour la dimension 0 (le corps du
programme). La seconde dimension correspond `a l'ordonnancement des it'erations des boucles
externes (i et k) et la troisi`eme indique l'ordre s'equentiel dans ces boucles externes. La quatri`eme
et la cinqui`eme dimensions de Sch expriment l'ordonnancement (des it'erations et s'equentiel) des
boucles de profondeur 2. Et ainsi de suite jusqu'`a la profondeur de l'instruction.

Ci-dessous sont repr'esent'ees les valeurs prises par ces fonctions d'ordonnancement Sch pour
chacune des instructions de l'exemple :

SS1ch prisq " 0i

0 S

S2ch

^"i

j

j.

"

0

i1

j
0

SS3ch

^"k

l

j.

"

1
k0

l0

SS4ch

^"k

l

j.

"

1
k0

l1 S

S5ch

^"k

l

j.

"

1
k0

l2 S

S6ch

^"k

l

j.

"

1
k0

l3

Les instructions S1 et S2 appartiennent `a la premi`ere boucle externe du programme (la
boucle i), mais S2 se situe dans la sous-boucle j. Les fonctions SS1ch et SS2ch sont donc identiques
sur leurs 2 premi`eres dimensions, et divergent ensuite indiquant que pour une m^eme instance de
i, S2 s'ex'ecute apr`es S1 (`a la troisi`eme dimension, il y a un 1 pour S2 et un 0 pour S1).

Les instructions S3, S4, S5 et S6 quant `a elles, se situent dans la seconde boucle externe (la
boucle k), ainsi que dans la sous-boucle l. Donc SS1ch et SS3ch divergent d`es la premi`ere dimension,
indiquant que la seconde boucle externe s'ex'ecute apr`es la premi`ere, et les fonctions SS3ch , SS4ch ,S

S5ch et SS6ch sont identiques sauf sur la derni`ere dimension qui donne l'ordre d'ex'ecution de ses

instructions dans la sous-boucle l.

9.3.1 D'efinition formelle :

L'ordonnancement d'une instruction S P SCoP s'exprime `a l'aide de la matrice d'ordonnancement \Theta S P M2^dS`1,dS`dgp`1pZq, telle que :

SSchpiq " \Theta S ^

>>
- iigp

1

fi
fl

94 9. D'efinitions du formalisme

Le fait que l'instance i1 de l'instruction S1 s'ex'ecute avant l'instance i2 de l'instruction S2
s''ecrit alors :

SS1ch pi1q ! SS3ch pi2q dhn~ \Theta S1 ^

>>
- i

1i

gp1

fi
fl ! \Theta S3 ^

>>
- i

2i

gp1

fi
fl

Les premi`eres colonnes de la matrice \Theta  (celles multipli'ees par i) permettent d'indiquer les
relations d'ordonnancement pour chacun des it'erateurs, celles correspondant aux param`etres
globaux permettront de d'ecrire des r'e-ordonnancement param'etriques, la derni`ere colonne (multipli'ee par la constante 1) permet l'ordonnancement relatif des instructions `a une profondeur
donn'ee.

Les matrices \Theta S correspondant aux fonctions d'ordonnancement SSch pr'ec'edentes sont :

\Theta S1 "

i M N P Q 10 0 0 0 0 0
1 0 0 0 0 00 0 0 0 0 0 \Theta S2 "

i j M N P Q 10 0 0 0 0 0 0
1 0 0 0 0 0 00 0 0 0 0 0 1
0 1 0 0 0 0 00 0 0 0 0 0 0

\Theta S3 "

k l M N P Q 10 0 0 0 0 0 1
1 0 0 0 0 0 00 0 0 0 0 0 0
0 1 0 0 0 0 00 0 0 0 0 0 0 \Theta 

S4 "

k l M N P Q 10 0 0 0 0 0 1
1 0 0 0 0 0 00 0 0 0 0 0 0
0 1 0 0 0 0 00 0 0 0 0 0 1

\Theta S5 "

k l M N P Q 10 0 0 0 0 0 1
1 0 0 0 0 0 00 0 0 0 0 0 0
0 1 0 0 0 0 00 0 0 0 0 0 2 \Theta 

S6 "

k l M N P Q 10 0 0 0 0 0 1
1 0 0 0 0 0 00 0 0 0 0 0 0
0 1 0 0 0 0 00 0 0 0 0 0 3

D'ecomposition it'eration / s'equentiel : On retrouve la m^eme d'ecomposition que pour
la fonction SSch dans la matrice \Theta S : la premi`ere ligne de la matrice \Theta S correspond `a l'ordre
s'equentiel dans le corps du programme. La seconde ligne de la matrice \Theta S correspond `a l'ordonnancement des it'erations `a la profondeur 1 (le premier niveau de boucle). La troisi`eme ligne de
la matrice \Theta S correspond `a l'ordonnancement s'equentiel `a la profondeur 1. La quatri`eme et la
cinqui`eme ligne de la matrice \Theta S expriment l'ordonnancement (des it'erations et s'equentiel) des
boucles de profondeur 2. Et ainsi de suite jusqu'`a la profondeur de l'instruction dS.

Les lignes paires (en commen,cant la num'erotation `a 0) de la matrice \Theta S repr'esentent l'ordonnancement s'equentiel. Elles s'expriment sans l'aide des it'erateurs. Les lignes impaires de
la matrice repr'esentent l'ordonnancement inter-it'eration. Ce dernier s'exprime naturellement `a
l'aide des it'erateurs et des param`etres globaux du SCoP.

Nous avons donc d'ecompos'e la matrice \Theta  suivant la parit'e de ces lignes, et n'avons conserv'e
pour les lignes repr'esentant l'ordonnancement s'equentiel que la derni`ere colonne. La matrice \Theta 

9.3. Ordonnancement 95
se d'ecompose donc en une matrice \Phi  et un vecteur colonne fi de la mani`ere suivante :

\Theta  "

>>
--
--
--
--
--
--
--
--
--
-

0 " " " 0 fi0
\Phi 1,1 " " " \Phi 1,d'1 \Phi 1,d

0 " " " 0 fi1
\Phi 2,1 " " " \Phi 2,d'1 \Phi 2,d.

.. . . . ... ...

\Phi d,1 " " " \Phi d,d'1 \Phi d,d

0 " " " 0 fid

fi
ffi
ffi
ffi
ffi
ffi
ffi
ffi
ffi
ffi
fl

Le vecteur fiS, qui refl`ete la s'equentialit'e des instructions, est appel'e vecteur d'ordonnancement de l'instruction S. C'est un vecteur colonne de dimension d ` 1. La matrice \Phi  PM

dS,dS`dgp`1pZq va, elle-m^eme ^etre d'ecompos'ee.Int'eressons nous par exemple `a la d'ecomposition de \Theta 

S5 en \Phi S5 et fiS5 :

\Theta S5 "

k l M N P Q 10 0 0 0 0 0 1
1 0 0 0 0 0 00 0 0 0 0 0 0
0 1 0 0 0 0 00 0 0 0 0 0 2

fiS5 " 10

2

\Phi S5 "

k l M N P Q 11 0 0 0 0 0 0

0 1 0 0 0 0 0

D'ecomposition it'eration / param`etre : Les premi`eres colonnes de la matrice \Phi  correspondent `a i (les it'erateurs). Les colonnes suivantes correspondent `a igp (les param`etres globaux).
Enfin, la derni`ere colonne (1) correspond `a la composante affine.

Nous avons donc d'ecompos'e verticalement la matrice \Phi  en deux matrices, l'une portant exclusivement sur les it'erateurs, et la seconde portant sur les param`etres globaux et la composante
affine. Le d'ecoupage est le suivant :

\Phi  "

>>
--
--
--
-

A1,1 " " " A1,d \Gamma 1,1 " " " \Gamma 1,dgp
A2,1 " " " A2,d \Gamma 2,1 " " " \Gamma 1,dgp.

.. . . . ... ... . . . ...

Ad,1 " " " Ad,d \Gamma d,1 " " " \Gamma 1,dgp

fi
ffi
ffi
ffi
fl

La matrice carr'ee A P MdS,dS pZq est appel'ee matrice d'ordonnancement des it'erations. La
matrice \Gamma  P MdS,dgp`1pZq est appel'ee matrice d'ordonnancement param'etrique.

Ci-dessous, la d'ecomposition de la matrice \Phi S5 en AS5 et \Gamma S5 :

\Phi S5 "

k l M N P Q 11 0 0 0 0 0 0

0 1 0 0 0 0 0

AS5 "

k l1 0

0 1 \Gamma 

S5 "

M N P Q 10 0 0 0 0

0 0 0 0 0

A partir de maintenant, l'ordonnancement de l'instruction S sera exprim'e `a l'aide des matrices AS, \Gamma S et du vecteur fiS.

96 9. D'efinitions du formalisme
Construction : Nous allons maintenant d'efinir la mani`ere dont les vecteurs et matrices AS,
\Gamma S et fiS sont extraites de l'arbre de syntaxe du compilateur. Ces vecteurs et matrices seront
par la suite modifi'es par les transformations de codes ayant un impact sur l'ordonnancement
(comme les transformations unimodulaires, la fusion ou la fission de boucle).

Avant d'appliquer toute transformation, les it'erateurs des boucles `a g'en'erer sont identiques
aux it'erateurs du code de d'epart. La matrice d'ordonnancement AS de chaque instruction S
extraite de l'arbre de syntaxe est donc initialis'ee `a la matrice identit'e de dimension dS.

Pour chaque instruction S de l'arbre de syntaxe, la matrice d'ordonnancement param'etrique
\Gamma S est initialis'ee `a matrice nulle de dimension dS par dgp ` 1. Comme indiqu'e lors de la d'efinition
de \Theta S, les colonnes correspondant aux param`etres globaux ne sont pr'esentes que pour permettre
aux transformations d'ordonnancement d'avoir des arguments param'etriques.

Enfin, le vecteur d'ordonnancement fiS de l'instruction S est directement li'e `a la positon de
l'instruction S dans l'arbre de syntaxe du SCoP : consid'erons l'arbre de syntaxe T correspondant
au SCoP, l'instruction S est situ'ee dans cet arbre `a la profondeur d. Pour chaque noeud N de
profondeur k travers'e lors du parcours de l'arbre depuis la racine jusqu'au noeud S, La valeur
fiSk correspond `a l'indice du noeud N dans son noeud parent (en commen,cant la num'erotation
`a 0).

Par exemple consid'erons le petit code suivant, et son arbre de syntaxe correspondant :

for (i=1; i<M; i++)

S1
S2
for (k=1; k<P; k++)

S3
for (l=1; l<Q; l++)

S4
S5

for i S2 for k

S1 S3 for l

S4 S5

0 1 2
0 0 1

0 1

Le vecteur d'ordonnancement fiS4 vaut

^
*21

0

o/
AE car l'instruction S4 se trouve dans la troisi`eme

boucle/instruction du corps de programme, que dans cette boucle (k) elle se situe dans la
deuxi`eme boucle/instruction, et que dans cette derni`ere boucle (l), c'est la premi`ere instruction.

Exemple de transformations : Il existe de nombreuses transformations d'ordonnancement,
que l'on peut regrouper en trois cat'egories :

Les transformations unimodulaires s'appliquent directement en multipliant les lignes impaires
de la matrice \Theta  (celles correspondant `a A " \Gamma ) par la matrice unimodulaire de la transformation.
Par exemple, la permutation de boucle permute deux lignes de la matrice \Theta .

Les transformations de retardement et avancement s'expriment gr^ace `a une transformation
de d'ecalage (Shift) qui s'exprime en additionnant la valeur de ce d'ecalage `a la matrice param'etrique \Gamma .

Les transformations de d'eplacement de code, comme la fission de boucle (Fission) ou la
fusion de boucle (Fuse) s'exprimeront directement sur les vecteurs d'ordonnancement fi des
instructions concern'ees.

Toutes ces transformations sont d'ecrites pr'ecis'ement dans le Chapitre 11.

9.4. Liste des Acc`es 97
9.4 Liste des Acc`es

La modification des domaines et de l'ordonnancement des instructions n'est pas la seule
technique utilis'ee lors de l'optimisation d'un programme. Les hi'erarchies m'emoires complexes
des architectures font de l'optimisation des acc`es aux tableaux une phase clef de l'optimisation
de code. C'est d'autant plus exact sur les codes scientifiques qui manipulent souvent de larges
tableaux multidimensionnels.

Une analyse approfondie des tableaux et des valeurs scalaires est 'egalement n'ecessaire pour
la v'erification des d'ependances de donn'ees, qui peuvent facilement ^etre viol'ees par les transformations de r'e-ordonnancement.

Commen,cons par introduire un court exemple 'ecrit en C de SCoP manipulant des tableaux
et des scalaires :

int A[512], Z[600][700];
for (i=1; i<M; i++)
(S1) A[i]=0;

for (j=1; j<M; j++)
(S2) A[i] += Z[M-i][j+1];
(S3) b += Z[i][j] * Z[j][i];

A est un tableau de dimension 1,
Z est un tableau de dimension 2,
b est un scalaire.

Pour chaque instruction, nous consid'erons son membre gauche et son membre droit. Le
membre gauche d'une affectation correspond `a la variable affect'ee, le membre droit correspond
`a la valeur qui est affect'ee. Les instructions qui ne sont pas des affectations ne poss`edent qu'un
membre droit.

Nous allons d'efinir pour chacun de ces membres de chaque instruction, un ensemble des
tableaux et scalaires acc'ed'es. Nous consid'erons le membre gauche comme un ensemble, d'une
part pour qu'il puisse ^etre facilement trait'e comme le membre droit, et d'autre part car certains langages, comme CAML, permettent d'avoir plusieurs variables dans le membre gauche en
d'efinissant directement des n-uplets de variables.

En Fortran ou en C, l'ensemble associ'e au membre gauche contient exactement un acc`es pour
les affectations et z'ero pour les autres types d'instructions. Les constructs C du type b " i ` `
ou c " ` ` i sont 'elimin'es par le front-end C et la phase de pr'e-optimisation du compilateur, et
remplac'es par plusieurs instructions (ici b " i; i` " 1 et i` " 1; c " i).

Affinit'e : Le Chapitre 5 `a mis en avant le fait que les acc`es aux tableaux pouvaient ^etre nonaffines dans un SCoP. Notre formalisme d'efinit toutefois une repr'esentation pour les acc`es qui
sont affines. Cela nous permet, d'une part de v'erifier pour ces acc`es que nos transformations
v'erifient les d'ependances de donn'ees, et d'autre part d'impl'ementer une s'erie de transformations
dans notre formalisme pour modifier ces acc`es affines.

Entre des acc`es non-affines et des acc`es (affines ou non), nous consid'ereront conservativement
qu'il y a d'ependance de donn'ees. Et la pr'esence d'un acc`es non-affine pour un tableau T interdira
toute modification de structure (comme la privatisation) sur le tableau.

Tableaux dynamiques : Les tableaux dynamiques, qui utilisent l'arithm'etique des pointeurs,
ont un fort impact sur la staticit'e du code du fait des probl`emes d'aliasing de pointeurs qu'ils
soul`event. La phase de pr'e-optimisation du compilateur Open64 prend en charge l'analyse li'ee
`a ces probl`emes d'aliasing et la promotion de tableaux dynamiques en tableaux statiques.

Dans la suite, nous ne consid'ererons que les tableaux statiques.

98 9. D'efinitions du formalisme
Tableaux multidimensionnels : dans la WHIRL, les tableaux mulitidimensionnels issus des
langages C et Fortran ne sont pas du tout g'er'es de la m^eme mani`ere. Les tableaux fortrans sont
consid'er'es comme de v'eritables tableaux multidimensionnels (avec une branche de l'arbre par
dimension) alors que les tableaux multidimensionnels C sont stock'es comme des tableaux de
tableaux.

Pour repr'esenter les tableaux dans notre formalisme, nous avons adopt'e une repr'esentation
proche du Fortran, consid'erant plut^ot des tableaux multidimensionnels que des tableaux de
tableaux.

Ordre de stockage : le stockage en m'emoire des tableaux d'efinis en C et en Fortran est
'egalement tr`es diff'erent. En Fortran les tableaux sont rang'es colonne par colonne, alors qu'en

C, ils sont stock'es ligne par ligne. Les optimisations pour la hi'erarchie m'emoire doivent prendre
en compte ce fait pour tirer parti de la localit'e spatiale.

Le compilateur Open64 et notre formalisme sont utilis'es dans le cadre de ces deux langages,
nous noterons simplement l'ordre de stockage comme suit : $ pour un stockage par lignes, et I.
pour un stockage par colonnes.

Taille des tableaux : la taille des tableaux statiques est d'efinie lors de leur initialisation, et
une taille est associ'ee `a chaque dimension du tableaux.

Soit T un tableau de dimension d. Notons dmipT q la taille de la dimension i du tableau T .
Alors, la taille du tableau T est d'efinie par le vecteur ST de dimension d, tel que :

ST "

>>
--
--
--
-

dm1pT q
dm2pT q.

..

dmdpT q

fi
ffi
ffi
ffi
fl

Fonction d'acc`es : `a un acc`es au tableau T de dimension t, on peut, dans le cas des acc`es
affines, associer une fonction d'acc`es affine f de dimension t correspondant `a l'acc`es. Par exemple,
pour l'acc`es au tableau Zrisrj ` 1s de l'instruction S2, on associe la fonction suivante :

f piq "

"M

' i

j ` 1

j

Pour toute fonction d'acc`es affine f `a un tableau T d'une instruction S on associe une matrice
F P Mt,dS`dSlv`dgp`1pZq, telle que :

f piSq " F ^

>>
--
--
-

iS
iSlv
igp

1

fi
ffi
ffi
fl

Par exemple, la matrice d'acc`es correspondant `a la fonction d'acc`es pr'ec'edente est la suivante :

F "

i j M 1
'1 0 1 00 1 0 1

9.5. Vecteur de d'eroulage 99
9.4.1 D'efinition formelle :

Pour chaque instruction S, nous d'efinissons deux ensembles LShs et RShs de n-uplets, chaque
n-uplet repr'esentant un acc`es `a un tableau ou un scalaire dans la partie gauche (LShs) ou la partie
droite (RShs) de l'instruction.

Soit T un tableau de dimension d, avec ST le vecteur indiquant la taille de chaque dimension
du tableau, et o l'ordre d'acc`es du langage dans lequel le tableau est d'efini. Un acc`es au tableau
T par la matrice d'acc`es F de dimension d s'exprime par le quadruplet pT, o, ST , Fq.

Les acc`es aux scalaires sont repr'esent'es par un 1-uplet compos'e du scalaire.

Exemple : revenons au code source pr'esent'e au d'ebut de cette section, les ensembles Lhs etR

hs associ'es `a chaque instruction du code source sont les suivants :

LS1hs "

$
&

%

"
""A, $,

"5120 , i M 11 0 0

,

,

,
.

- R

S1hs "

!)

LS2hs "

$
&

%

"
""A, $,

"5120 , i M 11 0 0

,

,

,
.

- L

S3hs "

!

b

)

RS2hs "

$
'&

'%

"
""A, $,

"5120 , i M 11 0 0

,

,

"
*
""Z, $,

"600

700

j

,

i j M 1
'1 0 1 00 1 0 1

,
<
,

,
/.

/-

RS3hs "

$
'&

'%b

"
*
""Z, $,

"600

700

j

,

i j M 11 0 0 0

0 1 0 0

,
<
,

"
*
""Z, $,

"600

700

j

,

i j M 10 1 0 0

1 0 0 0

,
<
,

,
/.

/-

Exemple de transformations : la transformation de privatisation (Privatize) qui ajoute
une dimension `a un tableaux (ou fait d'un scalaire un tableau `a une dimension) est un exemple
de transformation sur les acc`es qui affecte la matrice d'acc`es, tout comme la transformation de
contraction (Contract) qui r'ealise l'op'eration inverse. Une transformation comme le padding
(Pad) modifie les vecteurs de taille des tableaux.

Ces transformations sont d'ecrites pr'ecis'ement dans le Chapitre 11.

9.5 Vecteur de d'eroulage

Le d'eroulage de boucle est une des transformations de programme les plus utilis'ees dans
le cadre de l'optimisation de programme. Le d'eroulage complet de boucle permet notamment
d''eliminer tout le contr^ole relatif `a la boucle. Cette technique est utilis'ee dans les transformations
comme l'unroll-and-jam, pr'esent'e dans la figure 9.1.

L'application de ce d'eroulage complet sur le formalisme pose un double probl`eme. D'une
part pour d'erouler compl`etement une boucle, il faudrait passer par une phase de g'en'eration de
code pour effectivement reconstruire les boucles et d'erouler celle qui nous int'eresse (en effet ce
d'eroulage n'est possible que si le nombre d'it'eration est connu statiquement, et c'est la phase de
g'en'eration de code qui permet de conna^itre le nombre d'it'erations). D'autre part, si nous appliquions le d'eroulage complet sur notre formalisme cela signifierait que toutes les instructions se

100 9. D'efinitions du formalisme

for(i=0; i<N ; i++)

for(j=0; j<N ; j++)

for(k=0; k<N ; k++)

A[i][j] += B[i][k] * C[k][j]

Y'N~

for(i=0; i<N ; i+=2)

for(j=0; j<N ; j++)

for(k=0; k<N ; k++)

A[i][j] += B[i][k] * C[k][j]
A[i+1][j] += B[i+1][k] * C[k][j]

Fig. 9.1 - Unroll and Jam sur le produit de matrices

trouvant dans la boucle d'eroul'ee seraient dupliqu'ees un nombre de fois 'egal au nombre d'it'erations de la boucle, ce qui entra^inerait un fort accroissement de la complexit'e du formalisme que
nous avions jusque l`a 'evit'e.

La solution logique consiste donc `a repousser les transformations de d'eroulage jusqu'`a la
phase de g'en'eration de code. Pour ce faire, nous notons pour chaque instruction, et `a chaque
profondeur, si celle-ci doit ^etre d'eroul'ee.

D'eroulage partiel : le d'eroulage partiel d'une boucle n fois s'impl'emente tr`es simplement
`a l'aide d'un strip-mine de la boucle avec un facteur de n, suivi du marquage pour d'erouler
compl`etement la boucle de ses n it'erations :

for(int i=0;i<4*M;i++)

S1(i)
S2(i) Y'N~

for(int ii=0;ii<M;ii++)

for(int i=4*ii;i<4*ii+4;i++)

S1(i)
S2(i)

Y'N~

for(int t0=0;t0<M;t0++)

S1(4*t0)
S2(4*t0)
S1(4*t0+1)
S2(4*t0+1)
S1(4*t0+2)
S2(4*t0+2)
S1(4*t0+3)
S2(4*t0+3)

D'efinition formelle : pour chaque instruction S du SCoP, nous d'efinissons le vecteur de
d'eroulage oeS de dimension d, tel que oeSk " 1 si l'instruction S doit ^etre d'eroul'ee pour sa
dimension k, et oeSk " 0 sinon.

Les vecteurs de d'eroulage sont initialement nuls, le g'en'erateur de code URGenT a 'et'e modifi'e
par Nicolas Vasilache pour prendre en compte ces vecteurs de d'eroulage et r'ealiser le d'eroulage
lors de la phase de g'en'eration de code.

L'algorithme est le suivant : Si pour une m^eme boucle de profondeur p, toutes les instructions
de la boucles sont marqu'ees pour ^etre d'eroul'ees `a la profondeur p, et que le nombre d'it'erations
de la boucle peut ^etre connu statiquement, alors la boucle est d'eroul'ee.

Exemple de transformations : comme indiqu'e plus haut, la transformation d'unroll-andjam est un bon exemple de transformation utilisant le d'eroulage complet.

101
Chapitre 10
Invariants du formalisme

Dans le formalisme pr'esent'e dans le chapitre 9, un SCoP donn'e peut avoir des repr'esentations
multiples, ce qui peut limiter l'applicabilit'e des transformations. Nous allons donc maintenant
vous pr'esenter une s'erie d'invariants li'es au formalisme permettant d'associer au formalisme des
r`egles de normalisation.

Ces r`egles de normalisation permettent d'assurer que la repr'esentation reste syntaxiquement
correcte au fur et `a mesure que le formalisme est modifi'e par les transformations. Il ne s'agit donc
pas d'assurer une correction s'emantique (le fait que le programme produise le m^eme r'esultat
que le programme de d'epart), mais d'assurer la correction syntaxique de la repr'esentation (le
fait que du code puisse ^etre g'en'er'e `a partir de la repr'esentation).

Compositionalit'e : la haute compositionalit'e du formalisme permet de prouver facilement
que toutes les transformations de haut niveau (qui s'expriment comme des compositions de
transformations 'el'ementaires) v'erifient les invariants du formalisme. En effet, une transformation
d'efinie par composition de transformations respectant les invariants du formalisme, v'erifie ellem^eme de facto ces invariants.

Par exemple, d'efinir la transformation unimodulaire gauche dans le formalisme (voir Section
11.2.1), et prouver qu'elle respecte les invariants du formalisme, signifierait que toute transformation s'exprimant uniquement `a l'aide de cette transformation (comme la permutation de
boucle, l'inversion de boucle, ou le skewing) respecte directement les invariants. La m^eme r`egle
s'applique aux transformations plus complexes : le Tiling respecte les invariants car il s'agit de
la composition de deux strip-mining et d'une permutation de boucle.

Validit'e et Complexit'e : les invariants permettent aussi de s'assurer qu'apr`es chaque transformation, le formalisme est syntaxiquement correct et que sa complexit'e reste globalement
inchang'ee. Par exemple l'invariant d'inversibilit'e de la matrice d'ordonnancement des it'erateurs
A, permet de s'assurer qu'il est possible pour le g'en'erateur de code de g'en'erer les nouveaux it'erateurs. De m^eme les bornes impos'ees `a chaque it'erateur assurent qu'il n'y aura pas de boucles
infinies.

Par exemple, pour le domaine de l'instruction S de la Figure 10.1(a), l'it'erateur i est born'e
ce qui permet de g'en'erer le code de la Figure 10.2(a). Le domaine repr'esent'e par la Figure
10.1(b) ne borne pas l'it'erateur i. Lors de la g'en'eration de la boucle correspondante, il est donc
impossible de g'en'erer une borne sup'erieure.

La faible croissance en complexit'e du formalisme assure que les recherches d'opportunit'e
pour de nouvelles transformations, et l''etude d'applicabilit'e de ces transformation ne croissent

102 10. Invariants du formalisme

DSom " tN d^ i d^ 2M ` 6u
\Lambda S "

$
&

%

i M N 11 0

'1 0
'1 2 0 6

,
.

-
(a) i born'e

DSom " tN d^ iu
\Lambda S "

#

i M N 11 0

'1 0

+

(b) i non-born'e
Fig. 10.1 - Exemple de domaines born'es ou non

for(int t0=N; t0<=2*M+6; t0++)

S(i=t0)

(a) Code correct

for(int i=N; ? ; i++)

S(i=t0)

(b) Probl`eme de borne sup'erieure

Fig. 10.2 - Exemple de code g'en'er'e

pas elles-m^emes en complexit'e, comme nous l'avions constat'e sur les repr'esentation syntaxiques
(voir Chapitre 4).

Applicabilit'e : ces invariants facilitent 'egalement la v'erification de l'applicabilit'e des transformations elles-m^emes. Consid'erons par exemple qu'il n'est l'egal de fusionner deux boucles, que
si elles sont cons'ecutives. Les deux boucles i de la figure 10.3(a) sont donc fusionnables, alors
que celles de la figure 10.3(b) ne le sont pas `a cause de l'instruction S2.

for(int i=0; i<N; i++)

S1
for(int i=0; i<N; i++)

S3

(a) Fusionnable

for(int i=0; i<N; i++)

S1
S2
for(int i=0; i<N; i++)

S3

(b) Non fusionnable

Fig. 10.3 - Exemple de boucles `a fusionner

La Figure 10.4 correspond `a une repr'esentation possible, non normalis'ee, des vecteurs d'ordonnancement des instructions S1, S2 et S3.

fiS1 " 78 fiS3 " 1012

(a) Fusionnable

fiS1 " 78 fiS2 " 9 fiS3 " 1012

(b) Non fusionnable
Fig. 10.4 - Exemple de repr'esentation non-normalis'ee

La seule information qu'il est possible d'extraire de ces vecteurs d'ordonnancement des instructions S2 et S3, est que ces deux instructions ne sont pas situ'ees dans la m^eme boucle (les
vecteurs diff`erent `a la premi`ere dimension), mais il est impossible de savoir si les boucles des
instructions S2 et S3 sont cons'ecutives, ni m^eme que S3 est la premi`ere instruction de sa boucle.
Pour tester la cons'ecutivit'e, il faut donc parcourir l'ensemble des instructions du SCoP, pour
'eventuellement trouver l'instruction S2 situ'ee entre les deux boucles.

Les invariants de s'equentialit'e et de densit'e d'efinis ci-dessous permettent de v'erifier imm'ediatement la propri'et'e de cons'ecutivit'e, sans avoir `a explorer le reste des instructions du SCoP.
La Figure 10.5 correspond `a la repr'esentation normalis'ee par les invariants de s'equentialit'e et
de densit'e sur les vecteurs d'ordonnancement.

10.1. Invariants d'ordonnancement 103

fiS1 " 00 fiS3 " 10

(a) Fusionnable

fiS1 " 00 fiS2 " 1 fiS3 " 20

(b) Non fusionnable
Fig. 10.5 - Exemple de repr'esentation normalis'ee

Beaucoup plus d'informations peuvent ^etre extraites de cette repr'esentation normalis'ee. Tout
d'abord la cons'ecutivit'e s'exprime directement : les deux boucles de la Figure 10.5(a) sont
cons'ecutives car `a la premi`ere dimension les valeurs des vecteurs d'ordonnancement sont 0 et 1.
Celles de la Figure 10.5(b) ne le sont pas (0 et 2 ne sont pas cons'ecutifs). De plus les instructions
S2 et S3 sont les premi`eres instructions de leur boucle respective car `a leur derni`ere dimension,
leur vecteur d'ordonnancement vaut 0.

Complexit'e : enfin, ces r`egles de normalisation permettent simplement d''eviter les risques de
d'ebordements entier. Par exemple les coefficients de chaque in'equation enti`ere du domaine sont
divis'es par le PGCD de ces coefficients pour d'une part permettre de reconna^itre facilement deux
in'equations identiques ou compl'ementaires, d'autre part pour maintenir dans les matrices des
domaines des coefficients les plus petits possibles. La Figure 10.6 donne un exemple de domaine,
et de matrices de domaines normalis'ees ou non

DSom " t4N d^ 8i d^ 2M ` 6u

(a) Domaine de d'epart

\Lambda S "

$
&

%

i M N 18 0

'4 0
'8 2 0 6

,
.

-
(b) Non-normlalis'e

\Lambda S "

$
&

%

i M N 12 0

'1 0
'4 1 0 3

,
.

-
(c) Normalis'e

Fig. 10.6 - Exemple de repr'esentations de domaines normalis'ees ou non

La Section 10.1 pr'esente les invariants d'ordonnancements associ'es aux matrices \Theta , A, \Gamma  et
au vecteur fi. La Section 10.2 pr'esente les invariants de domaines s'appliquant `a la matrice \Lambda .
Dans la Section 10.3, nous expliquerons comment l'ensemble de ces invariants est v'erifi'e.

10.1 Invariants d'ordonnancement
Dimensions : la section 9.3 a d'efinie la d'ecomposition de la matrice \Theta  en deux matrices A
et \Gamma  et un vecteur d'ordonnancement fi ; les transformations de programmes manipuleront \Theta  `a
travers ces trois composantes. Du fait de cette d'ecomposition, il existe une corr'elation entre les
dimensions de ces trois composantes, qui s'exprime de la mani`ere suivante :

@S P SCoP : dimp\Gamma Sq " dimpASq (inv-dim-\Gamma )

@S P SCoP : dimpfiSq " dimpAS q ` 1 (inv-dim-fi)

104 10. Invariants du formalisme
S'equentialit'e : le second invariant d'ordonnancement est celui de s'equentialit'e : Deux instructions ne peuvent avoir la m^eme date d'ex'ecution si, ces deux instructions sont diff'erentes, ou
si les deux instances d'it'erations consid'er'ees sont diff'erentes. Cet invariant permet de supprimer
toute ambigu"it'e sur l'ordonnancement lors de la phase de g'en'eration de code1. Cela s'exprime
par les deux invariants suivants :

@~i,~j, S P SCoP, S1 P SCoP : S 0 S1 n~ `Sp~iq 0 `S

1

p~jq

@~i,~j, S P SCoP, S1 P SCoP : S 0 S1 n~ `Sp~iq 0 `S

1

p~jq

Ces invariants 'etant difficiles `a v'erifier directement, nous avons introduit deux invariants
n'ayant pas d'impact sur l'expressivit'e de l'ordonnancement et plus contraignants que les invariants pr'ec'edents :

Invertibilit'e sur les A : le premier de ces deux invariants assure la s'equentialit'e de \Theta  pour
ces lignes impaires en assurant l'invertibilit'e de la matrice A.

@S P SCoP : detpASq 0 0 (inv-inv-A)

Actuellement, notre g'en'erateur de code URGenT ne traite que des matrices A unimodulaires,
mais il est pr'evu de revoir cela pour repr'esenter facilement qu'une instructions est ex'ecut'ee plus
rapidement qu'une autre.

S'equentialit'e sur les fi : le second de ces deux invariants assure la s'equentialit'e sur les
lignes paires de la matrice d'ordonnancement \Theta  en assurant cette s'equentialit'e sur les vecteurs
d'ordonnancement fi.

@S, S1 P SCoP : S 0 S1 n~ fiS 0 fiS

1 (inv-seq-fi)

Le formalisme assure ainsi que chaque instruction S soit identifiable de mani`ere unique par
son vecteur d'ordonnancement fiS. Cette propri'et'e est cruciale pour la d'efinition des transformations de programmes : ainsi non seulement une instruction est identifi'ee de mani`ere unique
par son vecteur fiS, mais les instructions appartenant `a un m^eme corps de boucle sont identifi'ee
par des fi-pr'efixe identiques. Consid'erons par exemple la Figure 10.7, toutes les instructions
appartenant `a la boucle i (S1, S2, S3 et S4) partagent le m^eme fi-pr'efixe r0s ; les instructions
de la boucle j partagent le m^eme fi-pr'efixe

`0

1

ae.

for(int i=0;i<N;i++)

S1 N~ [ 0 0 ]
for(int j=0;j<N;j++)

S2 N~ [ 0 1 0 ]
S3 N~ [ 0 1 1 ]
S4 N~ [ 0 2 ]
S5 N~ [ 1 ]

Fig. 10.7 - Instructions avec leur vecteurs d'it'erations
Les fi-pr'efixe serviront donc directement `a indiquer quelles instructions et quels nids de
boucle sont les cibles des transformations de programme.

1On ne s'int'eresse qu'`a la g'en'eration de codes s'equentiels, ou de codes parall`eles avec des structures de contr^ole
s'equentielles et des annotations parall`eles (OpenMP)

10.2. Invariants de domaine 105
Densit'e : nous avons finalement ajout'e un invariant de densit'e sur les vecteurs d'ordonnancement, pour r'eduire les risques de d'ebordement entier, faciliter la comparaison de ces vecteurs,
et exprimer simplement la cons'ecutivit'e. Cet invariant s'exprime ainsi :

Dk e^ 0, S P SCoP | fiSk a, 0 n~ DS1 P SCoP

^
^
^
^ fi

S1k " fiSk ' 1

@i P r 0, k s

^
^ fiS1i " fiSi (inv-den-fi)

i.e. Pour un fi-pr'efixe donn'e, la dimension suivante des vecteurs d'ordonnancement de l'ensemble
des instructions forme un intervalle d'entiers r0, Ks avec K positif. Les instructions `a la m^eme
profondeur ont donc des fi cons'ecutifs.

La propri'et'e de densit'e permet de d'efinir la fonction fimaxpP q qui permet de conna^itre le
nombre d'instructions ou de boucles `a une profondeur donn'ee poss'edant le m^eme pr'efixe P .
La Figure 10.8 pr'esente un exemple de code avec ses vecteurs d'it'eration, et quelques exemples
d'utilisation de la fonction fimax.

for(i=0; i<N ;i++)

for(j=0; j<N ;j++)

S1 [ 0 0 0 ]
for(k=0; k<N ;k++)

S2 [ 0 0 1 0 ]
S3 [ 0 0 1 1 ]
for(l=0; l<N ;l++)

S5 [ 0 0 1 2 0 ]
S6 [ 0 1 ]

fimaxpr0sq " 1
fimaxpr0 0sq " 1
fimaxpr0 0 1sq " 2
fimaxpr0 0 1 2sq " 0

Fig. 10.8 - Exemple d'utilisation de la fonction fimax
La d'efinition formelle de la fonction fimax est la suivante :

fimaxpP q " maxm pDS P SCoP | pP , mq D^ fiSq

10.2 Invariants de domaine
Primalit'e : les domaines d'it'eration expriment les in'equations affines bornant les poly`edres.
Or, il y a plusieurs mani`ere d'exprimer la m^eme 'equation : les in'equations suivantes t3i d^ 6u et
t2i d^ 4u par exemple correspondent au m^eme demi-plan. Pour d'ecrire chacune de ces in'equations
de mani`ere unique, nous d'efinissons l'invariant d'unicit'e suivant sur les domaines :

@S P SCoP, @i P r1, dSs, gcdp\Lambda Si q " gcdp\Lambda Si,0, \Lambda Si,1, " " " , \Lambda Si,dS q " 1 (inv-prm-\Lambda )

En imposant que les coefficients non nuls d'une ligne de \Lambda S soient premiers entre eux dans
leur ensemble, nous 'evitons la double repr'esentation de l'exemple ci-dessus (qui sera repr'esent'ee
ti d^ 2u dans les deux cas), et 'evitons les 'eventuels probl`emes de d'ebordements d'entier. Cette
restriction n'a aucun impact sur l'expressivit'e des domaines.

10.3 V'erification des invariants

Chacune des transformations que nous allons d'efinir dans les Chapitres 11 et 12 partent
du principe qu'avant d'^etre appliqu'ee, le formalisme respecte les invariants, et v'erifie apr`es
application que les invariants sont toujours respect'es.

106 10. Invariants du formalisme

Le respect des invariants `a la fin de la s'equence de transformations assure que le g'en'erateur
de code est capable `a partir de la repr'esentation de g'en'erer un code syntaxiquement correct.

10.3.1 Par construction

Commen,cons donc par v'erifier qu'`a la construction du formalisme les invariants sont respect'es
pour les diff'erents types d'invariants.

Invariants d'ordonnancement : les invariants sur les dimensions inv-dim-\Gamma  et inv-dim-fi
sont bien entendu respect'es `a la construction lors de la s'eparation de \Theta  en A, \Gamma  et fi. De plus, au
d'epart toutes les matrices A sont des matrices identit'e, et les matrices \Gamma  sont nulles. L'invariant
inv-inv-A est donc lui aussi v'erifi'e. Les vecteurs d'ordonnancement fi sont construits `a partir
de la position de chaque instruction dans l'arbre de syntaxe (voir Section 9.3), ce qui assure les
invariants de s'equentialit'e et de densit'e inv-seq-fi et inv-den-fi.

Invariants de domaine : les domaines 'etant construits `a partir des in'equations correspondant
aux bornes de boucles et aux conditionnelles du programme source, au d'epart chaque it'erateur
est born'e, et il est facile lors de l'ajout d'une in'equation `a la matrice des domaines de diviser
les coefficients de cette in'equation par le PGCD des coefficients. Les invariants de bornitude et
d'unicit'e inv-bnd-its et inv-prm-\Lambda  sont donc eux aussi v'erifi'es.

10.3.2 Par application successive de transformations

Le Chapitre 12 liste les diff'erentes transformations usuelles. Pour chacune d'elles une preuve
est fournie concernant le respect des invariants. Comme indiqu'e en d'ebut de ce chapitre, cette
preuve est d'autant plus simple que la transformation s'exprime par compositions de transformations respectant elles-m^emes les invariants.

L'application successive de transformations correspond `a la composition de ces transformations appliqu'ees successivement. Elle respecte donc elle aussi les invariants du formalisme.

107
Chapitre 11
Transformations de Programme dans
le Formalisme

Nous allons maintenant d'efinir la mani`ere dont les transformations de programmes sont d'efinies dans le formalisme. Une des importantes contributions de notre travail est de faire une
s'eparation claire entre le fait qu'une transformation ait s'emantiquement du sens, c'est `a dire
qu'elle soit exprimable `a l'aide du formalisme, et le fait qu'une transformation soit s'emantiquement s^ure, c'est `a dire que les propri'et'es statiques de la transformation soient v'erifi'ees (comme
les contraintes sur les d'ependances de donn'ees).

L'objectif est 'evidemment de rel^acher la plupart des contraintes sur le source pour 'elargir le
champ d'applicabilit'e des transformations sans ^etre biais'e par la pr'ecision des mod`eles statiques
d'analyse. Par exemple, de nombreuses transformations de boucles sont compromises par le
manque d'informations `a propos de leurs bornes, ou le fonctionnement par bloc des optimiseurs.
Dans la plupart des cas, une repr'esentation poly'edrique 'evite ce genre de difficult'es en s'eparant
domaines et ordonnancement, et permettant ainsi que les op'erations soient r'ealis'ees au niveau
des instructions et non des boucles.

Nous commencerons dans ce chapitre par d'efinir une s'erie de constructeurs, des fonctions
r'ealisant des op'erations de base sur des vecteurs et des matrices. Nous pr'esenterons ensuite une
s'erie de transformations primitives, impl'ementant les manipulations de base associ'ees au formalisme, et respectant les invariants. Le chapitre suivant pr'esentera la liste des transformations
usuelles repr'esent'ees dans notre formalisme.

11.1 Constructeurs

Commen,cons par d'efinir une s'erie de fonctions sur les SCoPs appel'ees constructeurs. La
plupart de ces op'erations sont des op'erations simples de calcul matriciel, des op'erations simples
sur la structure de matrices comme l'ajout / la suppression de lignes et de colonnes, et l'op'erateur
de translation sur les vecteurs d'ordonnancement.

La notion de constructeur est 'eloign'ee du formalisme. Il s'agit par exemple de d'efinir le
constructeur d'insertion de colonne dans une matrice, et non celui d'insertion d'une colonne dans
la matrice \Lambda . Aucune v'erification des invariants n'est donc r'ealis'ee au niveau des constructeurs.
Ce sont les primitives et les transformations qui effectueront cette v'erification.

108 11. Transformations de Programme dans le Formalisme
11.1.1 Op'erations de calcul matriciel

Nous nous autorisons les op'erations de calculs classiques sur les vecteurs et les matrices, avec
les contraintes habituelles rappel'ees ci-dessous :

- Addition de matrices : Soit A et B deux matrices de r lignes et c colonnes, la matrice C

d'efinie par C " A ` B poss`ede r lignes et c colonnes, et est telle que :

@i P r1, rs, j P r1, cs : Ci,j " Ai,j ` Bi,j
- Soustraction de matrices : Soit A et B deux matrices de r lignes et c colonnes, la matrice

C d'efinie par C " A ' B poss`ede r lignes et c colonnes, et est telle que :

@i P r1, rs, j P r1, cs : Ci,j " Ai,j ' Bi,j
- Multiplication de matrices : Soit la matrice A de r lignes et d colonnes, soit la matrice

B de d lignes et c colonnes. La matrice C d'efinie par C " A * B poss`ede r lignes et c
colonnes, et est telle que :

@i P r1, rs, j P r1, cs : Ci,j "

dy"

k"1

Ai,k * Bk,j

- Addition de vecteurs : Soit a et b deux vecteurs de dimension d, le vecteur c d'efini par

c " a ` b est de dimension d, et est tel que :

@i P r1, ds : ci " ai ` bi
- Soustraction de vecteurs : Soit a et b deux vecteurs de dimension d, le vecteur c d'efini par

c " a ' b est de dimension d, et est tel que

@i P r1, ds : ci " ai ' bi
- Multiplication de vecteur par un scalaire : Soit a un vecteur de dimension d, k un scalaire,

le vecteur b d'efini par b " k * a est de dimension d, et est tel que :

@i P r1, ds : bi " ai * k
- Addition d'un scalaire `a un vecteur : Soit a un vecteur de dimension d, k un scalaire, le

vecteur b d'efini par b " a ` k est de dimension d, et est tel que :

@i P r1, d ' 1s : bi " ai
bd " ad ` k

11.1.2 Op'erations sur les structures

Comme indiqu'e au d'ebut de cette section, ces constructeurs agissent sur la structure des
matrices et des vecteurs, permettant d'ajouter ou de supprimer des lignes ou des colonnes. Ces
constructeurs v'erifient rarement les invariants sur les dimensions du fait des corr'elations entre les
tailles des matrices, mais sont toujours appel'es successivement sur l'ensemble des matrices li'ees.
C'est la valeur du vecteur v des constructeurs d'insertion qui influe sur le respect des invariants
inv-inv-A et inv-prm-\Lambda .

11.1. Constructeurs 109
InsRow : Soit une matrice M avec c colonnes et au moins l lignes, et un vecteur v de dimension
c. InsRowpM, l, vq ins`ere une nouvelle ligne `a la position l dans la matrice M et remplit cette
ligne avec les valeurs du vecteur v.

InsCol : Soit une matrice M avec l lignes et au moins c colonnes, et un vecteur v de dimension
l. InsColpM, c, vq ins`ere une nouvelle colonne `a la position c dans la matrice M et remplit cette
colonne avec les valeurs du vecteur v.

RemRow : Soit une matrice M avec au moins l lignes. RemRowpM, lq supprime la ligne `a la
position l dans la matrice M .

RemCol : Soit une matrice M avec au moins c colonnes. RemColpM, lq supprime la colonne `a
la position c dans la matrice M .

Concat : Soit Doit u et v deux vecteurs de dimensions du et dv. La concat'enation des vecteurs
u et v, not'ee c " u , v est le vecteur de dimension du ` dv, tel que :

" c

k " uk @k P r0, dur

ck " vk'du @k P rdu, du ` dvr

11.1.3 Op'eration d'ordonnancement

Pour pouvoir impl'ementer les futures primitives d'insertion / de suppression d'instructions,
et forcer le respect des invariants de s'equentialit'e inv-seq-fi et de densit'e inv-den-fi, il est n'ecessaire d'avoir un constructeur de r'e-ordonnancement permettant de cr'eer les trous o`u ins'erer les
nouvelles instructions, ou de supprimer ceux cr'e'es par la suppression d'instructions.

Le r'e-ordonnancement d'une instruction S a un impact direct sur son vecteur de d'ordonnancement fiS, mais 'egalement sur les vecteurs de d'ordonnancement fiS

1 des instructions S1

partageant des propri'et'es communes avec S. En effet, le d'eplacement vers l'avant ou l'arri`ere de
l'instruction S `a la profondeur ` provoque le m^eme d'eplacement sur toutes les instructions S1 `a
la profondeur ` telles que prefixpfiS

1, `

q " prefixpfiS, `q.

D'efinition : Soit P de dimension d le pr'efixe du vecteur d'ordonnancement des instructions `a
r'eordonnancer, soit Q vecteur pr'efix'e par P la date logique `a partir de laquelle les instructions
doivent ^etre d'eplac'ees, et o la distance de d'eplacement scalaire, le constructeur MovepP, Q, oq
est alors d'efini par :

MovepP, Q, oq :>
>
>
>
>
>
>
>

d DH dimpP q
@S P SCoP^
^
^
^ P

D^ fiS ^ Q D^ fiS n~ fiSd DH fiSd ` o;

P D^ fiS ^ Q ! fiS n~ fiSd DH fiSd ` o;

La premi`ere incr'ementation de fiS d'eplace les instructions s'electionn'ees, la seconde correspond au d'eplacement induit sur les instructions poss'edant un pr'efixe commun.

110 11. Transformations de Programme dans le Formalisme

for(i=0; i<N; i++)

for(j=0; j<N; j++)

S1
S2
S3
S4
for(j=0; j<N; j++)

S5
S6

Fig. 11.1 - Code source

fiS1 " 00

0

fiS2 " 00

1

fiS3 " 00

2

fiS4 " 01 fiS5 " 02

0

fiS6 " 1

Fig. 11.2 - Vecteurs d'ordonnancement correspondant `a la Figure 11.1

Exemples : La Figure 11.1 pr'esente un exemple de code source. Nous allons consid'erer deux
exemples de l'utilisation du constructeur Move. Ce constructeur n'affectant que les vecteurs
d'ordonnancement de la repr'esentation, nous ne nous int'eresserons qu'`a ces vecteurs. La Figure
11.2 correspond `a la repr'esentation du code de la Figure 11.1 dans notre formalisme.

Pour le premier exemple, nous allons cr'eer l'espace n'ecessaire pour l'insertion d'une instructions entre S1 et S2, au m^eme niveau que ces deux derni`eres, ce qui est r'ealis'e par Move(

`0

0

ae,^

*00

1

o/
AE,1),

et qui produit le r'esultat correspondant `a la figure 11.3. Seules les instructions S2 et S3 sont
d'ecal'es par cette op'eration, `a la 3`eme dimension. Dans le code source XXX repr'esente l'endroit
ou le trou est ins'er'e.

fiS1 " 00

0

fiS2 " 00

2

fiS3 " 00

3

fiS4 " 01 fiS5 " 02

0

fiS6 " 1

for(i=0; i<N; i++)

for(j=0; j<N; j++)

S1
XXX
S2
S3
S4
for(j=0; j<N; j++)

S5
S6

Fig. 11.3 - Premier exemple : Insertion entre S1 et S2

Pour le second exemple, en partant du m^eme source (Figure 11.1) et de la m^eme repr'esentation (Figure 11.2), nous allons appliquer la transformation Move(i0,,

^
*00

1

o/
AE,2). Cette fois le d'ecalage

s'effectue `a la seconde dimension, et le r'esultat produit correspond `a la Figure 11.4. Cette fois,
seules les instructions S1 et S6 ne sont pas affect'ees par le constructeur.

Cette utilisation du cosntructeur Move est beaucoup plus complexe que la premi`ere. Le
d'eplacement de 2 casse la boucle j en deux et laisse un espace entre les deux boucles (XXX).
Les instructions S2 et S3 n''etant pas d'eplac'ees sur leur troisi`eme dimension, un espace apparait
'egalement dans la seconde boucle (Y Y Y ).

11.2. Primitives 111

fiS1 " 00

0

fiS2 " 02

1

fiS3 " 02

2

fiS4 " 03 fiS5 " 04

0

fiS6 " 1

for(i=0; i<N; i++)

for(j=0; j<N; j++)

S1
XXX
for(j=0; j<N; j++)

YYY
S2
S3
S4
for(j=0; j<N; j++)

S5
S6

Fig. 11.4 - Deuxi`eme exemple : D'eplacement `a la seconde dimension

Effet sur les invariants : Le constructeur Move ne modifie que les vecteurs d'ordonnancement
fi de certaines instructions, sans changer leur dimension. Il respecte donc les invariants inv-dim-\Gamma ,
inv-dim-fi, inv-inv-A et inv-prm-\Lambda .

Lorsque le d'eplacement est positif (o a, 0), si le constructeur Move d'eplace des instructions
vers des valeurs existantes de fi, ces valeurs sont 'egalement d'eplac'ees, assurant ainsi que l'invariant de s'equentialit'e inv-den-fi est respect'e. Par contre, l'objectif de ce constructeur 'etant de
cr'eer un trou de taille o `a la dimension d " dimpP q, l'invariant de densit'e inv-den-fi peut ne pas
^etre respect'e.

Lorsque le d'eplacement est n'egatif (o a* 0), le constructeur Move est utilis'e pour boucher
un trou dans les vecteurs d'it'erations en ramenant des instructions vers l'arri`ere. L'invariant
de s'equentialit'e inv-seq-fi peut donc ^etre viol'e si le trou n'existe pas. Par contre, l'invariant de
densit'e inv-den-fi est respect'e.

11.2 Primitives

Avec les constructeurs d'efinis dans la section pr'ec'edente, nous allons maintenant d'efinir les
transformations primitives. Elle servent de blocs de base permettant de manipuler le formalisme,
et ainsi de construire des transformations de plus haut niveau avec un v'eritable sens s'emantique.

Contrairement aux constructeurs qui offrent les op'erations permettant de manipuler des matrices arbitraires, les primitives effectuent des op'erations sur une des composante du formalisme
en respectant les invariants du formalisme.

L'organisation de cette section est la suivante : Pour chaque primitive, nous pr'esenterons
d'abord son r^ole et sa d'efinition, suivi des d'etails techniques la concernant. Nous montrerons
ensuite que cette primitive respecte l'ensemble des invariants.

11.2.1 Transformation unimodulaire g'en'erique

Cette transformation est la primitive utilis'ee par toutes les transformations unimodulaires
gauches, comme la permutation de boucle, l'inversion de boucle ou le skewing. Du point de
vue du formalisme, elle affecte les lignes impaires (en commen,cant la num'erotation `a 0) de la
matrice \Theta , ce qui correspond `a la concat'enation des matrices A et \Gamma  que nous noterons rA " " " \Gamma s.
L'op'eration matricielle a effectu'ee est M ^ rA " " " \Gamma s, ce qui se d'ecompose en M ^ A et M ^ \Gamma .

112 11. Transformations de Programme dans le Formalisme
D'efinition : La primitive LeftUnimodularpP, M q effectue la transformation unimodulaire
correspondant `a la matrice M pour les instructions ayant comme fi-pr'efixe P . La d'efinition est
la suivante : LeftUnimodular

pP, M q :>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^ A

S DH M ^ AS

\Gamma S DH M ^ \Gamma S

Pr'erequis : La matrice M doit bien sur ^etre unimodulaire, et de m^eme dimension que AS, ce
qui s'exprime comme suit :

@S P SCoP^
^
^
^
^
^ P

D^ fiS n~

$
&

%

dim rowpM q " dim rowpASq
dim colpM q " dim colpASq
detpM q " *1

Invariants : Les matrices AS et \Gamma S de certaines instructions sont affect'ees par cette primitive.
Les invariants `a v'erifier sont donc inv-dim-\Gamma , inv-dim-fi, inv-inv-A. Pour v'erifier les deux premiers invariants sur les dimensions, montrons que les dimensions des matrices AS et \Gamma S restent
inchang'ees.

Soit d la dimension de la matrice carr'ee AS avant d'appliquer la primitive. Les pr'erequis
imposent que la matrice la m^eme dimension `a la matrice M . La premi`ere multiplication multiplie
donc deux matrices de taille pd ^ dq, le r'esultat est donc 'egalement de taille pd ^ dq. La seconde
multiplication multiplie une matrice de taille pd ^ dq par une matrice de taille pdgp ` 1 ^ dq, le
r'esultat est donc de taille pdgp ` 1 ^ dq. Les dimensions des matrices AS et \Gamma S sont conserv'ees.
Les invariants inv-dim-\Gamma  et inv-dim-fi sont donc respect'es.

Revenons au calcul de AS. Il s'agit d'une multiplication de deux matrices inversibles (la matrice AS de d'epart est inversible d'apr`es inv-inv-A, et M est unimodulaire d'apr`es les pr'erequis),
le r'esultat de la multiplication est donc inversible. L'invariant inv-inv-A est respect'e.

11.2.2 Ajout d'une in'equation au Domaine

L'ajout d'in'equations au domaine d'une instruction est une op'eration courante. Elle peut `a
la fois servir `a exprimer une nouvelle contrainte, comme pour la transformations de peeling, ou
`a exprimer de nouvelles bornes de boucles comme dans la transformation de strip-mining.

D'efinition : La primitive AddDomainIneqpP, cq ajoute la contrainte c aux domaines des
instructions ayant comme fi-pr'efixe P . La primitive est d'efinie comme suit :

AddDomainIneqpP, cq :>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^ c2

DH c{ gcdpcq

\Lambda S DH InsRowp\Lambda S, 0, c2q

Pr'erequis : La dimension de la contrainte ins'er'ee dans la matrice \Lambda  doit correspondre au
nombre de colonnes de la matrice, ce qui s'exprime par :

@S P SCoP^
^ P D^ fiS n~ dimpcq " dS ` dSlv ` dgp ` 1

11.2. Primitives 113
Invariants : La primitive ne modifiant que les domaines, le seul invariant `a v'erifier est invprm-\Lambda , qui v'erifie que les coefficients non nuls de chaque ligne de la matrice \Lambda  sont premiers entre
eux dans leur ensemble. Les coefficients de la nouvelle ligne c2 ins'er'ee dans \Lambda  correspondent `a
ceux de c divis'e par le PGCD des coefficients de c, ils respectent donc cette propri'et'e.

11.2.3 Ajout d'une variable locale

L'ajout de variable locale permet d'exprimer de nouveaux modulos dans le formalisme. Le
strip-mine peut par exemple ^etre r'ealis'e avec un stride, et ce nouveau stride peut ^etre exprim'e
par une 'equation du type i " 4p avec p une variable locale non contrainte.

L'ajout de l''equation i " 4p proprement dite est effectu'e par un double appel `a la primitive
AddDomainIneq pr'esent'ee ci-dessus. Mais il faut auparavant permettre l'existence de cette
nouvelle variable p. C'est ce que r'ealise cette primitive.

D'efinition : La primitive AddLocalVarpP q ajoute une nouvelle variable locale aux instructions ayant comme fi-pr'efixe P . La d'efinition de la primitive est la suivante :

AddLocalVarpP q :>
>
>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^
^
^
^
^

dSlv DH dSlv ` 1
\Lambda S DH InsColp\Lambda S, dS ` 1, 0q
@pT, Fq P LShs Y RShs^
^ F DH InsColpF, dS ` 1, 0q

La nouvelle variable locale est ins'er'ee juste apr`es les it'erateurs. La dimension correspondant
`a la nouvelle variable locale est donc dS ` 1.

Pr'erequis : L'ajout de variable locale est toujours l'egal, et n'a aucun effet tant que cette
nouvelle variable locale n'est pas utilis'ee par les primitives AddDomainIneq qui suivent.

Invariants : Cette primitive ne modifie que les domaines et les fonctions d'acc`es aux tableaux
de certaines instructions. Le seul invariant `a v'erifier est donc une nouvelle fois inv-prm-\Lambda , qui
v'erifie que les coefficients non nuls de chaque ligne de la matrice \Lambda  sont premiers entre eux dans
leur ensemble. La transformations se bornant `a ins'erer une colonne de 0 dans certaines matrices
\Lambda , cette propri'et'e est v'erifi'ee.

11.2.4 Ajout d'une it'erateur (Extension)

L'ajout d'un nouvel it'erateur permet de cr'eer de nouveaux nids de boucles. La primitive
Extend permet d'ajouter un nouvel it'erateur, mais ne renseigne pas sur les bornes de ce nouvel
it'erateur.

D'efinition : La primitive ExtendpP, l, cq ajoute un nouvel it'erateur aux instructions ayant
comme fi-pr'efixe P . Ce nouvel it'erateur est ins'er'e dans la matrice A `a la ligne l et la colonne c.

114 11. Transformations de Programme dans le Formalisme
La d'efinition de la primitive est la suivante :

ExtendpP, l, cq :>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^

dS DH dS ` 1
AS DH InsColpAS, c, 0q
AS DH InsRowpAS , l, 0q
ASl,c DH 1
\Gamma S DH InsRowp\Gamma S, l, 0q
fiS DH InsRowpfiS, l, 0q
@M P \Lambda S^
^ M DH InsColpM, c, 0q

@pT, o, ST , Fq P LShs Y RShs^
^ F DH InsColpF, c, 0q

oeS DH InsRowpoeS , l, 0q

Toutes les matrices du formalisme sont ainsi 'etendues pour prendre en compte ce nouvel
it'erateur, mais aucune contrainte n'est impos'ee sur cet it'erateur. Pour ajouter les contraintes
n'ecessaires sur cet it'erateur pour respecter l'invariant inv-bnd-its, il faut utiliser la primitive
AddDomainIneq.

Pr'erequis : L'extension est toujours l'egale, mais pour ^etre valide n'ecessite un double appel `a
AddDomainIneq pour borner l'it'erateur.

Invariants : Une nouvelle ligne est ajout'ee aux matrices A et \Gamma  ainsi qu'au vecteur fi. Une
colonne est 'egalement ajout'e `a la matrice A qui reste donc carr'ee. Les invariants inv-dim-\Gamma  et
inv-dim-fi sont donc respect'es.

Dans la matrice A une ligne et une colonne de 0 sont ajout'es et un 1 est plac'e `a l'intersection.
La valeur du nouveau d'eterminant est donc inchang'ee ('eventuellement au signe pr`es) comme
le montre la figure 11.5. Le nouveau d'eterminant est donc non-nul, et l'invariant inv-inv-A est
v'erifi'e.

^
^
^
^
^
^
^
^

a b 0 c

0 0 1 0
d e 0 f
g h 0 i

^
^
^
^
^
^
^
^

" *1 ^

^
^
^
^
^
^

a b c
d e f

g h i

^
^
^
^
^
^

Fig. 11.5 - Calcul du nouveau d'eterminant
Les invariants de s'equentialit'e et de densit'e des vecteurs d'ordonnancement inv-seq-fi et invden-fi sont 'egalement respect'e car c'est un 0 qui est ins'er'e dans les vecteurs d'ordonnancement.

Finalement, ajout'e une colonne de z'ero dans les matrices de \Lambda  n'a pas d'effet sur la valeur
du PGCD des coefficients non-nuls donc inv-prm-\Lambda  est respect'e, et comme indiqu'e ci-dessus
l'invariant inv-bnd-its n'est pas respect'e pour le nouvel it'erateur, et des appels `a la primitive
AddDomainIneq sont n'ecessaires.

115
Chapitre 12
Listes des transformations de codes
usuelles

Apr`es avoir pr'esent'e dans le Chapitre 11 les constructeurs et les primitives qui permettent
de construire les transformations de programmes dans le formalisme, nous allons pr'esenter un
ensemble de transformations de programme usuelles.

Nous pr'esenterons chacune de ces transformations dans sa repr'esentation syntaxique, puis
dans celle correspondant `a notre formalisme, soulignant le b'en'efice apport'e par la repr'esentation
poly'edrique. Chaque transformation est illustr'ee par un exemple d'etaill'e, une d'efinition formelle
dans notre formalisme, et d'une preuve du respect des invariants du formalisme.

12.1 Fusion de boucle (Loop Merging)

La fusion de boucle, qui fusionne deux boucles en une seule, peut cr'eer des opportunit'es de
promotions scalaires en rassemblant en une seule boucle les utilisations multiples d'un tableau.

12.1.1 Repr'esentation syntaxique
D'efinition : La fusion de boucle prend deux boucles adjacentes dont on peut statiquement
d'eterminer que le nombre d'it'eration est identique, et combine leur corps de boucle en une unique
boucle. Pour fusionner deux boucles, leur bornes de boucles doivent ^etre identiques.

Exemple : Suit un exemple de fusion des deux boucles i en une seule boucle. Dans la repr'esentation syntaxique, seules les instructions des deux boucles (ici S2 et S3) sont affect'ees par la
transformation.

avant fusion
for(k=0; k<Z ; k++)

S1
for(i=0; i<N; i++)

S2
for(i=0; i<N; i++)

S3
S4
S5

apr`es fusion
for(k=0; k<Z ; k++)

S1
for(i=0; i<N; i++)

S2
S3
S4
S5

116 12. Listes des transformations de codes usuelles
12.1.2 Repr'esentation dans le formalisme
D'efinition : La transformation F usepP q fusionne la boucle correspondant au fi-pr'efixe P avec
la boucle qui la suit. La d'efinition est la suivante :

FusepP q :>
>
>
>
>
>
>
>
>
>

Q DH enclosepP q
R DH P ` 1
b DH betaM axpP q ` 1
MovepR, R, bq
MovepQ, R, '1q

Le premier Move d'ecale les instructions de la seconde boucle `a la dimension d " dimpP q du
nombre d'instructions b dans la premi`ere boucle. Le second Move remonte toutes les instructions de la seconde boucle ainsi que les instructions qui la suivent au niveau d ' 1, r'ealisant
effectivement la fusion.

Pr'erequis : Pour fusionner deux boucles, il faut que ces deux boucles existent, ce qui se v'erifie
comme suit :

^

"

DS P SCoP | P A* fiS

DS P SCoP | P ` 1 A* fiS

Par contre, nous nous affranchissons totalement de la limitation sur les valeurs des bornes
de boucles sans accro^itre la complexit'e du formalisme. C'est le g'en'erateur de code qui effectuera
du versionning pour prendre en charge les parties non communes aux deux boucles, et celuici ne sera appel'e qu'`a la toute fin du processus, lorsque toutes les transformations auront 'et'e
appliqu'ees.

Exemple : Consid'erons l'exemple syntaxique pr'esent'e ci-dessus. La transformation n'affectant que les vecteurs d'ordonnancement fi, int'eressons nous `a leur valeur avant d'appliquer la
transformation de fusion :

fiS1 " 00 fiS2 " 01

0

fiS3 " 02

0

fiS4 " 03 fiS5 " 1

Contrairement `a ce qui se passe dans la repr'esentation syntaxique, les instructions S2 et
S3 ne sont pas les seules affect'ees par la transformation. Le vecteur d'ordonnancement fiS4
de l'instruction S4 ayant un pr'efixe commun avec celui de l'instruction S2, elle est 'egalement
affect'ee, mais pas l'instruction S5. Les nouveaux vecteurs d'ordonnancement sont alors :

fiS1 " 00 fiS2 " 01

0

fiS3 " 01

1

fiS4 " 02 fiS5 " 1

Cette transformation correspond `a Fusepr 0 1 sq.
12.2 Fission de boucle (Loop fission, Loop distribution)

La fission de boucle r'ealise l'oppos'e de la fusion de boucle en s'eparant une unique boucle en
deux boucles distinctes.

12.2. Fission de boucle (Loop fission, Loop distribution) 117
12.2.1 Repr'esentation syntaxique
D'efinition : La fission prend une boucle contenant plusieurs instructions, et la s'epare en deux
boucles avec le m^eme "iteration-space traversal", telles que les instructions de la boucle de d'epart
se retrouvent soit dans la premi`ere boucle, soit la seconde boucle.

Exemple : L'exemple ci-dessous pr'esente la fission d'une boucle i en deux, commen,cant la
fission `a l'instruction S3. Encore une fois avec la repr'esentation syntaxique seules les instructions
de la boucle (ici S2 et S3) semblent ^etre affect'ees par la transformation.

avant fission
for(k=0; k<Z ; k++)

S1
for(i=0; i<N; i++)

S2
S3
S4
S5

apr`es fission
for(k=0; k<Z ; k++)

S1
for(i=0; i<N; i++)

S2
for(i=0; i<N; i++)

S3
S4
S5

12.2.2 Repr'esentation dans le formalisme
D'efinition : La transformation FissionpP q fissionne `a partir de l'instruction S de fi-pr'efixe
P la boucle englobant l'instruction S. La d'efinition est la suivante :

FissionpP q :>
>
>
>
>
>
>
>
>
>

Q " enclosepP, 2q
R " enclosepP q ` 1
b " P pdimpP q ' 1q
MovepQ, P, 1q
MovepR, R, 'bq

Pr'erequis : L'existence de l'instruction `a partir de laquelle pratiquer la fission, et son appartenance `a une boucle se v'erifie comme suit :

^

" dim

pP q a, 1

DS P SCoP | P " fiS

Contrairement `a la fusion, la fission n'engendre aucun risque de versionning.

Exemple : Consid'erons l'exemple syntaxique ci-dessus. La transformation Fission ne modifie
que les vecteurs d'ordonnancement fi de certaines instructions. Int'eressons nous `a leur valeur
avant d'appliquer la transformation :

fiS1 " 00 fiS2 " 01

0

fiS3 " 01

1

fiS4 " 02 fiS5 " 1

Contrairement au comportement de la repr'esentation syntaxique, les instructions S2 et S3
ne sont pas les seules `a ^etre affect'ees par la transformation. Le vecteur d'ordonnancement fiS4
de l'instruction S4 poss'edant un pr'efixe commun avec ces instructions, cette instruction est

118 12. Listes des transformations de codes usuelles
'egalement d'eplac'ee. L'instruction S5, par contre, n'est pas affect'ee par la transformation. Apr`es

avoir appliqu'e la transformation, les vecteurs d'ordonnancement des instructions deviennent :

fiS1 " 00 fiS2 " 01

0

fiS3 " 02

0

fiS4 " 03 fiS5 " 1

Cela correspond `a la transformation Fissionpr 0 1 1 sq
12.3 D'eplacement de blocs de code (Code Motion)

La fusion de boucles se limite `a fusionner `a la m^eme dimension des boucles cons'ecutives. La
transformation de d'eplacement de code est une extension de la fusion de boucle, qui permet de
d'eplacer des blocs de code arbitraires et de les ins'erer `a une dimension arbitraire.

12.3.1 Repr'esentation syntaxique

Le d'eplacement de blocs de codes est utilis'e pour rapprocher les producteurs de donn'ees des
consommateurs. C'est une transformation classique de l'optimisation `a la main des codes sources
effectu'ee par couper / coller. Elle permet souvent de supprimer des tableaux temporaires.

D'efinition : Le d'eplacement de blocs de codes translate un bloc d'instructions, pour rapprocher des instructions ou rendre l'egales des transformations.

Exemple : L'exemple ci-dessous correspond au d'eplacement du bloc consommant le tableau
A pour le rapprocher de son initialisation. Pour qu'un tel d'eplacement soit l'egal, il ne faut pas
que le tableau A soit r'eaffect'e dans les instructions S2 . . .SN .

avant motion
for(i=0; i<N ; i++)

for(j=0; j<N; j++)
(S1) A[i][j]=i+j
(S4) ...
... ...

(SN) ...

for(i=0; i<N ; i++)

for(j=0; j<N; j++)
(S2) ... = ... * A[i][j]
(S3) ...

apr`es motion
for(i=0; i<N ; i++)

for(j=0; j<N; j++)
(S1) A[i][j]=i+j
(S2) ... = ... * A[i][j]
(S4) ...
... ...

(SN) ...
(S3) ...

12.3.2 Repr'esentation dans le formalisme

Le d'eplacement de code dans le formalisme est r'ealis'e en modifiant les vecteurs d'ordonnancements des instructions, en leur appliquant la m^eme translation.

D'efinition : La transformation MotionpP, T q d'eplace l'ensemble des instructions pr'efix'ees
par P vers la destination T . La profondeur des instructions reste inchang'ee. La d'efinition est la

12.3. D'eplacement de blocs de code (Code Motion) 119
suivante :

MotionpP, T q :>
>
>
>
>
>
>
>
>
>
>
>
>
>

dimpP q ` 1 " dimpT q n~ bs DH betaM axpP q ` 1
dimpP q ` 1 0 dimpT q n~ bs DH 1
D DH T ' pref ixpP, dimpT qq
MovepenclosepT q, T, bsq
@S P SCoP tel que P D^ fiS^
^ fiS DH fiS ` D

MovepP, P, '1q

Les trois premi`eres lignes calculent la taille du bloc `a d'eplacer bs et la translation correspondant au d'eplacement D. Le premier Move cr'ee le trou de taille bs dans lequel vont ^etre d'eplac'ees
les instructions. La boucle d'eplace les instructions par une translation de D. Enfin le dernier
Move rebouche le trou cr'e'e par le d'eplacement des instructions qui correspond `a leur position
initiale. La taille de ce trou est toujours de 1.

Pr'erequis : La profondeur des instructions 'etant inchang'ees, il s'agit de s'assurer que la
profondeur de la destination est compatible avec celle des instructions sources. Cela est v'erifi'e
de la mani`ere suivante :

dimpT q d^ dimpP q ` 1

Exemple : Reprenons l'exemple du mod`ele syntaxique en consid'erant qu'il n'y qu'une seule
instruction S3 entre les deux boucles `a rapprocher. Avant la transformation, les vecteurs d'ordonnancement des instructions S1, S2, S3 et S4 sont :

fiS1 " 00

0

fiS2 " 20

0

fiS3 " 3... fiS4 " 1...

La transformation Motion([2 0],[0 0 1]), engendre une translation de D "[ -2 0 1 ], et modifie
les vecteurs d'ordonnancement de la mani`ere suivante :

fiS1 " 00

0

fiS2 " 00

1

fiS3 " 2... fiS4 " 1...

Invariants : Cette transformation affectant uniquement les vecteurs d'it'eration des instructions, les seuls invariants `a v'erifier sont ceux concernant les vecteurs d'it'eration. Le premier
Move cr'ee un trou de taille bs dans lequel est d'eplac'e un bloc de code de taille bs qui le remplit
donc int'egralement. De plus l'ordre des instructions d'eplac'e est conserv'e, donc la propri'et'e de
s'equentialit'e 'egalement. Le second Move rebouche le trou laiss'e par les instructions d'eplac'ees.
La taille de ce trou est forc'ement de 1. En effet, si une seule instruction est d'eplac'ee, cette taille
est effectivement 1. Si plusieurs instructions sont d'eplac'ees, alors toutes les instructions avec le
m^eme fi-pr'efixe sont d'eplac'ees, ce qui cr'ee effectivement un trou de 1 `a la dimension dimpP q (la
dimension correspondant au nid de boucle d'eplac'e). Le trou est donc effectivement bouch'e par
le Move qui assure le respect des invariants de s'equentialit'e et de densit'e.

120 12. Listes des transformations de codes usuelles
12.4 Permutation de boucles (Loop Interchange)

La permutation de boucle est une transformation unimodulaire tr`es utilis'ee dans l'optimisation de code, car elle permet de changer la localit'e spatiale des r'ef'erences m'emoires apparaissant
dans la paire de boucle, et peut 'egalement favoriser la promotion scalaire dans la nouvelle boucle
interne.

12.4.1 Repr'esentation syntaxique
D'efinition : La transformation de permutation de boucle 'echange l'ordre de deux boucles
cons'ecutives dans un nid de boucle.

Exemple : L'exemple ci-dessous montre un exemple syntaxique de la permutation de deux
boucles i et j.

avant permutation
for(i=0; i<N; i++)

for(j=0; j<M; j++)

S1
S2

apr`es permutation
for(j=0; j<M; j++)

for(i=0; i<N; i++)

S1
S2

12.4.2 Repr'esentation dans le formalisme

La figure ci-dessous repr'esente l'espace d'it'eration d'une instruction S et les poly`edres correspondant avant et apr`es avoir appliqu'e la transformation (ici la permutation de i et j). Les
fl`eches rouges repr'esentent l'ordre de travers'ee des poly`edres.

j
i

b b b b
b b b b
b b b b
b b b b

0 1 2 3 4 5
1
2
3
4
5

j

i

b b b b
b b b b
b b b b
b b b b

0 1 2 3 4 5
1
2
3
4
5

D'efinition : La transformation InterchangepP, oq permute les dimensions o et o ` 1 des
instructions ayant P comme fi-pr'efixe. La d'efinition est la suivante :

InterchangepP, oq :>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^
^
^
^
^
^
^
^
^
^
^

d DH dimpASq
M DH Idpdq
Mo,o DH 0
Mo`1,o`1 DH 0
Mo,o`1 DH 1
Mo`1,o DH 1
LeftUnimodularpfiS, M q

La transformation Interchange appelle la transformation unimodulaire LeftUnimodular
avec une matrice M qui est la matrice identit'e avec deux lignes cons'ecutives 'echang'ees. Par

12.5. Inversion de boucle (Loop Reversal) 121
exemple, pour dimpP q " 5, et o " 3, la matrice M serait :

M "

>>
--
--
--
--
-

1 0 0 0 0
0 1 0 0 0
0 0 0 1 0
0 0 1 0 0
0 0 0 0 1

fi
ffi
ffi
ffi
ffi
fl

Pour la permutation de boucle classique (du point de vue syntaxique) la valeur de o est
'egale `a dimpP q ' 1. Toutes les instructions de la paire de boucle sont alors permut'ees. Notre

formalisme permet 'egalement de n'interchanger que certaines des instructions avec une valeur
de o inf'erieure `a dimpP q ' 1.

Pr'erequis : Il faut que les deux dimensions concern'ees par l'inversion soit inf'erieure `a celle
du pr'efixe, car sinon des dimensions inexistantes pourraient ^etre permut'ees. Cela s''ecrit :

o d^ dimpP q ' 1

Exemple : Reprenons l'exemple fourni dans la section syntaxique permutant les boucles i et
j. La matrice M vaudrait M i

` 0 1

1 0

ae. Les valeurs des matrices A avant d'appliquer la transformation sont : Avant d'appliquer la transformation, la matrice A de l'instruction est :

` 1 0

0 1

ae et

apr`es application de la transformation, elle devient

` 0 1

1 0

ae.

Invariants : La transformation Interchange consistant en un appel `a la transformation
LeftUnimodular, elle respecte les invariants si la matrice M est unimodulaire, ce qui est le
cas par construction.

12.5 Inversion de boucle (Loop Reversal)

L'une des trois transformations unimodulaires de base, l'inversion de boucle est g'en'eralement
utilis'ee pour am'eliorer l'applicabilit'e de certaines heuristiques pour la parall'elisation de boucles.

12.5.1 Repr'esentation syntaxique
D'efinition : L'inversion de boucle inverse l'ordre dans lequel une it'eration particuli`ere d'une
boucle est r'ealis'ee.

Exemple : Ci-dessous, un exemple d'inversion de boucle sur la boucle j.

avant inversion
for(i=0;i<N;i++)

for(j=0;j<N;j++)

S1
S2

apr`es inversion
for(i=0;i<N;i++)

for(j=N-1;j>=0;j--)

S1
S2

122 12. Listes des transformations de codes usuelles
12.5.2 Repr'esentation dans le formalisme

La figure ci-dessous repr'esente l'espace d'it'eration d'une instruction S et les poly`edres correspondant avant et apr`es avoir appliqu'e la transformation (ici l'inversion de la boucle j). Les
fl`eches repr'esentent l'ordre de travers'ee des poly`edres.

j
i

b b b b
b b b b
b b b b
b b b b

0 1 2 3 4 5
1
2
3
4
5

j

i

b b b b
b b b b
b b b b
b b b b

0 1 2 3 4 5
1
2
3
4
5

D'efinition : La transformation ReversepP, oq inverse l'ordre de parcours pour les instructions
ayant P comme fi-pr'efixe, sur l'it'erateur de la dimension o. La transformation est d'efinie comme
suit :

ReversepP, oq :>
>
>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^
^
^
^
^

d DH dimpASq
M DH Idpdq
Mo,o DH '1
LeftUnimodularpfiS, M q

La transformation Reverse est r'ealis'ee en appelant la transformation unimodulaire gauche
g'en'erique LeftUnimodular, avec comme matrice unimodulaire une matrice diagonale avec le
coefficient de la dimension o 'egal `a '1 et non 1. Par exemple, pour dimpP q " 4, et o " 3, la
matrice M serait :

M "

>>
--
--
-

1 0 0 0
0 1 0 0
0 0 '1 0
0 0 0 1

fi
ffi
ffi
fl

Un comportement identique `a la version syntaxique (l'inversion des it'erations de toutes les
instructions d'une boucle) correspond `a une valeur de o " dimpP q. Mais le formalisme permet
'egalement pour des valeurs de o a* dimpP q d'inverser les it'erations de certaines instructions de

la boucles, sans inverser les autres.

Pr'erequis : Il faut que la dimension concern'ee par l'inversion soit inf'erieure `a celle du pr'efixe,
car sinon une dimension inexistante pourrait ^etre invers'ee. Cela s''ecrit :

o d^ dimpP q

Exemple : Consid'erons dans un premier temps la transformation correspondant `a celle r'ealis'ee
avec la repr'esentation syntaxique. La matrice M vaudrait alors M i

` 1 0

0 \Delta 1

ae , et la valeur des

matrices A des instructions S1 et S2 passerait de

` 1 0

0 1

ae avant d'appliquer la transformation `a

` 1 0

0 \Delta 1

ae apr`es l'application de la transformation. Cet exemple correspond `a la transformation

Reversepr 0 0 s, 2q.

12.6. Torsion de boucles (Skewing) 123

Consid'erons dans un second temps la transformation correspondant `a l'inversion de la premi`ere instruction seule. Ceci est r'ealis'e par Reversepr 0 0 0 s, 2q, et produit les m^emes effets
que pr'ec'edemment sur l'instruction S2 mais n'affecte pas S3.

Invariants : La transformation Reverse s'effectuant par un appel `a la transformation unimodulaire g'en'erique LeftUnimodular, elle respecte donc naturellement les invariants du formalisme si les pr'erequis de la transformation LeftUnimodular sont respect'es, c'est `a dire si
la matrice M est unimodulaire, ce qui est le cas par construction.

Notes : Consid'erons l'exemple simple suivant : une boucle for allant de 1 `a N ex'ecutant deux
instructions S1 et S2. La trace d'ex'ecution de cet exemple est le suivant :

S1r0s; S2r0s; S1r1s; S2r1s; S1r2s; S2r2s; " " " ; S1rN s; S2rN s
Apr`es l'inversion de la boucle pour la premi`ere instruction uniquement, la trace d'ex'ecution
du code g'en'er'e tel quel serait :

S1rN s; S1rN ' 1s; " " " ; S1r1s; S1r0s; S2r0s; S2r1s; S2r2s; " " " ; S2rN s
Notez que les instructions S1 et S2 ne sont pas interlac'ees. Pour qu'elle le soient, il faut
r'e-aligner les deux instructions de d'epart (S1rN s et S2r0s) au moyen d'un Shift. En shiftant le
N it'erations vers le bas l'instruction S1 (ou vers le haut l'instruction S2), la trace d'ex'ecution
devient alors :

S1rN s; S2r0s; S1rN ' 1s; S2r1s; S1rN ' 2s; S2r2s; " " " ; S1r0s; S2rN s

12.6 Torsion de boucles (Skewing)

La transformation de Skew, est une des trois transformations unimodulaires de base, qui
modifie la forme de l'espace d'it'eration. Elle est r'ealis'ee pour rendre parall`ele l'ordre de travers'ee
de l'espace d'it'eration et les d'ependances, pour rendre possible la parall'elisation de la boucle
interne.

12.6.1 Repr'esentation syntaxique
D'efinition : La transformation de skewing r'ealise une torsion de l'espace d'it'eration, effectuant
un changement de rep`ere qui peut rendre possible la parall'elisation lorsque les d'ependances ne
sont pas parall`eles aux axes.

Exemple : L'exemple ci-dessous correspond au skewing de la double boucle i, j en deux nouveaux it'erateurs x, y tels que x " i et y " j ` i.

avant skewing
for(i=1;i<N;i++)

for(j=1;j<N;j++)

A[i,j]=A[i-1,j]+A[i,j-1]

apr`es skewing
for(x=1;x<N;i++)

for(y=x+1;y<x+N;y++)

A[x,y-x]=A[x-1,y-x]+A[x,y-x-1]

124 12. Listes des transformations de codes usuelles
12.6.2 Repr'esentation dans le formalisme

La figure ci-dessous repr'esente l'espace d'it'eration d'une instruction S et les poly`edres correspondants avant et apr`es avoir appliqu'e la transformation. Les fl`eches rouges repr'esentent l'ordre
de travers'ee des poly`edres.

j
i

b b b b
b b b b
b b b b
b b b b

0 1 2 3 4 5
1
2
3
4
5

j

i

b b b b
b b b b
b b b b
b b b b

0 1 2 3 4 5 6 7 8
1
2
3
4
5

D'efinition : La transformation SkewpP, s, r, cq r'ealise un skewing de facteur s non nul des
instructions dont P est un fi-pr'efixe. La d'efinition est la suivante :

SkewpP, s, r, cq :>
>
>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^
^
^
^
^

d DH dimpASq
M DH Idpdq
Mr,c DH s
LeftUnimodularpfiS, M q

La transformation Skew s'effectue gr^ace `a la transformation unimodulaire gauche g'en'erique
LeftUnimodular, avec comme matrice unimodulaire une matrice diagonale avec le facteur de
skew s aux coordonn'ees r, c. Par exemple, pour dimpP q " 5, s " 7, r " 3 et c " 2, la matrice
M serait :

M "

>>
--
--
--
--
-

1 0 0 0 0
0 1 0 0 0
0 S 1 0 0
0 0 0 1 0
0 0 0 0 1

fi
ffi
ffi
ffi
ffi
fl

Pr'erequis : La matrice M doit ^etre unimodulaire, et du facteur de skewing s qui doit ^etre
non nul. Ce qui s''ecrit :

^

$
&

%

dimpP q a, 1
r 0 c
s 0 0

Exemple : Reprenons l'exemple fournie dans la section syntaxique, avec les nouveaux it'erateurs x " i et y " j ` i. La matrice M vaudrait M i

` 1 0

1 1

ae. Les valeurs des matrices A

avant d'appliquer la transformation sont : Avant d'appliquer la transformation, la matrice A de
l'instruction est :

` 1 0

0 1

ae et apr`es application de la transformation, elle devient ` 1 0

1 1

ae.

Invariants : La transformation Skew s'effectuant par un appel `a la transformation unimodulaire g'en'erique LeftUnimodular, elle respecte naturellement les invariants du formalisme,
si les pr'erequis de la transformation LeftUnimodular sont respect'es, c'est `a dire si la matrice
M est unimodulaire, ce qui est le cas par construction.

12.7. 'Epluchage d'it'erations (Peeling) 125
12.7 'Epluchage d'it'erations (Peeling)

L''epluchage d'it'erations est tr`es souvent utilis'e pour s'eparer un nid de boucle en un prologue
(ou un 'epilogue) et un coeur de boucle afin de permettre de transformer plus avant le coeur de la
boucle. Quelques it'erations de boucles sont ainsi g'en'eralement 'epluch'ees. Cette transformation
de boucle est souvent utilis'ee dans les compilateurs pour rendre les transformations comme la
fusion de boucle (qui requiert des bornes de boucles identiques) possibles, ou pour permettre de
calculer des invariants de boucles sur le coeur.

12.7.1 Repr'esentation syntaxique
D'efinition : La transformation de peeling appliqu'ee sur une boucle permet de sortir les premi`eres (ou les derni`eres) it'erations de la boucle. Ces instructions peel'ees se retrouvent donc `a
l'ext'erieur de la boucle et les bornes de la boucle sont mises `a jour en cons'equence.

Exemple : L'exemple ci-dessous correspond au peeling de la premi`ere et de la derni`ere it'eration
de la boucle i :

avant peeling
for(i=0; i<=N; i++)

S1[i]=...
S2[i]=...
S3[i]=...

apr`es peeling
S1[0]=...

S2[0]=...
S3[0]=...
for(i=1; i<N; i++)

S1[i]=...
S2[i]=...
S3[i]=...
S1[N]=...
S2[N]=...
S3[N]=...

12.7.2 Repr'esentation dans le formalisme

Dans le formalisme, l''epluchage d'it'erations s'exprime sur les domaines des instructions. Les
instructions d'une boucle sont ainsi dupliqu'ees dans deux boucles aux domaines compl'ementaires. Contrairement au comportement dans le mod`ele syntaxique, la boucle correspondant aux
instructions peel'ees n'est pas d'eroul'ee. L''epluchage des deux premi`eres it'erations d'une boucle
correspondrait donc `a :

avant peeling
for(i=0; i<=N; i++)

S1[i]=...
S2[i]=...

apr`es peeling
for(i=0; i<2; i++)

S1[i]=...
S2[i]=...
for(i=2; i<N; i++)

S1[i]=...
S2[i]=...

D'efinition : La transformation PeelpP, cq r'ealise un 'epluchage d'it'erations sur les instructions
ayant pour fi-pr'efixe P . L''epluchage est r'ealis'e pour l'it'erateur i `a la dimension l " dimpP q, le
vecteur c de dimension dgp ` 1 repr'esente la fronti`ere d''epluchage : Toutes les instructions de fipr'efixe P sont dupliqu'ees dans deux boucles aux domaines compl'ementaires par les contraintes

126 12. Listes des transformations de codes usuelles
i a* c et i e^ c. La d'efinition est la suivante :

PeelpP, cq :>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

l DH dimpP q
DS P SCoP tel que P A* fiS^
^ MovepenclosepP q, P, 1q

@S P SCoP tel que P A* fiS^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^

S2 DH S
fiSl DH fiSl ' 1

v1 DH ~0d

S

' 1l

v2 DH ~0d

S

` 1l

v1 DH v1 , c
v2 DH v2 ,

`

p'1q ^ c ' 1

*

AddDomainIneqpfiS, v1q
AddDomainIneqpfiS2, v2qS

CoP DH SCoP Y t S2 u

Pr'erequis : Le vecteur c exprime une contrainte pour un it'erateur donn'e par rapport aux
param`etres globaux du SCoP. Sa dimension est donc fix'ee par le nombre de param`etres globaux :

dimpcq " dgp ` 1

Note : L'ensemble des instructions peel'ees se retrouve dupliqu'e, ce qui augmente la complexit'e du formalisme, alors que l'ensemble des matrices concernant les deux instructions est
quasi-identiques (Mis `a part les deux in'equations compl'ementaires dans les domaines,et les fi
cons'ecutifs). Nous envisageons dans un futur proche de pouvoir d'efinir plusieurs instances d'une
m^eme instructions, chacune avec des domaines disjoints, qui permettraient d''eviter cette duplication. Les diff'erentes instances partagerait alors le m^eme vecteur d'it'eration, et il faudrait donc
trouver une mani`ere de distinguer les deux instances.

Exemple : Consid'erons de nouveau le pealing des deux premi`eres instructions du code pr'esent'e dans la repr'esentation poly'edrique. Les domaines et les vecteurs d'ordonnancements des
instructions S1 et S2 sont les suivants :

DS*om "

$
'&

'%

i N 11 0 0
'1 1 0

,
/.

/- fi

S1 " 00 fiS2 " 01

Apr`es peeling des deux premi`eres it'erations par la transformation Peelpr0s, r 0 0 1 sq chaque
instruction Sk est remplac'ee par les instructions Sk1 et Sk2 dont les vecteurs d'ordonnancement
et les domaines sont les suivants :

DS*

1

om "

$
''
'&

''
'%

i N 11 0 0
'1 1 0
'1 0 1

,
//
/.

//
/-

fiS1

1

" 00 fiS2

1

" 01

DS*

2

om "

$
''
'&

''
'%

i N 11 0 0
'1 1 01 0

'2

,
//
/.

//
/-

fiS1

2

" 10 fiS2

2

" 11

12.8. 'Epluchage du temps (Time Peeling) 127
Invariants : Les domaines des instructions transform'ees sont modifi'es par la transformation
AddDomainIneq qui respecte les invariants sur les domaines. La transformation de peeling
cr'ee d'abord un trou pour la nouvelle boucle (celle correspondant aux instructions peel'ees) puis
les instructions de la boucle de d'epart sont dupliqu'ees dans cette nouvelle boucle, assurant le
respect des invariants d'ordonnancement.

12.8 'Epluchage du temps (Time Peeling)

L''epluchage d'it'eration d'efini dans la section pr'ec'edente 'epluche des it'erations des it'erateurs du domaine. Il est 'egalement int'eressant de pouvoir 'eplucher les it'erations des boucles
g'en'er'ees, c'est `a dire d''eplucher parall`element `a l'ordonnancement impos'e par la matrice \Theta . La
transformation TimePeel r'ealise cette op'eration.

La m'ethodologie est exactement la m^eme que pour la transformation Peel, si ce n'est que
les deux vecteurs compl'ementaires v1 et v2 ajout'e aux instructions sont construits diff'eremment,
prenant en compte l'ordonnancement.

D'efinition : La transformation TimePeelpP, cq r'ealise un 'epluchage du temps sur les instructions ayant pour fi-pr'efixe P . L''epluchage est r'ealis'e pour l'it'erateur du temps i `a la dimension
l " dimpP q, la contrainte c repr'esente la fronti`ere d''epluchage : Toutes les instructions de fipr'efixe P sont dupliqu'ees dans deux boucles aux domaines compl'ementaires par les contraintesS

chpiq a* c et Schpiq e^ c. La d'efinition est la suivante :

TimePeelpP, cq :>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

l DH dimpP q
DS P SCoP tel que P A* fiS^
^ MovepenclosepP q, P, 1q

@S P SCoP tel que P A* fiS^
^
^
^
^
^
^
^
^
^
^
^
^
^

S2 DH S
fiSl DH fiSl ' 1
v1 DH ASl , p\Gamma Sl ' c ' 1q
v2 DH ASl , pc ' \Gamma Sl q
AddDomainIneqpfiS, v1q
AddDomainIneqpfiS2, v2qS

CoP DH SCoP Y t S2 u

Pr'erequis : Comme pr'ec'edemment, le vecteur c exprime une contrainte pour un it'erateur
donn'e par rapport aux param`etres globaux du SCoP. La contrainte sur sa dimension est donc :

dimpcq " dgp ` 1

Exemple : Une diff'erence existe entre les transformations Peel et TimePeel si l''epluchage
a lieu dans une boucle pr'ealablement permut'ee, skew'ee ou shift'ee. Consid'erons donc la simple
boucle suivante contenant deux instructions S1 et S2.

for(i=0; i<=N; i++)

S1(i)
S2(i)

128 12. Listes des transformations de codes usuelles
La repr'esentation de cette boucle dans le formalisme apr`es avoir shifter l'instruction S1 de 10
it'erations vers l'avant dans la boucle i est :

AS1 "

i1 \Gamma S1

"

N 10 10 fiS1

" 00 \Lambda S1 "

i N 11 0 0

'1 1 0

AS2 "

i1 \Gamma S2

"

N 10 0 fiS2

" 01 \Lambda S2 "

i N 11 0 0

'1 1 0

Apr`es l''epluchage d'it'eration Peel([0],[0 3]) qui 'epluche les 4 premi`ere it'erations du domaine,
la repr'esentation des instructions situ'ees avant la fronti`ere d''epluchage devient :

AS1 "

i1 \Gamma S1

"

N 10 10 fiS1

" 00 \Lambda S1 "

i N 11 0 0
'1 1 0
'1 0 3

AS2 "

i1 \Gamma S2

"

N 10 0 fiS2

" 01 \Lambda S2 "

i N 11 0 0
'1 1 0
'1 0 3

Les domaines des deux instructions sont identiques. Cela signifie que le peeling va affecter les
instructions shift'ees, consid'erant qu'elle font partie de la boucle.

Alors qu'apr`es l''epluchage du temps TimePeel([0],[0 3]) qui 'epluche les 4 premi`ere it'eration
du temps, la repr'esentation de ses m^emes instructions devient :

AS1 "

i1 \Gamma S1

"

N 10 10 fiS1

" 00 \Lambda S1 "

i N 11 0 0
'1 1 0
'1 0 '7

AS2 "

i1 \Gamma S2

"

N 10 0 fiS2

" 01 \Lambda S2 "

i N 11 0 0
'1 1 0
'1 0 3

Cette fois les deux domaines sont diff'erents, et le peeling ne concerne plus les instructions
pr'ec'edemment shift'ees.

De la m^eme mani`ere pour 'eplucher la nouvelle boucle interne apr`es un interchange, il vaut
mieux utilis'e le TimePeel. Plus g'en'eralement, pour 'eliminer les it'erations correspondant aux
bornes trop complexes des codes g'en'er'es, il faut utiliser la transformation TimePeel, alors que
la transformation Peel est `a utiliser pour r'ealiser des Index Set Splitting.

Invariants : Tout comme pour la transformations Peel , les invariants sont respect'es.

12.9. D'ecalage (Shifting) 129
12.9 D'ecalage (Shifting)

La transformation de d'ecalage Shift est utilis'ee par les transformations de pipeline logiciel,
pour d'ecaler certaines instructions et cr'eer des coeurs de boucles sans d'ependances internes, et
donc parall'elisables. A l'oppos'e un d'ecalage peut 'egalement servir `a raccourcir des distances de
r'eutilisation des valeurs.

12.9.1 Repr'esentation syntaxique
D'efinition : Le d'ecalage de boucle d'eplace des instructions de la boucle entre diff'erentes
it'erations. Le but est de transformer des d'ependances internes en d'ependances port'ees par la
boucle, ou inversement.

Exemple : L'exemple ci-dessous correspond au d'ecalage de l'instruction S1 d'une it'eration
vers l'arri`ere dans la boucle i :

avant d'ecalage

for(i=0;i<=N;i++)

for(j=0;j<=N;j++)

S1(i,j)
S2(i,j)

apr`es d'ecalage
for(j=0;j<=N;j++)

S1(0,j)
for(i=0;i<=N-1;i++)

for(j=0;j<=N;j++)

S1(i+1,j)
S2(i,j)
for(j=0;j<=N;j++)

S2(N,j)

12.9.2 Repr'esentation dans le formalisme

Dans le formalisme le d'ecalage se traduit par une translation des matrices \Gamma  de certaines
instructions. Il est donc possible d'effectuer des d'ecalages param'etriques gr^ace aux param`etres
globaux du SCoP, et de d'ecaler simultan'ement dans plusieurs boucles.

D'efinition : La transformation ShiftpP, M q r'ealise le d'ecalage des instructions pr'efix'ees par
P par la matrice de d'eplacement M . La d'efinition est la suivante :

ShiftpP, M q :>
>
>
>

@S P SCoP tel que P D^ fiS^
^ \Gamma S DH \Gamma S ` M ;

Pr'erequis : La matrice M 'etant additionn'ee aux matrices \Gamma  des instructions dont le fi-pr'efixe
est P , il existe une relation entre les dimensions de ces deux matrices, qui s'exprime ainsi :

" dim col

pM q " dgp ` 1

P D^ fiS n~ dim rowpM q " dS

Exemple : Nous allons reprendre l'exemple correspondant `a la repr'esentation syntaxique, en
nous int'eressant exclusivement aux valeurs des matrices \Gamma . Avant transformations les valeurs de
ces matrices pour les instructions S1 et S2 sont :

\Gamma S1 "

N 10 0

0 0 \Gamma 

S2 "

N 10 0

0 0

130 12. Listes des transformations de codes usuelles

Apr`es shifting de l'instruction S1 d'une it'eration vers l'arri`ere dans la boucle i par la transformation Shift([ 0 0 0 ] , [ 0 -1 ]), les valeurs des matrices deviennent :

\Gamma S1 "

N 10

'10 0 \Gamma S2 "

N 10 0

0 0

Si l'on avait d'ecal'e l'instruction S2 de N it'erations vers l'avant dans la boucle j par la
transformation Shift([ 0 0 1 ],[ 1 0 ]), toutes les it'erations de S1 pour la boucle j auraient 'et'e
effectu'ees avant celles de S2, et la matrice \Gamma S2 serait devenue :

\Gamma S2 "

N 10 0

1 0

Invariants : Les valeurs des matrices \Gamma  n'ont aucun impact sur les invariants du formalisme.
La transformation Shift respecte donc l'ensemble des invariants.

12.10 D'eroulage complet (Full unroll)

Le d'eroulage complet de boucle permet de r'eduire l'impact caus'e par le contr^oles li'es aux
it'erateurs de la boucle d'eroul'ee. Ses principaux d'esavantages sont bien 'evidemment l'augmentation de la taille du code, et le fait que pour d'erouler compl`etement une boucle, il faut ^etre
capable de calculer statiquement le nombre d'it'erations.

12.10.1 Repr'esentation syntaxique
D'efinition : Le d'eroulage complet de boucle consiste `a dupliquer le corps de boucles un
nombre de fois 'egal au nombre d'it'erations de la boucle pour pouvoir totalement 'eliminer cette
derni`ere.

Exemple : L'exemple ci-dessous correspond au d'eroulage complet de la boucle i :

avant d'eroulage
for(i=0;i<4;i++)

for(j=0;j<N;j++)

S1(i,j)

apr`es d'eroulage
for(j=0;j<N;j++)

S1(0,j)
for(j=0;j<N;j++)

S1(1,j)
for(j=0;j<N;j++)

S1(2,j)
for(j=0;j<N;j++)

S1(3,j)

12.10.2 Repr'esentation dans le formalisme

Nous avons indiqu'e dans la Section 9.5, que nous laissions au g'en'erateur de code le soin
d'effectuer les d'eroulages de boucles, et pr'esent'e le vecteur oe permettant d'indiquer au g'en'erateur
quelles boucles d'erouler. Cette transformation de code consiste donc `a modifier ce vecteur de
d'eroulage.

12.11. Strip-mine d'it'erations (sans stride) 131
D'efinition : La transformation FullUnrollpP, lq note que les instructions de fi-pr'efixe P
doivent ^etre d'eroul'ees `a la dimension l. La d'efinition est la suivante :

FullUnrollpP, lq :>
>
>
>

@S P SCoP tel que P D^ fiS^
^ oeSl DH 1

Pr'erequis : Le d'eroulage d'une instruction S est toujours l'egal tant que la dimension reste
inf'erieure `a la profondeur de l'instruction, ce qui s'assure par :

l d^ dimpP q
Notez que comme indiqu'e dans la Section 9.5, une boucle n'est d'eroul'ee `a une dimension donn'ee
que si toutes les instructions de la boucles sont marqu'ees pour ^etre d'eroul'ees `a cette dimension,
et que le nombre d'it'eration peut ^etre calcul'e statiquement.

Exemple : Consid'erons le vecteur de d'eroulage de l'instruction S1 du code pr'esent'e dans la
section de la repr'esentation syntaxique, avant d'eroulage, sa valeur avant et apr`es d'eroulage est
la suivante :

oeS1 "

i j0 0

Y'N~ oeS2 "

i j1 0

Invariants : Aucun invariant n''etant associ'e aux vecteurs de d'eroulage, cette transformation
respecte les invariants du formalisme.

12.11 Strip-mine d'it'erations (sans stride)

Le strip-mining d'ecompose une boucle en deux boucles imbriqu'ees couvrant le m^eme espace
d'it'eration. Cette transformation est utilis'ee par les transformations d'unroll-and-jam et de tiling.
Cette version du strip-minig s''ecrit sans stride `a l'aide de multiplication.

12.11.1 Repr'esentation syntaxique
D'efinition : La transformation de strip-mine d'ecompose un parcours lin'eaire en plusieurs
parcours lin'eaires comme l'indique la figure ci-dessous :

0 N 0 N
La technique consiste `a r'e-'ecrire la boucle sous forme de deux boucles imbriqu'ees. Le petit
parcours est r'ealis'e par la boucle interne, et la boucle externe r'ep`ete ce petit parcours.

Exemple : L'exemple ci-dessous correspond au strip-mine de la boucle i par un facteur 4.

avant strip-mine
for(i=0;i<N;i++)

S1(i)
S2(i)

apr`es strip-mine
for(ii=0;ii<N/4;ii++)

for(i=4*ii;i<min(N,4*ii+3);i++)

S1(i)
S2(i)

Le minimum vient du fait que N n'est pas forc'ement un multiple de 4, et donc que la derni`ere
it'eration de la boucle externe ne doit pas forc'ement parcourir 4 valeurs.

132 12. Listes des transformations de codes usuelles
12.11.2 Repr'esentation dans le formalisme

Dans le formalisme, un strip-mine est facilement repr'esent'e par un Extend qui permet de
cr'eer le nouvel it'erateur, et une s'erie d'ajout d'in'equations aux domaines par AddDomainIneq
pour indiquer les bornes de la nouvelle boucle.

D'efinition : La transformation StripMinepP, kq r'ealise un strip-mine des instructions ayant
pour fi-pr'efixe P `a la dimension l " dimpP q. Le facteur de strip-mine est k. La d'efinition est la
suivante :

StripMinepP ARAM q :
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

l DH dimpP q
ExtendpP, l, lq
@S P SCoP tel que P D^ fiS^
^
^
^
^
^
^
^
^
^

n DH dS ` dSlv ` dgp ` 1
v1 DH ~0n ' k ^ ~1l ` ~1l`1 k ^ ii d^ i
v2 DH ~0n ` k ^ ~1l ' ~1l`1 ` pk ' 1q ^ ~1n i d^ k ^ ii ` k ' 1
AddDomainIneqpfiS, v1q
AddDomainIneqpfiS, v2q

Pr'erequis : Le seul pr'erequis concerne la taille de la tuile qui doit ^etre positive, ce qui s'exprime par :

k a, 0

Exemple : Reprenons l'exemple pr'esent'e pour le mod`ele syntaxique, avant d'appliquer le
strip-mine, l'instruction S1 'etait repr'esent'ee dans le formalisme de la mani`ere suivante :

AS1 "

i1 \Gamma S1

"

N 10 0 fiS1

" 00 \Lambda S1 "

i N 11 0 0

'1 1 '1

Apr`es strip-mine par la transformation StripMine([0],4), la repr'esentation de l'instruction
S1 dans le formalisme devient :

AS1 "

ii i1 0

0 1 \Gamma 

S1 "

N 10 0

0 0 fi

S1 " 00

0 \Lambda 

S1 "

ii i N 10 1 0 0

0 '1 1 '1
'4 1 0 04

'1 0 3

Invariants : En tant que composition de transformations v'erifiant les invariants, la transformation de StripMine v'erifie les invariants. Le nouvel it'erateur cr'ee par la transformation
Extend est born'e par les deux transformations AddDomainIneq.

12.12 Strip-mine d'it'erations (avec stride)

Un strip-mine peut 'egalement ^etre repr'esent'e par une paire de boucle avec un stride, comme
dans l'exemple ci-dessous, qui correspond au m^eme strip-mine que dans la section 12.11.

12.12. Strip-mine d'it'erations (avec stride) 133

avant strip-mine
for(i=0;i<N;i++)

S1(i)
S2(i)

apr`es strip-mine
for(ii=0;ii<N;ii+=4)

for(i=ii;i<min(N,ii+3);i++)

S1(i)
S2(i)

12.12.1 Repr'esentation dans le formalisme

Cette fois, nous 'evitons les multiplication aux niveau de la boucle interne en cr'eant un stride
dans la boucle externe gr^ace `a l''egalit'e ii " k ^ p.

D'efinition : La transformation StripMineStridepP, kq r'ealise un strip-mine des instructions
ayant pour fi-pr'efixe P `a la dimension l " dimpP q. Le facteur de strip-mine est k. La d'efinition
est la suivante :

StripMineStridepP, kq :>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

l DH dimpP q
ExtendpP, l, lq
AddLocalVarpP q
@S P SCoP tel que P D^ fiS^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^

p DH dS ` 1
n DH dS ` dSlv ` dgp ` 1
v1 DH ~0n ' ~1l ` ~1l`1 ii d^ i
v2 DH ~0n ` ~1l ' ~1l`1 ` pk ' 1q ^ ~1n i d^ ii ` k ' 1
v3 DH ~0n ` k ^ ~1p ' ~1l ii " k ^ p
v4 DH ~0n ' k ^ ~1p ` ~1l
AddDomainIneqpfiS, v1q
AddDomainIneqpfiS, v2q
AddDomainIneqpfiS, v3q
AddDomainIneqpfiS, v4q

L''egalit'e ii " k ^ p, avec une variable p libre de toute contrainte assure que ii est un multiple
de k, et ainsi que la boucle externe g'en'er'ee aura un stride de k.

Pr'erequis : Tout comme pour la transformation StripMine la seule contrainte concerne le
param`etre k, et s'exprime par :

k a, 0

Exemple : Reprenons une nouvelle fois le m^eme exemple, en partant de la repr'esentation
suivante :

AS1 "

i1 \Gamma S1

"

N 10 0 fiS1

" 00 \Lambda S1 "

i N 11 0 0

'1 1 '1

Apr`es strip-mine par la transformation StripMineStride([0],4), la repr'esentation de l'instruction S1 dans le formalisme devient :

134 12. Listes des transformations de codes usuelles

AS1 "

ii i1 0

0 1 \Gamma 

S1 "

N 10 0

0 0 fi

S1 " 00

0 \Lambda 

S1 "

ii i p N 10 1 0 0 0

0 '1 0 1 '1
'1 1 0 0 01

'1 0 0 31 0

'4 0 0
'1 0 4 0 0

Invariants : Tout comme la transformation de StripMine, cette transformation respecte les
invariants du formalisme.

12.13 Strip-mine temporel

Les deux transformations d'efinies dans les sections pr'ec'edentes r'ealise un strip-mine sur les
it'erateur des domaines. Tout comme pour la transformation de peeling, il peut ^etre int'eressant
de strip-miner plut^ot les boucles g'en'er'ees.

D'efinition : La transformation TimeStripMinepP, kq r'ealise un strip-mine des instructions
ayant pour fi-pr'efixe P `a la dimension l " dimpP q. Le facteur de strip-mine est k. La d'efinition
est la suivante :

TimeStripMinepP, kq :>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

l DH dimpP q
ExtendpP, l, lq
@S P SCoP tel que P D^ fiS
^
^
^
^
^
^
^
^
^
^

n DH dS ` dSlv ` dgp ` 1
v1 DH pASl`1 , \Gamma Sl`1q ' k ^ ~1l
v2 DH '1 ^ pASl`1 , \Gamma Sl`1q ` k ^ ~1l ` pk ' 1q ^ ~1n
AddDomainIneqpfiS, v1q
AddDomainIneqpfiS, v2q

Comme pour la transformation TimePeel, les deux contraintes ajout'ees au domaine prennent
en compte l'ordonnancement des instructions strip-min'ees. Pour illustrer la diff'erence entre les
transformations StripMine et TimeStripMine, consid'erons le code suivant :

for(i=0; i<=N; i++)

S1(i)
S2(i)

Apr`es un shift de 10 it'erations vers l'avant, la repr'esentation des instructions S1 et S2 devient
la suivante :

AS1 "

i1 \Gamma S1

"

N 10 10 fiS1

" 00 \Lambda S1 "

i N 11 0 0

'1 1 0

AS2 "

i1 \Gamma S2

"

N 10 0 fiS2

" 01 \Lambda S2 "

i N 11 0 0

'1 1 0

12.14. Privatisation de tableau (Array privatization) 135

Apr`es strip-mine par la transformation StripMine([0],4), la repr'esentation des instructions
S1 et S2 devient :

AS1 "

ii i1 0

0 1 \Gamma 

S1 "

N 10 0

0 10 fi

S1 " 00

0 \Lambda 

S1 "

ii i N 10 1 0 0

0 '1 1 0
'4 1 0 04

'1 0 3

AS2 "

ii i1 0

0 1 \Gamma 

S2 "

N 10 0

0 0 fi

S2 " 00

1 \Lambda 

S2 "

ii i N 10 1 0 0

0 '1 1 0
'4 1 0 04

'1 0 3

Apr`es strip-mine par la transformation TimeStripMine([0],4), la repr'esentation des instructions S1 et S2 devient :

AS1 "

ii i1 0

0 1 \Gamma 

S1 "

N 10 0

0 10 fi

S1 " 00

0 \Lambda 

S1 "

ii i N 10 1 0 0

0 '1 1 0
'4 1 0 104

'1 0 '7

AS2 "

ii i1 0

0 1 \Gamma 

S2 "

N 10 0

0 0 fi

S2 " 00

1 \Lambda 

S2 "

ii i N 10 1 0 0

0 '1 1 0
'4 1 0 104

'1 0 '7

Ainsi la transformation StripMine affecte 'egalement les instructions shift'ees, alors que la
transformation TimeStripMine n'affecte que les instructions restantes de la boucle. Lorsque
des instructions seront shift'ee pour rendre l'egal un strip-mine, il faudra donc utiliser un TimeStripMine.

12.14 Privatisation de tableau (Array privatization)

La privatisation de tableau est souvent utilis'ee pour 'eliminer des d'ependances de type WAW
afin de pouvoir parall'eliser des nids de calculs. Le prix a payer est souvent une accumulation des
r'esultats une fois le calcul effectu'e.

12.14.1 Repr'esentation syntaxique
D'efinition : La privatisation de tableau consiste `a ajouter une nouvelle dimension `a un tableau. Elle est souvent r'ealis'ee dans le cadre de calculs de type accumulation.

136 12. Listes des transformations de codes usuelles
Exemple : L'exemple ci-dessous correspond `a la privatisation du scalaire a, et permet de
parall'eliser les it'erations de la boucle.

avant privatisation
for(i=0;i<N;i++)

a= ...
B[i]= ... * a
...

apr`es privatisation
for(i=0;i<N;i++)

A[i]= ...
B[i]= ... * A[i]
...

12.14.2 Repr'esentation dans le formalisme

Dans le formalisme, la privatisation est effectu'ee sur les acc`es des listes Lhs et Rhs. La
d'efinition ci-dessous concerne la privatisation de tableaux.

D'efinition : La transformation PrivatizepP, A, l, sq r'ealise la privatisation du tableau A dans
les instructions dont le fi-pr'efixe est P , `a la dimension l, la taille de cette nouvelle dimension
'etant s. La d'efinition est la suivante :

PrivatizepP, A, l, sq :>
>
>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^
^
^
^
^

@pA, o, SA, Fq P LShs Y RShs^
^
^
^
^
^

SA DH InsRowpSA, lqS

Al DH s

F DH InsRowpF, lq

Pr'erequis : La nouvelle dimension ajout'ee au tableau doit ^etre cons'ecutive `a une des dimensions actuelles du tableau, ce qui s'exprime pour tout acc`es modifi'e par la transformation
par :

l d^ dimpSAq ` 1

Exemple : L'effet sur l'ensemble des acc`es 'etant le m^eme, int'eressons nous par exemple `a
l'acc`es suivant :

"

""A, $,

"5120 , i M 11 0 0

,

,

Apr`es privatisation `a la seconde dimension par la transformation Privatize([],A,10), l'acc`es
devient :

"

*
""A, $,

"512

10

j

,

i M 11 0 0

0 0 0

,
<
,

Notez que les acc`es modifi'es par privatisation, l'utilisent pas la nouvelle dimension. Il faut
encore modifier les fonctions d'acc`es pour obtenir un tel r'esultat.

Invariants : Seuls les acc`es 'etant modifi'es par cette transformation, les invariants du formalisme sont respect'es.

12.15. Contraction de tableau (Array contraction) 137
12.15 Contraction de tableau (Array contraction)

La contraction de tableau r'ealise l'op'eration inverse de la privatisation, r'eduisant le nombre
de dimension d'un tableau. Cette transformation est souvent r'ealis'ee apr`es une fusion pour
'eliminer un tableau temporaire en le rempla,cant par un scalaire.

12.15.1 Repr'esentation syntaxique
D'efinition : La contraction de tableau consiste `a supprimer une dimension d'un tableau.

Exemple : L'exemple ci-dessous correspond `a la contraction du tableau A :

avant contraction
for(i=0;i<N;i++)

A[i]= B[i]+C[i]
D[i]= E[i]*A[i]

apr`es contraction
for(i=0;i<N;i++)

a= B[i]+C[i]
D[i]= E[i]*a

12.15.2 Repr'esentation dans le formalisme

Dans le formalisme, la contraction est effectu'ee sur les acc`es des listes Lhs et Rhs. La d'efinition
ci-dessous concerne la contraction de tableaux multidimensionnels.

D'efinition : La transformation ContractpP, A, lq r'ealise la contraction du tableau A dans
les instructions dont le fi-pr'efixe est P , `a la dimension l. La d'efinition est la suivante :

ContractpP, A, lq :>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^
^
^

@pA, o, SA, Fq P LShs Y RShs^
^
^
^ S

A DH RemRowpSA, lq

F DH RemRowpF, lq

Pr'erequis : La dimension supprim'ee au tableaux doit exister, ce qui pour chaque acc`es modifi'e
s'exprime par :

l d^ dimpSAq

Exemple : Une nouvelle fois, 'etudions l'effet de la transformation sur un acc`es dont voici la
repr'esentation :

"

*
""A, $,

"512

10

j

,

i M 11 0 0

0 1 1

,
<
,

Apr`es contraction de la seconde dimension par la transformation Contract([],A,2), l'acc`es
devient :

"

""A, $,

"5120 , i M 11 0 0

,

,

Notes : Cette transformation supprime purement et simplement une dimension de la fonction
d'acc`es. Pour r'ealiser une s'erialisation, il faut utiliser la transformation Serialize.

138 12. Listes des transformations de codes usuelles
Invariants : Seuls les acc`es 'etant modifi'es par cette transformation, les invariants du formalisme sont respect'es.

12.16 S'erialisation de tableau (Array serialization)

La contraction de tableau supprime une dimension devenue inutile `a un tableau. La s'erialisation de tableau s'erialise deux dimensions d'un acc`es `a un tableau pour supprimer une dimension
du tableau.

12.16.1 Repr'esentation syntaxique
D'efinition : La s'erialisation de tableau supprime une dimension `a un tableau en s'erialisant
deux dimension de ce tableaux.

Exemple : L'exemple ci-dessous correspond `a la s'erialisation des deux dimensions du tableau
A dans la double boucle i, j :

avant s'erialisation
int A[10][100]

for(i=0;i<10;i++)

for(j=0;j<100;j++)

A[i,j]= ...

apr`es s'erialisation
int A[1000]

for(i=0;i<10;i++)

for(j=0;j<100;j++)

A[i*100+j]= ...

12.16.2 Repr'esentation dans le formalisme

Dans le formalisme, cette transformation se d'ecompose en une r'e'ecriture de la fonction
d'acc`es suivie d'une contraction de tableau.

D'efinition : La transformation SerializepP, A, lq r'ealise la s'erialisation du tableau A dans
les instructions dont le fi-pr'efixe est P , aux dimensions l et l ` 1. La d'efinition est la suivante :

SerializepP, A, lq :>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^

@pA, o, SA, Fq P LShs Y RShs^
^ Fl DH Fl ` SAl

`1 ^ Fl`1Contract

pP, A, l ` 1q

Pr'erequis : Pour chaque acc`es modifi'e, les dimensions concern'ees doivent exister, ce qui
s'exprime par :

l a* dimpSAq

Exemple : Une nouvelle fois, 'etudions l'effet de la transformation sur un acc`es dont voici la
repr'esentation :

"

*
""A, $,

"512

10

j

,

i M 11 0 0

0 1 1

,
<
,

Apr`es s'erialisation par la transformation Serialize([],A,1), l'acc`es devient :

12.17. Padding 139

"
""A, $,

"51200 , i M 11 10 10

,

,

Invariants : Seuls les acc`es 'etant modifi'es par cette transformation, les invariants du formalisme sont respect'es.

12.17 Padding

La transformation de padding est utilis'ee lorsque la pr'esence de conflit de cache est d'etect'e
de mani`ere `a limiter les interf'erences dans la hi'erarchie m'emoire.

12.17.1 Repr'esentation syntaxique
D'efinition : Le padding consiste `a augmenter la taille des tableaux afin de modifier l'alignement des donn'ees.

Exemple : Dans l'exemple ci-dessous, un padding du tableau A est r'ealis'e, modifiant la taille
de sa seconde dimension.

avant padding
int A[512][512]

for(i=0;i<512;i++)

for(j=0;j<512;j++)

A[i,j]= ...

apr`es padding
int A[512][513]

for(i=0;i<512;i++)

for(j=0;j<512;j++)

A[i,j]= ...

12.17.2 Repr'esentation dans le formalisme

Dans le formalisme, le padding affecte la composante S des acc`es.

D'efinition : La transformation PadpP, A, l, padq effectue un padding du tableau A pour les
instructions dont le fi-pr'efixe est P , `a la dimension l d'une valeur de pad. La d'efinition est la
suivante : Pad

pP, A, l, padq :>
>
>
>
>
>

@S P SCoP tel que P D^ fiS^
^
^
^

@pA, o, SA, Fq P LShs Y RShs^
^ SAl DH SAl ` pad

Pr'erequis : Pour chaque acc`es modifi'e, la dimension padd'ee doit exister, ce qui s'exprime
par :

l d^ dimpSAq

Exemple : Consid'erons un acc`es `a un tableau A dont la repr'esentation dans le formalisme est
la suivante :

"

*
""A, $,

"512

512

j

,

i M 11 0 0

0 1 0

,
<
,

140 12. Listes des transformations de codes usuelles

Apr`es padding de la seconde dimension du tableau de 1 par la transformation Pad([],A,2,1)
la repr'esentation devient :

"
*
""A, $,

"512

513

j

,

i M 11 0 0

0 1 0

,
<
,

Invariants : Seuls les acc`es 'etant modifi'es par cette transformation, les invariants du formalisme sont respect'es.

12.18 Transposition de tableau (Array Transposition)

La transposition de matrice r'eordonne les 'el'ements du tableau transformant des acc`es colonnes par colonnes en acc`es lignes par lignes ou vice versa. Cette transformation am'eliore la
localit'e quand les matrices sont stock'ees en m'emoire d'une mani`ere inadapt'ee `a leur parcours
du point de vue des caches m'emoires.

Permuter un tableau peut ^etre une alternative au changement de tous les parcours concernant
le tableau par des Interchange.

12.18.1 Repr'esentation syntaxique
D'efinition : La transposition de tableau 'echange le r^ole des colonnes et des lignes dans le
tableau. Ainsi, chaque 'el'ement d'un tableau `a deux dimensions Ai,j devient Aj,i.

Exemple : Dans l'exemple ci-dessous, le tableau A est transpos'e pour am'eliorer la localit'e :

avant transposition
int A[10][100]

for(j=0;j<100;j++)

for(i=0;i<10;i++)

A[i,j]= ...

apr`es transposition
int A[100][10]

for(j=0;j<100;j++)

for(i=0;i<10;i++)

A[j,i]= ...

12.18.2 Repr'esentation dans le formalisme

Dans le formalisme, la transposition permute des lignes de la fonction d'acc`es et de la composante S.

D'efinition : La transformation TransposepP, A, lq effectue une transposition du tableau A
pour les instructions dont le fi-pr'efixe est P , entre les dimensions l et l ` 1. La d'efinition est la

12.19. Ajout d'informations de contexte 141
suivante : Transpose

pP, A, lq :
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

@S P SCoP tel que P D^ fiS
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^

@pA, o, SA, Fq P LShs Y RShs^
^
^
^
^
^
^
^
^
^
^
^
^
^
^
^

l1 DH SAl
l2 DH SAl`1S

Al DH l2S

Al

`1 DH l1f 1

DH Fl

f 2 DH Fl`1
Fl DH f 2
Fl`1 DH f 1

Pr'erequis : Pour chaque acc`es modifi'e, les deux dimensions transpos'ees doivent exister, ce
qui s'exprime par :

l a* dimpSAq

Exemple : Consid'erons un acc`es `a un tableau A dont la repr'esentation dans le formalisme est
la suivante :

"

*
""A, $,

"100

10

j

,

i M 11 0 1

0 1 0

,
<
,

Apr`es transposition des deux dimensions par la transformation Pad([],A,1), la repr'esentation
de cet acc`es devient : "

*
""A, $,

" 10

100

j

,

i M 10 1 0

1 0 1

,
<
,

Invariants : Seuls les acc`es 'etant modifi'es par cette transformation, les invariants du formalisme sont respect'es.

12.19 Ajout d'informations de contexte

Nous associons 'egalement des informations de contexte aux param`etres globaux des SCoPs.
Ces informations de contexte (que nous n'avons pas repr'esent'ees dans le formalisme) permettent
de borner les param`etres globaux, ce qui simplifie le travail du g'en'erateur de code, et diminue
le temps de g'en'eration. Cela permet 'egalement d''eviter du versionning, portions de code aux
gardes incompatibles avec le contexte 'etant 'elimin'ees.

Consid'erons une nouvelle fois l'exemple introduit dans le Chapitre 4, et sa liste de transformations `a appliquer :

for (i=0; i<M; i++)
S1 Z[i] = 0;

for (j=0; j<N; j++)
S2 Z[i] += (A[i][j] + B[j][i]) * X[j];

for (k=0; k<P; k++)

for (l=0; l<Q; l++)
S3 Z[k] += A[k][l] * Y[l];

Fusion des boucles i et k
Fusion des boucles j et l
Fission de l'instruction Z[i]=0
Strip-mine de la boucle i
Strip-mine de la boucle j
Permutation des boucles i et jj

142 12. Listes des transformations de codes usuelles

'Enorm'ement de versionning est produit lors de la double fusion du fait des bornes de boucles
non identiques, ce versionning peut ^etre r'eduit si les ordre de grandeurs des couples M , P et
N ,Q sont connus.

Le strip-mine va 'egalement produire du versionning, du fait que la taille de la tuile peut ^etre
sup'erieure `a M , N , P et Q. Indiquer que ces quatre valeurs sont sup'erieures `a 100 pour une
taille de tuile de 32 'elimine ce versionning.

De mani`ere g'en'erale, beaucoup de param`etres correspondent `a des tailles de structures. Le
simple fait de sp'ecifier que ces param`etres sont positifs simplifie le travail du g'en'erateur de code.
Par exemple, la division enti`ere math'ematique n''etant pas impl'ement'ee de la m^eme mani`ere
sur les nombres entiers positifs et n'egatif, indiquer qu'un param`etre est positif permet d''eviter
qu'une conditionnelle soit ins'er'ee pour tester le signe du param`etre chaque fois qu'il est divis'e.

D'efinition : Le contexte ressemble aux matrices de domaines, mais ne concerne que les param`etres globaux et la composante affine. La transformation AddContextpP, cq ajoute l'information de contexte c au SCoP contenant une instruction pr'efix'ee par P .

Exemple : La transformation AddContext([ 0 ],[1 0 0 0 0]) par exemple permet d'indiquer
que le param`etre global P est positif. La matrice de contexte indiquant que l'ensemble des
param`etres globaux sont positifs est la suivante :

M N O P 11 0 0 0 0

0 1 0 0 00 0 1 0 0
0 0 0 1 0

143
Chapitre 13
Exemple de composition de
transformations dans le formalisme

Nous avions dans les Chapitre 4 mis en avant les limitations de la repr'esentation syntaxique.
Le formalisme que nous avons pr'esent'e dans les Chapitres 9, 10 et 11 permet de composer les
transformations sans aucune r'ef'erence `a la forme syntaxique, alors que les mod'elisations poly'edriques pr'ec'edentes cherchaient `a appliquer une unique transformation essayant de reproduire

toutes les optimisations [41, 66], ou r'eclamaient des 'etapes g'en'erations de codes interm'ediaires
[103, 53].

Pour illustrer l'avantage de la composition de transformation libre de toute repr'esentation
syntaxique, et pour donner un exemple complet de l'optimisation d'un code dans notre formalisme, consid'erons de nouveau l'exemple du Chapitre 4 rappel'e dans la Figure 13.1.

long long Z[900],A[900][800],B[900][800],X[700],Y[600];
for (i=0; i<M; i++)
S1 Z[i] = 0;

for (j=0; j<N; j++)
S2 Z[i] += (A[i][j] + B[j][i]) * X[j];

for (k=0; k<P; k++)

for (l=0; l<Q; l++)
S3 Z[k] += A[k][l] * Y[l];

Fig. 13.1 - Exemple de programme `a optimiser

Dans le Chapitre 4, nous avions d'etermin'e la s'equence de transformation suivante :

- Fusion des boucles i et k
- Fusion des boucles j et l
- Fission de l'instruction Z[i]=0 `a l'ext'erieur de la boucle i,
- Strip-mine de la boucle j
- Strip-mine de la boucle i
- Permutation des boucles i et jj (la boucle g'en'er'ee via le strip-mine de la boucle j)

Nous allons maintenant appliquer cette m^eme s'equence de transformations sur la repr'esentation
de ce programme. La Section 13.1 va pr'esenter la repr'esentation de l'exemple le la Figure 13.1.
La Section 13.3 pr'esentera les effets sur le formalisme de la s'equence de transformations, 'etape
par 'etape.

144 13. Exemple de composition de transformations dans le formalisme
13.1 Repr'esentation de l'exemple dans le formalisme

L'exemple de la Figure 13.1 correspond `a un unique SCoP avec les param`etres globaux
suivants igp " rM, N, P, Qst. Les Figures 13.2, 13.3 et 13.4 pr'esentent les valeurs des diff'erentes
composantes du formalisme repr'esentant ce SCoP.

DS1om "

$
'&

'%

i M N P Q 11 0 0 0 0 0
'1 1 0 0 0 '1

,
/.

/- 0

d^ i d^ M ' 1

DS2om "

$
''
''
'&

''
''
'%

i j M N P Q 11 0 0 0 0 0 0
'1 0 1 0 0 0 '10 1 0 0 0 0 0

0 '1 0 1 0 0 '1

,
//
//
/.

//
//
/-

0 d^ i d^ M ' 1
0 d^ j d^ N ' 1

DS3om "

$
''
''
'&

''
''
'%

k l M N P Q 11 0 0 0 0 0 0
'1 0 0 0 1 0 '10 1 0 0 0 0 0

0 '1 0 0 0 1 '1

,
//
//
/.

//
//
/-

0 d^ k d^ P ' 1
0 d^ l d^ Q ' 1

Fig. 13.2 - Domaines d'it'erations des instructions S1, S2 et S3

AS1 "

i1 \Gamma S

1 "

M N P Q 10 0 0 0 0 fiS

1 " 00

AS2 "

i j1 0

0 1 \Gamma 

S2 "

M N P Q 10 0 0 0 0

0 0 0 0 0 fi

S2 " 01

0

AS3 "

k l1 0

0 1 \Gamma 

S3 "

M N P Q 10 0 0 0 0

0 0 0 0 0 fi

S3 " 10

0

Fig. 13.3 - Ordonnancement des instructions S1, S2 et S3

13.1. Repr'esentation de l'exemple dans le formalisme 145

LS1hs "

$
&

%

"
""Z, $,

"9000 , i M N P Q 11 0 0 0 0 0

,

,

,
.

-

RS1hs "

!)

LS2hs "

$
&

%

"
""Z, $,

"9000 , i j M N P Q 11 0 0 0 0 0 0

,

,

,
.

-

RS2hs "

$
''
''
''
''
''
''
''
''
''
''
&

''
''
''
''
''
''
''
''
''
''
%

"
""Z, $,

"9000 , i j M N P Q 11 0 0 0 0 0 0

,

,
"
*
""A, $,

"900

800

j

,

i j M N P Q 11 0 0 0 0 0 0

0 1 0 0 0 0 0

,
<
,

"
*
""B, $,

"900

800

j

,

i j M N P Q 10 1 0 0 0 0 0

1 0 0 0 0 0 0

,
<
,

"
""X, $,

"7000 , i j M N P Q 10 1 0 0 0 0 0

,

,

,
//
//
//
//
//
//
//
//
//
//
.

//
//
//
//
//
//
//
//
//
//
-

LS3hs "

$
&

%

"
""Z, $,

"9000 , k l M N P Q 11 0 0 0 0 0 0

,

,

,
.

-

RS3hs "

$
''
''
''
''
''
''
'&

''
''
''
''
''
''
'%

"
""Z, $,

"9000 , k l M N P Q 11 0 0 0 0 0 0

,

,
"
*
""A, $,

"900

800

j

,

k l M N P Q 11 0 0 0 0 0 0

0 1 0 0 0 0 0

,
<
,

"
""Y, $,

"6000 , k l M N P Q 10 1 0 0 0 0 0

,

,

,
//
//
//
//
//
//
/.

//
//
//
//
//
//
/-

Fig. 13.4 - Liste des acc`es des instructions S1, S2 et S3

146 13. Exemple de composition de transformations dans le formalisme
13.2 Repr'esentation de la s'equence de transformations dans le

formalisme

Consid'erons que les labels LBL1, LBL2, et LBL3 pointent les instructions S1, S2 et S3 `a
leur profondeur respective, la s'equence de transformations est alors la suivante :

Fusion des boucles externes FusepenclosepLBL1qq
Fusion des boucles internes FusepenclosepLBL2qq
Fission de l'initialisation FissionpenclosepLBL2qq
Strip-mine de la boucle interne StripMinepenclosepLBL2q, 64q
Strip-mine de la boucle externe StripMinepenclosepLBL2, 3q, 64q
Permutation des boucles du milieu InterchangepenclosepLBL2, 2qq

13.3 La s'equence de transformations, 'etape par 'etape

'Etape 1 : Fusion des boucles i et k : FusepenclosepLBL1qq. Dans notre repr'esentation,
la fusion des boucles i et k n'a un effet que sur le vecteur d'ordonnancement de l'instruction S3.
Apr`es fusion, l'instruction S3 se retrouve elle aussi dans le premi`ere boucle du programme (0 dans
la premi`ere dimension du vecteur d'ordonnancement), et deviens la troisi`eme instruction/sousboucle de cette boucle (2 dans la seconde dimension du vecteur).

fiS3 " 02

0

\Delta 1
\Gamma 1

'Etape 2 : Fusion des boucles j et l : FusepenclosepLBL2qq. La fusion des boucles j et l,
'egalement, ne modifie que le vecteur d'ordonnancement de l'instruction S3. L'instruction S3 est

maintenant la seconde instruction (1 `a la 3`eme dimension) de la seconde instruction/sous-boucle
(1 `a la 2nde dimension) de la premi`ere boucle (0 `a la 1`ere dimension).

fiS3 " 01

1

\Delta 1
\Gamma 1

'Etape 3 : Fission de l'initialisation de Z : FissionpenclosepLBL2qq. La fission de l'instruction Z[i]=0 a un impact sur les vecteurs d'ordonnancement des instructions S2 et S3. Apr`es
fission les instructions S2 et S3 se retrouvent dans la deuxi`eme boucle du programme (1 `a la
1`ere dimension), dans la premi`ere sous-boucle de cette boucle (0 `a le 2nde dimension) et sont
les premi`ere et seconde instructions de cette sous-boucle.

fiS2 " 10

0

\Gamma 1
\Delta 1 fiS3 " 10

1

\Gamma 1
\Delta 1

13.3. La s'equence de transformations, 'etape par 'etape 147

'Etape 4 : Strip-mining de la boucle j/l : StripMinepenclosepLBL2q, 64q. Le stripmine de la boucle j/l affecte principalement les domaines des instructions S2 et S3 : Le stripmine ajoute un nouvel it'erateur, une nouvelle variable locale, et les 4 in'equations contraignant
ces nouvelles variables. Les structures des vecteurs et matrices d'ordonnancement, ainsi que
les matrices d'acc`es aux tableaux sont 'egalement modifi'ees pour prendre en compte le nouvel
it'erateur, sans pour autant modifier les fonctions d'ordonnancement ou les fonctions d'acc`es.

DS2om "

i jj j p0 M N P Q 11 0 0 0 0 0 0 0 0
'1 0 0 0 1 0 0 0 '10 0 1 0 0 0 0 0 0

0 0 '1 0 0 1 0 0 '10

'1 1 0 0 0 0 0 00 1

'1 0 0 0 0 0 630
'1 0 64 0 0 0 0 00 1 0

'64 0 0 0 0 0

0 d^ i d^ M ' 1
0 d^ j d^ N ' 1
jj d^ j d^ jj ` 63
jj " 64 ^ p0

DS3om "

k ll l p0 M N P Q 11 0 0 0 0 0 0 0 0
'1 0 0 0 0 0 1 0 '10 0 1 0 0 0 0 0 0

0 0 '1 0 0 0 0 1 '10

'1 1 0 0 0 0 0 00 1

'1 0 0 0 0 0 630
'1 0 64 0 0 0 0 00 1 0

'64 0 0 0 0 0

0 d^ k d^ P ' 1
0 d^ l d^ Q ' 1
ll d^ l d^ ll ` 63
ll " 64 ^ p0

AS2 "

i jj j1 0 0
0 1 00 0 1 \Gamma S2 "

M N P Q 10 0 0 0 0

0 0 0 0 00 0 0 0 0 fiS2 "

10

00

AS3 "

k ll l1 0 0
0 1 00 0 1 \Gamma S3 "

M N P Q 10 0 0 0 0

0 0 0 0 00 0 0 0 0 fiS3 "

10

01

'Etape 5 : Strip-mining de la boucle i/k : StripMinepenclosepLBL2, 3q, 64q. De la m^eme
mani`ere, le strip-mine de la boucle i/k affecte les domaines des instructions S2 et S3, ajoutant
deux nouvelles colonnes et 4 nouvelles lignes, et les structures des vecteurs/matrices d'acc`es aux

148 13. Exemple de composition de transformations dans le formalisme
tableaux et d'ordonnancement.

DS2om "

ii i jj j p0 p1 M N P Q 10 1 0 0 0 0 0 0 0 0 0

0 '1 0 0 0 0 1 0 0 0 '10 0 0 1 0 0 0 0 0 0 0
0 0 0 '1 0 0 0 1 0 0 '10 0

'1 1 0 0 0 0 0 0 00 0 1

'1 0 0 0 0 0 0 630 0
'1 0 64 0 0 0 0 0 00 0 1 0

'64 0 0 0 0 0 0
'1 1 0 0 0 0 0 0 0 0 01

'1 0 0 0 0 0 0 0 0 63
'1 0 0 0 0 64 0 0 0 0 01 0 0 0 0

'64 0 0 0 0 0

0 d^ i d^ M ' 1
0 d^ j d^ N ' 1
jj d^ j d^ jj ` 63
jj " 64 ^ p0
ii d^ i d^ ii ` 63
ii " 64 ^ p1

DS3om "

kk k ll l p0 p1 M N P Q 10 1 0 0 0 0 0 0 0 0 0

0 '1 0 0 0 0 0 0 1 0 '10 0 0 1 0 0 0 0 0 0 0
0 0 0 '1 0 0 0 0 0 1 '10 0

'1 1 0 0 0 0 0 0 00 0 1

'1 0 0 0 0 0 0 630 0
'1 0 64 0 0 0 0 0 00 0 1 0

'64 0 0 0 0 0 0
'1 1 0 0 0 0 0 0 0 0 01

'1 0 0 0 0 0 0 0 0 63
'1 0 0 0 0 64 0 0 0 0 01 0 0 0 0

'64 0 0 0 0 0

0 d^ k d^ P ' 1
0 d^ l d^ Q ' 1
ll d^ l d^ ll ` 63
ll " 64 ^ p0
kk d^ k d^ kk ` 63
kk " 64 ^ p1

AS2 "

ii i jj j1 0 0 0

0 1 0 00 0 1 0
0 0 0 1

\Gamma S2 "

M N P Q 10 0 0 0 0

0 0 0 0 00 0 0 0 0
0 0 0 0 0

fiS2 "

10
00
0

AS3 "

kk k ll l1 0 0 0

0 1 0 00 0 1 0
0 0 0 1

\Gamma S3 "

M N P Q 10 0 0 0 0

0 0 0 0 00 0 0 0 0
0 0 0 0 0

fiS3 "

10
00
1

'Etape 6 : Permutation des boucles i et j : InterchangepenclosepLBL2, 2qq. La permutation des boucles i et j n'affecte que les matrices d'ordonnancement des instructions S2 et
S3, permutant leur seconde et leur troisi`eme lignes.

AS2 "

ii i jj j1 0 0 0

0 0 1 00 1 0 0
0 0 0 1

\Gamma S2 "

M N P Q 10 0 0 0 0

0 0 0 0 00 0 0 0 0
0 0 0 0 0

13.4. Conclusion 149

AS3 "

kk k ll l1 0 0 0

0 0 1 00 1 0 0
0 0 0 1

\Gamma S3 "

M N P Q 10 0 0 0 0

0 0 0 0 00 0 0 0 0
0 0 0 0 0

13.4 Conclusion

Lors de l'application de de cette s'equence de six transformations, le nombre d'instructions
dans notre formalisme est rest'e constant (3). La phase de g'en'eration de code n'est appel'ee que
lorsque toutes les transformations ont 'et'e appliqu'ees, et produit un code d'un peu moins de 500
lignes offrant un speed-up de 3.52 par rapport au code de d'epart.

La Figure 13.5 pr'esente les temps d'ex'ecution sur un Alpha 21364 EV7, ainsi que les speedups par rapport au code de d'epart, pour les transformations effectu'ees par le pr'e-processeur
KAP C(v4.1) [51], et pour notre s'equence de transformations.

5
10
15
20
25

Temps
d'ex
'ecution

(s)

1

Original

2.05

KAP

3.52
S'equence
Fig. 13.5 - Temps d'ex'ecution et Speed-ups

150 13. Exemple de composition de transformations dans le formalisme151
Chapitre 14
Recherche de s'equences de
transformations

Dans les chapitres pr'ec'edents, nous avons montr'e que l'application de transformations de
programme peut maintenant ^etre exprim'ee par une s'erie de calculs sur les diff'erentes matrices
associ'ees `a chaque instruction du programme. Cette approche apporte une am'elioration majeure
du point de vue de la flexibilit'e par rapport `a l'approche syntaxique, car elle 'evite l'explosion en
taille de la repr'esentation apr`es l'application de chaque transformation. En fait, seules quelques
transformations, comme le strip-mining, et le peeling augmentent tr`es l'eg`erement le nombre
d'instructions ou la dimension des matrices.

Ce chapitre pr'esente de nouvelles pistes illustrant `a quel point notre repr'esentation poly'edrique peut encore am'eliorer les algorithmes de recherche de s'equences de transformations,

dont l'espace de recherche est gigantesque.

Dans la Section 14.1, nous pr'esentons les propri'et'es associ'ees aux transformations qui permettent de r'eduire l'espace de recherche des s'equences de transformations. La Section 14.2
pr'esente une techniques alternatives `a la recherche des s'equences de transformations.

14.1 Propri'et'es de commutativit'e

Plusieurs propri'et'es permettent de r'eduire l'espace de recherche. Dans cette section, nous
allons pr'esenter les propri'et'es de commutativit'e et de confluence, qui permettent de r'eduire
consid'erablement le nombre de s'equences `a consid'erer.

14.1.1 Commutativit'e

Gr^ace `a la s'eparation claire entre les diff'erentes composantes de notre formalisme (domaines
d'it'erations, ordonnancement et fonctions d'acc`es), et gr^ace aussi `a la s'eparation de la composante d'ordonnancement (inter-it'eration, param'etrique et s'equentiel), nous obtenons simplement
des propri'et'es de commutativit'e pour nos transformations. Ainsi, la plupart des transformations de donn'ees (Privatize, Contract, Pad, . . .) commutent avec les transformations de
contr^ole (Shift, Interchange, Fuse, Fission, . . .), tout comme les transformations de r'eordonnancement des it'erateurs (Interchange, Reverse, Skew) avec les transformations de
r'e-ordonnancement s'equentiel (Fuse, Fission).

Mais, il existe 'egalement des propri'et'e de commutativit'e entre des transformations touchant
la m^eme composante. Par exemple la fusion de boucle commute avec la fission de boucle, et la
fusion elle-m^eme. La Figure 14.1 pr'esente de nouveau l'exemple du chapitre pr'ec'edent.

152 14. Recherche de s'equences de transformations

long long Z[900],A[900][800],B[900][800],X[700],Y[600];
for (i=0; i<M; i++)
S1 Z[i] = 0;

for (j=0; j<N; j++)
S2 Z[i] += (A[i][j] + B[j][i]) * X[j];

for (k=0; k<P; k++)

for (l=0; l<Q; l++)
S3 Z[k] += A[k][l] * Y[l];

Fig. 14.1 - Exemple de programme `a optimiser

'Echanger l'ordre dans lequel sont appliqu'ees les deux fusions et la fission produit la m^eme
repr'esentation dans notre formalisme. Les Figures 14.2 et 14.3 montrent l''evolution de la repr'esentation en appliquant, d'une part, la double fusion puis la fission, et d'autre part, la fission
puis la double fusion.

fiS1 " 00 fiS2 " 01

0

fiS3 " 10

0

Y'N~ fiS1 " 00 fiS2 " 01

0

fiS3 " 02

0

O"

fiS1 " 00 fiS2 " 01

0

fiS3 " 01

1

Y'N~ fiS1 " 00 fiS2 " 10

0

fiS3 " 10

1

Fig. 14.2 - Double fusion, puis fission

fiS1 " 00 fiS2 " 01

0

fiS3 " 10

0

Y'N~ fiS1 " 00 fiS2 " 10

0

fiS3 " 20

0

O"

fiS1 " 00 fiS2 " 10

0

fiS3 " 11

0

Y'N~ fiS1 " 00 fiS2 " 10

0

fiS3 " 10

1

Fig. 14.3 - Fission, puis double fusion
Les deux s'equences de transformations produisent le m^eme r'esultat final. La connaissance de
ces propri'et'es de commutativit'e est extr^emement important dans un contexte de processus de
compilation it'eratif, car elles vont permettre de diminuer consid'erablement l'espace des s'equences
`a rechercher.

14.1.2 Confluence

Nous pouvons 'egalement associer `a notre formalisme des propri'et'es de confluence entre les
s'equences de transformations. Par exemple, le d'eroulage (partiel) de la boucle externe suivi de
la fusion (unroll-and-jam) est strictement 'equivalent au strip-mining, la permutation de boucle
et le d'eroulage complet.

14.2. Une approche alternative : rechercher les valeurs des matrices 153

Ces propri'et'es de confluence sont 'egalement tr`es importantes dans le contexte de la recherche
it'erative, non seulement elles permettent de r'eduire la taille de l'espace de recherche, mais elles
permettent 'egalement de mieux comprendre la structure de cet espace de recherche, ce qui
permettra de trouver des techniques de recherche plus efficaces [28].

14.2 Une approche alternative : rechercher les valeurs des matrices

Notre formalisme permet 'egalement de consid'erer une nouvelle approche pour la recherche
de composition de transformations de programme : Comme les transformations de programmes
au sein de notre formalisme ne font que modifier des valeurs dans des matrices, et que l'eg`erement
changer la structure de ces matrices. Une alternative consiste `a directement chercher les valeurs
optimales au sein des diff'erentes matrices, en prenant soin de respecter les d'ependances. En
effet, changer quelques valeurs dans les matrices de la repr'esentation du programme 'equivaut
g'en'eralement `a des s'equences compl`etes de transformations, et la recherche de ces valeurs est
une t^ache beaucoup plus simple que la recherche de la s'equence de transformations `a appliquer
et des diff'erents param`etres de chacune des transformations qui la compose.

Par exemple, consid'erons la matrice d'ordonnancement \Theta S3 de l'instruction S3 du code de
la Figure 14.1. Sa valeur est donn'ee dans la Figure 14.4(a). Une approche syst'ematique effectuant des transformations d'ordonnancement pourrait lors de la recherche proposer la matrice
d'ordonnancement \Theta S

13 de la Figure 14.4(b).

\Theta S3 "

k l M N P Q 10 0 0 0 0 0 1
1 0 0 0 0 0 00 0 0 0 0 0 0
0 1 0 0 0 0 00 0 0 0 0 0 0

(a) Matrice de d'epart

\Theta S

13

"

k l M N P Q 10 0 0 0 0 0 0
0 1 0 0 0 0 00 0 0 0 0 0 1
1 0 0 0 0 0 00 0 0 0 0 0 1

(b) Valeur propos'ee lors de la recherche
Fig. 14.4 - Matrice d'ordonnancement de l'instruction S3

On peut d'enoter sept diff'erences entre les matrices \Theta S3 et \Theta S

13, et ces diff'erences correspondent `a l'application de trois transformations : La permutation des boucles k et l, la fusion
des boucles externes, et la fusion des boucles internes. Cela signifie que la recherche de valeurs
dans les matrices est 'equivalente `a la recherche de compositions de transformations.

Enfin, notre outil permet de calculer `a la demande le graphe complet des d'ependances poly'edriques, capturant les it'erations d'ependantes entre deux paires de r'ef'erences a un m^eme tableau

ou `a la m^eme variable scalaire. Ce graphe permet de caract'eriser l'ensemble complet de tous
les ordonnancement, domaines et fonctions d'acc`es associ'es `a des s'equences de transformation
l'egales. Cela permet tr`es rapidement, soit de filtrer les transformations violant ces d'ependances,
soit de les corriger [12]. En utilisant le lemme de Farkas et la caract'erisation des ordonnancements multidimensionnels propos'ee par Feautrier [41], il est possible de caract'eriser l'ensemble
des valeurs des matrices repr'esentant les transformations l'egales.

Ainsi, la recherche de la meilleure transformation dans ces domaines pourrait ^etre effectu'ee
par des outils math'ematiques de programmation lin'eaire, avec de bien meilleures complexit'es, et
une bien meilleure scalabilit'e que les algorithmes g'en'etiques recherchant les s'equences de transformations. Cette id'ee est similaire `a celle du chunking permettant d'am'eliorer automatiquement

154 14. Recherche de s'equences de transformations
la localit'e des programmes et propos'ee dans [11, 12].

155

Chapitre 15
Optimisation de Code : Le
SpecFP2000 SWIM

Dans ce chapitre, nous allons pr'esenter l'optimisation du benchmark swimdes SpecFP 2000
[95] par notre environnement de compilation, montrant ainsi l'efficacit'e de cet environnement
sur une application repr'esentative des applications r'eelles. Les deux architectures cibles 32 bits
et 64 bits que nous avons utilis'ees sont indiqu'ees dans la Figure 15.1

Processeur Athlon XP 2800+ (Barton) Athlon 64 2400+ (Clawhammer)
Fr'equence 2.08GHz 2.2GHz
Cache L2 512KB 1MB
RAM 512MB DDR SDRAM 1GB DDR SDRAM
OS Mandriva 10.1 Debian GNU/Linux Sid
Kernel 2.6.8 2.6. 11

Fig. 15.1 - Plateforme de test

Nous avons choisi d'optimiser le benchmark swim car apr`es fusion, la couverture de programme en SCoP est excellente (100%) et qu'il permet ainsi d'illustrer l'int'eret d'impl'ementer
de longues s'equences de transformations de programmes. L'optimisation manuelle r'ealis'ee dans
la Section 2.5 avait permis de trouver une s'equence de 10 transformations, dans ce chapitre
nous appliquerons une s'equence de 44 transformations de programmes permettant de battre les
performances peak du compilateur Open64.

Dans la Section 15.1 nous pr'esenterons d'abord les r'esultats obtenus par notre s'equence de
transformations et les comparerons avec ceux du compilateur ayant atteint les meilleures performances peak, avec les meilleures options de compilation possibles. Dans la Section 15.2 nous
expliquerons la strat'egie d'optimisation que nous avons utilis'ee pour optimiser cette application. Enfin, dans la Section 15.3 nous pr'esenterons la liste des transformations appliqu'ees, en
fournissant le script correspondant `a la s'equence de transformation.

15.1 R'esultats

Dans cette section, nous allons pr'esenter les r'esultats correspondant `a l'application automatique par URUK de la s'equence de transformation pr'esent'ee dans la Section 15.3. Nous nous
int'eresserons bien sur aux performances, mais 'egalement au temps de compilation, la taille de
code et la taille des structures au sein de la repr'esentation.

156 15. Optimisation de Code : Le SpecFP2000 SWIM
Performances : Le compilateur actuel poss'edant les meilleures performances peak pour ce
benchmark est Pathscale EKOPath (v2.1). Les meilleurs options d'optimisations pour nos deux
architectures sont pr'esent'ees dans la Figure 15.2.

Athlon XP -O3 -m32 -OPT:ro=2:Olimit=0:div_split=on:alias=typed

-LNO:fusion=2:prefetch=2 -ipa -fno-math-errno
Athlon 64 -march=athlon64 -LNO:fusion=2:prefetch=2 -m64

-Ofast -msse2 -lmpath

Fig. 15.2 - Option de compilation peak

La Figure 15.3 indique les diff'erents temps d'ex'ecution sur chacune des deux architectures du
benchmark swim, compil'e en base (avec juste -O3 et -m32 ou -m64 pour indiquer l'architecture
cible), compil'e en peak (avec les options compil'es ci-dessus), et compil'e en appliquant avec nos
outils la s'equence de transformations pr'esent'ee dans la Section 15.3.

50
100
150
200
250
300
350
400
450

Temps
d'ex
'ecution

(s)

1

Base

1.15

Peak

1.51
S'equence
(a) Athlon XP

50
100
150
200
250
300
350
400
450

Temps
d'ex
'ecution

(s)

1
Base

1.39

Peak

1.92
S'equence
(b) Athlon 64

Fig. 15.3 - Temps d'ex'ecution et Speed-ups

Les performances obtenues par notre s'equence de transformations sont meilleures que les
performances Peak : L'am'elioration de speed-up par rapport aux performances peak est de
+31% sur l'Athlon XP, et de +38% sur l'Athlon 64.

Temps de compilation : La Figure 15.5 indique les diff'erents temps correspondant aux diff'erentes 'etapes de la compilation : L'extraction des informations de la WHIRL et la construction
de la WRaP, L'application de la s'equences de transformation sur la WRaP, la g'en'eration de code
effectu'ee par CLooG ou par URGenT, et finalement fin de la compilation effectu'ee par Open64
de la WHIRL que nous avons g'en'er'ee.

Ces temps ont 'et'e mesur'es sur un Athlon XP 2GHz. Nous pouvons observer que pour CLooG,
la majorit'e du temps de compilation est pass'e dans le g'en'erateur de code et la partie back-end du
compilateur Open64. Le g'en'erateur de code URGenT tire efficacement parti de notre formalisme
et permet de diviser le temps de cette phase par 7.75. La r'eduction du temps correspondant `a
la partie back-end du compilateur (fin de la compilation) s'explique par la diff'erence entre le
nombre d'instructions g'en'er'ees par les deux g'en'erateurs de code.

Les phases d'analyses de d'ependances poly'edriques permettent de v'erifier `a posteriori que
les transformations de programmes n'ont pas viol'ees les d'ependances. Comme indiqu'e dans la
Section 15.2 d'ecrivant la m'ethodologie de recherche, ces phases d'analyses sont utilis'ees pour
trouver les transformations rendant valide l'application d'une transformation optimisante. Le

15.2. M'ethodologie de recherche 157
temps de cette phase n'est pas comptabilis'e dans le temps de compilation total qui correspond
au temps global de compilation une fois tous les probl`emes de l'egalit'e r'esolus.

CLooG URGenT
Construction de la WRaP a*1s
Applications des transformations a*1s
D'ependances Poly'edriques 12s
G'en'eration de code 33s 4s
Fin de la compilation 39s 21s
Temps total de compilation 73s 26s

Fig. 15.4 - Temps de compilation

Les temps n'egligeables correspondant `a la construction et la manipulation du formalisme
sont extr^emement encourageants dans le cadre de la composition de longues s'equences de transformations, et l'int'egration dans un processus it'eratif.

Taille des structures : La Figure 15.5 indique dans sa partie sup'erieure la taille des structures
utilis'ees pour repr'esenter le programme source, et dans sa partie inf'erieure les informations
concernant le programme g'en'er'e. L'analyse de d'ependance capture les informations exactes
correspondant `a 215 acc`es `a des tableaux, repr'esent'es par 441 matrices de d'ependances. La
diff'erence entre le nombre de lignes g'en'er'ees par les deux g'en'erateurs de code CLooG et URGenT
d'un facteur de 2.7 s'explique par le fait que l''elimination des affectations redondantes pr'esent'ees
dans la Section 20.2.1 n'a 'et'e r'ealis'ee que pour l'outil URGenT.

CLooG URGenT
Nombre de lignes du programme source 412
Nombre d'instructions dans la repr'esentation 112
Nombre d'acc`es `a des tableaux 215
Profondeur maximale du code source 3
Nombre de matrices repr'esentant les d'ependances 441
Profondeur maximale du code g'en'er'e 5
Nombre de lignes sources g'en'er'ees 6146 2267

Fig. 15.5 - Taille des structures

15.2 M'ethodologie de recherche

La diff'erence de compilateur et d'architecture entre l''etude de la Section 2.5 (Compilateur HP
pour Alpha 21264), et notre architecture cible (IA32, AMD64) modifie compl`etement la s'equence
de transformation `a appliquer pour optimiser le programme. En fait les compilateurs modernes
(comme EKOPath de Pathscale ou ORC) sont d'ej`a capable d'appliquer automatiquement une
bonne partie de la s'equence de transformation de la Figure 15.6. En fait seule la fusion des
boucles issues de la fonction inlin'ee calc3 n'est pas r'ealis'ee, car elle requiert tout d'abord une
combinaison complexe de shifts et de peel pour la rendre l'egale.

La strat'egie d'optimisation qui a 'et'e suivie est la suivante : L'id'ee g'en'erale 'etait de pouvoir
fusionner les boucles calc1, calc2 et calc3 ensemble, ce que le compilateur ne parvenait pas `a
faire. Pour cela nous avons d'eplacer calc3 pour rendre la fusion avec calc1 et calc2 possible, afin

158 15. Optimisation de Code : Le SpecFP2000 SWIM

A1 : -32s

A2 : -30s A3 : -15s

Peeling Shifting
Peeling Shifting Fusion
Peeling Shifting

Array forw.
substitution Padding Tiling

Fig. 15.6 - Optimisation de swim sur Alpha 21264 (rappel de la Figure 2.12)
de fusionner les boucles issues de ces trois fonctions, et enfin pratiquer quelques transformations
sur le noyau fusionn'e (tiling, unroll and jam) pour am'eliorer encore la localit'e.

Pour chacune de ces trois 'etapes (d'eplacement, fusion et optimisation du noyau) nous avons
r'ealis'e directement les transformations ad-hoc (d'eplacement, d'eplacement encore pour la fusion,
tuilage et unroll and jam pour l'optimisation du noyau) sans nous soucier des d'ependances de
donn'ees. L'outil d'analyse de d'ependances poly'edrique PolyDeps nous indiquait ensuite pr'ecis'ement quelles d'ependances de donn'ees avait 'et'e viol'ees, et indiquait les valeurs de shifting ou de
peeling `a r'ealiser pour qu'elles ne le soient plus. Nous avons ainsi, au fur et `a mesure, pu ajouter
les transformations de peeling et shifting rendant nos transformations l'egales.

Cette strat'egie, consistant `a corriger les transformations permet d'aller beaucoup plus loin
que les techniques classiques par reconnaissance de motifs, mais peuvent parfois d'egrader les
performances. Elle est donc particuli`erement bien adapt'ee dans un processus de compilation
it'eratif.

15.3 La liste des transformations

Nous allons pr'esenter le script URUK ayant permis d'optimiser le benchmark swim. Ce script
est pr'esent'e en plusieurs parties dans lesquelles sont d'etaill'ees les transformations `a appliquer,
et pourquoi elle sont appliqu'ees. Toutes ces transformations sont appliqu'ees apr`es inlining des
fonctions calc1, calc2 et calc3 par le compilateur, et avec le g'en'erateur de code URGenT.

15.3.1 Les labels du programme source

Pour comprendre la s'equence de transformations, commen,cons par pr'esenter les labels qui
d'ecore le code. Les trois fonctions de calculs de ce benchmark sont calc1, calc2 et calc3. Les
labels C1L*, C2L*, et C3L* d'ecorent les instructions issues de ces trois fonctions.

Les transformations de peeling dupliquant actuellement les instructions, les labels sont 'egalement dupliqu'es. Toute instruction contenant un label L dupliqu'ee par un peeling cr'ee deux
instructions d'ecor'ees respectivement par les labels L_p1 et L_p2. L'outil d'eterminera automatiquement les vecteurs d'ordonnancement correspondant aux diff'erents labels.

Enfin, les trois fonctions calc1, calc2 et calc3 sont inlin'ees dans la boucle externe principale
du programme, et le label BEGIN_OF_EXTERNAL_LOOP d'ecore la premi`ere instruction de cette
boucle externe.

15.3.2 Informations de contexte

La premi`ere partie du script renseigne sur le contexte des param`etres globaux. Cette partie
n'est pas indispensable mais permet de r'eduire consid'erablement le temps de g'en'eration en
r'eduisant le versionning concernant les param`etres.

15.3. La liste des transformations 159

ContexteA
DDCONTEXT(C1L1,'ITMAX>=9')A
DDCONTEXT(C1L1,'doloop_ub>=9')A
DDCONTEXT(C1L1,'N>=500')A
DDCONTEXT(C1L1,'M>=500')A
DDCONTEXT(C1L1,'MNMIN<=M')A
DDCONTEXT(C1L1,'MNMIN<=N')A
DDCONTEXT(C1L1,'MNMIN>=500')A
DDCONTEXT(C1L1,'doloop_ub>=ITMAX')A
DDCONTEXT(C1L1,'doloop_ub<=ITMAX')A
DDCONTEXT(C1L1,'M<=N')A
DDCONTEXT(C1L1,'M>=N')

Ce contexte permet d'une part d'exprimer les relations entre les param`etres (ici par exemple
que MNMIN est le minimum des deux param`etres M et N), les sp'ecificit'es des jeux de donn'ees
utilis'es (ici M=N pour tous les jeux de donn'ees), et l'ordre de grandeur des param`etres (ici que la
taille des structures (M et N) est sup'erieure `a 500^500 et que le nombre d'it'eration (ITMAX)est
sup'erieur `a 10.

Enfin les doloop_ub correspondent `a des copies locales de variables Fortran common qui
servent pour les bornes sup'erieures de boucles. Ici, c'est ITMAX qui est copi'ee dans cette variable.

15.3.3 D'eplacement de calc3

On commence alors par remonter l'int'egralit'e des boucles et instructions de calc3 (qui a
'et'e inlin'ee) avant calc1 et calc2 (au tout d'ebut de la boucle externe). La fonction calc3 devant

s'ex'ecuter apr`es calc1 et calc2, il est n'ecessaire pour rendre se d'eplacement l'egal de retarder
calc3 d'une it'eration dans cette boucle externe.

De'placement de calc3S
HIFT(enclose(C3L1),{[0,0,0,0,0,1],[0,0,0,0,0,0],[0,0,0,0,0,0]})S
HIFT(enclose(C3L10),{[0,0,0,0,0,1],[0,0,0,0,0,0]})S
HIFT(enclose(C3L11),{[0,0,0,0,0,1],[0,0,0,0,0,0]})S
HIFT(C3L12,{[0,0,0,0,0,1]})S
HIFT(C3L13,{[0,0,0,0,0,1]})S
HIFT(C3L14,{[0,0,0,0,0,1]})S
HIFT(C3L15,{[0,0,0,0,0,1]})S
HIFT(C3L16,{[0,0,0,0,0,1]})S
HIFT(C3L17,{[0,0,0,0,0,1]})

MOTION(enclose(C3L1),BEGIN_OF_EXTERNAL_LOOP)M

OTION(enclose(C3L10),BEGIN_OF_EXTERNAL_LOOP)M
OTION(enclose(C3L11),BEGIN_OF_EXTERNAL_LOOP)M
OTION(C3L12,BEGIN_OF_EXTERNAL_LOOP)M
OTION(C3L13,BEGIN_OF_EXTERNAL_LOOP)M
OTION(C3L14,BEGIN_OF_EXTERNAL_LOOP)M
OTION(C3L15,BEGIN_OF_EXTERNAL_LOOP)M
OTION(C3L16,BEGIN_OF_EXTERNAL_LOOP)M
OTION(C3L17,BEGIN_OF_EXTERNAL_LOOP)

Les transformations de shifting s'appliquent `a chacune des 3 boucles et des 6 instructions de
calc3 pour les retarder d'une it'eration dans la boucle externe. Les transformations de motion
s'appliquent elles aussi `a chacune de ces boucles et instructions pour les d'eplacer au d'ebut de la
boucle externe.

15.3.4 Fusions des boucles calc3, calc1 et calc2

Pour rapprocher la production des valeurs de leurs consommations, nous voulons maintenant
fusionner les boucles calc3, calc1 et calc2. Pour rendre cette transformation l'egale, il est n'ecessaire

160 15. Optimisation de Code : Le SpecFP2000 SWIM
de peeler les premi`eres et derni`eres instructions de chaque boucles afin d'obtenir un noyau
fusionnable et 'eviter les d'ependances de donn'ees pr'esentes sur les bords des tableaux. Les shifts
sur les boucles internes permettent de r'ealiser un pseudo software-pipelining rendant la fusion
l'egale.

Fusion des trois bouclesP
EEL(enclose(C3L1,2),[0,0,0,0,0,3])P
EEL(enclose(C3L1_p2,2),[0,0,1,0,0,-3])P
EEL(enclose(C3L1_p2_p1,1),[0,0,0,0,0,3])P
EEL(enclose(C3L1_p2_p1_p2,1),[0,0,0,1,0,-3])P
EEL(enclose(C1L1,2),[0,0,0,0,0,2])P
EEL(enclose(C1L1_p2,2),[0,0,1,0,0,-2])P
EEL(enclose(C1L1_p2_p1,1),[0,0,0,0,0,2])P
EEL(enclose(C1L1_p2_p1_p2,1),[0,0,0,1,0,-2])P
EEL(enclose(C2L1,2),[0,0,0,0,0,1])P
EEL(enclose(C2L1_p2,2),[0,0,1,0,0,-1])P
EEL(enclose(C2L1_p2_p1,1),[0,0,0,0,0,3])P
EEL(enclose(C2L1_p2_p1_p2,1),[0,0,0,1,0,-3])

SHIFT(enclose(C1L1_p2_p1_p2_p1),{[0,0,0,0,0,0],[0,0,0,0,0,1],[0,0,0,0,0,1]})S

HIFT(enclose(C2L1_p2_p1_p2_p1),{[0,0,0,0,0,0],[0,0,0,0,0,2],[0,0,0,0,0,2]})

MOTION(enclose(C2L1_p2_p1_p2_p1),TARGET_p2_p1_p2_p1)M

OTION(enclose(C1L1_p2_p1_p2_p1),C2L1_p2_p1_p2_p1)M
OTION(enclose(C3L1_p2_p1_p2_p1),C1L1_p2_p1_p2_p1)

15.3.5 Unroll-and-jam dans le noyau fusionn'e

La derni`ere partie de la s'equence de transformations r'ealise un Unroll and Jam de noyau
fusionn'e pr'ec'edemment. Ceci est r'ealis'e gr^ace `a un tiling suivi de d'eroulages des boucles externes.
Le d'eroulage est rendu l'egal en peelant les premi`eres et derni`eres it'erations du noyau.

Unroll-and-jamT
IMESTRIPMINE(enclose(C3L1_p2_p1_p2_p1,2),2,2)T
IMESTRIPMINE(enclose(C3L1_p2_p1_p2_p1,1),4,2)I
NTERCHANGE(enclose(C3L1_p2_p1_p2_p1,2))

TIMEPEEL(enclose(C3L1_p2_p1_p2_p1,3),4,[0,0,0,0,0,2])T

IMEPEEL(enclose(C3L1_p2_p1_p2_p1_p2,3),4,[0,0,1,0,0,-2])T
IMEPEEL(enclose(C3L1_p2_p1_p2_p1_p2_p1,1),5,[0,0,0,0,0,2])T
IMEPEEL(enclose(C3L1_p2_p1_p2_p1_p2_p1_p2,1),5,[0,0,0,1,0,-2])

FULLUNROLL(enclose(C3L1_p2_p1_p2_p1_p2_p1_p2_p1,2))F

ULLUNROLL(enclose(C3L1_p2_p1_p2_p1_p2_p1_p2_p1,1))

Le double strip-mining suivi de l'interchange impl'emente le tiling. Les transformations de
peeling permettent d'exclure les bornes de boucles en min/max, et ainsi obtenir un coeur de
noyau d'eroulable.

161
Quatri`eme partie
Impl'ementation du processus

d'optimisation

163
Chapitre 16
Processus de Compilation

Nous allons maintenant vous pr'esenter notre environnement d'optimisation. Il est compos'e
de diff'erents outils, que nous allons vous pr'esenter dans cette Partie IV : l'outil WRaP-IT extrait
les SCoPs depuis la forme interm'ediaire du compilateur Open64 et construit leur repr'esentation
poly'edrique, la WRaP. L'outil URUK applique les transformations de programmes sur cette
repr'esentation. Et enfin les outils CLooG et URGenT sont les g'en'erateurs de code associ'es `a
notre repr'esentation, qui `a partir de la WRaP, r'eg'en`ere de la forme interm'ediaire du compilateur.
La Figure 16.1 donne une vue globale du processus de compilation.

input.c
PreOPT

LNO
WOPT

CG
output.bin

IR WRaP-IT WRaP URUK WRaP URGenT

IR

Extraction Transformations G'en'eration de code

Fig. 16.1 - Processus de compilation
L'environnement complet a 'et'e impl'ement'e sous licence GPL comme un plug-in pour les
compilateurs bas'es sur Open64 de SGI. Le compilateur Open64 ORC [80] nous procure un backend permettant de compiler des codes pour architecture IA64, et le compilateur EKOPath de
Pathscale[21] fournit un back-end pour les architectures IA32 et AMD64. Les outils ont 'et'e
r'ealis'es en C et en C++, et compilent sous gcc-3.3

Tous ces outils sont disponibles `a l'adresse suivante : http ://www.lri.fr/"girbal/site wrapit.
Dans les chapitres suivants, nous allons vous pr'esenter ces diff'erents outils.

164 16. Processus de Compilation165
Chapitre 17
Quiver : Biblioth`eque de composants

La biblioth`eque de composants Quiver a 'et'e d'evelopp'ee car les diff'erents outils (WRaPIT, URUK, les g'en'erateurs de codes) manipulent des structures de donn'ees communes. Cette
biblioth`eque d'efinit donc les composants de base comme les matrices, les vecteurs ou les arbres.

Dans la section 17.1 nous pr'esenterons les raisons qui nous ont pouss'e `a d'evelopper notre
propre biblioth`eque de composants. Puis dans les sections suivantes, nous pr'esenterons les diff'erentes classes que nous avons d'efinies pour notre s'erie d'outils : les listes g'en'eriques, les vecteurs,
les matrices et les arbres.

17.1 Choix d'impl'ementation

L'outil URUK a 'et'e d'evelopp'e en C++, pour pouvoir b'en'eficier des op'erateurs surcharg'es.
Ceux-ci permettent de repr'esenter par exemple l'addition de matrice par l'op'erateur "+", ce
qui aide `a la lisibilit'e, et permet d'avoir une concordance quasi directe avec les d'efinitions du
formalisme.

Les deux classes les plus importantes sont celles impl'ementant les vecteurs et les matrices.
Les op'erateurs et fonctions suivantes ont 'et'e d'efinies dans ces classes :

- Les op'erations de calcul usuelles d'efinies dans la Section 11.1.1 sont impl'ement'ees par

surcharge des op'erateurs "+", "*", etc. Pour multiplier un vecteur V par un scalaire k, on
'ecrit donc V * k.
- Les op'erations sur les structures d'efinies dans la Section 11.1.2 sont impl'ement'ees sous

forme de m'ethodes. Pour ins'erer la ligne correspondant au vecteur V dans la matrice M
`a la colonne c, on 'ecrit donc M.ins rowpc, V q;
- Le formalisme utilise 'egalement beaucoup les notations D^, A*, ! pour indiquer des relations

de type "pr'efixe de" ou tester l'ordre s'equentiel. Nous avons impl'ement'e ces notations en
surchargeant les op'erateurs c++ a*", a* et a*a*.
- Les acc`es directs aux composantes des vecteurs et des matrices sont impl'ement'es en surchargeant l'op'erateur (). La notation \Gamma r,c se transcrit donc en C par Gammapr, cq.

Ces deux classes sont impl'ement'ees sous forme de templates, les matrices 'etant des listes de
vecteurs de m^eme dimension, et les vecteurs des listes d'entiers.

166 17. Quiver : Biblioth`eque de composants
17.2 Structures de donn'ees
17.2.1 Les listes

Les listes g'en'eriques sont impl'ement'ees par une classe templat'ee g'en'erique, ce qui permet
d'impl'ementer n'importe quel type de liste d'objets. La seule restriction est que les objets d'une
liste doivent pouvoir ^etre comparables `a l'aide des op'erateurs == et !=, ceci afin de pouvoir 'ecrire
les m'ethodes de recherche dans les listes.

La classe QuiverList peut ^etre utilis'ee pour impl'ementer aussi bien des listes `a acc`es al'eatoire, des piles, des files, et des ensembles. Chacune de ces utilisations poss`ede une s'erie de
m'ethodes d'edi'ees : Par exemple, une pile est acc'ed'ee `a l'aide des m'ethodes push et pop ; la m'ethode enset permet d'ajouter un 'el'ement `a la QuiverList en la consid'erant comme un ensemble,
si un tel 'el'ement existe d'ej`a dans la liste, il ne sera pas dupliqu'e.

En interne, les 'el'ements de la liste sont rang'es dans une liste cha^in'ee. Aucune optimisation
n'a 'et'e r'ealis'ee pour optimiser les op'erations d'allocations et de d'esallocations m'emoire : En
effet les listes ne servent que pendant les phases de cr'eation et de manipulation de la WRaP,
phases qui sont quasi-instantan'ees dans le processus de compilation.

Classe template'e pour les listes ge'ne'riques
template <class T>
class QuiverList
{public:

/*** Constructors & Destructor ***/QuiverList

(); // Create an empty listQuiverList
(const QuiverList<T> &l); // Copy constructor
QuiverList& operator=(const QuiverList<T> &l); // Copy constructor
virtual ~QuiverList(); // Free the list
/*** Boolean Operators ***/
virtual bool operator==(const QuiverList<T> &l) const; // Test for equality
virtual bool operator!=(const QuiverList<T> &l) const; // Test for inequality
/*** Methods: generic ***/
virtual long size() const; // Return the number of element of the list
virtual void concat(const QuiverList &l); // Concatenate another list at the end
virtual void concat(const T &val); // Concatenate a single element at the end
virtual bool hasPrefix(const QuiverList &p) const; // Test for prefixing
virtual bool isPrefix(const QuiverList &l) const; // Test for prefixing
virtual bool contains(const T &val) const; // Check if an element is in the list
virtual void remove(const T &val); // Remove an element if present in the list
/*** Methods: indexed list ***/
virtual T& operator()(long rank); // Access to an item of the list
virtual const T& operator()(long rank) const; // Access to an item of the list
virtual void insert(long rank,const T &val); // Insert a value int the list at rank
virtual void del(long rank); // Delete value at rank
virtual T get(long rank); // Return value at rank
virtual void setOrigin(long org); // Set the index of the first element
virtual long getOrigin() const; // Set the index of the first element
/*** Methods: stack ***/
virtual void push(const T &val); // Push a new value in the stack
virtual T pop(); // Pop a value from the stack
/*** Methods: queue ***/
virtual void enqueue(const T &val); // Add a new value to the queue
virtual T dequeue(); // Dequeue a value from the queue
/*** Methods: set ***/
virtual void enset(const T &val); // Enset a value unless it is already in
virtual void enset(const QuiverList &l); // Duplicate-less union with another set
protected:

virtual void check(const T &val); // Check new value validity
long _size; // Number of elements in the list
long _origin; // Origin offset of the list
struct item_t // Node of the list
{ T value; // Value of the current node

item_t *next; // Pointer to the next node
} *items; // List elements as a linked list

17.2. Structures de donn'ees 167

/*** Pretty printer ***/
public: friend ostream & operator<<(ostream &os, const QuiverList<T> &l);
};

17.2.2 Les vecteurs et les matrices

La classe QuiverVector repr'esentant les vecteurs d'entiers est impl'ement'ee en utilisant la
classe templat'ee QuiverList comme une liste d'entiers. Plusieurs m'ethodes ont 'et'e ajout'ees `a la
classe pour permettre de pratiquer facilement les op'erations usuelles r'ealis'ees sur ces vecteurs,
comme l'addition de vecteur ou la multiplication par un scalaire.

Des m'ethodes plus ad-hoc ont 'egalement 'et'e ajout'ees pour pouvoir tester si un vecteur est
le pr'efixe d'un autre, op'eration couramment r'ealis'ee lors du formalisme (P D^ fiS) ; pour tester
la pr'ec'edence sur les vecteurs d'ordonnancement (fiS ! fiS

1) ; pour ne garder que des parties

d'un vecteur ; et enfin pour pouvoir normaliser un vecteur en divisant chaque coefficient par le
PGCD des coefficients.

Classe pour les vecteurs d'entiers
class QuiverVector: public QuiverList<INT64>
{public:

/*** Constructors and destructor ***/QuiverVector

(); // Create an empty vectorQuiverVector
(long size,long rank=0); // Creates with depth size, filled with 0 but 1 at rank.QuiverVector
(const QuiverVector &u); // Copy constructor
QuiverVector& operator=(const QuiverVector &v2); // Copy constructor
virtual ~QuiverVector(); // Free the vector
/*** Operators ***/
QuiverVector operator+(const QuiverVector &v2) const; // Add values of two vectors
QuiverVector operator-(const QuiverVector &v2) const; // Substract values of two vectors
QuiverVector operator+(Value i) const; // Add i to the rightest part of the vector
QuiverVector operator-(Value i) const; // Substract i to the rightest part of the vector
QuiverVector operator*(Value k) const; // Multiply each cell by k
bool operator<(const QuiverVector &v2) const; // Test for strict prefixing
bool operator<=(const QuiverVector &v2) const; // Test for prefixing or equal
bool operator<<(const QuiverVector &v2) const; // Test for lexicographic order
/*** Methods ***/
long dim() const; // Alias for size
void expand(Value value); // Alias for enqueue
QuiverVector prefix(long prefsize) const; // Keep the prefsize first elements
QuiverVector suffix(long prefsize) const; // Keep all but the prefsize first elements
QuiverVector enclose(long k=1) const; // Keep all but the k lasts
long gcd() const; // Return the gcd of the vector elements.
void normalize(); // Divide all the vector values by its gcd.
/*** Pretty printer ***/
friend ostream& operator<<(ostream &os, const QuiverVector &v);
};

La classe QuiverMatrix repr'esentant les matrices d'entiers est impl'ement'ee comme une liste
de QuiverVector, les vecteurs 'etant de m^eme taille et repr'esentant les lignes de la matrice.

Une fois encore, une s'erie de m'ethodes ont 'et'e ajout'ees `a la classe pour en faciliter l'utilisation. D'abord gr^ace `a des m'ethodes d'acc`es permettant d'acc'eder rapidement `a une ligne ou
une cellule de la matrice (Pour acc'eder `a la cellule situ'ee ligne 3 colonne 8 de la matrice M on
'ecrit M(3,8)). Une nouvelle fois les op'erateurs d'addition et de multiplications ont 'et'e surcharg'e

pour 'ecrire simplement les op'erations de calculs sur les matrices (C=A*B r'ealise la multiplication
matricielle si les dimensions sont compatibles).

Des m'ethodes ont 'et'e ajout'ees pour manipuler les structures des matrices comme pr'esent'ee
dans la Section 11.1.2 du formalisme : ins_row, ins_col, del_row et del_col.

La m'ethode check de la classe QuiverList est surcharg'ee pour v'erifier que les diff'erents
vecteurs ajout'es `a la liste ont bien la m^eme dimension que les pr'ec'edents.

168 17. Quiver : Biblioth`eque de composants

Classe pour les matrices d'entiers
class QuiverMatrix: public QuiverList<QuiverVector>
{public:

/*** Constructors and destructor ***/QuiverMatrix

(); // Create an empty matrixQuiverMatrix
(long r,long c); // Creates a 0 filled (r rows, c columns)QuiverMatrix
(long s); // Creates a 0 filled square matrix (size s)QuiverMatrix
(const QuiverMatrix &m); // Copy constructor
QuiverMatrix operator=(const QuiverMatrix &m); // Copy constructor
virtual ~QuiverMatrix();
/*** Operators ***/
virtual QuiverVector& operator()(long rank); // Easy access to a row by its rank
virtual Value& operator()(long r,long c); // Easy access to a cell
virtual QuiverMatrix operator*(const QuiverMatrix &m) const; // Matrix multiplication
virtual QuiverMatrix operator+(const QuiverMatrix &m) const; // Matrix addition
/*** Methods ***/
virtual long dim_row() const; // Return the number of rows of the matrix
virtual long dim_col() const; // Return the number of columns of the matrix
virtual QuiverVector& row(long rank); // Return a vector corresponding to a matrix row
virtual QuiverVector col(long rank); // Return a vector corresponding to a matrix column
virtual void ins_row(long rank); // Insert a 0 filled row vector before a rank
virtual void ins_row(long rank, QuiverVector &v); // Insert a row vector before a rank
virtual void ins_col(long rank); // Insert a 0 filled column vector before a rank
virtual void ins_col(long rank, QuiverVector &v); // Insert a column vector before a rank
virtual void normalize(); // Normalize each row of the matrix
virtual QuiverMatrix prefix(long prefsize) const; // Keep the prefsize first lines
virtual void del_row(long rank); // Delete row at rank
virtual void del_col(long rank); // Delete column at rank
virtual void move_col(long src,long dest); // Move column at rank src to rank dest
long det() const; // Return determinant of matrix
Matrix * QuiverMatrix::Matrixize() const; // Allocate and return corresponding polylib Matrix
protected:

virtual void check(const QuiverVector &val);
long nb_cols; // Number of columns of the matrix
/*** Pretty printer ***/
public: friend ostream& operator<<(ostream &os, const QuiverMatrix &m);
};

17.2.3 Les arbres

Les arbres sont impl'ement'es par une classe templat'ee qui permet de sp'ecifier le type de
l'objet utilis'e pour stocker la valeur associ'ee `a un noeud de l'arbre. Les contructeurs permettent
de construire soit une feuille (avec une valeur associ'ee) soit un noeud (avec une valeur associ'ee
et une liste de fils impl'ement'ee par une QuiverList de QuiverTree).

Les m'ethodes associ'ees permettent de conna^itre le nombre de fils d'un noeud, d'acc'eder `a
un des fils du noeud, ou encore d'acc'eder aux valeurs stock'ees dans les noeuds et les feuilles.

Classe pour les arbres ge'ne'riques
template <class NODVAL>
class QuiverTree
{public:

/*** Constructors and destructor ***/QuiverTree

(); // Create an empty tree nodeQuiverTree
(const NODVAL &val // Create a node

,const QuiverList< QuiverTree<NODVAL> > &child);QuiverTree
(const NODVAL &val); // Create a leafQuiverTree
(const QuiverTree<NODVAL> &l); // Copy constructor
QuiverTree& operator=(const QuiverTree<NODVAL> &l); // Copy constructor
virtual ~QuiverTree(); // Free the tree
/*** Operators ***/
virtual bool operator==(const QuiverTree<NODVAL> &l) const; // test for equality
virtual bool operator!=(const QuiverTree<NODVAL> &l) const; // test for inequality
virtual QuiverTree<NODVAL> & operator()(long index); // get one of the node child
/*** Methods ***/
long nb_child() const; // Return number of children

17.2. Structures de donn'ees 169

protected:

/*** Properties ***/
NODVAL value; // Value stored in the node
QuiverList< QuiverTree<NODVAL> > children; // Children of the node
/*** Pretty printer ***/
public: friend ostream & operator<<(ostream &os,const QuiverTree<NODVAL> &l);
};

170 17. Quiver : Biblioth`eque de composants171

Chapitre 18
WRaP-IT : WHIRL Represented as
Polyedra - Interface Tool

Une infrastructure de compilation moderne comme Open64 pr'esent'e dans la Section 3 facilite grandement l'extraction de SCoPs de taille significative. Les phases analyses et de pr'eoptimisation prennent en charge l'inlining de fonction, la propagation de constante, la normalisation des boucles en do-loops, la suppression de gotos et l''elimination de code mort.

WRaP-IT est une biblioth`eque construite autour d'Open64 qui convertit la forme interm'ediaire g'en'er'ee par le compilateur Open64, la WHIRL, dans une impl'ementation de notre
formalisme, la WRaP. Une correspondance est gard'ee dans la WRaP vers les tables des symboles et les branches de l'arbre syntaxique de la WHIRL. Une fois les SCoPs transform'es, leur
code pourra ainsi ^etre g'en'er'e et la partie de l'arbre correspondante dans la WHIRL remplac'ee
par la nouvelle instance du SCoP.

Nous allons maintenant vous pr'esenter l'algorithme de WRaP-IT, qui identifie les parties
`a contr^ole statiques et collecte les informations relatives `a notre formalisme pour les diff'erents
SCoPs composant le programme.

18.1 Algorithme d'extraction des SCoPs

L'algorithme d'extraction des SCoPs est appliqu'e `a chaque fonction du programme, apr`es les
'eventuelles opportunit'es d'inlining. Pour illustrer cet algorithme, Partons de l'exemple suivant

qui correspond au corps d'une fonction pr'esente dans le programme :

Exemple de fonction `a traiter
if(N>1)
(L1) for (int i=1; i<N; i++)
(S1) A[i]=0;
(L2) for (int j=1; j<i*i; j++)
(S2) Z[i+1][2*j]=i+j;
(L3) do k=0, j

if (k<N-j)
(S3) S3
(S4) S4
(L4) do p = 0, 6
(S5) S5
(S6) S6

Les diff'erentes phases de l'algorithme sont les suivantes :

Initialisation : Chaque instruction, boucle et acc`es est marqu'e comme 'etant suppos'e affine.

172 18. WRaP-IT : WHIRL Represented as Polyedra - Interface Tool
R'ecup'eration d'informations : La premi`ere 'etape de l'algorithme s'effectue gr^ace `a une
travers'ee de syntaxe d'une fonction. Pendant cette travers'ee, nous stockons les informations
relatives aux bornes de boucles, aux pr'edicats des conditionnelles et aux acc`es aux tableaux
sous forme d'arbres repr'esentant des expressions arithm'etico-logiques quelconques.

On extrait ainsi :

- Pour chaque boucle : La conjonction d'in'equations correspondant aux bornes de la boucles.
- Pour chaque instruction : La conjonction de ces conditionnelles englobantes.
- Pour chaque acc`es T : L'arbre de racine T dont les branches correspondent aux fonctions

d'acc`es sur chacune des dimensions.
Voici par exemple les informations extraites de l'arbre concernant la boucle L2, les conditionnelles
associ'ees `a l'instruction S3, et l'acc`es au tableau Z de l'instruction S2.

Bornes de la boucle L2

^

e^ d^
j 1 j ^

i i

Conditionnelles englobant S3

^

a, a*
N 1 k '

N j

Acc`es Z de S2

Z
` *

i 1 2 j

A cette 'etape, les instructions, les boucles ou les acc`es peuvent ^etre marqu'es comme non
affine si l'algorithme construisant l'arbre des expressions arithm'etico-logiques 'echoue. Cela est
possible en cas d'inconsistance sur les types des expressions arithm'etiques et logiques (utilisation
d'op'erateurs logiques sur des expressions arithm'etiques, ou d'op'erateur arithm'etique sur des
expressions logiques), ou encore si des valeurs flottantes font parties de l'expression. Par exemple,
consid'erons la conditionnelle suivante : if((i>1)+(i<N)). Elle est syntaxiquement correcte en
C bien que r'ealisant l'op'eration arithm'etique d'addition sur des valeurs logiques bool'eennes.
Nous ne construisons donc pas l'arbre correspondant `a cette conditionnelle, et marquons les
instructions des blocs then et else comme non-statiques.

Les boucles while que le compilateur Open64 n'a pas r'eussi `a transformer en do-loop, sont
'egalement marqu'ees comme non statiques. Cela arrive lorsque l'it'erateur de la boucle est modifi'e

plus d'une fois dans le corps de la boucle while, ou quand l'it'erateur de cette boucle est flottant.

Enfin, les acc`es aux tableaux dynamiques, effectu'es par des pointeurs, sont marqu'es comme
non statiques.

18.1. Algorithme d'extraction des SCoPs 173
Normalisations des arbres arithm'etico-logiques : La seconde 'etape, est une phase de
normalisation des arbres que nous venons d'extraire. Il s'agit de r'e-'ecrire toutes les op'erations
logiques uniquement `a l'aide des op'erateurs a*, a,, d^, e^, ^ et _.
Les diff'erentes 'etapes de ce processus de normalisation sont les suivantes :

- Les comparaisons d''egalit'e et d'in'egalit'e sont d'abord transform'ees en conjonctions et

disjonctions.

"
T1 T2

^
d^ e^
T1 T2 T1 T2

0
T1 T2

_
a* a,
T1 T2 T1 T2
- Les op'erateurs de comparaison restants (a*, a,, d^, e^) sont normalis'es par r'e-'ecriture uniquement `a l'aide des op'erateurs e^, ^ et _.

a,
T1 T2

e^
T1 `

T2 1

a*
T1 T2

e^
T2 `

T1 1
d^

T1 T2

e^
T2 T1
C'est 'egalement lors de cette 'etape de normalisation que les acc`es imbriqu'es (Comme A[3+B[i]])
sont marqu'es comme non statiques. Il ne peuvent ^etre repr'esent'es par des fonctions d'acc`es affines.

Test d'affinit'e Une analyse d'affinit'e est ensuite pratiqu'ee sur les arbres normalis'es. Comme
nous nous sommes d'ej`a assur'es qu'il n'y avait aucune trace d'arithm'etique de pointeurs, ni
aucune valeur flottante dans les expressions, il ne reste plus qu'`a v'erifier que toutes les multiplications pr'esentes dans les expressions comportent au moins un argument scalaire.

174 18. WRaP-IT : WHIRL Represented as Polyedra - Interface Tool

Cela est r'ealis'e par un parcours en profondeur de l'arbre. Quand un noeud de type ^ est
rencontr'e, on v'erifie qu'au moins un de ces deux fils est une constante enti`ere. Si ce n'est pas
le cas, l'arbre est marqu'e comme non statique. Cette v'erification est suffisante car la phase de
pr'e-optimisation du compilateur Open64 a r'ealis'e la propagation et la r'esolution des calculs
entiers.

La boucle L2 est donc marqu'ee comme non statique, car l'arbre normalis'e correspondant `a
cette boucle multiplie deux valeurs non scalaires i :

Bornes normalis'ees de la boucle L2

^

e^ e^
j 1 j^

i i

Extraction des disjonctions : Nous transformons ensuite les arbres logiques en disjonctions
de conjonctions pour pouvoir les repr'esenter sous forme d'une union de poly`edres. Pour ce faire,
nous r'ealisons un nouveau parcours de l'arbre en effectuant la r'e-'ecriture suivante :

^

T1 _

T2 T3

_
^ ^
T1 T2 T1 T3

D'etermination des param`etres de chaque arbre : De l'ensemble des arbres construits
pour un SCoP sont ensuite extraits les param`etres globaux du SCoP, qui doivent rester constants
le long du SCoP, sous r'eserve de briser la staticit'e.

Propagation de la non affinit'e sur les boucles : La non staticit'e des boucles et des
conditionnelles est h'erit'ee par les boucles englobantes de la mani`ere suivante :

- Une boucle contenant une instruction dont les conditionnelles sont non-affines est marqu'ee

comme non-affine.
- Une boucle contenant une boucle non-affine est marqu'ee comme non affine.

D'elimitation des SCoPs : Les fronti`eres des SCoPs sont plac'ees de mani`ere `a exclure les
parties de code `a contr^ole non-statique des SCoPs. Les instructions dont les conditionnelles sont
non affines, sont donc exclues des SCoPs, tout comme les boucles marqu'ees comme non affines.

Le fait que les acc`es soient affines ou non n'a absolument aucun impact sur la d'elimitation
des SCoPs.

18.2. Structures de donn'ees 175

Notez que le fait qu'une boucle soit marqu'ee comme non-affine n'emp^eche pas son corps de
boucle d'^etre possiblement consid'er'e comme un SCoP. On consid`ere en effet dans ce corps de
boucle, que les instructions du corps de boucle sont de profondeur 0, et que l'it'erateur de la
boucle non-statique englobante est une constante.

Consid'erons de nouveau l'exemple de d'epart avec en pointill'e les fronti`eres de SCoP engendr'ees par la non staticit'e de la boucle L2 :

SCoP d'ecomposition
if(N>1)

(L1) for (int i=1; i<N; i++)
(S1) A[i]=0;
....................................................
(L2) for (int j=1; j<i*i; j++)
....................................................
(S2) Z[i+1][2*j]=i+j;
(L3) do k=0, j

if (k<N-j)
(S3) S3
(S4) S4
....................................................
(L4) do p = 0, 6
(S5) S5
(S6) S6

Les instructions S2, S3 et S4 forment elles-m^emes un SCoP dont j est un param`etre global,
et dans lequel l'instruction S2 est de profondeur 0.

Conversion dans le formalisme : Les SCoPs ayant 'et'e d'elimit'es, il ne reste plus qu'`a
construire les diff'erentes matrices repr'esentant les arbres arithm'etico-logiques affines des instructions des SCoP, comme indiqu'e dans les Sections 9.2, 9.3, et 9.4.

L'union de matrice des domaines est calcul'e pour chaque instruction S par conjonction des
bornes de boucles englobant S dans le SCoP et d'un des membres de l'ensemble de disjonction
repr'esent'e par les conditionnelles de S.

18.2 Structures de donn'ees

L'ensemble des structures de donn'ees pr'esent'ees ci-dessous utilisent les structures de Quiver
d'efinie dans le Chapitre 17. Elles d'efinissent l'ensemble des structures n'ecessaires `a la repr'esentation de la WRaP.

18.2.1 Symboles de la table des symboles

La table des symboles est d'efinie comme une liste de WrapSymbol. Il y a deux constructeurs
possibles pour ces symboles, suivant qu'ils soient extraits des tables de symboles d'Open64, ou
qu'ils correspondent `a de nouveaux symboles cr'e'es par les transformations.

L''egalit'e des symboles n'est pas repr'esent'ee par l''egalit'e du nom de ces symboles, mais sur
leur offset dans la table des symboles d'Open64, ce qui permet de diff'erencier deux variables
i diff'erentes, et de les faire coexister. Cela arrive souvent lorsque du code est d'eplac'e par les
transformations de fusion ou de d'eplacement.

176 18. WRaP-IT : WHIRL Represented as Polyedra - Interface Tool

Classe pour les arbres ge'ne'riques
class WrapSymbol
{public:

/*** Constructors and destructor ***/WrapSymbol

(); // Create an empty symbolWrapSymbol
(const char *_name); // Create a new symbolWrapSymbol
(WN *wn); // Create a symbol from a WHIRL nodeWrapSymbol
(const WrapSymbol &S); // Copy constructor
WrapSymbol& operator=(const WrapSymbol &S); // Copy constructor
virtual ~WrapSymbol(); // Free the symbol
/*** Operators ***/
virtual bool operator==(const WrapSymbol &s) const; // Test for equality
virtual bool operator!=(const WrapSymbol &s) const; // Test for inequality
/*** Properties ***/
char *name; // Name of the Symbol
ST *st; // Symbol table
int offset; // Offset in the symbol table
/*** Pretty printer ***/
friend ostream & operator<<(ostream &os, const WrapSymbol &s);
};

18.2.2 Arbres arithm'etico-logiques

Les WrapTree correspondent aux arbres arithm'etico-logiques. Ils sont impl'ement'es par des
QuiverTree de WrapTreeNode. Les trois constructeurs de la classe WrapTreeNode correspondent
respectivement `a la cr'eation des deux types de feuilles (enti`eres ou symboliques) et aux noeuds
repr'esentant les op'erateurs de l'expression. Les deux op'erateurs de comparaisons associ'es aux
noeuds permettent une comparaison r'ecursive des arbres repr'esentant les expressions arithm'eticologiques.

Classe pour les arbres arithme'tico-logiques
class WrapTreeNode
{public:

enum WTN_type
{ wtn_EMPTY, // Root node of empty trees (leaf)

wtn_CONST, // INTEGER CONST (leaf)
wtn_SYMB, // VARIABLE (leaf)
wtn_ARRAY, // ARRAY ACCESS (N-ary node)
wtn_NONSTAT, // NON STATIC SUB EXPR (leaf)
wtn_PLUS, // ADD (binary node)
wtn_MINUS, // SUBSTRACT (binary node)
wtn_MULT, // MULTIPLY (binary node)
wtn_NEG, // NEGATE (unary node)
wtn_MOD, // MODULO (binary node)
wtn_GT, // GREATER THAN (binary)
wtn_GTE, // GREATER OR EQUAL (binary)
wtn_EQ, // EQUAL (binary)
wtn_AND, // LOGICAL AND (binary)
wtn_OR // LOGICAL OR (binary)
};
/*** Constructors and destructor ***/WrapTreeNode

(); // Create an empty nodeWrapTreeNode
(enum WTN_type _type); // Create an operator nodeWrapTreeNode
(enum WTN_type _type,int i); // Create an integer leafWrapTreeNode
(enum WTN_type _type,const WrapSymbol &S); // Create a symbol leafWrapTreeNode
(const WrapTreeNode &n); // Copy constructor
WrapTreeNode& operator=(const WrapTreeNode &n); // Copy constructor
virtual ~WrapTreeNode(); // Free the node
/*** Operators ***/
virtual bool operator==(const WrapTreeNode &N) const; // Test for equality
virtual bool operator!=(const WrapTreeNode &N) const; // Test for inequality
/*** Properties ***/
enum WTN_type node_type; // Type of the node (see enum)
int ival; // Integer value of const leafs
WrapSymbol symbol; // Symbol value of symbol leafs

18.2. Structures de donn'ees 177

/*** Pretty printer ***/
friend ostream & operator<<(ostream &os, const WrapTreeNode &n);
};

typedef QuiverTree<WrapTreeNode> WrapTree;

18.2.3 Acc`es `a des tableaux, des scalaires ou des it'erateurs

Les acc`es `a des scalaires ou des tableaux dans les instructions du code sont repr'esent'es par
des WrapAccess. Il existe trois types d'acc`es : ceux correspondant aux tableaux, qui disposent
d'un arbre repr'esentant l'acc`es, et dans le cas des acc`es affines d'une matrice d'acc`es, ceux qui
correspondent aux it'erateurs des boucles, et ceux correspondant aux autres scalaires. Les deux
constructeurs correspondent aux acc`es de type scalaire et tableau.

Apr`es les phases d'analyses d'ecrites dans la premi`ere section de ce chapitre, certains scalaires
sont promus comme it'erateurs par la m'ethode promote_iterators, et les matrices d'acc`es des
acc`es affines sont calcul'ees par la m'ethode build_matrix.

Classe pour les acce`s
class WrapAccess
{public:

enum type_t {ua_unknown,ua_array,ua_scalar,ua_iter};
/*** Constructors and destructor ***/
WrapAccess();
WrapAccess::WrapAccess(const WrapSymbol &S);
WrapAccess::WrapAccess(WN *wn,WN *rootnode);
WrapAccess(const WrapAccess &A); // Copy constructor
WrapAccess& operator=(const WrapAccess &A); // Copy constructor
virtual ~WrapAccess(); // Free the access
/*** Operators ***/
virtual bool operator==(const WrapAccess &A) const; // Test for equality
virtual bool operator!=(const WrapAccess &A) const; // Test for equality
/*** methods ***/
void build_matrix(const QuiverList<WrapSymbol> &var); // Build access matrix from the tree
void promote_iterators(const QuiverList<WrapSymbol> &its); // Promote some scalars to iterators
/*** Properties ***/
type_t type; // Access type (array, scalar or iterator)
bool is_static; // True if access is affine, non recursive
WrapSymbol variable; // The symbol of the scalar / array
QuiverMatrix access_matrix; // Access matrix (for affine accesses)
WrapTree access_tree; // Tree representing the access
/*** Pretty printer ***/
friend ostream & operator<<(ostream &os, const WrapAccess &A);
};

18.2.4 Conditionnelles

Si le formalisme n'a pas de repr'esentation sp'ecifique aux conditionnelles (les conditions sont
stock'ees dans les domaines), il faut pendant l'algorithme de construction des SCoPs associer `a
chaque instruction une liste des conditionnelles englobantes. Ces conditionnelles sont repr'esent'ees
par des QuiverList de WrapIf.

Le constructeur est appel'e avec le noeud de la WHIRL correspondant au if, et un bool'een
indiquant si l'instruction se situe dans le then ou dans le else (auquel cas il faut nier la condition).
Ce sont les phases d'analyses qui renseignent la propri'et'e de staticit'e is_static.

Classe pour les conditionnelles
class WrapIf
{public:

/*** Constructors and destructor ***/WrapIf

(); // Create an uninitialized ifWrapIf
(WN *wn,bool in_then); // Create an if from a whirl node

178 18. WRaP-IT : WHIRL Represented as Polyedra - Interface Tool

WrapIf(const WrapIf &I); // Copy constructor
WrapIf& operator=(const WrapIf &I); // Copy constructor
virtual ~WrapIf(); // Free the if
/*** Operators ***/
virtual bool operator==(const WrapIf &I) const; // Test for equality
virtual bool operator!=(const WrapIf &I) const; // Test for inequality
/*** Properties ***/
WN *whirl_node; // WHIRL NODE of this IF
WrapTree condition_tree; // Tree storing the condition
bool is_static; // Boolean telling if "IF" is static or not
INT32 linenum; // Linenumber of the IF in the original source code.
};

18.2.5 Instructions

Les instructions de notre formalisme sont impl'ement'ees par des WrapStatement Ils sont
constitu'es des diff'erentes composantes du formalisme : Les matrices Alpha, Gamma et Beta qui
repr'esentent l'ordonnancement, la liste des domaines domain impl'ement'ee comme une liste de
matrices, les listes d'acc`es LHS et RHS, et enfin le vecteur de d'eroulage unroll

La comparaison de deux instructions se base uniquement sur la comparaison de leur vecteur d'ordonnancement, et un pointeur vers le noeud de la WHIRL wn permet d'effectuer les
remplacements correspondant `a la modification des acc`es dans l'instruction lors de la phase de
g'en'eration.

Classe pour les instructions
class WrapStatement
{public:

/*** Constructors and destructor ***/
WrapStatement(); // Create an empty statement
WrapStatement(const WrapStatement &S); // Copy constructor
WrapStatement& operator=(const WrapStatement &S); // Copy constructor
~WrapStatement(); // Free the statement
/*** Operators ***/
bool operator==(const WrapStatement &S) const; // Test for equality, relying on Beta values
bool operator!=(const WrapStatement &S) const; // Test for inequality, relying on Beta values
/*** Methods ***/
void setname(char *nam); // Set the name of the statement
void setuid(); // Set a new unique id to the statement.
void checkInvariants() const; // Check invariants within the statement
QuiverMatrix theta() const; // Compute the theta matrix
/*** Properties ***/
char *name; // name of the statement, usefull for debugging
long d; // number of englobing iterators (size of alpha)
long dgp; // number of global parameters from the parent SCoP
long dlp; // number of local parameters of the statement's domains and accesses
QuiverList<QuiverMatrix> domain; // domain of the statement
QuiverMatrix Alpha; // alpha component of the theta ordering matrix.
QuiverMatrix Gamma; // gamma component of the theta ordering matrix.
QuiverVector Beta; // beta component of the theta ordering matrix.
QuiverList<WrapAccess> LHS; // left hand side accesses of the statement
QuiverList<WrapAccess> RHS; // right hand side accesses of the statement
QuiverList<UrukLabelTag> labels; // Labels associated with this statement
QuiverVector Unroll; // Vector of 0 or 1 to unroll or not at provided dimension
WN *wn; // Whirl node corresponding to the statement
QuiverList<WrapSymbol> iterators; // list of iterators of the statement
unsigned long long uid; // Unique ID for the statement
};

18.2.6 SCoPs

Les parties `a contr^ole statique sont repr'esent'ees par des WrapSCoP qui sont compos'es d'une
QuiverList de WrapStatement. Des m'ethodes correspondent 'egalement `a l'impl'ementation de

18.2. Structures de donn'ees 179
la fonction fimax, ou au test de l'existence d'une instruction avec un vecteur d'ordonnancement
donn'e dans le SCoP.

La m'ethode call_cloog convertit la WRaP pour appeler le g'en'erateur de code CLooG
ou URGenT, qui produit un CloogProgram. La m'ethode call_wloog appelle le "printer" qui
retranscrit ce CloogProgram en WHIRL. Les pointeurs de WHIRL node wn_* servent alors `a
ins'erer le SCoP r'eg'en'er'e au bon endroit dans la WHIRL de d'epart, rempla,cant l'ancienne version
du SCoP.

Classe pour les SCoPs
class WrapSCoP
{public:

/*** Constructors and destructor ***/
WrapSCoP(); // Create an empty SCoP
WrapSCoP(const WrapSCoP &S); // Copy constructor
WrapSCoP& operator=(const WrapSCoP &S); // Copy constructor
~WrapSCoP(); // Free the SCoP
/*** Operators ***/
bool operator==(const WrapSCoP &S) const; // Test equality (needed to make SCoP lists)
bool operator!=(const WrapSCoP &S) const; // Test inequality (needed to make SCoP lists)
/*** Methods ***/
long size() const; // Return the number of statements in the SCoP
WrapStatement& operator()(int n); // Easy access to one of the SCoP statements
void add(const WrapStatement &S); // Add a new statement to the SCoP
void del(const QuiverVector &beta); // Remove some statements relying on beta-prefix.
void checkInvariants() const; // Check invariants within the SCoP
int betaOffsetMax(const QuiverVector &P) const; // Return maximum beta offset for a given beta prefix
bool betaExists(const QuiverVector &P) const; // Return true if a statment with specified prefix exists
void call_cloog(); // Code Generation : WRaP -> CLooG
void call_wloog(); // Code Generation : CLooG -> WHIRL
protected:

/*** Properties ***/
long dgp; // number of SCoP global parameters
QuiverMatrix context; // Context information on global parameters.
QuiverList<WrapSymbol> parameters; // SCoP global parameters
WN *wn_BLOCK; // Whirl node of the block containing the SCoP
WN *wn_PREV; // Whirl node of the previous statement of the SCoP
WN *wn_NEXT; // Whirl node of the next statement of the SCoP
WN *wn; // Whirl node of the first element of the SCoP
QuiverList<WrapStatement> statements; // Statements of the SCoP
bool modified; // Set to true when the SCoP is transformed
};

18.2.7 Fonctions

Les fonctions du programmes de d'epart sont impl'ement'ees par des WrapFunction. Il s'agit
simplement d'une QuiverList de WrapSCoP, avec quelques m'ethodes ad-hoc, non d'etaill'ees ici.

Classe pour les fonctions
class WrapFunction
{public:

/*** Constructors and destructor ***/
WrapFunction();
WrapFunction(const char *func_name);
WrapFunction(const WrapFunction &S); // Copy constructor
WrapFunction& operator=(const WrapFunction &S); // Copy constructor
~WrapFunction(); // Free the function
/*** Operators ***/
bool operator==(const WrapFunction &F) const; // check equality (needed by uruk_list)
bool operator!=(const WrapFunction &F) const; // check inequality (needed by uruk_list)
WrapSCoP& operator()(int n); // Easy access to one of the function SCoPs
/*** Methods ***/
long size() const; // Return the number of SCoPs in the function
void add(const WrapSCoP &S); // Add a new SCoP to the function
void del(int index); // Remove a SCoP from the function
protected:

180 18. WRaP-IT : WHIRL Represented as Polyedra - Interface Tool

/*** Properties ***/
char *name; // Function name
QuiverList<WrapSCoP> SCoPs; // SCoPs of the Function
};

181

Chapitre 19
URUK : Unified Representation
Universal Kernel

URUK est le logiciel clef de notre environnement. Pilot'e par langage de script, il applique
les transformations de programmes sur la WRaP.

Une des fonctionnalit'es importantes d'URUK est la capacit'e d'appliquer des transformations
sans effectuer tous les tests de validit'e interm'ediaires, et sans r'ef'erence au programme syntaxique.
Cela permet de n'effectuer les analyses de d'ependances qu'`a la demande, et apr`es avoir appliqu'e
la transformation.

Comme nous consid'erons des compositions de transformations, pour annuler une transformation que l'on d'etecte comme invalide, il suffit de repartir de la repr'esentation de d'epart (celle
extraite de la WHIRL) et de r'e-appliquer toutes les transformations sauf la derni`ere. Cela prend
moins de quelques secondes, car la phase de g'en'eration de code n'est appel'ee `a aucun moment
lors de la composition, mais uniquement en toute fin de programme.

Ce type de comportement est extr^emement int'eressant du fait de la diff'erence de complexit'e
entre des algorithmes diff'erents devant v'erifier les contraintes ad-hoc sur les d'ependances pour
chacune des transformations, et un algorithme `a posteriori, qui v'erifie que les relations de d'ependances sur les instructions transform'ees ne sont pas viol'ees. C'est un comportement 'egalement
int'eressant dans le cadre d'un processus de compilation it'erative, car cela permet de filtrer
automatiquement les transformations selon leur validit'e.

Les deux objectifs premiers d'URUK, mis `a part l'impl'ementation des transformations sur
le formalisme, sont : De rester le plus simple possible du point de vue de l'utilisateur qui n'est
pas forc'ement familier avec le formalisme. Et, de permettre facilement `a l'utilisateur expert
du formalisme de d'efinir de nouvelles transformations complexes, facilitant leur expression par
composition des transformations existantes.

Nous allons maintenant vous pr'esenter l'outil, du point de vue de l'utilisateur, puis du d'eveloppeur expert.

19.1 Utilisation

Cette section pr'esente l'outil URUK du point de vue de l'utilisateur voulant appliquer des
transformations d'ej`a d'efinies dans le formalisme. C'est un processus en deux 'etapes : Il faut
dans un premier temps d'ecorer le code source pour indiquer o`u les diff'erentes transformations
doivent ^etre appliqu'ees, et dans un second temps fournir un script contenant les transformations
`a appliquer automatiquement.

182 19. URUK : Unified Representation Universal Kernel
D'ecoration du programme : Notre formalisme est le plus d'etach'e possible de la repr'esentation syntaxique du programme. Nous avons toutefois besoin d'un moyen d'identifier les boucles
et les instructions dans le formalisme. Dans le Chapitre 9, nous avons montr'e que les instructions pouvaient ^etre identifi'ees de mani`ere unique par leur vecteur d'ordonnancement fi, et que
les blocs d'instructions appartenant `a la m^eme boucle 'etaient caract'eris'es par des fi-pr'efixes
communs.

Pour ^etre capable, `a partir de la version syntaxique, d'exprimer la valeur de ces fi-pr'efixes,
nous d'ecorons le code avec des labels `a la syntaxe particuli`ere (Le nom de ces labels doivent
commencer par URUK ).

Consid'erons par exemple le code suivant, dans lequel chaque instruction a 'et'e d'ecor'ee par
un de ces labels :

for (i=1; i<M; i++)

__URUK_L1:
(S1) A[i]=0;

for (j=1; j<N; j++)

__URUK_L2:
(S2) A[i] += Z[i][j] * X[j];

__URUK_L3:
(S3) b = Z[i][j] * Z[j][i]

if (k<l)

__URUK_L4:
(S4) c = X[j] * X[P-j]

La date d'ex'ecution associ'ee `a chacun de ces labels est celle de l'instruction qu'elle d'ecore.
Dans l'exemple, on peut donc obtenir directement la valeur du vecteur d'ordonnancement de
l'instruction Sk par le label Lk.

Il n'est bien s^ur pas n'ecessaire de d'ecorer l'ensemble des instructions du programme. Les
d'ecorations servant `a indiquer `a quels endroits les transformations doivent ^etre appliqu'ees, et
d'ependent donc des transformations `a appliquer.

Ci-dessous sur la gauche, un exemple simple de code, et `a droite la d'ecoration n'ecessaire
pour la transformation de fusion des boucles i et j :

for (i=1; i<M; i++)

S1
S2
for (j=1; j<M; j++)

S3
S4

for (i=1; i<M; i++)

__URUK_L1:
S1
S2
for (j=1; j<M; j++)

S3
S4

Scripts URUK : Les scripts URUK d'efinissent les transformations de programmes `a appliquer. Les param`etres de ces transformations peuvent utiliser les labels d'efinis pr'ec'edemment
pour indiquer `a quel endroit du code appliquer les transformations.
Les scripts fournissent une s'erie de fonctions associ'ees aux labels permettant d'extraire des
informations int'eressantes :

- depthpLq renvoie la profondeur du label L (le nombre de boucles englobant le label dans

le SCoP). Pour l'exemple, nous avons : depthpL1q " 1, et @k P r2, 4s depthpLkq " 2.
- enclosepLq repr'esente toutes les instructions incluses dans la boucles interne englobante.

Pour l'exemple nous avons enclosepL2q " enclosepL3q " enclosepL4q qui correspond `a
toutes les instructions de la boucle j. Par analogie avec la repr'esentation syntaxique, on
dit que enclosepL2q correspond `a la boucle j.

19.1. Utilisation 183

Notez que enclosepL1q qui correspond `a toutes les instructions de la boucle i, repr'esente
'egalement les instructions S2 " " " S4 qui sont dans une sous boucles de la boucle i.
- enclosepL, oq correspond `a la composition o fois de la fonction enclose sur un label L. On

a donc enclosepL, 1q " enclosepLq, et enclosepL, 2q " enclosepenclosepLqq qui correspond
`a toutes les instructions de la boucle "grand-m`ere" du label consid'er'e.
Pour en revenir `a la transformation de fusion des boucles i et j, le script correspondant `a la
transformation sur le code d'ecor'e est le suivant :

fusion(enclose(L1))

Et il indique qu'il faut fusionner les instructions correspondant avec la boucle i, implicitement
avec celles de la boucle qui la suit.

Un exemple : L'exemple ci-dessous illustre l'optimisation d'un petit noyau de calcul, en
'evitant toute r'ef'erence au formalisme.

A gauche le noyau de calcul d'ecor'e `a optimiser, et `a droite le script URUK.

for (i=0; i<M; i++)

__URUK_LBL1:
Z[i] = 0;
for (j=0; j<N; j++)

__URUK_LBL2:
Z[i] += (A[i][j] + B[j][i]) * X[j];
for (k=0; k<P; k++)

for (l=0; l<Q; l++)

Z[k] += A[k][l] * Y[l];

fusion(enclose(LBL1))
fusion(enclose(LBL2))
fission(enclose(LBL2))
stripmine(enclose(LBL2,2),64)
stripmine(enclose(LBL2),64)
interchange(enclose(LBL2,2))

Cela correspond `a la fusion des boucles externes i et k, `a la fusion des boucles internes j et
l, `a la fission de l'initialisation de Zris, puis au tiling des boucles fusionn'ees via 2 strip-mine et
une permutation de boucle.

Les deux paires de boucles fusionn'ees ayant des bornes diff'erentes, repr'esenter syntaxiquement cette transformation produit 'enorm'ement de versionning, chaque version ayant une garde
correspondant `a la composition des cas M a* P , M a, P , M " P , N a* Q, N a, Q et N " Q. Ci
dessous, la version correspondant au cas M a, P :

...
if ((M > P) && (N == Q) && (P >= 63))

for (ii=0; ii<P-63; ii+=64)

for (jj=0; jj<Q; jj+=64)

for (i=ii; i<ii+63; i++)

for (j=jj; j<min(Q,jj+63); j++)

Z[i] += (A[i][j] + B[j][i]) * X[j];
Z[i] += A[i][j] * Y[j];
for (ii=P-62; ii<P; ii+=64)

for (jj=0; jj<Q; jj+=64)

for (i=ii; i<P; i++)

for (j=jj; j<min(Q,jj+63); j++)

Z[i] += (A[i][j] + B[j][i]) * X[j];
Z[i] += A[i][j] * Y[j];
for (i=P+1; i<min(ii+63,M); i++)

for (j=jj; j<min(N,jj+63); j++)

Z[i] += (A[i][j] + B[j][i]) * X[j];
for (ii=P+1; ii<M; ii+=64)

for (jj=0; jj<N; jj+=64)

for (i=ii; i<min(ii+63,M); i++)

for (j=jj; j<min(N,jj+63); j++)

Z[i] += (A[i][j] + B[j][i]) * X[j];
...

184 19. URUK : Unified Representation Universal Kernel
19.2 D'eveloppement

Une bonne compr'ehension du formalisme est bien souvent n'ecessaire pour d'efinir de nouvelles
transformations, surtout si le d'eveloppeur ne les exprime pas en composant des transformations
pr'e-'existantes.

Nous avons utilis'e la biblioth`eque Quiver pour d'evelopper URUK, les composantes du formalisme (SCoP, instruction, acc`es) sont 'egalement impl'ement'ees sous forme de classes, et de
propri'et'e de classes, afin d'acc'eder facilement `a ces composantes, par les m^emes techniques de
surcharge d'op'erateurs.

- Les ensembles peuvent ^etre acc'ed'es par surcharge de l'op'erateur (). Par exemple, scop(k)

correspond `a la k-i`eme instruction du SCoP scop.
- Les diff'erentes matrices d'efinies dans le chapitre 9, sont des propri'et'es de la classe des

instructions. S.Alpha est donc un objet de classe matrice, et S.Beta un objet de classe
vecteur. S.Lamdap3q correspond `a la troisi`eme matrice de l'ensemble de matrice S.Lambda
repr'esentant une union de poly`edre.
Tout ces choix permettent que l'impl'ementation des constructeurs, des primitives et des transformations soient extr^emement similaire `a leur d'efinition formelle. Par exemple, reprenons le
coeur de la d'efinition formelle du constructeur Move, et son impl'ementation en c++ :

^
^
^
^
^
^

d DH dimpP q
P D^ fiS ^ Q D^ fiS n~ fiSd DH fiSd ` o;
P D^ fiS ^ Q ! fiS n~ fiSd DH fiSd ` o;

d=P.dim();
if ((P<=S.Beta) && (Q<=S.Beta)) S.Beta(d)+=o;
if ((P<=S.Beta) && (Q<<S.Beta)) S.Beta(d)+=o;

Fichiers de d'efinition : Pour simplifier encore la d'efinition de transformations de code, nous
avons d'efini un langage pour les fichiers de d'efinition des transformations. Chacun de ces fichiers
d'ecrit une transformation, sp'ecifiant son nom, ses param`etres, les contraintes 'eventuelles sur ces
param`etres, et le code de la transformation en c++ 'etendu.

Le c++ 'etendu que nous utilisons est du c++ classique auquel nous avons ajout'e un construct
foreach, qui permet de parcourir les 'el'ements d'un ensemble. L'exemple ci-dessous correspond
au fichier de d'efinition du constructeur Move.

%transformation move
%param BetaPrefix P // Beta prefix of the statement that may be moved
%param BetaPrefix Q // Prefix from where the statements should be moved.
%param Integer offset // displacement length

%prereq P<=Q
%code
{ foreach UrukStatement S in SCoP

{ if ((P<=S.Beta) && (Q<=S.Beta)) S.Beta(P.dim())+=offset;

else if ((P<=S.Beta) && (Q<<S.Beta)) S.Beta(P.dim())+=offset;
}
}

La section %transformation d'efinit le nom de la transformation. La section %param
d'efini les param`etres de la transformation et leur type. On peut 'egalement fournir une valeur
par d'efaut pour le param`etre, ainsi qu'un commentaire sur son r^ole. La section %prereq sert
`a d'efinir les prori'et'es requises pour les param`etres. Ici, P doit ^etre un pr'efixe de Q. Enfin, la
section %code donne le code de la transformation.

19.3. Structures de donn'ees 185
Composition : Nous avons plusieurs fois mis en avant l'int'er^et de d'efinir les transformations
comme des compositions de transformations 'el'ementaires. Voici un exemple de ce genre de
d'efinition qui d'efinit la transformation de tiling `a l'aide des transformations de strip-mining et
de permutation de boucle. Pour l'exemple, nous nous limiterons `a des tuiles carr'ees.

%transformation tiling
%param BetaPrefix P // Beta prefix of the statement to tile
%param Integer k // Size of the tile

%prereq k>0
%code
{ Q=P.enclose();

stripmine(Q,64).apply(SCoP);
stripmine(P,64).apply(SCoP);
interchange(Q).apply(SCoP);
}

19.3 Structures de donn'ees
19.3.1 Les param`etres des transformations

Les transformations d'efinies dans le Chapitre 12 poss`edent en fait une petite vari'et'e de type
d'arguments diff'erents : Les vecteurs (utilis'es dans toute les transformations pour le fi-pr'efixe),
les entiers (comme le facteur de d'eroulage du StripMine), et les matrices (comme celle de
d'ecalage pour la transformation Shift). Pour pouvoir construire automatiquement les transformations `a partir de leur fichier de d'efinition, nous avons impl'ement'e la classe UrukTParameter
permettant de repr'esenter ces diff'erents types de param`etres. Cette classe sera h'erit'ee par la
classe correspondant `a chacun des types de param`etres : UTP_value, UTP_vector, et UTP_matrix.

Les constructeurs de la classe correspondent aux diff'erents types de param`etres et seront
d'ecrits dans les classes h'erit'ees, tout comme les m'ethodes permettant d'acc'eder aux informations
relatives `a ces types.

Les deux types de param`etres entier et vecteur, peuvent ^etre repr'esent'es sous forme d'une
valeur imm'ediate stock'ee dans le param`etre, ou gr^ace `a un label situ'e dans le code source. Ces
vecteurs issus de labels correspondent donc `a des fi-pr'efixes d'instructions, et les entiers issus des
labels `a la profondeur de ces pr'efixes. Les informations sont conserv'ees le plus longtemps possible
sous la forme de label, de cette mani`ere les fi-pr'efixes et leur profondeur suivent naturellement
les instructions auxquelles ils sont attach'es lors de l'application des transformations.

La m'ethode reach permet de savoir si le param`etre de la transformation correspond `a un
SCoP donn'e. Si le param`etre est un imm'ediat, c'est toujours le cas. Si c'est un label, une
instruction avec le label correspondant est recherch'ee dans le SCoP pour savoir si c'est le cas.
Les m'ethodes get permettent de calculer les valeurs effectives des param`etres (la valeur des
imm'ediats ou la valeur calcul'ee `a partir des labels) et sont appel'ees lors de l'application des
transformations.

Classe ge'ne'rique pour les parame`tres des transformations
class UrukTParameter
{public:

/*** Constructors and destructor ***/UrukTParameter

(); // Create an undefined parameterUrukTParameter
(const char *nam, long e); // Create a labeled parameterUrukTParameter
(const char *sym); // Create a symbolic parameterUrukTParameter
(long val); // Create an integer parameterUrukTParameter
(const QuiverVector &v); // Create a vector parameterUrukTParameter
(const QuiverMatrix &m); // Create a matrix parameter

186 19. URUK : Unified Representation Universal Kernel

UrukTParameter(const UrukTParameter &L); // Copy constructor
UrukTParameter& operator=(const UrukTParameter &L); // Copy constructor
virtual ~UrukTParameter(); // Free the parameter
/*** Methods ***/
virtual bool reach(UrukSCoP &scop) const; // True if the parameter reach the SCoP
virtual void link(UrukSCoP &scop); // Link the parameter to a SCoP
virtual long get_value() const; // Get the integer value from the parameter
virtual QuiverVector get_vector() const; // Get the vector from the parameter
virtual QuiverMatrix get_matrix() const; // Get the matrix from the parameter
/*** Properties - labels ***/
char *name; // Label name
long enclose_value; // Number of englobing loop to consider
/*** Properties - symbolic expression ***/
char *symbolic_expr; // Symbolic expression (for symbolic vectors)
/*** Properties - immediate value ***/
QuiverMatrix matrix; // Immediate matrix value
QuiverVector vector; // Immediate vector value
long value; // Immediate integer value
/*** Properties - other ***/
UrukSCoP *SCoP;
};

La classe UTP_value repr'esente les param`etres entiers. Elle poss`ede un constructeur pour
les valeurs imm'ediates enti`eres, et un pour les profondeurs de labels. Ce dernier constructeur
poss`ede un argument entier indiquant le nombre de fois qu'il faut pratiquer enclose sur le
pr'efixe (le nombre de boucles englobantes `a consid'erer). Ainsi pour conna^itre la profondeur de
la boucle englobant l'instruction S de label L, on construit le param`etre UTP_value("L",1).

Classe pour les parame`tres entiers
class UTP_value : public UrukTParameter
{public:

/*** Constructors and destructor ***/UTP_value

(); // Create an empty value parameterUTP_value
(const char *nam, long e); // Create from label and enclosureUTP_value
(long val); // Create from immediate value
virtual ~UTP_value(); // Free the value parameter
/*** Methods ***/
virtual long get() const; // Return the value corresponding to the parameter
/*** Pretty printer ***/
friend ostream& operator<<(ostream &os, const UTP_value &P);
};

La classe UTP_vector repr'esente les param`etres vectoriels. Tout comme la classe UTP_value
elle peut repr'esenter des valeurs imm'ediates (la valeur du vecteur est alors directement stock'ee dans le param`etre) ou des valeurs par label. Elle dispose 'egalement d'un constructeur
construisant un param`etre vectoriel `a partir d'une expression symbolique sous forme de cha^ine
de caract`eres (comme 'N>=1000' ou 'i-2j+3'). Tout comme pour les labels, cette repr'esentation sous forme de cha^ine est conserv'ee le plus longtemps possible, puis transform'ee par un
analyseur lexical et syntaxique en vecteur lors de l'application de la transformation (voir Section
19.4.1 pour des d'etails sur la grammaire de ces analyseurs).

Classe pour les parame`tres vectoriels
class UTP_vector : public UrukTParameter
{public:

/*** Constructors and destructor ***/UTP_vector

(); // Create an empty vector parameterUTP_vector
(const char *nam, long e); // Create from label and enclosureUTP_vector
(const QuiverVector &v); // Create from vectorUTP_vector
(const char *sym); // Create from symbolic expression
virtual ~UTP_vector(); // Free the vector parameter
/*** Methods ***/
UTP_vector enclose(int k=1) const; // Increase enclosing value of the vector

19.3. Structures de donn'ees 187

virtual UTP_value dim() const; // Return the dimension of the vector parameter
virtual QuiverVector get() const; // Return the vector corresponding to the parameter
/*** Pretty printer ***/
friend ostream& operator<<(ostream &os, const UTP_vector &P);
};

La classe UTP_matrix repr'esentant les param`etres matriciels est la plus simple des trois
classes, car une matrice ne peut pas ^etre construire `a partir d'un label, ni (encore) d'expressions
symboliques.

Classe pour les parame`tres matriciels
class UTP_matrix : public UrukTParameter
{public:

/*** Constructors and destructor ***/UTP_matrix

(); // Create an empty matrix parameterUTP_matrix
(const QuiverMatrix &m); // Create from immediate matrix value
virtual ~UTP_matrix(); // Free the matrix parameter
/*** Methods ***/
virtual QuiverMatrix get() const; // Return the matrix corresponding to the parameter
/*** Pretty printer ***/
friend ostream& operator<<(ostream &os, const UTP_matrix &P);
};

19.3.2 Les transformations

Il existe une classe qui correspond `a chaque transformation de programme. Cette classe est
g'en'er'ee automatiquement `a partir des fichiers de d'efinitions, et h'erite de la classe g'en'erique des
transformations. Les m'ethodes de cette classe sont toutes abstraites, et seront en fait impl'ement'ees dans les classes d'efinissant chaque transformation.

Deux propri'et'es servent d'une part `a compter le nombre de fois qu'une transformation a 'et'e
appliqu'ee (une transformation dont aucun param`etre n'est un label va ^etre appliqu'ee `a chaque
SCoP), et d'autre part `a indiquer si la transformation utilise des valeurs par d'efaut (par exemple
par d'efaut, la transformation de permutation de boucle 'echange les deux boucles les plus internes
englobant un label, il est possible de sp'ecifier une profondeur de permutation moins importante.
Cette propri'et'e indique si ce param`etre optionnel a 'et'e ou non sp'ecifi'e).

Classe ge'ne'rique he'rite'e par les transformations
class UrukTransf
{public:

virtual ~UrukTransf();
virtual bool check_prereq(UrukSCoP &SCoP)=0; // Check if transformation prerequisites are met
virtual void apply(UrukSCoP &SCoP)=0; // Apply the transformation
virtual bool reach(UrukSCoP &SCoP) const=0; // Returns true if the transformation reach this SCoP
protected:

/*** Properties ***/
int applied; // Number of times this transformation was applied
bool is_default; // True if default parameters should be used
/*** Pretty printer ***/
public: friend ostream& operator<<(ostream &os, const UrukTransf &T);
};

Le prototype de chaque transformation 'etant quasiment identique (aux param`etres des
constructeurs pr`es) nous ne pr'esenterons que la transformation de permutation de boucle. Les
arguments de cette transformation sont donc un fi-prefixe des instructions `a permuter, et 'eventuellement la dimension des it'erateurs `a permuter (les deux it'erateurs sont cons'ecutifs). Le fichier
de d'efinition est indiqu'e ci-dessous :

Fichier de de'finition de la permutation de boucle
%transformation interchange

188 19. URUK : Unified Representation Universal Kernel

%param BetaPrefix P // The beta prefix of the statements to transform
%param Dimension o = P.dim()-1 // The dimension to be interchanged with the next one

%prereq o <= P.dim()-1 // Only interchange existing dimensions
%code
{ foreach UrukStatement S in SCoP

{ if(P<=S.Beta)

{ long ds=S.Beta.dim()-1;

QuiverMatrix M = QuiverMatrix(ds,ds); // First build a squared matrix of size ds
for(long i=1;i<o;i++) M(i,i)=1; // that looks like identity matrix with
for(long i=o+2;i<=ds;i++) M(i,i)=1; // two consecutive rows swaped
M(o,o+1)=1;
M(o+1,o)=1;
UT_leftU(S.Beta,M).apply(SCoP); // Then apply left unimodular transformation
}
}
}

Et la classe correspondante UT_interchange automatiquement g'en'er'ee `a partir de cette
d'efinition est la suivante :

Classe de la permutation de boucle (ge'ne're'e automatiquement a` partir du .def)
class UT_interchange: public UrukTransf
{public:UT_interchange

(const UTP_vector &P,const UTP_value &o); // Constructor withou default valueUT_interchange
(const UTP_vector &P); // Constructor with default value o=P.dim()-1
virtual bool check_prereq(UrukSCoP &SCoP); // Check transformation prerequisites
virtual void apply(UrukSCoP &SCoP); // Apply the transformation
virtual bool reach(UrukSCoP &SCoP) const;
protected:

UTP_vector P_prm; // The beta prefix of the statements to transform
UTP_value o_prm; // The dimension to be interchanged with the next one
};

La section code du fichier de d'efinition est plac'ee dans la m'ethode apply de la transformation,
apr`es avoir r'ecup'er'e les valeurs correspondant aux param`etres.

19.4 Analyseurs lexicaux et syntaxiques

Dans cette section, nous allons d'ecrire les diff'erents analyseurs lexico-syntaxiques composant
URUK, et principalement ceux correspondant aux fichiers de d'efinition des transformations dans
le formalisme, et ceux correspondant aux scripts URUK des transformations `a appliquer `a un
programme. Tous ces analyseurs ont 'et'e impl'ement'es avec les outils Flex et Bison.

19.4.1 Expressions arithm'etiques symboliques

Nous avons d'efini dans la section 19.3.1 que les param`etres des transformations issus des
scripts URUK pouvaient ^etre des expressions arithm'etiques symboliques repr'esent'ees sous forme
de cha^ine de caract`eres. La grammaire d'efinie ci-dessous correspond `a l'extraction de ces expressions sous forme d'objets de classe QuiverExpr `a partir de ces cha^ines de caract`eres. Ces
expressions ne seront effectivement 'evalu'ees que lors de l'application de la transformation.

quoted_expression:

"'" !expression? "'" { $2 }

expression:!

nocomp? "<=" !nocomp? { QuiverExpr(QuiverExprNode::node_le,$1,$3) }
| !nocomp? ">=" !nocomp? { QuiverExpr(QuiverExprNode::node_ge,$1,$3) }

19.4. Analyseurs lexicaux et syntaxiques 189

| !nocomp? "<" !nocomp? { QuiverExpr(QuiverExprNode::node_lt,$1,$3) }
| !nocomp? ">" !nocomp? { QuiverExpr(QuiverExprNode::node_gt,$1,$3) }
| !nocomp? { $1 }

nocomp:

& !nocomp? "+" !nocomp? { QuiverExpr(QuiverExprNode::node_add,$1,$3) }
| & !val? "*" !nocomp? { QuiverExpr(QuiverExprNode::node_mul,$1,$3) }
| & !val? { $1 }
| & !sym? { $1 }

sym:

TOK_SYM { QuiverExpr($1) }

val:

TOK_VAL { QuiverExpr($1) }

19.4.2 Scripts URUK de s'equences de transformations

Les scripts URUK d'efinis dans la section 19.1 repr'esentent les s'equences de transformations
`a appliquer `a un programme. Chaque ligne de ces scripts correspond `a une transformation et ses
param`etres : entiers, vecteurs et matrices. Les vecteurs peuvent ^etre indiqu'es comme un vecteur
d'entiers ([2,1,4]), par un nom de label (LBL1), ou par une expression arithm'etico-symbolique
(N>100).

Cette grammaire est automatiquement g'en'er'ee par URUK `a partir des fichiers de d'efinition
qui d'efinissent l'ensemble des transformations impl'ement'ees dans le formalisme. Les param`etres
de chaque transformation dans la grammaire sont ainsi ad-hoc pour chacune d'elle.

init:!

transformations?

transformations:!

transformation? e^
| !transformation? e^ !transformations?
| e^ !transformations?

transformation:

"interchange" "(" !vector? "," !value? ")" { transfs.enqueue(UT_interchange($3,$5)) }
| "interchange" "(" !vector? ")" { transfs.enqueue(UT_interchange($3)) }
... ...

| "shift" "(" !vector? "," !matrix? ")" { transfs.enqueue(UT_shift($3,$5)) }
vector:

"[" !vec? "]" { UTP_vector($2) }
| TOK_SYMBOLIC { UTP_vector($1) }
| TOK_NAME { UTP_vector($1,0) }
| "enclose" "(" TOK_NAME ")" { UTP_vector($3,1) }
| "enclose" "(" TOK_NAME "," TOK_INT ")" { UTP_vector($3,$5) }

matrix:

"{" !mat? "}" { UTP_matrix($2) }

value:

TOK_INT { UTP_value($1) }
| "depth" "(" TOK_NAME ")" { UTP_value($3,0) }
| "depth" "(" TOK_NAME "," TOK_INT ")" { UTP_value($3,$5) }

vec:

TOK_INT { QuiverVector().enqueue($1) }
| !vec? "," TOK_INT { $1.enqueue($3) }

mat:

190 19. URUK : Unified Representation Universal Kernel

"[" !vec? "]" { QuiverMatrix().enqueue($2) }
| !mat? "," "[" !vec? "]" { $1.enqueue($4) }

19.4.3 Fichiers de d'efinition des transformations

Enfin, nous avons indiqu'e au d'ebut de la Section 19.2 que chaque transformation dans le
formalisme 'etait d'efinie gr^ace `a un fichier de d'efinition. La grammaire ci-dessous correspond `a ces
fichiers. Chacun est compos'e d'un ent^ete sp'ecifiant le nom de la transformation, de d'efinitions
sp'ecifiant les param`etres de la transformation et ses pr'erequis, et d'une section code contenant
le code C++ de la transformation.

init:

"%transformation" TOK_EOL e^ !definitions? "%code" TOK_COD

definitions:

"
| e^
| !definition? !definitions?

definition:

| "%nomodify" e^
| "%param" !paramtype? TOK_IDENT !default? !comment? e^
| "%prereq" TOK_EOL e^

comment:

"
| "//" TOK_EOL

default:

"
| "=" TOK_EOL

paramtype:

"BetaPrefix"
| "Dimension"
| "Matrix"
| "Vector"
| "Integer"

191
Chapitre 20
Les g'en'erateurs de code CLooG et
URGenT

Dans le Chapitre 7, nous avons pr'esent'e des outils de g'en'eration de code CLooG et URGenT.
Dans ce chapitre, nous allons pr'esenter les d'eveloppements correspondant `a leur int'egration dans
notre formalisme.

Dans la Section 20.1 nous expliquerons comment sont construits les poly`edres 'etendus `a
partir de notre formalisme, afin qu'il soient donn'es en entr'ee du g'en'erateur de code. Dans la
Section 20.2 nous expliquerons comment nous exploitons les r'esultats obtenus apr`es la g'en'eration
de code pour effectivement g'en'erer de la WHIRL.

20.1 Cr'eation des poly`edres 'etendus

Les poly`edres 'etendus sont les poly`edres repr'esentant `a la fois les contraintes correspondant aux domaines d'it'erations et `a l'ordonnancement des instructions. Ces poly`edres sont donc
repr'esent'e dans le formalisme par la double contrainte suivante :

Domaines : La premi`ere contrainte correspond `a la d'efinition des domaines d'it'erations de la
Section 9.2. Elle d'efinit les poly`edres par des ensembles d'in'egalit'es param'etriques :

DSom "

 i

P Zd

S

| D\Lambda Sk P \Lambda S | \Lambda Sk ^

>>
--
--
-

i
iSlv
igp

1

fi
ffi
ffi
fl e^ 0

(,

Chaque domaine \Lambda Sk de l'union \Lambda S peut se d'ecomposer de la mani`ere indiqu'ee dans la Figure
20.1 consid'erant respectivement les composantes correspondant aux it'erateurs, aux variables
locales et aux param`etres globaux du SCoP.

i ilv igp 1
\Lambda Si \Lambda Slv \Lambda Sgp * e^ 0

Fig. 20.1 - Repr'esentation d'un domaine de l'union

192 20. Les g'en'erateurs de code CLooG et URGenT
Ordonnancement : La seconde contrainte correspond `a la d'efinition des matrices d'ordonnancement de la Section 9.3.

SSchpiq " \Theta S ^

>>
- iigp

1

fi
fl

La fonction d'ordonnancement affine sp'ecifiant l'ordre dans lequel il faut scanner les poly`edres
s'exprime de la mani`ere d'efinie dans la Figure 20.2. La composante correspondant aux variables
locales est nulle.

i ilv igp 11

'\Theta Si 0 '\Theta Sgp '`S1 " 0

Fig. 20.2 - Repr'esentation de l'ordonnancement par un poly`edre
Poly`edre 'etendu Le poly`edre 'etendu est construit en prenant en compte ce double ensemble
de contraintes. Ce poly`edre est construit pour chaque poly`edre de l'ensemble DSom et la fonction
d'ordonnancement SSch, et est repr'esent'e par la Figure 20.3.

i ilv igp 11
'\Theta Si 0 '\Theta Sgp '`S " 01

0 \Lambda Si \Lambda Slv \Lambda Sgp *S e^ 0

Fig. 20.3 - Repr'esentation du poly`edre 'etendu
20.2 G'en'eration de WHIRL

Les g'en'erateurs de code CLooG et URGenT sont des outils g'en'eriques de g'en'eration de code.
Il ne g'en`erent pas de la WHIRL mais une structure interne semblable `a un arbre de syntaxe,
d'ecor'e de matrices correspondant aux domaines des nids de boucles g'en'er'es. C'est la structure
de l'arbre qui donne l'ordonnancement du code g'en'er'e.

CLooG et URGenT sont fournis chacun avec un pretty-printer qui renvoie le code g'en'er'e
sous la forme d'un source pseudo-C ou pseudo-Fortran comme celui de la Figure 20.4(b).

Nous avons impl'ement'e au sein de URUK, juste apr`es l'appel au g'en'erateur de code pour
construire l'arbre d'ecor'e, un algorithme fonctionnant de la m^eme mani`ere que ces pretty-printers,
mais g'en'erant des branches de WHIRL plut^ot que des lignes de sources C. Ainsi on obtient un
morceau d'arbre de WHIRL correspondant au SCoP g'en'er'e et nous ins'erons ce morceau dans
la WHIRL `a la place du SCoP originel.

Ce "printer" de WHIRL doit toutefois ^etre beaucoup plus robuste que les pretty-printer
originaux de CLooG et URGenT car ils g'en`erent du code devant ^etre ex'ecut'e, et dont on esp`ere
tirer de la performance. Les sous-sections suivantes relatent les techniques utilis'ees pour am'eliorer
dans le printer la g'en'eration des instructions, celle des boucles et celle des conditionnelles.

20.2. G'en'eration de WHIRL 193

for(int t0=0; t0<=N; t0++)

Z[i]=0;
for(int t1=0; t1<=N; t1++)

Z[i] += A[i][j] * Y[j];

(a) Source de d'epart

for(int t0=0; t0<=N; t0++)

i=0;
S1;
for(int t1=0; t1<=N; t1++)

i=t0;
j=t1;
S2;

(b) Pseudo code g'en'er'e par CLooG

Fig. 20.4 - Pretty printer de CLooG

20.2.1 G'en'eration des instructions : 'Elimination des redondances

Consid'erons par exemple le code de la Figure 20.5, et la s'equence de transformations correspondant `a la fusion des boucles internes et des boucles externes.

for(int i=0; i<=N; i++)

for(int j=0; j<=N; j++)

S1[i][j] += i*j;
S2[i][j] -= i*j;
for(int k=0; k<=N; k++)

for(int l=0; l<=N; l++)

S3[k][l] += k*l;
S4[k][l] -= k*l;

Fig. 20.5 - Code de d'epart
Le code g'en'er'e apr`es transformation poss`ede deux it'erateurs temporels t0 et t1, et `a chaque
instruction Sk est associ'ee une s'erie d'affectations permettant d'exprimer les it'erateurs du domaine en fonction des it'erateurs du temps. La Figure 20.6(a) correspond au code produit apr`es
g'en'eration. On remarque que ces affectations ne sont pas toujours n'ecessaires : En fait, les instructions S1 et S2 poss`edent la m^eme s'erie d'affectations, tout comme les instructions S3 et
S4.

for(int t0=0; t0<=N; t0++)

for(int t1=0; t1<=N; t1++)

i=t0;
j=t1;
S1[i][j] += i*j;
i=t0;
j=t1;
S2[i][j] -= i*j;
k=t0;
l=t1;
S3[k][l] += k*l;
k=t0;
l=t1;
S4[k][l] -= k*l;

(a) Sans 'elimination des redondances

for(int t0=0; t0<=N; t0++)

for(int t1=0; t1<=N; t1++)

i=t0
j=t1
S1[i][j] += i*j;
S2[i][j] -= i*j;
k=t0
l=t1
S3[k][l] += k*l;
S4[k][l] -= k*l;

(b) Avec 'elimination des redondances

Fig. 20.6 - G'en'eration des instructions avec leurs affectations
En maintenant un historique de ces affectations qui associe `a un index correspondant au
membre gauche de l'affectation, l'arbre correspondant au membre droit, il est possible de v'erifier
avant d''ecrire une affectation si une affectation similaire avec le m^eme membre droit a d'ej`a 'et'e
r'ealis'ee, et dans ce cas, ne pas 'ecrire l'affectation. On obtient alors le code de la Figure 20.6(b).

Cette am'elioration `a un impact non n'egligeable sur le temps n'ecessaire au compilateur

194 20. Les g'en'erateurs de code CLooG et URGenT
Open64 pour g'en'erer du code `a partir de la WHIRL produite, et sur l'espace m'emoire requis par
cette g'en'eration. En effet sans cette am'elioration chaque instruction du SCoP serait pr'ec'ed'ee
d'un nombre d'affectations correspondant `a sa profondeur, ce qui multiplie le nombre d'instructions par 3 en moyenne. Certes le compilateur 'elimine les affectations inutiles, mais cette phase
d''elimination a lieu tr`es tardivement, sur le code trois adresses. Le compilateur consid`ere donc
le r'e-ordonnancement de toutes ces instructions dans ses repr'esentations haut niveau.

20.2.2 G'en'eration des bornes de boucles

Pour g'en'erer une boucle se situant `a un niveau donn'e, on extrait des matrices des domaines
les in'equations correspondant `a la borne inf'erieure, et celles correspondant `a la boucle sup'erieure.
L'invariant du formalisme inv-bnd-its nous assure que chaque it'erateur poss`ede au moins une
borne inf'erieure et une borne sup'erieure, mais il peut en poss'eder plusieurs. De plus, dans les
in'equations correspondant `a ces bornes, le coefficient associ'e `a l'it'erateur n'est pas forc'ement 1.
Consid'erons par exemple les bornes de la Figure 20.7.

N d^ 3 ^ t0
2 ^ M d^ t0

(a) Bornes inf'erieures

3 ^ t0 d^ P
2 ^ t0 d^ Q
(b) Bornes inf'erieures

Fig. 20.7 - Bornes de boucle `a g'en'erer

Il s'agit de consid'erer la conjonction de ces in'egalit'es. Une solution simple consiste `a d'efinir
les bornes de boucles inf'erieures (lb) et sup'erieures (ub) comme indiqu'e dans la Figure 20.8.

lb " max

' R N

3

V

, 2M

_

ub " min

' Z P

3

^

,

Z Q

2

^ _

Fig. 20.8 - Technique triviale de g'en'eration
Cette technique triviale `a un double d'esavantage : Tout d'abord l'impl'ementation des fonctions min et max se fait par une structure en if then else qui ajoute donc du contr^ole suppl'ementaire au niveau des bornes de boucles. Ces boucles pouvant ^etre les boucles internes de
nids de boucles plus importants, ce contr^ole peut avoir un impact sur les performances.

L'autre difficult'e vient de la diff'erence entre la division enti`ere math'ematique, et la division
enti`ere impl'ement'ee sur les compilateurs, qui se comporte diff'eremment sur les nombres n'egatifs.
Dans le pretty-printer CLooG ces bornes de boucles sont effectu'ees avec les fonctions floor et
ceil sur la division flottante du num'erateur et du d'enominateur, comme indiqu'e dans la Figure
20.9.

lb = max( ceil((float)N/3.0) , 2*M ) ub = min( floor((float)P/3.0) , floor(Q(float)/2.0) )

Fig. 20.9 - Passage par les flottants
Le co^ut au niveau des performances pour ce passage en arithm'etique flottante est tr`es lourd,
et pire encore, parfois les r'esultats sont faux. En effet les nombres entiers sont arrondis lorsqu'il sont repr'esent'es sous forme de flottants. Par exemple, l'entier 28 peut ^etre repr'esent'e par
27, 999999999 ou 28.000000001. Or f loorp28q " ceilp28q " 28 alors que f loorp27, 999999999q "
27 et que ceil(28.000000001)=29. Techniquement cela signifie que parfois se produisent des it'erations en plus ou en moins.

20.2. G'en'eration de WHIRL 195

Pour r'esoudre ce probl`eme, nous avons commenc'e par impl'ementer la v'eritable division
enti`ere math'ematique en arithm'etique enti`ere. La division enti`ere de D par N a, 0 est d'efinie
par N/D si N e^ 0, et ((N-1)/D)+1 si N a* 0. Mais cela ajoute une nouvelle conditionnelle pour
chaque division enti`ere.

Nous avons donc cherch'e `a r'eduire le nombre de divisions enti`eres. C'est possible si l'on pense
`a la fa,con dont les bornes de boucles sup'erieures sont exprim'ees en C (voir Figure 20.10(a)). La
borne sup'erieure est en fait exprim'ee par une condition bool'eenne d'arr^et de la boucle.

for(int i=... ; i<min(P/3,Q/2) ; i++)

...

(a) Bornes de d'epart

for(int i=... ; i<P/3 && i<Q/2; i++)

...

(b) Conversions des min/max

for(int i=... ; 3*i<P && 2*i<Q; i++)

...

(c) Suppression des divisions

Fig. 20.10 - Bornes sup'erieures en C

Les fonctions min situ'ees dans les bornes de boucles sup'erieures et les fonctions max situ'ees
dans les bornes de boucles inf'erieures peuvent donc ^etre 'ecrites sous forme de conjonctions
comme dans la Figure 20.10(b). Pour supprimer les divisions il suffit alors de multiplier toute
l''egalit'e, et l'on obtient le code de la Figure 20.10(c).

Malheureusement les do-loops de la WHIRL n'autorisent pas l''ecriture de conjonction de
plusieurs comparaisons pour les bornes sup'erieures, mais permettent uniquement d''ecrire une
unique comparaison. Nous sommes donc oblig'es de maintenir les min et les max. Il est toutefois
possible de supprimer les divisions en multipliant l'ensemble des in'equations par le PPCM des
diviseurs comme l'indique la Figure 20.11

for(int i=... ; 6*i<min(2*P,3*Q); i++)

...

Fig. 20.11 - Borne sup'erieure finale : Aucune division
Nous avons 'egalement envisag'e de simplifier ces expressions si le contexte le permet. En
effet, ces bornes de boucles s'expriment souvent `a l'aide des param`etres globaux du SCoP, et ces
informations de contexte sont souvent disponibles `a leur sujet. Il est par exemple tr`es fr'equent
que ces param`etres correspondent aux tailles des structures, ce qui indique alors que la valeur
du param`etre P est positive, et que donc la division enti`ere s'effectue sur les nombres positifs
(donc sans conditionnelle). Il serait 'egalement possible de r'esoudre gr^ace aux informations de
contexte certains minimums ou maximums.

20.2.3 G'en'eration des conditionnelles

La g'en'eration des conditionnelles est similaire `a celle des bornes de boucles sup'erieures
pr'esent'ees pr'ec'edemment. Il est cette fois-ci possible d'avoir des conjonctions de comparaisons.
Nous reprenons donc les techniques d'ecrites pr'ec'edemment pour 'eviter les divisions enti`eres
pr'esentes dans les conditionnelles de CLooG. Les in'egalit'es enti`eres strictes ont 'et'e rendues plus
lisibles en ne les g'en'erant pas comme des in'egalit'es larges (i<=N-1 et i+1<=N sont 'ecrits i<N).
Cela n'a aucun impact sur la performance du code g'en'er'e, mais aide `a la lisibilit'e du source pour
le d'ebogage.

196 20. Les g'en'erateurs de code CLooG et URGenT197
Chapitre 21
Conclusion

21.1 Contributions

Dans cette th`ese, nous avons d'efini une nouvelle classe d'abstraction pour repr'esenter les programmes : les parties `a contr^ole statique. Pour cette abstraction, nous avons d'efini un formalisme
permettant de repr'esenter les programmes et l'int'egralit'e des transformations de programme.

Ce formalisme fait une s'eparation claire entre ces diff'erentes composantes (domaines, ordonnancement, acc`es), et facilite `a la fois la composition de transformations de programme
permettant de construire les longues s'equences de transformations n'ecessaires `a une bonne optimisation des applications, et facilite 'egalement la recherche de cette s'equence optimisante. Ce
formalisme permet en effet d'envisager deux techniques pour la recherche de cette s'equence :

- D'une part en cherchant naturellement les transformations la composant, le choix de ces

transformations pouvant ^etre guid'e par une 'etude du comportement du programme sur
l'architecture. C'est la techniques la plus simple `a utiliser pour un utilisateur expert de
l'optimisation de programme, mais elle requiert d'identifier les r'egions `a optimiser avec des
labels. Pour cette technique l''etape de v'erification de d'ependances peut fournir une s'erie
de pr'etransformations (peeling ou shifting) rendant le cas 'ech'eant cette transformation
s'electionn'ee l'egale.
- D'autre part, il est possible de rechercher directement les valeurs de certaines matrices

composant le formalisme. L''etape de v'erification des d'ependances peut alors servir de test
de validit'e des valeurs test'ees. Par contre, il est plus difficile de guider les choix des valeurs,
et cette technique est moins naturelle pour l'utilisateur.
En couplant ces deux types de recherche, et en les dirigeant par des algorithmes de recherche
(g'en'etiques ou autres), il est envisageable de parcourir efficacement l'espace de recherche des
transformations et de leurs param`etres.

Nous avons 'egalement propos'e une impl'ementation de notre formalisme via un ensemble
d'outils utilisant le compilateur Open64. Les modifications que nous avons dues apporter au
compilateur lui m^eme sont minimes : Nous avons juste ajout'e les noms des labels `a la table des
symboles pour ^etre capables de reconna^itre les labels des transformations.
Le d'eveloppement de cette impl'ementation a 'et'e guid'e par deux objectifs :

- Que l'outil soit utilisable par des experts de la compilation, connaissant les transformations

de programmes, mais pouvant ^etre 'etrangers `a notre formalisme. Ainsi, l'outil leur permet
d'appliquer automatiquement les transformations de programme qu'ils d'esirent sur le code
qu'ils sont en train d'optimiser.
- Que le d'eveloppement de nouvelles transformations pour l'utilisateur expert du formalisme

soit le plus simple possible : Pour chaque nouvelle transformation, il suffit d''ecrire un fichier

198 21. Conclusion

de d'efinition correspondant.
Cette impl'ementation nous a permis d'optimiser avec succ`es le benchmark swim des SpecFP
2000, obtenant des speed-ups compris entre 31% et 38% par rapport aux meilleurs compilateurs
statiques disponibles.

21.2 Perspectives

Dans cette section, nous allons vous pr'esenter les perspectives de notre travail. Tout d'abord
au niveau de la formalisation du probl`eme, et ensuite au niveau de l'impl'ementation pour permettre d'avoir un v'eritable processus d'optimisation semi-automatique it'eratif.

21.2.1 Recherche d'opportunit'es de transformation

Nous avons impl'ement'e un processus complet permettant d'appliquer semi-automatiquement
les transformations de programme, mais nous manquons encore d'outils r'ealisant la recherche
d'opportunit'es pour ces transformations. C'est actuellement un utilisateur expert de l'optimisation de programme qui les s'electionne.

Il faudrait impl'ementer les recherches d'opportunit'es relatives aux transformations, celles
ci devant bien entendu s'effectuer dans notre mod`ele. Ces recherches d'opportunit'es pourraient
^etre d'efinies de la m^eme mani`ere que les transformations, gr^ace `a des fichiers de d'efinition.

En pr'emisse `a ces opportunit'es, nous avons d'evelopp'e sommairement celle correspondant
au d'eplacement de code pour rapprocher les producteurs des consommateurs. L'algorithme de
recherche d'opportunit'e appliqu'e `a une boucle est le suivant :

- Recherche des consommations, en comptant combien de fois les tableaux sont acc'ed'es et

r'eutilis'es.
- Pour les acc`es dont la r'eutilisation est la plus forte, des d'eplacements de code sont propos'es

sous forme d'une liste de transformation Motion.
- Les tests de validit'e `a posteriori permettent alors de conna^itre lesquelles de ces transformations sont valides.
- L'ensemble des transformations valides est ensuite test'e en g'en'erant les scripts correspondants.
Une recherche similaire reste `a ^etre effectu'ee pour chacune des transformations de programme
d'efinies dans le formalisme.

21.2.2 Extension de la notion de labels et instances d'instruction

L'ensemble des transformations a 'et'e d'evelopp'e en prenant soin de ne pas augmenter la complexit'e du formalisme. Deux transformations modifient toutefois sa complexit'e : Le StripMine
qui incr'emente logiquement la taille de toutes les matrices `a cause du nouvel it'erateur, et le
Peel qui duplique les instructions. Or les peeling vont souvent par paire pour s'eparer les kernels des premi`eres et des derni`eres it'erations dans les boucles, ce qui triple effectivement le
nombre d'instructions n'ecessaire pour repr'esenter la boucle.

Nous pr'evoyons d'impl'ementer les instances au sein des instructions. Il s'agirait de repr'esenter
plusieurs instances d'une m^eme instruction (avec des domaines disjoints) au sein de la m^eme
repr'esentation d'une instruction dans le formalisme. Toute ces instances pourraient avoir le m^eme
ordonnancement.

21.2. Perspectives 199

Cette modification n'ecessite bien entendu la modification du g'en'erateur de code. Mais elle
n'ecessite 'egalement une nouvelle technique pour repr'esenter une instance d'instruction particuli`ere, les labels actuels ne permettant pas de distinguer ces instances.

Les labels actuels ne permettent pas non plus de repr'esenter des r'egions de programme :
par exemple, les instructions "issues de la fonction f avant qu'elle soit inlin'ee". ou un groupe
d'instructions ne repr'esentant pas toutes les instructions d'une boucle. Il reste donc `a trouver un
moyen de repr'esenter efficacement les r'egions de programme pour appliquer les transformations
`a ces r'egions.

21.2.3 Int'egration dans un processus de compilation it'erative

Le formalisme d'ecrit dans cette th`ese a 'et'e con,cu pour faciliter la composition de transformations, afin de trouver les longues s'equences de transformations permettant d'optimiser les
applications. Dans l'introduction, nous avions sugg'er'e de guider la recherche de cette s'equence
de transformations optimisantes, par une connaissance pr'ecise du comportement du programme
sur l'architecture.

Pour ce faire, il faut encore int'egrer notre environnement de compilation dans un processus
de compilation it'eratif. La Figure 21.1 pr'esente une possibilit'e d'impl'ementation, issu de la
repr'esentation de la compilation it'erative (Figure 2.10).

Source

Compilateur

Analyses statiques

Binaires
interm'ediaires

Binaire

final

Profiling / Simulation

Analyses dynamiques

Syst`eme Expert
Analyses empiriques
Algorithmes g'en'etiques

R'esultats
Empiriques

Transformation Pool

FEEDBACK

IR IR

Fig. 21.1 - Processus d'optimisation it'eratif
Les analyses statiques repr'esentent les analyses classiques des compilateurs. Les analyses
dynamiques peuvent ^etre issues de la simulation du programme ou de son ex'ecution avec des
compteurs de performances. Les analyses empiriques peuvent ^etre r'ealis'ees gr^ace `a une 'etude empiriques de codes repr'esentatifs. David Parello a r'ealis'e [82] une telle 'etude pour les SpecFP 2000
sur un Alpha 21264, permettant ainsi d'associer `a des 'ev'enements de l'architecture (comme la
sous-utilisation de parties de l'architecture) un arbre de d'ecision s'electionnant le type de transformations `a utiliser. Ces analyses empiriques permettent donc de guider le choix des transformations parmi celles disponibles. Des algorithmes g'en'etiques, et notre syst`eme d'analyse de
d'ependance `a posteriori, pourraient alors permettre de trouver les param`etres optimaux de ces
transformations.

200 21. Conclusion
21.2.4 Architecture client / serveur

Actuellement, l'outil URUK utilise les biblioth`eques WRaP-IT et URGenT pour g'en'erer,
`a partir d'un fichier WHIRL (.N) et d'un script de transformation (.US) un nouveau fichier
WHIRL (.N) o`u toutes les transformations de programme du script ont 'et'e appliqu'ees. Le
processus de compilation it'eratif peut ainsi ^etre repr'esent'e par la Figure 21.2, un nouveau script
URUK 'etant g'en'er'e pour chaque 'etape de la compilation it'erative.

SRC Open64 .N

US

WRaP-IT

URUK
URGenT

.N Open64 BIN

Ex'ecution

&
Analyses

Nouveau script
Fig. 21.2 - Processus de compilation actuel

Ce processus relance donc l'outil URUK `a chaque 'etape du processus it'eratif, ce qui implique
'egalement que WRaP-IT (biblioth`eque de URUK) refasse l'extraction des SCoPs 'egalement `a

chaque 'etape.

Hormis le fait que cette r'e-extraction syst'ematique n'est pas n'ecessaire, elle complique 'egalement l'impl'ementation des opportunit'es sous forme de transformations : Les labels ajout'es par
les transformations d'opportunit'e qui g'en'ereraient de nouveaux scripts ne seraient pas conserv'es
dans la phase suivante correspondant `a l'ex'ecution de ces scripts.

En faisant de URUK une application client/serveur, il serait possible de maintenir la m^eme
WRaP tout au long du processus. Les transformations pr'esentes dans les scripts URUK deviendraient alors des directives envoy'ees au serveur. Il serait 'egalement ais'e d'impl'ementer la
directive reset qui restaurerait la WRaP de d'epart (par une simple copie d'objet C++ pour
sauver la WRaP de d'epart), ou celle qui termine la s'equence de transformation, active la phase
de g'en'eration de code, et teste les performances du binaire g'en'er'e.

21.2.5 Support de GCC 4.0

Dans le chapitre 3, nous avons expliqu'e les choix nous ayant men'es `a choisir le compilateur
Open64 comme base pour notre processus d'optimisation. A l''epoque du choix, ORC-2.0 et
gcc-2.95 'etaient disponibles, et cette version de gcc ne disposait pas d'une repr'esentation interm'ediaire unique, et un gros effort de d'eveloppement 'etait n'ecessaire pour r'einjecter une forme
interm'ediaire modifi'ee dans le compilateur. Nous avions donc opt'e pour ORC malgr'e la plus
grande repr'esentativit'e de gcc sur le march'e des compilateurs.

Un 'enorme travail sur les formes interm'ediaires ayant 'et'e r'ealis'e dans gcc-4, il est envisageable de r'e-impl'ementer nos outils pour utiliser ce compilateur. L'impl'ementation de nos outils
a 'et'e pens'ee pour faciliter ce changement de compilateur.

Dans WRaP-IT, il faut bien s^ur r'e'ecrire l'extraction des SCoPs en utilisant l'API correspondant au nouveau compilateur, mais les algorithmes restent les m^emes. Au niveau de la WRaP,
il n'y a quasiment aucune modification `a apporter : seuls les trois pointeurs pr'esents dans les

21.2. Perspectives 201
WrapSCoP indiquant la position du SCoP dans la repr'esentation interm'ediaire du compilateur
sont `a changer.

Dans l'outil URUK qui applique les transformations, il n'y a aucune modification `a apporter
jusqu'`a la phase de g'en'eration de code. Et dans cette phase de g'en'eration, les outils (CLooG et
URGenT) n'ont pas non plus `a ^etre modifi'es. Les seules modification `a apporter sont dans le
printer qui transcrit la repr'esentation de CLooG ou URGenT vers la repr'esentation interm'ediaire
du compilateur, une nouvelle fois par un changement d'API.

202 21. Conclusion203
Annexe A
Support de l'analyse dynamique
pour l'optimisation it'erative - DiST :
Distribution de simulations

Dans le cadre de ce travail, nous avons 'et'e amen'es `a travailler sur des techniques permettant
d'acc'el'erer le processus de compilation it'erative, plus pr'ecis'ement la phase de simulation des
binaires interm'ediaires pour en extraire un maximum d'informations utiles pour guider les phases
de compilation suivantes. Cette annexe correspond `a un article publi'e sur la parall'elisation de
la simulation par distribution de traces [43] `a la conf'erence Sigmetrics'03.

A.1 Abstract

Alors que la simulation de l'architecture est souvent trait'ee comme un probl`eme de m'ethodologie, elle est au coeur de la plupart des travaux de recherche en architecture des processeurs,
et la vitesse de simulation est souvent le goulot d''etranglement du processus d'essai/erreur de la
recherche. Pour acc'el'erer la simulation pendant ce processus de recherche et obtenir des r'esultats
plus rapidement, les chercheurs r'eduisent habituellement la taille de la trace d'instructions `a simuler. Les m'ethodes plus sophistiqu'ees comme l''echantillonnage de la trace (trace sampling) ou
la simulation distribu'ee sont rarement utilis'ees car elles sont consid'er'ees comme insuffisamment
fiables et complexes du fait de leur impact sur la pr'ecision et les probl`emes de pr'echauffage
(warm-up) associ'es. Dans ce chapitre, nous pr'esentons DiST, une m'ethode pratique de distribution de la simulation o`u, `a la diff'erence d'autres techniques de simulation qui sacrifient la
pr'ecision au profit de la vitesse, l'utilisateur est d'elest'e de la plupart des probl`emes de pr'ecision gr^ace `a un m'ecanisme automatique et dynamique pour ajuster la taille de l'intervalle de
pr'echauffage. De plus, le m'ecanisme est con,cu de fa,con `a toujours privil'egier la pr'ecision par
rapport `a l'acc'el'eration. L'acc'el'eration augmente avec la quantit'e de ressources de calcul disponibles, ce qui apporte une acc'el'eration moyenne de 7,35 pour 10 machines avec une erreur
moyenne sur l'IPC de 1,81% et une erreur maximum sur l'IPC de 5,06%. En plus de proposer
une solution aux probl`emes de pr'echauffage de la simulation distribu'ee, nous avons exp'erimentalement montr'e que notre technique est bien plus pr'ecise que les techniques de r'eduction de
taille de la trace et d''echantillonnage de la trace pour une acc'el'eration identique. Nous avons
'egalement montr'e que non seulement l'erreur sur l'IPC et d'autres m'etriques restait faible, mais

qu'un chercheur pouvait baser ses d'ecisions de recherche sur les r'esultats de simulation de DiST.
Finalement, nous expliquons comment l'outil DiST est con,cu pour ^etre facilement int'egrable

204 Annexe A
dans les simulateurs architecturaux existants avec tr`es peu de modifications et d'efforts.
A.2 Introduction

Au sein des travaux et articles de recherche en architecture, la simulation (et la m'ethodologie
en g'en'eral) est souvent consid'er'ee comme un probl`eme mineur. Cependant, dans les 'editions
2002 des quatre plus importantes conf'erences en architecture des ordinateurs (MICRO, ISCA,
ASPLOS et HPCA), les simulateurs pr'ecis au cycle sont utilis'es dans 72 sur 103 articles, soit
70% des articles : la simulation est un outil critique au coeur des travaux de recherche. Tous les
architectes de processeur ont pu constater dans leurs recherches que ce qu'ils 'etaient capables
de simuler pendant une p'eriode de temps restreinte d'eterminait souvent l''etendue, la pr'ecision
et la qualit'e de leur travail de recherche, et m^eme dans certains cas, le nombre de solutions et
d'id'ees qu'ils pouvaient 'evaluer.

Par cons'equent, la simulation et la capacit'e d'acc'el'erer la simulation ne sont pas juste des
probl`emes de m'ethodologie, ils affectent directement la partie recherche des travaux en architecture, et m'eritent donc plus d'attention.

Dans beaucoup de cas, 'evaluer une nouvelle id'ee est un processus d'essai/erreur : on impl'emente une variation d'une id'ee, on la teste, on modifie le simulateur, on la teste encore, et ainsi
de suite. En pratique, quand une id'ee est potentiellement int'eressante, les architectes de processeur veulent confirmer leurs observations en simulant et en validant cette id'ee sur un nombre
important de benchmarks, par exemple, une partie ou la totalit'e des benchmarks SPEC, pour
un ensemble de param`etres architecturaux. Dans ce cas, avoir beaucoup de ressources de calcul
est utile car les simulations peuvent s'ex'ecuter en parall`ele sur un nombre important de machines. Cependant, entre ces 'etapes de convergence, le processus de recherche consiste souvent `a
analyser ce qui est arriv'e dans quelques uns, voire m^eme un unique benchmark, conduisant ainsi
`a une s'equence r'ep'et'ee de modification et d'ex'ecution du simulateur. Parce que cette partie du
processus de recherche peut ^etre la plus gourmande en temps, les chercheurs pr'ef`erent souvent
perdre temporairement en pr'ecision pour gagner du temps, supposant que les d'ecisions de recherche ne seront pas trop alt'er'ees par cette perte de pr'ecision. Ainsi, les chercheurs r'eduisent
souvent leur taille de trace pour obtenir des r'esultats plus rapidement, pour ensuite ex'ecuter
de plus longues traces sur plus de benchmarks et plus de param`etres lorsque le processus de
recherche semble converger `a nouveau. Cependant, `a cause de la taille croissante des structures
de donn'ees comme celles des caches L2, la technique de r'eduction de la taille de la trace peut
devenir insuffisamment fiable et par cons'equent une alternative insatisfaisante, comme nous le
montrerons plus tard.

A cause de la complexit'e grandissante du processeur, la simulation du processeur est maintenant 'egalement utilis'ee pour l'optimisation et l'analyse des performances d'un programme [19,
84, 96] o`u le temps de simulation est encore plus critique. Les simulateurs permettent une compr'ehension en profondeur du comportement d'un programme sur des architectures complexes
de processeur, mais dans ce cas, le processus d'optimisation est habituellement enti`erement s'equentiel : un unique programme est optimis'e sur une unique architecture.

Finalement, le temps de simulation augmente en m^eme temps que la complexit'e du processeur
et la taille de l'application. Par exemple, simuler un benchmark SPEC95 tournant sur un processeur MIPS R2000 compos'e de 5 'etages de pipeline demande environ 7 heures sur un Pentium 4
1,6 GHz, alors que simuler un benchmark SPEC2000 tournant sur un processeur superscalaire de
degr'e 4 (en utilisant SimAlpha [31]) demande environ 356 heures sur la m^eme machine. L'aspect
le plus frustrant des simulateurs de processeur est que leur complexit'e et leur nature s'equentielle
font que leur parall'elisation est difficile. Par cons'equent, ex'ecuter une ou plusieurs simulations,

A.2. Introduction 205
avoir beaucoup de ressources de calcul ne permet pas de r'eduire consid'erablement le temps de
simulation.

Plusieurs 'etudes ont d'emontr'e que les m'ethodes d''echantillonnage de trace peuvent apporter
une acc'el'eration significative sans perdre trop de pr'ecision [69, 76, 75]. Cependant, elles ne proposent pas une m'ethode simple et compl`ete pour contr^oler les probl`emes de pr'ecision associ'es ;
en effet, la perte de pr'ecision augmente relativement rapidement avec l'acc'el'eration puisque le
principe est encore de r'eduire la taille de la trace afin de diminuer le temps de simulation. Conte
et al. [26] ont analys'e en d'etail l'effet de remettre `a z'ero l''etat du processeur dans les techniques
d''echantillonnage, mais la m'ethode n'a pas eu l'accueil attendu dans la communaut'e car ces
m'ethodes sont souvent trop complexes `a appliquer pour r'esoudre un probl`eme de m'ethodologie.
Plusieurs 'etudes [94, 93, 92, 58, 15, 50, 34] ont propos'e d'identifier les r'egions repr'esentatives
d'un programme pour la simulation, mais en pratique, une recherche exhaustive des articles de
recherche dans les plus grandes conf'erences a montr'e que peu de groupes de recherche utilisent
effectivement de telles techniques, encore `a cause de leur complexit'e, leur 'etendue d'application
limit'ee ou le manque d'outils largement diffus'es. N'eanmoins, l'approche des Basic Block Vector [92] est prometteuse car compl`etement ind'ependante du mat'eriel ; cependant, alors que la
m'ethode est assez pr'ecise pour les m'etriques globales comme l'IPC, elle est moins pr'ecise pour
les grandes structures m'emoires comme le cache L2, car elle est bas'ee sur des traces relativement
petites, et plus important encore le m'ecanisme n'est pas con,cu pour ajuster la taille de la trace
par rapport `a la taille des composants m'emoires ; finalement, la technique est sensible au jeu de
donn'ees, et l'analyse doit d'abord ^etre men'ee pour chaque couple programme/jeu de donn'ees.

Nguyen et al. [74] ont propos'e une autre approche pour acc'el'erer la simulation : d'ecouper
l'ensemble de la trace en N morceaux s'epar'es, appel'e chunk, puis les distribuer sur N machines.
A cause du d'ecoupage, la pr'ecision de la simulation d'ecro^it car l''etat du processeur est implicitement remis `a z'ero (notamment les structures m'emoires), mais l'intervalle minimum de
pr'echauffage varie fortement avec chaque chunk, et combinaison benchmark/simulateur. Pour
calculer la taille de l'intervalle de pr'echauffage, Nguyen et al. [74] proposent une heuristique
qui requi`ere de conna^itre `a l'avance le taux de d'efauts (miss rate) du cache L1 pour chaque
programme. Haskins et al. [49] proposent une technique probabiliste plus sophistiqu'ee pour d'eterminer la taille de l'intervalle de pr'echauffage, mais ils ont 'egalement besoin d'ex'ecuter une
simulation des caches pour chaque benchmark, et leurs calculs sont tr`es co^uteux en temps pour
les caches associatifs. Ainsi dans la plupart des cas, ces heuristiques sont impraticables.

Dans ce chapitre, nous pr'esentons DiST (Distributed Simulation Tool), une technique pratique de distribution de la simulation qui ajuste automatiquement la taille de l'intervalle de
pr'echauffage afin de satisfaire des seuils d'erreur d'efinis par l'utilisateur, d'echargeant ainsi l'utilisateur de la plupart des probl`emes de pr'ecision. Par cons'equent, DiST peut fortement r'eduire
le temps de la simulation avec une l'eg`ere perte de pr'ecision de la simulation tout en restant
facile `a utiliser. La technique se concentre sur la limitation des probl`emes de pr'ecision, et est
con,cue pour toujours privil'egier la pr'ecision par rapport `a l'acc'el'eration. Alors que les chercheurs veulent toujours acc'el'erer leurs simulations, aucun chercheur n'est pr^et `a accepter une
perte impr'evisible de la pr'ecision qui puisse invalider ses d'ecisions de recherche. Nous avons
montr'e exp'erimentalement que, pour aucun des SPEC CPU2000 (SPEC CINT2000 et SPEC
CFP2000), l'erreur sur l'IPC ne d'epassait 5,29% en appliquant notre technique `a SimAlpha [31],
un simulateur de processeur Compaq Alpha EV6 valid'e. SimAlpha est d'eriv'e de SimpleScalar [17, 5], le simulateur le plus couramment utilis'e dans la communaut'e de l'architecture des
processeurs. DiST atteint une acc'el'eration de 7,35 avec 10 machines. De plus, nous avons montr'e
exp'erimentalement que les d'ecisions de recherche typiques (la comparaison de la performance
relative de deux configurations mat'erielles simul'ees) ne sont jamais affect'ees par la l'eg`ere perte

206 Annexe A
de pr'ecision, en supposant que la variation de la m'etrique observ'ee n'est pas plus petite que
l'erreur. Pour toutes les statistiques, nous avons toujours observ'e que, soit l'erreur relative est
faible, soit le nombre d''ev'enements est n'egligeable. Finalement, l'outil DiST a 'et'e sp'ecifiquement con,cu pour ^etre facilement int'egrable dans les simulateurs existant avec des modifications
mineures : afin d'int'egrer l'outil dans SimpleScalar et SimAlpha, nous avons modifi'e seulement
10 lignes de code de chaque simulateur.

La section A.3 introduit les principes de la technique de distribution de la simulation, la
section A.4 d'ecrit l'impl'ementation de DiST, la section A.5 d'ecrit le protocole exp'erimental,
la section A.6 pr'esente les acc'el'erations obtenues et analyse les probl`emes de pr'ecision, et la
section A.7 aborde les nouvelles applications comme l'optimisation de programme que permet
la simulation rapide.

A.3 Principes

Avec DiST, l'acc'el'eration de la simulation provient du d'ecoupage de la simulation en un
ensemble de N chunks et de leur distribution sur le m^eme nombre de machines. Impl'ementer
le d'ecoupage et la distribution de la simulation est plut^ot simple, sauf pour le probl`eme de la
pr'ecision.

Les mod`eles de simulation au niveau cycle ne sont pas 100% pr'ecis : ils incluent presque
tous des approximations, par exemple, une impr'ecision dans la description du syst`eme m'emoire,
trop ou pas assez de chemins de donn'ees, l'impact du syst`eme d'exploitation n'est pas consid'er'e . . . Par cons'equent, l'ajout d'une petite source d'impr'ecision est acceptable. Pour ^etre tol'er'ee
en pratique, elle doit satisfaire certaines contraintes : l'utilisateur doit avoir confiance dans le
fait que l'erreur suppl'ementaire est faible, et de plus, elle doit avoir un impact aussi faible que
possible sur ses d'ecisions de recherche. Le but de notre technique est d'atteindre ces objectifs
de pr'ecision avec le moins d'intervention de l'utilisateur. Le principal d'efi est de contr^oler automatiquement le niveau de pr'ecision et privil'egier la pr'ecision par rapport `a l'acc'el'eration en
sacrifiant l'acc'el'eration lorsque c'est n'ecessaire.

2fl 3fl 4fl 5fl 6fl 7fl 8fl 9fl 10fl 11fl 12fl 13fl 14fl 15fl
1fl 2fl 3fl 4fl 5fl

8fl 9fl 10fl

12fl 13fl 14fl 15fl

6fl 7fl

11fl6fl 7fl
11fl

1fl
Chunk 1fl
Chunk 2fl
Chunk 3fl

Se'quentielfl

Temps de simulationfl
Subchunkfl
Subchunk de chevauchementfl
Subchunk de pre'chauffagefl
Emulationfl

Fig. A.1 - Ordonnancement des chunks et des subchunks.
Les principes de la simulation distribu'ee sont les suivants. Supposons que l'on souhaite ex'ecuter une simulation de N instructions avec 3 machines : alors, chaque machine simulera N3
instructions. Les N3 premi`eres instructions sont simul'ees sur la premi`ere machine, les N3 instructions suivantes sur la seconde, et ainsi de suite, voir la Figure A.1. Chaque machine ex'ecute
le programme depuis le d'ebut, mais commence `a simuler seulement `a la premi`ere instruction
du chunk sp'ecifi'e, ainsi, chaque machine doit 'emuler (simulation fonctionnelle seulement) le

A.3. Principes 207
programme jusqu'`a atteindre ce point. La premi`ere machine ne fait donc pas d''emulation, la
seconde machine 'emule N3 instructions et la troisi`eme machine 'emule 2^N3 instructions. Consid'erons l''ecart de vitesse entre l''emulation et la simulation, le d'eroulement dans le temps typique
d'une simulation distribu'ee ressemblerait `a la Figure A.1. Cependant, `a la fin de l''emulation,
avant de commencer la simulation, toutes les structures du processeur sont vides (caches, tables
de pr'ediction de branchement. . . ) donc les premi`eres instructions simul'ees provoqueront des
comportements inhabituels (taux de d'efauts de cache excessif, mauvaises pr'edictions de branchement. . . ) qui fausseront les statistiques. Pour r'esoudre ce probl`eme, l''etat du processeur est
habituellement pr'echauff'e/rafra^ichi en simulant un certain nombre d'instructions sans garder
les m'etriques correspondantes ; en d'autres mots, la simulation d'ebute avant que la premi`ere
instruction du chunk soit atteinte. Parce que cet intervalle de pr'echauffage peut avoir un impact
important `a la fois sur la pr'ecision et le temps de simulation, la plus grande difficult'e est de
trouver une taille d'intervalle de pr'echauffage appropri'ee.

Le m'ecanisme de pr'echauffage dynamique. Avec DiST, au lieu d'ex'ecuter un nombre
fixe d'instructions de pr'echauffage avant le chunk m, nous laissons le chunk m ' 1 ex'ecuter
des instructions suppl'ementaires apr`es avoir termin'e toutes ses instructions. Par cons'equent, les
derni`eres instructions du chunk m ' 1 sont les m^emes que celles du d'ebut du chunk m. Durant
cette p'eriode de chevauchement, nous comparons constamment les r'esultats de simulation du
chunk m'1 et du chunk m jusqu'`a ce qu'ils convergent. Quand ils deviennent presque identiques,
nous pouvons raisonnablement supposer que l''etat du processeur du chunk m a 'et'e proprement
pr'echauff'e et que nous pouvons arr^eter le chunk m ' 1. Plus pr'ecis'ement, pour effectuer ces comparaisons, nous d'ecoupons chaque chunk en un ensemble de subchunks de taille fixe (typiquement
quelques millions d'instructions, voir la section A.5). Par exemple, sur la Figure A.1, les chunks 2
et 3 ont besoin respectivement de 2 et 1 subchunks de pr'echauffage ; sym'etriquement, les chunks
1 et 2 font 2 et 1 subchunks de chevauchement. Durant la p'eriode de chevauchement, les chunks
m et m ' 1 affichent les statistiques de simulation de tous les subchunks, et un processus hors
ligne r'ecolte les donn'ees et compare les statistiques des subchunks correspondants aux m^emes
instructions. L'utilisateur peut sp'ecifier, avec un langage de script simple d'ecrit en section A.4,
quelles statistiques sont utilis'ees pour la comparaison et quel est le seuil de convergence. Typiquement, dans beaucoup de simulations de cette section, la convergence est bas'ee sur l'IPC avec
un seuil de convergence de 98%, ce qui signifie que l'IPC des subchunks des chunks m et m'1 ne
peut pas diff'erer de plus de 2%. D`es qu'un subchunk respecte ce crit`ere, le pr'echauffage s'arr^ete.
Toutes les statistiques des subchunks de pr'echauffage "impr'ecis" du chunk m, c'est `a dire, les
subchunks simul'es avant que la convergence soit atteinte, sont alors 'elimin'es et remplac'es dans
le chunk m par les statistiques des subchunks suppl'ementaires (de chevauchement) du chunk
m ' 1. Remarquez que, en supposant que tous les chunks vont `a la m^eme vitesse, les subchunks
suppl'ementaires n'ont pas d'impact sur le temps de la simulation distribu'ee, car le dernier chunk
n'a pas de tels subchunks, voir la Figure A.1. Finalement, un autre avantage de la technique est
que la pr'ecision de la simulation est implicitement privil'egi'ee par rapport `a l'acc'el'eration de la
simulation : dans le pire des cas o`u le chunk m ' 1 ne converge pas avec le chunk m ou un des
chunks suivants, le chunk m ' 1 continuera s'equentiellement pendant le reste de la simulation.

Surtout, le principal int'er^et du pr'echauffage dynamique par rapport aux techniques pr'ec'edentes de pr'echauffage statique n'est pas la vitesse mais la pr'ecision : en utilisant le pr'echauffage
dynamique, il est possible de distribuer la simulation et assurer un niveau raisonnable de pr'ecision avec une intervention minimale de l'utilisateur.

208 Annexe A
A.4 Impl'ementation

L'utilisation de la simulation distribu'ee pose plusieurs probl`emes d'impl'ementation : bien
r'egler le m'ecanisme de pr'echauffage dynamique, appliquer la distribution sur un simulateur
existant, combiner les statistiques distribu'ees de chaque chunk sans modifier les proc'edures
manipulant les statistiques de ce simulateur, sp'ecifier des contraintes de pr'ecision locales. A la
fin de cette sous-section, nous pr'esentons 'egalement une br`eve description de l'environnement
logiciel.

Utiliser des simulateurs existants. Le d'eveloppement d'un simulateur est une tache
laborieuse et gourmande en temps `a cause d'un long processus de mod'elisation, de d'ebogage et
de validation. Par cons'equent, DiST est con,cu de fa,con `a ne n'ecessiter que des modifications
minimales du simulateur. Pour int'egrer DiST dans un simulateur, nous avons seulement besoin
de forcer le simulateur `a afficher p'eriodiquement les statistiques plut^ot que de le laisser les
afficher uniquement `a la fin de la simulation. Pour int'egrer DiST dans SimAlpha [31], nous
avons seulement eu `a modifier 10 lignes de code source. Le d'etail des modifications apport'ees `a
ces simulateurs est disponible sur http ://www.microlib.org/DiST. De la m^eme fa,con, DiST a 'et'e
int'egr'e dans SimpleScalar [17, 5], dans le simulateur de PowerPC 750 [72], et dans le simulateur
modulaire de processeur superscalaire g'en'erique OoOSysC [73] tous deux 'ecrits en SystemC [81].

Un simulateur est compatible avec DiST s'il fournit un m'ecanisme pour sauter des instructions du programme, c'est `a dire une avance rapide (fastforward) : un 'emulateur ou bien un
m'ecanisme de check-point. Bien que nous ayons utilis'e l''emulation pour l'avance rapide dans
cette 'etude, le "checkpointing" est bien plus fiable et efficace car il garantit que tous les threads
distribu'es ne seront pas sensibles aux effets du syst`eme d'exploitation, et en outre, il 'evite la
phase d''emulation.

Combiner les statistiques distribu'ees. Pendant la simulation, DiST collecte les statistiques du simulateur pour chaque subchunk ; A la fin de la simulation distribu'ee, toutes les
statistiques locales collect'ees doivent ^etre combin'ees pour obtenir les statistique de l'ex'ecution
compl`ete. Selon la statistique, la tache peut ^etre triviale ou requ'erir plus de traitements. Par
exemple, les statistiques cumulatives comme le nombre de d'efauts (de cache ou de pr'ediction de
branchement) ont seulement besoin d'^etre somm'ees pour obtenir les statistiques de l'ex'ecution
compl`ete. Mais les rapports doivent ^etre recalcul'es, c'est `a dire, si le chunk 1 affiche le rapport

A1
B1 et le chunk 2 affiche

A2
B2 , le rapport pour l'ex'ecution compl`ete est

A1`A2
B1`B2 , non

A1
B1 `

A2
B2 . Pourcela, l'outil impl'emente un langage de script simple pour d'efinir les statistiques. Nous supposons que, `a la fin de l'ex'ecution, le simulateur 'ecrit dans un fichier texte qui contient toutes les
statistiques, et que ces statistiques sont list'ees ligne par ligne.

Reportez-vous `a la Figure A.2 pour les statistiques de d'efaut du cache L1 dans la sortie de
SimAlpha (non modifi'e).

DL1.hits # total number of (all) hits
DL1.misses
DL1.accesses
DL1.miss_rate

# total number of misses
# total number of accesses
# miss rate (i.e., misses/ref)

25916780

0.0173
1497571725.0000

1471654945

Fig. A.2 - Un exemple de sortie d'un simulateur (SimAlpha).
Dans l'outil, DL1.hits, par exemple, est directement utilis'e comme un nom de variable pour
caract'eriser la statistique, ainsi la seule contrainte suppl'ementaire sur un fichier de statistiques
est de comporter un nom unique pour chaque statistique. Le fichier de statistiques liste les

A.4. Impl'ementation 209
variables qui sont soit suivies d'un commentaire (dans ce cas elles sont cumul'ees), ou par "=" et
n'importe quelle expression math'ematique suivie d'un commentaire.

DL1.misses : "total number of misses"
DL1.accesses = DL1.hits + DL1.misses : "total number of accesses"
DL1.miss_rate = DL1.misses / DL1.accesses : "miss rate (i.e., misses/ref)

DL1.hits : "total number of (all) hits"

Fig. A.3 - Un exemple de script pour combiner les statistiques.
Par exemple, la quatri`eme ligne de la Figure A.3 sp'ecifie que la statistique de l'ex'ecution compl`ete DL1.miss_rate est 'egale au rapport entre la statistique de l'ex'ecution compl`ete
DL1.misses et la statistique de l'ex'ecution compl`ete DL1.accesses, qui est elle-m^eme d'efinie
plus haut comme 'etant la somme de deux statistiques de l'ex'ecution compl`ete.

Ainsi pour obtenir les statistiques de l'ex'ecution compl`ete, l'utilisateur a seulement besoin
d'obtenir le fichier de sortie et 'ecrire les expressions appropri'ees pour certaines statistiques. A
l'ex'ecution, l'outil analysera les sorties locales du simulateur et les comparera avec les expressions. Par cons'equent, il n'est pas n'ecessaire de modifier les proc'edures de gestion et de sortie sur
fichier des statistiques d'un simulateur pour int'egrer DiST, sauf si plusieurs statistiques portent
le m^eme nom.

Impl'ementer les contraintes locales. Nous utilisons le m^eme langage de script et le m^eme
m'ecanisme d'analyse des statistiques pour impl'ementer les contraintes de pr'ecision locales. Par
exemple, si nous d'esirons imposer une pr'ecision locale de 1% sur le taux de d'efauts du cache L1
de donn'ees, nous ins'ererons la ligne de la Figure A.4 dans le fichier des contraintes.

abs(~DL1.miss_rate - DL1.miss_rate) / DL1.miss_rate < 0.01
Fig. A.4 - Un exemple de contrainte locale de pr'ecision.

DL1.miss_rate repr'esente la statistique du nouveau chunk, par exemple, le chunkm, qui est
compar'ee avec la statistique du chunk qui se termine, par exemple, le chunkm'1. La comparaison
est r'ep'et'ee sur chaque subchunk jusqu'`a ce que la condition soit remplie, comme expliqu'e `a la
section A.3. Les diff'erentes contraintes sont list'ees dans un fichier de contraintes locales, voir la
Figure A.4, et l'outil effectue un "et logique" entre toutes ces contraintes.

DiST. DiST utilise lui-m^eme une architecture client/serveur, voir Figure A.5. Nous supposons que le code objet du simulateur et les donn'ees des benchmarks sont sur toutes les machines
(h^otes). Lorsqu'un simulateur est d'emarr'e en utilisant DiST, DiST lance un client sur chaque machine h^ote distante (un chunk par client) en utilisant un service d'ex'ecution `a distance. Chaque
client se connecte au serveur qui d'etermine la taille du chunk, assigne les chunks en fonction
du nombre de processeurs disponibles et de la vitesse de chacun des processeurs. Le serveur est
multithread'e : un thread ma^itre et un thread par client ; les clients obtiennent leur configuration
au d'emarrage et envoient ensuite leurs statistiques au serveur apr`es chaque subchunk ; le serveur
d'etermine quand un client doit ^etre arr^et'e en comparant les subchunks de chevauchement et
les subchunks de pr'echauffage de deux clients cons'ecutifs ; finalement, le thread ma^itre combine
'egalement les statistiques lorsque tous les chunks sont termin'es. Remarquez que distribuer plusieurs chunks de la trace d'un m^eme benchmark sur diff'erentes machines pose le probl`eme du
partage de fichier (ils 'ecrivent dans les m^emes fichiers de sortie du benchmark) que le serveur
r'esout en copiant les fichiers.

210 Annexe A

Liste machines

Constraintes
Statistiques

ThreadMaitre

Simulateur Simulateur

socket socket
Client

socket
Client

ThreadClient ThreadClient
Configuration Configuration

StatistiquesStatistiques

stderr

Sur la machinelocale
stderr Sur les machinesdistantes

socket

Fig. A.5 - L'architecture de DiST.

Fig. A.6 - L'interface graphique utilisateur de DiST.

A.5. Protocole exp'erimental 211

Remarquez 'egalement que puisque chaque client envoie seulement un message par subchunk,
le trafic r'eseau est tr`es bas et ne provoque pas de contentions, m^eme avec un grand nombre de
machines (plusieurs dizaines). Par exemple, avec SimpleScalar, une trace de 4 milliards d'instructions et des subchunks de 16 millions d'instructions entra^ine seulement quelques centaines
de messages de 100 octets chacun. Par cons'equent, DiST est compatible avec des r'eseaux lents.

Comparaison de DiST avec les syst`emes de gestion de charge de travail. Beaucoup
d'environnements, comme Condor [67], proposent d'exploiter plusieurs ressources de calcul en
distribuant les travaux sur plusieurs machines. Par exemple, Condor ordonnance, suspend, et
migre les travaux de sa file d'attente pour optimiser l'utilisation des processeurs. Cependant,
Condor n'est pas con,cu pour g'erer les communications inter-processus, en particulier pour les
travaux coop'eratifs d'une application client/serveur comme DiST. N'eanmoins, nous pourrions
am'eliorer DiST en utilisant Condor et la librairie de Condor pour distribuer nos propres travaux
plus efficacement sur les ressources de calcul disponibles.

Une interface graphique utilisateur. Finalement, DiST est fourni avec une interface
graphique utilisateur, voir Figure A.6, qui est tr`es utile pour surveiller la progression, la quantit'e
de pr'echauffage pour chaque chunk et pour estimer le temps total de simulation.

A.5 Protocole exp'erimental

L'environnement de simulation. Dans la sous-section suivante, nous utilisons SimAlpha
et les SPEC2000 pour 'evaluer la simulation distribu'ee. Nous avons choisi SimAlpha [31] plut^ot
que SimpleScalar [17, 5] car l'architecture simul'ee est plus proche de celle d'un vrai processeur
(la Figure A.7 d'ecrit la configuration de base de SimAlpha), et parce que le rapport de la vitesse
de l''emulateur sur la vitesse du simulateur est sup'erieur `a celui de SimpleScalar, l'acc'el'eration
limite est donc elle-m^eme sup'erieure, voir la sous-section A.6. Nous avons utilis'e une trace de 4
milliards d'instructions pour chaque benchmark, et saut'e les 4 premiers milliards d'instructions.
Nous avons r'ealis'e les exp'eriences principales (acc'el'eration et pr'ecision) sur 22 SPEC2000 (4
n'ont pu ^etre ex'ecut'ees sur nos machines). Nous avons ex'ecut'e nos exp'eriences sur diff'erents
groupes de machine ; nous avions acc`es `a 10 Pentium III 733 MHz avec 128 Mo, 10 Pentium III
733 MHz avec 256 Mo, et un acc`es restreint `a 40 Athlons XP 1800+ avec 1 Go. A cause de ces
restrictions, toutes nos exp'eriences n'ont pu ^etre r'ealis'ees sur les 40 Athlons. Pour chaque figure,
nous indiquons sur quel groupe de machine les exp'eriences ont 'et'e men'ees. Remarquez que 10 des
22 SPEC2000 provoquaient un swap excessif durant la simulation sur les Pentium III 733 MHz
avec 128 Mo d^u `a des ressources m'emoires trop limit'ees, c'est pourquoi le temps d'ex'ecution, et
donc l'acc'el'eration, n'a pu ^etre estim'ee avec pr'ecision. Par cons'equent, nous avons d'efini un jeu
de tests complet correspondant aux 22 benchmarks, et un jeu de r'ef'erence de 12 benchmarks
qui ont pu ^etre ex'ecut'es sur toutes les machines, voir la Figure A.8 (heureusement, le jeu de
r'ef'erence est compos'e d'un m'elange de codes SPECINT et SPECFP). A cause de ces contraintes
de machine, seules quelques exp'eriences sont seulement donn'ees sur le jeu de r'ef'erence.

Param'etrage de DiST. Les principaux probl`emes de param'etrage de DiST sont trouver une taille de subchunk appropri'ee et d'efinir le seuil de convergence. Intuitivement, plus le
subchunk est grand, plus la comparaison entre les subchunks de pr'echauffage et ceux de chevauchement est pertinente et pr'ecise. Ainsi, plus le subchunk est grand, plus l'erreur est petite.
Mais avec de trop grand subchunks, la p'eriode de pr'echauffage et donc le temps de simulation
sur une machine m peut augmenter jusqu'`a affecter le temps de la simulation distribu'ee, voir
la Figure A.9. Par cons'equent, nous avons besoin de trouver une taille de subchunk qui soit un
compromis raisonnable entre la pr'ecision et la vitesse. La Figure A.10 montre que des subchunks
de 16 millions d'instructions permettent d'obtenir `a la fois une erreur faible et un surco^ut (d^u

212 Annexe A

Param`etre Valeur

Coeur du processeur
Largeur du Fetch jusqu'`a 4 instructions par cycle
Largeur de Issue jusqu'`a 4 op'erations enti`eres par cycle

jusqu'`a 4 op'erations flottantes par cycle
Unit'es Fonctionnelles 4 ALUs + 2 FPUs
Largeur de Commit jusqu'`a 11 instructions par cycle

Pr'ediction de Branchement
Pr'edicateur Pr'edicteur du 21264 (hybride)
BTB 512 entr'ees/4-way associative
Return Addr Stack 32 entr'ees

Hi'erarchie M'emoire
L1 Data Cache 32 KB/2-way associative/LRU
L1 Instruction Cache 32 KB/2-way associative/LFU
L2 Cache 2 MB/direct mapped/LRU
ITLB 128 entr'ees/fully associative
DTLB 128 entr'ees/fully associative

Fig. A.7 - Configuration de base.

SpecINT2000 SpecFP2000
175.vpr 172.mgrid
186.crafty 178.galgel
197.parser 179.art
252.eon 187.facerc
255.vortex 188.ammp
300.twolf 200.sixtrack

Fig. A.8 - jeu de r'ef'erence.

au pr'echauffage) faible.

Nous avons trouv'e exp'erimentalement que dans beaucoup de cas contraindre l'erreur sur
l'IPC est suffisant pour atteindre une pr'ecision raisonnable sur la plupart des m'etriques des
composants du processeur. Il n'est utile d'imposer une contrainte sur l'erreur d'une autre m'etrique que pour 'etudier sp'ecifiquement un composant de l'architecture. Nos exp'eriences ont
aussi montr'e qu'une contrainte de pr'ecision locale de 98% sur l'IPC 'etait suffisante pour tous
les benchmarks : par exemple, `a 90% ou moins, la pr'ecision diminue significativement et le m'ecanisme de pr'echauffage n'est pas exploit'e, alors qu'au-del`a de 99%, le surco^ut du pr'echauffage
augmente significativement jusqu'`a faire d'ecro^itre l'acc'el'eration, cf. Figure A.11.

D'efinitions. Dans ce paragraphe, nous d'efinissons plusieurs mesures. L'erreur globale sur

une m'etrique est d'efinie par la formule suivante : metricdist

' metricseq

metricseqo`u
metricseq est la m'etrique fournie par la simulation s'equentielle sur un seul processeur, et

metricdist est la m'etrique combin'ee calcul'ee par DiST apr`es que tous les chunks aient 'et'e ex'ecut'es.
Le temps s'equentiel est le temps de la simulation s'equentielle sur un seul processeur.
Le temps distribu'e est l'intervalle de temps entre le d'ebut du premier chunk et la fin du dernier
chunk, voir la Figure A.9.
L'acc'el'eration est le rapport du temps s'equentiel sur le temps distribu'e.

A.5. Protocole exp'erimental 213

Chunk 0

Chunk 1
Chunk 2

Chunk 3

Subchunk
no Chunk

Subchunk de
Subchunk de

Temps de simulation
Impact duSans le surcout
Temps total de la simulation distribue'e

chevauchement
pre'chauffage

surcout
Fig. A.9 - Impact de la taille de subchunk sur le temps total de la simulation distribu'ee.

Fig. A.10 - Impact de la taille de subchunk sur l'acc'el'eration et la pr'ecision ; 10 PIII 500.

Fig. A.11 - Choisir un seuil de convergence bas'e sur l'IPC.

214 Annexe A

Fig. A.12 - Acc'el'eration avec 10, 20 et 40 machines ; jeu complet, Athlon XP 1800+.
Fig. A.13 - Acc'el'eration avec 10 et 20 machines ; jeu de r'ef'erence, 10 PIII 500 et 10 PIII 500 ` 10 PIII733.
Fig. A.14 - Acc'el'eration avec 40 machines ; jeu restreint, 16 milliards d'instructions, en sautant les 4milliards premi`eres instructions, 40 Athlons XP 1800+.

A.6. Acc'el'eration et Pr'ecision (R'esultats exp'erimentaux) 215
A.6 Acc'el'eration et Pr'ecision (R'esultats exp'erimentaux)

Fig. A.15 - Pr'ecision de DiST ; jeu complet, 40 Athlons.
Fig. A.16 - Pr'ecision avec une petite trace (100 millions d'instructions) ; jeu complet, 1 Athlon.

Fig. A.17 - Pr'ecision de l''echantillonnage de trace ; jeu complet, 1 Athlon.
L'acc'el'eration. La simulation distribu'ee peut atteindre des acc'el'erations tr`es importantes.
La Figure A.12 montre que DiST atteint une acc'el'eration moyenne de 7,35 avec 10 processeurs,
11,15 avec 20 processeurs et 14,29 avec 40 processeurs, pour une contrainte de pr'ecision locale
`a 98% sur l'IPC, et pour une trace simul'ee de 4 milliards d'instructions.

Avec une trace d'instruction plus grande (16 milliards), DiST profite mieux d'un grand
nombre de machines, et avec 40 processeurs l'acc'el'eration moyenne augmente jusqu'`a 19,5 avec
un maximum de 39,07 pour art, voir la Figure A.14. Par exemple, le temps moyen de simulation
pour une trace de 16 milliards d'instructions est de 20 heures contre seulement 1 heure avec 40

216 Annexe A
machines.

L'acc'el'eration moyenne n'est pas la m^eme pour tous les benchmarks `a cause de la taille
variable de la phase de pr'echauffage. A mesure que le nombre de machines augmente, le surco^ut
du pr'echauffage augmente alors que la taille de la trace reste constante, ainsi l'acc'el'eration
n'augmente pas lin'eairement car il y a proportionnellement plus de subchunks de pr'echauffage
dans chaque chunk (+6% pour 10, +12% pour 20, et +22% pour 40 machines avec une trace de
4 milliards d'instructions).

Avec 10 Pentium III 500 MHz, l'acc'el'eration est de 7,82 avec un temps de simulation moyen
de 15 heures, cf. Figure A.13. Elle passe `a 14,35 en utilisant un groupe de machines h'et'erog`enes
constitu'e de 10 Pentium III 500MHz (256 Mo) et 10 Pentium III 733MHz (128 Mo), o`u la
performance de r'ef'erence est donn'ee par un Pentium 500 MHz (256 Mo).

Acc'el'eration limite. Outre la limitation de la taille de la trace d'instruction, le rapport de
la vitesse de l''emulateur sur la vitesse du simulateur est la limite sup'erieure de l'acc'el'eration.
Consid'erons un cas simple o`u la vitesse d''emulation et de simulation restent constantes pendant
toute la simulation. vs repr'esente la vitesse du simulateur (le nombre d'instructions par secondes),
ve la vitesse de l''emulateur, I le nombre d'instructions par chunk, et N le nombre de chunks
(c'est `a dire le nombre de processeurs). ts " I{vs est le temps n'ecessaire pour simuler un chunk,
et te " I{ve est le temps pour 'emuler un chunk. Alors, Tseq " N " ts est le temps s'equentiel, et
Tdist " pN ' 1q " te ` ts est le temps distribu'e (le temps d''emuler N ' 1 chunks et de simuler le

dernier chunk). L'acc'el'eration est alors 'egale `a TseqT

dist

" N

" ts

pN ' 1q " te ` ts . Remarquez que quand
N N~ 8, l'acc'el'eration tend vers ts{te " ve{vs, c'est `a dire, le rapport de la vitesse de l''emulateur

sur la vitesse du simulateur.

Nous avons remarqu'e que le rapport de vitesse change avec chaque couple simulateur/'emulateur
que ce soit sur Athlon ou sur Pentium III, et ce pour chaque benchmark. Sur Athlon, les rapports moyens de vitesse sont 31 pour SimAlpha, 23 pour SimpleScalar et 185 pour le simulateur
de PowerPC 750 'ecrit en SystemC. Sur Pentium III, ils sont respectivement 48, 36 et 239. Le
rapport de vitesse varie 'egalement selon le benchmark, par exemple, entre 32 et 94 pour SimAlpha sur Pentium III. N'eanmoins, nous n'avons pu atteindre l'acc'el'eration limite d'aucun
de ces simulateurs. En supposant de disposer d'un tr`es grand nombre de machines, la meilleure
fa,con de profiter de la simulation distribu'ee et de DiST est de d'evelopper des 'emulateurs rapides [61, 89]. Il est 'egalement possible de s'affranchir de la phase d''emulation en utilisant du
"checkpoiting", comme celui impl'ement'e dans SimpleScalar [17, 5] (EIO checkpointing). Dans

ce cas, la performance de DiST est seulement limit'ee par le nombre de ressources de calcul
disponibles.

La pr'ecision. M^eme si la simulation distribu'ee peut acc'el'erer significativement la simulation, les chercheurs ne l'utiliseront effectivement que s'ils ont suffisamment confiance dans
la pr'ecision des r'esultats. Pour cela, nous avons appliqu'e la simulation distribu'ee sur tous les
SPEC2000 (voir la section A.5), et nous avons trouv'e que non seulement l'erreur moyenne sur
l'IPC de la simulation distribu'ee est relativement faible avec une valeur de 2,60% mais aussi
qu'elle reste toujours inf'erieure `a 5,17%, en utilisant une contrainte de pr'ecision locale de 98%,
cf. Figure A.15. Outre l'IPC, l'erreur sur d'autres m'etriques importantes comme la pr'ediction
de branchement, le taux de d'efauts des caches L1 et L2 reste inf'erieure `a 10% dans la plupart
des cas.

A.6. Acc'el'eration et Pr'ecision (R'esultats exp'erimentaux) 217

Erreur faible ou nombre d''ev'enements n'egligeable. Nous avons toujours observ'e que
soit l'erreur relative est faible, soit le nombre d''ev'enements est n'egligeable. Consid'erons la Figure A.15 o`u les colonnes repr'esentent la valeur absolue de l'erreur relative (qui peut ^etre positive
ou n'egative), et la ligne la fr'equence des d'efauts du cache L2 ; L'axe vertical de gauche correspond aux colonnes alors que l'axe vertical de droite correspond `a la ligne. La fr'equence de d'efaut
du cache L2 est d'efinie comme le rapport du nombre de d'efauts du cache L2 sur la taille de la
trace. Dans les trois cas o`u l'erreur n'est pas n'egligeable, c'est `a dire, le taux de d'efauts du cache
L2 de eon (266%), crafty et twolf, le nombre d''ev'enements mesur'e pour chaque m'etrique est en
fait n'egligeable (1985 d'efauts de cache pour eon), la variation minime du nombre d''ev'enements
a donc un impact n'egligeable sur la performance, et donc une variation est peu susceptible de
changer les d'ecisions de recherche.

Le pr'echauffage dynamique est n'ecessaire, particuli`erement pour les grandes
structures m'emoires. M^eme si DiST atteint presque le m^eme niveau de pr'ecision sur tous les
benchmarks, c'est `a dire, une erreur moyenne sur l'IPC de 2,60%, le m'ecanisme de pr'echauffage
dynamique est tr`es souvent utile car la taille du pr'echauffage varie significativement entre chaque
benchmark, voir la Figure A.18 o`u nous avons mesur'e la taille moyenne de pr'echauffage (le
nombre de subchunks de pr'echauffage par chunk). Le m'ecanisme de pr'echauffage dynamique est
encore plus utile lorsque nous faisons varier la taille du cache L2. Consid'erons la Figure A.19 :
nous voyons clairement que les grandes structures m'emoires ont un impact important sur la taille
du pr'echauffage, c'est `a dire, qu'augmenter la taille du cache L2 accro^it la taille du pr'echauffage,
l'effet variant consid'erablement d'un programme `a l'autre. Alors que nous avons observ'e que la
quantit'e de pr'echauffage augmente avec la taille du cache L2 sur 8 des 12 benchmarks, pour
2 benchmarks la taille du pr'echauffage est inchang'ee, et pour 2 autres benchmarks, vortex et
sixtrack la taille du pr'echauffage change inopin'ement. N'eanmoins, le m'ecanisme de pr'echauffage
dynamique est n'ecessaire pour obtenir `a la fois la pr'ecision demand'ee et pr'eserver l'acc'el'eration
en 'evitant un surco^ut excessif d^u au pr'echauffage. Naturellement, quand la taille de l'intervalle
de pr'echauffage augmente en m^eme temps que la taille du cache L2, l'acc'el'eration diminue
l'eg`erement, c'est `a dire que DiST privil'egie implicitement la pr'ecision par rapport `a la vitesse.

Confiance dans les d'ecisions de recherche. Pour augmenter encore la confiance en
DiST, nous avons fait plusieurs exp'eriences pour montrer que les d'ecisions de recherche sont
assez peu influenc'ees par la faible perte de pr'ecision. Dans ce but, nous avons s'electionn'e trois
composants du processeur souvent 'etudi'es par les chercheurs (la pr'ediction de branchement,
le cache L2, et le banc de registre), et pour chaque composant, nous avons fait varier un seul
param`etre. Pour chaque composant et valeur de param`etre, nous nous sommes concentr'es sur
la direction de la variation de performance, c'est `a dire, positive ou n'egative, par rapport `a
la configuration par d'efaut du param`etre, et l'amplitude de la variation de performance. Une
d'ecision de recherche n'est pas affect'ee par la simulation distribu'ee si le changement de direction
est le m^eme qu'avec une simulation s'equentielle, et dans une moindre mesure, si l'amplitude de
la variation est 'egalement similaire. Nous avons observ'e que la direction de la variation et son
amplitude sont presque identiques pour la simulation s'equentielle et distribu'ee. Implicitement,
ces exp'eriences montrent qu'une d'ecision de recherche bas'ee sur la simulation distribu'ee, par
exemple, en choisissant la valeur optimal d'un param`etre pour un composant du processeur, est
g'en'eralement la m^eme qu'une d'ecision bas'ee sur la simulation s'equentielle.

Pour nos exp'eriences, nous avons fait varier la taille du cache L2, la taille des tables du
pr'edicteur de branchement de l'EV6, et le nombre de registres physiques dans SimAlpha [31].
Les Figures A.20, A.22, et A.24 montrent la variation de performance pour chaque valeur de
param`etre par rapport `a la valeur par d'efaut du param`etre, en utilisant la simulation s'equentielle
et distribu'ee. Les Figures A.21 et A.23 montrent la variation correspondant aux m'etriques des

218 Annexe A

Fig. A.18 - Taille de pr'echauffage moyenne par chunk ; jeu de r'ef'erence, Athlon.
Fig. A.19 - Influence des grandes structures m'emoires sur l'acc'el'eration et la pr'ecision ; jeu de
r'ef'erence, 10 PIII 500.

composants du processeur lorsque cela est possible : respectivement le taux de d'efauts du cache
L2 et le taux de bonnes pr'edictions des branchements.

La direction de la variation est presque toujours identique, et l'amplitude de la variation
est souvent tr`es proche, sauf lorsque la valeur absolue du nombre d''ev'enements est n'egligeable
comme le taux de d'efauts du cache L2 dans eon. La comparaison devient moins pr'ecise seulement
lorsque la diff'erence de performance est du m^eme ordre de grandeur que l'erreur (quelques
pourcents). Consid'erons les exp'eriences sur la pr'ediction de branchement de la Figure A.22 et
les benchmarks vpr, gcc, crafty et parser : l'amplitude de variation de l'IPC est tr`es faible et
la direction de la variation diff`ere. Cependant, la direction et l'amplitude de la variation de la
m'etrique 'etudi'ee (le taux de bonnes pr'edictions des branchements) sont la plupart du temps les
m^emes qu'avec la simulation s'equentielle, et ce sur tous les benchmarks, voir la Figure A.23, une
d'ecision de recherche bas'ee sur cette m'etrique serait donc correcte. De fa,con g'en'erale, l'amplitude
de la variation est un indicateur important de la fiabilit'e des r'esultats produits par la simulation
distribu'ee : lorsqu'elle devient de l'ordre du pourcent, c'est `a dire, sous l'erreur typique d'une

A.6. Acc'el'eration et Pr'ecision (R'esultats exp'erimentaux) 219
Fig. A.20 - Variation de l'IPC en variant la tailledu cache L2 ; jeu de r'ef'erence, 10 PIII 500. Fig. A.21 - Variation du taux de d'efauts du cacheL2 en variant la taille du cache L2 ; jeu de r'ef'erence,

10 PIII 500.

Fig. A.22 - Variation de l'IPC en variant la taillede la table de pr'ediction de branchement ; jeu de r'ef'erence, 10 PIII 500.

Fig. A.23 - Variation du taux de pr'ediction desbranchements en variant la taille de la table de pr'ediction de branchement ; jeu de r'ef'erence, 10 PIII500.

Fig. A.24 - Variation de l'IPC en variant le nombrede registres physiques ; jeu de r'ef'erence, 10 PIII 500.

220 Annexe A
simulation distribu'ee, le chercheur sait qu'il ne peut avoir confiance en ces r'esultats.

Comparaison de DiST avec la r'eduction de trace et l''echantillonnage de trace.
La r'eduction de trace. Comme nous l'avons dit pr'ec'edemment, la r'eduction de la taille de la trace
est une m'ethode simple pour acc'el'erer la simulation. Pour comparer la pr'ecision de la technique
de r'eduction de trace avec DiST, nous avons diminu'e la taille de la trace de fa,con `a obtenir le
m^eme temps de simulation que celui de DiST, c'est `a dire, une trace de 100 millions d'instructions
pour tous les benchmarks. Nous avons alors mesur'e l'erreur moyenne pour chaque chunk de
100 millions d'instructions d'une simulation distribu'ee avec DiST de 4 milliards d'instructions ;
Comme l'erreur peut ^etre positive ou n'egative suivant le chunk, nous avons mesur'e la moyenne
de la valeur absolue de l'erreur relative sur tous les chunks de 100 millions d'instructions, voir
la Figure A.16. Nous pouvons voir que la variation de l'erreur est de loin sup'erieure `a celle de
DiST, entre 3,28% (twolf) et 120,48% (gcc) pour l'IPC, et entre 5,74% (art) et 1766% (fma3d)
pour le taux de d'efauts du cache L2 ; remarquons que dans beaucoup de cas, quand l'erreur est
grande le nombre d''ev'enements n'est pas n'egligeable (ici, le nombre de d'efaut du cache L2).
Par cons'equent, il peut ^etre tr`es difficile d'avoir confiance dans des r'esultats et des d'ecisions de
recherche bas'es sur de telles tailles de trace (notez bien qu'une trace de 100 millions n'est pas
inhabituelle dans les articles de recherche).

Des travaux r'ecents [92] proposent une nouvelles approche pour r'eduire la taille de la trace
en choisissant soigneusement son point de d'epart. Cette technique est efficace et pr'ecise (3%
d'erreur sur l'IPC avec plusieurs traces de 100 millions d'instructions par rapport `a une ex'ecution
compl`ete) sauf pour les grands composants comme le cache L2 (plus de 20% sur le taux de d'efauts
du cache L2) car elle est bas'ee sur de petites traces de taille fixe. Am'eliorer cette technique en
utilisant le m'ecanisme de pr'echauffage dynamique de DiST pour d'eterminer automatiquement
la taille de trace appropri'ee permettrait d'allier efficacit'e et pr'ecision sur une grande vari'et'e de
composants.

L''echantillonnage de trace. L''echantillonnage de trace est une autre technique plus sophistiqu'ee pour r'eduire la taille de la trace [69]. Au lieu de choisir une trace de T r'ef'erences cons'ecutives, la trace est d'ecoup'ee en un certain nombre d'intervalles distribu'es al'eatoirement dans une
trace plus grande. Comme les instructions simul'ees qui en r'esultent se r'epartissent sur une large
portion du programme, la trace est habituellement plus repr'esentative. D'un autre cot'e, le programme doit ^etre 'emul'e entre chaque intervalle simul'e ce qui ralentit la simulation par rapport
`a la simulation d'une trace r'eduite d'instructions contigu"es. Nous avons appliqu'e l''echantillonnage de trace en d'ecoupant la trace en 40 intervalles, r'eduisant ainsi la taille de l'intervalle de
fa,con `a obtenir une acc'el'eration identique `a celle de DiST. La distance entre deux intervalles est
choisie al'eatoirement. M^eme si la technique d''echantillonnage de trace donne g'en'eralement une
meilleure pr'ecision que simplement r'eduire la taille de la trace, la Figure A.17 montre qu'elle est
bien moins pr'ecise que DiST.

Finalement, remarquez que, si l'acc'el'eration de la simulation est vraiment vitale, il est possible de combiner la technique de r'eduction de trace avec DiST.

A.6. Acc'el'eration et Pr'ecision (R'esultats exp'erimentaux) 221
Fig. A.25 - 'Echantillonnage de trace : variationdu taux de pr'ediction de branchement en variant la
taille de la table du pr'edicteur de branchement ; 1PIII 500.

Fig. A.26 - R'eduction de la taille de trace : tauxde pr'ediction de branchement en variant la taille de

la table du pr'edicteur de branchement ; 1 PIII 500.

Fig. A.27 - 'Evolution de l'erreur globale sur l'IPC ; jeu complet, 10 PIII 500.
Fig. A.28 - 'Evolution de l'erreur globale sur le taux de d'efauts du cache L1 ; jeu complet, 10
PIII 500.

222 Annexe A

Confiance dans les d'ecisions de recherche. Par exemple, lorsque nous faisons varier la taille de
la table de pr'ediction des branchements, les techniques de r'eduction de trace et d''echantillonnage
de trace obtiennent des r'esultats moins bons que DiST. Ces techniques ne d'etectent presque
aucune variation d'amplitude, ce que vous pouvez observer en comparant la Figure A.23 avec
les Figures A.26 et A.25.

Un m'ecanisme simple pour des validations occasionnelles pendant le processus
de recherche. Toutes les exp'eriences ont montr'e que l'on peut avoir confiance dans les r'esultats
donn'es par DiST, et que DiST est une technique d'acc'el'eration plus fiable que les techniques de
r'eduction de trace. N'eanmoins, lorsque le chercheur utilise DiST pour une s'equence particuli`erement longue d''etapes d'analyse sans validation compl`ete avec la simulation traditionnelle et/ou
beaucoup de benchmarks, il existe toujours un faible risque que plusieurs jours d'analyse soient
bas'es sur des mauvais choix d'eriv'es de r'esultats de simulation erron'es, comme pour l'utilisation de petites traces. Pour une question d'efficacit'e, DiST utilise un m'ecanisme de rattrapage
simple : le premier chunk s'ex'ecute jusqu'`a terminaison, c'est `a dire, jusqu'`a la fin de la trace
compl`ete. Le chercheur commence `a effectuer ses d'ecisions/analyses de recherche d`es que DiST
a termin'e, et quand la trace compl`ete est termin'ee, elle/il peut v'erifier la v'eritable erreur de
DiST. Cette validation est optionnelle, l'utilisateur peut d'ecider de tuer le thread de validation
s'il ne s'est pas d'ej`a termin'e, afin d'avoir toutes les machines disponibles pour atteindre une
acc'el'eration maximale.

Pr'ecision contre acc'el'eration : l'erreur augmente avec le nombre de machines,
mais lentement. Comme la pr'ecision n'est assur'ee que localement, l'erreur peut augmenter
avec le nombre de machines. Consid'erons le chunk m. Puisque le seuil de convergence est n'ecessairement plus petit que 100% (sinon la convergence ne se produirait quasiment jamais), la
pr'ecision se d'egrade avec chaque nouveau chunk, ce qui signifie que la convergence est obtenue
sans une parfaite correspondance des statistiques des chunks m ' 1 et m. Au fur et mesure du
temps, ces erreurs se cumulent, et plus m augmente, plus la perte de pr'ecision s'accro^it. Par
cons'equent, alors que l'erreur "locale" reste fixe, born'ee par les contraintes de pr'ecision locales,
l'erreur "globale" peut diverger. En pratique, m^eme si nous avons observ'e que, pour certains
codes, l'erreur "globale" augmente avec le nombre de chunks, voir la Figure A.27, la progression
est g'en'eralement tr`es lente. De plus, pour toutes les autres m'etriques telle que le taux de d'efauts
du cache L1, l'erreur "globale" reste presque constante, voir la Figure A.28.

La pr'ecision peut ^etre bas'ee sur d'autres m'etriques que l'IPC. Remarquez que les
besoins de pr'ecision peuvent porter sur d'autres m'etriques que l'IPC : si le but des simulations est
l'analyse d'un composant sp'ecifique du processeur, la contrainte de pr'ecision locale peut porter
sur les statistiques qui sont int'eressantes pour cette analyse. Nous pouvons soit remplacer la
contrainte sur l'IPC par une contrainte sur une autre statistique, ou bien ajouter une nouvelle
contrainte sur une autre statistique. Par exemple, supposons que nous nous int'eressons au taux
de d'efauts du cache L2. Nos exp'eriences ont 'et'e men'ees avec une contrainte sur l'IPC (erreur
inf'erieure `a 10% au lieu de 2%) et nous avons trouv'e que l'erreur moyenne sur le taux de d'efauts
du cache L2 est 'egale `a 3,24% ; nous avons alors ajout'e une contrainte de pr'ecision locale sur le
taux de d'efauts du cache L2 (erreur inf'erieure `a 2%), et relanc'e les exp'eriences : l'erreur globale
moyenne sur le taux de d'efauts du cache L2 a diminu'e pour atteindre 2,17%, et m^eme l'erreur
moyenne sur l'IPC est rest'ee proche de ce que nous avions atteint avec une contrainte stricte de
2% sur l'IPC. La plupart du temps, lorsque les contraintes locales sont trop nombreuses ou trop
exigeantes, celles-ci ont un effet redondant ou diminuent l'acc'el'eration. Par exemple, en ajoutant
une contrainte de pr'ecision locale de 2% sur le taux de d'efauts de cache L2 `a une contrainte de
10% sur l'IPC, l'erreur sur le cache L2 s'am'eliore mais le nombre total moyen de subchunks de
pr'echauffage augmente en passant de 13 `a 48.

A.7. La simulation rapide autorise de nouvelles applications 223

\Gamma \Gamma \Gamma \Gamma \Delta \Delta \Delta \Delta 

\Gamma \Gamma \Delta \Delta 

chunk

subchunk

SimulationEmulation

Simulation comple`te de'but fin

TraceOriginale

Pre'chauffage
Trace Modifie'ede'but fin

simulation incrementale

Overheadintervalle modifie'

Fig. A.29 - Analyse it'eratives et optimisations locales de programme utilisant le pr'echauffage
de DiST.

A.7 La simulation rapide autorise de nouvelles applications

Les compilateurs ont de plus en plus de mal `a suivre l'augmentation rapide en complexit'e
de l'architecture, ce qui se traduit par un 'ecart grandissant entre la performance cr^ete et la performance soutenue. Actuellement les optimisations de programme d'ependent soit des outils de
profilage en temps ou des compteurs mat'eriels comme DCPI [2] et ProfileMe [30]. Cependant,
simuler l'ex'ecution d'un programme sur l'architecture du processeur cible fournit une quantit'e d'information qui peut aider consid'erablement `a comprendre pourquoi une d'egradation de
performance se produit, comment les diff'erents composants du processeur interagissent et comment le comportement du programme peut ^etre am'elior'e. Les simulateurs de processeurs sont
rarement utilis'es pour l'optimisation de programme car ils sont extr^emement lents. Suivant le
nombre de machines de simulation disponibles et le rapport de vitesse 'emulateur/simulateur,
DiST permet de passer d'une d'egradation des performances de simulation de plusieurs centaines
`a quelques centaines ou moins. Quelques modifications suppl'ementaires peuvent rendre DiST
encore plus appropri'e pour le processus d'essai/erreur de l'optimisation de programme. Nous
d'ecrivons bri`evement une de ces modification dans cette sous-section.

Le plus souvent, l'optimisation de programme se concentrera sur une portion de code donn'ee o`u les optimisations sont r'ep'etitivement appliqu'ees et test'ees. Habituellement, apr`es une
simulation initiale, le programmeur applique des transformations (locales) sur le code et doit ensuite ex'ecuter de nouveau une simulation compl`ete pour contr^oler l'impact des transformations.
Quelques modifications de DiST permettent la (re)simulation s'electives d'un petit sur-ensemble
de l'intervalle de trace modifi'e, voir la Figure A.29 ; au moment d'entrer dans cet intervalle,
l''etat du processeur est alors presque le m^eme qu'avec la simulation originale sans r'eellement
simuler les instructions qui pr'ec`edent. Nous allons maintenant d'ecrire la technique avec plus de
d'etails.

L'intervalle modifi'e doit ^etre d'eduit d'apr`es l'emplacement exacte des instructions aux bords
de la trace originale et modifi'ee. Ces instructions sont simplement estampill'ees par l'insertion de
directives dans le code assembleur. Une alternative compl`etement automatique consiste `a se reposer sur des outils de correspondance binaire (binary matching) pour automatiquement localiser
les portions de code modifi'ees. Par exemple, BMAT [100] est utilis'e pour suivre les modifications
locales sur un code objet pendant le processus de d'ebogage d'une grande application.

Nous avons ensuite `a trouver le chunk dont la p'eriode de pr'echauffage pr'ec`ede imm'ediatement (et ne chevauche pas) l'intervalle modifi'e. Pendant la simulation originale, nous stockons
la taille de cette p'eriode de pr'echauffage. Pour re-simuler l'intervalle, nous pouvons simple224 Annexe A
ment 'emuler jusqu'au d'ebut de ce chunk, et alors commencer la simulation avec DiST. Afin
de d'eterminer quand la statistique devient valide, la taille de pr'echauffage d'etermin'ee dynamiquement est remplac'ee par la taille enregistr'ee. Quand la simulation commence, l''etat du
processeur est exactement le m^eme qu'avec DiST, sans simuler les chunks pr'ec'edents. La partie
basse de la Figure A.29 repr'esente une simulation incr'ementale lanc'ee apr`es une transformation
du programme. Remarquez qu'il est m^eme possible d'analyser l'impact de la transformation
de programme sur le reste du programme en se basant sur la simulation, en supposant que la
transformation de programme n'affecte pas le programme au-del`a du point de fin. Cette approche incr'ementale l'eg`ere est un pas vers l'utilisation de simulateurs pr'ecis en environnements
et m'ethodologies d'optimisation.

A.8 Conclusions

La vitesse de simulation n''etant pas qu'un probl`eme de m'ethodologie mais peut avoir un fort
impact sur l'exploration de l'espace de conception, nous avons pr'esent'e DiST, une technique de
simulation distribu'ee qui peut acc'el'erer la simulation d'un processeur tout en pr'eservant une
grande pr'ecision. La pr'ecision est toujours privil'egi'ee par rapport `a l'acc'el'eration gr^ace `a un
m'ecanisme de pr'echauffage dynamique qui ajuste automatiquement la taille du pr'echauffage
de chaque chunk distribu'e afin de satisfaire des contraintes de pr'ecision locales d'efinies par
l'utilisateur. DiST est bien plus pr'ecis que la technique traditionnelle de r'eduction de trace
utilis'ee par beaucoup de chercheurs pour acc'el'erer certaines parties de leurs recherches ; et il est
significativement plus pr'ecis que d'autres techniques plus sophistiqu'ees comme l''echantillonnage
de trace. De plus, nous avons montr'e exp'erimentalement que cette technique est fiable et que les
d'ecisions de recherche bas'ees sur la simulation distribu'ee ne sont g'en'eralement pas affect'ees par
la l'eg`ere perte de pr'ecision ; en outre, DiST offre un m'ecanisme de backup pour une validation `a
posteriori. L'acc'el'eration peut augmenter avec le nombre de ressources de calcul disponibles et
est actuellement limit'ee par la taille de la trace et le rapport de vitesse 'emulateur/simulateur.
Finalement, l'outil est con,cu pour ^etre int'egr'e dans les simulateurs existant avec tr`es peu de
modifications. Nous diffusons une version de SimAlpha et SimpleScalar disponible avec DiST
sur http ://www.microlib.org/DiST.

DiST acc'el`ere la simulation et l'acc'el'eration est born'ee par le rapport de vitesse 'emulateur/simulateur. En utilisant du "check-pointing", cette borne dispara^it et le comportement des
threads n'est pas perturb'e par les variations de comportement des appels syst`emes. L'utilisation
de DiST avec du "checkpointing", par exemple, permettrait donc potentiellement d'am'eliorer `a
la fois l'acc'el'eration et la pr'ecision.

La simulation rapide autorise de nouvelles applications comme l'analyse du comportement
des programmes sur des architectures complexes de processeurs. En partant du principe de pr'echauffage de DiST, nous pouvons rapidement et de fa,con r'ep'et'ee analyser/modifier une section
de code donn'ee sans relancer une simulation compl`ete. Dans le futur, nous avons l'intention de
nous int'eresser `a des am'eliorations plus avanc'ees de ces applications, en particulier en acc'el'erant
ou m^eme en supprimant la phase d''emulation qui pr'ec`ede la section de code cibl'ee en utilisant
du "checkpointing".

225
Bibliographie

[1] C. Ancourt and F. Irigoin. Scanning polyhedra with DO loops. In Proceedings of the 3rd

ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming, volume 26,
pages 39-50, Williamsburg, VA, April 1991.

[2] J. Anderson, L. Berc, J. Dean, S. Ghemawat, M. Henzinger, S. Leung, D. Sites, M. Vandevoorde, C. Waldspurger, and W. Weihl. Continuous profiling : Where have all the cycles
gone, July 1997.

[3] Matthew Arnold, Stephen J. Fink, David Grove, Michael Hind, and Peter F. Sweeney.

Adaptive optimization in the jalapeno JVM. In Conference on Object-Oriented, pages
47-65, 2000.

[4] Joel Auslander, Matthai Philipose, Craig Chambers, Susan J. Eggers, and Brian N. Bershad. Fast, effective dynamic compilation. In SIGPLAN Conference on Programming
Language Design and Implementation, pages 149-159, 1996.

[5] Todd Austin, Eric Larson, and Dan Ernst. SimpleScalar : An Infrastructure for Computer

System Modeling. IEEE Computer, 35(2), February 2002.

[6] Eduard Ayguad'e and Jordi Torres. Partitioning the statement per iteration space using

non-singular matrices. In ICS '93 : Proceedings of the 7th international conference on
Supercomputing, pages 407-415, New York, NY, USA, 1993. ACM Press.

[7] Utpal Banerjee. A theory of loop permutations. In Selected papers of the second workshop

on Languages and compilers for parallel computing, pages 54-74, London, UK, UK, 1990.
Pitman Publishing.

[8] Utpal Banerjee. Unimodular transformation of double loops. In Advances in Languages

and Compilers for Parallel Computing, pages 192-219, London, UK, UK, 1991. Pitman
Publishing.

[9] Denis Barthou, Albert Cohen, and Jean-Fran,cois Collard. Maximal static expansion. In

POPL '98 : Proceedings of the 25th ACM SIGPLAN-SIGACT symposium on Principles
of programming languages, pages 98-106, New York, NY, USA, 1998. ACM Press.

[10] C. Bastoul. Efficient code generation for automatic parallelization and optimization. In

ISPDC'2 IEEE International Symposium on Parallel and Distributed Computing, Ljubjana, Slovenia, October 2003.

[11] C. Bastoul and P. Feautrier. Improving data locality by chunking. In CC'12 Intl. Conference on Compiler Construction, LNCS 2622, pages 320-335, Warsaw, Poland, april 2003.

[12] C. Bastoul and P. Feautrier. More legal transformations for locality. In Euro-Par'10,

number 3149 in LNCS, pages 272-283, Pisa, august 2004.

[13] W. Blume, R. Eigenmann, K. Faigin, J. Grout, J. Hoeflinger, D. Padua, P. Petersen,

W. Pottenger, L. Rauchwerger, P. Tu, and S. Weatherford. Parallel programming with
Polaris. IEEE Computer, 29(12) :78-82, December 1996.

226 BIBLIOGRAPHIE

[14] F. Bodin, T. Kisuk, P. M. W. Knijnenburg, M. F. P. O'Boyle, and E. Rohou. Iterative compilation in a non-linear optimisation space. In PACT'98 : Proceedings of the International
Conference on Parallel Architectures and Compilation Techniques, October 1998.

[15] P. Bose and T. M. Conte. Performance analysis and its impact on design. IEEE Computer,

pages 41-49, May 1998.

[16] P. Boulet, A. Darte, G.-A. Silber, and F. Vivien. Loop parallelization algorithms : From

parallelism extraction to code generation. Parallel Computing, 24(3) :421-444, 1998.

[17] D. Burger and T. Austin. The Simplescalar Tool Set, Version 2.0. Technical Report

CS-TR-97-1342, Department of Computer Sciences, University of Wisconsin, June 1997.

[18] M. Byler, J.R.B. Davies, C. Huson, B. Leasure, and M. Wolfe. Multiple version loops. In

International conf. on Parallel Processing, August 1987.

[19] Siddhartha Chatterjee and Sandeep Sen. Cache-efficient matrix transposition. In Sixth

International Symposium on High-Performance Computer Architecture, pages 195-205,
Toulouse, France, 2000.

[20] Wei-Yu Chen. Building a source-to-source upc-to-c translator. Master's thesis, University

of California Berkeley, 2004.

[21] F. Chow. Maximizing application performance through inter-procedural optimization with

the pathscale eko compiler suite. http ://www.pathscale.com/whitepapers.html, August
2004.

[22] C. Coarfa, F. Zhao, N. Tallent, J. Mellor-Crummey, and Y. Dotsenko. Open-source compiler technology for source-to-source optimization.
http ://www.cs.rice.edu/ johnmc/research.html.

[23] A. Cohen. Program Analysis and Transformation : from the Polytope Model to Formal

Languages. PhD thesis, University of Versailles, France, December 1999.

[24] J.-F. Collard, D. Barthou, and P. Feautrier. Fuzzy array dataflow analysis. In ppopp, pages

92-102, July 1995.

[25] Charles Consel and Fran&#231 ;ois No&#235 ;l. A general approach for run-time specialization and its application to c. In POPL '96 : Proceedings of the 23rd ACM SIGPLANSIGACT symposium on Principles of programming languages, pages 145-156, New York,
NY, USA, 1996. ACM Press.

[26] T. Conte, M. Hirsch, and K. Menezes. Reducing state loss for effective trace sampling of

superscalar processors. In International Conference on Computer Design, pages 468-477,
1996.

[27] K. D. Cooper, M. W. Hall, R. T. Hood, K. Kennedy, K. S. McKinley, J. M. MellorCrummey, L. Torczon, and S. K. Warren. The ParaScope parallel programming environment. Proceedings of the IEEE, 81(2) :244-263, 1993.

[28] K. D. Cooper, D. Subramanian, and L. Torczon. Adaptive optimizing compilers for the

21st century. J. of Supercomputing, 2002.

[29] Alain Darte, Rob Schreiber, and Gilles Villard. Lattice-based memory allocation. In

CASES '03 : Proceedings of the 2003 international conference on Compilers, architecture
and synthesis for embedded systems, pages 298-308, New York, NY, USA, 2003. ACM
Press.

[30] Jeffrey Dean, James E. Hicks, Carl A. Waldspurger, William E. Weihl, and George Z. Chrysos. ProfileMe : Hardware support for instruction-level profiling on out-of-order processors.

BIBLIOGRAPHIE 227

In International Symposium on Microarchitecture, pages 292-302, Research Triangle Park,
North Carolina, 1997.

[31] R. Desikan, D. Burger, and S. W. Keckler. Measuring Experimental Error in Microprocessor Simulation. In The 28th Annual Intl. Symposium on Computer Architecture,
Anchorage, Alaska, June 2001.

[32] Pedro C. Diniz and Martin C. Rinard. Dynamic feedback : an effective technique for

adaptive computing. In PLDI '97 : Proceedings of the ACM SIGPLAN 1997 conference
on Programming language design and implementation, pages 71-84, New York, NY, USA,
1997. ACM Press.

[33] Michael L. Dowling. Optimal code parallelization using unimodular transformations. Parallel Computing, 16 :157-171, 1990.

[34] L. Eeckhout, K. De Bosschere, and H. Neefs. Performance analysis through synthetic

trace generation. In Int. Symp. on Performance Analysis of Systems and Software, Liege,
Belgium, April 2000.

[35] R. Eigenmann, J. Hoeflinger, and D. Padua. On the automatic parallelization of the perfect

benchmarks. ieeetpds, 9(1) :5-23, January 1998.

[36] Dawson R. Engler. Vcode : a retargetable, extensible, very fast dynamic code generation

system. In PLDI '96 : Proceedings of the ACM SIGPLAN 1996 conference on Programming
language design and implementation, pages 160-170, New York, NY, USA, 1996. ACM
Press.

[37] P. Feautrier. Array expansion. In ACM Int. Conf. on Supercomputing, pages 429-441, St.

Malo, France, July 1988.

[38] P. Feautrier. Parametric integer programming. RAIRO Recherche Op'erationnelle, 22 :243-

268, September 1988.

[39] P. Feautrier. Dataflow analysis of scalar and array references. International Journal of

Parallel Programming, 20(1) :23-53, February 1991.

[40] P. Feautrier. Some efficient solutions to the affine scheduling problem. part I. onedimensional time. International Journal of Parallel Programming, 21(5) :313-348, October
1992.

[41] P. Feautrier. Some efficient solutions to the affine scheduling problem, part II, multidimensional time. International Journal of Parallel Programming, 21(6) :389-420, December
1992. See also Part I, one dimensional time, 21(5) :315-348.

[42] G. Fursin, M. O'Boyle, and P. Knijnenburg. Evaluating iterative compilation. In Proc.

Languages and Compilers for Parallel Computers (LCPC), LNCS, pages 305-315, Washington DC, July 2002. Springer-Verlag.

[43] S. Girbal, G. Mouchard, A. Cohen, and O. Temam. Dist : A simple, reliable and scalable method to significantly reduce processor architecture simulation time. In SIGMETRICS'03, June 2003.

[44] Martin Griebl and Christian Lengauer. The loop parallelizer loopo-announcement. In

Languages and Compilers for Parallel Computing, pages 603-604, 1996.

[45] Martin Griebl, Christian Lengauer, and S. Wetzel. Code generation in the polytope model.

In IEEE PACT, pages 106-111, 1998.

[46] A.C. Guillou, P. Quinton, T. Risset, C. Wagner, and D. Massicotte. High Level Design

of Digital Filters in Mobile Communications. DATE Design Contest 2001, March 2001.
Second place, available at http ://www.irisa.fr/bibli/publi/pi/2001/1405/1405.html.

228 BIBLIOGRAPHIE

[47] R. Gupta and R. Bodik. Adaptive loop transformations for scientific programs. In SPDP

'95 : Proceedings of the 7th IEEE Symposium on Parallel and Distributeed Processing, page
368, Washington, DC, USA, 1995. IEEE Computer Society.

[48] M. Hall et al. Maximizing multiprocessor performance with the SUIF compiler. IEEE

Computer, 29(12) :84-89, December 1996.

[49] J.W. Haskins and K. Skadron. Minimal subset evaluation : Rapid warm-up for simulated hardware state. In Proc. of the 2001 International Conference on Computer Design,
Austin, Texas, September 2001.

[50] V. S. Iyengar and L. H Trevillyan. Evaluation and generation of reduced traces for benchmarks. Technical Report RC20610, IBM T. J. Watson, Oct 1996.

[51] KAP C/OpenMP for Tru64 UNIX and KAP DEC Fortran for Digital UNIX.

http ://www.hp.com/techsevers/software/kap.html.

[52] W. Kelly, W. Pugh, and E. Rosser. Code generation for multiple mappings. In Frontiers

'95 : The 5th Symposium on the Frontiers of Massively Parallel Computation, McLean,
VA, 1995.

[53] Wayne Kelly. Optimization within a unified transformation framework. Technical Report

CS-TR-3725, University of Maryland, 1996.

[54] Wayne Kelly, Vadim Maslov, William Pugh, Evan Rosser, Tatiana Shpeisman, and David

Wonnacott. The omega library interface guide. Technical report, College Park, MD, USA,
1995.

[55] Wayne Kelly and William Pugh. A framework for unifying reordering transformations.

Technical report, University of Maryland at College Park, College Park, MD, USA, 1993.

[56] T. Kisuki, P. Knijnenburg, K. Gallivan, and M. O'Boyle. The effect of cache models

on iterative compilation for combined tiling and unrolling. In Parallel Architectures and
Compilation Techniques (PACT'00). IEEE Computer Society Press, October 2001.

[57] Toru Kisuki, Peter M. W. Knijnenburg, Michael F. P. O'Boyle, Fran,csois Bodin, and Harry

A. G. Wijshoff. A feasibility study in iterative compilation. In ISHPC '99 : Proceedings
of the Second International Symposium on High Performance Computing, pages 121-132,
London, UK, 1999. Springer-Verlag.

[58] A. KleinOsowski, J. Flynn, N. Meares, and D. Lilja. Adapting the SPEC 2000 benchmark suite for simulation-based computer architecture research. In Proceedings of the
Third IEEE Annual Workshop on Workload Characterization, International Conference
on Computer Design (ICCD),, pages 73-82, September 2000.

[59] Induprakas Kodukula and Keshav Pingali. Transformations for imperfectly nested loops.

In Supercomputing '96 : Proceedings of the 1996 ACM/IEEE conference on Supercomputing
(CDROM), page 12, 1996.

[60] D. Kuck. The Structure of Computers and Computations. John Wiley & Sons, Inc., 1978.
[61] T. Lafage, A. Seznec, E. Rohou, and F. Bodin. Code cloning tracing : A "pay per trace"

approach. In EuroPar'99 Parallel Processing, Toulouse, France, August 1999.

[62] V. Lefebvre. Automatic Data Expansion for Parallel Programs. PhD thesis, University of

Versailles, France, 1998.

[63] V. Lefebvre and P. Feautrier. Automatic storage management for parallel programs. Parallel Computing, 24(3) :649-671, 1998.

BIBLIOGRAPHIE 229

[64] W. Li and K. Pingali. A singular loop transformation framework based on non-singular

matrices. Intl. J. of Parallel Programming, 22(2) :183-205, April 1994.

[65] Amy Lim and Monica S. Lam. Communication-free parallelization via affine transformations. In LCPC '94 : Proceedings of the 7th International Workshop on Languages and
Compilers for Parallel Computing, pages 92-106, London, UK, 1995. Springer-Verlag.

[66] Amy W. Lim and Monica S. Lam. Maximizing parallelism and minimizing synchronization

with affine transforms. In POPL '97 : Proceedings of the 24th ACM SIGPLAN-SIGACT
symposium on Principles of programming languages, pages 201-214, New York, NY, USA,
1997. ACM Press.

[67] M. J. Litzkow, M. Livny, and M. W. Mutka. Condor - a hunter of idle workstations. In

Proc. of the 8th Intl. Conf. on Distributed Computing Systems, pages 104-111, San Jose,
Calif, June 1988.

[68] Shun Long and Grigori Fursin. A heuristic search algorithm based on unified transformation framework. International Workshop on High Performance Scientific and Engineering
Computing (HPSEC-05), June 2005.

[69] Margaret Martonosi, Anoop Gupta, and Thomas Anderson. Effectiveness of trace sampling

for performance debugging tools. In Proceedings of the 1993 ACM SIGMETRICS conference on Measurement and modeling of computer systems, pages 248-259. ACM Press,
1993.

[70] C. Mauras. Alpha, un langage 'equationnel pour la conception et la programmation d'architectures parall`eles synchrones. PhD thesis, Universit'e de Rennes I, France, December
1989.

[71] D. E. Maydan, S. P. Amarasinghe, and M. S. Lam. Array dataflow analysis and its use in

array privatization. In 20thACM Symp. on Principles of Programming Languages, pages
2-15, Charleston, South Carolina, January 1993.

[72] G. Mouchard. PowerPC G3 simulator. http ://www.microlib.org, 2002.
[73] Gilles Mouchard and Daniel Gracia P'erez. OoOSysC.

http ://www.microlib.org/OoOSysC/, 2004.

[74] A. Nguyen, M. Michael, A. Nanda, K. Ekanadham, and P. Bose. Accuracy and speed-up

of parallel trace-driven architectural simulation. In Proc. Int'l Parallel Processing Symp.,
IEEE Computer Soc. Press,, pages 39-44, Geneva, Switzerland, April 1997.

[75] D. B. Noonburg and J. P. Shen. A framework for statistical modeling of superscalar

processor performance. In Proc. Thrird In. Symp. On High Perf. Computer Architecture,
San Antonio, Texas, February 1997.

[76] Sebastien Nussbaum and James Smith. Modeling superscalar processors via statistical

simulation. In PACT '01, International Conference on Parallel Architectures and Compilation Techniques, Barcelona, September 2001.

[77] M. O'Boyle. MARS : a distributed memory approach to shared memory compilation.

In Proc. Language, Compilers and Runtime Systems for Scalable Computing, Pittsburgh,
May 1998. Springer-Verlag.

[78] M. O'Boyle, P. Knijnenburg, and G. Fursin. Feedback assisted iterative compilation. In

Proc. LCR, May 2000.

[79] Open64 compiler tools. http ://open64.sourcefourge.net.
[80] Open research compiler. http ://ipf-orc.sourceforge.net.

230 BIBLIOGRAPHIE

[81] OSCI. SystemC. http ://www.systemc.org, 2000-2002.
[82] D. Parello. M'etholodologie d'optimisation de programmes pour architectures de processeurs

complexes. PhD thesis, University of Paris XI, France, September 2004.

[83] David Parello, Olivier Temam, Albert Cohen, and Jean-Marie Verdun. Toward a systematic, pragmatic and architecture-aware program optimization process for complex processors. In Supercomputing 2004, Pittsburgh PA USA, November 2004.

[84] David Parello, Olivier Temam, and Jean-Marie Verdun. On increasing architecture awareness in program optimizations to bridge the gap between peak and sustained processor
performance - matrix-multiply revisited. In Supercomputing 2002, Baltimore, November
2002.

[85] A. Phansalkar, A. Joshi, L. Eeckhout, and L. John. Four generations of SPEC CPU

benchmarks : what has changed and what has not. Technical Report TR-041026-01-1,
University of Texas Austin, 2004.

[86] W. Pugh. A practical algorithm for exact array dependence analysis. Communications of

the ACM, 35(8) :27-47, August 1992.

[87] F. Quiller'e and S. Rajopadhye. Optimizing memory usage in the polyhedral model. ACM

Trans. on Programming Languages and Systems, 22(5) :773-815, September 2000.

[88] F. Quiller'e, S. Rajopadhye, and D. Wilde. Generation of efficient nested loops from polyhedra. Intl. J. of Parallel Programming, 28(5) :469-498, october 2000.

[89] V. Rajesh and R. Moona. Processor modeling for hardware software codesign. In International Conference on VLSI Design, Goa, India, January 1999.

[90] R. Schreiber, S. Aditya, B. Rau, V. Kathail, S. Mahlke, S. Abraham, and G. Snider. Highlevel synthesis of nonprogrammable hardware accelerators. Technical report, HewlettPackard, May 2000.

[91] A. Schrijver. Theory of Linear and Integer Programming. wiley, Chichester, UK, 1986.
[92] T. Sherwood, E. Perelman, G. Hamerly, and B. Calder. Automatically Characterizing

Large Scale Program Behavior. In Proc. of Tenth International Conference on Architectural
Support for Programming Languages and Operating Systems, San Jose, Calif, October 2002.

[93] Tim Sherwood, Erez Perelman, and Brad Calder. Basic block distribution analysis to find

periodic behavior and simulation points in applications. In International Conference on
Parallel Architecture and Compilation Techniques, Barcelona, Spain, September 2001.

[94] Kevin Skadron, Margaret Martonosi, and Douglas W. Clark. Selecting a Single, Representative Sample for Accurate Simulation of SPECint Benchmarks. Technical Report
TR-595-99, University of Princeton, January 1999.

[95] Standard performance evaluation corporation. http ://www.spec.org.
[96] Xavier Vera, Malardalens Hogskola, and Jingling Xue. Let's study whole-program cache

behaviour analytically. In Proceedings of the Eighth International Symposium on HighPerformance Computer Architecture (HPCA'02), Boston, Massachusettes, February 2002.

[97] E. Visser. Stratego : A language for program transformation based on rewriting strategies.

System description of Stratego 0.5. In A. Middeldorp, editor, Rewriting Techniques and
Applications (RTA'01), volume 2051 of Lecture Notes in Computer Science, pages 357-361.
Springer-Verlag, May 2001.

[98] Michael J. Voss and Rudolf Eigemann. High-level adaptive program optimization with

adapt. In PPoPP '01 : Proceedings of the eighth ACM SIGPLAN symposium on Principles

BIBLIOGRAPHIE 231

and practices of parallel programming, pages 93-102, New York, NY, USA, 2001. ACM
Press.

[99] Michael J. Voss and Rudolf Eigenmann. A framework for remote dynamic program optimization. SIGPLAN Not., 35(7) :32-40, 2000.

[100] Z. Wang, K. Pierce, and S. McFarling. BMAT -- a binary matching tool for stale profile

propagation. Journal of Instruction-Level Parallelism, 2(1-6), 2000.

[101] Doran Wilde and Sanjay V. Rajopadhye. Memory reuse analysis in the polyhedral model.

In Euro-Par '96 : Proceedings of the Second International Euro-Par Conference on Parallel
Processing, pages 389-397, London, UK, 1996. Springer-Verlag.

[102] Robert P. Wilson, Robert S. French, Christopher S. Wilson, Saman P. Amarasinghe, Jennifer M. Anderson, Steve W. K. Tjiang, Shih-Wei Liao, Chau-Wen Tseng, Mary W. Hall,
Monica S. Lam, and John L. Hennessy. Suif : an infrastructure for research on parallelizing
and optimizing compilers. SIGPLAN Not., 29(12) :31-37, 1994.

[103] M. E. Wolf. Improving Locality and Parallelism in Nested Loops. PhD thesis, Stanford

University, August 1992. Published as CSL-TR-92-538.

[104] M.E. Wolf and M. S. Lam. An algorithmic approach to compound loop transformations.

In Languages and Compilers for Parallel Computing, pages 243-273, London, UK, UK,
1990. Pitman Publishing.

[105] Micheal J. Wolfe. Techniques for improving the inherent parallelism in programs. Master's

thesis, University of Illinois at Urbana-Champlain, 1978.

[106] D. Wonnacott and W. Pugh. Nonlinear array dependence analysis. In Proc. Third Workshop on Languages, Compilers and Run-Time Systems for Scalable Computers, 1995. Troy,
New York.

[107] J. Xue. Automating non-unimodular loop transformations for massive parallelism. Parallel

Computing, 20(5) :711-728, 1994.