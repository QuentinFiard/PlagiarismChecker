

Acta  Informatica 2,  12--39  (1973) ffi9  by  Springer-Verlag  t973 

Efficient  L R (1)  Parsers 
T. Anderson,  J.  Eve  and  J. J.  Hom ing 

Received April  7,  t972 

Summary.  Knuth's  LR(t)  parsing  algorithm  is  sufficiently  general  to  handle  the parsing of most programming languages with the additional  benefit of earlier detection 
of syntax  errors  than  in  other  formal methods  used  in  compilers.  The  major  obstacle impeding  the  use  of this  algorithm  is  the  large  space  requirement  for parsing  tables. 

In  addition,  certain  optimisations  described  here,  which  increase  parsing  speed, exacerbate the  space problem. 

Two  approaches  for overcoming this  problem are  explored. 

t.  Using  parsers  related  to  the  LR(t)  parser  which  parse  a  large  subset  of the LR(t)  grammars,  but  which  have  much  smaller parsing  tables. 

2.  Devising  compact  encodings  and  performing  space  optimisations  on  these tables. 

Time  and  space  efficiency  is  evaluated  using  the  Stanford  University  Algol W compiler as a  base for comparison since the  parsing  routine  in  this  compiler is among 
the  more efficient presently used. 

1.  Introduction 
The widespread  use of context  free grammars to model the  syntax of program- 
ming  languages  has  resulted  in  the  parsing  problem  for  such  languages  receiving 

a  great  deal  of  attention  both  theoretically  and  practically. 

It   is known  that,  for  parsing  an  arbitrary  context  free  language,  an  amount 
of time proportional to the cube and an amount of space proportional to the square 
of  the  length  of  the  input  string  is  sufficient  (see,  for  example,  Earley,  t970). 

For various subclasses of context  free grammars these  bounds  can be considerably 
improved.  Programming languages  are  generally  amenable  to  analysis  by  parsing 

methods  with  time  and  space  requirements  which  are  linearly  related  to  the 
length  of  the  input  string.  Several  such  linear  parsing  algorithms  are  described 
in  the  survey  article  of Feldman  and  Gries  (t 968). 

Historically, these parsers were classified into top down and bottom up categories 
according  to  the  primary  strategy  adopted.  In  the  former,  starting  from  the 
principal  nonterminal  of a  grammar,  an  attempt  is made  to  produce  a  derivation 

of  the  input  string.  Bottom  up  methods  start  with  the  input  string  and  try  to 
produce  a  parse  directly. 

It   was  pointed  out  by  Knuth  (t965)  that  the  bottom  up  strategy  results  in  a 
parse  which  has  the  property,  when  viewed  (in  reverse)  as  a  derivation,  that  the 
rightmost  nonterminal  in  each  sentential  form  is  replaced  in  each  step.  The  top 
down  strategy  results  in  a  derivation  in  which  the  leftmost  nonterminal  in  each 

sentential  form is replaced  at  each step  (Lewis and  Steams,  t968) ; i.e.  the  bottom 
up  strategy  leads  to  a  right  canonical  parse  while  the  top  down  strategy  leads 

Efficient L R (t)  Parsers  t 3 
to the le]t canonical derivation. It is probably the case that these are the appropriate 
formal notions  embodied in the intuitive ideas  of bottom up and top down.  In his 

paper, Knuth defined a subclass of the context free languages, the LR(k) languages, 
which  are  precisely the  set  of languages  for which  the  right  canonical  parse  can 
be  obtained  deterministically  (i.e.  without  backing  up  and  changing  any  parsing 

decision  already  made)  in  a  single  pass  over  the  input  string  from  left  to  right, 

looking  at  most  k  symbols  ahead  on  the  input  string  to  determine  each  parsing 
decision.  Similarly  Lewis  and  Stearns  consider  the  LL(k)  languages,  in  which 
the  left  canonical  derivation  can  be  obtained  deterministicaUy  under  the  same 

constraints. Both classes of language can be parsed in  time and  space linearly proportional 

to  the  length  of  the  input  string,  but  the  fact  that  the  LL(k)  languages  are 
properly contained in  the  LR(k)  language~ implies  that  the  latter  are  potentially 

of  greater  practical  interest.  (It  is  true,  however,  that  in  the  former  category 
at any point in a parse only the first k terminal  symbols generated by a production 
need  to  be  matched  with  the  input  string  to  determine  whether  that  production 
was  used  in  the  derivation.  In  the  case  of  LR(k)  languages  it  is  not  possible,  in 
general, to determine whether a  production has been used until k terminal symbols beyond the  last  generated by  that  production have  been  inspected.) 

The  LR(k)  property  is  associated  with  a  grammar;  a  language  is  LR(k)  by 
virtue  of  there  existing  at  least  one  such  grammar  which  generates  it.  Knuth 

has given two procedures which decide, when given a particular value of k, whether 

a  grammar  is LR(k).  The second of these  can be modified to  provide state  tables. 

In  the  event  that  the  grammar  is LR(k),  a  relatively simple interpreter  for scan- 
ning  these  tables,  in  conjunction  with  a  stack,  provides  a  parsing  routine  for 

the  language.  Knuth  has  also  shown  that  any  language  which  is  LR(k)  is  LR(I). 

(If  sentences  of  the  language  terminate  with  a  unique  symbol  which  does  not 
appear  elsewhere  in  a  sentence,  this  result  can  be  sharpened  to  LR(O).) Un- 
fortunately,  exploitation  of  this  result  in  compilers  founders  on  the  fact  that  it 
involves  generating  an  LR(t)  or  LR(O) grammar  in  which  the  phrase  structure 
of the  original grammar  is  corrupted. 

In  the  case  of  programming  languages,  the  need  for more  than  one  character 
of look  ahead  arises  primarily  at  the  lexical level due  to  the  paucity  of  symbols 
available  on  many  current  input  devices.  The  occurrence  of  " : "   and  " :="   in 
ALGOL 60 is a well-known example.  Typically, for efficiency if for no other reason, 
lexical  analysis  is  separated  from  syntactic  analysis,  and  the  lexical  scan  can 
deal  with  look  ahead  problems  at  this  level  of  analysis  as  a  minor  addition  to 

its other tasks.  It  is  also  the  case that  construction of other than  trivial program- 
ming  language  grammars  is  an  extremely error  prone  process  almost  invariably 
resulting  in  grammars  which  are  syntactically  ambiguous.  Assuming  that  lexical 

problems  have  been  treated  separately,  it  appears  that  programming  language grammars largely meet the constraints which allow the use "of the LR(t)  algorithm; 

changes  to  a  grammar  to  accomodate  deviations  from the  constraints  are  slight. Amending  a  grammar  to  enable  the  use  of the  more restrictive  SLR(t)  algorithm 

advocated  ill  this  paper  is  not  always  necessary  (see  Section 6.1)  and  at  worst 
is  a  small  additional  burden  which  can  be treated  in  conjuction with  the  problem 
of eliminating  genuine  ambiguities. 

t 4  T. Anderson et al. : 

The  state  tables  of  the  LR(k)  algorithm,  even  for  k =  t,  are  too  large  for  use 
directly  in  a  compiler  or  compiler  writing  system;  e.g.  a  program  implementing 
the LR(t)  algorithm was applied to an ALGOL 60  grammar, the run was terminated 
with  the  insertion  of the  10000th  state-input  entry  into  the  state  table,  at  which 
point  t  237  states  had  been  created  (see also  Korenjak,  t969).  The  work  reported 

here  addresses  the  problems  raised  by  Knuth,  of  developing  algorithms  that 
accept  LR(k)  grammars or special  classes  of them  and  of mechanically  producing 
efficient parsing programs. 

2.  Definitions  and  Notation 
Let  0  denote  the  empty set  and  A  denote  the  null  string. 

If X  and  Y  are  sets  of  strings  and  xy  denotes  the  concatenation  of  x  and  y, 
then  X Y   = {xy I x E X  and y  E Y }  

If X ~   {A} then  sets  X i are  defined  by 

X i $   for  i  0 
and  X*  is  defined  by 

co X*  =  U X i. 

4=0 

A  context lree grammar (with an end marker) is a  quadruple G =  (VN, V r, P, S_L ), 
where 

V N is  a  finite  set  of non, terminal  symbols, 

V r  is  a  finite  set  of terminal  symbols, 
V N n  V r  =  0  and  V  denotes  VN U Vr, 

SE V N is  the  start symbol  or principal  nonterminal  of the  grammar, 

_k r  V  is the  endmarker, 
S_]_ is  the  start string, 

P  is  a  finite  subset  of V N X V*  called  the  set  of productions. 
A  production  (A, ~)  ma y  be  denoted  by  A-->~,  where  AE VN, aE V*.  A  and 
are  the  left hand side  (LHS)  and  right hand side  (RHS)  respectively of the  produc- 
tion A -+a. 

It will prove convenient to number the productions  (in some arbitrary manner) 
by  the  integers  t,  2 . . . . .   s  and  to  use  the  notation 

Ap---~XplXp2  ...  Xp,~,  %~_0 
to  denote  the  p-th  member  of  the  set  of  productions. 

Unless  otherwise  stated 

A,  B,  C . . . .   denote  members of V N 

a,  b, c . . . .   denote  members of V T 
X,  Y  denote  members of  V 

~, r,  y . . . .   denote  members  of  V*. 

Efficient L R (l)  Parsers  t 5 
If  G =  (VN, VT,  P,  S_L)  is  a  context  free  grammar,  then  ~  directly  derives  fl, 
(written  ~ , f l )   if there  exist  7,  3, oJE V*  and  A EV N such  that 

~ = 7 A ~ ,   f l = T a ~   and  A - + o ~ i s i n P .  
Also  a  derives  fl  (written  ~:gfl)  if  there  exist  o~ o,  oJ 1 . . . . .   co~E V*,  n  =>0  such 
that 

----o~ o ~ o h . . .   ~co~ =ft. 

If o0, o~1 . . . . .   oJ~ V N then  the  derivation  is  a  chain  derivation. 
The  p-th  production  is  a  chain  production  if np =  t  and  Xp~fi  V x. 
The  p-th  production  is  left  recursive  if  Ap =  Xpl;  Ap  is  said  to  be  directly  left recursive. 

A  nonterminal  symbol  A  is  left  recursive  if  A  ~ 7 ~ A o J ,   7, o~E V*. 

If A E V  N and  ~E V* - - A   then  we  define  the  sets 

first  (o 0  =  {XE  V[ o~,Xa~  where  o~ E V*} 
lollow  (A)  ----{XE Vu_l_  [S_J_;*'flAX 7  where  /SE V*  and  XTE  V*_]_}. 

3.  The  Constructor  Algorithms 
In  this  section  algorithms  are  given  for the  construction  of recognisers  in  the 
form of state  tables.  The  fundamental  algorithm  is that  of Knuth  and  the  ensuing 
discussion  presumes  familiarity with  it;  however,  the  descriptions  of the  modified 
algorithms  derived  from  it  and  presented  here  are  self contained. 

In  Knuth's  algorithm,  a  state  (Knuth  uses  stateset  in  place  of state)  of a  parse 
is  defined  as  a  set  of  triples  of  the  form  [p,/'; ~1.  The  appearance  of  [p,/'; ~l  in 
a  state  corresponds  to  the  informal notion  that  in  this  state  the  parse has reached 
a  point  consistent  with  the  propositions  that 

(a)  production  number  p  ma y  have  been  used  to  generate  the  portion  of  the 
sentence  scanned  thus  far, 

(b) if production  p  has been used,  the symbols Xp 1, Xp ~ ..... Xp i  (or derivations 
therefrom)  of  production  p  have  already  been  recognised. 

(c)  if  production  p  has  been  used,  the  k  letter  terminal  symbol  string  a  ma y 
legitimately  immediately succeed  the  current  use  of production  p. 

It  is  appropriate  to  consider  the  reason  for  the  large  number  of states  arising 
in  the  LR(k)  algorithm.  Consider  an  LR(t)  grammar  in  which  a  nonterminal 
symbol A  occurs in  the  R HS  of some production  where it  is immediately followed 
by  a  nonterminal  B;  if  p  is  the  (index)  number  of  a  production  defining  A,  the LR(1) 

algorithm will generate  a state containing  {[p, t  ; bll,  ~p, t  ; b2] ... ..  [p, 1 ; b,l } 
where  b i  ( i = 1   . . . . .   r)  are  members  of  V r  such  that  B ~ b i ~ .   (We  assume  for 
simplicity that  neither  A  nor  B  generate  the  empty string.)  Similarly if A  appears 
elsewhere  followed by a  nonterminal  C,  a  state containing { [p,  i  ; ql,  EP, t  ; c21 . . . . .  

[p,  ~ ; c~l},  arises  (where  C ~  cifl ).  Each  of  these  states  can  spawn  others  which 
include  triples  [p, ];  bil  and  [p, i;  ckl  respectively with  i >   1.  Thus  a  nonterminal 

which  appears m any  times in the  RHS   of the  productions  of a  grammar generates 
m an y  states  to  keep  track  of  the  m any  different  right  contexts  of  its  use.  Only 

t 6  T. Anderson et al. : 
when/"----rip  (i.e. all characters on the  R HS  of production p  have been recognised) 
are  the  third  components  of  the  triples  in  a  state  used.  If  in  a  state  containing 

[p, %;  bi],  and  the  next  character on the  input  string  is  bi this  is  taken  to  imply 
that  production  p  did  indeed generate  the  preceding portion  of the  input  string. If [ ~= np, then in the two states { [p, [; bxj . . . . .   [p, [ ; b,J} and { [p, [ ; q] .....  [p, [ ; c,] } 

the  same  set  of input  symbols will be  permissible;  each input  symbol in this  pair 
of states  will cause transition  to  the  appropriate  one of a  pair of successor states. 

Each  such  pair  of states  could  be  replaced  by  a  single  state  were  it  not  for  the 
possibility  that  the  terminal  symbols  which  follow A  in  one  context  (and  thus 
signal  the  use  of  some  production  p  in  a  parse)  may  overlap  with  the  set  of 

terminal  symbols  which  signal  that  p  has  not  been  used  in  some  other  context. 
Consider,  for example,  the  grammar  with  productions, 

i)  S-->aAc  4)  S---~aBd 
2)  S-->bBc  5)  A---~e 
3)  S - + b A d   6)  B-+e 

In  the input  string' a  e c',  it is  ' c'  which signals  that  ' e'  must  be  parsed  as an 'A' 
using  production  5.  For  the  string  'b e c',  it  is  'c'  which  signals  that  'e'  must  be 

parsed  as  a  ' B '   using  production  6  and  not  as  an  'A'  using  production  5. 

The  preceding  discussion  motivated  the  following  algorithm  which  utilises 
the  left  contextual  information  inherent  to  the  p,/"  components  of  the  [p,/';  ~] 
elements  of  the  LR(k)  states.  Thereafter,  like  the  very  successful  precedence 

methods,  it  relies  upon  there, being  no  intersection  between  the  set  of  terminal 
symbols which  imply  the  use  of a  certain  production in  one  context with  the  set 
of terminal  symbols precluding its  use in  another context.  The  class  of grammars 

to which the  algorithm applies  (and which  it implicitly defines)  are  called SLR(k) (Simple  LR(k)) 

grammars.  These  grammars  were  defined  independently  by 
DeRemer  (t969,  1971);  for  consistency  his  nomenclature  is  used.  The  present formulation offers a  different viewpoint  and  includes  algorithms  for constructing 

efficient SLR(I)  parsers.  The  basic  algorithm  is  described  only  for  the  practical case  k =  1,  which  is  somewhat  simpler  than  the  algorithm  for  general  k,  both 

conceptually and  computationaUy. 

3.1.  The  SLR(I)  Algorithm 
Let  G = ( V  N, V T, P,  $3-)  be  a  context  free  grammar.  The  p-th  production  is 
denoted by 

A p - ~ X p , , X p ~ . . . X p , ~ ,   t<=p<=s  and  np_-->0.  (1) 
The sets  Tp =/ollow  ( A p) n  (V T u  3_) 

(2) 

are  computed  as  a  preliminary  step  before  commencing  the  algorithm  (see Appendix). 

A  state  ~  is  a  set  of  elements  [p, i],  where  the  occurrence  of  an  element in  a  state  means  informally that  potentially ]  characters  on  the  RHS  of produc- 
tion p  have been  recognised. 

Efficient L R (1)  Parsers  17 
The start string S_L  is treated as though it were the  RHS  of a zero-th produc- tion  in  the  grammar,  so  the  initial  state  5{0 ={[0,  0]}  implies  that  no  character 
of  the  start  string  has  been  recognised.  The  algorithm  involves  maintaining  a stack throughout the  parse which is represented  (to the  left of the  vertical bar)  as 

9~o~9~  ...  5P~lY o~  (3) 
y~ VTU 3_  denotes  the  next  input  symbol  and  co  represents  the  (unexamined) 

remainder of the input  string.  Initially, the stack  contains  the  single  element  6~o. Assume  that  a  parse  has  reached  the  state  S~  so  that  the  stack  and  input  are 

represented  by  (3)- The  steps  involved in  proceeding to the  next state  ~ + t   are  as follows. 

Step 1.  Compute  f  from  6~  where  ~  is  defined recursively  as  the  smallest set satisfying 

~ :   =  s~ u  {[q, 0113 Ep, i]e ~ ,   i  <  np,  Xp(]+l) =Aq}  (4) 
i.e. if  [p, ~] is in the set, the  (1" +  l)-th character,  Xp(i+l),  of production p  is poten- tially about  to  be  recognised;  if  Xp(i+l)  is  a  nonterminal  symbol  defined by,  for 

example,  production  number  q,  then  the  first  character  of  production  number  q could be  about  to  be  recognised,  so  Iq, O] is  added  to  the  set  to  reflect this. 

Step 2.  Compute  the  following sets  of terminal  symbols 

z  = {~e  v~l 3 [p, i]e S ,   i  <  np, ~ =  xp(~+~)}  (5 a) zp ='rp  if  [p, np]e ~d 

=  0  otherwise.  (5 b) 
Membership  of Zp  by  the  next  input  symbol y  signals  the  recognition  of a  string generated by production p. Z is the set of terminal symbols which might legitimately 
be  encountered  next  upon  the  input  string  and  which  indicate  that  the  end  of  a 

string  generated  by  some  production  has  not  been  reached.  (From  (8)  it  will follow that  when yEZt,,  the  states ~9~  . . . . .   oct,_l, 5P~ on the  top  of  the  stack 

are  the  states  entered  after  recognising Xpt , Xpe,  ...,  Xp~p respectively.  Further 
5a~_np  includes  the  element  [p,  01  and,  by  (4),  an  element  [p',  i']  such  that 

Xp,(i,+t ) =Ap.) 

Provided  that  Zc~Zp=ZpnZq=O 

for all  P4:q,  (6) 

an unambiguous choice of action can be made depending upon the next  character 
on the  input  string: 

1)  If y E Z,  stack  y  so  that  the  stack-input  representation  becomes 

~ o ~ - . .   : ~ y l   ~o 
and  rename  the  stack-input  symbols producing 

~  ...  9~,,,X,++l[y co'  (7a) 
i.e. y  is renamed Xm+ 1 and  the  first symbol of co becomes the  new y. 

2  Acta  Informatica,  Vol. 2 

t 8  T. Anderson et al. : 

2)  If y ~Zp, let  r  = m - - u p .   On  removing  the  top  np  elements  from  the  stack and inserting Ap,  the  stack-input  representation  becomes 

5'go 5~1. . . ~  A p I y  o 
which after renaming symbols is 

5"go5~1... 5:~X,,,+l[y o.  (Zb) 
Step  3.  Using  the  5:,, defined  by  (7a)  or  (7b)  compute  5:,~ as  in  Step  t  (or recall it)  and  replace  X,,+ 1 on  the  stack  by  5:,,+1 where 

~am+ 1 ={[p,  f + t ] [   [~, f] ~ ]d ,   f($l'p,  Xm+l =Xp(]+l)}  (8) 
i.e.  the  symbol  X,,+~,  left  on  the  stack  in  Step  2,  has  just  been  recognised.  If [p, ]]E S:,~ and  the  (i +  l)-th  symbol on  the  RHS  of production  p  matches  Xm+ 1 

then  [ p , / + l ]   is  included  in  5:,,+1  to  reflect  the  fact  that,  in  the  next  state, potentially ?' +  1  symbols on  the  RHS  of production  p  have  been  recognised. 

If  oc:~+x : { [ 0 ,   t]},  the  parse  is  complete;  otherwise  an  inductive  step  on  m 
has  been  completed,  and  the  algorithm  proceeds  from  Step  t.  This  method  of terminating  the  algorithm  requires  that  the  state  whose  set  denotation  includes 

the  member  [0,  t ]  has  only this  member;  this  implies  the  very  weak  constraint that  the  start  symbol of the  grammar  must  not  be left recursive. 

The  description  of the  algorithm deliberately parallels  that  of  Knuth's  LR(k) 
algorithm  in  order  to  facilitate  comparison,  We  observe  that 

t)  The set  (5 a)  corresponds to the set  (t9)  in  Knuth's LR(k)  algorithm  (taking k =  1  in  the  latter)  but  it  is  appreciably  less  costly  to  compute.  In  essence,  (5 a) 

differs in  simply ignoring the  cases  where  Xp(i+l)  are  nonterminal  symbols;  this is permissable  since the  closure computation  (of 5a~ to  5:,~) in  Step  1 ensures  that 
if  [p, ]]65a~,  then  ~9~ contains  all  appropriate  [p', 0]  such  that  Xp(i+t)=gXp, sW, where  o~ ~ V*.  It  follows that,  in  determining  the  single  symbol  terminal  strings 

derived from the symbol Xp(/+~), attention can be restricted to those symbols Xp,~ which  are  terminals.  This  same  observation,  for  k--> t  implies  that  the  set  (19) 
in  the  LR(k)  algorithm can  be  replaced by 
Z  ={ill 2~ [P, ]; ~3 e ~m, f <'n,p, fl =a  *,  a =Xp0.+l)e  VT, r  eHl~-l(Xp(j+2)...  Xpn~~ 

When  k is  other  than  one,  the  computational simplification is not  so great. 

2) The only difference between the  SLR(I)  algorithm and the LR(t)  algorithm lies in replacing set  (20) of the latter by  (5 b)  above. 

3) A grammar (and hence the language it defines) is SLR(t)  if the conditions (6) hold for all states 5~i which can arise in parsing sentences of the  language. 
4)  The  SLR algorithm retains  two important  properties  of the  LR  algorithm. Syntactic  errors  are  located  on  the  first  terminal  of  a  sentence  which  is  not 
generated in accordance with the rules of the grammar.  Such errors become appar- ent in  Step 2 of the algorithm in that y CZ and yCZp for any p. The second feature 
is that  when  the  stack  is reduced  in  Step 2,  it  is  known,  a  priori,  that  the  states removed  from the  top  of the  stack  correspond  to  the  symbols of the  RHS  of the 

production.  In  this  respect  also  the  algorithm is  an  improvement  on  the  various 

Efficient L R (t)  Parsers  19 
precedence  methods.  This  correspondence  is  established  by  relation  (8)  which 

associates  the  symbol  X~+ 1 with  the  state  5:,~+r  (X,,+I  is  termed  the  associated 
symbol  of the  state  oC#r~+r) Korenjak  (t969)  has  described  a  method,  closely related  to  the  SLR  method, 

for  reducing  the  number  of  states  generated  by  the  LR  algorithm.  In  it,  the 

LR  algorithm  is  used  to  construct  sub-parsers  for  certain  selected  nonterminals 
of  a  grammar.  The  main  parser  for  the  grammar  is  also  constructed  by  the  LR 
algorithm,  but  special  provision  is  made  for  invoking  the  sub-parsers  whenever 
the  corresponding nonterminals  are  to  be  recognised.  Since each  sub-parser  must 
work  for  all  right  contexts  of its  nonterminal  in  the  RHS  of  the  productions  of 
the  grammar,  it  seems  clear  that  the  SLR  algorithm  is  equivalent  to  Korenjak's 
if,  in  the  latter,  sub-parsers  are  constructed  for all  nonterminals  of the  grammar. 

3.2. SLR(t)  State  Tables and  the Basic  Parsing Algorithm 
The  SLR(f)  algorithm  has  been  described  in  terms  of  parsing  a  given  input 
string.  It  can be modified to produce state  tables  which,  with  a  simple interpreter 

and  a  stack,  suffice  to  parse  all  strings  derived  according  to  the  grammar.  To 
produce the  state  tables,  a  list  of all  possible  states  is maintained  and  m  becomes 
the  index  to  states  in  this  list.  (Initially  the  list  contains  only  5~0 ={[0,  0t}  and 
m----0.)  Step  t  of the  algorithm  is  unchanged;  Steps 2  and  3  are  replaced  by  the following. 

Step 2. Compute 

z'  =  { x ~   v[  3 [p,  il ~ :.~,  i  <  np,  x  =  xp(j+l)}  (5 a') 
Zp  as in  (5 b). 

(Note  that  the  members  of  Z'  in  (Sa')  range  over  the  entire  vocabulary.  The 
members  of Z  in  (5 a)  were  restricted  to  V T.  Indeed 

Z  =Z' c~V r 
and  conditions  (6) must  still  hold.) 

Step  3. For each symbol X C V,  a state table entry for the state  5: m is  determined 
from : 

If Xr Z' ^ Xr Zp for any  p,  the  entry  is  blank, 
if XE Zp,  the  entry is  the  production  number  p, 
if XE Z',  the  entry  is  the  state  5:  to  be  entered  next,  where 

~ = { [ P ,   f "3F 1]1 [P, ]']E ~  ]< np,  X  =Xp(]+l) }. 
Any  such  state  5f  not  present  in  the  list  of  all  possible  states  is  added.  If  m 
is not  pointing  to  the  last  state  in  this  list,  it  is incremented by  one and  a  return 

is made to step  t. 

As an  example,  Fig.  2 contains  the  state  table  produced by this  modified form of  the  SLR(I)  algorithm for  the grammar  in Fig. i.  In Fig. 2, production numbers 

are  prefixed by  a  minus  sign.  For  indicating  next  states,  the  denotation  as  a  set 
of [P, ?'] elements is inconvenient ; the index number of the state in the list produced 
by  the  modified algorithm  replaces  it. 

2* 

20  T. Anderson et al. : 

The following procedure, which is a  consequence of the method of construction 
of the  state  tables,  suffices to  interpret  them.  Assume  that  state  i  is  the  current 
state  and  symbol 1" is being scanned  (initially i =  0  corresponding  to  5~o ={[0,  0]} 
and  7' is  the  first  symbol on  the  input  string) ; then 

Step 1.  Stack  i  on the  parse  stack  and  examine  the  (i,/')-th  entry  of the  state 
table.  If  the  entry  is  blank,  then  the  terminal  symbol/'  is  invalid  and  the  sub- 
sequent  action  is determined by  an  error handling  routine. 

Ste# 2.  If the  entry is a  state  number,  then  this  state  number is  assigned  to i, 
the  next  input  symbol  is  read  and  assigned  to/" and  a  return  is  made  to  Step t. 

Step 3.  (The  entry  must  be  a  production  number.)  One  stack  element  is 
popped from the stack  for each character on the  RHS  of this  production,  thereby 

uncovering  a  state  number  k.  The  LH S  of  the  production  is  a  nonterminal  1. 
The  (k,  l)-th  entry  of  the  state  table,  which  necessarily  is  a  state  number,  is 
assigned  to i  and  a  return is made  to  Step  1. 

A  convenient termination  of this  procedure can  be  achieved by detecting  the 
next  state  number  corresponding to  the  state  {[0,  t]}  in  Step 2. 

The  rather  small  example  of  Fig.  t  conveys  no  impression  of  the  size  of  the 
tables  which  would  result  for  a  practical  grammar;  examples  will  be  given  in 

Section 6. 

3.3.  The  L A L R (t)  Algorithm 
Consider the  grammar  with  productions 

t)  S - + a A d   3)  S -+ bA c 
2)  S-->a  e c  4)  A--~e. 

On  attempting  to  produce  an  SLR(I)  state  table  for  this  grammar  as  described 
in 3.2, a state { [2,  2],  [4,  1 ]} will be generated. For this state, Z  =  {c} and Z4 =  {c, d}, hence  Zc~Z4#  O,  demonstrating  that  the  grammar  is  not  SLR(t).  However,  if 

in state { [2,  2],  [4,  1 ]} with input  symbol y  ----c the stack is reduced using produc- 
tion  4,  then  this  corresponds  to  recognition  of  aA.  Since  aA c cannot  begin  any 
sentential form in the language, Z4 could (and should) be taken as {d} in this instance. 

More  generally,  consider  the  parser  in  a  state  5P  for  which  a E Zp  with  input 
symbol y  =  a.  Denote  by  ~  the  string  of associated  symbols  of  the  states  on  the 
stack  after  reduction  by  production  p.  If  for  all  such  ~,  there is no o9 E V* such 

that  S  ~,t   a  co  then  a  should  be  deleted  from  Zp.  (Note  that  no  symbols  can be  deleted  from Z  since  this  would  imply  the  possibility  of reading past  an  error 

in  the  input  string.) This  inaccuracy  in  the  sets  Zp  of  the  SL R(t)  algorithm  is  due  to  the  use  of 

the  sets  Tp  to  determine  the  symbols  which  indicate  reduction  of  the  stack, 
instead  of that  subset  of Tp which  is  the  permitted right  context  of production p in  a  particular  state.  Tp is  the  permitted  right  context  of  production  p  over  all 

states. In  the  above example,  the  state  {[2, 2],  [4,  t]}  can  only be reached in  parsing 
a  string generated  by production t  or  2;  production 3  cannot  be  involved so that 

Efficient L R (1)  Parsers  2t 
in  the  context of this  state  only the  subset  {d} of T, =  {c, d} can  follow the  use of 
production 4. 

The  example  also  demonstrates  that  a  larger  class  of grammars  than  SLR(t) 
can  be  parsed  using  a  state  table  in  which  Zp is  computed  correctly rather  than 
substituting  Tp.  This  larger  class  is  termed  LALR(t)  following  DeRemer.  It 

should  also  be  pointed  out  that  LALR(t)  state  tables  may  be  more  economical 
of storage under some representations e.g.  the list representation discussed in  5.t. 

The one disadvantage  of LALR(I)  compared with SLR(I) is that  computation 
of the  state  tables  of the  former is much  more  complex,  though  clearly less  effort 
is  involved than  in  computing  LR(t)  tables. 

Two  alternative  methods  for  constructing  LALR(t)  tables  will  be  briefly 
presented here. LALR(t) 

state  tables  may be computed directly. To do this  the LR(I)  notion 
of a  state  as  a  set  of  triples  [p,/';  aJ  as  discussed  in  Section 3  is  needed.  Also 
required are the LR(t)  versions of Eqs.  (4) and  (Sb) i.e. 

=  u  o;  b]l  [p,  i;  ale  i < - , ,   Xp(i+l~=A,, 

b e first  (Xp(i+~)... Xp,p a) c~ Vr} 

z,  ={al  EP, 
If  formulated  to  parse  a given  input  string  there would  be no difference  between 
an  LALR(t)  parser  and  an  LR(t)  parser.  The  difference  arises  in  constructing 
the  state  table.  The determination of whether  a  state  is already in the list  of pos- 
sible  states  is  made  only  on  the  basis  of  the  p  and  ]  components  of  the  triples, 
i.e.  as in  an  LR(O) computation.  Two sets  of triples  belong to  the  same  state  and 

are  merged if  for each  triple  [p,/';  a I  in  one  set  there  is  a  triple  [p',/";  a']  in  the 
other  set  such  that  p =p'  and  /" =]'.  Such  merging  may  introduce  new  triples 

(differing  only  in  the  third  component);  if  so,  the  augmented  state  is  marked. 
When  the  list  of  states  is  completed,  each  marked  state  is  treated  in  turn,  by 
first  removing  the  mark,  then  recomputing  the  set  of possible  next  states.  (The 
mark  on  a  state  indicates  that  its  right  context  has  been  enlarged  with  the  con~ 

sequence that  the  right  context  of some  of its  next  states  become enlarged.)  The 
recomputed next states  are merged with  the  original versions in  the  list  of states, 

marking  any  which  become  augmented.  The  reprocessing  of  marked  states  is 
continued until  all  marks  have  been  removed.  (Termination is  ensured  since  the 
right  context  of  each  state  must  increase  to  be  marked,  and  V T  is  finite.)  This 
method implicitly uses LR(O) states  to represent  equivalence classes  of the  states 
in  an  LR(t)  state  table,  but  the  computation  is  not  as  large  as  full  LR(I),  since 

not  every LR(t)  state  is  necessarily generated. 

A  second  method  is  to  first  form  an  SLR(t)  table  and  then  eliminate  the 
invalid  members  of  the  Zp  sets  as  follows.  Define  an  n-th  predecessor  (n _--> 1)  of 

a  state  s  as  any state  from which  an  n  -- t-th  predecessor of ~9 a can be obtained as  a  possible  next  state,  and  take  5 r  to  be  its  own  0-th  predecessor.  Denote  the 

exact right context of [p, i] in a state 5~lby R(5~1, [p, i]), which  is  defined recursively 
by  R (~ ,  [p, i]) ={ aE  VTI aelirst(Xq(k+,)  ...  Xq,, b),  [q, k I e ~ ' ,   Xq(~+l)=A,, 

be R(5~,,  Eq, kJ), 5~2 is  a  ]-th  predecessor of  5~t }. 

22  T. Anderson et al. : 
This  definition provides  an  algorithm  if  circularity is  avoided  by  taking 

R(~,  It, l]) ={A} 
whenever  a  computation  of  R(~,  Jr, l])  invokes  itself.  This  may  result  in  the 

spurious  inclusion  of  A  in  the  final  set;  it  should  be  deleted.  The  exact  right 
context  of  [~, rip]  in  a  state  may  now  be  used  as  Zp  for  that  state,  giving  an LALR(t) 

state table. In  practice  it  is  only  necessary  to  refine Zp  in  the  cases  where  ZnZp ~  0 or 

Zpc~Zq=~O. This  would  achieve  acceptance  of  all  LALR(t)  grammars  without 

necessarily  performing  a  full  LALR(t)  computation.  Lalonde  (197t)  has  used 

this  technique  to  refine the  sets Zp  for every state  which  is  not  LR(O). 

4.  Transforming the  State Tables 
A  number  of  transformations  can  be  applied  to  state  tables  produced  by 
algorithms  of  the  LR  type  with  a  view  to  reducing  their  space  requirements  or 
improving the performance of the parsing process based upon them.  Conceptually, 

at  least,  these  transformations  may  be  envisaged  as  being  applied  to  the  matrix 
representation of the state  tables;  modification of the  constructor algorithm  may 
be  more convenient. 

For practical purposes,  reduction of the  number  of states  (rows of the  matrix) 
by  general  state  minimisation  techniques  (Pager,  t970)  can  be  discounted;  the 
combinatorial nature  of these techniques militates against  their use.  Even SLR(I) 
tables typically involve a few hundred states for programming language grammars. 
Recourse  to  these  techniques  also  neutralises  some  of  the  benefits  of  the  LR 
methods with  respect to  error detection.  It  is necessary to  develop special techni- 

ques taking into account features of the LR algorithms and general characteristics 

of  programming  language  grammars  to  reduce  the  size  of  the  state  tables  sub- 
stantially. It  is  appropriate  to  recall  that,  in  LR  type  state  tables,  the  blank  entries  in 

columns  corresponding  to  nonterminal  symbols  are  not  significant;  all  syntactic 
errors  are  detected  by  encountering a  blank  entry in  a  column  associated  with  a 

(terminal) input  symbol. We observe then that  merging states with nonconflicting 
nonterminal  entries is  possible  but  that  merging  states  with  other  than  identical 
entries for terminal  symbols  can  upset  the  error detection  capability.  In  SLR(I) 

tables,  states  with  nonconflicting  nonterminal  entries  and  identical  terminal 

entries cannot occur (Anderson, 1972). Merging states with nonconflicting terminal 
entries is possible with delayed error detection if the parsing algorithm is modified to  include  checking  that  the  associated  symbols  of  the  states  on  the  top  of  the 

stack  match  the  RHS  of  the  appropriate  production  every  time  a  production number  entry  is  encountered.  Detection  of errors  on  the  first  input  character  to 

depart  from  the  rules  of syntax  is  a  useful  feature  of  LR  methods.  Apart  from possible  benefits  in  the  error  recovery  problem,  compilers  using  delayed  error 

detection  are  prone  to  failures  in  semantic  routines  in  the  interval  between reading the invalid character and the error being detected by the syntax analyser. 
Attention  has  been  intentionally  confined  to  transformations  preserving  this 

immediate indication  of errors. 

Efficient L R (1)  Parsers  23 
4.1.  Elimination  o/LR(O)  Reduce  States  and  Chain  Derivations 
In  Fig.  2,  the  rows  t,  2,  3,  8,  1t,  t3,  20,  22,  23,  24  and  26  have  the  LR(O) 
property  that  it  is  not  necessary  to  inspect  the  input  symbol  to  determine  the 
necessary  action  since  there  is  a  unique  action  in  each  of  these  states,  namely, 
reducing  the  stack  using  a  production  number  which  is  associated  with  all  valid 
entries  in  these  states.  Failure  to  inspect  the  input  symbol  on  any  production 

number  entry  in  the  table  causes  no  significant  delay  in  error  detection;  the 

subsequent  action  of the  parser will be to use  the  LHS  of the  production  to  deter- 
mine  the  next  action  of  the  parser.  Ultimately  a  next  state  entry  is  encountered 

when  this  input  symbol  must  be  inspected.  It  follows  that  states  containing  a 
unique  reduce  action  can  be eliminated  by  the  simple device  of replacing the  next 
state  entries  in  the  table  causing  transition  into  such  states  by  the  appropriate 
production  number. 

Some  of  the  states  which  would  be  eliminated  by  this  change,  notably  those 
corresponding  to  rows  t,  2,  3  and  t I  in  Fig.  2  are  involved  in  a  more  general 
transformation  which  is  suggested  by  considering  the  problem  of  eliminating 
chain  derivations.  The  need  to  group  syntactic  constructs  together  to  form  a 
further  syntactic  construct  results  in  frequent  occurrences  of  productions  of  the 

form  A - + B ,   where  A,  B  E VN.  The  specification  of  precedence  of  operations  in 
arithmetic  expressions,  for  example,  also  introduces  productions  of  this  type, 
and  derivations  of the  form 

~Alfl ~o~A~fl  3 " "   ~:tA,~fl  ~o~ y  fl,  where  A1,  A ,  . . . .   , A,~E V N 
result  very  frequently.  Usually,  in  compilers,  only  the  final  step  involving  the 
production  A~--~ 7  has  semantic  significance  and  a  parser  which  bypasses  the 
other  steps  would  be  advantageous. 

The  example grammar  admits  the  chain 

E ~ T ~ P  
and  there  are  two  states  (rows  6  and  t 2  of  Fig.  2)  in  which  an  instance  of E  is  to 
be recognised.  Considering row 6, it is observed that  when a  P  has been recognised, 
a  transfer  is made  to  row  t t  where  production  7 causes  P  to  be parsed  as  T,  then 

on  return  to  row  6,  the  T  entry  implies  a  transfer  to  row  t 0  where,  if  the  input 
symbol  is  ' * ',  a  transfer  is  made  to  row  t 7,  otherwise  production  number  5 must 

be applied  causing  T  to be parsed as E.  Row  6 then  indicates  that  for E  a  transfer 
is  made  to  row 9.  At  this  stage  it  would  emerge  that  ' ) '   is  an  invalid  successor 
to  the  present  instance  of  an  E;  it  is  valid  however  in  row  t 2.  We  observe  that, 

if there  is no  semantic  significance  attached  to  production  7,  then  row  1 t  m ay  as 
well not  exist,  a  transfer to row  10 would  suffice;  in  row  f 0, if there  is no  semantic 

I  S---~A  8  T - + T * P  2  S~I  9  P-+(E) 
3  A-+id:=E  10  P-+id 4  /-+ifB  then  AL  11  B-+I3orid 

5  E-+T  t2  B-+id 6  E-+E+T  13  L-+elseS 

7 T-+P  14  L-+A Fig.  I 

24 

id  +  ( 

T.  Anderson   et  al.  : 
*  if  lhen  or  else  :=  _L  S  A  I  E  T  P  B  L 
o  [o,o] t  [o,   1] 

211, 1] 3  [2,1] 
413 ,1 ] 

5  [4,  t] 
6  [3 ,2 ] 7  [  4,2], 

[t,,  l] 8  [12,  t] 
9  [  3,  3], [6 ,  t] 
1o  [  5,  t], [8,1]  

11  [7 ,1]  
12  [  9,  t] 13  [1o,  t] 

14  [4,3] t5  [1t,  2] 
16  [6, 2] ~?  [  8,2] 
18  [  6,  1], 

[  9,2] 
t9  [4,4 ] 20  [t t,  3] 

21  [  6,  3], [8,1] 
22  [  8,3] 
23  [  9,  3] 
24  [  4,  5] 
25  [t3,  1] 26  [i  3,  2] 

4  5  I  2  3 

-0  
-t -2 

8 
13  12 

16 
--5 
--7 13  t2 
--10 
4 20 

13  t2 
t3  12 

16 

14  15 
--12  --12 

--3  --3 

--5  17  --5  --5 
--7  --7  --7  --7 
--10  --10  --10  --t0 

19 

23 

25 --11  --11 
--6  --6  t7  --6  --6 
--8  --8  --  8  --8  --8 
--9  --9  --  9  --9  --9 --4 

4  5  26  23  

--t3 

9 1011  
18  10  11 

2t  11 

22 

--14  24 

Fig. 2 
significance  attached  to  production  5,  then  the  -- 5 entries  simply serve  to  delay 

an error signal until  row 9 is entered.  The  redundant  references to the  -- 5 entries 
could be  eliminated  by  replacing  -- 5 entries  in  row  t 0  by  the  entries  in  the  cor- 
responding  columns  of  row 9  (omitting  the  --5  entry  in  the  ' ) '   column)  were 
it  not  for the  fact that  row  t0  is entered  from row  t2  also.  By a  similar  argument 
the  entries  from  row  t8  should  replace  --5  entries  in  row  t0  (omitting  those  in 
the  ' e ls e '  and  '_L'  columns).  These  assignments  are  incompatible.  If  no  entries 
are  omitted  from  row 10,  the  assignment  incompatibility  disappears  but  so  also 
does  the  error  detection  capability.  Complete  elimination  of  chain  derivations 
is  possible  only at  the  price  of delayed  error  detection  (matching  stack  symbols 

with  a  production  RHS  whenever  the  stack  is  reduced)  or  at  the  expense  of 
introducing  extra  states,  e.g.  if in  the  example,  state  t0  is  split  into  two  copies, 

row 6  can  use  one  and  row  t 2  the  other. 

It  is  clear  that  states  containing  a  single  [t5,/']  element  can  be  eliminated  if 
/" =rip.  A  special  case  arises  whenever  np = 1 ,   XplE VN and  production  p  has  no 

Efficient L R (t)  Parsers  25 
semantic  significance.  In  this  case, all  reference to  production  p  may  be  deleted. 

(The  conditions  n p =   t,  XplE V N imply  that  production  p  is  a  chain production; 
future usage  of this  term will imply the  additional requirement that  no semantics 
are  associated  with  this  production.)  The  changes  to  the  state  tables  are  most 

readily  described  in  terms  of further  modifications  to  the  constructor  algorithm. In  the  modified SLR(t)  algorithm,  step  2  computes  a  set Z'  and  sets Z~  for each 

state.  For each member  of a  set Zp the  state  table  contains  a  production number 
entry  - - p   in  the  corresponding  column.  For each member  of Z',  step 3  computes 
the  appropriate  next  state  entry  and  adds  any  new  states  to  the  list  of  states. 
Only  Step 3  is modified to  accomodate the  required  changes. 

Step 8. The  treatment  of Z'  is  altered. 
Let Z' ~-- {X 1, X 2 . . . . .   X,}  and  C =  {p I production  p  is  a  chain  production}. 

Compute  the  sets  W/= { [p, i  +  t] 13 [p, i] E 5~,  i <n p,  X, =  Xp(i+l)},  t  --< i <-- r. The  sets  W/are  the  next  states  of  the  SLR(t)  algorithm.  The  elimination  of 

all  intermediate  steps  in  a  chain  derivation  can  be  achieved  by  computing,  for 
t =  t,  2 . . . . .   r,  the  smallest  set 

We' =weu  {[p, i]~ We'l [q, t]~W,',  qeC, Aq----Xi} 
then,  for each t,  compute  ~"----{[p,  i ] e ~' l p r   C } . 

Then  members  of  {~"1  ~ "   " t  4: {[P, np]}}  not  already  present  are  added  to  the list  of states. 

Any We" consisting  of a  single  [p, np]  element  would  produce  an  LR(O) state 
in  which  the  only valid  action  would  be  to  reduce  the  stack  using  production  p. 

Such  a  set  We" is  precluded  from  generating  a  new  state  and  instead  the  entry 
in  the  state  table  for  state  SP m and  symbol  X e is  made  to  specify a  reduction  of 

the  stack  using  production  p.  If  this  is  done,  one  state  (the  LR(O) state  which 
has  been  eliminated)  is  missing  from  the  stack  when  the  reduction  occurs  and 

an  element must  be added  to  preserve the  stack  alignment.  If X t E V N an  ordinary 
production  number  entry,  denoted  by  - - p   in  Fig.  2,  can  be  employed;  if  X, E V r 

a  new  type  of  entry  is  needed,  a  scan-production number entry  which  will  be 
denoted by  *p.  A  scan-production  number  entry  indicates  that  a  further  symbol 
must  be  read  from  the  input  string.  In  either  case  the  stack  pointer  must  be 
incremented  by  one before the  reduction is  performed. 

The  computations  of  Step 3  are  illustrated  in  the  case  of  5r  2]}  for 
the  example  grammar  of  Fig.  t.  (See  also  rows  6,  9,  t0,  tt ,  12  and  t3  of  Fig.  2.) The set 

Z' ={ |d,  (, E,  T,  P},  hence 
t  x,  ~  w/  w/' 

l  id  ([t0,  1]}  {EtO,  l]} 2  (  {[9,~]}  {E 9, 1]} 
3  E  ([  3, 3],  [6, t]}  {[  3, 33, [6, t]} 4  T  {[  5, 1],  [8, 1]}  ([  5, 1],  [8, 1],  [3, 3],  [6, t]} 

5  P  {[7, I]}  {[  7, 1],  [5, 1],  [8, 1],  [3, 3],  [6, t]} 

{[1o, t]} {[  9, t]} 
{[  3, 3],  [6, 1]} {[  8,  1],  [3,  3],  [6,  1]} 
{[  8, t3,  [3, 3],  [6, t]} 

26  T.  An de rs on   et  al.  : 

id  +  (  )  *if  then  or  else  :=  _L  S  .4  I  E  T  PB  L 
o  [o,o] 

4 13 ,1 ]  

5 14 ,1 ] 6  [3 ,2 ] 

7  [  4,  2], [11, 1] 
9  [  3,3], [6,1] 
1o  [  8, t], 

[  3,3], [6,1] 

1o' E 8, t], 

[  6,  1], 

[  9,2] t2  [  9,  1] 

t4  [  4,  3] 15  [1t, 2] 

16  [  6,2] 
17  [  8,2] t8  [  6,  1], 

[  9,2] 
19  [  4,4] 2t  [  6,  3], 

[8,~] 
25  [t3,  1] 

4  5  --0  --0  --0 

6 
"12  7 "10  12  9  10  10 

t4  15 
16  --3  --3 

16  17  --3  --3 

16  *9  t7 
"10  12  18  10'  10' 

4  19 
"11 "10  12  21  21 

"10  12  --8 

16  *9 

--6 
4 

25  --14  --4 
--6  t7  --6  --  6 

5  -- i3 -- 13   --13 

Fig.  3 

The appearance  of  [5,  1] in IV, implies  (since production  5 is the  chain produc- 
tion  E - +  T)  that  W, u  W a constitutes  W~'. The  appearance  of  [7,  1 ]  in  W~ implies 

(since  production 7  is  T-->P,  a  chain  production)  that  W,  must  be  included  in 
Ws' with  W 5.  This  introduces  [5,  1]  into  Ws', which  implies  that  W a must  also  be 

included.  The  Wi", I  _--<i_~5, result  from  the  W / o n   removing  [5,  1]  and  [7,  t] 
from W4' and W6'. Fig.  3 shows the state table for the example grammar  resulting from the above 

modifications to  the  constructor  algorithm. Some  steps  in  chain  derivations  may  be  eliminated  without  increasing  the 

number  of states  by  taking 

Wt" =W~  (9) 

where  X i ~ X  u ~ X   v 3 . . .   ~ X ~   ~ X  t  is  the  longest  chain  derivation  for  which 
Wu, W v . . . . .   W w and W t each have a  single member.  In  terms of the previous discus- 
sion  relating  to  Fig.  2  this  modification  eliminates  states  like  {[7,  1 ]}  in  row  1 t while  avoiding  the  replication  of  {[5,  t],  [8,  1]}  in  row  10,  which  is  entailed  in 

eliminating  the  chain production  5. A  special  case which  is  not  covered by  the  modifications is the case of produc- 
tions  with  a  null  RHS.  Usually  semantic  information  will  be  associated  but  if 
not,  for  such  a  production  p,  the  state  table  entries  for  the  members  of Zp  are replaced  by  the  entry  for Ap in  the  same  row  of the  table.  In  Fig.  3  the  effect of 

Efficient L R (1)  Parsers  27 
this  would  be to  copy the  -- 4 entry  in  the  L  column  of row  19 into  the  s  column 
to  replace  the  existing  --14  entry;  however  to  keep  the  stack  of  states  correct 
when  this  - - 4   entry  is  encountered  the  length  of  the  R HS  of  production  4  must 
be regarded  as reduced  by one.  Precisely this  effect would  result  if the  production 

L---~A  were  eliminated  from  the  grammar  of  Fig.  I  (by  substituting  it  in  produc- 

tion  4)  thereby  replacing  L ~ A   by  I ~   if B  then  A.  On  processing  the  modified 
grammar,  the  reference to production  14  (L--~A) would be  replaced by a  reference 
to  the  new  production  which  differs  from  production  4  in  omitting  the  final  L. 

To accomodate the  addition  of a  new type of entry in  the  state table,  the  pars- 
ing  algorithm  must  be  amended.  Step  3  is  replaced  by  the  two  steps 

Step 3.  If  the  entry  is  a  scan  production  entry  then  the  next  input  symbol 
is  read  and  assigned  to  j  and  ?" is  also  stacked. 

Step 4.  (The entry  is either  a  production  number  or  a  scan production  number 
entry.)  One  element is popped from the  parse stack for each character  on the  RHS  
of this  production  thereby  uncovering  a  state  number  k.  The  LHS  of the  produc- 

tion  is  a  nonterminal  l.  If the  (k, l)-th  entry  of the  state  table  is, 

a)  a  state  number,  then  this  state  number is assigned to i  and  a  return  is made 

to  Step  1 
or 

b)  a  production  number,  then  l  is  stacked  and  a  return  is  made  to  Step 4. 

4.2.  Simple  Row Merging  and  Partitioning  o/State  Tables 
The  state  table  in  Fig.  3  is  quite  typical  in  that  ma ny  of  the  states  have  no 
entries  in  the  columns  corresponding  to  nonterminal  symbols;  states  with  this 

property  can  be  renumbered  to  occur  in  adjacent  rows  at  the  end  of  the  state 
table.  An  obvious  space  saving  results  by  first  performing  this  renumbering  and 
then  partitioning  the  state  table  into  two  arrays;  the  T-table  contains  only 

terminal  symbol  columns  and  the  N-table  only  nonterminal  symbol  columns. 

Fig.  4  results  from  Fig.  3  using  the  state  renumbering  scheme: 

Old  number  0  4  5  6  7  9  t0  t0'  t2  14  15  t6  17  t8  19  2t  25 
New  number  I  l0  8  3  1t  12  t3  16  4  9  14  5  6  t5  7  t7  2 
If  the  state  table  is  separated  into  a  terminal  part  and  a  nonterminal  part, 
advantage  can  be  taken  of  the  fact  that  several  rows  in  the  terminal  array  are 
identical;  at  the  expense  of  an  array  with  one  element  for  each  state,  indirect 

addressing  permits  the  identical  rows  to  be  overlaid.  The  nonterminal  array  can 
be  similarly  treated;  in  this  case  rows with  nonconflicting  entries  can  be  overlaid 

to  produce  state  tables  of  the  form  shown  in  Fig.  5. 

As  a  final  comment  on  the  matrix  representation  of  the  state  table,  it  is 
worth  noting  that  the  states  can  be  renumbered  so  that  the  next  state  numbers 

in a  column of the  T-table are represented by  a  sequence of consecutive integers ai, 
which  can  be  decomposed  into  the  form  c +  b i where 

c  =  mill (a i  --  i  ). 

i 

28  T.  An de rs o n  et  al.  : 

id  +  (  )  *  if  then  or  else  :=  3_  S  A  I  E  T  P  B  L 
t  [o,  o3  1o 2  [t3,  t3  1o 
3  [  3,  2]  "t 0 
4  [  9,  1]  *t0 

5  [  6,  2]  *t0 
6  [  8,  2]  "t 0 

7  [4 ,4 ] 8  [  4,  1]  "12 

9  [  4,  3]  10 to  [  3,  t] 
11  [  4,  2], [1t,  t] 

12  [  3,  3],  5 [6 ,   t] 
13  [  8,  1],  5 

[  3,3], [6 ,1 ] 

14  [1t,  2]  "11 
15  [  6,  t],  5 

[  9,2] 
16  [  8,  1],  5 [  6,  1], 

[  9,2] 
t7  [  6,  3],  --6 [  8,  t] 

Row  number 
T-table  N-table 

1  1 
2  I 

3  2 4  2 

5  2 6  2 
7  3 8  4 
9  5 1o  6 
11  7 12  8 
13  9 t4  1o 

t5  tt 16  12 
17  13 

8 

8 
4 
4 
4 

4 

*9 
*9  6 

--6  6 

2  - -t 4 

3 9  14 
--3 
~3  

~6  
Fig.  4 
id  +  ( 

-- 3 
--  3 

- -6  

--0  --0  --0 
--t3  --13  --13 

12  13  13 
15  16  t6 

17  17 --8 

)  *  if  then  or  else  :=  _1_ 
1 
2 

3 4 

5 6 

7 8 
9 1o 
tt 
t2 
13 

10 
"10 

"12 

10 

"11 

8 
4 

--4 
11 

5  *9 5  *9  6 
--6  --6  6  --6  --6 

9  14 
5  --3  --3 
5  6  --3  --3 

T-table A  I  E  T  P  B  L 
--o 
- -t3  

--0  --0  12  t3  t3  11 
--t 3  --13  15  16  t6 

7  17  t7 --8 

--4 

N-table 
Fig.  5 

2  --14 

Efficient L R (1)  Parsers  29 
The  existence  of such  a  renumbering  of states  follows from the  fact  that  all  next 
state  entries  causing transition  to  a  particular  state  lie in  one column of the  state 

table,  namely,  the  column  corresponding  to  the  associated  symbol  of  the  state. 

The values bi can be stored in the table and c in an array element  corresponding 
to  the  column. The requirement  that  the  ai be consecutive is not compatible with 
the  renumbering  to  partition  the  state  table;  it  is  sufficient,  however,  if  the 
range  of b~ values  in  any  column is  small  compared with  the  number  of states  in 
the state table; then fewer bits are  needed to encode the  b~ than the state numbers. 

Advantage  can  only  be  taken  of  this  if  production  number  entries  can  also  be 
compactly  encoded.  It  is  not  possible,  in  general,  to  renumber  productions  so 
that  those  in  a  row  of  the  T-table  have  consecutive  numbers,  but  it  should  be 
possible  to  keep  the  range  of production  numbers  in  a  row  small  compared  with 
the  total  number  of  productions.  No  attempt  has  been  made  to  pursue  this 
possibility. 

5.  List  Representation  of  the  State  Tables 
The  motivation  for representing  state  tables  by  means  of lists  is twofold: one 
is  the  obvious  space  saving  resulting  from  the  elimination  of  blank  entries;  the 

other  is  to  exploit  the  list  searching instructions  available  on  modern  computers. 

The  IBM  System/360  "translate  and  test"  instruction,  for  example,  permits 
the  searching  of a  set,  A,  of 8 bit  characters  for the  first  occurrence of a  member 
of a  second set,  B.  Its result  is,  in  effect, either  the  index  of this  element  in A,  or 
an  indication  that  no  element  in  A  matches  an  element  in  B. 

a.1. Encoding of the T-table 
For  row  i  of  the  T-table,  two  arrays  are  constructed:  one,  TCHAR(i),  is  a 
list  of  the  valid  input  characters  for  this  row;  the  other,  TACTION(i),  is  the 
list  of  corresponding  entries  from  the  row  of  the  state  table.  Given  an  input 

character in  set  B  and  taking  TCHAR(i)  as set  A,  the  translate  and  test  instruc- 
tion  provides  either  an  index  into  TACTION(i)  for  the  appropriate  state  table 
entry  or  an  indication  that  the  input  symbol is  invalid. 

Production  number  entries  referring  to  the  same  production  often  occur 
several  times  in  a  row  of  the  T-table  (see  rows 8,  9,  13,  of  Fig.  5).  Because  error 
detection  can  be  deferred  until  after  the  stack  has  been  reduced,  it  is  convenient 

to  omit  all  entries  for  one  production  from  TCHAR(i)  and  TACTION(i)  for 
such  a  row.  Instead  a  special  code,  de/ault, representing  a  symbol  not  in  V  is 
appended  at  the  end  of the  list  TCHAR(i) and  the  production number is inserted 
in  the  corresponding  element  of  TACTION(i).  The  default  code is included  in 
set  B  for  the  translate  and  test  instruction.  For  grammars  more  complex  than 
our  example,  two  or  more  sets  of production  number  entries  may exist  in  a  row; 
one  is  chosen  for  the  default  entry  which  reduces  the  number  of  elements  in TCHAR(i) 

as much  as  possible. 
The  arrays  TCHAR(i)  and  TACTION(i)  for  all  rows/  can  conveniently 
be  stored  head  to  tail  in  arrays  TSYM  and  TACT.  Access  to  these  arrays  is 
achieved  via  an  array  TSTA TE  containing  one  entry  with 'two  fields  for  each 

30  T. Anderson  et al. : 
row i.  One  of these  fields  contains  an  index  to  the  first  elements  of  T S Y M   and 

T A C T   for  row i;  the  other  field  specifies  the  number  of  entries  in  these  arrays 
for  row i,  The  compacted  form  of  the  T-table  shown  in  Fig.  5  is  a  convenient 

form from which to build the lists. There is now the possibility of further economies 
in storage e.g.  the  only entry in row  5 of Fig.  5 is identical  to  an  entry which  must 
be  present  in  T S Y M   and  T A C T   for  row  t  ;  no  additional  space  is  needed  for  it. 

5.2.  Compacting  the  T-Table  lists 
The  general  problem  of  overlapping  the  entries  in  T S Y M   and  T A C T   from 
rows  of  the  state  tables  which  have  common  subsets  of  entries  to  economise  on 
storage  under  the  restriction  that  all  elements  of  a  row  must  lie  in  sequential 
positions  is  nontrivial;  however,  worthwhile  storage  savings  can  be  achieved 
with  relatively  simple  strategies.  Two  which  have  proved  to  be  quite  effective 

are  described. 

Let  Ai={a~l,  ai2 . . . . .   ai~}  denote  the  elements  of  T C H A R ( i )   and  Bi---- 
{b a,  bi~ . . . . .   bi,~} denote  the  corresponding  elements  of  T A C T I O N ( i ) .   Sufficient 

(though  certainly  not  necessary)  conditions  for  entries  from  two  rows  i  and  j  to 
overlap  in  the  arrays  T S Y M   and  T A C T   are 

1)  A ~ n A i ~ O ,  
2)  if  ai~ = a i z E A t n A   i then  bt~ =biz  (t0) 
3)  ai,,  and  ai, ~ are  not  both  equal  to  the  default  code. 

Since  A i =  (A t - -A i)   *  ( A t n   Ai)  and  A i =  (A i --Ai)  u  (Atc~Ai),  the  elements  of 
A t - - A   i,  then  A ~ A i ,   and  finally A i - - A  t can  be inserted  in  T S Y M   in  sequence. 

(As  each  element  a~k or  air  is  inserted  into  T S Y M ,   its  corresponding  element  bik 
or  bit  is  inserted  in  the  corresponding  position  of  T A C T ) .   Condition  3  above 
ensures  that,  after  perhaps  interchanging  the  roles  of  the  names  i  and  1',  any 
default  code is located in  the  set A i - - A  t and  this  must  be the  last element  of this 
set  to  be inserted  into  T S Y M .  

No  att empt  is  made  to  overlap  entries  from  more  than  two  states,  and  the 
pairs  of  states  are  selected  with  the  aid  of  a  triangular  matrix  C  for  which  the 
elements  are  defined  by 

Cq  =  0, for any pair of rows i  and  1" not  satisfying the  three  conditions  (10), 
C o- =  cardinality  of A i n  A i, otherwise. 

Pairs of states r  and s whose entries are to be overlapped are selected by repeatedly determining 

C,s =  max (Ct j) 
then  effectively replacing  all  entries  in  rows  and  columns  r  and  s  by  zeros,  until 
no  nonzero  element  remains  in  the  matrix  C. 

If  two  states  both  contain  default  entries,  the  conditions  for  overlapping 
their  entries include  the  requirement  that  bin ~ =  bi~s; this  seems to  be  rarely  satis- 
fied  in  practice  unless  chain  derivations  are  eliminated  when  the  technique 

described  next  is far more  effective. 

Efficient L R (t)  Parsers  3 t 
The treatment  of chain derivations was illustrated in  Section  4.t  by considering 
the  derivation  E  ~  T  ~  P  in  the  example  grammar  of  Fig.  !.  The  sets  W3", W4" 
and Ws" were seen to correspond to the states entered  after recognising E,  T  and  P 
respectively.  The  method  of constructing these  sets ensures  that  Ws" _~ W," _  W~", 

from  which  it  follows  that  the  (nonblank)  state  table  entries  for  the  state  Ws" 

are  a  subset  of those  for the  state  W4" which  in  turn  are  a  subset  of  those  for W~". 
Consequently,  in  the  list  representation,  the  entries  for both  of the  states  W3" and 
W,"  can  be  overlaid  oil  those  of  Ws". If  during  the  construction  of  state  tables, 
the  state  numbers  of  sets  of  states  like  Ws", W4" and  Ws"  are  recorded,  they  can 
be  used  to  overlay entries  in  the  arrays  T S Y M   and  TACT. 

The  procedure  below is  similar  in  intent  but  caters  for  'accidental'  inclusions 
of the  entries  of one state  within  another.  The  process involves appending  a  mark 
to  each  state;  initially  all  states  are  unmarked. 

Step 1.  An  unmarked  state  @  with  the  ma xi m u m  number  of  nonblank 
entries  is  selected;  then  the  largest  set  Qz is  computed  such  that 

Qz ~-{~[ ~  is  unmarked,  the  nonblank  entries  of  state  ~  are  included  in  those 

of 

The  r  members  of Q1 

are  arranged  in  order  of  descending  numbers  of  nonblank  entries. 

Step 2.  A  set  Q2  is  constructed.  Initially  its  only  member  is  ~/1.  For  k---- 
2,  3 . . . . .   r  in  turn,  if  the  nonblank  entries  of  ~ k   are  included  in  the  nonblank 
entries  of  each  member  of  Q,,  then  ~j,  is  included  in  Q~.  The  states  in  Q,  can 

have  their  nonblank  entries  overlaid  on  those  of  @  in  the  list  representation  of 
the  T-table.  The  members  of  Q,  are  marked  and  a  return  is  made  to  Step  1  to 

obtain  a  further  compatible  set  for overlaying. 

The algorithm terminates when all states are marked.  Note that  for m a n y  states 
"~M the  corresponding  sets  Q2 =  { ~ } .  

In  practice  this  latter  process  for  compacting  lists  has  been  applied  first  and 
the  other  technique  has  been  applied  only  to  those  states  ~9~M for  which  the  cor- 
responding  set Q~ - - { ~ } .  

&3.Encoding  o/the  N-Table 
The  encoding  used  for  the  N-table  is  basically  similar  to  that  of  the  T-table, 
using  three  corresponding  arrays  N S T A T E ,   N S Y M   and  NACT.  As  blank 

entries  in  the  N-table  can  never  be  encountered  by  the  parsing  algorithm,  the 
default  entry  technique  used in  encoding  the  T-table  m ay be  applied  to  eliminate 
a  frequently  occurring  entry  from  either  a  row  or  a  column  of  the  N-table. 

Elimination  of  chain  derivations  ensures  that  in  some rows  several  entries  are 
identical.  In  columns,  repetitions  of  the  same  next  state  can  be  expected,  since 

all  next  state  entries  leading  to  a  particular  row  originate  in  the  same  column. 
There  is  little  doubt  that  choosing  a  default  value  for  each  column  is  superior 
and  is  extremely  effective  in  reducing  the  space  requirements.  The  choice  of 

32  T. Anderson et al. : 
default  entry  is  a  value  occurring  at  least  as  often  as  any  other  in  a  column. 
An  array  N D E F   contains  the  default  value for each  column  of the  N-table,  and 
the  arrays  N S Y M   and  N A C T   contain  only  those  entries  from  a  row  which 
differ from  the  default  value  of the  corresponding  column. 

Looking up an entry in the N-table involves a search through the list in N S Y M  
which is accessed via N S T A   TE,  and,  if an entry matching  the given nonterminal 
symbol  is  found  in  N S Y M ,   the  corresponding  element  in  N A C T   is  selected, 

otherwise the  nonterminal  symbol is used  to  select an  element  from ND EF .  

Overlapping  of  entries  in  the  arrays  N S Y M   and  N A C T   is  possible;  unless 
chain  derivations  are  eliminated,  the  overall benefit here is  very much  less,  since 
the  default  entry  technique  results  in  these  arrays  being  small  compared  to 

T S Y M   and  T A C T .   The elimination of chain derivations results in columns  of the 
N-table  becoming  identical  or  in  the  nonblank  entries  of  one  colunm  becoming 
a  subset  of  those  in  another  column.  Both  conditions  are  apparent  in  Fig. 4. 

Basing  the  list  representations  on  columns  rather  than  rows  allows  appreciable 
space saving  by overlaying, but  the lengths  of the  lists  to be searched tend  to be 
longer  than  those  based  on  rows  for larger grammars.  Again,  to  keep  the  length 

of  the  lists  short,  the  N-table  representation  of  Fig.  4  is  preferred  to  that  of 
Fig.  5 as  a  basis  for  constructing  the  fists. 

6.  Implementation and  Results 
Programs  have  been  constructed  to  produce  SLR(I)  state  tables  and  to 
perform most of the transformations described, thereby enabling the effects of the 
latter  to  be  examined  when  applied  to  grammars  for  two  existing  languages, ALGOL W  and  XPL. 

ALGOL W  is  essentially  the  language  described  by  Wirth  and  Hoare  (t966). 
It is of interest here for several reasons. The language is reasonably large, contain- 
ing  all  Of  the  facilities  of  ALGOL 60  with  several  significant  extensions.  The 

compiler  constructed  at  Stanford  University  for  the  IBM 360  is  fast,  notwith- 
standing  its  three  passes,  and  produces  efficient  code.  Its  speed  is  due,  in  no 
small  measure,  to  the  parsing  method  used.  The  parser  is  based  on  the  simple 

precedence  method  of  Wirth  and  Weber  (1966),  but  it  contains  a  significant 

(unpublished)  extension  due  to  Susan  Graham  which  enables  chain  derivations to  be bypassed when  parsing simple precedence languages.  It  is largely the  capa- 

bility  of  bypassing  chain  derivations  which  accounts  for  the  well  known  speed 
of operator precedence methods and ad hoc parsers which are similar. The existing 
parser  for the  ALGOL W  compiler  is  thus  a  suitable  subject  with  which  to  make space  and  time  comparisons.  The  compiler  is  written  in  PL360  (Wirth,  t968) 

making it  trivial to  ascertain  the  existing  parsing  table  space requirements  and  a 
relatively simple  matter  to  replace  the  parser  for  timing  comparisons. 

The  X P L  compiler  (McKeeman,  Homing  and  Wortman,  t970)  uses  a  mixed strategy precedence parser with one character of lookahead. The class of grammars 

accomodated  by  this  method  is  larger  than  and  properly  includes  the  simple precedence grammars.  X P L  is of interest since Lalonde (1971)  has already replaced 
the mixed strategy precedence parser in the  X P L   compiler by an LALR(1)  parser and  reported on the  space  and  time  comparisons  of his  implementation. 

Efficient L R (1)  Parsers  33 

6.1.  Space Efficiency 
To  put  space requirements  in  context,  the  formats  used  for  array  elements 
are  described  briefly.  T S Y M   and  N S Y M   have  8 bit  elements  permitting  a  255 
symbols  vocabulary.  (Since  the  state  tables  are  split  into  a  T-table  and  an 

N-table  then  255  symbols in  each  of  Vu and  V r  are  in  fact  permitted.)  T S TA  TE 
and  N S T A T E   have  16 bit  elements  which  specify  both  a  pointer  and  a  length; 
using  t0  bits  for  the  pointer  allows  approximately  t 024  nondefault  entries  from 

each  of  the  N-table  and  the  T-table,  provided  that  no  more  than  64  entries 
occur  in  a  single  row  of  these  tables.  The  use  of  16 bit  elements  for  the  arrays TA C T,  NA C T 

and  ND EF reflects convenience of access  on  an  I B M   System/360 
rather  than  information  content.  These  elements  include  a  two  bit  field  distin- 

guishing  the  type  of  state  table  e nt r y -- n ex t   state,  production  number  or  scan- 
production  n u m be r - - a n d  an  integer  defining  either  the  next  state  or  production 

number.  As  space  is  available  within  these  elements,  the  length  of the  R HS   of  a 
production  is  included  for  production  and  scan-production  entries;  these  lengths 

could  equally  well  be  stored  in  a  separate  array,  as  indeed  the  LHS   symbols  of 
the  productions  are.  Eight  bit  entries  suffice  for  the  array  LHS. 

It  is perhaps  appropriate  to  interpolate  a  practical  comment on  the  use  of LR 
analysers.  Prograrnming  language  grammars  are  not  usually  context  free  and 
so  are  not  LR(k),  much  less  SLR(t).  While  the  lexical  analyser  and  semantic 
routines  of a  compiler can  usually  be so designed  that  an  SLR(t)  grammar repre- 

sents  the  syntax  of  a  language,  it  m a y  not  always  prove  convenient  or  possible. 
The  failure  of  a  grammar  to  satisfy  the  SLR(1)  condition  implies  that  for  one 

or  more  state-input  symbol  combinations  there  is  not  a  unique  action  in  the 

T-table.  The  list  of  possible  alternative  actions  for  one  of  these  state-input 
combinations  can  contain  at  most  one  action  of the  next  state  or scan-production 
number  type;  the  others  are  necessarily  of  the  production  number  type.  In  the 

current  implementation it is assumed that  a  semantic routine,  uniquely  associated 
with  a  particular  production,  is  invoked  whenever  a  production  number  or  scan- 
production  number  entry  naming  that  production  is  encountered.  Provided  that 

this  semantic  routine  can  determine  whether  or  not  its  associated  production 
m a y  be  applied  to  reduce  the  stack  at  this  point  in  the  parse,  such  lists  of actions 

can  be  accomodated  by  means  of  a  fourth  type  of  entry  in  the  T A C T   array, 
which  specifies  both  the  number  of  alternative  entries  and  points  to  the  first  of 

the  alternatives  in  an  array  S U P T A C T .   The  entries  in  S U P T A C T   have  the 
same  format  as  those  in  TACT.  A  next  state  or  scan-production  entry,  if  one 
exists,  is  placed  last  in  the  list  of  alternative  actions  and  is  used  only  if  no  pro- 

duction  number  entry  is  found  to  be  applicable.  The  amendment  to  the  parsing 
routine  to  deal  with  this  extension  involves  the  inclusion  of  a  flag  which  is  set 
on  encountering  an  entry  of  the  fourth  type  in  T A C T   and  which  is  reset  either 

by  a  semantic  routine  which  determines  that  its  correspo.nding  production  m ay 
be  applied  or  by  the  parsing  routine  if  the  last  entry  is  of  the  next  state  type. 

The  parsing  routine  selects  alternatives  from  the  list  passing  control  to  the 
appropriate  semantic  routines  so long  as  the  flag is  set. 

Typically, this mechanism m ay be used to handle the concept of types associated 
with  identifiers  in  m an y  programming  languages. 

3  Acta  Infonnatica,  Vol. 2 

34  T.  Anderson  et al. : 
Table t.  Storage space  for ALGOL W  and  XP L   parse  tables  with  chain  derivations partially eliminated 

ALGOL W  XPL 
Grammar Productions  t 90  t 08 
Terminal symbols  61  41 Nonterminal symbols  71  48 
Average length of production  RHS.  2.30  2.07 

SLR(t)  state tables States  330  t 83 

Entries in terminal columns  4 5 t 3  I 178 Entries in nonterminal columns  l 552  395 

States with nonunique entries  7  0 Nonunique entries  810  0 

E/leas of transforming  state tables LR(O) states eliminated  166  84 
Identical rows eliminated from  T-Table  37  23 Rows with nonunique entries eliminated from  T-Table  4  0 
Entries eliminated using  T-table defaults  2 543  731 Entries eliminated using N-table defaults  1338  325 

Entries eliminated by removing identical  T-table rows  526  146 Entries eliminated by overlaying rows in the  T-table list representation  143  53 

SLR(t)  tables in list lorm Array elements in:  TSTATE  160  99 
NSTATE  6O  39 TSYM, TACT  328  164 
NSYM, NACT  2t4  70 LHS  190  108 

NDEF  7t  48 SUPTACT  t 8  0 
Total storage requirements in bytes for: SLR(t)  parser with partial  chain elimination  2434  1 182 

Simple Precedence parser  (with complete chain elimination)  6 730  -- Mixed Strategy Precedence parser  (with  no chain elimination)  --  2962 

The  space  compactions  described  can  usefully  be  applied  to  these  extensions 
to  the  T-table.  Two  rows  of  the  T-table  can  be  merged  if  for  each  input  symbol 
there  are  identical  unique  actions  or  identical  lists  of  nonunique  actions.  In  any 
row  of  the  T-table,  a  list  of  alternatives  containing  only  production  number 
entries  m a y   be  chosen  as  the  default  entry  for the  row.  In  the  array  S U P T A C T  
lists  m a y   be  overlaid. 

Table  t  provides information  on  the  size  of the  ALGOL W  and  X P L   grammars 
together  with  details  of  the  S L R ( t )   state  tables  for  these  grammars.  The  effect 
on the tables  of the  various transformations  is indicated,  and storage requirements 

are  given  based  on  the  list  representation  data  structures  which  have  been 
described.  Finally,  for  comparison,  the  storage  requirements  of  the  existing 

parse  tables  in  the  current  ALGOL W  and  X P L   compilers  are  included.  The 
table  sizes  given  in  Table  t  result  from  using  (9)  to  partially  eliminate  chain 

Efficient  L R  (t)  Parsers  35 
Table 2.  Storage  space  for  ALGOL W  parse  tables  with  full  elimination  of  chain  derivations 

ALGOLW 
SLR(1)  state  tables 
States 
Entries in terminal columns 
Entries in nonterminal columns 
States  with  nonunique entries 
Nonunique entries 

E[]ects  o] trans]orming  state tables LR(O) 
states eliminated 
Identical  rows removed from  T-table 
Rows with  nonunique entries eliminated from  T-table 
Entries eliminated using  T-table  defaults 

Entries eliminated using N-table  defaults 
Entries eliminated by  removing identical  T-table  rows 

Entries eliminated by  overlaying rows in the  T-table list representation 

State  Tables in  List Form 
Array  elements in:  TSTATE 

NSTATE 
TSYM,  TACT 
NSYM,  NACT 

LHS 
N DEF 

SUPTACT 
Total  storage requirement in bytes: 

469 
7483 
t  556 

7 8t0 

155 

37 4 

3455 |  022 

524 
1 605 

310 61 
937 

534 t90 

7t 18 
5 523 

derivations. If no eliminations were attempted, the arrays N S  Y M   and N A C  T would 
have  contained 86 fewer elements in  the  case of ALGOL W  and  14 fewer for XPL. 

The  space  requirements  for  X P L   are  slightly  better  than  those  reported  by 
Lalonde for his implementation.  The data structures used here lead to a somewhat 
simpler parsing routine and  even without  considering elimination of chain deriva- 
tions  rather  more  optimisation  to  reduce  parsing  time  has  been  employed here. 

Table 2  provides  similar  data,  for  ALGOL W  only,  when  chain  derivations 
are  completely  eliminated.  Without  the  overlaying  techniques  of  Section 5.2, 
the  space  requirements  compared  with  partial  chain  elimination  would  have 
quadrupled,  mainly  because  the  number  of  entries  in  T S Y M   and  T A C T   have 
increased  sevenfold.  Lesser  contributions  arise  from  the  doubling  of the  number 

of states  to be recorded and  the fact that  use of default entries for columns of the 
N-table  is less effective in  saving  space.  The  overlaying techniques recover much 

of  this  extra  space  so  that  the  final  space  requirements  quoted  in  Table 2  are only about twice those of Table  I. It is clear that space requirements for languages 

with  many  operators  in  an  extensive  hierarchy  would  he  great.  On  breaking in the middle, the  12 step chain derivation for an ALGOL W  expression (by stipula- 
ting  the  existence of a  semantic  routine for the  appropriate  production)  and  then creating  parse  tables  with  full  chain  elimination  specified,  it  was  observed  that 
the  resulting  tables  had  a  space  requirement  midway  between  those  reported  in Tables 1  and  2.  Time-space  trading  is  possible  in  this  way. 

3* 

36  T. Anderson et al. : 

In  comparison  with  the  current  ALGOL W  parser,  the  SLR(t)  parser  fares 
favourably  on  space  requirements  even  when  full  chain  elimination  is  specified. 

6.2.  Time Efficiency 
The  syntax  analysis  phase  of  the  ALGOL W  compiler  was  timed  using  several 
ALGOL W  programs as input  and with  four variants of the  SLR parser substituted 
for the  existing  parser.  Since it  was  easy to  suppress  the  effects of chain  elimina- 
tion  in  the  latter,  timings  with  and  without  it  were  taken  for  comparison.  The 

performance  ranking  of  the  six  parsers  was  substantially  the  same  whichever 
program  was  used  for input.  The  results  for five  of  these  programs  are  shown  in 

Table 3 ; times are quotedin seconds and are not more accurate than 4- 0.0t seconds. 

Table 3. Time (seconds) of the syntax analysis  phase of the ALGOL W compiler  using various parsing methods 

SLR(1)  SP  SLR(t) PC  SLR(t) SC  SLR(t) C  SPC, 
Program t  0.43  0.41  0.35  0.31  0.28  0.27 Program 2  1.12  1.09  0.94  0.83  0.76  0.75 
Program 3  1.64  t.59  t.39  1,21  1.09  1.10 Program 4  2.40  2.32  2.02  1.78  1.61  1.60 

Program 5  4.07  3.92  3.42  3.02  2.76  2.75 

In  order  of increasing  speed  the  parsers  are: 

1)  SLR(t).  An  SLR(t)  parser  with  LR(O)  reduce  states  removed  but  with 
no  chain  elimination  attempted. 

2)  SP.  The  existing  simple  precedence  parser  of  the  ALGOL W  compiler  but 
with  elimination  of chain  derivations  suppressed. 

3)  SLR(t)PC.  The  parser  for  which  space  data  was  given in  Table  t.  Chains 
are  partially  eliminated  (to  the  extent  that  they  can  be  without  increasing  the 
number  of states). 

4)  SLR(I)SC.  The  parser  mentioned  at  the  end  of  the  previous  section  in 
which  the  derivation  for  an  ALGOL W  expression  was  broken  in  the  middle  but 

otherwise  chains  were  completely eliminated. 

5)  SLR(I)C.  The  parser  for  which  space  data  was  given  in  Table 2  and  in 
which  the  chain  derivations  have  been  completely eliminated. 

6)  SPC.  The  existing  ALGOL W  parser. 
The  most important  comparison is between the  SLR(I)C and  the  SPC parser. 
The  slight  difference  in  performance  between  the  two  parsers  can  be  viewed  as 
resulting  from  minor  optimisations  in  the  SPC  parser;  similar  optimisations  are 

available  within  the  SLR  framework  but  more  direct  methods  of  improving 
performance of SLR  parsers are  available and  look more promising.  For example, 
after  complete  elimination  of  chains,  overlaying  of  identical  columns  of  the 
N-table  (after  default  entries  have  been  removed)  offers  a  way  of  replacing  list 

searching  by  direct  table  look  up  without  increasing  space  requirements  enor- 
mously. 

Efficient L R (t)  Parsers  37 
The times in  the last  two  columns of Table 3 are  approximately one third  of 
the total compilation time of the programs.  In  conjunction with  the first column 

they imply that  elimination of chain derivations improves total compilation time by about t 5 %. 

The  fact  that  performance  differences between  the  SLR(I)  and  SP  parsers 
are so small merits comment; particularly since Lalonde reported that his LALR(t) 
parser  (using  software  list  searching)  produced parsing  times  which  were  about 
60%  of those given by the mixed stategy precedence parser in the XPL compiler. This difference is largely accounted for by the different ways in which the simple 

precedence and  mixed strategy precedence methods determine which  production 
to use when the stack must be reduced. The simple precedence method determines 

the  number  of symbols which  must  be  removed from the  stack--a  fact  used  by 
the  SP parser in  setting  up  a  hashing  function which  is  known  to  be  extremely 

efficient  (thereby largely  negating  the  potential  advantage  of  the  LR  methods, 
namely, knowing a priori which production to apply). In the absence of knowledge 

of the  length  of the  production, the  mixed strategy precedence method involves 
a  search  through  all  productions  with  a  final  symbol  matching  that  at  the  top 

of the stack.  Two further comments may be made.  Unpacking two bit precedence 
entries  is  expensive;  the  SP  parser  expends  3 800 bytes  to  avoid  this  penalty. 

Secondly, pressing  the  translate  and  test  instruction  into  service is  not  an  ideal 
way  of searching lists,  particularly in  view  of the  abysmal  indexing capabilities 

of the IBM System]360 character handling instructions. The overhead for search- ing short lists is high. 

In  terms  of  time  space  trade-offs,  Table 3  suggests  that  the  PC  variant 
(24t9 bytes)  gives  a  substantial  performance  improvement  for  a  modest  space premium  (258 bytes)  when  compared  with  the  straightforward  SLR(t)  parser. 

The SLR(I)SC and SLR(I)C variants with space requirements of approximately 
4000 and  5 500 bytes are less  economical. 

7.  Summary 
The  parsing  methods based  on  the  SLR(t)  algorithm  accept  a  wider  class  of 
grammars than other formal methods used at present, with consequential weaken- 
ing of constraints in choosing a grammar which conveniently reflects the semantics 

of a  language.  While  this  is  perhaps  the  major  advantage  of these  methods,  the early  detection  of  syntactic  errors  has  immediate  benefit  to  both  the  compiler 

writer and the compiler user and has potential benefit in the error recovery problem. 

The  implementation  described  here  was  deliberately  directed  towards  ex- ploiting  the  list  searching  instructions  available  on  computers  such  as  the 

Univac tt08  and  IBM 360;  it  was shown  that  in such  an  environment the  above 

advantages  can  be  obtained  with  time  and  space  efficiencies quite  comparable 
to  one  of the  better  methods  currently in  use.  The  absence  of hardware  assisted 
list  searching  does  not  necessarily imply  untenably  large  space  requirements  to achieve  high  performance.  Suggestions  for  compactly encoding the  matrix  form 

of  the  state  tables  were  made  in  passing;  also  since  typically  there  are  many states  in  the  state  table  having  only  one  or  two  entries,  mixed  matrix--list 
representations  are  possible.  If  the  early error  detection requirement is relaxed, further compaction techniques become available which have been excluded here. 

38  T. Anderson et al. : 

Finally,  given  a  particular  representation  of  the  state  tables,  the  parsing 
routine  which  utilises  them  is  independent  of  whether  the  tables  are  SLR(t), LALR(t) 

or  LR(t).  Likewise  the  table  compaction  techniques  are,  in  the  main, 
applicable  to  all  three  kinds  of  table  although  they  have  been  described  in  the 

context  of SLR(t)  tables. 

Acknowledgements. It is a pleasure to acknowledge many discussions  with E.H.  Sat- terthwaite  and  W.C. Lynch. Thanks  are  also  due to the  former and  J.M.  Rushby for 
reading drafts  of this  manuscript and  pointing out deficiencies. 

Appendix 
The  sets  first(x)  and  follow(A)  may  be  computed  from  the  definitions  given 
below. 

First  nonterminal symbols generating the  empty string are  determined  recur- 
sively using 

A=gA  iffA-->BIB~...B n,  Bi=~A,  t<i<--n,  n>~O. 
For  a  terminal  symbol x, first(x)  ={x}. 
For  a  nonterminal  symbol A 

XEfirst(A)  iff  X----A v 

A-+B~...BnYT,  Big'A,  t ~ i ~ n ,   n>=O,  XEfirst(Y) 

If ~ e  V*  then 

XEfirst(o~)  iff  ~r  XEfirst(Y)v  (Y:gA^XEfirst(fl)) 
The  sets  last (x) are  needed in  the  computation  of follow (A)  and  are  obtained 
analogously to first (x), i.e.  laa(x) ={x} 

Xelast(A)  iff  X = A  v 

A~flYB,...Bn,  Bi~A,  1~i~_n,  n>O,  X e last ( Y) 
Finally 

XEfollow(Y)  iff  3A-->flYxB 1...  BnXl~2 ,  Bi=~A,  I <_i<_n,  n>O, 

Y e last ~ ) ,   X~ first (Xl). 
.L E/ollow(Y)  iff  YElast(S) 

References 
Anderson, T. : Syntactic analysis of L R (k) languages. Ph.  D. Thesis (1972), University of Newcastle  upon Tyne. 

DeRemer,  F. L. :  Practical  translators  for  L R (k)  languages.  Ph. D.Thesis  t 969, Department  of Electrical Engineering, M. I. T. 
DeRemer,  F.L.:  Simple  LR(k)  grammars.  CACM 14,  453-460  (1971). Earley,  J.:  An  efficient  context  free  parsing  algorithm.  CACM 13,  94-t02  (t970). 

Feldman,  J.  R.,  Gries,  D. : Translator writing systems.  CACM 11,  77-1 ~3  (t968). Knuth,  D. E. :  On  the  translation  of  languages  from  left  to  right.  Information and 

Control  8,  607-639  (1965). 

Efficient  L R (1)  Parsers  39 
Korenjak,  A.:  A  practical  method  for  constructing  LR(k) processors.  CACM  12, 6t 3-623  (1969). 

Lalonde, W.R .:  Art  efficient  L AL R   parser  generator.  Tech.  Rep.  CSRG-2  (197t), University of Toronto. 
Lewis,  P.M.,  Steaxas,  R.E. :  Syntax  directed Vransduction.  JACM  lS,  465-488  (1968). McKeeman,  W.M.,  Homing,  J.J.,  Wortman,  D.B. :  A  compiler  generator.  Prentice 

Hall t970. Pager,  D. :  A  solution  to  an  open  problem  by  Knuth.  Informatiort  and  Control  14, 

462-473  (1970). Wirth,  N. :  PL360,  a  programming  language  for  the  360 computers.  JACM  15,  37-74 

(t968). Wirth,  N.,  Hoare,  C. A. R. :  A  contribution  to  the  development  of  ALGOL. CACM  9, 
4t3-432  (t966). Wirth, N., Weber, H. :  EVLER:  A  generalisation  of  ALGOL, and  its  formal  definition: 

Part  I.  CACM  9,  t3-23  (t966). 

Dr.  T.  Anderson  and  Dr.  J.  Eve Computing  Laboratory 
The  University Newcastle  upon  Tyne  NE i  7 RU 

England 

Dr.  J. J.  Homing Department  of Computer  Science, 

University of Toronto Toronto  181 
Canada 