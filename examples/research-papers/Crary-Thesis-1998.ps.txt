

TYPE-THEORETIC METHODOLOGY FOR PRACTICAL

PROGRAMMING LANGUAGES

A Dissertation
Presented to the Faculty of the Graduate School

of Cornell University
in Partial Fulfillment of the Requirements for the Degree of

Doctor of Philosophy

by
Karl Fredrick Crary

August 1998

cfl Karl Fredrick Crary 1998
ALL RIGHTS RESERVED

TYPE-THEORETIC METHODOLOGY FOR PRACTICAL PROGRAMMING

LANGUAGES

Karl Fredrick Crary, Ph.D.

Cornell University 1998

The significance of type theory to the theory of programming languages has long been recognized. Advances in programming languages have often derived from understanding that stems
from type theory. However, these applications of type theory to practical programming languages have been indirect; the differences between practical languages and type theory have
prevented direct connections between the two.

This dissertation presents systematic techniques directly relating practical programming
languages to type theory. These techniques allow programming languages to be interpreted in
the rich mathematical domain of type theory. Such interpretations lead to semantics that are
at once denotational and operational, combining the advantages of each, and they also lay the
foundation for formal verification of computer programs in type theory.

Previous type theories either have not provided adequate expressiveness to interpret practical languages, or have provided such expressiveness at the expense of essential features of the
type theory. In particular, no previous type theory has supported a notion of partial functions
(needed to interpret recursion in practical languages), and a notion of total functions and objects (needed to reason about data values), and an intrinsic notion of equality (needed for most
interesting results). This dissertation presents the first type theory incorporating all three, and
discusses issues arising in the design of that type theory.

This type theory is used as the target of a type-theoretic semantics for a expressive programming calculus. This calculus may serve as an internal language for a variety of functional
programming languages. The semantics is stated as a syntax-directed embedding of the programming calculus into type theory.

A critical point arising in both the type theory and the type-theoretic semantics is the issue
of admissibility. Admissibility governs what types it is legal to form recursive functions over. To
build a useful type theory for partial functions it is necessary to have a wide class of admissible
types. In particular, it is necessary for all the types arising in the type-theoretic semantics to
be admissible. In this dissertation I present a class of admissible types that is considerably
wider than any previously known class.

Biographical Sketch
Karl Crary was born in Madison, Wisconsin in 1971. In 1977 he moved with his family to
Seattle, Washington where he grew up. He started college at Carnegie Mellon University in
1989, and earned bachelor's degrees in Computer Science and Economics in 1993. He then
began graduate school at Cornell University where he remained until 1998.

iii

Acknowledgements
I wish to thank my parents, Fred and Betsy, for their constant love and support throughout
my childhood and adulthood. More than anyone else, they have shaped the way I see and
think about the world. I want to thank Ross Willard for introducing me to logic and modern
mathematics, and John Reynolds for introducing me to the world of type theory. I also am
very grateful to Robert Harper for serving as my undergraduate thesis advisor, for teaching me
so much, and for all his encouragement while I was his student and continuing even today.

Particular thanks go to Robert Constable, my graduate advisor, and to Greg Morrisett.
The least they did was to teach me most of the material on which this dissertation, and the
rest of my work, is based. More importantly they were a constant source of ideas, sound advice
and encouragement. I also wish to thanks Dexter Kozen for all his help and influence.

I also wish to thank all the many teachers, family and friends who helped me get where I
am today, and who made it pleasant getting here. Finally, I want to thank God for creating
the world, and for showing me the life beyond.

iv

Table of Contents
1 Introduction 1

1.1 The KML Programming Language . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.1.1 Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.1.2 Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.1.3 The Role of Type Theory in the Design . . . . . . . . . . . . . . . . . . . 3
1.2 Principals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

1.2.1 Type Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.2.2 Lambda-K . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.3 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

2 Lambda-K 6

2.1 The Core Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.2 The Module Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
2.3 Static Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2.4 Design Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.4.1 The Phase Distinction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2.4.2 Top and Bottom Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

3 Type-Theoretic Semantics 13

3.1 A Computational Denotational Semantics . . . . . . . . . . . . . . . . . . . . . . 14
3.2 The Language of Type Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

3.2.1 Domain and Category Theory . . . . . . . . . . . . . . . . . . . . . . . . . 15
3.3 A Type-Theoretic Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

3.3.1 Basic Embedding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.3.2 Embedding Recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
3.3.3 Embedding Kinds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
3.3.4 Embedding Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
3.4 Properties of the Embedding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
3.5 Prospects for Extension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

4 Foundational Type Theory 32

4.1 Nuprl . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

4.1.1 Basic Types and Operators . . . . . . . . . . . . . . . . . . . . . . . . . . 32
4.1.2 Equality and Well-formedness . . . . . . . . . . . . . . . . . . . . . . . . . 34
4.1.3 Propositions as Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
4.1.4 Equality, Subtyping and Inequality . . . . . . . . . . . . . . . . . . . . . . 35

v

4.1.5 Constructivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
4.1.6 Constructing New Types using Logic . . . . . . . . . . . . . . . . . . . . . 37
4.1.7 Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
4.1.8 Partial Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
4.2 Sequents and Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

4.2.1 Functionality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
4.2.2 Extract-Style Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
4.3 Issues in Partial Object Type Theory . . . . . . . . . . . . . . . . . . . . . . . . . 45

4.3.1 Partial Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
4.3.2 Computation in Active Positions . . . . . . . . . . . . . . . . . . . . . . . 46
4.3.3 Fixpoint Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
4.3.4 Computational Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
4.3.5 Other Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
4.4 Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

4.4.1 Type Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
4.4.2 Judgement Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
4.4.3 Classical Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

5 Admissibility 59

5.1 The Fixpoint Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
5.2 Computational Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

5.2.1 Computational Approximation . . . . . . . . . . . . . . . . . . . . . . . . 61
5.2.2 Finite Approximations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
5.2.3 Least Upper Bound Theorem . . . . . . . . . . . . . . . . . . . . . . . . . 62
5.3 Admissibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63

5.3.1 Predicate-Admissibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
5.3.2 Monotonicity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
5.3.3 Set and Quotient Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
5.3.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
5.4 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70

6 Conclusion 72
A Lambda-K Typing Rules 74
B Nuprl Proof Rules 79
C Proofs 89
Bibliography 98

vi

List of Figures

2.1 Lambda-K Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.2 Lambda-K Shorthand . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.3 Higher Order Power and Singleton Kinds . . . . . . . . . . . . . . . . . . . . . . 8
2.4 A Typical Module Encoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9

3.1 Type Theory Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.2 The Type Triangle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
3.3 Embedding Kinds and Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
3.4 Embedding Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
3.5 Embedding Signatures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.6 Embedding Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

4.1 Basic Nuprl Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
4.2 Derived Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
4.3 Operational Semantics for Nuprl . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
4.4 Primitive Nuprl Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
4.5 Type Specifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
4.6 Type Definitions (Data Types) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4.7 Type Definitions (Assertions) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4.8 Type Definitions (Set and Quotient) . . . . . . . . . . . . . . . . . . . . . . . . . 55

5.1 Admissibility, coadmissibility and monotonicity conditions . . . . . . . . . . . . . 71

vii

Chapter 1
Introduction

The distance between theory and practice is shorter in theory than in practice.

--Unknown

The development of practical programming languages has lagged far behind the state-of-theart of theoretical programming language study. Examples abound of programming language
techniques and methods that have been well known and understood for years, but still have yet
to appear in any practical programming system. This can be frustrating to the programming
language theoretician who also writes code, and that frustration is not diminished by the
knowledge that the gap between theory and practice is common to many, if not most, fields of
study.

The main reason that the gap between theory and practice is often so wide is the issue
of elegance. Programming languages can admit extremely elegant theoretical study. This
elegance is partly responsible for the rapid progress of results in theoretical programming languages, and it is partly responsible for the attractiveness of programming languages as a field
of study. However, such elegance is usually achieved by abstracting away from the details of
real languages--details that are essential for real languages to be usable.

In my thesis research, I set out to design and implement a practical programming language
to incorporate unutilized developments in programming language theory. The result was a
dialect of ML that came to be called KML. Not surprisingly, I was soon grappling with the
elegance gap between theory and practice. To manage the complexity of a real system, I allowed
type theory to drive the design. That is, I adopted the strategy of choosing, at every design
point, an option that was easily represented and justified in an underlying foundation of type
theory.

This strategy proved remarkably effective, and resulted in a language design that was versatile and powerful but also relatively simple. However, allowing type theory to drive the design
of KML paid another dividend, which had wider applications than to the KML language alone.
The type-theoretic design of KML led me to explore not only how type theory can motivate
language design informally, but also to explore how (and why) to draw formal connections
between practical programming languages and foundational type theory.

This dissertation focuses on the latter aspect of my thesis research, formal connections
between practical programming languages and foundational type theory. In this thesis we will
see various specific applications of such connections, but from a broader standpoint the aim
of the work I discuss here is to draw theory and practice closer together. The constructs that
make up type theory are powerful and uniform, making it possible to reason about issues facing
real languages without sacrificing elegance.

1

1.1 The KML Programming Language
A complete discussion of the KML programming language is beyond the scope of this dissertation. I give here a brief and informal introduction to KML and its contributions.

1.1.1 Features
The main objective of KML was first to incorporate into a practical dialect of the ML programming language a number of useful language features not present in preceding dialects of
ML while building the entire language on a solid theoretical foundation. KML is structured to
greatly resemble Standard ML; for the most part, Standard ML is a strict subset of KML. The
differences between KML and Standard ML lie in the way KML is specified, and in the additional language features supported by KML: object-oriented programming, subtyping, a more
expressive module system and first-class polymorphism. These features are chosen because they
can assist in a real and practical way with the task of programming.

A KML compiler is implemented that consists of a KML-specific front end, which compiles
KML to an intermediate language based on the polymorphic lambda calculus, and a back end
that compiles that intermediate language to Typed Assembly Language [77, 76].

At the time of this writing, the design of KML is substantially complete but is still changing
in a number of areas. Therefore, the reader should take the following descriptions of KML's
features as tentative.

Objects Object-oriented programming is supported in KML through a primitive object calculus [31] that is substantially similar to that of Abadi and Cardelli [1, 2]. Objects are seen as
collections of method functions, each of which takes the entire object as an argument and computes a result [58]. A method's results may be a new object of the same type; such results are
usually produced by updating one of the fields of the object with a new method implementation.

In the present design, primitive objects are the extent of the support for object-oriented
programming. From primitive objects it is possible to code more complicated artifices like
classes and inheritance. I plan built-in syntactic support for classes and inheritance in a future
version of the design.

Subtyping The KML type system completely integrates support for subtyping. Subtyping
arises by dropping methods from objects and fields from records, and also from stated definitions. Definitional subtyping happens in bounded quantification, where code is written to be
polymorphic over all types that are subtypes of a given type, and in abstract subtyping, where
a type in a module is specified to be a subtype of some other type. KML allows unrestricted
subsumption, that is, a member of a subtype may always be used in place of a member of the
supertype without any mediating syntax such as a coercion.

Expressive Modules The KML module system builds on the module system of Standard
ML with two main enhancements. The first is higher-order functors. While Standard ML
functors may take and return only structures, the KML module system allows functors to take
other functors as arguments and return functors as results. Thus, the KML module system is
fully featured typed lambda calculus.

The second enhancement is to allow type definitions in signatures. Allowing type definitions
in signatures, combined with a type system that leaks no type information in the absence of
such definitions, allows so-called "translucent" modules, modules that leak exactly the desired

2

amount of type information. Translucent modules allow the greatest amount of abstraction
possible in a system, while still permitting enough leakage to link modules together.

First-Class Polymorphism Most dialects of ML, including Standard ML, restrict polymorphic terms so that they cannot be placed into data structures, passed to functions or returned
by functions. (Formally, this restriction stems from a prenex restriction on quantified types:
quantifiers must appear all the way out, which means that quantified types cannot make up a
component of any larger type.) Thus, polymorphic values are not first class; they must always
be instantiated before they may be used. In contrast, polymorphic values in KML are first
class; they may be arguments or results of functions and may be stored in data structures.

KML also permits polymorphic recursion [78], where a polymorphic function calls itself
recursively with a different type argument. Polymorphic recursion is necessary to make good
use of first-class polymorphism (otherwise all type arguments are statically predetermined), but
it is also useful in other contexts [79].

1.1.2 Comparison
During the time I was developing KML, Xavier Leroy and his colleagues released the Objective
CAML system [64]. Objective CAML shares many of the same goals as KML, in particular
the goals of providing support for object-oriented programming and a more expressive module
system. However, Objective CAML does not support first-class polymorphism and possesses
no formal semantics or definition.

The greatest similarity between KML and Objective CAML lies in the module systems,
which provide almost identical expressiveness, despite various technical differences. A greater
contrast exists in the object system. The object system of KML is derived from the object
calculus of Crary [31], which derives its lineage from the object systems of Abadi and Cardelli
[1, 2] and their predecessors. In contrast, the object system of Objective CAML is based on the
object system of R'emy and Vouillon [85], which derives its lineage from the record extension
calculi of R'emy [84].

The greatest practical difference between the object systems of KML and Objective CAML
lies in support for subtyping. Unlike KML, Objective CAML provides no automatic subsumption; objects must be coerced to supertypes by an explicit coercion. However, by abandoning
subtyping with subsumption, Objective CAML is able to enjoy feasible type inference, which
is prohibitively difficult for KML. Moreover, in many cases the practical benefits of subtyping
are obtained in Objective CAML by quantification over row variables that extend object types
to unspecified supertypes (details appear in R'emy and Vouillon [85] and Leroy [64]).

1.1.3 The Role of Type Theory in the Design
In order to produce an elegant and coherent design for KML, I allowed type-theoretic considerations to drive the design. In order to convey the flavor of this interaction, I briefly describe
two design points that were informed by type theory.

In a module calculus, one important issue to settle is the equational theory: under what
circumstances are modules and components of modules considered equal to others. The definition of Standard ML [71] employed a system of unique stamps to dictate when two modules
were considered equal. This system becomes even more involved when extended to higher-order
modules [66]. In KML, I simplified the equational theory by eliminating equality of modules
in favor of equality of the types that make up those modules (a similar choice was made for

3

Standard ML (Revised) [72]), and then ruling that types are equal exactly when equivalence
may be proven from stated type definitions in a logic of types. (Leroy made a similar decision
in the design of the Objective CAML module system.)

Another key design point was what form support for object-oriented programming should
take. Rather than begin with a source level system of objects or classes, I focused on the typetheoretic interpretation of objects. With an theory of objects in hand, I worked backwards
to the KML object calculus. The result was an object system with comparable power to that
of Abadi and Cardelli [1, 2], but with a simpler theory and a more efficient implementation.
Details appear in Crary [31].

1.2 Principals
1.2.1 Type Theory
One may view foundational type theory as being, at its core, a typed functional programming
language with a very rich type system. That type system is capable of expressing complex
relationships between objects; sufficiently complex, that it may encode (almost) any sentence
in logic and mathematics. In this way, type theory may serve as a foundation for mathematics
and computation.

To some degree, this view reflects the bias of a computer scientist. Type theory has been
used as a foundation for mathematics since before the advent of modern computers; for instance,
Whitehead and Russell's influential 1910 treatise Principia Mathematica [96] was a type theory
in some ways similar to the type theory of this dissertation. Nevertheless, type theory has been
particularly successful as a foundation for computer science. This is largely because type theory
deals elegantly with structured data and computation (the "stuff" of computer science), which
must be painstakingly constructed in most other foundational frameworks.

The particular type theory I use in this dissertation is a variant of the Nuprl type theory
[19]. Nuprl traces its lineage back to Martin-L"of's Intuitionistic Type Theory [67], which was
first intended to clarify the syntax and semantics of intuitionistic mathematics. The Nuprl
type theory adapted Intuitionistic Type Theory as a foundation for computer programming by
simplifying its structure and adding a number of new type constructors. Although my results
are stated in the context of the Nuprl type theory, my intention is that the methodology behind
those results be applicable to type theories in general.

1.2.2 Lambda-K
In order to manage the complexities of a real programming language, KML is defined in terms
of a smaller internal language called *K. Lambda-K provides all the expressiveness of the full
KML language, but is considerably simpler and more elegant, because many of the complex
constructs of KML are broken up by the definition into simpler constructs in *K.

The main thrust of this dissertation, then, is an exploration of how to draw formal connections between the internal language *K and the Nuprl type theory. These formal connections
then apply back to the high-level language KML by way of its definition. However, I wish to
view the KML particulars as only a case study in the general methodology I explore. Similar
results can be drawn for other languages; for example, Harper and Stone [48] give an interpretation of Standard ML in terms of an internal language very much like *K. Thus, with some
minor modifications, my results would apply to Standard ML as well. Accordingly, I do not

4

present the formal definition of KML in *K in this dissertation; to do so would unduly focus
on the particulars and distract from the broader methodology.

The Nuprl type theory is predicative, so in order to draw formal connections to Nuprl from
*K, it is necessary for *K to be predicative as well. However, the *K used in defining KML
is not predicative. Consequently, in this dissertation I use a predicative variant of *K that
drops a number of features. Recursive types, stateful computation and objects all depend on
impredicativity in some way, and are regrettably omitted. Restoring these is an important
avenue for future research, and I discuss some possible ways it might be done in Section 3.5.

1.3 Overview
After this introductory chapter, the technical material commences in Chapter 2 with an exposition KML's internal language *K. In keeping with the view of *K as a case study, that
chapter is brief. The primary original contribution of *K is a module calculus that combines
contributions from the translucent sums calculi of Harper and Lillibridge [44] and Leroy [62],
the phase-distinction calculus of Harper, Mitchell and Moggi [46], and the applicative functors
calculus of Leroy [63].

Chapter 3 begins with an informal description of the Nuprl type theory, and then continues
with an embedding of *K into Nuprl, the first of the three main technical contributions of this
dissertation. That embedding provides a type-theoretic semantics of *K, and thereby draws a
sharp formal connection between KML and type theory. I also discuss at length the applications
and some of the consequences of the semantics.

In Chapter 4 I discuss in detail my variant of the Nuprl type theory, the second main technical contribution of this dissertation. This type theory is the first constructive type theory to
include an intrinsic notion of equality and also to allow reasoning about both partial and total
functions. All three notions are necessary to give an adequate account of practical programming languages; partiality is clearly necessary for Turing-complete languages, and equality and
totality are necessary to say anything interesting about such languages once interpreted. I also
discuss practical issues that arise when using a type theory incorporating partiality. Finally, I
give a rigorous semantics to the type theory and show its consistency.

Central to the type theory is a fixpoint rule for typing recursive functions. However, the
fixpoint rule is not valid for recursive functions on every type. Types for which the fixpoint
rule is valid are known as admissible. In Chapter 5 I give general techniques for showing
types to be admissible, the third main technical contribution of this dissertation. Before this
work, type theories incorporating partiality were handicapped by a dearth of types known
to be admissible. A critical step in the method is a elegant least upper bound theorem for
computational approximation with applications beyond the admissibility results to which I
apply it.

Concluding remarks appear in Chapter 6. Following my concluding remarks, the dissertation
closes with three appendices. Appendix A gives the complete typing rules for *K. Appendix
B gives the complete inference rules for Nuprl proofs. In the interest of readability throughout
the dissertation, difficult proofs are removed to Appendix C.

5

Chapter 2
Lambda-K
The KML programming language provides a very expressive language for practical programming. However, experience with Standard ML has shown that although direct formal definitions of practical programming languages may be written [71, 72], those definitions are too
unwieldy to be very useful except as a language specification for compiler implementers and
are particularly impractical for theoretical study.1 Simple languages are much more practical
for theoretical study, and are useful in implementations as well: The first step of a compiler is
typically to elaborate the external language into a simpler intermediate language.

In order to use a simpler and more manageable language than full KML, in this thesis I
will be using a simple typed calculus called *K. A framework that proved to be workable
was to augment the higher-order polymorphic lambda calculus, F! [35, 36], with power [17, 18]
and singleton [41] kinds, dependent function and record kinds, and strong sums. This design is
discussed at length in this chapter.

The syntax of *K is defined by the rules given in Figure 2.1 and consists of five syntactic
classes. The class of terms contains the basic constructs of the polymorphic lambda calculus
with records. The class of type constructors (which I will usually refer to as "constructors")
contains the types of well-formed terms and a lambda calculus (with records) built over them for
computing types. (Typical type constructors are actual types, such as integers, or (first-order)
type operators, such as lists.) The class of kinds then contains the "types" of type constructors.
The two remaining classes, modules and signatures, contain the terms and types of *K's module
system. The static semantics of *K also uses contexts, which assign kinds, types and signatures
to constructor variables (ranged over by ff), term variables (ranged over by x) and module
variables (ranged over by s). Figure 2.2 contains several convenient abbreviations for use with
*K.

Throughout this thesis, in any calculi with binding structure (such as *K), I consider two
expressions to be identical if they differ only by alpha-variation. When two expressions e1 and
e2 are alpha-equal I write e1 j e2. Also, the simultaneous capture-avoiding substitution of
expressions e1; : : : ; en for variables x1; : : : ; xn in e will be denoted by e[e1 \Delta  \Delta  \Delta  en=x1 \Delta  \Delta  \Delta  xn].

1The Definition of Standard ML [71] runs to 65 pages and consists of 196 rules (plus many additional implied
rules for propagating exception packets) and considerable supporting machinery. The revised Definition [72] is
simpler, but still runs to 54 pages and 189 rules.

6

kinds ^ ::= Typei j \Pi ff:^1:^2 j f`1 . ff1 : ^1; : : : ; `n . ffn : ^ng j Pi(c) j Si(c)
constructors c ::= ff j *ff:^:c j c1[c2] j f`1 = c1; : : : ; `n = cng j ss`(c) j c1 ! c2 j c1 ) c2 j

8ff:^:c j f`1 : c1; : : : ; `n : cng j h`1 : c1; : : : ; `n : cni j ext(m)
terms e ::= x j *x:c:e j e1e2 j \Lambda ff:^:e j e[c] j f`1 = e1; : : : ; `n = eng j ss`(e) j inj `(e) j

case(e; `1 . x1: e1; : : : ; `n . xn: en) j fix c(e) j ext(m)
signatures oe ::= h^i j hhcii j \Pi s:oe1:oe2 j f`1 . s1 : oe1; : : : ; `n . sn : oeng
modules m ::= s j hci j hheii j *s:oe:m j m1m2 j f`1 = m1; : : : ; `n = mng j ss`(m) j m : oe
contexts \Gamma  ::= ffl j \Gamma [ff : ^] j \Gamma [x : c] j \Gamma [s : oe]

Figure 2.1: Lambda-K Syntax

o/1 \Theta  \Delta  \Delta  \Delta  \Theta  o/n def= fl1 : o/1; : : : ; ln : o/ng

he1; : : : ; eni def= fl1 = e1; : : : ; ln = eng

ssi(e) def= ssli(e)
o/1 + \Delta  \Delta  \Delta  + o/n def= hl1 : o/1; : : : ; ln : o/ni

inj i(e) def= inj li(e)
case(e; x1:e1; : : : ; xn:en) def= case(e; l1 . x1: e1; : : : ; ln . xn: en)

(where l1; l2; : : : are distinguished labels)

Figure 2.2: Lambda-K Shorthand

2.1 The Core Calculus
The type system of *K includes functions and records at the term and constructor levels, and
polymorphic functions at the term level, using the standard notations. Evaluation is intended
to be call-by-value. Records of terms, record types, and records of constructors that differ
only in field order are considered identical. The type of functions from o/1 to o/2 is denoted by
o/1 ! o/2; functions that return without computational effects are considered pure functions and
may be given the pure function type o/1 ) o/2 (for appropriate o/1 and o/2). The type system also
includes the labelled disjoint union type, denoted by h`1 : c1; : : : ; `n : cni, members of which are
formed by inj `(e) and eliminated by case(e; `1 . x1: e1; : : : ; `n . xn: en). As with records, disjoint
union types or case expressions that differ only in field order are considered identical. Recursive
functions are supported in the standard way by a fix operator. The remaining construct, ext (m),
deals with the module calculus and is discussed in Section 2.2.

A subtyping relation is defined over the types of *K. Intuitively, o/1 is a subtype of o/2
(denoted o/1 _ o/2) when every term belonging to o/1 also belongs to o/2. As usual, functions are
contravariant on the left and covariant on the right; records are covariant in the field types and
subtypes are produced by adding fields. Pure function types are subtypes of the corresponding
function types.

Kinds The kind level is more novel. Ignoring the i annotations, Type contains well-formed
types. The power kind, denoted by P(o/ ) for any type o/ , contains well-formed types that are
subtypes of the given type o/ . The singleton kind, denoted by S(o/ ) for any type o/ , contains
well-formed types that are equivalent to the given type o/ . The level annotations i, which are
positive integers, restrict the memberships of these kinds. The level of a kind or type is defined
to be the highest level annotation appearing within it. The kinds Typei, Pi(o/ ) and Si(o/ ) contain

7

R(c : Typei) def= Ri(c)
R(c : ^1 ! ^2) def= \Pi ff:^1:R(c[ff] : ^2)
R(c : f`i : ^i[i=1:::n]g) def= f`i : R(ss`i(c) : ^i)[i=1:::n]g

(R represents either P or S)

Figure 2.3: Higher Order Power and Singleton Kinds

only types with levels less than i. Thus, types belonging to Type 1 cannot contain quantify over
any (nontrivial) kinds, and types belonging to Type2 can only quantify over level-1 kinds. For
Pi(c) or Si(c) the level of c must be less than i.

This level annotation mechanism makes *K predicative, which is necessary to perform Chapter 3's embedding into the predicative type theory of Nuprl. Since these annotations are tedious
to provide, I discuss some alternatives in Section 3.5. In a practical system based on this annotation mechanism, the system would have to infer level annotations for the user [47].

The kind of functions mapping constructors of kind ^1 to constructors of kind ^2 may be
denoted ^1 ! ^2, but since constructors may appear within kinds, it is desirable to allow a more
precise characterization of such functions: The kind \Pi ff:^1:^2 includes all functions mapping
^1 constructors to ^2 constructors where ff stands for the function's argument and may appear
free in ^2. Such kinds are referred to as dependent function kinds since the result kind depends
on the argument. For example, a function with kind \Pi ff:Type i:Pi(ff) when applied to any type
o/ returns a constructor of kind Pi(o/ ), that is, a subtype of o/ . The independent function kind
^1 ! ^2 is shorthand for \Pi ff:^1:^2 when ff does not appear free in ^2.

Records of type constructors may also be given dependent kinds. The kind f`1 . ff1 :
^1; : : : ; `n . ffn : ^ng contains all records f`1 = c1; : : : ; `n = cng such that each ci has the
corresponding kind ^i with the values of preceding fields substituted for the free variables.
That is, ci must have kind ^i[c1 \Delta  \Delta  \Delta  ci\Gamma 1=ff1 \Delta  \Delta  \Delta  ffi\Gamma 1]. The external labels (ranged over by `)
must be kept distinct from the internal binding occurrences because variables must alpha-vary
but labels must not.2 This is discussed in greater length in Harper and Lillibridge [44]. As a
shorthand, I will often omit . ff (pronounced "as alpha") from a dependent record kind when
ff does not appear free in the following kinds; an independent record kind is one that contains
no internal binding occurrences at all. I consider two dependent record kinds to be identical
when they differ only in field order, so long as no field is reordered to appear after a field that
depends upon it.

Although power and singleton kinds are made using only types (not higher-order constructors), dependent kinds may be used to build higher-order power and singleton kinds. For
example, the kind \Pi ff:Typei:Pi(list [ff]) includes type constructors that are pointwise subtypes
of list. Higher-order power and singleton kinds may be generally defined as in Figure 2.3.

Just as a subtyping relation was defined over the types, a subkinding relation is defined over
the kinds. This relation is denoted by ^1 _ ^2 when ^1 is a subkind of ^2. Function and record
kinds obey similar rules to the subtyping rules. Additional subkinding relationships result from
level annotations, Typei _ Typei+1 (and likewise for singleton and power kinds), and from
power and singleton kinds: for any type o/ , Si(o/ ) _ Pi(o/ ) _ Typei, and also Pi(o/1) _ Pi(o/2)
when o/1 _ o/2.

2These two names may be burdensome for a programmer to supply, so, as a practical matter, in KML it is
permitted to write one name for use as both the internal and the external name; this poses no problems so long
as it is possible to use separate names when they are needed [44].

8

sig

tycon foo : type
module S1 :

sig

tycon bar : type
tycon baz = foo -? bar
val gnurf : baz
end
val blap : S1.bar
end

=)

f foo . sfoo : hTypei;

S1 . sS1 :

f bar . sbar : hTypei;

baz . sbaz : hS(ext(sfoo) ! ext(sbar))i;
gnurf : hhext(sbaz)ii g;
blap : hhext(ssbar(sS1))ii g

struct

tycon foo = int -? int
module S1 =

struct

tycon bar = int
tycon baz =

(int -? int) -? int
val gnurf =

fn f : int -? int =? f 0
end
val blap = 12
end

=)

f foo = hint ! inti;

S1 =

f bar = hinti;

baz = h(int ! int) ! inti;
gnurf = hh*f:(int ! int): f 0ii g;
blap = hh12ii g

Figure 2.4: A Typical Module Encoding
2.2 The Module Calculus
Lambda-K modules form their own syntactic class, and their types are called signatures, which
also form their own syntactic class. A primitive module is either a single constructor hci or a
single term hheii. If c has kind ^, then hci has signature h^i. Likewise, if e has type o/ , then hheii
has signature hho/ ii.

Modules are also formed using lambda-abstractions (for functors) and records (for structures). Such modules may be given dependent function signatures and dependent record signatures that are precisely analogous to the dependent function and dependent record kind
discussed above. Data abstraction is achieved by forgetting type information using the construct m : oe, which coerces the module m to have the signature oe (if that signature is valid
for m); any type information about m not reflected in oe is forgotten. As with the subtyping
and subkinding relations over the types and kinds, the signatures have a subsignature relation,
which obeys rules similar to the rules governing subtyping and subkinding.

Modules are used within the core calculus by means of the extraction construct: ext (m) for
module m. If m has signature h^i, then the constructor ext (m) has kind ^. Likewise, if m has
signature hho/ ii then the term ext (m) has type o/ . Exactly what modules are legal to extract
from is an issue that is discussed in Section 2.4.1.

With the above constructs, it is easy to encode high-level KML modules. A KML structure
is constructed by building a record out of its contents with every constructor field encased in h\Delta i
and every term field encased in hh\Delta ii. Figure 2.4 shows the encoding of a typical KML module
with a substructure into *K. Note the use of an internal and an external name in the encoding
of the blap field of the signature. Functors and their signatures are encoded using * and \Pi  in
the obvious manner.

Since modules form their own syntactic class and are not reflected directly into the core
calculus, *K modules are second-class. This decision is based on issues related to the phase

9

distinction (Section 2.4.1). To permit first-class modules would require considerably different
approaches to these issues that would reduce the expressiveness of the calculus, as we will see
shortly. Fortunately, the first-class module restriction does not seem to be an onerous one: the
most commonly cited use for a first-class module, the ability to select at run-time an efficient
implementation, can be achieved using existential types [73] or objects.

2.3 Static Semantics
The static semantics of *K appears in Appendix A. Nine judgements are used; six for the core
calculus and three for the module calculus:

1. The kind equality judgement \Gamma  `K ^1 = ^2 indicates that ^1 and ^2 are equal (in context

\Gamma ).

2. The subkinding judgement \Gamma  `K ^1 _ ^2 indicates that every constructor in ^1 is in ^2,

as discussed previously.

3. The constructor equality judgement \Gamma  `K c1 = c2 : ^ indicates that c1 and c2 are equal

as members of kind ^.

4. The subtyping judgement \Gamma  `K c1 _ c2 indicates that every term in c1 is in c2.
5. The typing judgement \Gamma  `K e : c indicates that the term e has the type c.
6. The valuability judgement \Gamma  `K e # c indicates that the term e has the type c and that

its computation terminates.

7. The subsignature judgement \Gamma  `K oe1 _ oe2 indicates that every module in oe1 is in oe2.
8. The module signature judgement \Gamma  `K m : oe indicates that the module m has signature

oe.

9. The module valuability judgement \Gamma  `K m # oe indicates that the module m has signature

oe and that its computation terminates.

Four additional judgements are derived from these nine. A kind is considered well-formed
when it is equal to itself, and similarly a constructor belongs to a kind exactly when it is equal
to itself in that kind. A type or signature is well-formed when it is a subtype or subsignature
of itself.

\Gamma  `K ^ kind def= \Gamma  `K ^ = ^

\Gamma  `K c : ^ def= \Gamma  `K c = c : ^
\Gamma  `K c : type def= \Gamma  `K c _ c

\Gamma  `K oe sig def= \Gamma  `K oe _ oe

2.4 Design Issues
2.4.1 The Phase Distinction
An important decision to be made in the design of any module calculus is how to account
for the phase distinction between compile-time and run-time expressions [16, 46, 44]. In the

10

absence of the module calculus, it is easy to say that the evaluation of type constructors
is a compile-time activity and the evaluation of terms is a run-time activity. However, the
module system presents a quandary since modules may contain terms and type constructors
may contain modules (through the extraction construct). Constructor evaluation cannot be a
run-time activity, unless we are willing to sacrifice type checking at compile time, but term
evaluation clearly cannot be a compile-time activity.

The central problem is how to structure the module system and its interactions with the core
calculus so that compile-time expressions (kinds and constructors) do not contain possibly divergent or effectful expressions. I discuss here two solutions to the problem: the phase-splitting
approach proposed by Harper, Mitchell and Moggi [46] and the value restriction approach proposed by Harper and Lillibridge [44] and Leroy [62]. Lambda-K makes use of the phase-splitting
approach.

In the phase-splitting approach, modules (including functors) are considered to consist of
two components: a compile-time component and a run-time component. The compile-time
component deals only with the constructor portions of modules while the run-time component
deals also with the term portions. Then extraction at the constructor level depends only on
the constructor portion of a module; any problematic behavior of the module's term portion
is irrelevant. This approach depends on designing the module calculus so that it is impossible
to write a module where a constructor field depends on any run-time computation; otherwise
constructor fields are run-time computations themselves and cannot be phase split into the
compile-time component.

In a system with first class modules, it is easy to construct a module that depends on the
result of a term expression, which rules out the phase-splitting approach. In their translucent
sum calculus [44], which has first class modules, Harper and Lillibridge enforce the phase
distinction more directly: Syntactic values have no interesting run-time behavior and may
therefore safely be treated as compile-time expressions. Extraction at the constructor level is
restricted to only valuable expression; arbitrary module expressions are not legal for extraction.

The phase-splitting approach also has some advantages that counterbalance the impossibility
of first-class modules: First, phase-splitting provides a convenient mechanism for implementing
the module system [46]. Second, phase-splitting allows greater flexibility in references from
the core language into the module language. For example, phase-splitting allows extraction
from functor applications, which is forbidden by the value restriction approach. This can be
quite useful in practice; for example, it allows the expression of transparent signatures for
functors [63], that is, signatures that completely specify the (type) behavior of the functor. For
example, suppose s has signature \Pi s0:oe:hTypei. Then the alternative signature \Pi s0:oe:hext (s s0)i
fully specifies the behavior of s, but this signature is valid only if it is permissible to extract
from functor applications. Leroy [63] discusses this issue at length.

2.4.2 Top and Bottom Types
Unlike many subtyping calculi, *K does not have top and bottom types. This is not because
they are problematic to add (they are not), but because a practical language is better off
without them. The main use for top and bottom is usually to ensure that there exist meets
and joins for any two types, but it is really only important to ensure that joins and meets exist
for types that have an upper or lower bound. In cases where two types have no upper (or
lower) bound, it is preferable to generate an error than to allow an artificial top (or bottom)
bound. For example, a program fragment if b then 12 else true is almost certainly a
mistake. Similarly, a function that makes incompatible demands on its argument could be

11

given a bottom domain type, but again such a useless function is certainly a mistake. It is
better the notify the programmer of the mistake immediately than to allow the trivial type and
postpone the error message, delivering it somewhere else instead of at the location where the
mistake was made.

The drawback of this design decision relates to expressions with side-effects. When an
expression is evaluated for side-effects, it is not uncommon to ignore the result value. In *K
this must be done explicitly, as in the code if b then f x; () else g x; (), where f and
g have incompatible return types. If the language included a top type, the programmer could
write the marginally simpler if b then f x else g x. However, even in very impure code, it
is not likely that allowing top and bottom would save effort for the programmer in this manner
nearly as often as disallowing them would save effort by catching mistakes. Additionally, writing
code to ignore result values explicitly provides useful documentation.

12

Chapter 3
Type-Theoretic Semantics
Type theory has become a popular framework for formal reasoning in computer science [22, 67,
37] and has formed the basis for a number of automated deduction systems, including Automath,
Nuprl, HOL and Coq [32, 19, 39, 8], among others. In addition to formalizing mathematics,
these systems are widely used for the analysis and verification of computer programs. To do
this, one must draw a connection between the programming language used and the language of
type theory; however, these connections have typically been informal translations, diminishing
the significance of the formal verification results.

Formal connections have been drawn in the work of Reynolds [86] and Harper and Mitchell
[45], each of whom sought to use type-theoretic analysis to explain an entire programming
language. Reynolds gave a type-theoretic interpretation of Idealized Algol, and Harper and
Mitchell did the same for a simplified fragment of Standard ML. Recently, Harper and Stone [48]
have given such an interpretation of full Standard ML (Revised) [72]. However, in each of these
cases, the type theories used were not sufficiently rich to form a foundation for mathematical
reasoning; for example, they were unable to express equality or induction principles. On the
other hand, Kreitz [59] gave an embedding of a fragment of Objective CAML [64] into the
foundational type theory of Nuprl. However, this fragment omitted some important constructs,
such as recursion and modules.

The difficulty has been that the same features of foundational type theories that make
them so expressive also highly constrain their semantics, thereby restricting the constructs that
may be introduced into them. For example, as I will discuss below, the existence of induction
principles precludes the typing of fix that is typical in programming languages. In this chapter
I show how to give a semantics to practical programming languages in foundational type theory.
In particular, I give an embedding of *K into the Nuprl type theory. This embedding is simple
and syntax-directed, which has been vital for its use in practical reasoning.

The applications of type-theoretic semantics are not limited to formal reasoning about
programs. Using such a semantics it can be considerably easier to prove desirable properties
about a programming language, such as type preservation, than with other means. We will see
two such examples in Section 3.4. The usefulness of such semantics is also not limited to one
particular programming language at a time. If two languages are given type-theoretic semantics,
then one may use type theory to show relationships between the two, and when the semantics are
simple, those relationships need be no more complicated than the inherent differences between
the two. This is particularly useful in the area of type-directed compilation [93, 75, 61, 43, 77].
The process of type-directed compilation consists of (in part) translations between various typed
intermediate languages. Embedding each into a common foundational type theory provides an

13

ideal framework for showing the invariance of program meaning throughout the compilation
process.

This semantics is also useful even if one ultimately desires a semantics in some framework
other than type theory. Martin-L"of type theory is closely tied to a structured operational
semantics and has denotational models in many frameworks including partial equivalence relations [5, 40], set theory [54] and domain theory [87, 81, 80]. Thus, foundational type theory
may be used as a "semantic intermediate language."

3.1 A Computational Denotational Semantics
My main motivation for a type-theoretic semantics has been to draw formal connections between programming languages and type theory, thereby making type theory a powerful tool for
reasoning about languages and programs without sacrificing any formality. However, a typetheoretic semantics is also valuable in its own right as mathematical model of a programming
language.

Most programming language semantics are either operational or denotational. A typical
operational semantics is specified by giving an evaluation relation on program terms (or an
evaluation relation on some abstract machine along with a translation into that machine).
Operational semantics have the advantage that they draw direct connections to computation,
and explaining how programs compute is one of the prime functions of a semantics. However,
operational semantics are typically rather brittle; a slight addition or change to an operational
semantics often requires reworking all proofs of properties of that semantics.

In contrast, a denotational semantics specifies, for every program term, a mathematical
object that the program term denotes. Typically a term's denotational is determined by composing in some way the denotations of its subterms. The compositionality of denotational
semantics usually makes them more robust to change than a typical operational semantics.
Furthermore, the equational theory of a denotational semantics is easier to work with since it
derives directly from the mathematical objects, without need for an intermediating evaluation
relation, and without needing to consider any surrounding context. However, the connection to
computation in a typical operational semantics (although present) is much more remote than
with an operational semantics.

A denotational semantics in type theory provides the advantages of both a denotational
semantics. The type-theoretic semantics I present is denotational, and accrues all the attendant
advantages of a denotational semantics, but type theory is in essence a programming language
itself (with its own operational semantics), so this semantics also draws a strong connection to
computation.

3.2 The Language of Type Theory
I begin with an informal overview of the programming features of the Nuprl type theory. It
is primarily those programming features that I will use in the embedding. The logic of types
is obtained through the propositions-as-types isomorphism [51], but this will not be critical to
our purposes in this chapter. I present and discuss the type theory in detail in Chapter 4.

As base types, the theory contains integers (denoted by Z), booleans1 (denoted by B ),
strings (denoted by Atom), the empty type Void , the trivial type Unit, and the type Top (which

1Booleans are actually defined in terms of the disjoint union type.

14

contains every well-formed term, and in which all well-formed terms are equal). Complex types
are built from the base types using various type constructors such as disjoint unions (denoted by
T1 + T2), dependent products2 (denoted by \Sigma x:T1:T2) and dependent function spaces (denoted
by \Pi x:T1:T2). When x does not appear free in T2, we write T1 \Theta  T2 for \Sigma x:T1:T2 and T1 ! T2
for \Pi x:T1:T2.

This gives an account of most of the familiar programming constructs other than polymorphism. To handle polymorphism we want to have functions that can take types as arguments.
These can be typed with the dependent types discussed above if one adds a type of all types.
Unfortunately, a single type of all types is known to make the theory inconsistent [36, 27, 70, 52],
so instead the type theory includes a predicative hierarchy of universes, U1 ; U2 ; U3 ; etc. The
universe U1 contains all types built up from the base types only, and the universe Ui+1 contains
all types built up from the base types and the universes U1 ; : : : ; Ui . In particular, no universe
is a member of itself.

Unlike *K, which has distinct syntactic classes for kinds, type constructors and terms, Nuprl
has only one syntactic class for all expressions. As a result, types are first class citizens and may
be computed just as any other term. For example, the expression if b then Z else Top (where
b is a boolean expression) is a valid type. Evaluation is call-by-name, but these constructions
may also be used in a call-by-value type theory with little modification.

To state the soundness of the embedding of *K, we will require two assertions from the logic
of types. These are equality, denoted by t1 = t2 in T , which states that the terms t1 and t2
are equal as members of type T , and subtyping, denoted by T1 _ T2, which states that every
member of type T1 is in type T2 (and that terms equal in T1 are equal in T2). A membership
assertion, denoted by t in T , is defined as t = t in T . The basic judgement in Nuprl is H `* P ,
which states that in context H (which contains hypotheses and declarations of variables) the
proposition P is true. Often the proposition P will be an assertion of equality or membership
in a type.

The basic operators discussed above are summarized in Figure 3.1. Note that the lambda
abstractions of Nuprl are untyped, unlike those of *K. In addition to the operators discussed
here, the type theory contains some other less familiar type constructors: the partial type, set
type and very dependent function type. In order to better motivate these type constructors,
we defer discussion of them until their point of relevance. The dynamic semantics of all the
type-theoretic operators is given in Figure 4.3.

3.2.1 Domain and Category Theory
Some of the mechanisms I use in the following section to give the type-theoretic semantics of
*K will look similar to mechanisms used to give programming language semantics in domain or
category theory. This is not coincidence; the three theories are closely related and some of the
mechanisms I use (such as the partial types of Section 3.3.2) are adapted from the folklore of
domain theory.

However, domain theory and category theory are not interchangeable with type theory
for the purposes in this dissertation. Type theory provides the highest degree of structure of
the three theories, domain theory hides some structure in the interest of greater abstraction
and generality, and category theory provides the least structure and the most abstraction and
generality. Thus, one can easily construct a domain or a category based on the Nuprl type

2These are sometimes referred to in the literature as dependent sums, but I prefer the terminology to suggest
the connection to the non-dependent type T1 \Theta  T2.

15

Type Formation Introduction Elimination
universe i Ui type formation

(for i * 1) operators
disjoint union T1 + T2 inj 1(e) case(e; x1:e1; x2:e2)

inj 2(e)
function space \Pi x:T1:T2 *x:e e1e2
product space \Sigma x:T1:T2 he1; e2i ss1(e)

ss2(e)
integers Z : : : ; \Gamma 1; 0; 1; 2; : : : assorted operations
booleans B true; false if-then-else
atoms Atom string literals equality test (=A)
void Void
unit Unit ?
top Top

Figure 3.1: Type Theory Syntax

theory, but one cannot easily work backwards (although such models of type theory do exist
[87, 81, 80]).

The structure of the Nuprl type theory stems from the fact that Nuprl provides direct access
to the primitives of computation and the types of Nuprl speak directly of the computational
behavior of terms. This structure is essential for achieving my goal of establishing a direct
computational significance for this semantics (recall Section 3.1). This structure also allows
type theory to address directly issues that pose significant challenges for domain theory (and
that are not directly meaningful in category theory). For example, in type theory we may
easily include or exclude divergent terms from types, allowing us to easily distinguish between
partial or total functions, and, more importantly, allowing us to use induction properties that
are invalid if one includes divergent terms.

3.3 A Type-Theoretic Semantics
I present the embedding of *K into type theory in three parts. In the first part I begin by giving
embeddings for most of the basic type and term operators. These embeddings are uniformly
straightforward. Second, I examine what happens when the embedding is expanded to include
fix . There we will find it necessary to modify some of the original embeddings of the basic
operators. In the third part I complete the semantics by giving embeddings for the kind-level
constructs of *K. The complete embedding is summarized in Figures 3.3 through 3.6.

The embedding itself could be formulated in type theory, leaving to metatheory only the
trivial task of encoding the abstract syntax of the programming language. Were this done, the
theorems of Section 3.4 could be proven within the framework of type theory. For simplicity,
however, I will state the embedding and theorems in metatheory.

3.3.1 Basic Embedding
The embedding is defined as a syntax-directed mapping (denoted by [[ \Delta  ]]) of *K expressions
to terms of type theory. Recall that in Nuprl all expressions are terms; in particular, types
are terms and may be computed just as any other term. Many *K expressions are translated

16

directly into type theory:

[[x]] def= x
[[ff]] def= ff
[[*x:c:e]] def= *x:[[e]]

[[e1e2]] def= [[e1]][[e2]]
[[c1 ! c2]] def= [[c1]] ! [[c2]]

Nothing happens here except that the types are stripped out of lambda abstractions to match
the syntax of Nuprl. Functions at the type constructor level are equally easy to embed, but I
defer discussion of them until Section 3.3.3.

Since the type theory does not distinguish between functions taking term arguments and
functions taking type arguments, polymorphic functions may be embedded just as easily, although a dependent type is required to express the dependency of c on ff in the polymorphic
type 8ff:^:c:

[[\Lambda ff:^:e]] def= *ff:[[e]]

[[e[c]]] def= [[e]][[c]]
[[8ff:^:c]] def= \Pi ff:[[^]]:[[c]]

Just as the type was stripped out of the lambda abstraction above, the kind is stripped out of
the polymorphic abstraction. The translation of the polymorphic function type above makes
use of the embedding of kinds, but, except for the elementary kind Type, I defer discussion of
the embedding of kinds until Section 3.3.3. The kind Type i, which contains level-i types, is
embedded as the universe containing level-i types:

[[Typei]] def= Ui

Records and Disjoint Unions A bit more delicate than the above, but still fairly simple, is
the embedding of records. Field labels are taken to be members of type Atom, and then records
are viewed as functions that map field labels to the contents of the corresponding fields. For
example, the record fx = 1; f = *x:int:xg, which has type fx : int; f : int ! intg, is embedded
as

*a: if a =A x then 1 else if a =A f then *x:x else ?

where a =A a0 is the equality test on atoms, which returns a boolean when a and a0 are atoms.

Since the type of this function's result depends upon its argument, this function must be
typed using a dependent type:

\Pi a:Atom: if a =A x then Z else if a =A f then Z ! Z else Top

17

In general, records and record types are embedded as follows:

[[f`1 = e1; : : : ; `n = eng]] def= *a: if a =A `1 then [[e1]]

...

else if a =A `n then [[en]]
else ?

[[ss`(e)]] def= [[e]] `
[[f`1 : c1; : : : ; `n : cng]] def= \Pi a:Atom: if a =A `1 then [[c1]]

...

else if a =A `n then [[cn]]
else Top

Note that this embedding validates the desired subtyping relationship on records. Since fx :
int ; f : int !intg _ fx : int g, we would like the embedding to respect the subtyping relationship:
[[fx : int; f : int ! int g]] _ [[fx : intg]]. Fortunately this is the case, since every type is a subtype
of Top, and in particular the part of the type relating to the omitted field, if a = f then
Z ! Z else Top, is a subtype of Top. The use of a type Top to catch extra labels is essential
for subtyping to work properly makes for a particularly elegant embedding of records, but it
is not essential. In the absence of Top one could produce a slightly less elegant embedding by
restricting the domain to exclude undesired labels using a set type (Section 3.3.3).

Disjoint unions are handled in a similar manner. The injection term inj x(1) is embedded
as the pair hx; 1i of its label and its argument. The types of this term include the sum type
hx : int; f : int ! inti, which is embedded using a dependent type as:

\Sigma a:Atom: if a =A x then Z else if a =A f then Z ! Z else Void
In general, disjoint unions are embedded as follows:

[[h`1 : c1; : : : ; `n : cni]] def= \Sigma a:Atom: if a =A `1 then [[c1]]

...

else if a =A `n then [[cn]]
else Void

[[inj `(e)]] def= h`; ei
[[ case(e; `1 . x1:e1; : : : ; `n . xn:en)]] def= if ss1(x) =A `1 then [[e1]][ss2(x)=x1]

...

else if ss1(x) =A `n then [[en]][ss2(x)=xn]
else ?

Again, this relation validates the desired subtyping relationship.

3.3.2 Embedding Recursion
A usual approach to typing general recursive definitions of functions, and the one used in *K,
is to add a fix construct with the typing rule:

H `* e in T ! T

H `* fix (e) in T (wrong)

18

In effect, this adds recursively defined (and possibly divergent) terms to existing types. Unfortunately, such a broad fixpoint rule makes Martin-L"of type theories inconsistent because of the
presence of induction principles. An induction principle on a type specifies the membership of
that type; for example, the standard induction principle on the natural numbers specifies that
every natural number is either zero or some finite iteration of successor on zero. The ability to
add divergent elements to a type would violate the specification implied by that type's induction
rule.

One simple way to derive an inconsistency from the above typing rule uses the simplest induction principle, induction on the empty type Void. The induction principle for Void indirectly
specifies that it has no members:

H `* e in Void

H `* e in T

However, it would be easy, using fix, to derive a member of Void : the identity function can be
given type Void ! Void , so fix (*x:x) would have type Void . Invoking the induction principle,
fix (*x:x) would be a member of every type and, by the propositions-as-types isomorphism,
would be a proof of every proposition. It is also worth noting that this inconsistency does not
stem from the fact that Void is an empty type; similar inconsistencies may be derived (with a
bit more work) for almost every type, including function types (to which the fix rule of *K is
restricted).

It is clear, then, that fix cannot be used to define new members of the basic types. How
then can recursive functions be typed? The solution is to add a new type constructor for partial
types [24, 25, 92]. For any type T , the partial type T is a supertype of T that contains all the
elements of T and also all divergent terms. (A total type is one that contains only convergent
terms.) The induction principles on T are different than those on T , so we can safely type fix
with the rule:3

H `* e in T ! T H `* T admiss

H `* fix (e) in T

We use partial types to interpret the possibly non-terminating computations of *K. When (in
*K) a term e has type o/ , the embedded term [[e]] will have type [[o/ ]]. Moreover, if e is valuable,
then [[e]] can still be given the stronger type [[o/ ]]. Before we can embed fix we must re-examine
the embedding of function types. In Nuprl, partial functions are viewed as functions with
partial result types:4

[[c1 ! c2]] def= [[c1]] ! [[c2]]
[[c1 ) c2]] def= [[c1]] ! [[c2]]

[[8ff:^:c]] def= \Pi ff:[[^]]:[[c]]

Note that, as desired, [[o/1 ) o/2]] _ [[o/1 ! o/2]], since [[o/2]] _ [[o/2]]. If partial polymorphic functions
were included in *K, they would be embedded as \Pi ff:[[^]]:[[c]].

Now suppose we wish to fix the function f which (in *K) has type (o/1 ! o/2) ! (o/1 ! o/2), and

suppose, for simplicity only, that f is valuable. Then [[f ]] has type ([[o/1]] ! [[o/2]]) ! [[o/1]] ! [[o/2]].

3The second subgoal, that the type T be admissible, is a technical condition related to the notion of admissibility in LCF [38]. All the types used in the embedding are admissible, so I ignore the admissibility condition
in the discussion of this chapter. Admissibility is discussed further in Chapter 4 and is examined in detail in
Chapter 5.

4This terminology can be somewhat confusing. A total type is one that contains only convergent expressions.

The partial function type T1 !T 2 contains functions that return possibly divergent elements, but those functions
themselves converge, so a partial function type is a total type.

19

This type does not quite fit the fix typing rule, which requires the domain type to be partial,
so we must coerce [[f ]] to a fixable type. We do this by eta-expanding [[f ]] to gain access to its
argument (call it g) and then eta-expanding that argument g:

*g:[[f ]](*x:g x) in [[o/1]] ! [[o/2]] ! [[o/1]] ! [[o/2]]
Eta-expanding g ensures that it terminates (since *x:g x is a canonical form), changing its type
from [[o/1]] ! [[o/2]] to [[o/1]] ! [[o/2]]. The former type is required by the fix rule, but the latter type
is expected by [[f ]]. Since the coerced [[f ]] fits the fix typing rule, we get that fix (*g:[[f ]](*x:g x))

has type [[o/1]] ! [[o/2]], as desired. Thus we may embed the fix construct as:

[[ fix c(e)]] def= fix (*g:[[e]](*x:g x))

Strictness In *K, a function may be applied to a possibly divergent argument, but in my
semantics functions expect their arguments to be convergent. Therefore we must change the
embedding of application to compute function arguments to canonical form before applying the
function.5 This is done using the sequencing construct let x = e1 in e2 which evaluates e1 to
canonical form e01 and then reduces to e2[e01=x]. The sequence term diverges if e1 or e2 does
and allows x be given a total type:

H `* e1 in T 2 H; x:T2 `* e2 in T1

H `* let x = e1 in e2 in T1

Application is then embedded in the expected way:

[[e1e2]] def= let x = [[e2]] in [[e1]] x
A final issue arises in regard to records and disjoint unions. In the embedding of Section
3.3.1, the record f` = eg would terminate even if e diverges. This would be unusual in a
call-by-value programming language, so we need to ensure that each member of a record is
evaluated:

[[f`1 = e1; : : : ; `n = eng]] def= let x1 = [[e1]] in

...

let xn = [[en]] in
*a: if a =A `1 then x1

...

else if a =A `n then xn
else ?

A similar change must be also be made for disjoint unions:

[[inj `(e)]] def= let x = [[e]] in h`; xi
5Polymorphic functions are unaffected because all type expressions converge (Corollary 3.4).

20

3.3.3 Embedding Kinds
The kind structure of *K contains three first-order kind constructors. We have already seen the
embedding of the kind Type; remaining are the power and singleton kinds. Each of these kinds
represents a collection of types, so each will be embedded as something similar to a universe, but
unlike the kind Typei, which includes all types of the indicated level, the power and singleton
kinds wish to exclude certain undesirable types. The power kind Pi(o/ ) contains only subtypes
of o/ and the singleton kind Si(o/ ) contains only types that are equal to o/ ; other types must be
left out.

The mechanism for achieving this exclusion is the set type [21]. If S is a type and P [\Delta ] is a
predicate over S, then the set type fz : S j P [z]g contains all elements z of S such that P [z] is
true. With this type, we can embed the power and singleton kinds as:6

[[Pi(c)]] def= fT : Ui j T _ [[c]] ^ [[c]] in Uig

[[Si(c)]] def= fT : Ui j T = [[c]] in Uig

Among the higher-order type constructors, functions at the type constructor level and their
kinds are handled just as at the term level, except that function kinds are permitted to have
dependencies but need not deal with partiality or strictness:

[[*ff:^:c]] def= *ff:[[c]]

[[c1[c2]]] def= [[c1]][[c2]]
[[\Pi ff:^1:^2]] def= \Pi ff:[[^1]]:[[^2]]

Dependent Record Kinds For records at the type constructor level, the embedding of the
records themselves is analogous to those at the term level (except that there is no issue of
strictness):

[[f`1 = c1; : : : ; `n = cng]] def= *a: if a =A `1 then [[c1]]

...

else if a =A `n then [[cn]]
else ?

[[ss`(c)]] def= [[c]] `

However, the embedding of this expression's kind is more complicated. This is because of the
need to express dependencies among the fields of the dependent record kind. Recall that the
embedding of a non-dependent record type already required a dependent type; to embed a
dependent record type will require expressing even more dependency. Consider the dependent
record kind f` . ff : Type1; `0 . ff0 : P1(ff)g. We might naively attempt to encode this like the
non-dependent record type as

\Pi a:Atom: if a =A ` then U1 else if a =A `0 then fT : U1 j T _ ff ^ ff in U1 g else Top (wrong)
but this encoding is not correct; the variable ff is now unbound. We want ff to refer to the
contents of field `. In the encoding, this means we want ff to refer to the value returned by the
function when applied to label `. So we want a type of functions whose return type can depend
not only upon their arguments but upon their own return values!

6The second clause in the embedding of the power kind ([[c]] in Ui) is used for technical reasons that require
that well-formedness of Pi(o/ ) imply that o/ : Typei.

21

The type I will use for this embedding is Hickey's very dependent function type [49]. This
type is a generalization of the dependent function type (itself a generalization of the ordinary
function type) and like it, the very dependent function type's members are just lambda abstractions. The difference is in the specification of a function's return type. The type is denoted by
ff j x:T1 ! T2g where f and x are binding occurrences that may appear free in T2 (but not in
T1).

As with the dependent function type, x stands for the function's argument, but the additional variable f refers to the function itself. A function g belongs to the type ff j x:T1 ! T2g
if g takes an argument from T1 (call it t) and returns a member of T2[t; g=x; f ].7

For example, the kind f` . ff : Type 1; `0 . ff0 : P1(ff)g discussed above is encoded as a very
dependent function type as:

ff j a:Atom ! if a =A ` then U1 else if a =A `0 then fT : U1 j T _ f ` ^ f ` in U1 g else Topg
To understand where this type constructor fits in with the more familiar type constructors,
consider the "type triangle" shown in Figure 3.2. On the right are the non-dependent type
constructors and in the middle are the dependent type constructors. Arrows are drawn from
type constructors to weaker ones that may be implemented with them. Horizontal arrows
indicate when a weaker constructor may be obtained by dropping a possible dependency from
a stronger one; for example, the function type T1 ! T2 is a degenerate form of the dependent
function type \Pi x:T1:T2 where the dependent variable x is not used in T2. Diagonal arrows
indicate when a weaker constructor may be implemented with a stronger one by performing
case analysis on a boolean; for example, the disjoint union type T1 + T2 is equivalent to the
type \Sigma b:B : if b then T1 else T2.8

If we ignore the very dependent function type, the type triangle illustrates how the basic type
constructors may be implemented by the dependent function and dependent product types. The
very dependent function type completes this picture: the dependent function is a degenerate
form where the f dependency is not used, and the dependent product may be implemented
by switching on a boolean. Thus, the very dependent function type is a single unified type
constructor from which all the basic type constructors may be constructed.

In general, dependent record kinds are encoded using a very dependent function type as
follows:

[[f`1 . ff1 : ^1; : : : ; `n . ffn : ^ng]] def= ff j a:Atom!

if a =A `1 then [[^1]]
else if a =A `2 then [[^2]][f `1=ff1]
...

else if a =A `n then

[[^n]][f `1 \Delta  \Delta  \Delta  f `n\Gamma 1=ff1 \Delta  \Delta  \Delta  ffn\Gamma 1]
else Topg

7To avoid the apparent circularity, in order for ff j x:T1 ! T2g to be well-formed we require that T2 may only
use the result of f when applied to elements of T1 that are less than x with regard to some well-founded order.
This restriction will not be a problem for this embedding because the order in which field labels appear in a
dependent record kind is a perfectly good well-founded order.

8By switching on a label, instead of a boolean, record types and tagged variant types could be implemented

and placed along the diagonals as well.

22

ff j x:T1 ! T2g HH

HH

HH

HH

HHj

\Pi x:T1:T2 -

HH

HH

HH

HH

HHj

\Sigma x:T1:T2 -

HH

HH

HH

HH

HHj

T1 ! T2
T1 \Theta  T2
T1 + T2
Figure 3.2: The Type Triangle

3.3.4 Embedding Modules
As discussed in Section 2.4.1, *K uses a phase-splitting interpretation of modules, where modules
(including higher-order modules) are considered to consist of two components: a compile-time
component and a run-time component. This is reflected in the type-theoretic semantics by an
embedding that explicitly phase-splits modules. The technique used is derived from Harper, et
al. [46].

The embeddings for modules and signatures are given by two syntax-directed mappings,
[[ \Delta  ]]c and [[ \Delta  ]]r, one for the compile-time component of the given expression and one for the run
time component. Given these, the embedding of a module is a pair of the compile-time and
run-time components:

[[m]] def= h[[m]]c; [[m]]ri

In signatures, the types of run-time fields may depend upon a compile-time member, as in
the signature ffoo . sfoo : hTypei; bar : hhext(sfoo)iig (corresponding to the KML module sig
tycon foo : type val bar : foo end). Consequently, the embedding of a signature is the
dependent product of the compile-time component and the run-time component. The run-time
component's embedding is a function that takes as an argument the compile-time member on
which it depends. In the embedding of the full signature, that function is applied to the variable
standing for the compile-time member:

[[oe]] def= \Sigma v:[[oe]]c:[[oe]]rv
The embeddings of basic modules and signatures are simple. The run-time component is trivial
for h^i signatures and hci modules, and the compile-time component is trivial for hhcii signatures

23

and hheii. Module variables s are split into separate variables sc and sr for each component.

[[hci]]c def= [[c]] (module compile-time component)

[[hci]]r def= ? (module run-time component--trivial)
[[h^i]]c def= [[^]] (signature compile-time component)

[[h^i]]r def= *v:Top (signature run-time component--trivial)
[[hheii]]c def= ? (module compile-time component--trivial)

[[hheii]]r def= [[e]] (module run-time component)
[[hhcii]]c def= Top (signature compile-time component--trivial)

[[hhcii]]r def= *v:[[c]] (signature run-time component)

[[s]]c def= sc (module compile-time component)

[[s]]r def= sr (module run-time component)

For each of the signatures above it is impossible for there to be any dependency of the run-time
component on the compile-time component, since for h^i there is no nontrivial run-time to
depend on anything, and for hhcii there is no nontrivial compile-time for anything to depend
on. As a result, the variable v is ignored in each case.

Functors For function modules and signatures, everything looks familiar in the compile-time
component, where the run-time material is ignored:

[[*s:oe:m]]c def= *sc:[[m]]c

[[m1m2]]c def= [[m1]]c[[m2]]c
[[\Pi s:oe1:oe2]]c def= \Pi sc:[[oe1]]c:[[oe2]]c

However, the run-time component may not similarly ignore the compile-time component, because of possible dependencies. Therefore, the run-time component abstracts over both the
compile-time and run-time components of its argument:

[[*s:oe:m]]r def= *sc: *sr: [[m]]r

[[m1m2]]r def= let x = [[m2]]r in [[m1]]r[[m2]]cx

The signature's run-time component, then, takes an argument v representing the compile-time
component and returns a curried function type. The result type is the run-time component of
the result signature and that depends on the compile-time component. Fortunately, the result's
compile-time component is available (as v sc), since v maps the compile-time component of the
argument to the compile-time component of the result.

[[\Pi s:oe1:oe2]]r def= *v: \Pi sc:[[oe1]]c: [[oe1]]rsc ! [[oe2]]r(v sc)

24

Structures For dependent record modules and signatures, the compile-time component looks
like dependent record kinds and the type constructor records that belong to them:

[[f`1 = m1; : : : ; `n = mng]]c def= *a: if a =A `1 then [[m1]]c

...

else if a =A `n then [[mn]]c

else ?

[[ss`(m)]]c def= [[m]]c`
[[f`1 . s1 : oe1; : : : ; `n . sn : oeng]]c def= ff j a:Atom !

if a =A `1 then [[oe1]]c
else if a =A `2 then [[oe2]]c[f `1=s1c]
...

else if a =A `n then

[[oen]]c[f `1 \Delta  \Delta  \Delta  f `n\Gamma 1=s1c \Delta  \Delta  \Delta  s(n\Gamma 1)c]
else Topg

The run-time component of modules looks much like the embedding of record terms (as with
those, a series of opening lets is necessary to ensure strictness):

[[f`1 = m1; : : : ; `n = mng]]r def= let x1 = [[m1]]r in

...

let xn = [[mn]]r in
*a: if a =A `1 then x1

...

else if a =A `n then xn
else ?
(where xi does not appear free in mi)

[[ss`(m)]]r def= [[m]]r`

The run-time component of signatures is also familiar, except that it must deal with dependencies on the compile-time component. Again, the run-time component takes an argument v
representing the compile-time component. The run-time component [[oei]]r of each field is applied
to the compile-time component of that field, which is v `i. Also, each field may have dependencies on the compile-time components of earlier fields. These dependencies will have been
expressed by free occurrences of the variables sic, into which we substitute the corresponding
compile-time components v `i. It is worthwhile to note that these substitutions for sic are the
only places where dependencies on the argument v are introduced.

[[f`1 . s1 : oe1; : : : ; `n . sn : oeng]]r

def= *v: \Pi a:Atom : if a =

A `1 then [[oe1]]r(v `1)

if a =A `2 then [[oe2]]r(v `2)[v `1=s1c]
...

else if a =A `n then

[[oen]]r(v `n)[v `1 \Delta  \Delta  \Delta  v `n\Gamma 1=s1c \Delta  \Delta  \Delta  s(n\Gamma 1)c]
else Top

25

[[Typei]] def= fT : Ui j T admiss ^ T totalg
[[\Pi ff:^1:^2]] def= \Pi ff:[[^1]]:[[^2]]
[[f`1 . ff1 : ^1; : : : ; `n . ffn : ^ng]] def= ff j a:Atom ! if a =A `1 then [[^1]]

else if a =A `2 then [[^2]][f `1=ff1]
...

else if a =A `n then

[[^n]][f `1 \Delta  \Delta  \Delta  f `n\Gamma 1=ff1 \Delta  \Delta  \Delta  ffn\Gamma 1]
else Topg
(where f; a do not appear free in ^i)

[[Pi(c)]] def= fT : Ui j T _ [[c]] ^ [[c]] in Ui ^ T admissg

(where T does not appear free in c)

[[Si(c)]] def= fT : Ui j T = [[c]] in Uig

(where T does not appear free in c)

[[ff]] def= ff
[[*ff:^:c]] def= *ff:[[c]]

[[c1[c2]]] def= [[c1]][[c2]]
[[f`1 = c1; : : : ; `n = cng]] def= *a: if a =A `1 then [[c1]]

...

else if a =A `n then [[cn]]
else ?
(where a does not appear free in ci)

[[ss`(c)]] def= [[c]] `
[[c1 ! c2]] def= [[c1]] ! [[c2]]
[[c1 ) c2]] def= [[c1]] ! [[c2]]

[[8ff:^:c]] def= \Pi ff:[[^]]:[[c]]
[[f`1 : c1; : : : ; `n : cng]] def= \Pi a:Atom: if a =A `1 then [[c1]]

...

else if a =A `n then [[cn]]

else Top
(where a does not appear free in ci)

[[h`1 : c1; : : : ; `n : cni]] def= \Sigma a:Atom: if a =A `1 then [[c1]]

...

else if a =A `n then [[cn]]

else Void
(where a does not appear free in ci)

[[ ext(m)]] def= [[m]]c

Figure 3.3: Embedding Kinds and Types

26

[[x]] def= x
[[*x:c:e]] def= *x:[[e]]

[[e1e2]] def= let x = [[e2]] in [[e1]] x

(where x does not appear free in e1)

[[\Lambda ff:^:e]] def= *ff:[[e]]

[[e[c]]] def= [[e]][[c]]
[[f`1 = e1; : : : ; `n = eng]] def= let x1 = [[e1]] in

...

let xn = [[en]] in
*a: if a =A `1 then x1

...

else if a =A `n then xn
else ?
(where xi does not appear free in ej)

[[ss`(e)]] def= [[e]] `
[[inj `(e)]] def= let x = [[e]] in h`; xi
[[ case(e; `1 . x1:e1; : : : ; `n . xn:en)]] def= let x = [[e]] in

if ss1(x) =A `1 then e1[ss2(x)=x1]
...

else if ss1(x) =A `n then en[ss2(x)=xn]
else ?
(where x does not appear free in ei)

[[ fixc(e)]] def= fix (*g:[[e]](*x:g x))

(where g does not appear free in e)

[[ ext(m)]] def= [[m]]r

Figure 3.4: Embedding Terms

3.4 Properties of the Embedding
I conclude my presentation of the type-theoretic semantics of *K by examining some of the
important properties of the semantics. We want the embedding to validate the intuitive meaning
of the judgements of *K's static semantics. If ^1 is a subkind of ^2 then we want the embedded
kind [[^1]] to be a subtype of [[^2]]; if c1 and c2 are equal in kind ^, we want the embedded
constructors [[c1]] and [[c2]] to be equal (in [[^]]); and if e has type o/ we want [[e]] to have type
[[o/ ]] (and [[o/ ]] if e is valuable). Similar properties are desired for the module judgements. This
is stated in Theorem 3.1:

Theorem 3.1 (Semantic Soundness) For every *K context \Gamma , let [[\Gamma ]] be defined as follows:

[[ ffl ]] def= ffl
[[\Gamma [ff : ^]]] def= [[\Gamma ]]; ff:[[^]]

[[\Gamma [x : c]]] def= [[\Gamma ]]; x:[[c]]
[[\Gamma [s : oe]]] def= [[\Gamma ]]; sc:[[oe]]c; sr:[[oe]]rsc

Then the following implications hold:

1. If \Gamma  `K ^ = ^0 then level (^) = level (^0) and [[\Gamma ]] `* [[^]] = [[^0]] in Ulevel (^)+1

27

[[oe]] def= \Sigma v:[[oe]]c:[[oe]]rv

(where v does not appear free in oe)

[[h^i]]c def= [[^]]

[[h^i]]r def= *v:Top
[[hhcii]]c def= Top

[[hhcii]]r def= *v:[[c]]

(where v does not appear free in c)

[[\Pi s:oe1:oe2]]c def= \Pi sc:[[oe1]]c:[[oe2]]c

[[\Pi s:oe1:oe2]]r def= *v: \Pi sc:[[oe1]]c: [[oe1]]rsc ! [[oe2]]r(v sc)

(where v; s do not appear free in oei)

[[f`1 . s1 : oe1; : : : ; `n . sn : oeng]]c def= ff j a:Atom ! if a =A `1 then [[oe1]]c

else if a =A `2 then [[oe2]]c[f `1=s1c]
...

else if a =A `n then

[[oen]]c[f `1 \Delta  \Delta  \Delta  f `n\Gamma 1=s1c \Delta  \Delta  \Delta  sn\Gamma 1c]
else Topg
(where f; a do not appear free in oei)

[[f`1 . s1 : oe1; : : : ; `n . sn : oeng]]r def= *v: \Pi a:Atom: if a =A `1 then [[oe1]]r(v `1)

if a =A `2 then [[oe2]]r(v `2)[v `1=s1c]
...

else if a =A `n then

[[oen]]r(v `n)

[v `1 \Delta  \Delta  \Delta  v `n\Gamma 1=s1c \Delta  \Delta  \Delta  sn\Gamma 1c]
else Topg
(where v; a do not appear free in oei)

Figure 3.5: Embedding Signatures

2. If \Gamma  `K ^ _ ^0 then [[\Gamma ]] `* ([[^]] in Ulevel (^)+1 ^ [[^0]] in Ulevel (^0)+1 ^ [[^]] _ [[^0]]).
3. If \Gamma  `K c = c0 : ^ then [[\Gamma ]] `* [[c]] = [[c0]] in [[^]].
4. If \Gamma  `K c _ c0 then [[\Gamma ]] `* [[c]] _ [[c0]].
5. If \Gamma  `K e : c then [[\Gamma ]] `* [[e]] in [[c]].
6. If \Gamma  `K e # c then [[\Gamma ]] `* [[e]] in [[c]].
7. If \Gamma  `K oe _ oe0 then [[\Gamma ]] `* ([[oe]] in Ulevel (oe)+1 ^ [[oe0]] in Ulevel (oe0)+1 ^ [[oe]] _ [[oe0]]).
8. If \Gamma  `K m : oe then [[\Gamma ]] `* ([[m]] in [[oe]] ^ [[m]]c in [[oe]]c).
9. If \Gamma  `K m # oe then [[\Gamma ]] `* [[m]] in [[oe]].
Proof

By induction on the derivations of the *K judgements.

We may observe two immediate consequences of the soundness theorem. One is the desirable
property of type preservation: evaluation does not change the type of a program. Figure 4.3
gives a small-step evaluation relation for the Nuprl type theory (denoted by t 7! t0 when t
evaluates in one step to t0). Type preservation of *K (Corollary 3.3) follows directly from
soundness and type preservation of Nuprl (Proposition 3.2).

28

[[m]] def= h[[m]]c; [[m]]ri

[[s]]c def= sc

[[s]]r def= sr
[[hci]]c def= [[c]]

[[hci]]r def= ?
[[hheii]]c def= ?

[[hheii]]r def= [[e]]
[[*s:oe:m]]c def= *sc:[[m]]c

[[*s:oe:m]]r def= *sc: *sr: [[m]]r

[[m1m2]]c def= [[m1]]c[[m2]]c

[[m1m2]]r def= let x = [[m2]]r in [[m1]]r[[m2]]cx

(where x does not appear free in m1, m2)

[[f`1 = m1; : : : ; `n = mng]]c def= *a: if a =A `1 then [[m1]]c

...

else if a =A `n then [[mn]]c
else ?
(where a does not appear free in mi)

[[f`1 = m1; : : : ; `n = mng]]r def= let x1 = [[m1]]r in

...

let xn = [[mn]]r in
*a: if a =A `1 then x1

...

else if a =A `n then xn
else ?
(where xi does not appear free in mi)

[[ss`(m)]]c def= [[m]]c`

[[ss`(m)]]r def= [[m]]r`

[[m : oe]]c def= [[m]]c

[[m : oe]]r def= [[m]]r

Figure 3.6: Embedding Modules

Proposition 3.2 If `* t in T and t 7!\Lambda  t0 then `* t0 in T .
Proof

Direct from Corollary 4.4.

Corollary 3.3 (Type Preservation) If `K e : o/ and [[e]] 7!\Lambda  t then `* t in [[o/ ]].

Another consequence of the soundness theorem is that the phase distinction [16, 46] is
respected in *K: all type expressions converge and therefore types may be computed in a
compile-time phase. This is expressed by Corollary 3.4:

Corollary 3.4 (Phase Distinction) If `K c : ^ then there exists canonical t such that
[[c]] 7!\Lambda  t.
Proof

For any well-formed *K kind ^, the embedded kind [[^]] can easily be shown to be a total type.
(Intuitively, every type is total unless it is constructed using the partial type constructor,
which is not used in the embedding of kinds.) The conclusion follows directly.

29

3.5 Prospects for Extension
In order to embed *K into type theory, I abandoned impredicativity. This was because the
standard semantics for Nuprl (discussed in Section 4.4) does not support it. However, Mendler
[69] has developed a semantic model of Nuprl enhanced with recursive types and some impredicative polymorphism. In that type theory, it is entirely straightforward to handle second-order
impredicativity. I have not used Mendler's type theory in this thesis because its semantics is
very complicated, and because it is not clear how easily it can be extended to support partial
types. An alternative type theory to be explored is the Calculus of Constructions [29, 28],
which also supplies impredicative features and could likely support the semantics discussed in
this chapter.

Another important avenue for future work is to extend the semantics in this chapter to
explain stateful computation. One promising device for doing this is to encode stateful computations as monads [82, 60], but this raises two difficulties. In order to encode references in
monads, all expressions that may side-effect the store must take the store as an argument. The
problem is how to assign a type to the store. Since side-effecting functions may be in the store
themselves, the store must be typed using a recursive type, and since side-effecting expressions
take the store as an argument, that recursive type will include negative occurrences of the
variable of recursion. Mendler's type theory may express recursive types with only positive
occurrences, but to allow negative occurrences is an open problem.9

Finally, a particularly compelling direction is to extend the semantics to account for objects,
and that turns out to require only the same mechanisms discussed above. In a weak sense, this
semantics can already support objects; the existential object encoding of Pierce and Turner [83]
uses only constructs available within the type theory used here. Unfortunately, that encoding
is not practical in a predicative system, because it involves quantification over the types of an
object's hidden instance variables. That quantification results in objects always belonging to
a universe one level higher than their underlying code, which prevents such object from being
first-class.10 However, in an impredicative type theory, Pierce and Turner's object encoding can
be used quite satisfactorily. In a type theory that additionally supplies recursive types (with
negative occurrences), a variety of other object encodings become possible as well [15, 13, 3, 31,
14]. Alternatively, the object encoding of Hickey [50] works entirely within the existing Nuprl
type theory and shows promise of being extendable to a practical object system.

3.6 Conclusions
I have shown how to give a type-theoretic semantics to an expressive programming calculus
that supports modular and object-oriented features. This semantics makes it possible to use
formal type-theoretic reasoning about programs and programming languages without informal
embeddings and without sacrificing core expressiveness of the programming language.

Formal reasoning aside, embedding programming languages into type theory allows a researcher to bring the full power of type theory to bear on a programming problem. For example,
in Crary [30] I use a type-theoretic interpretation to expose the relation of power kinds to a
nonconstructive set type. Adjusting this interpretation to make the power kind constructive

9See Birkedal and Harper [11] for a promising approach that may lead to a solution of this problem.
10However, in some contexts it is not necessary for objects to be first class. For example, Jackson [57] independently used an encoding essentially the same as Pierce and Turner's to implement computational abstract
algebra. In that context, algebras were rarely intermingled with the elements of an algebra, and when they were,
an increase in the universe level was acceptable.

30

results in the proof-passing technique used to implement higher-order coercive subtyping in
KML.

Furthermore, the simplicity of the semantics makes it attractive to use as a mathematical
model similar in spirit, if not in detail, to the Scott-Strachey program [90]. This semantics
works out so neatly because type theory provides built-in structure well-suited for analysis of
programming. Most importantly, type theory provides structured data and an intrinsic notion
of computation. Non-type-theoretic models of type theory can expose the "scaffolding" when
one desires the details of how that structure may be implemented (Section 4.4).

As a theory of structured data and computation, type theory is itself a very expressive programming language. Practical programming languages are less expressive, but offer properties
that foundational type theory does not, such as decidable type checking. I suggest that it is
profitable to take type theory as a foundation for programming, and to view practical programming languages as tractable approximations of type theory. The semantics in this chapter
illustrates how to formalize these approximations. This view not only helps to explain programming languages and their features, as I have done here, but also provides a greater insight
into how we can bring more of the expressiveness of type theory into programming languages.

31

Chapter 4
Foundational Type Theory
In this chapter I present in detail the foundational type theory of Nuprl. Broadly speaking,
the intent of the Nuprl type theory is to provide a formal foundation for mathematics that
is intrinsically computational. Like the simpler type theories that provide the superstructure
for various programming languages (such as *K), Nuprl is a theory of structured data and
computation. The essential difference between Nuprl (and other foundational type theories [68,
29, 42]) and the simpler type systems of ordinary programming languages is the expressiveness
of the type system. Foundational type theories provide type structure rich enough to encode
(almost) arbitrary logical and mathematical propositions.

This logical character of the Nuprl type system is not immediately evident at a first inspection. Instead, the constructs that make up Nuprl are those of a fairly simple programming
language: data such as integers, functions, and pairs, and types for classifying such data. Those
computational constructs are interpreted as logical statements using the propositions-as-types
correspondence discussed in Section 4.1.3. This conflating of logic and data is one of the interesting aspects of type theory, and is in contrast to most other mathematical foundations (such
as set theory), which draw sharp distinctions between objects and logical sentences.

4.1 Nuprl
The standard Nuprl type theory is presented in Constable et al. [19]. I present here a variant
of the Nuprl type theory with a number of innovations. Chief among those innovations are
the partial type mechanisms added in order to make it possible to reason about potentially
nonterminating computations. In Section 4.3 I discuss some of the design decisions for my
version of Nuprl.

4.1.1 Basic Types and Operators
At the core of the type theory are the basic data types summarized in Figure 4.1. Each of these
data types have a collection of introduction operators, and a collection of analysis (or elimination) operators. Nuprl does not have distinct syntactic classes for types and terms; instead,
types are ordinary terms that may be computed using the same operations for computing data.
For example, if A and B are types then so is if b then A else B. The basic types of Nuprl are
the following:

ffl Atom: The collection of introduction forms for Atom is the set of string literals. The sole

elimination form for Atom is the equality test a =A a0, which is equivalent to true when a

32

Type Formation Introduction Elimination
atoms Atom string literals equality test (=A)
integers Z : : : ; \Gamma 1; 0; 1; 2; : : : assorted operations \Phi 
booleans B true; false if e then e1 else e2
disjoint union T1 + T2 inj 1(e) case(e; x1:e1; x2:e2)

inj 2(e)
product space \Sigma x:T1:T2 he1; e2i ss1(e)

ss2(e)
function space \Pi x:T1:T2 *x:e e1e2
very-dependent ff j x:T1 ! T2g *x:e e1e2
function
unit Unit ?
void Void
universe i Ui type formation

(for i * 1) operators

Figure 4.1: Basic Nuprl Types

and a0 are equal atoms, and is equivalent to false when a and a0 are unequal atoms. (Note
that Atom has considerably less structure than a type of strings; the essential properties
of Atom are only a countably infinite set of introduction forms and an equality test.)

ffl Integer (Z): The collection of introduction forms for Z is the set of integer literals. The

elimination forms for integers are boolean equality and inequality tests (=Z and ^Z),
and a collection of binary operations (ranged over by \Phi ), such as plus, times, etc. For
convenience, these operators are taken to be defined on all integer values and return zero
in exceptional cases such as division by zero.

ffl Boolean (B ): The introduction forms for B are true and false. Booleans are eliminated

by the branching construct if b then e1 else e2. (For simplicity, booleans will eventually
be defined in terms of the unit and disjoint union types.)

ffl Disjoint Union (A + B): The introduction forms of A + B are inj 1(a) (when a is a

term belonging to A) and inj (b) (when b is a term belonging to B). Disjoint unions are
eliminated by the case analysis construct case(e; x1:e1; x2:e2).

ffl Dependent Product (\Sigma x:A:B): The introduction forms of \Sigma x:A:B are ha; bi, when a belongs to A and b belongs to B[a=x]. Disjoint unions are eliminated by the projection
constructs ss1(e) and ss2(e). As usual, when x does not appear free in B, I write \Sigma x:A:B
as the non-dependent product A \Theta  B. (This type is also known in the literature as a
dependent sum, general sum or strong sum. I choose the term dependent product in
order to emphasize the connection to the non-dependent product.)

ffl Dependent Function (\Pi x:A:B): The introduction form of \Pi x:A:B is *x:b, when b[a=x]

belongs to B[a=x] for every a belonging to A. Functions are eliminated by the application
construct e1e2. As usual, when x does not appear free in B, I write \Pi x:A:B as the
non-dependent function type A ! B.

ffl Very Dependent Function (ff j x:A ! Bg): The very dependent function type (due to

Hickey [49]) has the same introduction form (*x:b) as the ordinary dependent function

33

type, but allows the result type B to depend not only on the argument x but on the
function itself. Thus, *x:b belongs to ff j x:A ! Bg when b[a=x] belongs to B[*x:b; a=f; x]
for every a belonging to A.

To avoid circularity, in order for a very dependent function type ff j x:A:Bg to be wellformed, we require that B only use f by applying it to elements of A that are less than x
with respect to some well-founded order. As discussed in Section 3.3.3, the very dependent
function type is sufficient to encode many of the other basic types discussed here, but it
is convenient (especially in Chapter 5) to retain those other types as primitive.

ffl Unit : The type Unit has the introduction form ? and no elimination forms. (For simplicity,

Unit will eventually be defined in terms of the equality type.)

ffl Void: The type Void is empty and therefore has no introduction forms.
ffl Universe (Ui ): Each type expression is Nuprl is also an ordinary term, and is a member

of a universe type. The universe U1 is the type containing all small types: those that can
be built without using a universe. The universe Ui+1 then contains all types that can be
built using no universe higher than Ui . In particular, no universe is a member of itself;
to include a single type that contained all types (including itself) would make the theory
inconsistent [36, 27, 70, 52]. The introduction forms for a universe are the type formation
operators. No elimination form for universes is provided, but this is only for simplicity;
type analysis operations could easily be added, following Constable and Zlatin [20, 26].

4.1.2 Equality and Well-formedness
Central to the type theory are two equality relations, one for equality of types and another for
equality of terms relative to a type. The type equality relation, written T1 = T2, states that
T1 and T2 are each well-formed types and are equal to each other. The term equality relation,
written e1 = e2 2 T , states that T is a type and that e1 and e2 are members of T and are equal
when considered as members of T . A specification of these two relations appears in Figure 4.5.

The reflexive forms of these relations are particularly important. Note that T = T exactly
when T is a well-formed type, and that e = e 2 T exactly when e is a member of T . These
reflexive cases are abbreviated as T type and e 2 T , respectively.

For example, \Pi x:A:B = \Pi x:A0:B0 if and only if A = A0 and B[a=x] = B0[a0=x] whenever
a = a0 2 A; and *x:b = *x:b0 2 \Pi x:A:B if and only if \Pi x:A:B type and b[a=x] = b0[a0=x] 2
B[a=x] whenever a = a0 2 A.

We will occasionally have need of a special degenerate type to serve as a supertype of all
types:

ffl Top: For any terms e1 and e2, e1 = e2 2 Top. (For simplicity, Top will eventually be

defined in terms of the every type.)

Notation 4.1 I write 8a 2 A: P to mean 8a: a 2 A ) P and 8a = a0 2 A: P to mean
8a; a0: a = a0 2 A ) P .

4.1.3 Propositions as Types
In order to use type theory for mathematics, we need a way to make logical statements (propositions) within the formal theory. This is done using the propositions-as-types correspondence,

34

also known as the Curry-Howard isomorphism [51]. In this correspondence, each logical sentence is interpreted as a type, with the understanding that that the sentence is true exactly
when the corresponding type is inhabited by some term. That inhabitant is referred to as the
witness of the proposition.

For example, the proposition False is interpreted as the uninhabited type Void . The other
logical connectives are interpreted as follows:

True def= Unit
P ^ Q def= P \Theta  Q
P . Q def= P + Q
P ) Q def= P ! Q
P , Q def= (P ! Q) \Theta  (Q ! P )

:P def= P ! Void
8x:T:P def= \Pi x:T:P
9x:T:P def= \Sigma x:T:P

Higher-order logic may be interpreted by this device as well. We may state a proposition
quantified over all (small) predicates as 8P :P1:Q. This is interpreted in the type theory by
defining the type of propositions Pi to be the universe Ui .

4.1.4 Equality, Subtyping and Inequality
Although the preceding is sufficient to encode propositional and higher-order predicate logic, we
are short on atomic propositions. For example, we would like to be able to speak about equality
within the logic, but none of the types discussed so far is able to express such a proposition.
To handle this sort of atomic assertion, we add new types that are defined to be inhabited by
the trivial term ? when the proposition they represent is true, and empty otherwise:

ffl Equality (e1 = e2 in T ): The type e1 = e2 in T is well-formed when e1 2 T and e2 2 T .

If e1 = e2 2 T then the type e1 = e2 in T has the introduction form ?, if not then the
type is empty (and is interpreted as a false proposition). Using the equality type, we may
also define a membership type (denoted e in T ) as e = e in T .

ffl Subtyping (T1 _ T2): The type T1 _ T2 is well-formed when T1 and T2 are well formed

types. If T1 is a subtype of T2 (i.e., e = e0 2 T2 whenever e = e0 2 T1) then T1 _ T2 has
the introduction form ?, otherwise it is empty (and is interpreted as a false proposition).

ffl Inequality (n1 ^ n2): The type n1 ^ n2 is well-formed when n1 2 Z and n2 2 Z and is

inhabited (by ?) when the integer value of is n1 is less than or equal to that of n2.

Be careful to note the distinction between e1 = e2 in T , a type (and a proposition) within
the formal type theory, and e1 = e2 2 T , a metatheoretical statement outside the theory.

Also note that subtyping is defined as type inclusion: if T1 _ T2 then the members of
T1 are actual members of T2. An alternative definition would be that T1 _ T2 when exists a
coercion from T1 to T2 [12]. This would provide an apparently more general notion of subtyping,
since the identity function could always serve as a coercion from a type to another type that
includes it. In its greatest generality, coercive subtyping may be represented by the proposition
T1 ) T2, which states that there exists a function from T1 to T2. Alternatively, if the coercion

35

interpretation is restricted to use a predetermined collection of coercions, then the two notions
of subtyping may be reconciled in a common type system [30]. This is done by building a
new type system in which a type T2 contains all the members of every type T1 such that T1
is coercible to T2. Then the equalities on such types are constructed so that coercion results
are deemed equal to the corresponding coercion arguments, and thus coercion functions may
formally be viewed as identity functions.

Negatability Consider the proposed proposition 3 in Atom. Certainly it is not true, but
it is not false either: Since the well-formedness criterion for the equality type requires its
equands to belong to the stated type, 3 in Atom is ill-formed and not a type at all. This
seemingly innocuous phenomenon has considerable consequences; it means that the membership
proposition is not negatable.

To understand why, consider the proposition e in T . If (metatheoretically speaking) e 2 T
then e in T is well-formed and true (i.e., inhabited). On the other hand, if e 62 T then e in T
is ill-formed and unusable. This does not mean that membership proposition is useless; on
the contrary, it is quite often essential. However, the membership proposition is useless as the
antecedent of an implication. As a simple example, the negation :(e in T ) is either false or
ill-formed, but never true and hence never useful. More generally, the implication e 2 T ) P
is no easier to prove than P , because the well-formedness of the implication cannot be shown
without proving the antecedent, rendering the antecedent useless.

The non-negatability phenomenon is not limited to the membership proposition. Consider
the proposition 8x:T1: x in T2. This proposition could be used to define the subtyping relation,
but like the membership proposition, it is well-formed only when true. That is why subtyping
is made a built-in type, because we would like to be able to prove theorems like A _ B )
Z ! A _ Z ! B and :(U2 _ U1 ). In Section 4.1.8 we will see a few more examples of primitive
types included to provide negatability.

4.1.5 Constructivity
The interpretation of propositions as types is convenient, but it also restricts the proof techniques that may be used to prove such propositions. Consider the proposition XM = 8P :P1: P .
:P . In classical logic, this proposition is certainly true: every proposition is either true or false
(alternatively, every type is either inhabited or uninhabited). However, for XM to be valid in
Nuprl, there must exist a function f that computes a member of P + :P for every (small)
proposition P . This is certainly impossible, since P may express an undecidable proposition.

The Nuprl logic restricts proofs to using only principles of reasoning that are constructive
(or intuitionistic [33]). This means that any proof of the existence of an object must show how
to construct it, and any proof of a disjunction must show how to determine which case is true.
In practice this means that proofs may not use the principle of the excluded middle (proposition
XM above) or proof by contradiction. (Contradiction may, however, be used to prove theorems
of the form ::P .)

The dividend of this restriction is that proofs may be interpreted as programs. Suppose we
prove 8x:Z: 9y:Z: P (x; y) constructively. In so doing, we have constructed a function inhabiting
the corresponding type \Pi x:Z: \Sigma y:Z: P (x; y); this function is the computational content of the
proof. The function may be applied to any integer x to compute the desired integer y and a
proof of P (x; y). More generally, whenever we prove the existence of objects, we may extract
the computational content from that proof: a program to compute those objects. I discuss this

36

process of extracting computational content from proofs further in Section 4.2.2. In Section
4.4.3 I discussed the controlled reintroduction of classical reasoning principles.

Propositions versus Booleans It is important to be clear on the distinction between the
type Pi of propositions and the type B of booleans. Propositions are types that are inhabited
when their intended meaning is true and are empty otherwise. Booleans are terms that compute
to the value true when their intended meaning is true and to false otherwise. Decidable propositions may also be stated as boolean expressions; for example true, false, a =A a0, n =Z n0
and n ^Z n0 are boolean forms of the propositions True, False, a = a0 in Atom, n = n0 in Z
and n ^ n0. Undecidable propositions can never be stated as boolean expressions because a
computation that resulted in such a boolean would solve the undecidable problem.

4.1.6 Constructing New Types using Logic
We may also use logical predicates to construct variants of other types, using two special type
constructors (due to Constable [21]):

ffl The set type fx:T j P g is the subtype of T that contains all t 2 T such that P [t=x] is true

(i.e., inhabited).

ffl The quotient type xy:T ==E[x; y] (when E[\Gamma ; \Gamma ] is an equivalence relation on T ) is the

supertype of T that coarsens the equality on T as follows: t1 = t2 2 xy:T ==E if and only
if t1; t2 2 T and E[t1; t2=x; y] is true (i.e., inhabited).

We may use set and quotient types to define a number of important variants on existing
types, such as the natural numbers, N def= fn : Z j 0 ^ ng, and the integers modulo k, Zk def=
mn:Z==((m \Gamma  n) mod k = 0 in Z). A number of other derived forms appear in Figure 4.2.

An important point about set and quotient types is that they suppress computational content of their predicate. Given that n 2 fx : Z j P [x]g, it is certainly the case that P [n] is
inhabited by some term, but there is no way to gain access to that term. An an extreme example, consider the squashed proposition #P def= fx : Unit j P g. Metatheoretically it is easy to see
that P is inhabited exactly when #P is, and the implication P ) #P can easily be shown valid.
However, the converse #P ) P is not valid, because it is not possible in general to produce a
proof of a proposition simply from knowing it to be true. In order words, it is not generally
possible to reconstruct suppressed computational content.

However, whenever the suppressed predicate is recursively enumerable, it is possible to
reconstruct computational content. This covers many uses, including those few uses discussed
above. On the other hand, it often is desirable to suppress computational content. For example,
a proof of 8x:Z: 9y:Z: P (x; y) computes both an integer y and a witness to P (x; y), but it may
be the case that so long as P (x; y) is true, the actual witness is not interesting. In such cases,
returning the witness is cluttersome at best, and computationally expense at worst. It would
then be more appropriate to prove the similar proposition 8x:Z:fy : Z j P (x; y)g.

4.1.7 Computation
Intrinsic to the type theory is an operational semantics that defines how Nuprl terms compute. This computation system is call-by-name (in contrast to *K) as is defined by a small-step
evaluation relation, t1 7! t2, and a set of canonical forms to which terms evaluate. The computation system is defined to be the restriction to closed terms of the evaluation step relation

37

Unit def= 0 = 0 in Z

B def= Unit + Unit
true def= inj 1(?)
false def= inj 2(?)
if b then e1 else e2 def= case(b; x:e1; x:e2) (where x is not free in e1, e2)

e in T def= e = e in T
T type def= T _ T

n ! m def= :(n * m)

N def= fn : Zj 0 ^ ng
Z+ def= fn : Zj 0 ! ng

Zk def= mn:Z==((m \Gamma  n) mod k = 0 in Z)

Q def= xy:(Z\Theta  Z+)==(ss1(x) \Theta  ss2(y) = ss1(y) \Theta  ss2(x) in Z)
#P def= fx : Unit j P g (where x is not free in P )
t halts def= t in! E

Top def= xy:E ==Unit

Figure 4.2: Derived Forms

given in Figure 4.3. Whether a term is canonical is governed by its outermost operator; the
canonical forms of Nuprl are the type formation constructs and the introduction forms (i.e.,
the middle column of Figure 4.1). Two important properties of evaluation are that evaluation
is deterministic and canonical forms are terminal:

Proposition 4.2 If t 7! t1 and t 7! t2 then t1 j t2. Moreover, if t is canonical then t 67! t0 for
any t0.

If t 7!\Lambda  t0 and t0 is canonical then we say that t converges (abbreviated t#) and t converges to
t0 (abbreviated t + t0). Note that if t + t1 and t + t2 then t1 j t2 and that if t is canonical then
t + t.

The computation system may be used to define a computational equivalence relation (often
known as applicative bisimulation) written t1 , t2. Computational equivalence will be formally
defined in Chapter 5 (Definition 5.3). Intuitively, two terms are computationally equivalent
if they both converge to canonical forms with the same outermost operator and the corresponding subterms are computationally equivalent, or if they both fail to converge. It may
be shown (Lemma 5.5, using Howe's method [53]) that computational equivalence includes
beta-equivalence.

The equalities on types are constructed to observe computational equivalence;1 that is, if
t 2 T and t , t0 then t = t0 2 T . This enables a powerful form of untyped reasoning called
direct computation. When two terms are computationally equivalent (for example, a beta redex
and contractum), they are indistinguishable by the type theory and may be freely exchanged
for each other in any expression or proof:

Theorem 4.3 If T type and T , T 0 then T = T 0. If t 2 T and t , t0 then t = t0 2 T .

1However, unlike the type system considered by Howe [53], equality in this type theory does not observe
computational approximation (Section 5.2.1). This is because of the presence of partial types (Section 4.1.8).
For example, ? approximates 1, but it is not the case that ? = 1 in Z.

38

e 7!s e

0

case(e; x1:e1; x2:e2) 7!s case(e

0; x1:e1; x2:e2)

case(inj 1(e); x1:e1; x2:e2) 7!s e1[e=x1] case(inj 2(e); x1:e1; x2:e2) 7!s e2[e=x2]

e1 7!s e

01

e1e2 7!s e

01e2 (*x:e1)e2 7!s e1[e2=x] e 7!

s e

0

ss1(e) 7!s ss1(e

0) ss1(he1; e2i) 7!s e1

e 7!s e

0

ss2(e) 7!s ss2(e

0) ss2(he1; e2i) 7!s e2

e1 7!s e

01

e1 (=A==Z=^Z) e2 7!s e

01 (=A==Z=^Z) e2

e1 is a string/integer literal e2 7!s e

02

e1 (=A==Z=^Z) e2 7!s e1 (=A==Z=^Z) e

02

e1 and e2 are string/integer literals, i = 1 iff e1 j e2

e1 (=A==Z) e2 7!s inj i(?)

e1 and e2 are integer literals, i = 1 iff e1 ^ e2

e1 ^Z e1 7! inj i(?)

e1 7!s e

01

let x = e1 in e2 7!s let x = e

01 in e2 e

1 is canonical

let x = e1 in e2 7!s e2[e1=x]

e1 7!s e

01

e1 \Phi  e2 7!s e

01 \Phi  e2

e1 is an integer literal e2 7!s e

02

e1 \Phi  e2 7!s e1 \Phi  e

02 e1 and e2 are integer literals e

1 \Phi  e2 = e

e1 \Phi  e2 7!s e

fix (e) 7!s e fix (e)
Figure 4.3: Operational Semantics for Nuprl

39

This theorem is codified in the type theory by the direct computation rules, Rules 8 through 15
(Appendix B). Since computational equivalence is undecidable (and since we wish to be able
to effectively determine whether an instance of a rule is valid), the direct computation rules
approximate computational equivalence with the auxiliary judgement `* t , t0 (where t and t0
are possibly open terms).

A simple application of Theorem 4.3 and direct computation is type preservation:

Corollary 4.4

ffl (Semantic type preservation) If t 2 T and t 7! t0 then t0 2 T .
ffl (Syntactic type preservation) If H `* t in T and t 7! t0 then H `* t0 in T .
Proof

If t 7! t0 then t , t0 (Proposition 5.4) and `* t , t0 (Rule 14). Semantic preservation follows
directly by Theorem 4.3 and syntactic preservation follows by application of Rules 8 and
11.

4.1.8 Partial Types
Of particular interest in the computation system is the operator fix , which allows recursive
computation and is evaluated by the rule fix (f ) 7! f (fix (f )).2 The primary use of fix is to
define recursive functions. Unfortunately, in the standard Nuprl type theory, recursion is not
as general tool as it is in most programming languages. All of the basic types of Nuprl are
total (that is, they contain only convergent terms), but in general there is no guarantee that
a recursive function converges. Thus, a recursive function (generally, a recursively computed
object) cannot be given a type unless it can be shown to converge, and it cannot be used
without giving it a type. However, it is not always convenient (or possible) to prove that
recursive functions terminate, and furthermore, it is sometimes interesting to reason about
functions that are known not to terminate for all inputs.

In order to be able to assign types to partial functions and nonconvergent objects, we add
a new type constructor:

ffl Partial type (T ): The partial type T (due to Constable and Smith [24, 25, 92]) is like a

lifted version of T : It contains all members of T , plus all nonconvergent terms. Terms are
equal in T if they have the same convergence behavior, and if they are equal in T when
they converge. That is, t = t0 2 T if and only if t# , t0# and t# ) t = t0 2 T .

With this type available, we may express the type of partial functions from A to B as A ! B.

It will also prove convenient to have a type of all convergent terms:

ffl Every (E ): For any convergent terms e1 and e2, e1 = e2 2 E .
In order to reason about termination in the logic, we add a new type to represent the atomic
proposition of convergence using the same device that we used to add equality, subtyping and
inequality types:

ffl Convergence (t in! T ): The type t in! T is well-formed when t 2 T and is inhabited (by

?) exactly when t#.

2The use of a fix operator greatly simplifies some of the results in this thesis (particularly the proof of Theorem
5.9), but it could in principle be eliminated and replaced with the Y combinator.

40

Note that t in! T is an inhabited type exactly when t in T is. A distinct convergence proposition
is needed in order to provide negatability, which is essential for any nontrivial termination
reasoning. Observe that t in! T is well-formed whenever t 2 T , but t 2 T is well-formed only
when it is true.

Constable and Smith [25, 92, 91] use an untyped convergence assertion in their type systems.
In this type theory I instead use a typed convergence assertion (as in Constable and Smith [24]).
However, an untyped convergence assertion can be defined as t halts = t in! E . (This is the
primary motivation for including the E type.) Unfortunately, as we will see in Section 4.3.1, in
the presence of equality the untyped version is rarely any more useful than the typed version.

Partial Type Formation The convergence type raises a somewhat surprising issue about the
formation of partial types. The type equality rule for convergence types states that t in! T and
t0 in! T are equal when t = t0 2 T , and equal types should always have the same membership.
Therefore, T should never equate convergent and non-convergent terms. However, we desire
that T be a subtype of T (i.e., if t = t0 2 T then t = t0 2 T ), so T should never equate convergent
and non-convergent terms either. Since many terms (Top for example) do equate terms with
different convergence behavior, we must add this as a restriction to the well-formedness of
partial types.

To not equate convergent and non-convergent terms is an awkward condition to maintain,
so instead my theory imposes the stronger condition that for T to be well-formed, T must be
total. It follows trivially that a total type cannot equal convergent and non-convergent terms.
The obvious definition of totality, 8x:T: x in! T , turns out to be non-negatable (since it depends
upon the well-formedness of T ) so I add totality as another primitive type:

ffl Totality (T total): The type T total is well-formed when T type and is inhabited (by ?)

exactly when T contains only terms that converge.

The Fixpoint Principle With partial types in the type theory, recursive functions can be
typed using the fixpoint principle:

e in T ! T ) fix (e) in T
The use of the fixpoint principle was illustrated in Section 3.3.2. However, the fixpoint principle
is not valid for every type; it is only valid for types that are admissible. Admissibility is defined
formally in Chapter 5 (Definition 5.13). Intuitively, a type is admissible if it contains a recursive
term whenever it contains a cofinite set of approximations to that term.

This issue does not arise in most ordinary programming languages because most type systems are not rich enough to allow the expression of inadmissible types. Nuprl is expressive
enough to construct inadmissible types, but nevertheless most types are still admissible. Chapter 5 discusses admissibility in detail, and presents a number of techniques for showing types
to be admissible.

Admissibility is introduced into the logic as another atomic proposition:

ffl Admissibility (T admiss): The type T admiss is well-formed when T type and is inhabited

(by ?) exactly when T is admissible.

This completes the set of primitive Nuprl types (except for four additional atomic propositions
introduced in Chapter 5). The list is summarized in Figure 4.4.

41

void Void
atom Atom
integer Z
disjoint union A + B
product space \Sigma x:A:B
function space \Pi x:A:B
very-dependent function ff j x:A ! Bg
partial type A
universe Ui

equality e1 = e2 in A
subtyping A _ B
inequality n1 ^ n2
convergence e in! A
totality A total
admissibility A admiss
set fx : A j P g
quotient xy:A==P
every E

Figure 4.4: Primitive Nuprl Types
Sequencing The final construct in the partial type theory is the sequencing construct let x =
e1 in e2. This expression evaluates e1 to canonical form (say v) then evaluates e2[v=x]. Hence,
the sequence term diverges if either e1 or e2 does. Since e2 is only evaluated if e1 converges,
the e2 portion of the sequencing term may be typed under the assumption that x has a total
type (the syntax for Nuprl sequents is formally defined in the next section):

H `* e1 in T H; x:T `* e2 in T 0 H `* T 0 type

H `* let x = e1 in e2 in T 0

As an aside, if T is reinterpreted as a monad type M (T ), then this is precisely the typing rule
for the bind operator in monad systems [74, 95, 94]. A monad system would also have a unit
operator to coerce T to M (T ); in this theory that is taken care of by subsumption, since T _ T .

One may extend the theory to a full type theory of monads by dispensing with T _ T ,
adding an explicit unit operator and adding rules comprising the monadic equality laws. This
would provide a powerful mechanism for abstractly managing effects in general [34], not just the
nontermination effects managed by the partial types. I have not done so in this type theory,
preferring instead to keep the type theory closely tied to its operational semantics, thereby
providing as much structure as possible at the expense of abstraction (recall Section 3.2.1).

4.2 Sequents and Proof
The Nuprl inference system has one judgement form, written as the sequent:

x1:T1; : : : ; xn:Tn `* C / t
This may be read informally as "t is a member of C when x1; : : : ; xn are members of T1; : : : ; Tn."
A more precise interpretation is discussed in Section 4.2.1 and a formal semantics is defined in
Section 4.4.2. The bindings (x1:T1; : : : ; xn:Tn) to the left of the turnstile are called hypotheses,
C is called the conclusion and t is called the witness.

The inference rules for deriving judgements of this form are listed in Appendix B. By way
of example, Rule 21 for applying subtyping amidst the hypothesis list is:

H; x : T 0; J `* C / s H `* T _ T 0

H; x : T ; J `* C / s

Note that in this rule the second subgoal is a subtyping proposition, which is computationally
uninteresting (it contains only terms that evaluate to ?). Since that proposition is computationally uninteresting, the statement of the rule suppresses the witness. In many rules the

42

consequent also is computationally uninteresting and the witness is suppressed in such rules as
well. In those rules, the witness should be taken to be ?. An example of such a rule is Rule 21
for applying subtyping in an equality assertion:

H `* t1 = t2 in T 0 H `* T 0 _ T

H `* t1 = t2 in T

Implicitly, this stands for the rule:

H `* t1 = t2 in T 0 / t H `* T 0 _ T / t0

H `* t1 = t2 in T / ?

4.2.1 Functionality
A sequent x1:T1; : : : ; xn:Tn `* C / t asserts not only membership of the witness t in the
conclusion type C, it also asserts that the conclusion and witness are functional over the
hypothesis variables. That is, if ~t = t1; : : : ; tn and ~t0 = t01; : : : ; t0n are equal substitutions for
x1:T1; : : : ; xn:Tn (in a manner that will be made precise in Section 4.4.2) then C[~t=~x] = C[~t0=~x]
and t[~t=~x] = t[~t0=~x] 2 C[~t=~x]. To see why this interpretation is necessary, consider the rule:

H `* A type H; x : A `* B / b

H `* A ! B / *x:b

The consequent states that *x:b is a function over A; that is, if a = a0 2 A then b[a=x] =
b[a0=x] 2 B. Under a weaker, membership only, interpretation of sequents, the second subgoal
is sufficient to conclude that b[a=x] 2 B and b[a0=x] 2 B, but cannot guarantee equality. A
functional interpretation of sequents (where sequents are seen as functions from hypotheses to
the conclusion) is necessary to validate the many rules of this form.3

4.2.2 Extract-Style Proof
In order to prove some proposition P , the propositions-as-types correspondence dictates that
one prove a sequent of the form `* P / t. However, it is typically the case that one is only
interested in proving the truth (inhabitation) of a proposition, and is not concerned that witness
be a particular term. Consequently, in the Nuprl proof development system [19, 56], a user is
presented with a sequent that omits the "/ t" witness term, even in cases when conclusion is
computationally interesting. The rules are then stated in a manner that makes it possible to
extract the witness from the proof. This is called extract-style proof. For example, consider
again the rule:

H `* A type H; x : A `* B / b

H `* A ! B / *x:b

In extract-style proof, this rule is applied to a sequent of the form H `*e P ) Q to produce
subgoals H `*e P type and H; x : P `*e Q. From the proof of the second subgoal is extracted
a witness b, possibly containing free occurrences of the variable x, and that witness is used to
construct the extract, *x:b, of the original sequent. In fact, since the variable x is only used

3In some alternative semantics for type theory (such as Howe's set theoretic semantics [54]), equality in a type
may be collapsed to actual object equality, trivially making the membership and functionality interpretations
the same. Extending the semantics of Howe to account for all the devices in this type theory is an open problem,
but one that shows some promise of feasibility.

43

in the extract, it may be made invisible to the user as well, resulting in the simple subgoal
H; P `*e Q.

For extract-style proof to be possible, all the rules in the system must be of the proper form.
Specifically, the rules must construct extracts in a bottom-up manner, or, in other words, the
applicability of a rule must not depend on the extract, since the extract cannot be known at the
time the rule is applied. However, the phrasing of the Nuprl proof rules that I state in Appendix
B, is devised in the interest of making the type theory as simple as possible, not supporting
extract-style proof, so some rules are not of the proper form. To support extract-style proof,
those rules must be replaced with extract-compatible rules. Fortunately, the necessary rules
are all derivable from the existing rules, so it is possible to support extract-style proof without
any additional metatheoretical justification.

The necessary condition for extract-compatibility is best understood by examining some
rules that violate it and seeing how they may be rewritten to follow it:

Extract and Membership The function type inhabitation rule discussed above is not among
the basic rules of the inference system. Rather it is derivable from them the equality rule on
function types:

H `* A type

H; x : A `* B / b
H; x : A `* b in B (5)
H `* *x:b in A ! B (60)

H `* A ! B / *x:b (4)

We gain considerable economy in the derivation rules by leaving out such inhabitation rules
and allowing them to be derived from the others, but in an extract-style system they must be
built-in instead. This is because Rule 5 is not appropriate for extract-style proof:

H `* C / t
H `* t in C

For this rule to be applicable, the extract t of the subproof must be the same term t that is
specified in the membership proposition in the consequent, and there is no guarantee that it
will. Another way of looking at this problem is that the rule with witnesses stripped out is
unsound; it does not follow from the inhabitation of C that any particular term t belongs to C:

H `*e C
H `*e t in C (wrong )

In an extract-style proof system, Rule 5 must be omitted and replaced by an inhabitation rule
to mirror each basic equality rule (e.g., 47, 48, 53, 60). However, note that the converse rule,
Rule 4, does not pose problems for extract-style proof.

Hypothesis Elimination Another class of rules that impose a restriction on the extract
term is the hypothesis elimination rules. The hypothesis elimination rule for products requires
(Rule 56) that all free occurrences of x and y in the extract term must appear as the pair hx; yi:

H; x : A; y : B; J [hx; yi=z] `* C[hx; yi=z] / s[hx; yi=z]

H; z : \Sigma x:A:B; J `* C / s (x; y 62 J; C; s)

To make this rule suitable for extract-style proof, it must be rephrased as the derivable rule:

H; x : A; y : B; J [hx; yi=z] `* C[hx; yi=z] / s

H; z : \Sigma x:A:B; J `* C / s[ss1(z); ss2(z)=x; y]

44

Similarly, the hypothesis elimination rule for disjoint unions,

H; y : A; J [inj 1(y)=x] `* C[inj 1(y)=x] / s[inj 1(y)=x]
H; y : B; J [inj 2(y)=x] `* C[inj 2(y)=x] / s[inj 2(y)=x]

H; x : A + B; J `* C / s (y 62 J; C; s)

must be rephrased as the derivable rule:

H; y : A; J [inj 1(y)=x] `* C[inj 1(y)=x] / s1
H; y : B; J [inj 2(y)=x] `* C[inj 2(y)=x] / s2

H; x : A + B; J `* C / case(x; y:s1; y:s2)

In contrast to these two rules, the hypothesis elimination rules for types with "uninteresting"
memberships, such as the equality types (Rule 99), do not pose a problem:

H; x : (t = t0 in T ); J [?=x] `* C[?=x] / s[?=x]

H; x : (t = t0 in T ); J `* C / s

In these rules it is not a problem for ? terms to propagate upwards, so such rules may be applied
simply by assuming that x does not appear free in s.

Hidden Variables A special case of hypothesis elimination that poses particular difficulties
is that of set and quotient types. The hypothesis elimination rule for set types (Rule 86) is:

H; x : A; y : B; J `* C / s
H; x : fx : A j Bg; J `* C / s (y 62 J; C; s)

As before, y is prohibited from appearing free in the extract term s, but in this case the rule
cannot be rephrased to make the problem disappear. The essential problem is that y represents
computational content that is not available, so the extract cannot depend upon it in any way.
To enforce this restriction, we must introduce a new mechanism: When the rule is applied, the
variable y is marked as hidden, establishing the invariant that it may not appear free in the
extract: H; x : A; [y : B]; J `

*e C

H; x : fx : A j Bg; J `*e C

This invariant is preserved by the inference system, and disallows the application of any rule
that would use that variable. However, when descending into subgoals that do not contribute
to the extract all hiding annotations may be removed.

It is important to note that this hidden variable mechanism is only a practical syntactic
device, and has no metatheoretical significance. The sole metatheoretical issue is addressed in
Rule 86 by the side condition that y not appear free in the extract.

4.3 Issues in Partial Object Type Theory
The type theory presented here joins together the expressiveness of the standard Nuprl type
theory, which does not support reasoning about partial objects (that is, nonconvergent terms),
and the type theory of Smith [92, 91], which addresses partial objects but does not support
equality. This theory also enhances Smith's theory by a considerably wider class of types that
are admissible for fixpoint induction (discussed at length in Chapter 5). Here I discuss some
issues arising in the design and application of a partial object type theory, particularly those
resulting from the combination of equality and partial objects.

45

4.3.1 Partial Computation
Given two terms a and b, each of which belong to Z, it is intuitively clear that the sum a + b
should also belong to Z. However, the rules for integer expressions deal with convergent terms:

H `* a in Z H `* b in Z

H `* a + b in Z

An informal argument for the desired membership is easy: To show that a + b in Z, suppose
that (a + b) halts and show a + b in Z. If (a + b) halts , then a halts and b halts . Consequently
a in Z and b in Z and therefore a + b in Z by the rule.

Unfortunately, formalizing this argument as a derivation runs into a problem; to show
the desired membership we incur the additional obligation of showing that the supposition
(a + b) halts is well-formed, as in the derivation below, and the eventual subgoal a + b in E is
no easier to prove than the original goal a + b in Z.

H `* a + b in E
H `* (a + b) halts type (108)..

..
H `* (a + b) halts , (a + b) halts H; x : (a + b) halts `* a + b in Z

H `* a + b in Z (71)

This difficulty does not reveal a defect in the logic. The problem is that in the presence of
equality, as discussed in Section 4.2.1, a sequent says much more than its naive reading; it
asserts the functionality of the conclusion over equal substitutions for the hypotheses. The
informal argument at the top is perfectly valid as a metatheoretical argument for closed terms,
but it does not extend to sequents.

However, it certainly would be a defect in the logic if goals of this form were unprovable.
This could be settled by fiat, by simply adding new partial typing rules for each operator, but
we would rather avoid such a heavy-handed solution. I present a more palatable solution in the
next section.

4.3.2 Computation in Active Positions
Consider the monad-style variation of a + b obtained by first computing the summands to
canonical form and them summing their values: let x = a in let y = b in x + y. This is easily
shown to belong to Z:

H `* a in Z

H; x : Z `* b in Z

H; x : Z; y : Z `* x + y in Z (44; 1)
H; x : Z; y : Z `* x + y in Z (70)
H; x : Z `* (let y = b in x + y) in Z (81)
H `* (let x = a in let y = b in x + y) in Z (81)

The desired result then follows by direct computation if it can be shown that `* a+ b , (let x =
a in let y = b in x + y). Of course, in general t2[t1=x] is not equivalent to let x = t1 in t2,
because the latter necessarily evaluates t1 but the former might not, which would lead to
different convergence behavior if t1 is divergent. However, in this case the term a + b does
evaluate a and b before converging.

The general principle at work here is that x and y are both in active positions in the
term x + y. An active position of a term is one that must be evaluated before the term can

46

converge. Canonical terms have no active positions, since they have already converged. The
active positions of non-canonical terms are defined as follows:

Definition 4.5 A term e appears actively in t if:

ffl t j e, or
ffl t j case(t1; x:t2; x:t3) and e appears actively in t1, or
ffl t j t1t2 and e appears actively in t1, or
ffl t j ssi(t0) and e appears actively in t0, or
ffl t j t1 =A t2 or t j t1 =Z t2 or t j t1 ^Z t2 and e appears actively in t1 or t2, or
ffl t j let x = t1 in t2 and e appears actively in t1 or t2, or
ffl t j t1 \Phi  t2 and e appears actively in t1 or t2, or
ffl t j fix (t0) and e appears actively in t0
Lemma 4.6 If x appears actively in t then t[e=x] , let x = e in t.
This lemma is put into practice in the type theory as Rule 15:

x appears actively in t2
`* t2[t1=x] , let x = t1 in t2

Another application of this device is for computational inducement. Observe that evaluating
a + b induces the evaluation of a and b, so if a + b converges then so do a and b. This can be
proven using active positions:

H `* a + b in! Z `* (let x = a in x + b) , a + b (15; 11)

H `* (let x = a in x + b) in! Z (8) H `* a in Z

H `* a in! Z (80)

4.3.3 Fixpoint Induction
The principal device for reasoning about programs in the LCF system [38] was fixpoint induction. Informally, fixpoint induction says that if an "admissible" predicate holds for divergent
terms and it is preserved by f , then it holds for the fixpoint of f . In notation: if P [?] and if
P [x] ) P [f (x)] then P [fix (f )].

Using the fixpoint principle in our type theory, we may derive a similar induction rule:

H; x : T ; y : (x in! T ) P ) `* P
H; x : T ; y : P ; z : (f x in! T ) `* P [f x=x]
H `* f in T ! T
H; x : T `* P type
H `* T total
H `* T admiss
H `* P admiss (x : T )
H; x : T ; y : #P `* P / e

H `* P [fix (f )=x] / e[fix (f ); ?=x; y]

47

This rule looks considerably more complicated than the informal statement, so let us examine
it in detail. The first subgoal,

H; x : T ; y : (x in! T ) P ) `* P
corresponds to the base case, P [?]. If one accepts classical reasoning principles, in particular
the proposition (x in! T ) . :(x in! T ), then this goal may be proven from the simpler goal
H `* P [?=x]. In Section 4.4.3, I discuss how classical reasoning principles may be justified
semantically if one takes a classical view of the metatheory. However, it is usually the case that
the given subgoal can be proven whenever H `* P [?=x] can, so classical methods are usually
unnecessary.

The second subgoal,

H; x : T ; y : P ; z : (f x in! T ) `* P [f x=x]
corresponds to the inductive case, P [x] ) P [f (x)]. The z hypothesis indicates that we are not
in the base case (i.e., f (x) 6= ?), and may be dropped, if desired, to bring the goal more in line
with the informal statement.

The next three subgoals are basic well-formedness conditions. The sixth subgoal, H `*
T admiss, is also a well-formedness condition, which is needed to take the fixpoint of f . The
seventh subgoal, H `* P admiss(x : T ), is the requirement on the admissibility of the predicate.
(More on this in Section 5.3.1.)

The final subgoal is the most curious:

H; x : T ; y : #P `* P / e
This goal stems from the uniformity condition for admissibility of set types (Section 5.3.3), but
we may give an informal explanation directly in the context of fixpoint induction. Suppose
v0 and g are the computational content of the base case and inductive case, respectively. For
simplicity, assume that v0 2 P [?=x] and g 2 P [t=x] ! P [f (t)=x] (for all t 2 T ). Then we
may build a sequence of P inhabitants for each of the finite approximations of fix (f ): Let
vi+1 = g(vi) so v0 2 P [?=x], v1 2 P [f (?)=x], v2 2 P [f (f (?))=x]; etc. We need a limit term
to inhabit the proposition P [fix (f )=x]. However, the sequence terms v0; v1; v2; : : : are unrelated
by computational approximation (Section 5.2.1) and do not in general approach any limit.

The final subgoal provides a term e that allows us to build a uniform sequence of inhabitants
that will approach a limit. Since the sequence v0; v1; v2; : : : inhabits the various P propositions,
the sequence e[?=x]; e[f (?)=x]; e[f (f (?))=x]; : : : also inhabits the various P propositions, and
the latter is guaranteed to approach a limit.

Lemma 4.7 The fixpoint induction rule is derivable.
Proof

The full derivation of the rule is tedious, so I sketch the argument. Let T 0 = fx : T j P g.
The key points are to show T 0 _ fx : T j P g and to show that f in T 0 ! T 0. From the
latter, and since T 0 is admissible (Rule 143 and subgoals 6, 7 and 8), we may conclude that
fix (f ) in T 0. Thus, by the first point, fix (f ) in fx : T j P g. We may then use subgoal 8 to
reconstruct the suppressed computational content of P [fix (f )=x].

To show T 0 _ fx : T j P g uses the base case. Suppose x in T 0. We wish to show that x in T
and P is inhabited. The former is easy, since T 0 _ T . To show the latter, suppose x halts

48

(i.e., x in! T ). Then x in T 0, so P is inhabited. Hence x in! T ) P . By the base case
subgoal, P is inhabited.

To show f in T 0 ! T 0 uses the inductive case. Suppose x in T 0. We wish to show that
f x in T 0. Suppose f x halts (i.e., f x in! T ). Then we wish to show that f x in T 0; that
is, that f x in T and P [f x=x] is inhabited. The former follows trivially from f x in! T . To
show the latter, observe that x in fx : T j P g (since T 0 _ fx : T j P g). Consequently P is
inhabited. By the inductive case subgoal, P [f x=x] is inhabited. 2

Two somewhat similar results to Lemma 4.7 were proven by Smith [92, 91]. Smith's results
differed in that one used classical reasoning principles and was based on the then-conjectural
admissibility of set types, and the other required the witnesses of the base and inductive cases
to have particular forms.

4.3.4 Computational Induction
Smith's type theory also provided another principle, computational induction, for reasoning
about partial objects. The idea to computational induction is that when a term converges,
it induces a well-founded order on its computation's intermediate values. Computational induction is generally useful for reasoning about programs since it corresponds to the intuitive
mechanism of reasoning about recursive programs by preconditions and postconditions, but it
is particularly useful for proving partial correctness of programs. Other induction principles are
inadequate for such proofs; if one could find a well-founded order on the inputs of a recursive
function, one could show total correctness instead.

Unfortunately, computation is an intrinsically intensional property; that is, it requires reasoning about the structure of terms as well as about their result value. In contrast, my type
theory is extensional; terms with the same result value are indistinguishable. Consequently, it
is trivially true that P [t2] ) P [t1] when t1 7! t2, and one may not draw any inductive conclusions from the fact. Smith's type theory was able to support computational induction because
it supported no notion of equality or functionality.

In order to support computational induction, we need to add support for intensional reasoning about terms. We may do this by adding to the type theory representations for all terms,
and by adding rules for reasoning intensionally about those representations and for linking
those representations back to the terms they represent. Mechanisms for accomplishing this are
discussed in detail in Constable and Crary [23].

4.3.5 Other Contributions
The version of the Nuprl type theory presented in this chapter makes a few minor contributions
other than those contributions relating to partial types:

ffl By adding a primitive subtyping assertion, subtyping becomes negatable (recall Section

4.1.4). This makes it possible to prove theorems that depend upon subtyping conditions.
More importantly, however, it makes it possible to define the power kind as Pi(T ) = fS :
Ui j S _ T g (recall Section 3.3.3). Without a negatable subtyping assertion, this set type
is ill-formed.

ffl This type theory adds rules for a typehood assertion, T type, which may be defined

either as *x:x in T ! T or as T _ T . I use the latter definition, in order to share some

49

rules with the subtyping assertion. Using a typehood assertion streamlines dealings with
well-formedness subgoals, such as the first subgoal of:

H `* A type H; x : A `* b in B

H `* *x:b in \Pi x:A:B

In the standard Nuprl theory, which does not use typehood assertions, the well-formedness
subgoal is stated as membership in some universe: A in Ui . However, to prove such a
subgoal requires the determination of which universe Ui the type A belongs to. This is
often inconvenient, and is sometimes impossible. For example, sometimes typehood can
only be shown using an inhabitation rule (Rule 19):

H `* t = t0 in T

H `* T type

This rule could not be stated in the standard theory, using universe membership, because
it would need to conclude that T was a member of some unknown universe Ui , and there
is no facility for existentially quantifying universe indices.

The use of typehood assertions is also useful in that it makes the type theory extensible
to systems where some types do not belong to any universe. For example, suppose the
computation system were augmented with a noncanonical operator U (\Gamma ) with the evaluation rule U (n) 7!s Un (for integer literals n). Then \Sigma x:Z: U (x) would be a valid type,
but since U (x) spans the universes, the type would be too large to belong to any single
universe.

ffl The inclusion of an inhabitation-to-membership rule (Rule 5) makes it possible to derive

the type inhabitation rules from the rules governing equality on types. This cuts the
number of rules nearly in half. As discussed in Section 4.2.2, an extract-style proof
development system must reintroduce those rules, but they may be reintroduced as derived
rules without additional metatheoretic justification.

4.4 Semantics
The remaining task is to show that the type theory presented here is consistent. As usual, I
do this by showing it sound with respect to a semantics. The development of the semantics is
divided into two parts; I begin by giving a semantics for types and then extend that semantics to
cover judgements as well. I give this semantics in the framework of partial equivalence relations.
Semantics exist for related theories (standard Nuprl or Martin-L"of type theory [67, 68]) in the
frameworks of set theory [54] and domain theory [87, 81, 80], among others [4, 10], and could
probably be developed for my theory as well.

4.4.1 Type Semantics
The semantics of types is characterized by the relations t1 = t2 2 T and T1 = T2 from Section
4.1.2. The first relation associates with each type T a partial equivalence relation,4 \Gamma  = \Gamma  2 T ,
over the set of terms. That relation dictates which terms belong to the type and which are
equal within that type. The second relation is another partial equivalence relation over terms
that dictates which terms are types and which are equal types.

4A symmetric and transitive relation.

50

t 2 T iff t = t 2 T
T type iff T = T
T1 = T2 iff 9T

01; T 02: (T1 + T 01) ^ (T2 + T 02) ^ (T 01 = T 02)

t1 = t2 2 T iff 9t

01; t02; T 0: (t1 + t01) ^ (t2 + t02) ^ (T + T 0) ^ (t01 = t02 2 T 0)

:(t1 = t2 2 Void)
a = a

0 2 Atom (a, a0 atoms) iff a j a0

n = n

0 2 Z (n, n0 integers) iff n j n0

t = t

0 2 E iff t# ^ t0#

inj 1(a) = inj 1(a

0) 2 A + B iff A + B type ^ a = a0 2 A

inj 2(b) = inj 2(b

0) 2 A + B iff A + B type ^ b = b0 2 B

ha; bi = ha

0; b0i 2 \Sigma x:A:B iff \Sigma x:A:B type ^ (a = a0 2 A) ^ (b = b0 2 B[a=x])

*x:b = *x:b

0 2 \Pi x:A:B iff \Pi x:A:B type ^ 8a = a0 2 A: b[a=x] = b0[a0=x] 2 B[a=x]

*x:b = *x:b

0 2 ff j x:A ! Bg iff ff j x:A ! Bg type ^ 8a = a0 2 A: b[a=x] = b0[a0=x] 2 B[*x:b; a=f; x]

t = t

0 2 T iff T type ^ (t# , t0#) ^ (t# ) t = t0 2 T )

a = a

0 2 fx : A j Bg iff fx : A j Bg type ^ a = a0 2 A ^ 9b: b 2 B[a=x]

a = a

0 2 xy:A==B iff (xy:A==B) type ^ a 2 A ^ a0 2 A ^ 9b: b 2 B[a; a0=x; y]

? 2 (a = a

0 in A) iff (a = a0 in A) type ^ (a = a0 2 A)

? 2 (A _ B) iff (A _ B) type ^ 8a = a

0 2 A: a = a0 2 B

? 2 (t ^ t

0) iff (t ^ t0) type ^ 9n; n0: t + n ^ t0 + n0 ^ n ^ n0

? 2 (a in! A) iff (a in! A) type ^ a#
? 2 (A total) iff (A total) type ^ 8t 2 A: t#
? 2 (A admiss) iff (A admiss) type ^ Adm(A)

For T ' T

0 iff T = T 0, and for T ' T 0 iff T = T 0 2 Ui:

Void ' Void Atom ' Atom Z ' Z E ' E
A + B ' A

0 + B0 iff A ' A0 ^ B ' B0

\Sigma x:A:B ' \Sigma x:A

0:B0 iff A ' A0 ^ 8a = a0 2 A: B[a=x] ' B0[a0=x]

\Pi x:A:B ' \Pi x:A

0:B0 iff A ' A0 ^ 8a = a0 2 A: B[a=x] ' B0[a0=x]

ff j x:A ! Bg ' ff j x:A

0 ! B0g iff A ' A0 ^

9P; ! : 8a1 = a

01 2 A: 8a2 = a02 2 A: P [a1; a2=x; y] ' P [a01; a02=x; y] ^

8a; a

0: a ! a0 , (9e: e 2 P [a; a0=x; y]) ^ ! is well-founded ^

8a = a

0 2 A: 8t = t0 2 ff j x:fe : A j P [e; a=x; y]g ! Bg:

B[t; a=f; x] ' B

0[t0; a0=f; x]

T ' T 0 iff T ' T

0 ^ 8t 2 T: t#

fx : A j Bg ' fx : A

0 j B0g iff A ' A0 ^ 8a = a0 2 A: B[a=x] ' B[a0=x] ^

8a = a

0 2 A: B0[a=x] ' B0[a0=x] ^

9t: t 2 \Pi x:A: B ! B

0 ^ 9t: t 2 \Pi x:A: B0 ! B

(xy:A==B) ' (xy:A

0==B0) iff A ' A0 ^

8a1 = a

01 2 A: 8a2 = a02 2 A: B[a1; a2=x; y] ' B[a01; a02=x; y] ^

8a1 = a

01 2 A: 8a2 = a02 2 A: B0[a1; a2=x; y] ' B0[a01; a02=x; y] ^

9t: t 2 \Pi x:A: \Pi y:A: B ! B

0 ^ 9t: t 2 \Pi x:A: \Pi y:A: B0 ! B ^

9t: t 2 \Pi x:A: B[x=y] ^ 9t: t 2 \Pi x:A: \Pi y:A: B ! B[y; x=x; y] ^
9t: t 2 \Pi x:A: \Pi y:A: \Pi z:A: B ! B[y; z=x; y] ! B[z=y]
(a1 = a2 in A) '

(a

01 = a02 in A0) iff A ' A0 ^ a1 = a01 2 A ^ a2 = a02 2 A

(A _ B) ' (A

0 _ B0) iff A ' A0 ^ B ' B0

(t1 _ t2) ' (t

01 _ t02) iff t1 = t01 2 Z^ t2 = t02 2 Z

(a in! A) ' (a

0 in! A0) iff A ' A0 ^ a = a0 2 A

(A total) ' (A

0 total) iff A ' A0

(A admiss) ' (A

0 admiss) iff A ' A0

Ui type
Ui 2 Uj iff i ! j

Figure 4.5: Type Specifications

51

These relations are specified in Figure 4.5. Unfortunately, the specification contains negative
occurrences of the relations being defined, so it cannot be taken as a valid inductive definition.
However, examination reveals that each clause of the specification uses the relations only at
types smaller than the type at issue in the clause. This suggests a way that we may rephrase
the specification as a valid inductive definition. The technique I use is due to Allen [5]; my
contribution here is its extension to a number of new types. An alternative but similar technique
is that of Harper [40], who shows how the specification can be rephrased to define an explicit
set theoretic relation as the least fixed point of a monotone operator.

The principal notion in the construction is that of a type system. A candidate type system
o/ is a relation o/ T T 0OE between closed terms T and T 0 and binary relations OE over closed terms.
The intended reading of o/ T T 0OE is that T and T 0 are equal types and OE is their equality relation.

Definition 4.8 A type system is a candidate type system o/ that satisfies seven properties:

ffl o/ is uniquely valued: if o/ T T 0OE and o/ T T 0OE0 then OE is OE0
ffl o/ is type symmetric: if o/ T T 0OE then o/ T 0T OE
ffl o/ is type transitive: if o/ T1T2OE and o/ T2T3OE then o/ T1T3OE
ffl o/ is type value respecting: if o/ T T OE and T 7! T 0 then o/ T T 0OE
ffl o/ is term symmetric: if o/ T T 0OE then OE is symmetric
ffl o/ is term transitive: if o/ T T 0OE then OE is transitive
ffl o/ is term value respecting: if o/ T T 0OE and t OE t and t 7! t0 then t OE t0

The goal is to build a type system that captures the intended meanings of the types. I
do this be defining a series of operators on candidate type systems. Note that each operator
uses it argument o/ only in positive positions, so they may be assembled into a valid inductive
definition.

The first (and most important) step of the construction is to define, for each type constructor, an operator on candidate type systems. Given candidate type system o/ , each operator is
to return a type system that contains all types built using its type constructor from types in
o/ . For example, Prod(o/ ) will contain all product types built from types in o/ . These operators
define the meanings of the type constructors. Their definitions appear in Figures 4.6 through
4.8.

Next we define another operator Close on candidate type systems. Given type system
o/ , Close(o/ ) contains all types built from types in o/ using any type constructor other than
universes. The intention is that the argument o/ define all universes up to some Ui , in which
case Close(o/ ) will define all types built from those universes, that is, all members of Ui+1 .
Close(o/ ) is defined to be the smallest candidate type system such that:

Close(o/ )T T 0OE iff o/ T T 0OE . (Wop2Types op(Close(o/ ))T T 0OE)

where Types = 8!:

Void; Atom; Int; Every; Union;
Prod; Fun; VFun; Bar; Eq; Sub;
Ineq; Conv; Total; Adm; Set; Quot

9=
;
Next we use mutual induction to define two series of candidate type systems, Univi and Nuprli.
Univi defines all universes Uj where j ! i, and Nuprli defines all types built up from those

52

Void(\Gamma )T T

0OE iff T + Void ^ T 0 + Void ^ 8t; t0: :(t OE t0)

Atom(\Gamma )T T

0OE iff T + Atom ^ T 0 + Atom ^ 8t; t0: t OE t0 , (9a 2 fatomsg: t + a ^ t0 + a)

Int(\Gamma )T T

0OE iff T + Z^ T 0 + Z^ 8t; t0: t OE t0 , (9n 2 fintegersg: t + n ^ t0 + n)

Every(\Gamma )T T

0OE iff T + E ^ T 0 + E ^ 8t; t0: t OE t0 , (t# ^ t0#)

Union(o/ )T T

0OE iff 9A; B; A0; B0; ff; fi:

T + A + B ^ T

0 + A0 + B0 ^ o/ AA0ff ^ o/ BB0fi ^

8t; t

0: t OE t0 ,

(9a; a

0: t + inj

1(a) ^ t

0 + inj

1(a

0) ^ a ff a0) .

(9b; b

0: t + inj

2(b) ^ t

0 + inj

2(b

0) ^ b ff b0)

Prod(o/ )T T

0OE iff 9A; B; A0; B0; ff; fi(

\Gamma ):

T + \Sigma x:A:B ^ T

0 + \Sigma x:A0:B0 ^ o/ AA0ff ^

8a; a

0: a ff a0 ) o/ (B[a=x])(B0[a0=x])fia ^

8t; t

0: t OE t0 ,

9a; b; a

0; b0: t + ha; bi ^ t0 + ha0; b0i ^ a ff a0 ^ b fia b0

Fun(o/)T T

0OE iff 9A; B; A0; B0; ff; fi(

\Gamma ):

T + \Pi x:A:B ^ T

0 + \Pi x:A0:B0 ^ o/ AA0ff ^

8a; a

0: a ff a0 ) o/ (B[a=x])(B0[a0=x])fia ^

8t; t

0: t OE t0 ,

9b; b

0: t + *x:b ^ t0 + *x:b0 ^

8a; a

0: a ff a0 ) b[a=x] fia b0[a0=x]

VFun(o/)T T

0OE iff 9A; B; A0; B0; P; !; ff; fl(

\Gamma ); ffi(\Gamma ;\Gamma ); ae(\Gamma ;\Gamma ):

T + ff j x:A ! Bg ^ T + ff j x:A

0 ! B0g ^ o/ AA0ff ^

8a1; a2; a

01; a02: a1 ff a01 ) a2 ff a02 )

o/(P [a1; a2=x; y])(P [a

01; a02=x; y])ae(a

1;a2) ^8a; a
0: a ! a0 , (9e: e ae(a;a

0) e) ^ ! is well-founded ^

8a; t; a

0; t0: a ff a0 ) t fla t0 ) o/(B[t; a=f; x])(B0[t0; a0=f; x])ffi(t;a) ^

8e; t; t

0: e ff e )

t fle t

0 ,

9b; b

0: t + *x:b ^ t0 + *x:b0 ^

8a; a

0: a ff a0 ) a ! e ) b[a=x] ffi(t;a) b0[a0=x]) ^

8t; t

0: t OE t0 ,

9b; b

0: t + *x:b ^ t0 + *x:b0 ^

8a; a

0: a ff a0 ) b[a=x] ffi(t;a) b0[a0=x]

Bar(o/)T T

0OE iff 9A; A0; ff:

T + A ^ T

0 + A0 ^ o/ AA0ff ^

8a: a ff a ) a# ^
8t; t

0: t OE t0 ,

(t# , t

0#) ^ (t# ) t ff t0)

Figure 4.6: Type Definitions (Data Types)

53

Eq(o/ )T T

0OE iff 9A; A0; a1; a2; a01; a02; ff:

T + (a1 = a2 in A) ^ T

0 + (a01 = a02 in A0) ^

o/ AA

0ff ^ a1 ff a01 ^ a2 ff a02 ^

8t; t

0: t OE t0 , (t + ? ^ t0 + ? ^ a1 ff a2)

Sub(o/ )T T

0OE iff 9A; B; A0; B0; ff; fi:

T + (A _ B) ^ T

0 + (A0 _ B0) ^ o/AA0ff ^ o/BB0fi ^

8t; t

0: t OE t0 , (t + ? ^ t0 + ? ^ 8a; a0: a ff a0 ) a fi a0)

Ineq(\Gamma )T T

0OE iff 9e1; e2; e01; e02: 9n1; n2 2 fintegersg:

T + (e1 ^ e2) ^ T

0 + (e01 ^ e02) ^

e1 + n1 ^ e

01 + n1 ^ e2 + n2 ^ e02 + n02 ^

8t; t

0: t OE t0 , (t + ? ^ t0 + ? ^ n1 ^ n2)

Conv(o/)T T

0OE iff 9A; A0; a; a0; ff:

T + (a in! A) ^ T

0 + (a0 in! A0) ^ o/AA0ff ^

(8e: e ff e ) e#) ^ (a# , a

0#) ^ (a# ) a ff a0) ^

8t; t

0: t OE t0 , (t + ? ^ t0 + ? ^ a#)

Total(o/)T T

0OE iff 9A; A0; ff:

T + (A total) ^ T

0 + (A0 total) ^ o/ AA0ff ^

8t; t

0: t OE t0 , (t + ? ^ t0 + ? ^ 8a: a ff a ) a#)

Adm(o/)T T

0OE iff 9A; A0; ff:

T + (A admiss) ^ T

0 + (A0 admiss) ^ o/AA0ff ^

8t; t

0: t OE t0 ,

t + ? ^ t

0 + ? ^

8f; e; e

0: (9j: 8k * j: e[k]f ff e0[k]f ) ) e[!]f ff e0[!]f

Figure 4.7: Type Definitions (Assertions)

universes.

UniviT T 0OE iff 9j ! i: T + Uj ^ T 0 + Uj ^

8A; A0: A OE A0 , 9ff: NuprljAA0ff

Nuprli def= Close(Univi)
Finally we may define a candidate type system Univ! that defines all universes, and define the
desired Nuprl! to be its closure:

Univ!T T 0OE iff 9i: T + Ui ^ T 0 + Ui ^

8A; A0: A OE A0 , 9ff: NuprliAA0ff

Nuprl! def= Close(Univ!)

We may now define the desired equality relations using Nuprl!:
Definition 4.9

ffl T1 = T2 iff 9OE: Nuprl!T1T2OE
ffl t1 = t2 2 T iff 9OE: Nuprl!T T OE ^ t1 OE t2
It remains to show that the equality relations have the desired properties. First we must show
that Nuprl! is actually a type system, as intended. Then we will observe that Nuprl! adheres
to the specification in Figure 4.5.

Lemma 4.10 If o/ is a type system, then for each op 2 Types, op(o/ ) is a type system.
Lemma 4.11 Each operator in Types defines disjoint types from the others and from o/ (when
o/ defines only universes). Formally, if

54

Set(o/ )T T

0OE iff 9A; B; A0; B0; ff; fi(

\Gamma ); fi

0

(\Gamma ); e; e

0:

T + fx : A j Bg ^ T + fx : A

0 j B0g ^ o/ AA0ff ^

8a; a

0: a ff a0 ) o/(B[a=x])(B[a0=x])fia ^

8a; a

0: a ff a0 ) o/(B0[a=x])(B0[a0=x])fi0a ^

(B implies B

0)

8a; b; a

0; b0: a ff a0 ) b fia b0 ) e[a; b=x; y] fi0a e[a0; b0=x; y] ^

(B

0 implies B)

8a; b; a

0; b0: a ff a0 ) b fi0a b0 ) e0[a; b=x; y] fia e0[a0; b0=x; y] ^

8t; t

0: t OE t0 , (t ff t0 ^ 9b: b fit b)

Quot(o/ )T T

0OE iff 9A; B; A0; B0; ff; fi(

\Gamma ;\Gamma ); fi

0

(\Gamma ;\Gamma ); e; e

0; er; es; et:

T + xy:A==B ^ T + xy:A

0==B0 ^ o/ AA0ff ^

8a1; a2; a

01; a02: a1 ff a01 ) a2 ff a02 )

o/ (B[a1; a2=x; y])(B[a

01; a02=x; y])fi(a

1;a2) ^8a

1; a2; a

01; a02: a1 ff a01 ) a2 ff a02 )

o/ (B

0[a1; a2=x; y])(B0[a01; a02=x; y])fi0

(a1;a2) ^

(B implies B

0)

8a1; a2; a

01; a02; b; b0: a1 ff a01 ) a2 ff a02 ) b fi(a

1;a2) b

0 )

e[a1; a2; b=x; y; z] fi

0

(a1;a2) e[a

01; a02; b0=x; y; z] ^

(B

0 implies B)

8a1; a2; a

01; a02; b; b0: a1 ff a01 ) a2 ff a02 ) b fi0

(a1;a2) b

0 )

e[a1; a2; b=x; y; z] fi(a1;a2) e[a

01; a02; b0=x; y; z] ^

(reflexivity)
8a; a

0: a ff a0 ) er[a=x] fi(a;a) er[a0=x] ^

(symmetry)
8a1; a2; a

01; a02; b; b0: a1 ff a01 ) a2 ff a02 ) b fi(a

1;a2) b

0 )

es[a1; a2; b=x; y; z] fi(a2;a1) es[a

01; a02; b0=x; y; z] ^

(transitivity)
8a1; a2; a3; a

01; a02; a03; b1; b2; b01; b02:

a1 ff a

01 ) a2 ff a02 ) a3 ff a03 )

b1 fi(a1;a2) b

01 ) b2 fi(a

2;a3) b

02 )

et[a1; a2; a3; b1; b2=x; y; z; v; w] fi(a1;a3)

es[a

01; a02; a03; b01; b02=x; y; z; v; w] ^

8t; t

0: t OE t0 , (t ff t ^ t0 ff t0 ^ 9b: b fi(t;t

0) b)

Figure 4.8: Type Definitions (Set and Quotient)

ffl o/ is type symmetric and type transitive, and
ffl o/ defines only universes (that is, if o/ T T OE then T + Ui for some i), and
ffl Close(o/ )T1T 01OE1 and Close(o/ )T2T 02OE2, and
ffl either T1 j T2 or T1 j T 02,
then either o/ T1T 01OE1 and o/ T2T 02OE2, or for some op 2 Types, op(Close(o/ ))T1T 01OE1 and
op(Close(o/ ))T2T 02OE2.

Lemma 4.12 If o/ is a type system and if o/ defines only universes, then Close(o/ ) is a type
system.

Lemma 4.13 For all i, Univi and Nuprli are type systems.

55

Lemma 4.14 Univ! and Nuprl! are type systems.
Proof

First show that Univ! is a type system: All but unique valuation and type transitivity are
directly by Lemma 4.13. For unique valuation and type transitivity, use Lemma 4.13 with
the observation that Univi is cumulative: for all i ! j, if UniviT T 0OE then UnivjT T 0OE.
Then Nuprl! is a type system by Lemma 4.12. 2

Proposition 4.15 The equality relations T1 = T2 and t1 = t2 2 T adhere to the specification
in Figure 4.5.

4.4.2 Judgement Semantics
I begin the semantics for judgements by defining the notion of an assignment of closed terms
to variables:

Definition 4.16

ffl An assignment is a sequence of pairs hx1; t1i \Delta  \Delta  \Delta  hxn; tni such that each xi is a distinct

variable and each ti is a closed term.

ffl The application ff(t) of an assignment ff to a term t, where ff j hx1; t1i \Delta  \Delta  \Delta  hxn; tni, is

t[t1 \Delta  \Delta  \Delta  tn=x1 \Delta  \Delta  \Delta  xn].

As discussed in Section 4.2.1, the intended meaning of the sequent H `* C / t is that ff(C) =
ff0(C) and ff(t) = ff0(t) 2 ff(C) when ff and ff0 are equal assignments for the hypotheses H. In
order to formalize this as a semantics for judgements, I must define exactly what is meant by
equal assignments.

The obvious idea is to say that assignments are equal when their corresponding terms are
equal in the appropriate types. We may call this notion "assignment similarity":

Definition 4.17 Assignment similarity (written ff1 ss ff2 2 H) is the smallest relation such
that:

ffl ffl ss ffl 2 ffl
ffl ff1hx; t1i ss ff2hx; t2i 2 (H; x : T ) if ff1 ss ff2 2 H and t1 = t2 2 ff1(T )

This notion provides a good starting point, but it will not serve as the needed notion of assignment equality, because it is neither symmetric nor transitive. Symmetry does not hold
because it is not generally the case for similar assignments ff1 and ff2 that ff1(T ) = ff2(T ), so
t1 = t2 2 ff1(T ) does not imply t2 = t1 2 ff2(T ). Transitivity fails for the same reason.

The solution is to impose on the inductive case the additional requirement that ff1(T ) =
ff2(T ). The leads to the first of three definitions of assignment equality:

Definition 4.18 Assignment equality with minimal functionality (written ff1 = ff2 2min H) is
the smallest relation such that:

ffl ffl = ffl 2min ffl
ffl ff1hx; t1i = ff2hx; t2i 2min (H; x : T ) if

56

- ff1 = ff2 2min H, and
- t1 = t2 2 ff1(T ), and
- ff1(T ) = ff2(T )

Proposition 4.19 Assignment equality with minimal functionality is symmetric and transitive.
This notion of equality is called minimal functionality because it uses the minimum extra constraint (over similarity) to ensure symmetry and transitivity. By strengthening that constraint,
we can get two other interesting forms of assignment equality. Note that in the third clause
of the inductive case of Definition 4.18, the assignments ff1 and ff2 are similar (since clearly
ff1 = ff2 2min H implies ff1 ss ff2 2 H) and fixed. We define pointwise functionality by allowing
one of the similar assignments to vary, and we define full functionality by allowing both of the
similar assignments to vary:

Definition 4.20 Assignment equality with pointwise functionality (written ff1 = ff2 2pw H) is
the smallest relation such that:

ffl ffl = ffl 2pw ffl
ffl ff1hx; t1i = ff2hx; t2i 2pw (H; x : T ) if

- ff1 = ff2 2pw H, and
- t1 = t2 2 ff1(T ), and
- for all ff, if ff1 ss ff 2 H then ff1(T ) = ff(T )

Definition 4.21 Assignment equality with full functionality (written ff1 = ff2 2full H) is the
smallest relation such that:

ffl ffl = ffl 2full ffl
ffl ff1hx; t1i = ff2hx; t2i 2full (H; x : T ) if

- ff1 = ff2 2full H, and
- t1 = t2 2 ff1(T ), and
- for all ff; ff0, if ff ss ff0 2 H then ff(T ) = ff0(T )

Following are some important properties of pointwise and full functionality. For any of the
three forms of functionality, I write ff 2 H to mean ff = ff 2 H.

Proposition 4.22

ffl If ff 2pw H, then for any ff0, ff ss ff0 2 H implies ff = ff0 2pw H
ffl If ff 2full H, then for any ff1; ff2, ff1 ss ff2 2 H implies ff1 = ff2 2full H
ffl Assignment equality with pointwise functionality is symmetric and transitive.
ffl Assignment equality with full functionality is symmetric and transitive.

57

We can now define the semantics of Nuprl judgements. Following Constable et al. [19], I use
pointwise functionality. (An avenue for future research is to explore semantics based on full
[6] or minimal functionality.) The semantics given by Constable et al. [19] is equivalent to this
one, but is considerably more complicated.

Definition 4.23 The judgement H `* C / t is valid if for all assignments ff and ff0, ff =
ff0 2pw H implies ff(C) = ff0(C) and ff(t) = ff0(t) 2 ff(C). The judgement `* t , t0 is valid if
t , t0.

Theorem 4.24 (Nuprl Soundness) Any judgement derivable in the Nuprl proof rules is
valid.

Proof

By induction on derivations.

Corollary 4.25 (Nuprl Consistency) The Nuprl proof rules are consistent.
Proof

The judgement `* Void / ? is invalid, and therefore unprovable. 2

4.4.3 Classical Reasoning
As discussed in Section 4.1.5, classical reasoning principles are semantically invalid within the
type theory. In the Nuprl semantics, validity of the excluded middle principle (8P: P . :P )
would imply the existence of a computable function that would determine the truth or falsity
of every proposition. However, in the underlying metatheory, we may consider using classical
reasoning principles.

The proof rules given in Appendix B and not marked as classical may all be proven valid
without classical reasoning. However, there are some additional rules that may be shown valid
in a classical metatheory.

The primary such rule is a weak form of the excluded middle principle:

H ` 8P :Pi: #(P . :P ) / *x:? (XM)
Proposition 4.26 The rule XM is semantically valid in a classical interpretation.
Note that this works because of the squashing of P .:P . The alternative axiom #(8P :Pi: P .:P )
is not semantically valid, because it still implies the existence of a general decision function,
even though that function is still not provided. In Chapter 5 we will see another example of
important rules validated by a classical metatheory but not a constructive metatheory. These
are the coadmissibility rules for partial types (Rules PWC and PC).

One practical use of the XM rule is for fixpoint induction (Section 4.3.3). Recall that the
fixpoint induction rule generates the subgoal H; x : T ; y : (x in! T ) P ) `* P . This subgoal
may be proven from the simpler subgoal H `* P [?=x] using the XM rule (and some of the
other subgoals of the fixpoint induction rule): Instantiating XM gives #(x in! T . :(x in! T )).
Then #P can be proven by cases, invoking hypothesis y if x in! T and substituting ? for x if
:(x in! T ). By subgoal 8, we may conclude P from #P .

58

Chapter 5
Admissibility
One of the earliest logical theorem provers was the LCF system [38], based on the logic of
partial computable functions [88, 89]. Although LCF enjoyed many groundbreaking successes,
one problem it faced was that, although it supported a natural notion of partial function, it had
difficulty expressing the notion of a total function. Later theorem provers based on constructive
type theory, such as Nuprl [19], based on Martin-L"of type theory [68], and Coq [8], based on
the Calculus of Constructions [29], faced the opposite problem; they had a natural notion of
total functions, but had difficulty dealing with partial functions. The lack of partial functions
seriously limited the scope of those theorem provers, because it made them unable to reason
about programs in real programming languages where recursion does not always necessarily
terminate.

This problem may be addressed in type theory by the partial type discussed in Chapter 4.
In a partial type theory, recursively defined objects may be typed using the fixpoint principle:
if f has type T ! T then fix (f ) has type T . However, the fixpoint principle is not valid
for every type T ; it is only valid for types that are admissible. This phenomenon was not
unknown to LCF; LCF used the related device of fixpoint induction, which was valid only for
admissible predicates. When the user attempted to invoke fixpoint induction, the system would
automatically check that the goal was admissible using a set of syntactic rules [55].

Despite their obvious uses in program analysis, partial types have seen little use in theorem
proving systems [25, 9, 7]. This is due in large part to two problems: partial type extensions
have been developed only for fragments of type theory that do not include equality, and too
few types have been known to be admissible. I addressed the former problem in Chapter 4; in
this chapter I address the latter.

Smith [92] gave a significant class of admissible types for a Nuprl-like theory, but his class
required product types to be non-dependent. The type \Sigma x:A:B (where x appears free in
B) was explicitly excluded. Later, Smith [91] extended his class to include some dependent
products \Sigma x:A:B, but disallowed any free occurrences of x to the left of an arrow in B. Partial
type extensions to Coq [7] were also restrictive, assuming function spaces to be the only type
constructor. These restrictions are quite strong; dependent products are used in encodings
of modules [65], objects [83], algebras [57], and even such simple devices as variant records.
Furthermore, ruling out dependent products disallows reasoning using fixpoint induction as
in LCF. (This is explained further in Section 5.1.) Finally, the restriction is particularly
unsatisfying since most types used in practice do turn out to be admissible, and may be shown
so by metatheoretical reasoning.

In this chapter I present a very wide class of admissible types using two devices, a condition

59

called predicate-admissibility and a monotonicity condition. In particular, many dependent
products may be shown to be admissible. Predicate-admissibility relates to when the limit
of a chain of type approximations contains certain terms, whereas admissibility relates to the
membership of a single type. Monotonicity is a simpler condition that will be useful for showing
types admissible that do not involve partiality.

5.1 The Fixpoint Principle
The central issue of this chapter is the fixpoint principle:

f 2 T ! T ) fix (f ) 2 T
The fixpoint principle allows us to type recursively defined objects, such as recursive functions.
Unfortunately, unlike in programming languages, where the principle can usually be invoked on
arbitrary types, expressive type theories such as the one in this thesis contain types for which
the fixpoint principle is not valid. I shall informally say that a type is admissible if the fixpoint
principle is valid for that type and give a formal definition in Section 5.3. To make maximum
use of a partial type theory, one wants as large a class of admissible types as possible.

In Section 5.3 I will explore two wide classes of admissible types, one derived from a predicateadmissibility condition and another derived from a monotonicity condition. But first, it is
worthwhile to note that there are indeed inadmissible types:

Theorem 5.1 There exist inadmissible types.
Proof Sketch

This example is due to Smith [92]. Recall that N = fn : Z j 0 ^ ng. Let T be the type of
functions that do not halt for all inputs, and let f be the function that halts on zero, and
on any other n immediately recurses with n \Gamma  1. This is formalized as follows:

T def= \Sigma h:(N ! N ): ((\Pi x:N : h x in! N) ! Void )

f def= *p:h*x: if x ^Z 0 then 0 else ss1(p)(x \Gamma  1); *y: ?i

Intuitively, any finite approximation of fix (f ) will recurse some limited number of times
and then give up, placing it in T , but fix (f ) will halt for every input, excluding it from T .
Formally, the function f has type T ! T , but fix (f ) 62 T . (The proof of these two facts
appears in Appendix C.) Therefore T is not admissible.

5.2 Computational Lemmas
Before presenting my main results in Section 5.3, I first require some lemmas about the computational behavior of the fixpoint operator. The central result is that fix (f ) is the least upper
bound of the finite approximations ?; f (?); f (f (?)); : : : with regard to a computational approximation relation defined below. The compactness of fix (if fix (f ) halts then one of its finite
approximations halts) will be a simple corollary of this result. However, the proof of the least
upper bound theorem is considerably more elegant than most proofs of compactness.

60

5.2.1 Computational Approximation
For convenience, throughout this section we will frequently consider terms using a unified representation scheme for terms: A term is either a variable or a compound term `(x11 \Delta  \Delta  \Delta  x1k1 :t1; : : : ;
xn1 \Delta  \Delta  \Delta  xnkn:tn) where the variables xi1; : : : ; xiki are bound in the subterm ti. For example, the
term \Pi x:T1:T2 is represented \Pi (T1; x:T2) and the term ht1; t2i is represented hi(t1; t2).

Informally speaking, a term t1 approximates the term t2 when: if t1 converges to a canonical
form then t2 converges to a canonical form with the same outermost operator, and the subterms
of t1's canonical form approximate the corresponding subterms of t2's canonical form. The
formal definition appears below and is due to Howe [53].1 Following Howe, when R is a binary
relation on closed terms, I adopt the convention extending R to possibly open terms that if t
and t0 are possibly open then t R t0 if and only if oe(t) R oe(t0) for every substitution oe such that
oe(t) and oe(t0) are closed.

Definition 5.2 (Computational Approximation)

ffl Let R be a binary relation on closed terms and suppose e and e0 are closed. Then e C(R) e0

exactly when if e + `(~x1:t1; : : : ; ~xn:tn) then there exists some closed e00 = `(~x1:t01; : : : ; ~xn:t0n)
such that e0 + e00 and ti R t0i.

ffl e ^0 e0 whenever e and e0 are closed.
ffl e ^i+1 e0 if and only if e C(^i) e0
ffl e ^ e0 if and only if e ^i e0 for every i

Definition 5.3 (Computational Equivalence) The terms e and e0 are computationally
equivalent (e , e0) if and only if e ^ e0 and e0 ^ e.

The following are facts about computational approximation that will be used without explicit reference. The first two follow immediately from the definition, the third is easy using
determinism (Proposition 4.2) and the last is proven using Howe's method [53].

Proposition 5.4

ffl ^ and ^i are reflexive and transitive.
ffl If t 7! t0 then t0 ^ t and t0 ^i t.
ffl If t 7! t0 then t ^ t0 and t ^i t0.

Lemma 5.5 (Congruence) If e ^ e0 and t ^ t0 then e[t=x] ^ e0[t0=x].

1Howe's definition actually differs slightly from the one here; he defines ^ as the greatest fixed point of the
operator C. It is not difficult to show that the two definitions are equivalent, as long as the computation system
is deterministic (Proposition 4.2). If the computation system is nondeterministic, the definition here fails to be
a fixed point, and the more complicated greatest fixed point definition must be employed.

61

5.2.2 Finite Approximations
With this notion of computational approximation in hand, we may now show that the terms
?; f ?; f (f ?); : : : form a chain of approximations to the term fix (f ). Let ? be the divergent
term fix (*x:x). Since ? never converges, ? ^ t for any term t. Let f i be defined as follows:

f 0 def= ?
f i+1 def= f (f i)

Certainly f 0 ^ f 1, since f 0 j ?. By congruence, f (f 0) ^ f (f 1), and thus f 1 ^ f 2. Similarly,
f i ^ f i+1 for all i. Thus f 0; f 1; f 2; : : : forms a chain; I now wish to show that fix (f ) is an
upper bound of the chain. Certainly f 0 ^ fix (f ). Suppose f i ^ fix (f ). By congruence f (f i) ^
f (fix (f )). Thus, since fix (f ) 7! f (fix (f )), it follows that f i+1 j f (f i) ^ f (fix (f )) ^ fix (f ). By
induction it follows that fix (f ) is an upper bound of the chain. The following corollary follows
from congruence and the definition of approximation:

Corollary 5.6 If there exists j such that e[f j=x]# then e[fix (f )=x]#. Moreover, the canonical
forms of e[f j=x] and e[fix (f )=x] must have the same outermost operator.

5.2.3 Least Upper Bound Theorem
In this section I summarize the proof of the least upper bound theorem. To begin, we need a
lemma stating a general property of evaluation. Lemma 5.7 captures the intuition that closed,
noncanonical terms that lie within a term being evaluated are not destructed; they either are
moved around unchanged (the lemma's first case) or are evaluated in place with the surrounding
term left unchanged (the lemma's second case). The variable x indicates positions where the
term of interest is found and, in the second case, the variable y indicates which of those positions,
if any, is about to be evaluated.

Lemma 5.7 If e1[t=x] 7! e2, and e1[t=x] is closed, and t is closed and noncanonical, then
either

ffl there exists e02 such that for any closed t0, e1[t0=x] 7! e02[t0=x], or
ffl there exist e01 and t0 such that e1 j e01[x=y], t 7! t0 and for any closed t00, e01[t00; t=x; y] 7!

e01[t00; t0=x; y].

It is worthwhile to note that Proposition 4.2 and Lemmas 5.5 and 5.7 are the only properties
of evaluation used in the proof of the least upper bound theorem, and that these properties are
true in computational systems with considerable generality. Consequently, the theorem may be
used in a variety of applications beyond the computational system of this thesis.

Lemma 5.8 shows that fix terms may be effectively simulated in any particular computation
by sufficiently large finite approximations. The lemma is simplified by using computational
approximation instead of evaluation for the simulation, which makes it unnecessary to track
which of the approximations are unfolded and which are not, an issue that often complicates
compactness proofs.

Lemma 5.8 (Simulation) For all f , e1 and e2 (where f is closed and x is the only free
variable of e1), there exist j and e02 such that if e1[fix (f )=x] 7!\Lambda  e2 then e2 j e02[fix (f )=x] and
for all k * j, e02[f k\Gamma j=x] ^ e1[f k=x].

62

Theorem 5.9 (Least Upper Bound) For all f , t and e (where f is closed), if 8j: e[f j=x] ^
t, then e[fix (f )=x] ^ t.

Proof Sketch

By induction on l that e[fix (f )=x] ^l t. (The complete proof in Appendix C addresses
free variables.) Suppose e[fix (f )=x] evaluates to some canonical form e0[fix (f )=x] (where
e0 is chosen by Lemma 5.8). Let e0 be of the form `(~x1:t1; : : : ; ~xn:tn). Using Lemma 5.8,
the assumption 8k: e[f k=x] ^ t, and transitivity, we may show that e0[f j=x] ^ t for all j.
Therefore t + `(~x1:t01; : : : ; ~xn:t0n) and ti[f j=x] ^ t0i for all j. Now, by induction, ti[fix (f )=x] ^l
t0i. Thus e[fix (f )=x] ^l+1 t.

There are two easy corollaries to the least upper bound theorem. One is that fix (f ) is the least
fixed point of f , and the other is compactness.

Corollary 5.10 (Least Fixed Point) For all closed f and t, if f (t) ^ t then fix (f ) ^ t.
Proof

Certainly f 0 j ? ^ t. Then f 1 j f (f 0) ^ f (t) ^ t. Similarly, by induction, f j ^ t for any
j. Therefore fix (f ) ^ t by Theorem 5.9. 2

Corollary 5.11 (Compactness) If f is closed and e[fix (f )=x]# then there exists some j such
that e[f j=x]#. Moreover, the canonical forms of e[fix (f )=x] and e[f j=x] must have the same
outermost operator.

Proof

Suppose there does not exist j such that e[f j=x]#. Then e[f j=x] ^ ? for all j. By Theorem
5.9, e[fix (f )=x] ^ ?. Therefore e[fix (f )=x] does not converge, but this contradicts the
assumption,2 so there must exist j such that e[f j=x]#. Since e[f j=x] ^ e[fix (f )=x], the
canonical forms of e[f j=x] and e[fix (f )=x] must have the same outermost operator. 2

5.3 Admissibility
I am now ready to begin specifying some wide classes of types for which the fixpoint principle
is valid. First we define admissibility. The simple property of validating the fixpoint principle
is too specific to allow any good closure conditions to be shown easily, so we generalize a bit
to define admissibility. A type is admissible if the upper bound t[fix (f )] of an approximation
chain t[f 0]; t[f 1]; t[f 2]; : : : belongs to the type whenever a cofinite subset of the chain belongs
to the type. This is formalized as Definition 5.13, but first I define some convenient notation.

Notation 5.12 For any natural number j, the notation t[j]f means t[f j=w], and the notation
t[!]f means t[fix (f )=w]. Also, the f subscript is dropped when the intended term f is unambiguously clear.

Definition 5.13 A type T is admissible (abbreviated Adm(T )) if:

8f; t; t0: (9j: 8k * j: t[k] = t0[k] 2 T ) ) t[!] = t0[!] 2 T
2Although this proof is non-constructive, a slightly less elegant constructive proof may be derived directly
from Lemma 5.8.

63

As expected, admissibility is sufficient to guarantee applicability of the fixpoint principle:
Theorem 5.14 For any T and f , if T is admissible and f = f 0 2 T !T then fix (f ) = fix (f 0) 2
T .

Proof

T type since T ! T type. Note that f j = f 0j 2 T for every j. Suppose fix (f )#. By
compactness, f j# for some j. Since f j = f 0j 2 T , it follows that f 0j# and thus fix (f 0)# by
Corollary 5.6. Similarly fix (f 0)# implies fix (f )#. It remains to show that fix (f ) = fix (f 0) 2 T
when fix (f )#. Suppose again that fix (f )#. As before, there exists j such that f j# by
compactness. Hence f j = f 0j 2 T . Since T is admissible, fix (f ) = fix (f 0) 2 T . 2

A number of closure conditions exist on admissible types and are given in Lemma 5.15.
Informally, basic compound types other than dependent products are admissible so long as
their component types in positive positions are admissible. Base types--natural numbers,
convergence types, and (for this lemma only) equality types--are always admissible. These are
essentially the admissible types of Smith [92], except that for a function type to be admissible
Smith required that its domain type be admissible.

Lemma 5.15

ffl Adm(A + B) if Adm(A) and Adm(B)
ffl Adm(\Pi x:A:B) if 8a 2 A: Adm(B[a=x])
ffl Adm(A \Theta  B) if Adm(A) and Adm(B)
ffl Adm(Void ), Adm(Atom), Adm(Z) and Adm(E )
ffl Adm(a = a0 in A)
ffl Adm(a ^ a0)
ffl Adm(A) if Adm(A)
ffl Adm(a in! A)
Proof

The proof follows the same lines as Smith's proof, except that handling equality adds a
small amount of complication to the proof. I show the function case by way of example.

Let f , t and t0 be arbitrary. Suppose j is such that 8k * j: t[k] = t0[k] 2 \Pi x:A:B. I need
to show that t[!] = t0[!] 2 \Pi x:A:B. Since \Pi x:A:B is inhabited it is a type. Both t[j] and
t0[j] converge to lambda abstractions, so, by Corollary 5.6, t[!] + *x:b and t0[!] + *x:b0 for
some terms b and b0. Suppose a = a0 2 A. To get that b[a=x] = b0[a0=x] 2 B[a=x] it
suffices to show that t[!]a = t0[!]a0 2 B[a=x]. Since Adm(B[a=x]), it suffices to show that
8k * j: t[k]a = t0[k]a0 2 B[a=x], which follows from the supposition. 2

Unfortunately, Lemma 5.15 can show the admissibility of a product space only if it is
non-dependent. Dependent products do not have an admissibility condition similar to that
of dependent functions. This reason for this is as follows: Admissibility states that a single
fixed type contains the limit of an approximation chain if it contains a cofinite subset of that
chain. For functions, disjoint union, partial types, and non-dependent products it is possible

64

to decompose prospective members in such a way that admissibility may be applied to a single
type (such as the type B[a=x] used in the proof of Lemma 5.15). In contrast, for a dependent
product, the right-hand term's desired type depends upon the left-hand term, which is changing
at the same time as the right-hand term. Consequently, there is no single type into which to
place the right-hand term.

However, understanding the problem with dependent products suggests a solution, to generalize the definition of admissibility to allow the type to vary. This leads to the notion of
predicate-admissibility that I discuss in the next section.

5.3.1 Predicate-Admissibility
Definition 5.16 A type T is predicate-admissible for x in S (abbreviated Adm(T j x : S)) if:

8f; t; t0; e: e[!] 2 S ^ (9j: 8k * j: e[k] 2 S ^ t[k] = t0[k] 2 T [e[k]=x]) ) t[!] = t0[!] 2 T [e[!]=x]

The term "predicate-admissibility" stems from its similarity to the notion of admissibility
of predicates in domain theory (and LCF). If one ignores the inhabiting terms t and t0, which
may be seen as evidences of the truth of the predicate T [ ], then predicate-admissibility is saying
T [e[!]] if T [e[k]] for all k greater than some j. This is precisely the notion of admissibility of
predicates in domain theory. Indeed, the results here were influenced by the work of Igarashi
[55], who established conditions on admissibility of domain-theoretic predicates.

To show the admissibility of a dependent product type, it is sufficient to show predicateadmissibility of the right-hand side (along with admissibility of the left):

Lemma 5.17 The type \Sigma x:A:B is admissible if Adm(A) and Adm(B j x : A).
Proof

Let f , t and t0 be arbitrary. Suppose j is such that 8k * j: t[k] = t0[k] 2 \Sigma x:A:B. It is
necessary to show that t[!] = t0[!] 2 \Sigma x:A:B. Since \Sigma x:A:B is inhabited it is a type. Both
t[j] and t0[j] converge to pairs, so, by Corollary 5.6, t[!] + ha; bi and t0[!] + ha0; b0i for some
terms a, b, a0 and b0. To get that a = a0 2 A it suffices to show that ss1(t[!]) = ss1(t0[!]) 2 A.
Since Adm(A), it suffices to show that 8k * j: ss1(t[k]) = ss1(t0[k]) 2 A, which follows from
the supposition.

To get that b = b0 2 B[a=x] (the interesting part), it suffices to show that ss2(t[!]) =
ss2(t0[!]) 2 B[ss1(t[!])=x]. Since Adm(B j x : A), it suffices to show that ss1(t[!]) 2 A, which
has already been shown, and 8k * j: ss1(t[k]) 2 A ^ ss2(t[k]) = ss2(t0[k]) 2 B[ss1(t[k])=x], which
follows from the supposition. 2

The conditions for predicate-admissibility are more elaborate, but also more general. I
may immediately state conditions for basic types other than functions. Informally, basic compound types other than functions are predicate-admissible so long as their component types are
predicate-admissible, and base types are always predicate-admissible.

Lemma 5.18

ffl Adm(A + B j y : S) if 8s 2 S: (A + B)[s=y] type and Adm(A j y : S) and Adm(B j y : S).
ffl Adm(\Sigma x:A:B j y : S) if 8s 2 S: (\Sigma x:A:B)[s=y] type and \Sigma y:S:A type and Adm(A j y : S)

and Adm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:A))

ffl Adm(Void j y : S), Adm(Atom j y : S), Adm(Z j y : S) and Adm(E j y : S)

65

ffl Adm(a1 = a2 in A j y : S) if 8s 2 S: (a1 = a2 in A)[s=y] type and Adm(A j y : S)
ffl Adm(a1 ^ a2 j y : S)
ffl Adm(A j y : S) if 8s 2 S: A[s=y] type and Adm(A j y : S)
ffl Adm(a in! A j y : S) if 8s 2 S: (a in! A)[s=y] type

Predicate-admissibility of a function type is more complicated because a function argument with the type A[e[!]=x] does not necessarily belong to any of the finite approximations
A[e[j]=x]. To settle this, it is necessary to require a coadmissibility condition on the domain
type. Then a function type will be predicate-admissible if the domain is weakly coadmissible
and the codomain is predicate-admissible.

Definition 5.19 A type T is weakly coadmissible for x in S (abbreviated WCoAdm(T j x : S))
if:

8f; t; t0; e: e[!] 2 S ^ (9j: 8k * j: e[k] 2 S) ^ t = t0 2 T [e[!]=x] )

(9j: 8k * j: t = t0 2 T [e[k]=x])

A type T is coadmissible for x in S (abbreviated CoAdm(T j x : S)) if:

8f; t; t0; e: e[!] 2 S ^ (9j: 8k * j: e[k] 2 S) ^ t[!] = t0[!] 2 T [e[!]=x] )

(9j: 8k * j: t[k] = t0[k] 2 T [e[k]=x])

Lemma 5.20 Adm(\Pi x:A:B j y : S) if 8s 2 S: (\Sigma x:A:B)[s=y] type and WCoAdm(A j y : S) and
8s 2 S; a 2 A[s=y]: Adm(B[a=x] j y : S)

Clearly coadmissibility implies weak coadmissibility. A general set of conditions listed in
Lemma 5.21 establish weak and full coadmissibility for various types. Weak and full coadmissibility are closed under disjoint union and dependent sum formation, and full coadmissibility is
additionally closed under equality-type formation. I use both notions of coadmissibility, rather
than just adopting one or the other, because full coadmissibility is needed for equality types but
under certain circumstances weak coadmissibility is easier to show (Proposition 5.22 below).

Lemma 5.21

ffl A + B is (weakly) coadmissible for y in S if 8s 2 S: (A + B)[s=y] type and A and B are

(weakly) coadmissible for y in S

ffl WCoAdm(\Sigma x:A:B j y : S) if 8s 2 S: (\Sigma x:A:B)[s=y] type and WCoAdm(A j y : S) and

8s 2 S; a 2 A[s=y]: WCoAdm(B[a=x] j y : S)

ffl CoAdm(\Sigma x:A:B j y : S) if 8s 2 S: (\Sigma x:A:B)[s=y] type and \Sigma y:S:A type and CoAdm(A j y :

S) and CoAdm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:A))

ffl Void , Atom, Z and E are strongly or weakly coadmissible for y in any S
ffl CoAdm(a1 = a2 in A j y : S) if 8s 2 S: (a1 = a2 in A)[s=y] type and CoAdm(A j y : S)
ffl a1 ^ a2 is strongly or weakly coadmissible for y in any S
ffl A is (weakly) coadmissible for y in S if 8s 2 S: A[s=y] type and A is (weakly) coadmissible

for y is S

66

ffl a in! A is strongly or weakly coadmissible for y in S if 8s 2 S: (a in! A)[s=y] type

When T does not depend upon S, predicate-admissibility and weak coadmissibility become
easier to show:

Proposition 5.22 Suppose x does not appear free in T . Then:

ffl Adm(T ) if Adm(T j x : S) and S is inhabited
ffl Adm(T j x : S) if Adm(T )
ffl WCoAdm(T j x : S)

There remains one more result related to predicate-admissibility. Suppose one wishes to
show Adm(T j x : S) where T depends upon x. There are two ways that x may be used in
T . First, T might contain an equality type where x appears in one or both of the equands. In
that case, predicate-admissibility can be shown with the tools discussed above. Second, T may
be an expression that computes a type from x. In this case, T can be simplified using direct
computation (Section 4.1.7), but another tool will be needed if T performs any case analysis
(as in the embedding of the *K disjoint union type in Section 3.3.1).

Lemma 5.23 Consider a type case(d; x:A; x:B) that depends upon y from S. Suppose there
exist T1 and T2 such that:

ffl 8s 2 S: d[s=y] 2 (T1 + T2)[s=y]
ffl 8s 2 S; t 2 T1[s=y]: A[s; t=y; x] type
ffl 8s 2 S; t 2 T2[s=y]: B[s; t=y; x] type
ffl \Sigma y:S:T1 type and \Sigma y:S:T2 type
Then the following are the case:

ffl Adm(case(d; x:A; x:B) j y : S) if Adm(A[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:T1)) and

Adm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:T2))

ffl WCoAdm(case(d; x:A; x:B) j y : S) if WCoAdm(A[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:T1)) and

WCoAdm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:T2))

ffl CoAdm(case(d; x:A; x:B) j y : S) if CoAdm(A[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:T1)) and

CoAdm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:T2))

5.3.2 Monotonicity
In some cases a very simple device may be used to show admissibility. We say that a type is
monotone if it respects computational approximation, and it is easy to show that all monotone
types are admissible.

Definition 5.24 A type T is monotone (abbreviated Mono(t)) if t = t0 2 T whenever t 2 T
and t ^ t0.

67

Lemma 5.25 All monotone types are admissible.
Proof

Let f , t and t0 be arbitrary and suppose there exists j such that t[j] = t0[j] 2 T . Since
t[j] ^ t[!] and t0[j] ^ t0[!], it follows that t[j] = t[!] 2 T and t0[j] = t0[!] 2 T . The result
follows directly. 2

All type constructors are monotone except universes and partial types, which are never
monotone. The proof of this fact is easy [53].

Proposition 5.26

ffl Mono(A + B) if Mono(A) and Mono(B)
ffl Mono(\Pi x:A:B) if Mono(A) and 8a 2 A: Mono(B[a=x])
ffl Mono(\Sigma x:A:B) if Mono(A) and 8a 2 A: Mono(B[a=x])
ffl Mono(Void ), Mono(Atom), Mono(Z), Mono(E ), Mono(a1 = a2 2 A), Mono(a1 ^ a2)

and Mono(a in! A)

5.3.3 Set and Quotient Types
Given the parallel between the dependent product and set types, it is natural to expect that
set types would have a similar admissibility rule: that fx : A j Bg if A is admissible and B is
predicate-admissible for x in A. Surprisingly, this turns out not to be the case. Suppose that
t[k] 2 fx : A j Bg for all k * j. Then for every k * j, there exists some term bk 2 B[t[k]=x]. We
would like it to follow by predicate-admissibility that there exists b! 2 B[t[!]=x], but it does
not. The problem is that each bk can be a completely different term, and predicate-admissibility
applies only when each bk is of the form b[f k=w] for a single fixed b.

Intuitively, the desired rule fails because the set type fx : AjBg suppresses the computational
content of B and therefore B can be inhabited non-uniformly, by unrelated terms for related
members of A. In contrast, if the chain t[j]; t[j+1]; t[j+2]; : : : belongs to \Sigma x:A:B, then the chain
ss2(t)[j]; ss2(t)[j+1]; ss2(t)[j+2]; : : : uniformly inhabits B.

For a concrete example, consider:

T def= fg : Z ! Unit j 9n:Z: :(gn in! Z)g

f def= *h: *x: if x ^Z 0 then ? else h(x \Gamma  1)

t def= *y: wy

The type T is not admissible: For all k, (t[k]f )k diverges, so t[k]f 2 T ; but t[!]f converges for all
arguments, so t[!]f 62 T . However, 9n:Z: :(gn in! Z) is predicate-admissible for g in Z ! Unit .
The problem is that the inhabiting integers are not related by computational approximation;
that is, they are not uniform.

To show a set type admissible, we need to be able to show that the selection predicate can
be inhabited uniformly:

Lemma 5.27 The type fx : A j Bg is admissible if:

ffl Adm(A), and

68

ffl Adm(B j x : A), and
ffl there exists b such that b[a=x] 2 B[a=x] whenever a 2 A and 9b0: b0 2 B[a=x].

Another way to state the uniformity condition (the third clause) is that the computational
content of B should be recoverable from knowing it exists (i.e., there exists a function with type
\Pi x:A: #B !B. In fact, the two versions are equivalent modulo a few functionality requirements:

Proposition 5.28

ffl If f 2 \Pi x:A: #B ! B then b[a=x] 2 B[a=x] whenever a 2 A and 9b0: b0 2 B[a=x], where

b = f x ?.

ffl If b[a=x] = b[a0=x] 2 B[a=x] whenever a = a0 2 A and 9b0: B[a=x] and if B[a=x] = B[a0=x]

whenever a = a0 2 A then *x:*y: b 2 \Pi x:A: #B ! B.

We may give a similar predicate-admissibility condition:
Lemma 5.29 Adm(fx : A j Bg j y : S) if 8s 2 S: (fx : A j Bg)[s=y] type and \Sigma y:S:A type
and Adm(A j y : S) and Adm(B[ss1(z); ss2(z)=y; x] j z : \Sigma y:S:A), and there exists b such that
b[a; s=x; y] 2 B[a; s=x; y] whenever s 2 S and a 2 A[s=y] and 9b0: b0 2 B[a; s=x; y]

Coadmissibility and monotonicity work on single terms, not chains, so the uniformity issue does
not arise, resulting in conditions fairly similar to those for dependent products:

Lemma 5.30

ffl WCoAdm(fx : A j Bg j y : S) if 8s 2 S: fx : A j Bg[s=y] type and WCoAdm(A j y : S) and

8s 2 S; a 2 A[s=y]: WCoAdm(B[a=x] j y : S)

ffl CoAdm(fx : A j Bg j y : S) if 8s 2 S: fx : A j Bg[s=y] type and \Sigma y:S:A type and

CoAdm(A j y : S) and WCoAdm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:A))

ffl Mono(fx : A j Bg) if Mono(A)
The conditions for quotient types are similar to those for set types:
Lemma 5.31

ffl Adm(xy:A==B) if Adm(A) and Adm(B[ss1(z); ss2(z)=x; y] j z : A \Theta  A), and there exists b

such that b[a; a0=x; y] 2 B[a; a0=x; y] whenever a 2 A and a0 2 A and 9b0: b0 2 B[a; a0=x; y].

ffl Adm(xy:A==B jz : S) if 8s 2 S:(xy:A==B)[s=z] type and \Sigma z:S:(A\Theta A) type and Adm(Ajz :

S) and Adm(B[ss1(z0); ss1(ss2(z0)); ss2(ss2(z0))=z; x; y] j z0 : \Sigma z:S:(A \Theta  A)), and there exists
b such that b[a; a0; s=x; y; z] 2 B[a; a0; s=x; y; z] whenever s 2 S and a 2 A[s=z] and
a0 2 A[s=z] and 9b0: b0 2 B[a; a0; s=x; y; z].

ffl WCoAdm(xy:A==B j z : S) if 8s 2 S: (xy:A==B)[s=z] type and WCoAdm(A j z : S) and

8s 2 S; a 2 A[s=z]; a0 2 A[s=z]: WCoAdm(B[a; a0=x; y] j z : S)

ffl CoAdm(xy:A==B j z : S) if 8s 2 S: (xy:A==B)[s=z] type and \Sigma z:S:(A \Theta  A) type and

CoAdm(A j z : S) and CoAdm(B[ss1(z0); ss1(ss2(z0)); ss2(ss2(z0))=z; x; y] j z0 : \Sigma z:S:(A \Theta  A))

ffl Mono(xy:A==B) if Mono(A)

69

5.3.4 Summary
Figure 5.1 provides a summary of the basic admissibility results of this chapter. It is worthwhile
to note that all these results are proved constructively, with the exception of (weak and full)
coadmissibility of partial types. The following theorem shows that the proofs of coadmissibility
of partial types are necessarily classical; if a constructive proof existed then one could extract an
algorithm meeting the theorem's specification, which can be used to solve the halting problem.

Theorem 5.32 There does not exist an algorithm that computes an integer j such that 8k *
j: t = t0 2 T [e[k]=x], when given S, T , f , t, t0, e and i such that:

ffl 8s 2 S: T [s=x] type
ffl CoAdm(T j x : S)
ffl e[!] 2 S
ffl 8k * i: e[k] 2 S
ffl t = t0 2 T [e[!]=x]

Recall the inadmissible type T from Theorem 5.1. That type fails the predicate-admissibility
condition because of the negative appearance of a function type, which could not be shown
weakly coadmissible, and it fails the monotonicity condition because it contains the partial
type N .

5.4 Conclusions
An interesting avenue for future investigation would be to find some negative results characterizing inadmissible types. Such negative results would be particularly interesting if they could
be given a syntactic character, like the results of this chapter. Along these lines, it would be
interesting to find whether the inability to show coadmissibility of function types represents a
weakness of this proof technique or an inherent limitation.

The results presented above provide metatheoretical justification for the fixpoint principle
over many types. In order for these results to be useful in theorem proving, they must be
introduced into the logic. One way to do this, and the way it is done here, is to introduce types
to represent the assertions Adm(T ), Adm(T j x : S), etc., that are inhabited exactly when the
underlying assertion is true (in much that same way as the equality type is inhabited exactly
when the equands are equal), and to add rules relating to these types that correspond to the
lemmas of Section 5.3. This brings the tools into the system in a semantically justifiable way,
but it is unpleasant in that it leads to a proliferation of new types and inference rules stemming
from discoveries outside the logic. Of the Nuprl proof rules of Appendix B, 84 rules (not quite
half) deal with admissibility. It would be preferable to deal with admissibility within the logic.
A theory with intensional reasoning principles, such as the one proposed in Constable and Crary
[23], would allow reasoning about computation internally. Then these results could be proved
within the theory and the only extra rule that would be required would be a single rule relating
admissibility to the the fixpoint principle.

However they are placed into the logic, these results allow for recursive computation on a
wide variety of types. This make partial types and fixpoint induction a useful tool in typetheoretic theorem provers. It also makes it possible to study many recursive programs that
used to be barred from the logic because they could not be typed.

70

For T j
A + B \Pi x:A:B \Sigma x:A:B
Adm(T ) if
T type and Adm(A) ^ Adm(B) 8a 2 A: Adm(B[a=x]) Adm(A) ^ Adm(B j x : A)

Adm(A j y : S) ^
WCoAdm(A j y : S) ^ Adm(B[ss1(z); ss2(z)=y; x]
Adm(T j y : S) if Adm(A j y : S) ^ 8s 2 S; a 2 A[s=y]: j z : (\Sigma y : S:A)) ^
8s 2 S: T [s=y] type and Adm(B j y : S) Adm(B[a=x] j y : S) \Sigma y:S:A type

WCoAdm(A j y : S) ^
WCoAdm(T j y : S) if WCoAdm(A j y : S) ^ 8s 2 S; a 2 A[s=y]:
8s 2 S: T [s=y] type and WCoAdm(B j y : S) -- WCoAdm(B[a=x] j y : S)

CoAdm(A j y : S) ^
CoAdm(B[ss1(z); ss2(z)=y; x]
CoAdm(T j y : S) if CoAdm(A j y : S) ^ j z : (\Sigma y : S:A)) ^
8s 2 S: T [s=y] type and CoAdm(B j y : S) -- \Sigma y:S:A type

Mono(A) ^ Mono(A) ^
Mono(T ) if Mono(A) ^ Mono(B) 8a 2 A: Mono(B[a=x]) 8a 2 A: Mono(B[a=x])

For T j
Void; Atom; Z;E; a1 ^ a2; a in! A a1 = a2 in A A
Adm(T ) if
T type and yes yes Adm(A)
Adm(T j y : S) if
8s 2 S: T [s=y] type and yes Adm(A j y : S) Adm(A j y : S)
WCoAdm(T j y : S) if
8s 2 S: T [s=y] type and yes CoAdm(A j y : S) WCoAdm(A j y : S)
CoAdm(T j y : S) if
8s 2 S: T [s=y] type and yes CoAdm(A j y : S) CoAdm(A j y : S)
Mono(T ) if yes yes --

Figure 5.1: Admissibility, coadmissibility and monotonicity conditions

71

Chapter 6
Conclusion
In this dissertation I have explored how to draw formal connections between type theory and
practical programming languages. These connections allow the full power of foundational type
theory to be brought to bear on research problems arising from real programs and programming
languages.

The least consequence of these contributions is that program verification results in typetheoretic systems may be directly applied to real programs, without trusting an intermediate
hand translation into type theory. More significantly, type theory may be applied to programming languages as a whole; this allows us to understand programming languages within a
rich mathematical framework, but one that is inherently computational and that also does not
disturb the essential structure of programs.

Three main technical achievements made this possible. First, I presented a semantics for
a practical programming calculus in the framework of the Nuprl type theory. This semantics
was stated as a syntax-directed embedding of the constructs, and used novel type-theoretic
mechanisms to address the language mechanisms of recursion, a rich dependent kind structure,
and a higher-order modules system with translucent signatures.

Second, backing up the type-theoretic semantics was the first constructive type theory
to include an intrinsic notion of equality, and to support reasoning about partial and total
functions. All three are necessary to allow interesting reasoning about real programs. Partiality
is necessary because real programs often make use of recursion. However, a notion of totality is
also necessary to allow reasoning about pure values, which are central to real programs as well.

Third, broad new techniques for showing admissibility of types for fixpoint induction were
necessary for each of the previous contributions. Although the techniques I present are still
conservative, they make possible admissibility proofs for many types that could not be shown
admissible by previous techniques. For example, types arising in the embedding of disjoint
unions (Section 3.3.1) and in fixpoint induction (Section 4.3.3) required the new techniques to
be shown admissible.

The broadest aim of this work has been to bring theory and practice closer together. Aside
from the specific contributions that make up this dissertation, I have found that an important
way this work has helped achieve that is as a conceptual tool for thinking about programming
and programming languages. Practical languages are made up of diverse sets of often complicated mechanisms. In contrast, languages for theoretical study usually are made up of small
sets of elegant mechanisms. Type theory, like other theoretical languages, is made up of elegant mechanisms, but I have shown in this dissertation that those mechanisms are sufficiently
powerful to account for most of the diverse mechanisms of practical languages, and those that

72

remain show great promise of being addressed as well (recall Section 3.5).

Consequently, I have found it very profitable to use type theory as a tool for considering
general programming issues. The power and elegance of type theory allow a researcher to derive
elegant solutions to diverse problems but do not require one to ignore practical issues to get
them.

73
Appendix A
Lambda-K Typing Rules

Level Definitions

level (Typei) def= i
level (Pi(c)) def= i
level (Si(c)) def= i
level (\Pi ff:^1:^2) def= max(level (^1); level (^2))
level (f`i . ffi : ^i[i=1:::n]g) def= maxni=1 level (^i)

Kind Formation and Equality

\Gamma  `K ^2 = ^1
\Gamma  `K ^1 = ^2 (KindEqSymm)

\Gamma  `K ^1 = ^2 \Gamma  `IL ^2 = ^3

\Gamma  `K ^1 = ^3 (KindEqTrans)

\Gamma  `K Typei = Typei (Type)
\Gamma  `K ^1 = ^01 \Gamma [ff : ^1] `K ^2 = ^02

\Gamma  `K \Pi ff:^1:^2 = \Pi ff:^01:^02 (ff 62 \Gamma )

(Pi)

\Gamma [ffj : ^j][j=1:::i

\Gamma 1] `

K ^i = ^

0i for 1 ^ i ^ n

\Gamma  `K f`i . ffi : ^i[i=1:::n]g = f`i . ffi : ^0i[i=1:::n]g

(ff[i=1:::m]i 62 \Gamma )

(DepRecord)

\Gamma  `K c1 = c2 : Typei
\Gamma  `K Pi(c1) = Pi(c2) (Pow)

\Gamma  `K c1 = c2 : Typei
\Gamma  `K Si(c1) = Si(c2) (Sing)

Subkinding

\Gamma  `K ^1 = ^2
\Gamma  `K ^1 _ ^2 (SubkindReflex)

\Gamma  `K ^1 _ ^2 \Gamma  `IL ^2 _ ^3

\Gamma  `K ^1 _ ^3 (SubkindTrans)

\Gamma  `K Typei _ Typej (i ^ j) (TypeSub)

\Gamma  `K ^01 _ ^1
\Gamma [ff : ^01] `K ^2 _ ^02
\Gamma [ff : ^1] `K ^2 kind

\Gamma  `K \Pi ff:^1:^2 _ \Pi ff:^01:^02 (ff 62 \Gamma ) (PiSub)

\Gamma [ffj : ^j][j=1:::i

\Gamma 1] `

K ^i _ ^

0i for 1 ^ i ^ n

\Gamma [ffj : ^j][j=1:::i

\Gamma 1] `

K ^i kind for n ! i ^ m

\Gamma [ffj : ^0j][j=1:::i

\Gamma 1] `

K ^

0i kind for 1 ^ i ^ n

\Gamma  `K f`i . ffi : ^i[i=1:::m]g _ f`i . ffi : ^0i[i=1:::n]g

(ff[i=1:::m]i 62 \Gamma ; m * n)

(DepRecordSub)

\Gamma  `K c1 _ c2
\Gamma  `K Pi(c1) _ Pj(c2) (i ^ j) (PowSub)

\Gamma  `K c : Typei
\Gamma  `K Pi(c) _ Typei (PowType)

\Gamma  `K c1 = c2 : Typei
\Gamma  `K Si(c1) _ Sj (c2) (i ^ j) (SingSub)

\Gamma  `K c : Typei
\Gamma  `K Si(c) _ Pi(c) (SingPow)

74

Constructor Formation and Equality

\Gamma  `K c2 = c1 : ^
\Gamma  `K c1 = c2 : ^ (EqSymm)

\Gamma  `K c1 = c2 : ^ \Gamma  `K c2 = c3 : ^

\Gamma  `K c1 = c3 : ^ (EqTrans)

\Gamma  `K ff = ff : ^ (\Gamma (ff) = ^) (TypeVar)
\Gamma  `K ^1 kind \Gamma [ff : ^1] `K c = c0 : ^2

\Gamma  `K *ff:^1:c = *ff:^1:c0 : \Pi ff:^1:^2 (ff 62 \Gamma )

(PiIntro)

\Gamma  `K c1 = c01 : \Pi ff:^1:^2 \Gamma  `K c2 = c02 : ^1

\Gamma  `K c1[c2] = c01[c02] : ^2[c2=ff]

(PiElim)

\Gamma  `K ci = c0i : ^i[c[j=1:::i

\Gamma 1]

j =ff

[j=1:::i\Gamma 1]
j ](for 1 ^ i ^ n)

\Gamma  `K f`i . ffi : ^i[i=1:::n]g kind
\Gamma  `K f`i = ci[i=1:::n]g = f`i = c0i[i=1:::n]g :

f`i . ffi : ^i[i=1:::n]g

(DepRecordIntro)

\Gamma  `K c = c0 : f`j . ffj : ^j[i=1:::n]g
\Gamma  `K ss`i (c) = ss`i (c0) :

^i[ss`j (c)[j=1:::i

\Gamma 1]=ff[j=1:::i\Gamma 1]

j ](1 ^ i ^ n)

(DepRecordElim)

\Gamma  `K c1 = c01 : Typei \Gamma  `K c2 = c02 : Typei

\Gamma  `K c1 ! c2 = c01 ! c02 : Typei

(Arrow)

\Gamma  `K c1 = c01 : Typei \Gamma  `K c2 = c02 : Typei

\Gamma  `K c1 ) c2 = c01 ) c02 : Typei

(TArrow)

\Gamma  `K ^1 = ^2 \Gamma [ff : ^1] `K c = c0 : Typei

\Gamma  `K 8ff:^1:c1 = 8ff:^2:c2 : Typei

(ff 62 \Gamma ; level (^1) ! i)

(Quant)

\Gamma  `K ci = c0i : Typej for 1 ^ i ^ n
\Gamma  `K f`1 : c1; : : : ; `n : cng =

f`1 : c01; : : : ; `n : c0ng : Typej

(Record)

\Gamma  `K ci = c0i : Typej for 1 ^ i ^ n
\Gamma  `K h`1 : c1; : : : ; `n : cni =

h`1 : c01; : : : ; `n : c0ni : Typej

(Union)

\Gamma  `K c = c0 : ^1 \Gamma  `K ^1 _ ^2

\Gamma  `K c = c0 : ^2 (Subkind)

\Gamma  `K (*ff:^0:c1)[c2] : ^
\Gamma  `K (*ff:^0:c1)[c2] = c1[c2=ff] : ^ (PiBeta)

\Gamma  `K *ff:^01:c[ff] : \Pi ff:^1:^2
\Gamma  `K *ff:^01:c[ff] = c : \Pi ff:^1:^2 (ff 62 c) (PiEta)

\Gamma  `K ss`j (f`i = ci[i=1:::n]g) : ^
\Gamma  `K ss`j (f`i = ci[i=1:::n]g) = cj : ^ (1 ^ j ^ n)

(DepRecordBeta)

\Gamma  `K f`i = ss`i(c)[i=1:::n]g : f`i . ffi : ^i[i=1:::n]g
\Gamma  `K f`i = ss`i (c)[i=1:::n]g = c : f`i . ffi : ^i[i=1:::n]g

(DepRecordEta)

\Gamma  `K c1 = c2 : Typei

\Gamma  `K c1 : Si(c2) (SingIntro)

\Gamma  `K c1 : Si(c2)
\Gamma  `K c1 = c2 : Typei (SingElim)

\Gamma  `K c1 = c2 : Typei \Gamma  `K c1 : Pi(c3)

\Gamma  `K c1 = c2 : Pi(c3) (PowFun)

\Gamma  `K c1 = c2 : Typei \Gamma  `K c1 : Si(c3)

\Gamma  `K c1 = c2 : Si(c3) (SingFun)

\Gamma  `K m : h^i
\Gamma  `K ext(m) : ^ (TypeModElim)

75

Subtyping

\Gamma  `K c1 _ c2 \Gamma  `K c2 _ c3

\Gamma  `K c1 _ c3 (SubTrans)

\Gamma  `K c01 _ c1 \Gamma  `K c2 _ c02

\Gamma  `K c1 ! c2 _ c01 ! c02 (ArrowSub)

\Gamma  `K c01 _ c1 \Gamma  `K c2 _ c02

\Gamma  `K c1 ) c2 _ c01 ) c02 (TArrowSub)

\Gamma  `K c1 type \Gamma  `K c2 type

\Gamma  `K c1 ) c2 _ c1 ! c2 (TotalSub)

\Gamma  `K ^2 _ ^1
\Gamma [ff : ^2] `K c1 _ c2
\Gamma [ff : ^1] `K c1 type

\Gamma  `K 8ff:^1:c1 _ 8ff:^2:c2 (ff 62 \Gamma ) (QuantSub)

\Gamma  `K ci _ c0i for 1 ^ i ^ n
\Gamma  `K ci type for n ! i ^ m

\Gamma  `K f`1 : c1; : : : ; `n : cmg _

f`1 : c01; : : : ; `n : c0ng

(m * n)

(RecordSub)
\Gamma  `K ci _ c0i for 1 ^ i ^ m
\Gamma  `K c0i type for m ! i ^ n

\Gamma  `K h`1 : c1; : : : ; `n : cmi _

h`1 : c01; : : : ; `n : c0ni

(m ^ n)

(UnionSub)
\Gamma  `K c1 _ c2 \Gamma  `K c1 : Typei \Gamma  `K c2 : Typei

\Gamma  `K c1 : Pi(c2)

(PowIntro)

\Gamma  `K c1 : Pi(c2)

\Gamma  `K c1 _ c2 (PowElim)

Typing

\Gamma  `K x : c (\Gamma (x) = c) (Var)

\Gamma  `K c1 type \Gamma [x : c1] `K e : c2

\Gamma  `K *x:c1:e : c1 ! c2 (x 62 \Gamma )

(ArrowIntro)

\Gamma  `K e1 : c1 ! c2 \Gamma  `K e2 : c1

\Gamma  `K e1e2 : c2 (ArrowElim)

\Gamma  `K c1 type \Gamma [x : c1] `K e # c2

\Gamma  `K *x:c1:e : c1 ) c2 (x 62 \Gamma )

(TArrowIntro)

\Gamma  `K e1 : c1 ) c2 \Gamma  `K e2 : c1

\Gamma  `K e1e2 : c2 (TArrowElim)

\Gamma  `K ^ kind \Gamma [ff : ^] `K e # c

\Gamma  `K \Lambda ff:^:e : 8ff:^:c (ff 62 \Gamma )

(QuantIntro)

\Gamma  `K e : 8ff:^:c2 \Gamma  `K c1 : ^

\Gamma  `K e[c1] : c2[c1=ff] (QuantElim)

\Gamma  `K ei : ci for 1 ^ i ^ n
\Gamma  `K f`1 = e1; : : : ; `n = eng : f`1 : c1; : : : ; `n : cng

(RecordIntro)

\Gamma  `K e : f`1 : c1; : : : ; `n : cng

\Gamma  `K ss`i (e) : ci (1 ^ i ^ n)

(RecordElim)

\Gamma  `K e : o/
\Gamma  `K inj `(e) : h` : o/ i (UnionIntro)

\Gamma  `K e : h`1 : o/1; : : : ; `n : o/ni
\Gamma [xi : o/i] `K ei : o/ (for 1 ^ i ^ n)

\Gamma  `K case(e; `1 . x1:e1; : : : ; `n . xn:en) : o/

(UnionElim)

\Gamma  `K e : (c1 ! c2) ! (c1 ! c2)

\Gamma  `K fix c1!c2(e) : c1 ! c2 (Fix)

\Gamma  `K m : hhcii
\Gamma  `K ext(m) : c (TermModElim)

\Gamma  `K e : c1 \Gamma  `K c1 _ c2

\Gamma  `K e : c2 (Subtype)

76

Valuability

\Gamma  `K x # c (\Gamma (x) = c) (VarHalt)

\Gamma  `K c1 type \Gamma [x : c1] `K e : c2

\Gamma  `K *x:c1:e # c1 ! c2 (x 62 \Gamma )

(ArrowIntroHalt)

\Gamma  `K c1 type \Gamma [x : c1] `K e # c2

\Gamma  `K *x:c1:e # c1 ) c2 (x 62 \Gamma )

(TArrowIntroHalt)

\Gamma  `K e1 # c1 ) c2 \Gamma  `K e2 # c1

\Gamma  `K e1e2 # c2

(TArrowElimHalt)

\Gamma  `K ^ kind \Gamma [ff : ^] `K e # c

\Gamma  `K \Lambda ff:^:e # 8ff:^:c (ff 62 \Gamma )

(QuantIntroHalt)

\Gamma  `K e # 8ff:^:c2 \Gamma  `K c1 : ^

\Gamma  `K e[c1] # c2[c1=ff] (QuantElimHalt)

\Gamma  `K ei # ci for 1 ^ i ^ n
\Gamma  `K f`1 = e1; : : : ; `n = eng # f`1 : c1; : : : ; `n : cng

(RecordIntroHalt)

\Gamma  `K e # f`1 : c1; : : : ; `n : cng

\Gamma  `K ss`i (e) # ci (i ^ i ^ n)

(RecordElimHalt)

\Gamma  `K e # o/
\Gamma  `K inj `(e) # h` : o/ i (UnionIntroHalt)

\Gamma  `K e # h`1 : o/1; : : : ; `n : o/ni
\Gamma [xi : o/i] `K ei # o/ (for 1 ^ i ^ n)

\Gamma  `K case(e; `1 . x1:e1; : : : ; `n . xn:en) # o/

(UnionElimHalt)

\Gamma  `K e # (c1 ! c2) ) (c1 ! c2)

\Gamma  `K fix c1!c2(e) # c1 ! c2 (FixHalt)

\Gamma  `K m # hhcii
\Gamma  `K ext(m) # c (TermModElimHalt)

\Gamma  `K e # c1 \Gamma  `K c1 _ c2

\Gamma  `K e # c2 (SubtypeHalt)

Signature Formation and Subsignatures

\Gamma  `K oe1 _ oe2 \Gamma  `K oe2 _ oe3

\Gamma  `K oe1 _ oe3 (SubsigTrans)

\Gamma  `K ^1 _ ^2
\Gamma  `K h^1i _ h^2i (TypeSig)

\Gamma  `K c1 _ c2
\Gamma  `K hhc1ii _ hhc2ii (TermSig)

\Gamma  `K oe01 _ oe1
\Gamma [s : oe01] `K oe2 _ oe02
\Gamma [s : oe1] `K oe2 sig

\Gamma  `K \Pi s:oe1:oe2 _ \Pi s:oe01:oe02 (PiSig)

\Gamma [sj : oej][j=1:::i

\Gamma 1] `

K oei _ oe

0i for 1 ^ i ^ n

\Gamma [sj : oej ][j=1:::i

\Gamma 1] `

K oei sig for n ! i ^ m

\Gamma [sj : oe0j][j=1:::i

\Gamma 1] `

K oe

0i sig for 1 ^ i ^ n

\Gamma  `K f`i . si : oei[i=1:::m]g _ f`i . si : oe0i[i=1:::n]g

(s[i=1:::m]i 62 \Gamma ; m * n)

(RecordSig)

Module Formation

\Gamma  `K s : oe (\Gamma (s) = oe) (ModVar)

\Gamma  `K c : ^
\Gamma  `K hci : h^i (TypeMod)

\Gamma  `K e : c
\Gamma  `K hheii : hhcii (TermMod)

\Gamma  `K oe sig \Gamma [s : oe1] `K m : oe2

\Gamma  `K *s:oe1:m : \Pi s:oe1:oe2 (PiModIntro)

\Gamma  `K m1 : \Pi s:oe1:oe2 \Gamma  `K m2 : oe1

\Gamma  `K m1m2 : oe2[m2=s] (PiModElim)

\Gamma  `K mi : oei[m[j=1:::i

\Gamma 1]

j =s

[j=1:::i\Gamma 1]
j ](for 1 ^ i ^ n)

\Gamma  `K f`i . si : oei[i=1:::n]g sig
\Gamma  `K f`i = mi[i=1:::n]g : f`i . si : oei[i=1:::n]g

(RecordModIntro)

77

\Gamma  `K m : f`j . sj : oej[i=1:::n]g
\Gamma  `K ss`i (m) : oei[ss`j (m)[j=1:::i

\Gamma 1]=s[j=1:::i\Gamma 1]

j ](1 ^ i ^ n)

(RecordModElim)
\Gamma  `K m : oe
\Gamma  `K (m : oe) : oe (Coerce)

\Gamma  `K *s:oe1:ms : \Pi s:oe1:oe2

\Gamma  `K m : \Pi s:oe1:oe2 (s 62 m) (PiModEta)

\Gamma  `K f`i = ss`i(m)[i=1:::n]g : f`i . si : oei[i=1:::n]g

\Gamma  `K m : f`i . si : oei[i=1:::n]g

(RecordModEta)

Module Valuability

\Gamma  `K s # oe (\Gamma (s) = oe) (ModVarHalt)

\Gamma  `K c : ^
\Gamma  `K hci # h^i (TypeModHalt)

\Gamma  `K e # c
\Gamma  `K hheii # hhcii (TermModHalt)

\Gamma  `K oe sig \Gamma [s : oe1] `K m : oe2

\Gamma  `K *s:oe1:m # \Pi s:oe1:oe2

(PiModIntroHalt)

\Gamma  `K mi # oei[m[j=1:::i

\Gamma 1]

j =s

[j=1:::i\Gamma 1]
j ](for 1 ^ i ^ n)

\Gamma  `K f`i . si : oei[i=1:::n]g sig
\Gamma  `K f`i = mi[i=1:::n]g # f`i . si : oei[i=1:::n]g

(RecordModIntroHalt)

\Gamma  `K m # f`j . sj : oej [i=1:::n]g
\Gamma  `K ss`i (m) # oei[ss`j (m)[j=1:::i

\Gamma 1]=s[j=1:::i\Gamma 1]

j ](1 ^ i ^ n)

(RecordModElimHalt)
\Gamma  `K m # oe
\Gamma  `K (m : oe) # oe (CoerceHalt)

78

Appendix B
Nuprl Proof Rules

Conventions

ffl Variables bound in a sequent are taken to be

distinct. For example, Rule 2 has the implicit
side condition that x not be bound by H, and
Rule 3 has the implicit side-condition that x
and y are distinct variables and neither is
bound by H or J.

ffl Rules apply only when the consequent and

subgoals are closed sequents. For example,
Rule 2 has the implicit side-condition that x
not appear free in H, and also (since, by the
first convention, x cannot be bound by H)
that x not appear free in J, C or t.

ffl When the inhabitant is omitted in the bottom (consequent) of a rule, the inhabitant is
taken to be ?.

ffl Rules that may be derived from other rules

are marked with a `D'.

Structural Rules

H; x : T ; J `* x in T (1)

H; J `* C / t
H; x : T ; J `* C / t (2)

H; y : T ; x : S; J `* C / t
H; x : S; y : T ; J `* C / t (3)

H `* t in C

H `* C / t (4)

H `* C / t
H `* t in C (5)

H `* T / t0 H; x : T `* C / t

H `* C[t0=x] / t[t0=x] (D6)

Substitution

H `* C[t0=x] / s
H `* t = t0 in T H; x : T `* C type

H `* C[t=x] / s (7)

Direct Computation

H `* C[t0=x] / s `* t , t0

H `* C[t=x] / s (8)

H; x : T [t0=y]; J `* C / s `* t , t0

H; x : T [t=y]; J `* C / s (9)

`* t , t (10)
`* t0 , t
`* t , t0 (11)

`* t1 , t2 `* t2 , t3

`* t1 , t3 (12)

`* t1 , t01 `* t2 , t02

`* t1[t2=x] , t01[t02=x] (13)

`* t , t0 (t 7!s t

0)

(14)

The evaluation step relation is defined in Figure
4.3.

x appears actively in t2
`* t2[t1=x] , let x = t1 in t2 (15)

The active positions of a term are defined in Definition 4.5.

x1 62 t2 and x2 62 t1
`* let x1 = t1 in let x2 = t2 in t ,

let x2 = t2 in let x1 = t1 in t

(16)

79

Equality

H `* t2 = t1 in T
H `* t1 = t2 in T (17)

H `* t1 = t2 in T H `* t2 = t3 in T

H `* t1 = t3 in T (18)

H `* t = t0 in T

H `* T type (19)

Subtyping

H; x : T `* x in T 0
H `* T type H `* T 0 type

H `* T _ T 0 (20)

H `* t1 = t2 in T 0 H `* T 0 _ T

H `* t1 = t2 in T (21)

H; x : T 0; J `* C / s H `* T _ T 0

H; x : T ; J `* C / s (22)

H `* T _ T 0
H `* T type (23)

H `* T _ T 0
H `* T 0 type (24)

Universes

H `* Ui in Uj (i ! j) (25)

H `* T in Ui
H `* T in Uj (i ! j) (26)

H `* T = T 0 in Ui

H `* T _ T 0 (27)

Void

H `* Void in Ui (28)

H `* t in Void

H `* C (29)

Atom

H `* Atom in Ui (30)

H `* a in Atom (string literal a) (31)
H `* a1 = a01 in Atom H `* a2 = a02 in Atom

H `* (a1 =A a2) = (a01 =A a02) in B

(32)

H `* a1 = a2 in Atom
H `* (a1 =A a2) = true in B (33)

H `* (a1 =A a2) = true in B

H `* a1 = a2 in Atom (34)

Integer

H `* Z in Ui (35)

H `* n in Z (integer literal n) (36)
H `* C[0=x] / b
H; x : Z; y : (0 ! x); z : C[x \Gamma  1=x] `* C / u
H; x : Z; y : (x ! 0); z : C[x + 1=x] `* C / d

H; x : Z `* C /

fix (*f:*x:

if x =Z 0 then b
else if 0 ^Z x then u[?; f (x \Gamma  1)=y; z]
else d[?; f (x + 1)=y; z]) x

(37)

H `* n1 = n01 in Z H `* n2 = n02 in Z

H `* (n1 =Z n2) = (n01 =Z n02) in B (38)

H `* n1 = n2 in Z
H `* (n1 =Z n2) = true in B (39)

H `* (n1 =Z n2) = true in B

H `* n1 = n2 in Z (40)

H `* n1 = n01 in Z H `* n2 = n02 in Z

H `* (n1 ^Z n2) = (n01 ^Z n02) in B (41)

H `* n1 ^ n2
H `* (n1 ^Z n2) = true in B (42)

H `* (n1 ^Z n2) = true in B

H `* n1 ^ n2 (43)

80

H `* n1 = n01 in Z H `* n2 = n02 in Z

H `* n1 \Phi  n2 = n01 \Phi  n02 in Z (44)

Not shown are the various rules governing the behavior of the binary operations \Phi .

Disjoint Union

H `* A = A0 in Ui H `* B = B0 in Ui

H `* A + B = A0 + B0 in Ui (45)

H `* A type H `* B type

H `* A + B type (46)

H `* a = a0 in A H `* A + B type

H `* inj 1(a) = inj 1(a0) in A + B (47)

H `* b = b0 in B H `* A + B type

H `* inj 2(b) = inj 2(b0) in A + B (48)

H `* t = t0 in A + B
H; x : A `* t1 = t01 in T
H; x : B `* t2 = t02 in T

H `* case(t; x:t1; x:t2) = case(t0; x:t01; x:t02) in T

(49)

H; y : A; J[inj 1(y)=x]

`* C[inj 1(y)=x] / s[inj 1(y)=x]
H; y : B; J[inj 2(y)=x]

`* C[inj 2(y)=x] / s[inj 2(y)=x]

H; x : A + B; J `* C / s (50)

Products

H `* A = A0 in Ui H; x : A `* B = B0 in Ui

H `* \Sigma x:A:B = \Sigma x:A0:B0 in Ui

(51)

H `* A type H; x : A `* B type

H `* \Sigma x:A:B type (52)

H `* a = a0 in A
H `* b = b0 in B[a=x] H `* \Sigma x:A:B type

H `* ha; bi = ha0; b0i in \Sigma x:A:B

(53)

H `* t = t0 in \Sigma x:A:B
H `* ss1(t) = ss1(t0) in A (54)

H `* t = t0 in \Sigma x:A:B
H `* ss2(t) = ss2(t0) in B[ss1(t)=x] (55)

H; x : A; y : B; J[hx; yi=z]

`* C[hx; yi=z] / s[hx; yi=z]

H; z : \Sigma x:A:B; J `* C / s (56)

H `* ss1(p1) = ss1(p2) in A
H `* ss2(p1) = ss2(p2) in B[ss1(p1)=x]
H `* p1 in \Sigma x:A1:B1
H `* p2 in \Sigma x:A2:B2
H `* \Sigma x:A:B type

H `* p1 = p2 in \Sigma x:A:B (57)

Functions

H `* A = A0 in Ui H; x : A `* B = B0 in Ui

H `* \Pi x:A:B = \Pi x:A0:B0 in Ui

(58)

H `* A type H; x : A `* B type

H `* \Pi x:A:B type (59)

H `* A type H; x : A `* b = b0 in B

H `* *x:b = *x:b0 in \Pi x:A:B (60)

H `* f = f 0 in \Pi x:A:B H `* a = a0 in A

H `* f a = f 0 a0 in B[a=x] (61)

H; x : A `* f1 x = f2 x in B
H `* A type
H `* f1 in \Pi x:A1:B1
H `* f2 in \Pi x:A2:B2

H `* f1 = f2 in \Pi x:A:B (62)

Very-Dependent Functions

H `* A = A0 in Ui
H; y : A; z : A `* P in Ui
H; x : A `* 0 ^ e
H; y : A; z : A; w : P `* e[y=x] ! e[z=x]
H; x : A;

f : fg j y : fy : A j P [x=z]g ! B[g; y=f; x]g
`* B = B0 in Ui

H `* ff j x:A ! Bg = ff j x:A0 ! B0g in Ui

(63)

81

H `* A type
H; y : A; z : A `* P type
H; x : A `* 0 ^ e
H; y : A; z : A; w : P `* e[y=x] ! e[z=x]
H; x : A;

f : fg j y : fy : A j P [x=z]g ! B[g; y=f; x]g
`* B type

H `* ff j x:A ! Bg type

(64)

H `* ff j x:A ! bg type
H; x : A `* b = b0 in B[*x:b=f ]

H `* *x:b = *x:b0 in ff j x:A ! bg (65)

H `* g = g0 in ff j x:A ! Bg H `* a = a0 in A

H `* g a = g0 a0 in B[g; a=f; x]

(66)

H; x : A `* g1x = g2x in B[g1=f ]
H `* ff j x:A ! Bg type
H `* g1 in ff j x:A1 ! B1g
H `* g2 in ff j x:A2 ! B2g

H `* g1 = g2 in ff j x:A ! Bg (67)

Partial Types

H `* T = T 0 in Ui H `* T total

H `* T = T 0 in Ui (68)

H `* T total

H `* T type (69)

H `* t = t0 in T H `* T type

H `* t = t0 in T (70)

H; x : (t1 in! T1) `* t1 = t2 in T
H `* t1 in! T1 , t2 in! T2 H `* T type

H `* t1 = t2 in T

(71)

H `* f = f 0 in T ! T H `* T admiss

H `* fix (f ) = fix (f 0) in T (72)

H `* T1 _ T2 H `* T2 total

H `* T1 _ T2 (D73)

Convergence

H `* t in! T 0 H `* t in T

H `* t in! T (74)

H `* t in T
H `* t in! T (t canonical) (75)

H `* t in! T

H `* t in T (76)

H `* t in! T 0 H `* t = t0 in T

H `* t = t0 in T (77)

H; x : T `* x in! T 0 H `* T type

H `* T total (78)

H `* t in T H `* T total

H `* t in! T (79)

H `* let x = t1 in t2 in! B H `* t1 in A

H `* t1 in! A (80)

Sequencing

H `* t1 = t01 in B
H; x : B `* t2 = t02 in A H `* A type

H `* (let x = t1 in t2) = (let x = t01 in t02) in A

(81)

H `* t1 in! B H; x : B `* t2 in A
H `* (let x = t1 in t2) = t2[t1=x] in A (82)

Set

H `* A = A0 in Ui
H; x : A `* B in Ui
H; x : A `* B0 in Ui
H; x : A `* B , B0

H `* fx : A j Bg = fx : A0 j B0g in Ui (83)

H `* A type H; x : A `* B type

H `* fx : A j Bg type (84)

H `* a = a0 in A
H `* B[a=x] H `* fx : A j Bg type

H `* a = a0 in fx : A j Bg (85)

82

H; x : A `* B type H; x : A; y : B; J `* C / s

H; x : fx : A j Bg; J `* C / s

(86)
Note that in Rule 86, y may not appear free in J,
C or s, by convention.

Quotient

H `* T = T 0 in Ui
H; x : T ; y : T `* E in Ui
H; x : T ; y : T `* E0 in Ui
H; x : T ; y : T `* E , E0
H; x : T `* E[x=y]
H; x : T ; y : T ; z : E `* E[y; x=x; y]
H; x : T ; y : T ; z : T ;

w : E; w0 : E[y; z=x; y] `* E[z=y]

H `* xy:T ==E = xy:T 0==E0 in Ui (87)

H `* T type
H; x : T ; y : T `* E type
H; x : T `* E[x=y]
H; x : T ; y : T ; z : E `* E[y; x=x; y]
H; x : T ; y : T ; z : T ;

w : E; w0 : E[y; z=x; y] `* E[z=y]

H `* xy:T ==E type (88)

H `* t = t0 in T H `* xy:T ==E type

H `* t = t0 in xy:T==E (89)

H `* t in T H `* t0 in T
H `* e in E[t; t0=x; y] H `* xy:T==E type

H `* t = t0 in xy:T ==E

(90)

H; x : A; y : A `* E type
H; x : (xy:T==E); J `* T type
H; x : A; y : A; z : B; J `* s = s0[y=x] in T

H; x : (xy:T==E); J `* s = s0 in T

(91)

Every Type

H `* E 2 Ui (92)

H `* t in! T H `* t0 in! T 0

H `* t = t0 in E (93)

H `* t in T H `* t0 in T 0

H `* t = t0 in Top (94)

H `* T total

H `* T _ E (D95)

Equality Type

H `* T = T 0 in Ui
H `* t1 = t01 in T H `* t2 = t02 in T

H `* (t1 = t2 in T ) = (t01 = t02 in T 0) in Ui (96)

H `* T type H `* t1 in T H `* t2 in T

H `* (t1 = t2 in T ) type (97)

H `* t = t0 in T
H `* ? in (t = t0 in T ) (98)

H; x : (t = t0 in T ); J[?=x] `* C[?=x] / s[?=x]

H; x : (t = t0 in T ); J `* C / s

(99)

Subtyping Type

H `* T1 = T 01 in Ui H `* T2 = T 02 in Ui

H `* (T1 _ T2) = (T 01 _ T 02) in Ui (100)

H `* T1 type H `* T2 type

H `* (T1 _ T2) type (101)

H `* T _ T 0
H `* ? in (T _ T 0) (102)

H; x : (T _ T 0); J[?=x] `* C[?=x] / s[?=x]

H; x : (T _ T 0); J `* C / s (103)

Inequality Type

H `* n1 = n01 in Z H `* n2 = n02 in Z

H `* (n1 ^ n2) = (n01 ^ n02) in Ui (104)

H `* n ^ n0
H `* ? in (n ^ n0) (105)

H; x : (n ^ n0); J[?=x] `* C[?=x] / s[?=x]

H; x : (n ^ n0); J `* C / s (106)

83

Convergence Type

H `* T = T 0 in Ui H `* t = t0 in T

H `* (t in! T ) = (t0 in! T 0) in Ui (107)

H `* t in T
H `* (t in! T ) type (108)

H `* t in! T
H `* ? in (t in! T ) (109)

H; x : (t in! T ); J[?=x] `* C[?=x] / s[?=x]

H; x : (t in! T ); J `* C / s (110)

Totality Type

H `* T = T 0 in Ui
H `* (T total) = (T 0 total) in Ui (111)

H `* T type
H `* (T total) type (112)

H `* T total
H `* ? in (T total) (113)

H; x : (T total); J[?=x] `* C[?=x] / s[?=x]

H; x : (T total); J `* C / s (114)

Admissibility Type

H `* T = T 0 in Ui
H `* (T admiss) = (T 0 admiss) in Ui (115)

H `* T type
H `* (T admiss) type (116)

H `* T admiss
H `* ? in (T admiss) (117)

H; x : (T admiss); J[?=x] `* C[?=x] / s[?=x]

H; x : (T admiss); J `* C / s

(118)

Totality

H `* T total

H `* T type (119)

H `* Ui total (120)
H `* Void total (121)
H `* Atom total (122)

H `* Z total (123)
H `* (A + B) type
H `* (A + B) total (124)

H `* (\Sigma x:A:B) type
H `* (\Sigma x:A:B) total (125)

H `* (\Pi x:A:B) type
H `* (\Pi x:A:B) total (126)

H `* A total H `* fx : A j Bg type

H `* fx : A j Bg total (127)

H `* A total H `* (xy:A==B) type

H `* (xy:A==B) total (128)

H `* E total (129)
H `* (t = t0 in T ) type
H `* (t = t0 in T ) total (130)

H `* (T _ T 0) type
H `* (T _ T 0) total (131)

H `* (t in! T ) type
H `* (t in! T ) total (132)

H `* (T total) type
H `* (T total) total (133)

H `* (T admiss) type
H `* (T admiss) total (134)

84

Admissibility

H `* T admiss

H `* T type (135)

H `* Void admiss (136)
H `* Atom admiss (137)

H `* Z admiss (138)

H `* A admiss H `* B admiss

H `* (A + B) admiss (139)

H `* A admiss H `* B admiss (x : A)

H `* (\Sigma x:A:B) admiss (140)

H; x : A `* B admiss H `* (\Pi x:A:B) type

H `* (\Pi x:A:B) admiss

(141)

H `* T admiss H `* T type

H `* T admiss (142)

H `* A admiss
H `* B admiss (x : A)
H; x : A; y : #B `* B

H `* fx : A j Bg admiss (143)

H `* A admiss
H `* B[ss1(z); ss2(z)=x; y] admiss (z : A \Theta  A)
H; x : A; y : A; z : #B `* B
H `* xy:A==B type

H `* xy:A==B admiss

(144)

H `* E admiss (145)

H `* (t = t0 in T ) type
H `* (t = t0 in T ) admiss (146)

H `* (T _ T 0) type
H `* (T _ T 0) admiss (147)

H `* (t ^ t0) type
H `* (t ^ t0) admiss (148)

H `* (t in! T ) type
H `* (t in! T ) admiss (149)

H `* (T total) type
H `* (T total) admiss (150)

H `* (T admiss) type
H `* (T admiss) admiss (151)

More Admissibility Type

H `* A = A0 in Ui
H; x : A `* B = B0 in Ui

H `* (B admiss (x : A)) =

(B0 admiss (x : A0)) in Ui (152)

H `* A type H; x : A `* B type

H `* (B admiss (x : A)) type (153)

H `* B admiss (x : A)
H `* ? in (B admiss (x : A)) (154)

H; x : (B admiss (x : A)); J[?=x]

`* C[?=x] / s[?=x]

H; x : (B admiss (x : A)); J `* C / s (155)

H `* A = A0 in Ui
H; x : A `* B = B0 in Ui

H `* (B wcoadmiss (x : A)) =

(B0 wcoadmiss (x : A0)) in Ui (156)

H `* A type H; x : A `* B type

H `* (B wcoadmiss (x : A)) type (157)

H `* B wcoadmiss (x : A)
H `* ? in (B wcoadmiss (x : A)) (158)

H; x : (B wcoadmiss (x : A)); J[?=x]

`* C[?=x] / s[?=x]

H; x : (B wcoadmiss (x : A)); J `* C / s (159)

85

H `* A = A0 in Ui
H; x : A `* B = B0 in Ui

H `* (B coadmiss (x : A)) =

(B0 coadmiss (x : A0)) in Ui (160)

H `* A type H; x : A `* B type

H `* (B coadmiss (x : A)) type (161)

H `* B coadmiss (x : A)
H `* ? in (B coadmiss (x : A)) (162)

H; x : (B coadmiss (x : A)); J[?=x]

`* C[?=x] / s[?=x]

H; x : (B coadmiss (x : A)); J `* C / s (163)

H `* T = T 0 in Ui
H `* (T mono) = (T 0 mono) in Ui (164)

H `* T type
H `* (T mono) type (165)

H `* T mono
H `* ? in (T mono) (166)

H; x : (T mono); J[?=x] `* C[?=x] / s[?=x]

H; x : (T mono); J `* C / s (167)

More Admissibility

H `* A admiss (x : T ) H `* T

H `* A admiss (x 62 A) (168)

H `* A admiss H `* T type

H `* A admiss (x : T ) (x 62 A) (169)

H `* A type H `* T type

H `* A wcoadmiss (x : T ) (x 62 A) (170)

H `* A coadmiss (x : T )
H `* A wcoadmiss (x : T ) (171)

H `* A mono
H `* A admiss (172)

H `* T type
H `* Void coadmiss (x : T ) (173)

H `* Void mono (174)

H `* T type
H `* Atom coadmiss (x : T ) (175)

H `* Atom mono (176)

H `* T type
H `* Z coadmiss (x : T ) (177)

H `* Z mono (178)
H `* A admiss (x : T )
H `* B admiss (x : T )

H `* (A + B) admiss (x : T ) (179)

H `* A wcoadmiss (x : T )
H `* B wcoadmiss (x : T )

H `* (A + B) wcoadmiss (x : T ) (180)

H `* A coadmiss (x : T )
H `* B coadmiss (x : T )

H `* (A + B) coadmiss (x : T ) (181)

H `* A mono H `* B mono

H `* (A + B) mono (182)

H `* A admiss (y : T )
H `* B[ss1(z); ss2(z)=y; x] admiss (z : \Sigma y:T:A)

H `* (\Sigma x:A:B) admiss (y : T )

(183)

H `* A wcoadmiss (y : T )
H; y0 : T ; x : A[y0=y] `* B wcoadmiss (y : T )
H; y : T `* \Sigma x:A:B type

H `* (\Sigma x:A:B) wcoadmiss (y : T )

(184)

86

H `* A coadmiss (y : T )
H `* B[ss1(z); ss2(z)=y; x] coadmiss (z : \Sigma y:T:A)

H `* (\Sigma x:A:B) coadmiss (y : T )

(185)

H `* A mono H; x : A `* B mono

H `* (\Sigma x:A:B) mono (186)

H `* A wcoadmiss (y : T )
H; y0 : T ; x : A[y0=y] `* B admiss (y : T )
H; y : T `* \Pi x:A:B type

H `* (\Pi x:A:B) admiss (y : T ) (187)

H `* A mono H; x : A `* B mono

H `* (\Pi x:A:B) mono (188)

H `* A admiss (x : T ) H; x : T `* A type

H `* A admiss (x : T )

(189)

H `* A admiss y : T
H `* B[ss1(z); ss2(z)=y; x] admiss (z : \Sigma y:T:A)
H; y : T ; x : A; z : #B `* B
H; y : T `* fx : A j Bg type

H `* fx : A j Bg admiss (y : T )

(190)

H `* A wcoadmiss (y : T )
H; y0 : T ; x : A[y0=y] `* B wcoadmiss (y : T )
H; y : T `* fx:A j Bg type

H `* fx : A j Bg wcoadmiss (y : T )

(191)

H `* A coadmiss (y : T )
H `* B[ss1(z); ss2(z)=y; x] coadmiss (z : \Sigma y:T:A)

H `* fx : A j Bg coadmiss (y : T )

(192)

H `* A mono H `* fx : A j Bg type

H `* fx : A j Bg mono (193)

H `* A admiss z : T
H `* B[ss1(w); ss1(ss2(w)); ss2(ss2(w))=z; x; y]

admiss(w : \Sigma z:T:(A \Theta  A))
H; z : T ; x : A; y : A; w : #B `* B
H; y : T `* xy:A==B type

H `* xy:A==B admiss (z : T )

(194)

H `* A wcoadmiss (z : T )
H; z0 : T ; x : A[z0=z]; y : A[z0=z] `*

B wcoadmiss (z : T )
H; z : T `* xy:A==B type

H `* xy:A==B wcoadmiss (z : T ) (195)

H `* A coadmiss (z : T )
H `* B[ss1(w); ss1(ss2(w)); ss2(ss2(w))=z; x; y]

coadmiss(w : \Sigma y:T:(A \Theta  A))

H `* xy:A==B coadmiss (z : T )

(196)

H `* A mono H `* xy:A==B type

H `* xy:A==B mono (197)

H `* T type
H `* E coadmiss (x : T ) (198)

H `* E mono (199)

H `* A admiss (x : T )
H; x : T `* (a = a0 in A) type

H `* (a = a0 in A) admiss (x : T ) (200)

H `* A coadmiss (x : T )
H; x : T `* (a = a0 in A) type

H `* (a = a0 in A) coadmiss (x : T ) (201)

H `* (a = a0 in A) type
H `* (a = a0 in A) mono (202)

H; x : T `* (a ^ a0) type H `* T type

H `* (a ^ a0) admiss (x : T ) (203)

87

H; x : T `* (a ^ a0) type H `* T type

H `* (a ^ a0) coadmiss (x : T ) (204)

H `* (a ^ a0) type
H `* (a ^ a0) in A) mono (205)

H; x : T `* (a in! A) type H `* T type

H `* (a in! A) admiss (x : T ) (206)

H; x : T `* (a in! A) type H `* T type

H `* (a in! A) coadmiss (x : T ) (207)

H `* (a in! A) type
H `* (a in! A) mono (208)

H; y : T `* d in T1 + T2
H; y : T ; x : T1 `* A type
H; y : T ; x : T2 `* B type
H `* A[ss1(z); ss2(z)=y; x]

admiss(z : \Sigma y:T:T1)
H `* B[ss1(z); ss2(z)=y; x]

admiss(z : \Sigma y:T:T2)

H `* case(d; x:A; x:B) admiss (y : T ) (209)

H; y : T `* d in T1 + T2
H; y : T ; x : T1 `* A type
H; y : T ; x : T2 `* B type
H `* A[ss1(z); ss2(z)=y; x]

wcoadmiss(z : \Sigma y:T:T1)
H `* B[ss1(z); ss2(z)=y; x]

wcoadmiss(z : \Sigma y:T:T2)

H `* case(d; x:A; x:B) wcoadmiss (y : T ) (210)

H; y : T `* d in T1 + T2
H; y : T ; x : T1 `* A type
H; y : T ; x : T2 `* B type
H `* A[ss1(z); ss2(z)=y; x]

coadmiss(z : \Sigma y:T:T1)
H `* B[ss1(z); ss2(z)=y; x]

coadmiss(z : \Sigma y:T:T2)

H `* case(d; x:A; x:B) coadmiss (y : T ) (211)

Classical Rules

H ` 8P :Pi: #(P . :P ) / *x:? (XM)

H `* A wcoadmiss (x : T ) H; x : T `* A type

H `* A wcoadmiss (x : T )

(PWC)

H `* A coadmiss (x : T ) H; x : T `* A type

H `* A coadmiss (x : T )

(PC)

H `* A = A0 in Ui
H; y : A; z : A `* P in Ui
H `* :(9f :N ! A: 8n:N: P [f (n + 1); f n=y; z])
H; x : A;

f : fg j y : fy : A j P [x=z]g ! B[g; y=f; x]g
`* B = B0 in Ui

H `* ff j x:A ! Bg = ff j x:A0 ! B0g in Ui

(VF)

H `* A type
H; y : A; z : A `* P type
H `* :(9f :N ! A: 8n:N: P [f (n + 1); f n=y; z])
H; x : A;

f : fg j y : fy : A j P [x=z]g ! B[g; y=f; x]g
`* B type

H `* ff j x:A ! Bg type

(VFT)

88

Appendix C
Proofs
Lemma C.1 If T 2 Ui and T , T 0 then T = T 0 2 Ui .
Proof

It is easy to verify that the statement holds for all T if it holds for canonical T . Therefore I
assume, without loss of generality, that T is canonical and prove the statement by induction
on the structure of T . I show the function and partial type cases, the other cases are similar.

Suppose T 2 Ui and T , T 0 where T j \Pi x:A:B. Then (for some A0; B0) T 0 + \Pi x:A0:B0
where A , A0 and B , B0. By induction A = A0 2 Ui . Suppose a = a0 2 A. Then
B[a=x] = B[a0=x] 2 Ui and B[a0=x] , B0[a0=x] so, by induction, B[a0=x] = B0[a0=x] 2 Ui. It
follows that B[a=x] = B0[a0=x] 2 Ui so T = T 0 2 Ui.

Suppose T 2 Ui and T , T 0 where T j A. Then (for some A0) T 0 + A0 where A , A0. Since
A 2 Ui , it follows by induction that A = A0 2 Ui . Hence A = A0 2 Ui so T = T 0 2 Ui . 2

Theorem 4.3 If T type and T , T 0 then T = T 0. If t 2 T and t , t0 then t = t0 2 T .
Proof

The first part is shown by a similar argument to Lemma C.1. For the second part, it is easy
to verify that the statement holds for all T if it holds for canonical T . Therefore I assume,
without loss of generality, that T is canonical and prove the statement by induction on the
structure of T . The case where T j Ui follows from Lemma C.1. I show the function and
partial type cases, the other cases are similar.

Suppose t 2 \Pi x:A:B and t , t0. Then (for some b) t + *x:b. Therefore (for some b0) t0 + *x:b0
and b , b0. Suppose a = a0 2 A. Then b[a=x] = b[a0=x] 2 B[a=x] and b[a0=x] , b0[a0=x]
so, by induction, b[a0=x] = b0[a0=x] 2 B[a=x]. It follows that b[a=x] = b0[a0=x] 2 B[a=x] so
t = t0 2 \Pi x:A:B.

Suppose t 2 T and t , t0. Certainly t# , t0#. Suppose t#, then t 2 T . By induction
t = t0 2 T and hence t = t0 2 T . 2

Lemma C.2 If x appears actively in t and t[e=x]# then e#.
Proof

By induction on the structure of t.

89

Lemma 4.6 If x appears actively in t then t[e=x] , let x = e in t.
Proof

This proof makes use of Proposition 5.4 and Lemma 5.5, but those facts are shown without
using this lemma. I first show that let x = e in t ^ t[e=x]. Let oe be a substitution such
that oe(let x = e in t) and oe(t[e=x]) are closed and suppose, without loss of generality, that
oe does not substitute for x. Suppose further that oe(let x = e in t)#. Then oe(e)# so let
oe(e) + v. Note that oe(e) , v. Therefore oe(let x = e in t) j let x = oe(e) in oe(t) ^ let x =
v in oe(t) ^ oe(t)[v=x] ^ oe(t)[oe(e)=x] j oe(t[e=x]). Hence let x = e in t ^ e[t=x].

I now show that t[e=x] ^ let x = e in t. Again suppose oe(let x = e in t) and oe(t[e=x]) are
closed and suppose, without loss of generality, that oe does not substitute for x. Suppose
further that oe(t[e=x])#. Note that the active positions of t are also active in oe(t). By Lemma
C.2, oe(e)#. Thus oe(t[e=x]) ^ oe(let x = e in t) in a similar manner as before. 2

Lemma 4.10 If o/ is a type system, then for each op 2 Types, op(o/ ) is a type system.
Proof

By tedious verification of all cases. The only subtle argument is for unique valuation: For
each operator other than VFun, the existential prefix's instances are uniquely given by o/ , T
and T 0. (Parametric variables (e.g., fi(\Gamma )) are unique over the membership of ff.) Therefore
OE is uniquely given for operators other than VFun.

For the VFun operator the term P is not uniquely given by o/ , T and T 0. The relations
!, ae(\Gamma ;\Gamma ), and fl(\Gamma ) also are not, but they are unique when also given P . Further, it is not
obvious that ffi(\Gamma ;\Gamma ) is uniquely given by o/ , T and T 0, but again it is clearly unique when also
given P . Suppose OE and OE0 are different equalities resulting from terms P and P 0. Define !
and !0, fl and fl0, and so forth, to be the various relations resulting from P and P 0. We wish
to show that t OE t0 implies t OE0 t0. Suppose t OE t0. Then t + *x:b and t0 + *x:b0. It remains to
show that b[a=x] ffi(t;a) b0[a0=x] implies b[a=x] ffi0(t;a) b0[a0=x] whenever a ff a0. However, ffi(t;a)

and ffi0(t;a) are identical relations when they are both defined, so it suffices to show that ffi0(t;a)
is defined for all a ff a. This may be shown by induction using the order !0. 2

Lemma 4.11 If

ffl o/ is type symmetric and type transitive, and
ffl o/ defines only universes (that is, if o/ T T OE then T + Ui for some i), and
ffl Close(o/ )T1T 01OE1 and Close(o/ )T2T 02OE2, and
ffl either T1 j T2 or T1 j T 02,
then either o/ T1T 01OE1 and o/ T2T 02OE2, or for some op 2 Types, op(Close(o/ ))T1T 01OE1 and
op(Close(o/ ))T2T 02OE2.

Proof

By inspection.

90

Lemma 4.12 If o/ is a type system and if o/ defines only universes, then Close(o/ ) is a type
system.

Proof

All but unique valuation and type transitivity are directly by Lemma 4.10 and induction.
Unique valuation and type transitivity are by Lemma 4.11 (to ensure both antecedents are
from the same case), then by Lemma 4.10 and induction. 2

Lemma 4.13 For all i, Univi and Nuprli are type systems.
Proof

By complete induction on i.

Theorem 5.1 There exist inadmissible types.
Proof

This example is due to Smith [92]. Let the type T and the function f be defined as follows:

T def= \Sigma h:(N ! N ): ((\Pi x:N: h x in! N) ! Void )

f def= *p:hg; *y: ?i

g def= *x: if x ^ 0 then 0 else ss1(p)(x \Gamma  1)

It is easy to verify that T type. We wish to show that f has type T ! T . Suppose t = t0 2 T .
We need g[t=p] = g[t0=p] 2 N ! N and *y: ? 2 (\Pi x:N: (g[t=p])x in! N) ! Void . The former
is easily shown; to show the latter, I assume that (g[t=p])n converges for every natural
number n and draw a contradiction. It follows that \Pi x:N: (g[t=p])x in! N is empty and
*y: ? is vacuously a function from any empty type to Void . Suppose (g[t=p])n converges for
every natural number n. Then the term if n ^ 0 then 0 else ss1(t)(n \Gamma  1) also converges
for every natural number n. It follows that t#, since ss1(t)(0)#, and hence t 2 T . Thus
(\Pi x:N: ss1 (t)(x) in! N) ! Void is inhabited (by ss2(t)) and consequently it cannot be the case
that ss1(t)(n)# for every natural number n. But this is a contradiction since ss1(t)(n \Gamma  1)#
for every n ? 1. Therefore f 2 T ! T .

However, it is not the case that fix (f ) 2 T . Suppose fix (f ) 2 T . Then fix (f ) 2 T since
fix (f ) converges (in two steps). Thus ss2(fix (f )) 2 (\Pi x:N: ss1 (fix (f ))(x) in! N)! Void , which
implies that ss1(fix (f )) is not total on N, but it is easy to show by induction that ss1(fix (f ))
is in fact total (on N). Therefore fix (f ) 62 T and hence T is not admissible. 2

Lemma 5.5 If e ^ e0 and t ^ t0 then e[t=x] ^ e0[t0=x].
Proof

The proof is a straightforward application of Howe's method. In order to keep this proof
brief, I draw from the terminology and results of Howe's paper [53] and will not repeat the
definitions or lemmas. I write t +k t0 when t + t0 in k steps and t +!k t0 when t + t0 in less
than k steps. It is sufficient to show that each of the noncanonical operators are extensional.

Case 1: Suppose t j e1e2, t0 j e01e02 and a are closed. Suppose further that t +k a,
ei ^\Lambda  e0i and the induction hypothesis holds (for every closed u1, u2 and u, if u1 +!k u2
and u1 ^\Lambda  u then u2 ^\Lambda  u). Then e1 +!k *x:b and b[e2=x] +!k a. By the induction
hypothesis, *x:b ^\Lambda  e01. By Howe's Lemma 2, there exists b0 *\Lambda  b such that e01 + *x:b0. By

91

Howe's Lemma 1, b[e2=x] ^\Lambda  b0[e02=x]. By the induction hypothesis a ^\Lambda  b0[e02=x]. However,
t0 7!\Lambda  b0[e02=x] so b0[e02=x] ^ t0. Consequently a ^\Lambda  t0, as desired.

Case 2: Suppose t j case(e; x:e1; x:e2), t0 j case(e0; x:e01; x:e02) and a are closed. Suppose
further that t +k a, e ^\Lambda  e0, ei ^\Lambda  e0i and the induction hypothesis holds. Then e +!k inj j(b)
(for some j = 1 or 2) and ej[b=x] +!k a. By the induction hypothesis, inj j(b) ^\Lambda  e0.
By Howe's Lemma 2, there exists b0 *\Lambda  b such that e0 + inj j(b0). By Howe's Lemma 1,
ej[b=x] ^\Lambda  e0j[b0=x]. By the induction hypothesis, a ^\Lambda  e0j[b0=x]. However, t0 7!\Lambda  e0j[v0=x] so
e0j[v0=x] ^ t0. Consequently a ^\Lambda  t0, as desired.

Case 3: Suppose t j ssi(e), t0 j ssi(e0) and a are closed. Suppose further that t +k a,
e ^\Lambda  e0 and the induction hypothesis holds. Then e +!k hb1; b2i and bi +!k a. By the
induction hypothesis, hb1; b2i ^\Lambda  e0. By Howe's Lemma 2, there exist b01 *\Lambda  b1 and b02 *\Lambda  b2
such that e0 + hb01; b02i. By the induction hypothesis, a ^\Lambda  b0i. However, t0 7! b0i so a ^\Lambda  t0.

Case 4: Suppose t j (e1 =A e2), t0 j (e01 =A e02) and a are closed. Suppose further
that t +k a, ei ^\Lambda  e0i and the induction hypothesis holds. Then, for some atoms ff1 and ff2,
ei +!k ffi. If ff1 = ff2 then a j true and otherwise a j false. By the induction hypothesis,
ffi ^\Lambda  e0i. By Howe's Lemma 2, e0i + ffi. Hence t0 + a, so a ^\Lambda  t0. The cases for =Z, ^Z and
\Phi  are similar.

Case 5: Suppose t j let x = e1 in e2, t0 j let x = e01 in e02 and a are closed. Suppose
further that t +k a, e1 ^\Lambda  e01, e2 ^ e02 and the induction hypothesis holds. Then e1 +!k v
and e2[v=x] +!k a. By the induction hypothesis, v ^\Lambda  e01. By Howe's Lemma 2, there exists
v0 *\Lambda  v such that e01 + v0. Then by Howe's Lemma 1, e2[v=x] ^\Lambda  e02[v0=x]. By the induction
hypothesis, a ^\Lambda  e02[v0=x]. However, t0 7!\Lambda  e02[v0=x] so a ^\Lambda  t0.

Case 6: Suppose t j fix (e), t0 j fix (e0) and a are closed. Suppose further that t +k a,
e ^\Lambda  e0 and the induction hypothesis holds. Then e +!k *x:b and b[fix (e)=x] +!k a. By
the induction hypothesis, *x:b ^\Lambda  e0. By Howe's Lemma 2, there exists b0 *\Lambda  b such that
e0 + *x:b0. By Howe's Lemma 1, b[fix (e)=x] ^\Lambda  b0[fix (e0)=x], since fix (e) ^\Lambda  fix (e0). By the
induction hypothesis, a ^\Lambda  b0[fix (e0)=x]. However, t0 7! b0[fix (e0)=x] so a ^\Lambda  t0. 2

Lemma 5.7 If e1[t=x] 7! e2, and e1[t=x] is closed, and t is closed and noncanonical, then either

ffl there exists e02 such that for any closed t0, e1[t0=x] 7! e02[t0=x], or

ffl there exist e01 and t0 such that e1 j e01[x=y], t 7! t0 and for any closed t00, e01[t00; t=x; y] 7!

e01[t00; t0=x; y].

Proof

Suppose e1 j x. Then t j e1[t=x] 7! e2. Let e01 = y and t0 = e2. Then e01[t00; t=x; y] j t 7!
t0 j e01[t00; t0=x; y]. The remaining cases are by induction on the derivation of e1[t=x] 7! e2.
I show the lambda rules; the other cases are similar.

Suppose the rule used is:

(*z:b)a 7! b[a=z]
The term e1[t=x] must have the form of a lambda abstraction applied to an argument. Thus
e1 must be of the form (*z:b)a, since e1 j x is already handled and e1 j x a is impossible
because t is noncanonical. Let e02 = b[a=z] and suppose t0 is closed. Then:

e1[t0=x] j (*z:b[t0=x])(a[t0=x])

7! b[t0=x](a[t0=x]=z)

j b[a=z][t0=x] (since t0 is closed)
j e02[t0=x]

92

Suppose the rule used is:

f 7! f 0

f a 7! f 0 a

Then it must be the case that e1 is of the form f1 a (since e1 j x is already handled) and
f1[t=x] 7! f2 (for some f2). Hence the induction hypothesis holds for f1. Suppose the first
case holds: there exists f 02 such that for any closed t0, f1[t0=x] 7! f 02[t0=x]. Let e02 = f 02 a and
suppose t0 is closed. Then:

e1[t0=x] j (f1[t0=x])(a[t0=x])

7! (f 02[t0=x])(a[t0=x])

j e02[t0=x]

Suppose the second case holds: there exist f 01 and t0 such that f1 j f 01[x=y], t 7! t0 and for
any closed t00, f 01[t00; t=x; y] 7! f 01[t00; t0=x; y]. Let e01 = f 01 a and suppose t00 is closed. Then:

e01[t00; t=x; y] j (f 01[t00; t=x; y])(a[t00; t=x; y])

j (f 01[t00; t=x; y])(a[t00; t0=x; y]) (since y is not free in a)
7! (f 01[t00; t0=x; y])(a[t00; t0=x; y])

j e01[t00; t0=x; y]

2

Lemma 5.8 For all f , e1 and e2 (where f is closed and x is the only free variable of e1),
there exist j and e02 such that if e1[fix (f )=x] 7!\Lambda  e2 then e2 j e02[fix (f )=x] and for all k * j,
e02[f k\Gamma j=x] ^ e1[f k=x].

Proof

I show the lemma for evaluations of length exactly one. The result then follows by induction
on the length of the evaluation sequence, summing the numbers j.

Use Lemma 5.7. Suppose the first case holds: there exists e02 such that for any closed t,
e1[t=x] 7! e02[t=x]. Then e1[fix (f )=x] 7! e02[fix (f )=x] and, for any k, e1[f k=x] 7! e02[f k=x].
Thus e02[f k\Gamma 0=x] ^ e1[f k=x]. Suppose the second case holds: there exists e01 such that e1 j
e01[x=y], and for any closed t, e01[t; fix (f )=x; y] 7! e01[t; f (fix (f ))=x; y]. Let e02 = e01[f x=y].
Then e1[fix (f )=x] 7! e02[fix (f )=x]. Suppose k * 1, then e02[f k\Gamma 1=x] j e01[f k\Gamma 1; f k=x; y] ^
e01[f k; f k=x; y] j e1[f k=x]. 2

Theorem 5.9 For all f , t and e (where f is closed), if 8j: e[f j=x] ^ t, then e[fix (f )=x] ^ t.
Proof

By induction on l that for all f , t and e (where f is closed), (8j: e[f j=x] ^ t) ) e[fix (f )=x] ^l
t. The result follows by the definition of ^. The basis is trivial.

Assume the induction hypothesis for l and 8j: e[f j=x] ^ t. Let oe be a substitution such
that oe(e[fix (f )=x]) and oe(t) are closed and suppose, without loss of generality, that oe does
not substitute for x. Then oe(e[fix (f )=x]) j oe(e)[fix (f )=x], oe(e[f j=x]) j oe(e)[f j=x] (for
any j), and the only free variable of oe(e) is x. Suppose oe(e[fix (f )=x]) + e0. By Lemma
5.8, e0 j e00[fix (f )=x] and, for some j and all k * j, e00[f k\Gamma j=x] ^ oe(e)[f k=x]. Then, by
assumption and transitivity, 8k * j: e00[f k\Gamma j=x] ^ oe(t). Therefore, changing variables to
replace k \Gamma  j with k, e00[f k=x] ^ oe(t) for any k.

Let e00 = `(~x1:t1; : : : ; ~xn:tn) (and suppose, without loss of generality, that x does not appear
in any ~xi). Then oe(t) + `(~x1:t01; : : : ; ~xn:t0n) where, for 1 ^ i ^ n and any k, ti[f k=x] ^ t0i.
By induction, ti[fix (f )=x] ^l t0i, for any i. Therefore oe(e[fix (f )=x]) ^l+1 oe(t) and hence
e[fix (f )=x] ^l+1 t. 2

93

Lemma 5.18

ffl Adm(A + B j y : S) if 8s 2 S: (A + B)[s=y] type and Adm(A j y : S) and Adm(B j y : S).
ffl Adm(\Sigma x:A:B j y : S) if 8s 2 S: (\Sigma x:A:B)[s=y] type and \Sigma y:S:A type and Adm(A j y : S)

and Adm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:A))

ffl Adm(Void j y : S), Adm(Atom j y : S), Adm(Z j y : S) and Adm(E j y : S)
ffl Adm(a1 = a2 in A j y : S) if 8s 2 S: (a1 = a2 in A)[s=y] type and Adm(A j y : S)
ffl Adm(a1 ^ a2 j y : S)
ffl Adm(A j y : S) if 8s 2 S: A[s=y] type and Adm(A j y : S)
ffl Adm(a in! A j y : S) if 8s 2 S: (a in! A)[s=y] type
Proof

I show the product and equality cases; the other cases are similar but easier.
Case 1: For the product case, let f , t, t0 and e be arbitrary. Suppose e[!] 2 S and
j is such that 8k * j: e[k] 2 S ^ t[k] = t0[k] 2 (\Sigma x:A:B)[e[k]=y]. It is necessary to show
that t[!] = t0[!] 2 (\Sigma x:A:B)[e[!]=y]. Since e[!] 2 S, it follows that (\Sigma x:A:B)[e[!]=y] type.
Both t[j] and t0[j] converge to pairs, so, by Corollary 5.6, t[!] + ha; bi and t0[!] + ha0; b0i
for some terms a, b, a0 and b0. To get that b = b0 2 B[e[!]=y][a=x], it suffices to show
that ss2(t[!]) = ss2(t0[!]) 2 B[e[!]=y][ss1(t[!])=x]. Rearranging, it suffices to show equality in
B[ss1(z); ss2(z)=y; x][he; ss1(t)i[!]=z].

Since Adm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:A)), it suffices to show that he; ss1(t)i[!] 2 \Sigma y:S:A
and 8k * j: he; ss1(t)i[k] 2 \Sigma y:S:A ^ ss2(t[k]) = ss2(t0[k]) 2 B[ss1(z); ss2(z)=y; x][he; ss1(t)i[k]=z].
The former will follow from a 2 A[e[!]=y] and the supposition. The left half of the latter also
follows from the supposition. Rearranging the right half, it suffices to show that ss2(t[k]) =
ss2(t0[k]) 2 B[e[k]=y][ss1(t[k])=x], which follows from the supposition. The proof that a = a0 2
A[e[!]=y] is similar but easier. Hence t[!] = t0[!] 2 (\Sigma x:A:B)[e[!]=y].

Case 2: For the equality case, again let f , t, t0 and e be arbitrary. Suppose e[!] 2 S and j
is such that 8k * j: e[k] 2 S ^ t[k] = t0[k] 2 (a1 = a2 in A)[e[k]=y]. It is necessary to show that
t[!] = t0[!] 2 (a1 = a2 in A)[e[!]=y]. Since e[!] 2 S, it follows that (a1 = a2 in A)[e[!]=y] type.
Both t[j] and t0[j] converge to ?, so, by Corollary 5.6, t[!] and t0[!] converge to ?. It remains
to show that a1[e[!]=y] = a2[e[!]=y] 2 A[e[!]=y]. Since Adm(A j y : S), it suffices to show that
8k * j: e[k] 2 S ^ a1[e[k]=y] = a2[e[k]=y] 2 A[e[k]=y]. This follows since (a1 = a2 in A)[e[k]=y]
is inhabited for all k * j. 2

Lemma 5.20 Adm(\Pi x:A:B j y : S) if 8s 2 S: (\Sigma x:A:B)[s=y] type and WCoAdm(A j y : S) and
8s 2 S; a 2 A[s=y]: Adm(B[a=x] j y : S)

Proof

Let f , t, t0 and e be arbitrary. Suppose e[!] 2 S and j is such that 8k * j: e[k] 2 S ^
t[k] = t0[k] 2 (\Pi x:A:B)[e[k]=y]. I need to show that t[!] = t0[!] 2 (\Pi x:A:B)[e[!]=y]. Since
e[!] 2 S, it follows that (\Pi x:A:B)[e[!]=y] type. Both t[j] and t0[j] converge to lambda
abstractions, so, by Corollary 5.6, t[!] + *x:b and t0[!] + *x:b0 for some terms b and b0.
Suppose a = a0 2 A[e[!]=y]. To get that b[a=x] = b0[a0=x] 2 B[e[!]; a=y; x] it suffices to show
that t[!]a = t0[!]a0 2 B[e[!]; a=y; x].

94

Since e[!] 2 S, it follows that Adm(B[a=x] j y : S). Therefore, it suffices to show that for
some j0 and all k * j0, t[k]a = t0[k]a0 2 B[e[k]; a=y; x]. Since WCoAdm(A j y : S), there exists
j00 such that 8k * j00: a = a0 2 A[e[k]=y]. Therefore j0 = max(j; j00) suffices. 2

Lemma 5.21

ffl A + B is (weakly) coadmissible for y in S if 8s 2 S: (A + B)[s=y] type and A and B are

(weakly) coadmissible for y in S

ffl WCoAdm(\Sigma x:A:B j y : S) if 8s 2 S: (\Sigma x:A:B)[s=y] type and WCoAdm(A j y : S) and

8s 2 S; a 2 A[s=y]: WCoAdm(B[a=x] j y : S)

ffl CoAdm(\Sigma x:A:Bjy : S) if 8s 2 S: (\Sigma x:A:B)[s=y]type and \Sigma y:S:Atype and CoAdm(Ajy : S)

and CoAdm(B[ss1(z); ss2(z)=y; x] j z : (\Sigma y:S:A))

ffl Void , Atom, Z and E are strongly or weakly coadmissible for y in any S
ffl CoAdm(a1 = a2 in A j y : S) if 8s 2 S: (a1 = a2 in A)[s=y] type and CoAdm(A j y : S)
ffl a1 ^ a2 is strongly or weakly coadmissible for y in any S
ffl A is (weakly) coadmissible for y in S if 8s 2 S: A[s=y] type and A is (weakly) coadmissible

for y is S

ffl a in! A is strongly or weakly coadmissible for y in S if 8s 2 S: (a in! A)[s=y] type
Proof

The proof is largely similar to the preceding proofs, but inverted. I show the proofs for full
coadmissibility of products and partial types.

Case 1: For the product case, let f , t, t0 and e be arbitrary. Suppose e[!] 2 S, j is such that
8k * j: e[k] 2 S, and t[!] = t0[!] 2 (\Sigma x:A:B)[e[!]=y]. It is necessary to show that there exists
j0 such that 8k * j0: t[k] = t0[k] 2 (\Sigma x:A:B)[e[k]=y]. For any k * j, (\Sigma x:A:B)[e[k]=y] type.
Both t[!] and t0[!] converge to pairs, so, by compactness, there exists some j00 such that for all
k * j00, t[k] and t[k] converge to pairs. Thus it suffices to show that for some j0 * max(j; j00)
and all k * j0, ss1(t[k]) = ss1(t0[k]) 2 A[e[k]=y] and ss2(t[k]) = ss2(t0[k]) 2 B[e[k]; ss1(t[k])=y; x]. I
show the latter; the former is similar.

Rearranging, it suffices to show equality in B[ss1(z); ss2(z)=y; x][he; ss1(t)i[k]=z]. By coadmissibility, it suffices to show he; ss1(t)i[!] 2 \Sigma y:S:A and 9j000: 8k * j000: he; ss1(t)i[k] 2 \Sigma y:S:A and
ss2(t[!]) = ss2(t0[!]) 2 B[ss1(z); ss2(z)=y; x][he; ss1(t)i[!]=z]. The first follows from the supposition and the second will follow from ss1(t[k]) 2 A[e[k]=y] and the supposition. Rearranging
the third, is suffices to show that ss2(t[!]) = ss2(t0[!]) 2 B[e[!]=y][ss1(t[!])=x], which follows
from the supposition.

Case 2: For the partial type case, let f , t, t0 and e be arbitrary. Suppose e[!] 2 S, j is
such that 8k * j: e[k] 2 S, and t[!] = t0[!] 2 A[e[!]=y]. I need to show that there exists j0
such that 8k * j0: t[k] = t0[k] 2 A[e[k]=y]. For any k * j, A[e[k]=y] type. Suppose t[!] does
not converge. (Note the non-constructivity of this argument.) Then t0[!] does not converge
and neither does t[k] or t0[k] for any k (since t[k] ^ t[!] and t0[k] ^ t0[k] for all k). Thus for all
k * j, t[k] = t0[k] 2 A[e[k]=y].

Suppose t[!] converges. Then t[!] = t0[!] 2 A[e[!]=y]. By coadmissibility, there exists j0 such
that 8k * j0: t[k] = t0[k] 2 A[e[k]=y]. Hence 8k * max(j; j0): t[k] = t0[k] 2 A[e[k]=y]. 2

95

Lemma 5.23 (Predicate-admissibility and weak and full coadmissibility of case analysis.)
Proof

The proof follows the same lines as those of Lemmas 5.18 and 5.21.

Lemma 5.27 The type fx : A j Bg is admissible if:

ffl Adm(A), and
ffl Adm(B j x : A), and
ffl there exists b such that b[a=x] 2 B[a=x] whenever a 2 A and 9b0: b0 2 B[a=x].
Proof

Let f , t and t0 be arbitrary. Suppose j is such that 8k * j: t[k] = t0[k] 2 fx : A j Bg. Since
fx : A j Bg is inhabited it is a type. Since Adm(A), t[!] = t0[!] 2 A. By set membership,
for all k * j there exists b0 such that b0 2 B[t[k]=x]. Thus b[t[k]=x] 2 B[t[k]=x] for all k * j.
Hence b[t[!]=x] 2 B[t[!]=x] follows by predicate-admissibility. 2

Lemma 5.29 (Predicate-admissibility of set types.)
Proof

The proof follows the same lines as Lemma 5.27.

Lemma 5.30 (Weak and full coadmissibility and monotonicity of set types.)
Proof

The proof follows the same lines as Lemma 5.21 and Proposition 5.26.

Lemma 5.31 (Admissibility, predicate-admissibility, weak and full coadmissibility and monotonicity of quotient types.)

Proof

The proof follows the same lines as the proofs for the set type.

Theorem 5.32 There does not exist an algorithm that computes an integer j such that 8k *
j: t = t0 2 T [e[k]=x], when given S, T , f , t, t0, e and i such that:

ffl 8s 2 S: T [s=x] type
ffl CoAdm(T j x : S)
ffl e[!] 2 S
ffl 8k * i: e[k] 2 S
ffl t = t0 2 T [e[!]=x]

96

Proof

Suppose such an algorithm exists. Let g be an arbitrary term that computes a total function
on integers; that is, g 2 Z ! Z. Given the algorithm, we may effectively determine whether
g iterated on 1 ever computes 0, which is certainly undecidable. Let f = *h: *n: if n =Z

0 then 0 else h(gx) and let h = fix (f ). Note that f 2 Z ! Z ! Z ! Z and h 2 Z ! Z. By
construction, g iterated on 1 computes 0 if and only if h(1)#.

We will use the algorithm to determine an upper bound on the number of recursive calls
needed to simulate h. Let S =

Z

T = x in! Z

f = as above
t; t0 = let y = h(1) in ?

e = w(1)

i = 0

Observe that e[!] = h(1) and e[k] = (f k)(1), so the first four preconditions of the algorithm
are satisfied. Moreover, CoAdm(T j x : S) can be shown constructively. For the final
precondition, suppose t#. Then h(1)# so t 2 h(1) in! Z.

Therefore let j be the result computed by the algorithm. I show that f j(1)# exactly when
h(1)#. Since f j(1) approximates h(1), it follows that f j(1)# implies h(1)#. By the algorithm
specification, t 2 f j(1) in! Z. If h(1)# then t#, so t 2 f j(1) in! Z and consequently f j(1)#.

Let h0 =

j timesz ""-- -
f (f \Delta  \Delta  \Delta  f (*y:1) \Delta  \Delta  \Delta ), and observe that f j(1)# exactly when h0(1) + 0. Consequently
h(1)# exactly when h0(1) + 0. However, h0 is total, so we may decide whether h(1)# by
running h0(1). 2

97

Bibliography

[1] Mart'in Abadi and Luca Cardelli. A theory of primitive objects: Untyped and first-order

systems. In Theoretical Aspects of Computer Software, volume 789 of Lecture Notes in
Computer Science, pages 296-320. Springer-Verlag, April 1994.

[2] Mart'in Abadi and Luca Cardelli. A Theory of Objects. Springer-Verlag, 1996.
[3] Mart'in Abadi, Luca Cardelli, and Ramesh Viswanathan. An interpretation of objects

and object types. In Twenty-Third ACM SIGACT-SIGPLAN Symposium on Principles
of Programming Languages, pages 296-409, St. Petersburg, Florida, January 1996.

[4] Peter Aczel. Frege structures revisited. In B. Nordstr"om and J. Smith, editors, Proceedings

of the 1983 Marstrand Workshop, 1983.

[5] Stuart Allen. A non-type-theoretic definition of Martin-L"of's types. In Second IEEE

Symposium on Logic in Computer Science, pages 215-221, Ithaca, New York, June 1987.

[6] Stuart Allen. A Non-Type-Theoretic Semantics for Type-Theoretic Language. Ph.D. dissertation, Department of Computer Science, Cornell University, Ithaca, New York, 1987.

[7] Philippe Audebaud. Partial objects in the calculus of constructions. In Sixth IEEE Symposium on Logic in Computer Science, pages 86-95, Amsterdam, July 1991.

[8] Bruno Barras, Samuel Boutin, Cristina Cornes, Judica"el Courant, Jean-Christophe

Filli^atre, Eduardo Gim'enez, Hugo Herbelin, G'erard Huet, C'esar Mu~noz, Chetan Murthy,
Catherine Parent, Christine Paulin-Mohring, Amokrane Sa"ibi, and Benjamin Werner. The
Coq Proof Assistant Reference Manual. INRIA-Rocquencourt, CNRS and ENS Lyon, 1996.

[9] David A. Basin. An environment for automated reasoning about partial functions. In

Ninth International Conference on Automated Deduction, volume 310 of Lecture Notes in
Computer Science. Springer-Verlag, 1988.

[10] Michael Beeson. Recursive models for constructive set theories. Annals of Mathematical

Logic, 23:127-178, 1982.

[11] Lars Birkedal and Robert Harper. Relational interpretations of recursive types in an

operational setting. In Theoretical Aspects of Computer Software, 1997.

[12] Val Breazu-Tannen, Thierry Coquand, Carl A. Gunter, and Andre Scedrov. Inheritance

as implicit coercion. Information and Computation, 93:172-221, 1991.

[13] Kim B. Bruce. A paradigmatic object-oriented programming language: Design, static

typing and semantics. Journal of Functional Programming, 4(2):127-206, April 1994.

98

[14] Kim B. Bruce, Luca Cardelli, and Benjamin C. Pierce. Comparing object encodings. In

Theoretical Aspects of Computer Software, Sendai, Japan, September 1997.

[15] Peter Canning, William Cook, Walter Hill, John Mitchell, and Walter Olthoff. F-bounded

quantification for object-oriented programming. In Conference on Functional Programming
Languages and Computer Architecture, pages 273-280, September 1989.

[16] Luca Cardelli. Phase distinctions in type theory. Unpublished manuscript, January 1988.
[17] Luca Cardelli. Structural subtyping and the notion of power type. In Fifteenth ACM

SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pages 70-79,
San Diego, January 1988.

[18] Luca Cardelli. Typeful programming. In Formal Description of Programming Concepts.

Springer-Verlag, 1991.

[19] R.L. Constable, S.F. Allen, H.M. Bromley, W.R. Cleaveland, J.F. Cremer, R.W. Harper,

D.J. Howe, T.B. Knoblock, N.P. Mendler, P. Panangaden, J.T. Sasaki, and S.F. Smith.
Implementing Mathematics with the Nuprl Proof Development System. Prentice-Hall, 1986.

[20] Robert L. Constable. Intensional analysis of functions and types. Technical Report CSR118-82, Department of Computer Science, University of Edinburgh, June 1982.

[21] Robert L. Constable. Constructive mathematics as a programming logic I: Some principles

of theory. In Topics in the Theory of Computation, volume 24 of Annals of Discrete
Mathematics, pages 21-37. Elsevier, 1985. Selected papers of the International Conference
on Foundations of Computation Theory 1983.

[22] Robert L. Constable. Type theory as a foundation for computer science. In Theoretical

Aspects of Computer Software 1991, volume 526 of Lecture Notes in Computer Science,
pages 226-243, Sendai, Japan, 1991. Springer-Verlag.

[23] Robert L. Constable and Karl Crary. Computational complexity and induction for partial

computable functions in type theory. Technical report, Department of Computer Science,
Cornell University, 1997.

[24] Robert L. Constable and Scott Fraser Smith. Partial objects in constructive type theory.

In Second IEEE Symposium on Logic in Computer Science, pages 183-193, Ithaca, New
York, June 1987.

[25] Robert L. Constable and Scott Fraser Smith. Computational foundations of basic recursive

function theory. In Third IEEE Symposium on Logic in Computer Science, pages 360-371,
Edinburgh, Scotland, July 1988.

[26] Robert L. Constable and Daniel R. Zlatin. The type theory of PL/CV3. ACM Transactions

on Programming Languages and Systems, 6(1):94-117, January 1984.

[27] Thierry Coquand. An analysis of Girard's paradox. In First IEEE Symposium on Logic

in Computer Science, pages 227-236, Cambridge, Massachusetts, June 1986.

[28] Thierry Coquand. Metamathematical investigations of a calculus of constructions. In

P. Odifreddi, editor, Logic and Computer Science, volume 31 of The APIC Series, pages
91-122. Academic Press, 1990.

99

[29] Thierry Coquand and G'erard Huet. The calculus of constructions. Information and Computation, 76:95-120, 1988.

[30] Karl Crary. Foundations for the implementation of higher-order subtyping. In 1997 ACM

SIGPLAN International Conference on Functional Programming, pages 125-135, Amsterdam, June 1997.

[31] Karl Crary. Simple, efficient object encoding using intersection types. Technical Report

TR98-1675, Department of Computer Science, Cornell University, April 1998.

[32] N. G. de Bruijn. A survey of the project Automath. In J. P. Seldin and J. R. Hindley,

editors, To H.B. Curry: Essays on Combinatory Logic, Lambda-Calculus and Formalism,
pages 579-606. Academic Press, 1980.

[33] Michael Dummett. Elements of Intuitionism. Oxford Logic Guides. Clarendon Press, 1977.
[34] Andrzej Filinski. Controlling Effects. Ph.D. dissertation, Carnegie Mellon University,

School of Computer Science, Pittsburgh, Pennsylvania, May 1996.

[35] Jean-Yves Girard. Une extension de l'interpr'etation de G"odel `a l'analyse, et son application

`a l''elimination de coupures dans l'analyse et la th'eorie des types. In J. E. Fenstad, editor,
Proceedings of the Second Scandinavian Logic Symposium, pages 63-92. North-Holland
Publishing Co., 1971.

[36] Jean-Yves Girard. Interpr'etation fonctionelle et 'elimination des coupures de l'arithm'etique

d'ordre sup'erieur. Ph.D. dissertation, Universit'e Paris VII, 1972.

[37] Jean-Yves Girard, Yves Lafont, and Paul Taylor. Proofs and Types. Cambridge University

Press, 1988.

[38] Michael J. Gordon, Arthur J. Milner, and Christopher P. Wadsworth. Edinburgh LCF:

A Mechanised Logic of Computation, volume 78 of Lecture Notes in Computer Science.
Springer-Verlag, 1979.

[39] Michael J. C. Gordon and Tom F. Melham. Introduction to HOL: A Theorem Proving

Environment for Higher-Order Logic. Cambridge University Press, 1993.

[40] Robert Harper. Constructing type systems over an operational semantics. Journal of

Symbolic Computation, 14:71-84, 1992.

[41] Robert Harper. Personal communication, 1993.
[42] Robert Harper, Furio Honsell, and Gordon Plotkin. A framework for defining logics.

Journal of the ACM, 40(1):143-184, January 93.

[43] Robert Harper and Mark Lillibridge. Explicit polymorphism and CPS conversion. In

Twentieth ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pages 206-219, January 1993.

[44] Robert Harper and Mark Lillibridge. A type-theoretic approach to higher-order modules

with sharing. In Twenty-First ACM SIGACT-SIGPLAN Symposium on Principles of
Programming Languages, pages 123-137, Portland, Oregon, January 1994.

100

[45] Robert Harper and John C. Mitchell. On the type structure of Standard ML. ACM

Transactions on Programming Languages and Systems, 15(2):211-252, April 1993.

[46] Robert Harper, John C. Mitchell, and Eugenio Moggi. Higher-order modules and the

phase distinction. In Seventeenth ACM SIGACT-SIGPLAN Symposium on Principles of
Programming Languages, pages 341-354, San Francisco, January 1990.

[47] Robert Harper and Robert Pollack. Type checking with universes. Theoretical Computer

Science, 89:107-136, 1991.

[48] Robert Harper and Chris Stone. A type-theoretic interpretation of Standard ML. In Proof,

Language and Interaction: Essays in Honour of Robin Milner. The MIT Press, 1998. To
appear.

[49] Jason J. Hickey. Formal objects in type theory using very dependent types. In Foundations

of Object Oriented Languages 3, 1996.

[50] Jason J. Hickey. A semantics of objects in type theory. Unpublished manuscript, 1997.
[51] W. Howard. The formulas-as-types notion of construction. In J. P. Seldin and J. R.

Hindley, editors, To H.B. Curry: Essays on Combinatory Logic, Lambda-Calculus and
Formalism, pages 479-490. Academic Press, 1980.

[52] Douglas J. Howe. The computational behaviour of Girard's paradox. In Second IEEE

Symposium on Logic in Computer Science, pages 205-214, Ithaca, New York, June 1987.

[53] Douglas J. Howe. Equality in lazy computation systems. In Fourth IEEE Symposium on

Logic in Computer Science, 1989.

[54] Douglas J. Howe. Semantic foundations for embedding HOL in Nuprl. Technical report,

Bell Labs, 1996.

[55] Shigeru Igarashi. Admissibility of fixed-point induction in first-order logic of typed theories.

Technical Report AIM-168, Computer Science Department, Stanford University, May 1972.

[56] Paul Jackson. The Nuprl Proof Development System, Version 4.1. Department of Computer Science, Cornell University, 1994.

[57] Paul Bernard Jackson. Enhancing the Nuprl Proof Development System and Applying it

to Computational Abstract Algebra. Ph.D. dissertation, Department of Computer Science,
Cornell University, Ithaca, New York, January 1995.

[58] Samuel Kamin. Inheritance in Smalltalk-80: A denotational definition. In Fifteenth ACM

SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pages 80-87,
San Diego, January 1988.

[59] Christoph Kreitz. Formal reasoning about communications systems I. Technical report,

Department of Computer Science, Cornell University, 1997.

[60] John Launchbury and Simon L. Peyton Jones. State in Haskell. Lisp and Symbolic Computation, 8(4):293-341, December 1995.

[61] Xavier Leroy. Unboxed objects and polymorphic typing. In Nineteenth ACM SIGACTSIGPLAN Symposium on Principles of Programming Languages, pages 177-188, 1992.

101

[62] Xavier Leroy. Manifest types, modules and separate compilation. In Twenty-First ACM

SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pages 109-122,
Portland, Oregon, January 1994.

[63] Xavier Leroy. Applicative functors and fully transparent higher-order modules. In TwentySecond ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages,
San Francisco, January 1995.

[64] Xavier Leroy. The Objective Caml System, Release 1.00. Institut National de Recherche

en Informatique et Automatique (INRIA), 1996.

[65] David MacQueen. Using dependent types to express modular structure. In Thirteenth

ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pages
277-286, St. Petersburg Beach, Florida, January 1986.

[66] David B. MacQueen and Mads Tofte. A semantics for higher-order functors. In Fifth

European Symposium on Programming, volume 788 of Lecture Notes in Computer Science,
pages 409-423. Springer-Verlag, 1994.

[67] Per Martin-L"of. An intuitionistic theory of types: Predicative part. In Proceedings of the

Logic Colloquium, 1973, volume 80 of Studies in Logic and the Foundations of Mathematics,
pages 73-118. North-Holland, 1975.

[68] Per Martin-L"of. Constructive mathematics and computer programming. In Sixth International Congress of Logic, Methodology and Philosophy of Science, volume 104 of Studies in
Logic and the Foundations of Mathematics, pages 153-175. North-Holland, 1982.

[69] Paul Francis Mendler. Inductive Definition in Type Theory. Ph.D. dissertation, Department of Computer Science, Cornell University, Ithaca, New York, September 1987.

[70] Albert R. Meyer and Mark B. Reinhold. `Type' is not a type. In Thirteenth ACM SIGACTSIGPLAN Symposium on Principles of Programming Languages, pages 287-295, St. Petersburg Beach, Florida, January 1986.

[71] Robin Milner, Mads Tofte, and Robert Harper. The Definition of Standard ML. The MIT

Press, Cambridge, Massachusetts, 1990.

[72] Robin Milner, Mads Tofte, Robert Harper, and David MacQueen. The Definition of Standard ML (Revised). The MIT Press, Cambridge, Massachusetts, 1997.

[73] John C. Mitchell and Gordon D. Plotkin. Abstract types have existential type. ACM

Transactions on Programming Languages and Systems, 10(3):470-502, July 1988.

[74] Eugenio Moggi. Notions of computation and monads. Information and Computation,

93:55-92, 1991.

[75] Greg Morrisett. Compiling with Types. Ph.D. dissertation, Carnegie Mellon University,

School of Computer Science, Pittsburgh, Pennsylvania, December 1995.

[76] Greg Morrisett, Karl Crary, Neal Glew, and David Walker. Stack-based typed assembly

language. In Second Workshop on Types in Compilation, March 1998.

102

[77] Greg Morrisett, David Walker, Karl Crary, and Neal Glew. From System F to typed

assembly language. In Twenty-Fifth ACM SIGACT-SIGPLAN Symposium on Principles
of Programming Languages, pages 85-97, San Diego, January 1998. Extended version
published as Cornell University technical report TR97-1651.

[78] Alan Mycroft. Polymorphic type schemes and recursive definitions. In Sixth International

Symposium on Programming, number 167 in Lecture Notes in Computer Science, pages
217-228. Springer-Verlag, April 1984.

[79] Chris Okasaki. Catenable double-ended queues. In 1997 ACM SIGPLAN International

Conference on Functional Programming, pages 66-74, Amsterdam, June 1997.

[80] Erik Palmgren. An information system interpretation of Martin-L"of's partial type theory

with universes. Information and Computation, 106:26-60, 1993.

[81] Erik Palmgren and Viggo Stoltenberg-Hansen. Domain interpretations of intuitionistic

type theory. U.U.D.M. Report 1989:1, Uppsala University, Department of Mathematics,
January 1989.

[82] Simon L. Peyton Jones and Philip Wadler. Imperative functional programming. In Twentieth ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages,
Charleston, South Carolina, January 1993.

[83] Benjamin C. Pierce and David N. Turner. Simple type-theoretic foundations for objectoriented programming. Journal of Functional Programming, 4(2):207-247, April 1994.

[84] Didier R'emy. Programming objects with ML-ART: An extension to ML with abstract and

record types. In Theoretical Aspects of Computer Software 1994, volume 789 of Lecture
Notes in Computer Science, pages 321-346, Sendai, Japan, 1994. Springer-Verlag.

[85] Didier R'emy and J'er^ome Vouillon. Objective ML: A simple object-oriented extension of

ML. In Twenty-Fourth ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages, pages 40-53, Paris, January 1997.

[86] John C. Reynolds. The essence of Algol. In J. W. de Bakker and J. C. van Vliet, editors,

Proceedings of the International Symposium on Algorithmic Languages, pages 345-372,
Amsterdam, October 1981. North-Holland.

[87] Adrian Rezus. Semantics of constructive type theory. Technical Report 70, Informatics

Department, Faculty of Science, Nijmegen, University, The Netherlands, September 1985.

[88] Dana Scott. Outline of a mathematical theory of computation. In Fourth Princeton

Conference on Information Sciences and Systems, pages 169-176, 1970.

[89] Dana Scott. Lattice theoretic models for various type-free calculi. In Fourth International

Congress of Logic, Methodology and Philosophy of Science. North-Holland, 1972.

[90] Dana Scott and Christopher Strachey. Toward a mathematical semantics for computer

languages. In Proceedings of the Symposium on Computers and Automata, volume 21 of
Microwave Research Institute Symposia Series. Polytechnic Institute of Brooklyn, 1971.

[91] Scott F. Smith. Hybrid partial-total type theory. International Journal of Foundations of

Computer Science, 6:235-263, 1995.

103

[92] Scott Fraser Smith. Partial Objects in Type Theory. Ph.D. dissertation, Department of

Computer Science, Cornell University, Ithaca, New York, January 1989.

[93] D. Tarditi, G. Morrisett, P. Cheng, C. Stone, R. Harper, and P. Lee. TIL: A typedirected optimizing compiler for ML. In 1996 ACM SIGPLAN Conference on Programming
Language Design and Implementation, pages 181-192, May 1996.

[94] Philip Wadler. Comprehending monads. In Mathematical Structures in Computer Science,

volume 2, pages 461-493. Cambridge University Press, 1992.

[95] Philip Wadler. The essence of functional programming. In Nineteenth ACM SIGACTSIGPLAN Symposium on Principles of Programming Languages, Albuquerque, New Mexico, January 1992.

[96] Alfred North Whitehead and Bertrand Russell. Principia Mathematica. Cambridge University Press, 2nd edition, 1910.

104