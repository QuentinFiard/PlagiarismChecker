

Certio/ed Programming with Dependent Types

Adam Chlipala
December 30, 2009
Copyright Adam Chlipala 2008-2009.
This work is licensed under a Creative Commons Attribution-Noncommercial-No

Derivative Works 3.0 Unported License. The license text is available at:

http://creativecommons.org/licenses/by-nc-nd/3.0/

Contents
1 Introduction 3

1.1 Whence This Book? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.2 Why Coq? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

1.2.1 Based on a Higher-Order Functional Programming Language . . . . . 4
1.2.2 Dependent Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.2.3 An Easy-to-Check Kernel Proof Language . . . . . . . . . . . . . . . 5
1.2.4 Convenient Programmable Proof Automation . . . . . . . . . . . . . 5
1.2.5 Proof by ReAEection . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.3 Why Not a Dioeerent Dependently-Typed Language? . . . . . . . . . . . . . 6
1.4 Engineering with a Proof Assistant . . . . . . . . . . . . . . . . . . . . . . . 7
1.5 Prerequisites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
1.6 Using This Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
1.7 Chapter Source Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9

2 Some Quick Examples 10

2.1 Arithmetic Expressions Over Natural Numbers . . . . . . . . . . . . . . . . . 11

2.1.1 Source Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.1.2 Target Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2.1.3 Translation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
2.1.4 Translation Correctness . . . . . . . . . . . . . . . . . . . . . . . . . 15
2.2 Typed Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

2.2.1 Source Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2.2.2 Target Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2.2.3 Translation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.2.4 Translation Correctness . . . . . . . . . . . . . . . . . . . . . . . . . 30

I Basic Programming and Proving 32
3 Introducing Inductive Types 33

3.1 Enumerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
3.2 Simple Recursive Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
3.3 Parameterized Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

2

3.4 Mutually Inductive Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
3.5 ReAEexive Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
3.6 An Interlude on Proof Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
3.7 Nested Inductive Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
3.8 Manual Proofs About Constructors . . . . . . . . . . . . . . . . . . . . . . . 55
3.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

4 Inductive Predicates 58

4.1 Propositional Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
4.2 What Does It Mean to Be Constructive? . . . . . . . . . . . . . . . . . . . . 64
4.3 First-Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
4.4 Predicates with Implicit Equality . . . . . . . . . . . . . . . . . . . . . . . . 66
4.5 Recursive Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
4.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

5 Ino/nite Data and Proofs 78

5.1 Computing with Ino/nite Data . . . . . . . . . . . . . . . . . . . . . . . . . . 79
5.2 Ino/nite Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
5.3 Simple Modeling of Non-Terminating Programs . . . . . . . . . . . . . . . . 86
5.4 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88

II Programming with Dependent Types 89
6 Subset Types and Variations 90

6.1 Introducing Subset Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
6.2 Decidable Proposition Types . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
6.3 Partial Subset Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
6.4 Monadic Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
6.5 A Type-Checking Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
6.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104

7 More Dependent Types 106

7.1 Length-Indexed Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
7.2 A Tagless Interpreter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
7.3 Dependently-Typed Red-Black Trees . . . . . . . . . . . . . . . . . . . . . . 115
7.4 A Certio/ed Regular Expression Matcher . . . . . . . . . . . . . . . . . . . . 124
7.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129

8 Dependent Data Structures 131

8.1 More Length-Indexed Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
8.2 Heterogeneous Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134

8.2.1 A Lambda Calculus Interpreter . . . . . . . . . . . . . . . . . . . . . 136
8.3 Recursive Type Deo/nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138

3

8.4 Data Structures as Index Functions . . . . . . . . . . . . . . . . . . . . . . . 141

8.4.1 Another Interpreter Example . . . . . . . . . . . . . . . . . . . . . . 144
8.5 Choosing Between Representations . . . . . . . . . . . . . . . . . . . . . . . 149
8.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149

9 Reasoning About Equality Proofs 151

9.1 The Deo/nitional Equality . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
9.2 Heterogeneous Lists Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . 153
9.3 Type-Casts in Theorem Statements . . . . . . . . . . . . . . . . . . . . . . . 158
9.4 Heterogeneous Equality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
9.5 Equivalence of Equality Axioms . . . . . . . . . . . . . . . . . . . . . . . . . 165
9.6 Equality of Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
9.7 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168

10 Generic Programming 171

10.1 ReAEecting Datatype Deo/nitions . . . . . . . . . . . . . . . . . . . . . . . . . 171
10.2 Recursive Deo/nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173

10.2.1 Pretty-Printing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
10.2.2 Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
10.3 Proving Theorems about Recursive Deo/nitions . . . . . . . . . . . . . . . . . 180

11 Universes and Axioms 187

11.1 The Type Hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187

11.1.1 Inductive Deo/nitions . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
11.2 The Prop Universe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
11.3 Axioms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197

11.3.1 The Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
11.3.2 Axioms of Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
11.3.3 Axioms and Computation . . . . . . . . . . . . . . . . . . . . . . . . 204

III Proof Engineering 206
12 Proof Search in Ltac 207

12.1 Some Built-In Automation Tactics . . . . . . . . . . . . . . . . . . . . . . . 207
12.2 Hint Databases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
12.3 Ltac Programming Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
12.4 Functional Programming in Ltac . . . . . . . . . . . . . . . . . . . . . . . . 218
12.5 Recursive Proof Search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
12.6 Creating Unio/cation Variables . . . . . . . . . . . . . . . . . . . . . . . . . . 226

4

13 Proof by ReAEection 233

13.1 Proving Evenness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
13.2 ReAEecting the Syntax of a Trivial Tautology Language . . . . . . . . . . . . 236
13.3 A Monoid Expression Simplio/er . . . . . . . . . . . . . . . . . . . . . . . . . 238
13.4 A Smarter Tautology Solver . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
13.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246

14 Proving in the Large 249

14.1 Ltac Anti-Patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
14.2 Debugging and Maintaining Automation . . . . . . . . . . . . . . . . . . . . 255
14.3 Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
14.4 Build Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266

IV Formalizing Programming Languages and Compilers 269
15 First-Order Abstract Syntax 270

15.1 Concrete Binding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
15.2 De Bruijn Indices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
15.3 Locally Nameless Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282

16 Dependent De Bruijn Indices 294

16.1 Deo/ning Syntax and Its Associated Operations . . . . . . . . . . . . . . . . . 294
16.2 Custom Tactics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
16.3 Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300

17 Higher-Order Abstract Syntax 305

17.1 Classic HOAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
17.2 Parametric HOAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
17.3 A Type Soundness Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
17.4 Big-Step Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317

18 Type-Theoretic Interpreters 322

18.1 Simply-Typed Lambda Calculus . . . . . . . . . . . . . . . . . . . . . . . . . 322
18.2 Adding Products and Sums . . . . . . . . . . . . . . . . . . . . . . . . . . . 326

19 Extensional Transformations 332

19.1 CPS Conversion for Simply-Typed Lambda Calculus . . . . . . . . . . . . . 332
19.2 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341

20 Intensional Transformations 342

20.1 From De Bruijn to PHOAS . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
20.2 From PHOAS to De Bruijn . . . . . . . . . . . . . . . . . . . . . . . . . . . 345

20.2.1 Connecting Notions of Well-Formedness . . . . . . . . . . . . . . . . 345

5

20.2.2 The Translation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
21 Higher-Order Operational Semantics 350

21.1 Closure Heaps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351
21.2 Languages and Translation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353
21.3 Correctness Proof . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357

6
Chapter 1
Introduction

1.1 Whence This Book?
We would all like to have programs check that our programs are correct. Due in no small
part to some bold but unfulo/lled promises in the history of computer science, today most
people who write software, practitioners and academics alike, assume that the costs of formal
program verio/cation outweigh the beneo/ts. The purpose of this book is to convince you that
the technology of program verio/cation is mature enough today that it makes sense to use
it in a support role in many kinds of research projects in computer science. Beyond the
convincing, I also want to provide a handbook on practical engineering of certio/ed programs
with the Coq proof assistant.

There are a good number of (though deo/nitely not "many") tools that are in wide use
today for building machine-checked mathematical proofs and machine-certio/ed programs.
This is my attempt at an exhaustive list of interactive "proof assistants" satisfying a few
criteria. First, the authors of each tool must intend for it to be put to use for software-
related applications. Second, there must have been enough engineering eoeort put into the
tool that someone not doing research on the tool itself would feel his time was well spent
using it. A third criterion is more of an empirical validation of the second: the tool must
have a signio/cant user community outside of its own development team.

ACL2 http://www.cs.utexas.edu/users/moore/acl2/

Coq http://coq.inria.fr/
Isabelle/HOL http://isabelle.in.tum.de/

PVS http://pvs.csl.sri.com/
Twelf http://www.twelf.org/

Isabelle/HOL, implemented with the "proof assistant development framework" Isabelle,
is the most popular proof assistant for the HOL logic. The other implementations of HOL
can be considered equivalent for purposes of the discussion here.

7

1.2 Why Coq?
This book is going to be about certio/ed programming using Coq, and I am convinced that
it is the best tool for the job. Coq has a number of very attractive properties, which I will
summarize here, mentioning which of the other candidate tools lack each property.

1.2.1 Based on a Higher-Order Functional Programming Language
There is no reason to give up the familiar comforts of functional programming when you start
writing certio/ed programs. All of the tools I listed are based on functional programming
languages, which means you can use them without their proof-related aspects to write and
run regular programs.

ACL2 is notable in this o/eld for having only a o/rst-order language at its foundation. That
is, you cannot work with functions over functions and all those other treats of functional
programming. By giving up this facility, ACL2 can make broader assumptions about how
well its proof automation will work, but we can generally recover the same advantages in
other proof assistants when we happen to be programming in o/rst-order fragments.

1.2.2 Dependent Types
A language of dependent types may include references to programs inside of types. For
instance, the type of an array might include a program expression giving the size of the
array, making it possible to verify absence of out-of-bounds accesses statically. Dependent
types can go even further than this, eoeectively capturing any correctness property in a type.
For instance, later in this book, we will see how to give a Mini-ML compiler a type that
guarantees that it maps well-typed source programs to well-typed target programs.

ACL2 and HOL lack dependent types outright. PVS and Twelf each supports a dioeerent
strict subset of Coq's dependent type language. Twelf's type language is restricted to a bare-
bones, monomorphic lambda calculus, which places serious restrictions on how complicated
computations inside types can be. This restriction is important for the soundness argument
behind Twelf's approach to representing and checking proofs.

In contrast, PVS's dependent types are much more general, but they are squeezed inside
the single mechanism of subset types, where a normal type is reo/ned by attaching a predicate
over its elements. Each member of the subset type is an element of the base type that
satiso/es the predicate.

Dependent types are not just useful because they help you express correctness properties
in types. Dependent types also often let you write certio/ed programs without writing anything
that looks like a proof. Even with subset types, which for many contexts can be used to
express any relevant property with enough acrobatics, the human driving the proof assistant
usually has to build some proofs explicitly. Writing formal proofs is hard, so we want to
avoid it as far as possible, so dependent types are invaluable.

8

1.2.3 An Easy-to-Check Kernel Proof Language
Scores of automated decision procedures are useful in practical theorem proving, but it is
unfortunate to have to trust in the correct implementation of each procedure. Proof assistants
satisfying the "de Bruijn criterion" may use complicated and extensible procedures to seek
out proofs, but in the end they produce proof terms in kernel languages. These core languages
have feature complexity on par with what you o/nd in proposals for formal foundations for
mathematics. To believe a proof, we can ignore the possibility of bugs during search and just
rely on a (relatively small) proof-checking kernel that we apply to the result of the search.

ACL2 and PVS do not meet the de Bruijn criterion, employing fancy decision procedures
that produce no "evidence trails" justifying their results.

1.2.4 Convenient Programmable Proof Automation
A commitment to a kernel proof language opens up wide possibilities for user extension of
proof automation systems, without allowing user mistakes to trick the overall system into
accepting invalid proofs. Almost any interesting verio/cation problem is undecidable, so it is
important to help users build their own procedures for solving the restricted problems that
they encounter in particular implementations.

Twelf features no proof automation marked as a bonao/de part of the latest release; there is
some automation code included for testing purposes. The Twelf style is based on writing out
all proofs in full detail. Because Twelf is specialized to the domain of syntactic metatheory
proofs about programming languages and logics, it is feasible to use it to write those kinds
of proofs manually. Outside that domain, the lack of automation can be a serious obstacle
to productivity. Most kinds of program verio/cation fall outside Twelf's forte.

Of the remaining tools, all can support user extension with new decision procedures by
hacking directly in the tool's implementation language (such as OCaml for Coq). Since
ACL2 and PVS do not satisfy the de Bruijn criterion, overall correctness is at the mercy of
the authors of new procedures.

Isabelle/HOL and Coq both support coding new proof manipulations in ML in ways that
cannot lead to the acceptance of invalid proofs. Additionally, Coq includes a domain-specio/c
language for coding decision procedures in normal Coq source code, with no need to break
out into ML. This language is called Ltac, and I think of it as the unsung hero of the proof
assistant world. Not only does Ltac prevent you from making fatal mistakes, it also includes
a number of novel programming constructs which combine to make a "proof by decision
procedure" style very pleasant. We will meet these features in the chapters to come.

1.2.5 Proof by ReAEection
A surprising wealth of beneo/ts follow from choosing a proof language that integrates a rich
notion of computation. Coq includes programs and proof terms in the same syntactic class.
This makes it easy to write programs that compute proofs. With rich enough dependent

9

types, such programs are certio/ed decision procedures. In such cases, these certio/ed proce-
dures can be put to good use without ever running them! Their types guarantee that, if we
did bother to run them, we would receive proper "ground" proofs.

The critical ingredient for this technique, many of whose instances are referred to as
proof by reAEection, is a way of inducing non-trivial computation inside of logical propositions
during proof checking. Further, most of these instances require dependent types to make it
possible to state the appropriate theorems. Of the proof assistants I listed, only Coq really
provides this support.

1.3 Why Not a Dioeerent Dependently-Typed Language?
The logic and programming language behind Coq belongs to a type-theory ecosystem with
a good number of other thriving members. Agda1 and Epigram2 are the most developed
tools among the alternatives to Coq, and there are others that are earlier in their lifecycles.
All of the languages in this family feel sort of like dioeerent historical ooeshoots of Latin.
The hardest conceptual epiphanies are, for the most part, portable among all the languages.
Given this, why choose Coq for certio/ed programming?

I think the answer is simple. None of the competition has well-developed systems for
tactic-based theorem proving. Agda and Epigram are designed and marketed more as pro-
gramming languages than proof assistants. Dependent types are great, because they often
help you prove deep theorems without doing anything that feels like proving. Nonethe-
less, almost any interesting certio/ed programming project will beneo/t from some activity
that deserves to be called proving, and many interesting projects absolutely require semi-
automated proving, if the sanity of the programmer is to be safeguarded. Informally, proving
is unavoidable when any correctness proof for a program has a structure that does not mirror
the structure of the program itself. An example is a compiler correctness proof, which prob-
ably proceeds by induction on program execution traces, which have no simple relationship
with the structure of the compiler or the structure of the programs it compiles. In building
such proofs, a mature system for scripted proof automation is invaluable.

On the other hand, Agda, Epigram, and similar tools have less implementation baggage
associated with them, and so they tend to be the default o/rst homes of innovations in practical
type theory. Some signio/cant kinds of dependently-typed programs are much easier to write
in Agda and Epigram than in Coq. The former tools may very well be superior choices for
projects that do not involve any "proving." Anecdotally, I have gotten the impression that
manual proving is orders of magnitudes more costly than manual coping with Coq's lack
of programming bells and whistles. In this book, I will devote signio/cant time to patterns
for programming with dependent types in Coq as it is today. We can hope that the type
theory community is tending towards convergence on the right set of features for practical
programming with dependent types, and that we will eventually have a single tool embodying

1http://appserv.cs.chalmers.se/users/ulfn/wiki/agda.php
2http://www.e-pig.org/

10

those features.
1.4 Engineering with a Proof Assistant
In comparisons with its competitors, Coq is often derided for promoting unreadable proofs.
It is very easy to write proof scripts that manipulate proof goals imperatively, with no
structure to aid readers. Such developments are nightmares to maintain, and they certainly
do not manage to convey "why the theorem is true" to anyone but the original author.
One additional (and not insignio/cant) purpose of this book is to show why it is unfair and
unproductive to dismiss Coq based on the existence of such developments.

I will go out on a limb and guess that the reader is a dedicated fan of some functional
programming language or another, and that he may even have been involved in teaching
that language to undergraduates. I want to propose an analogy between two attitudes:
coming to a negative conclusion about Coq after reading common Coq developments in the
wild, and coming to a negative conclusion about Your Favorite Language after looking at the
programs undergraduates write in it in the o/rst week of class. The pragmatics of mechanized
proving and program verio/cation have been under serious study for much less time than the
pragmatics of programming have been. The computer theorem proving community is still
developing the key insights that correspond to those that functional programming texts and
instructors impart to their students, to help those students get over that critical hump where
using the language stops being more trouble than it is worth. Most of the insights for Coq
are barely even disseminated among the experts, let alone set down in a tutorial form. I
hope to use this book to go a long way towards remedying that.

If I do that job well, then this book should be of interest even to people who have
participated in classes or tutorials specio/cally about Coq. The book should even be useful to
people who have been using Coq for years but who are mystio/ed when their Coq developments
prove impenetrable by colleagues. The crucial angle in this book is that there are "design
patterns" for reliably avoiding the really grungy parts of theorem proving, and consistent
use of these patterns can get you over the hump to the point where it is worth your while to
use Coq to prove your theorems and certify your programs, even if formal verio/cation is not
your main concern in a project. We will follow this theme by pursuing two main methods for
replacing manual proofs with more understandable artifacts: dependently-typed functions
and custom Ltac decision procedures.

1.5 Prerequisites
I try to keep the required background knowledge to a minimum in this book. I will assume
familiarity with the material from usual discrete math and logic courses taken by all under-
graduate computer science majors, and I will assume that readers have signio/cant experience
programming in one of the ML dialects, in Haskell, or in some other, closely-related language.

11

Experience with only dynamically-typed functional languages might lead to befuddlement
in some places, but a reader who has come to grok Scheme deeply will probably be o/ne.

A good portion of the book is about how to formalize programming languages, compil-
ers, and proofs about them. To understand those parts, it will be helpful to have a basic
knowledge of formal type systems, operational semantics, and the theorems usually proved
about such systems. As a reference on these topics, I recommend Types and Programming
Languages, by Benjamin C. Pierce.

1.6 Using This Book
This book is generated automatically from Coq source o/les using the wonderful coqdoc
program. The latest PDF version is available at:

http://adam.chlipala.net/cpdt/cpdt.pdf
There is also an online HTML version available, with a hyperlink from each use of an identio/er
to that identio/er's deo/nition:

http://adam.chlipala.net/cpdt/html/toc.html
The source code to the book is also freely available at:

http://adam.chlipala.net/cpdt/cpdt.tgz
There, you can o/nd all of the code appearing in this book, with prose interspersed in
comments, in exactly the order that you o/nd in this document. You can step through
the code interactively with your chosen graphical Coq interface. The code also has special
comments indicating which parts of the chapters make suitable starting points for interactive
class sessions, where the class works together to construct the programs and proofs. The
included Makeo/le has a target templates for building a fresh set of class template o/les
automatically from the book source.

I believe that a good graphical interface to Coq is crucial for using it productively. I
use the Proof General3 mode for Emacs, which supports a number of other proof assistants
besides Coq. There is also the standalone CoqIDE program developed by the Coq team.
I like being able to combine certio/ed programming and proving with other kinds of work
inside the same full-featured editor, and CoqIDE has had a good number of crashes and
other annoying bugs in recent history, though I hear that it is improving. In the initial part
of this book, I will reference Proof General procedures explicitly, in introducing how to use
Coq, but most of the book will be interface-agnostic, so feel free to use CoqIDE if you prefer
it.

3http://proofgeneral.inf.ed.ac.uk/

12

1.7 Chapter Source Files

Chapter Source
Some Quick Examples StackMachine.v
Introducing Inductive Types InductiveTypes.v

Inductive Predicates Predicates.v
Ino/nite Data and Proofs Coinductive.v
Subset Types and Variations Subset.v

More Dependent Types MoreDep.v
Dependent Data Structures DataStruct.v
Reasoning About Equality Proofs Equality.v

Generic Programming Generic.v
Universes and Axioms Universes.v

Proof Search in Ltac Match.v

Proof by ReAEection Reflection.v
Proving in the Large Large.v
First-Order Abstract Syntax Firstorder.v
Dependent De Bruijn Indices DeBruijn.v
Higher-Order Abstract Syntax Hoas.v

Type-Theoretic Interpreters Interps.v
Extensional Transformations Extensional.v

Intensional Transformations Intensional.v
Higher-Order Operational Semantics OpSem.v

13

Chapter 2
Some Quick Examples

I will start ooe by jumping right in to a fully-worked set of examples, building certio/ed
compilers from increasingly complicated source languages to stack machines. We will meet
a few useful tactics and see how they can be used in manual proofs, and we will also see
how easily these proofs can be automated instead. I assume that you have installed Coq and
Proof General. The code in this book is tested with Coq version 8.2pl1, though parts may
work with other versions.

As always, you can step through the source o/le StackMachine.v for this chapter interac-
tively in Proof General. Alternatively, to get a feel for the whole lifecycle of creating a Coq
development, you can enter the pieces of source code in this chapter in a new .v o/le in an
Emacs buoeer. If you do the latter, include a line Require Import List Tactics. at the start
of the o/le, to match some code hidden in this rendering of the chapter source, and be sure
to run the Coq binary coqtop with the command-line argument -I SRC, where SRC is the
path to a directory containing the source for this book. In either case, you will need to run
make in the root directory of the source distribution for the book before getting started. If
you have installed Proof General properly, it should start automatically when you visit a .v
buoeer in Emacs.

There are some minor headaches associated with getting Proof General to pass the proper
command line arguments to the coqtop program. The best way to add settings that will be
shared by many source o/les is to add a custom variable setting to your .emacs o/le, like this:

(custom-set-variables

...
'(coq-prog-args '("-I" "/path/to/cpdt/src"))
...
)

The extra arguments demonstrated here are the proper choices for working with the code
for this book. The ellipses stand for other Emacs customization settings you may already
have. It can be helpful to save several alternate sets of AEags in your .emacs o/le, with all but
one commented out within the custom-set-variables block at any given time.

14

With Proof General, the portion of a buoeer that Coq has processed is highlighted in some
way, like being given a blue background. You step through Coq source o/les by positioning
the point at the position you want Coq to run to and pressing C-C C-RET. This can be used
both for normal step-by-step coding, by placing the point inside some command past the
end of the highlighted region; and for undoing, by placing the point inside the highlighted
region.

2.1 Arithmetic Expressions Over Natural Numbers
We will begin with that staple of compiler textbooks, arithmetic expressions over a single
type of numbers.

2.1.1 Source Language
We begin with the syntax of the source language.
Inductive binop : Set := Plus | Times.

Our o/rst line of Coq code should be unsurprising to ML and Haskell programmers. We
deo/ne an algebraic datatype binop to stand for the binary operators of our source lan-
guage. There are just two wrinkles compared to ML and Haskell. First, we use the keyword
Inductive, in place of data, datatype, or type. This is not just a trivial surface syntax
dioeerence; inductive types in Coq are much more expressive than garden variety algebraic
datatypes, essentially enabling us to encode all of mathematics, though we begin humbly
in this chapter. Second, there is the : Set fragment, which declares that we are deo/ning a
datatype that should be thought of as a constituent of programs. Later, we will see other
options for deo/ning datatypes in the universe of proofs or in an ino/nite hierarchy of universes,
encompassing both programs and proofs, that is useful in higher-order constructions.

Inductive exp : Set :=|

Const : nat ! exp|
Binop : binop ! exp ! exp ! exp.

Now we deo/ne the type of arithmetic expressions. We write that a constant may be built
from one argument, a natural number; and a binary operation may be built from a choice of
operator and two operand expressions.

A note for readers following along in the PDF version: coqdoc supports pretty-printing
of tokens in LaTeX or HTML. Where you see a right arrow character, the source contains the
ASCII text -?. Other examples of this substitution appearing in this chapter are a double
right arrow for =? and the inverted 'A' symbol for forall. When in doubt about the ASCII
version of a symbol, you can consult the chapter source code.

Now we are ready to say what these programs mean. We will do this by writing an
interpreter that can be thought of as a trivial operational or denotational semantics. (If you

15

are not familiar with these semantic techniques, no need to worry; we will stick to "common
sense" constructions.)

Definition binopDenote (b : binop) : nat ! nat ! nat :=

match b with|

Plus ) plus|
Times ) mult
end.

The meaning of a binary operator is a binary function over naturals, deo/ned with pattern-
matching notation analogous to the case and match of ML and Haskell, and referring to the
functions plus and mult from the Coq standard library. The keyword Definition is Coq's
all-purpose notation for binding a term of the programming language to a name, with some
associated syntactic sugar, like the notation we see here for deo/ning a function. That sugar
could be expanded to yield this deo/nition:

Definition binopDenote : binop ! nat ! nat ! nat := fun (b : binop) )

match b with|

Plus ) plus|
Times ) mult
end.

In this example, we could also omit all of the type annotations, arriving at:
Definition binopDenote := fun b )

match b with|

Plus ) plus|
Times ) mult
end.

Languages like Haskell and ML have a convenient principal typing property, which gives
us strong guarantees about how eoeective type inference will be. Unfortunately, Coq's type
system is so expressive that any kind of "complete" type inference is impossible, and the
task even seems to be hard heuristically in practice. Nonetheless, Coq includes some very
helpful heuristics, many of them copying the workings of Haskell and ML type-checkers for
programs that fall in simple fragments of Coq's language.

This is as good a time as any to mention the preponderance of dioeerent languages associ-
ated with Coq. The theoretical foundation of Coq is a formal system called the Calculus of
Inductive Constructions (CIC), which is an extension of the older Calculus of Constructions
(CoC). CIC is quite a spartan foundation, which is helpful for proving metatheory but not so
helpful for real development. Still, it is nice to know that it has been proved that CIC enjoys
properties like strong normalization, meaning that every program (and, more importantly,
every proof term) terminates; and relative consistency with systems like versions of Zermelo
Fraenkel set theory, which roughly means that you can believe that Coq proofs mean that

16

the corresponding propositions are "really true," if you believe in set theory.

Coq is actually based on an extension of CIC called Gallina. The text after the := and
before the period in the last code example is a term of Gallina. Gallina adds many useful
features that are not compiled internally to more primitive CIC features. The important
metatheorems about CIC have not been extended to the full breadth of these features, but
most Coq users do not seem to lose much sleep over this omission.

Commands like Inductive and Definition are part of the vernacular, which includes
all sorts of useful queries and requests to the Coq system.

Finally, there is Ltac, Coq's domain-specio/c language for writing proofs and decision
procedures. We will see some basic examples of Ltac later in this chapter, and much of this
book is devoted to more involved Ltac examples.

We can give a simple deo/nition of the meaning of an expression:
Fixpoint expDenote (e : exp) : nat :=

match e with|

Const n ) n|
Binop b e1 e2 ) (binopDenote b) (expDenote e1 ) (expDenote e2 )
end.

We declare explicitly that this is a recursive deo/nition, using the keyword Fixpoint. The
rest should be old hat for functional programmers.

It is convenient to be able to test deo/nitions before starting to prove things about them.
We can verify that our semantics is sensible by evaluating some sample uses.

Eval simpl in expDenote (Const 42).

= 42 : nat

Eval simpl in expDenote (Binop Plus (Const 2) (Const 2)).

= 4 : nat

Eval simpl in expDenote (Binop Times (Binop Plus (Const 2) (Const 2)) (Const 7)).

= 28 : nat

2.1.2 Target Language
We will compile our source programs onto a simple stack machine, whose syntax is:
Inductive instr : Set :=|

IConst : nat ! instr|
IBinop : binop ! instr.

Definition prog := list instr.
Definition stack := list nat.

An instruction either pushes a constant onto the stack or pops two arguments, applies
a binary operator to them, and pushes the result onto the stack. A program is a list of
instructions, and a stack is a list of natural numbers.

17

We can give instructions meanings as functions from stacks to optional stacks, where
running an instruction results in None in case of a stack underAEow and results in Some s'
when the result of execution is the new stack s'. :: is the "list cons" operator from the Coq
standard library.

Definition instrDenote (i : instr) (s : stack) : option stack :=

match i with|

IConst n ) Some (n :: s)|
IBinop b )

match s with|

arg1 :: arg2 :: s' ) Some ((binopDenote b) arg1 arg2 :: s' )| )

None
end
end.

With instrDenote deo/ned, it is easy to deo/ne a function progDenote, which iterates appli-
cation of instrDenote through a whole program.

Fixpoint progDenote (p : prog) (s : stack) -struct p"" : option stack :=

match p with|

nil ) Some s|
i :: p' )

match instrDenote i s with|

None ) None|
Some s' ) progDenote p' s'
end
end.

There is one interesting dioeerence compared to our previous example of a Fixpoint.
This recursive function takes two arguments, p and s. It is critical for the soundness of
Coq that every program terminate, so a shallow syntactic termination check is imposed on
every recursive function deo/nition. One of the function parameters must be designated to
decrease monotonically across recursive calls. That is, every recursive call must use a version
of that argument that has been pulled out of the current argument by some number of match
expressions. expDenote has only one argument, so we did not need to specify which of its
arguments decreases. For progDenote, we resolve the ambiguity by writing -struct p"" to
indicate that argument p decreases structurally.

Recent versions of Coq will also infer a termination argument, so that we may write
simply:

Fixpoint progDenote (p : prog) (s : stack) : option stack :=

match p with|

nil ) Some s|
i :: p' )

match instrDenote i s with

18

| None ) None|

Some s' ) progDenote p' s'
end
end.

2.1.3 Translation
Our compiler itself is now unsurprising. ++ is the list concatenation operator from the Coq
standard library.

Fixpoint compile (e : exp) : prog :=

match e with|

Const n ) IConst n :: nil|
Binop b e1 e2 ) compile e2 ++ compile e1 ++ IBinop b :: nil
end.

Before we set about proving that this compiler is correct, we can try a few test runs,
using our sample programs from earlier.

Eval simpl in compile (Const 42).

= IConst 42 :: nil : prog

Eval simpl in compile (Binop Plus (Const 2) (Const 2)).

= IConst 2 :: IConst 2 :: IBinop Plus :: nil : prog

Eval simpl in compile (Binop Times (Binop Plus (Const 2) (Const 2)) (Const 7)).

= IConst 7 :: IConst 2 :: IConst 2 :: IBinop Plus :: IBinop Times :: nil : prog

We can also run our compiled programs and check that they give the right results.
Eval simpl in progDenote (compile (Const 42)) nil.

= Some (42 :: nil) : option stack

Eval simpl in progDenote (compile (Binop Plus (Const 2) (Const 2))) nil.

= Some (4 :: nil) : option stack

Eval simpl in progDenote (compile (Binop Times (Binop Plus (Const 2) (Const 2)) (Const
7))) nil.

= Some (28 :: nil) : option stack

2.1.4 Translation Correctness
We are ready to prove that our compiler is implemented correctly. We can use a new
vernacular command Theorem to start a correctness proof, in terms of the semantics we
deo/ned earlier:

Theorem compile correct : 8 e, progDenote (compile e) nil = Some (expDenote e :: nil).

Though a pencil-and-paper proof might clock out at this point, writing "by a routine
induction on e," it turns out not to make sense to attack this proof directly. We need to

19

use the standard trick of strengthening the induction hypothesis. We do that by proving an
auxiliary lemma:

Lemma compile correct' : 8 e p s,

progDenote (compile e ++ p) s = progDenote p (expDenote e :: s).

After the period in the Lemma command, we are in the interactive proof-editing mode. We
o/nd ourselves staring at this ominous screen of text:

1 subgoal

============================8

(e : exp) (p : list instr) (s : stack),
progDenote (compile e ++ p) s = progDenote p (expDenote e :: s)

Coq seems to be restating the lemma for us. What we are seeing is a limited case of
a more general protocol for describing where we are in a proof. We are told that we have
a single subgoal. In general, during a proof, we can have many pending subgoals, each of
which is a logical proposition to prove. Subgoals can be proved in any order, but it usually
works best to prove them in the order that Coq chooses.

Next in the output, we see our single subgoal described in full detail. There is a double-
dashed line, above which would be our free variables and hypotheses, if we had any. Below
the line is the conclusion, which, in general, is to be proved from the hypotheses.

We manipulate the proof state by running commands called tactics. Let us start out by
running one of the most important tactics:

induction e.

We declare that this proof will proceed by induction on the structure of the expression e.
This swaps out our initial subgoal for two new subgoals, one for each case of the inductive
proof:

2 subgoals

n : nat
============================8

(s : stack) (p : list instr),

progDenote (compile (Const n) ++ p) s =
progDenote p (expDenote (Const n) :: s)

subgoal 2 is:8

(s : stack) (p : list instr),

progDenote (compile (Binop b e1 e2 ) ++ p) s =
progDenote p (expDenote (Binop b e1 e2 ) :: s)

20

The o/rst and current subgoal is displayed with the double-dashed line below free variables
and hypotheses, while later subgoals are only summarized with their conclusions. We see
an example of a free variable in the o/rst subgoal; n is a free variable of type nat. The
conclusion is the original theorem statement where e has been replaced by Const n. In a
similar manner, the second case has e replaced by a generalized invocation of the Binop
expression constructor. We can see that proving both cases corresponds to a standard proof
by structural induction.

We begin the o/rst case with another very common tactic.

intros.

The current subgoal changes to:

n : nat
s : stack
p : list instr
============================
progDenote (compile (Const n) ++ p) s =
progDenote p (expDenote (Const n) :: s)

We see that intros changes 8-bound variables at the beginning of a goal into free vari-
ables.

To progress further, we need to use the deo/nitions of some of the functions appearing in
the goal. The unfold tactic replaces an identio/er with its deo/nition.

unfold compile.

n : nat
s : stack
p : list instr
============================
progDenote ((IConst n :: nil) ++ p) s =
progDenote p (expDenote (Const n) :: s)

unfold expDenote.
n : nat
s : stack
p : list instr
============================
progDenote ((IConst n :: nil) ++ p) s = progDenote p (n :: s)

We only need to unfold the o/rst occurrence of progDenote to prove the goal:
unfold progDenote at 1.

21

n : nat
s : stack
p : list instr
============================

(o/x progDenote (p0 : prog) (s0 : stack) -struct p0 "" :

option stack :=

match p0 with|

nil ) Some s0|
i :: p' )

match instrDenote i s0 with|

Some s' ) progDenote p' s'|
None ) None (A:=stack)
end
end) ((IConst n :: nil) ++ p) s =
progDenote p (n :: s)

This last unfold has left us with an anonymous o/xpoint version of progDenote, which
will generally happen when unfolding recursive deo/nitions. Fortunately, in this case, we can
eliminate such complications right away, since the structure of the argument (IConst n :: nil)
++ p is known, allowing us to simplify the internal pattern match with the simpl tactic:

simpl.

n : nat
s : stack
p : list instr
============================
(o/x progDenote (p0 : prog) (s0 : stack) -struct p0 "" :

option stack :=

match p0 with|

nil ) Some s0|
i :: p' )

match instrDenote i s0 with|

Some s' ) progDenote p' s'|
None ) None (A:=stack)
end
end) p (n :: s) = progDenote p (n :: s)

Now we can unexpand the deo/nition of progDenote:
fold progDenote.

22

n : nat
s : stack
p : list instr
============================
progDenote p (n :: s) = progDenote p (n :: s)

It looks like we are at the end of this case, since we have a trivial equality. Indeed, a
single tactic o/nishes us ooe:

reflexivity.

On to the second inductive case:

b : binop
e1 : exp
IHe1 : 8 (s : stack) (p : list instr),

progDenote (compile e1 ++ p) s = progDenote p (expDenote e1 :: s)
e2 : exp
IHe2 : 8 (s : stack) (p : list instr),

progDenote (compile e2 ++ p) s = progDenote p (expDenote e2 :: s)
============================8

(s : stack) (p : list instr),
progDenote (compile (Binop b e1 e2 ) ++ p) s =
progDenote p (expDenote (Binop b e1 e2 ) :: s)

We see our o/rst example of hypotheses above the double-dashed line. They are the
inductive hypotheses IHe1 and IHe2 corresponding to the subterms e1 and e2, respectively.

We start out the same way as before, introducing new free variables and unfolding and
folding the appropriate deo/nitions. The seemingly frivolous unfold/fold pairs are actually
accomplishing useful work, because unfold will sometimes perform easy simplio/cations.

intros.
unfold compile.
fold compile.
unfold expDenote.
fold expDenote.

Now we arrive at a point where the tactics we have seen so far are insuOEcient. No further
deo/nition unfoldings get us anywhere, so we will need to try something dioeerent.

b : binop
e1 : exp
IHe1 : 8 (s : stack) (p : list instr),

progDenote (compile e1 ++ p) s = progDenote p (expDenote e1 :: s)

23

e2 : exp
IHe2 : 8 (s : stack) (p : list instr),

progDenote (compile e2 ++ p) s = progDenote p (expDenote e2 :: s)
s : stack
p : list instr
============================

progDenote ((compile e2 ++ compile e1 ++ IBinop b :: nil) ++ p) s =
progDenote p (binopDenote b (expDenote e1 ) (expDenote e2 ) :: s)

What we need is the associative law of list concatenation, available as a theorem app ass
in the standard library.

Check app ass.

app ass

: 8 (A : Type) (l m n : list A), (l ++ m) ++ n = l ++ m ++ n

We use it to perform a rewrite:
rewrite app ass.

changing the conclusion to:

progDenote (compile e2 ++ (compile e1 ++ IBinop b :: nil) ++ p) s =
progDenote p (binopDenote b (expDenote e1 ) (expDenote e2 ) :: s)

Now we can notice that the lefthand side of the equality matches the lefthand side of the
second inductive hypothesis, so we can rewrite with that hypothesis, too:

rewrite IHe2.

progDenote ((compile e1 ++ IBinop b :: nil) ++ p) (expDenote e2 :: s) =
progDenote p (binopDenote b (expDenote e1 ) (expDenote e2 ) :: s)

The same process lets us apply the remaining hypothesis.
rewrite app ass.
rewrite IHe1.

progDenote ((IBinop b :: nil) ++ p) (expDenote e1 :: expDenote e2 :: s) =
progDenote p (binopDenote b (expDenote e1 ) (expDenote e2 ) :: s)

Now we can apply a similar sequence of tactics to that that ended the proof of the o/rst
case.

unfold progDenote at 1.
simpl.

24

fold progDenote.
reflexivity.

And the proof is completed, as indicated by the message:

Proof completed.

And there lies our o/rst proof. Already, even for simple theorems like this, the o/nal proof
script is unstructured and not very enlightening to readers. If we extend this approach
to more serious theorems, we arrive at the unreadable proof scripts that are the favorite
complaints of opponents of tactic-based proving. Fortunately, Coq has rich support for
scripted automation, and we can take advantage of such a scripted tactic (deo/ned elsewhere)
to make short work of this lemma. We abort the old proof attempt and start again.

Abort.
Lemma compile correct' : 8 e s p, progDenote (compile e ++ p) s =

progDenote p (expDenote e :: s).
induction e; crush.
Qed.

We need only to state the basic inductive proof scheme and call a tactic that automates
the tedious reasoning in between. In contrast to the period tactic terminator from our last
proof, the semicolon tactic separator supports structured, compositional proofs. The tactic
t1; t2 has the eoeect of running t1 and then running t2 on each remaining subgoal. The
semicolon is one of the most fundamental building blocks of eoeective proof automation. The
period terminator is very useful for exploratory proving, where you need to see interme-
diate proof states, but o/nal proofs of any serious complexity should have just one period,
terminating a single compound tactic that probably uses semicolons.

The crush tactic comes from the library associated with this book and is not part of
the Coq standard library. The book's library contains a number of other tactics that are
especially helpful in highly-automated proofs.

The proof of our main theorem is now easy. We prove it with four period-terminated
tactics, though separating them with semicolons would work as well; the version here is
easier to step through.

Theorem compile correct : 8 e, progDenote (compile e) nil = Some (expDenote e :: nil).

intros.

e : exp
============================

progDenote (compile e) nil = Some (expDenote e :: nil)

At this point, we want to massage the lefthand side to match the statement of com-
pile correct'. A theorem from the standard library is useful:

Check app nil end.

25

app nil end

: 8 (A : Type) (l : list A), l = l ++ nil

rewrite (app nil end (compile e)).

This time, we explicitly specify the value of the variable l from the theorem statement,
since multiple expressions of list type appear in the conclusion. rewrite might choose the
wrong place to rewrite if we did not specify which we want.

e : exp
============================

progDenote (compile e ++ nil) nil = Some (expDenote e :: nil)

Now we can apply the lemma.
rewrite compile correct'.

e : exp
============================

progDenote nil (expDenote e :: nil) = Some (expDenote e :: nil)

We are almost done. The lefthand and righthand sides can be seen to match by simple
symbolic evaluation. That means we are in luck, because Coq identio/es any pair of terms as
equal whenever they normalize to the same result by symbolic evaluation. By the deo/nition
of progDenote, that is the case here, but we do not need to worry about such details. A
simple invocation of reflexivity does the normalization and checks that the two results
are syntactically equal.

reflexivity.
Qed.

2.2 Typed Expressions
In this section, we will build on the initial example by adding additional expression forms
that depend on static typing of terms for safety.

2.2.1 Source Language
We deo/ne a trivial language of types to classify our expressions:
Inductive type : Set := Nat | Bool.

Now we deo/ne an expanded set of binary operators.
Inductive tbinop : type ! type ! type ! Set :=

26

| TPlus : tbinop Nat Nat Nat|

TTimes : tbinop Nat Nat Nat|
TEq : 8 t, tbinop t t Bool|
TLt : tbinop Nat Nat Bool.

The deo/nition of tbinop is dioeerent from binop in an important way. Where we declared
that binop has type Set, here we declare that tbinop has type type ! type ! type !
Set. We deo/ne tbinop as an indexed type family. Indexed inductive types are at the heart
of Coq's expressive power; almost everything else of interest is deo/ned in terms of them.

ML and Haskell have indexed algebraic datatypes. For instance, their list types are
indexed by the type of data that the list carries. However, compared to Coq, ML and
Haskell 98 place two important restrictions on datatype deo/nitions.

First, the indices of the range of each data constructor must be type variables bound at
the top level of the datatype deo/nition. There is no way to do what we did here, where we,
for instance, say that TPlus is a constructor building a tbinop whose indices are all o/xed at
Nat. Generalized algebraic datatypes (GADTs) are a popular feature in GHC Haskell and
other languages that removes this o/rst restriction.

The second restriction is not lifted by GADTs. In ML and Haskell, indices of types must
be types and may not be expressions. In Coq, types may be indexed by arbitrary Gallina
terms. Type indices can live in the same universe as programs, and we can compute with
them just like regular programs. Haskell supports a hobbled form of computation in type
indices based on multi-parameter type classes, and recent extensions like type functions bring
Haskell programming even closer to "real" functional programming with types, but, without
dependent typing, there must always be a gap between how one programs with types and
how one programs normally.

We can deo/ne a similar type family for typed expressions.
Inductive texp : type ! Set :=|

TNConst : nat ! texp Nat|
TBConst : bool ! texp Bool|
TBinop : 8 arg1 arg2 res, tbinop arg1 arg2 res ! texp arg1 ! texp arg2 ! texp res.

Thanks to our use of dependent types, every well-typed texp represents a well-typed
source expression, by construction. This turns out to be very convenient for many things we
might want to do with expressions. For instance, it is easy to adapt our interpreter approach
to deo/ning semantics. We start by deo/ning a function mapping the types of our languages
into Coq types:

Definition typeDenote (t : type) : Set :=

match t with|

Nat ) nat|
Bool ) bool
end.

It can take a few moments to come to terms with the fact that Set, the type of types of
programs, is itself a o/rst-class type, and that we can write functions that return Sets. Past

27

that wrinkle, the deo/nition of typeDenote is trivial, relying on the nat and bool types from
the Coq standard library.

We need to deo/ne a few auxiliary functions, implementing our boolean binary operators
that do not appear with the right types in the standard library. They are entirely standard
and ML-like, with the one caveat being that the Coq nat type uses a unary representation,
where O is zero and S n is the successor of n.

Definition eq bool (b1 b2 : bool) : bool :=

match b1, b2 with|

true, true ) true|
false, false ) true|

, ) false
end.

Fixpoint eq nat (n1 n2 : nat) : bool :=

match n1, n2 with|

O, O ) true|
S n1', S n2' ) eq nat n1' n2'|

, ) false
end.

Fixpoint lt (n1 n2 : nat) : bool :=

match n1, n2 with|

O, S ) true|
S n1', S n2' ) lt n1' n2'|

, ) false
end.

Now we can interpret binary operators:
Definition tbinopDenote arg1 arg2 res (b : tbinop arg1 arg2 res)

: typeDenote arg1 ! typeDenote arg2 ! typeDenote res :=
match b in (tbinop arg1 arg2 res)

return (typeDenote arg1 ! typeDenote arg2 ! typeDenote res) with|

TPlus ) plus|
TTimes ) mult|
TEq Nat ) eq nat|
TEq Bool ) eq bool|
TLt ) lt
end.

This function has just a few dioeerences from the denotation functions we saw earlier.
First, tbinop is an indexed type, so its indices become additional arguments to tbinopDenote.
Second, we need to perform a genuine dependent pattern match to come up with a deo/nition
of this function that type-checks. In each branch of the match, we need to use branch-specio/c
information about the indices to tbinop. General type inference that takes such information
into account is undecidable, so it is often necessary to write annotations, like we see above

28

on the line with match.

The in annotation restates the type of the term being case-analyzed. Though we use
the same names for the indices as we use in the type of the original argument binder, these
are actually fresh variables, and they are binding occurrences. Their scope is the return
clause. That is, arg1, arg2, and arg3 are new bound variables bound only within the return
clause typeDenote arg1 ! typeDenote arg2 ! typeDenote res. By being explicit about the
functional relationship between the type indices and the match result, we regain decidable
type inference.

In fact, recent Coq versions use some heuristics that can save us the trouble of writing
match annotations, and those heuristics get the job done in this case. We can get away with
writing just:

Definition tbinopDenote arg1 arg2 res (b : tbinop arg1 arg2 res)

: typeDenote arg1 ! typeDenote arg2 ! typeDenote res :=
match b with|

TPlus ) plus|
TTimes ) mult|
TEq Nat ) eq nat|
TEq Bool ) eq bool|
TLt ) lt
end.

The same tricks suOEce to deo/ne an expression denotation function in an unsurprising
way:

Fixpoint texpDenote t (e : texp t ) : typeDenote t :=

match e with|

TNConst n ) n|
TBConst b ) b|
TBinop b e1 e2 ) (tbinopDenote b) (texpDenote e1 ) (texpDenote e2 )
end.

We can evaluate a few example programs to convince ourselves that this semantics is
correct.

Eval simpl in texpDenote (TNConst 42).

= 42 : typeDenote Nat

Eval simpl in texpDenote (TBConst true).

= true : typeDenote Bool

Eval simpl in texpDenote (TBinop TTimes (TBinop TPlus (TNConst 2) (TNConst 2)) (TNConst
7)).

= 28 : typeDenote Nat

Eval simpl in texpDenote (TBinop (TEq Nat) (TBinop TPlus (TNConst 2) (TNConst 2))
(TNConst 7)).

= false : typeDenote Bool

29

Eval simpl in texpDenote (TBinop TLt (TBinop TPlus (TNConst 2) (TNConst 2)) (TNConst
7)).

= true : typeDenote Bool

2.2.2 Target Language
Now we want to deo/ne a suitable stack machine target for compilation. In the example
of the untyped language, stack machine programs could encounter stack underAEows and
"get stuck." This was unfortunate, since we had to deal with this complication even though
we proved that our compiler never produced underAEowing programs. We could have used
dependent types to force all stack machine programs to be underAEow-free.

For our new languages, besides underAEow, we also have the problem of stack slots with
naturals instead of bools or vice versa. This time, we will use indexed typed families to avoid
the need to reason about potential failures.

We start by deo/ning stack types, which classify sets of possible stacks.

Definition tstack := list type.

Any stack classio/ed by a tstack must have exactly as many elements, and each stack
element must have the type found in the same position of the stack type.

We can deo/ne instructions in terms of stack types, where every instruction's type tells
us what initial stack type it expects and what o/nal stack type it will produce.

Inductive tinstr : tstack ! tstack ! Set :=|

TINConst : 8 s, nat ! tinstr s (Nat :: s)|
TIBConst : 8 s, bool ! tinstr s (Bool :: s)|
TIBinop : 8 arg1 arg2 res s,

tbinop arg1 arg2 res!

tinstr (arg1 :: arg2 :: s) (res :: s).

Stack machine programs must be a similar inductive family, since, if we again used the
list type family, we would not be able to guarantee that intermediate stack types match
within a program.

Inductive tprog : tstack ! tstack ! Set :=|

TNil : 8 s, tprog s s|
TCons : 8 s1 s2 s3,

tinstr s1 s2!

tprog s2 s3!
tprog s1 s3.

Now, to deo/ne the semantics of our new target language, we need a representation for
stacks at runtime. We will again take advantage of type information to deo/ne types of value
stacks that, by construction, contain the right number and types of elements.

Fixpoint vstack (ts : tstack) : Set :=

match ts with

30

| nil ) unit|

t :: ts' ) typeDenote t * vstack ts'
end%type.

This is another Set-valued function. This time it is recursive, which is perfectly valid,
since Set is not treated specially in determining which functions may be written. We say
that the value stack of an empty stack type is any value of type unit, which has just a single
value, tt. A nonempty stack type leads to a value stack that is a pair, whose o/rst element
has the proper type and whose second element follows the representation for the remainder
of the stack type. We write %type so that Coq knows to interpret * as Cartesian product
rather than multiplication.

This idea of programming with types can take a while to internalize, but it enables
a very simple deo/nition of instruction denotation. Our deo/nition is like what you might
expect from a Lisp-like version of ML that ignored type information. Nonetheless, the fact
that tinstrDenote passes the type-checker guarantees that our stack machine programs can
never go wrong.

Definition tinstrDenote ts ts' (i : tinstr ts ts' ) : vstack ts ! vstack ts' :=

match i with|

TINConst n ) fun s ) (n, s)|
TIBConst b ) fun s ) (b, s)|
TIBinop b ) fun s )

match s with

(arg1, (arg2, s' )) ) ((tbinopDenote b) arg1 arg2, s' )
end
end.

Why do we choose to use an anonymous function to bind the initial stack in every case
of the match? Consider this well-intentioned but invalid alternative version:

Definition tinstrDenote ts ts' (i : tinstr ts ts' ) (s : vstack ts) : vstack ts' :=

match i with|

TINConst n ) (n, s)|
TIBConst b ) (b, s)|
TIBinop b )

match s with

(arg1, (arg2, s' )) ) ((tbinopDenote b) arg1 arg2, s' )
end
end.

The Coq type-checker complains that:
The term "(n, s)" has type "(nat * vstack ts)%type"

while it is expected to have type "vstack ?119".

31

The text ?119 stands for a unio/cation variable. We can try to help Coq o/gure out the
value of this variable with an explicit annotation on our match expression.

Definition tinstrDenote ts ts' (i : tinstr ts ts' ) (s : vstack ts) : vstack ts' :=

match i in tinstr ts ts' return vstack ts' with|

TINConst n ) (n, s)|
TIBConst b ) (b, s)|
TIBinop b )

match s with

(arg1, (arg2, s' )) ) ((tbinopDenote b) arg1 arg2, s' )
end
end.

Now the error message changes.
The term "(n, s)" has type "(nat * vstack ts)%type"

while it is expected to have type "vstack (Nat :: t)".

Recall from our earlier discussion of match annotations that we write the annotations to
express to the type-checker the relationship between the type indices of the case object and
the result type of the match. Coq chooses to assign to the wildcard after TINConst the
name t , and the type error is telling us that the type checker cannot prove that t is the same
as ts. By moving s out of the match, we lose the ability to express, with in and return
clauses, the relationship between the shared index ts of s and i.

There are reasonably general ways of getting around this problem without pushing
binders inside matches. However, the alternatives are signio/cantly more involved, and the
technique we use here is almost certainly the best choice, whenever it applies.

We o/nish the semantics with a straightforward deo/nition of program denotation.
Fixpoint tprogDenote ts ts' (p : tprog ts ts' ) : vstack ts ! vstack ts' :=

match p with|

TNil ) fun s ) s|
TCons i p' ) fun s ) tprogDenote p' (tinstrDenote i s)
end.

2.2.3 Translation
To deo/ne our compilation, it is useful to have an auxiliary function for concatenating two
stack machine programs.

Fixpoint tconcat ts ts' tsj (p : tprog ts ts' ) : tprog ts' tsj ! tprog ts tsj :=

match p with|

TNil ) fun p' ) p'|
TCons i p1 ) fun p' ) TCons i (tconcat p1 p' )

32

end.

With that function in place, the compilation is deo/ned very similarly to how it was before,
modulo the use of dependent typing.

Fixpoint tcompile t (e : texp t ) (ts : tstack) : tprog ts (t :: ts) :=

match e with|

TNConst n ) TCons (TINConst n) (TNil )|
TBConst b ) TCons (TIBConst b) (TNil )|
TBinop b e1 e2 ) tconcat (tcompile e2 )

(tconcat (tcompile e1 ) (TCons (TIBinop b) (TNil )))
end.

One interesting feature of the deo/nition is the underscores appearing to the right of)
arrows. Haskell and ML programmers are quite familiar with compilers that infer type
parameters to polymorphic values. In Coq, it is possible to go even further and ask the system
to infer arbitrary terms, by writing underscores in place of specio/c values. You may have
noticed that we have been calling functions without specifying all of their arguments. For
instance, the recursive calls here to tcompile omit the t argument. Coq's implicit argument
mechanism automatically inserts underscores for arguments that it will probably be able to
infer. Inference of such values is far from complete, though; generally, it only works in cases
similar to those encountered with polymorphic type instantiation in Haskell and ML.

The underscores here are being o/lled in with stack types. That is, the Coq type inferencer
is, in a sense, inferring something about the AEow of control in the translated programs. We
can take a look at exactly which values are o/lled in:

Print tcompile.

tcompile =
o/x tcompile (t : type) (e : texp t ) (ts : tstack) -struct e"" :

tprog ts (t :: ts) :=
match e in (texp t0 ) return (tprog ts (t0 :: ts)) with|

TNConst n ) TCons (TINConst ts n) (TNil (Nat :: ts))|
TBConst b ) TCons (TIBConst ts b) (TNil (Bool :: ts))|
TBinop arg1 arg2 res b e1 e2 )

tconcat (tcompile arg2 e2 ts)

(tconcat (tcompile arg1 e1 (arg2 :: ts))

(TCons (TIBinop ts b) (TNil (res :: ts))))
end

: 8 t : type, texp t ! 8 ts : tstack, tprog ts (t :: ts)

We can check that the compiler generates programs that behave appropriately on our
sample programs from above:

Eval simpl in tprogDenote (tcompile (TNConst 42) nil) tt.

= (42, tt) : vstack (Nat :: nil)

Eval simpl in tprogDenote (tcompile (TBConst true) nil) tt.

33

= (true, tt) : vstack (Bool :: nil)
Eval simpl in tprogDenote (tcompile (TBinop TTimes (TBinop TPlus (TNConst 2) (TNConst
2)) (TNConst 7)) nil) tt.

= (28, tt) : vstack (Nat :: nil)

Eval simpl in tprogDenote (tcompile (TBinop (TEq Nat) (TBinop TPlus (TNConst 2) (TNConst
2)) (TNConst 7)) nil) tt.

= (false, tt) : vstack (Bool :: nil)

Eval simpl in tprogDenote (tcompile (TBinop TLt (TBinop TPlus (TNConst 2) (TNConst 2))
(TNConst 7)) nil) tt.

= (true, tt) : vstack (Bool :: nil)

2.2.4 Translation Correctness
We can state a correctness theorem similar to the last one.
Theorem tcompile correct : 8 t (e : texp t ),

tprogDenote (tcompile e nil) tt = (texpDenote e, tt).

Again, we need to strengthen the theorem statement so that the induction will go through.
This time, I will develop an alternative approach to this kind of proof, stating the key lemma
as:

Lemma tcompile correct' : 8 t (e : texp t ) ts (s : vstack ts),

tprogDenote (tcompile e ts) s = (texpDenote e, s).

While lemma compile correct' quantio/ed over a program that is the "continuation" for
the expression we are considering, here we avoid drawing in any extra syntactic elements.
In addition to the source expression and its type, we also quantify over an initial stack type
and a stack compatible with it. Running the compilation of the program starting from that
stack, we should arrive at a stack that dioeers only in having the program's denotation pushed
onto it.

Let us try to prove this theorem in the same way that we settled on in the last section.

induction e; crush.

We are left with this unproved conclusion:

tprogDenote

(tconcat (tcompile e2 ts)

(tconcat (tcompile e1 (arg2 :: ts))

(TCons (TIBinop ts t ) (TNil (res :: ts))))) s =
(tbinopDenote t (texpDenote e1 ) (texpDenote e2 ), s)

We need an analogue to the app ass theorem that we used to rewrite the goal in the last
section. We can abort this proof and prove such a lemma about tconcat.

Abort.

34

Lemma tconcat correct : 8 ts ts' tsj (p : tprog ts ts' ) (p' : tprog ts' tsj)

(s : vstack ts),
tprogDenote (tconcat p p' ) s
= tprogDenote p' (tprogDenote p s).
induction p; crush.
Qed.

This one goes through completely automatically.
Some code behind the scenes registers app ass for use by crush. We must register tcon-
cat correct similarly to get the same eoeect:

Hint Rewrite tconcat correct : cpdt.

We ask that the lemma be used for left-to-right rewriting, and we ask for the hint to be
added to the hint database called cpdt, which is the database used by crush. Now we are
ready to return to tcompile correct', proving it automatically this time.

Lemma tcompile correct' : 8 t (e : texp t ) ts (s : vstack ts),

tprogDenote (tcompile e ts) s = (texpDenote e, s).
induction e; crush.
Qed.

We can register this main lemma as another hint, allowing us to prove the o/nal theorem
trivially.

Hint Rewrite tcompile correct' : cpdt.
Theorem tcompile correct : 8 t (e : texp t ),

tprogDenote (tcompile e nil) tt = (texpDenote e, tt).
crush.
Qed.

35

Part I
Basic Programming and Proving

36

Chapter 3
Introducing Inductive Types

In a sense, CIC is built from just two relatively straightforward features: function types and
inductive types. From this modest foundation, we can prove eoeectively all of the theorems of
math and carry out eoeectively all program verio/cations, with enough eoeort expended. This
chapter introduces induction and recursion for functional programming in Coq.

3.1 Enumerations
Coq inductive types generalize the algebraic datatypes found in Haskell and ML. Confusingly
enough, inductive types also generalize generalized algebraic datatypes (GADTs), by adding
the possibility for type dependency. Even so, it is worth backing up from the examples of the
last chapter and going over basic, algebraic datatype uses of inductive datatypes, because
the chance to prove things about the values of these types adds new wrinkles beyond usual
practice in Haskell and ML.

The singleton type unit is an inductive type:

Inductive unit : Set :=|

tt.

This vernacular command deo/nes a new inductive type unit whose only value is tt, as
we can see by checking the types of the two identio/ers:

Check unit.

unit : Set

Check tt.

tt : unit

We can prove that unit is a genuine singleton type.
Theorem unit singleton : 8 x : unit, x = tt.

The important thing about an inductive type is, unsurprisingly, that you can do induction
over its values, and induction is the key to proving this theorem. We ask to proceed by
induction on the variable x .

37

induction x.

The goal changes to:
tt = tt

...which we can discharge trivially.
reflexivity.
Qed.

It seems kind of odd to write a proof by induction with no inductive hypotheses. We
could have arrived at the same result by beginning the proof with:

destruct x .
...which corresponds to "proof by case analysis" in classical math. For non-recursive inductive
types, the two tactics will always have identical behavior. Often case analysis is suOEcient,
even in proofs about recursive types, and it is nice to avoid introducing unneeded induction
hypotheses.

What exactly is the induction principle for unit? We can ask Coq:

Check unit ind.

unit ind : 8 P : unit ! Prop, P tt ! 8 u : unit, P u

Every Inductive command deo/ning a type T also deo/nes an induction principle named
T ind. Coq follows the Curry-Howard correspondence and includes the ingredients of pro-
gramming and proving in the same single syntactic class. Thus, our type, operations over
it, and principles for reasoning about it all live in the same language and are described by
the same type system. The key to telling what is a program and what is a proof lies in the
distinction between the type Prop, which appears in our induction principle; and the type
Set, which we have seen a few times already.

The convention goes like this: Set is the type of normal types, and the values of such
types are programs. Prop is the type of logical propositions, and the values of such types
are proofs. Thus, an induction principle has a type that shows us that it is a function for
building proofs.

Specio/cally, unit ind quantio/es over a predicate P over unit values. If we can present a
proof that P holds of tt, then we are rewarded with a proof that P holds for any value u of
type unit. In our last proof, the predicate was (fun u : unit ) u = tt).

We can deo/ne an inductive type even simpler than unit:
Inductive Empty set : Set := .

Empty set has no elements. We can prove fun theorems about it:
Theorem the sky is falling : 8 x : Empty set, 2 + 2 = 5.

destruct 1.
Qed.

Because Empty set has no elements, the fact of having an element of this type implies
anything. We use destruct 1 instead of destruct x in the proof because unused quantio/ed

38

variables are relegated to being referred to by number. (There is a good reason for this,
related to the unity of quantio/ers and implication. An implication is just a quantio/cation
over a proof, where the quantio/ed variable is never used. It generally makes more sense to
refer to implication hypotheses by number than by name, and Coq treats our quantio/er over
an unused variable as an implication in determining the proper behavior.)

We can see the induction principle that made this proof so easy:

Check Empty set ind.

Empty set ind : 8 (P : Empty set ! Prop) (e : Empty set), P e

In other words, any predicate over values from the empty set holds vacuously of every
such element. In the last proof, we chose the predicate (fun : Empty set ) 2 + 2 = 5).

We can also apply this get-out-of-jail-free card programmatically. Here is a lazy way of
converting values of Empty set to values of unit:

Definition e2u (e : Empty set) : unit := match e with end.

We employ match pattern matching as in the last chapter. Since we match on a value
whose type has no constructors, there is no need to provide any branches.

Moving up the ladder of complexity, we can deo/ne the booleans:
Inductive bool : Set :=|

true|
false.

We can use less vacuous pattern matching to deo/ne boolean negation.
Definition not (b : bool) : bool :=

match b with|

true ) false|
false ) true
end.

An alternative deo/nition desugars to the above:
Definition not' (b : bool) : bool :=

if b then false else true.

We might want to prove that not is its own inverse operation.
Theorem not inverse : 8 b : bool, not (not b) = b.

destruct b.

After we case-analyze on b, we are left with one subgoal for each constructor of bool.

2 subgoals

============================

not (not true) = true

subgoal 2 is:

39

not (not false) = false

The o/rst subgoal follows by Coq's rules of computation, so we can dispatch it easily:
reflexivity.

Likewise for the second subgoal, so we can restart the proof and give a very compact
justio/cation.

Restart.

destruct b; reflexivity.
Qed.

Another theorem about booleans illustrates another useful tactic.
Theorem not ineq : 8 b : bool, not b 6= b.

destruct b; discriminate.
Qed.

discriminate is used to prove that two values of an inductive type are not equal, when-
ever the values are formed with dioeerent constructors. In this case, the dioeerent constructors
are true and false.

At this point, it is probably not hard to guess what the underlying induction principle
for bool is.

Check bool ind.

bool ind : 8 P : bool ! Prop, P true ! P false ! 8 b : bool, P b

3.2 Simple Recursive Types
The natural numbers are the simplest common example of an inductive type that actually
deserves the name.

Inductive nat : Set :=|

O : nat|
S : nat ! nat.

O is zero, and S is the successor function, so that 0 is syntactic sugar for O, 1 for S O,
2 for S (S O), and so on.

Pattern matching works as we demonstrated in the last chapter:

Definition isZero (n : nat) : bool :=

match n with|

O ) true|
S ) false
end.

Definition pred (n : nat) : nat :=

match n with

40

| O ) O|

S n' ) n'
end.

We can prove theorems by case analysis:
Theorem S isZero : 8 n : nat, isZero (pred (S (S n))) = false.

destruct n; reflexivity.
Qed.

We can also now get into genuine inductive theorems. First, we will need a recursive
function, to make things interesting.

Fixpoint plus (n m : nat) : nat :=

match n with|

O ) m|
S n' ) S (plus n' m)
end.

Recall that Fixpoint is Coq's mechanism for recursive function deo/nitions. Some theo-
rems about plus can be proved without induction.

Theorem O plus n : 8 n : nat, plus O n = n.

intro; reflexivity.
Qed.

Coq's computation rules automatically simplify the application of plus, because unfolding
the deo/nition of plus gives us a match expression where the branch to be taken is obvious
from syntax alone. If we just reverse the order of the arguments, though, this no longer
works, and we need induction.

Theorem n plus O : 8 n : nat, plus n O = n.

induction n.

Our o/rst subgoal is plus O O = O, which is trivial by computation.
reflexivity.

Our second subgoal is more work and also demonstrates our o/rst inductive hypothesis.

n : nat
IHn : plus n O = n
============================

plus (S n) O = S n

We can start out by using computation to simplify the goal as far as we can.
simpl.

Now the conclusion is S (plus n O) = S n. Using our inductive hypothesis:
rewrite IHn.

41

...we get a trivial conclusion S n = S n.
reflexivity.

Not much really went on in this proof, so the crush tactic from the Tactics module can
prove this theorem automatically.

Restart.

induction n; crush.
Qed.

We can check out the induction principle at work here:
Check nat ind.

nat ind : 8 P : nat ! Prop,

P O ! (8 n : nat, P n ! P (S n)) ! 8 n : nat, P n

Each of the two cases of our last proof came from the type of one of the arguments to
nat ind. We chose P to be (fun n : nat ) plus n O = n). The o/rst proof case corresponded
to P O and the second case to (8 n : nat, P n ! P (S n)). The free variable n and inductive
hypothesis IHn came from the argument types given here.

Since nat has a constructor that takes an argument, we may sometimes need to know
that that constructor is injective.

Theorem S inj : 8 n m : nat, S n = S m ! n = m.

injection 1; trivial.
Qed.

injection refers to a premise by number, adding new equalities between the corre-
sponding arguments of equated terms that are formed with the same constructor. We end
up needing to prove n = m ! n = m, so it is unsurprising that a tactic named trivial is
able to o/nish the proof.

There is also a very useful tactic called congruence that can prove this theorem imme-
diately. congruence generalizes discriminate and injection, and it also adds reasoning
about the general properties of equality, such as that a function returns equal results on
equal arguments. That is, congruence is a complete decision procedure for the theory of
equality and uninterpreted functions, plus some smarts about inductive types.

We can deo/ne a type of lists of natural numbers.
Inductive nat list : Set :=|

NNil : nat list|
NCons : nat ! nat list ! nat list.

Recursive deo/nitions are straightforward extensions of what we have seen before.
Fixpoint nlength (ls : nat list) : nat :=

match ls with|

NNil ) O|
NCons ls' ) S (nlength ls' )

42

end.
Fixpoint napp (ls1 ls2 : nat list) : nat list :=

match ls1 with|

NNil ) ls2|
NCons n ls1' ) NCons n (napp ls1' ls2 )
end.

Inductive theorem proving can again be automated quite eoeectively.
Theorem nlength napp : 8 ls1 ls2 : nat list, nlength (napp ls1 ls2 )

= plus (nlength ls1 ) (nlength ls2 ).
induction ls1 ; crush.
Qed.

Check nat list ind.

nat list ind

: 8 P : nat list ! Prop,

P NNil !
(8 (n : nat) (n0 : nat list), P n0 ! P (NCons n n0 )) !8

n : nat list, P n

In general, we can implement any "tree" types as inductive types. For example, here are
binary trees of naturals.

Inductive nat btree : Set :=|

NLeaf : nat btree|
NNode : nat btree ! nat ! nat btree ! nat btree.

Fixpoint nsize (tr : nat btree) : nat :=

match tr with|

NLeaf ) S O|
NNode tr1 tr2 ) plus (nsize tr1 ) (nsize tr2 )
end.

Fixpoint nsplice (tr1 tr2 : nat btree) : nat btree :=

match tr1 with|

NLeaf ) NNode tr2 O NLeaf|
NNode tr1' n tr2' ) NNode (nsplice tr1' tr2 ) n tr2'
end.

Theorem plus assoc : 8 n1 n2 n3 : nat, plus (plus n1 n2 ) n3 = plus n1 (plus n2 n3 ).

induction n1 ; crush.
Qed.

Theorem nsize nsplice : 8 tr1 tr2 : nat btree, nsize (nsplice tr1 tr2 )

= plus (nsize tr2 ) (nsize tr1 ).
Hint Rewrite n plus O plus assoc : cpdt.

induction tr1 ; crush.

43

Qed.
Check nat btree ind.

nat btree ind

: 8 P : nat btree ! Prop,

P NLeaf !
(8 n : nat btree,

P n ! 8 (n0 : nat) (n1 : nat btree), P n1 ! P (NNode n n0 n1 )) !8

n : nat btree, P n

3.3 Parameterized Types
We can also deo/ne polymorphic inductive types, as with algebraic datatypes in Haskell and
ML.

Inductive list (T : Set) : Set :=|

Nil : list T|
Cons : T ! list T ! list T.

Fixpoint length T (ls : list T ) : nat :=

match ls with|

Nil ) O|
Cons ls' ) S (length ls' )
end.

Fixpoint app T (ls1 ls2 : list T ) : list T :=

match ls1 with|

Nil ) ls2|
Cons x ls1' ) Cons x (app ls1' ls2 )
end.

Theorem length app : 8 T (ls1 ls2 : list T ), length (app ls1 ls2 )

= plus (length ls1 ) (length ls2 ).
induction ls1 ; crush.
Qed.

There is a useful shorthand for writing many deo/nitions that share the same parameter,
based on Coq's section mechanism. The following block of code is equivalent to the above:

Section list.

Variable T : Set.

Inductive list : Set :=|

Nil : list|
Cons : T ! list ! list.

Fixpoint length (ls : list) : nat :=

44

match ls with|

Nil ) O|
Cons ls' ) S (length ls' )
end.

Fixpoint app (ls1 ls2 : list) : list :=

match ls1 with|

Nil ) ls2|
Cons x ls1' ) Cons x (app ls1' ls2 )
end.

Theorem length app : 8 ls1 ls2 : list, length (app ls1 ls2 )

= plus (length ls1 ) (length ls2 ).
induction ls1 ; crush.
Qed.
End list.

After we end the section, the Variables we used are added as extra function parameters
for each deo/ned identio/er, as needed. We verify that this has happened using the Print
command, a cousin of Check which shows the deo/nition of a symbol, rather than just its
type.

Print list.

Inductive list (T : Set) : Set :=

Nil : list T | Cons : T ! list T ! list Tlist

The o/nal deo/nition is the same as what we wrote manually before. The other elements of
the section are altered similarly, turning out exactly as they were before, though we managed
to write their deo/nitions more succinctly.

Check length.

length

: 8 T : Set, list T ! nat
The parameter T is treated as a new argument to the induction principle, too.

Check list ind.

list ind

: 8 (T : Set) (P : list T ! Prop),

P (Nil T ) !
(8 (t : T ) (l : list T ), P l ! P (Cons t l )) !8

l : list T , P l
Thus, even though we just saw that T is added as an extra argument to the constructor
Cons, there is no quantio/er for T in the type of the inductive case like there is for each of
the other arguments.

45

3.4 Mutually Inductive Types
We can deo/ne inductive types that refer to each other:
Inductive even list : Set :=|

ENil : even list|
ECons : nat ! odd list ! even list

with odd list : Set :=|

OCons : nat ! even list ! odd list.

Fixpoint elength (el : even list) : nat :=

match el with|

ENil ) O|
ECons ol ) S (olength ol )
end

with olength (ol : odd list) : nat :=

match ol with|

OCons el ) S (elength el )
end.

Fixpoint eapp (el1 el2 : even list) : even list :=

match el1 with|

ENil ) el2|
ECons n ol ) ECons n (oapp ol el2 )
end

with oapp (ol : odd list) (el : even list) : odd list :=

match ol with|

OCons n el' ) OCons n (eapp el' el )
end.

Everything is going roughly the same as in past examples, until we try to prove a theorem
similar to those that came before.

Theorem elength eapp : 8 el1 el2 : even list,

elength (eapp el1 el2 ) = plus (elength el1 ) (elength el2 ).
induction el1 ; crush.

One goal remains:

n : nat
o : odd list
el2 : even list
============================

S (olength (oapp o el2 )) = S (plus (olength o) (elength el2 ))

46

We have no induction hypothesis, so we cannot prove this goal without starting another
induction, which would reach a similar point, sending us into a futile ino/nite chain of induc-
tions. The problem is that Coq's generation of T ind principles is incomplete. We only get
non-mutual induction principles generated by default.

Abort.
Check even list ind.

even list ind

: 8 P : even list ! Prop,

P ENil !
(8 (n : nat) (o : odd list), P (ECons n o)) !8

e : even list, P e

We see that no inductive hypotheses are included anywhere in the type. To get them,
we must ask for mutual principles as we need them, using the Scheme command.

Scheme even list mut := Induction for even list Sort Prop
with odd list mut := Induction for odd list Sort Prop.

Check even list mut.

even list mut

: 8 (P : even list ! Prop) (P0 : odd list ! Prop),

P ENil !
(8 (n : nat) (o : odd list), P0 o ! P (ECons n o)) !
(8 (n : nat) (e : even list), P e ! P0 (OCons n e)) !8

e : even list, P e

This is the principle we wanted in the o/rst place. There is one more wrinkle left in using
it: the induction tactic will not apply it for us automatically. It will be helpful to look
at how to prove one of our past examples without using induction, so that we can then
generalize the technique to mutual inductive types.

Theorem n plus O' : 8 n : nat, plus n O = n.

apply (nat ind (fun n ) plus n O = n)); crush.
Qed.

From this example, we can see that induction is not magic. It only does some book-
keeping for us to make it easy to apply a theorem, which we can do directly with the apply
tactic. We apply not just an identio/er but a partial application of it, specifying the predicate
we mean to prove holds for all naturals.

This technique generalizes to our mutual example:

Theorem elength eapp : 8 el1 el2 : even list,

elength (eapp el1 el2 ) = plus (elength el1 ) (elength el2 ).

apply (even list mut

(fun el1 : even list ) 8 el2 : even list,

47

elength (eapp el1 el2 ) = plus (elength el1 ) (elength el2 ))
(fun ol : odd list ) 8 el : even list,

olength (oapp ol el ) = plus (olength ol ) (elength el ))); crush.
Qed.

We simply need to specify two predicates, one for each of the mutually inductive types.
In general, it would not be a good idea to assume that a proof assistant could infer extra
predicates, so this way of applying mutual induction is about as straightforward as we could
hope for.

3.5 ReAEexive Types
A kind of inductive type called a reAEexive type is deo/ned in terms of functions that have the
type being deo/ned as their range. One very useful class of examples is in modeling variable
binders. For instance, here is a type for encoding the syntax of a subset of o/rst-order logic:

Inductive formula : Set :=|

Eq : nat ! nat ! formula|
And : formula ! formula ! formula|
Forall : (nat ! formula) ! formula.

Our kinds of formulas are equalities between naturals, conjunction, and universal quan-
tio/cation over natural numbers. We avoid needing to include a notion of "variables" in our
type, by using Coq functions to encode quantio/cation. For instance, here is the encoding of8

x : nat, x = x :

Example forall reAE : formula := Forall (fun x ) Eq x x ).

We can write recursive functions over reAEexive types quite naturally. Here is one trans-
lating our formulas into native Coq propositions.

Fixpoint formulaDenote (f : formula) : Prop :=

match f with|

Eq n1 n2 ) n1 = n2|
And f1 f2 ) formulaDenote f1 ^ formulaDenote f2|
Forall f ' ) 8 n : nat, formulaDenote (f ' n)
end.

We can also encode a trivial formula transformation that swaps the order of equality and
conjunction operands.

Fixpoint swapper (f : formula) : formula :=

match f with|

Eq n1 n2 ) Eq n2 n1|
And f1 f2 ) And (swapper f2 ) (swapper f1 )|
Forall f ' ) Forall (fun n ) swapper (f ' n))
end.

48

It is helpful to prove that this transformation does not make true formulas false.
Theorem swapper preserves truth : 8 f, formulaDenote f ! formulaDenote (swapper f ).

induction f ; crush.
Qed.

We can take a look at the induction principle behind this proof.
Check formula ind.

formula ind

: 8 P : formula ! Prop,

(8 n n0 : nat, P (Eq n n0 )) !
(8 f0 : formula,

P f0 ! 8 f1 : formula, P f1 ! P (And f0 f1 )) !
(8 f1 : nat ! formula,

(8 n : nat, P (f1 n)) ! P (Forall f1 )) !8

f2 : formula, P f2

Focusing on the Forall case, which comes third, we see that we are allowed to assume that
the theorem holds for any application of the argument function f1. That is, Coq induction
principles do not follow a simple rule that the textual representations of induction variables
must get shorter in appeals to induction hypotheses. Luckily for us, the people behind the
metatheory of Coq have verio/ed that this AEexibility does not introduce unsoundness.

Up to this point, we have seen how to encode in Coq more and more of what is possible
with algebraic datatypes in Haskell and ML. This may have given the inaccurate impression
that inductive types are a strict extension of algebraic datatypes. In fact, Coq must rule out
some types allowed by Haskell and ML, for reasons of soundness. ReAEexive types provide
our o/rst good example of such a case.

Given our last example of an inductive type, many readers are probably eager to try
encoding the syntax of lambda calculus. Indeed, the function-based representation technique
that we just used, called higher-order abstract syntax (HOAS), is the representation of choice
for lambda calculi in Twelf and in many applications implemented in Haskell and ML. Let
us try to import that choice to Coq:

Inductive term : Set :=|

App : term ! term ! term|
Abs : (term ! term) ! term.

Error : Non strictly positive occurrence of "term" in "(term ! term) ! term"

We have run afoul of the strict positivity requirement for inductive deo/nitions, which says
that the type being deo/ned may not occur to the left of an arrow in the type of a constructor
argument. It is important that the type of a constructor is viewed in terms of a series of
arguments and a result, since obviously we need recursive occurrences to the lefts of the

49

outermost arrows if we are to have recursive occurrences at all.

Why must Coq enforce this restriction? Imagine that our last deo/nition had been ac-
cepted, allowing us to write this function:

Definition uhoh (t : term) : term :=

match t with|

Abs f ) f t| )

t
end.

Using an informal idea of Coq's semantics, it is easy to verify that the application uhoh
(Abs uhoh) will run forever. This would be a mere curiosity in OCaml and Haskell, where
non-termination is commonplace, though the fact that we have a non-terminating program
without explicit recursive function deo/nitions is unusual.

For Coq, however, this would be a disaster. The possibility of writing such a function
would destroy all our cono/dence that proving a theorem means anything. Since Coq combines
programs and proofs in one language, we would be able to prove every theorem with an
ino/nite loop.

Nonetheless, the basic insight of HOAS is a very useful one, and there are ways to realize
most beneo/ts of HOAS in Coq. We will study a particular technique of this kind in the later
chapters on programming language syntax and semantics.

3.6 An Interlude on Proof Terms
As we have emphasized a few times already, Coq proofs are actually programs, written in
the same language we have been using in our examples all along. We can get a o/rst sense of
what this means by taking a look at the deo/nitions of some of the induction principles we
have used.

Print unit ind.

unit ind =
fun P : unit ! Prop ) unit rect P

: 8 P : unit ! Prop, P tt ! 8 u : unit, P u

We see that this induction principle is deo/ned in terms of a more general principle,
unit rect.

Check unit rect.

unit rect

: 8 P : unit ! Type, P tt ! 8 u : unit, P u

unit rect gives P type unit ! Type instead of unit ! Prop. Type is another universe,
like Set and Prop. In fact, it is a common supertype of both. Later on, we will discuss

50

exactly what the signio/cances of the dioeerent universes are. For now, it is just important
that we can use Type as a sort of meta-universe that may turn out to be either Set or Prop.
We can see the symmetry inherent in the subtyping relationship by printing the deo/nition
of another principle that was generated for unit automatically:

Print unit rec.

unit rec =
fun P : unit ! Set ) unit rect P

: 8 P : unit ! Set, P tt ! 8 u : unit, P u

This is identical to the deo/nition for unit ind, except that we have substituted Set for
Prop. For most inductive types T , then, we get not just induction principles T ind, but also
recursion principles T rec. We can use T rec to write recursive deo/nitions without explicit
Fixpoint recursion. For instance, the following two deo/nitions are equivalent:

Definition always O (u : unit) : nat :=

match u with|

tt ) O
end.

Definition always O' (u : unit) : nat :=

unit rec (fun : unit ) nat) O u.

Going even further down the rabbit hole, unit rect itself is not even a primitive. It is a
functional program that we can write manually.

Print unit rect.

unit rect =
fun (P : unit ! Type) (f : P tt) (u : unit) )
match u as u0 return (P u0 ) with|

tt ) f
end

: 8 P : unit ! Type, P tt ! 8 u : unit, P u

The only new feature we see is an as clause for a match, which is used in concert with
the return clause that we saw in the introduction. Since the type of the match is dependent
on the value of the object being analyzed, we must give that object a name so that we can
refer to it in the return clause.

To prove that unit rect is nothing special, we can reimplement it manually.

Definition unit rect' (P : unit ! Type) (f : P tt) (u : unit) :=

match u with|

tt ) f
end.

We rely on Coq's heuristics for inferring match annotations.
We can check the implementation of nat rect as well:

51

Print nat rect.

nat rect =
fun (P : nat ! Type) (f : P O) (f0 : 8 n : nat, P n ! P (S n)) )
o/x F (n : nat) : P n :=

match n as n0 return (P n0 ) with|

O ) f|
S n0 ) f0 n0 (F n0 )
end

: 8 P : nat ! Type,

P O ! (8 n : nat, P n ! P (S n)) ! 8 n : nat, P n
Now we have an actual recursive deo/nition. o/x expressions are an anonymous form of
Fixpoint, just as fun expressions stand for anonymous non-recursive functions. Beyond
that, the syntax of o/x mirrors that of Fixpoint. We can understand the deo/nition of
nat rect better by reimplementing nat ind using sections.

Section nat ind'.

First, we have the property of natural numbers that we aim to prove.

Variable P : nat ! Prop.
Then we require a proof of the O case.
Hypothesis O case : P O.
Next is a proof of the S case, which may assume an inductive hypothesis.
Hypothesis S case : 8 n : nat, P n ! P (S n).
Finally, we deo/ne a recursive function to tie the pieces together.
Fixpoint nat ind' (n : nat) : P n :=

match n with|

O ) O case|
S n' ) S case (nat ind' n' )
end.
End nat ind'.

Closing the section adds the Variables and Hypothesises as new fun-bound arguments
to nat ind', and, modulo the use of Prop instead of Type, we end up with the exact same
deo/nition that was generated automatically for nat rect.

We can also examine the deo/nition of even list mut, which we generated with Scheme for
a mutually-recursive type.

Print even list mut.

even list mut =
fun (P : even list ! Prop) (P0 : odd list ! Prop)

(f : P ENil) (f0 : 8 (n : nat) (o : odd list), P0 o ! P (ECons n o))
(f1 : 8 (n : nat) (e : even list), P e ! P0 (OCons n e)) )
o/x F (e : even list) : P e :=

52

match e as e0 return (P e0 ) with|

ENil ) f|
ECons n o ) f0 n o (F0 o)
end
with F0 (o : odd list) : P0 o :=

match o as o0 return (P0 o0 ) with|

OCons n e ) f1 n e (F e)
end
for F

: 8 (P : even list ! Prop) (P0 : odd list ! Prop),

P ENil !
(8 (n : nat) (o : odd list), P0 o ! P (ECons n o)) !
(8 (n : nat) (e : even list), P e ! P0 (OCons n e)) !8

e : even list, P e
We see a mutually-recursive o/x, with the dioeerent functions separated by with in the
same way that they would be separated by and in ML. A o/nal for clause identio/es which of
the mutually-recursive functions should be the o/nal value of the o/x expression. Using this
deo/nition as a template, we can reimplement even list mut directly.

Section even list mut'.

First, we need the properties that we are proving.

Variable Peven : even list ! Prop.
Variable Podd : odd list ! Prop.

Next, we need proofs of the three cases.
Hypothesis ENil case : Peven ENil.
Hypothesis ECons case : 8 (n : nat) (o : odd list), Podd o ! Peven (ECons n o).
Hypothesis OCons case : 8 (n : nat) (e : even list), Peven e ! Podd (OCons n e).

Finally, we deo/ne the recursive functions.
Fixpoint even list mut' (e : even list) : Peven e :=

match e with|

ENil ) ENil case|
ECons n o ) ECons case n (odd list mut' o)
end
with odd list mut' (o : odd list) : Podd o :=

match o with|

OCons n e ) OCons case n (even list mut' e)
end.
End even list mut'.

Even induction principles for reAEexive types are easy to implement directly. For our
formula type, we can use a recursive deo/nition much like those we wrote above.

Section formula ind'.

53

Variable P : formula ! Prop.
Hypothesis Eq case : 8 n1 n2 : nat, P (Eq n1 n2 ).
Hypothesis And case : 8 f1 f2 : formula,

P f1 ! P f2 ! P (And f1 f2 ).
Hypothesis Forall case : 8 f : nat ! formula,

(8 n : nat, P (f n)) ! P (Forall f ).

Fixpoint formula ind' (f : formula) : P f :=

match f with|

Eq n1 n2 ) Eq case n1 n2|
And f1 f2 ) And case (formula ind' f1 ) (formula ind' f2 )|
Forall f ' ) Forall case f ' (fun n ) formula ind' (f ' n))
end.
End formula ind'.

3.7 Nested Inductive Types
Suppose we want to extend our earlier type of binary trees to trees with arbitrary o/nite
branching. We can use lists to give a simple deo/nition.

Inductive nat tree : Set :=|

NLeaf' : nat tree|
NNode' : nat ! list nat tree ! nat tree.

This is an example of a nested inductive type deo/nition, because we use the type we
are deo/ning as an argument to a parametrized type family. Coq will not allow all such
deo/nitions; it eoeectively pretends that we are deo/ning nat tree mutually with a version
of list specialized to nat tree, checking that the resulting expanded deo/nition satiso/es the
usual rules. For instance, if we replaced list with a type family that used its parameter
as a function argument, then the deo/nition would be rejected as violating the positivity
restriction.

Like we encountered for mutual inductive types, we o/nd that the automatically-generated
induction principle for nat tree is too weak.

Check nat tree ind.

nat tree ind

: 8 P : nat tree ! Prop,

P NLeaf' !
(8 (n : nat) (l : list nat tree), P (NNode' n l )) !8

n : nat tree, P n

There is no command like Scheme that will implement an improved principle for us. In
general, it takes creativity to o/gure out how to incorporate nested uses to dioeerent type
families. Now that we know how to implement induction principles manually, we are in a

54

position to apply just such creativity to this problem.

First, we will need an auxiliary deo/nition, characterizing what it means for a property
to hold of every element of a list.

Section All.

Variable T : Set.
Variable P : T ! Prop.

Fixpoint All (ls : list T ) : Prop :=

match ls with|

Nil ) True|
Cons h t ) P h ^ All t
end.
End All.

It will be useful to look at the deo/nitions of True and ^, since we will want to write
manual proofs of them below.

Print True.

Inductive True : Prop := I : True

That is, True is a proposition with exactly one proof, I, which we may always supply
trivially.

Finding the deo/nition of ^ takes a little more work. Coq supports user registration of
arbitrary parsing rules, and it is such a rule that is letting us write ^ instead of an application
of some inductive type family. We can o/nd the underlying inductive type with the Locate
command.

Locate "^".

Notation Scope
"A ^ B" := and A B : type scope

(default interpretation)

Print and.

Inductive and (A : Prop) (B : Prop) : Prop := conj : A ! B ! A ^ B
For conj: Arguments A, B are implicit
For and : Argument scopes are [type scope type scope]
For conj: Argument scopes are [type scope type scope ]

In addition to the deo/nition of and itself, we get information on implicit arguments and
parsing rules for and and its constructor conj. We will ignore the parsing information for
now. The implicit argument information tells us that we build a proof of a conjunction by
calling the constructor conj on proofs of the conjuncts, with no need to include the types of
those proofs as explicit arguments.

Now we create a section for our induction principle, following the same basic plan as in
the last section of this chapter.

55

Section nat tree ind'.

Variable P : nat tree ! Prop.

Hypothesis NLeaf ' case : P NLeaf'.
Hypothesis NNode' case : 8 (n : nat) (ls : list nat tree),

All P ls ! P (NNode' n ls).

A o/rst attempt at writing the induction principle itself follows the intuition that nested
inductive type deo/nitions are expanded into mutual inductive deo/nitions.

Fixpoint nat tree ind' (tr : nat tree) : P tr :=

match tr with|

NLeaf' ) NLeaf ' case|
NNode' n ls ) NNode' case n ls (list nat tree ind ls)
end

with list nat tree ind (ls : list nat tree) : All P ls :=

match ls with|

Nil ) I|
Cons tr rest ) conj (nat tree ind' tr ) (list nat tree ind rest )
end.

Coq rejects this deo/nition, saying "Recursive call to nat tree ind' has principal argument
equal to "tr" instead of rest." The term "nested inductive type" hints at the solution to
the problem. Just like true mutually-inductive types require mutually-recursive induction
principles, nested types require nested recursion.

Fixpoint nat tree ind' (tr : nat tree) : P tr :=

match tr with|

NLeaf' ) NLeaf ' case|
NNode' n ls ) NNode' case n ls

((o/x list nat tree ind (ls : list nat tree) : All P ls :=

match ls with|

Nil ) I|
Cons tr rest ) conj (nat tree ind' tr ) (list nat tree ind rest )
end) ls)
end.

We include an anonymous o/x version of list nat tree ind that is literally nested inside
the deo/nition of the recursive function corresponding to the inductive deo/nition that had
the nested use of list.

End nat tree ind'.

We can try our induction principle out by deo/ning some recursive functions on nat trees
and proving a theorem about them. First, we deo/ne some helper functions that operate on
lists.

56

Section map.

Variables T T' : Set.
Variable f : T ! T'.

Fixpoint map (ls : list T ) : list T' :=

match ls with|

Nil ) Nil|
Cons h t ) Cons (f h) (map t )
end.
End map.

Fixpoint sum (ls : list nat) : nat :=

match ls with|

Nil ) O|
Cons h t ) plus h (sum t )
end.

Now we can deo/ne a size function over our trees.
Fixpoint ntsize (tr : nat tree) : nat :=

match tr with|

NLeaf' ) S O|
NNode' trs ) S (sum (map ntsize trs))
end.

Notice that Coq was smart enough to expand the deo/nition of map to verify that we are
using proper nested recursion, even through a use of a higher-order function.

Fixpoint ntsplice (tr1 tr2 : nat tree) : nat tree :=

match tr1 with|

NLeaf' ) NNode' O (Cons tr2 Nil)|
NNode' n Nil ) NNode' n (Cons tr2 Nil)|
NNode' n (Cons tr trs) ) NNode' n (Cons (ntsplice tr tr2 ) trs)
end.

We have deo/ned another arbitrary notion of tree splicing, similar to before, and we can
prove an analogous theorem about its relationship with tree size. We start with a useful
lemma about addition.

Lemma plus S : 8 n1 n2 : nat,

plus n1 (S n2 ) = S (plus n1 n2 ).
induction n1 ; crush.
Qed.

Now we begin the proof of the theorem, adding the lemma plus S as a hint.
Theorem ntsize ntsplice : 8 tr1 tr2 : nat tree, ntsize (ntsplice tr1 tr2 )

= plus (ntsize tr2 ) (ntsize tr1 ).
Hint Rewrite plus S : cpdt.

57

We know that the standard induction principle is insuOEcient for the task, so we need to
provide a using clause for the induction tactic to specify our alternate principle.

induction tr1 using nat tree ind'; crush.

One subgoal remains:
n : nat
ls : list nat tree
H : All

(fun tr1 : nat tree )8

tr2 : nat tree,
ntsize (ntsplice tr1 tr2 ) = plus (ntsize tr2 ) (ntsize tr1 )) ls
tr2 : nat tree
============================

ntsize

match ls with|

Nil ) NNode' n (Cons tr2 Nil)|
Cons tr trs ) NNode' n (Cons (ntsplice tr tr2 ) trs)
end = S (plus (ntsize tr2 ) (sum (map ntsize ls)))

After a few moments of squinting at this goal, it becomes apparent that we need to do a
case analysis on the structure of ls. The rest is routine.

destruct ls; crush.

We can go further in automating the proof by exploiting the hint mechanism.
Restart.
Hint Extern 1 (ntsize (match ?LS with Nil ) | Cons ) end) = ) )

destruct LS ; crush.
induction tr1 using nat tree ind'; crush.
Qed.

We will go into great detail on hints in a later chapter, but the only important thing to
note here is that we register a pattern that describes a conclusion we expect to encounter
during the proof. The pattern may contain unio/cation variables, whose names are preo/xed
with question marks, and we may refer to those bound variables in a tactic that we ask to
have run whenever the pattern matches.

The advantage of using the hint is not very clear here, because the original proof was so
short. However, the hint has fundamentally improved the readability of our proof. Before,
the proof referred to the local variable ls, which has an automatically-generated name. To
a human reading the proof script without stepping through it interactively, it was not clear
where ls came from. The hint explains to the reader the process for choosing which variables
to case analyze on, and the hint can continue working even if the rest of the proof structure
changes signio/cantly.

58

3.8 Manual Proofs About Constructors
It can be useful to understand how tactics like discriminate and injection work, so it
is worth stepping through a manual proof of each kind. We will start with a proof o/t for
discriminate.

Theorem true neq false : true 6= false.

We begin with the tactic red, which is short for "one step of reduction," to unfold the
deo/nition of logical negation.

red.

============================

true = false ! False

The negation is replaced with an implication of falsehood. We use the tactic intro H to
change the assumption of the implication into a hypothesis named H.

intro H.

H : true = false
============================

False

This is the point in the proof where we apply some creativity. We deo/ne a function whose
utility will become clear soon.

Definition f (b : bool) := if b then True else False.

It is worth recalling the dioeerence between the lowercase and uppercase versions of truth
and falsehood: True and False are logical propositions, while true and false are boolean
values that we can case-analyze. We have deo/ned f such that our conclusion of False is com-
putationally equivalent to f false. Thus, the change tactic will let us change the conclusion
to f false.

change (f false).

H : true = false
============================

f false

Now the righthand side of H 's equality appears in the conclusion, so we can rewrite,
using the notation  to request to replace the righthand side the equality with the lefthand
side.

rewrite  H.

59

H : true = false
============================

f true

We are almost done. Just how close we are to done is revealed by computational simpli-
o/cation.

simpl.

H : true = false
============================

True

trivial.
Qed.

I have no trivial automated version of this proof to suggest, beyond using discriminate
or congruence in the o/rst place.

We can perform a similar manual proof of injectivity of the constructor S . I leave a walk-
through of the details to curious readers who want to run the proof script interactively.

Theorem S inj' : 8 n m : nat, S n = S m ! n = m.

intros n m H.
change (pred (S n) = pred (S m)).
rewrite H.
reflexivity.
Qed.

3.9 Exercises

1. Deo/ne an inductive type truth with three constructors, Yes, No, and Maybe. Yes

stands for certain truth, No for certain falsehood, and Maybe for an unknown situation.
Deo/ne "not," "and," and "or" for this replacement boolean algebra. Prove that your
implementation of "and" is commutative and distributes over your implementation of
"or."

2. Modify the o/rst example language of Chapter 2 to include variables, where variables are

represented with nat. Extend the syntax and semantics of expressions to accommodate
the change. Your new expDenote function should take as a new extra o/rst argument
a value of type var ! nat, where var is a synonym for naturals-as-variables, and the
function assigns a value to each variable. Deo/ne a constant folding function which does
a bottom-up pass over an expression, at each stage replacing every binary operation
on constants with an equivalent constant. Prove that constant folding preserves the
meanings of expressions.

60

3. Reimplement the second example language of Chapter 2 to use mutually-inductive

types instead of dependent types. That is, deo/ne two separate (non-dependent) induc-
tive types nat exp and bool exp for expressions of the two dioeerent types, rather than a
single indexed type. To keep things simple, you may consider only the binary operators
that take naturals as operands. Add natural number variables to the language, as in
the last exercise, and add an "if" expression form taking as arguments one boolean ex-
pression and two natural number expressions. Deo/ne semantics and constant-folding
functions for this new language. Your constant folding should simplify not just bi-
nary operations (returning naturals or booleans) with known arguments, but also "if"
expressions with known values for their test expressions but possibly undetermined
"then" and "else" cases. Prove that constant-folding a natural number expression
preserves its meaning.

4. Using a reAEexive inductive deo/nition, deo/ne a type nat tree of ino/nitary trees, with

natural numbers at their leaves and a countable ino/nity of new trees branching out of
each internal node. Deo/ne a function increment that increments the number in every
leaf of a nat tree. Deo/ne a function leapfrog over a natural i and a tree nt. leapfrog
should recurse into the ith child of nt, the i+1st child of that node, the i+2nd child of
the next node, and so on, until reaching a leaf, in which case leapfrog should return
the number at that leaf. Prove that the result of any call to leapfrog is incremented by
one by calling increment on the tree.

5. Deo/ne a type of trees of trees of trees of (repeat to ino/nity). That is, deo/ne an inductive

type trexp, whose members are either base cases containing natural numbers or binary
trees of trexps. Base your deo/nition on a parameterized binary tree type btree that you
will also deo/ne, so that trexp is deo/ned as a nested inductive type. Deo/ne a function
total that sums all of the naturals at the leaves of a trexp. Deo/ne a function increment
that increments every leaf of a trexp by one. Prove that, for all tr, total (increment
tr ) >= total tr. On the way to o/nishing this proof, you will probably want to prove a
lemma and add it as a hint using the syntax Hint Resolve name of lemma..

6. Prove discrimination and injectivity theorems for the nat btree type deo/ned earlier

in this chapter. In particular, without using the tactics discriminate, injection, or
congruence, prove that no leaf equals any node, and prove that two equal nodes carry
the same natural number.

61

Chapter 4
Inductive Predicates

The so-called "Curry-Howard Correspondence" states a formal connection between func-
tional programs and mathematical proofs. In the last chapter, we snuck in a o/rst introduc-
tion to this subject in Coq. Witness the close similarity between the types unit and True
from the standard library:

Print unit.

Inductive unit : Set := tt : unit
Print True.

Inductive True : Prop := I : True

Recall that unit is the type with only one value, and True is the proposition that always
holds. Despite this supero/cial dioeerence between the two concepts, in both cases we can
use the same inductive deo/nition mechanism. The connection goes further than this. We
see that we arrive at the deo/nition of True by replacing unit by True, tt by I, and Set by
Prop. The o/rst two of these dioeerences are supero/cial changes of names, while the third
dioeerence is the crucial one for separating programs from proofs. A term T of type Set is a
type of programs, and a term of type T is a program. A term T of type Prop is a logical
proposition, and its proofs are of type T .

unit has one value, tt. True has one proof, I. Why distinguish between these two types?
Many people who have read about Curry-Howard in an abstract context and not put it
to use in proof engineering answer that the two types in fact should not be distinguished.
There is a certain aesthetic appeal to this point of view, but I want to argue that it is best
to treat Curry-Howard very loosely in practical proving. There are Coq-specio/c reasons for
preferring the distinction, involving eOEcient compilation and avoidance of paradoxes in the
presence of classical math, but I will argue that there is a more general principle that should
lead us to avoid conAEating programming and proving.

The essence of the argument is roughly this: to an engineer, not all functions of type A !
B are created equal, but all proofs of a proposition P ! Q are. This idea is known as proof
irrelevance, and its formalizations in logics prevent us from distinguishing between alternate
proofs of the same proposition. Proof irrelevance is compatible with, but not derivable in,

62

Gallina. Apart from this theoretical concern, I will argue that it is most eoeective to do
engineering with Coq by employing dioeerent techniques for programs versus proofs. Most
of this book is organized around that distinction, describing how to program, by applying
standard functional programming techniques in the presence of dependent types; and how
to prove, by writing custom Ltac decision procedures.

With that perspective in mind, this chapter is sort of a mirror image of the last chapter,
introducing how to deo/ne predicates with inductive deo/nitions. We will point out similarities
in places, but much of the eoeective Coq user's bag of tricks is disjoint for predicates versus
"datatypes." This chapter is also a covert introduction to dependent types, which are the
foundation on which interesting inductive predicates are built, though we will rely on tactics
to build dependently-typed proof terms for us for now. A future chapter introduces more
manual application of dependent types.

4.1 Propositional Logic
Let us begin with a brief tour through the deo/nitions of the connectives for propositional
logic. We will work within a Coq section that provides us with a set of propositional variables.
In Coq parlance, these are just terms of type Prop.

Section Propositional.

Variables P Q R : Prop.

In Coq, the most basic propositional connective is implication, written !, which we have
already used in almost every proof. Rather than being deo/ned inductively, implication is
built into Coq as the function type constructor.

We have also already seen the deo/nition of True. For a demonstration of a lower-level
way of establishing proofs of inductive predicates, we turn to this trivial theorem.

Theorem obvious : True.

apply I.
Qed.

We may always use the apply tactic to take a proof step based on applying a particular
constructor of the inductive predicate that we are trying to establish. Sometimes there is
only one constructor that could possibly apply, in which case a shortcut is available:

Theorem obvious' : True.

constructor.
Qed.

There is also a predicate False, which is the Curry-Howard mirror image of Empty set
from the last chapter.

Print False.
Inductive False : Prop :=

63

We can conclude anything from False, doing case analysis on a proof of False in the
same way we might do case analysis on, say, a natural number. Since there are no cases to
consider, any such case analysis succeeds immediately in proving the goal.

Theorem False imp : False ! 2 + 2 = 5.

destruct 1.
Qed.

In a consistent context, we can never build a proof of False. In inconsistent contexts
that appear in the courses of proofs, it is usually easiest to proceed by demonstrating that
inconsistency with an explicit proof of False.

Theorem arith neq : 2 + 2 = 5 ! 9 + 9 = 835.

intro.

At this point, we have an inconsistent hypothesis 2 + 2 = 5, so the specio/c conclusion is
not important. We use the elimtype tactic to state a proposition, telling Coq that we wish
to construct a proof of the new proposition and then prove the original goal by case analysis
on the structure of the new auxiliary proof. Since False has no constructors, elimtype False
simply leaves us with the obligation to prove False.

elimtype False.

H : 2 + 2 = 5
============================

False

For now, we will leave the details of this proof about arithmetic to crush.

crush.
Qed.

A related notion to False is logical negation.
Print not.

not = fun A : Prop ) A ! False

: Prop ! Prop

We see that not is just shorthand for implication of False. We can use that fact explicitly
in proofs. The syntax \Lambda P expands to not P .

Theorem arith neq' : ~ (2 + 2 = 5).

unfold not.

============================

2 + 2 = 5 ! False

crush.
Qed.

64

We also have conjunction, which we introduced in the last chapter.
Print and.
Inductive and (A : Prop) (B : Prop) : Prop := conj : A ! B ! A ^ B

The interested reader can check that and has a Curry-Howard doppelganger called prod,
the type of pairs. However, it is generally most convenient to reason about conjunction
using tactics. An explicit proof of commutativity of and illustrates the usual suspects for
such tasks. ^ is an ino/x shorthand for and.

Theorem and comm : P ^ Q ! Q ^ P.

We start by case analysis on the proof of P ^ Q .

destruct 1.

H : P
H0 : Q
============================

Q ^ P

Every proof of a conjunction provides proofs for both conjuncts, so we get a single subgoal
reAEecting that. We can proceed by splitting this subgoal into a case for each conjunct of Q^

P .

split.

2 subgoals

H : P
H0 : Q
============================

Q

subgoal 2 is:

P

In each case, the conclusion is among our hypotheses, so the assumption tactic o/nishes
the process.

assumption.
assumption.
Qed.

Coq disjunction is called or and abbreviated with the ino/x operator ..
Print or.
Inductive or (A : Prop) (B : Prop) : Prop :=

65

or introl : A ! A . B | or intror : B ! A . B
We see that there are two ways to prove a disjunction: prove the o/rst disjunct or prove
the second. The Curry-Howard analogue of this is the Coq sum type. We can demonstrate
the main tactics here with another proof of commutativity.

Theorem or comm : P . Q ! Q . P.

As in the proof for and, we begin with case analysis, though this time we are met by two
cases instead of one.

destruct 1.

2 subgoals

H : P
============================

Q . P

subgoal 2 is:

Q . P

We can see that, in the o/rst subgoal, we want to prove the disjunction by proving its
second disjunct. The right tactic telegraphs this intent.

right ; assumption.
The second subgoal has a symmetric proof.

1 subgoal

H : Q
============================

Q . P

left ; assumption.
Qed.

It would be a shame to have to plod manually through all proofs about propositional
logic. Luckily, there is no need. One of the most basic Coq automation tactics is tauto,
which is a complete decision procedure for constructive propositional logic. (More on what
"constructive" means in the next section.) We can use tauto to dispatch all of the purely
propositional theorems we have proved so far.

Theorem or comm' : P . Q ! Q . P.

tauto.
Qed.

Sometimes propositional reasoning forms important plumbing for the proof of a theorem,

66

but we still need to apply some other smarts about, say, arithmetic. intuition is a gener-
alization of tauto that proves everything it can using propositional reasoning. When some
goals remain, it uses propositional laws to simplify them as far as possible. Consider this
example, which uses the list concatenation operator ++ from the standard library.

Theorem arith comm : 8 ls1 ls2 : list nat,

length ls1 = length ls2 . length ls1 + length ls2 = 6!

length (ls1 ++ ls2 ) = 6 . length ls1 = length ls2.
intuition.

A lot of the proof structure has been generated for us by intuition, but the o/nal proof
depends on a fact about lists. The remaining subgoal hints at what cleverness we need to
inject.

ls1 : list nat
ls2 : list nat
H0 : length ls1 + length ls2 = 6
============================

length (ls1 ++ ls2 ) = 6 . length ls1 = length ls2

We can see that we need a theorem about lengths of concatenated lists, which we proved
last chapter and is also in the standard library.

rewrite app length.

ls1 : list nat
ls2 : list nat
H0 : length ls1 + length ls2 = 6
============================

length ls1 + length ls2 = 6 . length ls1 = length ls2

Now the subgoal follows by purely propositional reasoning. That is, we could replace
length ls1 + length ls2 = 6 with P and length ls1 = length ls2 with Q and arrive at a
tautology of propositional logic.

tauto.
Qed.

intuition is one of the main bits of glue in the implementation of crush, so, with a little
help, we can get a short automated proof of the theorem.

Theorem arith comm' : 8 ls1 ls2 : list nat,

length ls1 = length ls2 . length ls1 + length ls2 = 6!

length (ls1 ++ ls2 ) = 6 . length ls1 = length ls2.
Hint Rewrite app length : cpdt.

crush.

67

Qed.
End Propositional.

4.2 What Does It Mean to Be Constructive?
One potential point of confusion in the presentation so far is the distinction between bool
and Prop. bool is a datatype whose two values are true and false, while Prop is a more
primitive type that includes among its members True and False. Why not collapse these
two concepts into one, and why must there be more than two states of mathematical truth?

The answer comes from the fact that Coq implements constructive or intuitionistic logic,
in contrast to the classical logic that you may be more familiar with. In constructive logic,
classical tautologies like ~ ~ P ! P and P . ~ P do not always hold. In general, we can
only prove these tautologies when P is decidable, in the sense of computability theory. The
Curry-Howard encoding that Coq uses for or allows us to extract either a proof of P or a
proof of ~ P from any proof of P . ~ P . Since our proofs are just functional programs
which we can run, this would give us a decision procedure for the halting problem, where
the instantiations of P would be formulas like "this particular Turing machine halts."

Hence the distinction between bool and Prop. Programs of type bool are computational
by construction; we can always run them to determine their results. Many Props are unde-
cidable, and so we can write more expressive formulas with Props than with bools, but the
inevitable consequence is that we cannot simply "run a Prop to determine its truth."

Constructive logic lets us deo/ne all of the logical connectives in an aesthetically-appealing
way, with orthogonal inductive deo/nitions. That is, each connective is deo/ned independently
using a simple, shared mechanism. Constructivity also enables a trick called program extrac-
tion, where we write programs by phrasing them as theorems to be proved. Since our proofs
are just functional programs, we can extract executable programs from our o/nal proofs,
which we could not do as naturally with classical proofs.

We will see more about Coq's program extraction facility in a later chapter. However, I
think it is worth interjecting another warning at this point, following up on the prior warning
about taking the Curry-Howard correspondence too literally. It is possible to write programs
by theorem-proving methods in Coq, but hardly anyone does it. It is almost always most
useful to maintain the distinction between programs and proofs. If you write a program by
proving a theorem, you are likely to run into algorithmic ineOEciencies that you introduced
in your proof to make it easier to prove. It is a shame to have to worry about such situations
while proving tricky theorems, and it is a happy state of aoeairs that you almost certainly
will not need to, with the ideal of extracting programs from proofs being cono/ned mostly to
theoretical studies.

68

4.3 First-Order Logic
The 8 connective of o/rst-order logic, which we have seen in many examples so far, is built
into Coq. Getting ahead of ourselves a bit, we can see it as the dependent function type
constructor. In fact, implication and universal quantio/cation are just dioeerent syntactic
shorthands for the same Coq mechanism. A formula P ! Q is equivalent to 8 x : P , Q,
where x does not appear in Q . That is, the "real" type of the implication says "for every
proof of P , there exists a proof of Q ."

Existential quantio/cation is deo/ned in the standard library.

Print ex.

Inductive ex (A : Type) (P : A ! Prop) : Prop :=

ex intro : 8 x : A, P x ! ex P

ex is parameterized by the type A that we quantify over, and by a predicate P over As.
We prove an existential by exhibiting some x of type A, along with a proof of P x . As usual,
there are tactics that save us from worrying about the low-level details most of the time. We
use the equality operator =, which, depending on the settings in which they learned logic,
dioeerent people will say either is or is not part of o/rst-order logic. For our purposes, it is.

Theorem exist1 : 9 x : nat, x + 1 = 2.

We can start this proof with a tactic exists, which should not be confused with the formula
constructor shorthand of the same name. (In the PDF version of this document, the reverse
'E' appears instead of the text "exists" in formulas.)

exists 1.

The conclusion is replaced with a version using the existential witness that we announced.

============================

1 + 1 = 2

reflexivity.
Qed.

We can also use tactics to reason about existential hypotheses.
Theorem exist2 : 8 n m : nat, (9 x : nat, n + x = m) ! n <= m.

We start by case analysis on the proof of the existential fact.

destruct 1.

n : nat
m : nat
x : nat
H : n + x = m
============================

69

n <= m
The goal has been replaced by a form where there is a new free variable x , and where we
have a new hypothesis that the body of the existential holds with x substituted for the old
bound variable. From here, the proof is just about arithmetic and is easy to automate.

crush.
Qed.

The tactic intuition has a o/rst-order cousin called firstorder. firstorder proves
many formulas when only o/rst-order reasoning is needed, and it tries to perform o/rst-order
simplio/cations in any case. First-order reasoning is much harder than propositional reason-
ing, so firstorder is much more likely than intuition to get stuck in a way that makes it
run for long enough to be useless.

4.4 Predicates with Implicit Equality
We start our exploration of a more complicated class of predicates with a simple example:
an alternative way of characterizing when a natural number is zero.

Inductive isZero : nat ! Prop :=|

IsZero : isZero 0.

Theorem isZero zero : isZero 0.

constructor.
Qed.

We can call isZero a judgment, in the sense often used in the semantics of programming
languages. Judgments are typically deo/ned in the style of natural deduction, where we write
a number of inference rules with premises appearing above a solid line and a conclusion
appearing below the line. In this example, the sole constructor IsZero of isZero can be
thought of as the single inference rule for deducing isZero, with nothing above the line and
isZero 0 below it. The proof of isZero zero demonstrates how we can apply an inference
rule.

The deo/nition of isZero dioeers in an important way from all of the other inductive
deo/nitions that we have seen in this and the previous chapter. Instead of writing just Set or
Prop after the colon, here we write nat ! Prop. We saw examples of parameterized types
like list, but there the parameters appeared with names before the colon. Every constructor
of a parameterized inductive type must have a range type that uses the same parameter,
whereas the form we use here enables us to use dioeerent arguments to the type for dioeerent
constructors.

For instance, isZero forces its argument to be 0. We can see that the concept of equality
is somehow implicit in the inductive deo/nition mechanism. The way this is accomplished is
similar to the way that logic variables are used in Prolog, and it is a very powerful mechanism
that forms a foundation for formalizing all of mathematics. In fact, though it is natural to

70

think of inductive types as folding in the functionality of equality, in Coq, the true situation
is reversed, with equality deo/ned as just another inductive type!

Print eq.

Inductive eq (A : Type) (x : A) : A ! Prop := reAE equal : x = x

eq is the type we get behind the scenes when uses of ino/x = are expanded. We see that
eq has both a parameter x that is o/xed and an extra unnamed argument of the same type.
The type of eq allows us to state any equalities, even those that are provably false. However,
examining the type of equality's sole constructor reAE equal, we see that we can only prove
equality when its two arguments are syntactically equal. This deo/nition turns out to capture
all of the basic properties of equality, and the equality-manipulating tactics that we have
seen so far, like reflexivity and rewrite, are implemented treating eq as just another
inductive type with a well-chosen deo/nition.

Returning to the example of isZero, we can see how to make use of hypotheses that use
this predicate.

Theorem isZero plus : 8 n m : nat, isZero m ! n + m = n.

We want to proceed by cases on the proof of the assumption about isZero.

destruct 1.

n : nat
============================

n + 0 = n

Since isZero has only one constructor, we are presented with only one subgoal. The
argument m to isZero is replaced with that type's argument from the single constructor
IsZero. From this point, the proof is trivial.

crush.
Qed.

Another example seems at o/rst like it should admit an analogous proof, but in fact
provides a demonstration of one of the most basic gotchas of Coq proving.

Theorem isZero contra : isZero 1 ! False.

Let us try a proof by cases on the assumption, as in the last proof.

destruct 1.

============================

False

It seems that case analysis has not helped us much at all! Our sole hypothesis disappears,
leaving us, if anything, worse ooe than we were before. What went wrong? We have met an
important restriction in tactics like destruct and induction when applied to types with

71

arguments. If the arguments are not already free variables, they will be replaced by new
free variables internally before doing the case analysis or induction. Since the argument 1 to
isZero is replaced by a fresh variable, we lose the crucial fact that it is not equal to 0.

Why does Coq use this restriction? We will discuss the issue in detail in a future chapter,
when we see the dependently-typed programming techniques that would allow us to write
this proof term manually. For now, we just say that the algorithmic problem of "logically
complete case analysis" is undecidable when phrased in Coq's logic. A few tactics and design
patterns that we will present in this chapter suOEce in almost all cases. For the current
example, what we want is a tactic called inversion, which corresponds to the concept of
inversion that is frequently used with natural deduction proof systems.

Undo.
inversion 1.
Qed.

What does inversion do? Think of it as a version of destruct that does its best to
take advantage of the structure of arguments to inductive types. In this case, inversion
completed the proof immediately, because it was able to detect that we were using isZero
with an impossible argument.

Sometimes using destruct when you should have used inversion can lead to confusing
results. To illustrate, consider an alternate proof attempt for the last theorem.

Theorem isZero contra' : isZero 1 ! 2 + 2 = 5.

destruct 1.

============================

1 + 1 = 4

What on earth happened here? Internally, destruct replaced 1 with a fresh variable,
and, trying to be helpful, it also replaced the occurrence of 1 within the unary representation
of each number in the goal. This has the net eoeect of decrementing each of these numbers.
If you are doing a proof and encounter a strange transmutation like this, there is a good
chance that you should go back and replace a use of destruct with inversion.

Abort.

4.5 Recursive Predicates
We have already seen all of the ingredients we need to build interesting recursive predicates,
like this predicate capturing even-ness.

Inductive even : nat ! Prop :=|

EvenO : even O|
EvenSS : 8 n, even n ! even (S (S n)).

72

Think of even as another judgment deo/ned by natural deduction rules. EvenO is a rule
with nothing above the line and even O below the line, and EvenSS is a rule with even n
above the line and even (S (S n)) below.

The proof techniques of the last section are easily adapted.

Theorem even 0 : even 0.

constructor.
Qed.

Theorem even 4 : even 4.

constructor ; constructor ; constructor.
Qed.

It is not hard to see that sequences of constructor applications like the above can get
tedious. We can avoid them using Coq's hint facility.

Hint Constructors even.
Theorem even 4' : even 4.

auto.
Qed.

Theorem even 1 contra : even 1 ! False.

inversion 1.
Qed.

Theorem even 3 contra : even 3 ! False.

inversion 1.

H : even 3
n : nat
H1 : even 1
H0 : n = 1
============================

False

inversion can be a little overzealous at times, as we can see here with the introduction of
the unused variable n and an equality hypothesis about it. For more complicated predicates,
though, adding such assumptions is critical to dealing with the undecidability of general
inversion.

inversion H1.
Qed.

We can also do inductive proofs about even.
Theorem even plus : 8 n m, even n ! even m ! even (n + m).

It seems a reasonable o/rst choice to proceed by induction on n.

induction n; crush.

73

n : nat
IHn : 8 m : nat, even n ! even m ! even (n + m)
m : nat
H : even (S n)
H0 : even m
============================

even (S (n + m))

We will need to use the hypotheses H and H0 somehow. The most natural choice is to
invert H.

inversion H.

n : nat
IHn : 8 m : nat, even n ! even m ! even (n + m)
m : nat
H : even (S n)
H0 : even m
n0 : nat
H2 : even n0
H1 : S n0 = n
============================

even (S (S n0 + m))

Simplifying the conclusion brings us to a point where we can apply a constructor.
simpl.

============================

even (S (S (n0 + m)))

constructor.

============================

even (n0 + m)

At this point, we would like to apply the inductive hypothesis, which is:

IHn : 8 m : nat, even n ! even m ! even (n + m)

Unfortunately, the goal mentions n0 where it would need to mention n to match IHn.
We could keep looking for a way to o/nish this proof from here, but it turns out that we
can make our lives much easier by changing our basic strategy. Instead of inducting on the

74

structure of n, we should induct on the structure of one of the even proofs. This technique is
commonly called rule induction in programming language semantics. In the setting of Coq,
we have already seen how predicates are deo/ned using the same inductive type mechanism as
datatypes, so the fundamental unity of rule induction with "normal" induction is apparent.

Restart.

induction 1.

m : nat
============================

even m ! even (0 + m)

subgoal 2 is:

even m ! even (S (S n) + m)

The o/rst case is easily discharged by crush, based on the hint we added earlier to try the
constructors of even.

crush.

Now we focus on the second case:
intro.

m : nat
n : nat
H : even n
IHeven : even m ! even (n + m)
H0 : even m
============================

even (S (S n) + m)

We simplify and apply a constructor, as in our last proof attempt.
simpl; constructor.

============================

even (n + m)

Now we have an exact match with our inductive hypothesis, and the remainder of the
proof is trivial.

apply IHeven; assumption.

In fact, crush can handle all of the details of the proof once we declare the induction
strategy.

Restart.

75

induction 1; crush.
Qed.

Induction on recursive predicates has similar pitfalls to those we encountered with inver-
sion in the last section.

Theorem even contra : 8 n, even (S (n + n)) ! False.

induction 1.

n : nat
============================

False

subgoal 2 is:

False

We are already sunk trying to prove the o/rst subgoal, since the argument to even was
replaced by a fresh variable internally. This time, we o/nd it easiest to prove this theorem by
way of a lemma. Instead of trusting induction to replace expressions with fresh variables,
we do it ourselves, explicitly adding the appropriate equalities as new assumptions.

Abort.
Lemma even contra' : 8 n', even n' ! 8 n, n' = S (n + n) ! False.

induction 1; crush.

At this point, it is useful to consider all cases of n and n0 being zero or nonzero. Only
one of these cases has any trickiness to it.

destruct n; destruct n0 ; crush.

n : nat
H : even (S n)
IHeven : 8 n0 : nat, S n = S (n0 + n0 ) ! False
n0 : nat
H0 : S n = n0 + S n0
============================

False

At this point it is useful to use a theorem from the standard library, which we also proved
with a dioeerent name in the last chapter.

Check plus n Sm.
plus n Sm

: 8 n m : nat, S (n + m) = n + S m

rewrite  plus n Sm in H0.

The induction hypothesis lets us complete the proof.

76

apply IHeven with n0 ; assumption.

As usual, we can rewrite the proof to avoid referencing any locally-generated names,
which makes our proof script more readable and more robust to changes in the theorem
statement. We use the notation  to request a hint that does right-to-left rewriting, just
like we can with the rewrite tactic.

Restart.
Hint Rewrite  plus n Sm : cpdt.

induction 1; crush;

match goal with|

[ H : S ?N = ?N0 + ?N0 ` ] ) destruct N ; destruct N0
end; crush; eauto.
Qed.

We write the proof in a way that avoids the use of local variable or hypothesis names,
using the match tactic form to do pattern-matching on the goal. We use unio/cation variables
preo/xed by question marks in the pattern, and we take advantage of the possibility to mention
a unio/cation variable twice in one pattern, to enforce equality between occurrences. The hint
to rewrite with plus n Sm in a particular direction saves us from having to o/gure out the
right place to apply that theorem, and we also take critical advantage of a new tactic, eauto.

crush uses the tactic intuition, which, when it runs out of tricks to try using only
propositional logic, by default tries the tactic auto, which we saw in an earlier example.
auto attempts Prolog-style logic programming, searching through all proof trees up to a cer-
tain depth that are built only out of hints that have been registered with Hint commands.
Compared to Prolog, auto places an important restriction: it never introduces new unio/ca-
tion variables during search. That is, every time a rule is applied during proof search, all
of its arguments must be deducible by studying the form of the goal. eauto relaxes this
restriction, at the cost of possibly exponentially greater running time. In this particular
case, we know that eauto has only a small space of proofs to search, so it makes sense to
run it. It is common in eoeectively-automated Coq proofs to see a bag of standard tactics
applied to pick ooe the "easy" subgoals, o/nishing with eauto to handle the tricky parts that
can beneo/t from ad-hoc exhaustive search.

The original theorem now follows trivially from our lemma.

Theorem even contra : 8 n, even (S (n + n)) ! False.

intros; eapply even contra'; eauto.
Qed.

We use a variant eapply of apply which has the same relationship to apply as eauto has
to auto. apply only succeeds if all arguments to the rule being used can be determined from
the form of the goal, whereas eapply will introduce unio/cation variables for undetermined
arguments. eauto is able to determine the right values for those unio/cation variables.

By considering an alternate attempt at proving the lemma, we can see another common
pitfall of inductive proofs in Coq. Imagine that we had tried to prove even contra' with all
of the 8 quantio/ers moved to the front of the lemma statement.

77

Lemma even contraj : 8 n' n, even n' ! n' = S (n + n) ! False.

induction 1; crush;

match goal with|

[ H : S ?N = ?N0 + ?N0 ` ] ) destruct N ; destruct N0
end; crush; eauto.

One subgoal remains:

n : nat
H : even (S (n + n))
IHeven : S (n + n) = S (S (S (n + n))) ! False
============================

False

We are out of luck here. The inductive hypothesis is trivially true, since its assumption
is false. In the version of this proof that succeeded, IHeven had an explicit quantio/cation
over n. This is because the quantio/cation of n appeared after the thing we are inducting
on in the theorem statement. In general, quantio/ed variables and hypotheses that appear
before the induction object in the theorem statement stay o/xed throughout the inductive
proof. Variables and hypotheses that are quantio/ed after the induction object may be varied
explicitly in uses of inductive hypotheses.

Why should Coq implement induction this way? One answer is that it avoids burdening
this basic tactic with additional heuristic smarts, but that is not the whole picture. Imagine
that induction analyzed dependencies among variables and reordered quantio/ers to pre-
serve as much freedom as possible in later uses of inductive hypotheses. This could make
the inductive hypotheses more complex, which could in turn cause particular automation
machinery to fail when it would have succeeded before. In general, we want to avoid quan-
tio/ers in our proofs whenever we can, and that goal is furthered by the refactoring that the
induction tactic forces us to do.

Abort.

4.6 Exercises

1. Prove these tautologies of propositional logic, using only the tactics apply, assumption,

constructor, destruct, intro, intros, left, right, split, and unfold.

(a) (True . False) ^ (False . True)
(b) P ! ~ ~ P

(c) P ^ (Q . R) ! (P ^ Q ) . (P ^ R)

2. Prove the following tautology of o/rst-order logic, using only the tactics apply, assert,

assumption, destruct, eapply, eassumption, and exists. You will probably o/nd

78

assert useful for stating and proving an intermediate lemma, enabling a kind of "for-
ward reasoning," in contrast to the "backward reasoning" that is the default for Coq
tactics. eassumption is a version of assumption that will do matching of unio/cation
variables. Let some variable T of type Set be the set of individuals. x is a constant
symbol, p is a unary predicate symbol, q is a binary predicate symbol, and f is a unary
function symbol.

(a) p x ! (8 x , p x ! 9 y, q x y ) ! (8 x y, q x y ! q y (f y)) ! 9 z , q z (f z )
3. Deo/ne an inductive predicate capturing when a natural number is an integer multiple

of either 6 or 10. Prove that 13 does not satisfy your predicate, and prove that any
number satisfying the predicate is not odd. It is probably easiest to prove the second
theorem by indicating "odd-ness" as equality to 2 * n + 1 for some n.

4. Deo/ne a simple programming language, its semantics, and its typing rules, and then

prove that well-typed programs cannot go wrong. Specio/cally:

(a) Deo/ne var as a synonym for the natural numbers.
(b) Deo/ne an inductive type exp of expressions, containing natural number constants,

natural number addition, pairing of two other expressions, extraction of the o/rst
component of a pair, extraction of the second component of a pair, and variables
(based on the var type you deo/ned).

(c) Deo/ne an inductive type cmd of commands, containing expressions and variable

assignments. A variable assignment node should contain the variable being as-
signed, the expression being assigned to it, and the command to run afterward.

(d) Deo/ne an inductive type val of values, containing natural number constants and

pairings of values.

(e) Deo/ne a type of variable assignments, which assign a value to each variable.

(f) Deo/ne a big-step evaluation relation eval, capturing what it means for an expres-

sion to evaluate to a value under a particular variable assignment. "Big step"
means that the evaluation of every expression should be proved with a single in-
stance of the inductive predicate you will deo/ne. For instance, "1 + 1 evaluates
to 2 under assignment va" should be derivable for any assignment va.

(g) Deo/ne a big-step evaluation relation run, capturing what it means for a command

to run to a value under a particular variable assignment. The value of a command
is the result of evaluating its o/nal expression.

(h) Deo/ne a type of variable typings, which are like variable assignments, but map

variables to types instead of values. You might use polymorphism to share some
code with your variable assignments.

(i) Deo/ne typing judgments for expressions, values, and commands. The expression

and command cases will be in terms of a typing assignment.

79

(j) Deo/ne a predicate varsType to express when a variable assignment and a variable

typing agree on the types of variables.

(k) Prove that any expression that has type t under variable typing vt evaluates under

variable assignment va to some value that also has type t in vt, as long as va and
vt agree.

(l) Prove that any command that has type t under variable typing vt evaluates under

variable assignment va to some value that also has type t in vt, as long as va and
vt agree.

A few hints that may be helpful:

(a) One easy way of deo/ning variable assignments and typings is to deo/ne both as in-

stances of a polymorphic map type. The map type at parameter T can be deo/ned
to be the type of arbitrary functions from variables to T . A helpful function for
implementing insertion into such a functional map is eq nat dec, which you can
make available with Require Import Arith.. eq nat dec has a dependent type
that tells you that it makes accurate decisions on whether two natural numbers
are equal, but you can use it as if it returned a boolean, e.g., if eq nat dec n m
then E1 else E2.

(b) If you follow the last hint, you may o/nd yourself writing a proof that involves an

expression with eq nat dec that you would like to simplify. Running destruct
on the particular call to eq nat dec should do the trick. You can automate this
advice with a piece of Ltac:

match goal with|

[ ` context [eq nat dec ?X ?Y] ] ) destruct (eq nat dec X Y )
end

(c) You probably do not want to use an inductive deo/nition for compatibility of

variable assignments and typings.

(d) The Tactics module from this book contains a variant crush' of crush. crush' takes

two arguments. The o/rst argument is a list of lemmas and other functions to be
tried automatically in "forward reasoning" style, where we add new facts without
being sure yet that they link into a proof of the conclusion. The second argument
is a list of predicates on which inverison should be attempted automatically. For
instance, running crush' (lemma1, lemma2) pred will search for chances to apply
lemma1 and lemma2 to hypotheses that are already available, adding the new
concluded fact if suitable hypotheses can be found. Inversion will be attempted
on any hypothesis using pred, but only those inversions that narrow the o/eld of
possibilities to one possible rule will be kept. The format of the list arguments to
crush' is that you can pass an empty list as tt, a singleton list as the unadorned
single element, and a multiple-element list as a tuple of the elements.

80

(e) If you want crush' to apply polymorphic lemmas, you may have to do a little

extra work, if the type parameter is not a free variable of your proof context (so
that crush' does not know to try it). For instance, if you deo/ne a polymorphic
map insert function assign of some type 8 T : Set, ..., and you want particular
applications of assign added automatically with type parameter U, you would need
to include assign in the lemma list as assign U (if you have implicit arguments
ooe) or assign (T := U ) or @assign U (if you have implicit arguments on).

81
Chapter 5
Ino/nite Data and Proofs

In lazy functional programming languages like Haskell, ino/nite data structures are every-
where. Ino/nite lists and more exotic datatypes provide convenient abstractions for commu-
nication between parts of a program. Achieving similar convenience without ino/nite lazy
structures would, in many cases, require acrobatic inversions of control AEow.

Laziness is easy to implement in Haskell, where all the deo/nitions in a program may be
thought of as mutually recursive. In such an unconstrained setting, it is easy to implement
an ino/nite loop when you really meant to build an ino/nite list, where any o/nite preo/x of the
list should be forceable in o/nite time. Haskell programmers learn how to avoid such slip-ups.
In Coq, such a laissez-faire policy is not good enough.

We spent some time in the last chapter discussing the Curry-Howard isomorphism, where
proofs are identio/ed with functional programs. In such a setting, ino/nite loops, intended or
otherwise, are disastrous. If Coq allowed the full breadth of deo/nitions that Haskell did, we
could code up an ino/nite loop and use it to prove any proposition vacuously. That is, the
addition of general recursion would make CIC inconsistent. For an arbitrary proposition P ,
we could write:

Fixpoint bad (u : unit) : P := bad u.

This would leave us with bad tt as a proof of P .
There are also algorithmic considerations that make universal termination very desirable.
We have seen how tactics like reflexivity compare terms up to equivalence under compu-
tational rules. Calls to recursive, pattern-matching functions are simplio/ed automatically,
with no need for explicit proof steps. It would be very hard to hold onto that kind of beneo/t
if it became possible to write non-terminating programs; we would be running smack into
the halting problem.

One solution is to use types to contain the possibility of non-termination. For instance,
we can create a "non-termination monad," inside which we must write all of our general-
recursive programs. This is a heavyweight solution, and so we would like to avoid it whenever
possible.

82

Luckily, Coq has special support for a class of lazy data structures that happens to
contain most examples found in Haskell. That mechanism, co-inductive types, is the subject
of this chapter.

5.1 Computing with Ino/nite Data
Let us begin with the most basic type of ino/nite data, streams, or lazy lists.
Section stream.

Variable A : Set.

CoInductive stream : Set :=|

Cons : A ! stream ! stream.
End stream.

The deo/nition is surprisingly simple. Starting from the deo/nition of list, we just need to
change the keyword Inductive to CoInductive. We could have left a Nil constructor in our
deo/nition, but we will leave it out to force all of our streams to be ino/nite.

How do we write down a stream constant? Obviously simple application of constructors
is not good enough, since we could only denote o/nite objects that way. Rather, whereas
recursive deo/nitions were necessary to use values of recursive inductive types eoeectively, here
we o/nd that we need co-recursive deo/nitions to build values of co-inductive types eoeectively.

We can deo/ne a stream consisting only of zeroes.

CoFixpoint zeroes : stream nat := Cons 0 zeroes.

We can also deo/ne a stream that alternates between true and false.
CoFixpoint trues : stream bool := Cons true falses
with falses : stream bool := Cons false trues.

Co-inductive values are fair game as arguments to recursive functions, and we can use
that fact to write a function to take a o/nite approximation of a stream.

Fixpoint approx A (s : stream A) (n : nat) : list A :=

match n with|

O ) nil|
S n' )

match s with|

Cons h t ) h :: approx t n'
end
end.

Eval simpl in approx zeroes 10.

= 0 :: 0 :: 0 :: 0 :: 0 :: 0 :: 0 :: 0 :: 0 :: 0 :: nil
: list nat

Eval simpl in approx trues 10.

83

= true

:: false

:: true

:: false

:: true :: false :: true :: false :: true :: false :: nil
: list bool

So far, it looks like co-inductive types might be a magic bullet, allowing us to import all
of the Haskeller's usual tricks. However, there are important restrictions that are dual to
the restrictions on the use of inductive types. Fixpoints consume values of inductive types,
with restrictions on which arguments may be passed in recursive calls. Dually, co-o/xpoints
produce values of co-inductive types, with restrictions on what may be done with the results
of co-recursive calls.

The restriction for co-inductive types shows up as the guardedness condition, and it can
be broken into two parts. First, consider this stream deo/nition, which would be legal in
Haskell.

CoFixpoint looper : stream nat := looper.
Error :
Recursive deo/nition of looper is ill -formed.
In environment
looper : stream nat

unguarded recursive call in "looper"

The rule we have run afoul of here is that every co-recursive call must be guarded by a
constructor ; that is, every co-recursive call must be a direct argument to a constructor of
the co-inductive type we are generating. It is a good thing that this rule is enforced. If the
deo/nition of looper were accepted, our approx function would run forever when passed looper,
and we would have fallen into inconsistency.

The second rule of guardedness is easiest to see by o/rst introducing a more complicated,
but legal, co-o/xpoint.

Section map.

Variables A B : Set.
Variable f : A ! B.

CoFixpoint map (s : stream A) : stream B :=

match s with|

Cons h t ) Cons (f h) (map t )
end.
End map.

This code is a literal copy of that for the list map function, with the Nil case removed and

84

Fixpoint changed to CoFixpoint. Many other standard functions on lazy data structures
can be implemented just as easily. Some, like o/lter, cannot be implemented. Since the
predicate passed to o/lter may reject every element of the stream, we cannot satisfy even the
o/rst guardedness condition.

The second condition is subtler. To illustrate it, we start ooe with another co-recursive
function deo/nition that is legal. The function interleave takes two streams and produces a
new stream that alternates between their elements.

Section interleave.

Variable A : Set.

CoFixpoint interleave (s1 s2 : stream A) : stream A :=

match s1, s2 with|

Cons h1 t1, Cons h2 t2 ) Cons h1 (Cons h2 (interleave t1 t2 ))
end.
End interleave.

Now say we want to write a weird stuttering version of map that repeats elements in a
particular way, based on interleaving.

Section map'.

Variables A B : Set.
Variable f : A ! B.

CoFixpoint map' (s : stream A) : stream B :=

match s with|

Cons h t ) interleave (Cons (f h) (map' s)) (Cons (f h) (map' s))
end.

We get another error message about an unguarded recursive call. This is because we
are violating the second guardedness condition, which says that, not only must co-recursive
calls be arguments to constructors, there must also not be anything but matches and calls
to constructors of the same co-inductive type wrapped around these immediate uses of co-
recursive calls. The actual implemented rule for guardedness is a little more lenient than
what we have just stated, but you can count on the illegality of any exception that would
enhance the expressive power of co-recursion.

Why enforce a rule like this? Imagine that, instead of interleave, we had called some
other, less well-behaved function on streams. Perhaps this other function might be deo/ned
mutually with map'. It might deconstruct its o/rst argument, retrieving map' s from within
Cons (f h) (map' s). Next it might try a match on this retrieved value, which amounts to
deconstructing map' s. To o/gure out how this match turns out, we need to know the top-level
structure of map' s, but this is exactly what we started out trying to determine! We run
into a loop in the evaluation process, and we have reached a witness of inconsistency if we
are evaluating approx (map' s) 1 for any s.

End map'.

85

5.2 Ino/nite Proofs
Let us say we want to give two dioeerent deo/nitions of a stream of all ones, and then we want
to prove that they are equivalent.

CoFixpoint ones : stream nat := Cons 1 ones.
Definition ones' := map S zeroes.

The obvious statement of the equality is this:
Theorem ones eq : ones = ones'.

However, faced with the initial subgoal, it is not at all clear how this theorem can be
proved. In fact, it is unprovable. The eq predicate that we use is fundamentally limited to
equalities that can be demonstrated by o/nite, syntactic arguments. To prove this equivalence,
we will need to introduce a new relation.

Abort.

Co-inductive datatypes make sense by analogy from Haskell. What we need now is a
co-inductive proposition. That is, we want to deo/ne a proposition whose proofs may be
ino/nite, subject to the guardedness condition. The idea of ino/nite proofs does not show up
in usual mathematics, but it can be very useful (unsurprisingly) for reasoning about ino/nite
data structures. Besides examples from Haskell, ino/nite data and proofs will also turn out
to be useful for modelling inherently ino/nite mathematical objects, like program executions.

We are ready for our o/rst co-inductive predicate.

Section stream eq.

Variable A : Set.

CoInductive stream eq : stream A ! stream A ! Prop :=|

Stream eq : 8 h t1 t2,

stream eq t1 t2!

stream eq (Cons h t1 ) (Cons h t2 ).
End stream eq.

We say that two streams are equal if and only if they have the same heads and their tails
are equal. We use the normal o/nite-syntactic equality for the heads, and we refer to our new
equality recursively for the tails.

We can try restating the theorem with stream eq.

Theorem ones eq : stream eq ones ones'.

Coq does not support tactical co-inductive proofs as well as it supports tactical inductive
proofs. The usual starting point is the coo/x tactic, which asks to structure this proof as a
co-o/xpoint.

coo/x.

ones eq : stream eq ones ones'
============================

86

stream eq ones ones'
It looks like this proof might be easier than we expected!
assumption.

Proof completed.

Unfortunately, we are due for some disappointment in our victory lap.
Qed.
Error :
Recursive deo/nition of ones eq is ill -formed.

In environment
ones eq : stream eq ones ones'

unguarded recursive call in "ones eq"

Via the Curry-Howard correspondence, the same guardedness condition applies to our
co-inductive proofs as to our co-inductive data structures. We should be grateful that this
proof is rejected, because, if it were not, the same proof structure could be used to prove
any co-inductive theorem vacuously, by direct appeal to itself!

Thinking about how Coq would generate a proof term from the proof script above, we
see that the problem is that we are violating the o/rst part of the guardedness condition.
During our proofs, Coq can help us check whether we have yet gone wrong in this way. We
can run the command Guarded in any context to see if it is possible to o/nish the proof in a
way that will yield a properly guarded proof term.

Guarded.

Running Guarded here gives us the same error message that we got when we tried to run
Qed. In larger proofs, Guarded can be helpful in detecting problems before we think we are
ready to run Qed.

We need to start the co-induction by applying one of stream eq's constructors. To do
that, we need to know that both arguments to the predicate are Conses. Informally, this is
trivial, but simpl is not able to help us.

Undo.
simpl.

ones eq : stream eq ones ones'
============================

87

stream eq ones ones'
It turns out that we are best served by proving an auxiliary lemma.
Abort.

First, we need to deo/ne a function that seems pointless on o/rst glance.
Definition frob A (s : stream A) : stream A :=

match s with|

Cons h t ) Cons h t
end.

Next, we need to prove a theorem that seems equally pointless.
Theorem frob eq : 8 A (s : stream A), s = frob s.

destruct s; reflexivity.
Qed.

But, miraculously, this theorem turns out to be just what we needed.
Theorem ones eq : stream eq ones ones'.

coo/x.

We can use the theorem to rewrite the two streams.
rewrite (frob eq ones).
rewrite (frob eq ones').

ones eq : stream eq ones ones'
============================

stream eq (frob ones) (frob ones')

Now simpl is able to reduce the streams.
simpl.

ones eq : stream eq ones ones'
============================

stream eq (Cons 1 ones)

(Cons 1

((coo/x map (s : stream nat) : stream nat :=

match s with|

Cons h t ) Cons (S h) (map t )
end) zeroes))

Since we have exposed the Cons structure of each stream, we can apply the constructor
of stream eq.

constructor.

88

ones eq : stream eq ones ones'
============================

stream eq ones

((coo/x map (s : stream nat) : stream nat :=

match s with|

Cons h t ) Cons (S h) (map t )
end) zeroes)

Now, modulo unfolding of the deo/nition of map, we have matched our assumption.
assumption.
Qed.

Why did this silly-looking trick help? The answer has to do with the constraints placed
on Coq's evaluation rules by the need for termination. The coo/x -related restriction that
foiled our o/rst attempt at using simpl is dual to a restriction for o/x. In particular, an
application of an anonymous o/x only reduces when the top-level structure of the recursive
argument is known. Otherwise, we would be unfolding the recursive deo/nition ad ino/nitum.

Fixpoints only reduce when enough is known about the deo/nitions of their arguments.
Dually, co-o/xpoints only reduce when enough is known about how their results will be used.
In particular, a coo/x is only expanded when it is the discriminee of a match. Rewriting
with our supero/cially silly lemma wrapped new matches around the two coo/x es, triggering
reduction.

If coo/x es reduced haphazardly, it would be easy to run into ino/nite loops in evaluation,
since we are, after all, building ino/nite objects.

One common source of diOEculty with co-inductive proofs is bad interaction with standard
Coq automation machinery. If we try to prove ones eq' with automation, like we have in
previous inductive proofs, we get an invalid proof.

Theorem ones eq' : stream eq ones ones'.

coo/x ; crush.

Guarded.
Abort.

The standard auto machinery sees that our goal matches an assumption and so applies
that assumption, even though this violates guardedness. One usually starts a proof like this
by destructing some parameter and running a custom tactic to o/gure out the o/rst proof
rule to apply for each case. Alternatively, there are tricks that can be played with "hiding"
the co-inductive hypothesis.

89

5.3 Simple Modeling of Non-Terminating Programs
We close the chapter with a quick motivating example for more complex uses of co-inductive
types. We will deo/ne a co-inductive semantics for a simple assembly language and use that
semantics to prove that assembly programs always run forever. This basic technique can
be combined with typing judgments for more advanced languages, where some ill-typed
programs can go wrong, but no well-typed programs go wrong.

We deo/ne suggestive synonyms for nat, for cases where we use natural numbers as reg-
isters or program labels. That is, we consider our idealized machine to have ino/nitely many
registers and ino/nitely many code addresses.

Definition reg := nat.
Definition label := nat.

Our instructions are loading of a constant into a register, copying from one register to
another, unconditional jump, and conditional jump based on whether the value in a register
is not zero.

Inductive instr : Set :=|

Imm : reg ! nat ! instr|
Copy : reg ! reg ! instr|
Jmp : label ! instr|
Jnz : reg ! label ! instr.

We deo/ne a type regs of maps from registers to values. To deo/ne a function set for
setting a register's value in a map, we import the Arith module from Coq's standard library,
and we use its function eq nat dec for comparing natural numbers.

Definition regs := reg ! nat.
Require Import Arith.
Definition set (rs : regs) (r : reg) (v : nat) : regs :=

fun r' ) if eq nat dec r r' then v else rs r'.

An inductive exec judgment captures the eoeect of an instruction on the program counter
and register bank.

Inductive exec : label ! regs ! instr ! label ! regs ! Prop :=|

E Imm : 8 pc rs r n, exec pc rs (Imm r n) (S pc) (set rs r n)|
E Copy : 8 pc rs r1 r2, exec pc rs (Copy r1 r2 ) (S pc) (set rs r1 (rs r2 ))|
E Jmp : 8 pc rs pc', exec pc rs (Jmp pc' ) pc' rs|
E JnzF : 8 pc rs r pc', rs r = 0 ! exec pc rs (Jnz r pc' ) (S pc) rs|
E JnzT : 8 pc rs r pc' n, rs r = S n ! exec pc rs (Jnz r pc' ) pc' rs.

We prove that exec represents a total function. In our proof script, we use a match tactic
with a context pattern. This particular example o/nds an occurrence of a pattern Jnz ?r
anywhere in the current subgoal's conclusion. We use a Coq library tactic case eq to do case
analysis on whether the current value rs r of the register r is zero or not. case eq dioeers
from destruct in saving an equality relating the old variable to the new form we deduce for

90

it.
Lemma exec total : 8 pc rs i,9

pc', 9 rs', exec pc rs i pc' rs'.
Hint Constructors exec.

destruct i ; crush; eauto;

match goal with|

[ ` context [Jnz ?r ] ] ) case eq (rs r )
end; eauto.
Qed.

We are ready to deo/ne a co-inductive judgment capturing the idea that a program runs
forever. We deo/ne the judgment in terms of a program prog, represented as a function
mapping each label to the instruction found there.

Section safe.

Variable prog : label ! instr.

CoInductive safe : label ! regs ! Prop :=|

Step : 8 pc r pc' r',

exec pc r (prog pc) pc' r'!

safe pc' r'!
safe pc r.

Now we can prove that any starting address and register bank lead to safe ino/nite ex-
ecution. Recall that proofs of existentially-quantio/ed formulas are all built with a single
constructor of the inductive type ex. This means that we can use destruct to "open up"
such proofs. In the proof below, we want to perform this opening up on an appropriate use
of the exec total lemma. This lemma's conclusion begins with two existential quantio/ers,
so we want to tell destruct that it should not stop at the o/rst quantio/er. We accomplish
our goal by using an intro pattern with destruct. Consult the Coq manual for the details
of intro patterns; the specio/c pattern [? [? ?]] that we use here accomplishes our goal of
destructing both quantio/ers at once.

Theorem always safe : 8 pc rs,

safe pc rs.
coo/x ; intros;

destruct (exec total pc rs (prog pc)) as [? [? ?]];

econstructor ; eauto.
Qed.
End safe.

If we print the proof term that was generated, we can verify that the proof is structured
as a coo/x, with each co-recursive call properly guarded.

Print always safe.

91

5.4 Exercises

1. (a) Deo/ne a co-inductive type of ino/nite trees carrying data of a o/xed parameter type.

Each node should contain a data value and two child trees.

(b) Deo/ne a function everywhere for building a tree with the same data value at every

node.

(c) Deo/ne a function map for building an output tree out of two input trees by travers-

ing them in parallel and applying a two-argument function to their corresponding
data values.

(d) Deo/ne a tree falses where every node has the value false.

(e) Deo/ne a tree true false where the root node has value true, its children have value

false, all nodes at the next have the value true, and so on, alternating boolean
values from level to level.

(f) Prove that true false is equal to the result of mapping the boolean "or" function

orb over true false and falses. You can make orb available with Require Import
Bool.. You may o/nd the lemma orb false r from the same module helpful. Your
proof here should not be about the standard equality =, but rather about some
new equality relation that you deo/ne.

92

Part II
Programming with Dependent Types

93

Chapter 6
Subset Types and Variations

So far, we have seen many examples of what we might call "classical program verio/cation."
We write programs, write their specio/cations, and then prove that the programs satisfy their
specio/cations. The programs that we have written in Coq have been normal functional
programs that we could just as well have written in Haskell or ML. In this chapter, we start
investigating uses of dependent types to integrate programming, specio/cation, and proving
into a single phase.

6.1 Introducing Subset Types
Let us consider several ways of implementing the natural number predecessor function. We
start by displaying the deo/nition from the standard library:

Print pred.
pred = fun n : nat ) match n with|

0 ) 0|
S u ) u
end
: nat ! nat

We can use a new command, Extraction, to produce an OCaml version of this function.
Extraction pred.

(** val pred : nat -? nat **)
let pred = function

-- O -? O
-- S u -? u

Returning 0 as the predecessor of 0 can come across as somewhat of a hack. In some

94

situations, we might like to be sure that we never try to take the predecessor of 0. We can
enforce this by giving pred a stronger, dependent type.

Lemma zgtz : 0 ? 0 ! False.

crush.
Qed.

Definition pred strong1 (n : nat) : n ? 0 ! nat :=

match n with|

O ) fun pf : 0 ? 0 ) match zgtz pf with end|
S n' ) fun ) n'
end.

We expand the type of pred to include a proof that its argument n is greater than 0.
When n is 0, we use the proof to derive a contradiction, which we can use to build a value
of any type via a vacuous pattern match. When n is a successor, we have no need for the
proof and just return the answer. The proof argument can be said to have a dependent type,
because its type depends on the value of the argument n.

One aspects in particular of the deo/nition of pred strong1 that may be surprising. We
took advantage of Definition's syntactic sugar for deo/ning function arguments in the case
of n, but we bound the proofs later with explicit fun expressions. Let us see what happens
if we write this function in the way that at o/rst seems most natural.

Definition pred strong1' (n : nat) (pf : n ? 0) : nat :=

match n with|

O ) match zgtz pf with end|
S n' ) n'
end.

Error : In environment
n : nat
pf : n ? 0
The term "pf" has type "n ? 0" while it is expected to have type
"0 ? 0"

The term zgtz pf fails to type-check. Somehow the type checker has failed to take
into account information that follows from which match branch that term appears in. The
problem is that, by default, match does not let us use such implied information. To get reo/ned
typing, we must always rely on match annotations, either written explicitly or inferred.

In this case, we must use a return annotation to declare the relationship between the
value of the match discriminee and the type of the result. There is no annotation that lets
us declare a relationship between the discriminee and the type of a variable that is already
in scope; hence, we delay the binding of pf, so that we can use the return annotation to
express the needed relationship.

We are lucky that Coq's heuristics infer the return clause (specio/cally, return n ? 0 !

95

nat) for us in this case. In general, however, the inference problem is undecidable. The known
undecidable problem of higher-order unio/cation reduces to the match type inference problem.
Over time, Coq is enhanced with more and more heuristics to get around this problem, but
there must always exist matches whose types Coq cannot infer without annotations.

Let us now take a look at the OCaml code Coq generates for pred strong1.

Extraction pred strong1.

(** val pred.strong1 : nat -? nat **)
let pred.strong1 = function

-- O -? assert false (* absurd case *)
-- S n' -? n'

The proof argument has disappeared! We get exactly the OCaml code we would have
written manually. This is our o/rst demonstration of the main technically interesting feature
of Coq program extraction: program components of type Prop are erased systematically.

We can reimplement our dependently-typed pred based on subset types, deo/ned in the
standard library with the type family sig.

Print sig.
Inductive sig (A : Type) (P : A ! Prop) : Type :=

exist : 8 x : A, P x ! sig P
For sig: Argument A is implicit
For exist: Argument A is implicit

sig is a Curry-Howard twin of ex, except that sig is in Type, while ex is in Prop. That
means that sig values can survive extraction, while ex proofs will always be erased. The
actual details of extraction of sigs are more subtle, as we will see shortly.

We rewrite pred strong1, using some syntactic sugar for subset types.

Locate "- : | """.
Notation Scope
"- x : A | P """ := sig (fun x : A ) P )

: type scope
(default interpretation)

Definition pred strong2 (s : -n : nat | n ? 0"") : nat :=

match s with|

exist O pf ) match zgtz pf with end|
exist (S n' ) ) n'
end.

Extraction pred strong2.

(** val pred.strong2 : nat -? nat **)

96

let pred.strong2 = function

-- O -? assert false (* absurd case *)
-- S n' -? n'

We arrive at the same OCaml code as was extracted from pred strong1, which may seem
surprising at o/rst. The reason is that a value of sig is a pair of two pieces, a value and
a proof about it. Extraction erases the proof, which reduces the constructor exist of sig
to taking just a single argument. An optimization eliminates uses of datatypes with single
constructors taking single arguments, and we arrive back where we started.

We can continue on in the process of reo/ning pred's type. Let us change its result type
to capture that the output is really the predecessor of the input.

Definition pred strong3 (s : -n : nat | n ? 0"") : -m : nat | proj1 sig s = S m"" :=

match s return -m : nat | proj1 sig s = S m"" with|

exist 0 pf ) match zgtz pf with end|
exist (S n' ) pf ) exist n' (reAE equal )
end.

The function proj1 sig extracts the base value from a subset type. Besides the use of that
function, the only other new thing is the use of the exist constructor to build a new sig value,
and the details of how to do that follow from the output of our earlier Print command. It
also turns out that we need to include an explicit return clause here, since Coq's heuristics
are not smart enough to propagate the result type that we wrote earlier.

By now, the reader is probably ready to believe that the new pred strong leads to the
same OCaml code as we have seen several times so far, and Coq does not disappoint.

Extraction pred strong3.

(** val pred.strong3 : nat -? nat **)
let pred.strong3 = function

-- O -? assert false (* absurd case *)
-- S n' -? n'

We have managed to reach a type that is, in a formal sense, the most expressive possible
for pred. Any other implementation of the same type must have the same input-output
behavior. However, there is still room for improvement in making this kind of code easier
to write. Here is a version that takes advantage of tactic-based theorem proving. We switch
back to passing a separate proof argument instead of using a subset type for the function's
input, because this leads to cleaner code.

Definition pred strong4 (n : nat) : n ? 0 ! -m : nat | n = S m"".

refine (fun n )

match n with|

O ) fun ) False rec

97

| S n' ) fun ) exist n'
end).

We build pred strong4 using tactic-based proving, beginning with a Definition command
that ends in a period before a deo/nition is given. Such a command enters the interactive
proving mode, with the type given for the new identio/er as our proof goal. We do most of
the work with the refine tactic, to which we pass a partial "proof" of the type we are trying
to prove. There may be some pieces left to o/ll in, indicated by underscores. Any underscore
that Coq cannot reconstruct with type inference is added as a proof subgoal. In this case,
we have two subgoals:

2 subgoals

n : nat

: 0 ? 0
============================

False

subgoal 2 is:

S n' = S n'

We can see that the o/rst subgoal comes from the second underscore passed to False rec,
and the second subgoal comes from the second underscore passed to exist. In the o/rst case,
we see that, though we bound the proof variable with an underscore, it is still available in
our proof context. It is hard to refer to underscore-named variables in manual proofs, but
automation makes short work of them. Both subgoals are easy to discharge that way, so let
us back up and ask to prove all subgoals automatically.

Undo.
refine (fun n )

match n with|

O ) fun ) False rec|
S n' ) fun ) exist n'
end); crush.
Defined.

We end the "proof" with Defined instead of Qed, so that the deo/nition we constructed
remains visible. This contrasts to the case of ending a proof with Qed, where the details of
the proof are hidden afterward. Let us see what our proof script constructed.

Print pred strong4.
pred strong4 =
fun n : nat )
match n as n0 return (n0 ? 0 ! -m : nat | n0 = S m"") with|

0 )

98

fun : 0 ? 0 )
False rec -m : nat | 0 = S m""

(Bool.dioe false true

(Bool.absurd eq true false

(Bool.dioe false true

(Bool.absurd eq true false (pred strong4 subproof n )))))|
S n' )

fun : S n' ? 0 )
exist (fun m : nat ) S n' = S m) n' (reAE equal (S n' ))
end

: 8 n : nat, n ? 0 ! -m : nat | n = S m""

We see the code we entered, with some proofs o/lled in. The o/rst proof obligation, the
second argument to False rec, is o/lled in with a nasty-looking proof term that we can be
glad we did not enter by hand. The second proof obligation is a simple reAEexivity proof.

We are almost done with the ideal implementation of dependent predecessor. We can
use Coq's syntax extension facility to arrive at code with almost no complexity beyond a
Haskell or ML program with a complete specio/cation in a comment.

Notation "!" := (False rec ).
Notation "[ e ]" := (exist e ).

Definition pred strong5 (n : nat) : n ? 0 ! -m : nat | n = S m"".

refine (fun n )

match n with|

O ) fun ) !|
S n' ) fun ) [n' ]
end); crush.
Defined.

One other alternative is worth demonstrating. Recent Coq versions include a facility
called Program that streamlines this style of deo/nition. Here is a complete implementation
using Program.

Obligation Tactic := crush.
Program Definition pred strong6 (n : nat) ( : n ? 0) : -m : nat | n = S m"" :=

match n with|

O )|
S n' ) n'
end.

Printing the resulting deo/nition of pred strong6 yields a term very similar to what we built
with refine. Program can save time in writing programs that use subset types. Nonetheless,
refine is often just as eoeective, and refine gives you more control over the form the o/nal
term takes, which can be useful when you want to prove additional theorems about your
deo/nition. Program will sometimes insert type casts that can complicate theorem-proving.

99

6.2 Decidable Proposition Types
There is another type in the standard library which captures the idea of program values that
indicate which of two propositions is true.

Print sumbool.
Inductive sumbool (A : Prop) (B : Prop) : Set :=

left : A ! -A"" + -B "" | right : B ! -A"" + -B ""
For left: Argument A is implicit
For right: Argument B is implicit

We can deo/ne some notations to make working with sumbool more convenient.
Notation "'Yes'" := (left ).
Notation "'No'" := (right ).
Notation "'Reduce' x" := (if x then Yes else No) (at level 50).

The Reduce notation is notable because it demonstrates how if is overloaded in Coq.
The if form actually works when the test expression has any two-constructor inductive type.
Moreover, in the then and else branches, the appropriate constructor arguments are bound.
This is important when working with sumbool s, when we want to have the proof stored in
the test expression available when proving the proof obligations generated in the appropriate
branch.

Now we can write eq nat dec, which compares two natural numbers, returning either a
proof of their equality or a proof of their inequality.

Definition eq nat dec (n m : nat) : -n = m"" + -n 6= m"".

refine (o/x f (n m : nat) : -n = m"" + -n 6= m"" :=

match n, m with|

O, O ) Yes|
S n', S m' ) Reduce (f n' m' )|

, ) No
end); congruence.
Defined.

Our deo/nition extracts to reasonable OCaml code.
Extraction eq nat dec.

(** val eq.nat.dec : nat -? nat -? sumbool **)

let rec eq.nat.dec n m =

match n with

-- O -? (match m with

-- O -? Left
-- S n0 -? Right)
-- S n' -? (match m with

100

-- O -? Right
-- S m' -? eq.nat.dec n' m')

Proving this kind of decidable equality result is so common that Coq comes with a tactic
for automating it.

Definition eq nat dec' (n m : nat) : -n = m"" + -n 6= m"".

decide equality.
Defined.

Curious readers can verify that the decide equality version extracts to the same OCaml
code as our more manual version does. That OCaml code had one undesirable property,
which is that it uses Left and Right constructors instead of the boolean values built into
OCaml. We can o/x this, by using Coq's facility for mapping Coq inductive types to OCaml
variant types.

Extract Inductive sumbool ) "bool" ["true" "false"].
Extraction eq nat dec'.

(** val eq.nat.dec' : nat -? nat -? bool **)
let rec eq.nat.dec' n m0 =

match n with

-- O -? (match m0 with

-- O -? true
-- S n0 -? false)
-- S n0 -? (match m0 with

-- O -? false
-- S n1 -? eq.nat.dec' n0 n1)

We can build "smart" versions of the usual boolean operators and put them to good use
in certio/ed programming. For instance, here is a sumbool version of boolean "or."

Notation "x ---- y" := (if x then Yes else Reduce y ).

Let us use it for building a function that decides list membership. We need to assume
the existence of an equality decision procedure for the type of list elements.

Section In dec.

Variable A : Set.
Variable A eq dec : 8 x y : A, -x = y"" + -x 6= y "".

The o/nal function is easy to write using the techniques we have developed so far.
Definition In dec : 8 (x : A) (ls : list A), -In x ls"" + -~ In x ls"".

refine (o/x f (x : A) (ls : list A) : -In x ls"" + -~ In x ls"" :=

match ls with|

nil ) No

101

| x' :: ls' ) A eq dec x x' ---- f x ls'
end); crush.
Qed.
End In dec.

In dec has a reasonable extraction to OCaml.
Extraction In dec.

(** val in.dec : ('a1 -? 'a1 -? bool) -? 'a1 -? 'a1 list -? bool **)
let rec in.dec a.eq.dec x = function

-- Nil -? false
-- Cons (x', ls') -?

(match a.eq.dec x x' with

-- true -? true
-- false -? in.dec a.eq.dec x ls')

6.3 Partial Subset Types
Our o/nal implementation of dependent predecessor used a very specio/c argument type to
ensure that execution could always complete normally. Sometimes we want to allow execution
to fail, and we want a more principled way of signaling that than returning a default value,
as pred does for 0. One approach is to deo/ne this type family maybe, which is a version of
sig that allows obligation-free failure.

Inductive maybe (A : Set) (P : A ! Prop) : Set :=|

Unknown : maybe P|
Found : 8 x : A, P x ! maybe P.

We can deo/ne some new notations, analogous to those we deo/ned for subset types.
Notation "-- x | P """"" := (maybe (fun x ) P )).
Notation "??" := (Unknown ).
Notation "[[ x ]]" := (Found x ).

Now our next version of pred is trivial to write.
Definition pred strong7 (n : nat) : --m | n = S m"""".

refine (fun n )

match n with|

O ) ??|
S n' ) [[n' ]]
end); trivial.
Defined.

102

Because we used maybe, one valid implementation of the type we gave pred strong7
would return ?? in every case. We can strengthen the type to rule out such vacuous
implementations, and the type family sumor from the standard library provides the easiest
starting point. For type A and proposition B , A + -B "" desugars to sumor A B , whose
values are either values of A or proofs of B .

Print sumor.
Inductive sumor (A : Type) (B : Prop) : Type :=

inleft : A ! A + -B "" | inright : B ! A + -B ""
For inleft: Argument A is implicit
For inright: Argument B is implicit

We add notations for easy use of the sumor constructors. The second notation is spe-
cialized to sumor s whose A parameters are instantiated with regular subset types, since this
is how we will use sumor below.

Notation "!!" := (inright ).
Notation "[[[ x ]]]" := (inleft [x ]).

Now we are ready to give the o/nal version of possibly-failing predecessor. The sumor -
based type that we use is maximally expressive; any implementation of the type has the
same input-output behavior.

Definition pred strong8 (n : nat) : -m : nat | n = S m"" + -n = 0"".

refine (fun n )

match n with|

O ) !!|
S n' ) [[[n' ]]]
end); trivial.
Defined.

6.4 Monadic Notations
We can treat maybe like a monad, in the same way that the Haskell Maybe type is interpreted
as a failure monad. Our maybe has the wrong type to be a literal monad, but a "bind"-like
notation will still be helpful.

Notation "x  e1 ; e2" := (match e1 with|

Unknown ) ??|
Found x ) e2
end)
(right associativity, at level 60).

The meaning of x  e1 ; e2 is: First run e1 . If it fails to o/nd an answer, then announce
failure for our derived computation, too. If e1 does o/nd an answer, pass that answer on to
e2 to o/nd the o/nal result. The variable x can be considered bound in e2.

103

This notation is very helpful for composing richly-typed procedures. For instance, here
is a very simple implementation of a function to take the predecessors of two naturals at
once.

Definition doublePred (n1 n2 : nat) : --p | n1 = S (fst p) ^ n2 = S (snd p)"""".

refine (fun n1 n2 )

m1  pred strong7 n1 ;
m2  pred strong7 n2 ;
[[(m1, m2 )]]); tauto.
Defined.

We can build a sumor version of the "bind" notation and use it to write a similarly
straightforward version of this function.

Notation "x - e1 ; e2" := (match e1 with|

inright ) !!|
inleft (exist x ) ) e2
end)
(right associativity, at level 60).

Definition doublePred' (n1 n2 : nat)

: -p : nat * nat | n1 = S (fst p) ^ n2 = S (snd p)""
+ -n1 = 0 . n2 = 0"".
refine (fun n1 n2 )

m1 - pred strong8 n1 ;
m2 - pred strong8 n2 ;
[[[(m1, m2 )]]]); tauto.
Defined.

6.5 A Type-Checking Example
We can apply these specio/cation types to build a certio/ed type-checker for a simple expression
language.

Inductive exp : Set :=|

Nat : nat ! exp|
Plus : exp ! exp ! exp|
Bool : bool ! exp|
And : exp ! exp ! exp.

We deo/ne a simple language of types and its typing rules, in the style introduced in
Chapter 4.

Inductive type : Set := TNat | TBool.
Inductive hasType : exp ! type ! Prop :=|

HtNat : 8 n,

104

hasType (Nat n) TNat|
HtPlus : 8 e1 e2,

hasType e1 TNat!

hasType e2 TNat!
hasType (Plus e1 e2 ) TNat|
HtBool : 8 b,

hasType (Bool b) TBool|
HtAnd : 8 e1 e2,

hasType e1 TBool!

hasType e2 TBool!
hasType (And e1 e2 ) TBool.

It will be helpful to have a function for comparing two types. We build one using decide
equality.

Definition eq type dec : 8 t1 t2 : type, -t1 = t2 "" + -t1 6= t2 "".

decide equality.
Defined.

Another notation complements the monadic notation for maybe that we deo/ned earlier.
Sometimes we want to include "assertions" in our procedures. That is, we want to run a
decision procedure and fail if it fails; otherwise, we want to continue, with the proof that it
produced made available to us. This ino/x notation captures that idea, for a procedure that
returns an arbitrary two-constructor type.

Notation "e1 ;; e2" := (if e1 then e2 else ??)

(right associativity, at level 60).

With that notation deo/ned, we can implement a typeCheck function, whose code is only
more complex than what we would write in ML because it needs to include some extra type
annotations. Every [[e]] expression adds a hasType proof obligation, and crush makes short
work of them when we add hasType's constructors as hints.

Definition typeCheck (e : exp) : --t | hasType e t """".

Hint Constructors hasType.

refine (o/x F (e : exp) : --t | hasType e t """" :=

match e with|

Nat ) [[TNat]]|
Plus e1 e2 )

t1  F e1 ;
t2  F e2 ;
eq type dec t1 TNat;;
eq type dec t2 TNat;;
[[TNat]]|
Bool ) [[TBool]]|
And e1 e2 )

t1  F e1 ;

105

t2  F e2 ;
eq type dec t1 TBool;;
eq type dec t2 TBool;;
[[TBool]]
end); crush.
Defined.

Despite manipulating proofs, our type checker is easy to run.
Eval simpl in typeCheck (Nat 0).

= [[TNat]]
: --t | hasType (Nat 0) t """"

Eval simpl in typeCheck (Plus (Nat 1) (Nat 2)).

= [[TNat]]
: --t | hasType (Plus (Nat 1) (Nat 2)) t """"

Eval simpl in typeCheck (Plus (Nat 1) (Bool false)).

= ??
: --t | hasType (Plus (Nat 1) (Bool false)) t """"

The type-checker also extracts to some reasonable OCaml code.
Extraction typeCheck.

(** val typeCheck : exp -? type0 maybe **)
let rec typeCheck = function

-- Nat n -? Found TNat
-- Plus (e1, e2) -?

(match typeCheck e1 with

-- Unknown -? Unknown
-- Found t1 -?

(match typeCheck e2 with

-- Unknown -? Unknown
-- Found t2 -?

(match eq.type.dec t1 TNat with

-- true -?

(match eq.type.dec t2 TNat with

-- true -? Found TNat
-- false -? Unknown)
-- false -? Unknown)))
-- Bool b -? Found TBool
-- And (e1, e2) -?

(match typeCheck e1 with

-- Unknown -? Unknown

106

-- Found t1 -?

(match typeCheck e2 with

-- Unknown -? Unknown
-- Found t2 -?

(match eq.type.dec t1 TBool with

-- true -?

(match eq.type.dec t2 TBool with

-- true -? Found TBool
-- false -? Unknown)
-- false -? Unknown)))

We can adapt this implementation to use sumor, so that we know our type-checker only
fails on ill-typed inputs. First, we deo/ne an analogue to the "assertion" notation.

Notation "e1 ;;; e2" := (if e1 then e2 else !!)

(right associativity, at level 60).

Next, we prove a helpful lemma, which states that a given expression can have at most
one type.

Lemma hasType det : 8 e t1,

hasType e t1! 8

t2,
hasType e t2!

t1 = t2.
induction 1; inversion 1; crush.
Qed.

Now we can deo/ne the type-checker. Its type expresses that it only fails on untypable
expressions.

Definition typeCheck' (e : exp) : -t : type | hasType e t "" + -8 t, ~ hasType e t "".

Hint Constructors hasType.

We register all of the typing rules as hints.

Hint Resolve hasType det.

hasType det will also be useful for proving proof obligations with contradictory contexts.
Since its statement includes 8-bound variables that do not appear in its conclusion, only
eauto will apply this hint.

Finally, the implementation of typeCheck can be transcribed literally, simply switching
notations as needed.

refine (o/x F (e : exp) : -t : type | hasType e t "" + -8 t, ~ hasType e t "" :=

match e with|

Nat ) [[[TNat]]]|
Plus e1 e2 )

t1 - F e1 ;

107

t2 - F e2 ;
eq type dec t1 TNat;;;
eq type dec t2 TNat;;;
[[[TNat]]]|
Bool ) [[[TBool]]]|
And e1 e2 )

t1 - F e1 ;
t2 - F e2 ;
eq type dec t1 TBool;;;
eq type dec t2 TBool;;;
[[[TBool]]]
end); clear F ; crush' tt hasType; eauto.

We clear F, the local name for the recursive function, to avoid strange proofs that refer
to recursive calls that we never make. The crush variant crush' helps us by performing
automatic inversion on instances of the predicates specio/ed in its second argument. Once
we throw in eauto to apply hasType det for us, we have discharged all the subgoals.

Defined.

The short implementation here hides just how time-saving automation is. Every use of
one of the notations adds a proof obligation, giving us 12 in total. Most of these obligations
require multiple inversions and either uses of hasType det or applications of hasType rules.

The results of simplifying calls to typeCheck' look deceptively similar to the results for
typeCheck, but now the types of the results provide more information.

Eval simpl in typeCheck' (Nat 0).

= [[[TNat]]]
: -t : type | hasType (Nat 0) t "" +

-(8 t : type, ~ hasType (Nat 0) t )""

Eval simpl in typeCheck' (Plus (Nat 1) (Nat 2)).

= [[[TNat]]]
: -t : type | hasType (Plus (Nat 1) (Nat 2)) t "" +

-(8 t : type, ~ hasType (Plus (Nat 1) (Nat 2)) t )""

Eval simpl in typeCheck' (Plus (Nat 1) (Bool false)).

= !!
: -t : type | hasType (Plus (Nat 1) (Bool false)) t "" +

-(8 t : type, ~ hasType (Plus (Nat 1) (Bool false)) t )""

6.6 Exercises
All of the notations deo/ned in this chapter, plus some extras, are available for import from
the module MoreSpecif of the book source.

108

1. Write a function of type 8 n m : nat, -n <= m"" + -n ? m"". That is, this function

decides whether one natural is less than another, and its dependent type guarantees
that its results are accurate.

2. (a) Deo/ne var , a type of propositional variables, as a synonym for nat.

(b) Deo/ne an inductive type prop of propositional logic formulas, consisting of vari-

ables, negation, and binary conjunction and disjunction.

(c) Deo/ne a function propDenote from variable truth assignments and props to Prop,

based on the usual meanings of the connectives. Represent truth assignments as
functions from var to bool.

(d) Deo/ne a function bool true dec that checks whether a boolean is true, with a

maximally expressive dependent type. That is, the function should have type 8
b, -b = true"" + -b = true ! False"".

(e) Deo/ne a function decide that determines whether a particular prop is true under

a particular truth assignment. That is, the function should have type 8 (truth
: var ! bool) (p : prop), -propDenote truth p"" + -~ propDenote truth p"".
This function is probably easiest to write in the usual tactical style, instead of
programming with refine. bool true dec may come in handy as a hint.

(f) Deo/ne a function negate that returns a simplio/ed version of the negation of a prop.

That is, the function should have type 8 p : prop, -p' : prop | 8 truth, propDenote
truth p $ ~ propDenote truth p' "". To simplify a variable, just negate it. Simplify
a negation by returning its argument. Simplify conjunctions and disjunctions
using De Morgan's laws, negating the arguments recursively and switching the
kind of connective. decide may be useful in some of the proof obligations, even
if you do not use it in the computational part of negate's deo/nition. Lemmas
like decide allow us to compensate for the lack of a general Law of the Excluded
Middle in CIC.

3. Implement the DPLL satiso/ability decision procedure for boolean formulas in conjunc-

tive normal form, with a dependent type that guarantees its correctness. An example
of a reasonable type for this function would be 8 f : formula, -truth : tvals | formu-
laTrue truth f"" + -8 truth, ~ formulaTrue truth f"". Implement at least "the basic
backtracking algorithm" as deo/ned here:

http://en.wikipedia.org/wiki/DPLL.algorithm
It might also be instructive to implement the unit propagation and pure literal elimi-
nation optimizations described there or some other optimizations that have been used
in modern SAT solvers.

109

Chapter 7
More Dependent Types

Subset types and their relatives help us integrate verio/cation with programming. Though
they reorganize the certio/ed programmer's workAEow, they tend not to have deep eoeects on
proofs. We write largely the same proofs as we would for classical verio/cation, with some of
the structure moved into the programs themselves. It turns out that, when we use dependent
types to their full potential, we warp the development and proving process even more than
that, picking up "free theorems" to the extent that often a certio/ed program is hardly more
complex than its uncertio/ed counterpart in Haskell or ML.

In particular, we have only scratched the tip of the iceberg that is Coq's inductive def-
inition mechanism. The inductive types we have seen so far have their counterparts in the
other proof assistants that we surveyed in Chapter 1. This chapter explores the strange new
world of dependent inductive datatypes (that is, dependent inductive types outside Prop), a
possibility which sets Coq apart from all of the competition not based on type theory.

7.1 Length-Indexed Lists
Many introductions to dependent types start out by showing how to use them to eliminate
array bounds checks. When the type of an array tells you how many elements it has, your
compiler can detect out-of-bounds dereferences statically. Since we are working in a pure
functional language, the next best thing is length-indexed lists, which the following code
deo/nes.

Section ilist.

Variable A : Set.

Inductive ilist : nat ! Set :=|

Nil : ilist O|
Cons : 8 n, A ! ilist n ! ilist (S n).

We see that, within its section, ilist is given type nat ! Set. Previously, every inductive
type we have seen has either had plain Set as its type or has been a predicate with some type
ending in Prop. The full generality of inductive deo/nitions lets us integrate the expressivity

110

of predicates directly into our normal programming.

The nat argument to ilist tells us the length of the list. The types of ilist's constructors
tell us that a Nil list has length O and that a Cons list has length one greater than the length
of its sublist. We may apply ilist to any natural number, even natural numbers that are
only known at runtime. It is this breaking of the phase distinction that characterizes ilist
as dependently typed.

In expositions of list types, we usually see the length function deo/ned o/rst, but here that
would not be a very productive function to code. Instead, let us implement list concatena-
tion.

Fixpoint app n1 (ls1 : ilist n1 ) n2 (ls2 : ilist n2 ) : ilist (n1 + n2 ) :=

match ls1 with|

Nil ) ls2|
Cons x ls1' ) Cons x (app ls1' ls2 )
end.

In Coq version 8.1 and earlier, this deo/nition leads to an error message:

The term "ls2" has type "ilist n2" while it is expected to have type

"ilist (?14 + n2)"

In Coq's core language, without explicit annotations, Coq does not enrich our typing
assumptions in the branches of a match expression. It is clear that the unio/cation variable
?14 should be resolved to 0 in this context, so that we have 0 + n2 reducing to n2, but
Coq does not realize that. We cannot o/x the problem using just the simple return clauses
we applied in the last chapter. We need to combine a return clause with a new kind of
annotation, an in clause. This is exactly what the inference heuristics do in Coq 8.2 and
later.

Specio/cally, Coq infers the following deo/nition from the simpler one.

Fixpoint app' n1 (ls1 : ilist n1 ) n2 (ls2 : ilist n2 ) : ilist (n1 + n2 ) :=

match ls1 in (ilist n1 ) return (ilist (n1 + n2 )) with|

Nil ) ls2|
Cons x ls1' ) Cons x (app' ls1' ls2 )
end.

Using return alone allowed us to express a dependency of the match result type on the
value of the discriminee. What in adds to our arsenal is a way of expressing a dependency on
the type of the discriminee. Specio/cally, the n1 in the in clause above is a binding occurrence
whose scope is the return clause.

We may use in clauses only to bind names for the arguments of an inductive type family.
That is, each in clause must be an inductive type family name applied to a sequence of
underscores and variable names of the proper length. The positions for parameters to the
type family must all be underscores. Parameters are those arguments declared with section
variables or with entries to the left of the o/rst colon in an inductive deo/nition. They cannot

111

vary depending on which constructor was used to build the discriminee, so Coq prohibits
pointless matches on them. It is those arguments deo/ned in the type to the right of the colon
that we may name with in clauses.

Our app function could be typed in so-called stratio/ed type systems, which avoid true
dependency. We could consider the length indices to lists to live in a separate, compile-time-
only universe from the lists themselves. Our next example would be harder to implement in
a stratio/ed system. We write an injection function from regular lists to length-indexed lists.
A stratio/ed implementation would need to duplicate the deo/nition of lists across compile-
time and run-time versions, and the run-time versions would need to be indexed by the
compile-time versions.

Fixpoint inject (ls : list A) : ilist (length ls) :=

match ls with|

nil ) Nil|
h :: t ) Cons h (inject t )
end.

We can deo/ne an inverse conversion and prove that it really is an inverse.
Fixpoint unject n (ls : ilist n) : list A :=

match ls with|

Nil ) nil|
Cons h t ) h :: unject t
end.

Theorem inject inverse : 8 ls, unject (inject ls) = ls.

induction ls; crush.
Qed.

Now let us attempt a function that is surprisingly tricky to write. In ML, the list head
function raises an exception when passed an empty list. With length-indexed lists, we can
rule out such invalid calls statically, and here is a o/rst attempt at doing so.

Definition hd n (ls : ilist (S n)) : A :=

match ls with|

Nil ) ???|
Cons h ) h
end.

It is not clear what to write for the Nil case, so we are stuck before we even turn our
function over to the type checker. We could try omitting the Nil case:

Definition hd n (ls : ilist (S n)) : A :=

match ls with|

Cons h ) h
end.

112

Error : Non exhaustive pattern-matching: no clause found for pattern Nil

Unlike in ML, we cannot use inexhaustive pattern matching, because there is no concep-
tion of a Match exception to be thrown. We might try using an in clause somehow.

Definition hd n (ls : ilist (S n)) : A :=

match ls in (ilist (S n)) with|

Cons h ) h
end.

Error : The reference n was not found in the current environment

In this and other cases, we feel like we want in clauses with type family arguments
that are not variables. Unfortunately, Coq only supports variables in those positions. A
completely general mechanism could only be supported with a solution to the problem of
higher-order unio/cation, which is undecidable. There are useful heuristics for handling non-
variable indices which are gradually making their way into Coq, but we will spend some time
in this and the next few chapters on eoeective pattern matching on dependent types using
only the primitive match annotations.

Our o/nal, working attempt at hd uses an auxiliary function and a surprising return
annotation.

Definition hd' n (ls : ilist n) :=

match ls in (ilist n) return (match n with O ) unit | S ) A end) with|

Nil ) tt|
Cons h ) h
end.

Definition hd n (ls : ilist (S n)) : A := hd' ls.

We annotate our main match with a type that is itself a match. We write that the function
hd' returns unit when the list is empty and returns the carried type A in all other cases. In
the deo/nition of hd, we just call hd'. Because the index of ls is known to be nonzero, the
type checker reduces the match in the type of hd' to A.

End ilist.

7.2 A Tagless Interpreter
A favorite example for motivating the power of functional programming is implementation
of a simple expression language interpreter. In ML and Haskell, such interpreters are often
implemented using an algebraic datatype of values, where at many points it is checked that
a value was built with the right constructor of the value type. With dependent types, we

113

can implement a tagless interpreter that both removes this source of runtime ineOEency and
gives us more cono/dence that our implementation is correct.

Inductive type : Set :=|

Nat : type|
Bool : type|
Prod : type ! type ! type.

Inductive exp : type ! Set :=|

NConst : nat ! exp Nat|
Plus : exp Nat ! exp Nat ! exp Nat|
Eq : exp Nat ! exp Nat ! exp Bool

| BConst : bool ! exp Bool|

And : exp Bool ! exp Bool ! exp Bool|
If : 8 t, exp Bool ! exp t ! exp t ! exp t

| Pair : 8 t1 t2, exp t1 ! exp t2 ! exp (Prod t1 t2 )|

Fst : 8 t1 t2, exp (Prod t1 t2 ) ! exp t1|
Snd : 8 t1 t2, exp (Prod t1 t2 ) ! exp t2.

We have a standard algebraic datatype type, deo/ning a type language of naturals,
booleans, and product (pair) types. Then we have the indexed inductive type exp, where
the argument to exp tells us the encoded type of an expression. In eoeect, we are deo/ning the
typing rules for expressions simultaneously with the syntax.

We can give types and expressions semantics in a new style, based critically on the chance
for type-level computation.

Fixpoint typeDenote (t : type) : Set :=

match t with|

Nat ) nat|
Bool ) bool|
Prod t1 t2 ) typeDenote t1 * typeDenote t2
end%type.

typeDenote compiles types of our object language into "native" Coq types. It is decep-
tively easy to implement. The only new thing we see is the %type annotation, which tells
Coq to parse the match expression using the notations associated with types. Without this
annotation, the * would be interpreted as multiplication on naturals, rather than as the
product type constructor. type is one example of an identifer bound to a notation scope.
We will deal more explicitly with notations and notation scopes in later chapters.

We can deo/ne a function expDenote that is typed in terms of typeDenote.

Fixpoint expDenote t (e : exp t ) : typeDenote t :=

match e with|

NConst n ) n|
Plus e1 e2 ) expDenote e1 + expDenote e2

114

| Eq e1 e2 ) if eq nat dec (expDenote e1 ) (expDenote e2 ) then true else false
| BConst b ) b|

And e1 e2 ) expDenote e1 && expDenote e2|
If e' e1 e2 ) if expDenote e' then expDenote e1 else expDenote e2

| Pair e1 e2 ) (expDenote e1, expDenote e2 )|

Fst e' ) fst (expDenote e' )|
Snd e' ) snd (expDenote e' )
end.

Despite the fancy type, the function deo/nition is routine. In fact, it is less complicated
than what we would write in ML or Haskell 98, since we do not need to worry about pushing
o/nal values in and out of an algebraic datatype. The only unusual thing is the use of an
expression of the form if E then true else false in the Eq case. Remember that eq nat dec
has a rich dependent type, rather than a simple boolean type. Coq's native if is overloaded
to work on a test of any two-constructor type, so we can use if to build a simple boolean
from the sumbool that eq nat dec returns.

We can implement our old favorite, a constant folding function, and prove it correct. It
will be useful to write a function pairOut that checks if an exp of Prod type is a pair, returning
its two components if so. Unsurprisingly, a o/rst attempt leads to a type error.

Definition pairOut t1 t2 (e : exp (Prod t1 t2)) : option (exp t1 * exp t2) :=

match e in (exp (Prod t1 t2)) return option (exp t1 * exp t2) with|

Pair e1 e2 ) Some (e1 , e2 )| )

None
end.

Error : The reference t2 was not found in the current environment

We run again into the problem of not being able to specify non-variable arguments in in
clauses. The problem would just be hopeless without a use of an in clause, though, since the
result type of the match depends on an argument to exp. Our solution will be to use a more
general type, as we did for hd. First, we deo/ne a type-valued function to use in assigning a
type to pairOut.

Definition pairOutType (t : type) :=

match t with|

Prod t1 t2 ) option (exp t1 * exp t2 )| )

unit
end.

When passed a type that is a product, pairOutType returns our o/nal desired type. On any
other input type, pairOutType returns unit, since we do not care about extracting components
of non-pairs. Now we can write another helper function to provide the default behavior of

115

pairOut, which we will apply for inputs that are not literal pairs.
Definition pairOutDefault (t : type) :=

match t return (pairOutType t ) with|

Prod ) None| )

tt
end.

Now pairOut is deceptively easy to write.
Definition pairOut t (e : exp t ) :=

match e in (exp t ) return (pairOutType t ) with|

Pair e1 e2 ) Some (e1, e2 )| )

pairOutDefault
end.

There is one important subtlety in this deo/nition. Coq allows us to use convenient ML-
style pattern matching notation, but, internally and in proofs, we see that patterns are
expanded out completely, matching one level of inductive structure at a time. Thus, the
default case in the match above expands out to one case for each constructor of exp besides
Pair, and the underscore in pairOutDefault is resolved dioeerently in each case. From an
ML or Haskell programmer's perspective, what we have here is type inference determining
which code is run (returning either None or tt), which goes beyond what is possible with
type inference guiding parametric polymorphism in Hindley-Milner languages, but is similar
to what goes on with Haskell type classes.

With pairOut available, we can write cfold in a straightforward way. There are really
no surprises beyond that Coq verio/es that this code has such an expressive type, given the
small annotation burden. In some places, we see that Coq's match annotation inference is
too smart for its own good, and we have to turn that inference ooe by writing return .

Fixpoint cfold t (e : exp t ) : exp t :=

match e with|

NConst n ) NConst n|
Plus e1 e2 )

let e1' := cfold e1 in
let e2' := cfold e2 in
match e1', e2' return with|

NConst n1, NConst n2 ) NConst (n1 + n2 )|

, ) Plus e1' e2'
end|
Eq e1 e2 )

let e1' := cfold e1 in
let e2' := cfold e2 in
match e1', e2' return with|

NConst n1, NConst n2 ) BConst (if eq nat dec n1 n2 then true else false)|

, ) Eq e1' e2'

116

end
| BConst b ) BConst b|

And e1 e2 )

let e1' := cfold e1 in
let e2' := cfold e2 in
match e1', e2' return with|

BConst b1, BConst b2 ) BConst (b1 && b2 )|

, ) And e1' e2'
end|
If e e1 e2 )

let e' := cfold e in
match e' with|

BConst true ) cfold e1|
BConst false ) cfold e2| )

If e' (cfold e1 ) (cfold e2 )
end

| Pair e1 e2 ) Pair (cfold e1 ) (cfold e2 )|

Fst e )

let e' := cfold e in
match pairOut e' with|

Some p ) fst p|
None ) Fst e'
end|
Snd e )

let e' := cfold e in
match pairOut e' with|

Some p ) snd p|
None ) Snd e'
end
end.

The correctness theorem for cfold turns out to be easy to prove, once we get over one
serious hurdle.

Theorem cfold correct : 8 t (e : exp t ), expDenote e = expDenote (cfold e).

induction e; crush.

The o/rst remaining subgoal is:

expDenote (cfold e1 ) + expDenote (cfold e2 ) =

expDenote

match cfold e1 with|

NConst n1 )

117

match cfold e2 with|

NConst n2 ) NConst (n1 + n2 )|
Plus ) Plus (cfold e1 ) (cfold e2 )|
Eq ) Plus (cfold e1 ) (cfold e2 )|
BConst ) Plus (cfold e1 ) (cfold e2 )|
And ) Plus (cfold e1 ) (cfold e2 )|
If ) Plus (cfold e1 ) (cfold e2 )|
Pair ) Plus (cfold e1 ) (cfold e2 )|
Fst ) Plus (cfold e1 ) (cfold e2 )|
Snd ) Plus (cfold e1 ) (cfold e2 )
end|
Plus ) Plus (cfold e1 ) (cfold e2 )|
Eq ) Plus (cfold e1 ) (cfold e2 )|
BConst ) Plus (cfold e1 ) (cfold e2 )|
And ) Plus (cfold e1 ) (cfold e2 )|
If ) Plus (cfold e1 ) (cfold e2 )|
Pair ) Plus (cfold e1 ) (cfold e2 )|
Fst ) Plus (cfold e1 ) (cfold e2 )|
Snd ) Plus (cfold e1 ) (cfold e2 )
end

We would like to do a case analysis on cfold e1 , and we attempt that in the way that has
worked so far.

destruct (cfold e1 ).
User error : e1 is used in hypothesis e

Coq gives us another cryptic error message. Like so many others, this one basically means
that Coq is not able to build some proof about dependent types. It is hard to generate
helpful and specio/c error messages for problems like this, since that would require some kind
of understanding of the dependency structure of a piece of code. We will encounter many
examples of case-specio/c tricks for recovering from errors like this one.

For our current proof, we can use a tactic dep destruct deo/ned in the book Tactics module.
General elimination/inversion of dependently-typed hypotheses is undecidable, since it must
be implemented with match expressions that have the restriction on in clauses that we have
already discussed. dep destruct makes a best eoeort to handle some common cases, relying
upon the more primitive dependent destruction tactic that comes with Coq. In a future
chapter, we will learn about the explicit manipulation of equality proofs that is behind
dep destruct 's implementation in Ltac, but for now, we treat it as a useful black box.

dep destruct (cfold e1 ).

This successfully breaks the subgoal into 5 new subgoals, one for each constructor of exp

118

that could produce an exp Nat. Note that dep destruct is successful in ruling out the other
cases automatically, in eoeect automating some of the work that we have done manually in
implementing functions like hd and pairOut.

This is the only new trick we need to learn to complete the proof. We can back up and
give a short, automated proof. The main inconvenience in the proof is that we cannot write a
pattern that matches a match without including a case for every constructor of the inductive
type we match over.

Restart.
induction e; crush;

repeat (match goal with|

[ ` context [match cfold ?E with NConst ) | Plus )|

Eq ) | BConst ) | And )|
If ) | Pair )|
Fst ) | Snd ) end] ] )
dep destruct (cfold E )|
[ ` context [match pairOut (cfold ?E) with Some )|

None ) end] ] )
dep destruct (cfold E )|
[ ` (if ?E then else ) = ] ) destruct E
end; crush).
Qed.

7.3 Dependently-Typed Red-Black Trees
Red-black trees are a favorite purely-functional data structure with an interesting invariant.
We can use dependent types to enforce that operations on red-black trees preserve the
invariant. For simplicity, we specialize our red-black trees to represent sets of nats.

Inductive color : Set := Red | Black.
Inductive rbtree : color ! nat ! Set :=|

Leaf : rbtree Black 0|
RedNode : 8 n, rbtree Black n ! nat ! rbtree Black n ! rbtree Red n|
BlackNode : 8 c1 c2 n, rbtree c1 n ! nat ! rbtree c2 n ! rbtree Black (S n).

A value of type rbtree c d is a red-black tree node whose root has color c and that has
black depth d. The latter property means that there are no more than d black-colored nodes
on any path from the root to a leaf.

At o/rst, it can be unclear that this choice of type indices tracks any useful property. To
convince ourselves, we will prove that every red-black tree is balanced. We will phrase our
theorem in terms of a depth calculating function that ignores the extra information in the
types. It will be useful to parameterize this function over a combining operation, so that

119

we can re-use the same code to calculate the minimum or maximum height among all paths
from root to leaf.

Require Import Max Min.
Section depth.

Variable f : nat ! nat ! nat.

Fixpoint depth c n (t : rbtree c n) : nat :=

match t with|

Leaf ) 0|
RedNode t1 t2 ) S (f (depth t1 ) (depth t2 ))|
BlackNode t1 t2 ) S (f (depth t1 ) (depth t2 ))
end.
End depth.

Our proof of balanced-ness decomposes naturally into a lower bound and an upper bound.
We prove the lower bound o/rst. Unsurprisingly, a tree's black depth provides such a bound
on the minimum path length. We use the richly-typed procedure min dec to do case analysis
on whether min X Y equals X or Y.

Theorem depth min : 8 c n (t : rbtree c n), depth min t >= n.

induction t ; crush;

match goal with|

[ ` context [min ?X ?Y] ] ) destruct (min dec X Y )
end; crush.
Qed.

There is an analogous upper-bound theorem based on black depth. Unfortunately, a
symmetric proof script does not suOEce to establish it.

Theorem depth max : 8 c n (t : rbtree c n), depth max t <= 2 * n + 1.

induction t ; crush;

match goal with|

[ ` context [max ?X ?Y] ] ) destruct (max dec X Y )
end; crush.

Two subgoals remain. One of them is:
n : nat
t1 : rbtree Black n
n0 : nat
t2 : rbtree Black n
IHt1 : depth max t1 <= n + (n + 0) + 1
IHt2 : depth max t2 <= n + (n + 0) + 1
e : max (depth max t1) (depth max t2) = depth max t1
============================

S (depth max t1) <= n + (n + 0) + 1

120

We see that IHt1 is almost the fact we need, but it is not quite strong enough. We will
need to strengthen our induction hypothesis to get the proof to go through.

Abort.

In particular, we prove a lemma that provides a stronger upper bound for trees with
black root nodes. We got stuck above in a case about a red root node. Since red nodes have
only black children, our IH strengthening will enable us to o/nish the proof.

Lemma depth max' : 8 c n (t : rbtree c n), match c with|

Red ) depth max t <= 2 * n + 1|

Black ) depth max t <= 2 * n
end.
induction t ; crush;

match goal with|

[ ` context [max ?X ?Y] ] ) destruct (max dec X Y )
end; crush;
repeat (match goal with|

[ H : context [match ?C with Red ) | Black ) end] ` ] )

destruct C
end; crush).
Qed.

The original theorem follows easily from the lemma. We use the tactic generalize pf,
which, when pf proves the proposition P , changes the goal from Q to P ! Q . It is useful to
do this because it makes the truth of P manifest syntactically, so that automation machinery
can rely on P , even if that machinery is not smart enough to establish P on its own.

Theorem depth max : 8 c n (t : rbtree c n), depth max t <= 2 * n + 1.

intros; generalize (depth max' t ); destruct c; crush.
Qed.

The o/nal balance theorem establishes that the minimum and maximum path lengths of
any tree are within a factor of two of each other.

Theorem balanced : 8 c n (t : rbtree c n), 2 * depth min t + 1 >= depth max t.

intros; generalize (depth min t ); generalize (depth max t ); crush.
Qed.

Now we are ready to implement an example operation on our trees, insertion. Insertion
can be thought of as breaking the tree invariants locally but then rebalancing. In particular,
in intermediate states we o/nd red nodes that may have red children. The type rtree captures
the idea of such a node, continuing to track black depth as a type index.

Inductive rtree : nat ! Set :=|

RedNode' : 8 c1 c2 n, rbtree c1 n ! nat ! rbtree c2 n ! rtree n.

Before starting to deo/ne insert, we deo/ne predicates capturing when a data value is in
the set represented by a normal or possibly-invalid tree.

Section present.

121

Variable x : nat.
Fixpoint present c n (t : rbtree c n) : Prop :=

match t with|

Leaf ) False|
RedNode a y b ) present a . x = y . present b|
BlackNode a y b ) present a . x = y . present b
end.

Definition rpresent n (t : rtree n) : Prop :=

match t with|

RedNode' a y b ) present a . x = y . present b
end.
End present.

Insertion relies on two balancing operations. It will be useful to give types to these
operations using a relative of the subset types from last chapter. While subset types let
us pair a value with a proof about that value, here we want to pair a value with another
non-proof dependently-typed value. The sigT type o/lls this role.

Locate "- : & """.

Notation Scope
"- x : A & P """ := sigT (fun x : A ) P )

Print sigT.

Inductive sigT (A : Type) (P : A ! Type) : Type :=

existT : 8 x : A, P x ! sigT P

It will be helpful to deo/ne a concise notation for the constructor of sigT.
Notation "-! x ?""" := (existT x ).

Each balance function is used to construct a new tree whose keys include the keys of
two input trees, as well as a new key. One of the two input trees may violate the red-black
alternation invariant (that is, it has an rtree type), while the other tree is known to be valid.
Crucially, the two input trees have the same black depth.

A balance operation may return a tree whose root is of either color. Thus, we use a sigT
type to package the result tree with the color of its root. Here is the deo/nition of the o/rst
balance operation, which applies when the possibly-invalid rtree belongs to the left of the
valid rbtree.

Definition balance1 n (a : rtree n) (data : nat) c2 :=

match a in rtree n return rbtree c2 n!

- c : color & rbtree c (S n) "" with|
RedNode' t1 y t2 )

match t1 in rbtree c n return rbtree n ! rbtree c2 n!

- c : color & rbtree c (S n) "" with

122

| RedNode a x b ) fun c d )

-!RedNode (BlackNode a x b) y (BlackNode c data d )?""|
t1' ) fun t2 )

match t2 in rbtree c n return rbtree n ! rbtree c2 n!

- c : color & rbtree c (S n) "" with|
RedNode b x c ) fun a d )

-!RedNode (BlackNode a y b) x (BlackNode c data d )?""|
b ) fun a t ) -!BlackNode (RedNode a y b) data t ?""
end t1'
end t2
end.

We apply a trick that I call the convoy pattern. Recall that match annotations only make
it possible to describe a dependence of a match result type on the discriminee. There is no
automatic reo/nement of the types of free variables. However, it is possible to eoeect such a
reo/nement by o/nding a way to encode free variable type dependencies in the match result
type, so that a return clause can express the connection.

In particular, we can extend the match to return functions over the free variables whose
types we want to reo/ne. In the case of balance1, we only o/nd ourselves wanting to reo/ne
the type of one tree variable at a time. We match on one subtree of a node, and we want
the type of the other subtree to be reo/ned based on what we learn. We indicate this with
a return clause starting like rbtree n ! ..., where n is bound in an in pattern. Such a
match expression is applied immediately to the "old version" of the variable to be reo/ned,
and the type checker is happy.

After writing this code, even I do not understand the precise details of how balancing
works. I consulted Chris Okasaki's paper "Red-Black Trees in a Functional Setting" and
transcribed the code to use dependent types. Luckily, the details are not so important here;
types alone will tell us that insertion preserves balanced-ness, and we will prove that insertion
produces trees containing the right keys.

Here is the symmetric function balance2, for cases where the possibly-invalid tree appears
on the right rather than on the left.

Definition balance2 n (a : rtree n) (data : nat) c2 :=

match a in rtree n return rbtree c2 n ! - c : color & rbtree c (S n) "" with|

RedNode' t1 z t2 )

match t1 in rbtree c n return rbtree n ! rbtree c2 n!

- c : color & rbtree c (S n) "" with|
RedNode b y c ) fun d a )

-!RedNode (BlackNode a data b) y (BlackNode c z d )?""|
t1' ) fun t2 )

match t2 in rbtree c n return rbtree n ! rbtree c2 n!

- c : color & rbtree c (S n) "" with|
RedNode c z' d ) fun b a )

-!RedNode (BlackNode a data b) z (BlackNode c z' d )?""

123

| b ) fun a t ) -!BlackNode t data (RedNode a z b)?""
end t1'
end t2
end.

Now we are almost ready to get down to the business of writing an insert function. First,
we enter a section that declares a variable x , for the key we want to insert.

Section insert.

Variable x : nat.

Most of the work of insertion is done by a helper function ins, whose return types are
expressed using a type-level function insResult.

Definition insResult c n :=

match c with|

Red ) rtree n|
Black ) - c' : color & rbtree c' n ""
end.

That is, inserting into a tree with root color c and black depth n, the variety of tree we
get out depends on c. If we started with a red root, then we get back a possibly-invalid tree
of depth n. If we started with a black root, we get back a valid tree of depth n with a root
node of an arbitary color.

Here is the deo/nition of ins. Again, we do not want to dwell on the functional details.

Fixpoint ins c n (t : rbtree c n) : insResult c n :=

match t with|

Leaf ) -! RedNode Leaf x Leaf ?""|
RedNode a y b )

if le lt dec x y

then RedNode' (projT2 (ins a)) y b
else RedNode' a y (projT2 (ins b))|
BlackNode c1 c2 a y b )

if le lt dec x y

then

match c1 return insResult c1 ! with|

Red ) fun ins a ) balance1 ins a y b| )

fun ins a ) -! BlackNode (projT2 ins a) y b ?""
end (ins a)
else

match c2 return insResult c2 ! with|

Red ) fun ins b ) balance2 ins b y a| )

fun ins b ) -! BlackNode a y (projT2 ins b) ?""
end (ins b)
end.

The one new trick is a variation of the convoy pattern. In each of the last two pattern

124

matches, we want to take advantage of the typing connection between the trees a and b.
We might naively apply the convoy pattern directly on a in the o/rst match and on b in
the second. This satisio/es the type checker per se, but it does not satisfy the termination
checker. Inside each match, we would be calling ins recursively on a locally-bound variable.
The termination checker is not smart enough to trace the dataAEow into that variable, so the
checker does not know that this recursive argument is smaller than the original argument.
We make this fact clearer by applying the convoy pattern on the result of a recursive call,
rather than just on that call's argument.

Finally, we are in the home stretch of our eoeort to deo/ne insert. We just need a few
more deo/nitions of non-recursive functions. First, we need to give the o/nal characterization
of insert's return type. Inserting into a red-rooted tree gives a black-rooted tree where black
depth has increased, and inserting into a black-rooted tree gives a tree where black depth
has stayed the same and where the root is an arbitrary color.

Definition insertResult c n :=

match c with|

Red ) rbtree Black (S n)|
Black ) - c' : color & rbtree c' n ""
end.

A simple clean-up procedure translates insResults into insertResults.
Definition makeRbtree c n : insResult c n ! insertResult c n :=

match c with|

Red ) fun r )

match r with|

RedNode' a x b ) BlackNode a x b
end|
Black ) fun r ) r
end.

We modify Coq's default choice of implicit arguments for makeRbtree, so that we do not
need to specify the c and n arguments explicitly in later calls.

Implicit Arguments makeRbtree [c n].

Finally, we deo/ne insert as a simple composition of ins and makeRbtree.
Definition insert c n (t : rbtree c n) : insertResult c n :=

makeRbtree (ins t ).

As we noted earlier, the type of insert guarantees that it outputs balanced trees whose
depths have not increased too much. We also want to know that insert operates correctly on
trees interpreted as o/nite sets, so we o/nish this section with a proof of that fact.

Section present.

Variable z : nat.

The variable z stands for an arbitrary key. We will reason about z 's presence in particular
trees. As usual, outside the section the theorems we prove will quantify over all possible keys,

125

giving us the facts we wanted.

We start by proving the correctness of the balance operations. It is useful to deo/ne a
custom tactic present balance that encapsulates the reasoning common to the two proofs.
We use the keyword Ltac to assign a name to a proof script. This particular script just
iterates between crush and identio/cation of a tree that is being pattern-matched on and
should be destructed.

Ltac present balance :=

crush;
repeat (match goal with|

[ H : context [match ?T with|

Leaf )|
RedNode )|
BlackNode )
end] ` ] ) dep destruct T|
[ ` context [match ?T with|

Leaf )|
RedNode )|
BlackNode )
end] ] ) dep destruct T
end; crush).

The balance correctness theorems are simple o/rst-order logic equivalences, where we use
the function projT2 to project the payload of a sigT value.

Lemma present balance1 : 8 n (a : rtree n) (y : nat) c2 (b : rbtree c2 n) ,

present z (projT2 (balance1 a y b))$

rpresent z a . z = y . present z b.
destruct a; present balance.
Qed.

Lemma present balance2 : 8 n (a : rtree n) (y : nat) c2 (b : rbtree c2 n),

present z (projT2 (balance2 a y b))$

rpresent z a . z = y . present z b.
destruct a; present balance.
Qed.

To state the theorem for ins, it is useful to deo/ne a new type-level function, since ins
returns dioeerent result types based on the type indices passed to it. Recall that x is the
section variable standing for the key we are inserting.

Definition present insResult c n :=

match c return (rbtree c n ! insResult c n ! Prop) with|

Red ) fun t r ) rpresent z r $ z = x . present z t|
Black ) fun t r ) present z (projT2 r ) $ z = x . present z t
end.

Now the statement and proof of the ins correctness theorem are straightforward, if ver-

126

bose. We proceed by induction on the structure of a tree, followed by o/nding case analysis
opportunities on expressions we see being analyzed in if or match expressions. After that,
we pattern-match to o/nd opportunities to use the theorems we proved about balancing. Fi-
nally, we identify two variables that are asserted by some hypothesis to be equal, and we use
that hypothesis to replace one variable with the other everywhere.

Theorem present ins : 8 c n (t : rbtree c n),

present insResult t (ins t ).
induction t ; crush;

repeat (match goal with|

[ H : context [if ?E then else ] ` ] ) destruct E|
[ ` context [if ?E then else ] ] ) destruct E|
[ H : context [match ?C with Red ) | Black ) end]`

] ) destruct C
end; crush);
try match goal with|

[ H : context [balance1 ?A ?B ?C] ` ] )

generalize (present balance1 A B C )
end;
try match goal with|

[ H : context [balance2 ?A ?B ?C] ` ] )

generalize (present balance2 A B C )
end;
try match goal with|

[ ` context [balance1 ?A ?B ?C] ] )

generalize (present balance1 A B C )
end;
try match goal with|

[ ` context [balance2 ?A ?B ?C] ] )

generalize (present balance2 A B C )
end;
crush;

match goal with|

[ z : nat, x : nat ` ] )

match goal with|

[ H : z = x ` ] ) rewrite H in *; clear H
end
end;
tauto.
Qed.

The hard work is done. The most readable way to state correctness of insert involves
splitting the property into two color-specio/c theorems. We write a tactic to encapsulate the

127

reasoning steps that work to establish both facts.

Ltac present insert :=

unfold insert ; intros n t ; inversion t ;

generalize (present ins t ); simpl;

dep destruct (ins t ); tauto.

Theorem present insert Red : 8 n (t : rbtree Red n),

present z (insert t )$

(z = x . present z t ).
present insert.
Qed.

Theorem present insert Black : 8 n (t : rbtree Black n),

present z (projT2 (insert t ))$

(z = x . present z t ).
present insert.
Qed.
End present.
End insert.

7.4 A Certio/ed Regular Expression Matcher
Another interesting example is regular expressions with dependent types that express which
predicates over strings particular regexps implement. We can then assign a dependent type
to a regular expression matching function, guaranteeing that it always decides the string
property that we expect it to decide.

Before deo/ning the syntax of expressions, it is helpful to deo/ne an inductive type capturing
the meaning of the Kleene star. We use Coq's string support, which comes through a
combination of the Strings library and some parsing notations built into Coq. Operators
like ++ and functions like length that we know from lists are deo/ned again for strings.
Notation scopes help us control which versions we want to use in particular contexts.

Require Import Ascii String.
Open Scope string scope.

Section star.

Variable P : string ! Prop.

Inductive star : string ! Prop :=|

Empty : star ""|
Iter : 8 s1 s2,

P s1!

star s2!
star (s1 ++ s2 ).
End star.

128

Now we can make our o/rst attempt at deo/ning a regexp type that is indexed by predicates
on strings. Here is a reasonable-looking deo/nition that is restricted to constant characters
and concatenation.

Inductive regexp : (string ! Prop) ! Set :=|

Char : 8 ch : ascii,

regexp (fun s ) s = String ch "")|
Concat : 8 (P1 P2 : string ! Prop) (r1 : regexp P1 ) (r2 : regexp P2 ),

regexp (fun s ) 9 s1 , 9 s2 , s = s1 ++ s2 ^ P1 s1 ^ P2 s2 ).

User error : Large non-propositional inductive types must be in Type

What is a large inductive type? In Coq, it is an inductive type that has a constructor
which quantio/es over some type of type Type. We have not worked with Type very much to
this point. Every term of CIC has a type, including Set and Prop, which are assigned type
Type. The type string ! Prop from the failed deo/nition also has type Type.

It turns out that allowing large inductive types in Set leads to contradictions when
combined with certain kinds of classical logic reasoning. Thus, by default, such types are
ruled out. There is a simple o/x for our regexp deo/nition, which is to place our new type
in Type. While o/xing the problem, we also expand the list of constructors to cover the
remaining regular expression operators.

Inductive regexp : (string ! Prop) ! Type :=|

Char : 8 ch : ascii,

regexp (fun s ) s = String ch "")|
Concat : 8 P1 P2 (r1 : regexp P1 ) (r2 : regexp P2 ),

regexp (fun s ) 9 s1, 9 s2, s = s1 ++ s2 ^ P1 s1 ^ P2 s2 )|
Or : 8 P1 P2 (r1 : regexp P1 ) (r2 : regexp P2 ),

regexp (fun s ) P1 s . P2 s)|
Star : 8 P (r : regexp P ),

regexp (star P ).

Many theorems about strings are useful for implementing a certio/ed regexp matcher, and
few of them are in the Strings library. The book source includes statements, proofs, and
hint commands for a handful of such omittted theorems. Since they are orthogonal to our
use of dependent types, we hide them in the rendered versions of this book.

A few auxiliary functions help us in our o/nal matcher deo/nition. The function split will
be used to implement the regexp concatenation case.

Section split.

Variables P1 P2 : string ! Prop.
Variable P1 dec : 8 s, -P1 s"" + -~ P1 s"".
Variable P2 dec : 8 s, -P2 s"" + -~ P2 s"".

We require a choice of two arbitrary string predicates and functions for deciding them.

129

Variable s : string.

Our computation will take place relative to a single o/xed string, so it is easiest to make
it a Variable, rather than an explicit argument to our functions.

split' is the workhorse behind split. It searches through the possible ways of splitting s
into two pieces, checking the two predicates against each such pair. split' progresses right-
to-left, from splitting all of s into the o/rst piece to splitting all of s into the second piece. It
takes an extra argument, n, which specio/es how far along we are in this search process.

Definition split' (n : nat) : n <= length s!

-9 s1, 9 s2, length s1 <= n ^ s1 ++ s2 = s ^ P1 s1 ^ P2 s2 ""
+ -8 s1 s2, length s1 <= n ! s1 ++ s2 = s ! ~ P1 s1 . ~ P2 s2 "".
refine (o/x F (n : nat) : n <= length s!

-9 s1, 9 s2, length s1 <= n ^ s1 ++ s2 = s ^ P1 s1 ^ P2 s2 ""
+ -8 s1 s2, length s1 <= n ! s1 ++ s2 = s ! ~ P1 s1 . ~ P2 s2 "" :=
match n with|

O ) fun ) Reduce (P1 dec "" && P2 dec s)|
S n' ) fun ) (P1 dec (substring 0 (S n' ) s)

&& P2 dec (substring (S n' ) (length s - S n' ) s))
---- F n'
end); clear F ; crush; eauto 7;
match goal with|

[ : length ?S <= 0 ` ] ) destruct S|
[ : length ?S' <= S ?N ` ] )

generalize (eq nat dec (length S' ) (S N )); destruct 1
end; crush.
Defined.

There is one subtle point in the split' code that is worth mentioning. The main body
of the function is a match on n. In the case where n is known to be S n', we write S n'
in several places where we might be tempted to write n. However, without further work to
craft proper match annotations, the type-checker does not use the equality between n and S
n'. Thus, it is common to see patterns repeated in match case bodies in dependently-typed
Coq code. We can at least use a let expression to avoid copying the pattern more than
once, replacing the o/rst case body with:

| S n' ) fun ) let n := S n' in

(P1 dec (substring 0 n s)

&& P2 dec (substring n (length s - n) s))
---- F n'

split itself is trivial to implement in terms of split'. We just ask split' to begin its search
with n = length s.

Definition split : -9 s1, 9 s2, s = s1 ++ s2 ^ P1 s1 ^ P2 s2 ""

130

+ -8 s1 s2, s = s1 ++ s2 ! ~ P1 s1 . ~ P2 s2 "".
refine (Reduce (split' (n := length s) )); crush; eauto.
Defined.
End split.

Implicit Arguments split [P1 P2 ].

One more helper function will come in handy: dec star, for implementing another linear
search through ways of splitting a string, this time for implementing the Kleene star.

Section dec star.

Variable P : string ! Prop.
Variable P dec : 8 s, -P s"" + -~ P s"".

Some new lemmas and hints about the star type family are useful here. We omit them
here; they are included in the book source at this point.

The function dec starj implements a single iteration of the star. That is, it tries to o/nd a
string preo/x matching P , and it calls a parameter function on the remainder of the string.

Section dec starj.

Variable n : nat.
n is the length of the preo/x of s that we have already processed.

Variable P' : string ! Prop.
Variable P' dec : 8 n' : nat, n' ? n!

-P' (substring n' (length s - n' ) s)""
+ -~ P' (substring n' (length s - n' ) s)"".
When we use dec starj, we will instantiate P' dec with a function for continuing the
search for more instances of P in s.

Now we come to dec starj itself. It takes as an input a natural l that records how much
of the string has been searched so far, as we did for split'. The return type expresses that
dec starj is looking for an index into s that splits s into a nonempty preo/x and a suOEx, such
that the preo/x satiso/es P and the suOEx satiso/es P' .

Definition dec starj (l : nat)

: -9 l', S l' <= l^

P (substring n (S l' ) s) ^ P' (substring (n + S l' ) (length s - (n + S l' )) s)""
+ -8 l', S l' <= l! ~

P (substring n (S l' ) s). ~
P' (substring (n + S l' ) (length s - (n + S l' )) s)"".
refine (o/x F (l : nat) : -9 l', S l' <= l^

P (substring n (S l' ) s) ^ P' (substring (n + S l' ) (length s - (n + S l' )) s)""
+ -8 l', S l' <= l! ~

P (substring n (S l' ) s). ~
P' (substring (n + S l' ) (length s - (n + S l' )) s)"" :=
match l with

131

| O )|

S l' )

(P dec (substring n (S l' ) s) && P' dec (n' := n + S l' ) )
---- F l'
end); clear F ; crush; eauto 7;
match goal with|

[ H : ?X <= S ?Y ` ] ) destruct (eq nat dec X (S Y )); crush
end.
Defined.
End dec starj.

The work of dec starj is nested inside another linear search by dec star', which provides
the o/nal functionality we need, but for arbitrary suOExes of s, rather than just for s overall.

Definition dec star' (n n' : nat) : length s - n' <= n!

-star P (substring n' (length s - n' ) s)""
+ -~ star P (substring n' (length s - n' ) s)"".
refine (o/x F (n n' : nat) : length s - n' <= n!

-star P (substring n' (length s - n' ) s)""
+ -~ star P (substring n' (length s - n' ) s)"" :=
match n with|

O ) fun ) Yes|
S nj ) fun )

le gt dec (length s) n'
---- dec starj (n := n' ) (star P ) (fun n0 ) Reduce (F nj n0 )) (length s - n' )
end); clear F ; crush; eauto;
match goal with|

[ H : star ` ] ) apply star substring inv in H ; crush; eauto
end;
match goal with|

[ H1 : ! - , H2 : 8 l' : nat, <= - ! ` ] )

generalize (H2 (lt le S H1 )); tauto
end.
Defined.

Finally, we have dec star. It has a straightforward implementation. We introduce a
spurious match on s so that simpl will know to reduce calls to dec star. The heuristic that
simpl uses is only to unfold identio/er deo/nitions when doing so would simplify some match
expression.

Definition dec star : -star P s"" + -~ star P s"".

refine (match s return with|

"" ) Reduce (dec star' (n := length s) 0 )| )

Reduce (dec star' (n := length s) 0 )
end); crush.

132

Defined.
End dec star.

With these helper functions completed, the implementation of our matches function is
refreshingly straightforward. We only need one small piece of specio/c tactic work beyond
what crush does for us.

Definition matches P (r : regexp P ) s : -P s"" + -~ P s"".

refine (o/x F P (r : regexp P ) s : -P s"" + -~ P s"" :=

match r with|

Char ch ) string dec s (String ch "")|
Concat r1 r2 ) Reduce (split (F r1 ) (F r2 ) s)|
Or r1 r2 ) F r1 s ---- F r2 s|
Star r ) dec star
end); crush;
match goal with|

[ H : ` ] ) generalize (H (reAE equal ))
end; tauto.
Defined.

7.5 Exercises

1. Deo/ne a kind of dependently-typed lists, where a list's type index gives a lower bound

on how many of its elements satisfy a particular predicate. In particular, for an arbi-
trary set A and a predicate P over it:

(a) Deo/ne a type plist : nat ! Set. Each plist n should be a list of As, where it

is guaranteed that at least n distinct elements satisfy P . There is wide latitude
in choosing how to encode this. You should try to avoid using subset types or
any other mechanism based on annotating non-dependent types with propositions
after-the-fact.

(b) Deo/ne a version of list concatenation that works on plist s. The type of this new

function should express as much information as possible about the output plist.

(c) Deo/ne a function plistOut for translating plist s to normal lists.
(d) Deo/ne a function plistIn for translating lists to plist s. The type of plistIn should

make it clear that the best bound on P -matching elements is chosen. You may
assume that you are given a dependently-typed function for deciding instances of
P .

(e) Prove that, for any list ls, plistOut (plistIn ls) = ls. This should be the only part

of the exercise where you use tactic-based proving.

(f) Deo/ne a function grab : 8 n (ls : plist (S n)), sig P . That is, when given a

plist guaranteed to contain at least one element satisfying P , grab produces such

133

an element. sig is the type family of sigma types, and sig P is extensionally
equivalent to -x : A | P x "", though the latter form uses an eta-expansion of P
instead of P itself as the predicate.

134
Chapter 8
Dependent Data Structures

Our red-black tree example from the last chapter illustrated how dependent types enable
static enforcement of data structure invariants. To o/nd interesting uses of dependent data
structures, however, we need not look to the favorite examples of data structures and algo-
rithms textbooks. More basic examples like length-indexed and heterogeneous lists come up
again and again as the building blocks of dependent programs. There is a surprisingly large
design space for this class of data structure, and we will spend this chapter exploring it.

8.1 More Length-Indexed Lists
We begin with a deeper look at the length-indexed lists that began the last chapter.
Section ilist.

Variable A : Set.

Inductive ilist : nat ! Set :=|

Nil : ilist O|
Cons : 8 n, A ! ilist n ! ilist (S n).

We might like to have a certio/ed function for selecting an element of an ilist by position.
We could do this using subset types and explicit manipulation of proofs, but dependent types
let us do it more directly. It is helpful to deo/ne a type family o/n, where o/n n is isomorphic
to -m : nat | m ! n"". The type family names stands for "o/nite."

Inductive o/n : nat ! Set :=|

First : 8 n, o/n (S n)|
Next : 8 n, o/n n ! o/n (S n).

o/n essentially makes a more richly-typed copy of the natural numbers. Every element
is a First iterated through applying Next a number of times that indicates which number is
being selected.

Now it is easy to pick a Prop-free type for a selection function. As usual, our o/rst
implementation attempt will not convince the type checker, and we will attack the deo/ciencies

135

one at a time.

Fixpoint get n (ls : ilist n) : o/n n ! A :=

match ls with|

Nil ) fun idx ) ?|
Cons x ls' ) fun idx )

match idx with|

First ) x|
Next idx' ) get ls' idx'
end
end.

We apply the usual wisdom of delaying arguments in Fixpoints so that they may be
included in return clauses. This still leaves us with a quandary in each of the match cases.
First, we need to o/gure out how to take advantage of the contradiction in the Nil case. Every
o/n has a type of the form S n, which cannot unify with the O value that we learn for n in
the Nil case. The solution we adopt is another case of match-within-return.

Fixpoint get n (ls : ilist n) : o/n n ! A :=

match ls with|

Nil ) fun idx )

match idx in o/n n' return (match n' with|

O ) A|
S ) unit
end) with|
First ) tt|
Next ) tt
end|
Cons x ls' ) fun idx )

match idx with|

First ) x|
Next idx' ) get ls' idx'
end
end.

Now the o/rst match case type-checks, and we see that the problem with the Cons case is
that the pattern-bound variable idx' does not have an apparent type compatible with ls'. We
need to use match annotations to make the relationship explicit. Unfortunately, the usual
trick of postponing argument binding will not help us here. We need to match on both ls
and idx ; one or the other must be matched o/rst. To get around this, we apply the convoy
pattern that we met last chapter. This application is a little more clever than those we
saw before; we use the natural number predecessor function pred to express the relationship

136

between the types of these variables.

Fixpoint get n (ls : ilist n) : o/n n ! A :=

match ls with|

Nil ) fun idx )

match idx in o/n n' return (match n' with|

O ) A|
S ) unit
end) with|
First ) tt|
Next ) tt
end|
Cons x ls' ) fun idx )

match idx in o/n n' return ilist (pred n' ) ! A with|

First ) fun ) x|
Next idx' ) fun ls' ) get ls' idx'
end ls'
end.

There is just one problem left with this implementation. Though we know that the local
ls' in the Next case is equal to the original ls', the type-checker is not satiso/ed that the
recursive call to get does not introduce non-termination. We solve the problem by convoy-
binding the partial application of get to ls', rather than ls' by itself.

Fixpoint get n (ls : ilist n) : o/n n ! A :=

match ls with|

Nil ) fun idx )

match idx in o/n n' return (match n' with|

O ) A|
S ) unit
end) with|
First ) tt|
Next ) tt
end|
Cons x ls' ) fun idx )

match idx in o/n n' return (o/n (pred n' ) ! A) ! A with|

First ) fun ) x|
Next idx' ) fun get ls' ) get ls' idx'
end (get ls' )
end.
End ilist.

Implicit Arguments Nil [A].
Implicit Arguments First [n].

137

A few examples show how to make use of these deo/nitions.
Check Cons 0 (Cons 1 (Cons 2 Nil)).

Cons 0 (Cons 1 (Cons 2 Nil))

: ilist nat 3

Eval simpl in get (Cons 0 (Cons 1 (Cons 2 Nil))) First.

= 0
: nat

Eval simpl in get (Cons 0 (Cons 1 (Cons 2 Nil))) (Next First).

= 1
: nat

Eval simpl in get (Cons 0 (Cons 1 (Cons 2 Nil))) (Next (Next First)).

= 2
: nat

Our get function is also quite easy to reason about. We show how with a short example
about an analogue to the list map function.

Section ilist map.

Variables A B : Set.
Variable f : A ! B.

Fixpoint imap n (ls : ilist A n) : ilist B n :=

match ls with|

Nil ) Nil|
Cons x ls' ) Cons (f x ) (imap ls' )
end.

It is easy to prove that get "distributes over" imap calls. The only tricky bit is remem-
bering to use the dep destruct tactic in place of plain destruct when faced with a baO/ing
tactic error message.

Theorem get imap : 8 n (idx : o/n n) (ls : ilist A n),

get (imap ls) idx = f (get ls idx ).
induction ls; dep destruct idx ; crush.
Qed.
End ilist map.

8.2 Heterogeneous Lists
Programmers who move to statically-typed functional languages from "scripting languages"
often complain about the requirement that every element of a list have the same type. With
fancy type systems, we can partially lift this requirement. We can index a list type with a
"type-level" list that explains what type each element of the list should have. This has been

138

done in a variety of ways in Haskell using type classes, and we can do it much more cleanly
and directly in Coq.

Section hlist.

Variable A : Type.
Variable B : A ! Type.

We parameterize our heterogeneous lists by a type A and an A-indexed type B .
Inductive hlist : list A ! Type :=|

MNil : hlist nil|
MCons : 8 (x : A) (ls : list A), B x ! hlist ls ! hlist (x :: ls).

We can implement a variant of the last section's get function for hlists. To get the
dependent typing to work out, we will need to index our element selectors by the types of
data that they point to.

Variable elm : A.
Inductive member : list A ! Type :=|

MFirst : 8 ls, member (elm :: ls)|
MNext : 8 x ls, member ls ! member (x :: ls).

Because the element elm that we are "searching for" in a list does not change across the
constructors of member, we simplify our deo/nitions by making elm a local variable. In the
deo/nition of member, we say that elm is found in any list that begins with elm, and, if
removing the o/rst element of a list leaves elm present, then elm is present in the original
list, too. The form looks much like a predicate for list membership, but we purposely deo/ne
member in Type so that we may decompose its values to guide computations.

We can use member to adapt our deo/nition of get to hlists. The same basic match tricks
apply. In the MCons case, we form a two-element convoy, passing both the data element x
and the recursor for the sublist mls' to the result of the inner match. We did not need to do
that in get's deo/nition because the types of list elements were not dependent there.

Fixpoint hget ls (mls : hlist ls) : member ls ! B elm :=

match mls with|

MNil ) fun mem )

match mem in member ls' return (match ls' with|

nil ) B elm|

:: ) unit
end) with|
MFirst ) tt|
MNext ) tt
end|
MCons x mls' ) fun mem )

match mem in member ls' return (match ls' with|

nil ) Empty set|
x' :: lsj )

139

B x' ! (member lsj ! B elm) ! B elm
end) with|
MFirst ) fun x ) x|
MNext mem' ) fun get mls' ) get mls' mem'
end x (hget mls' )
end.
End hlist.

Implicit Arguments MNil [A B ].
Implicit Arguments MCons [A B x ls].

Implicit Arguments MFirst [A elm ls].
Implicit Arguments MNext [A elm x ls].

By putting the parameters A and B in Type, we allow some very higher-order uses. For
instance, one use of hlist is for the simple heterogeneous lists that we referred to earlier.

Definition someTypes : list Set := nat :: bool :: nil.

Example someValues : hlist (fun T : Set ) T ) someTypes :=

MCons 5 (MCons true MNil).

Eval simpl in hget someValues MFirst.

= 5
: (fun T : Set ) T ) nat

Eval simpl in hget someValues (MNext MFirst).

= true
: (fun T : Set ) T ) bool

We can also build indexed lists of pairs in this way.
Example somePairs : hlist (fun T : Set ) T * T )%type someTypes :=

MCons (1, 2) (MCons (true, false) MNil).

8.2.1 A Lambda Calculus Interpreter
Heterogeneous lists are very useful in implementing interpreters for functional programming
languages. Using the types and operations we have already deo/ned, it is trivial to write an
interpreter for simply-typed lambda calculus. Our interpreter can alternatively be thought
of as a denotational semantics.

We start with an algebraic datatype for types.

Inductive type : Set :=|

Unit : type|
Arrow : type ! type ! type.

Now we can deo/ne a type family for expressions. An exp ts t will stand for an expression
that has type t and whose free variables have types in the list ts. We eoeectively use the

140

de Bruijn variable representation, which we will discuss in more detail in later chapters.
Variables are represented as member values; that is, a variable is more or less a constructive
proof that a particular type is found in the type environment.

Inductive exp : list type ! type ! Set :=|

Const : 8 ts, exp ts Unit

| Var : 8 ts t, member t ts ! exp ts t|

App : 8 ts dom ran, exp ts (Arrow dom ran) ! exp ts dom ! exp ts ran|
Abs : 8 ts dom ran, exp (dom :: ts) ran ! exp ts (Arrow dom ran).

Implicit Arguments Const [ts].

We write a simple recursive function to translate types into Sets.
Fixpoint typeDenote (t : type) : Set :=

match t with|

Unit ) unit|
Arrow t1 t2 ) typeDenote t1 ! typeDenote t2
end.

Now it is straightforward to write an expression interpreter. The type of the function,
expDenote, tells us that we translate expressions into functions from properly-typed environ-
ments to o/nal values. An environment for a free variable list ts is simply a hlist typeDenote
ts. That is, for each free variable, the heterogeneous list that is the environment must have
a value of the variable's associated type. We use hget to implement the Var case, and we use
MCons to extend the environment in the Abs case.

Fixpoint expDenote ts t (e : exp ts t ) : hlist typeDenote ts ! typeDenote t :=

match e with|

Const ) fun ) tt

| Var mem ) fun s ) hget s mem|

App e1 e2 ) fun s ) (expDenote e1 s) (expDenote e2 s)|
Abs e' ) fun s ) fun x ) expDenote e' (MCons x s)
end.

Like for previous examples, our interpreter is easy to run with simpl.
Eval simpl in expDenote Const MNil.

= tt

: typeDenote Unit

Eval simpl in expDenote (Abs (dom := Unit) (Var MFirst)) MNil.

= fun x : unit ) x
: typeDenote (Arrow Unit Unit)

Eval simpl in expDenote (Abs (dom := Unit)

(Abs (dom := Unit) (Var (MNext MFirst)))) MNil.

141

= fun x : unit ) x
: typeDenote (Arrow Unit (Arrow Unit Unit))

Eval simpl in expDenote (Abs (dom := Unit) (Abs (dom := Unit) (Var MFirst))) MNil.

= fun x0 : unit ) x0
: typeDenote (Arrow Unit (Arrow Unit Unit))

Eval simpl in expDenote (App (Abs (Var MFirst)) Const) MNil.

= tt
: typeDenote Unit

We are starting to develop the tools behind dependent typing's amazing advantage over
alternative approaches in several important areas. Here, we have implemented complete
syntax, typing rules, and evaluation semantics for simply-typed lambda calculus without
even needing to deo/ne a syntactic substitution operation. We did it all without a single line
of proof, and our implementation is manifestly executable. In a later chapter, we will meet
other, more common approaches to language formalization. Such approaches often state and
prove explicit theorems about type safety of languages. In the above example, we got type
safety, termination, and other meta-theorems for free, by reduction to CIC, which we know
has those properties.

8.3 Recursive Type Deo/nitions
There is another style of datatype deo/nition that leads to much simpler deo/nitions of the get
and hget deo/nitions above. Because Coq supports "type-level computation," we can redo
our inductive deo/nitions as recursive deo/nitions.

Section o/list.

Variable A : Set.

Fixpoint o/list (n : nat) : Set :=

match n with|

O ) unit|
S n' ) A * o/list n'
end%type.

We say that a list of length 0 has no contents, and a list of length S n' is a pair of a data
value and a list of length n'.

Fixpoint OEn (n : nat) : Set :=

match n with|

O ) Empty set|
S n' ) option (OEn n' )
end.

142

We express that there are no index values when n = O, by deo/ning such indices as type
Empty set; and we express that, at n = S n', there is a choice between picking the o/rst
element of the list (represented as None) or choosing a later element (represented by Some
idx, where idx is an index into the list tail).

Fixpoint fget (n : nat) : o/list n ! OEn n ! A :=

match n with|

O ) fun idx ) match idx with end|
S n' ) fun ls idx )

match idx with|

None ) fst ls|
Some idx' ) fget n' (snd ls) idx'
end
end.

Our new get implementation needs only one dependent match, and its annotation is
inferred for us. Our choices of data structure implementations lead to just the right typing
behavior for this new deo/nition to work out.

End o/list.

Heterogeneous lists are a little trickier to deo/ne with recursion, but we then reap similar
beneo/ts in simplicity of use.

Section fhlist.

Variable A : Type.
Variable B : A ! Type.

Fixpoint fhlist (ls : list A) : Type :=

match ls with|

nil ) unit|
x :: ls' ) B x * fhlist ls'
end%type.

The deo/nition of fhlist follows the deo/nition of o/list, with the added wrinkle of dependently-
typed data elements.

Variable elm : A.
Fixpoint fmember (ls : list A) : Type :=

match ls with|

nil ) Empty set|
x :: ls' ) (x = elm) + fmember ls'
end%type.

The deo/nition of fmember follows the deo/nition of OEn. Empty lists have no members,
and member types for nonempty lists are built by adding one new option to the type of
members of the list tail. While for index we needed no new information associated with the
option that we add, here we need to know that the head of the list equals the element we

143

are searching for. We express that with a sum type whose left branch is the appropriate
equality proposition. Since we deo/ne fmember to live in Type, we can insert Prop types as
needed, because Prop is a subtype of Type.

We know all of the tricks needed to write a o/rst attempt at a get function for fhlists.

Fixpoint fhget (ls : list A) : fhlist ls ! fmember ls ! B elm :=

match ls with|

nil ) fun idx ) match idx with end|

:: ls' ) fun mls idx )
match idx with|

inl ) fst mls|
inr idx' ) fhget ls' (snd mls) idx'
end
end.

Only one problem remains. The expression fst mls is not known to have the proper type.
To demonstrate that it does, we need to use the proof available in the inl case of the inner
match.

Fixpoint fhget (ls : list A) : fhlist ls ! fmember ls ! B elm :=

match ls with|

nil ) fun idx ) match idx with end|

:: ls' ) fun mls idx )
match idx with|

inl pf ) match pf with|

reAE equal ) fst mls
end|
inr idx' ) fhget ls' (snd mls) idx'
end
end.

By pattern-matching on the equality proof pf, we make that equality known to the type-
checker. Exactly why this works can be seen by studying the deo/nition of equality.

Print eq.
Inductive eq (A : Type) (x : A) : A ! Prop := reAE equal : x = x

In a proposition x = y, we see that x is a parameter and y is a regular argument. The
type of the constructor reAE equal shows that y can only ever be instantiated to x . Thus,
within a pattern-match with reAE equal, occurrences of y can be replaced with occurrences of
x for typing purposes.

End fhlist.
Implicit Arguments fhget [A B elm ls].

144

8.4 Data Structures as Index Functions
Indexed lists can be useful in deo/ning other inductive types with constructors that take vari-
able numbers of arguments. In this section, we consider parameterized trees with arbitrary
branching factor.

Section tree.

Variable A : Set.

Inductive tree : Set :=|

Leaf : A ! tree|
Node : 8 n, ilist tree n ! tree.
End tree.

Every Node of a tree has a natural number argument, which gives the number of child
trees in the second argument, typed with ilist. We can deo/ne two operations on trees of
naturals: summing their elements and incrementing their elements. It is useful to deo/ne a
generic fold function on ilists o/rst.

Section ifoldr.

Variables A B : Set.
Variable f : A ! B ! B.
Variable i : B.

Fixpoint ifoldr n (ls : ilist A n) : B :=

match ls with|

Nil ) i|
Cons x ls' ) f x (ifoldr ls' )
end.
End ifoldr.

Fixpoint sum (t : tree nat) : nat :=

match t with|

Leaf n ) n|
Node ls ) ifoldr (fun t' n ) sum t' + n) O ls
end.

Fixpoint inc (t : tree nat) : tree nat :=

match t with|

Leaf n ) Leaf (S n)|
Node ls ) Node (imap inc ls)
end.

Now we might like to prove that inc does not decrease a tree's sum.
Theorem sum inc : 8 t, sum (inc t ) >= sum t.

induction t ; crush.

145

n : nat
i : ilist (tree nat) n
============================

ifoldr (fun (t' : tree nat) (n0 : nat) ) sum t' + n0 ) 0 (imap inc i) >=
ifoldr (fun (t' : tree nat) (n0 : nat) ) sum t' + n0 ) 0 i

We are left with a single subgoal which does not seem provable directly. This is the same
problem that we met in Chapter 3 with other nested inductive types.

Check tree ind.
tree ind

: 8 (A : Set) (P : tree A ! Prop),

(8 a : A, P (Leaf a)) !
(8 (n : nat) (i : ilist (tree A) n), P (Node i)) !8

t : tree A, P t

The automatically-generated induction principle is too weak. For the Node case, it gives
us no inductive hypothesis. We could write our own induction principle, as we did in Chapter
3, but there is an easier way, if we are willing to alter the deo/nition of tree.

Abort.
Reset tree.

First, let us try using our recursive deo/nition of ilists instead of the inductive version.
Section tree.

Variable A : Set.

Inductive tree : Set :=|

Leaf : A ! tree|
Node : 8 n, o/list tree n ! tree.

Error : Non strictly positive occurrence of "tree" in

"forall n : nat, o/list tree n ! tree"

The special-case rule for nested datatypes only works with nested uses of other inductive
types, which could be replaced with uses of new mutually-inductive types. We deo/ned o/list
recursively, so it may not be used for nested recursion.

Our o/nal solution uses yet another of the inductive deo/nition techniques introduced in
Chapter 3, reAEexive types. Instead of merely using o/n to get elements out of ilist, we can
deo/ne ilist in terms of o/n. For the reasons outlined above, it turns out to be easier to work
with OEn in place of o/n.

Inductive tree : Set :=|

Leaf : A ! tree|
Node : 8 n, (OEn n ! tree) ! tree.

146

A Node is indexed by a natural number n, and the node's n children are represented as
a function from OEn n to trees, which is isomorphic to the ilist-based representation that we
used above.

End tree.
Implicit Arguments Node [A n].

We can redeo/ne sum and inc for our new tree type. Again, it is useful to deo/ne a generic
fold function o/rst. This time, it takes in a function whose range is some OEn type, and it folds
another function over the results of calling the o/rst function at every possible OEn value.

Section rifoldr.

Variables A B : Set.
Variable f : A ! B ! B.
Variable i : B.

Fixpoint rifoldr (n : nat) : (OEn n ! A) ! B :=

match n with|

O ) fun ) i|
S n' ) fun get ) f (get None) (rifoldr n' (fun idx ) get (Some idx )))
end.
End rifoldr.

Implicit Arguments rifoldr [A B n].
Fixpoint sum (t : tree nat) : nat :=

match t with|

Leaf n ) n|
Node f ) rifoldr plus O (fun idx ) sum (f idx ))
end.

Fixpoint inc (t : tree nat) : tree nat :=

match t with|

Leaf n ) Leaf (S n)|
Node f ) Node (fun idx ) inc (f idx ))
end.

Now we are ready to prove the theorem where we got stuck before. We will not need to
deo/ne any new induction principle, but it will be helpful to prove some lemmas.

Lemma plus ge : 8 x1 y1 x2 y2,

x1 >= x2!

y1 >= y2!
x1 + y1 >= x2 + y2.
crush.
Qed.

Lemma sum inc' : 8 n (f1 f2 : OEn n ! nat),

(8 idx, f1 idx >= f2 idx )

147

! rifoldr plus 0 f1 >= rifoldr plus 0 f2.
Hint Resolve plus ge.

induction n; crush.
Qed.

Theorem sum inc : 8 t, sum (inc t ) >= sum t.

Hint Resolve sum inc'.

induction t ; crush.
Qed.

Even if Coq would generate complete induction principles automatically for nested in-
ductive deo/nitions like the one we started with, there would still be advantages to using this
style of reAEexive encoding. We see one of those advantages in the deo/nition of inc, where
we did not need to use any kind of auxiliary function. In general, reAEexive encodings often
admit direct implementations of operations that would require recursion if performed with
more traditional inductive data structures.

8.4.1 Another Interpreter Example
We develop another example of variable-arity constructors, in the form of optimization of
a small expression language with a construct like Scheme's cond. Each of our conditional
expressions takes a list of pairs of boolean tests and bodies. The value of the conditional
comes from the body of the o/rst test in the list to evaluate to true. To simplify the interpreter
we will write, we force each conditional to include a o/nal, default case.

Inductive type' : Type := Nat | Bool.
Inductive exp' : type' ! Type :=|

NConst : nat ! exp' Nat|
Plus : exp' Nat ! exp' Nat ! exp' Nat|
Eq : exp' Nat ! exp' Nat ! exp' Bool

| BConst : bool ! exp' Bool
| Cond : 8 n t, (OEn n ! exp' Bool)!

(OEn n ! exp' t ) ! exp' t ! exp' t.

A Cond is parameterized by a natural n, which tells us how many cases this conditional
has. The test expressions are represented with a function of type OEn n ! exp' Bool, and
the bodies are represented with a function of type OEn n ! exp' t , where t is the overall
type. The o/nal exp' t argument is the default case.

We start implementing our interpreter with a standard type denotation function.

Definition type'Denote (t : type') : Set :=

match t with|

Nat ) nat

148

| Bool ) bool
end.

To implement the expression interpreter, it is useful to have the following function that
implements the functionality of Cond without involving any syntax.

Section cond.

Variable A : Set.
Variable default : A.

Fixpoint cond (n : nat) : (OEn n ! bool) ! (OEn n ! A) ! A :=

match n with|

O ) fun ) default|
S n' ) fun tests bodies )

if tests None

then bodies None
else cond n'

(fun idx ) tests (Some idx ))
(fun idx ) bodies (Some idx ))
end.
End cond.

Implicit Arguments cond [A n].

Now the expression interpreter is straightforward to write.
Fixpoint exp'Denote t (e : exp' t ) : type'Denote t :=

match e with|

NConst n ) n|
Plus e1 e2 ) exp'Denote e1 + exp'Denote e2|
Eq e1 e2 )

if eq nat dec (exp'Denote e1 ) (exp'Denote e2 ) then true else false

| BConst b ) b|

Cond tests bodies default )

cond
(exp'Denote default )
(fun idx ) exp'Denote (tests idx ))
(fun idx ) exp'Denote (bodies idx ))

end.

We will implement a constant-folding function that optimizes conditionals, removing
cases with known-false tests and cases that come after known-true tests. A function cfoldCond
implements the heart of this logic. The convoy pattern is used again near the end of the
implementation.

Section cfoldCond.

149

Variable t : type'.
Variable default : exp' t.

Fixpoint cfoldCond (n : nat)

: (OEn n ! exp' Bool) ! (OEn n ! exp' t ) ! exp' t :=
match n with|

O ) fun ) default|
S n' ) fun tests bodies )

match tests None return with|

BConst true ) bodies None|
BConst false ) cfoldCond n'

(fun idx ) tests (Some idx ))
(fun idx ) bodies (Some idx ))| )

let e := cfoldCond n'

(fun idx ) tests (Some idx ))
(fun idx ) bodies (Some idx )) in
match e in exp' t return exp' t ! exp' t with|

Cond n tests' bodies' default' ) fun body )

Cond
(S n)
(fun idx ) match idx with|

None ) tests None|
Some idx ) tests' idx
end)
(fun idx ) match idx with|

None ) body|
Some idx ) bodies' idx
end)
default'|
e ) fun body )

Cond
1
(fun ) tests None)
(fun ) body )
e
end (bodies None)
end
end.
End cfoldCond.

Implicit Arguments cfoldCond [t n].

Like for the interpreters, most of the action was in this helper function, and cfold itself
is easy to write.

150

Fixpoint cfold t (e : exp' t ) : exp' t :=

match e with|

NConst n ) NConst n|
Plus e1 e2 )

let e1' := cfold e1 in
let e2' := cfold e2 in
match e1', e2' return with|

NConst n1, NConst n2 ) NConst (n1 + n2 )|

, ) Plus e1' e2'
end|
Eq e1 e2 )

let e1' := cfold e1 in
let e2' := cfold e2 in
match e1', e2' return with|

NConst n1, NConst n2 ) BConst (if eq nat dec n1 n2 then true else false)|

, ) Eq e1' e2'
end

| BConst b ) BConst b|

Cond tests bodies default )

cfoldCond
(cfold default )
(fun idx ) cfold (tests idx ))
(fun idx ) cfold (bodies idx ))

end.

To prove our o/nal correctness theorem, it is useful to know that cfoldCond preserves
expression meanings. This lemma formalizes that property. The proof is a standard mostly-
automated one, with the only wrinkle being a guided instantation of the quantio/ers in the
induction hypothesis.

Lemma cfoldCond correct : 8 t (default : exp' t )

n (tests : OEn n ! exp' Bool) (bodies : OEn n ! exp' t ),
exp'Denote (cfoldCond default tests bodies )
= exp'Denote (Cond n tests bodies default ).
induction n; crush;

match goal with|

[ IHn : 8 tests bodies, , tests : ! , bodies : ! ` ] )

generalize (IHn (fun idx ) tests (Some idx )) (fun idx ) bodies (Some idx )));

clear IHn; intro IHn
end;
repeat (match goal with

151

| [ ` context [match ?E with|

NConst )|
Plus )|
Eq )|
BConst )|
Cond )
end] ] ) dep destruct E|
[ ` context [if ?B then else ] ] ) destruct B
end; crush).
Qed.

It is also useful to know that the result of a call to cond is not changed by substituting
new tests and bodies functions, so long as the new functions have the same input-output
behavior as the old. It turns out that, in Coq, it is not possible to prove in general that
functions related in this way are equal. We treat this issue with our discussion of axioms in
a later chapter. For now, it suOEces to prove that the particular function cond is extensional ;
that is, it is unaoeected by substitution of functions with input-output equivalents.

Lemma cond ext : 8 (A : Set) (default : A) n (tests tests' : OEn n ! bool)

(bodies bodies' : OEn n ! A),
(8 idx, tests idx = tests' idx )!

(8 idx, bodies idx = bodies' idx )!
cond default tests bodies
= cond default tests' bodies'.
induction n; crush;

match goal with|

[ ` context [if ?E then else ] ] ) destruct E
end; crush.
Qed.

Now the o/nal theorem is easy to prove. We add our two lemmas as hints and perform
standard automation with pattern-matching of subterms to destruct.

Theorem cfold correct : 8 t (e : exp' t ),

exp'Denote (cfold e) = exp'Denote e.
Hint Rewrite cfoldCond correct : cpdt.
Hint Resolve cond ext.

induction e; crush;

repeat (match goal with|

[ ` context [cfold ?E] ] ) dep destruct (cfold E )
end; crush).
Qed.

152

8.5 Choosing Between Representations
It is not always clear which of these representation techniques to apply in a particular
situation, but I will try to summarize the pros and cons of each.

Inductive types are often the most pleasant to work with, after someone has spent the
time implementing some basic library functions for them, using fancy match annotations.
Many aspects of Coq's logic and tactic support are specialized to deal with inductive types,
and you may miss out if you use alternate encodings.

Recursive types usually involve much less initial eoeort, but they can be less convenient to
use with proof automation. For instance, the simpl tactic (which is among the ingredients
in crush) will sometimes be overzealous in simplifying uses of functions over recursive types.
Consider a call get l f, where variable l has type o/list A (S n). The type of l would be
simplio/ed to an explicit pair type. In a proof involving many recursive types, this kind of
unhelpful "simplio/cation" can lead to rapid bloat in the sizes of subgoals.

Another disadvantage of recursive types is that they only apply to type families whose
indices determine their "skeletons." This is not true for all data structures; a good coun-
terexample comes from the richly-typed programming language syntax types we have used
several times so far. The fact that a piece of syntax has type Nat tells us nothing about the
tree structure of that syntax.

ReAEexive encodings of data types are seen relatively rarely. As our examples demon-
strated, manipulating index values manually can lead to hard-to-read code. A normal in-
ductive type is generally easier to work with, once someone has gone through the trouble
of implementing an induction principle manually with the techniques we studied in Chap-
ter 3. For small developments, avoiding that kind of coding can justify the use of reAEexive
data structures. There are also some useful instances of co-inductive deo/nitions with nested
data structures (e.g., lists of values in the co-inductive type) that can only be deconstructed
eoeectively with reAEexive encoding of the nested structures.

8.6 Exercises
Some of the type family deo/nitions and associated functions from this chapter are duplicated
in the DepList module of the book source. Some of their names have been changed to be
more sensible in a general context.

1. Deo/ne a tree analogue of hlist. That is, deo/ne a parameterized type of binary trees

with data at their leaves, and deo/ne a type family htree indexed by trees. The structure
of an htree mirrors its index tree, with the type of each data element (which only occur
at leaves) determined by applying a type function to the corresponding element of the
index tree. Deo/ne a type standing for all possible paths from the root of a tree to
leaves and use it to implement a function tget for extracting an element of an htree
by path. Deo/ne a function htmap2 for "mapping over two trees in parallel." That is,

153

htmap2 takes in two htrees with the same index tree, and it forms a new htree with
the same index by applying a binary function pointwise.

Repeat this process so that you implement each deo/nition for each of the three deo/ni-
tion styles covered in this chapter: inductive, recursive, and index function.

2. Write a dependently-typed interpreter for a simple programming language with ML-

style pattern-matching, using one of the encodings of heterogeneous lists to represent
the dioeerent branches of a case expression. (There are other ways to represent the
same thing, but the point of this exercise is to practice using those heterogeneous list
types.) The object language is deo/ned informally by this grammar:

t ::= bool | t + t
p ::= x | b | inl p | inr p
e ::= x | b | inl e | inr e | case e of [p ) e]* | ) e

x stands for a variable, and b stands for a boolean constant. The production for case
expressions means that a pattern-match includes zero or more pairs of patterns and
expressions, along with a default case.
Your interpreter should be implemented in the style demonstrated in this chapter. That
is, your deo/nition of expressions should use dependent types and de Bruijn indices to
combine syntax and typing rules, such that the type of an expression tells the types
of variables that are in scope. You should implement a simple recursive function
translating types t to Set, and your interpreter should produce values in the image of
this translation.

154

Chapter 9
Reasoning About Equality Proofs

In traditional mathematics, the concept of equality is usually taken as a given. On the
other hand, in type theory, equality is a very contentious subject. There are at least three
dioeerent notions of equality that are important, and researchers are actively investigating
new deo/nitions of what it means for two terms to be equal. Even once we o/x a notion of
equality, there are inevitably tricky issues that arise in proving properties of programs that
manipulate equality proofs explicitly. In this chapter, we will focus on design patterns for
circumventing these tricky issues, and we will introduce the dioeerent notions of equality as
they are germane.

9.1 The Deo/nitional Equality
We have seen many examples so far where proof goals follow "by computation." That is, we
apply computational reduction rules to reduce the goal to a normal form, at which point
it follows trivially. Exactly when this works and when it does not depends on the details
of Coq's deo/nitional equality. This is an untyped binary relation appearing in the formal
metatheory of CIC. CIC contains a typing rule allowing the conclusion E : T from the
premise E : T 0 and a proof that T and T 0 are deo/nitionally equal.

The cbv tactic will help us illustrate the rules of Coq's deo/nitional equality. We redeo/ne
the natural number predecessor function in a somewhat convoluted way and construct a
manual proof that it returns 0 when applied to 1.

Definition pred' (x : nat) :=

match x with|

O ) O|
S n' ) let y := n' in y
end.

Theorem reduce me : pred' 1 = 0.

CIC follows the traditions of lambda calculus in associating reduction rules with Greek
letters. Coq can certainly be said to support the familiar alpha reduction rule, which allows

155

capture-avoiding renaming of bound variables, but we never need to apply alpha explicitly,
since Coq uses a de Bruijn representation that encodes terms canonically.

The delta rule is for unfolding global deo/nitions. We can use it here to unfold the
deo/nition of pred'. We do this with the cbv tactic, which takes a list of reduction rules and
makes as many call-by-value reduction steps as possible, using only those rules. There is an
analogous tactic lazy for call-by-need reduction.

cbv delta.

============================

(fun x : nat ) match x with|

0 ) 0|
S n' ) let y := n' in y
end) 1 = 0

At this point, we want to apply the famous beta reduction of lambda calculus, to simplify
the application of a known function abstraction.

cbv beta.

============================

match 1 with|

0 ) 0|
S n' ) let y := n' in y
end = 0

Next on the list is the iota reduction, which simplio/es a single match term by determining
which pattern matches.

cbv iota.

============================

(fun n' : nat ) let y := n' in y) 0 = 0

Now we need another beta reduction.
cbv beta.

============================

(let y := 0 in y) = 0

The o/nal reduction rule is zeta, which replaces a let expression by its body with the
appropriate term subsituted.

cbv zeta.

156

============================

0 = 0

reflexivity.
Qed.

The standard eq relation is critically dependent on the deo/nitional equality. eq is often
called a propositional equality, because it reio/es deo/nitional equality as a proposition that
may or may not hold. Standard axiomatizations of an equality predicate in o/rst-order logic
deo/ne equality in terms of properties it has, like reAEexivity, symmetry, and transitivity.
In contrast, for eq in Coq, those properties are implicit in the properties of the deo/nitional
equality, which are built into CIC's metatheory and the implementation of Gallina. We could
add new rules to the deo/nitional equality, and eq would keep its deo/nition and methods of
use.

This all may make it sound like the choice of eq's deo/nition is unimportant. To the
contrary, in this chapter, we will see examples where alternate deo/nitions may simplify
proofs. Before that point, we will introduce eoeective proof methods for goals that use proofs
of the standard propositional equality "as data."

9.2 Heterogeneous Lists Revisited
One of our example dependent data structures from the last chapter was heterogeneous
lists and their associated "cursor" type. The recursive version poses some special challenges
related to equality proofs, since it uses such proofs in its deo/nition of member types.

Section fhlist.

Variable A : Type.
Variable B : A ! Type.

Fixpoint fhlist (ls : list A) : Type :=

match ls with|

nil ) unit|
x :: ls' ) B x * fhlist ls'
end%type.

Variable elm : A.
Fixpoint fmember (ls : list A) : Type :=

match ls with|

nil ) Empty set|
x :: ls' ) (x = elm) + fmember ls'
end%type.

Fixpoint fhget (ls : list A) : fhlist ls ! fmember ls ! B elm :=

match ls return fhlist ls ! fmember ls ! B elm with|

nil ) fun idx ) match idx with end

157

| :: ls' ) fun mls idx )

match idx with|

inl pf ) match pf with|

reAE equal ) fst mls
end|
inr idx' ) fhget ls' (snd mls) idx'
end
end.
End fhlist.

Implicit Arguments fhget [A B elm ls].

We can deo/ne a map-like function for fhlists.
Section fhlist map.

Variables A : Type.
Variables B C : A ! Type.
Variable f : 8 x, B x ! C x.

Fixpoint fhmap (ls : list A) : fhlist B ls ! fhlist C ls :=

match ls return fhlist B ls ! fhlist C ls with|

nil ) fun ) tt|

:: ) fun hls ) (f (fst hls ), fhmap (snd hls ))
end.

Implicit Arguments fhmap [ls].

For the inductive versions of the ilist deo/nitions, we proved a lemma about the interaction
of get and imap. It was a strategic choice not to attempt such a proof for the deo/nitions
that we just gave, because that sets us on a collision course with the problems that are the
subject of this chapter.

Variable elm : A.
Theorem get imap : 8 ls (mem : fmember elm ls) (hls : fhlist B ls),

fhget (fhmap hls) mem = f (fhget hls mem).
induction ls; crush.

Part of our single remaining subgoal is:

a0 : a = elm
============================

match a0 in ( = a2 ) return (C a2 ) with|

reAE equal ) f a1
end = f match a0 in ( = a2 ) return (B a2 ) with|

reAE equal ) a1
end

This seems like a trivial enough obligation. The equality proof a0 must be reAE equal,

158

since that is the only constructor of eq. Therefore, both the matches reduce to the point
where the conclusion follows by reAEexivity.

destruct a0.
User error : Cannot solve a second -order unio/cation problem

This is one of Coq's standard error messages for informing us that its heuristics for
attempting an instance of an undecidable problem about dependent typing have failed. We
might try to nudge things in the right direction by stating the lemma that we believe makes
the conclusion trivial.

assert (a0 = reAE equal ).
The term "reAE equal ?98" has type "?98 = ?98"

while it is expected to have type "a = elm"

In retrospect, the problem is not so hard to see. ReAEexivity proofs only show x = x for
particular values of x , whereas here we are thinking in terms of a proof of a = elm, where
the two sides of the equality are not equal syntactically. Thus, the essential lemma we need
does not even type-check!

Is it time to throw in the towel? Luckily, the answer is "no." In this chapter, we will see
several useful patterns for proving obligations like this.

For this particular example, the solution is surprisingly straightforward. destruct has
a simpler sibling case which should behave identically for any inductive type with one
constructor of no arguments.

case a0.

============================

f a1 = f a1

It seems that destruct was trying to be too smart for its own good.

reflexivity.
Qed.

It will be helpful to examine the proof terms generated by this sort of strategy. A simpler
example illustrates what is going on.

Lemma lemma1 : 8 x (pf : x = elm), O = match pf with reAE equal ) O end.

simple destruct pf ; reflexivity.
Qed.

simple destruct pf is a convenient form for applying case. It runs intro to bring into
scope all quantio/ed variables up to its argument.

159

Print lemma1.
lemma1 =
fun (x : A) (pf : x = elm) )
match pf as e in ( = y) return (0 = match e with|

reAE equal ) 0
end) with|
reAE equal ) reAE equal 0
end

: 8 (x : A) (pf : x = elm), 0 = match pf with|

reAE equal ) 0
end

Using what we know about shorthands for match annotations, we can write this proof in
shorter form manually.

Definition lemma1' :=

fun (x : A) (pf : x = elm) )

match pf return (0 = match pf with|

reAE equal ) 0
end) with|
reAE equal ) reAE equal 0
end.

Surprisingly, what seems at o/rst like a simpler lemma is harder to prove.
Lemma lemma2 : 8 (x : A) (pf : x = x ), O = match pf with reAE equal ) O end.

simple destruct pf.
User error : Cannot solve a second -order unio/cation problem

Abort.

Nonetheless, we can adapt the last manual proof to handle this theorem.
Definition lemma2 :=

fun (x : A) (pf : x = x ) )

match pf return (0 = match pf with|

reAE equal ) 0
end) with|
reAE equal ) reAE equal 0
end.

We can try to prove a lemma that would simplify proofs of many facts like lemma2:
Lemma lemma3 : 8 (x : A) (pf : x = x ), pf = reAE equal x.

simple destruct pf.

160

User error : Cannot solve a second -order unio/cation problem

Abort.

This time, even our manual attempt fails.

Definition lemma3' :=

fun (x : A) (pf : x = x ) )

match pf as pf ' in ( = x' ) return (pf ' = reAE equal x' ) with|

reAE equal ) reAE equal
end.

The term "reAE equal x'" has type "x' = x'" while it is expected to have type

"x = x'"

The type error comes from our return annotation. In that annotation, the as-bound
variable pf ' has type x = x', refering to the in-bound variable x'. To do a dependent match,
we must choose a fresh name for the second argument of eq. We are just as constrained to
use the "real" value x for the o/rst argument. Thus, within the return clause, the proof we
are matching on must equate two non-matching terms, which makes it impossible to equate
that proof with reAEexivity.

Nonetheless, it turns out that, with one catch, we can prove this lemma.

Lemma lemma3 : 8 (x : A) (pf : x = x ), pf = reAE equal x.

intros; apply UIP reAE.
Qed.

Check UIP reAE.
UIP reAE

: 8 (U : Type) (x : U ) (p : x = x ), p = reAE equal x

UIP reAE comes from the Eqdep module of the standard library. Do the Coq authors know
of some clever trick for building such proofs that we have not seen yet? If they do, they did
not use it for this proof. Rather, the proof is based on an axiom.

Print eq rect eq.
eq rect eq =
fun U : Type ) Eq rect eq.eq rect eq U

: 8 (U : Type) (p : U ) (Q : U ! Type) (x : Q p) (h : p = p),

x = eq rect p Q x p h

eq rect eq states a "fact" that seems like common sense, once the notation is deciphered.
eq rect is the automatically-generated recursion principle for eq. Calling eq rect is another
way of matching on an equality proof. The proof we match on is the argument h, and x is
the body of the match. eq rect eq just says that matches on proofs of p = p, for any p, are

161

superAEuous and may be removed.

Perhaps surprisingly, we cannot prove eq rect eq from within Coq. This proposition is
introduced as an axiom; that is, a proposition asserted as true without proof. We cannot
assert just any statement without proof. Adding False as an axiom would allow us to prove
any proposition, for instance, defeating the point of using a proof assistant. In general,
we need to be sure that we never assert inconsistent sets of axioms. A set of axioms is
inconsistent if its conjunction implies False. For the case of eq rect eq, consistency has
been verio/ed outside of Coq via "informal" metatheory.

This axiom is equivalent to another that is more commonly known and mentioned in type
theory circles.

Print Streicher K.
Streicher K =
fun U : Type ) UIP reAE Streicher K U (UIP reAE U )

: 8 (U : Type) (x : U ) (P : x = x ! Prop),

P (reAE equal x ) ! 8 p : x = x , P p

This is the unfortunately-named "Streicher's axiom K," which says that a predicate on
properly-typed equality proofs holds of all such proofs if it holds of reAEexivity.

End fhlist map.

9.3 Type-Casts in Theorem Statements
Sometimes we need to use tricks with equality just to state the theorems that we care about.
To illustrate, we start by deo/ning a concatenation function for fhlists.

Section fhapp.

Variable A : Type.
Variable B : A ! Type.

Fixpoint fhapp (ls1 ls2 : list A)

: fhlist B ls1 ! fhlist B ls2 ! fhlist B (ls1 ++ ls2 ) :=
match ls1 with|

nil ) fun hls2 ) hls2|

:: ) fun hls1 hls2 ) (fst hls1, fhapp (snd hls1 ) hls2 )
end.

Implicit Arguments fhapp [ls1 ls2 ].

We might like to prove that fhapp is associative.

Theorem fhapp ass : 8 ls1 ls2 ls3

(hls1 : fhlist B ls1 ) (hls2 : fhlist B ls2 ) (hls3 : fhlist B ls3 ),
fhapp hls1 (fhapp hls2 hls3 ) = fhapp (fhapp hls1 hls2 ) hls3.

162

The term

"fhapp (ls1:=ls1 ++ ls2) (ls2:=ls3) (fhapp (ls1:=ls1) (ls2:=ls2) hls1 hls2)

hls3" has type "fhlist B ((ls1 ++ ls2) ++ ls3)"
while it is expected to have type "fhlist B (ls1 ++ ls2 ++ ls3)"

This o/rst cut at the theorem statement does not even type-check. We know that the two
fhlist types appearing in the error message are always equal, by associativity of normal list
append, but this fact is not apparent to the type checker. This stems from the fact that
Coq's equality is intensional, in the sense that type equality theorems can never be applied
after the fact to get a term to type-check. Instead, we need to make use of equality explicitly
in the theorem statement.

Theorem fhapp ass : 8 ls1 ls2 ls3

(pf : (ls1 ++ ls2 ) ++ ls3 = ls1 ++ (ls2 ++ ls3 ))
(hls1 : fhlist B ls1 ) (hls2 : fhlist B ls2 ) (hls3 : fhlist B ls3 ),
fhapp hls1 (fhapp hls2 hls3 )
= match pf in ( = ls) return fhlist ls with|

reAE equal ) fhapp (fhapp hls1 hls2 ) hls3
end.
induction ls1 ; crush.

The o/rst remaining subgoal looks trivial enough:

============================

fhapp (ls1 :=ls2) (ls2 :=ls3) hls2 hls3 =
match pf in ( = ls) return (fhlist B ls) with|

reAE equal ) fhapp (ls1 :=ls2) (ls2 :=ls3) hls2 hls3
end

We can try what worked in previous examples.

case pf.
User error : Cannot solve a second -order unio/cation problem

It seems we have reached another case where it is unclear how to use a dependent match
to implement case analysis on our proof. The UIP reAE theorem can come to our rescue
again.

rewrite (UIP reAE pf ).

============================

fhapp (ls1 :=ls2) (ls2 :=ls3) hls2 hls3 =
fhapp (ls1 :=ls2) (ls2 :=ls3) hls2 hls3

163

reflexivity.
Our second subgoal is trickier.

pf : a :: (ls1 ++ ls2 ) ++ ls3 = a :: ls1 ++ ls2 ++ ls3
============================

(a0,
fhapp (ls1 :=ls1) (ls2 :=ls2 ++ ls3 ) b

(fhapp (ls1 :=ls2) (ls2 :=ls3) hls2 hls3 )) =
match pf in ( = ls) return (fhlist B ls) with|

reAE equal )

(a0,
fhapp (ls1 :=ls1 ++ ls2 ) (ls2 :=ls3)

(fhapp (ls1 :=ls1) (ls2 :=ls2) b hls2 ) hls3 )
end

rewrite (UIP reAE pf ).
The term "pf" has type "a :: (ls1 ++ ls2) ++ ls3 = a :: ls1 ++ ls2 ++ ls3"

while it is expected to have type "?556 = ?556"

We can only apply UIP reAE on proofs of equality with syntactically equal operands, which
is not the case of pf here. We will need to manipulate the form of this subgoal to get us
to a point where we may use UIP reAE. A o/rst step is obtaining a proof suitable to use in
applying the induction hypothesis. Inversion on the structure of pf is suOEcient for that.

injection pf ; intro pf '.

pf : a :: (ls1 ++ ls2 ) ++ ls3 = a :: ls1 ++ ls2 ++ ls3
pf ' : (ls1 ++ ls2 ) ++ ls3 = ls1 ++ ls2 ++ ls3
============================

(a0,
fhapp (ls1 :=ls1) (ls2 :=ls2 ++ ls3 ) b

(fhapp (ls1 :=ls2) (ls2 :=ls3) hls2 hls3 )) =
match pf in ( = ls) return (fhlist B ls) with|

reAE equal )

(a0,
fhapp (ls1 :=ls1 ++ ls2 ) (ls2 :=ls3)

(fhapp (ls1 :=ls1) (ls2 :=ls2) b hls2 ) hls3 )
end

Now we can rewrite using the inductive hypothesis.

164

rewrite (IHls1 pf ' ).
============================

(a0,
match pf ' in ( = ls) return (fhlist B ls) with|

reAE equal )

fhapp (ls1 :=ls1 ++ ls2 ) (ls2 :=ls3)

(fhapp (ls1 :=ls1) (ls2 :=ls2) b hls2 ) hls3
end) =
match pf in ( = ls) return (fhlist B ls) with|

reAE equal )

(a0,
fhapp (ls1 :=ls1 ++ ls2 ) (ls2 :=ls3)

(fhapp (ls1 :=ls1) (ls2 :=ls2) b hls2 ) hls3 )
end

We have made an important bit of progress, as now only a single call to fhapp appears
in the conclusion. Trying case analysis on our proofs still will not work, but there is a move
we can make to enable it. Not only does just one call to fhapp matter to us now, but it also
does not matter what the result of the call is. In other words, the subgoal should remain true
if we replace this fhapp call with a fresh variable. The generalize tactic helps us do exactly
that.

generalize (fhapp (fhapp b hls2 ) hls3 ).

8 f : fhlist B ((ls1 ++ ls2 ) ++ ls3 ),
(a0,
match pf ' in ( = ls) return (fhlist B ls) with|

reAE equal ) f
end) =
match pf in ( = ls) return (fhlist B ls) with|

reAE equal ) (a0, f)
end

The conclusion has gotten markedly simpler. It seems counterintuitive that we can have
an easier time of proving a more general theorem, but that is exactly the case here and
for many other proofs that use dependent types heavily. Speaking informally, the reason
why this kind of activity helps is that match annotations only support variables in certain
positions. By reducing more elements of a goal to variables, built-in tactics can have more
success building match terms under the hood.

In this case, it is helpful to generalize over our two proofs as well.

generalize pf pf '.

165

8 (pf0 : a :: (ls1 ++ ls2 ) ++ ls3 = a :: ls1 ++ ls2 ++ ls3 )

(pf '0 : (ls1 ++ ls2 ) ++ ls3 = ls1 ++ ls2 ++ ls3 )
(f : fhlist B ((ls1 ++ ls2 ) ++ ls3 )),
(a0,
match pf '0 in ( = ls) return (fhlist B ls) with|

reAE equal ) f
end) =
match pf0 in ( = ls) return (fhlist B ls) with|

reAE equal ) (a0, f)
end

To an experienced dependent types hacker, the appearance of this goal term calls for a
celebration. The formula has a critical property that indicates that our problems are over.
To get our proofs into the right form to apply UIP reAE, we need to use associativity of list
append to rewrite their types. We could not do that before because other parts of the goal
require the proofs to retain their original types. In particular, the call to fhapp that we
generalized must have type (ls1 ++ ls2 ) ++ ls3, for some values of the list variables. If we
rewrite the type of the proof used to type-cast this value to something like ls1 ++ ls2 ++
ls3 = ls1 ++ ls2 ++ ls3, then the lefthand side of the equality would no longer match the
type of the term we are trying to cast.

However, now that we have generalized over the fhapp call, the type of the term being
type-cast appears explicitly in the goal and may be rewritten as well. In particular, the o/nal
masterstroke is rewriting everywhere in our goal using associativity of list append.

rewrite app ass.

============================8

(pf0 : a :: ls1 ++ ls2 ++ ls3 = a :: ls1 ++ ls2 ++ ls3 )

(pf '0 : ls1 ++ ls2 ++ ls3 = ls1 ++ ls2 ++ ls3 )
(f : fhlist B (ls1 ++ ls2 ++ ls3 )),
(a0,
match pf '0 in ( = ls) return (fhlist B ls) with|

reAE equal ) f
end) =
match pf0 in ( = ls) return (fhlist B ls) with|

reAE equal ) (a0, f)
end

We can see that we have achieved the crucial property: the type of each generalized
equality proof has syntactically equal operands. This makes it easy to o/nish the proof with
UIP reAE.

intros.
rewrite (UIP reAE pf0 ).

166

rewrite (UIP reAE pf '0 ).
reflexivity.
Qed.
End fhapp.

Implicit Arguments fhapp [A B ls1 ls2 ].

9.4 Heterogeneous Equality
There is another equality predicate, deo/ned in the JMeq module of the standard library,
implementing heterogeneous equality.

Print JMeq.
Inductive JMeq (A : Type) (x : A) : 8 B : Type, B ! Prop :=

JMeq reAE : JMeq x x

JMeq stands for "John Major equality," a name coined by Conor McBride as a sort of
pun about British politics. JMeq starts out looking a lot like eq. The crucial dioeerence is
that we may use JMeq on arguments of dioeerent types. For instance, a lemma that we failed
to establish before is trivial with JMeq. It makes for prettier theorem statements to deo/ne
some syntactic shorthand o/rst.

Infix "==" := JMeq (at level 70, no associativity).
Definition UIP reAE' (A : Type) (x : A) (pf : x = x ) : pf == reAE equal x :=

match pf return (pf == reAE equal ) with|

reAE equal ) JMeq reAE
end.

There is no quick way to write such a proof by tactics, but the underlying proof term
that we want is trivial.

Suppose that we want to use UIP reAE' to establish another lemma of the kind of we have
run into several times so far.

Lemma lemma4 : 8 (A : Type) (x : A) (pf : x = x ),

O = match pf with reAE equal ) O end.
intros; rewrite (UIP reAE' pf ); reflexivity.
Qed.

All in all, refreshingly straightforward, but there really is no such thing as a free lunch.
The use of rewrite is implemented in terms of an axiom:

Check JMeq eq.
JMeq eq

: 8 (A : Type) (x y : A), x == y ! x = y

167

It may be surprising that we cannot prove that heterogeneous equality implies normal
equality. The diOEculties are the same kind we have seen so far, based on limitations of match
annotations.

We can redo our fhapp associativity proof based around JMeq.

Section fhapp'.

Variable A : Type.
Variable B : A ! Type.

This time, the naive theorem statement type-checks.

Theorem fhapp ass' : 8 ls1 ls2 ls3

(hls1 : fhlist B ls1 ) (hls2 : fhlist B ls2 ) (hls3 : fhlist B ls3 ),
fhapp hls1 (fhapp hls2 hls3 ) == fhapp (fhapp hls1 hls2 ) hls3.
induction ls1 ; crush.

Even better, crush discharges the o/rst subgoal automatically. The second subgoal is:

============================

(a0,
fhapp (B :=B) (ls1 :=ls1) (ls2 :=ls2 ++ ls3 ) b

(fhapp (B :=B) (ls1 :=ls2) (ls2 :=ls3) hls2 hls3 )) ==
(a0,
fhapp (B :=B) (ls1 :=ls1 ++ ls2 ) (ls2 :=ls3)

(fhapp (B :=B) (ls1 :=ls1) (ls2 :=ls2) b hls2 ) hls3 )

It looks like one rewrite with the inductive hypothesis should be enough to make the goal
trivial.

rewrite IHls1.
Error : Impossible to unify "fhlist B ((ls1 ++ ?1572) ++ ?1573)" with

"fhlist B (ls1 ++ ?1572 ++ ?1573)"

We see that JMeq is not a silver bullet. We can use it to simplify the statements of
equality facts, but the Coq type-checker uses non-trivial heterogeneous equality facts no
more readily than it uses standard equality facts. Here, the problem is that the form (e1 ,
e2 ) is syntactic sugar for an explicit application of a constructor of an inductive type. That
application mentions the type of each tuple element explicitly, and our rewrite tries to
change one of those elements without updating the corresponding type argument.

We can get around this problem by another multiple use of generalize. We want to
bring into the goal the proper instance of the inductive hypothesis, and we also want to
generalize the two relevant uses of fhapp.

generalize (fhapp b (fhapp hls2 hls3 ))

(fhapp (fhapp b hls2 ) hls3 )

168

(IHls1 b hls2 hls3 ).
============================8

(f : fhlist B (ls1 ++ ls2 ++ ls3 ))

(f0 : fhlist B ((ls1 ++ ls2 ) ++ ls3 )), f == f0 ! (a0, f) == (a0, f0 )

Now we can rewrite with append associativity, as before.

rewrite app ass.

============================8

f f0 : fhlist B (ls1 ++ ls2 ++ ls3 ), f == f0 ! (a0, f) == (a0, f0 )

From this point, the goal is trivial.

intros f f0 H ; rewrite H ; reflexivity.
Qed.
End fhapp'.

9.5 Equivalence of Equality Axioms
Assuming axioms (like axiom K and JMeq eq) is a hazardous business. The due diligence
associated with it is necessarily global in scope, since two axioms may be consistent alone
but inconsistent together. It turns out that all of the major axioms proposed for reasoning
about equality in Coq are logically equivalent, so that we only need to pick one to assert
without proof. In this section, we demonstrate this by showing how each the previous two
sections' approaches reduces to the other logically.

To show that JMeq and its axiom let us prove UIP reAE, we start from the lemma UIP reAE'
from the previous section. The rest of the proof is trivial.

Lemma UIP reAEj : 8 (A : Type) (x : A) (pf : x = x ), pf = reAE equal x.

intros; rewrite (UIP reAE' pf ); reflexivity.
Qed.

The other direction is perhaps more interesting. Assume that we only have the axiom of
the Eqdep module available. We can deo/ne JMeq in a way that satiso/es the same interface
as the combination of the JMeq module's inductive deo/nition and axiom.

Definition JMeq' (A : Type) (x : A) (B : Type) (y : B ) : Prop :=9

pf : B = A, x = match pf with reAE equal ) y end.

Infix "===" := JMeq' (at level 70, no associativity ).

We say that, by deo/nition, x and y are equal if and only if there exists a proof pf that
their types are equal, such that x equals the result of casting y with pf. This statement can
look strange from the standpoint of classical math, where we almost never mention proofs
explicitly with quantio/ers in formulas, but it is perfectly legal Coq code.

169

We can easily prove a theorem with the same type as that of the JMeq reAE constructor
of JMeq.

Theorem JMeq reAE' : 8 (A : Type) (x : A), x === x.

intros; unfold JMeq' ; exists (reAE equal A); reflexivity.
Qed.

The proof of an analogue to JMeq eq is a little more interesting, but most of the action
is in appealing to UIP reAE.

Theorem JMeq eq' : 8 (A : Type) (x y : A),

x === y ! x = y.
unfold JMeq' ; intros.

H : 9 pf : A = A,

x = match pf in ( = T ) return T with|

reAE equal ) y
end
============================

x = y

destruct H.
x0 : A = A
H : x = match x0 in ( = T ) return T with|

reAE equal ) y
end
============================

x = y

rewrite H.
x0 : A = A
============================

match x0 in ( = T ) return T with|

reAE equal ) y
end = y

rewrite (UIP reAE x0 ); reflexivity.
Qed.

We see that, in a very formal sense, we are free to switch back and forth between the
two styles of proofs about equality proofs. One style may be more convenient than the other
for some proofs, but we can always intercovert between our results. The style that does not

170

use heterogeneous equality may be preferable in cases where many results do not require
the tricks of this chapter, since then the use of axioms is avoided altogether for the simple
cases, and a wider audience will be able to follow those "simple" proofs. On the other hand,
heterogeneous equality often makes for shorter and more readable theorem statements.

It is worth remarking that it is possible to avoid axioms altogether for equalities on types
with decidable equality. The Eqdep dec module of the standard library contains a parametric
proof of UIP reAE for such cases.

9.6 Equality of Functions
The following seems like a reasonable theorem to want to hold, and it does hold in set theory.

Theorem S eta : S = (fun n ) S n).
Unfortunately, this theorem is not provable in CIC without additional axioms. None of
the deo/nitional equality rules force function equality to be extensional. That is, the fact
that two functions return equal results on equal inputs does not imply that the functions
are equal. We can assert function extensionality as an axiom.

Axiom ext eq : 8 A B (f g : A ! B ),

(8 x, f x = g x )!

f = g.

This axiom has been verio/ed metatheoretically to be consistent with CIC and the two
equality axioms we considered previously. With it, the proof of S eta is trivial.

Theorem S eta : S = (fun n ) S n).

apply ext eq; reflexivity.
Qed.

The same axiom can help us prove equality of types, where we need to "reason under
quantio/ers."

Theorem forall eq : (8 x : nat, match x with|

O ) True|
S ) True
end)
= (8 : nat, True).

There are no immediate opportunities to apply ext eq, but we can use change to o/x
that.

change ((8 x : nat, (fun x ) match x with|

0 ) True|
S ) True
end) x ) = (nat ! True)).
rewrite (ext eq (fun x ) match x with

171

| 0 ) True|

S ) True
end) (fun ) True)).

2 subgoals

============================

(nat ! True) = (nat ! True)

subgoal 2 is:8

x : nat, match x with|

0 ) True|
S ) True
end = True

reflexivity.
destruct x ; constructor.
Qed.

9.7 Exercises

1. Implement and prove correct a substitution function for simply-typed lambda calculus.

In particular:

(a) Deo/ne a datatype type of lambda types, including just booleans and function

types.

(b) Deo/ne a type family exp : list type ! type ! Type of lambda expressions,

including boolean constants, variables, and function application and abstraction.

(c) Implement a deo/nitional interpreter for exps, by way of a recursive function over

expressions and substitutions for free variables, like in the related example from
the last chapter.

(d) Implement a function subst : 8 t' ts t , exp (t' :: ts) t ! exp ts t' ! exp ts

t . The type of the o/rst expression indicates that its most recently bound free
variable has type t'. The second expression also has type t', and the job of subst
is to substitute the second expression for every occurrence of the "o/rst" variable
of the o/rst expression.

(e) Prove that subst preserves program meanings. That is, prove8

t' ts t (e : exp (t' :: ts) t ) (e' : exp ts t' ) (s : hlist typeDenote ts),

expDenote (subst e e' ) s = expDenote e (expDenote e' s ::: s)

where ::: is an ino/x operator for heterogeneous "cons" that is deo/ned in the book's
DepList module.

172

The material presented up to this point should be suOEcient to enable a good solution
of this exercise, with enough ingenuity. If you get stuck, it may be helpful to use the
following structure. None of these elements need to appear in your solution, but we
can at least guarantee that there is a reasonable solution based on them.

(a) The DepList module will be useful. You can get the standard dependent list

deo/nitions there, instead of copying-and-pasting from the last chapter. It is worth
reading the source for that module over, since it deo/nes some new helpful functions
and notations that we did not use last chapter.

(b) Deo/ne a recursive function liftVar : 8 ts1 ts2 t t', member t (ts1 ++ ts2 ) !

member t (ts1 ++ t' :: ts2 ). This function should "lift" a de Bruijn variable so
that its type refers to a new variable inserted somewhere in the index list.

(c) Deo/ne a recursive function lift' : 8 ts t (e : exp ts t ) ts1 ts2 t', ts = ts1 ++

ts2 ! exp (ts1 ++ t' :: ts2 ) t which performs a similar lifting on an exp. The
convoluted type is to get around restrictions on match annotations. We delay
"realizing" that the o/rst index of e is built with list concatenation until after a
dependent match, and the new explicit proof argument must be used to cast some
terms that come up in the match body.

(d) Deo/ne a function lift : 8 ts t t', exp ts t ! exp (t' :: ts) t , which handles simpler

top-level lifts. This should be an easy one-liner based on lift'.

(e) Deo/ne a recursive function substVar : 8 ts1 ts2 t t', member t (ts1 ++ t' :: ts2 )!

(t' = t ) + member t (ts1 ++ ts2 ). This function is the workhorse behind
substitution applied to a variable. It returns inl to indicate that the variable we
pass to it is the variable that we are substituting for, and it returns inr to indicate
that the variable we are examining is not the one we are substituting for. In the
o/rst case, we get a proof that the necessary typing relationship holds, and, in the
second case, we get the original variable modio/ed to reAEect the removal of the
substitutee from the typing context.

(f) Deo/ne a recursive function subst' : 8 ts t (e : exp ts t ) ts1 t' ts2, ts = ts1 ++

t' :: ts2 ! exp (ts1 ++ ts2 ) t' ! exp (ts1 ++ ts2 ) t . This is the workhorse
of substitution in expressions, employing the same proof-passing trick as for lift'.
You will probably want to use lift somewhere in the deo/nition of subst'.

(g) Now subst should be a one-liner, deo/ned in terms of subst'.
(h) Prove a correctness theorem for each auxiliary function, leading up to the proof

of subst correctness.

(i) All of the reasoning about equality proofs in these theorems follows a regular

pattern. If you have an equality proof that you want to replace with reAE equal
somehow, run generalize on that proof variable. Your goal is to get to the
point where you can rewrite with the original proof to change the type of the
generalized version. To avoid type errors (the infamous "second-order unio/cation"

173

failure messages), it will be helpful to run generalize on other pieces of the
proof context that mention the equality's lefthand side. You might also want to
use generalize dependent, which generalizes not just one variable but also all
variables whose types depend on it. generalize dependent has the sometimes-
helpful property of removing from the context all variables that it generalizes.
Once you do manage the mind-bending trick of using the equality proof to rewrite
its own type, you will be able to rewrite with UIP reAE.

(j) A variant of the ext eq axiom from the end of this chapter is available in the

book module Axioms, and you will probably want to use it in the lift' and subst'
correctness proofs.

(k) The change tactic should come in handy in the proofs about lift and subst, where

you want to introduce "extraneous" list concatenations with nil to match the forms
of earlier theorems.

(l) Be careful about destructing a term "too early." You can use generalize on

proof terms to bring into the proof context any important propositions about the
term. Then, when you destruct the term, it is updated in the extra propositions,
too. The case eq tactic is another alternative to this approach, based on saving
an equality between the original term and its new form.

174

Chapter 10
Generic Programming

Generic programming makes it possible to write functions that operate over dioeerent types of
data. Parametric polymorphism in ML and Haskell is one of the simplest examples. ML-style
module systems and Haskell type classes are more AEexible cases. These language features
are often not as powerful so we would like. For instance, while Haskell includes a type class
classifying those types whose values can be pretty-printed, per-type pretty-printing is usually
either implemented manually or implemented via a deriving clause, which triggers ad-hoc
code generation. Some clever encoding tricks have been used to achieve better within Haskell
and other languages, but we can do datatype-generic programming much more cleanly with
dependent types. Thanks to the expressive power of CIC, we need no special language
support.

Generic programming can often be very useful in Coq developments, so we devote this
chapter to studying it. In a proof assistant, there is the new possibility of generic proofs
about generic programs, which we also devote some space to.

10.1 ReAEecting Datatype Deo/nitions
The key to generic programming with dependent types is universe types. This concept
should not be confused with the idea of universes from the metatheory of CIC and related
languages. Rather, the idea of universe types is to deo/ne inductive types that provide
syntactic representations of Coq types. We cannot directly write CIC programs that do case
analysis on types, but we can case analyze on reAEected syntactic versions of those types.

Thus, to begin, we must deo/ne a syntactic representation of some class of datatypes. In
this chapter, our running example will have to do with basic algebraic datatypes, of the kind
found in ML and Haskell, but without additional bells and whistles like type parameters and
mutually-recursive deo/nitions.

The o/rst step is to deo/ne a representation for constructors of our datatypes.

Record constructor : Type := Con -

nonrecursive : Type;

175

recursive : nat
"".

The idea is that a constructor represented as Con T n has n arguments of the type that
we are deo/ning. Additionally, all of the other, non-recursive arguments can be encoded in
the type T . When there are no non-recursive arguments, T can be unit. When there are
two non-recursive arguments, of types A and B , T can be A * B . We can generalizer to any
number of arguments via tupling.

With this deo/nition, it as easy to deo/ne a datatype representation in terms of lists of
constructors.

Definition datatype := list constructor.

Here are a few example encodings for some common types from the Coq standard library.
While our syntax type does not support type parameters directly, we can implement them
at the meta level, via functions from types to datatypes.

Definition Empty set dt : datatype := nil.
Definition unit dt : datatype := Con unit 0 :: nil.
Definition bool dt : datatype := Con unit 0 :: Con unit 0 :: nil.
Definition nat dt : datatype := Con unit 0 :: Con unit 1 :: nil.
Definition list dt (A : Type) : datatype := Con unit 0 :: Con A 1 :: nil.

Empty set has no constructors, so its representation is the empty list. unit has one
constructor with no arguments, so its one reAEected constructor indicates no non-recursive
data and 0 recursive arguments. The representation for bool just duplicates this single
argumentless constructor. We get from bool to nat by changing one of the constructors to
indicate 1 recursive argument. We get from nat to list by adding a non-recursive argument
of a parameter type A.

As a further example, we can do the same encoding for a generic binary tree type.

Section tree.

Variable A : Type.

Inductive tree : Type :=|

Leaf : A ! tree|
Node : tree ! tree ! tree.
End tree.

Definition tree dt (A : Type) : datatype := Con A 0 :: Con unit 2 :: nil.

Each datatype representation stands for a family of inductive types. For a specio/c real
datatype and a reputed representation for it, it is useful to deo/ne a type of evidence that
the datatype is compatible with the encoding.

Section denote.

Variable T : Type.

This variable stands for the concrete datatype that we are interested in.

Definition constructorDenote (c : constructor) :=

176

nonrecursive c ! ilist T (recursive c) ! T.
We write that a constructor is represented as a function returning a T . Such a function
takes two arguments, which pack together the non-recursive and recursive arguments of the
constructor. We represent a tuple of all recursive arguments using the length-indexed list
type ilist that we met in Chapter 7.

Definition datatypeDenote := hlist constructorDenote.

Finally, the evidence for type T is a hetergeneous list, including a constructor denotation
for every constructor encoding in a datatype encoding. Recall that, since we are inside a
section binding T as a variable, constructorDenote is automatically parameterized by T .

End denote.

Some example pieces of evidence should help clarify the convention. First, we deo/ne
some helpful notations, providing dioeerent ways of writing constructor denotations. There is
really just one notation, but we need several versions of it to cover dioeerent choices of which
variables will be used in the body of a deo/nition. The ASCII ~? from the notation will be
rendered later as .

Notation "[ ! , ! \Lambda ? x ]" := ((fun ) x ) : constructorDenote (Con )).
Notation "[ v , ! \Lambda ? x ]" := ((fun v ) x ) : constructorDenote (Con )).
Notation "[ ! , r \Lambda ? x ]" := ((fun r ) x ) : constructorDenote (Con )).
Notation "[ v , r \Lambda ? x ]" := ((fun v r ) x ) : constructorDenote (Con )).

Definition Empty set den : datatypeDenote Empty set Empty set dt :=

HNil.
Definition unit den : datatypeDenote unit unit dt :=

[!, !  tt] ::: HNil.
Definition bool den : datatypeDenote bool bool dt :=

[!, !  true] ::: [!, !  false] ::: HNil.
Definition nat den : datatypeDenote nat nat dt :=

[!, !  O] ::: [!, r  S (hd r )] ::: HNil.
Definition list den (A : Type) : datatypeDenote (list A) (list dt A) :=

[!, !  nil] ::: [x, r  x :: hd r ] ::: HNil.
Definition tree den (A : Type) : datatypeDenote (tree A) (tree dt A) :=

[v, !  Leaf v ] ::: [!, r  Node (hd r ) (hd (tl r ))] ::: HNil.

10.2 Recursive Deo/nitions
We built these encodings of datatypes to help us write datatype-generic recursive functions.
To do so, we will want a reAEected representation of a recursion scheme for each type, similar
to the T rect principle generated automatically for an inductive deo/nition of T . A clever
reuse of datatypeDenote yields a short deo/nition.

Definition o/xDenote (T : Type) (dt : datatype) :=

177

8 (R : Type), datatypeDenote R dt ! (T ! R).

The idea of a recursion scheme is parameterized by a type and a reputed encoding of
it. The principle itself is polymorphic in a type R, which is the return type of the recursive
function that we mean to write. The next argument is a hetergeneous list of one case of
the recursive function deo/nition for each datatype constructor. The datatypeDenote function
turns out to have just the right deo/nition to express the type we need; a set of function
cases is just like an alternate set of constructors where we replace the original type T with
the function result type R. Given such a reAEected deo/nition, a o/xDenote invocation returns
a function from T to R, which is just what we wanted.

We are ready to write some example functions now. It will be useful to use one new
function from the DepList library included in the book source.

Check hmake.

hmake

: 8 (A : Type) (B : A ! Type),

(8 x : A, B x ) ! 8 ls : list A, hlist B l

hmake is a kind of map alternative that goes from a regular list to an hlist. We can use
it to deo/ne a generic size function which counts the number of constructors used to build a
value in a datatype.

Definition size T dt (fx : o/xDenote T dt ) : T ! nat :=

fx nat (hmake (B := constructorDenote nat) (fun r ) foldr plus 1 r ) dt ).

Our deo/nition is parameterized over a recursion scheme fx . We instantiate fx by passing
it the function result type and a set of function cases, where we build the latter with hmake.
The function argument to hmake takes three arguments: the representation of a constructor,
its non-recursive arguments, and the results of recursive calls on all of its recursive arguments.
We only need the recursive call results here, so we call them r and bind the other two inputs
with wildcards. The actual case body is simple: we add together the recursive call results
and increment the result by one (to account for the current constructor). This foldr function
is an hlist-specio/c version deo/ned in the DepList module.

It is instructive to build o/xDenote values for our example types and see what specialized
size functions result from them.

Definition Empty set o/x : o/xDenote Empty set Empty set dt :=

fun R emp ) match emp with end.
Eval compute in size Empty set o/x.

= fun emp : Empty set ) match emp return nat with

end
: Empty set ! nat

Despite all the fanciness of the generic size function, CIC's standard computation rules
suOEce to normalize the generic function specialization to exactly what we would have written
manually.

178

Definition unit o/x : o/xDenote unit unit dt :=

fun R cases ) (hhd cases ) tt INil.
Eval compute in size unit o/x.

= fun : unit ) 1
: unit ! nat

Again normalization gives us the natural function deo/nition. We see this pattern repeated
for our other example types.

Definition bool o/x : o/xDenote bool bool dt :=

fun R cases b ) if b

then (hhd cases) tt INil
else (hhd (htl cases)) tt INil.
Eval compute in size bool o/x.

= fun b : bool ) if b then 1 else 1
: bool ! nat

Definition nat o/x : o/xDenote nat nat dt :=

fun R cases ) o/x F (n : nat) : R :=

match n with|

O ) (hhd cases) tt INil|
S n' ) (hhd (htl cases)) tt (ICons (F n' ) INil)
end.

To peek at the size function for nat, it is useful to avoid full computation, so that the
recursive deo/nition of addition is not expanded inline. We can accomplish this with proper
AEags for the cbv reduction strategy.

Eval cbv beta iota delta -[plus] in size nat o/x.

= o/x F (n : nat) : nat := match n with|

0 ) 1|
S n' ) F n' + 1
end
: nat ! nat

Definition list o/x (A : Type) : o/xDenote (list A) (list dt A) :=

fun R cases ) o/x F (ls : list A) : R :=

match ls with|

nil ) (hhd cases) tt INil|
x :: ls' ) (hhd (htl cases)) x (ICons (F ls' ) INil)
end.
Eval cbv beta iota delta -[plus] in fun A ) size (@list o/x A).

= fun A : Type )

o/x F (ls : list A) : nat :=

match ls with

179

| nil ) 1|

:: ls' ) F ls' + 1
end
: 8 A : Type, list A ! nat

Definition tree o/x (A : Type) : o/xDenote (tree A) (tree dt A) :=

fun R cases ) o/x F (t : tree A) : R :=

match t with|

Leaf x ) (hhd cases) x INil|
Node t1 t2 ) (hhd (htl cases)) tt (ICons (F t1 ) (ICons (F t2 ) INil))
end.
Eval cbv beta iota delta -[plus] in fun A ) size (@tree o/x A).

= fun A : Type )

o/x F (t : tree A) : nat :=

match t with|

Leaf ) 1|
Node t1 t2 ) F t1 + (F t2 + 1)
end
: 8 A : Type, tree A ! n

10.2.1 Pretty-Printing
It is also useful to do generic pretty-printing of datatype values, rendering them as human-
readable strings. To do so, we will need a bit of metadata for each constructor. Specio/cally,
we need the name to print for the constructor and the function to use to render its non-
recursive arguments. Everything else can be done generically.

Record print constructor (c : constructor) : Type := PI -

printName : string;
printNonrec : nonrecursive c ! string
"".

It is useful to deo/ne a shorthand for applying the constructor PI. By applying it explicitly
to an unknown application of the constructor Con, we help type inference work.

Notation "\Theta " := (PI (Con )).

As in earlier examples, we deo/ne the type of metadata for a datatype to be a heteroge-
neous list type collecting metadata for each constructor.

Definition print datatype := hlist print constructor.

We will be doing some string manipulation here, so we import the notations associated
with strings.

Local Open Scope string scope.

Now it is easy to implement our generic printer, using another function from DepList.

180

Check hmap.

hmap

: 8 (A : Type) (B1 B2 : A ! Type),

(8 x : A, B1 x ! B2 x ) !8

ls : list A, hlist B1 ls ! hlist B2 ls

Definition print T dt (pr : print datatype dt ) (fx : o/xDenote T dt ) : T ! string :=

fx string (hmap (B1 := print constructor) (B2 := constructorDenote string)

(fun pc x r ) printName pc ++ "(" ++ printNonrec pc x

++ foldr (fun s acc ) ", " ++ s ++ acc) ")" r ) pr ).

Some simple tests establish that print gets the job done.
Eval compute in print HNil Empty set o/x.

= fun emp : Empty set ) match emp return string with

end
: Empty set ! string

Eval compute in print (\Theta  "tt" (fun ) "") ::: HNil) unit o/x.

= fun : unit ) "tt()"
: unit ! string

Eval compute in print (\Theta  "true" (fun ) "")

::: \Theta  "false" (fun ) "")
::: HNil) bool o/x.

= fun b : bool ) if b then "true()" else "false()"
: bool ! s

Definition print nat := print (\Theta  "O" (fun ) "")

::: \Theta  "S" (fun ) "")
::: HNil) nat o/x.
Eval cbv beta iota delta -[append ] in print nat.

= o/x F (n : nat) : string :=

match n with|

0%nat ) "O" ++ "(" ++ "" ++ ")"|
S n' ) "S" ++ "(" ++ "" ++ ", " ++ F n' ++ ")"
end
: nat ! string

Eval simpl in print nat 0.

= "O()"
: string

Eval simpl in print nat 1.

= "S(, O())"
: string

181

Eval simpl in print nat 2.

= "S(, S(, O()))"
: string

Eval cbv beta iota delta -[append ] in fun A (pr : A ! string) )

print (\Theta  "nil" (fun ) "")
::: \Theta  "cons" pr
::: HNil) (@list o/x A).

= fun (A : Type) (pr : A ! string) )

o/x F (ls : list A) : string :=

match ls with|

nil ) "nil" ++ "(" ++ "" ++ ")"|
x :: ls' ) "cons" ++ "(" ++ pr x ++ ", " ++ F ls' ++ ")"
end
: 8 A : Type, (A ! string) ! list A ! string

Eval cbv beta iota delta -[append ] in fun A (pr : A ! string) )

print (\Theta  "Leaf" pr
::: \Theta  "Node" (fun ) "")
::: HNil) (@tree o/x A).

= fun (A : Type) (pr : A ! string) )

o/x F (t : tree A) : string :=

match t with|

Leaf x ) "Leaf" ++ "(" ++ pr x ++ ")"|
Node t1 t2 )

"Node" ++ "(" ++ "" ++ ", " ++ F t1 ++ ", " ++ F t2 ++ ")"
end
: 8 A : Type, (A ! string) ! tree A ! string

10.2.2 Mapping
By this point, we have developed enough machinery that it is old hat to deo/ne a generic
function similar to the list map function.

Definition map T dt (dd : datatypeDenote T dt ) (fx : o/xDenote T dt ) (f : T ! T )

: T ! T :=
fx T (hmap (B1 := constructorDenote T ) (B2 := constructorDenote T )

(fun c x r ) f (c x r )) dd ).

Eval compute in map Empty set den Empty set o/x.

= fun ( : Empty set ! Empty set) (emp : Empty set) )

match emp return Empty set with
end
: (Empty set ! Empty set) ! Empty set ! Empty set

182

Eval compute in map unit den unit o/x.

= fun (f : unit ! unit) ( : unit) ) f tt
: (unit ! unit) ! unit ! unit

Eval compute in map bool den bool o/x.

= fun (f : bool ! bool) (b : bool) ) if b then f true else f false
: (bool ! bool) ! bool ! bool

Eval compute in map nat den nat o/x.

= fun f : nat ! nat )

o/x F (n : nat) : nat :=

match n with|

0%nat ) f 0%nat|
S n' ) f (S (F n' ))
end
: (nat ! nat) ! nat ! nat

Eval compute in fun A ) map (list den A) (@list o/x A).

= fun (A : Type) (f : list A ! list A) )

o/x F (ls : list A) : list A :=

match ls with|

nil ) f nil|
x :: ls' ) f (x :: F ls' )
end
: 8 A : Type, (list A ! list A) ! list A ! list A

Eval compute in fun A ) map (tree den A) (@tree o/x A).

= fun (A : Type) (f : tree A ! tree A) )

o/x F (t : tree A) : tree A :=

match t with|

Leaf x ) f (Leaf x )|
Node t1 t2 ) f (Node (F t1) (F t2))
end
: 8 A : Type, (tree A ! tree A) ! tree A ! tree A

Definition map nat := map nat den nat o/x.
Eval simpl in map nat S 0.

= 1%nat
: nat

Eval simpl in map nat S 1.

= 3%nat
: nat

Eval simpl in map nat S 2.

= 5%nat

183

: nat
10.3 Proving Theorems about Recursive Deo/nitions
We would like to be able to prove theorems about our generic functions. To do so, we need
to establish additional well-formedness properties that must hold of pieces of evidence.

Section ok.

Variable T : Type.
Variable dt : datatype.

Variable dd : datatypeDenote T dt.
Variable fx : o/xDenote T dt.

First, we characterize when a piece of evidence about a datatype is acceptable. The
basic idea is that the type T should really be an inductive type with the deo/nition given
by dd . Semantically, inductive types are characterized by the ability to do induction on
them. Therefore, we require that the usual induction principle is true, with respect to the
constructors given in the encoding dd .

Definition datatypeDenoteOk :=8

P : T ! Prop,

(8 c (m : member c dt ) (x : nonrecursive c) (r : ilist T (recursive c)),

(8 i : o/n (recursive c), P (get r i ))!

P ((hget dd m) x r ))! 8
v, P v.

This deo/nition can take a while to digest. The quantio/er over m : member c dt is
considering each constructor in turn; like in normal induction principles, each constructor
has an associated proof case. The expression hget dd m then names the constructor we have
selected. After binding m, we quantify over all possible arguments (encoded with x and r )
to the constructor that m selects. Within each specio/c case, we quantify further over i : o/n
(recursive c) to consider all of our induction hypotheses, one for each recursive argument of
the current constructor.

We have completed half the burden of deo/ning side conditions. The other half comes in
characterizing when a recursion scheme fx is valid. The natural condition is that fx behaves
appropriately when applied to any constructor application.

Definition o/xDenoteOk :=8

(R : Type) (cases : datatypeDenote R dt )

c (m : member c dt )
(x : nonrecursive c) (r : ilist T (recursive c)),
fx cases ((hget dd m) x r )
= (hget cases m) x (imap (fx cases ) r ).

As for datatypeDenoteOk, we consider all constructors and all possible arguments to them
by quantifying over m, x , and r. The lefthand side of the equality that follows shows a call to

184

the recursive function on the specio/c constructor application that we selected. The righthand
side shows an application of the function case associated with constructor m, applied to the
non-recursive arguments and to appropriate recursive calls on the recursive arguments.

End ok.

We are now ready to prove that the size function we deo/ned earlier always returns positive
results. First, we establish a simple lemma.

Lemma foldr plus : 8 n (ils : ilist nat n),

foldr plus 1 ils ? 0.
induction ils; crush.
Qed.

Theorem size positive : 8 T dt

(dd : datatypeDenote T dt ) (fx : o/xDenote T dt )
(dok : datatypeDenoteOk dd ) (fok : o/xDenoteOk dd fx )
(v : T ),
size fx v ? 0.
unfold size; intros.

============================

fx nat

(hmake

(fun (x : constructor) ( : nonrecursive x )

(r : ilist nat (recursive x )) ) foldr plus 1%nat r ) dt ) v ? 0

Our goal is an inequality over a particular call to size, with its deo/nition expanded. How
can we proceed here? We cannot use induction directly, because there is no way for Coq to
know that T is an inductive type. Instead, we need to use the induction principle encoded
in our hypothesis dok of type datatypeDenoteOk dd . Let us try applying it directly.

apply dok.
Error : Impossible to unify "datatypeDenoteOk dd" with

"fx nat

(hmake

(fun (x : constructor) ( : nonrecursive x)

(r : ilist nat (recursive x)) ) foldr plus 1%nat r) dt) v ? 0".

Matching the type of dok with the type of our conclusion requires more than simple
o/rst-order unio/cation, so apply is not up to the challenge. We can use the pattern tactic to
get our goal into a form that makes it apparent exactly what the induction hypothesis is.

pattern v.

185

============================

(fun t : T )

fx nat

(hmake

(fun (x : constructor) ( : nonrecursive x )

(r : ilist nat (recursive x )) ) foldr plus 1%nat r ) dt) t ? 0) v

apply dok ; crush.
H : 8 i : o/n (recursive c),

fx nat

(hmake

(fun (x : constructor) ( : nonrecursive x )

(r : ilist nat (recursive x )) ) foldr plus 1%nat r ) dt )
(get r i) ? 0
============================

hget

(hmake

(fun (x0 : constructor) ( : nonrecursive x0 )

(r0 : ilist nat (recursive x0 )) ) foldr plus 1%nat r0 ) dt ) m x
(imap

(fx nat

(hmake

(fun (x0 : constructor) ( : nonrecursive x0 )

(r0 : ilist nat (recursive x0 )) )
foldr plus 1%nat r0 ) dt )) r ) ? 0

An induction hypothesis H is generated, but we turn out not to need it for this example.
We can simplify the goal using a library theorem about the composition of hget and hmake.

rewrite hget hmake.

============================

foldr plus 1%nat

(imap

(fx nat

(hmake

(fun (x0 : constructor) ( : nonrecursive x0 )

(r0 : ilist nat (recursive x0 )) )
foldr plus 1%nat r0 ) dt )) r ) ? 0

The lemma we proved earlier o/nishes the proof.
apply foldr plus.

186

Using hints, we can redo this proof in a nice automated form.
Restart.
Hint Rewrite hget hmake : cpdt.
Hint Resolve foldr plus.

unfold size; intros; pattern v ; apply dok ; crush.
Qed.

It turned out that, in this example, we only needed to use induction degenerately as case
analysis. A more involved theorem may only be proved using induction hypotheses. We will
give its proof only in unautomated form and leave eoeective automation as an exercise for
the motivated reader.

In particular, it ought to be the case that generic map applied to an identity function is
itself an identity function.

Theorem map id : 8 T dt

(dd : datatypeDenote T dt ) (fx : o/xDenote T dt )
(dok : datatypeDenoteOk dd ) (fok : o/xDenoteOk dd fx )
(v : T ),
map dd fx (fun x ) x ) v = v.

Let us begin as we did in the last theorem, after adding another useful library equality
as a hint.

Hint Rewrite hget hmap : cpdt.
unfold map; intros; pattern v ; apply dok ; crush.

H : 8 i : o/n (recursive c),

fx T

(hmap

(fun (x : constructor) (c : constructorDenote T x )

(x0 : nonrecursive x ) (r : ilist T (recursive x )) )
c x0 r ) dd ) (get r i) = get r i
============================

hget dd m x

(imap

(fx T

(hmap

(fun (x0 : constructor) (c0 : constructorDenote T x0 )

(x1 : nonrecursive x0 ) (r0 : ilist T (recursive x0 )) )
c0 x1 r0 ) dd )) r ) = hget dd m x r

Our goal is an equality whose two sides begin with the same function call and initial
arguments. We believe that the remaining arguments are in fact equal as well, and the
f equal tactic applies this reasoning step for us formally.

f equal.

187

============================

imap

(fx T

(hmap

(fun (x0 : constructor) (c0 : constructorDenote T x0 )

(x1 : nonrecursive x0 ) (r0 : ilist T (recursive x0 )) )
c0 x1 r0 ) dd )) r = r

At this point, it is helpful to proceed by an inner induction on the heterogeneous list r
of recursive call results. We could arrive at a cleaner proof by breaking this step out into an
explicit lemma, but here we will do the induction inline to save space.

induction r ; crush.

The base case is discharged automatically, and the inductive case looks like this, where
H is the outer IH (for induction over T values) and IHn is the inner IH (for induction over
the recursive arguments).

H : 8 i : o/n (S n),

fx T

(hmap

(fun (x : constructor) (c : constructorDenote T x )

(x0 : nonrecursive x ) (r : ilist T (recursive x )) )
c x0 r ) dd )
(match i in (o/n n' ) return ((o/n (pred n' ) ! T ) ! T ) with|

First n ) fun : o/n n ! T ) a|
Next n idx' ) fun get ls' : o/n n ! T ) get ls' idx'
end (get r )) =
match i in (o/n n' ) return ((o/n (pred n' ) ! T ) ! T ) with|

First n ) fun : o/n n ! T ) a|
Next n idx' ) fun get ls' : o/n n ! T ) get ls' idx'
end (get r )
IHr : (8 i : o/n n,

fx T

(hmap

(fun (x : constructor) (c : constructorDenote T x )

(x0 : nonrecursive x ) (r : ilist T (recursive x )) )
c x0 r ) dd ) (get r i) = get r i) !
imap

(fx T

(hmap

(fun (x : constructor) (c : constructorDenote T x )

(x0 : nonrecursive x ) (r : ilist T (recursive x )) )

188

c x0 r ) dd )) r = r
============================

ICons

(fx T

(hmap

(fun (x0 : constructor) (c0 : constructorDenote T x0 )

(x1 : nonrecursive x0 ) (r0 : ilist T (recursive x0 )) )
c0 x1 r0 ) dd ) a)
(imap

(fx T

(hmap

(fun (x0 : constructor) (c0 : constructorDenote T x0 )

(x1 : nonrecursive x0 ) (r0 : ilist T (recursive x0 )) )
c0 x1 r0 ) dd )) r ) = ICons a r

We see another opportunity to apply f equal, this time to split our goal into two dioeerent
equalities over corresponding arguments. After that, the form of the o/rst goal matches our
outer induction hypothesis H, when we give type inference some help by specifying the right
quantio/er instantiation.

f equal.
apply (H First).

============================

imap

(fx T

(hmap

(fun (x0 : constructor) (c0 : constructorDenote T x0 )

(x1 : nonrecursive x0 ) (r0 : ilist T (recursive x0 )) )
c0 x1 r0 ) dd )) r = r

Now the goal matches the inner IH IHr.
apply IHr ; crush.

i : o/n n
============================

fx T

(hmap

(fun (x0 : constructor) (c0 : constructorDenote T x0 )

(x1 : nonrecursive x0 ) (r0 : ilist T (recursive x0 )) )
c0 x1 r0 ) dd ) (get r i) = get r i

We can o/nish the proof by applying the outer IH again, specialized to a dioeerent o/n

189

value.

apply (H (Next i )).
Qed.

190
Chapter 11
Universes and Axioms

Many traditional theorems can be proved in Coq without special knowledge of CIC, the logic
behind the prover. A development just seems to be using a particular ASCII notation for
standard formulas based on set theory. Nonetheless, as we saw in Chapter 4, CIC dioeers
from set theory in starting from fewer orthogonal primitives. It is possible to deo/ne the
usual logical connectives as derived notions. The foundation of it all is a dependently-typed
functional programming language, based on dependent function types and inductive type
families. By using the facilities of this language directly, we can accomplish some things
much more easily than in mainstream math.

Gallina, which adds features to the more theoretical CIC, is the logic implemented in Coq.
It has a relatively simple foundation that can be deo/ned rigorously in a page or two of formal
proof rules. Still, there are some important subtleties that have practical ramio/cations. This
chapter focuses on those subtleties, avoiding formal metatheory in favor of example code.

11.1 The Type Hierarchy
Every object in Gallina has a type.
Check 0.

0

: nat

It is natural enough that zero be considered as a natural number.
Check nat.

nat

: Set

From a set theory perspective, it is unsurprising to consider the natural numbers as a
"set."

Check Set.

191

Set

: Type

The type Set may be considered as the set of all sets, a concept that set theory handles
in terms of classes. In Coq, this more general notion is Type.

Check Type.

Type

: Type

Strangely enough, Type appears to be its own type. It is known that polymorphic lan-
guages with this property are inconsistent. That is, using such a language to encode proofs
is unwise, because it is possible to "prove" any proposition. What is really going on here?

Let us repeat some of our queries after toggling a AEag related to Coq's printing behavior.

Set Printing Universes.
Check nat.

nat

: Set

Check Set.

Set

: Type (* (0)+1 *)

Check Type.

Type (* Top.3 *)

: Type (* (Top.3)+1 *)

Occurrences of Type are annotated with some additional information, inside comments.
These annotations have to do with the secret behind Type: it really stands for an ino/nite
hierarchy of types. The type of Set is Type(0), the type of Type(0) is Type(1), the type
of Type(1) is Type(2), and so on. This is how we avoid the "Type : Type" paradox. As a
convenience, the universe hierarchy drives Coq's one variety of subtyping. Any term whose
type is Type at level i is automatically also described by Type at level j when j ? i.

In the outputs of our o/rst Check query, we see that the type level of Set's type is (0)+1.
Here 0 stands for the level of Set, and we increment it to arrive at the level that classio/es
Set.

In the second query's output, we see that the occurrence of Type that we check is assigned
a fresh universe variable Top.3. The output type increments Top.3 to move up a level in
the universe hierarchy. As we write code that uses deo/nitions whose types mention universe
variables, unio/cation may reo/ne the values of those variables. Luckily, the user rarely has to
worry about the details.

Another crucial concept in CIC is predicativity. Consider these queries.

192

Check 8 T : nat, o/n T.8

T : nat, o/n T

: Set

Check 8 T : Set, T.8

T : Set, T

: Type (* max(0, (0)+1) *)

Check 8 T : Type, T.8

T : Type (* Top.9 *) , T

: Type (* max(Top.9, (Top.9)+1) *)

These outputs demonstrate the rule for determining which universe a 8 type lives in. In
particular, for a type 8 x : T1, T2, we take the maximum of the universes of T1 and T2. In
the o/rst example query, both T1 (nat) and T2 (o/n T ) are in Set, so the 8 type is in Set,
too. In the second query, T1 is Set, which is at level (0)+1; and T2 is T , which is at level
0. Thus, the 8 exists at the maximum of these two levels. The third example illustrates the
same outcome, where we replace Set with an occurrence of Type that is assigned universe
variable Top.9. This universe variable appears in the places where 0 appeared in the previous
query.

The behind-the-scenes manipulation of universe variables gives us predicativity. Consider
this simple deo/nition of a polymorphic identity function.

Definition id (T : Set) (x : T ) : T := x.
Check id 0.

id 0

: nat

Check id Set.
Error : Illegal application (Type Error ):
...
The 1st term has type "Type (* (Top.15)+1 *)" which should be coercible to "Set".

The parameter T of id must be instantiated with a Set. nat is a Set, but Set is not.
We can try o/xing the problem by generalizing our deo/nition of id.

Reset id.
Definition id (T : Type) (x : T ) : T := x.
Check id 0.

id 0

: nat

Check id Set.

193

id Set

: Type (* Top.17 *)

Check id Type.

id Type (* Top.18 *)

: Type (* Top.19 *)

So far so good. As we apply id to dioeerent T values, the inferred index for T 's Type
occurrence automatically moves higher up the type hierarchy.

Check id id.
Error : Universe inconsistency (cannot enforce Top.16 ! Top.16).

This error message reminds us that the universe variable for T still exists, even though it
is usually hidden. To apply id to itself, that variable would need to be less than itself in the
type hierarchy. Universe inconsistency error messages announce cases like this one where a
term could only type-check by violating an implied constraint over universe variables. Such
errors demonstrate that Type is predicative, where this word has a CIC meaning closely
related to its usual mathematical meaning. A predicative system enforces the constraint
that, for any object of quantio/ed type, none of those quantio/ers may ever be instantiated
with the object itself. Impredicativity is associated with popular paradoxes in set theory,
involving inconsistent constructions like "the set of all sets that do not contain themselves."
Similar paradoxes result from uncontrolled impredicativity in Coq.

11.1.1 Inductive Deo/nitions
Predicativity restrictions also apply to inductive deo/nitions. As an example, let us consider
a type of expression trees that allows injection of any native Coq value. The idea is that an
exp T stands for a reAEected expression of type T .

Inductive exp : Set ! Set :=|

Const : 8 T : Set, T ! exp T|
Pair : 8 T1 T2, exp T1 ! exp T2 ! exp (T1 * T2 )|
Eq : 8 T , exp T ! exp T ! exp bool.

Error : Large non-propositional inductive types must be in Type.

This deo/nition is large in the sense that at least one of its constructors takes an argument
whose type has type Type. Coq would be inconsistent if we allowed deo/nitions like this one
in their full generality. Instead, we must change exp to live in Type. We will go even further
and move exp's index to Type as well.

Inductive exp : Type ! Type :=

194

| Const : 8 T, T ! exp T|

Pair : 8 T1 T2, exp T1 ! exp T2 ! exp (T1 * T2 )|
Eq : 8 T, exp T ! exp T ! exp bool.

Note that before we had to include an annotation : Set for the variable T in Const's
type, but we need no annotation now. When the type of a variable is not known, and when
that variable is used in a context where only types are allowed, Coq infers that the variable
is of type Type. That is the right behavior here, but it was wrong for the Set version of exp.

Our new deo/nition is accepted. We can build some sample expressions.

Check Const 0.

Const 0

: exp nat

Check Pair (Const 0) (Const tt).

Pair (Const 0) (Const tt)

: exp (nat * unit)

Check Eq (Const Set) (Const Type).

Eq (Const Set) (Const Type (* Top.59 *) )

: exp bool

We can check many expressions, including fancy expressions that include types. However,
it is not hard to hit a type-checking wall.

Check Const (Const O).
Error : Universe inconsistency (cannot enforce Top.42 ! Top.42).

We are unable to instantiate the parameter T of Const with an exp type. To see why, it
is helpful to print the annotated version of exp's inductive deo/nition.

Print exp.
Inductive exp

: Type (* Top.8 *) !

Type
(* max(0, (Top.11)+1, (Top.14)+1, (Top.15)+1, (Top.19)+1) *) :=
Const : 8 T : Type (* Top.11 *) , T ! exp T|
Pair : 8 (T1 : Type (* Top.14 *) ) (T2 : Type (* Top.15 *) ),

exp T1 ! exp T2 ! exp (T1 * T2 )|
Eq : 8 T : Type (* Top.19 *) , exp T ! exp T ! exp bool

We see that the index type of exp has been assigned to universe level Top.8. In addition,
each of the four occurrences of Type in the types of the constructors gets its own universe
variable. Each of these variables appears explicitly in the type of exp. In particular, any

195

type exp T lives at a universe level found by incrementing by one the maximum of the four
argument variables. A consequence of this is that exp must live at a higher universe level
than any type which may be passed to one of its constructors. This consequence led to the
universe inconsistency.

Strangely, the universe variable Top.8 only appears in one place. Is there no restriction
imposed on which types are valid arguments to exp? In fact, there is a restriction, but it
only appears in a global set of universe constraints that are maintained "ooe to the side," not
appearing explicitly in types. We can print the current database.

Print Universes.
Top.19 ! Top.9 <= Top.8
Top.15 ! Top.9 <= Top.8 <= Coq.Init.Datatypes.38
Top.14 ! Top.9 <= Top.8 <= Coq.Init.Datatypes.37
Top.11 ! Top.9 <= Top.8

Print Universes outputs many more constraints, but we have collected only those that
mention Top variables. We see one constraint for each universe variable associated with
a constructor argument from exp's deo/nition. Top.19 is the type argument to Eq. The
constraint for Top.19 eoeectively says that Top.19 must be less than Top.8, the universe of
exp's indices; an intermediate variable Top.9 appears as an artifact of the way the constraint
was generated.

The next constraint, for Top.15, is more complicated. This is the universe of the second
argument to the Pair constructor. Not only must Top.15 be less than Top.8, but it also comes
out that Top.8 must be less than Coq.Init.Datatypes.38. What is this new universe variable?
It is from the deo/nition of the prod inductive family, to which types of the form A * B are
desugared.

Print prod.
Inductive prod (A : Type (* Coq.Init.Datatypes.37 *) )

(B : Type (* Coq.Init.Datatypes.38 *) )

: Type (* max(Coq.Init.Datatypes.37, Coq.Init.Datatypes.38) *) :=
pair : A ! B ! A * B

We see that the constraint is enforcing that indices to exp must not live in a higher
universe level than B -indices to prod. The next constraint above establishes a symmetric
condition for A.

Thus it is apparent that Coq maintains a tortuous set of universe variable inequalities
behind the scenes. It may look like some functions are polymorphic in the universe levels
of their arguments, but what is really happening is imperative updating of a system of
constraints, such that all uses of a function are consistent with a global set of universe levels.
When the constraint system may not be evolved soundly, we get a universe inconsistency
error.

Something interesting is revealed in the annotated deo/nition of prod. A type prod A

196

B lives at a universe that is the maximum of the universes of A and B . From our earlier
experiments, we might expect that prod 's universe would in fact need to be one higher than
the maximum. The critical dioeerence is that, in the deo/nition of prod, A and B are deo/ned as
parameters; that is, they appear named to the left of the main colon, rather than appearing
(possibly unnamed) to the right.

Parameters are not as AEexible as normal inductive type arguments. The range types of all
of the constructors of a parameterized type must share the same parameters. Nonetheless,
when it is possible to deo/ne a polymorphic type in this way, we gain the ability to use the
new type family in more ways, without triggering universe inconsistencies. For instance,
nested pairs of types are perfectly legal.

Check (nat, (Type, Set)).

(nat, (Type (* Top.44 *) , Set))

: Set * (Type (* Top.45 *) * Type (* Top.46 *) )

The same cannot be done with a counterpart to prod that does not use parameters.
Inductive prod' : Type ! Type ! Type :=|

pair' : 8 A B : Type, A ! B ! prod' A B.

Check (pair' nat (pair' Type Set)).
Error : Universe inconsistency (cannot enforce Top.51 ! Top.51).

The key beneo/t parameters bring us is the ability to avoid quantifying over types in the
types of constructors. Such quantio/cation induces less-than constraints, while parameters
only introduce less-than-or-equal-to constraints.

Coq includes one more (potentially confusing) feature related to parameters. While
Gallina does not support real universe polymorphism, there is a convenience facility that
mimics universe polymorphism in some cases. We can illustrate what this means with a
simple example.

Inductive foo (A : Type) : Type :=|

Foo : A ! foo A.

Check foo nat.

foo nat

: Set

Check foo Set.

foo Set

: Type

Check foo True.

foo True

197

: Prop
The basic pattern here is that Coq is willing to automatically build a "copied-and-pasted"
version of an inductive deo/nition, where some occurrences of Type have been replaced by
Set or Prop. In each context, the type-checker tries to o/nd the valid replacements that are
lowest in the type hierarchy. Automatic cloning of deo/nitions can be much more convenient
than manual cloning. We have already taken advantage of the fact that we may re-use the
same families of tuple and list types to form values in Set and Type.

Imitation polymorphism can be confusing in some contexts. For instance, it is what is
responsible for this weird behavior.

Inductive bar : Type := Bar : bar.
Check bar.

bar

: Prop

The type that Coq comes up with may be used in strictly more contexts than the type
one might have expected.

11.2 The Prop Universe
In Chapter 4, we saw parallel versions of useful datatypes for "programs" and "proofs." The
convention was that programs live in Set, and proofs live in Prop. We gave little explanation
for why it is useful to maintain this distinction. There is certainly documentation value from
separating programs from proofs; in practice, dioeerent concerns apply to building the two
types of objects. It turns out, however, that these concerns motivate formal dioeerences
between the two universes in Coq.

Recall the types sig and ex, which are the program and proof versions of existential
quantio/cation. Their deo/nitions dioeer only in one place, where sig uses Type and ex uses
Prop.

Print sig.

Inductive sig (A : Type) (P : A ! Prop) : Type :=

exist : 8 x : A, P x ! sig P

Print ex.

Inductive ex (A : Type) (P : A ! Prop) : Prop :=

ex intro : 8 x : A, P x ! ex P

It is natural to want a function to extract the o/rst components of data structures like
these. Doing so is easy enough for sig.

Definition projS A (P : A ! Prop) (x : sig P ) : A :=

match x with

198

| exist v ) v
end.

We run into trouble with a version that has been changed to work with ex.

Definition projE A (P : A ! Prop) (x : ex P ) : A :=

match x with|

ex intro v ) v
end.

Error :
Incorrect elimination of "x" in the inductive type "ex":
the return type has sort "Type" while it should be "Prop".
Elimination of an inductive object of sort Prop
is not allowed on a predicate in sort Type
because proofs can be eliminated only to build proofs.

In formal Coq parlance, "elimination" means "pattern-matching." The typing rules of
Gallina forbid us from pattern-matching on a discriminee whose type belongs to Prop, when-
ever the result type of the match has a type besides Prop. This is a sort of "information
AEow" policy, where the type system ensures that the details of proofs can never have any
eoeect on parts of a development that are not also marked as proofs.

This restriction matches informal practice. We think of programs and proofs as clearly
separated, and, outside of constructive logic, the idea of computing with proofs is ill-formed.
The distinction also has practical importance in Coq, where it aoeects the behavior of extrac-
tion.

Recall that extraction is Coq's facility for translating Coq developments into programs
in general-purpose programming languages like OCaml. Extraction erases proofs and leaves
programs intact. A simple example with sig and ex demonstrates the distinction.

Definition sym sig (x : sig (fun n ) n = 0)) : sig (fun n ) 0 = n) :=

match x with|

exist n pf ) exist n (sym eq pf )
end.

Extraction sym sig.

(** val sym.sig : nat -? nat **)
let sym.sig x = x

Since extraction erases proofs, the second components of sig values are elided, making
sig a simple identity type family. The sym sig operation is thus an identity function.

Definition sym ex (x : ex (fun n ) n = 0)) : ex (fun n ) 0 = n) :=

match x with

199

| ex intro n pf ) ex intro n (sym eq pf )
end.

Extraction sym ex.

(** val sym.ex : .. **)
let sym.ex = ..

In this example, the ex type itself is in Prop, so whole ex packages are erased. Coq
extracts every proposition as the type , whose single constructor is . Not only are
proofs replaced by , but proof arguments to functions are also removed completely, as we
see here.

Extraction is very helpful as an optimization over programs that contain proofs. In
languages like Haskell, advanced features make it possible to program with proofs, as a way
of convincing the type checker to accept particular deo/nitions. Unfortunately, when proofs
are encoded as values in GADTs, these proofs exist at runtime and consume resources.
In contrast, with Coq, as long as you keep all of your proofs within Prop, extraction is
guaranteed to erase them.

Many fans of the Curry-Howard correspondence support the idea of extracting programs
from proofs. In reality, few users of Coq and related tools do any such thing. Instead,
extraction is better thought of as an optimization that reduces the runtime costs of expressive
typing.

We have seen two of the dioeerences between proofs and programs: proofs are subject
to an elimination restriction and are elided by extraction. The remaining dioeerence is that
Prop is impredicative, as this example shows.

Check 8 P Q : Prop, P . Q ! Q . P.8

P Q : Prop, P . Q ! Q . P

: Prop

We see that it is possible to deo/ne a Prop that quantio/es over other Props. This is fortu-
nate, as we start wanting that ability even for such basic purposes as stating propositional
tautologies. In the next section of this chapter, we will see some reasons why unrestricted
impredicativity is undesirable. The impredicativity of Prop interacts crucially with the elim-
ination restriction to avoid those pitfalls.

Impredicativity also allows us to implement a version of our earlier exp type that does
not suoeer from the weakness that we found.

Inductive expP : Type ! Prop :=|

ConstP : 8 T, T ! expP T|
PairP : 8 T1 T2, expP T1 ! expP T2 ! expP (T1 * T2 )|
EqP : 8 T, expP T ! expP T ! expP bool.

Check ConstP 0.

200

ConstP 0

: expP nat

Check PairP (ConstP 0) (ConstP tt).

PairP (ConstP 0) (ConstP tt)

: expP (nat * unit)

Check EqP (ConstP Set) (ConstP Type).

EqP (ConstP Set) (ConstP Type)

: expP bool

Check ConstP (ConstP O).

ConstP (ConstP 0)

: expP (expP nat)

In this case, our victory is really a shallow one. As we have marked expP as a family of
proofs, we cannot deconstruct our expressions in the usual programmatic ways, which makes
them almost useless for the usual purposes. Impredicative quantio/cation is much more useful
in deo/ning inductive families that we really think of as judgments. For instance, this code
deo/nes a notion of equality that is strictly stronger than the base equality =.

Inductive eqPlus : 8 T, T ! T ! Prop :=|

Base : 8 T (x : T ), eqPlus x x|
Func : 8 dom ran (f1 f2 : dom ! ran),

(8 x : dom, eqPlus (f1 x ) (f2 x ))!

eqPlus f1 f2.

Check (Base 0).

Base 0

: eqPlus 0 0

Check (Func (fun n ) n) (fun n ) 0 + n) (fun n ) Base n)).

Func (fun n : nat ) n) (fun n : nat ) 0 + n) (fun n : nat ) Base n)

: eqPlus (fun n : nat ) n) (fun n : nat ) 0 + n)

Check (Base (Base 1)).

Base (Base 1)

: eqPlus (Base 1) (Base 1)

11.3 Axioms
While the specio/c logic Gallina is hardcoded into Coq's implementation, it is possible to add
certain logical rules in a controlled way. In other words, Coq may be used to reason about
many dioeerent reo/nements of Gallina where strictly more theorems are provable. We achieve
this by asserting axioms without proof.

201

We will motivate the idea by touring through some standard axioms, as enumerated in
Coq's online FAQ. I will add additional commentary as appropriate.

11.3.1 The Basics
One simple example of a useful axiom is the law of the excluded middle.
Require Import Classical Prop.
Print classic.

*** [ classic : 8 P : Prop, P . ~ P ]

In the implementation of module Classical Prop, this axiom was deo/ned with the com-
mand

Axiom classic : 8 P : Prop, P . ~ P.

An Axiom may be declared with any type, in any of the universes. There is a synonym
Parameter for Axiom, and that synonym is often clearer for assertions not of type Prop. For
instance, we can assert the existence of objects with certain properties.

Parameter n : nat.
Axiom positive : n ? 0.
Reset n.

This kind of "axiomatic presentation" of a theory is very common outside of higher-order
logic. However, in Coq, it is almost always preferable to stick to deo/ning your objects,
functions, and predicates via inductive deo/nitions and functional programming.

In general, there is a signio/cant burden associated with any use of axioms. It is easy to
assert a set of axioms that together is inconsistent. That is, a set of axioms may imply False,
which allows any theorem to proved, which defeats the purpose of a proof assistant. For
example, we could assert the following axiom, which is consistent by itself but inconsistent
when combined with classic.

Axiom not classic : 9 P : Prop, ~ (P . ~ P ).
Theorem uhoh : False.

generalize classic not classic; firstorder.
Qed.

Theorem uhoh again : 1 + 1 = 3.

destruct uhoh.
Qed.

Reset not classic.

On the subject of the law of the excluded middle itself, this axiom is usually quite harm-
less, and many practical Coq developments assume it. It has been proved metatheoretically
to be consistent with CIC. Here, "proved metatheoretically" means that someone proved on
paper that excluded middle holds in a model of CIC in set theory. All of the other axioms
that we will survey in this section hold in the same model, so they are all consistent together.

202

Recall that Coq implements constructive logic by default, where excluded middle is not
provable. Proofs in constructive logic can be thought of as programs. A 8 quantio/er denotes
a dependent function type, and a disjunction denotes a variant type. In such a setting,
excluded middle could be interpreted as a decision procedure for arbitrary propositions,
which computability theory tells us cannot exist. Thus, constructive logic with excluded
middle can no longer be associated with our usual notion of programming.

Given all this, why is it all right to assert excluded middle as an axiom? The intuitive
justio/cation is that the elimination restriction for Prop prevents us from treating proofs as
programs. An excluded middle axiom that quantio/ed over Set instead of Prop would be
problematic. If a development used that axiom, we would not be able to extract the code to
OCaml (soundly) without implementing a genuine universal decision procedure. In contrast,
values whose types belong to Prop are always erased by extraction, so we sidestep the axiom's
algorithmic consequences.

Because the proper use of axioms is so precarious, there are helpful commands for deter-
mining which axioms a theorem relies on.

Theorem t1 : 8 P : Prop, P ! ~ ~ P.

tauto.
Qed.

Print Assumptions t1.

Closed under the global context
Theorem t2 : 8 P : Prop, ~ ~ P ! P.

tauto.
Error : tauto failed.

intro P ; destruct (classic P ); tauto.
Qed.

Print Assumptions t2.

Axioms:
classic : 8 P : Prop, P . ~ P

It is possible to avoid this dependence in some specio/c cases, where excluded middle is
provable, for decidable families of propositions.

Theorem classic nat eq : 8 n m : nat, n = m . n 6= m.

induction n; destruct m; intuition; generalize (IHn m); intuition.
Qed.

Theorem t2' : 8 n m : nat, ~ ~ (n = m) ! n = m.

intros n m; destruct (classic nat eq n m); tauto.
Qed.

203

Print Assumptions t2'.
Closed under the global context

Mainstream mathematical practice assumes excluded middle, so it can be useful to have
it available in Coq developments, though it is also nice to know that a theorem is proved in
a simpler formal system than classical logic. There is a similar story for proof irrelevance,
which simplio/es proof issues that would not even arise in mainstream math.

Require Import ProofIrrelevance.
Print proof irrelevance.

*** [ proof irrelevance : 8 (P : Prop) (p1 p2 : P ), p1 = p2 ]

This axiom asserts that any two proofs of the same proposition are equal. If we replaced
p1 = p2 by p1 $ p2, then the statement would be provable. However, equality is a stronger
notion than logical equivalence. Recall this example function from Chapter 6.

Definition pred strong1 (n : nat) : n ? 0 ! nat :=

match n with|

O ) fun pf : 0 ? 0 ) match zgtz pf with end|
S n' ) fun ) n'
end.

We might want to prove that dioeerent proofs of n ? 0 do not lead to dioeerent results
from our richly-typed predecessor function.

Theorem pred strong1 irrel : 8 n (pf1 pf2 : n ? 0), pred strong1 pf1 = pred strong1 pf2.

destruct n; crush.
Qed.

The proof script is simple, but it involved peeking into the deo/nition of pred strong1.
For more complicated function deo/nitions, it can be considerably more work to prove that
they do not discriminate on details of proof arguments. This can seem like a shame, since
the Prop elimination restriction makes it impossible to write any function that does oth-
erwise. Unfortunately, this fact is only true metatheoretically, unless we assert an axiom
like proof irrelevance. With that axiom, we can prove our theorem without consulting the
deo/nition of pred strong1.

Theorem pred strong1 irrel' : 8 n (pf1 pf2 : n ? 0), pred strong1 pf1 = pred strong1 pf2.

intros; f equal; apply proof irrelevance.
Qed.

In the chapter on equality, we already discussed some axioms that are related to proof
irrelevance. In particular, Coq's standard library includes this axiom:

Require Import Eqdep.
Import Eq rect eq.
Print eq rect eq.

204

*** [ eq rect eq :8

(U : Type) (p : U ) (Q : U ! Type) (x : Q p) (h : p = p),
x = eq rect p Q x p h ]

This axiom says that it is permissible to simplify pattern matches over proofs of equalities
like e = e. The axiom is logically equivalent to some simpler corollaries.

Corollary UIP reAE : 8 A (x : A) (pf : x = x ), pf = reAE equal x.

intros; replace pf with (eq rect x (eq x ) (reAE equal x ) x pf ); [

symmetry; apply eq rect eq|

exact (match pf as pf ' return match pf ' in = y return x = y with|

reAE equal ) reAE equal x
end = pf ' with|
reAE equal ) reAE equal
end) ].
Qed.

Corollary UIP : 8 A (x y : A) (pf1 pf2 : x = y), pf1 = pf2.

intros; generalize pf1 pf2 ; subst; intros;

match goal with|

[ ` ?pf1 = ?pf2 ] ) rewrite (UIP reAE pf1 ); rewrite (UIP reAE pf2 ); reflexivity
end.
Qed.

These corollaries are special cases of proof irrelevance. In developments that only need
proof irrelevance for equality, there is no need to assert full irrelevance.

Another facet of proof irrelevance is that, like excluded middle, it is often provable for
specio/c propositions. For instance, UIP is provable whenever the type A has a decidable
equality operation. The module Eqdep dec of the standard library contains a proof. A
similar phenomenon applies to other notable cases, including less-than proofs. Thus, it is
often possible to use proof irrelevance without asserting axioms.

There are two more basic axioms that are often assumed, to avoid complications that do
not arise in set theory.

Require Import FunctionalExtensionality.
Print functional extensionality dep.

*** [ functional extensionality dep :8

(A : Type) (B : A ! Type) (f g : 8 x : A, B x ),
(8 x : A, f x = g x ) ! f = g ]

This axiom says that two functions are equal if they map equal inputs to equal outputs.
Such facts are not provable in general in CIC, but it is consistent to assume that they are.

A simple corollary shows that the same property applies to predicates. In some cases,
one might prefer to assert this corollary as the axiom, to restrict the consequences to proofs

205

and not programs.
Corollary predicate extensionality : 8 (A : Type) (B : A ! Prop) (f g : 8 x : A, B x ),

(8 x : A, f x = g x ) ! f = g.
intros; apply functional extensionality dep; assumption.
Qed.

11.3.2 Axioms of Choice
Some Coq axioms are also points of contention in mainstream math. The most prominent
example is the axiom of choice. In fact, there are multiple versions that we might consider,
and, considered in isolation, none of these versions means quite what it means in classical
set theory.

First, it is possible to implement a choice operator without axioms in some potentially
surprising cases.

Require Import ConstructiveEpsilon.
Check constructive deo/nite description.

constructive deo/nite description

: 8 (A : Set) (f : A ! nat) (g : nat ! A),

(8 x : A, g (f x ) = x ) !8

P : A ! Prop,
(8 x : A, -P x "" + -~ P x "") !
(9! x : A, P x ) ! -x : A | P x ""

Print Assumptions constructive deo/nite description.
Closed under the global context

This function transforms a decidable predicate P into a function that produces an el-
ement satisfying P from a proof that such an element exists. The functions f and g, in
conjunction with an associated injectivity property, are used to express the idea that the set
A is countable. Under these conditions, a simple brute force algorithm gets the job done:
we just enumerate all elements of A, stopping when we o/nd one satisfying P . The existence
proof, specio/ed in terms of unique existence 9!, guarantees termination. The deo/nition of
this operator in Coq uses some interesting techniques, as seen in the implementation of the
ConstructiveEpsilon module.

Countable choice is provable in set theory without appealing to the general axiom of
choice. To support the more general principle in Coq, we must also add an axiom. Here is
a functional version of the axiom of unique choice.

Require Import ClassicalUniqueChoice.
Check dependent unique choice.

dependent unique choice

: 8 (A : Type) (B : A ! Type) (R : 8 x : A, B x ! Prop),

(8 x : A, 9! y : B x , R x y) !

206

9 f : 8 x : A, B x , 8 x : A, R x (f x )
This axiom lets us convert a relational specio/cation R into a function implementing
that specio/cation. We need only prove that R is truly a function. An alternate, stronger
formulation applies to cases where R maps each input to one or more outputs. We also
simplify the statement of the theorem by considering only non-dependent function types.

Require Import ClassicalChoice.
Check choice.

choice

: 8 (A B : Type) (R : A ! B ! Prop),

(8 x : A, 9 y : B , R x y ) !9

f : A ! B , 8 x : A, R x (f x )

This principle is proved as a theorem, based on the unique choice axiom and an additional
axiom of relational choice from the RelationalChoice module.

In set theory, the axiom of choice is a fundamental philosophical commitment one makes
about the universe of sets. In Coq, the choice axioms say something weaker. For instance,
consider the simple restatement of the choice axiom where we replace existential quantio/ca-
tion by its Curry-Howard analogue, subset types.

Definition choice Set (A B : Type) (R : A ! B ! Prop) (H : 8 x : A, -y : B | R x y "")

: -f : A ! B | 8 x : A, R x (f x )"" :=
exist (fun f ) 8 x : A, R x (f x ))
(fun x ) proj1 sig (H x )) (fun x ) proj2 sig (H x )).

Via the Curry-Howard correspondence, this "axiom" can be taken to have the same
meaning as the original. It is implemented trivially as a transformation not much deeper
than uncurrying. Thus, we see that the utility of the axioms that we mentioned earlier comes
in their usage to build programs from proofs. Normal set theory has no explicit proofs, so the
meaning of the usual axiom of choice is subtlely dioeerent. In Gallina, the axioms implement
a controlled relaxation of the restrictions on information AEow from proofs to programs.

However, when we combine an axiom of choice with the law of the excluded middle,
the idea of "choice" becomes more interesting. Excluded middle gives us a highly non-
computational way of constructing proofs, but it does not change the computational nature
of programs. Thus, the axiom of choice is still giving us a way of translating between two
dioeerent sorts of "programs," but the input programs (which are proofs) may be written in
a rich language that goes beyond normal computability. This truly is more than repackaging
a function with a dioeerent type.

The Coq tools support a command-line AEag -impredicative-set, which modio/es Gallina
in a more fundamental way by making Set impredicative. A term like 8 T : Set, T has type
Set, and inductive deo/nitions in Set may have constructors that quantify over arguments of
any types. To maintain consistency, an elimination restriction must be imposed, similarly
to the restriction for Prop. The restriction only applies to large inductive types, where some

207

constructor quantio/es over a type of type Type. In such cases, a value in this inductive type
may only be pattern-matched over to yield a result type whose type is Set or Prop. This
contrasts with Prop, where the restriction applies even to non-large inductive types, and
where the result type may only have type Prop.

In old versions of Coq, Set was impredicative by default. Later versions make Set
predicative to avoid inconsistency with some classical axioms. In particular, one should
watch out when using impredicative Set with axioms of choice. In combination with excluded
middle or predicate extensionality, this can lead to inconsistency. Impredicative Set can be
useful for modeling inherently impredicative mathematical concepts, but almost all Coq
developments get by o/ne without it.

11.3.3 Axioms and Computation
One additional axiom-related wrinkle arises from an aspect of Gallina that is very dioeerent
from set theory: a notion of computational equivalence is central to the deo/nition of the
formal system. Axioms tend not to play well with computation. Consider this example. We
start by implementing a function that uses a type equality proof to perform a safe type-cast.

Definition cast (x y : Set) (pf : x = y) (v : x ) : y :=

match pf with|

reAE equal ) v
end.

Computation over programs that use cast can proceed smoothly.
Eval compute in (cast (reAE equal (nat ! nat)) (fun n ) S n)) 12.

= 13
: nat

Things do not go as smoothly when we use cast with proofs that rely on axioms.
Theorem t3 : (8 n : nat, o/n (S n)) = (8 n : nat, o/n (n + 1)).

change ((8 n : nat, (fun n ) o/n (S n)) n) = (8 n : nat, (fun n ) o/n (n + 1)) n));

rewrite (functional extensionality (fun n ) o/n (n + 1)) (fun n ) o/n (S n))); crush.
Qed.

Eval compute in (cast t3 (fun ) First)) 12.

= match t3 in ( = P ) return P with|

reAE equal ) fun n : nat ) First
end 12
: o/n (12 + 1)

Computation gets stuck in a pattern-match on the proof t3. The structure of t3 is
not known, so the match cannot proceed. It turns out a more basic problem leads to this

208

particular situation. We ended the proof of t3 with Qed, so the deo/nition of t3 is not available
to computation. That is easily o/xed.

Reset t3.
Theorem t3 : (8 n : nat, o/n (S n)) = (8 n : nat, o/n (n + 1)).

change ((8 n : nat, (fun n ) o/n (S n)) n) = (8 n : nat, (fun n ) o/n (n + 1)) n));

rewrite (functional extensionality (fun n ) o/n (n + 1)) (fun n ) o/n (S n))); crush.
Defined.

Eval compute in (cast t3 (fun ) First)) 12.

= match

match

match

functional extensionality
....

We elide most of the details. A very unwieldy tree of nested matches on equality proofs
appears. This time evaluation really is stuck on a use of an axiom.

If we are careful in using tactics to prove an equality, we can still compute with casts
over the proof.

Lemma plus1 : 8 n, S n = n + 1.

induction n; simpl; intuition.
Defined.

Theorem t4 : 8 n, o/n (S n) = o/n (n + 1).

intro; f equal; apply plus1.
Defined.

Eval compute in cast (t4 13) First.

= First
: o/n (13 + 1)

209

Part III
Proof Engineering

210

Chapter 12
Proof Search in Ltac

We have seen many examples of proof automation so far. This chapter aims to give a
principled presentation of the features of Ltac, focusing in particular on the Ltac match
construct, which supports a novel approach to backtracking search. First, though, we will
run through some useful automation tactics that are built into Coq. They are described in
detail in the manual, so we only outline what is possible.

12.1 Some Built-In Automation Tactics
A number of tactics are called repeatedly by crush. intuition simplio/es propositional
structure of goals. congruence applies the rules of equality and congruence closure, plus
properties of constructors of inductive types. The omega tactic provides a complete decision
procedure for a theory that is called quantio/er-free linear arithmetic or Presburger arithmetic,
depending on whom you ask. That is, omega proves any goal that follows from looking only
at parts of that goal that can be interpreted as propositional formulas whose atomic formulas
are basic comparison operations on natural numbers or integers.

The ring tactic solves goals by appealing to the axioms of rings or semi-rings (as in
algebra), depending on the type involved. Coq developments may declare new types to be
parts of rings and semi-rings by proving the associated axioms. There is a simlar tactic o/eld
for simplifying values in o/elds by conversion to fractions over rings. Both ring and o/eld
can only solve goals that are equalities. The fourier tactic uses Fourier's method to prove
inequalities over real numbers, which are axiomatized in the Coq standard library.

The setoid facility makes it possible to register new equivalence relations to be understood
by tactics like rewrite. For instance, Prop is registered as a setoid with the equivalence
relation "if and only if." The ability to register new setoids can be very useful in proofs of a
kind common in math, where all reasoning is done after "modding out by a relation."

211

12.2 Hint Databases
Another class of built-in tactics includes auto, eauto, and autorewrite. These are based
on hint databases, which we have seen extended in many examples so far. These tactics
are important, because, in Ltac programming, we cannot create "global variables" whose
values can be extended seamlessly by dioeerent modules in dioeerent source o/les. We have
seen the advantages of hints so far, where crush can be deo/ned once and for all, while still
automatically applying the hints we add throughout developments.

The basic hints for auto and eauto are Hint Immediate lemma, asking to try solving
a goal immediately by applying a lemma and discharging any hypotheses with a single
proof step each; Resolve lemma, which does the same but may add new premises that are
themselves to be subjects of nested proof search; Constructor type, which acts like Resolve
applied to every constructor of an inductive type; and Unfold ident, which tries unfolding
ident when it appears at the head of a proof goal. Each of these Hint commands may be used
with a suOEx, as in Hint Resolve lemma : my db. This adds the hint only to the specio/ed
database, so that it would only be used by, for instance, auto with my db. An additional
argument to auto specio/es the maximum depth of proof trees to search in depth-o/rst order,
as in auto 8 or auto 8 with my db. The default depth is 5.

All of these Hint commands can be issued alternatively with a more primitive hint kind,
Extern. A few examples should do best to explain how Hint Extern works.

Theorem bool neq : true 6= false.

auto.

crush would have discharged this goal, but the default hint database for auto contains
no hint that applies.

Abort.

It is hard to come up with a bool-specio/c hint that is not just a restatement of the
theorem we mean to prove. Luckily, a simpler form suOEces.

Hint Extern 1 ( 6= ) ) congruence.
Theorem bool neq : true 6= false.

auto.
Qed.

Our hint says: "whenever the conclusion matches the pattern 6= , try applying
congruence." The 1 is a cost for this rule. During proof search, whenever multiple rules
apply, rules are tried in increasing cost order, so it pays to assign high costs to relatively
expensive Extern hints.

Extern hints may be implemented with the full Ltac language. This example shows a
case where a hint uses a match.

Section forall and.

Variable A : Set.
Variables P Q : A ! Prop.

212

Hypothesis both : 8 x, P x ^ Q x.
Theorem forall and : 8 z, P z.

crush.

crush makes no progress beyond what intros would have accomplished. auto will not
apply the hypothesis both to prove the goal, because the conclusion of both does not unify
with the conclusion of the goal. However, we can teach auto to handle this kind of goal.

Hint Extern 1 (P ?X) )

match goal with|

[ H : 8 x, P x ^ ` ] ) apply (proj1 (H X ))
end.

auto.
Qed.

We see that an Extern pattern may bind unio/cation variables that we use in the associated
tactic. proj1 is a function from the standard library for extracting a proof of R from a proof
of R ^ S .

End forall and.

After our success on this example, we might get more ambitious and seek to generalize
the hint to all possible predicates P .

Hint Extern 1 (?P ?X) )

match goal with|

[ H : 8 x , P x ^ ` ] ) apply (proj1 (H X ))
end.

User error : Bound head variable

Coq's auto hint databases work as tables mapping head symbols to lists of tactics to try.
Because of this, the constant head of an Extern pattern must be determinable statically. In
our o/rst Extern hint, the head symbol was not, since x 6= y desugars to not (eq x y ); and,
in the second example, the head symbol was P .

This restriction on Extern hints is the main limitation of the auto mechanism, preventing
us from using it for general context simplio/cations that are not keyed ooe of the form of the
conclusion. This is perhaps just as well, since we can often code more eOEcient tactics with
specialized Ltac programs, and we will see how in later sections of the chapter.

We have used Hint Rewrite in many examples so far. crush uses these hints by calling
autorewrite. Our rewrite hints have taken the form Hint Rewrite lemma : cpdt, adding them
to the cpdt rewrite database. This is because, in contrast to auto, autorewrite has no default
database. Thus, we set the convention that crush uses the cpdt database.

This example shows a direct use of autorewrite.

Section autorewrite.

213

Variable A : Set.
Variable f : A ! A.

Hypothesis f f : 8 x, f (f x ) = f x.
Hint Rewrite f f : my db.
Lemma f f f : 8 x, f (f (f x )) = f x.

intros; autorewrite with my db; reflexivity.
Qed.

There are a few ways in which autorewrite can lead to trouble when insuOEcient care is
taken in choosing hints. First, the set of hints may deo/ne a nonterminating rewrite system,
in which case invocations to autorewrite may not terminate. Second, we may add hints that
"lead autorewrite down the wrong path." For instance:

Section garden path.

Variable g : A ! A.
Hypothesis f g : 8 x, f x = g x.
Hint Rewrite f g : my db.

Lemma f f f' : 8 x, f (f (f x )) = f x.

intros; autorewrite with my db.

============================

g (g (g x )) = g x

Abort.
Our new hint was used to rewrite the goal into a form where the old hint could no longer
be applied. This "non-monotonicity" of rewrite hints contrasts with the situation for auto,
where new hints may slow down proof search but can never "break" old proofs.

Reset garden path.

autorewrite works with quantio/ed equalities that include additional premises, but we must
be careful to avoid similar incorrect rewritings.

Section garden path.

Variable P : A ! Prop.
Variable g : A ! A.
Hypothesis f g : 8 x, P x ! f x = g x.
Hint Rewrite f g : my db.

Lemma f f f' : 8 x, f (f (f x )) = f x.

intros; autorewrite with my db.

============================

g (g (g x )) = g x

214

subgoal 2 is:

P x
subgoal 3 is:

P (f x )
subgoal 4 is:

P (f x )

Abort.
The inappropriate rule o/red the same three times as before, even though we know we
will not be able to prove the premises.

Reset garden path.

Our o/nal, successful, attempt uses an extra argument to Hint Rewrite that specio/es a
tactic to apply to generated premises.

Section garden path.

Variable P : A ! Prop.
Variable g : A ! A.
Hypothesis f g : 8 x, P x ! f x = g x.
Hint Rewrite f g using assumption : my db.

Lemma f f f' : 8 x, f (f (f x )) = f x.

intros; autorewrite with my db; reflexivity.
Qed.

autorewrite will still use f g when the generated premise is among our assumptions.

Lemma f f f g : 8 x, P x ! f (f x ) = g x.

intros; autorewrite with my db; reflexivity.
Qed.
End garden path.

It can also be useful to use the autorewrite with db in * form, which does rewriting in
hypotheses, as well as in the conclusion.

Lemma in star : 8 x y, f (f (f (f x ))) = f (f y)!

f x = f (f (f y)).
intros; autorewrite with my db in *; assumption.
Qed.

End autorewrite.

12.3 Ltac Programming Basics
We have already seen many examples of Ltac programs. In the rest of this chapter, we
attempt to give a more principled introduction to the important features and design patterns.

215

One common use for match tactics is identio/cation of subjects for case analysis, as we
see in this tactic deo/nition.

Ltac o/nd if :=

match goal with|

[ ` if ?X then else ] ) destruct X
end.

The tactic checks if the conclusion is an if, destructing the test expression if so. Certain
classes of theorem are trivial to prove automatically with such a tactic.

Theorem hmm : 8 (a b c : bool),

if a

then if b

then True
else True
else if c

then True
else True.
intros; repeat o/nd if ; constructor.
Qed.

The repeat that we use here is called a tactical, or tactic combinator. The behavior
of repeat t is to loop through running t , running t on all generated subgoals, running t
on their generated subgoals, and so on. When t fails at any point in this search tree, that
particular subgoal is left to be handled by later tactics. Thus, it is important never to use
repeat with a tactic that always succeeds.

Another very useful Ltac building block is context patterns.

Ltac o/nd if inside :=

match goal with|

[ ` context [if ?X then else ] ] ) destruct X
end.

The behavior of this tactic is to o/nd any subterm of the conclusion that is an if and
then destruct the test expression. This version subsumes o/nd if.

Theorem hmm' : 8 (a b c : bool),

if a

then if b

then True
else True
else if c

then True
else True.
intros; repeat o/nd if inside; constructor.
Qed.

We can also use o/nd if inside to prove goals that o/nd if does not simplify suOEciently.

216

Theorem hmm2 : 8 (a b : bool),

(if a then 42 else 42) = (if b then 42 else 42).
intros; repeat o/nd if inside; reflexivity.
Qed.

Many decision procedures can be coded in Ltac via "repeat match loops." For instance,
we can implement a subset of the functionality of tauto.

Ltac my tauto :=

repeat match goal with|

[ H : ?P ` ?P ] ) exact H

| [ ` True ] ) constructor|

[ ` ^ ] ) constructor|
[ ` ! ] ) intro

| [ H : False ` ] ) destruct H|

[ H : ^ ` ] ) destruct H|
[ H : . ` ] ) destruct H

| [ H1 : ?P ! ?Q, H2 : ?P ` ] )

let H := fresh "H" in

generalize (H1 H2 ); clear H1 ; intro H
end.

Since match patterns can share unio/cation variables between hypothesis and conclusion
patterns, it is easy to o/gure out when the conclusion matches a hypothesis. The exact tactic
solves a goal completely when given a proof term of the proper type.

It is also trivial to implement the "introduction rules" for a few of the connectives.
Implementing elimination rules is only a little more work, since we must give a name for a
hypothesis to destruct.

The last rule implements modus ponens. The most interesting part is the use of the
Ltac-level let with a fresh expression. fresh takes in a name base and returns a fresh
hypothesis variable based on that name. We use the new name variable H as the name we
assign to the result of modus ponens. The use of generalize changes our conclusion to be
an implication from Q . We clear the original hypothesis and move Q into the context with
name H.

Section propositional.

Variables P Q R : Prop.

Theorem propositional : (P . Q . False) ^ (P ! Q ) ! True ^ Q.

my tauto.
Qed.
End propositional.

It was relatively easy to implement modus ponens, because we do not lose information

217

by clearing every implication that we use. If we want to implement a similarly-complete
procedure for quantio/er instantiation, we need a way to ensure that a particular proposition
is not already included among our hypotheses. To do that eoeectively, we o/rst need to learn
a bit more about the semantics of match.

It is tempting to assume that match works like it does in ML. In fact, there are a few
critical dioeerences in its behavior. One is that we may include arbitrary expressions in
patterns, instead of being restricted to variables and constructors. Another is that the same
variable may appear multiple times, inducing an implicit equality constraint.

There is a related pair of two other dioeerences that are much more important than the
others. match has a backtracking semantics for failure. In ML, pattern matching works
by o/nding the o/rst pattern to match and then executing its body. If the body raises an
exception, then the overall match raises the same exception. In Coq, failures in case bodies
instead trigger continued search through the list of cases.

For instance, this (unnecessarily verbose) proof script works:

Theorem m1 : True.

match goal with|

[ ` ] ) intro|
[ ` True ] ) constructor
end.
Qed.

The o/rst case matches trivially, but its body tactic fails, since the conclusion does not
begin with a quantio/er or implication. In a similar ML match, that would mean that the
whole pattern-match fails. In Coq, we backtrack and try the next pattern, which also
matches. Its body tactic succeeds, so the overall tactic succeeds as well.

The example shows how failure can move to a dioeerent pattern within a match. Failure
can also trigger an attempt to o/nd a dioeerent way of matching a single pattern. Consider
another example:

Theorem m2 : 8 P Q R : Prop, P ! Q ! R ! Q.

intros; match goal with|

[ H : ` ] ) idtac H
end.

Coq prints "H1 ". By applying idtac with an argument, a convenient debugging tool for
"leaking information out of matches," we see that this match o/rst tries binding H to H1 ,
which cannot be used to prove Q . Nonetheless, the following variation on the tactic succeeds
at proving the goal:

match goal with|

[ H : ` ] ) exact H
end.
Qed.

The tactic o/rst unio/es H with H1 , as before, but exact H fails in that case, so the tactic
engine searches for more possible values of H. Eventually, it arrives at the correct value, so

218

that exact H and the overall tactic succeed.

Now we are equipped to implement a tactic for checking that a proposition is not among
our hypotheses:

Ltac notHyp P :=

match goal with|

[ : P ` ] ) fail 1| )

match P with|

?P1 ^ ?P2 ) o/rst [ notHyp P1 | notHyp P2 | fail 2 ]| )

idtac
end
end.

We use the equality checking that is built into pattern-matching to see if there is a
hypothesis that matches the proposition exactly. If so, we use the fail tactic. Without
arguments, fail signals normal tactic failure, as you might expect. When fail is passed an
argument n, n is used to count outwards through the enclosing cases of backtracking search.
In this case, fail 1 says "fail not just in this pattern-matching branch, but for the whole
match." The second case will never be tried when the fail 1 is reached.

This second case, used when P matches no hypothesis, checks if P is a conjunction.
Other simplio/cations may have split conjunctions into their component formulas, so we need
to check that at least one of those components is also not represented. To achieve this, we
apply the o/rst tactical, which takes a list of tactics and continues down the list until one
of them does not fail. The fail 2 at the end says to fail both the o/rst and the match
wrapped around it.

The body of the ?P1 ^ ?P2 case guarantees that, if it is reached, we either succeed
completely or fail completely. Thus, if we reach the wildcard case, P is not a conjunction.
We use idtac, a tactic that would be silly to apply on its own, since its eoeect is to succeed
at doing nothing. Nonetheless, idtac is a useful placeholder for cases like what we see here.

With the non-presence check implemented, it is easy to build a tactic that takes as input
a proof term and adds its conclusion as a new hypothesis, only if that conclusion is not
already present, failing otherwise.

Ltac extend pf :=

let t := type of pf in

notHyp t ; generalize pf ; intro.

We see the useful type of operator of Ltac. This operator could not be implemented in
Gallina, but it is easy to support in Ltac. We end up with t bound to the type of pf. We
check that t is not already present. If so, we use a generalize/intro combo to add a new
hypothesis proved by pf.

With these tactics deo/ned, we can write a tactic completer for adding to the context all
consequences of a set of simple o/rst-order formulas.

Ltac completer :=

219

repeat match goal with|

[ ` ^ ] ) constructor|
[ H : ^ ` ] ) destruct H|
[ H : ?P ! ?Q, H' : ?P ` ] )

generalize (H H' ); clear H ; intro H|
[ ` 8 x, ] ) intro

| [ H : 8 x, ?P x ! , H' : ?P ?X ` ] )

extend (H X H' )
end.

We use the same kind of conjunction and implication handling as previously. Note that,
since ! is the special non-dependent case of 8, the fourth rule handles intro for implications,
too.

In the o/fth rule, when we o/nd a 8 fact H with a premise matching one of our hypotheses,
we add the appropriate instantiation of H 's conclusion, if we have not already added it.

We can check that completer is working properly:

Section o/rstorder.

Variable A : Set.
Variables P Q R S : A ! Prop.

Hypothesis H1 : 8 x, P x ! Q x ^ R x.
Hypothesis H2 : 8 x, R x ! S x.

Theorem fo : 8 x, P x ! S x.

completer.

x : A
H : P x
H0 : Q x
H3 : R x
H4 : S x
============================

S x

assumption.
Qed.
End o/rstorder.

We narrowly avoided a subtle pitfall in our deo/nition of completer. Let us try another
deo/nition that even seems preferable to the original, to the untrained eye.

Ltac completer' :=

repeat match goal with|

[ ` ^ ] ) constructor|
[ H : ^ ` ] ) destruct H|
[ H : ?P ! , H' : ?P ` ] )

220

generalize (H H' ); clear H ; intro H|
[ ` 8 x, ] ) intro

| [ H : 8 x, ?P x ! , H' : ?P ?X ` ] )

extend (H X H' )
end.

The only dioeerence is in the modus ponens rule, where we have replaced an unused
unio/cation variable ?Q with a wildcard. Let us try our example again with this version:

Section o/rstorder'.

Variable A : Set.
Variables P Q R S : A ! Prop.

Hypothesis H1 : 8 x, P x ! Q x ^ R x.
Hypothesis H2 : 8 x, R x ! S x.

Theorem fo' : 8 x, P x ! S x.

completer'.
Coq loops forever at this point. What went wrong?
Abort.
End o/rstorder'.

A few examples should illustrate the issue. Here we see a match-based proof that works
o/ne:

Theorem t1 : 8 x : nat, x = x.

match goal with|

[ ` 8 x, ] ) trivial
end.
Qed.

This one fails.
Theorem t1' : 8 x : nat, x = x.

match goal with|

[ ` 8 x , ?P ] ) trivial
end.

User error : No matching clauses for match goal
Abort.

The problem is that unio/cation variables may not contain locally-bound variables. In
this case, ?P would need to be bound to x = x , which contains the local quantio/ed variable
x . By using a wildcard in the earlier version, we avoided this restriction.

221

The Coq 8.2 release includes a special pattern form for a unio/cation variable with an
explicit set of free variables. That unio/cation variable is then bound to a function from the
free variables to the "real" value. In Coq 8.1 and earlier, there is no such workaround.

No matter which version you use, it is important to be aware of this restriction. As
we have alluded to, the restriction is the culprit behind the ino/nite-looping behavior of
completer'. We unintentionally match quantio/ed facts with the modus ponens rule, circum-
venting the "already present" check and leading to dioeerent behavior.

12.4 Functional Programming in Ltac
Ltac supports quite convenient functional programming, with a Lisp-with-syntax kind of
AEavor. However, there are a few syntactic conventions involved in getting programs to be
accepted. The Ltac syntax is optimized for tactic-writing, so one has to deal with some
inconveniences in writing more standard functional programs.

To illustrate, let us try to write a simple list length function. We start out writing it just
like in Gallina, simply replacing Fixpoint (and its annotations) with Ltac.

Ltac length ls :=

match ls with|

nil ) O|

:: ls' ) S (length ls' )
end.

Error : The reference ls' was not found in the current environment

At this point, we hopefully remember that pattern variable names must be preo/xed by
question marks in Ltac.

Ltac length ls :=

match ls with|

nil ) O|

:: ?ls' ) S (length ls' )
end.

Error : The reference S was not found in the current environment

The problem is that Ltac treats the expression S (length ls' ) as an invocation of a tactic
S with argument length ls'. We need to use a special annotation to "escape into" the Gallina
parsing nonterminal.

Ltac length ls :=

match ls with

222

| nil ) O|

:: ?ls' ) constr :(S (length ls' ))
end.

This deo/nition is accepted. It can be a little awkward to test Ltac deo/nitions like this.
Here is one method.

Goal False.

let n := length (1 :: 2 :: 3 :: nil) in

pose n.

n := S (length (2 :: 3 :: nil)) : nat
============================

False

We use the pose tactic, which extends the proof context with a new variable that is set
equal to particular a term. We could also have used idtac n in place of pose n, which would
have printed the result without changing the context.

n only has the length calculation unrolled one step. What has happened here is that, by
escaping into the constr nonterminal, we referred to the length function of Gallina, rather
than the length Ltac function that we are deo/ning.

Abort.
Reset length.

The thing to remember is that Gallina terms built by tactics must be bound explicitly via
let or a similar technique, rather than inserting Ltac calls directly in other Gallina terms.

Ltac length ls :=

match ls with|

nil ) O|

:: ?ls' )
let lsj := length ls' in

constr :(S lsj)
end.

Goal False.

let n := length (1 :: 2 :: 3 :: nil) in

pose n.

n := 3 : nat
============================

False

Abort.

We can also use anonymous function expressions and local function deo/nitions in Ltac,
as this example of a standard list map function shows.

223

Ltac map T f :=

let rec map' ls :=

match ls with|

nil ) constr :(@nil T )|
?x :: ?ls' )

let x' := f x in

let lsj := map' ls' in

constr :(x' :: lsj)
end in
map'.

Ltac functions can have no implicit arguments. It may seem surprising that we need to
pass T , the carried type of the output list, explicitly. We cannot just use type of f, because
f is an Ltac term, not a Gallina term, and Ltac programs are dynamically typed. f could use
very syntactic methods to decide to return dioeerently typed terms for dioeerent inputs. We
also could not replace constr :(@nil T ) with constr :nil, because we have no strongly-typed
context to use to infer the parameter to nil. Luckily, we do have suOEcient context within
constr :(x' :: lsj).

Sometimes we need to employ the opposite direction of "nonterminal escape," when we
want to pass a complicated tactic expression as an argument to another tactic, as we might
want to do in invoking map.

Goal False.

let ls := map (nat * nat)%type ltac:(fun x ) constr :(x, x )) (1 :: 2 :: 3 :: nil) in

pose ls.

l := (1, 1) :: (2, 2) :: (3, 3) :: nil : list (nat * nat)
============================

False

Abort.

12.5 Recursive Proof Search
Deciding how to instantiate quantio/ers is one of the hardest parts of automated o/rst-order
theorem proving. For a given problem, we can consider all possible bounded-length sequences
of quantio/er instantiations, applying only propositional reasoning at the end. This is proba-
bly a bad idea for almost all goals, but it makes for a nice example of recursive proof search
procedures in Ltac.

We can consider the maximum "dependency chain" length for a o/rst-order proof. We
deo/ne the chain length for a hypothesis to be 0, and the chain length for an instantiation
of a quantio/ed fact to be one greater than the length for that fact. The tactic inster n is
meant to try all possible proofs with chain length at most n.

Ltac inster n :=

224

intuition;

match n with|

S ?n' )

match goal with|

[ H : 8 x : ?T, , x : ?T ` ] ) generalize (H x ); inster n'
end
end.

inster begins by applying propositional simplio/cation. Next, it checks if any chain length
remains. If so, it tries all possible ways of instantiating quantio/ed hypotheses with properly-
typed local variables. It is critical to realize that, if the recursive call inster n' fails, then the
match goal just seeks out another way of unifying its pattern against proof state. Thus, this
small amount of code provides an elegant demonstration of how backtracking match enables
exhaustive search.

We can verify the eOEcacy of inster with two short examples. The built-in firstorder
tactic (with no extra arguments) is able to prove the o/rst but not the second.

Section test inster.

Variable A : Set.
Variables P Q : A ! Prop.
Variable f : A ! A.
Variable g : A ! A ! A.

Hypothesis H1 : 8 x y, P (g x y) ! Q (f x ).
Theorem test inster : 8 x y, P (g x y) ! Q (f x ).

inster 2.
Qed.

Hypothesis H3 : 8 u v, P u ^ P v ^ u 6= v ! P (g u v ).
Hypothesis H4 : 8 u, Q (f u) ! P u ^ P (f u).

Theorem test inster2 : 8 x y, x 6= y ! P x ! Q (f y) ! Q (f x ).

inster 3.
Qed.
End test inster.

The style employed in the deo/nition of inster can seem very counterintuitive to functional
programmers. Usually, functional programs accumulate state changes in explicit arguments
to recursive functions. In Ltac, the state of the current subgoal is always implicit. Nonethe-
less, in contrast to general imperative programming, it is easy to undo any changes to this
state, and indeed such "undoing" happens automatically at failures within matches. In this
way, Ltac programming is similar to programming in Haskell with a stateful failure monad
that supports a composition operator along the lines of the o/rst tactical.

Functional programming purists may react indignantly to the suggestion of programming
this way. Nonetheless, as with other kinds of "monadic programming," many problems are
much simpler to solve with Ltac than they would be with explicit, pure proof manipulation
in ML or Haskell. To demonstrate, we will write a basic simplio/cation procedure for logical

225

implications.

This procedure is inspired by one for separation logic, where conjuncts in formulas are
thought of as "resources," such that we lose no completeness by "crossing out" equal con-
juncts on the two sides of an implication. This process is complicated by the fact that, for
reasons of modularity, our formulas can have arbitrary nested tree structure (branching at
conjunctions) and may include existential quantio/ers. It is helpful for the matching process
to "go under" quantio/ers and in fact decide how to instantiate existential quantio/ers in the
conclusion.

To distinguish the implications that our tactic handles from the implications that will
show up as "plumbing" in various lemmas, we deo/ne a wrapper deo/nition, a notation, and
a tactic.

Definition imp (P1 P2 : Prop) := P1 ! P2.
Infix "*?" := imp (no associativity, at level 95).
Ltac imp := unfold imp; firstorder.

These lemmas about imp will be useful in the tactic that we will write.
Theorem and True prem : 8 P Q,

(P ^ True *? Q )!

(P *? Q ).
imp.
Qed.

Theorem and True conc : 8 P Q,

(P *? Q ^ True)!

(P *? Q ).
imp.
Qed.

Theorem assoc prem1 : 8 P Q R S,

(P ^ (Q ^ R) *? S )!

((P ^ Q ) ^ R *? S ).
imp.
Qed.

Theorem assoc prem2 : 8 P Q R S,

(Q ^ (P ^ R) *? S )!

((P ^ Q ) ^ R *? S ).
imp.
Qed.

Theorem comm prem : 8 P Q R,

(P ^ Q *? R)!

(Q ^ P *? R).
imp.
Qed.

Theorem assoc conc1 : 8 P Q R S,

226

(S *? P ^ (Q ^ R))!

(S *? (P ^ Q ) ^ R).
imp.
Qed.

Theorem assoc conc2 : 8 P Q R S,

(S *? Q ^ (P ^ R))!

(S *? (P ^ Q ) ^ R).
imp.
Qed.

Theorem comm conc : 8 P Q R,

(R *? P ^ Q )!

(R *? Q ^ P ).
imp.
Qed.

The o/rst order of business in crafting our matcher tactic will be auxiliary support for
searching through formula trees. The search prem tactic implements running its tactic
argument tac on every subformula of an imp premise. As it traverses a tree, search prem
applies some of the above lemmas to rewrite the goal to bring dioeerent subformulas to the
head of the goal. That is, for every subformula P of the implication premise, we want P to
"have a turn," where the premise is rearranged into the form P ^ Q for some Q . The tactic
tac should expect to see a goal in this form and focus its attention on the o/rst conjunct of
the premise.

Ltac search prem tac :=

let rec search P :=

tac
---- (apply and True prem; tac)
---- match P with|

?P1 ^ ?P2 )

(apply assoc prem1; search P1 )
---- (apply assoc prem2; search P2 )
end
in match goal with|

[ ` ?P ^ *? ] ) search P|
[ ` ^ ?P *? ] ) apply comm prem; search P|
[ ` *? ] ) progress (tac ---- (apply and True prem; tac))
end.

To understand how search prem works, we turn o/rst to the o/nal match. If the premise
begins with a conjunction, we call the search procedure on each of the conjuncts, or only
the o/rst conjunct, if that already yields a case where tac does not fail. search P expects
and maintains the invariant that the premise is of the form P ^ Q for some Q . We pass
P explicitly as a kind of decreasing induction measure, to avoid looping forever when tac

227

always fails. The second match case calls a commutativity lemma to realize this invariant,
before passing control to search. The o/nal match case tries applying tac directly and then,
if that fails, changes the form of the goal by adding an extraneous True conjunct and calls
tac again.

search itself tries the same tricks as in the last case of the o/nal match. Additionally, if
neither works, it checks if P is a conjunction. If so, it calls itself recursively on each conjunct,
o/rst applying associativity lemmas to maintain the goal-form invariant.

We will also want a dual function search conc, which does tree search through an imp
conclusion.

Ltac search conc tac :=

let rec search P :=

tac
---- (apply and True conc; tac)
---- match P with|

?P1 ^ ?P2 )

(apply assoc conc1; search P1 )
---- (apply assoc conc2; search P2 )
end
in match goal with|

[ ` *? ?P ^ ] ) search P|
[ ` *? ^ ?P ] ) apply comm conc; search P|
[ ` *? ] ) progress (tac ---- (apply and True conc; tac))
end.

Now we can prove a number of lemmas that are suitable for application by our search
tactics. A lemma that is meant to handle a premise should have the form P ^ Q *? R for
some interesting P , and a lemma that is meant to handle a conclusion should have the form
P *? Q ^ R for some interesting Q .

Theorem False prem : 8 P Q,

False ^ P *? Q.
imp.
Qed.

Theorem True conc : 8 P Q : Prop,

(P *? Q )!

(P *? True ^ Q ).
imp.
Qed.

Theorem Match : 8 P Q R : Prop,

(Q *? R)!

(P ^ Q *? P ^ R).
imp.
Qed.

228

Theorem ex prem : 8 (T : Type) (P : T ! Prop) (Q R : Prop),

(8 x, P x ^ Q *? R)!

(ex P ^ Q *? R).
imp.
Qed.

Theorem ex conc : 8 (T : Type) (P : T ! Prop) (Q R : Prop) x,

(Q *? P x ^ R)!

(Q *? ex P ^ R).
imp.
Qed.

We will also want a "base case" lemma for o/nishing proofs where cancelation has removed
every constituent of the conclusion.

Theorem imp True : 8 P,

P *? True.
imp.
Qed.

Our o/nal matcher tactic is now straightforward. First, we intros all variables into
scope. Then we attempt simple premise simplio/cations, o/nishing the proof upon o/nding
False and eliminating any existential quantio/ers that we o/nd. After that, we search through
the conclusion. We remove True conjuncts, remove existential quantio/ers by introducing
unio/cation variables for their bound variables, and search for matching premises to cancel.
Finally, when no more progress is made, we see if the goal has become trivial and can be
solved by imp True. In each case, we use the tactic simple apply in place of apply to use a
simpler, less expensive unio/cation algorithm.

Ltac matcher :=

intros;

repeat search prem ltac:(simple apply False prem ---- (simple apply ex prem; intro));

repeat search conc ltac:(simple apply True conc ---- simple eapply ex conc

---- search prem ltac:(simple apply Match));
try simple apply imp True.

Our tactic succeeds at proving a simple example.
Theorem t2 : 8 P Q : Prop,

Q ^ (P ^ False) ^ P *? P ^ Q.
matcher.
Qed.

In the generated proof, we o/nd a trace of the workings of the search tactics.
Print t2.
t2 =
fun P Q : Prop )
comm prem (assoc prem1 (assoc prem2 (False prem (P :=P ^ P ^ Q) (P ^ Q ))))

229

: 8 P Q : Prop, Q ^ (P ^ False) ^ P *? P ^ Q
We can also see that matcher is well-suited for cases where some human intervention is
needed after the automation o/nishes.

Theorem t3 : 8 P Q R : Prop,

P ^ Q *? Q ^ R ^ P.
matcher.

============================

True *? R

matcher canceled those conjuncts that it was able to cancel, leaving a simplio/ed subgoal
for us, much as intuition does.

Abort.

matcher even succeeds at guessing quantio/er instantiations. It is the unio/cation that
occurs in uses of the Match lemma that does the real work here.

Theorem t4 : 8 (P : nat ! Prop) Q, (9 x, P x ^ Q ) *? Q ^ (9 x, P x ).

matcher.
Qed.

Print t4.
t4 =
fun (P : nat ! Prop) (Q : Prop) )
and True prem

(ex prem (P :=fun x : nat ) P x ^ Q )

(fun x : nat )

assoc prem2

(Match (P :=Q)

(and True conc

(ex conc (fun x0 : nat ) P x0 ) x

(Match (P :=P x ) (imp True (P :=True))))))))
: 8 (P : nat ! Prop) (Q : Prop),

(9 x : nat, P x ^ Q ) *? Q ^ (9 x : nat, P x )

12.6 Creating Unio/cation Variables
A o/nal useful ingredient in tactic crafting is the ability to allocate new unio/cation variables
explicitly. Tactics like eauto introduce unio/cation variable internally to support AEexible
proof search. While eauto and its relatives do backward reasoning, we often want to do
similar forward reasoning, where unio/cation variables can be useful for similar reasons.

230

For example, we can write a tactic that instantiates the quantio/ers of a universally-
quantio/ed hypothesis. The tactic should not need to know what the appropriate instan-
tiantiations are; rather, we want these choices o/lled with placeholders. We hope that, when
we apply the specialized hypothesis later, syntactic unio/cation will determine concrete values.

Before we are ready to write a tactic, we can try out its ingredients one at a time.

Theorem t5 : (8 x : nat, S x ? x ) ! 2 ? 1.

intros.

H : 8 x : nat, S x ? x
============================

2 ? 1

To instantiate H generically, we o/rst need to name the value to be used for x .
evar (y : nat).

H : 8 x : nat, S x ? x
y := ?279 : nat
============================

2 ? 1

The proof context is extended with a new variable y, which has been assigned to be equal
to a fresh unio/cation variable ?279. We want to instantiate H with ?279. To get ahold of
the new unio/cation variable, rather than just its alias y, we perform a trivial call-by-value
reduction in the expression y. In particular, we only request the use of one reduction rule,
delta, which deals with deo/nition unfolding. We pass a AEag further stipulating that only
the deo/nition of y be unfolded. This is a simple trick for getting at the value of a synonym
variable.

let y' := eval cbv delta [y] in y in

clear y; generalize (H y' ).

H : 8 x : nat, S x ? x
============================

S ?279 ? ?279 ! 2 ? 1

Our instantiation was successful. We can o/nish by using the reo/ned formula to replace
the original.

clear H ; intro H.

H : S ?281 ? ?281
============================

231

2 ? 1
We can o/nish the proof by using apply's unio/cation to o/gure out the proper value of
?281. (The original unio/cation variable was replaced by another, as often happens in the
internals of the various tactics' implementations.)

apply H.
Qed.

Now we can write a tactic that encapsulates the pattern we just employed, instantiating
all quantio/ers of a particular hypothesis.

Ltac insterU H :=

repeat match type of H with| 8

x : ?T, )
let x := fresh "x" in

evar (x : T );
let x' := eval cbv delta [x ] in x in

clear x ; generalize (H x' ); clear H ; intro H
end.

Theorem t5' : (8 x : nat, S x ? x ) ! 2 ? 1.

intro H ; insterU H ; apply H.
Qed.

This particular example is somewhat silly, since apply by itself would have solved the goal
originally. Separate forward reasoning is more useful on hypotheses that end in existential
quantio/cations. Before we go through an example, it is useful to deo/ne a variant of insterU
that does not clear the base hypothesis we pass to it.

Ltac insterKeep H :=

let H' := fresh "H'" in

generalize H ; intro H' ; insterU H'.

Section t6.

Variables A B : Type.
Variable P : A ! B ! Prop.
Variable f : A ! A ! A.
Variable g : B ! B ! B.

Hypothesis H1 : 8 v, 9 u, P v u.
Hypothesis H2 : 8 v1 u1 v2 u2,

P v1 u1!

P v2 u2!
P (f v1 v2 ) (g u1 u2 ).

Theorem t6 : 8 v1 v2, 9 u1, 9 u2, P (f v1 v2 ) (g u1 u2 ).

intros.

232

Neither eauto nor firstorder is clever enough to prove this goal. We can help out by
doing some of the work with quantio/ers ourselves.

do 2 insterKeep H1.
Our proof state is extended with two generic instances of H1 .

H' : 9 u : B , P ?4289 u
H'0 : 9 u : B , P ?4288 u
============================9

u1 : B , 9 u2 : B , P (f v1 v2 ) (g u1 u2 )

eauto still cannot prove the goal, so we eliminate the two new existential quantio/ers.

repeat match goal with|

[ H : ex ` ] ) destruct H
end.

Now the goal is simple enough to solve by logic programming.

eauto.
Qed.
End t6.

Our insterU tactic does not fare so well with quantio/ed hypotheses that also contain
implications. We can see the problem in a slight modio/cation of the last example. We
introduce a new unary predicate Q and use it to state an additional requirement of our
hypothesis H1 .

Section t7.

Variables A B : Type.
Variable Q : A ! Prop.
Variable P : A ! B ! Prop.
Variable f : A ! A ! A.
Variable g : B ! B ! B.

Hypothesis H1 : 8 v, Q v ! 9 u, P v u.
Hypothesis H2 : 8 v1 u1 v2 u2,

P v1 u1!

P v2 u2!
P (f v1 v2 ) (g u1 u2 ).

Theorem t6 : 8 v1 v2, Q v1 ! Q v2 ! 9 u1, 9 u2, P (f v1 v2 ) (g u1 u2 ).

intros; do 2 insterKeep H1 ;

repeat match goal with|

[ H : ex ` ] ) destruct H
end; eauto.

This proof script does not hit any errors until the very end, when an error message like
this one is displayed.

233

No more subgoals but non-instantiated existential variables :
Existential 1 =
?4384 : [A : Type

B : Type
Q : A ! Prop
P : A ! B ! Prop
f : A ! A ! A
g : B ! B ! B
H1 : 8 v : A, Q v ! 9 u : B , P v u
H2 : 8 (v1 : A) (u1 : B ) (v2 : A) (u2 : B ),

P v1 u1 ! P v2 u2 ! P (f v1 v2 ) (g u1 u2 )
v1 : A
v2 : A
H : Q v1
H0 : Q v2
H' : Q v2 ! 9 u : B , P v2 u ` Q v2 ]

There is another similar line about a dioeerent existential variable. Here, "existential
variable" means what we have also called "unio/cation variable." In the course of the proof,
some unio/cation variable ?4384 was introduced but never unio/ed. Unio/cation variables are
just a device to structure proof search; the language of Gallina proof terms does not include
them. Thus, we cannot produce a proof term without instantiating the variable.

The error message shows that ?4384 is meant to be a proof of Q v2 in a particular proof
state, whose variables and hypotheses are displayed. It turns out that ?4384 was created by
insterU, as the value of a proof to pass to H1 . Recall that, in Gallina, implication is just
a degenerate case of 8 quantio/cation, so the insterU code to match against 8 also matched
the implication. Since any proof of Q v2 is as good as any other in this context, there was
never any opportunity to use unio/cation to determine exactly which proof is appropriate.
We expect similar problems with any implications in arguments to insterU.

Abort.
End t7.

Reset insterU.

We can redeo/ne insterU to treat implications dioeerently. In particular, we pattern-match
on the type of the type T in 8 x : ?T, .... If T has type Prop, then x 's instantiation should
be thought of as a proof. Thus, instead of picking a new unio/cation variable for it, we instead
apply a user-supplied tactic tac. It is important that we end this special Prop case with ----
fail 1, so that, if tac fails to prove T , we abort the instantiation, rather than continuing
on to the default quantio/er handling.

Ltac insterU tac H :=

repeat match type of H with

234

| 8 x : ?T, )

match type of T with|

Prop )

(let H' := fresh "H'" in

assert (H' : T ); [

solve [ tac ]|

generalize (H H' ); clear H H' ; intro H ])
---- fail 1| )

let x := fresh "x" in

evar (x : T );
let x' := eval cbv delta [x ] in x in

clear x ; generalize (H x' ); clear H ; intro H
end
end.

Ltac insterKeep tac H :=

let H' := fresh "H'" in

generalize H ; intro H' ; insterU tac H'.

Section t7.

Variables A B : Type.
Variable Q : A ! Prop.
Variable P : A ! B ! Prop.
Variable f : A ! A ! A.
Variable g : B ! B ! B.

Hypothesis H1 : 8 v, Q v ! 9 u, P v u.
Hypothesis H2 : 8 v1 u1 v2 u2,

P v1 u1!

P v2 u2!
P (f v1 v2 ) (g u1 u2 ).

Theorem t6 : 8 v1 v2, Q v1 ! Q v2 ! 9 u1, 9 u2, P (f v1 v2 ) (g u1 u2 ).

We can prove the goal by calling insterKeep with a tactic that tries to o/nd and apply
a Q hypothesis over a variable about which we do not yet know any P facts. We need to
begin this tactic code with idtac; to get around a strange limitation in Coq's proof engine,
where a o/rst-class tactic argument may not begin with a match.

intros; do 2 insterKeep ltac:(idtac; match goal with|

[ H : Q ?v ` ] )

match goal with|

[ : context [P v ] ` ] ) fail 1| )

apply H
end
end) H1 ;

235

repeat match goal with|

[ H : ex ` ] ) destruct H
end; eauto.
Qed.
End t7.

It is often useful to instantiate existential variables explicitly. A built-in tactic provides
one way of doing so.

Theorem t8 : 9 p : nat * nat, fst p = 3.

econstructor ; instantiate (1 := (3, 2)); reflexivity.
Qed.

The 1 above is identifying an existential variable appearing in the current goal, with the
last existential appearing assigned number 1, the second last assigned number 2, and so on.
The named existential is replaced everywhere by the term to the right of the :=.

The instantiate tactic can be convenient for exploratory proving, but it leads to very
brittle proof scripts that are unlikely to adapt to changing theorem statements. It is often
more helpful to have a tactic that can be used to assign a value to a term that is known
to be an existential. By employing a roundabout implementation technique, we can build a
tactic that generalizes this functionality. In particular, our tactic equate will assert that two
terms are equal. If one of the terms happens to be an existential, then it will be replaced
everywhere with the other term.

Ltac equate x y :=

let H := fresh "H" in

assert (H : x = y); [ reflexivity | clear H ].

equate fails if it is not possible to prove x = y by reflexivity. We perform the proof
only for its unio/cation side eoeects, clearing the fact x = y afterward. With equate, we can
build a less brittle version of the prior example.

Theorem t9 : 9 p : nat * nat, fst p = 3.

econstructor ; match goal with|

[ ` fst ?x = 3 ] ) equate x (3, 2)
end; reflexivity.
Qed.

236

Chapter 13
Proof by ReAEection

The last chapter highlighted a very heuristic approach to proving. In this chapter, we
will study an alternative technique, proof by reAEection. We will write, in Gallina, decision
procedures with proofs of correctness, and we will appeal to these procedures in writing very
short proofs. Such a proof is checked by running the decision procedure. The term reAEection
applies because we will need to translate Gallina propositions into values of inductive types
representing syntax, so that Gallina programs may analyze them.

13.1 Proving Evenness
Proving that particular natural number constants are even is certainly something we would
rather have happen automatically. The Ltac-programming techniques that we learned in the
last chapter make it easy to implement such a procedure.

Inductive isEven : nat ! Prop :=|

Even O : isEven O|
Even SS : 8 n, isEven n ! isEven (S (S n)).

Ltac prove even := repeat constructor.
Theorem even 256 : isEven 256.

prove even.
Qed.

Print even 256.
even 256 =
Even SS

(Even SS

(Even SS

(Even SS

...and so on. This procedure always works (at least on machines with ino/nite resources),
but it has a serious drawback, which we see when we print the proof it generates that 256

237

is even. The o/nal proof term has length linear in the input value. This seems like a shame,
since we could write a trivial and trustworthy program to verify evenness of constants. The
proof checker could simply call our program where needed.

It is also unfortunate not to have static typing guarantees that our tactic always behaves
appropriately. Other invocations of similar tactics might fail with dynamic type errors, and
we would not know about the bugs behind these errors until we happened to attempt to
prove complex enough goals.

The techniques of proof by reAEection address both complaints. We will be able to write
proofs like this with constant size overhead beyond the size of the input, and we will do it
with verio/ed decision procedures written in Gallina.

For this example, we begin by using a type from the MoreSpecif module (included in the
book source) to write a certio/ed evenness checker.

Print partial.
Inductive partial (P : Prop) : Set := Proved : P ! [P ] | Uncertain : [P ]

A partial P value is an optional proof of P . The notation [P ] stands for partial P .
Local Open Scope partial scope.

We bring into scope some notations for the partial type. These overlap with some of the
notations we have seen previously for specio/cation types, so they were placed in a separate
scope that needs separate opening.

Definition check even (n : nat) : [isEven n].

Hint Constructors isEven.

refine (o/x F (n : nat) : [isEven n] :=

match n with|

0 ) Yes|
1 ) No|
S (S n' ) ) Reduce (F n' )
end); auto.
Defined.

We can use dependent pattern-matching to write a function that performs a surprising
feat. When given a partial P , this function partialOut returns a proof of P if the partial value
contains a proof, and it returns a (useless) proof of True otherwise. From the standpoint of
ML and Haskell programming, it seems impossible to write such a type, but it is trivial with
a return annotation.

Definition partialOut (P : Prop) (x : [P ]) :=

match x return (match x with|

Proved ) P|
Uncertain ) True
end) with|
Proved pf ) pf

238

| Uncertain ) I
end.

It may seem strange to deo/ne a function like this. However, it turns out to be very useful
in writing a reAEective verison of our earlier prove even tactic:

Ltac prove even reAEective :=

match goal with|

[ ` isEven ?N] ) exact (partialOut (check even N ))
end.

We identify which natural number we are considering, and we "prove" its evenness by
pulling the proof out of the appropriate check even call.

Theorem even 256' : isEven 256.

prove even reAEective.
Qed.

Print even 256'.
even 256' = partialOut (check even 256)

: isEven 256

We can see a constant wrapper around the object of the proof. For any even number,
this form of proof will suOEce. What happens if we try the tactic with an odd number?

Theorem even 255 : isEven 255.

prove even reAEective.
User error : No matching clauses for match goal

Thankfully, the tactic fails. To see more precisely what goes wrong, we can run manually
the body of the match.

exact (partialOut (check even 255)).
Error : The term "partialOut (check even 255)" has type
"match check even 255 with|

Yes ) isEven 255|
No ) True
end" while it is expected to have type "isEven 255"

As usual, the type-checker performs no reductions to simplify error messages. If we
reduced the o/rst term ourselves, we would see that check even 255 reduces to a No, so that
the o/rst term is equivalent to True, which certainly does not unify with isEven 255.

Abort.

239

13.2 ReAEecting the Syntax of a Trivial Tautology Lan-

guage

We might also like to have reAEective proofs of trivial tautologies like this one:
Theorem true galore : (True ^ True) ! (True . (True ^ (True ! True))).

tauto.
Qed.

Print true galore.
true galore =
fun H : True ^ True )
and ind (fun : True ) or introl (True ^ (True ! True)) I) H

: True ^ True ! True . True ^ (True ! True)

As we might expect, the proof that tauto builds contains explicit applications of natural
deduction rules. For large formulas, this can add a linear amount of proof size overhead,
beyond the size of the input.

To write a reAEective procedure for this class of goals, we will need to get into the actual
"reAEection" part of "proof by reAEection." It is impossible to case-analyze a Prop in any way
in Gallina. We must reAEect Prop into some type that we can analyze. This inductive type
is a good candidate:

Inductive taut : Set :=|

TautTrue : taut|
TautAnd : taut ! taut ! taut|
TautOr : taut ! taut ! taut|
TautImp : taut ! taut ! taut.

We write a recursive function to "unreAEect" this syntax back to Prop.
Fixpoint tautDenote (t : taut) : Prop :=

match t with|

TautTrue ) True|
TautAnd t1 t2 ) tautDenote t1 ^ tautDenote t2|
TautOr t1 t2 ) tautDenote t1 . tautDenote t2|
TautImp t1 t2 ) tautDenote t1 ! tautDenote t2
end.

It is easy to prove that every formula in the range of tautDenote is true.
Theorem tautTrue : 8 t, tautDenote t.

induction t ; crush.
Qed.

To use tautTrue to prove particular formulas, we need to implement the syntax reAEection
process. A recursive Ltac function does the job.

240

Ltac tautReAEect P :=

match P with|

True ) TautTrue|
?P1 ^ ?P2 )

let t1 := tautReAEect P1 in
let t2 := tautReAEect P2 in

constr :(TautAnd t1 t2 )|
?P1 . ?P2 )

let t1 := tautReAEect P1 in
let t2 := tautReAEect P2 in

constr :(TautOr t1 t2 )|
?P1 ! ?P2 )

let t1 := tautReAEect P1 in
let t2 := tautReAEect P2 in

constr :(TautImp t1 t2 )
end.

With tautReAEect available, it is easy to o/nish our reAEective tactic. We look at the goal
formula, reAEect it, and apply tautTrue to the reAEected formula.

Ltac obvious :=

match goal with|

[ ` ?P ] )

let t := tautReAEect P in

exact (tautTrue t )
end.

We can verify that obvious solves our original example, with a proof term that does not
mention details of the proof.

Theorem true galore' : (True ^ True) ! (True . (True ^ (True ! True))).

obvious.
Qed.

Print true galore'.

true galore' =
tautTrue

(TautImp (TautAnd TautTrue TautTrue)

(TautOr TautTrue (TautAnd TautTrue (TautImp TautTrue TautTrue))))
: True ^ True ! True . True ^ (True ! True)

It is worth considering how the reAEective tactic improves on a pure-Ltac implementation.
The formula reAEection process is just as ad-hoc as before, so we gain little there. In general,
proofs will be more complicated than formula translation, and the "generic proof rule"
that we apply here is on much better formal footing than a recursive Ltac function. The
dependent type of the proof guarantees that it "works" on any input formula. This is all in

241

addition to the proof-size improvement that we have already seen.
13.3 A Monoid Expression Simplio/er
Proof by reAEection does not require encoding of all of the syntax in a goal. We can insert
"variables" in our syntax types to allow injection of arbitrary pieces, even if we cannot apply
specialized reasoning to them. In this section, we explore that possibility by writing a tactic
for normalizing monoid equations.

Section monoid.

Variable A : Set.
Variable e : A.
Variable f : A ! A ! A.

Infix "+" := f.
Hypothesis assoc : 8 a b c, (a + b) + c = a + (b + c).
Hypothesis identl : 8 a, e + a = a.
Hypothesis identr : 8 a, a + e = a.

We add variables and hypotheses characterizing an arbitrary instance of the algebraic
structure of monoids. We have an associative binary operator and an identity element for it.

It is easy to deo/ne an expression tree type for monoid expressions. A Var constructor
is a "catch-all" case for subexpressions that we cannot model. These subexpressions could
be actual Gallina variables, or they could just use functions that our tactic is unable to
understand.

Inductive mexp : Set :=|

Ident : mexp|
Var : A ! mexp|
Op : mexp ! mexp ! mexp.

Next, we write an "un-reAEect" function.
Fixpoint mdenote (me : mexp) : A :=

match me with|

Ident ) e|
Var v ) v|
Op me1 me2 ) mdenote me1 + mdenote me2
end.

We will normalize expressions by AEattening them into lists, via associativity, so it is
helpful to have a denotation function for lists of monoid values.

Fixpoint mldenote (ls : list A) : A :=

match ls with|

nil ) e|
x :: ls' ) x + mldenote ls'

242

end.
The AEattening function itself is easy to implement.
Fixpoint AEatten (me : mexp) : list A :=

match me with|

Ident ) nil|
Var x ) x :: nil|
Op me1 me2 ) AEatten me1 ++ AEatten me2
end.

AEatten has a straightforward correctness proof in terms of our denote functions.
Lemma AEatten correct' : 8 ml2 ml1,

mldenote ml1 + mldenote ml2 = mldenote (ml1 ++ ml2 ).
induction ml1 ; crush.
Qed.

Theorem AEatten correct : 8 me, mdenote me = mldenote (AEatten me).

Hint Resolve AEatten correct'.

induction me; crush.
Qed.

Now it is easy to prove a theorem that will be the main tool behind our simplio/cation
tactic.

Theorem monoid reAEect : 8 me1 me2,

mldenote (AEatten me1 ) = mldenote (AEatten me2 )!

mdenote me1 = mdenote me2.
intros; repeat rewrite AEatten correct; assumption.
Qed.

We implement reAEection into the mexp type.
Ltac reAEect me :=

match me with|

e ) Ident|
?me1 + ?me2 )

let r1 := reAEect me1 in
let r2 := reAEect me2 in

constr :(Op r1 r2 )| )

constr :(Var me)
end.

The o/nal monoid tactic works on goals that equate two monoid terms. We reAEect each
and change the goal to refer to the reAEected versions, o/nishing ooe by applying monoid reAEect
and simplifying uses of mldenote.

Ltac monoid :=

match goal with

243

| [ ` ?me1 = ?me2 ] )

let r1 := reAEect me1 in
let r2 := reAEect me2 in

change (mdenote r1 = mdenote r2 );

apply monoid reAEect; simpl mldenote
end.

We can make short work of theorems like this one:

Theorem t1 : 8 a b c d, a + b + c + d = a + (b + c) + d.

intros; monoid.

============================

a + (b + (c + (d + e))) = a + (b + (c + (d + e)))

monoid has canonicalized both sides of the equality, such that we can o/nish the proof by
reAEexivity.

reflexivity.
Qed.

It is interesting to look at the form of the proof.
Print t1.
t1 =
fun a b c d : A )
monoid reAEect (Op (Op (Op (Var a) (Var b)) (Var c)) (Var d ))

(Op (Op (Var a) (Op (Var b) (Var c))) (Var d ))
(reAE equal (a + (b + (c + (d + e)))))

: 8 a b c d : A, a + b + c + d = a + (b + c) + d

The proof term contains only restatements of the equality operands in reAEected form,
followed by a use of reAEexivity on the shared canonical form.

End monoid.

Extensions of this basic approach are used in the implementations of the ring and o/eld
tactics that come packaged with Coq.

13.4 A Smarter Tautology Solver
Now we are ready to revisit our earlier tautology solver example. We want to broaden the
scope of the tactic to include formulas whose truth is not syntactically apparent. We will
want to allow injection of arbitrary formulas, like we allowed arbitrary monoid expressions
in the last example. Since we are working in a richer theory, it is important to be able to
use equalities between dioeerent injected formulas. For instance, we cannot prove P ! P by

244

translating the formula into a value like Imp (Var P ) (Var P ), because a Gallina function has
no way of comparing the two P s for equality.

To arrive at a nice implementation satisfying these criteria, we introduce the quote tactic
and its associated library.

Require Import Quote.
Inductive formula : Set :=|

Atomic : index ! formula|
Truth : formula|
Falsehood : formula|
And : formula ! formula ! formula|
Or : formula ! formula ! formula|
Imp : formula ! formula ! formula.

The type index comes from the Quote library and represents a countable variable type.
The rest of formula's deo/nition should be old hat by now.

The quote tactic will implement injection from Prop into formula for us, but it is not
quite as smart as we might like. In particular, it interprets implications incorrectly, so we
will need to declare a wrapper deo/nition for implication, as we did in the last chapter.

Definition imp (P1 P2 : Prop) := P1 ! P2.
Infix "*?" := imp (no associativity, at level 95).

Now we can deo/ne our denotation function.
Definition asgn := varmap Prop.
Fixpoint formulaDenote (atomics : asgn) (f : formula) : Prop :=

match f with|

Atomic v ) varmap o/nd False v atomics|
Truth ) True|
Falsehood ) False|
And f1 f2 ) formulaDenote atomics f1 ^ formulaDenote atomics f2|
Or f1 f2 ) formulaDenote atomics f1 . formulaDenote atomics f2|
Imp f1 f2 ) formulaDenote atomics f1 *? formulaDenote atomics f2
end.

The varmap type family implements maps from index values. In this case, we deo/ne
an assignment as a map from variables to Props. formulaDenote works with an assignment,
and we use the varmap o/nd function to consult the assignment in the Atomic case. The o/rst
argument to varmap o/nd is a default value, in case the variable is not found.

Section my tauto.

Variable atomics : asgn.

Definition holds (v : index) := varmap o/nd False v atomics.

We deo/ne some shorthand for a particular variable being true, and now we are ready to
deo/ne some helpful functions based on the ListSet module of the standard library, which
(unsurprisingly) presents a view of lists as sets.

245

Require Import ListSet.
Definition index eq : 8 x y : index, -x = y"" + -x 6= y"".

decide equality.
Defined.

Definition add (s : set index) (v : index) := set add index eq v s.
Definition In dec : 8 v (s : set index), -In v s"" + -~ In v s"".

Local Open Scope specif scope.

intro; refine (o/x F (s : set index) : -In v s"" + -~ In v s"" :=

match s with|

nil ) No|
v' :: s' ) index eq v' v ---- F s'
end); crush.
Defined.

We deo/ne what it means for all members of an index set to represent true propositions,
and we prove some lemmas about this notion.

Fixpoint allTrue (s : set index) : Prop :=

match s with|

nil ) True|
v :: s' ) holds v ^ allTrue s'
end.

Theorem allTrue add : 8 v s,

allTrue s!

holds v!
allTrue (add s v ).
induction s; crush;

match goal with|

[ ` context [if ?E then else ] ] ) destruct E
end; crush.
Qed.

Theorem allTrue In : 8 v s,

allTrue s!

set In v s!
varmap o/nd False v atomics.
induction s; crush.
Qed.

Hint Resolve allTrue add allTrue In.
Local Open Scope partial scope.

Now we can write a function forward which implements deconstruction of hypotheses. It
has a dependent type, in the style of Chapter 6, guaranteeing correctness. The arguments

246

to forward are a goal formula f, a set known of atomic formulas that we may assume are
true, a hypothesis formula hyp, and a success continuation cont that we call when we have
extended known to hold new truths implied by hyp.

Definition forward (f : formula) (known : set index) (hyp : formula)

(cont : 8 known', [allTrue known' ! formulaDenote atomics f ])
: [allTrue known ! formulaDenote atomics hyp ! formulaDenote atomics f ].
refine (o/x F (f : formula) (known : set index) (hyp : formula)

(cont : 8 known', [allTrue known' ! formulaDenote atomics f ])
: [allTrue known ! formulaDenote atomics hyp ! formulaDenote atomics f ] :=
match hyp with|

Atomic v ) Reduce (cont (add known v ))|
Truth ) Reduce (cont known)|
Falsehood ) Yes|
And h1 h2 )

Reduce (F (Imp h2 f ) known h1 (fun known' )

Reduce (F f known' h2 cont )))|
Or h1 h2 ) F f known h1 cont && F f known h2 cont|
Imp ) Reduce (cont known)
end); crush.
Defined.

A backward function implements analysis of the o/nal goal. It calls forward to handle
implications.

Definition backward (known : set index) (f : formula)

: [allTrue known ! formulaDenote atomics f ].
refine (o/x F (known : set index) (f : formula)

: [allTrue known ! formulaDenote atomics f ] :=
match f with|

Atomic v ) Reduce (In dec v known)|
Truth ) Yes|
Falsehood ) No|
And f1 f2 ) F known f1 && F known f2|
Or f1 f2 ) F known f1 ---- F known f2|
Imp f1 f2 ) forward f2 known f1 (fun known' ) F known' f2 )
end); crush; eauto.
Defined.

A simple wrapper around backward gives us the usual type of a partial decision procedure.
Definition my tauto (f : formula) : [formulaDenote atomics f ].

intro; refine (Reduce (backward nil f )); crush.
Defined.
End my tauto.

Our o/nal tactic implementation is now fairly straightforward. First, we intro all quanti-

247

o/ers that do not bind Props. Then we call the quote tactic, which implements the reAEection
for us. Finally, we are able to construct an exact proof via partialOut and the my tauto
Gallina function.

Ltac my tauto :=

repeat match goal with|

[ ` 8 x : ?P, ] )

match type of P with|

Prop ) fail 1| )

intro
end
end;
quote formulaDenote;
match goal with|

[ ` formulaDenote ?m ?f ] ) exact (partialOut (my tauto m f ))
end.

A few examples demonstrate how the tactic works.
Theorem mt1 : True.

my tauto.
Qed.

Print mt1.
mt1 = partialOut (my tauto (Empty vm Prop) Truth)

: True

We see my tauto applied with an empty varmap, since every subformula is handled by
formulaDenote.

Theorem mt2 : 8 x y : nat, x = y *? x = y.

my tauto.
Qed.

Print mt2.
mt2 =
fun x y : nat )
partialOut

(my tauto (Node vm (x = y) (Empty vm Prop) (Empty vm Prop))

(Imp (Atomic End idx ) (Atomic End idx )))
: 8 x y : nat, x = y *? x = y

Crucially, both instances of x = y are represented with the same index, End idx. The
value of this index only needs to appear once in the varmap, whose form reveals that
varmaps are represented as binary trees, where index values denote paths from tree roots
to leaves.

248

Theorem mt3 : 8 x y z,

(x ! y ^ y ? z ) . (y ? z ^ x ! S y)
*? y ? z ^ (x ! y . x ! S y).
my tauto.
Qed.

Print mt3.
fun x y z : nat )
partialOut

(my tauto

(Node vm (x ! S y ) (Node vm (x ! y) (Empty vm Prop) (Empty vm Prop))

(Node vm (y ? z ) (Empty vm Prop) (Empty vm Prop)))
(Imp

(Or (And (Atomic (Left idx End idx )) (Atomic (Right idx End idx )))

(And (Atomic (Right idx End idx )) (Atomic End idx )))
(And (Atomic (Right idx End idx ))

(Or (Atomic (Left idx End idx )) (Atomic End idx )))))
: 8 x y z : nat,

x ! y ^ y ? z . y ? z ^ x ! S y *? y ? z ^ (x ! y . x ! S y)

Our goal contained three distinct atomic formulas, and we see that a three-element
varmap is generated.

It can be interesting to observe dioeerences between the level of repetition in proof terms
generated by my tauto and tauto for especially trivial theorems.

Theorem mt4 : True ^ True ^ True ^ True ^ True ^ True ^ False *? False.

my tauto.
Qed.

Print mt4.
mt4 =
partialOut

(my tauto (Empty vm Prop)

(Imp

(And Truth

(And Truth

(And Truth (And Truth (And Truth (And Truth Falsehood))))))
Falsehood))
: True ^ True ^ True ^ True ^ True ^ True ^ False *? False

Theorem mt4' : True ^ True ^ True ^ True ^ True ^ True ^ False ! False.

tauto.
Qed.

Print mt4'.

249

mt4' =
fun H : True ^ True ^ True ^ True ^ True ^ True ^ False )
and ind

(fun ( : True) (H1 : True ^ True ^ True ^ True ^ True ^ False) )

and ind

(fun ( : True) (H3 : True ^ True ^ True ^ True ^ False) )

and ind

(fun ( : True) (H5 : True ^ True ^ True ^ False) )

and ind

(fun ( : True) (H7 : True ^ True ^ False) )

and ind

(fun ( : True) (H9 : True ^ False) )

and ind (fun ( : True) (H11 : False) ) False ind False H11 )

H9 ) H7 ) H5 ) H3 ) H1 ) H
: True ^ True ^ True ^ True ^ True ^ True ^ False ! False

13.5 Exercises

1. Implement a reAEective procedure for normalizing systems of linear equations over ra-

tional numbers. In particular, the tactic should identify all hypotheses that are linear
equations over rationals where the equation righthand sides are constants. It should
normalize each hypothesis to have a lefthand side that is a sum of products of constants
and variables, with no variable appearing multiple times. Then, your tactic should add
together all of these equations to form a single new equation, possibly clearing the orig-
inal equations. Some coeOEcients may cancel in the addition, reducing the number of
variables that appear.

To work with rational numbers, import module QArith and use Local Open Scope
Q scope. All of the usual arithmetic operator notations will then work with rationals,
and there are shorthands for constants 0 and 1. Other rationals must be written as
num # den for numerator num and denominator den. Use the ino/x operator == in
place of =, to deal with dioeerent ways of expressing the same number as a fraction.
For instance, a theorem and proof like this one should work with your tactic:

Theorem t2 : 8 x y z , (2 # 1) * (x - (3 # 2) * y) == 15 # 1!

z + (8 # 1) * x == 20 # 1!
(-6 # 2) * y + (10 # 1) * x + z == 35 # 1.
intros; reAEectContext ; assumption.
Qed.

Your solution can work in any way that involves reAEecting syntax and doing most
calculation with a Gallina function. These hints outline a particular possible solution.

250

Throughout, the ring tactic will be helpful for proving many simple facts about ratio-
nals, and tactics like rewrite are correctly overloaded to work with rational equality
==.

(a) Deo/ne an inductive type exp of expressions over rationals (which inhabit the Coq

type Q). Include variables (represented as natural numbers), constants, addition,
subtraction, and multiplication.

(b) Deo/ne a function lookup for reading an element out of a list of rationals, by its

position in the list.

(c) Deo/ne a function expDenote that translates exps, along with lists of rationals

representing variable values, to Q .

(d) Deo/ne a recursive function eqsDenote over list (exp * Q ), characterizing when all

of the equations are true.

(e) Fix a representation lhs of AEattened expressions. Where len is the number of

variables, represent a AEattened equation as ilist Q len. Each position of the list
gives the coeOEcient of the corresponding variable.

(f) Write a recursive function linearize that takes a constant k and an expression e

and optionally returns an lhs equivalent to k * e. This function returns None
when it discovers that the input expression is not linear. The parameter len of
lhs should be a parameter of linearize, too. The functions singleton, everywhere,
and map2 from DepList will probably be helpful. It is also helpful to know that
Qplus is the identio/er for rational addition.

(g) Write a recursive function linearizeEqs : list (exp * Q ) ! option (lhs * Q ). This

function linearizes all of the equations in the list in turn, building up the sum
of the equations. It returns None if the linearization of any constituent equation
fails.

(h) Deo/ne a denotation function for lhs.

(i) Prove that, when exp linearization succeeds on constant k and expression e, the

linearized version has the same meaning as k * e.

(j) Prove that, when linearizeEqs succeeds on an equation list eqs, then the o/nal

summed-up equation is true whenever the original equation list is true.

(k) Write a tactic o/ndVarsHyps to search through all equalities on rationals in the

context, recursing through addition, subtraction, and multiplication to o/nd the
list of expressions that should be treated as variables. This list should be suitable
as an argument to expDenote and eqsDenote, associating a Q value to each natural
number that stands for a variable.

(l) Write a tactic reAEect to reAEect a Q expression into exp, with respect to a given

list of variable values.

(m) Write a tactic reAEectEqs to reAEect a formula that begins with a sequence of impli-

cations from linear equalities whose lefthand sides are expressed with expDenote.

251

This tactic should build a list (exp * Q ) representing the equations. Remember
to give an explicit type annotation when returning a nil list, as in constr :(@nil
(exp * Q )).

(n) Now this o/nal tactic should do the job:

Ltac reAEectContext :=

let ls := o/ndVarsHyps in

repeat match goal with|

[ H : ?e == ?num # ?den ` ] )

let r := reAEect ls e in

change (expDenote ls r == num # den) in H ;
generalize H
end;
match goal with|

[ ` ?g ] ) let re := reAEectEqs g in

intros;

let H := fresh "H" in
assert (H : eqsDenote ls re); [ simpl in *; tauto|

repeat match goal with|

[ H : expDenote == ` ] ) clear H
end;
generalize (linearizeEqsCorrect ls re H ); clear H ; simpl;

match goal with|

[ ` ?X == ?Y ! ] )

ring simplify X Y ; intro
end ]
end.

252

Chapter 14
Proving in the Large

It is somewhat unfortunate that the term "theorem-proving" looks so much like the word
"theory." Most researchers and practitioners in software assume that mechanized theorem-
proving is profoundly impractical. Indeed, until recently, most advances in theorem-proving
for higher-order logics have been largely theoretical. However, starting around the beginning
of the 21st century, there was a surge in the use of proof assistants in serious verio/cation
eoeorts. That line of work is still quite new, but I believe it is not too soon to distill some
lessons on how to work eoeectively with large formal proofs.

Thus, this chapter gives some tips for structuring and maintaining large Coq develop-
ments.

14.1 Ltac Anti-Patterns
In this book, I have been following an unusual style, where proofs are not considered o/nished
until they are "fully automated," in a certain sense. SEach such theorem is proved by a single
tactic. Since Ltac is a Turing-complete programming language, it is not hard to squeeze
arbitrary heuristics into single tactics, using operators like the semicolon to combine steps.
In contrast, most Ltac proofs "in the wild" consist of many steps, performed by individual
tactics followed by periods. Is it really worth drawing a distinction between proof steps
terminated by semicolons and steps terminated by periods?

I argue that this is, in fact, a very important distinction, with serious consequences for
a majority of important verio/cation domains. The more uninteresting drudge work a proof
domain involves, the more important it is to work to prove theorems with single tactics. From
an automation standpoint, single-tactic proofs can be extremely eoeective, and automation
becomes more and more critical as proofs are populated by more uninteresting detail. In
this section, I will give some examples of the consequences of more common proof styles.

As a running example, consider a basic language of arithmetic expressions, an interpreter
for it, and a transformation that scales up every constant in an expression.

Inductive exp : Set :=

253

| Const : nat ! exp|

Plus : exp ! exp ! exp.

Fixpoint eval (e : exp) : nat :=

match e with|

Const n ) n|
Plus e1 e2 ) eval e1 + eval e2
end.

Fixpoint times (k : nat) (e : exp) : exp :=

match e with|

Const n ) Const (k * n)|
Plus e1 e2 ) Plus (times k e1 ) (times k e2 )
end.

We can write a very manual proof that double really doubles an expression's value.
Theorem eval times : 8 k e,

eval (times k e) = k * eval e.
induction e.

trivial.
simpl.
rewrite IHe1.
rewrite IHe2.
rewrite mult plus distr l.
trivial.
Qed.

We use spaces to separate the two inductive cases. The second case mentions automatically-
generated hypothesis names explicitly. As a result, innocuous changes to the theorem state-
ment can invalidate the proof.

Reset eval times.
Theorem eval double : 8 k x,

eval (times k x ) = k * eval x.
induction x.

trivial.
simpl.

rewrite IHe1.
Error : The reference IHe1 was not found in the current environment.

The inductive hypotheses are named IHx1 and IHx2 now, not IHe1 and IHe2.
Abort.

254

We might decide to use a more explicit invocation of induction to give explicit binders
for all of the names that we will reference later in the proof.

Theorem eval times : 8 k e,

eval (times k e) = k * eval e.
induction e as [ | ? IHe1 ? IHe2 ].

trivial.
simpl.
rewrite IHe1.
rewrite IHe2.
rewrite mult plus distr l.
trivial.
Qed.

We pass induction an intro pattern, using a | character to separate out instructions for
the dioeerent inductive cases. Within a case, we write ? to ask Coq to generate a name
automatically, and we write an explicit name to assign that name to the corresponding
new variable. It is apparent that, to use intro patterns to avoid proof brittleness, one
needs to keep track of the seemingly unimportant facts of the orders in which variables are
introduced. Thus, the script keeps working if we replace e by x , but it has become more
cluttered. Arguably, neither proof is particularly easy to follow.

That category of complaint has to do with understanding proofs as static artifacts. As
with programming in general, with serious projects, it tends to be much more important
to be able to support evolution of proofs as specio/cations change. Unstructured proofs like
the above examples can be very hard to update in concert with theorem statements. For
instance, consider how the last proof script plays out when we modify times to introduce a
bug.

Reset times.
Fixpoint times (k : nat) (e : exp) : exp :=

match e with|

Const n ) Const (1 + k * n)|
Plus e1 e2 ) Plus (times k e1 ) (times k e2 )
end.

Theorem eval times : 8 k e,

eval (times k e) = k * eval e.
induction e as [ | ? IHe1 ? IHe2 ].

trivial.
simpl.

rewrite IHe1.
Error : The reference IHe1 was not found in the current environment.

255

Abort.

Can you spot what went wrong, without stepping through the script step-by-step? The
problem is that trivial never fails. Originally, trivial had been succeeding in proving an
equality that follows by reAEexivity. Our change to times leads to a case where that equality
is no longer true. trivial happily leaves the false equality in place, and we continue on to
the span of tactics intended for the second inductive case. Unfortunately, those tactics end
up being applied to the o/rst case instead.

The problem with trivial could be "solved" by writing solve [trivial] instead, so that
an error is signaled early on if something unexpected happens. However, the root problem
is that the syntax of a tactic invocation does not imply how many subgoals it produces.
Much more confusing instances of this problem are possible. For example, if a lemma L is
modio/ed to take an extra hypothesis, then uses of apply L will general more subgoals than
before. Old unstructured proof scripts will become hopelessly jumbled, with tactics applied
to inappropriate subgoals. Because of the lack of structure, there is usually relatively little
to be gleaned from knowledge of the precise point in a proof script where an error is raised.

Reset times.
Fixpoint times (k : nat) (e : exp) : exp :=

match e with|

Const n ) Const (k * n)|
Plus e1 e2 ) Plus (times k e1 ) (times k e2 )
end.

Many real developments try to make essentially unstructured proofs look structured by
applying careful indentation conventions, idempotent case-marker tactics included soley to
serve as documentation, and so on. All of these strategies suoeer from the same kind of failure
of abstraction that was just demonstrated. I like to say that if you o/nd yourself caring about
indentation in a proof script, it is a sign that the script is structured poorly.

We can rewrite the current proof with a single tactic.

Theorem eval times : 8 k e,

eval (times k e) = k * eval e.
induction e as [ | ? IHe1 ? IHe2 ]; [

trivial|

simpl; rewrite IHe1 ; rewrite IHe2 ; rewrite mult plus distr l; trivial ].
Qed.

This is an improvement in robustness of the script. We no longer need to worry about
tactics from one case being applied to a dioeerent case. Still, the proof script is not especially
readable. Probably most readers would not o/nd it helpful in explaining why the theorem is
true.

The situation gets worse in considering extensions to the theorem we want to prove. Let
us add multiplication nodes to our exp type and see how the proof fares.

Reset exp.

256

Inductive exp : Set :=|

Const : nat ! exp|
Plus : exp ! exp ! exp|
Mult : exp ! exp ! exp.

Fixpoint eval (e : exp) : nat :=

match e with|

Const n ) n|
Plus e1 e2 ) eval e1 + eval e2|
Mult e1 e2 ) eval e1 * eval e2
end.

Fixpoint times (k : nat) (e : exp) : exp :=

match e with|

Const n ) Const (k * n)|
Plus e1 e2 ) Plus (times k e1 ) (times k e2 )|
Mult e1 e2 ) Mult (times k e1 ) e2
end.

Theorem eval times : 8 k e,

eval (times k e) = k * eval e.

induction e as [ | ? IHe1 ? IHe2 ]; [

trivial|

simpl; rewrite IHe1 ; rewrite IHe2 ; rewrite mult plus distr l; trivial ].

Error : Expects a disjunctive pattern with 3 branches.

Abort.

Unsurprisingly, the old proof fails, because it explicitly says that there are two inductive
cases. To update the script, we must, at a minimum, remember the order in which the
inductive cases are generated, so that we can insert the new case in the appropriate place.
Even then, it will be painful to add the case, because we cannot walk through proof steps
interactively when they occur inside an explicit set of cases.

Theorem eval times : 8 k e,

eval (times k e) = k * eval e.
induction e as [ | ? IHe1 ? IHe2 | ? IHe1 ? IHe2 ]; [

trivial|

simpl; rewrite IHe1 ; rewrite IHe2 ; rewrite mult plus distr l; trivial|
simpl; rewrite IHe1 ; rewrite mult assoc; trivial ].
Qed.

Now we are in a position to see how much nicer is the style of proof that we have followed
in most of this book.

Reset eval times.

257

Hint Rewrite mult plus distr l : cpdt.
Theorem eval times : 8 k e,

eval (times k e) = k * eval e.
induction e; crush.
Qed.

This style is motivated by a hard truth: one person's manual proof script is almost always
mostly inscrutable to most everyone else. I claim that step-by-step formal proofs are a poor
way of conveying information. Thus, we had might as well cut out the steps and automate
as much as possible.

What about the illustrative value of proofs? Most informal proofs are read to convey the
big ideas of proofs. How can reading induction e; crush convey any big ideas? My position
is that any ideas that standard automation can o/nd are not very big after all, and the real
big ideas should be expressed through lemmas that are added as hints.

An example should help illustrate what I mean. Consider this function, which rewrites
an expression using associativity of addition and multiplication.

Fixpoint reassoc (e : exp) : exp :=

match e with|

Const ) e|
Plus e1 e2 )

let e1' := reassoc e1 in
let e2' := reassoc e2 in

match e2' with|

Plus e21 e22 ) Plus (Plus e1' e21 ) e22| )

Plus e1' e2'
end|
Mult e1 e2 )

let e1' := reassoc e1 in
let e2' := reassoc e2 in

match e2' with|

Mult e21 e22 ) Mult (Mult e1' e21 ) e22| )

Mult e1' e2'
end
end.

Theorem reassoc correct : 8 e, eval (reassoc e) = eval e.

induction e; crush;

match goal with|

[ ` context [match ?E with Const ) | Plus ) | Mult ) end] ] )

destruct E ; crush
end.

One subgoal remains:
IHe2 : eval e3 * eval e4 = eval e2

258

============================

eval e1 * eval e3 * eval e4 = eval e1 * eval e2

crush does not know how to o/nish this goal. We could o/nish the proof manually.
rewrite  IHe2 ; crush.

However, the proof would be easier to understand and maintain if we separated this
insight into a separate lemma.

Abort.
Lemma rewr : 8 a b c d, b * c = d ! a * b * c = a * d.

crush.
Qed.

Hint Resolve rewr.
Theorem reassoc correct : 8 e, eval (reassoc e) = eval e.

induction e; crush;

match goal with|

[ ` context [match ?E with Const ) | Plus ) | Mult ) end] ] )

destruct E ; crush
end.
Qed.

In the limit, a complicated inductive proof might rely on one hint for each inductive
case. The lemma for each hint could restate the associated case. Compared to manual proof
scripts, we arrive at more readable results. Scripts no longer need to depend on the order in
which cases are generated. The lemmas are easier to digest separately than are fragments
of tactic code, since lemma statements include complete proof contexts. Such contexts can
only be extracted from monolithic manual proofs by stepping through scripts interactively.

The more common situation is that a large induction has several easy cases that au-
tomation makes short work of. In the remaining cases, automation performs some standard
simplio/cation. Among these cases, some may require quite involved proofs; such a case may
deserve a hint lemma of its own, where the lemma statement may copy the simplio/ed version
of the case. Alternatively, the proof script for the main theorem may be extended with some
automation code targeted at the specio/c case. Even such targeted scripting is more desirable
than manual proving, because it may be read and understood without knowledge of a proof's
hierarchical structure, case ordering, or name binding structure.

14.2 Debugging and Maintaining Automation
Fully-automated proofs are desirable because they open up possibilities for automatic adap-
tation to changes of specio/cation. A well-engineered script within a narrow domain can
survive many changes to the formulation of the problem it solves. Still, as we are work-

259

ing with higher-order logic, most theorems fall within no obvious decidable theories. It is
inevitable that most long-lived automated proofs will need updating.

Before we are ready to update our proofs, we need to write them in the o/rst place. While
fully-automated scripts are most robust to changes of specio/cation, it is hard to write every
new proof directly in that form. Instead, it is useful to begin a theorem with exploratory
proving and then gradually reo/ne it into a suitable automated form.

Consider this theorem from Chapter 7, which we begin by proving in a mostly manual
way, invoking crush after each steop to discharge any low-hanging fruit. Our manual eoeort
involves choosing which expressions to case-analyze on.

Theorem cfold correct : 8 t (e : exp t ), expDenote e = expDenote (cfold e).

induction e; crush.

dep destruct (cfold e1 ); crush.
dep destruct (cfold e2 ); crush.

dep destruct (cfold e1 ); crush.
dep destruct (cfold e2 ); crush.

dep destruct (cfold e1 ); crush.
dep destruct (cfold e2 ); crush.

dep destruct (cfold e1 ); crush.
dep destruct (expDenote e1 ); crush.

dep destruct (cfold e); crush.
dep destruct (cfold e); crush.
Qed.

In this complete proof, it is hard to avoid noticing a pattern. We rework the proof,
abstracting over the patterns we o/nd.

Reset cfold correct.
Theorem cfold correct : 8 t (e : exp t ), expDenote e = expDenote (cfold e).

induction e; crush.

The expression we want to destruct here turns out to be the discriminee of a match, and
we can easily enough write a tactic that destructs all such expressions.

Ltac t :=

repeat (match goal with|

[ ` context [match ?E with NConst ) | Plus )|

Eq ) | BConst ) | And )|
If ) | Pair )|
Fst ) | Snd ) end] ] )
dep destruct E
end; crush).

t.

260

This tactic invocation discharges the whole case. It does the same on the next two cases,
but it gets stuck on the fourth case.

t.
t.
t.

The subgoal's conclusion is:

============================
(if expDenote e1 then expDenote (cfold e2 ) else expDenote (cfold e3 )) =
expDenote (if expDenote e1 then cfold e2 else cfold e3 )

We need to expand our t tactic to handle this case.
Ltac t' :=

repeat (match goal with|

[ ` context [match ?E with NConst ) | Plus )|

Eq ) | BConst ) | And )|
If ) | Pair )|
Fst ) | Snd ) end] ] )
dep destruct E|
[ ` (if ?E then else ) = ] ) destruct E
end; crush).

t'.

Now the goal is discharged, but t' has no eoeect on the next subgoal.
t'.

A o/nal revision of t o/nishes the proof.
Ltac tj :=

repeat (match goal with|

[ ` context [match ?E with NConst ) | Plus )|

Eq ) | BConst ) | And )|
If ) | Pair )|
Fst ) | Snd ) end] ] )
dep destruct E|
[ ` (if ?E then else ) = ] ) destruct E|
[ ` context [match pairOut ?E with Some )|

None ) end] ] )
dep destruct E
end; crush).

tj.
tj.
Qed.

261

We can take the o/nal tactic and move it into the initial part of the proof script, arriving
at a nicely-automated proof.

Reset t.
Theorem cfold correct : 8 t (e : exp t ), expDenote e = expDenote (cfold e).

induction e; crush;

repeat (match goal with|

[ ` context [match ?E with NConst ) | Plus )|

Eq ) | BConst ) | And )|
If ) | Pair )|
Fst ) | Snd ) end] ] )
dep destruct E|
[ ` (if ?E then else ) = ] ) destruct E|
[ ` context [match pairOut ?E with Some )|

None ) end] ] )
dep destruct E
end; crush).
Qed.

Even after we put together nice automated proofs, we must deal with specio/cation changes
that can invalidate them. It is not generally possible to step through single-tactic proofs
interactively. There is a command Debug On that lets us step through points in tactic
execution, but the debugger tends to make counterintuitive choices of which points we would
like to stop at, and per-point output is quite verbose, so most Coq users do not o/nd this
debugging mode very helpful. How are we to understand what has broken in a script that
used to work?

An example helps demonstrate a useful approach. Consider what would have happened
in our proof of reassoc correct if we had o/rst added an unfortunate rewriting hint.

Reset reassoc correct.
Theorem confounder : 8 e1 e2 e3,

eval e1 * eval e2 * eval e3 = eval e1 * (eval e2 + 1 - 1) * eval e3.
crush.
Qed.

Hint Rewrite confounder : cpdt.
Theorem reassoc correct : 8 e, eval (reassoc e) = eval e.

induction e; crush;

match goal with|

[ ` context [match ?E with Const ) | Plus ) | Mult ) end] ] )

destruct E ; crush
end.

One subgoal remains:

262

============================

eval e1 * (eval e3 + 1 - 1) * eval e4 = eval e1 * eval e2

The poorly-chosen rewrite rule o/red, changing the goal to a form where another hint no
longer applies. Imagine that we are in the middle of a large development with many hints.
How would we diagnose the problem? First, we might not be sure which case of the inductive
proof has gone wrong. It is useful to separate out our automation procedure and apply it
manually.

Restart.
Ltac t := crush; match goal with|

[ ` context [match ?E with Const ) | Plus )|

Mult ) end] ] )
destruct E ; crush
end.

induction e.

Since we see the subgoals before any simplio/cation occurs, it is clear that this is the case
for constants. t makes short work of it.

t.

The next subgoal, for addition, is also discharged without trouble.
t.

The o/nal subgoal is for multiplication, and it is here that we get stuck in the proof state
summarized above.

t.

What is t doing to get us to this point? The info command can help us answer this kind
of question.

Undo.
info t.

== simpl in *; intuition; subst; autorewrite with cpdt in *;

simpl in *; intuition; subst; autorewrite with cpdt in *;
simpl in *; intuition; subst; destruct (reassoc e2 ).
simpl in *; intuition.

simpl in *; intuition.
simpl in *; intuition; subst; autorewrite with cpdt in *;

refine (eq ind r

(fun n : nat )

n * (eval e3 + 1 - 1) * eval e4 = eval e1 * eval e2 ) IHe1 );

263

autorewrite with cpdt in *; simpl in *; intuition;
subst; autorewrite with cpdt in *; simpl in *;
intuition; subst.

A detailed trace of t 's execution appears. Since we are using the very general crush tactic,
many of these steps have no eoeect and only occur as instances of a more general strategy.
We can copy-and-paste the details to see where things go wrong.

Undo.

We arbitrarily split the script into chunks. The o/rst few seem not to do any harm.
simpl in *; intuition; subst; autorewrite with cpdt in *.
simpl in *; intuition; subst; autorewrite with cpdt in *.
simpl in *; intuition; subst; destruct (reassoc e2 ).
simpl in *; intuition.
simpl in *; intuition.

The next step is revealed as the culprit, bringing us to the o/nal unproved subgoal.
simpl in *; intuition; subst; autorewrite with cpdt in *.

We can split the steps further to assign blame.
Undo.
simpl in *.
intuition.
subst.
autorewrite with cpdt in *.

It was the o/nal of these four tactics that made the rewrite. We can o/nd out exactly what
happened. The info command presents hierarchical views of proof steps, and we can zoom
down to a lower level of detail by applying info to one of the steps that appeared in the
original trace.

Undo.
info autorewrite with cpdt in *.

== refine (eq ind r (fun n : nat ) n = eval e1 * eval e2 )

(confounder (reassoc e1 ) e3 e4 )).

The way a rewrite is displayed is somewhat baroque, but we can see that theorem con-
founder is the o/nal culprit. At this point, we could remove that hint, prove an alternate
version of the key lemma rewr, or come up with some other remedy. Fixing this kind of
problem tends to be relatively easy once the problem is revealed.

Abort.

Sometimes a change to a development has undesirable performance consequences, even if

264

it does not prevent any old proof scripts from completing. If the performance consequences
are severe enough, the proof scripts can be considered broken for practical purposes.

Here is one example of a performance surprise.

Section slow.

Hint Resolve trans eq.

The central element of the problem is the addition of transitivity as a hint. With tran-
sitivity available, it is easy for proof search to wind up exploring exponential search spaces.
We also add a few other arbitrary variables and hypotheses, designed to lead to trouble
later.

Variable A : Set.
Variables P Q R S : A ! A ! Prop.
Variable f : A ! A.

Hypothesis H1 : 8 x y, P x y ! Q x y ! R x y ! f x = f y.
Hypothesis H2 : 8 x y, S x y ! R x y.

We prove a simple lemma very quickly, using the Time command to measure exactly how
quickly.

Lemma slow : 8 x y, P x y ! Q x y ! S x y ! f x = f y.

Time eauto 6.

Finished transaction in 0. secs (0.068004u,0.s)

Qed.

Now we add a dioeerent hypothesis, which is innocent enough; in fact, it is even provable
as a theorem.

Hypothesis H3 : 8 x y, x = y ! f x = f y.
Lemma slow' : 8 x y, P x y ! Q x y ! S x y ! f x = f y.

Time eauto 6.

Finished transaction in 2. secs (1.264079u,0.s)

Why has the search time gone up so much? The info command is not much help, since
it only shows the result of search, not all of the paths that turned out to be worthless.

Restart.
info eauto 6.

== intro x ; intro y ; intro H ; intro H0 ; intro H4 ;

simple eapply trans eq.
simple apply reAE equal.

simple eapply trans eq.

265

simple apply reAE equal.
simple eapply trans eq.
simple apply reAE equal.

simple apply H1 .
eexact H.

eexact H0.
simple apply H2 ; eexact H4 .
This output does not tell us why proof search takes so long, but it does provide a clue that
would be useful if we had forgotten that we added transitivity as a hint. The eauto tactic
is applying depth-o/rst search, and the proof script where the real action is ends up buried
inside a chain of pointless invocations of transitivity, where each invocation uses reAEexivity
to discharge one subgoal. Each increment to the depth argument to eauto adds another
silly use of transitivity. This wasted proof eoeort only adds linear time overhead, as long as
proof search never makes false steps. No false steps were made before we added the new
hypothesis, but somehow the addition made possible a new faulty path. To understand
which paths we enabled, we can use the debug command.

Restart.
debug eauto 6.

The output is a large proof tree. The beginning of the tree is enough to reveal what is
happening:

1 depth=6
1.1 depth=6 intro
1.1.1 depth=6 intro
1.1.1.1 depth=6 intro
1.1.1.1.1 depth=6 intro
1.1.1.1.1.1 depth=6 intro
1.1.1.1.1.1.1 depth=5 apply H3
1.1.1.1.1.1.1.1 depth=4 eapply trans eq
1.1.1.1.1.1.1.1.1 depth=4 apply reAE equal
1.1.1.1.1.1.1.1.1.1 depth=3 eapply trans eq
1.1.1.1.1.1.1.1.1.1.1 depth=3 apply reAE equal
1.1.1.1.1.1.1.1.1.1.1.1 depth=2 eapply trans eq
1.1.1.1.1.1.1.1.1.1.1.1.1 depth=2 apply reAE equal
1.1.1.1.1.1.1.1.1.1.1.1.1.1 depth=1 eapply trans eq
1.1.1.1.1.1.1.1.1.1.1.1.1.1.1 depth=1 apply reAE equal
1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1 depth=0 eapply trans eq

266

1.1.1.1.1.1.1.1.1.1.1.1.1.1.2 depth=1 apply sym eq ; trivial
1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1 depth=0 eapply trans eq
1.1.1.1.1.1.1.1.1.1.1.1.1.1.3 depth=0 eapply trans eq
1.1.1.1.1.1.1.1.1.1.1.1.2 depth=2 apply sym eq ; trivial
1.1.1.1.1.1.1.1.1.1.1.1.2.1 depth=1 eapply trans eq
1.1.1.1.1.1.1.1.1.1.1.1.2.1.1 depth=1 apply reAE equal
1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1 depth=0 eapply trans eq
1.1.1.1.1.1.1.1.1.1.1.1.2.1.2 depth=1 apply sym eq ; trivial
1.1.1.1.1.1.1.1.1.1.1.1.2.1.2.1 depth=0 eapply trans eq
1.1.1.1.1.1.1.1.1.1.1.1.2.1.3 depth=0 eapply trans eq

The o/rst choice eauto makes is to apply H3 , since H3 has the fewest hypotheses of
all of the hypotheses and hints that match. However, it turns out that the single hypoth-
esis generated is unprovable. That does not stop eauto from trying to prove it with an
exponentially-sized tree of applications of transitivity, reAEexivity, and symmetry of equality.
It is the children of the initial apply H3 that account for all of the noticeable time in proof
execution. In a more realistic development, we might use this output of info to realize that
adding transitivity as a hint was a bad idea.

Qed.
End slow.

It is also easy to end up with a proof script that uses too much memory. As tactics run,
they avoid generating proof terms, since serious proof search will consider many possible
avenues, and we do not want to built proof terms for subproofs that end up unused. Instead,
tactic execution maintains thunks (suspended computations, represented with closures), such
that a tactic's proof-producing thunk is only executed when we run Qed. These thunks can
use up large amounts of space, such that a proof script exhausts available memory, even
when we know that we could have used much less memory by forcing some thunks earlier.

The abstract tactical helps us force thunks by proving some subgoals as their own lemmas.
For instance, a proof induction x ; crush can in many cases be made to use signio/cantly less
peak memory by changing it to induction x ; abstract crush. The main limitation of abstract
is that it can only be applied to subgoals that are proved completely, with no undetermined
unio/cation variables remaining. Still, many large automated proofs can realize vast memory
savings via abstract.

14.3 Modules
Last chapter's examples of proof by reAEection demonstrate opportunities for implementing
abstract proof strategies with stronger formal guarantees than can be had with Ltac script-
ing. Coq's module system provides another tool for more rigorous development of generic
theorems. This feature is inspired by the module systems found in Standard ML and Ob-
jective Caml, and the discussion that follows assumes familiarity with the basics of one of

267

those systems.

ML modules facilitate the grouping of abstract types with operations over those types.
Moreover, there is support for functors, which are functions from modules to modules. A
canonical example of a functor is one that builds a data structure implementation from a
module that describes a domain of keys and its associated comparison operations.

When we add modules to a base language with dependent types, it becomes possible to
use modules and functors to formalize kinds of reasoning that are common in algebra. For
instance, this module signature captures the essence of the algebraic structure known as a
group. A group consists of a carrier set G, an associative binary operation f, a left identity
element e for f, and an operation i that is a left inverse for f.

Module Type GROUP.

Parameter G : Set.
Parameter f : G ! G ! G .
Parameter e : G .
Parameter i : G ! G .

Axiom assoc : 8 a b c, f (f a b) c = f a (f b c).
Axiom ident : 8 a, f e a = a.
Axiom inverse : 8 a, f (i a) a = e.
End GROUP.

Many useful theorems hold of arbitrary groups. We capture some such theorem state-
ments in another module signature.

Module Type GROUP THEOREMS.

Declare Module M : GROUP.

Axiom ident' : 8 a, M.f a M.e = a.
Axiom inverse' : 8 a, M.f a (M.i a) = M.e.
Axiom unique ident : 8 e', (8 a, M.f e' a = a) ! e' = M.e.
End GROUP THEOREMS.

We implement generic proofs of these theorems with a functor, whose input is an arbitrary
group M. The proofs are completely manual, since it would take some eoeort to build suitable
generic automation; rather, these theorems can serve as a basis for an automated procedure
for simplifying group expressions, along the lines of the procedure for monoids from the last
chapter. We take the proofs from the Wikipedia page on elementary group theory.

Module Group (M : GROUP) : GROUP THEOREMS with Module M := M.

Module M := M.

Import M.
Theorem inverse' : 8 a, f a (i a) = e.

intro.
rewrite  (ident (f a (i a))).
rewrite  (inverse (f a (i a))) at 1.

268

rewrite assoc.
rewrite assoc.
rewrite  (assoc (i a) a (i a)).
rewrite inverse.
rewrite ident.
apply inverse.
Qed.

Theorem ident' : 8 a, f a e = a.

intro.
rewrite  (inverse a).
rewrite  assoc.
rewrite inverse'.
apply ident.
Qed.

Theorem unique ident : 8 e', (8 a, M.f e' a = a) ! e' = M.e.

intros.
rewrite  (H e).
symmetry.
apply ident'.
Qed.
End Group.

We can show that the integers with + form a group.
Require Import ZArith.
Open Scope Z scope.

Module Int.

Definition G := Z.
Definition f x y := x + y.
Definition e := 0.
Definition i x := -x.

Theorem assoc : 8 a b c, f (f a b) c = f a (f b c).

unfold f ; crush.
Qed.
Theorem ident : 8 a, f e a = a.

unfold f, e; crush.
Qed.
Theorem inverse : 8 a, f (i a) a = e.

unfold f, i, e; crush.
Qed.
End Int.

Next, we can produce integer-specio/c versions of the generic group theorems.
Module IntTheorems := Group(Int).

269

Check IntTheorems.unique ident.

IntTheorems.unique ident

: 8 e' : Int.G, (8 a : Int.G, Int.f e' a = a) ! e' = Int.e

Theorem unique ident : 8 e', (8 a, e' + a = a) ! e' = 0.

exact IntTheorems.unique ident.
Qed.

As in ML, the module system provides an eoeective way to structure large developments.
Unlike in ML, Coq modules add no expressiveness; we can implement any module as an
inhabitant of a dependent record type. It is the second-class nature of modules that makes
them easier to use than dependent records in many case. Because modules may only be
used in quite restricted ways, it is easier to support convenient module coding through
special commands and editing modes, as the above example demonstrates. An isomorphic
implementation with records would have suoeered from lack of such conveniences as module
subtyping and importation of the o/elds of a module.

14.4 Build Processes
As in software development, large Coq projects are much more manageable when split across
multiple o/les and when decomposed into libraries. Coq and Proof General provide very good
support for these activities.

Consider a library that we will name Lib, housed in directory LIB and split between o/les
A.v, B.v, and C.v. A simple Makeo/le will compile the library, relying on the standard Coq
tool coq makefile to do the hard work.

MODULES := A B C
VS := $(MODULES:%=%.v)

.PHONY: coq clean
coq: Makefile.coq

make -f Makefile.coq

Makefile.coq: Makefile $(VS)

coq.makefile -R . Lib $(VS) -o Makefile.coq

clean:: Makefile.coq

make -f Makefile.coq clean
rm -f Makefile.coq

The Makeo/le begins by deo/ning a variable VS holding the list of o/lenames to be included
in the project. The primary target is coq, which depends on the construction of an auxil-
iary Makeo/le called Makefile.coq. Another rule explains how to build that o/le. We call

270

coq makefile, using the -R AEag to specify that o/les in the current directory should be con-
sidered to belong to the library Lib. This Makeo/le will build a compiled version of each
module, such that X.v is compiled into X.vo.

Now code in B.v may refer to deo/nitions in A.v after running

Require Import Lib.A.

Library Lib is presented as a module, containing a submodule A, which contains the
deo/nitions from A.v. These are genuine modules in the sense of Coq's module system, and
they may be passed to functors and so on.

Require Import is a convenient combination of two more primitive commands. Require
o/nds the .vo o/le containing the named module, ensuring that the module is loaded into mem-
ory. Import loads all top-level deo/nitions of the named module into the current namespace,
and it may be used with local modules that do not have corresponding .vo o/les. Another
command, Load, is for inserting the contents of a named o/le verbatim. It is generally bet-
ter to use the module-based commands, since they avoid rerunning proof scripts, and they
facilitate reorganization of directory structure without the need to change code.

Now we would like to use our library from a dioeerent development, called Client and
found in directory CLIENT, which has its own Makeo/le.

MODULES := D E
VS := $(MODULES:%=%.v)

.PHONY: coq clean
coq: Makefile.coq

make -f Makefile.coq

Makefile.coq: Makefile $(VS)

coq.makefile -R LIB Lib -R . Client $(VS) -o Makefile.coq

clean:: Makefile.coq

make -f Makefile.coq clean
rm -f Makefile.coq

We change the coq makefile call to indicate where the library Lib is found. Now D.v
and E.v can refer to deo/nitions from Lib module A after running

Require Import Lib.A.

and E.v can refer to deo/nitions from D.v by running
Require Import Client.D.

271

It can be useful to split a library into several o/les, but it is also inconvenient for client
code to import library modules individually. We can get the best of both worlds by, for
example, adding an extra source o/le Lib.v to Lib's directory and Makeo/le.

Require Export Lib.A Lib.B Lib.C.

Now client code can import all deo/nitions from all of Lib's modules simply by running
Require Import Lib.

The two Makeo/les above share a lot of code, so, in practice, it is useful to deo/ne a common
Makeo/le that is included by multiple library-specio/c Makeo/les.

The remaining ingredient is the proper way of editing library code o/les in Proof General.
Recall this snippet of .emacs code from Chapter 2, which tells Proof General where to o/nd
the library associated with this book.

(custom-set-variables

...
'(coq-prog-args '("-I" "/path/to/cpdt/src"))
...
)

To do interactive editing of our current example, we just need to change the AEags to point
to the right places.

(custom-set-variables

...
; '(coq-prog-args '("-I" "/path/to/cpdt/src"))

'(coq-prog-args '("-R" "LIB" "Lib" "-R" "CLIENT" "Client"))
...
)

When working on multiple projects, it is useful to leave multiple versions of this setting
in your .emacs o/le, commenting out all but one of them at any moment in time. To switch
between projects, change the commenting structure and restart Emacs.

272

Part IV
Formalizing Programming Languages

and Compilers

273

Chapter 15
First-Order Abstract Syntax

Many people interested in interactive theorem-proving want to prove theorems about pro-
gramming languages. That domain also provides a good setting for demonstrating how to
apply the ideas from the earlier parts of this book. This part introduces some techniques
for encoding the syntax and semantics of programming languages, along with some example
proofs designed to be as practical as possible, rather than to illustrate basic Coq technique.

To prove anything about a language, we must o/rst formalize the language's syntax. We
have a broad design space to choose from, and it makes sense to start with the simplest
options, so-called o/rst-order syntax encodings that do not use dependent types. These
encodings are o/rst-order because they do not use Coq function types in a critical way. In
this chapter, we consider the most popular o/rst-order encodings, using each to prove a basic
type soundness theorem.

15.1 Concrete Binding
The most obvious encoding of the syntax of programming languages follows usual context-
free grammars literally. We represent variables as strings and include a variable in our AST
deo/nition wherever a variable appears in the informal grammar. Concrete binding turns
out to involve a surprisingly large amount of menial bookkeeping, especially when we encode
higher-order languages with nested binder scopes. This section's example should give a AEavor
of what is required.

Module Concrete.

We need our variable type and its decidable equality operation.
Definition var := string.
Definition var eq := string dec.

We will formalize basic simply-typed lambda calculus. The syntax of expressions and
types follows what we would write in a context-free grammar.

Inductive exp : Set :=

274

| Const : bool ! exp|

Var : var ! exp|
App : exp ! exp ! exp|
Abs : var ! exp ! exp.

Inductive type : Set :=|

Bool : type|
Arrow : type ! type ! type.

It is useful to deo/ne a syntax extension that lets us write function types in more standard
notation.

Infix "*?" := Arrow (right associativity, at level 60).

Now we turn to a typing judgment. We will need to deo/ne it in terms of typing contexts,
which we represent as lists of pairs of variables and types.

Definition ctx := list (var * type).

The deo/nitions of our judgments will be prettier if we write them using mixo/x syntax.
To deo/ne a judgment for looking up the type of a variable in a context, we o/rst reserve
a notation for the judgment. Reserved notations enable mutually-recursive deo/nition of a
judgment and its notation; in this sense, the reservation is like a forward declaration in C.

Reserved Notation "G ---v x : t" (no associativity, at level 90, x at next level ).

Now we deo/ne the judgment itself, for variable typing, using a where clause to associate
a notation deo/nition.

Inductive lookup : ctx ! var ! type ! Prop :=|

First : 8 x t G,

(x, t ) :: G ---v x : t|
Next : 8 x t x' t' G,

x 6= x'!

G ---v x : t!
(x', t' ) :: G ---v x : t

where "G ---v x : t" := (lookup G x t ).
Hint Constructors lookup.

The same technique applies to deo/ning the main typing judgment. We use an at next
level clause to cause the argument e of the notation to be parsed at a low enough precedence
level.

Reserved Notation "G ---e e : t" (no associativity, at level 90, e at next level ).
Inductive hasType : ctx ! exp ! type ! Prop :=|

TConst : 8 G b,

G ---e Const b : Bool|
TVar : 8 G v t,

G ---v v : t

275

! G ---e Var v : t|
TApp : 8 G e1 e2 dom ran,

G ---e e1 : dom *? ran!

G ---e e2 : dom!
G ---e App e1 e2 : ran|
TAbs : 8 G x e' dom ran,

(x, dom) :: G ---e e' : ran!

G ---e Abs x e' : dom *? ran

where "G ---e e : t" := (hasType G e t ).
Hint Constructors hasType.

It is useful to know that variable lookup results are unchanged by adding extra bindings
to the end of a context.

Lemma weaken lookup : 8 x t G' G1,

G1 ---v x : t!

G1 ++ G' ---v x : t.
induction G1 as [ | [? ?] ? ]; crush;

match goal with|

[ H : ---v : ` ] ) inversion H ; crush
end.
Qed.

Hint Resolve weaken lookup.

The same property extends to the full typing judgment.
Theorem weaken hasType' : 8 G' G e t,

G ---e e : t!

G ++ G' ---e e : t.
induction 1; crush; eauto.
Qed.

Theorem weaken hasType : 8 e t,

nil ---e e : t! 8

G', G' ---e e : t.
intros; change G' with (nil ++ G' );

eapply weaken hasType'; eauto.
Qed.

Hint Resolve weaken hasType.

Much of the inconvenience of o/rst-order encodings comes from the need to treat capture-
avoiding substitution explicitly. We must start by deo/ning a substitution function.

Section subst.

Variable x : var.
Variable e1 : exp.

276

We are substituting expression e1 for every free occurrence of x . Note that this deo/nition
is specialized to the case where e1 is closed; substitution is substantially more complicated
otherwise, potentially involving explicit alpha-variation. Luckily, our example of type safety
for a call-by-value semantics only requires this restricted variety of substitution.

Fixpoint subst (e2 : exp) : exp :=

match e2 with|

Const ) e2|
Var x' ) if var eq x' x then e1 else e2|
App e1 e2 ) App (subst e1 ) (subst e2 )|
Abs x' e' ) Abs x' (if var eq x' x then e' else subst e' )
end.

We can prove a few theorems about substitution in well-typed terms, where we assume
that e1 is closed and has type xt .

Variable xt : type.
Hypothesis Ht' : nil ---e e1 : xt.

It is helpful to establish a notation asserting the freshness of a particular variable in a
context.

Notation "x # G" := (8 t' : type, In (x, t' ) G ! False) (no associativity, at level 90).
To prove type preservation, we will need lemmas proving consequences of variable lookup
proofs.

Lemma subst lookup' : 8 x' t,

x 6= x'! 8

G1, G1 ++ (x, xt ) :: nil ---v x' : t!

G1 ---v x' : t.
induction G1 as [ | [? ?] ? ]; crush;

match goal with|

[ H : ---v : ` ] ) inversion H
end; crush.
Qed.

Hint Resolve subst lookup'.
Lemma subst lookup : 8 x' t G1,

x' # G1!

G1 ++ (x, xt ) :: nil ---v x' : t!
t = xt.
induction G1 as [ | [? ?] ? ]; crush; eauto;

match goal with|

[ H : ---v : ` ] ) inversion H
end; crush; (elimtype False; eauto;

match goal with|

[ H : nil ---v : ` ] ) inversion H

277

end)
---- match goal with|

[ H : ` ] ) apply H ; crush; eauto
end.
Qed.

Implicit Arguments subst lookup [x' t G1 ].
Another set of lemmas allows us to remove provably unused variables from the ends of
typing contexts.

Lemma shadow lookup : 8 v t t' G1,

G1 ---v x : t'!

G1 ++ (x, xt ) :: nil ---v v : t!
G1 ---v v : t.
induction G1 as [ | [? ?] ? ]; crush;

match goal with|

[ H : nil ---v : ` ] ) inversion H|
[ H1 : ---v : , H2 : ---v : ` ] )

inversion H1 ; crush; inversion H2 ; crush
end.
Qed.

Lemma shadow hasType' : 8 G e t,

G ---e e : t! 8

G1, G = G1 ++ (x, xt ) :: nil! 8

tj, G1 ---v x : tj!

G1 ---e e : t.
Hint Resolve shadow lookup.

induction 1; crush; eauto;

match goal with|

[ H : (?x0, ) :: ++ (?x, ) :: ---e : ` ] )

destruct (var eq x0 x ); subst; eauto
end.
Qed.

Lemma shadow hasType : 8 G1 e t tj,

G1 ++ (x, xt ) :: nil ---e e : t!

G1 ---v x : tj!
G1 ---e e : t.
intros; eapply shadow hasType'; eauto.
Qed.

Hint Resolve shadow hasType.
Disjointness facts may be extended to larger contexts when the appropriate obligations
are met.

278

Lemma disjoint cons : 8 x x' t (G : ctx),

x # G!

x' 6= x!
x # (x', t ) :: G.
firstorder;

match goal with|

[ H : ( , ) = ( , ) ` ] ) injection H
end; crush.
Qed.

Hint Resolve disjoint cons.
Finally, we arrive at the main theorem about substitution: it preserves typing.

Theorem subst hasType : 8 G e2 t,

G ---e e2 : t! 8

G1, G = G1 ++ (x, xt ) :: nil!

x # G1!
G1 ---e subst e2 : t.
induction 1; crush;

try match goal with|

[ ` context [if ?E then else ] ] ) destruct E
end; crush; eauto 6;
match goal with|

[ H1 : x # , H2 : ---v x : ` ] )

rewrite (subst lookup H1 H2 )
end; crush.
Qed.

We wrap the last theorem into an easier-to-apply form specialized to closed expressions.

Theorem subst hasType closed : 8 e2 t,

(x, xt ) :: nil ---e e2 : t!

nil ---e subst e2 : t.
intros; eapply subst hasType; eauto.
Qed.
End subst.

Hint Resolve subst hasType closed.

A notation for substitution will make the operational semantics easier to read.
Notation "[ x \Lambda ? e1 ] e2" := (subst x e1 e2 ) (no associativity, at level 80).

To deo/ne a call-by-value small-step semantics, we rely on a standard judgment charac-
terizing which expressions are values.

Inductive val : exp ! Prop :=|

VConst : 8 b, val (Const b)|
VAbs : 8 x e, val (Abs x e).

279

Hint Constructors val.

Now the step relation is easy to deo/ne.
Reserved Notation "e1 ==? e2" (no associativity, at level 90).
Inductive step : exp ! exp ! Prop :=|

Beta : 8 x e1 e2,

val e2!

App (Abs x e1 ) e2 ==? [x  e2 ] e1|
Cong1 : 8 e1 e2 e1',

e1 ==? e1'!

App e1 e2 ==? App e1' e2|
Cong2 : 8 e1 e2 e2',

val e1!

e2 ==? e2'!
App e1 e2 ==? App e1 e2'

where "e1 ==? e2" := (step e1 e2 ).
Hint Constructors step.

The progress theorem says that any well-typed expression can take a step. To deal with
limitations of the induction tactic, we put most of the proof in a lemma whose statement
uses the usual trick of introducing extra equality hypotheses.

Lemma progress' : 8 G e t, G ---e e : t!

G = nil!
val e . 9 e', e ==? e'.
induction 1; crush; eauto;

try match goal with|

[ H : ---e : *? ` ] ) inversion H
end;
match goal with|

[ H : ` ] ) solve [ inversion H ; crush; eauto ]
end.
Qed.

Theorem progress : 8 e t, nil ---e e : t!

val e . 9 e', e ==? e'.
intros; eapply progress'; eauto.
Qed.

A similar pattern works for the preservation theorem, which says that any step of execu-
tion preserves an expression's type.

Lemma preservation' : 8 G e t, G ---e e : t!

G = nil! 8

e', e ==? e'

280

! nil ---e e' : t.
induction 1; inversion 2; crush; eauto;

match goal with|

[ H : ---e Abs : ` ] ) inversion H
end; eauto.
Qed.

Theorem preservation : 8 e t, nil ---e e : t! 8

e', e ==? e'!

nil ---e e' : t.
intros; eapply preservation'; eauto.
Qed.

End Concrete.

This was a relatively simple example, giving only a taste of the proof burden associated
with concrete syntax. We were helped by the fact that, with call-by-value semantics, we
only need to reason about substitution in closed expressions. There was also no need to
alpha-vary an expression.

15.2 De Bruijn Indices
De Bruijn indices are much more popular than concrete syntax. This technique provides a
canonical representation of syntax, where any two alpha-equivalent expressions have syn-
tactically equal encodings, removing the need for explicit reasoning about alpha conversion.
Variables are represented as natural numbers, where variable n denotes a reference to the
nth closest enclosing binder. Because variable references in eoeect point to binders, there is
no need to label binders, such as function abstraction, with variables.

Module DeBruijn.

Definition var := nat.
Definition var eq := eq nat dec.

Inductive exp : Set :=|

Const : bool ! exp|
Var : var ! exp|
App : exp ! exp ! exp|
Abs : exp ! exp.

Inductive type : Set :=|

Bool : type|
Arrow : type ! type ! type.

Infix "*?" := Arrow (right associativity, at level 60).

The deo/nition of typing proceeds much the same as in the last section. Since variables
are numbers, contexts can be simple lists of types. This makes it possible to write the lookup
judgment without mentioning inequality of variables.

281

Definition ctx := list type.
Reserved Notation "G ---v x : t" (no associativity, at level 90, x at next level ).
Inductive lookup : ctx ! var ! type ! Prop :=|

First : 8 t G,

t :: G ---v O : t|
Next : 8 x t t' G,

G ---v x : t!

t' :: G ---v S x : t

where "G ---v x : t" := (lookup G x t ).
Hint Constructors lookup.
Reserved Notation "G ---e e : t" (no associativity, at level 90, e at next level ).
Inductive hasType : ctx ! exp ! type ! Prop :=|

TConst : 8 G b,

G ---e Const b : Bool|
TVar : 8 G v t,

G ---v v : t!

G ---e Var v : t|
TApp : 8 G e1 e2 dom ran,

G ---e e1 : dom *? ran!

G ---e e2 : dom!
G ---e App e1 e2 : ran|
TAbs : 8 G e' dom ran,

dom :: G ---e e' : ran!

G ---e Abs e' : dom *? ran

where "G ---e e : t" := (hasType G e t ).
In the hasType case for function abstraction, there is no need to choose a variable name.
We simply push the function domain type onto the context G.

Hint Constructors hasType.

We prove roughly the same weakening theorems as before.
Lemma weaken lookup : 8 G' v t G,

G ---v v : t!

G ++ G' ---v v : t.
induction 1; crush.
Qed.

Hint Resolve weaken lookup.
Theorem weaken hasType' : 8 G' G e t,

G ---e e : t

282

! G ++ G' ---e e : t.
induction 1; crush; eauto.
Qed.

Theorem weaken hasType : 8 e t,

nil ---e e : t! 8

G', G' ---e e : t.
intros; change G' with (nil ++ G' );

eapply weaken hasType'; eauto.
Qed.

Hint Resolve weaken hasType.
Section subst.

Variable e1 : exp.

Substitution is easier to deo/ne than with concrete syntax. While our old deo/nition needed
to use two comparisons for equality of variables, the de Bruijn substitution only needs one
comparison.

Fixpoint subst (x : var) (e2 : exp) : exp :=

match e2 with|

Const ) e2|
Var x' ) if var eq x' x then e1 else e2|
App e1 e2 ) App (subst x e1 ) (subst x e2 )|
Abs e' ) Abs (subst (S x ) e' )
end.

Variable xt : type.
We prove similar theorems about inversion of variable lookup.

Lemma subst eq : 8 t G1,

G1 ++ xt :: nil ---v length G1 : t!

t = xt.
induction G1 ; inversion 1; crush.
Qed.

Implicit Arguments subst eq [t G1 ].
Lemma subst eq' : 8 t G1 x,

G1 ++ xt :: nil ---v x : t!

x 6= length G1!
G1 ---v x : t.
induction G1 ; inversion 1; crush;

match goal with|

[ H : nil ---v : ` ] ) inversion H
end.
Qed.

Hint Resolve subst eq'.

283

Lemma subst neq : 8 v t G1,

G1 ++ xt :: nil ---v v : t!

v 6= length G1!
G1 ---e Var v : t.
induction G1 ; inversion 1; crush.
Qed.

Hint Resolve subst neq.
Hypothesis Ht' : nil ---e e1 : xt.
The next lemma is included solely to guide eauto, which will not apply computational
equivalences automatically.

Lemma hasType push : 8 dom G1 e' ran,

dom :: G1 ---e subst (length (dom :: G1 )) e' : ran!

dom :: G1 ---e subst (S (length G1 )) e' : ran.
trivial.
Qed.

Hint Resolve hasType push.
Finally, we are ready for the main theorem about substitution and typing.

Theorem subst hasType : 8 G e2 t,

G ---e e2 : t! 8

G1, G = G1 ++ xt :: nil!

G1 ---e subst (length G1 ) e2 : t.
induction 1; crush;

try match goal with|

[ ` context [if ?E then else ] ] ) destruct E
end; crush; eauto 6;
try match goal with|

[ H : ---v : ` ] )

rewrite (subst eq H )
end; crush.
Qed.

Theorem subst hasType closed : 8 e2 t,

xt :: nil ---e e2 : t!

nil ---e subst O e2 : t.
intros; change O with (length (@nil type)); eapply subst hasType; eauto.
Qed.
End subst.

Hint Resolve subst hasType closed.

We deo/ne the operational semantics much as before.
Notation "[ x \Lambda ? e1 ] e2" := (subst e1 x e2 ) (no associativity, at level 80).

284

Inductive val : exp ! Prop :=|

VConst : 8 b, val (Const b)|
VAbs : 8 e, val (Abs e).

Hint Constructors val.
Reserved Notation "e1 ==? e2" (no associativity, at level 90).
Inductive step : exp ! exp ! Prop :=|

Beta : 8 e1 e2,

val e2!

App (Abs e1 ) e2 ==? [O  e2 ] e1|
Cong1 : 8 e1 e2 e1',

e1 ==? e1'!

App e1 e2 ==? App e1' e2|
Cong2 : 8 e1 e2 e2',

val e1!

e2 ==? e2'!
App e1 e2 ==? App e1 e2'

where "e1 ==? e2" := (step e1 e2 ).
Hint Constructors step.

Since we have added the right hints, the progress and preservation theorem statements
and proofs are exactly the same as in the concrete encoding example.

Lemma progress' : 8 G e t, G ---e e : t!

G = nil!
val e . 9 e', e ==? e'.
induction 1; crush; eauto;

try match goal with|

[ H : ---e : *? ` ] ) inversion H
end;
repeat match goal with|

[ H : ` ] ) solve [ inversion H ; crush; eauto ]
end.
Qed.

Theorem progress : 8 e t, nil ---e e : t!

val e . 9 e', e ==? e'.
intros; eapply progress'; eauto.
Qed.

Lemma preservation' : 8 G e t, G ---e e : t!

G = nil! 8

e', e ==? e'!

nil ---e e' : t.

285

induction 1; inversion 2; crush; eauto;

match goal with|

[ H : ---e Abs : ` ] ) inversion H
end; eauto.
Qed.

Theorem preservation : 8 e t, nil ---e e : t! 8

e', e ==? e'!

nil ---e e' : t.
intros; eapply preservation'; eauto.
Qed.

End DeBruijn.

15.3 Locally Nameless Syntax
The most popular Coq syntax encoding today is the locally nameless style, which has been
around for a while but was popularized recently by Aydemir et al., following a methodology
summarized in their paper "Engineering Formal Metatheory." A specialized tutorial by that
group1 explains the approach, based on a library. In this section, we will build up all of the
necessary ingredients from scratch.

The one-sentence summary of locally nameless encoding is that we represent free variables
as concrete syntax does, and we represent bound variables with de Bruijn indices. Many
proofs involve reasoning about terms transplanted into dioeerent free variable contexts; con-
crete encoding of free variables means that, to perform such a transplanting, we need no
o/x-up operation to adjust de Bruijn indices. At the same time, use of de Bruijn indices for
local variables gives us canonical representations of expressions, with respect to the usual
convention of alpha-equivalence. This makes many operations, including substitution of open
terms in open terms, easier to implement.

The "Engineering Formal Metatheory" methodology involves a number of subtle design
decisions, which we will describe as they appear in the latest version of our running example.

Module LocallyNameless.

Definition free var := string.
Definition bound var := nat.

Inductive exp : Set :=|

Const : bool ! exp|
FreeVar : free var ! exp|
BoundVar : bound var ! exp|
App : exp ! exp ! exp|
Abs : exp ! exp.

1http://www.cis.upenn.edu/~plclub/oregon08/

286

Note the dioeerent constructors for free vs. bound variables, and note that the lack of a
variable annotation on Abs nodes is inherited from the de Bruijn convention.

Inductive type : Set :=|

Bool : type|
Arrow : type ! type ! type.

Infix "*?" := Arrow (right associativity, at level 60).

As typing only depends on types of free variables, our contexts borrow their form from
the concrete binding example.

Definition ctx := list (free var * type).
Reserved Notation "G ---v x : t" (no associativity, at level 90, x at next level ).
Inductive lookup : ctx ! free var ! type ! Prop :=|

First : 8 x t G,

(x, t ) :: G ---v x : t|
Next : 8 x t x' t' G,

x 6= x'!

G ---v x : t!
(x', t' ) :: G ---v x : t

where "G ---v x : t" := (lookup G x t ).
Hint Constructors lookup.

The o/rst unusual operation we need is opening, where we replace a particular bound
variable with a particular free variable. Whenever we "go under a binder," in the typing
judgment or elsewhere, we choose a new free variable to replace the old bound variable of
the binder. Opening implements the replacement of one by the other. It is like a specialized
version of the substitution function we used for pure de Bruijn terms.

Section open.

Variable x : free var.

Fixpoint open (n : bound var) (e : exp) : exp :=

match e with|

Const ) e|
FreeVar ) e|
BoundVar n' )

if eq nat dec n' n

then FreeVar x
else if le lt dec n' n

then e
else BoundVar (pred n' )|
App e1 e2 ) App (open n e1 ) (open n e2 )|
Abs e1 ) Abs (open (S n) e1 )
end.

287

End open.

We will also need to reason about an expression's set of free variables. To keep things
simple, we represent sets as lists that may contain duplicates. Note how much easier this
operation is to implement than over pure de Bruijn terms, since we do not need to maintain
a separate numeric argument that keeps track of how deeply we have descended into the
input expression.

Fixpoint freeVars (e : exp) : list free var :=

match e with|

Const ) nil|
FreeVar x ) x :: nil|
BoundVar ) nil|
App e1 e2 ) freeVars e1 ++ freeVars e2|
Abs e1 ) freeVars e1
end.

It will be useful to have a well-formedness judgment for our terms. This notion is called
local closure. An expression may be declared to be closed, up to a particular maximum de
Bruijn index.

Inductive lclosed : nat ! exp ! Prop :=|

CConst : 8 n b, lclosed n (Const b)|
CFreeVar : 8 n v, lclosed n (FreeVar v )|
CBoundVar : 8 n v, v ! n ! lclosed n (BoundVar v )|
CApp : 8 n e1 e2, lclosed n e1 ! lclosed n e2 ! lclosed n (App e1 e2 )|
CAbs : 8 n e1, lclosed (S n) e1 ! lclosed n (Abs e1 ).

Hint Constructors lclosed.

Now we are ready to deo/ne the typing judgment.
Reserved Notation "G ---e e : t" (no associativity, at level 90, e at next level ).
Inductive hasType : ctx ! exp ! type ! Prop :=|

TConst : 8 G b,

G ---e Const b : Bool|
TFreeVar : 8 G v t,

G ---v v : t!

G ---e FreeVar v : t|
TApp : 8 G e1 e2 dom ran,

G ---e e1 : dom *? ran!

G ---e e2 : dom!
G ---e App e1 e2 : ran|
TAbs : 8 G e' dom ran L,

(8 x, ~ In x L ! (x, dom) :: G ---e open x O e' : ran)!

G ---e Abs e' : dom *? ran

288

where "G ---e e : t" := (hasType G e t ).
Compared to the previous versions, only the TAbs rule is surprising. The rule uses co-
o/nite quantiifcation. That is, the premise of the rule quantio/es over all x values that are
not members of a o/nite set L. A proof may choose any value of L when applying TAbs.
An alternate, more intuitive version of the rule would o/x L to be freeVars e'. It turns out
that the greater AEexibility of the rule above simplio/es many proofs signio/cantly. This typing
judgment may be proved equivalent to the more intuitive version, though we will not carry
out the proof here.

Specio/ally, what our version of TAbs says is that, to prove that Abs e' has a function
type, we must prove that any opening of e' with a variable not in L has the proper type.
For each x choice, we extend the context G in the usual way.

Hint Constructors hasType.

We prove a standard weakening theorem for typing, adopting a more general form than
in the previous sections.

Lemma lookup push : 8 G G' x t x' t',

(8 x t, G ---v x : t ! G' ---v x : t )!

(x, t ) :: G ---v x' : t'!
(x, t ) :: G' ---v x' : t'.
inversion 2; crush.
Qed.

Hint Resolve lookup push.
Theorem weaken hasType : 8 G e t,

G ---e e : t! 8

G', (8 x t, G ---v x : t ! G' ---v x : t )!

G' ---e e : t.
induction 1; crush; eauto.
Qed.

Hint Resolve weaken hasType.

We deo/ne a simple extension of crush to apply in many of the lemmas that follow.
Ltac ln := crush;

repeat (match goal with|

[ ` context [if ?E then else ] ] ) destruct E|
[ : context [if ?E then else ] ` ] ) destruct E
end; crush); eauto.

Two basic properties of local closure will be useful later.
Lemma lclosed S : 8 x e n,

lclosed n (open x n e)!

lclosed (S n) e.
induction e; inversion 1; ln.

289

Qed.
Hint Resolve lclosed S.
Lemma lclosed weaken : 8 n e,

lclosed n e! 8

n', n' >= n!

lclosed n' e.
induction 1; crush.
Qed.

Hint Resolve lclosed weaken.
Hint Extern 1 ( >= ) ) omega.

To prove some further properties, we need the ability to choose a variable that is disjoint
from a particular o/nite set. We implement a specio/c choice function fresh; its details do
not matter, as all we need is the o/nal theorem about it, freshOk. Concretely, to choose a
variable disjoint from set L, we sum the lengths of the variable names in L and choose a
new variable name that is one longer than that sum. This variable can be the string "x ",
followed by a number of primes equal to the sum.

Open Scope string scope.
Fixpoint primes (n : nat) : string :=

match n with|

O ) "x"|
S n' ) primes n' ++ "'"
end.

Fixpoint sumLengths (L : list free var) : nat :=

match L with|

nil ) O|
x :: L' ) String.length x + sumLengths L'
end.

Definition fresh (L : list free var) := primes (sumLengths L).

A few lemmas suOEce to establish the correctness theorem freshOk for fresh.
Theorem freshOk' : 8 x L, String.length x ? sumLengths L! ~

In x L.
induction L; crush.
Qed.

Lemma length app : 8 s2 s1,

String.length (s1 ++ s2 ) = String.length s1 + String.length s2.
induction s1 ; crush.
Qed.

Hint Rewrite length app : cpdt.
Lemma length primes : 8 n, String.length (primes n) = S n.

290

induction n; crush.
Qed.

Hint Rewrite length primes : cpdt.
Theorem freshOk : 8 L, ~ In (fresh L) L.

intros; apply freshOk'; unfold fresh; crush.
Qed.

Hint Resolve freshOk.

Now we can prove that well-typedness implies local closure. fresh will be used for us
automatically by eauto in the Abs case, driven by the presence of freshOk as a hint.

Lemma hasType lclosed : 8 G e t,

G ---e e : t!

lclosed O e.
induction 1; eauto.
Qed.

An important consequence of local closure is that certain openings are idempotent.
Lemma lclosed open : 8 n e, lclosed n e! 8

x, open x n e = e.
induction 1; ln.
Qed.

Hint Resolve lclosed open hasType lclosed.
Open Scope list scope.

We are now almost ready to get down to the details of substitution. First, we prove six
lemmas related to treating lists as sets.

Lemma In cons1 : 8 T (x x' : T ) ls,

x = x'!

In x (x' :: ls).
crush.
Qed.

Lemma In cons2 : 8 T (x x' : T ) ls,

In x ls!

In x (x' :: ls).
crush.
Qed.

Lemma In app1 : 8 T (x : T ) ls2 ls1,

In x ls1!

In x (ls1 ++ ls2 ).
induction ls1 ; crush.
Qed.

Lemma In app2 : 8 T (x : T ) ls2 ls1,

291

In x ls2!

In x (ls1 ++ ls2 ).
induction ls1 ; crush.
Qed.

Lemma freshOk app1 : 8 L1 L2,~

In (fresh (L1 ++ L2 )) L1.
intros; generalize (freshOk (L1 ++ L2 )); crush.
Qed.

Lemma freshOk app2 : 8 L1 L2,~

In (fresh (L1 ++ L2 )) L2.
intros; generalize (freshOk (L1 ++ L2 )); crush.
Qed.

Hint Resolve In cons1 In cons2 In app1 In app2.

Now we can deo/ne our simplest substitution function yet, thanks to the fact that we only
subsitute for free variables, which are distinguished syntactically from bound variables.

Section subst.

Hint Resolve freshOk app1 freshOk app2.

Variable x : free var.
Variable e1 : exp.

Fixpoint subst (e2 : exp) : exp :=

match e2 with|

Const ) e2|
FreeVar x' ) if string dec x' x then e1 else e2|
BoundVar ) e2|
App e1 e2 ) App (subst e1 ) (subst e2 )|
Abs e' ) Abs (subst e' )
end.

Variable xt : type.
It comes in handy to deo/ne disjointness of a variable and a context dioeerently than in
previous examples. We use the standard list function map, as well as the function fst for
projecting the o/rst element of a pair. We write @fst rather than just fst to ask that fst's
implicit arguments be instantiated with inferred values.

Definition disj x (G : ctx) := In x (map (@fst ) G ) ! False.
Infix "#" := disj (no associativity, at level 90).

Ltac disj := crush;

match goal with|

[ : :: = ?G0 ++ ` ] ) destruct G0
end; crush; eauto.

Some basic properties of variable lookup will be needed on the road to our usual theorem
connecting substitution and typing.

292

Lemma lookup disj' : 8 t G1,

G1 ---v x : t! 8

G, x # G!

G1 = G ++ (x, xt ) :: nil!
t = xt.
unfold disj ; induction 1; disj.
Qed.

Lemma lookup disj : 8 t G,

x # G!

G ++ (x, xt ) :: nil ---v x : t!
t = xt.
intros; eapply lookup disj'; eauto.
Qed.

Lemma lookup ne' : 8 G1 v t,

G1 ---v v : t! 8

G, G1 = G ++ (x, xt ) :: nil!

v 6= x!
G ---v v : t.
induction 1; disj.
Qed.

Lemma lookup ne : 8 G v t,

G ++ (x, xt ) :: nil ---v v : t!

v 6= x!
G ---v v : t.
intros; eapply lookup ne'; eauto.
Qed.

Hint Extern 1 ( ---e : ) )

match goal with|

[ H1 : , H2 : ` ] ) rewrite (lookup disj H1 H2 )
end.
Hint Resolve lookup ne.

Hint Extern 1 (@eq exp ) ) f equal.
We need to know that substitution and opening commute under appropriate circum-
stances.

Lemma open subst : 8 x0 e' n,

lclosed n e1!

x 6= x0!
open x0 n (subst e' ) = subst (open x0 n e' ).
induction e' ; ln.
Qed.

We state a corollary of the last result which will work more smoothly with eauto.

293

Lemma hasType open subst : 8 G x0 e t,

G ---e subst (open x0 0 e) : t!

x 6= x0!
lclosed 0 e1!
G ---e open x0 0 (subst e) : t.
intros; rewrite open subst; eauto.
Qed.

Hint Resolve hasType open subst.
Another lemma establishes the validity of weakening variable lookup judgments with
fresh variables.

Lemma disj push : 8 x0 (t : type) G,

x # G!

x 6= x0!
x # (x0, t ) :: G.
unfold disj ; crush.
Qed.

Hint Resolve disj push.
Lemma lookup cons : 8 x0 dom G x1 t,

G ---v x1 : t! ~

In x0 (map (@fst ) G )!
(x0, dom) :: G ---v x1 : t.
induction 1; crush;

match goal with|

[ H : ---v : ` ] ) inversion H
end; crush.
Qed.

Hint Resolve lookup cons.
Hint Unfold disj.

Finally, it is useful to state a version of the TAbs rule specialized to the choice of L that
is useful in our main substitution proof.

Lemma TAbs specialized : 8 G e' dom ran L x1,

(8 x, ~ In x (x1 :: L ++ map (@fst ) G ) ! (x, dom) :: G ---e open x O e' : ran)!

G ---e Abs e' : dom *? ran.
eauto.
Qed.

Now we can prove the main inductive lemma in a manner similar to what worked for
concrete binding.

Lemma hasType subst' : 8 G1 e t,

G1 ---e e : t! 8

G, G1 = G ++ (x, xt ) :: nil

294

! x # G!

G ---e e1 : xt!
G ---e subst e : t.
induction 1; ln;

match goal with|

[ L : list free var, : ?x # ` ] )

apply TAbs specialized with L x ; eauto 20
end.
Qed.

The main theorem about substitution of closed expressions follows easily.

Theorem hasType subst : 8 e t,

(x, xt ) :: nil ---e e : t!

nil ---e e1 : xt!
nil ---e subst e : t.
intros; eapply hasType subst'; eauto.
Qed.
End subst.

Hint Resolve hasType subst.

We can deo/ne the operational semantics in almost the same way as in previous examples.
Notation "[ x \Lambda ? e1 ] e2" := (subst x e1 e2 ) (no associativity, at level 60).
Inductive val : exp ! Prop :=|

VConst : 8 b, val (Const b)|
VAbs : 8 e, val (Abs e).

Hint Constructors val.
Reserved Notation "e1 ==? e2" (no associativity, at level 90).
Inductive step : exp ! exp ! Prop :=|

Beta : 8 e1 e2 x,

val e2! ~

In x (freeVars e1 )!
App (Abs e1 ) e2 ==? [x  e2 ] (open x O e1 )|
Cong1 : 8 e1 e2 e1',

e1 ==? e1'!

App e1 e2 ==? App e1' e2|
Cong2 : 8 e1 e2 e2',

val e1!

e2 ==? e2'!
App e1 e2 ==? App e1 e2'

where "e1 ==? e2" := (step e1 e2 ).
Hint Constructors step.

295

The only interesting change is that the Beta rule requires identifying a fresh variable
x to use in opening the abstraction body. We could have avoided this by implementing a
more general open that allows substituting expressions for variables, not just variables for
variables, but it simplio/es the proofs to have just one general substitution function.

Now we are ready to prove progress and preservation. The same proof script from the
last examples suOEces to prove progress, though signio/cantly dioeerent lemmas are applied for
us by eauto.

Lemma progress' : 8 G e t, G ---e e : t!

G = nil!
val e . 9 e', e ==? e'.
induction 1; crush; eauto;

try match goal with|

[ H : ---e : *? ` ] ) inversion H
end;
repeat match goal with|

[ H : ` ] ) solve [ inversion H ; crush; eauto ]
end.
Qed.

Theorem progress : 8 e t, nil ---e e : t!

val e . 9 e', e ==? e'.
intros; eapply progress'; eauto.
Qed.

To establish preservation, it is useful to formalize a principle of sound alpha-variation.
In particular, when we open an expression with a particular variable and then immediately
substitute for the same variable, we can replace that variable with any other that is not free
in the body of the opened expression.

Lemma alpha open : 8 x1 x2 e1 e2 n,~

In x1 (freeVars e2 )! ~

In x2 (freeVars e2 )!
[x1  e1 ](open x1 n e2 ) = [x2  e1 ](open x2 n e2 ).
induction e2 ; ln.
Qed.

Hint Resolve freshOk app1 freshOk app2.

Again it is useful to state a direct corollary which is easier to apply in proof search.
Lemma hasType alpha open : 8 G L e0 e2 x t,~

In x (freeVars e0 )!

G ---e [fresh (L ++ freeVars e0 )  e2 ](open (fresh (L ++ freeVars e0 )) 0 e0 ) : t!
G ---e [x  e2 ](open x 0 e0 ) : t.
intros; rewrite (alpha open x (fresh (L ++ freeVars e0 ))); auto.
Qed.

Hint Resolve hasType alpha open.

296

Now the previous sections' preservation proof scripts o/nish the job.
Lemma preservation' : 8 G e t, G ---e e : t!

G = nil! 8

e', e ==? e'!

nil ---e e' : t.
induction 1; inversion 2; crush; eauto;

match goal with|

[ H : ---e Abs : ` ] ) inversion H
end; eauto.
Qed.

Theorem preservation : 8 e t, nil ---e e : t! 8

e', e ==? e'!

nil ---e e' : t.
intros; eapply preservation'; eauto.
Qed.

End LocallyNameless.

297

Chapter 16
Dependent De Bruijn Indices

The previous chapter introduced the most common form of de Bruijn indices, without es-
sential use of dependent types. In earlier chapters, we used dependent de Bruijn indices to
illustrate tricks for working with dependent types. This chapter presents one complete case
study with dependent de Bruijn indices, focusing on producing the most maintainable proof
possible of a classic theorem about lambda calculus.

The proof that follows does not provide a complete guide to all kinds of formalization
with de Bruijn indices. Rather, it is intended as an example of some simple design patterns
that can make proving standard theorems much easier.

We will prove commutativity of capture-avoiding substitution for basic untyped lambda
calculus:

x1 6= x2 ) [e1/x1][e2/x2]e = [e2/x2][[e2/x2]e1/x1]e

16.1 Deo/ning Syntax and Its Associated Operations
Our deo/nition of expression syntax should be unsurprising. An expression of type exp n may
refer to n dioeerent free variables.

Inductive exp : nat ! Type :=|

Var : 8 n, o/n n ! exp n|
App : 8 n, exp n ! exp n ! exp n|
Abs : 8 n, exp (S n) ! exp n.

The classic implementation of substitution in de Bruijn terms requires an auxiliary oper-
ation, lifting, which increments the indices of all free variables in an expression. We need to
lift whenever we igo under a binder.j It is useful to write an auxiliary function liftVar that
lifts a variable; that is, liftVar x y will return y + 1 if y >= x , and it will return y otherwise.
This simple description uses numbers rather than our dependent o/n family, so the actual
specio/cation is more involved.

298

Combining a number of dependent types tricks, we wind up with this concrete realiza-
tion.

Fixpoint liftVar n (x : o/n n) : o/n (pred n) ! o/n n :=

match x with|

First ) fun y ) Next y|
Next x' ) fun y )

match y in o/n n' return o/n n' ! (o/n (pred n' ) ! o/n n' )!

o/n (S n' ) with|
First ) fun x' ) First|
Next y' ) fun fx' ) Next (fx' y' )
end x' (liftVar x' )
end.

Now it is easy to implement the main lifting operation.
Fixpoint lift n (e : exp n) : o/n (S n) ! exp (S n) :=

match e with|

Var f ' ) fun f ) Var (liftVar f f ' )|
App e1 e2 ) fun f ) App (lift e1 f ) (lift e2 f )|
Abs e1 ) fun f ) Abs (lift e1 (Next f ))
end.

To deo/ne substitution itself, we will need to apply some explicit type casts, based on
equalities between types. A single equality will suOEce for all of our casts. Its statement is
somewhat strange: it quantio/es over a variable f of type o/n n, but then never mentions f.
Rather, quantifying over f is useful because o/n is a dependent type that is inhabited or not
depending on its index. The body of the theorem, S (pred n) = n, is true only for n > 0,
but we can prove it by contradiction when n = 0, because we have around a value f of the
uninhabited type o/n 0.

Theorem nzf : 8 n (f : o/n n), S (pred n) = n.

destruct 1; trivial.
Qed.

Now we deo/ne a notation to streamline our cast expressions. The code [f return n, r for
e] denotes a cast of expression e whose type can be obtained by substituting some number
n1 for n in r. f should be a proof that n1 = n2, for any n2. In that case, the type of the
cast expression is r with n2 substituted for n.

Notation "[ f 'return' n , r 'for' e ]" :=

match f in = n return r with|

reAE equal ) e
end.

This notation is useful in deo/ning a variable substitution operation. The idea is that
substVar x y returns None if x = y; otherwise, it returns a isquishedj version of y with a
smaller o/n index, reAEecting that variable x has been substituted away. Without dependent

299

types, this would be a simple deo/nition. With dependency, it is reasonably intricate, and
our main task in automating proofs about it will be hiding that intricacy.

Fixpoint substVar n (x : o/n n) : o/n n ! option (o/n (pred n)) :=

match x with|

First ) fun y )

match y in o/n n' return option (o/n (pred n' )) with|

First ) None|
Next f ' ) Some f '
end|
Next x' ) fun y )

match y in o/n n'

return o/n (pred n' ) ! (o/n (pred n' ) ! option (o/n (pred (pred n' ))))!

option (o/n (pred n' )) with|
First ) fun x' ) Some [nzf x' return n, o/n n for First]|
Next y' ) fun fx' )

match fx' y' with|

None ) None|
Some f ) Some [nzf y' return n, o/n n for Next f ]
end
end x' (substVar x' )
end.

It is now easy to deo/ne our o/nal substitution function. The abstraction case involves two
casts, where one uses the sym eq function to convert a proof of n1 = n2 into a proof of n2
= n1.

Fixpoint subst n (e : exp n) : o/n n ! exp (pred n) ! exp (pred n) :=

match e with|

Var f ' ) fun f v ) match substVar f f ' with|

None ) v|
Some f j ) Var f j
end|
App e1 e2 ) fun f v ) App (subst e1 f v ) (subst e2 f v )|
Abs e1 ) fun f v ) Abs [sym eq (nzf f ) return n, exp n for

subst e1 (Next f ) [nzf f return n, exp n for lift v First]]
end.

Our o/nal commutativity theorem is about subst, but our proofs will rely on a few more
auxiliary deo/nitions. First, we will want an operation more that increments the index of a
o/n while preserving its interpretation as a number.

Fixpoint more n (f : o/n n) : o/n (S n) :=

match f with|

First ) First|
Next f ' ) Next (more f ' )

300

end.

Second, we will want a kind of inverse to liftVar.
Fixpoint unliftVar n (f : o/n n) : o/n (pred n) ! o/n (pred n) :=

match f with|

First ) fun g ) [nzf g return n, o/n n for First]|
Next f ' ) fun g )

match g in o/n n'

return o/n n' ! (o/n (pred n' ) ! o/n (pred n' )) ! o/n n' with|

First ) fun f ' ) f '|
Next g' ) fun unlift ) Next (unlift g' )
end f ' (unliftVar f ' )
end.

16.2 Custom Tactics
Less than a page of tactic code will be suOEcient to automate our proof of commuativity. We
start by deo/ning a workhorse simplio/cation tactic simp, which extends crush in a few ways.

Ltac simp := repeat progress (crush; try discriminate;

We enter an inner loop of applying hints specio/c to our domain.
repeat match goal with

Our o/rst two hints o/nd places where equality proofs are pattern-matched on. The o/rst
hint matches pattern-matches in the conclusion, while the second hint matches pattern-
matches in hypotheses. In each case, we apply the library theorem UIP reAE, which says that
any proof of a fact like e = e is itself equal to reAE equal. Rewriting with this fact enables
reduction of the pattern-match that we found.

| [ ` context [match ?pf with reAE equal ) end] ] )
rewrite (UIP reAE pf )|

[ : context [match ?pf with reAE equal ) end] ` ] )
rewrite (UIP reAE pf ) in *

The next hint o/nds an opportunity to invert a o/n equality hypothesis.

| [ H : Next = Next ` ] ) injection H ; clear H
If we have two equality hypotheses that share a lefthand side, we can use one to rewrite
the other, bringing the hypotheses' righthand sides together in a single equation.

301

| [ H : ?E = , H' : ?E = ` ] ) rewrite H in H'
Finally, we would like automatic use of quantio/ed equality hypotheses to perform rewrit-
ing. We pattern-match a hypothesis H asserting proposition P . We try to use H to perform
rewriting everywhere in our goal. The rewrite succeeds if it generates no additional hypothe-
ses, and, to prevent ino/nite loops in proof search, we clear H if it begins with universal
quantio/cation.

| [ H : ?P ` ] ) rewrite H in *; [match P with| 8

x , ) clear H| )

idtac
end]
end).

In implementing another level of automation, it will be useful to mark which free vari-
ables we generated with tactics, as opposed to which were present in the original theorem
statement. We use a dummy marker predicate Generated to record that information. A
tactic not generated fails if and only if its argument is a generated variable, and a tactic
generate records that its argument is generated.

Definition Generated n ( : o/n n) := True.
Ltac not generated x :=

match goal with|

[ : Generated x ` ] ) fail 1| )

idtac
end.

Ltac generate x := assert (Generated x ); [ constructor | ].

A tactic destructG performs case analysis on o/n values. The built-in case analysis tactics
are not smart enough to handle all situations, and we also want to mark new variables as
generated, to avoid ino/nite loops of case analysis. Our destructG tactic will only proceed if
its argument is not generated.

Theorem o/n inv : 8 n (f : o/n (S n)), f = First . 9 f ', f = Next f '.

intros; dep destruct f ; eauto.
Qed.

Ltac destructG E :=

not generated E ; let x := fresh "x" in

(destruct (o/n inv E ) as [ | [x ]] || destruct E as [ | ? x ]);
[ | generate x ].

Our most powerful workhorse tactic will be dester, which incorporates all of simp's sim-
plio/cations and adds heuristics for automatic case analysis and automatic quantio/er instan-
tiation.

302

Ltac dester := simp;

repeat (match goal with

The o/rst hint expresses our main insight into quantio/er instantiation. We identify a
hypothesis IH that begins with quantio/cation over o/n values. We also identify a free o/n
variable x and an arbitrary equality hypothesis H. Given these, we try instantiating IH with
x . We know we chose correctly if the instantiated proposition includes an opportunity to
rewrite using H.

| [ x : o/n , H : = , IH : 8 f : o/n , ` ] )

generalize (IH x ); clear IH ; intro IH ; rewrite H in IH

This basic idea suOEces for all of our explicit quantio/er instantiation. We add one more
variant that handles cases where an opportunity for rewriting is only exposed if two dioeerent
quantio/ers are instantiated at once.

| [ x : o/n , y : o/n , H : = ,

IH : 8 (f : o/n ) (g : o/n ), ` ] )
generalize (IH x y); clear IH ; intro IH ; rewrite H in IH

We want to case-analyze on any o/n expression that is the discriminee of a match expres-
sion or an argument to more.

| [ ` context [match ?E with First ) | Next ) end] ] )

destructG E|
[ : context [match ?E with First ) | Next ) end] ` ] )

destructG E|
[ ` context [more ?E] ] ) destructG E

Recall that simp will simplify equality proof terms of facts like e = e. The proofs in
question will either be of n = S (pred n) or S (pred n) = n, for some n. These equations do
not have syntactically equal sides. We can get to the point where they do have equal sides
by performing case analysis on n. Whenever we do so, the n = 0 case will be contradictory,
allowing us to discharge it by o/nding a free variable of type o/n 0 and performing inversion
on it. In the n = S n' case, the sides of these equalities will simplify to equal values, as
needed. The next two hints identify n values that are good candidates for such case analysis.

| [ x : o/n ?n ` ] )

match goal with|

[ ` context [nzf x ] ] )

destruct n; [ inversion x | ]

303

end|
[ x : o/n (pred ?n), y : o/n ?n ` ] )

match goal with|

[ ` context [nzf x ] ] )

destruct n; [ inversion y | ]
end

Finally, we o/nd match discriminees of option type, enforcing that we do not destruct any
discriminees that are themselves match expressions. Crucially, we do these case analyses with
case eq instead of destruct. The former adds equality hypotheses to record the relationships
between old variables and their new deduced forms. These equalities will be used by our
quantio/er instantiation heuristic.

| [ ` context [match ?E with None ) | Some ) end] ] )

match E with|

match with None ) | Some ) end ) fail 1| )

case eq E ; firstorder
end

Each iteration of the loop ends by calling simp again, and, after no more progress can be
made, we o/nish by calling eauto.

end; simp); eauto.

16.3 Theorems
We are now ready to prove our main theorem, by way of a progression of lemmas.

The o/rst pair of lemmas characterizes the interaction of substitution and lifting at the
variable level.

Lemma substVar unliftVar : 8 n (f0 : o/n n) f g,

match substVar f0 f, substVar (liftVar f0 g ) f with|

Some f1, Some f2 ) 9 f ', substVar g f1 = Some f '^

substVar (unliftVar f0 g) f2 = Some f '|
Some f1, None ) substVar g f1 = None|
None, Some f2 ) substVar (unliftVar f0 g) f2 = None|
None, None ) False
end.
induction f0 ; dester.
Qed.

Lemma substVar liftVar : 8 n (f0 : o/n n) f,

304

substVar f0 (liftVar f0 f ) = Some f.
induction f0 ; dester.
Qed.

Next, we deo/ne a notion of igreater-than-or-equalj for o/n values, prove an inversion
theorem for it, and add that theorem as a hint.

Inductive o/n ge : 8 n1, o/n n1 ! 8 n2, o/n n2 ! Prop :=|

GeO : 8 n1 (f1 : o/n n1 ) n2,

o/n ge f1 (First : o/n (S n2 ))|
GeS : 8 n1 (f1 : o/n n1 ) n2 (f2 : o/n n2 ),

o/n ge f1 f2!

o/n ge (Next f1 ) (Next f2 ).

Hint Constructors o/n ge.
Lemma o/n ge inv' : 8 n1 n2 (f1 : o/n n1 ) (f2 : o/n n2 ),

o/n ge f1 f2!

match f1, f2 with|

Next f1', Next f2' ) o/n ge f1' f2'|

, ) True
end.
destruct 1; dester.
Qed.

Lemma o/n ge inv : 8 n1 n2 (f1 : o/n n1 ) (f2 : o/n n2 ),

o/n ge (Next f1 ) (Next f2 )!

o/n ge f1 f2.
intros; generalize (o/n ge inv' (f1 := Next f1 ) (f2 := Next f2 )); dester.
Qed.

Hint Resolve o/n ge inv.

A congruence lemma for the o/n constructor Next is similarly useful.
Lemma Next cong : 8 n (f1 f2 : o/n n),

f1 = f2!

Next f1 = Next f2.
dester.
Qed.

Hint Resolve Next cong.

We prove a crucial lemma about liftVar in terms of o/n ge.
Lemma liftVar more : 8 n (f : o/n n) (f0 : o/n (S n)) g,

o/n ge g f0!

match liftVar f0 f in o/n n'

return o/n n' ! (o/n (pred n' ) ! o/n n' ) ! o/n (S n' ) with|

First n0 ) fun ) First

305

| Next n0 y' ) fun fx' ) Next (fx' y' )
end g (liftVar g ) = liftVar (more f0 ) (liftVar g f ).
induction f ; inversion 1; dester.
Qed.

Hint Resolve liftVar more.

We suggest a particular way of changing the form of a goal, so that other hints are able
to match.

Hint Extern 1 ( = lift (Next (more ?f))) )

change (Next (more f )) with (more (Next f )).

We suggest applying the f equal tactic to simplify equalities over expressions. For
instance, this would reduce a goal App f1 x1 = App f2 x2 to two goals f1 = f2 and x1 =
x2.

Hint Extern 1 (eq (A := exp ) ) ) f equal.

Our consideration of lifting in isolation o/nishes with another hint lemma. The auxiliary
lemma with a strengthened induction hypothesis is where we put o/n ge to use, and we do
not need to mention that predicate again afteward.

Lemma double lift' : 8 n (e : exp n) f g,

o/n ge g f!

lift (lift e f ) (Next g) = lift (lift e g ) (more f ).
induction e; dester.
Qed.

Lemma double lift : 8 n (e : exp n) g,

lift (lift e First) (Next g ) = lift (lift e g) First.
intros; apply double lift'; dester.
Qed.

Hint Resolve double lift.

Now we characterize the interaction of substitution and lifting on variables. We start with
a more general form substVar lift' of the o/nal lemma substVar lift, with the latter proved as
a direct corollary of the former.

Lemma substVar lift' : 8 n (f0 : o/n n) f g,

substVar [nzf f0 return n, o/n (S n) for

liftVar (more g) [sym eq (nzf f0 ) return n, o/n n for f0 ]]
(liftVar (liftVar (Next f0 ) [nzf f0 return n, o/n n for g ]) f )
= match substVar f0 f with|

Some f j ) Some [nzf f0 return n, o/n n for liftVar g f j]|
None ) None
end.
induction f0 ; dester.
Qed.

306

Lemma substVar lift : 8 n (f0 f g : o/n (S n)),

substVar (liftVar (more g ) f0 ) (liftVar (liftVar (Next f0 ) g) f )
= match substVar f0 f with|

Some f j ) Some (liftVar g f j)|
None ) None
end.
intros; generalize (substVar lift' f0 f g); dester.
Qed.

We follow a similar decomposition for the expression-level theorem about substitution
and lifting.

Lemma lift subst' : 8 n (e1 : exp n) f g e2,

lift (subst e1 f e2 ) g
= [sym eq (nzf f ) return n, exp n for

subst

(lift e1 (liftVar (Next f ) [nzf f return n, o/n n for g ]))
[nzf f return n, o/n (S n) for

liftVar (more g) [sym eq (nzf f ) return n, o/n n for f ]]
[nzf f return n, exp n for lift e2 g]].
induction e1 ; generalize substVar lift; dester.
Qed.

Lemma lift subst : 8 n g (e2 : exp (S n)) e3,

subst (lift e2 First) (Next g ) (lift e3 First) = lift (n := n) (subst e2 g e3 ) First.
intros; generalize (lift subst' e2 g First e3 ); dester.
Qed.

Hint Resolve lift subst.

Our last auxiliary lemma characterizes a situation where substitution can undo the eoeects
of lifting.

Lemma undo lift' : 8 n (e1 : exp n) e2 f,

subst (lift e1 f ) f e2 = e1.
induction e1 ; generalize substVar liftVar; dester.
Qed.

Lemma undo lift : 8 n e2 e3 (f0 : o/n (S (S n))) g,

e3 = subst (lift e3 (unliftVar f0 g)) (unliftVar f0 g )

(subst (n := S n) e2 g e3 ).
generalize undo lift'; dester.
Qed.

Hint Resolve undo lift.

Finally, we arrive at the substitution commutativity theorem.
Lemma subst comm' : 8 n (e1 : exp n) f g e2 e3,

subst (subst e1 f e2 ) g e3

307

= subst
(subst e1 (liftVar f g ) [nzf g return n, exp n for

lift e3 [sym eq (nzf g ) return n, o/n n for unliftVar f g ]])
(unliftVar f g)
(subst e2 g e3 ).
induction e1 ; generalize (substVar unliftVar (n := n)); dester.
Qed.

Theorem subst comm : 8 (e1 : exp 2) e2 e3,

subst (subst e1 First e2 ) First e3
= subst (subst e1 (Next First) (lift e3 First)) First (subst e2 First e3 ).
intros; generalize (subst comm' e1 First First e2 e3 ); dester.
Qed.

The o/nal theorem is specialized to the case of substituting in an expression with exactly
two free variables, which yields a statement that is readable enough, as statements about de
Bruijn indices go.

This proof script is resilient to specio/cation changes. It is easy to add new constructors
to the language being treated. The proofs adapt automatically to the addition of any con-
structor whose subterms each involve zero or one new bound variables. That is, to add such
a constructor, we only need to add it to the deo/nition of exp and add (quite obvious) cases
for it in the deo/nitions of lift and subst.

308

Chapter 17
Higher-Order Abstract Syntax

In many cases, detailed reasoning about variable binders and substitution is a small annoy-
ance; in other cases, it becomes the dominant cost of proving a theorem formally. No matter
which of these possibilities prevails, it is clear that it would be very pragmatic to o/nd a
way to avoid reasoning about variable identity or freshness. A well-established alternative
to o/rst-order encodings is higher-order abstract syntax, or HOAS. In mechanized theorem-
proving, HOAS is most closely associated with the LF meta logic and the tools based on it,
including Twelf.

In this chapter, we will see that HOAS cannot be implemented directly in Coq. However,
a few very similar encodings are possible and are in fact very eoeective in some important
domains.

17.1 Classic HOAS
The motto of HOAS is simple: represent object language binders using meta language
binders. Here, "object language" refers to the language being formalized, while the meta
language is the language in which the formalization is done. Our usual meta language,
Coq's Gallina, contains the standard binding facilities of functional programming, making it
a promising base for higher-order encodings.

Recall the concrete encoding of basic untyped lambda calculus expressions.

Inductive uexp : Set :=|

UVar : string ! uexp|
UApp : uexp ! uexp ! uexp|
UAbs : string ! uexp ! uexp.

The explicit presence of variable names forces us to think about issues of freshness and
variable capture. The HOAS alternative would look like this.

Reset uexp.

Inductive uexp : Set :=

309

| UApp : uexp ! uexp ! uexp|

UAbs : (uexp ! uexp) ! uexp.

We have avoided any mention of variables. Instead, we encode the binding done by
abstraction using the binding facilities associated with Gallina functions. For instance, we
might represent the term *x. x x as UAbs (fun x ) UApp x x ). Coq has built-in support
for matching binders in anonymous fun expressions to their uses, so we avoid needing to
implement our own binder-matching logic.

This deo/nition is not quite HOAS, because of the broad variety of functions that Coq
would allow us to pass as arguments to UAbs. We can thus construct many uexps that do
not correspond to normal lambda terms. These deviants are called exotic terms. In LF,
functions may only be written in a very restrictive computational language, lacking, among
other things, pattern matching and recursive function deo/nitions. Thus, thanks to a careful
balancing act of design decisions, exotic terms are not possible with usual HOAS encodings
in LF.

Our deo/nition of uexp has a more fundamental problem: it is invalid in Gallina.

Error : Non strictly positive occurrence of "uexp" in

"(uexp ! uexp) ! uexp".

We have violated a rule that we considered before: an inductive type may not be deo/ned
in terms of functions over itself. Way back in Chapter 3, we considered this example and the
reasons why we should be glad that Coq rejects it. Thus, we will need to use more cleverness
to reap similar beneo/ts.

The root problem is that our expressions contain variables representing expressions of
the same kind. Many useful kinds of syntax involve no such cycles. For instance, it is easy
to use HOAS to encode standard o/rst-order logic in Coq.

Inductive prop : Type :=|

Eq : 8 T, T ! T ! prop|
Not : prop ! prop|
And : prop ! prop ! prop|
Or : prop ! prop ! prop|
Forall : 8 T, (T ! prop) ! prop|
Exists : 8 T, (T ! prop) ! prop.

Fixpoint propDenote (p : prop) : Prop :=

match p with|

Eq x y ) x = y|
Not p ) ~ (propDenote p)|
And p1 p2 ) propDenote p1 ^ propDenote p2|
Or p1 p2 ) propDenote p1 . propDenote p2|
Forall f ) 8 x, propDenote (f x )|
Exists f ) 9 x, propDenote (f x )

310

end.

Unfortunately, there are other recursive functions that we might like to write but cannot.
One simple example is a function to count the number of constructors used to build a prop.
To look inside a Forall or Exists, we need to look inside the quantio/er's body, which is
represented as a function. In Gallina, as in most statically-typed functional languages, the
only way to interact with a function is to call it. We have no hope of doing that here; the
domain of the function in question has an arbitary type T , so T may even be uninhabited.
If we had a universal way of constructing values to look inside functions, we would have
uncovered a consistency bug in Coq!

We are still suoeering from the possibility of writing exotic terms, such as this example:

Example true prop := Eq 1 1.
Example false prop := Not true prop.
Example exotic prop := Forall (fun b : bool ) if b then true prop else false prop).

Thus, the idea of a uniform way of looking inside a binder to o/nd another well-deo/ned
prop is hopelessly doomed.

A clever HOAS variant called weak HOAS manages to rule out exotic terms in Coq. Here
is a weak HOAS version of untyped lambda terms.

Parameter var : Set.
Inductive uexp : Set :=|

UVar : var ! uexp|
UApp : uexp ! uexp ! uexp|
UAbs : (var ! uexp) ! uexp.

We postulate the existence of some set var of variables, and variable nodes appear ex-
plicitly in our syntax. A binder is represented as a function over variables, rather than as
a function over expressions. This breaks the cycle that led Coq to reject the literal HOAS
deo/nition. It is easy to encode our previous example, *x. x x:

Example self app := UAbs (fun x ) UApp (UVar x ) (UVar x )).

What about exotic terms? The problems they caused earlier came from the fact that
Gallina is expressive enough to allow us to perform case analysis on the types we used as the
domains of binder functions. With weak HOAS, we use an abstract type var as the domain.
Since we assume the existence of no functions for deconstructing var s, Coq's type soundness
enforces that no Gallina term of type uexp can take dioeerent values depending on the value
of a var available in the typing context, except by incorporating those variables into a uexp
value in a legal way.

Weak HOAS retains the other disadvantage of our previous example: it is hard to write
recursive functions that deconstruct terms. As with the previous example, some functions are
implementable. For instance, we can write a function to reverse the function and argument
positions of every UApp node.

Fixpoint swap (e : uexp) : uexp :=

match e with

311

| UVar ) e|

UApp e1 e2 ) UApp (swap e2 ) (swap e1 )|
UAbs e1 ) UAbs (fun x ) swap (e1 x ))
end.

However, it is still impossible to write a function to compute the size of an expression.
We would still need to manufacture a value of type var to peer under a binder, and that is
impossible, because var is an abstract type.

17.2 Parametric HOAS
In the context of Haskell, Washburn and Weirich introduced a technique called parametric
HOAS, or PHOAS. By making a slight alteration in the spirit of weak HOAS, we arrive at
an encoding that addresses all three of the complaints above: the encoding is legal in Coq,
exotic terms are impossible, and it is possible to write any syntax-deconstructing function
that we can write with o/rst-order encodings. The last of these advantages is not even present
with HOAS in Twelf. In a sense, we receive it in exchange for giving up a free implementation
of capture-avoiding substitution.

The o/rst step is to change the weak HOAS type so that var is a variable inside a section,
rather than a global parameter.

Reset uexp.
Section uexp.

Variable var : Set.

Inductive uexp : Set :=|

UVar : var ! uexp|
UApp : uexp ! uexp ! uexp|
UAbs : (var ! uexp) ! uexp.
End uexp.

Next, we can encapsulate choices of var inside a polymorphic function type.
Definition Uexp := 8 var, uexp var.

This type Uexp is our o/nal, exotic-term-free representation of lambda terms. Inside the
body of a Uexp function, var values may not be deconstructed illegaly, for much the same
reason as with weak HOAS. We simply trade an abstract type for parametric polymorphism.

Our running example *x. x x is easily expressed:

Example self app : Uexp := fun var ) UAbs (var := var )

(fun x : var ) UApp (var := var ) (UVar (var := var ) x ) (UVar (var := var ) x )).

Including all mentions of var explicitly helps clarify what is happening here, but it is
convenient to let Coq's local type inference o/ll in these occurrences for us.

Example self app' : Uexp := fun ) UAbs (fun x ) UApp (UVar x ) (UVar x )).

312

We can go further and apply the PHOAS technique to dependently-typed ASTs, where
Gallina typing guarantees that only well-typed terms can be represented. For the rest of this
chapter, we consider the example of simply-typed lambda calculus with natural numbers and
addition. We start with a conventional deo/nition of the type language.

Inductive type : Type :=|

Nat : type|
Arrow : type ! type ! type.

Infix "*?" := Arrow (right associativity, at level 60).

Our deo/nition of the expression type follows the deo/nition for untyped lambda calculus,
with one important change. Now our section variable var is not just a type. Rather, it is a
function returning types. The idea is that a variable of object language type t is represented
by a var t . Note how this enables us to avoid indexing the exp type with a representation
of typing contexts.

Section exp.

Variable var : type ! Type.

Inductive exp : type ! Type :=|

Const' : nat ! exp Nat|
Plus' : exp Nat ! exp Nat ! exp Nat

| Var : 8 t, var t ! exp t|

App' : 8 dom ran, exp (dom *? ran) ! exp dom ! exp ran|
Abs' : 8 dom ran, (var dom ! exp ran) ! exp (dom *? ran).
End exp.

Implicit Arguments Const' [var ].
Implicit Arguments Var [var t ].
Implicit Arguments Abs' [var dom ran].

Our o/nal representation type wraps exp as before.
Definition Exp t := 8 var, exp var t.

We can deo/ne some smart constructors to make it easier to build Exps without using
polymorphism explicitly.

Definition Const (n : nat) : Exp Nat :=

fun ) Const' n.
Definition Plus (E1 E2 : Exp Nat) : Exp Nat :=

fun ) Plus' (E1 ) (E2 ).
Definition App dom ran (F : Exp (dom *? ran)) (X : Exp dom) : Exp ran :=

fun ) App' (F ) (X ).

A case for function abstraction is not as natural, but we can implement one candidate
in terms of a type family Exp1, such that Exp1 free result represents an expression of type
result with one free variable of type free.

313

Definition Exp1 t1 t2 := 8 var, var t1 ! exp var t2.
Definition Abs dom ran (B : Exp1 dom ran) : Exp (dom *? ran) :=

fun ) Abs' (B ).

Now it is easy to encode a number of example programs.
Example zero := Const 0.
Example one := Const 1.
Example one again := Plus zero one.
Example ident : Exp (Nat *? Nat) := Abs (fun X ) Var X ).
Example app ident := App ident one again.
Example app : Exp ((Nat *? Nat) *? Nat *? Nat) := fun )

Abs' (fun f ) Abs' (fun x ) App' (Var f ) (Var x ))).
Example app ident' := App (App app ident) one again.

We can write syntax-deconstructing functions, such as CountVars, which counts how many
Var nodes appear in an Exp. First, we write a version countVars for exps. The main trick is
to specialize countVars to work over expressions where var is instantiated as fun ) unit.
That is, every variable is just a value of type unit, such that variables carry no information.
The important thing is that we have a value tt of type unit available, to use in descending
into binders.

Fixpoint countVars t (e : exp (fun ) unit) t ) : nat :=

match e with|

Const' ) 0|
Plus' e1 e2 ) countVars e1 + countVars e2|
Var ) 1|
App' e1 e2 ) countVars e1 + countVars e2|
Abs' e' ) countVars (e' tt)
end.

We turn countVars into CountVars with explicit instantiation of a polymorphic Exp value
E. We can write an underscore for the paramter to E, because local type inference is able to
infer the proper value.

Definition CountVars t (E : Exp t ) : nat := countVars (E ).

A few evaluations establish that CountVars behaves plausibly.
Eval compute in CountVars zero.

= 0
: nat

Eval compute in CountVars one.

= 0
: nat

Eval compute in CountVars one again.

314

= 0
: nat

Eval compute in CountVars ident.

= 1
: nat

Eval compute in CountVars app ident.

= 1
: nat

Eval compute in CountVars app.

= 2
: nat

Eval compute in CountVars app ident'.

= 3
: nat

We might want to go further and count occurrences of a single distinguished free variable
in an expression. In this case, it is useful to instantiate var as fun ) bool. We will
represent the distinguished variable with true and all other variables with false.

Fixpoint countOne t (e : exp (fun ) bool) t ) : nat :=

match e with|

Const' ) 0|
Plus' e1 e2 ) countOne e1 + countOne e2|
Var true ) 1|
Var false ) 0|
App' e1 e2 ) countOne e1 + countOne e2|
Abs' e' ) countOne (e' false)
end.

We wrap countOne into CountOne, which we type using the Exp1 deo/nition from before.
CountOne operates on an expression E with a single free variable. We apply an instantiated
E to true to mark this variable as the one countOne should look for. countOne itself is careful
to instantiate all other variables with false.

Definition CountOne t1 t2 (E : Exp1 t1 t2 ) : nat :=

countOne (E true).

We can check the behavior of CountOne on a few examples.
Example ident1 : Exp1 Nat Nat := fun X ) Var X.
Example add self : Exp1 Nat Nat := fun X ) Plus' (Var X ) (Var X ).
Example app zero : Exp1 (Nat *? Nat) Nat := fun X ) App' (Var X ) (Const' 0).
Example app ident1 : Exp1 Nat Nat := fun X )

App' (Abs' (fun Y ) Var Y )) (Var X ).

315

Eval compute in CountOne ident1.

= 1
: nat

Eval compute in CountOne add self.

= 2
: nat

Eval compute in CountOne app zero.

= 1
: nat

Eval compute in CountOne app ident1.

= 1
: nat

The PHOAS encoding turns out to be just as general as the o/rst-order encodings we saw
previously. To provide a taste of that generality, we implement a translation into concrete
syntax, rendered in human-readable strings. This is as easy as representing variables as
strings.

Section ToString.

Open Scope string scope.

Fixpoint natToString (n : nat) : string :=

match n with|

O ) "O"|
S n' ) "S(" ++ natToString n' ++ ")"
end.

Function toString takes an extra argument cur, which holds the last variable name as-
signed to a binder. We build new variable names by extending cur with primes. The function
returns a pair of the next available variable name and of the actual expression rendering.

Fixpoint toString t (e : exp (fun ) string) t ) (cur : string) : string * string :=

match e with|

Const' n ) (cur, natToString n)|
Plus' e1 e2 )

let (cur', s1 ) := toString e1 cur in
let (curj, s2 ) := toString e2 cur' in
(curj, "(" ++ s1 ++ ") + (" ++ s2 ++ ")")|
Var s ) (cur, s)|
App' e1 e2 )

let (cur', s1 ) := toString e1 cur in
let (curj, s2 ) := toString e2 cur' in
(curj, "(" ++ s1 ++ ") (" ++ s2 ++ ")")|
Abs' e' )

316

let (cur', s) := toString (e' cur ) (cur ++ "'") in
(cur', "("" ++ cur ++ ", " ++ s ++ ")")
end.

Definition ToString t (E : Exp t ) : string := snd (toString (E ) "x").
End ToString.

Eval compute in ToString zero.

= "O"%string
: string

Eval compute in ToString one.

= "S(O)"%string
: string

Eval compute in ToString one again.

= "(O) + (S(O))"%string
: string

Eval compute in ToString ident.

= "("x, x)"%string
: string

Eval compute in ToString app ident.

= "(("x, x)) ((O) + (S(O)))"%string
: string

Eval compute in ToString app.

= "("x, ("x', (x) (x')))"%string
: string

Eval compute in ToString app ident'.

= "((("x, ("x', (x) (x')))) (("xj, xj))) ((O) + (S(O)))"%string
: string

Our o/nal example is crucial to using PHOAS to encode standard operational semantics.
We deo/ne capture-avoiding substitution, in terms of a function AEatten which takes in an
expression that represents variables as expressions. AEatten replaces every node Var e with e.

Section AEatten.

Variable var : type ! Type.

Fixpoint AEatten t (e : exp (exp var ) t ) : exp var t :=

match e with|

Const' n ) Const' n|
Plus' e1 e2 ) Plus' (AEatten e1 ) (AEatten e2 )|
Var e' ) e'|
App' e1 e2 ) App' (AEatten e1 ) (AEatten e2 )

317

| Abs' e' ) Abs' (fun x ) AEatten (e' (Var x )))
end.
End AEatten.

Flattening turns out to implement the heart of substitution. We apply E2, which has
one free variable, to E1, replacing the occurrences of the free variable by copies of E1. AEatten
takes care of removing the extra Var applications around these copies.

Definition Subst t1 t2 (E1 : Exp t1 ) (E2 : Exp1 t1 t2 ) : Exp t2 := fun )

AEatten (E2 (E1 )).

Eval compute in Subst one ident1.

= fun var : type ! Type ) Const' 1
: Exp Nat

Eval compute in Subst one add self.

= fun var : type ! Type ) Plus' (Const' 1) (Const' 1)
: Exp Nat

Eval compute in Subst ident app zero.

= fun var : type ! Type )

App' (Abs' (fun X : var Nat ) Var X )) (Const' 0)
: Exp Nat

Eval compute in Subst one app ident1.

= fun var : type ! Type )

App' (Abs' (fun x : var Nat ) Var x )) (Const' 1)
: Exp Nat

17.3 A Type Soundness Proof
With Subst deo/ned, there are few surprises encountered in deo/ning a standard small-step,
call-by-value semantics for our object language. We begin by classifying a subset of expres-
sions as values.

Inductive Val : 8 t, Exp t ! Prop :=|

VConst : 8 n, Val (Const n)|
VAbs : 8 dom ran (B : Exp1 dom ran), Val (Abs B ).

Hint Constructors Val.

Since this language is more complicated than the one we considered in the chapter on
o/rst-order encodings, we will use explicit evaluation contexts to deo/ne the semantics. A value
of type Ctx t u is a context that yields an expression of type u when o/lled by an expression
of type t . We have one context for each position of the App and Plus constructors.

Inductive Ctx : type ! type ! Type :=|

AppCong1 : 8 (dom ran : type),

318

Exp dom ! Ctx (dom *? ran) ran|
AppCong2 : 8 (dom ran : type),

Exp (dom *? ran) ! Ctx dom ran|
PlusCong1 : Exp Nat ! Ctx Nat Nat|
PlusCong2 : Exp Nat ! Ctx Nat Nat.

A judgment characterizes when contexts are valid, enforcing the standard call-by-value
restriction that certain positions must hold values.

Inductive isCtx : 8 t1 t2, Ctx t1 t2 ! Prop :=|

IsApp1 : 8 dom ran (X : Exp dom), isCtx (AppCong1 ran X )|
IsApp2 : 8 dom ran (F : Exp (dom *? ran)), Val F ! isCtx (AppCong2 F )|
IsPlus1 : 8 E2, isCtx (PlusCong1 E2 )|
IsPlus2 : 8 E1, Val E1 ! isCtx (PlusCong2 E1 ).

A simple deo/nition implements plugging a context with a specio/c expression.
Definition plug t1 t2 (C : Ctx t1 t2 ) : Exp t1 ! Exp t2 :=

match C with|

AppCong1 X ) fun F ) App F X|
AppCong2 F ) fun X ) App F X|
PlusCong1 E2 ) fun E1 ) Plus E1 E2|
PlusCong2 E1 ) fun E2 ) Plus E1 E2
end.

Infix "@" := plug (no associativity, at level 60).

Finally, we have the step relation itself, which combines our ingredients in the standard
way. In the congruence rule, we introduce the extra variable E1 and its associated equality
to make the rule easier for eauto to apply.

Reserved Notation "E1 ==? E2" (no associativity, at level 90).
Inductive Step : 8 t, Exp t ! Exp t ! Prop :=|

Beta : 8 dom ran (B : Exp1 dom ran) (X : Exp dom),

Val X!

App (Abs B ) X ==? Subst X B|
Sum : 8 n1 n2,

Plus (Const n1 ) (Const n2 ) ==? Const (n1 + n2 )|
Cong : 8 t t' (C : Ctx t t' ) E E' E1,

isCtx C!

E1 = C @ E!
E ==? E'!
E1 ==? C @ E'

where "E1 ==? E2" := (Step E1 E2 ).
Hint Constructors isCtx Step.

To prove type soundness for this semantics, we need to overcome one crucial obstacle.

319

Standard proofs use induction on the structure of typing derivations. Our encoding mixes
typing derivations with expression syntax, so we want to induct over expression structure.
Our expressions are represented as functions, which do not, in general, admit induction in
Coq. However, because of our use of parametric polymorphism, we know that our expressions
do, in fact, have inductive structure. In particular, every closed value of Exp type must belong
to the following relation.

Inductive Closed : 8 t, Exp t ! Prop :=|

CConst : 8 n,

Closed (Const n)|
CPlus : 8 E1 E2,

Closed E1!

Closed E2!
Closed (Plus E1 E2 )|
CApp : 8 dom ran (E1 : Exp (dom *? ran)) E2,

Closed E1!

Closed E2!
Closed (App E1 E2 )|
CAbs : 8 dom ran (E1 : Exp1 dom ran),

Closed (Abs E1 ).

How can we prove such a fact? It probably cannot be established in Coq without axioms.
Rather, one would have to establish it metatheoretically, reasoning informally outside of Coq.
For now, we assert the fact as an axiom. The later chapter on intensional transformations
shows one approach to removing the need for an axiom.

Axiom closed : 8 t (E : Exp t ), Closed E.

The usual progress and preservation theorems are now very easy to prove. In fact,
preservation is implicit in our dependently-typed deo/nition of Step. This is a huge win,
because we avoid completely the theorem about substitution and typing that made up the
bulk of each proof in the chapter on o/rst-order encodings. The progress theorem yields to a
few lines of automation.

We deo/ne a slight variant of crush which also looks for chances to use the theorem
inj pair2 on hypotheses. This theorem deals with an artifact of the way that inversion
works on dependently-typed hypotheses.

Ltac my crush' :=

crush;
repeat (match goal with|

[ H : ` ] ) generalize (inj pair2 H ); clear H
end; crush).

Hint Extern 1 ( = @ ) ) simpl.

This is the point where we need to do induction over functions, in the form of expressions
E. The judgment Closed provides the perfect framework; we induct over Closed derivations.

Lemma progress' : 8 t (E : Exp t ),

320

Closed E!

Val E . 9 E', E ==? E'.
induction 1; crush;

repeat match goal with|

[ H : Val ` ] ) inversion H ; []; clear H ; my crush'
end; eauto 6.
Qed.

Our o/nal proof of progress makes one top-level use of the axiom closed that we asserted
above.

Theorem progress : 8 t (E : Exp t ),

Val E . 9 E', E ==? E'.
intros; apply progress'; apply closed .
Qed.

17.4 Big-Step Semantics
Another standard exercise in operational semantics is proving the equivalence of small-step
and big-step semantics. We can carry out this exercise for our PHOAS lambda calculus.
Most of the steps are just as pleasant as in the previous section, but things get complicated
near to the end.

We must start by deo/ning the big-step semantics itself. The deo/nition is completely
standard.

Reserved Notation "E1 ===? E2" (no associativity, at level 90).
Inductive BigStep : 8 t, Exp t ! Exp t ! Prop :=|

SConst : 8 n,

Const n ===? Const n|
SPlus : 8 E1 E2 n1 n2,

E1 ===? Const n1!

E2 ===? Const n2!
Plus E1 E2 ===? Const (n1 + n2 )

| SApp : 8 dom ran (E1 : Exp (dom *? ran)) E2 B V2 V,

E1 ===? Abs B!

E2 ===? V2!
Subst V2 B ===? V!
App E1 E2 ===? V|
SAbs : 8 dom ran (B : Exp1 dom ran),

Abs B ===? Abs B

where "E1 ===? E2" := (BigStep E1 E2 ).

321

Hint Constructors BigStep.

To prove a crucial intermediate lemma, we will want to name the transitive-reAEexive
closure of the small-step relation.

Reserved Notation "E1 ==?* E2" (no associativity, at level 90).
Inductive MultiStep : 8 t, Exp t ! Exp t ! Prop :=|

Done : 8 t (E : Exp t ), E ==?* E|
OneStep : 8 t (E E' Ej : Exp t ),

E ==? E'!

E' ==?* Ej!
E ==?* Ej

where "E1 ==?* E2" := (MultiStep E1 E2 ).
Hint Constructors MultiStep.

A few basic properties of evaluation and values admit easy proofs.
Theorem MultiStep trans : 8 t (E1 E2 E3 : Exp t ),

E1 ==?* E2!

E2 ==?* E3!
E1 ==?* E3.
induction 1; eauto.
Qed.

Theorem Big Val : 8 t (E V : Exp t ),

E ===? V!

Val V.
induction 1; crush.
Qed.

Theorem Val Big : 8 t (V : Exp t ),

Val V!

V ===? V.
destruct 1; crush.
Qed.

Hint Resolve Big Val Val Big.

Another useful property deals with pushing multi-step evaluation inside of contexts.
Lemma Multi Cong : 8 t t' (C : Ctx t t' ),

isCtx C! 8

E E', E ==?* E'!

C @ E ==?* C @ E'.
induction 2; crush; eauto.
Qed.

Lemma Multi Cong' : 8 t t' (C : Ctx t t' ) E1 E2 E E',

322

isCtx C!

E1 = C @ E!
E2 = C @ E'!
E ==?* E'!
E1 ==?* E2.
crush; apply Multi Cong; auto.
Qed.

Hint Resolve Multi Cong'.

Unrestricted use of transitivity of ==?* can lead to very large eauto search spaces, which
has very inconvenient eOEciency consequences. Instead, we deo/ne a special tactic mtrans that
tries applying transitivity with a particular intermediate expression.

Ltac mtrans E :=

match goal with|

[ ` E ==?* ] ) fail 1| )

apply MultiStep trans with E ; [ solve [ eauto ] | eauto ]
end.

With mtrans, we can give a reasonably short proof of one direction of the equivalence
between big-step and small-step semantics. We include proof cases specio/c to rules of the
big-step semantics, since leaving the details to eauto would lead to a very slow proof script.
The use of solve in mtrans 's deo/nition keeps us from going down unfruitful paths.

Theorem Big Multi : 8 t (E V : Exp t ),

E ===? V!

E ==?* V.
induction 1; crush; eauto;

repeat match goal with|

[ n1 : , E2 : ` ] ) mtrans (Plus (Const n1 ) E2 )|
[ n1 : , n2 : ` ] ) mtrans (Plus (Const n1 ) (Const n2 ))|
[ B : , E2 : ` ] ) mtrans (App (Abs B ) E2 )
end.
Qed.

We are almost ready to prove the other direction of the equivalence. First, we wrap an
earlier lemma in a form that will work better with eauto.

Lemma Big Val' : 8 t (V1 V2 : Exp t ),

Val V2!

V1 = V2!
V1 ===? V2.
crush.
Qed.

Hint Resolve Big Val'.

Now we build some quite involved tactic support for reasoning about equalities over

323

PHOAS terms. First, we will call equate conj F G to determine the consequences of an
equality F = G. When F = f e 1 ... e n and G = f e' 1 ... e' n, equate conj will return a
conjunction e 1 = e' 1 ^ ... ^ e n = e' n. We hardcode a pattern for each value of n from
1 to 5.

Ltac equate conj F G :=

match constr :(F, G ) with|

( ?x1, ?x2) ) constr :(x1 = x2 )|
( ?x1 ?y1, ?x2 ?y2) ) constr :(x1 = x2 ^ y1 = y2 )|
( ?x1 ?y1 ?z1, ?x2 ?y2 ?z2) ) constr :(x1 = x2 ^ y1 = y2 ^ z1 = z2 )|
( ?x1 ?y1 ?z1 ?u1, ?x2 ?y2 ?z2 ?u2) )

constr :(x1 = x2 ^ y1 = y2 ^ z1 = z2 ^ u1 = u2 )|
( ?x1 ?y1 ?z1 ?u1 ?v1, ?x2 ?y2 ?z2 ?u2 ?v2) )

constr :(x1 = x2 ^ y1 = y2 ^ z1 = z2 ^ u1 = u2 ^ v1 = v2 )
end.

The main tactic is my crush, which generalizes our earlier my crush' by performing in-
version on hypotheses that equate PHOAS terms. Coq's built-in inversion is only designed
to be useful on equalities over inductive types. PHOAS terms are functions, so inversion
is not very helpful on them. To perform the equivalent of discriminate, we instantiate the
terms with var as fun ) unit and then appeal to normal discriminate. This eliminates
some contradictory cases. To perform the equivalent of injection, we must consider all
possible var instantiations. Some fairly intricate logic strings together these elements. The
details are not worth discussing, since our conclusion will be that one should avoid dealing
with proofs of facts like this one.

Ltac my crush :=

my crush' ;
repeat (match goal with|

[ H : ?F = ?G ` ] )

(let H' := fresh "H'" in

assert (H' : F (fun ) unit) = G (fun ) unit)); [ congruence|

discriminate || injection H' ; clear H' ];
my crush' ;
repeat match goal with|

[ H : context [fun ) unit] ` ] ) clear H
end;
match type of H with|

?F = ?G )

let ec := equate conj F G in

let var := fresh "var" in

assert ec; [ intuition; unfold Exp; apply ext eq; intro var ;

assert (H' : F var = G var ); try congruence;

match type of H' with|

?X = ?Y )

324

let X := eval hnf in X in

let Y := eval hnf in Y in

change (X = Y ) in H'
end; injection H' ; my crush' ; tauto|
intuition; subst ]
end);
clear H
end; my crush' );
my crush'.

With that complicated tactic available, the proof of the main lemma is straightforward.
Lemma Multi Big' : 8 t (E E' : Exp t ),

E ==? E'! 8

Ej, E' ===? Ej!

E ===? Ej.
induction 1; crush; eauto;

match goal with|

[ H : ===? ` ] ) inversion H ; my crush; eauto
end;
match goal with|

[ H : isCtx ` ] ) inversion H ; my crush; eauto
end.
Qed.

Hint Resolve Multi Big'.

The other direction of the overall equivalence follows as an easy corollary.
Theorem Multi Big : 8 t (E V : Exp t ),

E ==?* V!

Val V!
E ===? V.
induction 1; crush; eauto.
Qed.

The lesson here is that working directly with PHOAS terms can easily lead to extremely
intricate proofs. It is usually a better idea to stick to inductive proofs about instantiated
PHOAS terms; in the case of this example, that means proofs about exp instead of Exp. Such
results can usually be wrapped into results about Exp without further induction. Dioeerent
theorems demand dioeerent variants of this underlying advice, and we will consider several
of them in the chapters to come.

325

Chapter 18
Type-Theoretic Interpreters

Throughout this book, we have given semantics for programming languages via executable
interpreters written in Gallina. PHOAS is quite compatible with that model, when we
want to formalize many of the wide variety of interesting non-Turing-complete programming
languages. Most such languages have very straightforward elaborations into Gallina. In
this chapter, we show how to extend our past approach to higher-order languages encoded
with PHOAS, and we show how simple program transformations may be proved correct with
respect to these elaborative semantics.

18.1 Simply-Typed Lambda Calculus
We begin with a copy of last chapter's encoding of the syntax of simply-typed lambda calculus
with natural numbers and addition. The primes at the ends of constructor names are gone,
since here our primary subject is exps instead of Exps.

Module STLC.

Inductive type : Type :=|

Nat : type|
Arrow : type ! type ! type.

Infix "*?" := Arrow (right associativity, at level 60).
Section vars.

Variable var : type ! Type.

Inductive exp : type ! Type :=|

Var : 8 t,

var t!

exp t

| Const : nat ! exp Nat|

Plus : exp Nat ! exp Nat ! exp Nat

326

| App : 8 t1 t2,

exp (t1 *? t2 )!

exp t1!
exp t2|
Abs : 8 t1 t2,

(var t1 ! exp t2 )!

exp (t1 *? t2 ).
End vars.

Definition Exp t := 8 var, exp var t.
Implicit Arguments Var [var t ].
Implicit Arguments Const [var ].
Implicit Arguments Plus [var ].
Implicit Arguments App [var t1 t2 ].
Implicit Arguments Abs [var t1 t2 ].

The deo/nitions that follow will be easier to read if we deo/ne some parsing notations for
the constructors.

Notation "# v" := (Var v ) (at level 70).
Notation "*) n" := (Const n) (at level 70).
Infix "+\Theta " := Plus (left associativity, at level 79).

Infix "@" := App (left associativity, at level 77).
Notation "" x , e" := (Abs (fun x ) e)) (at level 78).
Notation "" ! , e" := (Abs (fun ) e)) (at level 78).

A few examples will be useful for testing the functions we will write.
Example zero : Exp Nat := fun ) *)0.
Example one : Exp Nat := fun ) *)1.
Example zpo : Exp Nat := fun ) zero +\Theta  one .
Example ident : Exp (Nat *? Nat) := fun ) "x, #x.
Example app ident : Exp Nat := fun ) ident @ zpo .
Example app : Exp ((Nat *? Nat) *? Nat *? Nat) := fun ) "f, "x, #f @ #x.
Example app ident' : Exp Nat := fun ) app @ ident @ zpo .

To write our interpreter, we must o/rst interpret object language types as meta language
types.

Fixpoint typeDenote (t : type) : Set :=

match t with|

Nat ) nat|
t1 *? t2 ) typeDenote t1 ! typeDenote t2
end.

The crucial trick of the expression interpreter is to represent variables using the typeDe-
note function. Due to limitations in Coq's syntax extension system, we cannot take advantage

327

of some of our notations when they appear in patterns, so, to be consistent, in patterns we
avoid notations altogether.

Fixpoint expDenote t (e : exp typeDenote t ) : typeDenote t :=

match e with|

Var v ) v

| Const n ) n|

Plus e1 e2 ) expDenote e1 + expDenote e2

| App e1 e2 ) (expDenote e1 ) (expDenote e2 )|

Abs e' ) fun x ) expDenote (e' x )
end.

Definition ExpDenote t (e : Exp t ) := expDenote (e ).

Some tests establish that ExpDenote produces Gallina terms like we might write manu-
ally.

Eval compute in ExpDenote zero.

= 0
: typeDenote Nat

Eval compute in ExpDenote one.

= 1
: typeDenote Nat

Eval compute in ExpDenote zpo.

= 1
: typeDenote Nat

Eval compute in ExpDenote ident.

= fun x : nat ) x
: typeDenote (Nat *? Nat)

Eval compute in ExpDenote app ident.

= 1
: typeDenote Nat

Eval compute in ExpDenote app.

= fun (x : nat ! nat) (x0 : nat) ) x x0
: typeDenote ((Nat *? Nat) *? Nat *? Nat)

Eval compute in ExpDenote app ident'.

= 1
: typeDenote Nat

We can update to the higher-order case our common example of a constant folding
function. The workhorse function cfold is parameterized to apply to an exp that uses any

328

var type. An output of cfold uses the same var type as the input. As in the deo/nition of
expDenote, we cannot use most of our notations in patterns, but we use them freely to make
the bodies of match cases easier to read.

Section cfold.

Variable var : type ! Type.

Fixpoint cfold t (e : exp var t ) : exp var t :=

match e with|

Var v ) #v

| Const n ) \Theta n|

Plus e1 e2 )

let e1' := cfold e1 in
let e2' := cfold e2 in
match e1', e2' return with|

Const n1, Const n2 ) \Theta (n1 + n2 )|

, ) e1' +\Theta  e2'
end

| App e1 e2 ) cfold e1 @ cfold e2|

Abs e' ) "x, cfold (e' x )
end.
End cfold.

Definition Cfold t (E : Exp t ) : Exp t := fun ) cfold (E ).

Now we would like to prove the correctness of Cfold, which follows from a simple inductive
lemma about cfold.

Lemma cfold correct : 8 t (e : exp t ),

expDenote (cfold e) = expDenote e.
induction e; crush; try (ext eq; crush);

repeat (match goal with|

[ ` context [cfold ?E] ] ) dep destruct (cfold E )
end; crush).
Qed.

Theorem Cfold correct : 8 t (E : Exp t ),

ExpDenote (Cfold E ) = ExpDenote E.
unfold ExpDenote, Cfold ; intros; apply cfold correct.
Qed.
End STLC.

329

18.2 Adding Products and Sums
The example is easily adapted to support products and sums, the basis of non-recursive
datatypes in ML and Haskell.

Module PSLC.

Inductive type : Type :=|

Nat : type|
Arrow : type ! type ! type|
Prod : type ! type ! type|
Sum : type ! type ! type.

Infix "*?" := Arrow (right associativity, at level 62).
Infix "**" := Prod (right associativity, at level 61).
Infix "++" := Sum (right associativity, at level 60).

Section vars.

Variable var : type ! Type.

Inductive exp : type ! Type :=|

Var : 8 t,

var t!

exp t

| Const : nat ! exp Nat|

Plus : exp Nat ! exp Nat ! exp Nat

| App : 8 t1 t2,

exp (t1 *? t2 )!

exp t1!
exp t2|
Abs : 8 t1 t2,

(var t1 ! exp t2 )!

exp (t1 *? t2 )

| Pair : 8 t1 t2,

exp t1!

exp t2!
exp (t1 ** t2 )|
Fst : 8 t1 t2,

exp (t1 ** t2 )!

exp t1|
Snd : 8 t1 t2,

exp (t1 ** t2 )!

exp t2

330

| Inl : 8 t1 t2,

exp t1!

exp (t1 ++ t2 )|
Inr : 8 t1 t2,

exp t2!

exp (t1 ++ t2 )|
SumCase : 8 t1 t2 t,

exp (t1 ++ t2 )!

(var t1 ! exp t )!
(var t2 ! exp t )!
exp t.
End vars.

Definition Exp t := 8 var, exp var t.
Implicit Arguments Var [var t ].
Implicit Arguments Const [var ].
Implicit Arguments Abs [var t1 t2 ].
Implicit Arguments Inl [var t1 t2 ].
Implicit Arguments Inr [var t1 t2 ].

Notation "# v" := (Var v ) (at level 70).
Notation "*) n" := (Const n) (at level 70).
Infix "+\Theta " := Plus (left associativity, at level 78).

Infix "@" := App (left associativity, at level 77).
Notation "" x , e" := (Abs (fun x ) e)) (at level 78).
Notation "" ! , e" := (Abs (fun ) e)) (at level 78).

Notation "[ e1 , e2 ]" := (Pair e1 e2 ).
Notation "#1 e" := (Fst e) (at level 75).
Notation "#2 e" := (Snd e) (at level 75).

Notation "'case' e 'of' x ) e1 | y ) e2" := (SumCase e (fun x ) e1 ) (fun y ) e2 ))

(at level 79).

A few examples can be deo/ned easily, using the notations above.
Example swap : Exp (Nat ** Nat *? Nat ** Nat) := fun ) "p, [#2 #p, #1 #p].
Example zo : Exp (Nat ** Nat) := fun ) [*)0, *)1].
Example swap zo : Exp (Nat ** Nat) := fun ) swap @ zo .

Example natOut : Exp (Nat ++ Nat *? Nat) := fun )

"s, case #s of x ) #x | y ) #y +\Theta  #y.
Example ns1 : Exp (Nat ++ Nat) := fun ) Inl (*)3).
Example ns2 : Exp (Nat ++ Nat) := fun ) Inr (*)5).
Example natOut ns1 : Exp Nat := fun ) natOut @ ns1 .
Example natOut ns2 : Exp Nat := fun ) natOut @ ns2 .

331

The semantics adapts without incident.
Fixpoint typeDenote (t : type) : Set :=

match t with|

Nat ) nat|
t1 *? t2 ) typeDenote t1 ! typeDenote t2|
t1 ** t2 ) typeDenote t1 * typeDenote t2|
t1 ++ t2 ) typeDenote t1 + typeDenote t2
end%type.

Fixpoint expDenote t (e : exp typeDenote t ) : typeDenote t :=

match e with|

Var v ) v

| Const n ) n|

Plus e1 e2 ) expDenote e1 + expDenote e2

| App e1 e2 ) (expDenote e1 ) (expDenote e2 )|

Abs e' ) fun x ) expDenote (e' x )

| Pair e1 e2 ) (expDenote e1, expDenote e2 )|

Fst e' ) fst (expDenote e' )|
Snd e' ) snd (expDenote e' )

| Inl e' ) inl (expDenote e' )|

Inr e' ) inr (expDenote e' )|
SumCase e' e1 e2 )

match expDenote e' with|

inl v ) expDenote (e1 v )|
inr v ) expDenote (e2 v )
end
end.

Definition ExpDenote t (e : Exp t ) := expDenote (e ).
Eval compute in ExpDenote swap.

= fun x : nat * nat ) (let ( , y ) := x in y, let (x0, ) := x in x0 )
: typeDenote (Nat ** Nat *? Nat ** Nat)

Eval compute in ExpDenote zo.

= (0, 1)
: typeDenote (Nat ** Nat)

Eval compute in ExpDenote swap zo.

= (1, 0)
: typeDenote (Nat ** Nat)

332

Eval cbv beta iota delta -[plus] in ExpDenote natOut.

= fun x : nat + nat ) match x with|

inl v ) v|
inr v ) v + v
end
: typeDenote (Nat ++ Nat *? Nat)

Eval compute in ExpDenote ns1.

= inl nat 3
: typeDenote (Nat ++ Nat)

Eval compute in ExpDenote ns2.

= inr nat 5
: typeDenote (Nat ++ Nat)

Eval compute in ExpDenote natOut ns1.

= 3
: typeDenote Nat

Eval compute in ExpDenote natOut ns2.

= 10
: typeDenote Nat

We adapt the cfold function using the same basic dependent-types trick that we applied
in an earlier chapter to a very similar function for a language without variables.

Section cfold.

Variable var : type ! Type.

Definition pairOutType t :=

match t return Type with|

t1 ** t2 ) option (exp var t1 * exp var t2 )| )

unit
end.

Definition pairOutDefault (t : type) : pairOutType t :=

match t with|

** ) None| )

tt
end.

Definition pairOut t1 t2 (e : exp var (t1 ** t2 ))

: option (exp var t1 * exp var t2 ) :=
match e in exp t return pairOutType t with|

Pair e1 e2 ) Some (e1, e2 )| )

pairOutDefault
end.

Fixpoint cfold t (e : exp var t ) : exp var t :=

333

match e with|

Var v ) #v

| Const n ) \Theta n|

Plus e1 e2 )

let e1' := cfold e1 in
let e2' := cfold e2 in
match e1', e2' return with|

Const n1, Const n2 ) \Theta (n1 + n2 )|

, ) e1' +\Theta  e2'
end

| App e1 e2 ) cfold e1 @ cfold e2|

Abs e' ) "x, cfold (e' x )

| Pair e1 e2 ) [cfold e1, cfold e2 ]|

Fst t1 e' )

let ej := cfold e' in

match pairOut ej with|

None ) #1 ej|
Some (e1, ) ) e1
end|
Snd e' )

let ej := cfold e' in

match pairOut ej with|

None ) #2 ej|
Some ( , e2 ) ) e2
end

| Inl e' ) Inl (cfold e' )|

Inr e' ) Inr (cfold e' )|
SumCase e' e1 e2 )

case cfold e' of

x ) cfold (e1 x )|
y ) cfold (e2 y )
end.
End cfold.

Definition Cfold t (E : Exp t ) : Exp t := fun ) cfold (E ).

The proofs are almost as straightforward as before. We o/rst establish two simple theorems
about pairs and their projections.

Section pairs.

Variables A B : Type.

334

Variable v1 : A.
Variable v2 : B.
Variable v : A * B.

Theorem pair eta1 : (v1, v2 ) = v ! v1 = fst v.

destruct v ; crush.
Qed.

Theorem pair eta2 : (v1, v2 ) = v ! v2 = snd v.

destruct v ; crush.
Qed.
End pairs.

Hint Resolve pair eta1 pair eta2.

To the proof script for the main lemma, we add just one more match case, detecting when
case analysis is appropriate on discriminees of matches over sum types.

Lemma cfold correct : 8 t (e : exp t ),

expDenote (cfold e) = expDenote e.
induction e; crush; try (ext eq; crush);

repeat (match goal with|

[ ` context [cfold ?E] ] ) dep destruct (cfold E )|
[ ` match ?E with inl ) | inr ) end = ] ) destruct E
end; crush); eauto.
Qed.

Theorem Cfold correct : 8 t (E : Exp t ),

ExpDenote (Cfold E ) = ExpDenote E.
unfold ExpDenote, Cfold ; intros; apply cfold correct.
Qed.
End PSLC.

335

Chapter 19
Extensional Transformations

Last chapter's constant folding example was particularly easy to verify, because that trans-
formation used the same source and target language. In this chapter, we verify a dioeerent
translation, illustrating the added complexities in translating between languages.

Program transformations can be classio/ed as intensional, when they require some no-
tion of inequality between variables; or extensional, otherwise. This chapter's example is
extensional, and the next chapter deals with the trickier intensional case.

19.1 CPS Conversion for Simply-Typed Lambda Calcu-

lus

A convenient method for compiling functional programs begins with conversion to continuation-
passing style, or CPS. In this restricted form, function calls never return; instead, we pass
explicit return pointers, much as in assembly language. Additionally, we make order of
evaluation explicit, breaking complex expressions into sequences of primitive operations.

Our translation will operate over the same source language that we used in the o/rst
part of last chapter, so we omit most of the language deo/nition. However, we do make one
signio/cant change: since we will be working with multiple languages that involve similar
constructs, we use Coq's notation scope mechanism to disambiguate. For instance, the span
of code dealing with type notations looks like this:

Notation "'Nat'" := TNat : source scope.
Infix "*?" := Arrow (right associativity, at level 60) : source scope.

Open Scope source scope.
Bind Scope source scope with type.
Delimit Scope source scope with source.

We explicitly place our notations inside a scope named source scope, and we associate a
delimiting key source with source scope. Without further commands, our notations would
only be used in expressions like (...)%source. We also open our scope locally within this

336

module, so that we avoid repeating %source in many places. Further, we bind our scope to
type. In some circumstances where Coq is able to infer that some subexpression has type
type, that subexpression will automatically be parsed in source scope.

The other critical new ingredient is a generalization of the Closed relation from two
chapters ago. The new relation exp equiv characters when two expressions may be con-
sidered syntactically equal. We need to be able to handle cases where each expression uses
a dioeerent var type. Intuitively, we will want to compare expressions that use their vari-
ables to store source-level and target-level values. We express pairs of equivalent variables
using a list parameter to the relation; variable expressions will be considered equivalent if
and only if their variables belong to this list. The rule for function abstraction extends the
list in a higher-order way. The remaining rules just implement the obvious congruence over
expressions.

Section exp equiv.

Variables var1 var2 : type ! Type.

Inductive exp equiv : list - t : type & var1 t * var2 t ""%type! 8

t, exp var1 t ! exp var2 t ! Prop :=|
EqVar : 8 G t (v1 : var1 t ) v2,

In (existT t (v1, v2 )) G!

exp equiv G (#v1) (#v2)

| EqConst : 8 G n,

exp equiv G (\Theta n) (\Theta n)|
EqPlus : 8 G x1 y1 x2 y2,

exp equiv G x1 x2!

exp equiv G y1 y2!
exp equiv G (x1 +\Theta  y1 ) (x2 +\Theta  y2 )

| EqApp : 8 G t1 t2 (f1 : exp (t1 *? t2 )) (x1 : exp t1 ) f2 x2,

exp equiv G f1 f2!

exp equiv G x1 x2!
exp equiv G (f1 @ x1 ) (f2 @ x2 )|
EqAbs : 8 G t1 t2 (f1 : var1 t1 ! exp var1 t2 ) f2,

(8 v1 v2, exp equiv (existT t1 (v1, v2 ) :: G ) (f1 v1 ) (f2 v2 ))!

exp equiv G (Abs f1 ) (Abs f2 ).
End exp equiv.

It turns out that, for any parametric expression E, any two instantiations of E with
particular var types must be equivalent, with respect to an empty variable list. The para-
metricity of Gallina guarantees this, in much the same way that it guaranteed the truth of
the axiom about Closed. Thus, we assert an analogous axiom here.

Axiom Exp equiv : 8 t (E : Exp t ) var1 var2,

exp equiv nil (E var1 ) (E var2 ).

337

End Source.

Now we need to deo/ne the CPS language, where binary function types are replaced with
unary continuation types, and we add product types because they will be useful in our
translation.

Module CPS.

Inductive type : Type :=|

TNat : type|
Cont : type ! type|
Prod : type ! type ! type.

Notation "'Nat'" := TNat : cps scope.
Notation "t _?" := (Cont t ) (at level 61) : cps scope.
Infix "**" := Prod (right associativity, at level 60) : cps scope.

Bind Scope cps scope with type.
Delimit Scope cps scope with cps.

Section vars.

Variable var : type ! Type.

A CPS program is a series of bindings of primitive operations (primops), followed by
either a halt with a o/nal program result or by a call to a continuation. The arguments to
these program-ending operations are enforced to be variables. To use the values of compound
expressions instead, those expressions must be decomposed into bindings of primops. The
primop language itself similarly forces variables for all arguments besides bodies of function
abstractions.

Inductive prog : Type :=|

PHalt :

var Nat!

prog|
App : 8 t,

var (t _?)!

var t!
prog|
Bind : 8 t,

primop t!

(var t ! prog)!
prog

with primop : type ! Type :=|

Const : nat ! primop Nat|
Plus : var Nat ! var Nat ! primop Nat

| Abs : 8 t,

(var t ! prog)

338

! primop (t _?)
| Pair : 8 t1 t2,

var t1!

var t2!
primop (t1 ** t2 )|
Fst : 8 t1 t2,

var (t1 ** t2 )!

primop t1|
Snd : 8 t1 t2,

var (t1 ** t2 )!

primop t2.
End vars.

Implicit Arguments PHalt [var ].
Implicit Arguments App [var t ].

Implicit Arguments Const [var ].
Implicit Arguments Plus [var ].
Implicit Arguments Abs [var t ].
Implicit Arguments Pair [var t1 t2 ].
Implicit Arguments Fst [var t1 t2 ].
Implicit Arguments Snd [var t1 t2 ].

Notation "'Halt' x" := (PHalt x ) (no associativity, at level 75) : cps scope.
Infix "@@" := App (no associativity, at level 75) : cps scope.
Notation "x  p ; e" := (Bind p (fun x ) e))

(right associativity, at level 76, p at next level ) : cps scope.
Notation "!  p ; e" := (Bind p (fun ) e))

(right associativity, at level 76, p at next level ) : cps scope.

Notation "*) n" := (Const n) (at level 70) : cps scope.
Infix "+\Theta " := Plus (left associativity, at level 79) : cps scope.

Notation "" x , e" := (Abs (fun x ) e)) (at level 78) : cps scope.
Notation "" ! , e" := (Abs (fun ) e)) (at level 78) : cps scope.

Notation "[ x1 , x2 ]" := (Pair x1 x2 ) : cps scope.
Notation "#1 x" := (Fst x ) (at level 72) : cps scope.
Notation "#2 x" := (Snd x ) (at level 72) : cps scope.

Bind Scope cps scope with prog primop.
Open Scope cps scope.

In interpreting types, we treat continuations as functions with codomain nat, choosing
nat as our arbitrary program result type.

Fixpoint typeDenote (t : type) : Set :=

match t with

339

| Nat ) nat|

t' _? ) typeDenote t' ! nat|
t1 ** t2 ) (typeDenote t1 * typeDenote t2 )%type
end.

A mutually-recursive deo/nition establishes the meanings of programs and primops.
Fixpoint progDenote (e : prog typeDenote) : nat :=

match e with|

PHalt n ) n|
App f x ) f x|
Bind p x ) progDenote (x (primopDenote p))
end

with primopDenote t (p : primop typeDenote t ) : typeDenote t :=

match p with|

Const n ) n|
Plus n1 n2 ) n1 + n2

| Abs e ) fun x ) progDenote (e x )
| Pair v1 v2 ) (v1, v2 )|

Fst v ) fst v|
Snd v ) snd v
end.

Definition Prog := 8 var, prog var.
Definition Primop t := 8 var, primop var t.
Definition ProgDenote (E : Prog) := progDenote (E ).
Definition PrimopDenote t (P : Primop t ) := primopDenote (P ).
End CPS.

Import Source CPS.

The translation itself begins with a type-level compilation function. We change every
function into a continuation whose argument is a pair, consisting of the translation of the
original argument and of an explicit return pointer.

Fixpoint cpsType (t : Source.type) : CPS.type :=

match t with|

Nat ) Nat %cps|
t1 *? t2 ) (cpsType t1 ** (cpsType t2 _?) _?)%cps
end%source.

Now we can deo/ne the expression translation. The notation x - e1 ; e2 stands for
translating source-level expression e1 , binding x to the CPS-level result of running the
translated program, and then evaluating CPS-level expression e2 in that context.

Reserved Notation "x - e1 ; e2" (right associativity, at level 76, e1 at next level ).

340

Section cpsExp.

Variable var : CPS.type ! Type.

Import Source.
Open Scope cps scope.

We implement a well-known variety of higher-order, one-pass CPS translation. The
translation cpsExp is parameterized not only by the expression e to translate, but also by a
meta-level continuation. The idea is that cpsExp evaluates the translation of e and calls the
continuation on the result. With this convention, cpsExp itself is a natural match for the
notation we just reserved.

Fixpoint cpsExp t (e : exp (fun t ) var (cpsType t )) t )

: (var (cpsType t ) ! prog var ) ! prog var :=
match e with|

Var v ) fun k ) k v

| Const n ) fun k )

x  \Theta n;
k x|
Plus e1 e2 ) fun k )

x1 - e1 ;
x2 - e2 ;
x  x1 +\Theta  x2 ;
k x

| App e1 e2 ) fun k )

f - e1 ;
x - e2 ;
kf  "r, k r ;
p  [x, kf ];
f @@ p|
Abs e' ) fun k )

f  CPS.Abs (var := var ) (fun p )

x  #1 p;
kf  #2 p;
r - e' x ;
kf @@ r );
k f
end

where "x - e1 ; e2" := (cpsExp e1 (fun x ) e2 )).
End cpsExp.

Since notations do not survive the closing of sections, we redeo/ne the notation associated

341

with cpsExp.
Notation "x - e1 ; e2" := (cpsExp e1 (fun x ) e2 )) : cps scope.
Implicit Arguments cpsExp [var t ].

We wrap cpsExp into the parametric version CpsExp, passing an always-halt continuation
at the root of the recursion.

Definition CpsExp (E : Exp Nat ) : Prog :=

fun ) cpsExp (E ) (PHalt (var := )).

Eval compute in CpsExp zero.

= fun var : type ! Type ) x  *)0; Halt x
: Prog

Eval compute in CpsExp one.

= fun var : type ! Type ) x  *)1; Halt x
: Prog

Eval compute in CpsExp zpo.

= fun var : type ! Type ) x  *)0; x0  *)1; x1  (x +\Theta  x0 ); Halt x1
: Prog

Eval compute in CpsExp app ident.

= fun var : type ! Type )

f  (" p, x  #1 p; kf  #2 p; kf @@ x );
x  *)0;
x0  *)1; x1  (x +\Theta  x0 ); kf  (" r, Halt r ); p  [x1, kf ]; f @@ p
: Prog

Eval compute in CpsExp app ident'.

= fun var : type ! Type )

f 
(" p,

x  #1 p;
kf  #2 p;
f 
(" p0,

x0  #1 p0 ;
kf0  #2 p0 ; kf1  (" r, kf0 @@ r ); p1  [x0, kf1 ]; x @@ p1 );
kf @@ f);
f0  (" p, x  #1 p; kf  #2 p; kf @@ x );
kf 
(" r,

x  *)0;
x0  *)1;
x1  (x +\Theta  x0 ); kf  (" r0, Halt r0 ); p  [x1, kf ]; r @@ p);

342

p  [f0, kf ]; f @@ p
: Prog

Eval compute in ProgDenote (CpsExp zero).

= 0
: nat

Eval compute in ProgDenote (CpsExp one).

= 1
: nat

Eval compute in ProgDenote (CpsExp zpo).

= 1
: nat

Eval compute in ProgDenote (CpsExp app ident).

= 1
: nat

Eval compute in ProgDenote (CpsExp app ident').

= 1
: nat

Our main inductive lemma about cpsExp needs a notion of compatibility between source-
level and CPS-level values. We express compatibility with a logical relation; that is, we
deo/ne a binary relation by recursion on type structure, and the function case of the relation
considers functions related if they map related arguments to related results. In detail, the
function case is slightly more complicated, since it must deal with our continuation-based
calling convention.

Fixpoint lr (t : Source.type)

: Source.typeDenote t ! CPS.typeDenote (cpsType t ) ! Prop :=
match t with|

Nat ) fun n1 n2 ) n1 = n2|
t1 *? t2 ) fun f1 f2 )8

x1 x2, lr x1 x2! 8

k, 9 r,
f2 (x2, k ) = k r^

lr (f1 x1 ) r
end%source.

The main lemma is now easily stated and proved. The most surprising aspect of the
statement is the presence of two versions of the expression to be compiled. The o/rst, e1 ,
uses a var choice that makes it a suitable argument to expDenote. The second expression, e2,
uses a var choice that makes its compilation, cpsExp e2 k, a suitable argument to progDenote.
We use exp equiv to assert that e1 and e2 have the same underlying structure, up to a
variable correspondence list G. A hypothesis about G ensures that all of its pairs of variables

343

belong to the logical relation lr. We also use lr, in concert with some quantio/cation over
continuations and program results, in the conclusion of the lemma.

The lemma's proof should be unsurprising by now. It uses our standard bag of Ltac
tricks to help out with quantio/er instantiation; crush and eauto can handle the rest.

Lemma cpsExp correct : 8 G t (e1 : exp t ) (e2 : exp t ),

exp equiv G e1 e2!

(8 t v1 v2, In (existT t (v1, v2 )) G ! lr t v1 v2 )! 8

k, 9 r,
progDenote (cpsExp e2 k ) = progDenote (k r )^

lr t (expDenote e1 ) r.
induction 1; crush;

repeat (match goal with|

[ H : 8 k, 9 r, progDenote (cpsExp ?E k ) = ^`

context [cpsExp ?E ?K] ] )
generalize (H K ); clear H|
[ ` 9 r, progDenote ( ?R) = progDenote ( r ) ^ ] )9

R|
[ t1 : Source.type ` ] )

match goal with|

[ Hlr : lr t1 ?X1 ?X2, IH : 8 v1 v2, ` ] )

generalize (IH X1 X2 ); clear IH ; intro IH ;

match type of IH with|

?P ! ) assert P
end
end
end; crush); eauto.
Qed.

A simple lemma establishes the degenerate case of cpsExp correct's hypothesis about G.
Lemma vars easy : 8 t v1 v2,

In (existT (fun t0 ) (Source.typeDenote t0 * typeDenote (cpsType t0 ))%type) t

(v1, v2 )) nil ! lr t v1 v2.
crush.
Qed.

A manual application of cpsExp correct proves a version applicable to CpsExp. This is
where we use the axiom Exp equiv .

Theorem CpsExp correct : 8 (E : Exp Nat ),

ProgDenote (CpsExp E ) = ExpDenote E.
unfold ProgDenote, CpsExp, ExpDenote; intros;

generalize (cpsExp correct (e1 := E ) (e2 := E )

(Exp equiv ) vars easy (PHalt (var := ))); crush.
Qed.

344

19.2 Exercises

1. When in the last chapter we implemented constant folding for simply-typed lambda

calculus, it may have seemed natural to try applying beta reductions. This would have
been a lot more trouble than is apparent at o/rst, because we would have needed to
convince Coq that our normalizing function always terminated.

It might also seem that beta reduction is a lost cause because we have no eoeective way
of substituting in the exp type; we only managed to write a substitution function for
the parametric Exp type. This is not as big of a problem as it seems. For instance, for
the language we built by extending simply-typed lambda calculus with products and
sums, it also appears that we need substitution for simplifying case expressions whose
discriminees are known to be inl or inr, but the function is still implementable.

For this exercise, extend the products and sums constant folder from the last chapter so
that it simplio/es case expressions as well, by checking if the discriminee is a known inl
or known inr. Also extend the correctness theorem to apply to your new deo/nition. You
will probably want to assert an axiom relating to an expression equivalence relation
like the one deo/ned in this chapter. Any such axiom should only mention syntax; it
should not mention any compilation or denotation functions. Following the format of
the axiom from the last chapter is the safest bet to avoid proving a worthless theorem.

345

Chapter 20
Intensional Transformations

The essential beneo/t of higher-order encodings is that variable contexts are implicit. We rep-
resent the object language's contexts within the meta language's contexts. For translations
like CPS conversion, this is a clear win, since such translations do not need to keep track
of details of which variables are available. Other important translations, including closure
conversion, need to work with variables as o/rst-class, analyzable values.

Another example is conversion from PHOAS terms to de Bruijn terms. The output
format makes the structure of variables explicit, so the translation requires explicit reasoning
about variable identity. In this chapter, we implement verio/ed translations in both directions
between last chapter's PHOAS language and a de Bruijn version of it. Along the way, we
show one approach to avoiding the use of axioms with PHOAS.

The de Bruijn version of simply-typed lambda calculus is deo/ned in a manner that should
be old hat by now.

Module DeBruijn.

Inductive exp : list type ! type ! Type :=|

Var : 8 G t,

member t G!

exp G t

| Const : 8 G, nat ! exp G Nat|

Plus : 8 G, exp G Nat ! exp G Nat ! exp G Nat

| App : 8 G t1 t2,

exp G (t1 *? t2 )!

exp G t1!
exp G t2|
Abs : 8 G t1 t2,

exp (t1 :: G ) t2!

exp G (t1 *? t2 ).

Implicit Arguments Const [G ].

346

Fixpoint expDenote G t (e : exp G t ) : hlist typeDenote G ! typeDenote t :=

match e with|

Var v ) fun s ) hget s v

| Const n ) fun ) n|

Plus e1 e2 ) fun s ) expDenote e1 s + expDenote e2 s

| App e1 e2 ) fun s ) (expDenote e1 s) (expDenote e2 s)|

Abs e' ) fun s x ) expDenote e' (x ::: s)
end.
End DeBruijn.

Import Phoas DeBruijn.

20.1 From De Bruijn to PHOAS
The heart of the translation into PHOAS is this function phoasify, which is parameterized
by an hlist that represents a mapping from de Bruijn variables to PHOAS variables.

Section phoasify.

Variable var : type ! Type.

Fixpoint phoasify G t (e : DeBruijn.exp G t ) : hlist var G ! Phoas.exp var t :=

match e with|

Var v ) fun s ) #(hget s v )

| Const n ) fun ) \Theta n|

Plus e1 e2 ) fun s ) phoasify e1 s +\Theta  phoasify e2 s

| App e1 e2 ) fun s ) phoasify e1 s @ phoasify e2 s|

Abs e' ) fun s ) "x, phoasify e' (x ::: s)
end.
End phoasify.

Definition Phoasify t (e : DeBruijn.exp nil t ) : Phoas.Exp t :=

fun ) phoasify e HNil.

It turns out to be trivial to establish the translation's soundness.
Theorem phoasify sound : 8 G t (e : DeBruijn.exp G t ) s,

Phoas.expDenote (phoasify e s) = DeBruijn.expDenote e s.
induction e; crush; ext eq; crush.
Qed.

We can prove that any output of Phoasify is well-formed, in a sense strong enough to let
us avoid asserting last chapter's axiom.

Print Wf.

347

Wf =
fun (t : type) (E : Exp t ) )8

var1 var2 : type ! Type, exp equiv nil (E var1 ) (E var2 )

: 8 t : type, Exp t ! Prop

Section vars.

Variables var1 var2 : type ! Type.

In the course of proving well-formedness, we will need to translate back and forth between
the de Bruijn and PHOAS representations of free variable information. The function zip
combines two de Bruijn substitutions into a single PHOAS context.

Fixpoint zip G (s1 : hlist var1 G )

: hlist var2 G ! list -t : type & var1 t * var2 t ""%type :=
match s1 with|

HNil ) fun ) nil|
HCons v1 s1' ) fun s2 ) existT (v1, hhd s2 ) :: zip s1' (htl s2 )
end.

Two simple lemmas about zip will make useful hints.
Lemma In zip : 8 t G (s1 : hlist G ) s2 (m : member t G ),

In (existT t (hget s1 m, hget s2 m)) (zip s1 s2 ).
induction s1 ; intro s2 ; dep destruct s2 ; intro m; dep destruct m; crush.
Qed.

Lemma unsimpl zip : 8 t (v1 : var1 t ) (v2 : var2 t )

G (s1 : hlist G ) s2 t' (e1 : Phoas.exp t' ) e2,
exp equiv (zip (v1 ::: s1 ) (v2 ::: s2 )) e1 e2!

exp equiv (existT (v1, v2 ) :: zip s1 s2 ) e1 e2.
trivial.
Qed.

Hint Resolve In zip unsimpl zip.

Now it is trivial to prove the main inductive lemma about well-formedness.
Lemma phoasify wf : 8 G t (e : DeBruijn.exp G t ) s1 s2,

exp equiv (zip s1 s2 ) (phoasify e s1 ) (phoasify e s2 ).
Hint Constructors exp equiv.

induction e; crush.
Qed.
End vars.

We apply phoasify wf manually to prove the o/nal theorem.
Theorem Phoasify wf : 8 t (e : DeBruijn.exp nil t ),

Wf (Phoasify e).
unfold Wf, Phoasify ; intros;

348

apply (phoasify wf e (HNil (B := var1 )) (HNil (B := var2 ))).
Qed.

Now, if we compose Phoasify with any translation over PHOAS terms, we can verify the
composed translation without relying on axioms. The conclusion of Phoasify wf is robustly
useful in verifying a wide variety of translations that use a wide variety of var instantiations.

20.2 From PHOAS to De Bruijn
The translation to de Bruijn terms is more involved. We will essentially be instantiating
and using a PHOAS term following a convention isomorphic to de Bruijn levels, which are
dioeerent from the de Bruijn indices that we have treated so far. With levels, a given bound
variable is referred to by the same number at each of its occurrences. In any expression, the
binders that are not enclosed by other binders are assigned level 0, a binder with just one
enclosing binder is assigned level 1, and so on. The uniformity of references to any binder
will be critical to our translation, since it is compatible with the pattern of o/lling in all of a
PHOAS variable's locations at once by applying a function.

We implement a special lookup function, for reading a numbered variable's type out of
a de Bruijn level typing context. The last variable in the list is taken to have level 0, the
next-to-last level 1, and so on.

Fixpoint lookup (ts : list type) (n : nat) : option type :=

match ts with|

nil ) None|
t :: ts' ) if eq nat dec n (length ts' ) then Some t else lookup ts' n
end.

Infix "##" := lookup (left associativity, at level 1).

With lookup, we can deo/ne a notion of well-formedness for PHOAS expressions that we
are treating according to the de Bruijn level convention.

Fixpoint wf (ts : list type) t (e : Phoas.exp (fun ) nat) t ) : Prop :=

match e with|

Phoas.Var t n ) ts ## n = Some t|
Phoas.Const ) True|
Phoas.Plus e1 e2 ) wf ts e1 ^ wf ts e2|
Phoas.App e1 e2 ) wf ts e1 ^ wf ts e2|
Phoas.Abs t1 e1 ) wf (t1 :: ts) (e1 (length ts))
end.

20.2.1 Connecting Notions of Well-Formedness
Our o/rst order of business now is to prove that any well-formed Exp instantiates to a well-
formed de Bruijn level expression. We start by characterizing, as a function of de Bruijn

349

level contexts, the set of PHOAS contexts that will occur in the proof, where we will be
inducting over an exp equiv derivation.

Fixpoint makeG (ts : list type) : list - t : type & nat * nat ""%type :=

match ts with|

nil ) nil|
t :: ts' ) existT t (length ts', length ts' ) :: makeG ts'
end.

Now we prove a connection between lookup and makeG, by way of a lemma about lookup.
Opaque eq nat dec.
Hint Extern 1 ( >= ) ) omega.

Lemma lookup contra' : 8 t ts n,

ts ## n = Some t!

n >= length ts!
False.
induction ts; crush;

match goal with|

[ : context [if ?E then else ] ` ] ) destruct E ; crush
end; eauto.
Qed.

Lemma lookup contra : 8 t ts,

ts ## (length ts) = Some t!

False.
intros; eapply lookup contra'; eauto.
Qed.

Hint Resolve lookup contra.
Lemma lookup In : 8 t v1 v2 ts,

In (existT (fun : type ) (nat * nat)%type) t (v1, v2 )) (makeG ts)!

ts ## v1 = Some t.
induction ts; crush;

match goal with|

[ ` context [if ?E then else ] ] ) destruct E ; crush
end; elimtype False; eauto.
Qed.

Hint Resolve lookup In.

We can prove the main inductive lemma by induction over exp equiv derivations.
Hint Extern 1 ( :: = makeG ( :: )) ) reflexivity.
Lemma Wf wf' : 8 G t e1 (e2 : Phoas.exp (fun ) nat) t ),

exp equiv G e1 e2! 8

ts, G = makeG ts

350

! wf ts e1.
induction 1; crush; eauto.
Qed.

Lemma Wf wf : 8 t (E : Exp t ),

Wf E!

wf nil (E (fun ) nat)).
intros; eapply Wf wf'; eauto.
Qed.

20.2.2 The Translation
Implementing the translation itself will require some proofs. Our main function dbify will
take wf proofs as arguments, and these proofs will be critical to constructing de Bruijn index
terms. First, we use congruence to prove two basic theorems about options.

Theorem None Some : 8 T (x : T ),

None = Some x!

False.
congruence.
Qed.

Theorem Some Some : 8 T (x y : T ),

Some x = Some y!

x = y.
congruence.
Qed.

We can use these theorems to implement makeVar, which translates a proof about lookup
into a de Bruijn index variable with a closely related type.

Fixpoint makeVar -ts n t "" : ts ## n = Some t ! member t ts :=

match ts with|

nil ) fun Heq ) match None Some Heq with end|
t' :: ts' ) if eq nat dec n (length ts' ) as b return (if b then else ) = !

then fun Heq ) match Some Some Heq with reAE equal ) HFirst end
else fun Heq ) HNext (makeVar Heq)
end.

Now dbify is straightforward to deo/ne. We use the functions proj1 and proj2 to decompose
proofs of conjunctions.

Fixpoint dbify -ts"" t (e : Phoas.exp (fun ) nat) t ) : wf ts e ! DeBruijn.exp ts t :=

match e in Phoas.exp t return wf ts e ! DeBruijn.exp ts t with|

Phoas.Var n ) fun wf ) DeBruijn.Var (makeVar wf)

| Phoas.Const n ) fun ) DeBruijn.Const n

351

| Phoas.Plus e1 e2 ) fun wf )

DeBruijn.Plus (dbify e1 (proj1 wf)) (dbify e2 (proj2 wf))

| Phoas.App e1 e2 ) fun wf )

DeBruijn.App (dbify e1 (proj1 wf)) (dbify e2 (proj2 wf))|
Phoas.Abs e1 ) fun wf ) DeBruijn.Abs (dbify (e1 (length ts)) wf)
end.

We deo/ne the parametric translation Dbify by appealing to the well-formedness transla-
tion theorem Wf wf that we proved earlier.

Definition Dbify t (E : Phoas.Exp t ) (W : Wf E ) : DeBruijn.exp nil t :=

dbify (E ) (Wf wf W ).

To prove soundness, it is helpful to classify a set of contexts which depends on a de Bruijn
index substitution.

Fixpoint makeG' ts (s : hlist typeDenote ts)

: list - t : type & nat * typeDenote t ""%type :=
match s with|

HNil ) nil|
HCons ts' v s' ) existT (length ts', v ) :: makeG' s'
end.

We prove an analogous lemma to the one we proved connecting makeG and lookup. This
time, we connect makeG' and hget.

Lemma In makeG' contra' : 8 t v2 ts (s : hlist ts) n,

In (existT t (n, v2 )) (makeG' s)!

n >= length ts!
False.
induction s; crush; eauto.
Qed.

Lemma In makeG' contra : 8 t v2 ts (s : hlist ts),

In (existT t (length ts, v2 )) (makeG' s)!

False.
intros; eapply In makeG' contra'; eauto.
Qed.

Hint Resolve In makeG' contra.
Lemma In makeG' : 8 t v1 v2 ts s (w : ts ## v1 = Some t ),

In (existT t (v1, v2 )) (makeG' s)!

hget s (makeVar w ) = v2.
induction s; crush;

match goal with|

[ ` context [if ?E then else ] ] ) destruct E ; crush
end;

352

repeat match goal with|

[ ` context [match ?pf with reAE equal ) end] ] )

rewrite (UIP reAE pf )
end; crush; elimtype False; eauto.
Qed.

Hint Resolve In makeG'.

Now the main inductive lemma can be stated and proved simply.
Lemma dbify sound : 8 G t (e1 : Phoas.exp t ) (e2 : Phoas.exp t ),

exp equiv G e1 e2! 8

ts (w : wf ts e1 ) s,
G = makeG' s!

DeBruijn.expDenote (dbify e1 w ) s = Phoas.expDenote e2.
induction 1; crush; ext eq; crush.
Qed.

In the usual way, we wrap dbify sound into the o/nal soundness theorem, formally estab-
lishing the expressive equivalence of PHOAS and de Bruijn index terms.

Theorem Dbify sound : 8 t (E : Exp t ) (W : Wf E ),

DeBruijn.expDenote (Dbify W ) HNil = Phoas.ExpDenote E.
unfold Dbify, Phoas.ExpDenote; intros; eapply dbify sound; eauto.
Qed.

353

Chapter 21
Higher-Order Operational Semantics

The last few chapters have shown how PHOAS can make it relatively painless to reason about
program transformations. Each of our example languages so far has had a semantics that
is easy to implement with an interpreter in Gallina. Since Gallina is designed to rule out
non-termination, we cannot hope to give interpreter-based semantics to Turing-complete
programming languages. Falling back on standard operational semantics leaves us with
the old bureaucratic concerns about capture-avoiding substitution. Can we encode Turing-
complete, higher-order languages in Coq without sacrio/cing the advantages of higher-order
encoding?

Any approach that applies to basic untyped lambda calculus is likely to extend to most
object languages of interest. We can attempt the "obvious" way of equipping a PHOAS
deo/nition for use in an operational semantics, without mentioning substitution explicitly.
Specio/cally, we try to work with expressions with var instantiated with a type of values.

Section exp.

Variable var : Type.

Inductive exp : Type :=|

Var : var ! exp|
App : exp ! exp ! exp|
Abs : (var ! exp) ! exp.
End exp.

Inductive val : Type :=|

VAbs : (val ! exp val) ! val.

Error : Non strictly positive occurrence of "val" in

"(val ! exp val) ! val".

We would like to represent values (which are all function abstractions) as functions from
variables to expressions, where we represent variables as the same value type that we are
deo/ning. That way, a value can be substituted in a function body simply by applying the

354

body to the value. Unfortunately, the positivity restriction rejects this deo/nition, for much
the same reason that we could not use the classical HOAS encoding.

We can try an alternate approach based on deo/ning val like a usual class of syntax.

Section val.

Variable var : Type.

Inductive val : Type :=|

VAbs : (var ! exp var ) ! val.
End val.

Now the puzzle is how to write the type of an expression whose variables are represented
as values. We would like to be able to write a recursive deo/nition like this one:

Fixpoint expV := exp (val expV ).

Of course, this kind of deo/nition is not structurally recursive, so Coq will not allow it.
Getting "substitution for free" seems to require some similar kind of self-reference.

In this chapter, we will consider an alternate take on the problem. We add a level of indi-
rection, introducing more explicit syntax to break the cycle in type deo/nitions. Specio/cally,
we represent function values as numbers that index into a closure heap that our operational
semantics maintains alongside the expression being evaluated.

21.1 Closure Heaps
The essence of the technique is to store function bodies in lists that are extended monoton-
ically as function abstractions are evaluated. We can deo/ne a set of functions and theorems
that implement the core functionality generically.

Section lookup.

Variable A : Type.

We start with a lookup function that generalizes last chapter's function of the same name.
It selects the element at a particular position in a list, where we number the elements starting
from the end of the list, so that prepending new elements does not change the indices of old
elements.

Fixpoint lookup (ls : list A) (n : nat) : option A :=

match ls with|

nil ) None|
v :: ls' ) if eq nat dec n (length ls' ) then Some v else lookup ls' n
end.

Infix "##" := lookup (left associativity, at level 1).

The second of our two deo/nitions expresses when one list extends another. We will write
ls1  ls2 to indicate that ls1 could evolve into ls2 ; that is, ls1 is a suOEx of ls2.

355

Definition extends (ls1 ls2 : list A) := 9 ls, ls2 = ls ++ ls1.
Infix "" := extends (no associativity, at level 80).

We prove and add as hints a few basic theorems about lookup and extends.
Theorem lookup1 : 8 x ls,

(x :: ls) ## (length ls) = Some x.
crush; match goal with|

[ ` context [if ?E then else ] ] ) destruct E
end; crush.
Qed.

Theorem extends reAE : 8 ls, ls  ls.9

nil; reflexivity.
Qed.

Theorem extends1 : 8 v ls, ls  v :: ls.

intros; 9 (v :: nil); reflexivity.
Qed.

Theorem extends trans : 8 ls1 ls2 ls3,

ls1  ls2!

ls2  ls3!
ls1  ls3.
intros ? ? ? [l1 ?] [l2 ?]; 9 (l2 ++ l1 ); crush.
Qed.

Lemma lookup contra : 8 n v ls,

ls ## n = Some v!

n >= length ls!
False.
induction ls; crush;

match goal with|

[ : context [if ?E then else ] ` ] ) destruct E
end; crush.
Qed.

Hint Resolve lookup contra.
Theorem extends lookup : 8 ls1 ls2 n v,

ls1  ls2!

ls1 ## n = Some v!
ls2 ## n = Some v.
intros ? ? ? ? [l ?]; crush; induction l ; crush;

match goal with|

[ ` context [if ?E then else ] ] ) destruct E
end; crush; elimtype False; eauto.
Qed.

356

End lookup.
Infix "##" := lookup (left associativity, at level 1).
Infix "" := extends (no associativity, at level 80).

Hint Resolve lookup1 extends reAE extends1 extends trans extends lookup.

We are dealing explicitly with the nitty-gritty of closure heaps. Why is this better than
dealing with the nitty-gritty of variables? The inconvenience of modeling lambda calculus-
style binders comes from the presence of nested scopes. Program evaluation will only involve
one global closure heap. Also, the short development that we just o/nished can be reused for
many dioeerent object languages. None of these deo/nitions or theorems needs to be redone
to handle specio/c object language features. By adding the theorems as hints, no per-object-
language eoeort is required to apply the critical facts as needed.

21.2 Languages and Translation
For the rest of this chapter, we will consider the example of CPS translation for untyped
lambda calculus with boolean constants. It is convenient to include these constants, because
their presence makes it easy to state a o/nal translation correctness theorem.

Module Source.

We deo/ne the syntax of source expressions in our usual way.

Section exp.

Variable var : Type.

Inductive exp : Type :=|

Var : var ! exp|
App : exp ! exp ! exp|
Abs : (var ! exp) ! exp|
Bool : bool ! exp.
End exp.

Implicit Arguments Bool [var ].
Definition Exp := 8 var, exp var.

We will implement a big-step operational semantics, where expressions are mapped to
values. A value is either a function or a boolean. We represent a function as a number that
will be interpreted as an index into the global closure heap.

Inductive val : Set :=|

VFun : nat ! val|
VBool : bool ! val.

A closure, then, follows the usual representation of function abstraction bodies, where
we represent variables as values.

Definition closure := val ! exp val.

357

Definition closures := list closure.

Our evaluation relation has four places. We map an initial closure heap and an expression
into a o/nal closure heap and a value. The interesting cases are for Abs, where we push the
body onto the closure heap; and for App, where we perform a lookup in a closure heap, to
o/nd the proper function body to execute next.

Inductive eval : closures ! exp val ! closures ! val ! Prop :=|

EvVar : 8 cs v,

eval cs (Var v ) cs v

| EvApp : 8 cs1 e1 e2 cs2 v1 c cs3 v2 cs4 v3,

eval cs1 e1 cs2 (VFun v1 )!

eval cs2 e2 cs3 v2!
cs2 ## v1 = Some c!
eval cs3 (c v2 ) cs4 v3!
eval cs1 (App e1 e2 ) cs4 v3

| EvAbs : 8 cs c,

eval cs (Abs c) (c :: cs) (VFun (length cs))

| EvBool : 8 cs b,

eval cs (Bool b) cs (VBool b).

A simple wrapper produces an evaluation relation suitable for use on the main expression
type Exp.

Definition Eval (cs1 : closures) (E : Exp) (cs2 : closures) (v : val) :=

eval cs1 (E ) cs2 v.

To prove our translation's correctness, we will need the usual notions of expression equiv-
alence and well-formedness.

Section exp equiv.

Variables var1 var2 : Type.

Inductive exp equiv : list (var1 * var2 ) ! exp var1 ! exp var2 ! Prop :=|

EqVar : 8 G v1 v2,

In (v1, v2 ) G!

exp equiv G (Var v1 ) (Var v2 )

| EqApp : 8 G f1 x1 f2 x2,

exp equiv G f1 f2!

exp equiv G x1 x2!
exp equiv G (App f1 x1 ) (App f2 x2 )|
EqAbs : 8 G f1 f2,

(8 v1 v2, exp equiv ((v1, v2 ) :: G ) (f1 v1 ) (f2 v2 ))!

exp equiv G (Abs f1 ) (Abs f2 )

358

| EqBool : 8 G b,

exp equiv G (Bool b) (Bool b).
End exp equiv.

Definition Wf (E : Exp) := 8 var1 var2, exp equiv nil (E var1 ) (E var2 ).
End Source.

Our target language can be deo/ned without introducing any additional tricks.
Module CPS.

Section exp.

Variable var : Type.

Inductive prog : Type :=|

Halt : var ! prog|
App : var ! var ! prog|
Bind : primop ! (var ! prog) ! prog

with primop : Type :=|

Abs : (var ! prog) ! primop

| Bool : bool ! primop
| Pair : var ! var ! primop|

Fst : var ! primop|
Snd : var ! primop.
End exp.

Implicit Arguments Bool [var ].
Notation "x  p ; e" := (Bind p (fun x ) e))

(right associativity, at level 76, p at next level ).

Definition Prog := 8 var, prog var.
Definition Primop := 8 var, primop var.

Inductive val : Type :=|

VFun : nat ! val|
VBool : bool ! val|
VPair : val ! val ! val.
Definition closure := val ! prog val.
Definition closures := list closure.

Inductive eval : closures ! prog val ! val ! Prop :=|

EvHalt : 8 cs v,

eval cs (Halt v ) v

| EvApp : 8 cs n v2 c v3,

359

cs ## n = Some c!

eval cs (c v2 ) v3!
eval cs (App (VFun n) v2 ) v3

| EvBind : 8 cs1 p e cs2 v1 v2,

evalP cs1 p cs2 v1!

eval cs2 (e v1 ) v2!
eval cs1 (Bind p e) v2

with evalP : closures ! primop val ! closures ! val ! Prop :=|

EvAbs : 8 cs c,

evalP cs (Abs c) (c :: cs) (VFun (length cs))

| EvPair : 8 cs v1 v2,

evalP cs (Pair v1 v2 ) cs (VPair v1 v2 )|
EvFst : 8 cs v1 v2,

evalP cs (Fst (VPair v1 v2 )) cs v1|
EvSnd : 8 cs v1 v2,

evalP cs (Snd (VPair v1 v2 )) cs v2

| EvBool : 8 cs b,

evalP cs (Bool b) cs (VBool b).

Definition Eval (cs : closures) (P : Prog) (v : val) := eval cs (P ) v.
End CPS.

Import Source CPS.

Finally, we deo/ne a CPS translation in the same way as in our previous example for
simply-typed lambda calculus.

Reserved Notation "x - e1 ; e2" (right associativity, at level 76, e1 at next level ).
Section cpsExp.

Variable var : Type.

Import Source.
Fixpoint cpsExp (e : exp var )

: (var ! prog var ) ! prog var :=
match e with|

Var v ) fun k ) k v

| App e1 e2 ) fun k )

f - e1 ;
x - e2 ;
kf  CPS.Abs k ;
p  Pair x kf ;

360

CPS.App f p|
Abs e' ) fun k )

f  CPS.Abs (var := var ) (fun p )

x  Fst p;
kf  Snd p;
r - e' x ;
CPS.App kf r );
k f

| Bool b ) fun k )

x  CPS.Bool b;
k x
end

where "x - e1 ; e2" := (cpsExp e1 (fun x ) e2 )).
End cpsExp.

Notation "x - e1 ; e2" := (cpsExp e1 (fun x ) e2 )).
Definition CpsExp (E : Exp) : Prog := fun ) cpsExp (E ) (Halt (var := )).

21.3 Correctness Proof
Our proof for simply-typed lambda calculus relied on a logical relation to state the key
induction hypothesis. Since logical relations proceed by recursion on type structure, we
cannot apply them directly in an untyped setting. Instead, we will use an inductive judgment
to relate source-level and CPS-level values. First, it is helpful to deo/ne an abbreviation for
the compiled version of a function body.

Definition cpsFunc var (e' : var ! Source.exp var ) :=

fun p : var )

x  Fst p;
kf  Snd p;
r - e' x ;
CPS.App kf r.

Now we can deo/ne our correctness relation cr, which is parameterized by source-level and
CPS-level closure heaps.

Section cr.

Variable s1 : Source.closures.
Variable s2 : CPS.closures.

Import Source.

Only equal booleans are related. For two function addresses l1 and l2 to be related, they
must point to valid functions in their respective closure heaps. The address l1 must point

361

to a function f1, and l2 must point to the result of compiling function f2. Further, f1 and
f2 must be equivalent syntactically in some variable environment G, and every variable pair
in G must itself belong to the relation we are deo/ning.

Inductive cr : Source.val ! CPS.val ! Prop :=|

CrBool : 8 b,

cr (Source.VBool b) (CPS.VBool b)

| CrFun : 8 l1 l2 G f1 f2,

(8 x1 x2, exp equiv ((x1, x2 ) :: G ) (f1 x1 ) (f2 x2 ))!

(8 x1 x2, In (x1, x2 ) G ! cr x1 x2 )!
s1 ## l1 = Some f1!
s2 ## l2 = Some (cpsFunc f2 )!
cr (Source.VFun l1 ) (CPS.VFun l2 ).
End cr.

Notation "s1 & s2 --* v1 \Lambda \Lambda  v2" := (cr s1 s2 v1 v2 ) (no associativity, at level 70).
Hint Constructors cr.

To prove our main lemma, it will be useful to know that source-level evaluation never
removes old closures from a closure heap.

Lemma eval monotone : 8 cs1 e cs2 v,

Source.eval cs1 e cs2 v!

cs1  cs2.
induction 1; crush; eauto.
Qed.

Further, cr continues to hold when its closure heap arguments are evolved in legal ways.
Lemma cr monotone : 8 cs1 cs2 cs1' cs2',

cs1  cs1'!

cs2  cs2'! 8

v1 v2, cs1 & cs2 --* v1 \Lambda \Lambda  v2!

cs1' & cs2' --* v1 \Lambda \Lambda  v2.
induction 3; crush; eauto.
Qed.

Hint Resolve eval monotone cr monotone.

We state a trivial fact about the validity of variable environments, so that we may add
this fact as a hint that eauto will apply.

Lemma push : 8 G s1 s2 v1' v2',

(8 v1 v2, In (v1, v2 ) G ! s1 & s2 --* v1 \Lambda \Lambda  v2 )!

s1 & s2 --* v1' \Lambda \Lambda  v2'!
(8 v1 v2, (v1', v2' ) = (v1, v2 ) . In (v1, v2 ) G ! s1 & s2 --* v1 \Lambda \Lambda  v2 ).
crush.
Qed.

362

Hint Resolve push.

Our o/nal preparation for the main lemma involves adding eoeective hints about the CPS
language's operational semantics. The following tactic performs one step of evaluation. It
uses the Ltac code eval hnf in e to compute the head normal form of e, where the head
normal form of an expression in an inductive type is an application of one of that inductive
type's constructors. The o/nal line below uses solve to ensure that we only take a Bind step
if a full evaluation derivation for the associated primop may be found before proceeding.

Ltac evalOne :=

match goal with|

[ ` CPS.eval ?cs ?e ?v ] )

let e := eval hnf in e in

change (CPS.eval cs e v );

econstructor ; [ solve [ eauto ] | ]
end.

For primops, we rely on eauto's usual approach. For goals that evaluate programs, we
instead ask to treat one or more applications of evalOne as a single step, which helps us
avoid passing eauto an excessively large bound on proof tree depth.

Hint Constructors evalP.
Hint Extern 1 (CPS.eval ) ) evalOne; repeat evalOne.

The o/nal lemma proceeds by induction on an evaluation derivation for an expression
e1 that is equivalent to some e2 in some environment G. An initial closure heap for each
language is quantio/ed over, such that all variable pairs in G are compatible. The lemma's
conclusion applies to an arbitrary continuation k, asserting that a o/nal CPS-level closure
heap s2 and a CPS-level program result value r2 exist.

Three conditions establish that s2 and r2 are chosen properly: Evaluation of e2 's com-
pilation with continuation k must be equivalent to evaluation of k r2. The original program
result r1 must be compatible with r2 in the o/nal closure heaps. Finally, s2' must be a
proper evolution of the original CPS-level heap s2 .

Lemma cpsExp correct : 8 s1 e1 s1' r1,

Source.eval s1 e1 s1' r1! 8

G (e2 : exp CPS.val),
exp equiv G e1 e2! 8

s2,
(8 v1 v2, In (v1, v2 ) G ! s1 & s2 --* v1 \Lambda \Lambda  v2 )! 8

k, 9 s2', 9 r2,
(8 r, CPS.eval s2' (k r2 ) r!

CPS.eval s2 (cpsExp e2 k ) r )^
s1' & s2' --* r1 \Lambda \Lambda  r2^
s2  s2'.

The proof script follows our standard approach. Its main loop applies three hints. First,
we perform inversion on any derivation of equivalence between a source-level function value

363

and some other value. Second, we eliminate redundant equality hypotheses. Finally, we look
for opportunities to instantiate inductive hypotheses.

We identify an IH by its syntactic form, noting the expression E that it applies to. It
is important to instantiate IHes in the right order, since existentially-quantio/ed variables
in the conclusion of one IH may need to be used in instantiating the universal quantio/ers
of a dioeerent IH. Thus, we perform a quick check to fail 1 if the IH we found applies
to an expression that was evaluated after another expression E' whose IH we did not yet
instantiate. The AEow of closure heaps through source-level evaluation is used to implement
the check.

If the hypothesis H is indeed the right IH to handle next, we use the guess tactic to guess
values for its universal quantio/ers and prove its hypotheses with eauto. This tactic is very
similar to inster from Chapter 12. It takes two arguments: the o/rst is a value to use for
any properly-typed universal quantio/er, and the second is the hypothesis to instantiate. The
o/nal inner match deduces if we are at the point of executing the body of a called function.
If so, we help guess by saying that the initial closure heap will be the current closure heap
cs extended with the current continuation k. In all other cases, guess is smart enough to
operate alone.

induction 1; inversion 1; crush;

repeat (match goal with|

[ H : & --* Source.VFun \Lambda \Lambda  ` ] ) inversion H ; clear H|
[ H1 : ?E = , H2 : ?E = ` ] ) rewrite H1 in H2 ; clear H1|
[ H : 8 G e2, exp equiv G ?E e2 ! ` ] )

match goal with|

[ : Source.eval ?CS E , : Source.eval ?E' ?CS ,

: 8 G e2, exp equiv G ?E' e2 ! ` ] ) fail 1| )
match goal with|

[ k : val ! prog val, : & ?cs --* \Lambda \Lambda  ,

: context [VFun] ` ] )
guess (k :: cs) H| )

guess tt H
end
end
end; crush); eauto 13.
Qed.

The o/nal theorem follows easily from this lemma.
Theorem CpsExp correct : 8 E cs b,

Source.Eval nil E cs (Source.VBool b)!

Wf E!
CPS.Eval nil (CpsExp E ) (CPS.VBool b).
Hint Constructors CPS.eval.

unfold Source.Eval, CPS.Eval, CpsExp; intros ? ? ? H1 H2 ;

364

generalize (cpsExp correct H1 (H2 ) (s2 := nil)

(fun pf ) match pf with end) (Halt (var := ))); crush;
match goal with|

[ H : & --* \Lambda \Lambda  ` ] ) inversion H
end; crush.
Qed.

365