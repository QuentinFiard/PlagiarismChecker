

Generation of LR Parsers by Partial Evaluation
MICHAEL SPERBER
Universit"at T"ubingen
and
PETER THIEMANN
Universit"at Freiburg

The combination of modern programming languages and partial evaluation yields new approaches
to old problems. In particular, the combination of functional programming and partial evaluation
can turn a general parser into a parser generator. We use an inherently functional approach to
implement general LR(k) parsers and specialize them with respect to the input grammars using
offline partial evaluation. The functional specification of LR parsing yields a concise implementation of the algorithms themselves. Furthermore, we demonstrate the elegance of the functional
approach by incorporating on-the-fly attribute evaluation for S-attributed grammars and two
schemes for error recovery, which lend themselves to natural and elegant implementation. The
parsers require only minor changes to achieve good specialization results. The generated parsers
have production quality and match those produced by traditional parser generators in speed and
compactness.

Categories and Subject Descriptors: D.1.1 [Programming Techniques]: Applicative (Functional) Programming; D.1.2 [Programming Techniques]: Automatic Programming; D.3.2
[Programming Languages]: Language Classifications--Applicative Languages; D.3.4 [Programming Languages]: Processors--Parsing; F.4.2 [Mathematical Logic and Formal Languages]: Grammars and Other Rewriting Systems--Parsing; I.2.2 [Artificial Intelligence]:
Automatic Programming--Program Transformation; Program Synthesis

General Terms: Algorithms, Experimentation, Languages, Performance
Additional Key Words and Phrases: Continuations, functional programming, LR parsing, parser
generation, partial evaluation

1. INTRODUCTION
LR parsing [Knuth 1965] is the predominant parsing technique in compiler frontends and other formal language processors. LR parsing is popular because many

realistic grammars are immediately amenable to this technique. Also, several LRparser generators are readily available, most notably Yacc [Johnson 1975] which

An earlier version of parts of this article appeared in Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, 1995 under the title
"The Essence of LR Parsing."
Authors' addresses: M. Sperber, Wilhelm-Schickard-Institut f"ur Informatik, Universit"at T"ubingen,
Sand 13, D-72076 T"ubingen, Germany; email: sperber@informatik.uni-tuebingen.de; P. Thiemann, Institut f"ur Informatik, Universit"at Freiburg, Universit"atsgel"ande Flugplatz, D-79110
Freiburg im Breisgau, Germany; email: thiemann@informatik.uni-freiburg.de.
Permission to make digital/hard copy of all or part of this material without fee for personal
or classroom use provided that the copies are not made or distributed for profit or commercial
advantage, the ACM copyright/server notice, the title of the publication, and its date appear, and
notice is given that copying is by permission of the ACM, Inc. To copy otherwise, to republish,
to post on servers, or to redistribute to lists requires prior specific permission and/or a fee.

cfl 2000 ACM 0164-0925/00/0300-0224 $5.00

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000, Pages 224-264.

Generation of LR Parsers by Partial Evaluation * 225
creates LALR parsers.Unfortunately, the techniques underlying LR parsing are difficult to comprehend.
We advocate a fresh approach to creating LR parser generators which ensures under-standability and correctness at every step, and leads to extremely efficient parsers:

(1) Write a concise, functional specification of LR parsing which is understandableand easy to prove correct.
(2) Use partial evaluation, an automatic program transformation, to turn the gen-eral parser into a generator of efficient parsers. The correctness of the partial

evaluator guarantees the correctness of this step.
The reason for the traditional opacity of presentations of LR parsing is mostlydue to the implementation methods: most presentations employ a stack automaton [Johnson 1975; Chapman 1987; Sippu and Soisalon-Soininen 1990; Wilhelm andMaurer 1995], and its usual implementation is an interpreter of a transition table.
Unfortunately, since the naive table representation of an LR automaton may beprohibitively large, it is necessary to use sparse table representations which in turn
require significant algorithmics and coding [Tarjan and Yao 1979; Dencker et al.1984]. Consequently, the LR parsers resulting from this approach are hard to read,
and typically contain numerous obscure performance hacks. This, in turn, makesfinding errors and tending to parsing conflicts difficult. Testing is only possible
with the generated parsers.These difficulties are in sharp contrast to LL techniques where grammars translate straightforwardly into readable recursive-descent parsers; this is one of themain advantages of LL techniques as cited by its advocates.

An alternative approach to LR parsing is much more transparent: start from afunctional specification of LR(k) parsing and derive the implementation by program
calculation [Leermakers 1993]. The resulting formulation of LR parsing turns out tobe quite simple. It relies on the recursive-ascent technique [Pennello 1986; Roberts
1988], analogous to the recursive-descent method commonly used in LL parsers.Our investigation starts from this inherently functional approach, which does not
require an explicit parse table or a parsing stack. By application of well-knownprogram transformation steps, we arrive at an original alternative specification
based on continuations. It shares the advantanges of the first approach and is evenmore concise and elegant.

Recursive ascent results in LR parsers which are considerably simpler and morecompact than formulations using a stack automaton. The specifications of the parsing algorithms translate directly into functional programs. These general parsersrun independently and take both a grammar and an input string as operands.
Adding attribute evaluation as well as effective error recovery fits elegantly into thefunctional framework. General parsers are comparatively easy to write and debug.
The interpretive framework also eases writing and debugging of grammars.Consequently, using an inherently functional approach as well as a functional programming language to implement LR parsing yields new insights into the method-ology of software development, and suggests that functional programming offers
fresh ideas for many old software construction problems.Starting from a general parser, a partial evaluator can, given an input grammar
and lookahead, automatically construct efficient specialized parsers. One particuACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

226 * M. Sperber and P. Thiemann
larly simple partial-evaluation technique, offline partial evaluation, suffices for thistask. The same technique can automatically generate efficient standalone parser
generators. The resulting parsers are simple in structure, consisting of mutuallyrecursive procedures that encode parser states. To achieve good results with offline partial evaluation, many realistic programs require slight changes, so-calledbinding-time improvements. Our parsers are no exception. However, the techniques
employed are fairly standard, and the improvements do not disrupt the structureof the original parsers.

The parser implementations are written in Scheme [IEEE 1991; Kelsey et al.1998] which makes for particularly concise and readable programs. It also facilitates the use of existing partial-evaluation systems for Scheme. We have used twodifferent systems for developing the parser generators: Bondorf's Similix [Bondorf
1991] for the initial experiments, and Thiemann's PGG system [Thiemann 1996a]for the production version. Both the PGG system as well as the parser code are
publicly available on the Internet [Sperber and Thiemann 1999; Thiemann 1999].In addition to the parsing algorithms, we have implemented attribute evaluation
and two styles of error recovery--the method of Yacc [Johnson 1975], which dependson user annotations to the input grammar, and R"ohrich's automatic backtrack-free
mechanism [R"ohrich 1980]. This demonstrates the feasibility of our approach.

Compared to real-world parser generators, the performance of the generatedparsers is competitive. When compiled with a high-performance Scheme implementation, they are about as fast as parsers generated by Bison [Donnelly andStallman 1995].

Overview The article is organized as follows: the first three sections introducesome notational preliminaries and two approaches to functional LR parsing: the
so-called direct-style approach (Section 3) and the continuation-based approach(Section 4). The presentation includes straightforward implementations in Scheme.
The following Section 5 is an introduction to offline partial evaluation.Section 6 describes the specialization of the parsing algorithm in direct style,
specifically the binding-time improvements. Moving on to the continuation-basedapproach, Section 7 describes the additional problems that had to be solved to
obtain satisfactory results. A refinement of the checking of the lookahead, whichimproves both styles of parsers, is the topic of Section 8.

Section 9 describes the implementation of attribute evaluation and error recoveryfor the continuation-based implementation. Section 10 gives the results of practical
experiments; Section 11 discusses related work.For concreteness, all concepts are explained and implemented using the programming language Scheme [Kelsey et al. 1998]. The conciseness of the language enablesus to include actual code in the article.

2. NOTATIONAL PRELIMINARIES
This section reviews notation for sequences and for context-free grammars. It alsointroduces the bunch notation [Leermakers 1993] for expressing nondeterministic

algorithms.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 227
2.1 Sequences
For a set A, A* denotes the set of finite sequences of elements of A with " denotingthe empty sequence. For some

, = a1 . . . an 2 A* let |,| := n be the length of ,.The
k-prefix of ,, ,|k, is a1 . . . aj where j = min(k, n).

2.2 Context-Free Grammars
A start-separated context-free grammar (or just grammar) is a tuple G = (N, T, P, S).
N is the set of nonterminals, T the set of terminals (disjoint from N), S 2 N thestart symbol,

V = T [ N the set of grammar symbols. P is the set of productions;productions have the form

A ! ff for a nonterminal A and a sequence ff of grammarsymbols. An
"-production has the form A ! ". There is exactly one production in
P with S as its left-hand side. It has the form S ! A where A 2 N.Some letters denote elements of certain sets by convention:

A, B, C, E 2 N

,, ae, o/ 2 T *

x, y, z 2 T
ff, fi, fl, ffi, *, u 2 V*

X, Y, Z 2 V

G induces the derives relation ) on V* with

ff ) fi :, ff = ffiAfl ^ fi = ffiufl ^ A ! u
where A ! u stands for 9p 2 P.p = A ! u and where ffi, A, fl, and u are implicitlyexistentially quantified on the right side of the ,. The reflexive and transitive

closure of ) is *). A derivation from ff0 to ffn is a sequence ff0, ff1, . . . , ffn where
ffi-1 ) ffi for 1 <= i <= n. A sentential form is a sequence appearing in a derivationbeginning with the start symbol. The leftmost-symbol rewriting )

` is a relationdefined as

Bff )` ffiff :, B ! ffi ^ ffi 6= "
with reflexive and transitive closure *)` .

An LR(k) item (or just item) is a triple consisting of a production A ! u, aposition

0 <= j <= |u| within its right-hand side, and a terminal string of length<=
k--the lookahead. An item is written as A ! ff * fi (ae) where the dot indicatesthe position, and

ae is the lookahead. When the lookahead is irrelevant (or k = 0),it is omitted. A kernel item has the form

A ! ff * fi (ae) with |ff| > 0. A predictitem has the form
A ! *ff (ae).An LR(k) state (or just state)

q is a nonempty set of LR(k) items.In the following, all productions, items, and states implicitly range over the

productions, items, and states of some arbitrary, but fixed, context-free grammar.Also, all derivations and rewrite steps are induced by this grammar.

2.3 Bunches
Bunches are a notational convenience for expressing nondeterministic algorithms ina more readable way than a set-based notation [Leermakers 1993].

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

228 * M. Sperber and P. Thiemann

A bunch denotes a nondeterministic choice of values. Any normal expressiondenotes a singleton bunch with just one value. If

a and b are bunches, then a | bis a bunch consisting of the values of
a and b. An empty bunch is said to fail andis therefore denoted by fail. In other words,

| is a nondeterministic choice operatorwith unit fail. It is associative, commutative, and idempotent. A function can only

be applied to a value, the member of a singleton bunch. If the argument containsa choice it must be distributed, first, i.e.,

f(fail) = fail and f(a | b) = f(a) | f(b).The guarded expression
x  a \Lambda  b stands for the bunch of all values of b where
x ranges over all values of a. Hence, it behaves like the set comprehension S{b |
x 2 a}. When x does not occur in b, a \Lambda  b is a valid shorthand. In this case, if theguard

a fails, the entire expression fails; otherwise, if a 6= fail, a \Lambda  b = b. Again,this is the behavior of the above set comprehension for

a = ; (the translation of failto sets). It is convenient to admit logical predicates as guards. A predicate denotes

the singleton bunch true if it is satisfied; otherwise it denotes fail. For furtherconvenience, guards sometimes use an informal pattern-matching notation. Such a
guarded expression also fails if the pattern does not match the value provided.
3. DIRECT-STYLE FUNCTIONAL LR PARSING
This section introduces one approach to functional LR parsing. The next sectionwill transform this approach into an even more elegant formulation, which is based

on continuations. To contrast the two, the approach presented in this section iscalled the direct-style approach.

Roughly, a parser for a context-free grammar is a function that maps a sequenceof terminals

, to a derivation from the start symbol to ,. An LR parser implementsthis function using an automaton operating on LR(k) states. When the automaton

is in state q, an item A ! ff * fi 2 q means that the parser has processed a suffixderivable from

ff in the input and is looking for something derivable from fi next.A parser state distinguishes between three cases. Either

fi = xffi where x is alsothe next terminal in the input. In that case, the parser can shift on

x, movingto a state that contains
A ! ffx * ffi. Otherwise, if fi = ", the parser has seeninput derivable from
A. Now, either ff = " so that the parser can directly shifton
A or ff 6= " in which case the parser must return to the state q introducingthat production. Hence,

q must contain the item A ! *ff and items of the form
B ! fl * Affi. In state q (which corresponds to the third case fi = Affi), the parsercan shift on

A, effectively reducing with the production A ! ff and making it partof the generated derivation.

3.1 Specifying Direct-Style LR Parsing
A functional LR parser is a set of mutually recursive functions [q], each of whichcorresponds to an LR state

q. For each A ! ff * fi 2 q and for each derivation from
fi to , there is a representative value (A ! ff*fi, , 0) in the bunch [q](,,0). For eachderivation found the bunch contains the item from which it originated and the rest

of the input string not yet parsed. Hence, the following specification formalizes LRparsing [Leermakers 1993]:

[q](x1x2 . . . xn) = \Gamma A ! ff * fi 2 q ^ fi *) x1 . . . xj\Delta 

\Lambda (A ! ff * fi, xj+1 . . . xn)

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 229
The initial state of an LR parser is q0 with q0 = {S ! *A}. S *) , holds if and onlyif

(S ! *A, ") occurs in the bunch produced by [q0](,).A few auxiliary definitions are necessary to cast the specification into an algorithm. The firstk function computes lookahead information:

firstk(ff) := \Phi ,|k | ff *) ,\Psi 
Each state q comes with a set of predict items

predict(q) := \Phi B ! ** (o/) | A ! ff * fi (ae) ++ B ! ** (o/)for

A ! ff * fi (ae) 2 q\Psi 

where ++ is the transitive closure of the relation + with exactly the followingpairings:

A ! ff * Bfi (ae) + B ! *ffi (o/) for all o/ 2 firstk(fiae)
The predict items of a state q are predictions on what derivations the parser mayenter next when in state

q. The elements of predict(q) are exactly those at theend of leftmost-symbol rewritings starting from items in

q. The union of q andpredict
(q) is called the closure of q, denoted by

closure(q) := q [ predict(q).
Repeated application of goto generates all other states. For a state q and a grammarsymbol

X:

goto(q, X) := {A ! ffX * fi (ae) | A ! ff * Xfi (ae) 2 closure(q)}
The general parser involves an auxiliary function [q] for each state q. An invocation

[q](X, x1 . . . xn) means that a grammar symbol X or a string derived from it hasjust been seen in the input and removed from it. The specification is

[q] (X, x1 . . . xn) =

(A ! ff * fi 2 q ^ fi *)` Xfl ^ fl *) x1 . . . xj)

\Lambda (A ! ff * fi, xj+1 . . . xn)

Thus, [q] is called whenever the functional equivalent of a "shift" action happens.Its implementation calls

[goto(q, X)] recursively and either returns the result (fora kernel item of the form

A ! ff * fi where |ff| > 0) or shifts the left-hand-sidenonterminal for a predict item of the form

C ! *ff, implemented as a recursive callof
[q].

3.2 Formulating Direct-Style LR Parsing
Figure 1 gives an "implementation" of the above functions [Leermakers 1993]. Theimplementation results from the specification by straightforward calculation. It

includes testing the k-lookahead. Hence it implements a nondeterministic LR(k)parsing algorithm. If the grammar is such that the parser is deterministic, the
grammar is called LR(k). This coincides with more traditional definitions of theterm [Knuth 1965; Chapman 1987; Sippu and Soisalon-Soininen 1990; Wilhelm and
Maurer 1995].In the implementation, the function

[q] first tries to shift on the next terminalsymbol
x. If there is an "-production B ! * in q, then [q] shifts on B. Finally, if

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

230 * M. Sperber and P. Thiemann

[q](,) := x,0  , \Lambda  [q](x; ,0)

j B ! * (ae) 2 predict(q) ^ (,)jk = ae \Lambda  [q](B; ,)
j A ! ff * (ae) 2 q ^ (,)jk = ae \Lambda  (A ! ff*; ,)

[q](X; ,) := A ! ff * Xfl 2 q ^

(A ! ffX * fl; o/)  [goto(q; X)] (,) \Lambda  (A ! ff * Xfl; o/)

j C ! *Xffi 2 predict(q) ^

(C ! X * ffi; o/)  [goto(q; X)] (,) \Lambda  [q](C; o/)

Fig. 1. Functional LR(k) parser, direct-style version.

q contains an item A ! ff* and, therefore, a reduction is possible, and the parserreturns that item along with the part of the input string not yet seen.

[q] first calls the function associated with goto(q, X), which returns an item anda rest string. When the parser has arrived at a state containing an item

A ! ff*,it returns through
|ff| - 1 function invocations, moving the dot back one symbolon each return:
A ! ffX * fl returned by [goto(q, X)] becomes A ! ff * Xfl. Thesecond alternative in

[q] is considered when the dot has arrived at the front of aright-hand side
C ! *Xffi by the process just described. In that case, [q] shifts onthe corresponding left-hand side

C.This technique for implementing LR parsing is called recursive ascent because

information about a production selected for inclusion in the derivation is passedon returning from a parsing function, thereby ascending in the function call graph.
This is in contrast to the recursive-descent technique for implementing LL parsing,where the parsing function selects a production to which it then makes a call,
thereby descending in the call graph.

Returning items from function calls may seem prohibitively expensive. In prac-tice, it is sufficient to return the left-hand side of the production and an integer

counting the number of levels left to return through. Our implementation of thespecification exploits this property.

Finally, the functional LR parsers have a close relation to the well-known stack-based implementations: The "run-time stack" of the procedure calls corresponds
to the parsing stack of traditional expositions of LR parsing.
3.3 Implementing Direct-Style LR Parsing
The formal specification of functional LR parsing gives rise to a naive workingimplementation of a general LR parser. Assuming an LR(k) input grammar, the

LR(k) parsing algorithm in Figure 1 becomes deterministic and thus transliterateseasily into a functional program which is shown in Figure 2.

The procedure ds-parse implements the function [ * ]. It accepts a grammar
grammar, the number of lookahead characters k, a function compute-closure thatcomputes the closure of a state, a set of LR(k) items

state, and the input input.The input is represented by a stream of pairs. Each pair contains a terminal

as its first component and an attribute value as its second component. (At-tribute values are only relevant for attribute evaluation discussed in Section 9.2.)
Compute-closure is a parameter so that the parser is sufficiently general to also

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 231
(define (ds-parse grammar k compute-closure state input)

(let ((closure (compute-closure state grammar k)))

(cond

((and (not (stream-empty? input))

(member (car (stream-car input))

(next-terminals closure grammar)))
(ds-parse-bar grammar k compute-closure closure

(car (stream-car input)) (stream-cdr input)))
((find-lookahead-item (accept closure) k input)

=> (lambda (item)

(let ((rhs-length (length (item-rhs item)))

(lhs (item-lhs item)))
(if (zero? rhs-length)

(ds-parse-bar grammar k compute-closure

state lhs input)
(values lhs rhs-length input)))))
(else (error "parse error")))))

(define (ds-parse-bar grammar k compute-closure state symbol input)

(let ((closure (compute-closure state grammar k)))

(call-with-values

(lambda ()

(ds-parse grammar k compute-closure

(goto closure symbol) input))
(lambda (lhs dot input)

(cond

((> dot 1)

(values lhs (- dot 1) input))
((and (initial? state grammar)

(equal? (grammar-start grammar) lhs))
(if (stream-empty? input)

'accept
(error "parse error")))
(else

(ds-parse-bar grammar k compute-closure

state lhs input)))))))

Fig. 2. Scheme implementation of direct-style functional LR(k) parser.
perform SLR or LALR parsing; Section 9.1 provides details.The

[ * ] function returns three values--the left-hand side of the production whichhas been reduced, the position of the dot in the right-hand side of that production, and the remaining input. The function find-lookahead-item selects an itemfrom the current state matching the lookahead in the current input. (The

condconditional form passes the return value of
find-lookahead-item to the functionin the
=> clause if it is not #f.) Accept extracts all items of the form A ! ff* fromthe closure of

state. Find-lookahead-item either returns an item matching thelookahead or
#f if no such item exists. Sections 6.1.2 and 8 discuss implementationstrategies for

find-lookahead-item.The implementation employs Scheme's support for functions returning multiple

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

232 * M. Sperber and P. Thiemann
values [Kelsey et al. 1998]. The values procedure constructs a multiple returnvalue from its arguments. Its counterpart,

call-with-values, is for processingmultiple values returned from a function: it calls the function of no arguments

which is its first parameter, and subsequently calls the function which is its secondparameter, passing the return values of the first function as arguments.

The ds-parse-bar procedure is the implementation of [ * ]. It first computesthe next state using the

goto function and applies ds-parse to obtain lhs, theleft-hand side of the production which has been reduced,

dot, the position of thedot in the right-hand side of that production, and
input, the remaining input.The position of the dot in the returned item guides further actions. If

dot isnot zero yet, the parser must move further backward. In this case,
ds-parse-barterminates with the dot shifted by one symbol to the left. The left-hand side

lhs andthe remaining input
input remain unchanged. Hence, the result is (values lhs (-
dot 1) input). Otherwise, if dot has reached zero, all symbols of the right-handside of the reduced production have already been popped. Then,

ds-parse-bar istail-called on the current state. It shifts the symbol
lhs and consumes the remaininginput
input.
Ds-parse-bar also performs checking for the end of input which is only allowedin the initial state of the grammar. (This checking is not present in the specification which implicitly assumes the input is delimited by k end-of-input symbols.)
Initial? checks if a state is the initial state.Most of the auxiliary functions such as those for constructing and accessing items

(item-lhs, item-rhs) as well as for accessing grammars (grammar-start), etc, aretrivial. Only

compute-closure is slightly more involved as it constructs a transitiveclosure.

4. CONTINUATION-BASED LR PARSING
The direct-style functional approach is a feasible way to implement LR parsing.However, it is possible to do better by expressing LR parsing with continuations

[Sperber 1994]. The continuation-based parser is the result of applying a sequenceof well-known transformation steps to the direct-style specification. The first step
transforms the direct-style parser into continuation-passing style as in Leermakers[1993]. The next step changes the representation of continuations in the resulting
parser using closure conversion [Reynolds 1972]. The final step is a subtle repre-sentation change of the parsing state in the continuation closures.

The resulting continuation-based parser is more concise than the direct-styleparser and just as amenable to effective specialization. In addition, it allows for a
natural and elegant implementation of attribute evaluation and error recovery (seeSection 9). It is also suitable for further improvements beyond the scope of this
article, notably an extended model of attribute evaluation [Sperber 1994], whichwould be cumbersome to implement in the direct-style version.

4.1 Transformation to Continuation-Passing Style
Figure 3 shows the result of transforming the direct-style specification of LR parsingfrom Figure 1 to continuation-passing style [Reynolds 1972; Plotkin 1975; Fischer

1993; Danvy and Filinski 1992]. Both functions [q] and [q] receive an additionalcontinuation parameter

c, which maps a pair of an LR(k) item and an input string to

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 233
[q](,; c) := x,0  , \Lambda  [q](x; ,0; c)

j B ! * (ae) 2 predict(q) ^ (,)jk = ae \Lambda  [q](B; ,; c)
j A ! ff * (ae) 2 q ^ (,)jk = ae \Lambda  c(A ! ff*; ,)

[q](X; ,; c) := [goto(q; X)](,; d(q; c))
d(q; c)(A ! ffX * fl; o/) := A ! ff * Xfl 2 q \Lambda  c(A ! ff * Xfl; o/)

j A ! ff * Xfl 2 predict(q) \Lambda  [q](A; o/; c)

Fig. 3. Direct-style functional LR(k) parser after transformation to continuation-passing style.

[q](,; c) := x,0  , \Lambda  [goto(q; x)](,0; d(q; c))

j B ! * (ae) 2 predict(q) ^ (,)jk = ae \Lambda  [goto(q; B)](,; d(q; c))
j A ! ff * (ae) 2 q ^ (,)jk = ae \Lambda  a(c; (A ! ff*; ,))

a(d(q; c); (A ! ffX * fl; o/)) := A ! ff * Xfl 2 q \Lambda  a(c; (A ! ff * Xfl; o/))

j A ! ff * Xfl 2 predict(q) \Lambda  [goto(q; A)](o/; d(q; c))

Fig. 4. Continuation-passing-style LR(k) parser after inlining and closure conversion.
a final answer. Following Leermakers [1993], a function d creates the continuation.It has been lifted to the toplevel by introducing the free variables

q and c asparameters. This will prove convenient for subsequent transformation steps.

An obvious transformation is inlining [q] into the definition of [q]. This movesthe case analysis into the continuation.

4.2 Applying Closure Conversion
Closure conversion [Reynolds 1972] replaces the construction of a first-class functionby the construction of a data structure (a closure) which contains a tag identifying

the body of the function and the values of its free variables. In addition, thetransformation replaces function application

c(v) by a call to a function a(c, v).The function
a performs a case analysis of c's tag and dispatches to the body ofthe corresponding function after putting the values of the free variables in place.

In the parser, the only function closure arising is the closure of the continuation
d(q, c) where q and c are the required values of the free variables. Hence, a simplereinterpretation of

d as the constructor tag for its closure yields the formulation inFigure 4.

4.3 Changing the Representation
The final transformation step changes the closure representation by including thefunction

[goto(q, A)] called in the second branch of a in the closure. To this end,the transformation introduces the function

f(q, k) that performs all shift actions onnonterminal symbols. It replaces the state

q in the continuation closure. Figure 5shows the resulting parser.

It is easy to see that the representation of a continuation is a list of functions
f(q, c) for varying q and c. Consequently, the function a is just a list-indexingfunction where the index is the position of the dot in the item argument. Finally,

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

234 * M. Sperber and P. Thiemann

[q](,; c) := x,0  , \Lambda  [goto(q; x)](,0; d(f(q; c); c))

j B ! * (ae) 2 predict(q) ^ (,)jk = ae \Lambda  [goto(q; B)](,; d(f(q; c); c))
j A ! ff * (ae) 2 q ^ (,)jk = ae \Lambda  a(c; (A ! ff*; ,))

a(d(f; c); (A ! ffX * fl; o/)) := ff 6= " \Lambda  a(c; (A ! ff * Xfl; o/))

j ff = " \Lambda  f(A; o/)

f(q; c)(A; o/) := A ! *Xfl 2 predict(q) \Lambda  [goto(q; A)](o/; c)

Fig. 5. Continuation-passing-style LR(k) after change in closure representation.

[q](,; c1; : : : ; cnactive(q)) :=

letrec

c0(X; ,) = [goto(q; X)] (,; c0; c1; : : : ; cnactive(goto(q;X))-1)
in

A ! ff * (ae) 2 closure(q) ^ (,)jk = ae \Lambda  cjffj(A; ,)

j x,0  , ^ x 2 nextterm(q) \Lambda  c0(x; ,0)

Fig. 6. Functional LR(k) parser, continuation-based version.
the parser [q](,, c) accesses its continuation at most at the maximal position ofthe dot in an item in

q. Formally, this is the number of active symbols of state q,nactive
(q):

nactive(q) := max{|ff| : A ! ff * fi 2 q}
When the parser is in state q, then nactive(q) is the maximal number of statesthrough which the parser may have to go back when it reduces by a production

in q. Therefore, as a further improvement, each call to [q] can prune c to lengthnactive

(q).

4.4 Formulating Continuation-Based LR Parsing
Two further transformation steps yield Sperber's LR parser [Sperber 1994]. Sperberpasses the functions in the list as separate arguments so that each access--and hence

each reduction step--takes unit time. The crucial insight here is that only the firstnactive

(q) elements of the list are accessed, as discussed above. This change ofrepresentation facilitates merging all cases where goto is called into one line of

code.A further definition is necessary to specify the resulting code concisely. The
function nextterm maps an LR state q to the set of all terminals on which q mightperform a shift action:

nextterm(q) := {x | A ! ff * xfi 2 closure(q)}
With this definition, Figure 6 shows the resulting specification.The locally created continuation

c0 performs a state transition. The invocationof
c0 with a grammar symbol X means "return to state q and shift on X." Theparameter

c1 is the continuation created by the previous state, c2 the one createdby the state two symbols back, and so on. With the continuations in place, the

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 235
(define (cps-parse grammar k compute-closure

state continuations input)
(let ((closure (compute-closure state)))

(define (c0 symbol input)

(cond

((not (and (initial? state grammar)

(equal? (grammar-start grammar) symbol)))
(cps-parse grammar k compute-closure

(goto closure symbol)
(cons c0

(take (- (nactive (goto closure symbol)) 1)

continuations))
input))
((stream-empty? input) 'accept)
(else 'error)))

(cond

((and (not (stream-empty? input))

(member (car (stream-car input))

(next-terminals closure grammar)))
(c0 (car (stream-car input)) (stream-cdr input)))
((find-lookahead-item (accept closure) k input)

=> (lambda (item)

((list-ref (cons c0 continuations)

(length (item-rhs item)))
(item-lhs item) input)))
(else 'error))))

Fig. 7. Scheme implementation of continuation-based parser.
actual parser dispatch has only two cases: when the parser has seen the completeright-hand side of a production and the lookahead matches, it goes back the number
of steps indicated by the length of the right-hand side. It does so by directly callingthe continuation belonging to the destination state instead of shifting the dot back
through multiple procedure invocations. It is sure to reach a state which can shifton the left-hand side of the production. Moreover, when the parser sees a terminal
matching the next terminal of an item, it shifts on that terminal by calling thecontinuation created in the current state.

4.5 Implementating Continuation-Based LR Parsing
Just as with the direct-style parser, the implementation is deterministic whengiven an LR(k) grammar. Figure 7 shows the transliteration of the above specification. The parameter continuations is a list containing the continuations
c1, . . . , cnactive(state) from the specification. The take function takes two argu-ments,

n and l, and extracts the first n elements of the list l. Otherwise, the codeis a direct transliteration of the formulation in Figure 6. The only thing it adds is

proper handling for the end of the input and a preference of shifting over reducingif both are possible.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

236 * M. Sperber and P. Thiemann
5. PRAGMATICS OF OFFLINE PARTIAL EVALUATION
This section provides some general background on partial evaluation. Readers fa-miliar with the field may want to skip it. In particular, the section gives a high-level

overview of what partial evaluation is, a brief introduction into the workings of off-line partial evaluators, an overview over some of the binding-time improvements
necessary for making programs amenable to offline partial evaluation, and a de-scription of performing partial evaluation with generating extensions.

5.1 Preliminaries
Partial evaluation is a specialization technique based on aggressive constant prop-agation: if parts of the input of a subject program are known at compile time, a

partial evaluator propagates this static input to generate a specialized program. Thespecialized program takes the remaining, dynamic parts of the input as parameters and produces the same results as the subject program applied to the completeinput.

For example, consider a program text p with semantics JpK, taking two inputsin
1 and in2. Suppose p terminates producing an output out:

out := JpK(in1, in2)
This situation provides opportunity for partial evaluation, by first running a partialevaluator pe on

p and in1 (which supposedly terminates):

pin1 := pe(p, in1)
The resulting specialized program pin1 must terminate and produce the same out-put out when applied to in

2:

out = Jpin1K(in 2)

5.2 Offline Partial Evaluation
Offline partial evaluation consists of two stages, a binding-time analysis and a staticreducer. The binding-time analysis annotates all expressions of a subject program

with a binding time--either as executable at partial-evaluation time (static) ordeferred to run time (dynamic), usually starting from a user-supplied annotation
of the inputs of the program.A prominent example for this kind of scenario is, of course, a general parser which
essentially accepts a static grammar and a dynamic input as arguments. Anotherpopular, simpler example for partial evaluation is the standard

append functionthat concatenates two lists. With its first input annotated as static and its second

input dynamic, the output of the binding-time analysis may look as follows, withthe dynamic operations underlined:

(define (append l1 l2)

(if (null? l1)

l2
(cons (car l1) (append (cdr l1) l2))))

This type of annotation actually implies a monovariant binding-time analysis--eachexpression receives one (and only one) annotation, and thus appears in only one

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 237
binding-time context. This sometimes forces the analysis to annotate an expressionas dynamic even though it may be static in certain situations during specialization.

The static reducer processes the annotated program and the static inputs to gen-erate a specialized program, reducing the static parts and rebuilding the dynamic
parts.For the

append example, this means that the reducer is always able to evaluatethe nonunderlined parts, and whenever it encounters an underlined construct, the

construct shows up in the specialized program. Hence, the specialized program willalways consist of a chain of

cons applications, ending with l2. For instance, if thereducer specializes
append with l1 = '(foo bar baz), the following specializedprogram results:

(define (append_1 l2)

(cons 'foo (cons 'bar (cons 'baz l2))))

By default, the static reducer unfolds all procedure applications, as with the re-cursive call to

append above. For some recursive procedure calls unfolding mightresult in infinite specialization. Therefore, the static reducer must generate specialized procedures for these calls to preserve the recursion. The expressions forwhich the static reducer generates such procedures are called memoization points.
When the static reducer encounters such a memoization point, it does not unfoldbut generates a procedure call instead. If it has already encountered the same
memoization point with the same static components of its free variables, the gener-ated call refers to a previously generated procedure. Otherwise, the reducer must
generate an appropriate specialized procedure.With the

append example, the binding-time analysis must insert a memoizationpoint at the recursive call if

l1 is dynamic, so as to prevent infinite unfolding.

5.3 Binding-Time Improvements
Every program transformation which enables the binding-time analysis to markmore expressions as static is a binding-time improvement. These improvements are

sometimes necessary to ensure good specialization results.

5.3.1 The Trick. "The Trick" is a well-known binding-time improvement [Joneset al. 1993]. It applies to a dynamic value

d which is known to belong to a finiteset
F of static values. The Trick amounts to choosing an appropriate context C of
d and replacing C[d] by a loop:

C[d] ) foreach s 2 F doif

s = d then C[s] else continue

Some partial evaluation systems will automatically select a context C and propagateit to the static value inside the loop [Lawall and Danvy 1994]. With such context

propagation in place, we only need to replace d by a loop to get the effect of TheTrick:

d ) foreach s 2 F doif

s = d then s else continue

To achieve context propagation, the binding-time analysis must not insert a mem-oization point at the dynamic conditional

s = d. The directive define-withoutACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

238 * M. Sperber and P. Thiemann
memoization tells the PGG system to do so. The loop translates directly into aScheme procedure which returns a static version of the dynamic parameter

elementif it occurs in the static list
set:

(define-without-memoization (maybe-the-member element set)

(let loop ((set set))

(cond

((null? set) #f)
((equal? element (car set)) (car set))
(else (loop (cdr set))))))

The above code returns #f in case element does not occur in set. If, however,
element is known to be in set, a slightly modified version of maybe-the-membercan exploit that knowledge and omit the last comparison.

(define-without-memoization (the-member element set)

(let loop ((set set))

(cond

((null? (cdr set)) (car set))
((equal? element (car set)) (car set))
(else (loop (cdr set))))))

5.3.2 Polyvariant Expansion. Monovariant binding-time analyses often markexpressions as dynamic even though they are static in some contexts. Consider

the following code fragment, assuming that main will be called with x static and ydynamic:

(define (main x y)

(+ (f x) (f y)))
(define (f z)

(+ z 1))

In principle, the specializer could perform the addition on x, but not on y. How-ever, since the monovariant binding-time analysis provides only one annotation for

the argument of f, it must annotate it as dynamic for all situations--an overlyconservative choice which makes for unsatisfactory specialization; namely for

x =
5 the specialized program is

(define (main-5 y)

(+ (+ 5 1) (+ y 1)))

It is possible to get around the problem by providing two versions of f--one foreach binding-time pattern:

(define (main x y)

(+ (f-s x) (f-d y)))
(define (f-s z)

(+ z 1))
(define (f-d z)

(+ z 1))

Specialization of this program produces the desired result:
ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 239
(define (main-5 y)

(+ 6 (+ y 1)))

5.4 Generating Extensions
An attractive feature of partial evaluation is the ability to construct generatingextensions. A generating extension for the general scenario of Section 5.1 above--a

program p with two inputs in1 and in2--is a program pgen which accepts the staticinput in

1 of p and produces the specialized program pin1:

pgen = pgg(p)

pin1 = Jpgen K(in1)

The pgg function that produces the generating extension is a program-generatorgenerator (PGG) to

p. (Actually, it is possible to generate a PGG automaticallyfrom a "normal" partial evaluator by a technique called double self-application [Futamura 1971; Turchin 1979; Jones et al. 1993]. However, it is more effective to writethe PGG directly.) A PGG is also called a compiler generator (cogen) because it
can turn an interpreter into a compiler. Specialization with generating extensionsis attractive because it is considerably faster than specialization with a normal,
interpretive partial evaluator [Bondorf 1991].Applied to the parsing scenario, a PGG turns a general parser into a parser
generator. In this article, we use Thiemann's PGG system [Thiemann 1996a] forthe implementation.

6. GENERATING EFFICIENT DIRECT-STYLE LR PARSERS
The implementation of direct-style parsing presented in Section 3.3 is not directlyamenable to efficient offline partial evaluation; a few improvements are necessary.

6.1 Improving Binding Times
Three applications of The Trick are sufficient to specialize the direct-style parsereffectively.

6.1.1 Shifting Statically. The calls to ds-parse-bar in Figure 2 require an ap-plication of The Trick: if the symbol argument

symbol is dynamic, then the resultof the function is dynamic as well. All symbol arguments are dynamic. However, for

each call to ds-parse-bar, the set of symbols which may occur is finite and static.A naive approach would take all grammar symbols as that finite set. However, it
is possible to restrict the set further. The first call in ds-parse corresponds to ashift on a terminal symbol. With nextterm

(q) as the static finite set and with thecall to
ds-parse-bar as context C, the first call has a static value for the symbolparameter.

The other calls pass a nonterminal as the symbol argument. The remaining callin

ds-parse passes lhs from the unique item with an empty right-hand side, sothis argument is already static. To the recursive call in

ds-parse-bar we haveto apply The Trick once more: in analogy to nextterm, the function nextnonterm

maps a state q to the set with the left-hand side nonterminals of items of the form
A ! *ff:

nextnonterm(q) := {A | A ! *ff 2 closure(q)}
ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

240 * M. Sperber and P. Thiemann
(define (ds-parse grammar k compute-closure state input)

(let ((closure (compute-closure state grammar k)))

(define (reduce)

(cond

((find-lookahead-item (accept closure) k input)

=> (lambda (item)

(let ((rhs-length (length (item-rhs item)))

(lhs (item-lhs item)))
(if (zero? rhs-length)

(ds-parse-bar grammar k compute-closure

closure lhs input)
(values lhs rhs-length input)))))
(else (error "parse error"))))

(cond!

((stream-empty? input) (reduce))!
((maybe-the-member (car (stream-car input))

(next-terminals closure grammar))
=> (lambda (symbol)

(ds-parse-bar grammar k compute-closure

closure symbol (stream-cdr input))))
(else (reduce)))))

(define (ds-parse-bar grammar k compute-closure closure symbol input)

(let ((the-next-nonterminals (next-nonterminals closure grammar)))

(call-with-values

(lambda ()

(ds-parse grammar k compute-closure

(goto closure symbol) input))
(lambda (lhs dot input)

(cond!

((null? the-next-nonterminals)!

(values lhs (- dot 1) input))
((> dot 1)

(values lhs (- dot 1) input))
((and (initial? closure grammar)

(equal? (grammar-start grammar) lhs))
(if (stream-empty? input)

'accept
(error "parse error")))
(else

(ds-parse-bar grammar k compute-closure

closure!
(the-member lhs the-next-nonterminals)
input)))))))

Fig. 8. Direct-style LR(k) parser after binding-time improvements.
ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 241
(define (lookahead-matches? k lookahead input)

(let loop ((k k) (lookahead lookahead) (input input))

(cond

((zero? k))
((null? lookahead) (stream-empty? input))
((stream-empty? input) #f)
((equal? (car lookahead) (car (stream-car input)))

(loop (- k 1) (cdr lookahead) (stream-cdr input)))
(else #f))))

(define (find-lookahead-item item-set k input)

(let loop ((item-set item-set))

(if (null? item-set)

#f
(let ((item (car item-set)))

(if (lookahead-matches? k (item-lookahead item) input)

item
(loop (cdr item-set)))))))

Fig. 9. Checking for lookahead.
The Trick is applicable in exactly the same way as before. By construction of thegoto function, the left-hand side,

lhs, of the item returned by ds-parse must bea member of nextnonterm
(q). Hence, it is possible to use the-member instead of
maybe-the-member in this case.Figure 8 shows the parser after the improvements. The listing marks bindingtime-improving changes with !. The reordering of the main conditional requiresfactoring out the

reduce action into a procedure; the code itself does not change,however. Moreover, the implementation passes

closure directly to ds-parse-barinstead of recomputing it there from
state; this speeds up parser generation.The improved parser contains another subtle change to separate binding times:

ds-parse has to restructure the test for reduction which results in the two callsto the function

reduce. This is to separate the dynamic test for the end of theinput from the static test for the next nonterminal.

Anding them together as in theoriginal version would make the next nonterminal dynamic.

6.1.2 Checking for Lookahead. The other place where The Trick applies is theimplementation of

find-lookahead-item. The loop in the naive implementation isimplicit; making it visible to the specializer enables new optimizations, for example,

loop unrolling. Figure 9 shows an implementation. Section 8 describes more efficientlookahead-checking strategies which avoid repeated deconstruction of the input
stream.
6.2 Generating Code
Binding-time analysis, applied to this parser for a static grammar and static looka-head size, classifies all computations concerned with computing lookahead sets,

items, closures, and actions as static. Only direct dependencies on the input andsome parse results remain dynamic.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

242 * M. Sperber and P. Thiemann

The specializer performs the equivalent of the standard sets-of-items constructionon-the-fly using its memoization point mechanism: for each state, specialization
generates one version of ds-parse and one of ds-parse-bar. It is beneficial tocater to the fact that the parser represents states by item lists, since Scheme lacks
a native set data type: a set typically has several representations as a list. Therefore,the parser normalizes the states by sorting the items to avoid redundant procedures
in the specialized parser.Furthermore, parser generation performs an optimization on parse tables which
is wellknown in the compiler community [Chapman 1987, Chap. 6.3]. Parse tablescan be simplified by merging reduce actions with the immediately preceding shift
action to a shift/reduce action if no conflicts arise. This transformation happensautomatically.

Figure 10 shows specialized code for both parsing procedures. It illustrates nicelyhow uses of The Trick result in cascaded tests in the specialized program (cf. the
tests (equal? lhs ...) and (equal? n mlet...)). The specialized code exhibitsonly two notable differences to hand-optimized code: it contains a few superfluous
lets, which the simplest of compiler optimizers will inline, and the code accesses thehead of the input several times, e.g.,

mlet-96, mlet-131, mlet-173, and mlet-187contain the same value. This duplication arises strictly from the behavior of the

original find-lookahead-item procedure which also performs the access once forevery lookahead check. It would be easy enough to avoid the duplication here, but,
as it turns out, a more efficient lookahead procedure which is described in Section 8takes care of this problem as a side effect.

6.3 Improving Further
Two further optimizations make the generated parsers more efficient.

6.3.1 Improving The Trick. Most uses of The Trick in the literature employ thesimple linear-search-based implementation shown in Section 5.3.1. However, if there

is a total order < for the elements of the static set, binary search is possible. If ter-minals and nonterminals are simply numbers, the Trick loop in

maybe-the-memberchanges to the variant shown in Figure 11. A variant of
the-member results byadding a special
cond branch for one-element lists.The call
(sort-list set <) sorts set in ascending order, and (take middle
sorted) returns the initial segment of length middle of list sorted.Whether using binary search actually gives a speed improvement depends highly

on the implementation strategies for conditionals used by the underlying Schemecompiler as well as on the grammar at hand. States with a large number of dispatches are rare.

6.3.2 Using Impure Features. The major bottleneck in the direct-style imple-mentation results from the necessity to return multiple values from a function--at

least the left-hand side of the production currently being reduced, the remainingnumber of procedure calls still to be returned through, and the remaining input. So
far, the return values differ only in their second component. Also, only one of themis live at any given time during the execution. Therefore, it is safe to replace its
components by global variables. A new version of the parser uses global variablesfor the left-hand-side nonterminal

lhs and the remaining input input and pass

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 243
(define (ds-parse-bar-50 clone-1)

(let* ((mlet-4 (lambda () (ds-parse-15 clone-1)))

(mlet-13

(lambda (lhs_1-5 dot_1-6 input_6-7)

(cond ((> dot_1-6 1)

(values lhs_1-5 (- dot_1-6 1) input_6-7))
((equal? 0 lhs_1-5)

(if (stream-empty? input_6-7)

'accept
(error "parse error")))
((equal? lhs_1-5 3) (ds-parse-bar-46 input_6-7))
((equal? lhs_1-5 2) (ds-parse-bar-47 input_6-7))
(else (ds-parse-bar-48 input_6-7))))))
(call-with-values mlet-4 mlet-13)))
(define (ds-parse-7 input-1)

(if (stream-empty? input-1)

(let* ((mlet-34 (stream-car input-1))

(mlet-33 (car mlet-34)))
(if (equal? 5 mlet-33)

(values 2 1 input-1)
(let* ((mlet-76 (stream-car input-1))

(mlet-75 (car mlet-76)))
(if (equal? 6 mlet-75)

(values 2 1 input-1)
(let* ((mlet-90 (stream-car input-1))

(mlet-89 (car mlet-90)))
(if (equal? 10 mlet-89)

(values 2 1 input-1)
(error "parse error")))))))
(let* ((mlet-96 (stream-car input-1))

(mlet-95 (car mlet-96)))
(cond ((equal? mlet-95 8)

(ds-parse-bar-8 (stream-cdr input-1)))
((equal? mlet-95 7)

(ds-parse-bar-16 (stream-cdr input-1)))
(else

(let* ((mlet-131 (stream-car input-1))

(mlet-130 (car mlet-131)))
(if (equal? 5 mlet-130)

(values 2 1 input-1)
(let* ((mlet-173 (stream-car input-1))

(mlet-172 (car mlet-173)))
(if (equal? 6 mlet-172)

(values 2 1 input-1)
(let* ((mlet-187 (stream-car input-1))

(mlet-186 (car mlet-187)))
(if (equal? 10 mlet-186)

(values 2 1 input-1)
(error "parse error"))))))))))))

Fig. 10. Specialized functional parser.
ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

244 * M. Sperber and P. Thiemann
(define (maybe-the-member element set)

(let loop ((sorted (sort-list set <)) (size (length set)))

(cond

((null? sorted) #f)
((>= size 3)

(let* ((middle (- (quotient (+ size 1) 2) 1))

(static-element (list-ref sorted middle)))
(cond

((= static-element element)

static-element)
((< element static-element)

(loop (take middle sorted) middle))
(else

(loop (list-tail sorted (+ middle 1))

(- size (+ middle 1)))))))
((= element (car sorted))

(car sorted))
(else

(loop (cdr sorted) (- size 1))))))

Fig. 11. The Trick using binary search.

(define *lhs* #f)
(define *input* #f)

(define (ds-parse grammar k compute-closure state input)

: : :

(ds-parse-bar grammar k compute-closure closure lhs input)!
(begin (set! *lhs* lhs)!

(set! *input* input)!
rhs-length)))))
: : :

(define (ds-parse-bar grammar k compute-closure closure symbol input)!

(let ((dot (ds-parse grammar k compute-closure!

(goto closure symbol) input))!
(lhs *lhs*)!
(input *input*))
: : :

Fig. 12. Direct-style parser using imperative features.
the position of the dot dot within the right-hand side of the item as result. Fig-ure 12 shows the changes to the implementation in Figure 2--the modified lines are
indicated with !. The resulting speedup of the specialized parsers is impressive.
7. GENERATING EFFICIENT CONTINUATION-BASED LR PARSERS
Just as with the parser in Section 6.1, a few changes are necessary to the naiveimplementation of the continuation-based parser to make it specialize well. Sometimes, transformation to continuation-passing style makes programs specialize betACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 245
ter [Consel and Danvy 1991]. However, our use of continuations in the parser is notmotivated by binding-time considerations; rather it is intrinsic in the formulation
of the parsing algorithm.
7.1 Termination
The use of continuations in specialization is often problematic, since it can lead tononterminating specialization. Therefore, we have performed specialization experiments with the intermediate versions of the transformation from the direct-styleformulation to the continuation-based one. Two of them have termination problems.
--The version after transformation to continuation-passing style (Figure 3) leadsto nonterminating specialization. The binding-time analysis discovers that the

continuation is static, and therefore specialization continues to generate newspecialized versions of

[q] for ever-growing continuation arguments.

--The version after closure conversion (Figure 4) exhibits essentially the same prob-lem. The list

d(q, c) is static and leads to the same phenomenon.

--In the final version, pruning the list according to nactive(q) is the essential step toensuring terminating specialization. Section 7.3 exhibits a further improvement

to avoid code blow-up.
7.2 Binding-Time Improvements
The Trick applies in the same situations as in the direct-style parser. However, thecompact specification of the continuation-based parser has only one place where

shifting occurs (the continuation), whereas in the direct-style version separatefunction calls are responsible for shifting on terminals and nonterminals, respectively. Hence, we only know that the symbol argument to c0 is a member ofnextterm

(state) [ nextnonterm(state). Applying The Trick naively would spe-cialize to one loop that tests

symbol against both terminals and nonterminals.However, the parser calls
c0 from two different call sites. The first site only everpasses nonterminals, the second only terminals. Thus, splitting

c0--into one versionfor nonterminals and another for terminals--and applying The Trick in the same

way as with the direct-style parser yields the desired results from specialization.Curiously, this amounts to undoing the clever steps leading from the result of the
transformation in Figure 5 to Sperber's formulation in Figure 6.
7.3 Removing the List of Continuations
Using standard Scheme lists for storing the continuations introduces a performanceproblem with most partial evaluators [Bondorf 1993]: these partial evaluators treat

cons, car, and cdr as ordinary primitive operations, rather than as data construc-tors and selectors. Traditional monovariant binding-time analyses [Bondorf 1991]
expect the arguments to a primitive to be static data of base type if the specializeris to reduce the primitive. Since our parser passes a procedure to the primitive
cons, the binding-time analysis detects a type clash and defers the expected errorto run time by marking the

cons as dynamic. Therefore, the specialized parserspresently construct and pass lists of continuations. This is grossly inefficient, as the

structure of the list is static.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

246 * M. Sperber and P. Thiemann!

(define-data c-list!

(c-cons c-car c-cdr)!
(c-nil))

(define (cps-parse grammar k compute-closure state continuations input)

(let* ((closure (compute-closure state grammar k))

(accept-items (accept closure))
(the-next-nonterminals (next-nonterminals closure grammar)))!

(define (shift symbol input)

(let ((next-state (goto closure symbol)))

(cps-parse grammar k compute-closure

next-state!
(c-cons (and (not (null? the-next-nonterminals))

shift-nonterminal)!
(c-take (- (nactive next-state) 1)

continuations))
input)))

(define (shift-nonterminal nonterminal input)!

(if (and (initial? state grammar)!

(equal? (grammar-start grammar) nonterminal))!
(if (stream-empty? input)

'accept
'error)
(shift!

(the-member nonterminal the-next-nonterminals)
input)))

(define (reduce item)!

((c-list-ref (c-cons (and (not (null? the-next-nonterminals))

shift-nonterminal)
continuations)
(length (item-rhs item)))
(item-lhs item) input))

(cond!

((stream-empty? input)!

(cond!

((find-eoi-lookahead-item accept-items) => reduce)!
(else 'error)))!
((maybe-the-member (car (stream-car input))

(next-terminals closure grammar))
=> (lambda (symbol)

(shift symbol (stream-cdr input))))
((find-lookahead-item accept-items k input) => reduce)
(else 'error))))

Fig. 13. Continuation-based parser after binding-time improvements.
ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 247
In the specification, the parser states simply pass the continuations as separatearguments. To achieve the same effect in the specialized parsers, it is necessary to
convey the structure of the list of continuations to the binding-time analysis andto the specializer. Most partial evaluators support partially static data structures
for just that purpose: they allow the construction of aggregates which contain bothstatic and dynamic components. In our case, the spine of the list is known. Hence,
declaring a partially static list datatype to the partial evaluator and replacing cons,
car, and cdr by their counterparts achieves the desired purpose. The binding-time analysis keeps the spine of the list static. The static reducer performs "arity

raising" and creates a separate parameter for each list element. Splitting up thelist of continuations is crucial for the performance of the specialized parsers.

However, with this change, the binding-time analysis actually propagates toomuch information. It maintains that the functions in the list are also static which
prompts the specializer to generate separate versions of each state for each possibleconstellation of continuations that may be its parameters, resulting in code blowup. Therefore, we have to force the binding-time analysis to regard the elementsof the

continuations list itself as dynamic. This is typically achieved by a specialoperator provided by the partial evaluator at hand which forces its argument to

become dynamic. Applying the operator to the occurrences of c0 has the desiredeffect.

Our final implementation achieves this effect by a different means. If the parseris in a state without an item of the form

A ! *ff then the parser will never shift ona nonterminal in this state. Therefore, in such a state, the parser puts a dummy

value #f on the list of continuations and never bothers to construct the actualcontinuation. Therefore, an element of the

continuations list might either bea function (an actual continuation) or a boolean

#f. The binding-time analysisdetects the apparent type clash and makes all the list elements dynamic to avoid

an error at specialization time. The corresponding test in the code is (not (null?
the-next-nonterminals)).Figure 13 shows the parser with the binding-time improvements applied. Changes

are again marked with ! symbols. Just as with the direct-style parser, the improvedversion factors out the reduce action into a separate procedure

reduce.

7.4 Generating Code
The results of specializing the continuation-based parser are similarly satisfyingas those from specializing the direct-style version. Figure 14 shows a sample. In

the sample, the shift-nonterminal function previously internal to cps-parsehas moved to the top level, as the PGG system performs Lambda lifting in the
frontend [Johnsson 1985]; this is purely a specific property of PGG. As the codewas generated using the same version of

find-lookahead-item, it shows the sameduplication of the calls to
stream-car and car--to be remedied in the next section.

8. EFFICIENT CHECKING FOR LOOKAHEAD
The specialized parsers should check for lookahead efficiently. Specifically, theyshould touch as few input characters as possible, and they should perform as few

operations as possible to determine the next state of the parser. As seen in SecACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

248 * M. Sperber and P. Thiemann
(define (cps-parse-19 mlet-1 mlet-2 clone-3 clone-4)

(if (stream-empty? clone-4)

(mlet-1 3 clone-4)
(let* ((mlet-7 (stream-car clone-4))

(mlet-6 (car mlet-7)))
(if (equal? 5 mlet-210)

(mlet-1 3 clone-4)
(let* ((mlet-481 (stream-car clone-4))

(mlet-480 (car mlet-481)))
(if (equal? 6 mlet-480)

(mlet-1 3 clone-4)
(let* ((mlet-571 (stream-car clone-4))

(mlet-570 (car mlet-571)))
(if (equal? 7 mlet-570)

(mlet-1 3 clone-4)
(let* ((mlet-601 (stream-car clone-4))

(mlet-600 (car mlet-601)))
(if (equal? 8 mlet-600)

(mlet-1 3 clone-4)
(let* ((mlet-611 (stream-car clone-4))

(mlet-610 (car mlet-611)))
(if (equal? 10 mlet-610)

(mlet-1 3 clone-4)
'error))))))))))))

(define (shift-nonterminal-3 nonterminal-2 input-1)

(cond ((equal? 0 nonterminal-2)

(if (stream-empty? input-1) 'accept 'error))
((equal? nonterminal-2 3)

(let ((mlet-6

(lambda (nonterminal_3-3 input_9-4)

(shift-nonterminal-3 nonterminal_3-3 input_9-4))))
(cps-parse-4 mlet-6 input-1)))
((equal? nonterminal-2 2)

(let ((mlet-11

(lambda (nonterminal_3-8 input_9-9)

(shift-nonterminal-3 nonterminal_3-8 input_9-9))))
(cps-parse-10 mlet-11 input-1)))
(else

(let ((mlet-16

(lambda (nonterminal_3-13 input_9-14)

(shift-nonterminal-3 nonterminal_3-13 input_9-14))))
(cps-parse-23 mlet-16 input-1)))))

Fig. 14. Specialized continuation-based parser.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 249
(define (find-lookahead-item item-set k input)

(let loop ((lookaheads+items (map (lambda (item)

(cons (item-lookahead item)

item))
item-set))
(remaining k)
(input input))
(cond

((null? lookaheads+items)

#f)
((zero? remaining)

(cdar lookaheads+items))
((and (not (= k remaining))

(stream-empty? input))
(let ((empties

(filter (lambda (lookahead+item)

(null? (car lookahead+item)))
lookaheads+items)))
(if (null? empties)

#f
(cdar empties))))
(else

(loop (filter-lookaheads+items lookaheads+items

(car (stream-car input)))
(- remaining 1)
(stream-cdr input))))))

(define (filter-lookaheads+items lookaheads+items terminal)

(let* ((non-empties (filter (lambda (lookahead+item)

(not (null? (car lookahead+item))))
lookaheads+items))
(one-lookaheads (map (lambda (lookahead+item)

(car (car lookahead+item)))
non-empties))
(static-terminal (maybe-the-member terminal

one-lookaheads))
(matches

(filter

(lambda (lookahead+item)

(equal? static-terminal (caar lookahead+item)))
non-empties)))

(map (lambda (lookahead+item)

(cons (cdr (car lookahead+item))

(cdr lookahead+item)))
matches)))

Fig. 15. Efficient checking for lookahead with tries.
ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

250 * M. Sperber and P. Thiemann
tions 6.2 and 7.4, the generated code still contains redundant accesses to the headof the input. This problem gets worse with

k > 1.Figure 15 displays the implementation of a variant of The Trick. The variant of

find-lookahead-item successively narrows down the set of items that matches thecurrent lookahead. For this purpose,

find-lookahead-item pairs up the remaininglookaheads with their respective items and uses

filter-lookaheads+items to firstweed out the items which do not match the next single lookahead, and subsequently

remove that one lookahead from the lookahead-item pairs. The filter functionwhich the code employs takes a predicate and a list as arguments. It returns a list
of exactly those elements that match the predicate. The new version effectively en-codes tries and therefore neither performs redundant checks nor extraneous accesses
to the input.
9. ADDITIONAL FEATURES
The presented parsers so far are LR(k) recognizers. A few modifications and addi-tions are necessary to make them useful for applications: SLR and LALR parsing,

attribute evaluation, and an error recovery mechanism. Partial evaluation-basedparser generation is amenable to these additions.

9.1 SLR and LALR
Pure LR parsers for realistic languages often lead to prohibitively big state automa-tons [Chapman 1987], and thus to impractically big parsers. Fortunately, most realistic formal languages are already amenable to treatment by SLR or LALR parserswhich introduce lookahead into essentially LR(0) parsers.

The SLR(k) parser corresponding to an LR(0) parser [DeRemer 1971] with states
q(0)0 , . . . , q(0)n has states q0, . . . , qn. In contrast to the LR(k) parser, the SLR(k)automaton has the following states:

qi := {A ! ff * fi (ae) | A ! ff * fi 2 q(0)i , ae 2 followk(A)}
In the definition, followk(A) is the set of all terminal sequences of length <= k thatmay follow

A in a sentential form.

followk(A) := {, | S *) fiAfl ^ , 2 firstk(fl)}
Analogously, the predict items are the same as in the LR(0) case, only with addedlookahead:

predict(qi) := {A ! ff * fi (ae) | A ! ff * fi 2 predict(0)(q(0)i ), ae 2 followk(A)}
The state transition goto is also just a variant the LR(0) case here called goto(0):

goto(qi, X) := qj for q(0)j = goto(0)(q(0)i , X)
It is immediately obvious how to modify an LR(0) parser into an SLR(k) parser--the main parsing function merely has to replace the current state by one decorated

by lookahead as described above. The effects of using SLR(k) instead of LR(k)are as expected: generation time and size decrease, often dramatically for realistic
grammars (see Table I in the next section).The LALR method uses a more precise method of computing the lookahead,
but also works by decorating an LR(0) parser [DeRemer 1969]. Thus, the same

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 251
[q](,; c1; : : : ; cnactive(q); s1; : : : ; snactive(q)) :=

letrec

c0(X; s0; ,) = [goto(q; X)](,; c0; c1; : : : ; cn; s0; s1; : : : ; sn)

where n = nactive(goto(q; X)) - 1
in

A ! ff * (ae) 2 closure(q) ^ ,jk = ae \Lambda  cjffj(A; fA!ff(sjffj; : : : ; s1); ,)
j , = x,0 ^ x 2 nextterm(q) \Lambda  c0(x; 2; ,0)

Fig. 16. Continuation-based LR(k) parser with attribute evaluation.
methodology as with the SLR case is applicable, merely replacing followk with the(more involved) LALR lookahead function.

Unfortunately, all efficient methods of computing LALR lookahead sets requireaccess to the entire LR(0) automaton in advance [DeRemer and Pennello 1982; Park
et al. 1985; Ives 1986; Park and Choe 1987; Ives 1987a; 1987b]. Since our generalparser does not have access to a representation of the automaton, introducing the
LALR method would require computing one and operating on that, instead ofrelying on the partial evaluator to implicitly generate it. The feasibility of the
approach is not impaired by this, but explicitly computing the automaton somewhatbreaks its spirit and elegance.

9.2 Attribute Grammars
The pure recognizers used so far are of little use in practice. To take advantage ofthe results of the parsing process, the parser must associate a semantics with the

input string. The most common way to do this is the attribute grammar mech-anism [Knuth 1968; 1971]. Many popular parser generators such as Yacc [Johnson 1975] restrict themselves to S-attributed grammars where all attributes can beevaluated "on-the-fly" during parsing. This is entirely sufficient for parsers whose
principal job is to compute an abstract representation of the syntax tree. Parserscan propagate additional values such as symbol tables via global variables. However, more general attribute evaluation strategies are also possible, and the parserspresented here are in fact especially amenable to them [Sperber 1994]. Moreover,
higher-order functions can simulate more general attribution schemes within theframework of S-attributed grammars [Chirica and Martin 1979].

An S-attributed grammar is a context-free grammar where each nonterminal Ais associated with a synthesized attribute

sA, while each production is augmentedwith an attribution. An attribution of a production

A ! X1 . . . Xn is a function
fA!X1...Xn which maps the synthesized attributes of the Xi, s1 . . . sn to the syn-thesized attribute of

A via

sA = fA!X1...Xn (s1, . . . , sn).
A straightforward extension of the direct-style parsers and the continuation-basedparsers performs attribute evaluation for S-attributed grammars on-the-fly--while
parsing the input. Attribute evaluation in the direct-style parser requires an explicitattribute stack. The continuation-based parser handles attributes in the same way
as the list of continuations, as a partially static list that contains the attributes

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

252 * M. Sperber and P. Thiemann
(define(cps-parse grammar k compute-closure state

continuations attribute-values input)
(let* ((closure (compute-closure state grammar k))

(accept-items (accept closure))
(the-next-nonterminals (next-nonterminals closure grammar)))

(define (shift symbol attribute-value input)

(let* ((next-state (goto closure symbol))

(keep (- (nactive next-state) 1)))
(cps-parse grammar k compute-closure

next-state
(c-cons (and (not (null? the-next-nonterminals)) shift-nonterminal)

(c-take keep continuations))!
(c-cons attribute-value (c-take keep attribute-values))
input)))

(define (shift-nonterminal nonterminal attribute-value input)

(if (and (initial? state grammar)

(equal? (grammar-start grammar) nonterminal))
(if (stream-empty? input)!

attribute-value
(error "parse error"))
(shift (the-member nonterminal the-next-nonterminals)

attribute-value input)))

(define (reduce item)

(let* ((rhs-length (length (item-rhs item)))

(attribution (production-attribution (item-production item)))!
(attribute-value!

(apply-attribution!

attribution!
(c-list->list!

(c-reverse!

(c-take rhs-length attribute-values))))))
((c-list-ref (c-cons (and (not (null? the-next-nonterminals))

shift-nonterminal)
continuations)
rhs-length)
(item-lhs item) attribute-value input)))

(cond ((stream-empty? input)

(cond ((find-eoi-lookahead-item accept-items) => reduce)

(else (error "parse error"))))
((maybe-the-member (car (stream-car input))

(next-terminals closure grammar))
=> (lambda (symbol)

(shift symbol (cdr (stream-car input)) (stream-cdr input))))
((find-lookahead-item accept-items k input) => reduce)
(else (error "parse error")))))

Fig. 17. Implementation of continuation-based parser with attribute evaluation.
ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 253
[q](,; s) := x,0  ,

\Lambda  [q](x; ,0; 2; s)
j B ! * (ae) 2 predict(q) ^ ,jk = ae

\Lambda  [q](B; ,; fB!"(); s)
j A ! ff * (ae) 2 q ^ ,jk = ae

\Lambda  (A ! ff*; ,; fA!ff(sjffj; : : : ; s1))

[q](X; ,; s0; s) := A ! ff * Xfl 2 q ^ (A ! ffX * fl; o/; s00)  [goto(q; X)](,; s0 : s)

\Lambda  (A ! ff * Xfl; o/; s00)
j C ! *Xffi 2 predict(q) ^ (C ! X * ffi; o/; s00)  [goto(q; X)](,; s0 : s)

\Lambda  [q](C; o/; s00; s)

Fig. 18. Direct-style LR(k) parser with attribute evaluation.
for the currently active symbols. It is simpler than the direct-style version andtherefore presented first.

The continuation-based parser adheres to the specification in Figure 16. Theattribute value domain is assumed to contain a value

2 which the parser assigns toterminals. In the implementation, the parser accepts sequences of token/attribute

pairs, so that terminals may also carry attribute information. Implementation--shown in Figure 17--is straightforward.

The specification of the direct-style parser with on-the-fly attribute evaluationshown in Figure 18 is somewhat more complicated. Now,

[q] accepts an inputstring and an attribute stack. As in a traditional LR parser, the attribute stack

contains the values of the attributes of all symbols currently on the parse stack.The function returns a triple consisting of an LR item, the remaining input, and
the value of the synthetic attribute of the left-hand-side nonterminal of the item.(The attribute value is generated when reduction of an item

A ! ff* is initiated.)
[q] is similarly extended to deal with the attribute stack and the attribute value ofthe shifted symbol.

The attribute stack is implemented as a list s with elements s1s2 . . . sn. The infixoperator

: puts an element in front of the list (implementing the push operation).The implementation never removes elements explicitly, but returning from a function invocation of [q] "forgets" the first element of s. In principle, the algorithmcould crop the lists just like the algorithm in Figure 16, but we left them as is to
keep the analogy with the attribute stack in a traditional implementation.In order to perform attribute evaluation the attribution of each production must
be transferred to the generated parser. One way to achieve attribute evaluation isto interpret the attributions:

(interpret (cons (attribution->definition attribution)

program)
(take rhs-length attribute-stack))

Unfortunately, this approach has several drawbacks. First, the interpreter must bewritten, which is straightforward, but rather tedious, especially if full Scheme is

to be supported. Second, parser generation becomes grossly inefficient because thepartial evaluator must specialize the interpreter which actually runs the code of the
attribution--at least one superfluous layer of interpretation.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

254 * M. Sperber and P. Thiemann

A much better choice consists in using eval to transform the text of the attri-bution into the actual code:

(apply (eval attribution (interaction-environment))

(take rhs-length attribute-stack))

Since attribution will be static, the specializer could remove eval from the codeand simply paste in the static value of

attribution, considered as code. For ex-ample, for the attribution
(lambda ($1 $2 $3) (* $1 $3)) the specializer shouldgenerate the following code:

(let ((var-9031 ((lambda ($1 $2 $3)

(* $1 $3))
(car var-9030)
(car var-9029)
(car clone-9018))))
...)))

The partial evaluator used for the implementation of the parsers handles eval and
apply correctly [Thiemann 1996b] which results in a clear, concise, and efficientsolution to the problem.

9.3 Error Recovery
Realistic applications of parsers require sensible handling of parsing errors. Specifi-cally, the parser should, on encountering a parsing error, issue an error message and

resume parsing in some way, repairing the error if possible. The literature aboundswith theoretical treatments of recovery techniques applicable to LR parsing [Chapman 1987; Sippu and Soisalon-Soininen 1990] using a wide variety of methods. Mostof these methods are phrase-level recovery techniques that work by transforming an
incorrect input into a correct one by deleting terminals from the input and insert-ing generated ones. Among the many phrase-level recovery techniques, few have
actually been used in production LR parser generators.To demonstrate the feasibility of effective error recovery in our approach, we have
implemented two realistic algorithms: the grammar-assisted method of Yacc [John-son 1975] based on error productions and the fully automatic technique of R"ohrich
[1980] as implemented in the Lalr parser generator [Grosch 1990].Since effective error recovery requires fine-grained control over the operation of
the parser, the continuation-based parser is considerably more amenable to the im-plementation of these techniques--hence, the treatment of error recovery is entirely
in the context of the continuation-based parsers.

9.3.1 Yacc-Style Error Recovery. Yacc provides a special "error terminal" asa means for the user to specify recovery annotations. A typical example is the

following grammar for arithmetic expressions E (terminals such as number, +, etc.,are in typewriter font):

E ! T | error | T +E | T -E
T ! P | P*T | P/T
P ! number | (E) | (error)

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 255
Whenever the parser encounters a parsing error, it pops symbols from the parsestack until it reaches a state where it can shift on the error terminal. There, the
parser shifts and then skips input terminals until the next input symbol is acceptableto the parser again. In the example, the parser, when encountering an error in a
parenthesized expression, will skip until the next closing parenthesis.To keep the error messages from avalanching, the parser needs to keep track of
the number of terminals that have been shifted since the last error; if the last errorhappened very recently, chances are the new error has actually been effected by the
error recovery. In that case, the parser should skip at least one input terminal (toguarantee termination), and refrain from issuing another error message.

This method is fairly crude, but has proven effective. It also has the advantageover fully automatic methods that it provides the grammar author with the ability
to tailor specific error messages to the context of a given error and specify sensibleattribute evaluation rules.

In the continuation-based parser, the Yacc method is fairly straightforward toimplement. In addition to the usual continuations to perform reductions, we supply
an error continuation handle-error which brings the parser back immediately intothe last state to shift on the error terminal [Leermakers 1993]. In addition, another
parameter error-status keeps track of the number of terminals that the parser stillneeds to shift until it can resume issuing error messages; in our case that number
is three. Thus, all calls to cps-parse pass the handle-error and error-statusparameters like this:

(cps-parse

. . .
(if (handles-error? closure grammar)

handle-error-here
handle-error)
. . .)

(Handle-error-here needs to be made dynamic to prevent nonterminating spe-cialization.)

Whenever the parser shifts on a terminal, it adjusts error-status to

(if (zero? error-status) error-status (- error-status 1))
Figure 19 shows the relevant handle-error-here function.Thus, Yacc-style error recovery fits our parser model very naturally, and calling the error continuation directly is certainly more efficient than scanning thestack explicitly, as Yacc needs to do. Additionally, we have the option to keep the
error-status count static. This results in an increase in code size, but also in asmall gain in parser speed.

9.3.2 Fully Automatic Backtrack-Free Error Recovery. In contrast to the simplemodel of Yacc, the sophisticated method of R"ohrich [1980] allows for (almost) fully
automatic error recovery. The price is added complexity and lower performance.We only sketch the method here, since the details of the algorithm are rather involved. R"ohrich's algorithm constructs a continuation automaton from the parsingautomaton which in turn constructs a valid continuation of the input from a valid
prefix (a prefix of a correct input). The continuation automaton is merely a special

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

256 * M. Sperber and P. Thiemann
(define (handle-error-here error-status input)

(let* ((next-state (goto closure (grammar-error grammar)))

(keep (- (nactive next-state) 1))
(next-closure (compute-closure next-state grammar k))
(next-accept-items (accept next-closure))
(input

(cond

((zero? error-status) input)
((stream-empty? input)

(error "parse error: premature end of input"))
(else (stream-cdr input)))))

(define (recover attribute-value input)

(cps-parse grammar k compute-closure

next-state
(c-cons (and (not (null? the-next-nonterminals))

shift-nonterminal)
(c-take keep continuations))
(c-cons attribute-value

(c-take keep attribute-values))
handle-error-here 3
input))

(let loop ((input input))

(define (reduce-recover item)

(let* ((rhs-length (length (item-rhs item)))

(attribution (production-attribution

(item-production item)))
(attribute-value

(apply-attribution

attribution
(c-list->list

(c-reverse

(c-cons #f (c-take (- rhs-length 1)

attribute-values)))))))
(recover attribute-value input)))
(cond

((stream-empty? input)

(cond

((find-eoi-lookahead-item next-accept-items) => reduce-recover)
(else (error "parse error: premature end of input"))))
((maybe-the-member (car (stream-car input))

(next-terminals next-closure grammar))
=> (lambda (symbol)

(recover (cdr (stream-car input)) input)))
((find-lookahead-item next-accept-items k input)

=> reduce-recover)
(else (loop (stream-cdr input)))))))

Fig. 19. Yacc-style error recovery.
ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 257
(begin

;; report the error
(display "Syntax error: expected one of ")
(write (uniq (append (next-terminals closure grammar)

(flatten (items-lookaheads accept-items)))))
(newline)

(set! *repairing?* #t)
(set! *anchors* '())

;; construct the set of anchors
(cps-parse grammar k compute-closure

state
continuations attribute-values
input)

;; skip until anchor
(let ((input

(let loop ((input input))

(if (and (not (stream-empty? input))

(member (car (stream-car input)) *anchors*))
input
(begin

(display "Deleting ")
(write (car (stream-car input)))
(newline)
(loop (stream-cdr input)))))))

(set! *anchors* #f)
(set! *repairing* #t)

;; repair
(cps-parse grammar k compute-closure

state
continuations attribute-values
input)))

Fig. 20. R"ohrich-style error handling.
interpretation of a variant of the LR state automaton. In the variant, the states areno longer sets of items but, rather, sorted sequences. This makes the automaton
with error recovery larger than the canonical LR automaton.On encountering an error, the algorithm performs the following steps:

(1) First, it simulates running the parser on a constructed continuation of thecurrent correct prefix until parsing terminates. All terminals of the continuation

form the set of anchors which are valid restarting points for parsing.
(2) The parser deletes terminals from the input until the next terminal is one ofthe anchors.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

258 * M. Sperber and P. Thiemann
(3) Then, the parser synthesizes a continuation (the same as generated in the firststep) up until the anchor from where it can resume parsing.

In a parser that interprets a representation of the LR state table, the simulation ofthe automaton is straightforward. To simulate running the parser, it merely needs
to copy the parsing stack so that it can be restored when actual parsing resumes.In our continuation-based parser, we have essentially two choices:

(1) construct separate functions for actually running the parser and simulating itor
(2) use the same functions for each task and keep track of the difference by a localstate.

The first alternative has the disadvantage that partial evaluation would create two(or even three) variants of the parser, one for regular parsing, one for collecting
anchors, and one for continuing the input. We have therefore chosen to use theregular parsing functions and keep a global state. One is the

*repairing?* flagwhich is true when error recovery is in progress. The other state component is

*anchors* which contains the current list of anchors as they are being collected.Figure 20 shows the code that the parser executes on encountering a parsing
error. For brevity's sake, it does not perform attribute evaluation. Once the parseris in "repair mode," it checks in each state if it can continue parsing with the
current lookahead. If not, the state has an associated continuation terminal whichthe parser can use instead. In that case, it must also generate an attribute value
for the generated terminal which is supplied as part of the source grammar.
10. EXPERIMENTAL RESULTS
With both the direct-style and the continuation-based implementation models, thegenerated LR parsers compare favorably with those generated by traditionally built

parser generators such as Bison [Donnelly and Stallman 1995] as well as thoseproduced by the partial evaluation of a stack-based implementation presented by
Mossin [1993].The two implementation models have different merits; while the direct-style approach leads to more compact parsers, the continuation-based parsers are fasterin most cases. We have applied both Mossin's parser generator as well as our
continuation-based and direct-style approaches to three different example gram-mars. To confine the results to parsing proper, the generated parsers do not perform
attribute evaluation or error recovery.Table I shows the sizes of the input grammars and the sizes of the generated
parsers. The sizes are given in the number of cells used for the Scheme representa-tions. The column "Mossin" gives numbers for parsers generated from Mossin's general parser; "LR" is for the direct-style parsers; and "CPS-LR" is for continuation-based parsers. In column "SLR" we give the sizes of the specialized direct-style
SLR(1) parsers. The example grammars are those used by Mossin: G1 defines bal-anced parentheses,

G2 arithmetic expressions, and G3 the language Mixwell [Joneset al. 1985].

Table II shows the run times of the generated parsers over different grammarsand inputs of varying sizes. The measurements were taken on an IBM RS/6000

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 259
Table I. Size of Specialized Parsers for k = 1 (in cons-cells)

G Size (G) Mossin LR CPS-LR SLR
G1 24 1608 652 1236 491
G2 48 3751 2070 2999 1197
G3 123 6181 5870 7294 2700

Table II. Run Times of the Specialized Parsers (timings in ms)
G Size (input) Mossin LR CPS-LR LR-Imp Bison
G1 2 0.0637 0.0986 0.0480 0.0439 0.0220

8 0.2030 0.2465 0.1343 0.0747 0.0586
28 0.6376 0.7474 0.4470 0.1896 0.1785
G2 3 0.1372 0.1732 0.0840 0.0554 0.0379

13 0.4213 0.6273 0.3689 0.1254 0.1123
35 0.9957 1.3755 0.9294 0.2605 0.2600
G3 9 0.1293 0.3509 0.1211 0.0671 0.0600

51 0.7699 1.6911 0.7523 0.3012 0.2847
186 2.6190 5.8680 2.9020 1.0130 0.9470
983 12.4240 31.0130 13.4630 4.5970 4.6280

model 320 with 24MB of real memory running AIX >3.2.5. We used Bigloo 1.7,a Scheme compiler which generates C code, with maximum optimization. The C
code was compiled using the native C compiler, xlc 1.3. The column "LR-Imp"shows the results for an imperative version of the direct-style parser along the lines
of Figure 12. The last column shows timings for equivalent LALR(1) parsers in Cgenerated by Bison 1.22 and compiled with maximum optimization. The input for
the Bison parser was fed directly from a constant array containing the token codes.Thus, all timings measure purely the parsing time.

The timings indicate that the speed of our functional parsers is within a factor of2 of (with direct-style parsing) or surpasses (with the continuation-based approach)
those generated from the stack-based approach by Mossin [1993]. The imperativedirect-style version even surpasses those timings and gets very close to the Bisongenerated parsers in speed. These results indicate the practicability of our approach.Moreover, we have used the continuation-based parser generator to develop the
front end of an ANSI C compiler [Kernighan and Ritchie 1988].Since it is possible to test a given grammar with the general parser, our observation has been that users typically only apply the parser generator toward the endof the development cycle. During development, the general parser allows for almost
instant turnaround.

11. RELATED WORK
The pioneering work on functional LR parsing is due to Pennello [1986]. He gives alow-level implementation of a direct-style functional parser. He reports a speedup

of 6 to 10 over implementations that utilize a table representation of the parsingautomaton. As a matter of fact, the Bison parser generator [Donnelly and Stallman
1995] which we used for comparisons in our benchmarks is much faster than theparser generator implementation Pennello used; it seems unlikely that significant
performance improvements are possible over the parser model presented here.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

260 * M. Sperber and P. Thiemann

Leermakers [1993] provides an overview of functional parsing. A summary alongwith a description of the continuation-based approach is given by Sperber [1994]. He
uses the continuation-based parsing algorithm to implement sophisticated attributeevaluation. The resulting algorithms are used in the parser generator of the Mo/rk
system for preprocessor generation.As already mentioned in this article, Mossin [1993] uses Similix [Bondorf 1993]
to obtain specialized LR(1) parsers from general parsers. He starts from a stack-based first-order approach which does not specialize well. He transforms the stack
data structure into a continuation which pops elements off the stack. The transfor-mation complicates the program considerably and requires intricate binding-time
improvements and other optimizations to achieve good specialization.

Dybkjaer [1985] as well as Ershov and Ostrovsky [1987] describe previous attemptsto specialize general parsers.

Pagan [1991] describes, among other examples for partial computation, the con-struction of LL and LR parser generators. However, his approach is rather adhoc,
and the generation of the parser generators is not automatic but done by hand.

Consel and Danvy [1993] give an overview of partial evaluation. Jones et al.[1993] give a more in-depth study of techniques and applications of the field.

The idea of self-application and its use for semantics-based compilation stemsfrom Futamura [1971] and has been refined by Turchin [1979]. Since then, compiler
generation and self-application have been among the main fields of interest for re-searchers in partial evaluation. This led to the discovery of offline partial evaluation
and the construction of practical compiler generators [Jones et al. 1985].

Instead of using a partial evaluator and self-application to create standaloneprogram generators, it is also possible to use a hand-written program-generator

generator [Launchbury and Holst 1991] which also boosts efficiency and solvessome coding problems as compared to using self-application. We have used such a
program-generator generator [Thiemann 1996a] to generate our parser generators.

The Trick seems to be as old as offline partial evaluation [Dybkjaer 1985; Gomardand Jones 1991; Bondorf 1993; Jones et al. 1993], as it is necessary for effective selfapplication. No existing offline partial evaluator automates The Trick. However,there is a formalization that incorporates The Trick into a binding-time analysis
for the lambda calculus and defines context propagating rules for static reductions[Danvy et al. 1996].

Swierstra and Duponcheel [1996] define a combinator library for recursive-descentparsers from LL(1) grammars in a lazy functional language based on earlier work
by Hutton [1990]. These parsers appear to specialize themselves by exploitingthe laziness of the language. There are two differences to our approach, despite
the fact that we are concerned with LR parsing. First, their combinators exploitthe memoization capabilities of the lazy evaluation. The effects are similar to
what specialization can achieve, but Holst and Gomard [1991] have shown thatspecialization is strictly stronger than lazy evaluation (even in the presence of full
laziness), at least in a higher-order programming language. Second, while ourparser generators can check whether the grammar satisfies the LR(k) (or SLR (k))
condition, the parser combinators loop when used for a grammar which is not LL(1).

Parser generation is a typical application of offline partial evaluation. Othersuch applications are compilation, compiler generation, and program transformaACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 261
tion. These applications share similar binding-time improvements which lead togood specialization, as well as the necessity of a memoization point mechanism to
obtain termination. The common improvement of using partial evaluation for theseapplications is the removal of interpretive overhead. Consequently, the speedup obtained depends mostly on the proportion of overhead in the original programs.Jones et al. [1993] describe a number of these applications. They are in contrast
to applications of offline partial evaluation in, for example, scientific computing.Here, the main benefit of specialization is constant propagation and loop unrolling,
just as in an optimizing compiler. Hence, specialization generally obtains mostlyconstant speedups in these areas.

12. CONCLUSION
We have used partial evaluation to generate fast and compact LR(k) parsers froma general functional parser and a reference grammar. We used two approaches

to implement the general parser: one which represents the parsing stack by theprocedure call stack, the other using continuations. No sacrifice of generality is
necessary to make the programs amenable to good specialization. There is no needto cater to specific optimizations used in parser generators, or to

k = 1.The functional approach needs only straightforward and well-known binding-time

improvements to generate efficient specialized parsers.The generated parsers are fast and compact, and they compare favorably with
Yacc-generated parsers. Consequently, partial evaluation is a realistic approach toimplementing production-quality parser generators.

APPENDIX
The parser generators constructed by transforming the general parsers describedin this article to generating extensions is available on the Worldwide Web under

http://www.informatik.uni-freiburg.de/proglang/software/essence/. Be-sides parser generators which are ready to run, the distribution also contains the
source for various general LR parsers, suitable for specialization with the PGGsystem. For the more adventurous, the PGG system is also available from

http://www.informatik.uni-freiburg.de/proglang/software/pgg/
ACKNOWLEDGMENTS
We thank Christian Mossin for graciously supplying us with the source code of hisprograms and sample inputs. Thanks are also due to the PEPM '95 referees who

provided detailed and constructive comments. Frank Knoll was a patient beta testerduring the development of his C front end. Finally, thanks are due to the anonymous
reviewers who provided helpful comments. One suggested that partial evaluationmight transform the direct-style parser into the continuation-based formulation; we
are especially grateful for his insight.
REFERENCES
Bondorf, A. 1991. Automatic autoprojection of higher order recursive equations. Science of

Computer Programming 17, 3-34.

Bondorf, A. 1993. Similix 5.0 Manual. DIKU, University of Copenhagen.
Chapman, N. P. 1987. LR parsing: theory and practice. Cambridge University Press, Cambridge.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

262 * M. Sperber and P. Thiemann
Chirica, L. and Martin, D. 1979. An order algebraic definition of Knuthian semantics. Theor.

Comp. Sci. 13, 1-27.
Consel, C. and Danvy, O. 1991. For a better support of static data flow. See Hughes [1991],

pp. 496-519.
Consel, C. and Danvy, O. 1993. Tutorial notes on partial evaluation. In Proc. 20th Annual

ACM Symposium on Principles of Programming Languages, Charleston, South Carolina, pp.
493-501. ACM Press.
Danvy, O. and Filinski, A. 1992. Representing control: A study of the CPS transformation.

Mathematical Structures in Computer Science 2, 361-391.
Danvy, O., Malmkjaer, K., and Palsberg, J. 1996. Eta-expansion does The Trick. ACM

Transactions on Programming Languages and Systems 18, 6 (Nov.), 730-751.
Dencker, P., D"urre, K., and Heuft, J. 1984. Optimization of parser tables for portable compilers. ACM Transactions on Programming Languages and Systems 6, 4 (Oct.), 546-572.
DeRemer, F. and Pennello, T. 1982. Efficient computation of LALR(1) look-ahead sets. ACM

Transactions on Programming Languages and Systems 4, 4 (Oct.), 615-649.
DeRemer, F. L. 1969. Practical translators for LR(k) parsers. Ph.D. thesis, Department of

Electrical Engineering, Massachusetts Institute of Technology, Cambridge, Ma.
DeRemer, F. L. 1971. Simple LR(k) grammars. Communications of the ACM 14, 7, 453-460.

Donnelly, C. and Stallman, R. 1995. Bison--The YACC-compatible Parser Generator. Boston,

MA: Free Software Foundation. Part of the Bison distribution.
Dybkjaer, H. 1985. Parsers and partial evaluation: An experiment. Student Report 85-7-15 (July),

DIKU, University of Copenhagen, Denmark.
Ershov, A. P. and Ostrovsky, B. N. 1987. Controlled mixed computation and its application to

systematic development of language-oriented parsers. In L. G. L. T. Meertens (Ed.), Program
Specification and Transformation, Proc. IFIP TC2/WG 2.1 Working Conference on Program
Specification and Transformation, pp. 31-48. North Holland.
Fischer, M. J. 1993. Lambda-calculus schemata. Lisp and Symbolic Computation 6, 3/4, 259-

288.

Futamura, Y. 1971. Partial evaluation of computation process -- an approach to a compilercompiler. Systems, Computers, Controls 2, 5, 45-50.

Gomard, C. K. and Jones, N. D. 1991. A partial evaluator for the untyped lambda-calculus.

Journal of Functional Programming 1, 1 (Jan.), 21-70.

Grosch, J. 1990. Lalr--a generator for efficient parsers. Software--Practice & Experience 20, 11

(Nov.), 1115-1135.
Holst, C. K. and Gomard, C. K. 1991. Partial evaluation is fuller laziness. In P. Hudak and

N. D. Jones (Eds.), Proc. ACM SIGPLAN Symposium on Partial Evaluation and SemanticsBased Program Manipulation PEPM '91, New Haven, CT, pp. 223-233. ACM. SIGPLAN
Notices 26(9).

Hughes, J. (Ed.) 1991. Functional Programming Languages and Computer Architecture, Volume

523 of Lecture Notes in Computer Science, Cambridge, MA. Springer-Verlag.

Hutton, G. 1990. Parsing using combinators. In K. Davis and J. Hughes (Eds.), Functional

Programming, Glasgow 1989, pp. 353-370. Springer-Verlag.
IEEE 1991. Standard for the Scheme programming language. Tech. Rep. 1178-1990, Institute of

Electrical and Electronic Engineers, Inc., New York.
Ives, F. 1986. Unifying view of recent LALR(1) lookahead set algorithms. SIGPLAN Notices 21, 7

(July), 131-135. Proceedings of the SIGPLAN'86 Symposium on Compiler Construction.
Ives, F. 1987a. An LALR(1) lookahead set algorithm. Unpublished manuscript.
Ives, F. 1987b. Response to remarks on recent algorithms for LALR lookahead sets. SIGPLAN

Notices 22, 8 (August), 99-104.
Johnson, S. C. 1975. Yacc--yet another compiler compiler. Tech. Rep. 32, AT&T Bell Laboratories, Murray Hill, NJ.
Johnsson, T. 1985. Lambda lifting: Transforming programs to recursive equations. In Proc. Functional Programming Languages and Computer Architecture 1985, Volume 201 of Lecture Notes
in Computer Science. Springer-Verlag.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

Generation of LR Parsers by Partial Evaluation * 263
Jones, N. D., Gomard, C. K., and Sestoft, P. 1993. Partial Evaluation and Automatic Program

Generation. Prentice-Hall.
Jones, N. D., Sestoft, P., and So/ndergaard, H. 1985. An experiment in partial evaluation:

The generation of a compiler generator. In J.-P. Jouannaud (Ed.), Rewriting Techniques and
Applications, Dijon, France, pp. 124-140. Springer-Verlag. LNCS 202.

Kelsey, R., Clinger, W., and Rees, J. 1998. Revised5 report on the algorithmic language Scheme. Higher-Order and Symbolic Computation 11, 1, 7-105. Also appears in ACM SIGPLAN Notices 33(9), September 1998. Available electronically as
http://www.neci.nj.nec.com/homepages/kelsey/r5rs.ps.gz.

Kernighan, B. W. and Ritchie, D. M. 1988. The C Programming Language. Prentice-Hall. 2nd

edition.
Knuth, D. E. 1965. On the translation of languages from left to right. Information and Control 8,

607-639.
Knuth, D. E. 1968. Semantics of context-free languages. Mathematical Systems Theory 2, 127-

145.
Knuth, D. E. 1971. Semantics of context-free languages. Mathematical Systems Theory 5, 95-96.

Correction to [Knuth 1968].
Launchbury, J. and Holst, C. K. 1991. Handwriting cogen to avoid problems with static typing.

In Draft Proceedings, Fourth Annual Glasgow Workshop on Functional Programming, Skye,
Scotland, pp. 210-218. Glasgow University.

Lawall, J. L. and Danvy, O. 1994. Continuation-based partial evaluation. In Proc. 1994 ACM

Conference on Lisp and Functional Programming, Orlando, Florida, USA, pp. 227-238. ACM
Press.
Leermakers, R. 1993. The Functional Treatment of Parsing. Kluwer Academic Publishers,

Boston.
Mossin, C. 1993. Partial evaluation of general parsers. In D. Schmidt (Ed.), Proc. ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation PEPM
'93, Copenhagen, Denmark, pp. 13-21. ACM Press.

Pagan, F. L. 1991. Partial Computation and the Construction of Language Processors. PrenticeHall.
Park, J. C. and Choe, K.-M. 1987. Remarks on recent algorithms for LALR lookahead sets.

SIGPLAN Notices 22, 4 (April), 30-32.
Park, J. C. H., Choe, K. M., and Chang, C. H. 1985. A new analysis of LALR formalisms.

ACM Transactions on Programming Languages and Systems 7, 1 (Jan.), 159-175.
Pennello, T. J. 1986. Very fast LR parsing. SIGPLAN Notices 21, 7, 145-151.
Plotkin, G. 1975. Call-by-name, call-by-value and the *-calculus. Theor. Comp. Sci. 1, 125-159.

Reynolds, J. C. 1972. Definitional interpreters for higher-order programming languages. In ACM

Annual Conference, pp. 717-740.
R"ohrich, J. 1980. Methods for the automatic construction of error correcting parsers. Acta

Inf. 13, 115-139.
Roberts, G. H. 1988. Recursive ascent: An LR analog to recursive descent. SIGPLAN Notices 23, 8, 23-29.
Sippu, S. and Soisalon-Soininen, E. 1990. Parsing Theory, Volume II (LR(k) and LL(k) Parsing)

of EATCS Monographs on Theoretical Computer Science. Springer-Verlag, Berlin.
Sperber, M. 1994. Attribute-directed functional LR parsing. Unpublished manuscript.
Sperber, M. and Thiemann, P. 1999. Essence--User Manual. Freiburg, Germany: Universit"at

Freiburg. Available from ftp://ftp.informatik.uni-freiburg.de/iif/thiemann/essence/.
Swierstra, S. D. and Duponcheel, L. 1996. Deterministic, error-correcting combinator parsers.

In J. Launchbury, E. Meijer, and T. Sheard (Eds.), Advanced Functional Programming,
Volume 1129 of Lecture Notes in Computer Science, pp. 184-207. Springer-Verlag.

Tarjan, R. E. and Yao, A. 1979. Storing a sparse table. Communications of the ACM 22, 11,

606-611.
Thiemann, P. 1996a. Cogen in six lines. In R. K. Dybvig (Ed.), Proc. International Conference

on Functional Programming 1996, Philadelphia, PA, pp. 180-189. ACM Press, New York.

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.

264 * M. Sperber and P. Thiemann
Thiemann, P. 1996b. Towards partial evaluation of full Scheme. In G. Kiczales (Ed.), Reflection'96, San Francisco, CA, USA, pp. 95-106.
Thiemann, P. 1999. The PGG System--User Manual. Freiburg, Germany: Universit"at Freiburg.

Available from ftp://ftp.informatik.uni-freiburg.de/iif/thiemann/pgg/.
Turchin, V. F. 1979. A supercompiler system based on the language Refal. SIGPLAN Notices 14, 2 (Feb.), 46-54.

Wilhelm, R. and Maurer, D. 1995. Compiler Design. Addison-Wesley.

Received August 1998; revised March 1999; accepted June 1999

ACM Transactions on Programming Languages and Systems, Vol. 22, No. 2, March 2000.