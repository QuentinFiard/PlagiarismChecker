

Semantics of Types for Mutable State

Amal Jamil Ahmed

A Dissertation
Presented to the Faculty

of Princeton University
in Candidacy for the Degree

of Doctor of Philosophy

Recommended for Acceptance

By the Department of

Computer Science

November 2004

cfl Copyright by Amal Jamil Ahmed, 2004. All rights reserved.

Abstract
Proof-carrying code (PCC) is a framework for mechanically verifying the safety
of machine language programs. A program that is successfully verified by a PCC
system is guaranteed to be safe to execute, but this safety guarantee is contingent
upon the correctness of various trusted components. For instance, in traditional
PCC systems the trusted computing base includes a large set of low-level typing
rules. Foundational PCC systems seek to minimize the size of the trusted computing
base. In particular, they eliminate the need to trust complex, low-level type systems
by providing machine-checkable proofs of type soundness for real machine languages.

In this thesis, I demonstrate the use of logical relations for proving the soundness
of type systems for mutable state. Specifically, I focus on type systems that ensure
the safe allocation, update, and reuse of memory. For each type in the language, I
define logical relations that explain the meaning of the type in terms of the operational semantics of the language. Using this model of types, I prove each typing
rule as a lemma.

The major contribution is a model of System F with general references -- that
is, mutable cells that can hold values of any closed type including other references,
functions, recursive types, and impredicative quantified types. The model is based
on ideas from both possible worlds and the indexed model of Appel and McAllester.

I show how the model of mutable references is encoded in higher-order logic. I
also show how to construct an indexed possible-worlds model for a von Neumann
machine. The latter is used in the Princeton Foundational PCC system to prove
type safety for a full-fledged low-level typed assembly language. Finally, I present a
semantic model for a region calculus that supports type-invariant references as well
as memory reuse.

iii

Acknowledgments
My work was funded by DARPA grant F30602-99-1-0519, NSF grant DGE-9972930,
and by the George Van Ness Lothrop Fellowship in Engineering for 2002-2003, a
Princeton University honorific fellowship.

First and foremost I would like to thank my advisor, Andrew Appel, for his
encouragement, support, and guidance throughout my graduate career. I am especially grateful for his energy and contagious enthusiasm which always made research
a pleasure. His door was always open, and his insights immensely valuable. I am
indebted to him for all that he has taught me, both technical and not.

Thanks also to my thesis readers, David Walker and Peter O'Hearn, for all the
time spent reading my thesis and for many helpful comments. David Walker taught
me a lot about logic and was both a mentor and friend. His influence on my work
and research interests is and, I expect, will remain evident. Peter O'Hearn is a
pool of immense wisdom and insight when it comes to research on mutable state. I
consider myself extremely fortunate to have had the benefit of his intuition. It has
undoubtedly helped me improve the quality of the work described in this thesis.

I've had the privilege of working with many talented people at Princeton. I have
learnt a great deal during my discussions with Juan Chen, Limin Jia, Neophytos
Michael, Xinming Ou, Chris Richards, Kedar Swadi, Gang Tan, and Dinghao Wu.
I would like to thank Roberto Virga and Xinming Ou for their contributions to this
thesis in terms of proof implementation.

Many people provided support and friendship during my time in graduate school.
I would especially like to thank Patrick Min and Iannis Tourlakis who made Office
417 a happy, fun, and special place. Thanks also to all the other grad students who
made my stay at the department more enjoyable, especially (in no particular order)

iv

Allison Klein, Sanjeev Kumar, Rudro Samanta, George Tzanetakis, Dan Dantas,
Jay Ligatti, and Georg Essl.

A special thanks to Melissa Lawson for taking care of countless numbers of things
without a hitch, including all the last-minute requests that I've dumped at her door.
Thanks also to the administrative and technical staff at the department who were
always friendly, always helpful, and amazing at making sure that everything ran
smoothly.

I would like to thank my parents for their endless love and support. Without a
doubt, I wouldn't be here today if it weren't for their belief that their daughter's
aspirations need never be different from their son's. This was certainly unorthodox
thinking for the part of the world I grew up in. Thanks also to my brother, Omar,
who has been a very important part of my life. I am especially grateful to him for
the interest and patience with which he has listened to my rambling and complaints,
and then known just what to say.

This thesis is dedicated to my father who passed away a few months before I
started at Princeton. His absence makes reaching this milestone bittersweet. But
it is comforting to know that he would have been happy and proud.

Finally, I would like to thank Ijlal, my husband and soulmate, for more love,
encouragement, and support than I could have ever thought possible.

v

For my Dadoo.
vi
Contents

Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii
1 Introduction 1

1.1 Mechanically Verifying Safety . . . . . . . . . . . . . . . . . . . . . 1

1.1.1 Type Systems . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.1.2 Type-Preserving Compilation . . . . . . . . . . . . . . . . . 5
1.1.3 Proof-Carrying Code . . . . . . . . . . . . . . . . . . . . . . 6
1.1.4 Foundational Proof-Carrying Code . . . . . . . . . . . . . . 7
1.2 Mutable State and Type Safety . . . . . . . . . . . . . . . . . . . . 9
1.3 Contributions and Dissertation Outline . . . . . . . . . . . . . . . . 10

2 Foundational Proofs of Safety 13

2.1 A Pure Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

2.1.1 Operational Semantics and Safety . . . . . . . . . . . . . . . 14
2.1.2 Semantics of Types and Judgments . . . . . . . . . . . . . . 15
2.1.3 Typability Implies Safety . . . . . . . . . . . . . . . . . . . . 17
2.1.4 Typing Rules as Lemmas . . . . . . . . . . . . . . . . . . . . 17
2.1.5 Discussion: Trusted Computing Base . . . . . . . . . . . . . 19
2.1.6 Discussion: Logical Relations . . . . . . . . . . . . . . . . . 19

vii

2.2 An Impure Language: Immutable References . . . . . . . . . . . . . 21

2.2.1 Semantics of Types using Possible Worlds . . . . . . . . . . 23
2.2.2 Validity of Types . . . . . . . . . . . . . . . . . . . . . . . . 27
2.2.3 Judgments, Typing Rules, and Safety . . . . . . . . . . . . . 28
2.2.4 Validity of Typing Rules . . . . . . . . . . . . . . . . . . . . 31
2.2.5 Discussion: Kripke Logical Relations . . . . . . . . . . . . . 33

3 Mutable References: Mutation & Quantified Types 36

3.1 Polymorphic *-calculus with Mutable Cells . . . . . . . . . . . . . . 38

3.1.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
3.1.2 Operational Semantics . . . . . . . . . . . . . . . . . . . . . 39
3.2 Towards a Model of Mutable References . . . . . . . . . . . . . . . 39

3.2.1 Need for a New Model . . . . . . . . . . . . . . . . . . . . . 39
3.2.2 Modeling Permissible Store Updates . . . . . . . . . . . . . 42
3.2.3 An Inconsistent Model . . . . . . . . . . . . . . . . . . . . . 43
3.2.4 A Hierarchy of Types . . . . . . . . . . . . . . . . . . . . . . 43
3.2.5 Stratifying Types Based on Syntax . . . . . . . . . . . . . . 44
3.2.6 Stratifying Types Based on Semantic Approximation . . . . 46
3.3 An Indexed Possible-Worlds Model . . . . . . . . . . . . . . . . . . 49

3.3.1 Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
3.3.2 Modeling Stratified Types as Sets . . . . . . . . . . . . . . . 50
3.3.3 Properties of Types . . . . . . . . . . . . . . . . . . . . . . . 51
3.3.4 Base Types . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
3.3.5 Function Types . . . . . . . . . . . . . . . . . . . . . . . . . 54
3.3.6 Quantified Types . . . . . . . . . . . . . . . . . . . . . . . . 56

viii

3.3.7 Judgments, Typing Rules, and Safety . . . . . . . . . . . . . 58
3.3.8 Components of Possible-Worlds Model . . . . . . . . . . . . 61
3.3.9 Well Founded and Nonexpansive Type Functions . . . . . . 62
3.4 Validity of Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
3.5 Validity of Typing Rules . . . . . . . . . . . . . . . . . . . . . . . . 66

3.5.1 Lambda Abstraction and Application . . . . . . . . . . . . . 66
3.5.2 Allocation, Assignment, Dereferencing . . . . . . . . . . . . 67
3.5.3 Type Abstraction and Application . . . . . . . . . . . . . . 72
3.5.4 Pack and Unpack . . . . . . . . . . . . . . . . . . . . . . . . 73
3.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

4 Mutable References: Extensions & Discussion 77

4.1 Eliminating Noncomputational Steps . . . . . . . . . . . . . . . . . 77
4.2 Modeling Additional Types . . . . . . . . . . . . . . . . . . . . . . 85

4.2.1 Recursive Types . . . . . . . . . . . . . . . . . . . . . . . . . 85
4.2.2 Union, Intersection, and Product Types . . . . . . . . . . . . 88
4.2.3 Singleton Types and Immutable References . . . . . . . . . . 88
4.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90

4.3.1 Allocation, Update, and Aliases . . . . . . . . . . . . . . . . 90
4.3.2 Cycles in Memory . . . . . . . . . . . . . . . . . . . . . . . . 92
4.4 Discussion and Related Work . . . . . . . . . . . . . . . . . . . . . 96

4.4.1 Limitation: Type Functions . . . . . . . . . . . . . . . . . . 96
4.4.2 Mixing Mutation and Quantified Types . . . . . . . . . . . . 96
4.4.3 Shared References and Monotonicity . . . . . . . . . . . . . 100
4.4.4 Coinduction and Non-wellfounded Sets . . . . . . . . . . . . 100

ix

4.4.5 Possible-Worlds Models . . . . . . . . . . . . . . . . . . . . . 101
4.4.6 Game Semantics . . . . . . . . . . . . . . . . . . . . . . . . 103
4.4.7 Other Related Work . . . . . . . . . . . . . . . . . . . . . . 103

5 Machine-Checked Proofs 105

5.1 Representation in CiC . . . . . . . . . . . . . . . . . . . . . . . . . 105
5.2 Representation in Higher-Order Logic . . . . . . . . . . . . . . . . . 108

5.2.1 A Hierarchy of G"odel Numberings . . . . . . . . . . . . . . . 108
5.2.2 Pretypes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
5.2.3 Defining the Representation Function . . . . . . . . . . . . . 115
5.2.4 Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
5.2.5 Judgments, Typing Rules, Safety . . . . . . . . . . . . . . . 119

6 Foundational Proof-Carrying Code 121

6.1 Overview of the FPCC System . . . . . . . . . . . . . . . . . . . . . 121
6.2 Von Neumann Model and Safety . . . . . . . . . . . . . . . . . . . . 124
6.3 Typed Machine Language . . . . . . . . . . . . . . . . . . . . . . . 125
6.4 Related Work: Syntactic Approach to FPCC . . . . . . . . . . . . . 132

7 Semantics of a Region Calculus 135

7.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
7.2 Operational Semantics . . . . . . . . . . . . . . . . . . . . . . . . . 137
7.3 Semantic Model of Types . . . . . . . . . . . . . . . . . . . . . . . . 138
7.4 Reference, Region Handle, and Function Types . . . . . . . . . . . . 141
7.5 Judgments and Typing Rules . . . . . . . . . . . . . . . . . . . . . 143
7.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

x

8 Conclusions and Future Work 147

8.1 A PER Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148

xi
List of Figures

1.1 Proof-Carrying Code Architecture . . . . . . . . . . . . . . . . . . . 6
1.2 Foundational Proof-Carrying Code Architecture . . . . . . . . . . . 8

2.1 Pure Functional Language (*P ): Operational Semantics . . . . . . . 14
2.2 Pure Functional Language (*P ): Type-checking Lemmas . . . . . . 16
2.3 Immutable References (*I ): Operational Semantics . . . . . . . . . 22
2.4 Immutable References (*I ): Type Definitions . . . . . . . . . . . . . 27
2.5 Immutable References (*I ): Type-checking Lemmas . . . . . . . . . 30

3.1 Mutable References (*M ): Syntax . . . . . . . . . . . . . . . . . . . 38
3.2 Mutable References (*M ): Operational Semantics . . . . . . . . . . 40
3.3 Store Update in the Presence of Aliasing . . . . . . . . . . . . . . . 41
3.4 Type Hierarchy Based on Syntax of Types . . . . . . . . . . . . . . 45
3.5 Type Hierarchy Based on Semantic Approximation . . . . . . . . . 48
3.6 Mutable References (*M ): Type Definitions . . . . . . . . . . . . . 59
3.7 Mutable References (*M ): Type-checking Lemmas . . . . . . . . . . 60

4.1 Union, Intersection, and Product Typing Rules . . . . . . . . . . . 89
4.2 Example 1: Allocation & Update in the Presence of Aliasing . . . . 91
4.3 Example 2: Creating a Cycle in the Store . . . . . . . . . . . . . . . 93

xii

4.4 Polymorphic References: SML Program . . . . . . . . . . . . . . . . 96
4.5 Polymorphic References: *M Program . . . . . . . . . . . . . . . . . 97

5.1 CiC: Definition of Type Hierarchy . . . . . . . . . . . . . . . . . . . 106
5.2 CiC: Definition of ref . . . . . . . . . . . . . . . . . . . . . . . . . . 107
5.3 CiC: Definition of S :k \Psi  . . . . . . . . . . . . . . . . . . . . . . . . 108
5.4 Higher-Order Logic: Pretype Definitions (parameterized by j) . . . 111
5.5 Higher-Order Logic: Type Definitions . . . . . . . . . . . . . . . . . 118

6.1 Foundational PCC System . . . . . . . . . . . . . . . . . . . . . . . 122
6.2 TML Type Constructors . . . . . . . . . . . . . . . . . . . . . . . . 128
6.3 Syntactic FPCC: Connecting TAL Evaluation to Real Machine Steps 133

7.1 Regions (*R): Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . 136
7.2 Regions (*R): Operational Semantics . . . . . . . . . . . . . . . . . 138
7.3 Regions (*R): Type-checking Lemmas . . . . . . . . . . . . . . . . . 144

8.1 Observationally Equivalent Contexts . . . . . . . . . . . . . . . . . 149
8.2 Observational Equivalence and Aliasing . . . . . . . . . . . . . . . . 151
8.3 Observationally Equivalent? . . . . . . . . . . . . . . . . . . . . . . 152

xiii

Chapter 1
Introduction
This thesis investigates the use of logical relations for proving the soundness of type
systems for mutable state. In particular, it focuses on type systems that ensure
the safe allocation, update, and reuse of a computer's memory. For each type in
the language, I shall define logical relations that explain the meaning of the type
in terms of the operational semantics of the language. This proof technique can
be used to build machine-checkable safety proofs for real assembly languages. Such
proofs are crucial for building flexible and secure systems for mechanically verifying
the safety of machine-language programs.

1.1 Mechanically Verifying Safety
Over the past decade, it has become increasingly common for networked devices
to receive and execute programs from various sources. Personal computers, PDAs,
and mobile phones can download and run new applications. Web browsers download
Java applets that provide customized user interfaces. Servers upload Java servlets
so that data-intensive computation can be performed closer to the repository of
the data. Scientists can upload software to satellites and space stations. And PC
owners can donate idle time on their PCs to projects that use distributed computing
to search for extraterrestrial intelligence,1 or to predict the Earth's climate fifty years
from now.2 (The advent of grid computing [FKT01, Par02] has made it easier to
donate CPU cycles; rather than sign up with specific projects, we can simply add
our computers to a computational grid that pools together resources to be shared
by a number of projects.)

In each of the above scenarios, we may not always know or may not completely
trust the producer of the code that we download and run. Nonetheless, we would

1http://setiathome.berkeley.edu/
2http://www.climateprediction.net/

1

like to be sure that the downloaded code will not misbehave -- for instance, a tax
calculator should correctly calculate my tax liability or refund, or at the very least,
it should not crash my PC or make it hang, or corrupt my financial data or leak
it to others. Downloaded code may misbehave thanks to a malicious producer or
simply due to bugs that went undetected despite the best intentions and efforts
of its producer. Therefore, regardless of who the producer is, it is desirable to
mechanically check that the behavior of the code matches our expectations. For
that we need two things:

* First, we have to specify precisely what we expect.

* Second, we need a mechanism that guarantees that the expectations are met.
Section 1.1.1 discusses a particularly effective way accomplishing both of the above.
But first, I shall digress and talk about the degrees and types of well-behavedness
that one might expect from (downloaded) code.

Correctness: Ideally, we would like be sure that the code we've received is correct
-- that is, it does the right thing and computes what we expect. To verify that the
code is correct, we must formally specify what we expect. This is possible for very
small programs but for large, complex software, it can be a daunting and error-prone
task. Consider, for example, the tax calculator I mentioned above. To verify that
this program correctly computes the 2003 tax liability for U.S. residents, one would
have to formally encode the entire 2003 U.S. Individual Income Tax Code. Even
after one has such an encoding, there is no guarantee that the encoding is correct.
The problem is that to formally specify what we expect a program to compute,
we must essentially write the program all over again, though perhaps in a more
deductive style. Such a task is as prone to errors as the task of writing the original
software.

Security : For most applications it is usually sufficient to prove weaker properties
about the code's behavior than partial or total correctness. We may, for instance,
be content with a guarantee that the downloaded code is secure. Unfortunately,
there is no universally accepted definition of security, so we must be more specific
about what security policies we want the code to satisfy. Some well-known concerns
addressed by security policies are access control, information flow, and availability.
Access control policies limit who can perform what actions on which objects. For
instance, we may have an access control policy that says if Alice runs the tax
calculation program (using security terminology, Alice is the principal ), then the
program may read, but not write, Alice's financial files, but it may neither read nor
write Bob's financial files. Information flow policies restrict what principals can
infer about objects by observing system behavior. Specifically, secrecy guarantees
that low-security (observable) data is not influenced by high-security (secret) data,
while integrity guarantees that high-security (trustworthy) data is not influenced,

2

or tainted, by low-security (unreliable) data. Availability policies restrict principals
from denying others the use of precious resources such as memory and CPU cycles.

Schneider [Sch00a] defined a security policy as a binary partition on sets of
executions, that is, as a predicate P that divides the set of executions into those that
satisfy the policy P and those that do not. Security policies may be classified based
on the kinds of mechanisms that may be used to enforce them. Broadly speaking,
enforcement mechanisms may place restrictions on what the code is allowed to do
(perhaps even by modifying the code), or simply check that the the code does not
violate the security policy.

Schneider specified a class of enforcement mechanisms called EM for execution
monitoring. An execution monitor intercepts security relevant events that occur as
the untrusted program executes, and intervenes (terminates the program [Sch00a]
or takes some corrective action [HMS03]) upon seeing an event that would lead to
a violation of the security policy being enforced. Hamlen, Morrisett, and Schneider [HMS03] present a taxonomy of enforceable security policies that shows how
classes of security policies enforceable by static analysis [LY99, MWCG99, Mye99,
Nac97], execution monitoring [And72, Lam71, LY99, RC91, Vis00], and program
rewriting [DG71, ES00a, ES00b, ET99, Sma97, WLAG93] relate to each other and
to various computational complexity classes.

Notice that access control policies are EM-enforceable; an execution monitor can
terminate a program that is about to perform an operation it is not authorized to.
Information flow policies are enforceable by program rewriting, but they are not
EM-enforceable. Informally, a set of executions satisfies an information flow policy
P if all the executions in that set are observably equivalent -- that is, one cannot
look at a single execution and decide whether it belongs to P. Execution monitors
are predicates on individual executions, hence, they cannot enforce information
flow policies. Program rewriters, meanwhile, can modify programs that violate the
policy being enforced such that the observable outputs that cause the violation are
suppressed.

Safety: At a bare minimum, we would like to have the assurance that the code
we are about to execute is safe. Lamport [Lam77] described a safety property as one
that stipulates that no "bad thing" happens during any execution.3 This implies
that all EM-enforceable security policies are actually safety properties. Well-known
examples of "bad" things (i.e., violations of safety properties) include dereferencing
a dangling pointer and using an integer as a pointer. The next section discusses
type systems, which are particularly well-suited to specifying and enforcing safety
properties.

3Also, Lamport [Lam77] describes a liveness property as one that guarantees that some "good
thing" must happen during any execution. Availability, which says that eventually a resource will
become available, is an example of a liveness property.

3

1.1.1 Type Systems
A type system is a collection of syntactic rules that specifies the set of acceptable
program behaviors. A type checker verifies that a program obeys the rules of a
particular type system. It does so by checking that types are assigned correctly
and consistently to all program subexpressions. Type checking guarantees that a
program is well-typed which, in turn, guarantees that the program is well-behaved
(as long as the type system correctly rules out "bad" behavior).

Cardelli [Car97] defined type safety in very general terms as the property that
programs do not cause untrapped errors (i.e., execution errors that are not immediately detected). Let us look at some specific examples of properties a type
system can enforce. Type systems typically guarantee a number of interrelated
safety properties, for instance, memory safety (programs can only access appropriate memory locations) and control safety (programs can only transfer control
to appropriate program points). Type systems that support type abstraction can
provide some powerful assurances about program behavior. Such systems can guarantee that the behavior of a program is independent of the representation of an
abstract type [Rey83]. One consequence of this representation independence (or
parametricity ) principle is that type checking can be modular -- that is, one can
swap the implementation of an abstraction with another well-typed one, without
having to type check the entire program. Another important consequence is that
simply by examining the type of a function, it is possible (in a purely functional
setting) to infer a number of its computational properties [Wad89]. Hence, just by
assigning an appropriate type to a function, it is possible to ensure that the function
does not perform any unauthorized operations on values of abstract type. Types
also make it easy to construct logical relations that can be used to verify adherence to policies that rely on some form of observational equivalence, for instance,
encryption protocols [SP01] and secure information flow [HR98].

There is a trade-off between the expressive power of a type system and automated, efficient type checking. While it is possible to construct arbitrarily expressive
type systems with the power of any logic, the downside is that such type systems
(e.g., NuPRL [CAB+86]) generally require sophisticated theorem provers and programmer guidance to construct a proof of type safety. For example, recent work
on dependent type systems [XP98, XP99] extends type checking to include the verification of value-range restrictions which allows many array bounds checks to be
eliminated, but the programmer must add additional typing annotations (e.g., loop
invariants) to aid the type checker. Notice, however, that while a code producer
must do additional work to prove the program safe, there is no added burden on
the code receiver, as long as the code she receives is accompanied by enough typing
annotations (or perhaps even a full-fledged proof of type-safety in an appropriate
logic) for the checker to mechanically verify that the code is safe.

4

In practice, it is common to restrict attention to type systems for which checking
is computable within a reasonable complexity bound so that code producers don't
have to do additional work to prove type safety. Such type systems give us an effective way of specifying what we expect, while type checking allows us to mechanically
verify that the expectations are met.

1.1.2 Type-Preserving Compilation
The programs we download are typically machine language programs rather than
high-level source code with type annotations. Fortunately, there has been a great
deal of research over the past decade on how to propagate type information present
in source language programs into compiler intermediate languages [TMC+96, SA95,
PJHH+93, LY99, DMTW97]. The fruits of this research, namely type-preserving
compilers and typed intermediate languages, have made it possible for type systems
to be used for mechanically verifying the safety of programs written in low-level
languages. At each stage of the compilation process, a type-preserving compiler
must correctly propagate typing information to subsequent stages. Type-preserving
compilers are also type-directed, that is, at each stage of compilation, they may
use typing information to guide program transformations or optimizations. The
output of each compilation phase is a program in an appropriate typed intermediate
language.

Type-checkers for compiler intermediate languages are important for two reasons. First, they allow compiler writers to (mechanically) detect bugs in their compilers. Specifically, if a progam type-checks before but not after an optimization,
that signals an error in the compiler. Second, they allow code receivers to mechanically verify the safety of lower level code, a feature that's successfully exploited in
the Java Virtual Machine [LY99].

The Java platform consists of a type-preserving compiler that translates a Java
program into a Java Virtual Machine Language (JVML) program (Java bytecode)
that may be shipped to a code receiver. The code receiver type checks the untrusted
JVML program (using the Java bytecode verifier) before running it. If the program
is well-typed the code receiver can be sure that the JVML program is safe to execute,
as long as the JVML type system is sound and the JVML type checker and run-time
system (which includes a just-in-time compiler or a JVML interpreter) are free of
bugs.

In their work on Typed Assembly Language (TAL) [MWCG98, MWCG99], Morrisett et al. showed that types could be propagated all the way to the target language. Specifically, their compiler produces assembly language programs with type
annotations for the Intel IA32 architecture [MCG+99]. A type checker verifies that
these programs are well-typed with respect to the type annotations before assembling them. The TAL program is safe to execute as long as the type checker and

5

SourceProgram

Verification Condition

(Safety Theorem)

Execute

OK

Verification Condition

(Safety Theorem)

VCGen +
Safety Policy

Safety Proof

Machine Code
Code Producer Code Consumer

Certifying

Compiler

Annotations

Prover Checker

VCGen +
Safety Policy

Trusted
Untrusted

Figure 1.1: Proof-Carrying Code Architecture
assembler have been implemented correctly.
1.1.3 Proof-Carrying Code
Proof-carrying code [Nec97, NL98a] goes one step further than TAL by generating proofs of safety for machine language programs. Figure 1.1 gives a simplified
illustration of the PCC architecture as described by Necula [Nec97]. In this architecture, the code producer compiles her source program using a certifying compiler
(essentially a type-preserving compiler) which produces machine code together with
a set of type annotations. The machine code is then sent to a Verification Condition
Generator (VCGen) which consults the safety policy that must be satisfied and infers the safety theorem for the given machine code -- that is, the theorem that must
be proved in order to show that the code adheres to the safety policy. A prover,
using the type annotations generated by the compiler as hints, generates a proof
of the safety theorem. The code producer then sends the machine code as well as
the safety proof to the code consumer. The consumer independently generates her
own safety theorem using the same VCGen and safety policy as the producer. Note
that this means she need only trust her own VCGen and safety policy, and not the
producer's. This safety theorem is then checked against the proof supplied by the

6

producer. Proof checking is computationally very easy and if the safety theorem is
indeed proved by the supplied proof, then the consumer is assured that the code is
safe to execute, as long as the trusted components (i.e., the proof checker and the
consumer's VCGen and safety policy) are implemented or specified correctly. The
Touchstone [NL98a] compiler implements this framework.

1.1.4 Foundational Proof-Carrying Code
A classic security principle, formulated by Saltzer and Schroeder [SS75] almost thirty
years ago, is as follows.

Minimal Trusted Computing Base:

Assurance that an enforcement mechanism behaves as intended is greatest
when the mechanism is small and simple.

In each of the safety mechanisms I described above, the safety guarantee is meaningful only if certain (trusted) components are implemented or specified correctly.
An important feature of the research advances described in the last two sections is
that they each reduced the size and complexity of the components that had to be
trusted. For instance, type checking source code guarantees safety only if the type
checker, compiler, and runtime are implemented correctly; successfully verified Java
bytecode is safe only if the bytecode verifier, JIT compiler, and Java runtime are
free of bugs; well-typed TAL code is safe only if the type-checker and assembler are
correct; and machine code certified by a PCC system is safe only if the safety policy
has no holes and if the VCGen is implemented correctly. So we have come from a
world where we had to trust entire compilers to a world where we must trust much
smaller components. But how do we build a system where the trusted computing
base is the smallest possible?

The goal of the Foundational Proof-Carrying Code (FPCC) project at Princeton
is to mechanically verify the safety of machine language programs using a minimal
trusted computing base. Foundational PCC [App01, AF00] addresses two areas of
particular concern in Necula's PCC. The first is Necula's VCGen which is a complex
and large program, approximately 23,000 lines of C [AW02]. The VCGen traverses
the machine language program and extracts a formula (in first-order logic) which is
true only if the given program obeys the safety policy. A bug in the VCGen would
imply that we are demanding a proof of the wrong theorem, i.e., a theorem that
does not guarantee that the given machine code is safe. Appel and Felty [AF00]
showed how to eliminate the VCGen and reason directly about machine code in
higher-order logic, instead of using the two-step process of generating a verification
condition and then proving it safe.

The second area of concern has to do with Necula's safety policy which has
axioms of the type system (i.e., the typing rules for the machine language) built in.

7

Prover
SourceProgram

Execute

OK

Checker
Machine Spec +

Safety Policy

Annotations

Certifying

Compiler

Machine Spec +

Safety Policy

Safety Proof

Machine Code
Code Producer Code Consumer

Trusted
Untrusted

Figure 1.2: Foundational Proof-Carrying Code Architecture
If the type system is not sound, then unsafe programs will be accepted. In fact,
League et al. [LST03] have shown that one of the SpecialJ [CLN+00] typing rules
is unsound. Appel et al. write the rules of their type system as machine-checkable
lemmas, instead of axioms. This means that the soundness of the type system can
be mechanically verified by the proof checker along with the rest of the safety proof.

Figure 1.2 illustrates the FPCC architecture; the trusted components are shaded.
In this framework, the VCGen has been replaced by a machine specification which
specifies the encoding and instruction semantics for a real machine (such as the
Sparc) in higher-order logic. For the Sparc, Michael and Appel [MA00] have shown
how to do this in just 1,600 lines of higher-order logic (encoded in Twelf [PS99],
an implementation of the LF logical framework [HHP93]). Also, the safety policy
shown in Figure 1.2 is much smaller and simpler than Necula's safety policy as it
does not have the type system built in. The FPCC safety theorem (also part of
the TCB) says simply that if a program can step from a computation state s to
a computation state s0 (in accordance with the machine instruction semantics and
without violating the safety policy), then it is possible to safely take one more step.

Not having the type system built into the safety policy makes a foundational
PCC architecture more flexible than Necula's PCC framework because the code producer can "explain" a novel type system or safety argument to the code consumer.

8

That is, the code producer does not have to program in a specific source language
or use a specific compiler as long as she sends the consumer a type soundness proof
for her compiler's TAL along with the machine code and the rest of the proof. In a
foundational PCC system, the code consumer can mechanically verify the safety of
the machine language program as well as the soundness of the type system used to
justify the program's safety.

Appel and Felty [AF00] prove the type system sound by defining the semantics of each type in terms of the operational semantics of the real machine. This
allows them prove the validity of each typing rule (i.e., each typing rule becomes
a lemma). They then prove that if a machine language expression is well-typed,
then it cannot get stuck. These proofs are foundational in that they rely only on
the axioms of higher-order logic and arithmetic, the operational semantics of the
target architecture, and the safety policy. Appel and Felty demonstrated how to
prove type soundness for a language with dynamically allocated immutable cells.
Appel and McAllester [AM01] extended the approach to languages with (co- and
contravariant) recursive types. This thesis shows how to extend the approach to
languages with mutable references.

1.2 Mutable State and Type Safety
In a language with mutable memory cells, should a cell update be permitted to
change the type of the memory cell, or must all memory updates be type-preserving?
The former are known as strong updates and the latter as weak updates. Typesafe languages typically require that updates be type-preserving because such a
constraint -- I'll call it the type invariance principle -- makes it easier to establish
type safety in the presence of aliasing.

More precisely, type safety guarantees that a well-typed program will not get
stuck. To prove type safety -- whether using syntactic subject-reduction [WF94] or
operationally-based logical relations (the method used by Appel and Felty [AF00])
-- we have to show that well-typed programs (or computation states) step to welltyped programs. In particular, since the memory (or heap or store) is part of the
computation state, we have to show that a well-typed memory steps to a well-typed
memory. This implies that if an update at some location ` in a well-typed memory
m changes the type of `, then we will have to correctly propagate the change to the
types of all of `'s aliases (and to the types of all aliases of `'s aliases, and so on) in
order to show that the updated memory m0 (as a whole) is well-typed. Alternatively,
we could devise a type system that tracks aliasing [SWM00, WM00, Wal01] such
that the types of aliases do not have to be explicitly modified when the type of the
aliased location changes.

A much simpler strategy, employed by practical languages like ML and Java, is

9

to require that the types of allocated memory cells never change. Thus, there are
no type changes to propagate; a type-preserving (or weak) update in a well-typed
memory m results in a well-typed memory m0.

Type Invariance Principle:

The type of every allocated memory location must remain unchanged for the
duration of program execution.

Enforcing the type invariance principle is tricky in a semantic setting; in fact,
na"ive attempts to enforce it lead to circularity. To ensure that every update is
type-preserving, we need to keep track of the type o/ of values that may be written
into each allocated location. We can do this using a memory typing \Psi  that maps
allocated locations to types. But now, consider the semantics of mutable reference
types (denoted ref o/ ). According to the type invariance principle, an allocated
memory location has type ref o/ iff it contains a value of type o/ and it will always
contain a value of type o/ . Therefore, in the definition of ref o/ , to check whether a
location ` will always contain a value of type o/ , we need to check that \Psi  maps ` to
o/ -- that is, the definition of ref o/ must refer to \Psi . To accommodate the latter, we
must model all types o/ so that they take store typings \Psi  as an argument. But this
means that types must be predicates on partial functions from locations to types. A
simple diagonalization argument will show that this set of types has an inconsistent
cardinality.

1.3 Contributions and Dissertation Outline
In this thesis, I will show how to construct machine-checkable foundational proofs
of safety for programs that mutate state. Foundational proofs rely only on the
operational semantics of the language and the axioms of the higher-order logic (or
any other suitable logic that may be used to encode the proofs). In particular,
I'll show how to prove type soundness for languages that support dynamically allocated, (weakly) updatable memory cells that may contain values of any type,
including functions, mutable references, co- and contravariant recursive types, and
even impredicative quantified types. I'll also describe how to extend these results
to permit memory reuse.

In chapter two, I will introduce the basic technique that I use throughout this
thesis to construct foundational safety proofs. This technique may be summarized
as follows: first, one defines the meaning of types and typing judgments based on
the operational semantics of the language; then, based on the meanings of types
and typing judgments, one proves the typing rules as lemmas; finally, one proves
that if a program type-checks then, based on the meaning of a typing judgment, the
program is safe. I demonstrate the technique in both a pure and an impure setting

10

-- specifically, I apply it to a purely functional *-calculus and to a *-calculus with
dynamically-allocated immutable references. I show that in the pure setting this
technique is precisely the logical relations proof technique (though my terminology and notation are different) and in the impure setting it corresponds to Kripke
(possible-worlds) logical relations.

In chapter three, I describe how to model a language with general references --
that is, mutable memory cells that may contain values of any closed type, including
other references and impredicative quantified types. While Java and ML do not
support impredicative polymorphism, the ability to store values of impredicative
quantified types in mutable cells is crucial in a typed target language for a certifying compiler for Java or ML (for instance, to represent ML function closures without
defunctionalizing). Because existing models of general references [AHM98, Lev02]
do not model impredicative polymorphism, they are not expressive enough to represent the semantics of the ML or Java type systems. Our goal is to model ML and
Java types.

Chapter three explains how to avoid the circularity I alluded to in the previous
section. Rather than model types as predicates on memory typings \Psi , I model types
as an infinite sequence of increasingly refined approximations; each approximation
in the sequence is a predicate on memory typings \Psi  whose codomains contain only
less refined type approximations.

Also in chapter three, I point out a correspondence between the possible-worlds
model of mutable references and that of the modal logic S4. Intuitively, in languages
that support the type invariance principle, which requires that something always be
true, reference types correspond to the modal logic connective 2 which is interpreted
in S4 as "always."

Chapter four discusses some changes and extensions to the language considered
in chapter three. In particular, I show how to modify the semantics of quantified
types to address the fact that, unlike the operational semantics in chapter three,
real machines do not have explicit instructions for type application and existential
unpacking. I also present some examples and discuss related work.

A foundational PCC system demands that all safety proofs be machine-checkable.
In chapter five, I explain how the model of mutable references may be encoded in
CiC (briefly) and in higher-order logic. As mentioned above, I construct a model of
mutable references by stratifying types into a series of approximations. Higher-order
logic, unlike CiC, does not provide a convenient mechanism for defining stratified
metalogical types; I'll explain how we can construct the stratification ourselves.

For foundational PCC, we need proofs of safety for real machine language programs. In chapter six, I describe the von Neumann model we've built for the FPCC
system being developed at Princeton.

In chapter seven, I show how to extend the mutable references model to support
the reuse of memory cells (possibly at different types), without violating the type11

invariance principle. Specifically, I present a semantics for a calculus with primitives
for region-based memory management.

Finally, chapter eight examines an important direction for future research which
is how to extend the model I've described to a partial equivalence relation (or PER)
model. Using a PER model one can reason about observational equivalence in the
presence of mutable state. This would permit foundational proofs of noninterference
(a program's observable behavior is independent of certain program inputs) and
the correctness of compiler optimizations (an unoptimized program's observable
behavior is equivalent to that of its optimized version).

12
Chapter 2
Foundational Proofs of Safety
A proof-carrying code (PCC) system consists of a type-preserving compiler that
produces programs in a typed assembly language (TAL). These programs are safe
provided that the TAL is sound and the translation of TAL programs to machine
code preserves safety. A foundational PCC system seeks to eliminate these caveats
by giving a semantics to TAL expressions and types in terms of the operational
semantics of the underlying von Neumann machine. I shall refer to such semantics
as denotational-operational since the denotation of types is based on the operation of
terms. The (untyped) machine code is then proved safe by showing that it satisfies
the TAL type annotations produced by the compiler.

The goal of this chapter is to introduce denotational-operational models in a
very simple setting. Imagine that the TAL mentioned above corresponds to the
simply-typed *-calculus, while the machine language corresponds to the untyped
*-calculus, and the semantics of a simply-typed *-calculus term is given via typeerasure. I shall explain how to define the semantics of types of the simply-typed
*-calculus based on the operational semantics of the untyped *-calculus and how
to use this semantic model to prove the safety of untyped *-calculus programs.

I first consider a pure functional language (Section 2.1) and then a simple language with mutable state, specifically, with dynamically allocated immutable references (Section 2.2). I specify safety for programs in each language, describe how
to prove them safe, and discuss how the proofs correspond to proofs based on the
logical relations technique. The presentation in Sections 2.1 and 2.2 resembles the
exposition by Appel and McAllester [AM01] of a model of types for the *-calculus
(specifically, the purely functional *-calculus with recursive types).

2.1 A Pure Language
Syntax The language I consider in this section is the lambda calculus with booleans.
I shall call this pure functional language *P . The syntax of *P terms is given by

13

e1 7-!P e01
e1 e2 7-!P e01 e2 (PO-app1)

e2 7-!P e02
(*x:e1) e2 7-!P (*x:e1) e02 (PO-app2)

(*x:e) v 7-!P e[v=x] (PO-app3)
Figure 2.1: Pure Functional Language (*P ): Operational Semantics
the following grammar.

Values v : : = true | false | *x:e
Expressions e : : = x | v | (e1 e2)

I use the metavariable x to range over a countably infinite set Var of variables.
A term v is a value if it is true, false or a lambda abstraction that contains no
free variables x. Notice that terms in this language are untyped, just as machine
instructions in a foundational PCC system would be untyped. I will show how to
give purely semantic (not syntactic) typings to the untyped lambda calculus.

2.1.1 Operational Semantics and Safety
The formal operational semantics for *P (shown in Figure 2.1) is an entirely conventional call-by-value semantics. It is specified by a relation 7-!P on closed terms.
The notation e 7-!P e0 denotes a single operational step from e to e0 and e 7-!*P e0
denotes a chain of the form e 7-!P e1 7-!P : : : 7-!P ej where ej is e0 and j >= 0
(i.e., e evaluates to e0 in zero or more steps).

A term e is irreducible if it has no successor in the step relation, that is, irred(e) if
e is a value or if e is a "stuck" expression (such as true(e0)) to which no operational
rule applies. I write val(e) to denote that term e is a closed value. An expression e
is considered safe if it never evaluates to a "stuck" expression.

Definition 2.1 (Safe)
A term e is safe if whenever e evaluates to e0, either e0 is a value or another step is

14

possible.

safe(e) def= 8e0: e 7-!*P e0 =) (val(e0) . 9e00: e0 7-!P e00)
To show that a given term is safe I will construct safety proofs based on type
systems. Such proofs typically consist of a typing derivation that proves that the
given term typechecks, but since I am interested in constructing foundational safety
proofs, I must also prove a theorem stating that typability implies safety. Proofs
that typability implies safety are typically based on syntactic subject reduction.
While it is possible to construct foundational safety proofs that rely on syntactic
subject reduction, in this thesis I will take a semantic approach, as pioneered in
the NuPrl system [CAB+86] and as applied to proof-carrying code by Appel and
Felty [AF00]. In a semantic proof, one assigns a meaning (a semantic truth value)
to type judgments. One then proves that if a type judgment is true, then the typed
program is safe. One also proves that the type inference rules are sound, that is,
if the premises are true then the conclusion is true. This ensures that derivable
type judgments are true, hence typable programs are safe. The rest of this section
explains how to construct such semantic safety proofs for *P programs.

2.1.2 Semantics of Types and Judgments
Values in *P may be booleans (of type bool) or functions (of type o/1 ! o/2). I
treat types as sets of values rather than as syntactic type expressions. Hence, the
type bool is a set that consists of just two values, true and false. To describe the
semantics of type o/1 ! o/2, I first have to specify what it means for a closed term e
to have type o/ (denoted by judgments of the form e : o/ ). Informally, e has type o/
if it evaluates to a value of type o/ .

Definition 2.2 (Expr : Type)
For any closed expression e and type o/ I write e : o/ if whenever e 7-!*P e0 and e0 is
irreducible, then e0 is a value in set o/ ; that is,

e : o/ def= 8e0: (e 7-!*P e0 ^ irred(e0)) =) e0 2 o/
I can now specify the semantics of function types. The type o/1 ! o/2 is the set of all
values of the form *x:e such that for any value v of type o/1 the result of substituting
v for x in e (written e[v=x]) is an expression of type o/2. The boolean and function
types are specified as follows.

bool def= { true; false }
o/1 ! o/2 def= { *x:e | 8v: v 2 o/1 =) e[v=x] : o/2 }

15

\Gamma  |=P x : \Gamma (x) (P-var)
\Gamma  |=P true : bool (P-true) \Gamma  |=P false : bool (P-false)

\Gamma  [x 7! o/1] |=P e : o/2
\Gamma  |=P *x:e : o/1 ! o/2 (P-abs)

\Gamma  |=P e1 : o/1 ! o/2 \Gamma  |=P e2 : o/1

\Gamma  |=P (e1 e2) : o/2 (P-app)

Figure 2.2: Pure Functional Language (*P ): Type-checking Lemmas
Up to now I have only dealt with closed *P expressions, as these are the ones
that are evaluated at run time. Now I turn to expressions with free variables, upon
which the static type-checking rules must operate. The notation F V (e) denotes the
set of variables that occur free in e.

Definition 2.3 (Semantics of Judgment)
A type environment is a mapping from lambda calculus variables to types. A value
environment (also known as a ground substitution) is a mapping from lambda calculus variables to values. For any type environment \Gamma  and value environment oe, I
write oe : \Gamma  if for all variables x 2 dom(\Gamma ) we have oe(x) : \Gamma (x); that is,

oe : \Gamma  def= 8x 2 dom(\Gamma ): oe(x) : \Gamma (x)
I write \Gamma  |=P e : o/ iff F V (e) ` dom(\Gamma ) and

8oe: oe : \Gamma  =) oe(e) : o/
where oe(e) is the result of replacing the free variables in e with their values under
oe. Finally, I write |=P e : o/ to mean \Gamma 0 |=P e : o/ for the empty environment \Gamma 0.

Note that \Gamma  |=P e : o/ can be viewed as a three place relation that holds on the type
environment \Gamma , the term e, and the type o/ .

The type-checking rules for *P are given in Figure 2.2. I write \Gamma  [x 7! o/ ] to
denote the type environment that is identical to \Gamma  except that it maps the variable

16

x (where x =2 dom(\Gamma )) to o/ . Each of the type inference lemmas in Figure 2.2 states
that if certain instances of the relation \Gamma  |=P e : o/ hold, then certain other instances
hold. Once I have proved the type inference lemmas in Figure 2.2, these lemmas can
be used in the same manner as standard type inference rules to prove statements of
the form \Gamma  |=P e : o/ .

2.1.3 Typability Implies Safety
A "program" in *P is simply a closed term e. I must now prove that if a type
judgment is true then the typed program is safe. In a conventional syntactic type
theory, the safety theorem (typability implies safety) is difficult (or at least tedious)
to prove. Here it follows directly from the definitions.

Theorem 2.4 (Safety)
If |=P e : o/ and o/ is a type, then safe(e).

Proof: To prove safe(e) we must show that for any term e0, if e evaluates to e0,
either e0 is a value or another step is possible. Suppose e 7-!*P e0. If e0 is not
irreducible, then there must exist some e00 such that e0 7-!P e00. Otherwise, e0 is
irreducible. By Definition 2.3, |=P e : o/ denotes \Gamma 0 |=P e : o/ where \Gamma 0 is the empty
context. From \Gamma 0 |=P e : o/ , again by Definition 2.3, it follows that e is closed. Choose
the empty value environment oe0 and by the semantics of \Gamma 0 |=P e : o/ (Definition 2.3)
we have oe0 : \Gamma 0 =) oe0(e) : o/ . The premise oe0 : \Gamma 0 is trivially satisfied; applying
the trivial substitution we have e : o/ . Since e 7-!*P e0 and irred(e0) it follows that
e0 2 o/ . Since o/ is a type, that is, a set of values, it follows that val(e0). \Lambda 

2.1.4 Typing Rules as Lemmas
It remains for us to show that the type inference rules shown in Figure 2.2 are
sound.

Theorem 2.5 (P-var)
If \Gamma  is a type environment and x is a variable such that x 2 dom(\Gamma ) then \Gamma  |=P x :
\Gamma (x).

Proof: For any oe such that oe : \Gamma  we must show that oe(x) : \Gamma (x). This is immediate from the definition of oe : \Gamma . \Lambda 

Theorem 2.6 (P-true)
If \Gamma  is a type environment then \Gamma  |=P true : bool.

17

Proof: For any oe such that oe : \Gamma  we must show that oe(true) : bool. Since true
is a closed term it suffices to prove that true : bool. This follows immediately from
the definition of bool. \Lambda 

Theorem 2.7 (P-false)
If \Gamma  is a type environment then \Gamma  |=P false : bool.

Proof: By the same argument as for theorem P-true. \Lambda 

Theorem 2.8 (P-abs)
Let \Gamma  be a type environment, let o/1 and o/2 be types, and let \Gamma  [x 7! o/1] be a type
environment that is identical to \Gamma  except that it maps x to o/1. If \Gamma  [x 7! o/1] |=P e : o/2
then \Gamma  |=P *x:e : o/1 ! o/2.

Proof: We must prove that under the premises of the theorem for any oe such
that oe : \Gamma  we have oe(*x:e) : o/1 ! o/2. Suppose oe : \Gamma  and that v is some value such
that v 2 o/1. Notice that the premise \Gamma  [x 7! o/1] |=P e : o/2 guarantees that x =2 dom(\Gamma )
(since, as mentioned above, the notation \Gamma  [x 7! o/1] assumes that x =2 dom(\Gamma )). By
the definition of o/1 ! o/2 it now suffices to show that oe(e[v=x]) : o/2. Let oe [x 7! v] be
the value environment identical to oe except that it maps x to v. From v : o/1 it follows that oe [x 7! v] : \Gamma  [x 7! o/1], which together with the premise \Gamma  [x 7! o/1] |=P e : o/2
(by Definition 2.3) implies oe [x 7! v](e) : o/2. But this implies oe(e[v=x]) : o/2. \Lambda 

Theorem 2.9 (P-app)
If \Gamma  is a type environment, e1 and e2 are (possibly open) terms, and o/1 and o/2 are
types such that \Gamma  |=P e1 : o/1 ! o/2 and \Gamma  |=P e2 : o/1 then \Gamma  |=P (e1 e2) : o/2.

Proof: We must prove that under the premises of the theorem for any oe such
that oe : \Gamma  we have oe(e1 e2) : o/2. Suppose oe : \Gamma . Let oe(e1 e2) 7-!*P e0 and irred(e0);
we must show that e0 2 o/2. By the operational semantics, it follows that:

1. oe(e1) 7-!*P e01 and irred(e01). By the premises of the theorem we have oe(e1) :

o/1 ! o/2 so by Definition 2.2 (Expr : Type) we have e01 2 o/1 ! o/2. From the
definition of ! it follows that e01 is of the form *x:e11.

2. oe(e2) 7-!*P e02 and irred(e02). By the premises of the theorem we have oe(e2) : o/1.

Hence, by Definition 2.2 (Expr : Type) we have e02 2 o/1.

3. (*x:e11)e02 7-!P e11[e02=x] 7-!*P e0. Since *x:e11 2 o/1 ! o/2 and e02 2 o/1,

by the definition of o/1 ! o/2 it follows that e11[e02=x] : o/2. By Definition 2.2
(Expr : Type) and irred(e0) it follows that e0 2 o/2 as we wanted to show.

\Lambda 

18

2.1.5 Discussion: Trusted Computing Base
I have shown that one can construct a foundational safety proof for any term e that
is well-typed with respect to the typing rules in Figure 2.2. The proof is foundational
because these typing rules are not treated as axioms, that is, they do not have to
be trusted. In fact, the only axioms that the proof relies on are:

* the operational semantics of the language (Figure 2.1) -- including, for instance, the definition of substitution (which rule PO-app3 relies on);

* the specification of safety (Definition 2.1);

* the axioms of higher-order logic (or any other suitable logic) in which the

specifications and proofs are formalized.1

All other definitions are built on top of these axioms and are not part of the trusted
computing base.

One can construct machine-checkable proofs by encoding the specifications and
proofs described above in a suitable logic and developing a proof checker for the
logic. The proof checker would also be part of the trusted computing base.

2.1.6 Discussion: Logical Relations
The semantic approach to proving safety that I have described above corresponds
exactly to the proof technique known as logical relations. To illustrate the correspondence, I will sketch out how one would prove that well-typed *P programs are
safe using logical relations. As much as possible, I will use the terminology one
would expect to see in a proof based on logical relations.

The *P operational semantics is exactly as before, that is, the semantics given
in Figure 2.1. Type judgments have the form \Gamma  `P e : o/ ; I use `P rather than
|=P to indicate that we are now dealing with a syntactic type theory -- though,

in this case, the difference is entirely cosmetic, as we shall see -- where \Gamma  is a
mapping from variables to syntactic type expressions and that o/ is a syntactic type
expression. The typing rules are exactly the rules shown in Figure 2.2 except that
each occurrence of |=P should be replaced by `P .

To prove that well-typed terms are safe using logical relations, one begins by
defining, for each type o/ , a unary relation (i.e., a set) Ro/ of closed terms e of type
o/ . I regard these sets as predicates and write Ro/ (e) for e 2 Ro/ . A logical relation
R = {Ro/ } is a family of relations Ro/ for each type o/ in the language. The relations
for *P may be defined as follows.

1Note that the definitions use logical connectives such as 8, =), ^, etc., and the proofs use
logical inference rules to operate on the definitions -- the latter is not immediately obvious since
the proofs, for simplicity of presentation, use informal reasoning in place of formal proof steps
such as "apply the 8 introduction rule . . . " or "using ^ elimination we have . . . " and so on.

19

* Rbool(e) iff for all e0 such that e 7-!*P e0 and irred(e0), either e0 = true or

e0 = false.

* Ro/1!o/2(e) iff for all e0 such that e 7-!*P e0 and irred(e0), e0 = *x:e2, and

whenever Ro/1(e1), we have Ro/2 (e e1).

Hence, the relation Ro/ consists of all expressions e such that if e 7-!*P e0 then
e0 2 Ro/ . Notice that Ro/ (e) corresponds to e : o/ (Definition 2.2) which I defined as
part of the (denotational-operational) semantic approach above.

There are now two parts to the proof of safety. First, one proves that every
element of every set Ro/ is safe. This follows easily from the definition of Ro/ . Notice
that this lemma corresponds to Theorem 2.4.

Lemma 2.10
If Ro/ (e), then safe(e).

Next, one shows that every well-typed term e of type o/ is an element of Ro/ .
For the lambda abstraction case (i.e., when e is of the form *x:e0), to conclude that
*x:e0 is an element of Ro/1!o/2 we will need to apply the induction hypothesis in order
to conclude that e0 is an element of Ro/2 . But here we have a problem: Ro/2 is a set
of closed terms, while e0 may contain free occurrences of the variable x. To deal
with this situation, we have to generalize the induction hypothesis to open terms.
Hence, we must prove the following lemma.

Lemma 2.11
If x1 : o/1; x2 : o/2; : : : ; xn : o/n `P e : o/ and v1; : : : ; vn are closed values of types
o/1; : : : ; o/n such that Ro/i(vi) for each i, then Ro/ (e[v1=x1]* * *[vn=xn]).

The proof is by induction on the type derivation x1 : o/1; x2 : o/2; : : : ; xn : o/n `P e : o/ .
Notice that the cases of this proof, namely for typing rules P-var, P-true, P-false,
P-abs, and P-app, mirror the proofs of the typing rule lemmas that I proved as part
of the semantic approach, that is, Theorems 2.5 through 2.9, respectively.

Given a closed program e, one can now easily prove the final theorem which says
that if `P e : o/ then safe(e). The proof is immediate using Lemmas 2.10 and 2.11.
This proof is foundational: the typing rules do not have to be trusted since the
property of the typing rules crucial to our proof (that well-typed terms are safe)
has been captured by the logical relation R = {Ro/ } via Lemma 2.11. Hence, the
TCB is identical to that described in Section 2.1.5.

The presentation here resembles that in Pierce [Pie02] (Chapter 12), where logical relations are used to prove that every well-typed term of the simply typed
*-calculus is normalizable. The logical relations proof technique is also described in
Mitchell [Mit96] and Gunter [Gun92].

20

2.2 An Impure Language: Immutable References
In this section I consider a language with side-effects, specifically, an extension
of the pure language of Section 2.1 (*P ) with dynamically allocated immutable
cells. Programs written in this language -- which I call *I -- can allocate new
reference cells on the heap (or store) but can never update existing cells. My aim
in this section is to explain what changes we must make to the semantic model as
we move from a pure language (without side-effects) to an impure language (with
side-effects). The language is restricted to immutable references for simplicity; the
semantics of mutable references is much trickier and will be the focus of Chapter 3.

Syntax The syntax of *I terms is given by the following grammar.

Values v : : = ` | true | false | *x:e
Expressions e : : = x | v | (e1 e2) | new(e) | ! e

I use the metavariable x to range over a countably infinite set Var of variables and
the metavariable ` to range over a countably infinite set of locations Loc. A term
e is a value (written val(e)) if it is a location `, a constant (true or false), or
a lambda abstraction with no free variables x. The language includes terms for
allocating (and simultaneously initializing) a new cell on the heap (new(e)) and for
reading the contents of an allocated cell (! e).

Operational Semantics A store S is a finite map from locations to closed values.
The small-step semantics for *I is given as a step relation between machine states.
The state of the abstract machine is described by a pair (S ; e) of a store and a
closed term. The notation (S ; e) 7-!I (S 0; e0) denotes a single operational step from
machine state (S ; e) to state (S 0; e0), while (S ; e) 7-!*I (S 0; e0) denotes a chain of j
steps, for some j >= 0, of the form (S ; e) 7-!I (S1; e1) 7-!I : : : 7-!I (Sj; ej) where Sj
is S 0 and ej is e0. The operational semantics is given in Figure 2.3 and is completely
standard. Notice that the only rule in the operational semantics that produces a
side-effect -- a store effect, to be precise -- is the rule that evaluates expressions of
the form new(v) (see IO-new2); it extends the store with a previously unallocated
location ` initialized to v. The operational rule for dereferencing a cell ` checks that
` is an allocated cell (see IO-deref2).

In a language with side-effects, the order in which terms are evaluated is important. In examples that follow, I shall write let x = e1 in e2 in place of (*x:e2)e1 to
make it readily obvious that e1 is evaluated before e2.

Safety A state (S ; e) is irreducible if it has no successor in the step relation, that
is, irred(S ; e) if e is a value or (S ; e) is a "stuck" state such as (S ; true(e)) or (S ; ! `)

21

(S ; e1) 7-!I (S 0; e01)
(S ; e1 e2) 7-!I (S 0; e01 e2) (IO-app1)

(S ; e2) 7-!I (S 0; e02)
(S ; (*x:e1) e2) 7-!I (S 0; (*x:e1) e02) (IO-app2)

(S ; (*x:e) v) 7-!I (S ; e[v=x]) (IO-app3)

(S ; e) 7-!I (S 0; e0)
(S ; new(e)) 7-!I (S 0; new(e0)) (IO-new1)

` =2 dom(S )
(S ; new(v)) 7-!I (S [` 7! v]; `) (IO-new2)

(S ; e) 7-!I (S 0; e0)
(S ; ! e) 7-!I (S 0; ! e0) (IO-deref1)

` 2 dom(S )
(S ; ! `) 7-!I (S ; S (`)) (IO-deref2)

Figure 2.3: Immutable References (*I ): Operational Semantics
where ` =2 dom(S ). A machine state (S ; e) is safe if it never reaches a "stuck" state.
Definition 2.12 (Safe)
A state (S ; e) is safe if whenever (S ; e) evaluates to a state (S 0; e0), either e0 is a
value or another step is possible.

safe(S ; e) def= 8S 0; e0: (S ; e) 7-!*I (S 0; e0)

=) (val(e0) . 9S 00; e00: (S 0; e0) 7-!I (S 00; e00))

22

I wish to show that a program e is safe to execute given an initial store S , i.e.,
safe(S ; e). To prove that an initial machine state (S ; e) is safe using the semantic
approach, I will first specify the semantics of types and type judgments; I will then
prove that if a type judgment is true, then the typed program is safe; and finally, I
will prove that the *I typing rules are sound.

2.2.1 Semantics of Types using Possible Worlds
Values in *I may be booleans of type bool, functions of type o/1 ! o/2, or store
locations ` of type box o/ (the type ascribed to immutable cells that contain values
of type o/ ). In Section 2.1, I modeled types of the purely functional *-calculus as
sets of values, or equivalently, as predicates on values. For *I, the model of types
as sets of values is inadequate. To see why, let us consider the semantics of the
immutable reference type box o/ . A location ` has type box o/ if (1) ` is an allocated
location, that is, if it is in the domain of the current store S , and (2) the value
stored at location ` in store S has type o/ . Hence, to determine if location ` has type
box o/ we need to have access to the current store. The solution is to model types
as predicates on stores as well as values. I say a type o/ is a set of pairs of the form
hS ; vi. Informally, hS ; vi 2 o/ means that value v has type o/ with respect to store
S . The semantics of immutable references can now be defined as follows.2

box o/ def= { hS ; ` i | ` 2 dom(S ) ^ hS ; S (`)i 2 o/ }
A type, however, is not just any set of pairs hS ; vi; there are certain properties
that these sets must satisfy as I shall illustrate through an example. Consider the
following program which allocates and initializes a cell, executes several instructions
(elided), and then dereferences the original cell. (The comments that follow each
line in the program describe aspects of the state immediately after that line has
been evaluated.)

% S0
let x1 = new(true) in % S1 = S0 [`1 7! true]; `1 =2 dom(S0); x1 7! `1
let x2 = : : : in % S2 = : : : ; x1 7! `1.

..

let xn = : : : in % Sn = : : : ; x1 7! `1
! x1 % Sn+1 = Sn

Suppose that we execute the above program with initial store S0. By the *I operational semantics, after evaluating the first line of the program we have store

2Notice that the second condition in the definition of box o/ (i.e., hS ; S (`)i 2 o/ ) essentially
subsumes the first (` 2 dom(S )), so I could have simply defined box o/ as { hS ; ` i | hS ; S (`)i 2 o/ }.

23

S1 = S0 [`1 7! true] for some location `1 =2 dom(S0) and x1 is bound to `1. According to the semantics of box above, hS1; `1i 2 box bool holds. Next, we evaluate the
elided terms; suppose that these include one or more new expressions, and suppose
that the net effect of these terms is to transform the store from S1 to Sn. Hence,
when we reach the final instruction (! x1), x1 is bound to `1 and we have store Sn.
At this point, from a semantic perspective, dereferencing `1 given store Sn is safe
as long as:

1. `1 is an allocated location, i.e., `1 2 dom(Sn)

2. Sn(`1) is a value of type bool
Together these two conditions imply that we need to prove hSn; `1i 2 box bool in
order to show that the last instruction is safe to execute. We already know that
hS1; `1i 2 box bool, but we need to account for the fact that Sn is different from
S1. An examination of the operational semantics suggests that condition (1) must
hold since there are no terms in *I that shrink the store -- hence, dom(Sn) must
be a superset of dom(S1). Similarly, condition (2) must be true since there are no
*I terms that update allocated locations -- hence, if ` is an allocated location in S1
then S1(`) = Sn(`). More formally, for any two machine states (S ; e) and (S 0; e0), if
(S ; e) 7-!*I (S 0; e0), then the relationship between S and S 0 is specified by S v S 0
(read "S 0 is a valid extension of S "):

Definition 2.13 (Store Extension)
A valid store extension is defined as follows:

S v S 0 def= 8`: ` 2 dom(S ) =) (` 2 dom(S 0) ^ S (`) = S 0(`))
The concept of a valid store extension S v S 0 is useful for restricting attention to
only those stores S 0 that are possible in the future given the operational semantics
of *I . Returning to the above example, given hS1; `1i 2 box bool and S1 v Sn, we
can show that hSn; `1i 2 box bool. In general, we want all of the types *I to have
this property exhibited by box bool, that is, we want type sets in *I to be closed
under valid store extension.

Definition 2.14 (Type)
A type is a set o/ of tuples of the form hS ; vi, where S is a store and v is a value,
such that if hS ; vi 2 o/ and S v S 0 then hS 0; vi 2 o/ ; that is,

type(o/ ) def= 8S ; S 0; v: (hS ; vi 2 o/ ^ S v S 0) =) hS 0; vi 2 o/
I have shown that the absence of cell deallocation and update in *I (captured
by the definition of v) is crucial for proving that box types are preserved under
evaluation. Now let us take a look at boolean and function types.

24

A value v has type bool as long as v is either true or false. Though types are
predicates on stores as well as values, the store is irrelevant when determining if a
value v has type bool. It trivially follows that bool is closed under store extension.

bool def= { hS ; vi | v = true . v = false }
When deciding if a value *x:e has type o/1 ! o/2 with respect to a current store S
we have to keep in mind that the program may not utilize (apply) *x:e until some
point in the future, a point when the store may be different from S thanks to the
evaluation of new terms in the interim. Let S 0 be that future store; since *I does
not allow cell deallocation or update, clearly it should be the case that S v S 0. For
any value v that has type o/1 with respect to S 0, if evaluating the expression e[v=x]
with store S 0 gives us a value of type o/2 (along with a store that is a valid extension
of S 0) then we may conclude that *x:e has type o/1 ! o/2 with respect to store S .
Before I can formally define o/1 ! o/2, I must specify what it means for a closed
expression e to have type o/ with respect to store S (written e :S o/ ). Informally, I
say e :S o/ if e evaluates to a value of type o/ and if the evaluation results in a store
S 0 that is a valid extension of store S .

Definition 2.15 (Expr : Type)
For any closed expression e and type o/ I write e :S o/ if whenever (S ; e) 7-!*I (S 0; e0)
and (S 0; e0) is irreducible, then hS ; e0i 2 o/ ; that is,

e :S o/ def= 8S 0; e0: ((S ; e) 7-!*I (S 0; e0) ^ irred(S 0; e0))

=) S v S 0 ^ hS 0; e0i 2 o/

Note that for a value v, the statements v :S o/ and hS ; vi 2 o/ are equivalent. The
semantics of function types can now be defined as follows.

o/1 ! o/2 def= { hS ; *x:ei | 8v; S 0: (S v S 0 ^ hS 0; vi 2 o/1) =) e[v=x] :S0 o/2 }

In order to prove that function types are closed under store extension I will
first need to show that valid store extension (v) is transitive (see Lemma 2.18 for
details). Store extension states that allocated cells cannot be freed or updated;
hence, stores can only grow, which means that v relates monotonically increasing
stores, so it is easy to show that v is transitive.

A Modal Interpretation The semantics that I have presented thus far is actually
a possible-worlds semantics. Possible-worlds models are often called Kripke models
in honor of Saul Kripke who introduced the notion of possible worlds [Kri63] when
he developed a model theory for propositional modal logic based on this concept. I
use possible worlds to capture the modal (temporal) nature of types in a language

25

with side-effects. In order to further motivate some of the properties of stores and
types in our model, I will now examine the connections between possible-worlds
models of modal logic and our model for *I .

Possible-worlds models are specified by defining the following (see Huth and
Ryan [HR00]):

* A set W , whose elements are called worlds. In Kripke's multiple-world interpretation of modal logic, a proposition is true or false relative to a world.
Similarly, in our model, a value v has type o/ relative to a world, that is, relative to a state of computation during evaluation. While one could use machine
states (S ; e) to model worlds, all the information that our model needs from a
world may be found in the store component of a machine state (see discussion
of the labeling function below). Hence, a world in our model corresponds to

a store, so we have W = Loc fin! Val , where Loc is the countably infinite set
of locations and Val is the set of *I values.

* A relation Acc ` W * W called the accessibility relation. Given worlds w and

w0, Acc(w; w0) says that w0 is accessible from w. In our model, this corresponds
to the store extension relation (v) and S v S 0 says that store S 0 is accessible
(or possible) from store S .

* A labeling function L : W ! P(Atoms) that, given a world w, yields the set

of atomic propositions that hold in that world. The atomic propositions p
that we are interested in are of the form: "location l is allocated and contains
value v." Therefore, in our model,

L(S ) = { (`; v) | S (`) = v }

* The properties that the accessibility relation Acc should satisfy. Imposing

different laws on the accessibility relation leads to different modal logics. Our
model is constructed to ensure that the v relation is reflexive and transitive.
This suggests a connection with the modal logic S4 since models of S4 also
require that the accessibility relation be reflexive and transitive.

In Kripke's semantics of modal logic, modal operators allow us to reason about
the truth of a proposition in all worlds accessible (or possible) from the current
world. The modal operator that we are particularly interested in is 2 which may be
pronounced "always" or "necessarily" or "everywhere" (among other possibilities)
depending on the desired interpretation. We shall interpret 2 as "always" and
interpret 2p as "It will always be true that p." This corresponds to interpreting
Acc(w; w0) as "w0 is in the future of w." To enforce this interpretation, a model for
this logic must satisfy 2p ! 22p -- informally, if p will always be true then it will

26

bool def= { hS ; vi | v = true . v = false }
box o/ def= { hS ; ` i | ` 2 dom(S ) ^ hS ; S (`)i 2 o/ }
o/1 ! o/2 def= { hS ; *x:ei | 8v; S 0: (S v S 0 ^ hS 0; vi 2 o/1) =) e[v=x] :S0 o/2 }

Figure 2.4: Immutable References (*I ): Type Definitions
always be true that p will always be true. This is equivalent to requiring that Acc
be transitive. Also, we assume that the future includes the present -- that is, if p
will always be true then p is true right now -- so the model must satisfy 2p ! p.
This is equivalent to requiring that Acc be reflexive. The resulting modal logic is
known as KT4 or S4 in the literature. Reading the proposition p as "location ` is
allocated and contains value v" we can see why the reflexivity and transitivity of v
captures the semantics of immutable references that we had wanted to describe.

2.2.2 Validity of Types
The type definitions developed in Section 2.2.1 are summarized in Figure 2.4. They
rely on Definitions 2.13 (Store Extension) and 2.15 (Expr : Type). Next, I shall
prove that each of the type constructors shown in Figure 2.4 is a type or produces
a type when applied to valid arguments. In each case, I have to show that types
are preserved under store extension (as specified by Definition 2.14). I shall first
prove some properties of store extension that we will need later, namely that store
extension is both reflexive and transitive.

Lemma 2.16 (Store Extension Reflexive)
S v S .

Proof: Immediate. \Lambda 

Lemma 2.17 (Store Extension Transitive)
If S1 v S2 and S2 v S3 then S1 v S3.

Proof: For any location ` 2 dom(S1) we must show that ` 2 dom(S3) and
S1(`) = S3(`). Suppose ` 2 dom(S1). From S1 v S2 we have ` 2 dom(S2) and
that S1(`) = S2(`). Since ` 2 dom(S2), from S2 v S3 it follows that ` 2 dom(S3)
and that S2(`) = S3(`). By the transitivity of equality it follows that S1(`) = S3(`).

\Lambda 

The fact that bool is a type follows immediately from its definition: whenever
hS ; vi 2 bool and S v S 0, we have hS 0; vi 2 bool since whether or not v is a boolean

27

is independent of the current store. To prove that o/1 ! o/2 is a type (assuming o/1
and o/2 are types) we will need to make use of Lemma 2.17 which says that store
extension is transitive.

Lemma 2.18 (Type o/1 ! o/2)
If o/1 and o/2 are types then o/1 ! o/2 is also a type.

Proof: We have to show that o/1 ! o/2 is closed under store extension. Suppose
hS ; vi 2 o/1 ! o/2 and that S v S 0. Note that v must be a closed abstraction of
the form *x:e. We have to show that hS 0; *x:ei 2 o/1 ! o/2. Suppose S 0 v S 00 and
hS 00; v1i 2 o/1 for some store S 00 and value v1 -- by the definition of ! we have to
show that e[v1=x] :S00 o/2. By Lemma 2.17 (v transitive) we have S v S 00. By the
definition of !, hS ; *x:ei 2 o/1 ! o/2 together with S v S 00 and hS 00; v1i 2 o/1 implies
e[v1=x] :S00 o/2. \Lambda 

Next, we prove that box o/ is a type as long as o/ is a type.
Lemma 2.19
If o/ is a type, then box o/ is a type.

Proof: To show that box o/ is closed under store extension, suppose hS ; vi 2 box o/
and S v S 0. We have to show that hS 0; vi 2 box o/ . Note that v must be some store
location `. From hS ; ` i 2 box o/ we have ` 2 dom(S ) and hS ; S (`)i 2 o/ . Since o/
is a type (i.e., it is closed under store extension), we have hS 0; S (`)i 2 o/ . From
` 2 dom(S ) and S v S 0 it follows that ` 2 dom(S 0) and S (`) = S 0(`). Hence,
hS 0; S 0(`)i 2 o/ . Now, by the definition of box, we have hS 0; ` i 2 box o/ . \Lambda 

2.2.3 Judgments, Typing Rules, and Safety
Up to now I have only dealt with closed *I terms, as these are the ones that
are evaluated at run time. Now I turn to terms with free variables, upon which
the static type-checking rules must operate. Type judgments in *I have the form
\Gamma  |=I e : o/ where \Gamma  is a type environment, that is, a mapping from variables to types.
As before, a value environment (ground substitution) is a mapping from lambda
calculus variables to values and the judgment \Gamma  |=I e : o/ can be viewed as a three
place relation that holds on the type environment \Gamma , the term e, and the type o/ .

Definition 2.20 (Semantics of Judgment)
For any type environment \Gamma  and value environment oe I write oe :S \Gamma  if for all
variables x 2 dom(\Gamma ) we have oe(x) :S \Gamma (x); that is,

oe :S \Gamma  def= 8x 2 dom(\Gamma ): oe(x) :S \Gamma (x)

28

I write \Gamma  |=I e : o/ iff F V (e) ` dom(\Gamma ) and

8oe; S : oe :S \Gamma  =) oe(e) :S o/
where oe(e) is the result of replacing the free variables in e with their values under
oe.

Finally, I write |=I e : o/ to mean \Gamma 0 |=I e : o/ for the empty type environment \Gamma 0.

The typing rules for *I are given in Figure 2.5. As in the previous section, I write
\Gamma  [x 7! o/ ] to denote the type environment that extends \Gamma  by mapping x to o/ where
x =2 dom(\Gamma ). There are two ways in which the type-checking rules in Figure 2.5
differ from the typing rules one is accustomed to (in syntactic type theories) for a
language with references -- that is, in addition to the fact that I use |=I rather
than `I . First, the type judgment does not contain a store typing \Psi  that maps
locations in the store to the types of the values that they may contain -- that is,
type judgments have the form \Gamma  |=I e : o/ rather than \Gamma ; \Psi  |=I e : o/ . Second, there
is no typing rule for locations, that is, with a conclusion of form \Gamma  |=I ` : box o/ .
These differences can be explained as follows. Our type-checking rules are used
to determine if a "program" is well-typed. A program in *I is a closed term that
does not contain any location symbols `, though, once a program begins executing
it may step (by means of new) to expressions that do contain location symbols.
A conventional subject-reduction proof requires that the type system be able to
type-check programs during execution, which means that there must be a way to
type-check locations `. Since we are not doing subject reduction, we do not need
to type-check executing programs. Hence, we do not need to type-check locations,
which means that we need neither a store typing \Psi , nor a typing rule for locations.3

I shall prove each of the type inference rules in Figure 2.5 as lemmas (see Section 2.2.4). These lemmas can then be used as standard type inference rules to
prove statements of the form \Gamma  |=I e : o/ .

Our goal is to prove that a program is safe to execute given an initial store S .
There are no additional constraints on S , in fact, S might as well be the empty
store because the program e -- since it has no free variables or location symbols --
cannot access any locations in S . Hence, we need to prove that given an arbitrary
store S and a well-typed program e (with some type o/ ), machine state (S ; e) is

3The fact that type judgments in *I do not require a store typing \Psi  may also be explained as
a benefit of using a possible-worlds model (where types are sets of store-value pairs) rather than a
model in which types are simply sets of values. A model in which types are simply sets of values
can neither keep track of which locations are allocated at different points during the computation,
nor specify how the store is allowed to change over time (as the v relation does). In such a model,
type judgments would need a store typing \Psi  in order to track allocated locations and to somehow
ensure that their types are preserved over the course of evaluation. The semantics of such type
judgments would have to quantify over stores S whose contents are of the types specified by \Psi .

29

\Gamma  |=I x : \Gamma (x) (I-var)
\Gamma  |=I true : bool (I-true) \Gamma  |=I false : bool (I-false)

\Gamma  [x 7! o/1] |=I e : o/2
\Gamma  |=I *x:e : o/1 ! o/2 (I-abs)

\Gamma  |=I e1 : o/1 ! o/2 \Gamma  |=I e2 : o/1

\Gamma  |=I (e1 e2) : o/2 (I-app)

\Gamma  |=I e : o/
\Gamma  |=I new(e) : box o/ (I-new)

\Gamma  |=I e : box o/

\Gamma  |=I ! e : o/ (I-deref)

Figure 2.5: Immutable References (*I ): Type-checking Lemmas
safe. Notice that the safety theorem requires that o/ be a valid type. One can prove
type(o/ ) using the lemmas in Section 2.2.2.

Theorem 2.21 (Safety)
If |=I e : o/ , o/ is a type, and S is a store, then (S ; e) is safe.

Proof: To prove safe(S ; e) we must show that for any state (S 0; e0) reachable in
some number of steps from (S ; e), either e0 is a value or another step is possible.
Suppose (S ; e) 7-!*I (S 0; e0). If (S 0; e0) is not irreducible, then there must exist some
(S 00; e00) such that (S 0; e0) 7-!I (S 00; e00). Otherwise, (S 0; e0) is irreducible and we
must prove that e0 is a value. From |=I e : o/ we have \Gamma 0 |=I e : o/ and it follows that e
is closed (since \Gamma 0 is the empty type environment). Choose the empty value environment oe0 and store S . By the definition of |=I we have oe0 :S \Gamma 0 =) oe0(e) :S o/ . The
premise oe0 :S \Gamma 0 is trivially satisfied; applying the trivial substitution we have e :S o/ .
Since (S ; e) 7-!*I (S 0; e0) and irred(S 0; e0) it follows by Definition 2.15 (Expr : Type)
that S v S 0 and hS 0; e0i 2 o/ . Since o/ is a type it follows that val(e0). \Lambda 

30

2.2.4 Validity of Typing Rules
It only remains for us to prove each of the typing rules in Figure 2.4 as lemmas. The
lemma for variables follows immediately from the definition of |=I . The lemmas for
I-true and I-false are immediate from the definition of |=I and type bool.

Theorem 2.22 (Abstraction)
Let \Gamma  be a type environment, let o/1 and o/2 be types, and let \Gamma  [x 7! o/1] be the type
environment that is identical to \Gamma  except that it maps x to o/1 (where x =2 dom(\Gamma )).
If \Gamma  [x 7! o/1] |=M e : o/2 then \Gamma  |=M *x:e : o/1 ! o/2.

Proof: We must show that under the premises of the theorem, for any oe and S
such that oe :S \Gamma , we have oe(*x:e) :S o/1 ! o/2. Suppose oe :S \Gamma . Let v and S 0 be
such that S v S 0 and hS 0; vi 2 o/1. By the definition of ! it now suffices to show
that oe(e[v=x]) :S0 o/2. Let oe [x 7! v] be the substitution identical to oe except that
it maps x to v. Since the codomain of \Gamma  contains types (which are closed under
store extension), and since v :S0 o/1, we now have that oe [x 7! v] :S0 \Gamma  [x 7! o/1].
This, together with the premise \Gamma  [x 7! o/1] |=I e : o/2, allows us to conclude that
oe [x 7! v](e) :S0 o/2. But this implies oe(e[v=x]) :S0 o/2. \Lambda 

Theorem 2.23 (Application)
If \Gamma  is a type environment, e1 and e2 are (possibly open) terms, and o/1 and o/2 are
types such that \Gamma  |=I e1 : o/1 ! o/2 and \Gamma  |=I e2 : o/2 then \Gamma  |=I (e1 e2) : o/2.

Proof: We must show that under the premises of the theorem, for any value
environment oe and store S such that oe :S \Gamma , we have oe(e1 e2) :S o/2. Suppose
oe :S \Gamma . Also, suppose (S ; oe(e1 e2)) 7-!*I (S 0; e0) and irred(S 0; e0) -- we must show
that S v S 0 and hS 0; e0i 2 o/2. The proof is in three parts. Informally, these
correspond to (1) reducing e1 to a value (say e01), (2) reducing e2 to a value (say
e02), and (3) applying the function value e01 to the argument value e02 and reducing
the beta-reduced expression to a value.

1. By the operational semantics it follows that (S ; oe(e1)) 7-!*I (S 01; e01) and

irred(S 01; e01). From the premise \Gamma  |=I e1 : o/1 ! o/2 and oe :S \Gamma  we have oe(e1) :S
o/1 ! o/2, so by Definition 2.15 (Expr : Type) we have hS 01; e01i 2 o/1 ! o/2. From
the definition of ! it follows that e01 is of the form *x:e11.

2. By the operational semantics we also have (S 01; oe(e2)) 7-!*I (S 02; e02) and irred(S 02; e02).

From oe :S \Gamma , S v S 01, and the fact that the codomain of \Gamma  contains types
(which are closed under store extension) it follows that oe :S0

1 \Gamma . This, togetherwith the premise \Gamma  |

=I e2 : o/1 gives us oe(e2) :S0

1 o/1. Hence, by Definition 2.15(Expr : Type) we have S 0

1 v S 02 and hS 02; e02i 2 o/1.

31

3. (S 02; (*x:e11)e02) 7-!I (S 02; e11[e02=x]) 7-!*I (S 0; e0). By the definition of !,

from hS 01; *x:e11i 2 o/1 ! o/2, S 01 v S 02, and hS 02; e02i 2 o/2 we have e11[e02=x] :S0

2 o/2.Then, by Definition 2.15 (Expr : Type) it follows that S 0

2 v S 0 and hS 0; e0i 2 o/2.

Finally, we have S v S 01 v S 02 v S 0 and store extension is transitive (Lemma 2.17).
Hence, we have S v S 0 and also hS 0; e0i 2 o/2 as we wanted to show. \Lambda 

Lemma 2.24 (Closed New)
If e is a closed term and o/ is a type such that e :S o/ then new(e) :S box o/ .

Proof: Suppose (S ; new(e)) 7-!*I (S 0; `) where irred(S 0; `); we must show that
S v S 0 and hS 0; ` i 2 box o/ . The proof is in two parts. Informally, these correspond
to (1) reducing e to a value and (2) allocating a new store location initialized to
that value.

1. By the operational semantics it follows that (S ; e) 7-!*I (S1; e1) and irred(S1; e1).

From the premise e :S o/ we have S v S1 and hS1; e1i 2 o/ .

2. By the operational semantics we also have (S1; new(e1)) 7-!I (S1 [` 7! e1]; `)

where ` =2 dom(S1). Since ` is a value we have irred(S1 [` 7! e1]; `). Note
that S 0 j S1 [` 7! e1]. Clearly, S1 v S 0; then, by the transitivity of v
(Lemma 2.17), S v S 0 as we wanted to show.

Since o/ is a type, from hS1; e1i 2 o/ and S1 v S 0 it follows that hS 0; e1i 2 o/ .
Since S 0(`) = e1, we have hS 0; S 0(`)i 2 o/ which, together with ` 2 S 0, implies
hS 0; ` i 2 box o/ as we wanted to show.

\Lambda 

Theorem 2.25 (New)
If \Gamma  is a type environment, e is a (possibly open) term, and o/ is a type such that
\Gamma  |=I e : o/ , then \Gamma  |=I new(e) : box o/ .

Proof: We must prove that for any value environment oe and store S such that
oe :S \Gamma  we have oe(new(e)) :S box o/ , or equivalently, new(oe(e)) :S box o/ . Suppose
oe :S \Gamma . From the premise \Gamma  |=I e : o/ we have oe(e) :S o/ . Since oe(e) is a closed term
the result now follows from Lemma 2.24. \Lambda 

Lemma 2.26 (Closed Deref )
If e is a closed term and o/ is a type such that e :S box o/ then ! e :S o/ .

32

Proof: Suppose (S ; ! e) 7-!*I (S 0; e0) such that irred(S 0; e0). We must prove that
S v S 0 and hS 0; e0i 2 o/ . Informally, the proof reasoning involves (1) reducing e to a
location ` and (2) reading the contents at location ` in the store. More formally, by
the operational semantics we have (S ; e) 7-!*I (S 0; `) and irred(S 0; `). Hence, from
the premise e :S box o/ we may conclude that S v S 0 and hS 0; `i 2 box o/ . By the
definition of box o/ we have ` 2 dom(S 0) and hS 0; S 0(`)i 2 o/ . By the operational
semantics we also have (S 0; ! `) 7-!I (S 0; e0) where e0 = S 0(`). Hence, hS 0; e0i 2 o/ .

\Lambda 

Theorem 2.27 (Deref )
If \Gamma  is a type environment, e is a (possibly open) term, and o/ is a type such that
\Gamma  |=I e : box o/ , then \Gamma  |=I ! e : o/ .

Proof: Follows from Lemma 2.26 in the same manner that Theorem 2.25 (New)
follows from Lemma 2.24 (Closed New). \Lambda 

2.2.5 Discussion: Kripke Logical Relations
In Section 2.1.6, I discussed the correspondence between logical relations and our
semantic model of the *-calculus with booleans. Analogously, there is a correspondence between Kripke logical relations and the possible-worlds model I have
developed for *I . Recall that a logical relation R = {Ro/ } is a family of relations
Ro/ for each type o/ in the language. For a Kripke logical relation, instead of having
a relation for each type, one must have a relation for each type and possible world.
Specifically, a (unary) Kripke logical relation over a set A is defined as follows.
Suppose that we have a set of worlds W , an accessibility relation Acc ` W * W ,
and a family {io/w w0} of transition functions where w and w0 are worlds such that
Acc(w; w0). A transition function maps some element a 2 A in world w to some
element a0 2 A in world w0. Then a Kripke logical relation is a family R = {Ro/w}
of relations Ro/w indexed by types o/ and worlds w 2 W , satisfying the following
condition:

(Monotonicity) Ro/w(a) implies Ro/w0(io/w w0(a)) for all w0 such that Acc(w; w0).
The monotonicity condition says that when Acc(w; w0), the relation Ro/w is contained
in Ro/w0, modulo the transition function. (See Mitchell [Mit96] for a detailed description of Kripke logical relations.)

To prove that well-typed *I terms are safe one would define a Kripke logical
relation as follows.

* Define a Kripke logical relation over the set A = { e | e is a *I term }.

33

* Pick the set of worlds W = Store, that is, worlds w correspond to stores S .

* Let the accessibility relation Acc = v.

* Let the transition functions correspond to the 7-!I relation, that is, io/S S0(e) =

e0 whenever (S ; e) 7-!*I (S 0; e0).

Next, for each type o/ and store S , one defines a set (i.e., a unary relation) Ro/S of
closed terms e that have type o/ with respect to some store S :

* RboolS (e) iff for all S 0 and e0 such that (S ; e) 7-!*I (S 0; e0) and irred(S 0; e0), we

have S v S 0 and either e0 = true or e0 = false.

* Ro/1!o/2S (e) iff for all S 0 and e0 such that (S ; e) 7-!*I (S 0; e0) and irred(S 0; e0), we

have S v S 0 and e0 = *x:e2, and for all stores S1 such that S v S1 whenever
Ro/1S

1 (e1), we have R

o/2
S1 (e e1).

* Rbox o/S (e) iff , for all S 0 and e0 such that (S ; e) 7-!*I (S 0; e0) and irred(S 0; e0), we

have S v S 0 and e0 = `, and for all stores S1 such that S v S1, Ro/S1(! e).

Notice that Ro/S (e) corresponds to e :S o/ (Definition 2.15) in our semantic model.
The monotonicity condition for our Kripke logical relation is as follows:

If Ro/S (e) and (S ; e) 7-!*I (S 0; e0), then Ro/S0(e0) for all S 0 such that S v S 0.
If the monotonicity condition holds, the above definition implies that the relation
Ro/S consists of all expressions e such that if (S ; e) 7-!*I (S 0; e0), then S v S 0 and
e0 2 Ro/S0.

As in Section 2.1.6, the proof is in two parts. First, we prove that if Ro/S (e) then
safe(S ; e) (which corresponds to Theorem 2.21). The proof follows easily from the
definition of Ro/S . Next, we show that every well-typed term e of type o/ is an element
of Ro/S for some store S . The proof is by induction on the type derivation and (as for
Lemma 2.11 in Section 2.1.6) the cases of this proof, namely for typing rules I-var,
I-true, I-false, I-abs, I-app, I-new, and I-deref, bear a close resemblance to
the proofs of the typing rule lemmas we proved in Section 2.2.4.

In order to prove this last lemma, we must prove that the Kripke monotonicity
condition holds. Informally, the proof follows from the fact that monotonicity over
the course of evaluation plays a fundamental role at every "layer" of our model. If
S is the current store and S 0 is some possible future store then:

* The lowest layer of the model, relying on the absence of cell deallocation and

update, specifies that if ` maps to v in S then ` maps to v in S 0. This is
captured by valid store extension (v) which establishes the monotonicity of
stores.

34

* The next layer of the model shows that if hS ; vi 2 o/ then hS 0; vi 2 o/ . For each

type o/ , we prove the monotonicity of sets of values of that type. To prove this
property (specified as type(o/ )) we must rely on the monotonicity of stores.

* The next layer establishes type preservation, that is, if e has type o/ with respect to store S and we reach a state (S 0; e0), then e0 has type o/ with respect S 0.
This corresponds precisely to Kripke monotonicity. We prove the monotonicity (over the course of evaluation) of sets of expressions of each type. The
proof relies on the monotonicity of sets of values of each type.

Hence, in *I we ultimately rely on the absence of deallocation and update to establish monotonicity at each "layer" of the model. Both cell updates and deallocation
are features that make monotonicity (and hence, type invariance) much harder to
establish. In subsequent chapters, I will describe how to prove type invariance in
the presence of features that make monotonicity harder to establish, namely cell
updates (Chapter 3) and deallocation (Chapter 7).

35

Chapter 3
Mutable References:
Mutation & Quantified Types

Almost all practical programming languages use mutable references.1 Object-oriented languages such as Java and functional languages such as ML permit general references -- that is, mutable memory cells that may contain values of any (staticallychecked) closed type, including recursive types, functions, and even other references.
Therefore, general references are essential in our plans to build foundational PCC
systems for practical languages. In a foundational PCC system we want to prove
the safety of low-level programs, that is, programs written in the target language
of a type-preserving compiler. Target languages for type-preserving compilation of
languages like ML and Java must not only support mutable references, but also
quantified types. Universal types, for instance, are useful for encoding ML parametric polymorphism and Java inheritance [Lea02], while existential types are essential for encoding ML function closures [MMH96, MWCG99] and abstract data
types [MP88], and also for Java object encoding [BCP99, Lea02].

Quantified types may be predicative or impredicative. Let type o/ = 9ff:o/ 0 (where
ff may occur free in o/ 0). We say that o/ is an impredicative existential type if ff may
be instantiated with any type, including o/ itself. The definition of impredicative
universal types is analogous. More generally,

a definition (of a set, a type, etc.) is called "impredicative" if it involves
a quantifier whose domain includes the very thing being defined [Pie02].

While high-level languages such as ML and Java do not themselves support impredicative polymorphism, this feature is essential in a target language for typepreserving compilation of these languages. Consider, for instance, type-preserving
compilers for higher-order functional languages (such as ML). As part of the typepreserving translation of higher-order functions into function closures -- known as

1Haskell [HPW91] is an exception.

36

typed closure conversion -- functions with free variables are replaced by code abstracted on an extra environment parameter; free variables in the body of the function are replaced by references to the environment; and the function is converted
into a "closure", that is, a data structure that contains the code and a representation of the code's environment. An important property of closure conversion is that
the representation of the environment is private to the closure. Hence, typed closure
conversion uses an existential quantifier to hide the type of the function environment [MMH96, MWCG99]. An ML function of type o/1 ! o/2 would be translated
to an existential package with two components as shown below -- I write C[[o/ ]] to
denote the translation of a source language type o/ . The first component is the code
which has type code(o/env; C[[o/1]]; C[[o/2]]) indicating that it takes an environment of
type o/env and an argument of type C[[o/1]], and returns a result of type C[[o/2]]. The
second is the environment which has type o/env.

C[[o/1 ! o/2]] = 9o/env: hcode(o/env; C[[o/1]]; C[[o/2]]) * o/envi
The environment of a function closure f can contain other function closures, including f itself -- that is, the existential can be instantiated with other existential
types, including itself -- so that the quantification must be impredicative. Furthermore, since ML has mutable references, the environment of a function closure can
contain a mutable reference. A mutable reference can, in turn, store a function closure. In the target language, therefore, mutable references must be able to contain
impredicative existentials and vice versa.2

In Chapter 2 (Section 2.2) I described a model for a language with dynamic
allocation of immutable cells. To build a foundational PCC system (based on the
semantic approach) for a practical high-level language such as ML or Java, we have
to construct a semantic model of a language that supports:

* dynamic heap allocation of mutable cells;

* impredicative polymorphism and general references (mutable cells that can

store functions, other mutable references, impredicative quantified types, etc.);

* recursive types (both covariant and contravariant).
Semantic models of general references have posed a challenge to semanticists for
years [FJM+96, TG00]. Building semantic models of impredicative polymorphism
is also difficult [CGW89], but modeling the combination of the two features seems
especially tricky. Recently, two models of mutable references have emerged, built

2There may be other, as yet undiscovered, ways of representing function closures, but for
now it seems we needs mutable references to impredicative quantified types, regardless of
whether we adopt a type-passing interpretation of polymorphism [MMH96] or one based on typeerasure [MWCG99].

37

Expressions e : : = x | ` | unit | *x:e | (e1 e2) | new(e) | ! e | e1 := e2

| \Lambda :e | e[ ] | pack e | unpack e1 as x in e2
Values v : : = ` | unit | *x:e | \Lambda :e | pack v

Figure 3.1: Mutable References (*M ): Syntax
using game semantics [AHM98] and category theory [Lev02] respectively, but neither
of these supports the storage of polymorphic values in mutable cells.

This chapter examines the challenges of modeling mutable references that may
store values of any closed type (including impredicative quantified types). To simplify the presentation, instead of directly describing the von Neumann model that
we have built for our foundational PCC system (see Chapter 6), I will first explain
how to construct a semantic model of the polymorphic *-calculus augmented with
mutable references. The material in this chapter is based on research done jointly
with Andrew Appel and Roberto Virga [AAV02, AAV03].

3.1 Polymorphic *-calculus with Mutable Cells
3.1.1 Syntax
The language I consider is the polymorphic lambda-calculus (also known as System
F) augmented with mutable references, existentials, and the constant unit. I call
this language *M . I have omitted booleans and immutable references from the
language, but these types along with cartesian products, intersection and union
types, and other standard constructions are easy to add to the model I shall present.
The syntax of lambda terms is given by the grammar shown in Figure 3.1. I use
the metavariable x to range over a countably infinite set Var of variables and the
metavariable ` to range over a countably infinite set Loc of locations. A term v is
a value if it is a location `, the constant unit, a term or type abstraction, or an
existential package, and if it contains no free term variables x.

This syntax is slightly unconventional: in most presentations the polymorphic operators \Lambda ff:e and e[o/ ] and the existential operators pack[o/; e] as 9ff:o/ 0 and
unpack e as [o/; x] in e0 mention types syntactically. I want to give purely semantic
(not syntactic) typings to untyped lambda calculus, so I omit all types from the syntax. In general, I let the vestigial operators remain in the untyped syntax in order
to preserve the operational semantics. For instance, the term \Lambda :e is a suspended
computation (normally written \Lambda ff:e); e[ ] runs the suspended computation.

38

3.1.2 Operational Semantics
A store S is a finite map from locations to closed values. The domain of S includes
all locations already allocated; locations not in dom(S ) are available to be allocated
by new in future computation steps. The small-step semantics for *M is given by
an abstract machine whose state is described by a pair (S ; e) of a store and a
closed term. The notation (S ; e) 7-!M (S 0; e0) denotes a single operational step. I
write (S ; e) 7-!jM (S 0; e0) to denote that there exists a chain of j steps of the form
(S ; e) 7-!M (S1; e1) 7-!M : : : 7-!M (Sj; ej) where Sj is S 0 and ej is e0. I write
(S ; e) 7-!*M (S 0; e0) if (S ; e) 7-!jM (S 0; e0) for some j >= 0.

The operational semantics is given in Figure 3.2 and is completely standard.3
There are only two rules in the operational semantics that produce side-effects. The
first is the rule that evaluates terms of the form new(v) (see MO-new2); it extends
the store with a previously unallocated location ` initialized to v. The second is the
rule that evaluates terms of the form ` := v (see MO-assign3); it checks that ` is
an allocated cell and updates the store so ` maps to v.

In the examples that follow, I use the notation let x = e1 in e2 as syntactic
sugar for (*x:e2)e1. I write let = e1 in e2 in place of (*x:e2)e1 when the variable
x does not occur free in e2.

3.2 Towards a Model of Mutable References
This section examines the challenges of modeling general references and gradually
closes in on a semantics that supports such references.

3.2.1 Need for a New Model
The model that I built for *I (*-calculus with immutable references) in Section 2.2
cannot be used to reason about the safety of programs written in an imperative
language -- that model prohibits updates to allocated cells. I could change the
model for *I so that it permits updates to store locations, but such updates may
lead to inconsistency in the presence of aliasing. To see why, consider the *M
program in Figure 3.3(a), in particular, the instruction x := y -- the variable x
points to an allocated cell and the assignment x := y updates the cell with the
value y. (The comments, which I shall explain momentarily, describe invariants

3The reader may not consider the rules MO-tapp2 (type application) and MO-unpack2 (unpacking an existential) completely standard. On a real machine, there are no such instructions. In
Chapter 4 (see Section 4.1) I will describe how the semantic model must be changed to accommodate an operational semantics that treats type application and existential unpacking as virtual
instructions, or coercions.

39

(S ; e1) 7-!M (S 0; e01)
(S ; e1 e2) 7-!M (S 0; e01 e2) (MO-app1)

(S ; e2) 7-!M (S 0; e02)
(S ; (*x:e1) e2) 7-!M (S 0; (*x:e1) e02) (MO-app2)

(S ; (*x:e) v) 7-!M (S ; e[v=x]) (MO-app3)

(S ; e) 7-!M (S 0; e0)
(S ; new(e)) 7-!M (S 0; new(e0)) (MO-new1)

` =2 dom(S )
(S ; new(v)) 7-!M (S [` 7! v]; `) (MO-new2)

(S ; e) 7-!M (S 0; e0)
(S ; ! e) 7-!M (S 0; ! e0) (MO-deref1)

` 2 dom(S )
(S ; ! `) 7-!M (S ; S (`)) (MO-deref2)

(S ; e1) 7-!M (S 0; e01)
(S ; e1 := e2) 7-!M (S 0; e01 := e2) (MO-assign1)

(S ; e2) 7-!M (S 0; e02)
(S ; v1 := e2) 7-!M (S 0; v1 := e02) (MO-assign2)

` 2 dom(S )
(S ; ` := v) 7-!M (S [` 7! v]; unit) (MO-assign3)

(S ; e) 7-!M (S 0; e0)
(S ; e[ ]) 7-!M (S 0; e0[ ]) (MO-tapp1) (S ; (\Lambda :e)[ ]) 7-!M (S ; e) (MO-tapp2)

(S ; e) 7-!M (S 0; e0)
(S ; pack e) 7-!M (S 0; pack e0) (MO-pack)

(S ; e1) 7-!M (S 0; e01)
(S ; unpack e1 as x in e2) 7-!M (S 0; unpack e01 as x in e2) (MO-unpack1)

(S ; unpack (pack v) as x in e2) 7-!M (S ; e2[v=x]) (MO-unpack2)
Figure 3.2: Mutable References (*M ): Operational Semantics

40

let : : : in
% x :S ref o/1; y :S o/1; z :S o/2

let = x := y in
% x :S0 ref o/1; y :S0 o/1; z :S0 o/2

erest

(a) Program fragment

x

z

(b) Store S
Figure 3.3: Store Update in the Presence of Aliasing
that should hold before and after the update.) Suppose that the typing derivation
for the program establishes the following:

1. \Gamma  |=M let = x := y in erest : o/ 0
2. \Gamma  |=M erest : o/ 0
where type environment \Gamma  = {x 7! ref o/1; y 7! o/1; z 7! o/2}.

Let S and S 0 denote the stores immediately before and after the evaluation of
x := y. By the semantics of *I judgments, judgment (1) implies that x :S ref o/1
(variable x has type ref o/1 with respect to store S ), y :S o/1, and z :S o/2 (see the
comments in Figure 3.3(a)). Judgment (2) implies that x, y, and z should have the
same types as before, but now with respect to store S 0. Hence, we need a semantic
model that allows us to prove the following Hoare triple.

{x :S ref o/1 ^ y :S o/1 ^ z :S o/2}
x := y
{x :S0 ref o/1 ^ y :S0 o/1 ^ z :S0 o/2}

Consider the scenario when S is the store depicted in Figure 3.3(b) -- the assignment
x := y updates the location that x points to (thereby modifying the data structure
that z points to), so that we cannot know if z has type o/2 with respect to the
modified store S 0. We do not want to rule out situations such as this one where an
aliased location is being updated. However, allowing updates of aliased locations
while guaranteeing consistency is not an easy task. We need to construct a semantic
model that ensures that even when we update an allocated location, type judgments
made with respect to the old store continue to be valid with respect to the new store.
This suggests that writing to an allocated location should be permitted only if the
update is type-preserving.

41

Languages like ML and Java also deal with the aliasing problem by allowing
only type-preserving updates, or weak updates. To permit reuse of memory, ML
and Java rely on garbage collection -- hence, strong updates are dealt with outside
of the type system. In this chapter, I shall only consider weak updates. The issue
of strong updates and memory reuse is discussed in Chapter 7.

Type-preserving updates imply that only values of a certain type may be written
at each allocated location. Hence, we require a model that, for each allocated
location, keeps track of this type. Unfortunately, tracking permissible store updates
is tricky.

3.2.2 Modeling Permissible Store Updates
In the model for immutable references described in Section 2.2 types are predicates
on stores and values. We say ` :S box o/ if location ` is allocated and if the value
stored at location ` is of type o/ . To allow for the type-preserving update of allocated
locations we might think of introducing a store typing \Psi , a finite map from locations
to closed types: for each allocated location `, we keep track of the type o/ of updates
allowed at `. A type would then be a predicate on three arguments: a store S , a
store typing \Psi , and a value v. Then our desired definition of ref o/ (the type ascribed
to mutable references) is as follows: we say ` :S;\Psi  ref o/ if location ` is allocated, if
the store typing \Psi  says that the permissible update type for location ` is o/ , and if
the value in the store at location ` is of type o/ .

ref o/ def= { hS ; \Psi ; ` i | ` 2 dom(\Psi ) ^ \Psi (`) = o/ ^ hS ; \Psi ; S (`)i 2 o/ }
Since the second condition in the above definition (i.e., \Psi (`) = o/ ) essentially subsumes the first (i.e., ` 2 dom(\Psi )), we can simplify the definition of ref as follows.

ref o/ def= { hS ; \Psi ; ` i | \Psi (`) = o/ ^ hS ; \Psi ; S (`)i 2 o/ }
Notice that implicit in the above definition is the assumption that the current store
S satisfies the store typing \Psi  (or S is well-typed with respect to \Psi ) -- that is, we
assume that if ` 2 dom(\Psi ) then ` 2 dom(S ) and S (`) has the type \Psi (`), or more
precisely, for all locations ` 2 dom(\Psi ), hS ; \Psi ; S (`)i 2 \Psi (`). But the latter implies
that the definition of ref o/ can be simplified to the following.

ref o/ def= { hS ; \Psi ; ` i | \Psi (`) = o/ }
Notice that the semantics of ref o/ no longer directly depends upon the store S . In
a sense, \Psi  contains all the information that we need about the "current" store S
in order to decide if a location has type ref o/ . Furthermore, there are no other
type predicates in our language that directly make use of the current store in their

42

definitions. Hence, to simplify the specification of our model, we can try to model
types as predicates on just store typings \Psi  and values v, that is, as sets of pairs
h\Psi ; vi.

3.2.3 An Inconsistent Model
The semantics of immutable references (Section 2.2) modeled a type as a predicate
on a store S (a finite map from locations to values) and a value v. I write the types
of these logical objects as,

Store = Loc fin! Val
Type = Store * Val ! o

where o is the type of propositions (true or false).

For the current model, we would like to model types as predicates on store
typings \Psi  (a finite map from locations to closed types) and values v. The types of
these logical objects are as follows.

StoreType = Loc fin! Type
Type = StoreType * Val ! o

But there is a problem with this specification: notice that the metalogical type of
Type is recursive, and, furthermore, that it has an inconsistent cardinality -- the
set of types must be bigger than itself.

3.2.4 A Hierarchy of Types
To better understand the problem, let us take a closer look at our latest desired
definition of ref. We say that a location ` has type ref o/ if it will always contain
a value of type o/ (where "always" includes the present and all possible futures) --
that is, if the current store typing \Psi  (such that the current store is well-typed with
respect to \Psi ) says that the permissible update type for location ` is o/ .

ref o/ def= { h\Psi ; ` i | \Psi (`) = o/ }
Notice that o/ is a "smaller" type than ref o/ and that to determine the members of
ref o/ we, in fact, only consider those locations in the store typing whose permissible
update types are "smaller" than ref o/ . This suggests a well-foundedness ordering:
types in our model should be stratified so that a type at level k relies not on the
entire store typing, but only on that subset of the store typing that maps locations

43

to types at level j for j < k. This leads us to the following Type hierarchy:

Type0 = Unit
StoreTypek = Loc fin! Typek
Typek+1 = StoreTypek * Val ! o

By stratifying types we have eliminated the circularity. The types and store typings
in our desired definition of ref o/ may now be annotated with levels to reflect the
existence of a type hierarchy. The type ref o/ at level k in the hierarchy (ref o/ 2 Typek)
may be defined as a predicate on a store typing \Psi  2 StoreTypek-1 and a value v as
shown below. In the interest of brevity, I shall write o/ k and \Psi k in place of "o/ such
that o/ 2 Typek" and "\Psi  such that \Psi  2 StoreTypek" respectively. Type levels and
store typing levels should always be assumed to be nonnegative integers.

(ref o/ )k is something like= {\Omega \Psi k-1; ` ff | \Psi k-1(`) = o/ k-1}
We still have to show that for each *M type o/ there exists some k >= 0 such that
o/ 2 Typek. In the next section I shall try to specify a method for stratifying the
full set of *M types so that it fits into the type hierarchy shown above.

3.2.5 Stratifying Types Based on Syntax
From the hypothetical definition of ref o/ above, we concluded that o/ is a "smaller"
(i.e., less complex) type than ref o/ -- informally, o/ has fewer nested occurrences of
ref than ref o/ . In terms of our type hierarchy then, ref o/ is a level k type if and
only if o/ is a level j type where j < k. But what does it mean for a type o/ to
belong to some level k in the type hierarchy? Informally, it means that at level k
we have sufficient "information" to conclude whether or not a value v has type o/ .
This information comes in the form of a store typing \Psi k-1 -- that is, a store typing
that tells us the permissible update types of only those locations that map to types
at levels k - 1 and below. The notion of having sufficient information at some level
suggests that for each (non-empty) type o/ there exists a finite level kmin such that
o/ 2 Typekmin and o/ =2 Typej where 0 <= j < kmin .

Suppose for the moment that the only types in our language are the empty type
?, the primitive types (say unit and bool) and mutable references ref. Then, to
determine whether a type o/ belongs to Typek for some k >= 0 we use the following
set of rules.

* o/ = ? =) o/ 2 Type0 (where ? is the empty type)

* o/ is a primitive type (i.e., unit or bool) =) o/ 2 Type1

* o/ 2 Typek =) ref o/ 2 Typek+1

44

^^^^

bool
0

1

ref (unit)

2
ref (ref (bool)) 3

4

unit

ref (bool)

ref (ref (unit))

ref (ref (ref (bool)))

ref (ref (ref (unit)))

Figure 3.4: Type Hierarchy Based on Syntax of Types

* o/ 2 Typek =) o/ 2 Typek+1
The last of the above rules deserves some further explanation. Informally, the last
rule stems from the fact that a type at some level k has more "information" than a
type at some level j < k -- the former is a predicate on \Psi k-1 whereas the latter is
a predicate on \Psi j-1 and \Psi j-1 ` \Psi k-1 since j < k. Therefore, if we have sufficient
information at level k to conclude that v has type o/ , then at level k + 1 we still have
sufficient information to conclude that v has type o/ .

Figure 3.4 illustrates the first few levels of the hierarchy for the types ?, unit,
bool, and ref. Level 0 contains only the empty type ?. Level 1 consists of the
primitive types unit and bool, as well as all the level 0 types. Level 2 consists of
the types ref unit, ref bool, and all of the level 1 types. In general, for all types
o/ in level k, level k + 1 consists of all types ref o/ , as well as the level k types o/ .
Hence, the third level in our type hierarchy contains types such as ref(ref(bool)) but
not ref(ref(ref(bool))). For any (finite) type expression there is some level in the
hierarchy powerful enough to contain it. Since the type expressions in a well-typed
monomorphic program are finite, we can find some level of the hierarchy strong
enough to type each program.

The Level of a Quantified Type Suppose we now add quantified types to the
language. Consider, for example, the type 9ff:ref ff. How do we determine if 9ff:ref ff
belongs to some level k in the type hierarchy? If we know that ff belongs to Typek

45

then we can conclude that ref ff belongs to Typek+1 and 9ff:ref ff belongs to Typek+1
(and the type ref(9ff:ref ff) belongs to Typek+2 and so on). But ff is a type variable,
so we cannot predict how complex the type that instantiates ff will be. For instance,
suppose we pick k to be 43; now if ff is instantiated with o/ = ref50(bool), then the
43rd level of the hierarchy won't contain o/ -- only the 51st level (and above) will.
Furthermore, we wish to model impredicative quantified types, which means that
ff -- which we assumed to be a level k type -- may be instantiated with 9ff:ref ff,
which we just concluded is a level k + 1 type -- but this implies that ff should be a
level k + 1 type. Hence, there is no finite level of the hierarchy that is guaranteed
to be powerful enough to contain 9ff:ref ff.

Imagine, for a moment, that we do know of a finite level k of the hierarchy that
is guaranteed to contain a type such as 9ff:ref ff or 8ff:(ref ff) ! ff. Hence, we
know that level k of the hierarchy must contain any type o/ that instantiates ff. But
this violates the essence of impredicative quantified types. In the existential case,
knowing that the witness type o/ is contained in level k of the hierarchy violates
the abstraction guaranteed by an existential type -- some information about the
hidden type is revealed. In the case of universal types, knowing that level k of the
hierararchy must contain any o/ that instantiates ff leaves us with a form of bounded
(rather than impredicative) polymorphism.

In earlier work [AAV02] we relied on the syntactic complexity of a type o/ in order
to determine a level of the type hierarchy that is guaranteed to contain o/ . As I have
just explained, this approach cannot accommodate references to quantified types
since we cannot know the level of a type variable. However, this does not mean
that we should abandon the idea of a type hierarchy -- what we need is a different
(non-syntactic) rationale for stratifying the set of types. In the next section, I will
explain an alternate interpretation of type levels that makes it possible to stratify
the set of *M types.

3.2.6 Stratifying Types Based on Semantic Approximation
Instead of requiring that levels in the type hierarchy correspond to the syntactic
complexity of type expressions, we shall treat levels as an indication of how many
more steps the program can safely execute. Informally, we want \Omega \Psi k-1; vff 2 o/ k to
mean that v "looks" like it belongs to type o/ for k steps -- perhaps v is not "really"
a member of type o/ , but any program of type o/ ! o/ 0 must execute for at least k
steps on v before getting to a stuck state. The statement \Omega \Psi k-1; vff 2 o/ k may also
be read as "the assumption that v has type o/ with respect to \Psi  cannot be proved
wrong within k steps of execution". Hence, levels in the type hierarchy correspond
to approximations of a type's behavior.

I call k the approximation index following Appel and McAllester's indexed model
of types [AM01]. The latter gave a semantics of recursive types for the purely

46

functional *-calculus, specifically, a semantics of covariant as well as contravariant
equirecursive types. In the indexed model, we say a value v has type o/ to approximation k if, in any computation running for no more than k steps, the value v
behaves as if it were an element of the type o/ . I wish to make use of this intuition
to stratify types in our model of mutable references.

Recall that the original observation that led us to a type hierarchy (see Section 3.2.4) was that o/ is a "smaller" type than ref o/ and that to determine the
members of the set ref o/ we need only consider those locations in the store typing
whose permissible update types are "smaller" than ref o/ . Suppose that location `
contains a value v. The assumption that ` has type ref o/ cannot be proved wrong
within k steps of execution if and only if the assumption that v has type o/ cannot
be proved wrong within k - 1 steps since the former requires an extra dereferencing step. Hence, in terms of the number of steps that can be safely executed, o/ is
"smaller" type than ref o/ . To determine the members of ref o/ to approximation k
we only need a store typing that tells us each store location's permissible update
type to approximation k - 1.

Consider, for instance, the type ref(ref(bool)). Figure 3.5(a) illustrates the stratification of ref(ref(bool)), assuming that the only types in the language are unit, bool,
and ref. Note that every type that appears in the figure denotes a set of pairs of
store typings and values. (In the figure, types of the form ref *(o/ ) denote zero or
more applications of ref to o/ .) Level 0 contains all the types in the language because
at level 0 (i.e., if we intend to run the program for 0 more steps) a value v of any
type behaves as if it belongs to ref(ref (bool)). Intuitively, the assumption that v
has type ref (ref(bool)) cannot be proved wrong in zero steps.

Level 1 contains a subset of the level 0 types, specifically, all types of the form
ref o/ , where o/ is any type. At level 1, a value v of any type of the form ref o/
behaves as if it belongs to ref(ref(bool)). Intuitively, a program that executes just
one step can dereference v without getting stuck (since v has type ref o/ ). Hence,
the assumption that v has type ref(ref(bool)) cannot be proved wrong in one step.

Level 2 contains a subset of the level 1 types, specifically, all types of the form
ref(ref(o/ )) (for any o/ ). At level 2, a value v of any type ref(ref o/ ) "looks" like a value
of type ref(ref(bool)). Intuitively, given v the program can perform two dereferences
without getting stuck, so the assumption that v has type ref(ref(bool)) cannot be
proved wrong in two steps.

Finally, level 3 contains only one type, namely ref(ref (bool)). At level 3 and
above (i.e., in the limit) the only values that behave as if they belong to ref(ref(bool))
are the ones that actually do. Intuitively, a program that executes for three or more
steps can tell precisely whether or not a value v has the type ref(ref(bool)). For
comparison, Figure 3.5(b) illustrates the stratification of type ref(bool).

The levels of the hierarchy provide approximations of a type o/ -- every value
that behaves as if it belongs to o/ for k steps of execution is contained in the kth

47

ref (ref (bool))

e^

4

3

ref (ref(ref*(bool)) 2

1

ref (ref (unit))

ref (bool)
ref (ref(ref*(unit))

0

unit
bool

ref (unit)

(a) Approximations of type ref(ref(bool))

ref (bool)

e^

4

3

2

1

ref (unit)

0

unit
bool
ref(ref*(bool)

ref(ref*(unit)

(b) Approximations of type ref(bool)
Figure 3.5: Type Hierarchy Based on Semantic Approximation
approximation of the type. Level 0 provides the least precise approximation of a
type; any type o/ to approximation 0 is equivalent to ?. The precision increases with
the level, that is, with the number of steps the program may execute. Accordingly, in
Figures 3.5(a) and 3.5(b), as we go from outside to inside (i.e., as the levels increase),

48

the number of types contained in each circle decrease. Hence, o/ 2 Typek+1 implies
o/ 2 Typek -- informally, if the assumption that v has type o/ cannot be proved
wrong within k steps, then it cannot be proved wrong within j < k steps. As a
result, the hierarchy in Figure 3.5 is "inside-out" as compared to the syntax-based
type hierarchy in Figure 3.4.

The Level of a Quantified Type The approximation power of the indexed
model helps us model mutable references to quantified types by allowing us to "pick
a level" for a type variable while ensuring safety and abstraction. Suppose in some
execution we are about to instantiate ff in 9ff:ref ff with ref50(bool), but we intend
to run the program for only 30 more steps. Then it's all the same whether we
instantiate ff with ref50(bool) or ref30(?), since in 30 execution steps the program
cannot dereference more than 30 references. Therefore, if we intend to run the
program for only k steps, it suffices to use the kth level of the hierarchy.

The next section more rigorously describes the ideas introduced in this section
and formalizes an indexed model of impredicative polymorphism and mutable references.

3.3 An Indexed Possible-Worlds Model
In this section I will describe how to construct a model of general references by
adapting the ideas underlying Appel and McAllester's indexed model to a setting
with mutable state.

A rough outline of the section is as follows. I start by giving a definition of
safety suited to the indexed model. I then show how to model the hierarchy of
types as a set and explain what properties these type sets must possess. Next,
I present the semantics of various types in *M , followed by the semantics of *M
judgments and the typing rules for the language. Finally, I explain how our model
is a possible-worlds model.

3.3.1 Safety
A state (S ; e) is irreducible if it has no successor in the step relation, that is,
irred(S ; e) if e is a value or (S ; e) is a "stuck" state such as (S ; unit(e0)) or (S ; ` := v)
where ` =2 dom(S ). I say that a machine state (S ; e) is safe for k steps if it takes at
least k steps for it to reach a "stuck" state. Note that any state is safe for 0 steps.
A state (S ; e) is safe if execution starting with (S ; e) does not reach a stuck state
in any number of steps.

49

Definition 3.1 (Safe)
A state (S ; e) is safe for k steps if for any reduction (S ; e) 7-!jM (S 0; e0) of j < k
steps, either e0 is a value or another step is possible.

safen(k; S ; e) def= 8j; S 0; e0: (j < k ^ (S ; e) 7-!jM (S 0; e0))

=) (val(e0) . 9S 00; e00: (S 0; e0) 7-!M (S 00; e00))

A state (S ; e) is called safe if it is safe for all k >= 0 steps.

safe(S ; e) def= 8k >= 0: safen(k; S ; e)
To show that a program e is safe to execute given an initial store S (i.e.,
safe(S ; e)), we have to prove that the initial machine state is safe for all k >= 0
steps (i.e., safen(k; S ; e) for all k >= 0). To this end, I will first specify the semantics of *M types and type judgments; I will then prove, based on these definitions,
that typability implies safety -- that is, if a type judgment is true, then the typed
program is safe; and finally, I will prove that the *M typing rules are sound.

3.3.2 Modeling Stratified Types as Sets
I am interested in modeling types as sets of tuples, but as explained in Section 3.2.3
a type cannot simply be a set of tuples of the form h\Psi ; vi since that leads to
an inconsistent model. The inconsistency can be eliminated by stratifying types,
which results in a type hierarchy as discussed in Section 3.2.4. I shall incorporate
the notion of a type hierarchy into our semantics as follows. First, I model types as
sets of tuples hk; \Psi ; vi, where k (the approximation index ) is a nonnegative integer,
\Psi  is a mapping from locations to types (that is, a mapping from locations to sets
of tuples of the form hk; \Psi ; vi), and v is a value -- we say that v has type o/ to
approximation k with respect to store typing \Psi . The intuitive idea is that in any
computation running for no more than k steps, the value v behaves as if it were an
element of the type o/ .

Next, I define the notion of a k-approximation of a type (which corresponds to
the kth level of the type in the hierarchy), and extend the notion pointwise to store
typings.

Definition 3.2 (Approx)
The k-approximation of a set is the subset of its elements whose index is less than
k; I also extend this notion pointwise to store typings:

bo/ ck def= {hj; \Psi ; vi | j < k ^ hj; \Psi ; vi 2 o/ }
b\Psi ck def= {(` 7! bo/ ck) | \Psi (`) = o/ }

50

Finally, since a na"ive construction of types as collections of tuples hk; \Psi ; vi
(where \Psi  is a relation on locations and types) can lead to paradoxes, I construct a
stratified semantics by requiring that all type definitions obey the following invariant: for all k >= 0, the definition of the (k + 1)-approximation of a type o/ cannot
consider any type beyond approximation k. I shall refer to this as the stratification
invariant. To comply with this invariant, when considering a tuple hk; \Psi ; vi, I do
not require \Psi  to be defined beyond b\Psi ck. Intuitively, if we intend to run the program for no more than k more steps, then typechecking with ` 7! bo/ ck is just as
safe as typechecking with ` 7! o/ .

Consider, for instance, the semantics of mutable reference types ref o/ . The
hypothetical definition of ref o/ from Section 3.2.4 (shown with level annotations) is
as follows.

(ref o/ )k is something like= {\Omega \Psi k-1; ` ff | \Psi k-1(`) = o/ k-1}
The actual definition of ref o/ is shown below. I say that a location ` has type ref o/
for k steps with respect to store typing \Psi  (written hk; \Psi ; ` i 2 ref o/ ) if ` will contain
a value of type o/ for at least k - 1 steps -- that is, if the store typing \Psi  says that
` may only be updated with values that "behave" like values of type o/ for at least
k - 1 steps. Hence, I define ref o/ so that it does not rely on \Psi  and o/ beyond b\Psi ck
and bo/ ck, respectively.

ref o/ def= {hk; \Psi ; ` i | b\Psi ck(`) = bo/ ck}
As I will show, all our definitions obey the stratification invariant and hence, our
types do indeed form a set, which can be constructed using recursively defined sets
Typek and StoreTypek as follows.

o/ 2 Type0 iff o/ = {}
o/ 2 Typek+1 iff 8 hj; \Psi ; vi 2 o/: j <= k ^ \Psi  2 StoreTypej

\Psi  2 StoreTypek iff 8` 2 dom(\Psi ): \Psi (`) 2 Typek

o/ 2 Type iff 8k: bo/ ck 2 Typek
\Psi  2 StoreType iff 8k: b\Psi ck 2 StoreTypek

3.3.3 Properties of Types
As we can see from the definition above, for o/ to be a type (written o/ 2 Type),
given hk; \Psi ; vi 2 o/ and a location ` 2 dom(\Psi ) such that \Psi (`) = o/ 0, it must be the
case that every element hk0; \Psi 0; v0i 2 o/ 0 has k0 < k. This, however, is not the only
property that a type set o/ must satisfy; there are other ways in which o/ must be
well-behaved as I shall illustrate through an example. Consider the program given

51

below which allocates and initializes a cell, executes several instructions (elided),
then dereferences the original cell before executing the rest of the program erest .

The comments that follow each line of the program describe aspects of the state
immediately after that line has been evaluated. Aspects of the computation state
that we must consider when reasoning about mutable references include not just
the current store S but also the current store typing \Psi , and the number of future
steps k that the program can safely take. In a state with store S , store typing \Psi ,
and k steps left to execute, I shall assume:

1. that dom(\Psi ) contains all the locations that the rest of the program might

access (except for those not yet allocated); and

2. that S satisfies \Psi  for k steps.4 I shall formalize this notion shortly (see

Definition 3.5), but roughly, S satisfies \Psi  for k steps -- or equivalently, S
is well-typed to approximation k with respect to \Psi  -- if, for each location
` 2 dom(\Psi ), ` 2 dom(S ) and S (`) has type \Psi (`) to approximation k.

Later, I shall describe how each of these assumptions is formally built into our model
(see Definitions 3.7 and 3.6 for assumptions (1) and (2), respectively).

% S0 = \Psi 0 = {}
let x1 = new(true) in % S1 = S0 [`1 7! true]; \Psi 1 = b\Psi 0c10 [`1 7! bboolc10];

% x1 7! `1; 10 more steps
let x2 = : : : in % S2 = : : : ; \Psi 2 = : : : ; x1 7! `1.

..

let xn = : : : in % Sn = : : : ; \Psi n = : : : ; x1 7! `1; 6 more steps
let y = ! x1 in % Sn+1 = : : : ; \Psi n+1 = : : :
erest

Suppose that we execute the above program with an initial empty store S0. Since
there are no allocated locations, the domain of the initial store typing \Psi 0 is empty.
By the *M operational semantics, after evaluating the first line of the program we
have store S1 = S0 [`1 7! true] for some location `1 =2 dom(S0) and x1 is bound
to `1. Suppose, at this point, that the program must execute 10 more steps. This
means that we only need to know the types that the contents of allocated locations
must have for another 9 steps (since an update or dereference would use up one
step). Hence, the store typing \Psi 1 = b\Psi 0c10 [`1 7! bboolc10] describes the "state" of
the store S1 with enough precision for us to be able to conclude that location `1 has
type ref bool for 10 steps -- that is, to conclude that h10; \Psi 1; `1i 2 ref bool according
to the semantics of ref above.

4The notion that S should satisfy \Psi  was briefly discussed in Section 3.2.2.

52

Next, we evaluate the elided terms; suppose that these include one or more
new and assignment expressions, and suppose that the net effect of these terms
is to transform the store from S1 to Sn. Just before we evaluate the expression
dereferencing x1, we have x1 bound to `1, store Sn, and 6 more steps to execute. At
this point, from a semantic perspective, it is safe to dereference `1 given store Sn as
long as:

1. `1 is an allocated location, i.e., `1 2 dom(Sn)
2. Sn(`1) looks like it belongs to type bool for 5 more steps
Together these two conditions imply that we need to prove that the store typing
\Psi n, which captures the "state" of the store Sn with 6 more steps to execute, maps
`1 to bboolc6. Equivalently, we need to prove h6; \Psi n; `1i 2 ref bool in order to show
that the instruction ! x1 is safe to execute.

We already know that h10; \Psi 1; `1i 2 ref bool, but we need to account for the
fact that \Psi n is different from \Psi 1. This difference is related to the fact that Sn is
different from S1 due to the allocation of new cells or the update of existing cells.
An examination of the *M operational semantics suggests that condition (1) must
hold since there are no terms in *M that shrink the store -- hence dom(Sn) must
be a superset of dom(S1). Since the store does not shrink, the store typing should
not shrink -- hence, dom(\Psi n) must be a superset of dom(\Psi 1).

The reason why condition (2) must hold is not as straightforward. Since assignment expressions in *M update allocated locations, Sn(`1) may not be equal to
S1(`1). But *M permits only type-preserving updates and this is where the store
typings come in. Intuitively, if \Psi 1 says that `1 has type o/ then \Psi n should also
say that `1 has type o/ . To be precise, though, we must take the number of future
execution steps into account as follows. If \Psi 1 says that some location `1 will have
type o/ for 10 steps, and we then execute 4 of those 10 steps to get to the state
described by \Psi n, then \Psi n should say that `1 will have type o/ for 6 steps.

The above notion of approximately type-preserving updates may be formalized
as follows. For any two machine states (S ; e) and (S 0; e0), and store typings \Psi 
and \Psi 0 such that S satisfies \Psi  for k steps and S 0 satisfies \Psi 0 for j <= k steps,
if (S ; e) 7-!k-jM (S 0; e0), then the relationship between \Psi  and \Psi 0 is specified by
(k; \Psi ) v (j; \Psi 0). I call v the extend-state relation.

Definition 3.3 (State Extension)
A valid state extension is defined as follows:

(k; \Psi ) v (j; \Psi 0) def= j <= k ^ (8` 2 dom(\Psi ): b\Psi 0cj(`) = b\Psi cj(`))
State extension specifies how a store typing may change during zero or more
computation steps. Computation steps might allocate new reference cells, in which

53

case dom(\Psi 0) will be a strict superset of dom(\Psi ). The computation might choose
to forget some information, in which case j will be strictly less than k and \Psi 0 will
be less precise (have a lower approximation level) than \Psi . This means, however,
that the program may now run for at most j more steps rather than k more steps.
Finally, the computation might update an allocated location ` with a new value
v. Since updates must be approximately type-preserving, if we have j steps left to
execute then, since the update itself takes up one step, v must have type \Psi (`) to
approximation j -- therefore, b\Psi 0cj(`) = b\Psi cj(`).

The concept of a valid state extension (k; \Psi ) v (j; \Psi 0) is useful for restricting
attention to only those store typings that are possible in the future given the operational semantics of *M . Returning to the above example, given h10; \Psi 1; `1i 2 ref bool
and (10; \Psi 1) v (6; \Psi n), we can show that h6; \Psi n; `1i 2 ref bool. In general, I want
all of the types in our language to have this property exhibited by ref bool, that is,
I want type sets in *M to be closed under valid state extension.

Definition 3.4 (Type)
A type is a set o/ of tuples of the form hk; \Psi ; vi where v is a value, k is a nonnegative
integer, and \Psi  is a store typing, and where the set o/ is closed under state extension;
that is,

type(o/ ) def= 8k; j; \Psi ; \Psi 0; v:

(hk; \Psi ; vi 2 o/ ^ (k; \Psi ) v (j; \Psi 0)) =) hj; \Psi 0; vi 2 o/

I have shown that the absence of cell deallocation in *M together with the
requirement that updates be approximately type-preserving (captured by the definition of v) are crucial for proving that ref types are preserved under evaluation.
Now let us consider each of the remaining types in *M .

3.3.4 Base Types
A value v has type unit if and only if v = unit. Though types are predicates on
approximation indices k and store typings \Psi  as well as values, the approximation
index and store typing are irrelevant when determining if a value v has type unit --
the same is true for other base types such as bool, int, char, and so on. It trivially
follows that unit is closed under state extension.

unit def= {hk; \Psi ; uniti}

3.3.5 Function Types
When deciding if a value *x:e has type o/1 ! o/2 for k steps (i.e., to approximation k)
with respect to store typing \Psi  we have to keep in mind that the program may not

54

utilize (apply) *x:e until some point in the future, a point when the store typing
may be different from \Psi  thanks to the evaluation of new terms in the interim. Also,
we must account for the number of execution steps we use up to get to that future
point. Hence, for *x:e in o/1 ! o/2 to be safe for k steps, since beta-reduction uses up
one step, the resulting (beta-reduced) expression must be safe for some j < k steps.
Let \Psi 0 be the future store typing to approximation j. Since *M does not allow cell
deallocation and requires approximately type-preserving updates, clearly it should
be the case that (k; \Psi ) v (j; \Psi 0).

Next, let S 0 be a store that satisfies \Psi 0 for j steps (i.e., S 0 is well-typed to
approximation j with respect to \Psi 0). Let v be a value that has type o/1 for j steps
with respect to \Psi 0. If evaluating the expression e[v=x] with store S 0 gives us a value
of type o/2 in less than j steps (along with a store that satisfies some store typing
that is a valid extension of \Psi 0) then we may conclude that *x:e has type o/1 ! o/2
for k steps with respect to \Psi . The formal definition makes this clearer, but before
I can formally define o/1 ! o/2, I need two auxiliary definitions.

First, I formally state what it means for store S to satisfy store typing \Psi  for k
steps (i.e., for S to be well-typed to approximation k with respect to \Psi ).

Definition 3.5 (Well-typed Store)
A store S is well-typed to approximation k with respect to a store typing \Psi  iff
dom(\Psi ) ` dom(S ) and the contents of each location ` 2 dom(\Psi ) has type \Psi (`) to
approximation k:

S :k \Psi  def= dom(\Psi ) ` dom(S ) ^

8j < k: 8` 2 dom(\Psi ): hj; b\Psi cj; S (`)i 2 b\Psi ck(`)

There are two things about the above definition that deserve comment. First, it
is important to note that all the tuples required to be in \Psi (`) have index strictly
less than k; this helps avoid circularity. Second, note that store S is allowed to
have "extra" allocated locations that are not typed by \Psi . We do not need to know
the types of these "extra" locations because, as we shall see, whenever our model
makes use of S :k \Psi  we already know that dom(\Psi ) contains all the locations that
the rest of the program may access, except for those not yet allocated.5 Hence, the
requirement that dom(\Psi ) ` dom(S ) is sufficient for our purposes. The requirement
dom(\Psi ) = dom(S ), though not incorrect, would have been overly restrictive.

Next, I specify what it means for a closed expression e to have type o/ for k
steps with respect to store typing \Psi  (written e :k;\Psi  o/ ). Intuitively, e :k;\Psi  o/ says
that in a state (S ; e) such that S :k \Psi , term e behaves like an element of o/ for k
steps of computation. If (S ; e) reaches a state (S 0; v) (i.e., if e evaluates to a value

5We "already know" that dom(\Psi ) contains all "relevant" allocated locations thanks to the
semantics of judgments -- see Definition 3.7.

55

v) in less than k steps, then it must be the case that v has type o/ and S 0 must be
a store that is well-typed with respect to a valid extension of \Psi . Otherwise, (S ; e)
can take k steps without getting stuck -- that is, there exist S 0 and e0 such that
(S ; e) 7-!kM (S 0; e0).

Definition 3.6 (Expr : Type)
For any closed expression e and type o/ , e :k;\Psi  o/ if whenever S :k \Psi , (S ; e) 7-!jM
(S 0; e0) for j < k, and (S 0; e0) is irreducible, then there exists a store typing \Psi 0 such
that (k; \Psi ) v (k - j; \Psi 0), S 0 :k-j \Psi 0, and hk - j; \Psi 0; e0i 2 o/ ; that is,

e :k;\Psi  o/ def= 8j; S ; S 0; e0: (0 <= j < k ^ S :k \Psi 

^ (S ; e) 7-!jM (S 0; e0) ^ irred(S 0; e0))
=) 9\Psi 0: (k; \Psi ) v (k - j; \Psi 0)

^ S 0 :k-j \Psi 0 ^ hk - j; \Psi 0; e0i 2 o/

Note that if e :k;\Psi  o/ and 0 <= j <= k then e :j;b\Psi cj o/ . This is because o/ is closed
under valid state extension and (k; \Psi ) v (j; b\Psi cj) is a valid state extension (one
that "forgets" some information, or retains information in a less precise form). Also
note that, if v is a value and k > 0, the statements v :k;\Psi  o/ and hk; \Psi ; vi 2 o/ are
equivalent.

The semantics of function types can now be defined as follows.

o/1 ! o/2 def= {hk; \Psi ; *x:ei | 8v; \Psi 0; j < k:

((k; \Psi ) v (j; \Psi 0) ^ hj; \Psi 0; vi 2 o/1)

=) e[v=x] :j;\Psi 0 o/2 }

In order to prove that function types are closed under state extension we will first
need to show that valid state extension (v) is transitive (see Lemma 3.13). State
extension specifies that the approximation index can either decrease or remain the
same, that allocated cells cannot be freed, and that the designated type of each location can only become less precise (which means that the type set becomes larger).
Hence, v relates monotonically decreasing approximation indices and monotonically
increasing store typings, so it is easy to show that v is transitive.

3.3.6 Quantified Types
For simplicity of presentation, I avoid the use of type variables in the representation
of quantified types. Specifically, instead of writing 8ff:o/ and 9ff:o/ where ff is the
only type variable that occurs free in the type expression o/ , I write 8F and 9F
where F is a closed function from types to types (also called a type functional).
The two representations are equivalent in terms of expressive power, but they lead
to different *M type judgments. To accommodate quantified types of the form

56

8ff:o/ and 9ff:o/ , a language needs type-checking rules that explicitly manage a set
of type variables. This means that *M type judgments would have to have the
form \Delta ; \Gamma  |=M e : o/ where \Delta  is the set of type variables that may appear in o/ . By
comparison, for quantified types of the form 8F and 9F , it would suffice to have *M
type judgments of the form \Gamma  |=M e : o/ (as I shall describe in Section 3.3.7). Hence,
though avoiding the use of type variables makes the representation of quantified
types (as well as the type-checking rules for quantified types -- see Figure 3.7)
slightly unconventional, it nonetheless leads to a simpler semantics of *M -- that
is, a semantics not cluttered by the bookkeeping of type variables.6

The use of closed type functionals F in the representation of quantified types
-- rather than type functionals F with free type variables -- limits the set of types
that we are able to express. I shall discuss this limitation and how to get around it
in Section 4.4.1.

Universal Types When deciding if a value \Lambda :e has type 8F for k steps (i.e., to
approximation k) with respect to a store typing \Psi , we have to keep in mind that
\Lambda :e may not be instantiated with a type until some point in the future. Let \Psi 0 be
the store typing at that future point, and let j <= k be the number of execution
steps left -- that is, we use up k - j steps to get to that future point. As discussed
in Section 3.3.5 (for function types), it must be the case that (k; \Psi ) v (j; \Psi 0).

If \Lambda :e is instantiated with the type o/ , we must make sure that o/ is a valid type.
But since we have j steps left to execute and type instantiation uses up one step,
we only need to ensure that o/ is a valid type for j - 1 steps, that is, type(bo/ cj).
Hence, if we have o/ such that type(bo/ cj), and e has type F (o/ ) for all i < j steps
with respect to store typing b\Psi 0ci, then we may conclude that \Lambda :e has type 8F for
k steps with respect to \Psi . Note that it suffices to check that o/ is a valid type to
approximation j since we only check that e has type F (o/ ) to approximation i < j.7
The semantics of 8F can be defined as follows.

8F def= {hk; \Psi ; \Lambda :ei | 8j; \Psi 0; o/: ((k; \Psi ) v (j; \Psi 0) ^ type(bo/ cj))

=) 8i < j: e :i;b\Psi 0ci F (o/ )}

It is important to note that above definition satisfies the stratification invariant
discussed in Section 3.3.2, which helps avoid circularity. To determine whether the
tuple hk; \Psi ; \Lambda :ei belongs to 8F , first, we do not require \Psi  to be defined beyond
b\Psi ck, and second, we only require type(bo/ cj) (where j <= k) rather than type(o/ ).

6Though I do not describe it here, it should be possible to support the use of type variables in
the representation of types by modifying the model I shall present so that it defines a semantics
of type-checking judgments \Delta ; \Gamma  |=M e : o/ rather than \Gamma  |=M e : o/ .

7To be precise, the truth of this statement is contingent upon F having a property that I have

not discussed yet, namely upon F being nonexpansive. I shall explain what it means for a type
functional to be nonexpansive in Section 3.3.9.

57

Hence, to define the (k + 1)-approximation of 8F , we do not consider any type
beyond approximation k as required by the stratification invariant.

The proof that universal types are closed under state extension relies on the
transitivity of state extension (see Lemma 3.16 in Section 3.4).

Existential Types To determine whether a value pack v has type 9F for k steps
with respect to store typing \Psi , we must make sure that two conditions are satisfied.
First, we must check that the witness type o/ is a valid type; since unpacking the
existential uses up one step, we only have to ensure that o/ is a valid type for k - 1
steps, that is, type(bo/ ck). Second, we must make sure that v has type F (o/ ) for all
j < k steps (since unpacking uses up one step) with respect to store typing b\Psi cj.
It suffices to check that o/ is a valid type to approximation k since we only check
that v has type F (o/ ) to approximation j < k.8 The semantics of 9F is as follows.

9F def= {hk; \Psi ; pack vi | 9o/: (type(bo/ ck) ^ 8j < k: hj; b\Psi cj; vi 2 F (o/ ))}
To decide whether hk; \Psi ; pack vi belongs to 9F , we do not require \Psi  to be defined
beyond b\Psi ck. Also, as in the definition of 8F above, we only require type(bo/ ck)
rather than type(o/ ). Hence, the definition of 9F adheres to the stratification invariant, helping us avoid circularity.

The *M type definitions developed thus far are collected in Figure 3.6 (along
with the definition of ?, the empty type). Proofs that these types are closed under
state extension are given in Section 3.4.

3.3.7 Judgments, Typing Rules, and Safety
Up to now I have only dealt with closed terms, as these are the ones that "step"
at run time. Now I turn to terms with free variables, upon which the static typechecking rules must operate. Type judgments in *M have the form \Gamma  |=M e : o/ where
\Gamma  is a type environment, that is, a mapping from term variables to types. A value
environment oe (also called a ground substitution) is a mapping from term variables
to values.

Definition 3.7 (Semantics of Judgment)
For any type environment \Gamma  and value environment oe I write oe :k;\Psi  \Gamma  (read "oe
approximately obeys \Gamma ") if for all variables x 2 dom(\Gamma ) we have oe(x) :k;\Psi  \Gamma (x); that
is,

oe :k;\Psi  \Gamma  def= 8x 2 dom(\Gamma ): oe(x) :k;\Psi  \Gamma (x)

8To be precise, this statement holds only if F is nonexpansive (see Section 3.3.9).

58

? def= {}
unit def= {hk; \Psi ; uniti}
o/1 ! o/2 def= {hk; \Psi ; *x:ei | 8v; \Psi 0; j < k: ((k; \Psi ) v (j; \Psi 0) ^ hj; \Psi 0; vi 2 o/1)

=) e[v=x] :j;\Psi 0 o/2}

ref o/ def= {hk; \Psi ; ` i | b\Psi ck(`) = bo/ ck}
8F def= {hk; \Psi ; \Lambda :ei | 8j; \Psi 0; o/: ((k; \Psi ) v (j; \Psi 0) ^ type(bo/ cj))

=) 8i < j: e :i;b\Psi 0ci F (o/ )}

9F def= {hk; \Psi ; pack vi | 9o/: (type(bo/ ck) ^ 8j < k: hj; b\Psi cj; vi 2 F (o/ ))}

Figure 3.6: Mutable References (*M ): Type Definitions
I write \Gamma  |= kM e : o/ iff F V (e) ` dom(\Gamma ) and

8oe; \Psi : oe :k;\Psi  \Gamma  =) oe(e) :k;\Psi  o/
where oe(e) is the result of replacing the free variables in e with their values under oe.

I write \Gamma  |=M e : o/ if for all k >= 0 we have \Gamma  |= kM e : o/ . Finally, I write |=M e : o/
to mean \Gamma 0 |=M e : o/ for the empty context \Gamma 0.

Hence, the meaning of the judgment \Gamma  |= kM e : o/ on an open expression e and type
o/ can be obtained from our semantics of a similar judgment on closed expressions,
so long as we quantify over all legitimate substitutions of values for variables. Note
that \Gamma  |=M e : o/ can be viewed as a three place relation that holds on the context \Gamma ,
the term e, and the type o/ .

The typing rules for *M are given in Figure 3.7. As before, I write \Gamma  [x 7! o/ ] to
denote the type environment that extends \Gamma  by mapping x to o/ where x =2 dom(\Gamma ). I
shall prove each of the type-checking rules in Figure 3.7 as lemmas (see Section 3.5).
These lemmas can then be used in the same manner as standard typing rules to
prove statements of the form \Gamma  |=M e : o/ .

A "program" in *M is a closed expression that does not contain any location
symbols `. When a program begins executing, it steps (by means of new) to expressions that may contain location symbols. A conventional subject-reduction proof
requires that the static type system be able to type-check programs during execution, which means that there must be a way to type-check locations `. However, our
judgment \Gamma  |=M e : o/ has no provision to type-check locations (for instance, there is
no store typing \Psi  to the left of the |=M symbol). Since we are not doing subject

59

\Gamma  |=M x : \Gamma (x) (M-var) \Gamma  |=M unit : unit (M-unit)

\Gamma  [x 7! o/1] |=M e : o/2
\Gamma  |=M *x:e : o/1 ! o/2 (M-abs)

\Gamma  |=M e1 : o/1 ! o/2 \Gamma  |=M e2 : o/1

\Gamma  |=M (e1 e2) : o/2 (M-app)

\Gamma  |=M e : o/
\Gamma  |=M new(e) : ref o/ (M-new)

\Gamma  |=M e : ref o/

\Gamma  |=M ! e : o/ (M-deref)

\Gamma  |=M e1 : ref o/ \Gamma  |=M e2 : o/

\Gamma  |=M e1 := e2 : unit (M-assign)

8o/: type(o/ ) =) \Gamma  |=M e : F (o/ )

\Gamma  |=M \Lambda :e : 8F (M-tabs)

type(o/ ) \Gamma  |=M e : 8F

\Gamma  |=M e[ ] : F (o/ ) (M-tapp)

type(o/ ) \Gamma  |=M e : F (o/ )

\Gamma  |=M pack e : 9F (M-pack)

\Gamma  |=M e1 : 9F 8o/: type(o/ ) =) \Gamma  [x 7! F (o/ )] |=M e2 : o/2

\Gamma  |=M unpack e1 as x in e2 : o/2 (M-unpack)

Figure 3.7: Mutable References (*M ): Type-checking Lemmas
reduction, we do not need to type-check executing programs -- hence, we do not
need to type-check location symbols.

I wish to prove that a *M program is safe to execute given an initial store S .
There are no additional constraints on S . In fact, S might as well be the empty store
because a program e -- since it has no free variables or location symbols -- cannot
access any locations in S . Hence, I would like to prove that given an arbitrary store
S and a well-typed program e, machine state (S ; e) is safe.

Theorem 3.8 (Safety)
If |=M e : o/ , o/ is a type, and S is a store, then (S ; e) is safe.

60

Proof: To prove safe(S ; e) we must show that for any k >= 0, it is safe to execute
(S ; e) for k steps. Hence, we must show that for any state (S 0; e0) reachable from
(S ; e) in less than k steps, either e0 is a value or another step is possible. Suppose
(S ; e) 7-!jM (S 0; e0) where j < k. If (S 0; e0) is not irreducible, then there must
exist some (S 00; e00) such that (S 0; e0) 7-!M (S 00; e00). Otherwise, (S 0; e0) is irreducible
and we must prove that e0 is a value. By Definition 3.7, from |=M e : o/ we have
\Gamma 0 |= kM e : o/ , where \Gamma 0 is the empty context, and it follows that e is closed. Choose
the empty value environment oe0 and the empty store typing \Psi 0. By the definition
of \Gamma 0 |= kM e : o/ (Definition 3.7) we have the following.

oe0 :k;\Psi 0 \Gamma 0 =) oe0(e) :k;\Psi 0 o/
The premise is trivially satisfied; applying the trivial substitution we obtain e :k;\Psi 0 o/ .
Since \Psi 0 is the empty store typing, it trivially follows that S :k \Psi 0. Then, from
e :k;\Psi 0 o/ (by Definition 3.6) -- since S :k \Psi 0, (S ; e) 7-!jM (S 0; e0) for j < k, and
irred(S 0; e0) -- it follows that there exists a store typing \Psi 0 such that (k; \Psi 0) v
(k - j; \Psi 0), S 0 :k-j \Psi 0, and hk - j; \Psi 0; e0i 2 o/ . Since o/ is a type it follows that val(e0).

\Lambda 

3.3.8 Components of Possible-Worlds Model
In Section 2.2.1 I described a model of *I (*-calculus with immutable references)
and discussed connections between it and Kripke models of modal logic. Those
observations continue to hold for our indexed model of *M which is also a possibleworlds model, though the set of worlds, the accessibility relation, and the labeling
function for our current possible-worlds semantics are different from what we saw
for *I . Let us look at each of the things one must specify when building a possibleworlds model.

First, one specifies a set W , whose elements are called worlds. In Kripke's
multiple-world interpretation of modal logic, a proposition is true or false relative
to a world. In our model, a value v has type o/ relative to a world, that is, relative
to a state of computation during evaluation. All the information that we need from
a world -- that is, in order to decide whether v has type o/ -- may be given by pairs
of the form (k; \Psi ) where k is the number of steps left to execute and \Psi  is the store
typing that describes the store component of the current machine state. Hence, in
our model the set of worlds W is as follows:

W = { (k; \Psi ) | k >= 0 ^ 8` 2 dom(\Psi ): (8 hk0; \Psi 0; vi 2 \Psi (`): k0 < k) }
Note that we could have used tuples (k; \Psi ; S ) as worlds, but instead, we have
constructed the model in such a way that S does not need to be a part of the

61

world (for reasons that were first discussed in Section 3.2.2). Informally, all the
information that we might need from S (in order to decide whether some v has type
o/ at some state of computation) is available from b\Psi ck.

Second, one specifies a relation Acc ` W * W called the accessibility relation.
Given worlds w and w0, Acc(w; w0) says that w0 is accessible from w. In our model,
this corresponds to the state extension relation (v) and (k; \Psi ) v (j; \Psi 0) says that
state (j; \Psi 0) is accessible (or possible) from state (k; \Psi ).

Third, one specifies a labeling function L : W ! P(Atoms) that, given a world
w, yields the set of atomic propositions that hold in that world. The atomic propositions p that we are interested in are of the form: "location l is allocated and its
contents belong to o/ ." Therefore, in our model,

L(k; \Psi ) = { (`; o/ ) | b\Psi ck(`) = o/ }
Finally, one specifies the properties that the accessibility relation Acc should
satisfy. Our model is constructed to ensure that the v relation is reflexive and
transitive. As for *I , this suggests a connection with the modal logic S4 since
models of S4 also require that the accessibility relation be reflexive and transitive.

3.3.9 Well Founded and Nonexpansive Type Functions
In the next two sections, I shall prove the validity of all *M types (Section 3.4)
and typing rules (Section 3.5). In order to prove some of the lemmas for quantified
types, I must first define the notion of a nonexpansive type functional.9

Informally, a type functional F is nonexpansive if, in order to determine whether
or not e has type F (o/ ) to approximation k, we do not need to know the entire set
o/ , but rather, it suffices to know the set o/ to approximation k.

Definition 3.9 (Nonexpansive)
A nonexpansive functional is a function F from types to types such that for any
type o/ and k >= 0 we have

bF (o/ )ck = bF (bo/ ck)ck
A related notion is that of a well founded type functional. Informally, a type
functional F is well founded if, in order to determine whether or not e has type
F (o/ ) to approximation k, it suffices to know the set o/ to approximation k - 1.

9Specifically, the lemmas for the validity of existential types 9F (Lemma 3.19) and the typing
rules for type abstraction (8F introduction, Theorem 3.28) and unpack (9F elimination, Theorem 3.33) require that F be a nonexpansive type functional.

62

Definition 3.10 (Well Founded)
A well founded functional is a function F from types to types such that for any type
o/ and k >= 0 we have

bF (o/ )ck+1 = bF (bo/ ck)ck+1

Let us consider some examples of nonexpansive and well founded functionals. I
write *ff:ff for the identity type function F (where * should not be confused with
the notation for lambda abstraction in our syntax of terms). The type function *ff:ff
is nonexpansive but not well founded. Meanwhile the type functions *ff:ref ff and
*ff:ff ! ff are well founded since the type constructors ref and ! are well founded.
Informally, e has type ref o/ to approximation k as long as e "contains" some value
that has type o/ to approximation k - 1 -- that is, it suffices to only know the set o/
to approximation k - 1. Intuitively, ref is well founded because dereferencing takes
up one step. Similarly, ! is well founded because beta-reduction takes up one step.
Note that every well founded constructor is nonexpansive.

The definitions of both well founded and nonexpansive functionals are due to
Appel and McAllester [AM01] who used the term "nonexpansive" by analogy with
the metric-space semantics of MacQueen, Plotkin, and Sethi [MPS86]. Appel and
McAllester proved that all the constructors that can be built by compositions of
their type constructors are nonexpansive. The same result holds in our model,
though the semantics of our type constructors is different. I shall state the lemma
here without proof. The proofs are similar to those by Appel and McAllester.

Lemma 3.11 (Nonexpansive Constructors)

1. Every well founded constructor is nonexpansive.

2. *ff:ff is nonexpansive.
3. *ff:o/ , where ff is not free in o/ , is well founded.
4. The composition of nonexpansive constructors is nonexpansive.
5. The composition of a nonexpansive constructor with a well founded constructor

(in either order) is well founded.

6. If F and G are nonexpansive, then *:F ff ! Gff is well founded.
7. If F is nonexpansive, then *ff:ref(F ff) is well founded.

In Chapter 4 (Section 4.1) I shall explain how to model quantified types 8F and
9F in a language that treats type application and the unpacking of existentials as
coercions rather than explicit "run time" steps. To accommodate such an operational semantics, the model requires that the type functionals F be well founded.
The notion of well founded functionals is also necessary for proving the validity of
recursive types uF (as I shall explain in Chapter 4, Section 4.2.1).

63

3.4 Validity of Types
The safety theorem (Theorem 3.8) states that a program e with type o/ is safe to
execute (Theorem 3.8) as long as o/ is a type (Definition 3.4). In this section, I shall
prove that each of the type constructors shown in Figure 3.6 is a type, or produces
a type when applied to valid arguments. In each case I have to show that types
are preserved under valid state extension (v). I shall first prove some properties of
state extension that we will need later, namely that valid state extension is both
reflexive and transitive.

Lemma 3.12 (State Extension Reflexive)
(k; \Psi ) v (k; \Psi ).

Proof: Trivial. \Lambda 

Lemma 3.13 (State Extension Transitive)
If (k1; \Psi 1) v (k2; \Psi 2) and (k2; \Psi 2) v (k3; \Psi 3) then (k1; \Psi 1) v (k3; \Psi 3).

Proof: The proof is in two parts. First, from the premises of the lemma and the
definition of v we have k2 <= k1 and k3 <= k2. It follows that k3 <= k1. Second,
suppose ` 2 dom(\Psi 1). Then the first premise of the lemma allows us to conclude
that b\Psi 2ck2(`) = b\Psi 1ck2(`). It follows that ` 2 dom(\Psi 2). Then, from the second
premise of the lemma we have b\Psi 3ck3 (`) = b\Psi 2ck3 (`). From b\Psi 2ck2 (`) = b\Psi 1ck2 (`)
and k3 <= k2 it follows that b\Psi 2ck3(`) = b\Psi 1ck3 (`) (by Definition 3.2 (Approx)).
Hence we may conclude that b\Psi 3ck3(`) = b\Psi 1ck3(`) by transitivity of set equality.

\Lambda 

The fact that ? and unit are types follows immediately from their definitions.
Next, we prove that o/1 ! o/2 is a type as long as o/1 and o/2 are types -- the proof
relies on the transitivity of state extension.

Lemma 3.14 (Type o/1 ! o/2)
If o/1 and o/2 are types then o/1 ! o/2 is also a type.

Proof: We must prove that o/1 ! o/2 is closed under valid state extension. Suppose
that hk; \Psi ; vi 2 o/1 ! o/2 and (k; \Psi ) v (j; \Psi 0). Note that hk; \Psi ; vi 2 o/1 ! o/2 implies
that v is of the form *x:e. We must prove that hj; \Psi 0; *x:ei 2 o/1 ! o/2. Suppose
(j; \Psi 0) v (i; \Psi 00) and hi; \Psi 00; v00i 2 o/1 for i < j and some value v00 -- we have to show
e[v00=x] :i;\Psi 00 o/2. Since i < j and by the definition of v we have j <= k, it follows that
i < k; by Lemma 3.13 we have (k; \Psi ) v (i; \Psi 00); and we already have hi; \Psi 00; v00i 2 o/1.
These three statements together with hk; \Psi ; *x:ei 2 o/1 ! o/2 and the definition of
! allow us to conclude that e[v00=x] :i;\Psi 00 o/2. \Lambda 

64

Lemma 3.15 (Type ref)
If o/ is a type then ref o/ is a type.

Proof: To show that ref o/ is closed under state extension, suppose that hk; \Psi ; vi 2
ref o/ and (k; \Psi ) v (j; \Psi 0). We must prove that hj; \Psi 0; vi 2 ref o/ . By the definition of
ref, since hk; \Psi ; vi 2 ref o/ , it follows that v is some location ` and b\Psi ck(`) = bo/ ck.
The latter implies that ` 2 dom(\Psi ). Then, from (k; \Psi ) v (j; \Psi 0) it follows that
b\Psi 0cj(`) = b\Psi cj(`), and hence, ` 2 dom(\Psi 0). In addition, from b\Psi ck(`) = bo/ ck and
j <= k, it follows by Definition 3.2 (Approx) that b\Psi cj(`) = bo/ cj, and so we may
conclude that b\Psi 0cj(`) = bo/ cj by transitivity of set equality. \Lambda 

Lemma 3.16 (Type 8F )
If F is a function from types to types then 8F is a type.

Proof: To prove that 8F is closed under state extension, suppose that hk; \Psi ; vi 2
8F and (k; \Psi ) v (j; \Psi 0). Note that hk; \Psi ; vi 2 8F implies that v is of the form \Lambda :e.
We must show that hj; \Psi 0; \Lambda :ei 2 8F . Suppose (j; \Psi 0) v (i; \Psi 00) and type(bo/ ci) for
some set o/ -- we must show that e :i0;b\Psi 00ci0 F (o/ ) for all i0 < i. Since state extension
is transitive (Lemma 3.13), we have (k; \Psi ) v (i; \Psi 00). Now, from hk; \Psi ; \Lambda :ei 2 8F
we may conclude that for any i0 < i, e :i0;b\Psi 00ci0 F (o/ ). \Lambda 

Lemma 3.17
If type(bo/ ck) and j <= k then type(bo/ cj).

Proof: Immediate from definitions 3.4 (Type) and 3.2 (Approx). \Lambda 

Lemma 3.18
If (k; \Psi ) v (j; \Psi 0), i < k, and i < j, then (i; b\Psi ci) v (i; b\Psi 0ci).

Proof: Immediate from definitions 3.3 (State Extension) and 3.2 (Approx). \Lambda 

Lemma 3.19 (Type 9F )
If F is a nonexpansive functional then 9F is a type.

Proof: To prove that 9F is closed under memory extension, suppose that hk; \Psi ; vi 2
9F and (k; \Psi ) v (j; \Psi 0). Note that hk; \Psi ; vi 2 9F implies that v is of the form
pack v0 where v0 is a value. We must show that hj; \Psi 0; pack v0i 2 9F . The proof has
two parts. First, we have to prove the existence of some set o/ such that type(bo/ cj).
From hk; \Psi ; pack v0i 2 9F it follows by the definition of 9F that there exists some
o/ such that type(bo/ ck). Since j <= k it follows by Lemma 3.17 that type(bo/ cj).

For the second part, let i < j; we must show hi; b\Psi 0ci; v0i 2 F (o/ ). Since i < j
and j <= k we have i < k, and from hk; \Psi ; pack v0i 2 9F we have hi; b\Psi ci; v0i 2 F (o/ ).

65

Since F is a function from types to types and bo/ cj is a type, F (bo/ cj) is a type. It
follows that bF (bo/ cj)cj is a type (by Definition 3.2 (Approx)). Since F is nonexpansive, we have that bF (bo/ cj)cj = bF (o/ )cj. Hence bF (o/ )cj is a type. Now,
since hi; b\Psi ci; v0i 2 F (o/ ) and i < j, it follows that hi; b\Psi ci; v0i 2 bF (o/ )cj. Furthermore, since (k; \Psi ) v (j; \Psi 0), i < j, and i < k, by Lemma 3.18 we may
conclude that (i; b\Psi ci) v (i; b\Psi 0ci). Since types are closed under state extension,
from hi; b\Psi ci; v0i 2 bF (o/ )cj and type(bF (o/ )cj) we may conclude that hi; b\Psi 0ci; v0i 2
bF (o/ )cj. But since i < j it follows that hi; b\Psi 0ci; v0i 2 F (o/ ). \Lambda 

3.5 Validity of Typing Rules
I shall now prove each of the typing rules in Figure 3.7 as lemmas. The lemma for
variables, stating that \Gamma  |=M x : \Gamma (x), follows immediately from the definition of |=M .
The lemma for M-unit is immediate from the definition of unit.

3.5.1 Lambda Abstraction and Application
Theorem 3.20 (Abstraction)
Let \Gamma  be a type environment, let o/1 and o/2 be types, and let \Gamma [x := o/1] be the type
environment that is identical to \Gamma  except that it maps x to o/1. If \Gamma [x := o/1] |=M e : o/2
then \Gamma  |=M *x:e : o/1 ! o/2.

Proof: We must show that under the premises of the theorem for any k >= 0 we
have \Gamma  |= kM *x:e : o/1 ! o/2. More specifically, for any oe and \Psi  such that oe :k;\Psi  \Gamma  we
must show that oe(*x:e) :k;\Psi  o/1 ! o/2. Suppose oe :k;\Psi  \Gamma . Let j < k and v, \Psi 0, be
such that (k; \Psi ) v (j; \Psi 0) and hj; \Psi 0; vi 2 o/1. By definition of ! it now suffices to
show that oe(e[v=x]) :j;\Psi 0 o/2. Let oe [x 7! v] be the substitution identical to oe except
that it maps x to v. Since the codomain of \Gamma  contains types (which are closed under
state extension), and since v :j;\Psi 0 o/1, we now have that oe [x 7! v] :j;\Psi 0 \Gamma  [x 7! o/1].
To show oe(e[v=x]) :j;\Psi 0 o/2, suppose S 0 :j \Psi 0. By the premise \Gamma  [x 7! o/1] |=M e : o/2,
together with S 0 :j \Psi 0 and oe [x 7! v] :j;\Psi 0 \Gamma  [x 7! o/1] we have oe [x 7! v](e) :j;\Psi 0 o/2.
But this implies oe(e[v=x]) :j;\Psi 0 o/2. \Lambda 

Theorem 3.21 (Application)
If \Gamma  is a type environment, e1 and e2 are (possibly open) terms, and o/1 and o/2 are
types such that \Gamma  |=M e1 : o/1 ! o/2 and \Gamma  |=M e2 : o/1 then \Gamma  |=M (e1 e2) : o/2.

Proof: We must prove that under the premises of the theorem, for any k >= 0,
we have \Gamma  |= kM (e1 e2) : o/2. More specifically, for any oe and \Psi  such that oe :k;\Psi  \Gamma 
we must show oe(e1 e2) :k;\Psi  o/2. From the premise \Gamma  |=M e1 : o/1 ! o/2 we have

66

oe(e1) :k;\Psi  o/1 ! o/2. To show oe(e1 e2) :k;\Psi  o/2, suppose S :k \Psi  for some store S .
Then, from oe(e1) :k;\Psi  o/1 ! o/2 it follows that (S ; oe(e1)) is safe for k steps. Either
(S ; oe(e1)) reduces for k steps without reaching a state (S 0; v1) where v1 is a value --
in which case (S ; oe(e1 e2)) does not generate a value in less than k steps and hence
oe(e1 e2) :k;\Psi  o/2 (for any o/2) -- or the value v1 is a lambda expression *x:e. In the
latter case, since oe(e1) :k;\Psi  o/1 ! o/2 and (S ; oe(e1)) 7-!jM (S 0; *x:e), where j < k and
irred(S 0; *x:e), it follows that there exists a \Psi 0 such that (k; \Psi ) v (k - j; \Psi 0) and
S 0 :k-j \Psi 0 and hk - j; \Psi 0; *x:ei 2 o/1 ! o/2.

From oe :k;\Psi  \Gamma  it follows that oe(x) :k;\Psi  \Gamma (x) for all variables x 2 dom(\Gamma ). A
type environment \Gamma  is a mapping from variables to types. Hence, since (k; \Psi ) v
(k - j; \Psi 0), it follows that oe(x) :k-j;\Psi 0 \Gamma (x) for all x 2 dom(\Gamma ) -- that is, we have
oe :k-j;\Psi 0 \Gamma . Now, from premise \Gamma  |=M e2 : o/1, since k - j >= 0, S 0 :k-j \Psi 0, and
oe :k-j;\Psi 0 \Gamma , we have oe(e2) :k-j;\Psi 0 o/1. It follows that (S 0; oe(e2)) is safe for k - j
steps, i.e., either (S 0; oe(e2)) does not generate a value in fewer than k - j steps --
in which case, (S ; oe(e1 e2)) does not generate a value in fewer than k steps so we
have oe(e1 e2) :k;\Psi  o/2 (for any o/2) -- or (S 0; oe(e2)) 7-!iM (S 00; v) where i < k - j.
In the latter case, (S ; oe(e1 e2)) 7-!j+iM (S 00; (*x:e)v) where j + i < k. Also, since
oe(e2) :k-j;\Psi 0 o/1 and (S 0; oe(e2)) 7-!iM (S 00; v) for i < k - j and irred(S 00; v), it follows
that there exists a \Psi 00 such that (k - j; \Psi 0) v (k - j - i; \Psi 00), S 00 :k-j-i \Psi 00, and
hk - j - i; \Psi 00; vi 2 o/1.

Pick memory typing \Psi * = b\Psi 00ck-j-i-1. Let k* = k - j - i - 1. Then the following information-forgetting state extension holds: (k - j - i; \Psi 00) v (k*; \Psi *). Since
hk - j - i; \Psi 00; vi 2 o/1 and o/1 is a type, we have hk*; \Psi *; vi 2 o/1. The definition
of ! then implies that e[v=x] :k*;\Psi * o/2. But we now have (S ; oe(e1 e2)) 7-!j+i+1M
(S 00; e[v=x]), (k; \Psi ) v (k*; \Psi *), S 00 :k* \Psi *, and e[v=x] :k*;\Psi * o/2. By Definition 3.6
(Expr : Type), this means that if (S 00; e[v=x]) generates a value in fewer than k* steps
then that value will be of type o/2. Hence, we may conclude that oe(e1 e2) :k;\Psi  o/2 as
we wanted to show. \Lambda 

3.5.2 Allocation, Assignment, Dereferencing
I use the notation aprx-extend(k; \Psi ; `; o/ ) to denote a store typing that extends b\Psi ck
by mapping ` to bo/ ck. aprx-extend serves as a useful abbreviation in the proof of
the M-new typing rule.

Definition 3.22 (Approximately Extend Store Typing)
The approximate extension of a store typing \Psi  with location ` mapped to type o/ is
defined as follows:

aprx-extend(k; \Psi ; `; o/ ) = b\Psi ck [ (` 7! bo/ ck)

67

Lemma 3.23 (Closed New)
If e is a closed term and o/ is a type such that e :k;\Psi  o/ then new(e) :k;\Psi  ref o/ .

Proof: Since o/ is a type by Lemma 3.15 ref o/ is a type. We must show new(e) :k;\Psi 
ref o/ . Suppose S :k \Psi  for some store S . Then we must show that (S ; new(e)) is safe
for k steps.

From e :k;\Psi  o/ and S :k \Psi  it follows that (S ; e) is safe for k steps. Hence, if the
state (S ; new(e)) reduces for k steps without reaching a state of the form (S 0; new(v)),
it follows that new(e) :k;\Psi  ref o/ . So we assume without loss of generality that
(S ; new(e)) 7-!jM (S 0; new(v)) for some j < k, store S 0, and value v. Then e :k;\Psi  o/
implies that there exists a \Psi 0 such that we have

1. (k; \Psi ) v (k - j; \Psi 0)
2. S 0 :k-j \Psi 0
3. hk - j; \Psi 0; vi 2 o/
4. Pick some location ` such that ` =2 dom(S 0). Suppose that (S 0; new(v)) 7-!M

(S 0 [` 7! v]; `)

5. Pick \Psi 00 = aprx-extend(k - j - 1; b\Psi 0ck-j-1; `; o/ ). Note that b\Psi 00ck-j-1 = \Psi 00

by the definition of aprx-extend.

6. The following information-forgetting store extension holds: (k - j; \Psi 0) v (k -

j - 1; b\Psi 0ck-j-1).

7. We must show that (k - j - 1; b\Psi 0ck-j-1) v (k - j - 1; \Psi 00). Suppose

`1 2 dom(b\Psi 0ck-j-1) -- we must show that b\Psi 0ck-j-1(`1) = b\Psi 00ck-j-1(`1) =
\Psi 00(`1). Since `1 2 dom(b\Psi 0ck-j-1) and since we have ` =2 dom(b\Psi 0ck-j-1, it
follows that `1 6= `. Then \Psi 00(`1) = bb\Psi 0ck-j-1ck-j-1(`1) = b\Psi 0ck-j-1(`1) as
needed.

8. We must show that S 0 [` 7! v] :k-j-1 \Psi 00. First, from (2) we have dom(\Psi 0) `

dom(S 0), which implies that dom(b\Psi 0ck-j-1) ` dom(S 0). Then dom(\Psi 00) =
dom(b\Psi 0ck-j-1) [ { ` } ` dom(S 0 [` 7! v]). Second, pick i < k - j - 1 and
`1 2 dom(\Psi 00); we have to show hi; b\Psi 00ci; S 0 [` 7! v](`1)i 2 b\Psi 00ck-j-1(`1).

* Suppose ` = `1. Then we must show hi; b\Psi 00ci; vi 2 \Psi 00(`) = bo/ ck-j-1.

Since hk - j; \Psi 0; vi 2 o/ , type(o/ ), and by (6) and (7) we have (k - j; \Psi 0) v
(k - j - 1; \Psi 00) v (i; b\Psi 00ci), it follows that hi; b\Psi 00ci; vi 2 o/ . From i <
k - j - 1 it follows that hi; b\Psi 00ci; vi 2 bo/ ck-j-1.

68

* Suppose ` 6= `1. Then we must show that hi; b\Psi 00ci; S 0(`1)i 2 b\Psi 0ck-j-1(`1).

From S 0 :k-j \Psi 0 and `1 2 dom(\Psi 0) we have hk - j - 1; b\Psi 0ck-j-1; S 0(`1)i 2
b\Psi 0ck-j(`1). From (7) and the fact that b\Psi 0ck-j(`1) is a type, we have
hk - j - 1; \Psi 00; S 0(`1)i 2 b\Psi 0ck-j(`1). Then, since i < k - j - 1 and
(k - j - 1; \Psi 00) v (i; b\Psi 00ci), we have hi; b\Psi 00ci; S 0(`1)i 2 b\Psi 0ck-j(`1).
Since i < k - j - 1, we have hi; b\Psi 00ci; S 0(`1)i 2 b\Psi 0ck-j-1(`1) as needed.

9. We must show that hk - j - 1; \Psi 00; `i 2 ref o/ . By the definition of ref, it

suffices to show b\Psi 00ck-j-1(`) = bo/ ck-j-1, that is, \Psi 00(`) = bo/ ck-j-1. Since
\Psi 00 = aprx-extend(k - j - 1; b\Psi 0ck-j-1; `; o/ ), by the definition of aprx-extend we
have \Psi 00(`) = bo/ ck-j-1 as we needed to show.

Finally, we have the following:

* (S ; new(e)) 7-!j+1M (S 0 [` 7! v]; `) (from (S ; new(e)) 7-!jM (S 0; new(v)) and

(3));

* (k; \Psi ) v (k - j - 1; \Psi 00) (from (1), (6), (7), and transitivity of v);

* S 0 [` 7! v] :k-j-1 \Psi 00 (from (8);

* hk - j - 1; \Psi 00; `i 2 ref o/ (from (9)).
Together these statements imply new(e) :k;\Psi ;S ref o/ . \Lambda 

Theorem 3.24 (New)
If \Gamma  is a type environment, e is a (possibly open) term, and o/ is a type such that
\Gamma  |=M e : o/ then \Gamma  |=M new(e) : ref o/

Proof: We must prove that for any k >= 0 we have \Gamma  |= kM new(e) : ref o/ . More
specifically, for any oe and \Psi  such that oe :k;\Psi  \Gamma , we must show oe(new(e)) :k;\Psi  ref o/ .
Suppose oe :k;\Psi  \Gamma . By the premise of the theorem we have oe(e) :k;\Psi  o/ . The result
now follows from Lemma 3.23. \Lambda 

Lemma 3.25 (Closed Dereferencing)
If e is a closed term and o/ is a type set such that e :k;\Psi  ref o/ then ! e :k;\Psi  o/ .

Proof: Since o/ is a type by Lemma 3.15 ref o/ is a type. To show ! e :k;\Psi  o/ ,
let S :k \Psi  for some store S . Then we must show that (S ; ! e) is safe for k steps.
Since e :k;\Psi  ref o/ it follows that (S ; e) is safe for k steps. Hence, the state (S ; ! e)
either reduces for k steps without reaching a state of the form (S 0; ! v), in which
case ! e :k;\Psi  o/ (for any o/ ), or (S ; ! e) 7-!jM (S 0; ! `) where ` 2 dom(S 0) and j < k.
In the latter case, since e :k;\Psi  ref o/ , Definition 3.6 (Expr : Type) implies that there

69

exists a \Psi 0 such that (k; \Psi ) v (k - j; \Psi 0), S 0 :k-j \Psi 0, and hk - j; \Psi 0; `i 2 ref o/ .
By the definition of ref it follows that b\Psi 0ck-j(`) = bo/ ck-j. From S 0 :k-j \Psi 0, since
` 2 dom(\Psi 0), we have hk - j - 1; b\Psi 0ck-j-1; S 0(`)i 2 b\Psi 0ck-j(`). Hence, we have
hk - j - 1; b\Psi 0ck-j-1; S 0(`)i 2 bo/ ck-j. Now, the following information-forgetting
store extension holds: (k - j; \Psi 0) v (k - j - 1; b\Psi 0ck-j-1). Then, we have

1. (S ; ! e) 7-!j+1M (S 0; S 0(`)) where irred(S 0; S 0(`));
2. (k; \Psi ) v (k - j - 1; b\Psi 0ck-j-1);
3. S 0 :k-j-1 b\Psi 0ck-j-1;
4. hk - j - 1; b\Psi 0ck-j-1; S 0(`)i 2 o/

These four statements imply ! e :k;\Psi  o/ . \Lambda 

Theorem 3.26 (Dereferencing)
If \Gamma  is a type environment, e is a (possibly open) term, and o/ is a type such that
\Gamma  |=M e : ref o/ then \Gamma  |=M ! e : o/

Proof: As for theorem 3.24 we must show that under the premises of the theorem
for any k >= 0, oe and \Psi  such that oe :k;\Psi  \Gamma  we have oe(! e) :k;\Psi  o/ . Suppose oe :k;\Psi  \Gamma .
By the premise of the theorem we have oe(e) :k;\Psi  ref o/ . The result now follows from
Lemma 3.25. \Lambda 

Theorem 3.27 (Assignment)
Let \Gamma  be a type environment, let e1 and e2 be (possibly open) terms and o/ be a type.
If \Gamma  |=M e1 : ref o/ and \Gamma  |=M e2 : o/ then \Gamma  |=M e1 := e2 : unit.

Proof: We must show that under the premises of the theorem, for any k >= 0,
we have \Gamma  |= kM e1 := e2 : unit. More specifically, for any oe and \Psi  such that oe :k;\Psi  \Gamma 
we must show oe(e1 := e2) :k;\Psi  unit. Let S be a store such that S :k \Psi ; then we
must show that (S ; oe(e1 := e2)) is safe for k steps. From the premise \Gamma  |=M e1 : ref o/
together with oe :k;\Psi  \Gamma , it follows that oe(e1) :k;\Psi  ref o/ . The latter, by Definition 3.6,
implies that (S ; oe(e1)) is safe for k steps. Suppose, without loss of generality, that
(S ; oe(e1)) reduces to (S ; `) in j steps where j < k. Then there exists \Psi 0 such that

1. (k; \Psi ) v (k - j; \Psi 0)
2. S 0 :k-j \Psi 0
3. hk - j; \Psi 0; `i 2 ref o/

70

Since the codomain of \Gamma  contains types (which are closed under state extension),
from oe :k;\Psi  \Gamma  and (1), it follows that oe :k-j;\Psi 0 \Gamma . Then, from \Gamma  |=M e2 : o/ we have
oe(e2) :k-j;\Psi 0 o/ from which it follows that (S 0; oe(e2)) is safe for k - j steps. Suppose,
without loss of generality, that (S 0; oe(e2)) reduces to (S 00; v) (where v is a value) in
i < k - j steps. Then there exists a \Psi 00 such that

4. (k - j; \Psi 0) v (k - j - i; \Psi 00)
5. S 00 :k-j-i \Psi 00
6. hk - j - i; \Psi 00; vi 2 o/
7. From (3) we have ` 2 dom(\Psi 0). From (4) we have ` 2 dom(\Psi 00). Then, from

(5) it follows that ` 2 dom(S 00). Therefore, we have (S ; oe(e1 := e2)) 7-!j+1M
(S 00; ` := v) 7-!M (S 00 [` 7! v]; unit) since ` 2 dom(S 00).

8. Let k0 = k - j - i - 1. We also have (k; \Psi ) v (k - j - i; \Psi 00) v (k0; b\Psi 00ck0).
9. By the definition of unit we have hk0; b\Psi 00ck0; uniti 2 unit.
10. It remains for us to show S 00 [` 7! v] :k0 b\Psi 00ck0:

First, from (5) we have dom(\Psi 00) ` dom(S 00). Then, dom(\Psi 00) ` dom(S 00 [` 7! v]),
and since dom(\Psi 00) = dom(bS 00ck0), it follows that dom(bS 00ck0) ` dom(S 00 [` 7! v]).

Second, pick i0 < k0 and `1 2 dom(b\Psi 00ck0). We have to show that
hi0; bb\Psi 00ck0ci0; S 00 [` 7! v](`1)i 2 b\Psi 00ck0(`1), or equivalently,
hi0; b\Psi 00ci0; S 00 [` 7! v](`1)i 2 b\Psi 00ck0(`1).

* Suppose `1 = `. Then we must show hi0; b\Psi 00ci0; vi 2 b\Psi 00ck0(`). From (6)

and the information-forgetting state extension (k-j -i; \Psi 00) v (i0; b\Psi 00ci0)
and type(o/ ) we have hi0; b\Psi 00ci0; vi 2 o/ . From (3), by the definition of ref,
we have b\Psi 0ck-j(`) = bo/ ck-j. And from (4) and (8) we have (k - j; \Psi 0) v
(k0; b\Psi 00ck0). Then, since ` 2 dom(\Psi 0) (from (3)), we have b\Psi 00ck0(`) =
b\Psi 0ck0(`) = bo/ ck0. Since i0 < k0 we have hi0; b\Psi 00ci0; vi 2 bo/ ck0. Hence,
hi0; b\Psi 00ci0; vi 2 b\Psi 00ck0(`) as we wanted to show.

* Suppose `1 6= `. Then we must show hi0; b\Psi 00ci0; S 00(`1)i 2 b\Psi 00ck0(`1).

From S 00 :k-j-i \Psi 00 and `1 2 dom(b\Psi 00ck0), we have hk0; b\Psi 00ck0; S 00(`1)i 2
b\Psi 00ck-j-i(`1). Then, since b\Psi 00ck-j-i(`1) is a type and (k0; b\Psi 00ck0) v
(i0; b\Psi 00ci0) (information-forgetting state extension since i0 < k0), it follows that hi0; b\Psi 00ci0; S 00(`1)i 2 b\Psi 00ck-j-i(`1). Since i0 < k0, we have
hi0; b\Psi 00ci0; S 00(`1)i 2 b\Psi 00ck0(`1) as we wanted to show.

Finally we have the following:

* (S ; oe(e1 := e2)) 7-!j+i+1M (S 00 [` 7! v]; unit) (from (7));

71

* (k; \Psi ) v (k0; b\Psi 00ck0) (from (8), by transitivity of v);

* S 00 [` 7! v] :k0 b\Psi 00ck0 (from (10));

* hk0; b\Psi 00ck0; uniti 2 unit (from (9)).
These four statements imply oe(e1 := e2) :k;\Psi  unit. \Lambda 

3.5.3 Type Abstraction and Application
Theorem 3.28 (Type Abstraction)
Let \Gamma  be a type environment and let F be a nonexpansive type functional. If \Gamma  |=M e :
F (o/ ) for any type set o/ , then \Gamma  |=M \Lambda :e : 8F .

Proof: We must show that, for any k >= 0 and oe and \Psi  such that oe :k;\Psi  \Gamma , we have
oe(\Lambda :e) :k;\Psi  8F . Suppose oe :k;\Psi  \Gamma . Let j, v, \Psi 0, and o/ be such that (k; \Psi ) v (j; \Psi 0)
and type(bo/ cj). By the definition of 8F it suffices to show that for any i < j we
have oe(e) :i;b\Psi 0ci F (o/ ). Since bo/ cj is a type, given the premises of the theorem it
follows that \Gamma  |=M e : F (bo/ cj). Hence, oe(e) :k;\Psi  F (bo/ cj). Also, since F is a function
from types to types, F (bo/ cj) is a type.

The following information-forgetting state extension holds: (j; \Psi 0) v (i; b\Psi 0ci).
Then by Lemma 3.13 (v transitive) it follows that (k; \Psi ) v (i; b\Psi 0ci). Hence, from
oe(e) :k;\Psi  F (bo/ cj) and type(F (bo/ cj)) we can conclude that oe(e) :i;b\Psi 0ci F (bo/ cj). Now
since i < j, by definitions 3.2, 3.4, and 3.6 (Approx, Type, and Expr : Type) it
follows that oe(e) :i;b\Psi 0ci bF (bo/ cj)cj. Using the premise that F is nonexpansive we
have that oe(e) :i;b\Psi 0ci bF (o/ )cj. But since i < j, Definition 3.2 (Approx) implies
oe(e) :i;b\Psi 0ci F (o/ ) as we needed to show. \Lambda 

Lemma 3.29 (Closed Type Application)
If e is a closed term, o/ is a type, and F is a function from types to types such that
e :k;\Psi  8F , then e[ ] :k;\Psi  F (o/ ).

Proof: We must prove e[ ] :k;\Psi  F (o/ ) under the premises of the lemma. Since F is
a function from types to types, by Lemma 3.16 8F is a type. To show e[ ] :k;\Psi  F (o/ ),
let S be a store such that S :k \Psi . From e :k;\Psi  8F we have that (S ; e) is safe
for k steps and if (S ; e) reduces to (S 0; v) (where v is a value) in fewer than k
steps, then v must be of the form \Lambda :e0. Hence, the state (S ; e[ ]) either reduces
for k steps without reaching a state of the form (S 0; v[ ]) or there exist e0 and S 0
such that (S ; e[ ]) 7-!jM (S 0; (\Lambda :e0)[ ]) with j < k. In the first case we have that
(S ; e[ ]) is safe for k steps and (S ; e) does not reduce to a value in fewer than k
steps and hence e[ ] :k;\Psi  F (o/ ). In the second case, it follows from the operational

72

semantics in Figure 3.2 that (S ; e) 7-!jM (S 0; \Lambda :e0). Since e :k;\Psi  8F , by Definition 3.6
(Expr : Type) there exists a store typing \Psi 0 such that:

1. (k; \Psi ) v (k - j; \Psi 0);
2. S 0 :k-j \Psi 0;
3. hk - j; \Psi 0; \Lambda :e0i 2 8F .
We also have the following:

4. (k - j; \Psi 0) v (k - j; \Psi 0) since state extension is reflexive (Lemma 3.12)
5. type(bo/ ck-j) (follows from type(o/ ))
By the definition of 8F , from (3), together with (4), (5), and k - j - 1 < k - j, we
can conclude that e0 :k-j-1;b\Psi 0ck-j-1 F (o/ ).
Finally, we have the following:

* (S ; e[ ]) 7-!j+1M (S 0; e0);

* (k; \Psi ) v (k - j - 1; b\Psi 0ck-j-1) (valid information-forgetting state extension);

* S 0 :k-j-1 b\Psi 0ck-j-1;

* e0 :k-j-1;b\Psi 0ck-j-1 F (o/ ) where F (o/ ) is a type.
These four statements imply e[ ] :k;\Psi  F (o/ ). \Lambda 

Theorem 3.30 (Type Application)
Let \Gamma  be a type environment, let F be a function from types to types, and let o/ be a
type. If \Gamma  |=M e : 8F then \Gamma  |=M e[ ] : F (o/ ).

Proof: We must prove that for any k >= 0 we have \Gamma  |= kM e[ ] : F (o/ ). More specifically, for any oe and \Psi  such that oe :k;\Psi  \Gamma , we must show oe(e[ ]) :k;\Psi  F (o/ ). Suppose
oe :k;\Psi  \Gamma . By the premise of the theorem we have oe(e) :k;\Psi  8F and type(o/ ). The
result now follows from Lemma 3.29. \Lambda 

3.5.4 Pack and Unpack
Lemma 3.31 (Closed Pack)
If e is a closed term, o/ is type set and F is a function from types to types such that
e :k;\Psi  F (o/ ) then pack e :k;\Psi  9F .

73

Proof: Since o/ is type and F is a function from types to types, F (o/ ) is a
type. To show pack e :k;\Psi  9F , suppose S :k \Psi  for some store S . We must
show that (S ; pack e) is safe for k steps. Assume without loss of generality that
(S ; pack e) 7-!jM (S 0; pack v) where j < k. Then, by the operational semantics of
*M we have (S ; e) 7-!jM (S 0; v). Hence, from e :k;\Psi  F (o/ ) we have that there exists
\Psi 0 such that (k; \Psi ) v (k - j; \Psi 0), S 0 :k-j \Psi 0, and hk - j; \Psi 0; vi 2 F (o/ ).

Next, we must show that hk - j; \Psi 0; pack vi 2 9F . This follows (by the definition
of 9F ) in two steps as follows.

1. From type(o/ ) we have type(bo/ ck-j).
2. Suppose i < k - j. We must show that hi; b\Psi 0ci; vi 2 F (o/ ). Note that

(k - j; \Psi 0) v (i; b\Psi 0ci) is a valid information-forgetting state extension (since
i < k - j). Since F (o/ ) is a type and we already have hk - j; \Psi 0; vi 2 F (o/ ), it
follows that hi; b\Psi 0ci; vi 2 F (o/ ) as needed.

Now we have the following:

* (S ; pack e) 7-!jM (S 0; pack v)

* (k; \Psi ) v (k - j; \Psi 0)

* S 0 :k-j \Psi 0

* hk - j; \Psi 0; pack vi 2 9F
These statements imply pack e :k;\Psi  9F . \Lambda 

Theorem 3.32 (Pack)
Let \Gamma  be a type environment, let o/ be a type, and let F be a function from types to
types. If e is a (possibly open) term such that \Gamma  |=M e : F (o/ ) the \Gamma  |=M pack e : 9F .

Proof: Follows from Lemma 3.31 in the same manner that Theorem 3.30 (Tapp)
follows from Lemma 3.29 (Closed Tapp). \Lambda 

Theorem 3.33 (Unpack)
Let \Gamma  be a type environment and let F be a nonexpansive type functional. If o/2
is a type and e1 and e2 are (possibly open) terms such that \Gamma  |=M e1 : 9F and
\Gamma  [x 7! F (o/ )] |=M e2 : o/2 for any type o/ , then \Gamma  |=M unpack e1 as x in e2 : o/2.

Proof: We must prove under the premises of the theorem for any k >= 0 and oe
and \Psi  such that oe :k;\Psi  \Gamma  that oe(unpack e1 as x in e2) :k;\Psi  o/2. From \Gamma  |=M e1 : 9F we
have oe(e1) :k;\Psi  9F . Now, since F is a nonexpansive functional, by Lemma 3.19 9F

74

is a type. To show oe(unpack e1 as x in e2) :k;\Psi  o/2, assume that S :k \Psi  for some store
S . We must show that (S ; oe(unpack e1 as x in e2)) is safe for k steps.

From oe(e1) :k;\Psi  9F and S :k \Psi  we have that (S ; oe(e1)) is safe for k steps, and
that if (S ; oe(e1)) generates a value in fewer than k steps that value must be of
the form pack v where v is a value. Hence, assume without loss of generality that
(S ; oe(unpack e1 as x in e2)) 7-!jM (S 0; oe(unpack (pack v) as x in e2)) for j < k and
store S 0. Then, by the operational semantics of *M (Figure 3.2) we can conclude
that (S ; oe(e1)) 7-!jM (S 0; oe(pack v)) (where oe(pack v) = pack v since value v has
no free variables). Since oe(e1) :k;\Psi  9F , by Definition 3.6 (Expr : Type) there exists
\Psi 0 such that:

1. (k; \Psi ) v (k - j; \Psi 0)
2. S 0 :k-j \Psi 0
3. hk - j; \Psi 0; pack vi 2 9F
From (3), by the definition of 9F , we have that:

4. there exists a set o/ such that bo/ ck-j is a type, and
5. hk - j - 1; b\Psi 0ck-j-1; vi 2 F (o/ ).
Since bo/ ck-j is a type, by the premises of the theorem we have \Gamma  [x 7! F (bo/ ck-j)]|=M e2 :
o/2. To make further use of this statement, we will first have to show that
hk - j - 1; b\Psi 0ck-j-1; vi 2 F (bo/ ck-j), which we do as follows:

6. From (5) and Definition 3.2 (Approx) we can conclude that

hk - j - 1; b\Psi 0ck-j-1; vi 2 bF (o/ )ck-j (since k - j - 1 < k - j). By the
premises of the theorem, F is nonexpansive, which implies that bF (o/ )ck-j =
bF (bo/ ck-j)ck-j. Hence, we have hk - j - 1; b\Psi 0ck-j-1; vi 2 bF (bo/ ck-j)ck-j.
But this implies that hk - j - 1; b\Psi 0ck-j-1; vi 2 F (bo/ ck-j) as we wanted to
show.

Let oe [x 7! v] be the substitution that is identical to oe except that it maps x to v.
Recall that the codomain of \Gamma  contains types (which are closed under state extension) and that we have oe :k;\Psi  \Gamma . Note that (k-j; \Psi 0) v (k-j-1; b\Psi 0ck-j-1) is a valid
information-forgetting state extension. From the latter and (1), by the transitivity
of v (Lemma 3.13), it follows that that (k; \Psi ) v (k-j-1; b\Psi 0ck-j-1). This, together
with (6), allows us to conclude that oe [x 7! v] :k-j-1;b\Psi 0ck-j-1 \Gamma  [x 7! F (bo/ ck-j)].
Hence, from \Gamma  [x 7! F (bo/ ck-j)] |=M e2 : o/2 it follows that oe [x 7! v](e2) :k-j-1;b\Psi 0ck-j-1
o/2. But this implies oe(e2[v=x]) :k-j-1;b\Psi 0ck-j-1 o/2.

Finally we have the following:

* (S ; oe(unpack e1 as x in e2)) 7-!j+1M (S 0; oe(e2[v=x]));

75

* (k; \Psi ) v (k - j - 1; b\Psi 0ck-j-1) (by transitivity of v);

* S 0 :k-j-1 b\Psi 0ck-j-1;

* oe(e2[v=x]) :k-j-1;b\Psi 0ck-j-1 o/2.
Hence, we can conclude that oe(unpack e1 as x in e2) :k;\Psi  o/2. \Lambda 

3.6 Summary
In this chapter I described the challenges of modeling general references, that is,
mutable references that may store values of any closed type, including function
types, other references, and even impredicative polymorphic types. Specifically, I
showed how to construct a denotational-operational model of *M (i.e., System F
+ mutable references + existentials) that permits foundational proofs of safety of
*M programs. The "vanilla" language and model presented in this chapter can be
modified and extended in various ways. The next chapter describes some of these
extensions and discusses related work.

76

Chapter 4
Mutable References:
Extensions & Discussion

We want to build a foundational proof-carrying code system that compiles programs
written in a practical language, like ML or Java, down to machine code that runs
on a von Neumann machine, such as the Sparc or Pentium. But real machines do
not have instructions for type application or for unpacking values of existential type
as the *M abstract machine did in the last chapter. Section 4.1 modifies the *M
operational semantics to address this fact and looks at how such a change affects
the semantics of universal and existential types. Also, practical languages require
support for recursive types -- e.g., ML supports both covariant and contravariant
recursive datatypes -- as well as product types, union and intersection types, immutable references and so on. In Section 4.2 I will show how to add such types to
the model I constructed for *M . In the remainder of the chapter I shall describe
some examples of how our semantic model allows us to prove the safety of programs
that mutate the store, offer some observations, and discuss related work.

4.1 Eliminating Noncomputational Steps
The *M operational semantics given in Chapter 3 (see Figure 3.2) has explicit "runtime" steps for unpacking an existential (unpack (pack v) as x in e) and applying
a universal ((\Lambda :e)[ ]). A real machine, however, has no such instructions. This
section looks at the ramifications of changing the *M operational semantics so that
unpacking an existential and applying a universal are treated as virtual instructions,
or coercions on type annotations, that may be erased (along with the types) just
before the program is run -- that is, they have no effect on the number of steps
a program has executed. All of the rules in Figure 3.2 remain unchanged, with
the exception of rules MO-tapp2 and MO-unpack2. The latter are replaced by the
two rules MO-tapp2' and MO-unpack2' given below. The virtual step or coercion

77

relation 7-!0M indicates that the number of real steps executed while performing the
coercion is zero. Hence, according to our modified operational semantics, applying
a universal or unpacking an existential requires zero steps. I shall treat the old
unannotated step relation 7-!M as 7-!1M .

(S ; (\Lambda :e)[ ]) 7-!0M (S ; e) (MO-tapp2')

(S ; unpack (pack v) as x in e2) 7-!0M (S ; e2[v=x]) (MO-unpack2')
The typing rules for universal and existential types remain unchanged, but it
turns out that these rules are no longer provable given our semantic definitions of 8F
and 9F in Section 3.3.6 (see Figure 3.6). To see why, consider a state of computation
where one can safely execute k more steps and one has a value pack v such that
hk; \Psi ; pack vi 2 9F . If the next "step" taken by the program is to unpack the value
pack v, then according to the new operational semantics the program should still be
able to safely execute k more steps. Hence, after unpacking the existential one needs
to be able to prove that hk; \Psi ; vi 2 F (o/ ) where o/ is the witness type. However,
the semantics of 9F (which I've shown below for easy reference) only allows one to
conclude that hj; b\Psi cj; vi 2 F (o/ ) for all j < k. This, in turn, is due to the fact
that the definition requires only the k-approximation of o/ to be a valid type (i.e.,
type(bo/ ck)).

9F def= {hk; \Psi ; pack vi | 9o/: (type(bo/ ck) ^ 8j < k: hj; b\Psi cj; vi 2 F (o/ ))}
In order to conclude that hj; b\Psi cj; vi 2 F (o/ ) for j <= k, one would have to know
that the (k + 1)-approximation of o/ is a valid type -- that is, one would have to
define 9F as follows:

9F bad def= {hk; \Psi ; pack vi | 9o/: (type(bo/ ck+1) ^ 8j <= k: hj; b\Psi cj; vi 2 F (o/ ))}
But the above definition violates the stratification invariant (see Section 3.3.2) by
considering the type o/ to approximation k+1. It seems, therefore, that we have a conundrum: the current semantics of 9F makes the typing rule for unpack impossible
to prove, while the modified semantics of 9F leads to an inconsistent model.

The solution to this problem is to require that F be well founded (Section 3.3.9).
Intuitively, if F is well founded then one can check that the witness type o/ is valid
to approximation k (i.e., require type(bo/ ck)), but still be able to decide that v has
type F (o/ ) to approximation k since the wellfoundedness of F allows us to execute

78

one more step. Recall that type constructors like ref and ! are well founded. The
reason for their wellfoundedness, intuitively, is the extra dereferencing step for ref
and the beta-reduction step for !. Hence, if the function F is well founded then
using a value of type 8F or 9F will require at least one real runtime step. The
strategy, then, is to piggyback the coercion onto this real runtime step.

To specify the new semantics of 8F and 9F , I need to first formalize an approximate notion of wellfoundedness.

Definition 4.1 (Well Founded Upto)
A type functional F is well founded upto k (written wfupto(k; F )) if for any type o/
and any j such that 0 <= j <= k we have

bF (o/ )cj+1 = bF (bo/ cj)cj+1
Note that it follows that F is well founded if and only if wfupto(k; F ) for all k >= 0.

Universal Types The new semantics of 8F is given below. When deciding if
hk; \Psi ; \Lambda :ei 2 8F , we require that F be well founded upto k -- as explained above,
this guarantees that there will be a real step that the type application coercion can
piggyback on. Now, suppose that \Lambda :e is instantiated with the type o/ at some point
in the future when there are j <= k real execution steps left and the store typing is
\Psi 0. First, one requires that (k; \Psi ) v (j; \Psi 0) holds. Second, one must make sure that
o/ is a valid type for j - 1 steps, that is, type(bo/ cj). Now if e has type F (o/ ) for j
(and fewer) real steps with respect to store typing \Psi 0, then it must be the case that
\Lambda :e has type 8F for k steps with respect to store typing \Psi .

8F def= {hk; \Psi ; \Lambda :ei | wfupto(k; F ) ^

(8j; \Psi 0; o/: ((k; \Psi ) v (j; \Psi 0) ^ type(bo/ cj))

=) e :j;\Psi 0 F (o/ ))}

Note that the above definition does not violate the stratification invariant. First,
it requires that F be well founded only upto k. Second, it requires that only the
j-approximation of o/ be a valid type, where j <= k. Finally, it does not require that
\Psi  be defined beyond b\Psi ck.

Existential Types When deciding whether hk; \Psi ; pack vi 2 9F one has to check
that F is well founded upto k (which guarantees that the unpack coercion will have
a real step to piggyback on). In addition, one must check for the existence of a
witness type o/ such that bo/ ck is a valid type, and make sure that v has type F (o/ )
for k steps. The semantics of 9F is as follows. The definition below adheres to the

79

stratification invariant.

9F def= {hk; \Psi ; pack vi | wfupto(k; F ) ^

(9o/: type(bo/ ck) ^ hk; \Psi ; vi 2 F (o/ ))}

Requiring Well-Founded Functionals in Practice We have seen that when
type application and existential unpacking are virtual instructions, types of the form
8F and 9F only make sense if F is a well-founded functional.1 Let us consider how
this restriction might affect us in practice in a target language for type-preserving
compilation. The identity type function *ff:ff is nonexpansive but not well founded
(as noted in Section 3.3.9), but fortunately, we never need to construct quantified
types 8F and 9F such that F is the identity type function since the former is
equivalent to ? and the latter to ?.

We shall see that the intersection and union (or untagged sum) type constructors
are also nonexpansive but not well founded. Hence, for instance, the type function
*ff:(ff [ unit) is not well founded, but the type function *ff:(F (ff) [ unit) is well
founded as long as F is well founded (and similarly for " ).

In a typed low-level language, universal types are commonly used to describe
the type of polymorphic functions. For instance, the polymorphic identity function
would have type 8F where F = *ff:(ff ! ff). Notice that F is well founded
because ! is well founded. Meanwhile, in a typed low-level language, the most
common use of existential types is to describe function closures and objects. For
instance, a closure would have type 9F where F = *ff:(o/code * ff) (where o/code is
the type of the code, ff is the type of the closure's environment, and "*" denotes
the cartesian product type). Here, F is well founded because the type constructor
for cartesian products (see Section 4.2) is well founded (since projection uses up a
step). In general, therefore, the quantified types 8F and 9F used in the output of
a type-preserving compiler are such that F is well founded.

Validity of Types and Typing Rules In the remainder of this section I shall
prove that the new 8F and 9F are valid types and that the typing rules for type
abstraction, type application, pack, and unpack are sound given the new semantics.

Lemma 4.2 (Type 8F )
If F is a function from types to types then 8F is a type.

Proof: To prove that 8F is closed under state extension, suppose that hk; \Psi ; vi 2
8F and (k; \Psi ) v (j; \Psi 0). Note that hk; \Psi ; vi 2 8F implies that v is of the form \Lambda :e.
We must show that hj; \Psi 0; \Lambda :ei 2 8F . The proof is in two parts.

1Note that one can still construct types 8F and 9F where F is nonexpansive, but rather than
erasing the corresponding type application and unpack coercions from the code before it runs, one
would have to replace each one with a nop.

80

1. We must show wfupto(j; F ). From hk; \Psi ; \Lambda :ei 2 8F we have wfupto(k; F ).

Since j <= k it follows that wfupto(j; F ).

2. Suppose (j; \Psi 0) v (i; \Psi 00) and type(bo/ ci) for some set o/ -- we must show

that e :i;\Psi 00 F (o/ ). Since state extension is transitive (Lemma 3.13), we have
(k; \Psi ) v (i; \Psi 00). Now, from hk; \Psi ; \Lambda :ei 2 8F we may conclude that e :i;\Psi 00
F (o/ ).

\Lambda 

Lemma 4.3 (Type 9F )
If F is a function from types to types then 9F is a type.

Proof: To prove that 9F is closed under memory extension, suppose that hk; \Psi ; vi 2
9F and (k; \Psi ) v (j; \Psi 0). Note that hk; \Psi ; vi 2 9F implies that v is of the form
pack v0 where v0 is a value. We must show that hj; \Psi 0; pack v0i 2 9F . The proof
has three parts. First, we have to prove wfupto(j; F ). From hk; \Psi ; pack v0i 2 9F
we have wfupto(k; F ). Since j <= k, we have wfupto(j; F ).

Second, we have to prove the existence of some set o/ such that type(bo/ cj). From
hk; \Psi ; pack v0i 2 9F it follows by the definition of 9F that there exists some o/ such
that type(bo/ ck). Since j <= k it follows by Lemma 3.17 that type(bo/ cj).

For the third part, we must show hj; \Psi 0; v0i 2 F (o/ ). From hk; \Psi ; pack v0i 2 9F
we have hk; \Psi ; v0i 2 F (o/ ). Since F is a function from types to types and bo/ ck
is a type, F (bo/ ck) is a type. It follows that bF (bo/ ck)ck+1 is a type (by Definition 3.2 (Approx)). Since wfupto(k; F ), we have bF (bo/ ck)ck+1 = bF (o/ )ck+1. Hence,
bF (o/ )ck+1 is a type. Now, since hk; \Psi ; v0i 2 F (o/ ) and k < k + 1, it follows that
hk; \Psi ; v0i 2 bF (o/ )ck+1. Furthermore, since (k; \Psi ) v (j; \Psi 0) and type(bF (o/ )ck+1), we
have hj; \Psi 0; v0i 2 bF (o/ )ck+1. But since j < k + 1 it follows that hj; \Psi 0; v0i 2 F (o/ ).

\Lambda 

Theorem 4.4 (Type Abstraction)
Let \Gamma  be a type environment and let F be a well founded type functional. If \Gamma  |=M e :
F (o/ ) for any type set o/ , then \Gamma  |=M \Lambda :e : 8F .

Proof: We must show that, for any k >= 0 and oe and \Psi  such that oe :k;\Psi  \Gamma , we
have oe(\Lambda :e) :k;\Psi  8F . Suppose oe :k;\Psi  \Gamma . The proof is in two parts. First we must
show wfupto(k; F ), which follows easily from the fact that F is well founded and
k >= 0.

For the second part, let j, v, \Psi 0, and o/ be such that (k; \Psi ) v (j; \Psi 0) and
type(bo/ cj) -- we must show that oe(e) :j;\Psi 0 F (o/ ). Since bo/ cj is a type, given the
premises of the theorem it follows that \Gamma  |=M e : F (bo/ cj). Hence, oe(e) :k;\Psi  F (bo/ cj).
Also, since F is a function from types to types, F (bo/ cj) is a type.

81

From type(F (bo/ cj)), oe(e) :k;\Psi  F (bo/ cj), and (k; \Psi ) v (j; \Psi 0) we can conclude that
oe(e) :j;\Psi 0 F (bo/ cj). Now since j < j + 1, by Definitions 3.2, 3.4, and 3.6 (Approx,
Type, and Expr : Type) it follows that oe(e) :j;\Psi 0 bF (bo/ cj)cj+1. Since wfupto(k; F )
and j <= k we have bF (o/ )cj+1 = bF (bo/ cj)cj+1. Hence, oe(e) :j;\Psi 0 bF (o/ )cj+1. But since
j < j + 1, Definition 3.2 (Approx) implies oe(e) :j;\Psi 0 F (o/ ) as we needed to show. \Lambda 

Lemma 4.5 (Closed Type Application)
If e is a closed term, o/ is a type, and F is a function from types to types such that
e :k;\Psi  8F , then e[ ] :k;\Psi  F (o/ ).

Proof: We must prove e[ ] :k;\Psi  F (o/ ) under the premises of the lemma. Since F is
a function from types to types, by Lemma 3.16 8F is a type. To show e[ ] :k;\Psi  F (o/ ),
let S be a store such that S :k \Psi . From e :k;\Psi  8F we have that (S ; e) is safe for k
steps and if (S ; e) reduces to (S 0; v) (where v is a value) in fewer than k steps, then
v must be of the form \Lambda :e0. Hence, assume without loss of generality that there
exist e0 and S 0 such that (S ; e[ ]) 7-!jM (S 0; (\Lambda :e0)[ ]) with j < k. It follows from the
operational semantics in Figure 3.2 that (S ; e) 7-!jM (S 0; \Lambda :e0). Since e :k;\Psi  8F , by
Definition 3.6 (Expr : Type) there exists a store typing \Psi 0 such that:

1. (k; \Psi ) v (k - j; \Psi 0);
2. S 0 :k-j \Psi 0;
3. hk - j; \Psi 0; \Lambda :e0i 2 8F .
We also have the following:

4. (k - j; \Psi 0) v (k - j; \Psi 0) since state extension is reflexive (Lemma 3.12)
5. type(bo/ ck-j) (follows from type(o/ ))
By the definition of 8F , from (3), together with (4) and (5), we can conclude
that e0 :k-j;\Psi 0 F (o/ ). Finally, we have (S ; e[ ]) 7-!jM (S 0; e0), (k; \Psi ) v (k - j; \Psi 0),
S 0 :k-j \Psi 0, and e0 :k-j;\Psi 0 F (o/ ) (where F (o/ ) is a type). These four statements imply
e[ ] :k;\Psi  F (o/ ). \Lambda 

Theorem 4.6 (Type Application)
Let \Gamma  be a type environment, let F be a function from types to types, and let o/ be a
type. If \Gamma  |=M e : 8F then \Gamma  |=M e[ ] : F (o/ ).

Proof: Follows from Lemma 4.5 in the same manner that Theorem 3.30 (Tapp)
follows from Lemma 3.29 (Closed Tapp). \Lambda 

82

Lemma 4.7 (Closed Pack)
Let e be a closed term, let o/ be a type, and let F be a type functional well founded
upto k. If e :k;\Psi  F (o/ ) then pack e :k;\Psi  9F .

Proof: Since o/ is type and F is a function from types to types, F (o/ ) is a
type. To show pack e :k;\Psi  9F , suppose S :k \Psi  for some store S . We must
show that (S ; pack e) is safe for k steps. Assume without loss of generality that
(S ; pack e) 7-!jM (S 0; pack v) where j < k. Then, by the operational semantics of
*M we have (S ; e) 7-!jM (S 0; v). Hence, from e :k;\Psi  F (o/ ) we have that there exists
\Psi 0 such that (k; \Psi ) v (k - j; \Psi 0), S 0 :k-j \Psi 0, and hk - j; \Psi 0; vi 2 F (o/ ).

Next, we must show that hk - j; \Psi 0; pack vi 2 9F . Following the definition of
9F the proof is in three parts. First, from the premise wfupto(k; F ) it follows that
wfupto(k -j; F ) since k -j <= k. Second, from type(o/ ) we have type(bo/ ck-j). Third,
we have hk - j; \Psi 0; vi 2 F (o/ ) from above.

Hence, we have the following: (S ; pack e) 7-!jM (S 0; pack v), (k; \Psi ) v (k - j; \Psi 0),
S 0 :k-j \Psi 0, and hk - j; \Psi 0; pack vi 2 9F . These four statements imply pack e :k;\Psi 
9F . \Lambda 

Theorem 4.8 (Pack)
Let \Gamma  be a type environment, let o/ be a type, and let F be a well founded function
from types to types. If e is a (possibly open) term such that \Gamma  |=M e : F (o/ ) the
\Gamma  |=M pack e : 9F .

Proof: We must prove that for any k >= 0 we have \Gamma  |= kM pack e : 9F . More
specifically, for any oe and \Psi  such that oe :k;\Psi  \Gamma , we must show oe(pack e) :k;\Psi  9F .
Suppose oe :k;\Psi  \Gamma . By the premise of the theorem we have oe(e) :k;\Psi  F (o/ ) and type(o/ ).
Since F is well founded, it follows that wfupto(k; F ). The result now follows from
Lemma 4.7. \Lambda 

Theorem 4.9 (Unpack)
Let \Gamma  be a type environment and let F be a function from types to types. If o/2
is a type and e1 and e2 are (possibly open) terms such that \Gamma  |=M e1 : 9F and
\Gamma  [x 7! F (o/ )] |=M e2 : o/2 for any type o/ , then \Gamma  |=M unpack e1 as x in e2 : o/2.

Proof: We must prove under the premises of the theorem for any k >= 0 and oe
and \Psi  such that oe :k;\Psi  \Gamma  that oe(unpack e1 as x in e2) :k;\Psi  o/2. From \Gamma  |=M e1 : 9F we
have oe(e1) :k;\Psi  9F . Now, since F is a nonexpansive functional, by Lemma 3.19 9F
is a type. To show oe(unpack e1 as x in e2) :k;\Psi  o/2, assume that S :k \Psi  for some store
S . We must show that (S ; oe(unpack e1 as x in e2)) is safe for k steps.

From oe(e1) :k;\Psi  9F and S :k \Psi  we have that (S ; oe(e1)) is safe for k steps, and
that if (S ; oe(e1)) generates a value in fewer than k steps that value must be of
the form pack v where v is a value. Hence, assume without loss of generality that

83

(S ; oe(unpack e1 as x in e2)) 7-!jM (S 0; oe(unpack (pack v) as x in e2)) for j < k and
store S 0. Then, by the operational semantics of *M (Figure 3.2) we can conclude
that (S ; oe(e1)) 7-!jM (S 0; oe(pack v)) (where oe(pack v) = pack v since value v has
no free variables). Since oe(e1) :k;\Psi  9F , by Definition 3.6 (Expr : Type) there exists
\Psi 0 such that:

1. (k; \Psi ) v (k - j; \Psi 0)

2. S 0 :k-j \Psi 0
3. hk - j; \Psi 0; pack vi 2 9F
From (3), by the definition of 9F , we have that:

4. there exists a set o/ such that bo/ ck-j is a type, and

5. hk - j - 1; b\Psi 0ck-j-1; vi 2 F (o/ ).
Since bo/ ck-j is a type, by the premises of the theorem we have \Gamma  [x 7! F (bo/ ck-j)]|=M e2 :
o/2. To make further use of this statement, we will first have to show that
hk - j - 1; b\Psi 0ck-j-1; vi 2 F (bo/ ck-j), which we do as follows:

6. From (5) and Definition 3.2 (Approx) we can conclude that

hk - j - 1; b\Psi 0ck-j-1; vi 2 bF (o/ )ck-j (since k - j - 1 < k - j). By the
premises of the theorem, F is nonexpansive, which implies that bF (o/ )ck-j =
bF (bo/ ck-j)ck-j. Hence, we have hk - j - 1; b\Psi 0ck-j-1; vi 2 bF (bo/ ck-j)ck-j.
But this implies that hk - j - 1; b\Psi 0ck-j-1; vi 2 F (bo/ ck-j) as we wanted to
show.

Let oe [x 7! v] be the substitution that is identical to oe except that it maps x to v.
Recall that the codomain of \Gamma  contains types (which are closed under state extension) and that we have oe :k;\Psi  \Gamma . Note that (k-j; \Psi 0) v (k-j-1; b\Psi 0ck-j-1) is a valid
information-forgetting state extension. From the latter and (1), by the transitivity
of v (Lemma 3.13), it follows that that (k; \Psi ) v (k-j-1; b\Psi 0ck-j-1). This, together
with (6), allows us to conclude that oe [x 7! v] :k-j-1;b\Psi 0ck-j-1 \Gamma  [x 7! F (bo/ ck-j)].
Hence, from \Gamma  [x 7! F (bo/ ck-j)] |=M e2 : o/2 it follows that oe [x 7! v](e2) :k-j-1;b\Psi 0ck-j-1
o/2. But this implies oe(e2[v=x]) :k-j-1;b\Psi 0ck-j-1 o/2.

Finally we have the following:

* (S ; oe(unpack e1 as x in e2)) 7-!j+1M (S 0; oe(e2[v=x]));

* (k; \Psi ) v (k - j - 1; b\Psi 0ck-j-1) (by transitivity of v);

* S 0 :k-j-1 b\Psi 0ck-j-1;

* oe(e2[v=x]) :k-j-1;b\Psi 0ck-j-1 o/2.
Hence, we can conclude that oe(unpack e1 as x in e2) :k;\Psi  o/2. \Lambda 

84

4.2 Modeling Additional Types
This section looks at how to extend *M with recursive types, union and intersection types, cartesian products, and immutable references. These are all features
one needs in a target language for type-preserving compilation of ML or Java. Section 4.3 presents examples that make use of some of these types.

4.2.1 Recursive Types
I extend *M with recursive types of the form uF , where F is a function from types
to types. The indexed model I presented in Chapter 3 can accommodate recursive
types without any changes to the underlying semantics. This is not surprising
given the fact that recursive types were the main motivation behind Appel and
McAllester's indexed model [AM01]. The material in this section is based on that
work.

I will show how to model equi-recursive types (uF is equal to F (uF )) -- as
opposed to iso-recursive types which require explicit fold and unfold terms (uF
isomorphic to F (uF ) via fold/unfold). Because equi-recursive types do not require
explicit fold and unfold terms, the syntax of *M terms remains exactly as shown in
Figure 3.1. The semantics of uF is given below -- F is a function from types to
types and the notation F k(o/ ) denotes k applications of F .

uF def= {hk; \Psi ; vi | hk; \Psi ; vi 2 F k+1(?)}
Note that if F is a function from types to types and o/ is a type then it follows
that F k(o/ ) is a type for any k >= 0. I extend the set of *M typing rules shown in
Figure 3.7 with the following two rules for recursive types.

\Gamma  |=M e : uF
\Gamma  |=M e : F (uF ) (M-unfold)

\Gamma  |=M e : F (uF )

\Gamma  |=M e : uF (M-fold)

In order to prove the validity of recursive types uF I need the following lemma
about well-founded functionals (which I defined in Section 3.3.9, see Definition 3.10).
The lemmas says that the type sets produced by j or more applications of a wellfounded functional to any type are identical to approximation j.

Lemma 4.10
For F well founded and j <= k, for any o/ , o/1, o/2,

(1) bF j(o/1)cj = bF j(o/2)cj
(2) bF j(o/ )cj = bF k(o/ )cj

85

Proof: (1) By induction.

bF j(o/1)c0 = ? = bF j(o/2)c0:
bF j+1(o/1)cj+1 =
bF (F j(o/1))cj+1 =
bF (bF j(o/1)cj)cj+1 =
bF (bF j(o/2)cj)cj+1 =
bF (F j(o/2))cj+1 =
bF j+1(o/2)cj+1:

(2) Using (1), taking o/2 = F k-j(o/1). \Lambda 
Now I can show that if F is a well-founded functional then uF is closed under state
extension.

Lemma 4.11 (Type uF )
If F is well founded, then uF is a type.

Proof: We must show that uF is closed under valid state extension. Suppose
that hk; \Psi ; vi 2 uF and that (k; \Psi ) v (j; \Psi 0).

hk; \Psi ; vi 2 uF
hk; \Psi ; vi 2 F k+1(?) by definition of uF
hj; \Psi 0; vi 2 F k+1(?) by Definition 3.4 (Type)
hj; \Psi 0; vi 2 bF k+1(?)cj+1 by Definition 3.2 (Approx)
hj; \Psi 0; vi 2 bF j+1(?)cj+1 by Lemma 4.10
hj; \Psi 0; vi 2 F j+1(?) by Definition 3.2 (Approx)
hj; \Psi 0; vi 2 uF by definition of uF

\Lambda 

Before I can prove the typing rules, I need a few auxiliary lemmas.
Lemma 4.12
bbo/ ck+1ck = bo/ ck.

Lemma 4.13
If F is well founded,

(a) buF ck = bF k?ck
(b) bF (uF )ck+1 = bF k+1?ck+1

86

Proof: (a) For k = 0, each side is equivalent to ?. For k > 0, each of the
following lines is equivalent:

hj; \Psi ; vi 2 buF ck
j < k ^ hj; \Psi ; vi 2 uF by Definition 3.2 (Approx)
j < k ^ hj; \Psi ; vi 2 F j+1? by definition of uF
j < k ^ hj; \Psi ; vi 2 bF j+1?cj+1 by Definition 3.2 (Approx)
j < k ^ hj; \Psi ; vi 2 bF k?cj+1 by Lemma 4.10
j < k ^ hj; \Psi ; vi 2 F k? by Definition 3.2 (Approx)
hj; \Psi ; vi 2 bF k?ck by Definition 3.2 (Approx)

(b) Each of the following sets is equivalent.

bF k+1?ck+1
bF (F k?)ck+1
bF (bF k?ck)ck+1 by well-foundedness of F
bF (buF ck)ck+1 by (a)
bF (uF )ck+1 by well-foundedness of F \Lambda 

Lemma 4.14
If F is well founded, buF ck = bF (uF )ck.

Proof: Each of the following sets is equivalent.

buF ck
bF k?ck by Lemma 4.13(a)
bF k+1?ck by Lemma 4.10
bbF k+1?ck+1ck by Lemma 4.12
bbF (uF )ck+1ck by Lemma 4.13(b)
bF (uF )ck by Lemma 4.12 \Lambda 

The lemmas for typing rules M-unfold and M-fold can now easily be proved.
Theorem 4.15 (Unfold and Fold)
If F is well founded, then uF = F (uF ). Hence, the typing rules for uF (M-unfold
and M-fold) hold for any well-founded functional F .

Proof: We have that hk; \Psi ; vi 2 uF iff hk; \Psi ; vi 2 buF ck+1 iff hk; \Psi ; vi 2
bF (uF )ck+1 iff hk; \Psi ; vi 2 F (uF ). \Lambda 

87

4.2.2 Union, Intersection, and Product Types
Union (or untagged sum) types of the form o/1 [ o/2 and intersection types o/1 " o/2
may be added to *M as follows. A value v has type o/1 [ o/2 for k steps with respect
to store typing \Psi  if v has type o/1 or if v has type o/2 for k steps with respect to \Psi .
Note that the "or" in the preceding sentence should not be interpreted as "exclusive
or" -- I am modeling non-disjoint union types here. Analogously, a value v has type
o/1 " o/2 for k steps with respect to store typing \Psi  if v has both type o/1 and type o/2
for k steps with respect to \Psi .

o/1 [ o/2 def= { hk; \Psi ; vi | hk; \Psi ; vi 2 o/1 . hk; \Psi ; vi 2 o/2 }
o/1 " o/2 def= { hk; \Psi ; vi | hk; \Psi ; vi 2 o/1 ^ hk; \Psi ; vi 2 o/2 }

Notice that both union and intersection types are nonexpansive but not well founded.

To add product types to *M , I extend the *M syntax shown in Figure 3.1 as
follows. Expressions e : : = : : : | he

1; e2i | ss1(e) | ss2(e)
Values v : : = : : : | hv1; v2i

A value hv1; v2i has type o/1 * o/2 for k steps with respect to store typing \Psi  if v1 and
v2 each have types o/1 and o/2 (respectively) for upto k - 1 steps with respect to the
appropriate approximation of \Psi .

o/1 * o/2 def= { hk; \Psi ; hv1; v2ii | 8j < k: hj; b\Psi cj; v1i 2 o/1 ^ hj; b\Psi cj; v2i 2 o/2 }
The typing rules for union, intersection, and product types are given in Figure 4.1.
The validity of the types defined in this section is easy to prove, as is the validity
of the typing rules shown in Figure 4.1. I shall omit the proofs here.

4.2.3 Singleton Types and Immutable References
A value v has singleton type S(v) (which identifies it exactly) for any number of
steps k and with respect to any store typing \Psi . The semantics of singleton types
is given below. (Notice the difference in fonts: S denotes a singleton type while S
denotes a store.)

S(v) def= { hk; \Psi ; vi }

Next, I extend *M with immutable reference types. The model of *I presented
in Section 2.2 supported immutable references by disallowing updates. The model
of *M , however, permits approximately type-preserving updates. Hence, to add
immutable references to *M I use a trick involving singleton types.

The first step is to extend the *M syntax with terms of the form inew(e) which
allocates an immutable reference cell initialized to the result of evaluating e. In

88

\Gamma  |=M e : o/1
\Gamma  |=M e : o/1 [ o/2 (M- [ i1)

\Gamma  |=M e : o/2
\Gamma  |=M e : o/1 [ o/2 (M- [ i2)

\Gamma  |=M e : o/1 [ o/2 \Gamma  [x 7! o/1] |=M e0 : o/ \Gamma  [x 7! o/2] |=M e0 : o/

\Gamma  |=M e0[e=x] : o/ (M- [ e)

\Gamma  |=M e : o/1 \Gamma  |=M e : o/2

\Gamma  |=M e : o/1 " o/2 (M- " i)

\Gamma  |=M e : o/1 " o/2

\Gamma  |=M e : o/1 (M- " e1)

\Gamma  |=M e : o/1 " o/2

\Gamma  |=M e : o/2 (M- " e2)

\Gamma  |=M e1 : o/1 \Gamma  |=M e2 : o/2

\Gamma  |=M he1; e2i : o/1 * o/2 (M-prod)

\Gamma  |=M e : o/1 * o/2

\Gamma  |=M ss1(e) : o/1 (M-fst)

\Gamma  |=M e : o/1 * o/2

\Gamma  |=M ss2(e) : o/2 (M-snd)

Figure 4.1: Union, Intersection, and Product Typing Rules
terms of the operational semantics, inew(e) is identical to new(e). However, they
are handled quite differently by the underlying semantic model. Recall the handling
of new: upon allocation of a mutable cell ` of type ref o/ , the *M semantics requires
that store typing \Psi  be extended with ` 7! bo/ ck (where k is the number of steps left
to execute). Meanwhile, the instruction inew is handled as follows: upon allocation
of an immutable cell ` of type box o/ , initialized to the value v (where v must have
type o/ to approximation k), the *M semantics requires that the store typing \Psi  be
extended with ` 7! bo/ " S(v)ck. Intuitively, the contents of cell ` must have the
type o/ as well as the type S(v) for the next k steps. This means that the program
is free to update the contents of cell ` but only with the exact value written into
the cell upon allocation. Hence, as required for an immutable reference cell, the
contents of ` remain unchanged. The semantics of immutable reference types is as
follows.

box o/ def= { hk; \Psi ; ` i | 9v: b\Psi ck = bo/ " S(v)ck }

Notice that the above definition requires only that there exist some value v such
that \Psi  (approximately) maps ` to o/ " S(v). As I informally explained above, that

89

value v should be equal to the contents of cell ` in the current store S . However,
the definition of box o/ cannot state this requirement because types do not have
access to the current store S -- they only have access to the current store typing \Psi .
Fortunately, the requirement is made explicit elsewhere in the model. Specifically,
given a current store S that is approximately well-typed with respect to store typing
\Psi  (see Definition 3.5 in Chapter 3, Section 3.3.5), it follows that S (`) must be equal
to v.2

Finally, I extend the set of *M typing rules in Figure 3.7 with the following
typing rules for box types. It is relatively straightforward to prove that box o/ is a
type and that the typing rules shown below are sound.

\Gamma  |=M e : o/
\Gamma  |=M inew(e) : box o/ (M-inew)

\Gamma  |=M e : box o/

\Gamma  |=M ! e : o/ (M-ideref)

One would expect box and ref to behave as immutable and mutable references
(respectively) are supposed to -- that is, box should be covariant and ref should be
neither covariant nor contravariant. These properties can be proved as lemmas.

4.3 Examples
In this section I shall present two program fragments and show how they can be
proved safe using the indexed model of *M . I shall assume that the compiler supplies
the typing derivation for each program. In each example, I shall assume that the
program (or program fragment) is well-typed with respect to some type environment
\Gamma 0, and that the expression erest (which denotes the rest of the program) is welltyped with respect to some type environment \Gamma rest , that is, \Gamma rest |=M erest : o/ 0 for
some type o/ 0.

4.3.1 Allocation, Update, and Aliases
I begin with a rather simple example. The program fragment shown below allocates
a new reference cell and initializes it with a pointer to an existing cell (pointed to
by variable x). Hence, x and ! y alias the same location -- let us call that location

2In our foundational PCC implementation, types are (roughly) sets of tuples of the form
hk; \Psi ; S ; vi -- that is, types have access to the store. Hence, the semantics of immutable reference types in our implementation is closer to the following:

box o/

def= { hk; \Psi ; S ; ` i | 9v: b\Psi c

k = bS(v)ck ^ 8j < k: hj; b\Psi cj; S ; S (`)i 2 bo/ck }

90

{ 9\Psi : x :k;\Psi  ref o/ ^ z :k;\Psi  o/ ^ S :k \Psi  }
let y = new(x) in
{ 9\Psi 0: x :k-1;\Psi 0 ref o/ ^ z :k-1;\Psi 0 o/ ^ y :k-1;\Psi 0 ref(ref o/ )

^ (k; \Psi ) v (k - 1; \Psi 0) ^ S 0 :k-1 \Psi 0 }
let = ! y := z in
{ 9\Psi 00: x :k-3;\Psi 00 ref o/ ^ z :k-3;\Psi 00 o/ ^ y :k-3;\Psi 00 ref(ref o/ )

^ (k - 1; \Psi 0) v (k - 3; \Psi 00) ^ S 00 :k-3 \Psi 00 }
erest

(a) Program fragment

200
201

x

202
203
204

S \Psi 

{200 a t ,

201 a ...,
202 a ... }

(b) Store S , where S :k \Psi 

y

200
201

x

202
203
204

S' \Psi '

{200 a t ,

201 a ...,
202 a ...,
203 a ref t }

(c) Store S 0, where S 0 :k-1 \Psi 0
Figure 4.2: Example 1: Allocation & Update in the Presence of Aliasing
`. The program then updates the contents of ` via the alias ! y.

% \Gamma 0 = { x : ref o/; z : o/ }

let y = new(x) in
% \Gamma 1 = { x : ref o/; z : o/; y : ref(ref o/ ) }

let = ! y := z in
% \Gamma rest = { x : ref o/; z : o/; y : ref(ref o/ ) }

erest

91

The assignment to ! y is safe because it is approximately type-preserving: ! y has
type ref o/ and the program updates it with a value of type o/ . The assignment has
no effect on the type of x which remains unchanged. Proving the program safe
amounts to proving each of the Hoare triples in the program fragment shown in
Figure 4.2(a) for all k >= 0.3 In the program fragment (Figure 4.2(a)), S is any
store that satisfies some initial store typing \Psi  such that x and z have the types
ref o/ and o/ (to approximation k) with respect to \Psi . Stores S 0 and S 00 denote the
stores obtained by evaluating, respectively, new(x) in store S and ! y := z in S 0.
Figures 4.2(b) and 4.2(c) illustrate the stores S and S 0 which are approximately
well-typed with respect to store typings \Psi  and \Psi 0 respectively; unallocated store
cells are shaded. Using the indexed model of *M that I have presented, one can
prove the validity of each of the Hoare triples in Figure 4.2(a). The program is safe
for any number of steps because the proof holds for all k >= 0.

4.3.2 Cycles in Memory
The *M model can handle cycles in the memory graph as I shall now illustrate.
Consider the following program which creates a reference cell initialized to true,
binds the new cell to variable x, and then, creates a cycle in memory by assigning
x to itself. Figure 4.3 illustrates the store before and after the assignment x := x.

% \Gamma 0 = : : :

let x = new(true) in
% \Gamma 1 = : : :

let = x := x in
% \Gamma rest = : : :

erest

What should \Gamma 0, \Gamma 1, and \Gamma rest be? From the code above, it looks like \Gamma 1 should map
x to ref bool; but in that case, the assignment x := x will not type check since it
assigns a value of type ref bool to a reference cell that should contain a value of type
bool. To show that the above program safely creates a cyclic data structure, one
either need recursive types or impredicative quantified types. I will first describe a
solution that makes use of recursive types (which I introduced in Section 4.2.1) and
then one that uses impredicative existential types.

3The approximation indices used in each of the invariants in Figure 4.2(a) indicate the number
of steps left to execute at each point. The last invariant uses approximation index k - 3 rather
than k - 2 because the preceding instruction uses up one step to dereference y and another step
to assign z to the result of the dereference.

92

100
101

x true

(a) Before: S :k \Psi 

100
101

x

(b) After: S 0 :k-1 \Psi 0
Figure 4.3: Example 2: Creating a Cycle in the Store
Cycles using Recursive Types Suppose that the compiler provides us with a
typing derivation such that \Gamma 0 is the empty type environment and \Gamma 1 = \Gamma rest =
{ x : ref(uF ) }, where F denotes the type function *ff: (bool [ ref ff). (Notice that
F is well founded by Lemma 3.11, intuitively, since the only occurrence of the type
variable ff is composed with the well-founded type constructor ref.) I show parts
of the typing derivation below. The following subtree of the derivation establishes
that that new(true) has type ref(uF ), where F denotes *ff: (bool [ ref ff). Hence,
we pick \Gamma 1 = { ref(uF ) }.

; |=M true : bool (M-true)
; |=M true : (bool [ ref (uF )) = F (uF ) (M- [ i1)

; |=M true : uF (M-fold)
; |=M new(true) : ref(uF ) (M-new)

The following sub-derivation shows that x := x is well-typed with respect to type
environment \Gamma 1 = { x : ref(uF ) }. Note that since F = *ff: (bool [ ref ff), we have
F (uF ) = bool [ ref(uF ).

\Gamma 1 |=M x : ref(uF ) (M-var)
\Gamma 1 |=M x : ref(F (uF )) (uF = F (uF ))
\Gamma 1 |=M x : ref(bool [ ref(uF ))

\Gamma 1 |=M x : ref(uF ) (M-var)
\Gamma 1 |=M x : bool [ ref(uF ) (M- [ i2)
\Gamma 1 |=M x := x : unit (M-assign)

Given the typing derivation described above, to prove that the program is safe
amounts to proving each of the Hoare triples in the program fragment given below.
The store S0 is the initial store, while S and S 0 denote the stores obtained by
evaluating, respectively, x = new(true) in store S0 and x := x in store S . Stores S

93

and S 0 are shown in Figure 4.3.

{ 9\Psi 0: S0 :k \Psi 0 }
let x = new(true) in
{ 9\Psi : x :k-1;\Psi  ref(uF ) ^ (k; \Psi 0) v (k - 1; \Psi ) ^ S :k-1 \Psi  }
let = x := x in
{ 9\Psi 0: x :k-2;\Psi 0 ref(uF ) ^ (k - 1; \Psi ) v (k - 2; \Psi 0) ^ S 0 :k-2 \Psi 0 }
erest

To prove the above Hoare triples, assume S0 is an arbitrary initial store and that
the address of the new cell is some location ` =2 dom(S0) -- in Figure 4.3, ` = 100.
Then S = S0 [` 7! true] and S 0 = S [` 7! ` ]. Let \Psi 0 be the empty store typing.
Pick \Psi  such that b\Psi ck-1 = { ` 7! buF ck-1 } and let \Psi 0 = b\Psi ck-2.

Cycles using Impredicative Existential Types We can handle cycles in the
store even without recursive types because *M supports impredicative quantified
types. This explains why the semantic model of *M presented in Chapter 3 did not
need to be altered or strengthened in any way in order to accommodate recursive
types in Section 4.2.1.

In the absence of recursive types, the compiler generates a typing derivation
such that \Gamma 0 is the empty type environment and \Gamma 1 = \Gamma rest = { x : 9F }, where the
type function *ff: ref(bool [ ff). (Notice that F is well founded by Lemma 3.11,
informally, since the nonexpansive type function bool [ ff is composed with the wellfounded type constructor ref.) The compiler also inserts pack and unpack coercions
into the original program to facilitate type checking. All coercions are erased prior
to execution, that is, once we have proved the program safe. The modified program
is as follows.

let x = pack (new(true)) in
% \Gamma  = { x : 9F }

let = (unpack x as z in z := x) in
% \Gamma rest = { x : 9F }

erest

Parts of the typing derivation are shown below. The following subtree of the
derivation establishes that pack (new(true)) is an existential package of type 9F
and that the witness type is also 9F -- that is, we are taking advantage of the
impredicativity of our existential types. Note that since F denotes *ff: ref(bool [ ff),
we have F (9F ) = ref(bool [ 9F ).

94

type(9F )

; |=M true : bool (M-true)
; |=M true : bool [ 9F (M- [ i1)
; |=M new(true) : ref(bool [ 9F ) (M-new)

; |=M new(true) : F (9F )
; |=M pack (new(true)) : 9F (M-pack)

The following sub-derivation shows that unpack x as z in z := x is well-typed with
respect to type environment \Gamma 1 = { x : 9F }. I've used \Gamma 0 as an abbreviation for
\Gamma 1 [z 7! F (9F )].

\Gamma 1 |=M x : 9F

\Gamma 0 |=M z : ref(bool [ 9F ) (M-var)

\Gamma 0 |=M x : 9F (M-var)
\Gamma 0 |=M z : bool [ 9F (M- [ i2)

\Gamma 1 [z 7! F (9F )] |=M z := x : unit where type(9F ) (M-assign)
\Gamma 1 |=M unpack x as z in z := x : unit (M-unpack)

Given the program and typing derivation I've just described, proving the program safe amounts to proving each of the Hoare triples in the program fragment
given below. The store S0 is the initial store, while S and S 0 denote the stores obtained by evaluating, respectively, x = new(true) in store S0 and unpack x as z in z :=
x in store S . Stores S and S 0 are shown in Figure 4.3 as before.

{ 9\Psi 0: S0 :k \Psi 0 }
let x = pack (new(true)) in
{ 9\Psi : x :k-1;\Psi  9F ^ (k; \Psi 0) v (k - 1; \Psi ) ^ S :k-1 \Psi  }
let = (unpack x as z in z := x) in
{ 9\Psi 0: x :k-2;\Psi 0 9F ^ (k - 1; \Psi ) v (k - 2; \Psi 0) ^ S 0 :k-2 \Psi 0 }
erest

To prove the above Hoare triples, assume S0 is an arbitrary initial store and that
the new cell is some ` =2 dom(S0); let ` = 100 as we had before in Figure 4.3. Also,
as before, S = S0 [` 7! true] and S 0 = S [` 7! ` ]. Let \Psi 0 be the empty store typing.
Finally, pick \Psi  such that b\Psi ck-1 = { ` 7! bbool [ 9F ck-1 } and let \Psi 0 = b\Psi ck-2.

It is important to note that we choose \Psi  such that b\Psi ck-1(`) = bbool [ 9F ck-1,
rather than, say, bbool [ ffck-1. The latter would be incorrect since mutable references should only store values of closed type. Hence, in this case, when we allocate
the reference cell, we substitute the witness type for ff. One crucial consequence
of this is that our model does not permit the witness type of existentials of the
form 9ff: (: : : ref (: : : ff : : :) : : :) to be changed by future updates. Languages that fail
to ensure that the witness types of such existentials never change usually run into

95

let val z = ref (fn x:'a => x) in

(z := (fn x => x + 1);

(!z) true) (* error *)

Figure 4.4: Polymorphic References: SML Program
unsoundness in the presence of aliasing. Grossman [Gro02] encountered precisely
this problem in Cyclone.

4.4 Discussion and Related Work
Mutable references are notorious for making life difficult for semanticists, type theorists, and language designers. In this section, I'll describe some of the problems
that arise in the presence of mutable references, and discuss how these problems are
dealt with in the indexed possible-worlds model, as well as in related work. I start,
however, by pointing out a limitation of the semantic model that I've presented.

4.4.1 Limitation: Type Functions
The semantics that I have described models quantified types 8F and 9F (Section 3.3), as well as recursive types uF (Section 4.2.1), where F is a type function.
A limitation of this semantics is that it does not allow us to express arbitrarily
nested recursive and quantified types such as the following:

9(*ff:ref(u(*fi:(ref fi) [ ff)))
In the above type, the recursive type cannot be written in the form uF since F is a
single-argument type function while the type expression inside the u refers to two
variables: fi, which is bound by u itself, and ff, which is bound by the existential.
Swadi [Swa03] shows how best to handle type expressions (i.e., multi-argument
type functions) and variables in our semantic approach. The solution is to use de
Bruijn indices as we have done in the von Neumann model that we've built for our
foundational PCC system (see Chapter 6).

4.4.2 Mixing Mutation and Quantified Types
Mutable references and quantified types often interact in subtle ways leading to
unsoundness. A well-known example is the problem of polymorphic references in
ML [Tof90] which is illustrated by the SML code shown in Figure 4.4. In ML, value

96

% \Gamma 0 = ;

let z = \Lambda : new(*x:x) in
% \Gamma 1 = { z : 8F } (where F = *ff: ref (ff ! ff))

let = z[ ] := *x: x + 1 in
% \Gamma 2 = { z : 8F } (where F = *ff: ref (ff ! ff))

( ! (z[ ]) ) true

Figure 4.5: Polymorphic References: *M Program
bindings are considered the basic units of type inference for which all ambiguity
must be resolved before type checking continues. Hence, for the code shown in
Figure 4.4, ML type inference gives z the type 8ff: ref (ff ! ff). With this type
ascribed to z, the type checker decides that the body of the let expression is welltyped, when in fact, it clearly violates type safety: it updates z with a function of
type int ! int and then applies z's contents to a value of type bool.

To ensure type safety in the presence of polymorphism and mutation, ML designers adopted the following restriction. Variables introduced by a val binding
are allowed to be polymorphic only if the right-hand side is a value. This is called
the value restriction on polymorphic declarations. The value restriction is a clever
yet simple way to rule out types like 8ff: ref (ff ! ff) by exploiting the fact that
expressions of such types cannot be values in ML. Although it is at the expense of
some expressiveness in the language, the value restriction achieves the desired goal
which is to ensure that contents of mutable references always have closed types.

Type inference isn't needed in a target language for type-preserving compilation
of ML since the compiler is expected to produce a target program with type annotations. Hence, in *M there is no need for constraints such as the value restriction.
We simply require that all types in the codomain of the store typing \Psi  be closed
types (as specified in Section 3.2.2). The tricky part is deciding, for each location
`, what closed type to add to the store typing when the type of pack ` is of the
form 9ff: ref (: : : ff : : :) or the type of \Lambda :new(e) is of the form 8ff: ref (: : : ff : : :) (where
new(e) eventually allocates `). I'll address this issue below with the help of some
examples.

Polymorphic References Unlike ML expressions of types such as 8ff: ref (ff !
ff), *M expressions of such types can be values. For example, the type abstraction
\Lambda : new(*x:x) is a value and has type 8ff: ref (ff ! ff). Let us consider the *M
program shown in Figure 4.5 which resembles the SML program in Figure 4.4 in
that it binds the variable z to a polymorphic reference of type 8ff: ref (ff ! ff), then

97

assigns the function *x: x + 1 to z, and then applies the contents of z to true. In
the *M program, notice that the variable z is bound to a value, but that value is
not a location (as the SML programmer expects), but rather a type abstraction. A
program that assigns to or dereferences a type abstraction will not type check, but
this *M program does type check because I have inserted type application coercions
z[ ] at appropriate points in the code to coerce z into a mutable reference that may
be updated or dereferenced. The important thing to note is that the program in
Figure 4.5 is safe. This is because evaluation of the program proceeds as follows.

* The expression z[ ] := *x: x + 1 first allocates a new cell `1 initialized to *x:x

-- the type of `1 is recorded in the store typing as (some approximation of)
int ! int -- and then updates cell `1 with the function *x: x + 1.

* The expression ( ! (z[ ]) ) true allocates a second new cell `2 initialized to *x:x

-- the type of `2 is recorded in the store typing as (some approximation of)
bool ! bool -- and then dereferences `2 and applies the result to true.

Hence, unlike the SML program, the *M program allocates two separate locations
`1 and `2. Since a *M store typing cannot map `1 and `2 to the open type ff ! ff,
we must determine what types to instantiate ff with. The typing derivation tells
us that the first coercion z[ ] effectively applies z to the type int while the second
applies z to the type bool. Hence, at the first allocation point, we close the open
type ff ! ff by instantiating ff with the closed type int and extend the store typing
so that it maps `1 to the closed type int ! int. Similarly, at the second allocation
point we close type ff ! ff by instantiating ff with bool and extend the store typing
so that it maps `2 to the closed type bool ! bool.

Storing Universal Types in Mutable Cells Consider again the SML program
shown in Figure 4.4 and this time assume that the variable z is given the type
ref (8ff: ff ! ff). The SML type checker now comes to a different conclusion about
well-typedness of the body of the let expression. Specifically, the assignment to z
(which updates z with a function of type int ! int) does not type check and the
program is (rightly) rejected.

A comparable program in *M might be as follows. Note that z has type
ref (8ff: ff ! ff) and that this program is also ill-typed.

let z = new(\Lambda : *x:x) in
let = z := \Lambda : (*x: x + 1) in
(! z)[ ] true

The expression new(\Lambda : *x:x) allocates a new location ` and binds ` to z. The store
typing is extended to map ` to (some approximation of) the type 8ff: ff ! ff. Thus,

98

the subsequent assignment to ` of a value of type 8ff: int ! int is not permitted by
the model which ensures that only values of type 8ff: ff ! ff may be assigned to `.

In a functional setting the only value that has type 8ff: (ff ! ff) is the polymorphic identity function [Wad89]. However, since mutation breaks parametricity, in a
language with mutable references any number of functions with varying side-effects
may have this type, as long as the function argument x is returned without ever
being used in a context where safety is contingent upon x having a particular type.

Abstract References Consider the value pack ` of type 9ff: ref (ff ! ff) and let
o/ be the witness type for pack `. The store typing cannot map ` to the open type
ff ! ff, so we close the latter by instantiating ff with the existential's witness type
o/ . Hence, upon allocation of cell `, we extend the store typing to map ` to (some
approximation of) the closed type o/ ! o/ .4 This implies that cell ` may only be
updated with functions of type o/ ! o/ -- that is, the witness type of the existential
must remain unchanged.

For mutable reference types of the form ref (: : : ff : : :) when the existential that
binds ff occurs outside the ref, changing the witness type of the existential amounts
to changing the type of the contents of the reference cell -- i.e., it violates the type
invariance principle. Changing the type of the contents of the reference cell may be
unsafe because *M permits aliases to the unpacked mutable cell ` and these aliases
have type ref (: : : o/ : : :) (where o/ is the witness type). By ensuring that the witness
types of such abstract references never change, the semantic model of *M ensures
type invariance and ultimately type safety.

Grossman [Gro02] encountered the above problem in an earlier version of Cyclone. Cyclone's support for mutation of existentials permits changes in witness
types, while its reference patterns allow the fields of existentials to be aliased. The
combination of these features results in unsoundness. Nonetheless, each feature is
safe on its own. In particular, mutation of existentials may violate type invariance,
but such mutations are type safe as long as there are no aliases to the fields of the
existentials.

Finally, note that even in a language that adheres to the type invariance principle, it is safe to change the witness type of an existential package that has a type
like 9ff: (ref int) * ff. The change has no effect on the type of the reference cell inside
the existential.

Storing Existential Types in Mutable Cells Thus far I have only discussed
types where ref occurs inside an existential. I shall now consider types where an
existential occurs inside ref. In each of the following examples it is safe to change
an existential's witness type.

4Section 4.3.2 describes another example that allocates a cell of type 9ff: ref (: : : ff : : :).

99

* Consider a location ` of type ref (9ff:ff * ff). The store typing maps ` to (some

approximation of) the closed type 9ff: ff * ff. Therefore, the model permits `
to contain a value v = pack h3; 5i with witness type int and subsequently, also
allows ` to be updated with the value v0 = pack htrue; falsei whose witness
type is bool.

* Suppose that a location ` has type ref (9ff: ff ! (ref bool)). The store typing

maps ` to 9ff: ff ! (ref bool) so one can safely update ` with a function of
type bool ! (ref bool) or with a function of type (ref int) ! (ref bool) and so
on.

4.4.3 Shared References and Monotonicity
I've described how to model a language that deals with the problem of shared references (aliasing) by adopting the type invariance principle I specified in Chapter 1.
By disallowing strong updates, this principle ensures that the types of all allocated
locations are preserved, and type preservation ensures monotonicity. As for *I (see
Section 2.2.5), in order to establish safety, we need to prove that our model of *M
is Kripke monotone. Informally, the proof follows from the fact that monotonicity
over the course of evaluation plays a central role at every layer of our model. Suppose that \Psi  is the current store typing and \Psi 0 is some possible future store typing.
The lowest layer of the model specifies that if ` maps to o/ in state (k; \Psi ) then `
maps to bo/ cj in state (j; \Psi 0). This is captured by valid state extension (v) which
establishes the monotonicity of states.

The next layer of the model shows that if hk; \Psi ; vi 2 o/ then hj; \Psi 0; vi 2 o/ . For
each type o/ , we prove the monotonicity of sets of values of that type as we use up
execution steps. To prove this property (specified as type(o/ )) we must rely on the
monotonicity of states.

The next layer establishes type preservation, that is, if e has type o/ with respect
to (k; \Psi ) where S :k \Psi , and we reach machine state (S 0; e0) where S 0 :j \Psi 0, then e0
has type o/ with respect (j; \Psi 0). This corresponds precisely to Kripke monotonicity.
We prove the monotonicity (over the course of evaluation) of sets of expressions of
each type. The proof relies on the monotonicity of sets of values of each type.

Hence, in *M we ultimately rely on approximately type-preserving updates and
the absence of cell deallocation to establish monotonicity at each "layer" of the
model. This monotonicity guarantee lies at the heart of why the mutation of shared
references does not violate safety.

4.4.4 Coinduction and Non-wellfounded Sets
The circularity I described in Section 3.2.3 can be dealt with without constructing
an indexed model -- that is, one can construct a possible-worlds model (of general

100

references) that is not stratified. To see how, let us consider the nature of possibleworlds. Peregrin's [Per93] analysis concludes that "a possible world in the intuitive
sense can be explicated as a maximal consistent class of statements". Thus, to
give the semantics of seemingly circular possible worlds one can use techniques like
coinduction [Par69, MT91b, BM96] or non-wellfounded sets [Acz88].

It may be argued that using coinduction or non-wellfounded sets would be simpler than constructing a stratified model of types. I believe, however, that while
the use of coinductive techniques may seem to simplify pencil-and-paper proofs, it
is unlikely to lead to simpler machine-checked proofs, and in fact, it would increase
the size of the trusted computing base. To see why, let us look at what the use
of coinduction entails. One way to incorporate coinduction would be to add the
Anti-Foundation Axiom (AFA) described by Aczel [Acz88] to the trusted computing base. Then we could use it to conclude that the circularity or lack of wellfounded
sets does not imply inconsistency. Aczel's formulation of the AFA is particularly
problematic5 because it is based on graphs. To specify the AFA (i.e., to add it
to the TCB) we would first need to be able to represent graphs; hence, we would
essentially have to add graphs to the TCB. Since one of the goals of the Princeton
Foundational PCC project is to minimize the trusted computing base, we have chosen not to use coinduction. In this thesis, I have shown how coinduction may be
avoided in our semantics by showing how the possible worlds may be stratified.

4.4.5 Possible-Worlds Models
A common feature of a number of models of mutable state (also called mutable store
in the literature) is that they specify how the state is allowed to vary over time --
that is, they are possible-worlds models. Models for Idealized Algol developed by
Reynolds and Oles [Rey81, Ole82, Ole85, Ole97] make use of functor categories;
functors are important because they capture the fact that the size of the store, as
well as its contents, may change over time. To specify how the state is allowed to
change at any point in the program, they use functor categories indexed by possible
worlds or store shapes. Note that these models do not handle general references.
Stark [Sta94] (building on work done with Pitts on possible-worlds models of the nucalculus [PS93]) describes a denotational semantics for Reduced ML that supports
integer references.

More recently, Levy [Lev01, Lev02] described a possible-worlds model that supports general references, but not quantified types. There are interesting correspondences between Levy's model and mine. His world-store (w; s), where w is a world
and s is a w-store, (i.e., each location in s is well-typed with respect to w) corresponds to a well-typed store S :k \Psi  in my model. His accessibility relation between

5There are other formulations of AFA which I have not considered (see Barwise and
Moss [BM96]).

101

worlds resembles state extension (v) in my model. His model has the property: "if
w <= w0 then every wo/ -value is a w0o/ -value (where wo/ -value denotes a value of type
o/ in world w); this corresponds to type(o/ ) in my model. The definition (denotation
to be more precise) of the type ref o/ in his model is: [[ref o/ ]]w = $wo/ (where $wo/
denotes "the set of cells of type o/ in w"). Notice that [[ref o/ ]] is defined in terms of
the syntax o/ rather than the semantics [[o/ ]]. Levy is faced with the same kind of
circularity that I described in Section 3.2.3. He solves it by observing that recursive
equations on domains have solutions. I solve it by showing that the hierarchy of
type approximations has a limit.

An important difference between Levy's work and mine is that while his semantics makes use of complicated mathematics (functor categories, for instance), mine
is based on the operational semantics of the language and requires only sets and
induction.

Benefit of Possible-Worlds Semantics I modeled types in *I as predicates on
stores S and values v. Let us compare this to the traditional Strachey approach
where types are modeled as sets of values. In such a model, a reference type box o/
is defined simply as Loc, the set of all locations `. This means that the semantics of
type box o/ does not guarantee that a location ` 2 box o/ is an allocated location. As a
result, the *I typing rule for dereferencing cannot be proved sound. Similarly, using
a semantics where *M types are modeled as sets of values, one cannot validate the
*M typing rules for dereferencing and assignment. Intuitively, this is due to the fact
that these rules rely on the intuition that memory access works locally. Suppose,
for instance, that we have a program eprog that allocates a number of cells over the
course of execution; let ! e1 be a subexpression of eprog. Regardless of the number of
cells allocated by the program, if one knows that e1 has type ref o/ then one should
be able to dereference e1 and get a value of type o/ -- we've seen that the typing
rule for dereferencing relies on this intuition.

More generally, program components often work with circumscribed collections
of resources. Possible-worlds semantics allows us to identify the resources of interest
in the worlds (stores or store typings) and to prove the soundness of typing rules
that would not otherwise be sound. This is because these rules work locally, in
that they do not explicitly keep track of all resources not altered by a program
component.

Without possible-worlds semantics, we could still prove the soundness of more
global typing rules that keep track of the whole store -- for instance, the typing
judgments could be augmented with store typings that track the set of allocated
locations and their types. But the local typing rules that we've used for *I and *M
are much simpler, and reasoning with them leads to type derivations (and hence,
proofs) that are more manageable in terms of both size and complexity.

Notice that Hoare logic rules, rely on the same intuition (i.e., the intuition that

102

memory access works locally) as our *I and *M typing rules. Hoare logic rules
describe only those resources that are altered by a program component -- it is
assumed that any resource not mentioned by the Hoare logic rule is unchanged.
Possible-worlds semantics is then the key to proving the soundness of such rules.

Others have used possible-worlds semantics to model languages with mutable
state but, for the most part, they haven't proved any technical results showing what
one gains from using possible-worlds semantics. Reynolds and Oles [Rey81, Ole82,
Ole85, Ole97] showed (intuitively) that their possible-worlds models of Idealized
Algol were more faithful to the stack discipline of Algol than traditional Strachey
semantics. Levy [Lev02] argued that Strachey semantics did not effectively capture
the semantics of references in a language with dynamic allocation. He did not,
however, demonstrate any concrete benefit of his model, whereas I have proved the
soundness of typing rules that cannot otherwise be validated.

4.4.6 Game Semantics
Hintikka [Hin75] advocated the use of game-theoretical semantics to model possible
worlds. Game semantics is especially useful in removing from consideration all
impossible possible worlds. Abramsky, Honda and McCusker[AHM98] describe a
game semantics of general references that they show to be fully abstract. In this
model, reference types are modeled by their behavior, or more specifically as a
product of a "read method" and a "write method" in the style of Reynolds [Rey81].
This representation of references is quite different from that in location-based models
such as the one presented in this thesis. It would be interesting to see if such a model
could be incorporated into a foundational PCC system. While Abramsky et al.'s
model does not support quantified types, Hughes [Hug97] has presented a games
model of System F. It would be useful to investigate whether Hughes' model of
System F can be incorporated into Abramsky et al.'s model of mutable references.

4.4.7 Other Related Work
The use of a store typing that maps locations to types is not new. Tofte [Tof90]
uses this approach in his type soundness proof for polymorphic references. Tofte,
however, makes use of coinduction to handle cycles in the memory graph. Harper
[Har96] has shown how a progress-and-preservation proof can be arranged so that
there is no need for coinduction. The model I've presented can handle cycles in
memory by virtue of the index k. For a reference to a memory cycle to be welltyped, one only needs to know that it is well-typed to approximation k. With each
memory dereference the k decreases. Hence, there is no need for coinduction.

Logical relations based on an operational semantics (or denotational-operational
models, as I have called them) have been used by others for reasoning about equiva103

lence of terms. Wand and Sullivan [WS97] describe a denotational semantics based
on an operational term model and use the approach for proving the correctness
of program transformations in a Scheme compiler. Pitts [Pit02] has made use of
operationally-based logical relations to reason about the equivalence of programs
written in a fragment of ML. Recently, Pitts has also shown how to handle existential types [Pit98] and parametric polymorphism [Pit00], but always in the absence
of general references and recursive datatypes. I shall have more to say about this
line of work in Section 8.1.

104
Chapter 5
Machine-Checked Proofs
A foundational proof-carrying code system demands that all proofs of safety be
machine-checkable. This chapter looks at how foundational proofs of safety may be
mechanized. For the prototype FPCC system we are building at Princeton, we have
constructed machine-checked safety proofs based on models of types for von Neumann machines. In this chapter, to keep the presentation simple, I shall describe
how to mechanize safety proofs based on models of types for the *-calculus. Specifically, I shall focus on machine-checked proofs for *M (the polymorphic *-calculus
with references and existentials from Chapter 3) with recursive types (Section 4.2.1).

One may choose to represent the proof in any one of a variety of logics. In Section 5.1 I'll explain how to encode the semantics of *M in the Calculus of Inductive
Constructions (CiC) [CH88, PM93] as that is the logic most suited to modeling the
*M type hierarchy. In Section 5.2 I'll explain how to formulate a solution in higherorder logic. For our prototype FPCC system, we have built machine-checked proofs
in higher-order logic represented in LF [HHP93] and type-checked by Twelf [PS99].
Note: The CiC encoding I present in Section 5.1 is due to Roberto Virga. The
representation function I describe in Section 5.2.3 was defined and implemented by
Roberto Virga; definition and proofs of the representation function were automated
by Roberto Virga and Xinming Ou.

5.1 Representation in CiC
As I explained in Chapter 3 (Section 3.3.2), all definitions in the semantics of *M
are carefully constructed to obey the stratification invariant which says that when
considering a tuple hk; \Psi ; vi the store typing \Psi  is not required to be defined beyond
b\Psi ck. Hence, types in *M form a set that can be constructed using the recursively

105

Fixpoint itype [k : nat] : Type :=

Cases k

of O => UnitT

| (S k') => (prodT (itype k')

((location -> (itype k'))

-> exp -> Prop))
end.

Definition istoretype [k : nat] : Type :=

location -> (itype k).

Definition type: Type := (k: nat) (itype k).

Figure 5.1: CiC: Definition of Type Hierarchy
defined sets Typek and StoreTypek as follows.

o/ 2 Type0 iff o/ = {}
o/ 2 Typek+1 iff 8 hj; \Psi ; vi 2 o/: j <= k ^ \Psi  2 StoreTypej

\Psi  2 StoreTypek iff 8` 2 dom(\Psi ): \Psi (`) 2 Typek
o/ 2 Type iff 8k: bo/ ck 2 Typek:

The Calculus of Inductive Constructions (CiC) [CH88, PM93], upon which the
Coq system [BBC+98] is based, can represent the above definitions quite directly.
The CiC encoding is shown in Figure 5.1. Each set Typek is modeled using a product
type (itype k) in CiC. More specifically, Type0 is modeled by the unit type UnitT,
while Typek+1 is given by the product of the representation of Typek and the set of
membership functions for pairs h\Psi ; vi, where \Psi  has type (istoretype k).

It is straightforward to obtain the k-th approximation of a type (bo/ ck): given an
object tau of type type, its k-th approximation will correspond to the application
(tau k). To check that a triple hk; \Psi ; vi is in tau, one needs to apply tau to k + 1,
and take the second component as follows.

(sndT (tau (S k)) Psi v) : Prop
The definition of the types and type constructors presented in Figure 3.6 can
be given by recursion on the natural numbers. At each step, one has to construct
an object of type (itype k). The case k = 0 is trivial, since IT (which has type
UnitT) is the only object belonging to (itype 0). For the case k + 1, one only has
to provide a formula that decides which tuples hk; \Psi ; vi belong to the type.

106

Definition refTy [tau : type] : type :=

(nat_rect itype IT

([k : nat][tauk : (itype k)]

(pairT tauk

([psi: (istoretype k)][v: exp]

(Ex [l : location]

(v = (loc l))
/\
(eqT (itype k) (psi l) (tau k))))))).

Figure 5.2: CiC: Definition of ref
Figure 5.2 illustrates the representation of the type constructor for mutable references. (The reader may want to compare this to the definition of ref in Figure 3.6.)

The predicate istore welltyped models the relation S :k \Psi  and is defined in
Figure 5.3. The definition relies on the function

istoretype_aprx : (k,j:nat)

(lt j k) -> (istoretype k)

-> (istoretype j)

which is used to "lower" an approximation to the correct index. It is straightforward
to define istoretype aprx in Coq.

The *M operational semantics and the remaining semantic definitions can be
similarly encoded in CiC.

Proof Checker and TCB I mentioned in Chapter 1 that one of the goals of
the Foundational PCC project at Princeton is to minimize the size of the trusted
computing base. Hence, in choosing a logic in which to encode our proofs, we must
take into account the size of the proof checker (which is a trusted component). One
drawback of representing the proofs in CiC is that existing CiC checkers are very
large and complex programs. In the foundational PCC project, we encode proofs
in higher-order logic represented in the LF metalogic [HHP93]. The minimal LF
checker that we have developed1 is at least an order of magnitude smaller than
existing CiC checkers.

1We use the Twelf checker during proof development, but it is hardly a minimal checker. Since
minimizing the size of the TCB is a central goal of our project, we have developed our own minimal
LF checker [AMSV02, WAS03].

107

Definition istore_welltyped [k : nat; psi : (istoretype k);

s : store] : Prop :=
(All [j : nat]
(All [l : location]
(All [v : exp]

(h : (lt j k))
((s l) = (Some exp v)

-> (ExT [psi' : (istoretype j)]

(eqT (istoretype j) (istoretype_aprx k j h psi) psi')
/\
((sndT (psi l)) psi' v)))))).

Figure 5.3: CiC: Definition of S :k \Psi 
5.2 Representation in Higher-Order Logic
In the foundational PCC system we are building at Princeton, proofs are encoded in
higher-order logic. Unfortunately, higher-order logic does not provide as convenient
a mechanism as CiC for making stratified metalogical types. As I shall explain, in
effect, we must construct the stratification ourselves.

Consider the recursively defined sets Typek and StoreTypek from the previous
section (page 5.1). The metalogical types of these sets may be written as follows.

Type0 = Unit
StoreTypek = Loc fin! Typek
Typek+1 = Nat * StoreTypek * Val ! o
Type = Typei where i >= 0

The stratified metalogical types above cannot be described using higher-order logic.
We need a single type of Type, not an infinite number of them.

5.2.1 A Hierarchy of G"odel Numberings
To achieve a single type of Type, I present a solution that replaces the (semantic)
type (Typek) in the store typing with its syntax, that is, with a type expression t (of
type TyExp). A type expression t should uniquely identify a type o/ -- that is, a type
expression may be thought of as the G"odel number of a type. Instead of encoding
these G"odel numbers using integers, I will use finite trees of natural numbers (though
a proof implementor is free to choose any other way of representing G"odel numbers).

108

Replacing types with type syntax in the store typing flattens out our type hierarchy, but now we need a way to map the type expressions t to the semantic types
(of metalogical type Typek) that they represent. One could try (unsuccessfully) to
accomplish this by constructing a G"odel-numbering function G that is a mapping
from type expressions t to all of the types o/ that can be constructed using the *M
type constructors. Unfortunately, the definitions of some of these type constructors
will need to refer to G, leading to a circularity -- for instance, the definition of
ref o/ (see Figure 3.6) will need to refer to G in order to relate the type expression
t = \Psi (`) to some type o/ 0 (i.e., G(t) = o/ 0) so that it can then check if bo/ 0ck = bo/ ck.
I resolve this circularity by constructing a hierarchy of G"odel numbering functions
Gk; the semantics of types at one level of the hierarchy (e.g., types in the codomain
of Gk) can make use of lower levels of the G"odel numbering function (i.e., any Gj
such that j < k). There are a number of subtleties that arise, as we shall see below.

The metalogical types (in higher-order logic) of what I will construct are given
below. Val v is a *M value; Loc ` is an addressable store location; Store S is a store;
TyExp t is a G"odel number (or type expression, or type syntax) which I encode as
a tree of natural numbers; StoreType \Psi  is a store typing, but in this model it maps
locations to type expressions instead of types; Type o/ is a set of triples, as before;
Rep j is a representation function (or G"odel numbering function) that maps G"odel
numbers to types.

Val = the type of *M values
Loc = Nat

Store = Loc fin! Exp
TyExp = Tree(Nat )

StoreType = Loc fin! TyExp
Type = Nat * StoreType * Val ! o
Rep = TyExp ! Type

I use the terms "representation function" and "G"odel-numbering function" interchangeably. Some of the notation (related to representation functions) that I
will use is as follows: G denotes the stratified G"odel numbering function that I will
construct; Gk (where k >= 0) denotes the k-th level of the stratified G"odel numbering
function G; the variable j denotes an arbitrary representation function. Their types
will always be as shown below.

G : Nat ! Rep
Gk : Rep
j : Rep

109

Definition 5.1 (Approx)
We define bo/ ck as before. However, since now store typings map locations into type
expressions, we need to parametrize the approximation of a store typing with respect
to a representation function:

b\Psi cj;k def= { ` 7! bj(t)ck | \Psi (`) = t }
Note that the metalogical type of b\Psi cj;k is Loc ! Type, which is different than the
metalogical type of \Psi .

All the definitions given in Section 3.3 follow through, but need to be parametrized by j as well.

Definition 5.2 (State Extension)
A valid state extension is defined as follows:

(k; \Psi ) vj (j; \Psi 0) def= j <= k ^ (8` 2 dom(\Psi ): b\Psi 0cj;j(`) = b\Psi cj;j(`))

Definition 5.3 (Type)
A type is a set o/ of tuples of the form hk; \Psi ; vi where k >= 0 and where the set o/ is
closed under state extension; that is,

typej(o/ ) def= 8k; j; \Psi ; \Psi 0; v:

(hk; \Psi ; vi 2 o/ ^ (k; \Psi ) vj (j; \Psi 0)) =) hj; \Psi 0; vi 2 o/

Definition 5.4 (Well-typed Store)
A store S is defined as well-typed to approximation k with respect to store typing \Psi 
as follows:

S :j;k \Psi  def= dom(\Psi ) ` dom(S ) ^

8j < k: 8` 2 dom(\Psi ): hj; \Psi ; S (`)i 2 b\Psi cj;k(`)

Definition 5.5 (Expr : Type)
For any closed expression e and type o/ ,

e :j;k;\Psi  o/ def= 8j; S ; S 0; e0: (0 <= j < k ^ S :j;k \Psi 

^ (S ; e) 7-!jM (S 0; e0) ^ irred(S 0; e0))
=) 9\Psi 0: (k; \Psi ) vj (k - j; \Psi 0)

^ S 0 :j;k-j \Psi 0 ^ hk - j; \Psi 0; e0i 2 o/

110

?j def= {}
unitj def= {hk; \Psi ; uniti}
o/1!jo/2 def= {hk; \Psi ; *x:ei | 8v; \Psi 0; j < k: ((k; \Psi ) vj (j; \Psi 0) ^ hj; \Psi 0; vi 2 o/1)

=) e[v=x] :j;j;\Psi 0 o/2}

refjo/ def= {hk; \Psi ; ` i | b\Psi cj;k(`) = bo/ ck}
8jF def= {hk; \Psi ; \Lambda :ei | wfupto(k; F ) ^

8j; \Psi 0; t: (k; \Psi ) vj (j; \Psi 0) =) e :j;j;\Psi 0 F (j(t))}

9jF def= {hk; \Psi ; pack vi | wfupto(k; F ) ^ 9t: hk; \Psi ; vi 2 F (j(t))}
ujF def= {hk; \Psi ; vi | hk; \Psi ; vi 2 F k+1(?j)}

Figure 5.4: Higher-Order Logic: Pretype Definitions (parameterized by j)
5.2.2 Pretypes
I explained in Section 5.2.1 that the definitions of some of the type constructors
need to refer to the representation function. But this leads to a problem: which
do we define first, the type constructors or the representation function? I shall
solve this problem by first defining pretype constructors. Each pretype constructor
(written with an overbar) needs a j parameter to stand in for some Gi (which has not
been defined yet). The intent is to (inductively) define the stratified representation
function G next, and then to define type constructors c from the corresponding
pretype constructors c simply by instantiating the j with an appropriate level of G
(i.e., with some Gi). Hence, informally, the distinction between pretype constructors
and type constructors is that the latter are not parametrized by a representation
function j. Definitions of the pretype constructors are given in Figure 5.4.

The definitions of 8jF and 9jF deserve some comment. First, note that these
definitions correspond to the definitions of quantified types presented in Section 4.1,
that is, they assume that type application and unpack are virtual instructions. Second, notice that in the definition of 8jF (likewise 9jF ) the quantification is over type
expressions t rather than types o/ . This is necessary in order to correctly handle polymorphic and abstract references, that is, types of the form 8ff: (: : : ref (: : : ff : : :) : : :)
and 9ff: (: : : ref (: : : ff : : :) : : :) (which I discussed at length in Section 4.4.2). Recall
that upon allocation of a cell ` of a type such as ref (ff ! ff) (where ff is bound by a
universal or existential type constructor that occurs outside the ref), we initialize `

111

with a value of some closed type of the form o/ ! o/ and extend the store typing \Psi  so
that it maps ` to the type o/ ! o/ . In the higher-order logic encoding, at the point
where `'s contents are initialized, there must be some type syntax (i.e., a G"odel
number t) associated with the witness type o/ with which we instantiate the bound
type ff. We need this type expression t in order to construct the type expression
t0 associated with the type o/ ! o/ so that we can extend the store typing \Psi  with
a mapping from ` to t0. To guarantee that there exists a type expression t for the
witness type o/ , in the definitions of the pretypes 8jF and 9jF , we require that the
underlying higher-order logic quantifiers bind type expressions t instead of types o/ .

Henceforth, I will use the metavariables o/ and & to range over types and pretypes,
respectively. Also, I will use the metavariable c for type constructors and c for the
corresponding pretype constructor.

Properties of Pretypes The pretype constructors in Figure 5.4 must satisfy
certain properties so that types eventually defined using these pretype constructors
can be proved valid. In particular, pretype constructors must be (1) nonexpansive,
(2) approximately congruent, and (3) closed under state extension. I will describe
each of these properties below, usually preceded by some auxiliary definitions. I start
by defining equality and approximate equality for constructs of various metalogical
types in our model.

Definition 5.6 (Equality and Approximate Equality)
Equality (=) and approximate equality (ssk) for types o/ and o/ 0, type functions F
and F 0, and representation functions j and j0 are defined as follows:

o/1 = o/2 def= 8k; \Psi ; v: hk; \Psi ; vi 2 o/1 () hk; \Psi ; vi 2 o/2
F1 = F2 def= 8o/: F1(o/ ) = F2(o/ )

j = j0 def= dom(j) = dom(j0) ^ (8t: j(t) = j0(t))

o/1 ssk o/2 def= bo/1ck = bo/2ck
F1 ssk F2 def= 8o/: bF1(o/ )ck = bF2(o/ )ck

j ssk j0 def= dom(j) = dom(j0) ^ (8t: j(t) ssk j0(t))

(1) Nonexpansive I define a notion of approximate nonexpansiveness, which is
analogous to the notion of approximate wellfoundedness (Definition 4.1).

Definition 5.7 (Nonexpansive Up To)
A type functional F is defined as nonexpansive up to k if

nxupto(k; F ) def= 8j; o/: 0 <= j <= k =) F (o/ ) ssj F (bo/ cj)

112

A type functional F is nonexpansive (Definition 3.9) if nxupto(k; F ) for all k >= 0.
Notice that nonexpansiveness vacuously holds for types ?j and unitj which may be
thought of as zero-argument type functions.

Lemma 5.8 (Pretypes Nonexpansive)
For all representation functions j and for all k >= 0,

* For all j such that 0 <= j <= k, and for all types o/ , refj(o/ ) ssj refj(bo/ cj).

* For all j such that 0 <= j <= k, and for all types o/1; o/2, (o/1!jo/2) ssj (bo/1cj!jbo/2cj).

* If c 2 { u; 8; 9 } and F is a type functional such that nxupto(k; F ), then for

all j such that 0 <= j <= k, and for all types o/ , cjF (o/ ) ssj cjF (bo/ cj).

Informally, nonexpansiveness says that if a constructor c is applied to some type
o/ , an index k, store typing \Psi , and value v, it should not inspect o/ in greater detail
than k -- that is, if o/ ssk o/ 0 then c(o/ ) ssk c(o/ 0) (see Definition 3.9 in Section 3.3.9).
Now, if o/ ssk o/ 0 for all k >= 0 (equivalently, o/ = o/ 0), then c(o/ ) ssk c(o/ 0) for all
k >= 0 (equivalently, c(o/ ) = c(o/ 0)) -- that is, nonexpansiveness implies extensionality. (A constructor is extensional if, when applied to equal arguments, it yields
equal results.)

Corollary 5.9 (Pretypes Extensional)
For all pretype constructors c defined in Figure 5.4 and for all representation functions j and j0 such that j = j0,

* If c 2 { ?; unit } then cj = cj0.

* For all o/; o/ 0, if o/ = o/ 0 then refj(o/ ) = refj0(o/ 0).

* For all o/1; o/ 01; o/2; o/ 02, if o/1 = o/ 01 and o/2 = o/ 02 then o/1!jo/2 = o/ 01!j0o/ 02.

* For all F; F 0, if c 2 { u; 8; 9 } and F and F 0 are nonexpansive type functionals

such that F = F 0, then cjF = cj0F 0.

(2) Approximately Congruent A constructor is approximately congruent if,
when applied to approximately equal arguments, it yields approximately equal results.

Lemma 5.10 (Pretypes Approximately Congruent)
For all pretype constructors c defined in Figure 5.4 and for all k >= 0 and representation functions j, j0 such that j ssk j0,

* If c 2 { ?; unit } then cj ssk cj0.

* For all o/; o/ 0, if o/ ssk o/ 0 then refj(o/ ) ssk refj0(o/ 0).

113

* For all o/1; o/ 01; o/2; o/ 02, if o/1 ssk o/ 01 and o/2 ssk o/ 02 then o/1!jo/2 ssk o/ 01!j0o/ 02.

* For all F; F 0, if c 2 { u; 8; 9 } and F and F 0 are type functionals such that

nxupto(k; F ), nxupto(k; F 0), and F ssk F 0, then cjF ssk cj0F 0.

(3) Closed Under State Extension Informally, let us say that a representation
function is "well-behaved" if it maps type expressions to valid types. For every
pretype constructor c, if we are given a "well-behaved" representation function j,
we want to be able to prove that cj is a valid type, that is, typej(cj). This property,
however, cannot be proved directly; we will have to prove the approximate validity
of types (upto level k) for all k >= 0. Intuitively, this is because the representation
function is stratified and defined inductively (see Section 5.2.3). Informally, if j is
well-behaved at level k then we can show that for all pretype constructors c, cj is
a valid type at level k + 1 (since c relies on j up to level k only). Once we have
proved the validity of all cj at level k + 1, we can show that j is well-behaved at
level k + 1, and so on.

Next, I define an approximate notion of type validity that requires only that a
set o/ be closed under state extension upto some k >= 0 (rather than for all k).

Definition 5.11 (Type Up To)
A set o/ is a type up to k (where k >= 0) with respect to a representation function j
if it consists of tuples of the form hk0; \Psi ; vi where k0 >= 0, and if it is closed under
state extension ( vj) up to level k:

typeuptoj(k; o/ ) def= 8j < k: 8i; \Psi ; \Psi 0; v:

(hj; \Psi ; vi 2 o/ ^ (j; \Psi ) vj (i; \Psi 0)) =) hi; \Psi 0; vi 2 o/

We also need an approximate notion of well-behavedness for a representation function j which says that each o/ in the codomain of j should a type up to k.

Definition 5.12 (Representation Function Well-Behaved Up To)
A representation function j is well-behaved up to k iff for all type expressions t,
j(t) is a type up to k with respect to j; that is:

repupto(k; j) def= 8t: typeuptoj(k; j(t))
Lemma 5.13 (Pretypes Closed Under State Extension)
For all pretype constructors c defined in Figure 5.4 and for all k >= 0 and representation functions j, j0 such that repupto(k; j) and j ssk j0,

* If c 2 { ?; unit } then typeuptoj(k; cj0).

* For all o/ , if typeuptoj(k; o/ ), then typeuptoj(k; refj0o/ ).

114

* For all o/1; o/2, if typeuptoj(k; o/1), and typeuptoj(k; o/2), then

typeuptoj(k; o/1!j0o/2).

* Let F be a type functional such that:

1. nxupto(k + 1; F ); and
2. for all o/ , if typeuptoj(k; o/ ) then typeuptoj(k; F (o/ )).

If c 2 { u; 8; 9 }, then typeuptoj(k; cj0F ).

5.2.3 Defining the Representation Function
Having defined the pretype constructors, we are free to G"odelize them. But first,
I must introduce some notation for representing trees of natural numbers. A tree
constructor treei(c0; t1; : : : ; ti) returns a tree with integer c0 at the root and i subtrees
t1; : : : ; ti, for example:

1

tree0(1)

4
1
tree1(4; tree0(1))

3
n1 n2
tree2(3; n1; n2)

For instance, suppose that the type constructors unit and ref are represented by
tree nodes labeled with "2" and "4" respectively. Then, the type unit (which takes
no arguments) may be represented by the tree tree0(2), while the type ref o/ may be
represented by the tree tree1(4; t) where the tree t represents the type o/ .

Before I present the definition of G, I should note that for our FPCC implementation we have automated the generation of the G"odel-numbering function G. We
have a logic program written in Twelf that, given a template that supplies a oneto-one mapping from natural numbers to the set of pretype constructors, outputs
the definition of G. For the definitions and examples that follow, suppose that we
have the following template.

constructor 1 ?
constructor 2 unit
constructor 3 !
constructor 4 ref
constructor 5 8
: : :

The G"odel-numbering function G is defined inductively as follows.

115

* Level 0 of the hierarchy is a relation that maps every G"odel number to the

bottom type, that is,

G0(t) = {}

* Level i + 1 of the hierarchy is defined as follows:

Gi+1(tree0(1)) = ?Gi
Gi+1(tree0(2)) = unitGi
Gi+1(tree2(3; t1; t2)) = Gi(t1) !Gi Gi(t2)
Gi+1(tree1(4; t)) = refGi(Gi(t))
: : :

I haven't shown the representation of uF , 8F and 9F because this would require
a G"odelization of type-functions as well as (closed) types. The way we handle this in
the proof of a full-scale type system is to G"odelize types with free de Bruijn variables
(which I refered to as "type expressions" in Section 4.4.1) instead of (closed) types.2

Some important properties of the representation function are as follows; I shall
formally state the corresponding lemmas later.

* All representation levels are defined on the same set of type expressions, which

constitutes the set of valid type expressions.

* Intuitively, each valid type expression t corresponds bijectively with a type o/

freely built using the constructors of Figure 3.6, and increasing representation
levels offer us increasingly better approximations of that type o/ .

Automating Proofs for G I mentioned above that we have automated the definition of the G"odel-numbering function G. Much more important, however, is the
fact that we've also automated the proofs of various properties of G. Generally,
we manually prove the core clauses of each proof and then write a set of tactics
and a logic program that glues together these proofs as appropriate, constructing
a proof customized to the set of pretype constructors listed in the template (and
hence, customized to the function G built for that set of constructors). In our proof
implementation, all of the lemmas given in the rest of this section have been proved
in such a fashion.

Lemma 5.14

* For all i >= 0, all type expressions in dom(Gi) are valid type expressions.

* For all i; j such that i >= 0 and j >= 0, dom(Gi) = dom(Gj).
2In our FPCC system, since we G"odelize open types (that is, types with free de Bruijn variables),
we then have to ensure that only closed types are stored in references.

116

* The definition of Gi+1 is extensional. Specifically, let j and j0 be representation

functions such that j = j0. If we apply the definition of Gi+1 to j (i.e., replace
all Gi in the definition with j), we get the same result as if we apply it to j0.

Many of the properties that we wish to prove about the representation function
may be proved by induction on the level of G. For instance, suppose that one wants
to prove some property P about the elements in the domain or the range (or both)
of all Gi. First, one defines P as a predicate of type (Nat * TyExp * Type) ! o.
(Recall that the metalogical type of G is Nat ! TyExp ! Type.) Then, one proves
that P holds for the base case -- that is, if G0 maps some t to o/ , then P0(t; o/ ) holds.
Next, one proves that P holds for the inductive step -- that is, assuming that for all
t and o/ , Gi(t) = o/ implies Pi(t; o/ ), one shows for each of the cases in the definition
of Gi+1 that for all t0; o/ 0, if Gi+1 maps t0 to o/ 0, then Pi+1(t0; o/ 0) holds. (For example,
for the ref case in the definition of Gi+1, one would have to show that if Pi(t; Gi(t))
holds, then Pi+1(tree1(4; t); refGi(Gi(t))) also holds.) Finally, one uses the following
generic induction principle for G to construct the proof that the property P holds
for all Gi.

Lemma 5.15 (G Induction)
Let P be a predicate of type (Nat * TyExp * Type) ! o. Suppose that we have the
following:

1. For all t; o/ , if G0(t) = o/ then P0(t; o/ ).
2. For all n >= 0, if: for all t; o/ , Gn(t) = o/ implies Pn(t; o/ ), then: for all t; o/ ,

Gn+1(t) = o/ implies Pn+1(t; o/ ).

Then, for all k >= 0 and all t; o/ , if Gk(t) = o/ then Pk(t; o/ ) holds.

Using the generic induction lemma above, we've automated proofs of various
lemmas, some of which I state next.

Lemma 5.16 (G Partial Function)
For all k >= 0 and for all type expressions t1; t2, if t1 = t2 then Gk(t1) = Gk(t2).

Lemma 5.17 (Representable Implies Type Up To)
For all k >= 0 and for all t; o/ such that Gk+1(t) = o/ , typeuptoGk (k; o/ ).

Proof (sketch): For the base case, we start by proving that repupto(0; G0). \Lambda 

Corollary 5.18 (G Well-Behaved Up To)
As a corollary of Lemma 5.17 we have: If j <= k then repupto(j; Gk).

117

? def= Skb?Gk ck
unit def= SkbunitGk ck
o/1 ! o/2 def= Skbo/1!Gk o/2ck
ref o/ def= SkbrefGk o/ ck
8F def= Skb8Gk F ck
9F def= Skb9Gk F ck
uF def= SkbuGk F ck

Figure 5.5: Higher-Order Logic: Type Definitions
As we can see from the sampling of lemmas in this section, proofs of properties
of G are too tedious and too long to be modified every time we want to add a type to
our language. Automating the definition of G and the proofs of the lemmas about
G has made it possible for us to add new types to our language simply by adding
the corresponding pretypes to the template.

5.2.4 Types
Each type o/ may now be defined as the union (over all k >= 0) of the k-approximations
of the corresponding pretype & (where & has access to the representation function
Gk). The type definitions appear in Figure 5.5.

Properties of Types We have to prove that the types defined in Figure 5.5 are
valid types, that is, that they are closed under state extension. The definition of
valid type (Definition 5.3) given in Section 5.2.1 is parametrized by a representation
function j. Now that we have defined the G"odel-numbering function we can give a
definition of type not parametrized by j. To do so we first combine the hierarchy
of representation functions Gi into a total representation function bG (of type Rep)
as follows. b

G(t) def= SkbGk(t)ck

The following properties of bG follow from Lemma 5.16 and Corollary 5.18.
Lemma 5.19
( bG Partial Function) For all type expressions t1; t2, if t1 = t2 then bG(t1) = bG(t2).

118

( bG Well-Behaved up to) For all k >= 0, the total representation function bG is

well-behaved up to k, i.e., 8k >= 0: repupto(k; bG).

Now we say that a set o/ is a type iff type

\Gamma G(o/ ). To prove this property, we can

use Lemma 5.17 to show that for all k >= 0, typeupto

\Gamma G(k; o/ ), but only if we can first

show that o/ is representable.

Definition 5.20 (Representable)
A type o/ is representable iff for each k, there exists some type expression t such that

bo/ ck = b bG(t)ck; that is,

reppable(o/ ) def= 8k >= 0: (9t: o/ ssk bG(t))
Note that in our current semantics, when we allocate a reference cell of type o/ , we
extend the store typing \Psi  with a new location ` mapped to a type expression t such
that t represents o/ . If a type o/ is not representable, then it cannot be stored in a
reference cell.

Theorem 5.21 (Types Representable)
Every type that can be constructed using the type constructors in Figure 5.5 is representable.

Theorem 5.22 (Types Valid)
Every type o/ that can be constructed using the type constructors in Figure 5.5 is a
valid type.

5.2.5 Judgments, Typing Rules, Safety
The semantics of judgments can now be defined using the total representation function bG as follows.

Definition 5.23 (Semantics of Judgment)
For any type environment \Gamma  and value environment oe I write oe :j;k;\Psi  \Gamma  ("oe approximately obeys \Gamma ") if for all variables x 2 dom(\Gamma ) we have oe(x) :j;k;\Psi  \Gamma (x); that
is,

oe :j;k;\Psi  \Gamma  def= 8x 2 dom(\Gamma ): oe(x) :j;k;\Psi  \Gamma (x)

I write \Gamma  |= kM e : o/ iff F V (e) ` dom(\Gamma ) and

8oe; \Psi : oe :

\Gamma G

;k;\Psi  \Gamma  =) oe(e) :

\Gamma G

;k;\Psi  o/

Theorem 5.24 (Validity of Typing Rules + Safety)
Using these definitions as the interpretation of the typing operators, all the typing
rules in Figure 3.7 hold, as does the statement of Theorem 3.8 (typability implies
safety).

119

Proof: The proof corresponds closely to the proof shown in Sections 3.4 and 3.5.
We are implementing a machine-checked version of this higher-order-logic proof in
the Twelf system. That proof is for von Neumann machines instead of for lambdacalculus, since our application is in proof-carrying code for a real machine. \Lambda 

120
Chapter 6
Foundational Proof-Carrying Code
I have shown how to construct proofs of safety for untyped *-calculus programs.
For a foundational proof-carrying code system, however, we need proofs of safety
for real machine language programs. In this chapter, I shall give an overview of the
Foundational Proof-Carrying Code (FPCC) project at Princeton and explain some
of the differences between the semantic model of *M and the von Neumann model
that we've built for our FPCC system. I'll conclude with a brief look at foundational
proof-carrying code systems that establish type soundness using a syntactic rather
than semantic approach.

6.1 Overview of the FPCC System
The goal of the FPCC project at Princeton is to build machine-checkable safety
proofs for machine language programs from the minimal set of axioms. Figure 6.1
illustrates the architecture of our FPCC system; the trusted components are shaded.
The FPCC system consists of a type-preserving compiler that compiles core ML into
Sparc machine code and simultaneously produces a typed assembly language program. This typed assembly language is called LTAL (for Low-level Typed Assembly
Language) [CWAF03, Che04]. LTAL is quite complex since it must be able to express the constructs of a real source language (core ML) compiled by a real compiler
(a variant of SML/NJ) to a real target machine (the Sparc). Furthermore, it is specialized to the target machine architecture as well as the set of assumptions and
conventions built into the compiler that produces it.

LTAL serves as an interface between the compiler and the FPCC checker. Chen
et al. [CWAF03, Che04] have designed LTAL so that it is gives as much flexibility
as possible to an optimizing compiler, and yet makes it possible to generate safety
proofs for machine code. To achieve this goal, LTAL must be able to describe
the machine state even, for instance, part-way through a sequence of instructions
that allocates on the heap or a sequence of instructions that does data-type tag

121

Axioms & Architecture Spec
Indexed model
of mutable references,
impredicative polymorphism, 

recursive types, etc. 

Model of

register
conventions

TML rules
Machine-checked proofs

of LTAL rules

Machine-checked proofs

of TML rules

LTAL rules

Checker

LTAL
program

Machine

code

Certifying

compiler

ML program

OK

Trusted
Untrusted

Figure 6.1: Foundational PCC System
discrimination. Hence, LTAL has no "macro" instructions; each LTAL instruction
corresponds to one Sparc instruction (or is a coercion with no runtime effect). Also,
LTAL gives the compiler the flexibility of choosing data representations (e.g., for
tagged disjoint sums) by providing low-level type constructors that support various
data representations and extraction and checking of tags. (Chen et al. [CWAF03]
provide a detailed comparison of various typed assembly languages.)

Type-checking in LTAL is syntax directed -- that is, Chen et al. use explicit
coercions to guide the type-checking instead of relying on subtyping which would
require a search. The LTAL typing rules are encoded as 4,000 lines of deterministic
Prolog that reads the machine code and the LTAL and typechecks it. Since the

122

LTAL rules are syntax directed, the type checker (running as a logic program) does
not need to backtrack.

For our FPCC system, we built a machine-checkable foundational proof of soundness for LTAL. We wanted to do construct this proof in a modular fashion, so we
designed Typed Machine Language (TML) [Swa03, TASW04, TA04] to serve as an
abstraction layer that hides the complex semantic models of types that one needs
in order to construct a foundational proof. TML provides a rich set of constructors
for types and instructions, and a powerful, orthogonal set of type primitives such
as immutable and mutable references, recursive types, first-order continuations, impredicative existential and universal types, union and intersection types, and many
other constructors that are useful in real typed assembly languages. Note that TML
is not syntax directed; the presence of impredicative quantified types, equi-recursive
types, unions and intersections, etc. makes type checking undecidable. However,
TML is very useful for building semantic models of specialized, expressive, syntaxdirected typed assembly languages. We build a semantic model (and soundness
proof) for LTAL by combining together the TML primitives.

The FPCC system has axioms that specify the operational semantics of the
Sparc [MA00] (1,600 lines of Twelf), as well as axioms for higher-order logic (135
lines of Twelf) and arithmetic (160 lines of Twelf). The specification of safety (see
Section 6.2) is also part of the TCB (105 lines of Twelf). Based on these axioms,
we have a (nearly complete) soundness proof of TML and LTAL that is about
124,000 lines of Twelf. The semantic model and machine-checked proofs of mutable
references, impredicative polymorphism, etc. that I've described in this thesis -- all
suitably adapted to a von Neumann setting -- are part of the TML soundness proof.
In Section 6.3 I shall briefly describe the semantics of TML types and instructions.

Finally, the FPCC system has a small LF proof-checker and interpreter that
is about 1,200 lines of C [WAS03]. This loads the Prolog rules for LTAL and
checks them for soundness by loading and checking the Twelf proof of LTAL and
TML soundness. It then interprets these rules to type-check an LTAL program
from the ML compiler. This component is based on the work of Wu, Appel, and
Stump [WAS03] who show how to build a trustworthy proof checker with small witnesses in two steps. First, one defines a language for proof-schemes. These represent
the part of the foundational proof that only needs to be checked once; in FPCC, the
proof schemes are the LTAL typing rules. One also provides a way to represent and
check soundness theorems for the proof schemes. Next, one implements an interpreter to execute the proof scheme on the theorem and witness. The proof witness
is that part of the foundational proof that is different for each machine language
program; in FPCC, the witness is the LTAL program.

The size of the trusted computing base for the FPCC system is about 3000 lines.
The size of the TCB in Necula's PCC [CLN+00, NR01] is about 26,000 lines. The
reader should refer to Appel and Wang [AW02] for a breakdown of the sizes of various

123

trusted components, and Wu et al. [WAS03] for the sizes of proof schemes and proof
witnesses, for both FPCC and Necula's PCC [CLN+00, NR01, NL98a, NL98b].

6.2 Von Neumann Model and Safety
A real machine language program runs on a real machine. The program's proof of
type-soundness will therefore be relative to that machine's operational semantics.
We'll assume that a real machine is a von Neumann machine such as the Sparc or the
Pentium. The first step, therefore, is to build a model of a von Neumann machine.
In this model, a real machine state comprises a register bank r and a memory m,
each of which is a function from integers (register numbers or memory addresses)
to integers (contents). We let the register r(pc) represent the program counter.
Program execution begins in some initial state (r0; m0) such that the program (a
sequence of machine instructions) is loaded at address `0 and r0(pc) = `0.

A machine instruction ' is modeled as a relation between machine states (r; m)
and (r0; m0): executing instruction ' in machine state (r; m) results in machine state
(r0; m0), provided that the execution does not violate the safety policy. For example, suppose that the safety policy requires that "only addresses > 1000 may
be updated." This is specified (as part of the safety policy) using the predicate

writable def= *x: x > 1000. Then, the store instruction is defined as follows.

store(i; j; c)((r; m); (r0; m0)) def= writable(r(j) + c) ^ m0(r(j) + c) = r(i) ^

(8x 6= (r(j) + c): m0(x) = m(x)) ^ r0 = r

Next, we specify the step relation (r; m) 7-! (r0; m0) which formally describes a
single instruction execution. It says that if the word in memory m at location r(pc)
decodes to a valid instruction ' and if incrementing the program counter of register
bank r gives us the register bank r00, then the instruction ' maps state (r00; m) to
state (r0; m0). The decode relation in the definition below maps machine words to
machine instructions (such as store(i; j; c) above).

(r; m) 7-! (r0; m0) def= 9r00; ': decode(m(r(pc)); ') ^

r00 = r [pc := r(pc) + 1] ^ '((r00; m); (r0; m0))

Therefore, the specification of a real machine, such as the Sparc, consists of two
parts, a "syntactic" part that specifies the encoding of machine instructions (the
decode relation) and a semantic part that specifies machine instruction semantics
(the definitions of store, load, etc.). The Sparc specification is the work of Michael
and Appel [MA00], who explain it in more detail.

Notice that the step relation 7-! omits any transition that violates the safety
policy, even if the real machine would be capable of executing it. Hence, from any

124

state (r; m), such that the next instruction violates the safety policy, there will be
no successor in the 7-! relation.

A state (r; m) in which some program is loaded is safe for k steps if

safen(k; r; m) def= 8r0; m0: (r; m) 7-!k-1 (r0; m0)

=) 9r00; m00: (r0; m0) 7-! (r00; m00)

A state is safe, written safe(r; m), if 8k >= 0:safen(k; r; m).

To prove the safety of machine language programs, we design a type system
in which we can say that if the registers collectively satisfy some type (r:o/ ), and
the program counter contains the address of a continuation that accepts that type
(r(pc) : codeptr (o/ )), then that state is safe. The soundness theorem is that typability implies safety.

6.3 Typed Machine Language
This section gives an overview of Typed Machine Language (TML) and its semantics. In particular, I shall focus on how the von Neumann model of TML differs
from the semantic model of *M that I presented in previous chapters.

States An abstract machine state s = (\Psi ; r; m) consists of a real part (r; m) and
a virtual part \Psi , called the alloc-map, which corresponds to the store typings that
we saw in Chapter 5. The alloc-map has no run-time manifestation; it is a mapping
from allocated locations to type expressions (i.e., the G"odel numbers of types).

Values Recall that in the model of *M , values were irreducible syntactic terms
of the lambda-calculus. For the von Neumann model, we let values be vectors v,
where v is a sequence of integers, or equivalently, a function from natural numbers
to integers. I write v(0) to denote the first slot of the vector. Consider the following
examples of values on a von Neumann machine.

* Suppose that v represents a boxed pair value in state (\Psi ; r; m). This means

that v(0) is the address of two words in memory such that m(v(0)) is the first
element and m(v(0) + 1) is the second.

* If v is a numeric value in state (\Psi ; r; m), then v(0) is equal to the integer to

be represented.

* If v is a continuation value in state (\Psi ; r; m), then v(0) must be the address `

of some machine code within memory m.

125

The reason for using a vector instead of a scalar is to represent the entire set of
arguments to a multi-argument function as a single value v. For example, in state
(\Psi ; r; m), if the set of arguments is the contents of the register bank then one would
choose v = r. I shall write -!n to denote the constant vector whose every slot
contains the value n.

Closed and Open Types In lieu of the type functions supported by *M (and
used to construct types such as 8F , 9F , and uF ), TML supports types with free de
Bruijn variables. As a result, in TML one may express arbitrarily nested recursive
and quantified types (see the discussion in Section 4.4.1). Hence, we need a notion
of closed types ' as well as open types o/ . A closed type is a set of tuples of the form
hk; s; vi where k is an approximation index (i.e., a natural number), s is a state,
and v is a value (i.e., a vector). An open type may have free type variables -- we
use de Bruijn indices starting at 0 -- so it must be interpreted in an environment
ae that maps the variables. An environment ae is a sequence of closed types. I write
ae; for the empty environment; I use * to add a closed type ' to the head of an
environment ae as follows.

(' * ae)(i) def= { hk; s; vi | (i = 0 ^ hk; s; vi 2 ') .

(i > 0 ^ hk; s; vi 2 ae(i - 1)) }

An open type is a function from environments to closed types. Consider, for example, the de Bruijn variable 3; we represent this open type using the function *ae: ae(3),
which picks the third closed type from the environment.

Representation Functions and Open Types Since an alloc-map \Psi  is a function from
locations ` to type expressions t, most of the definitions that follow will have to be
parametrized by a representation function j that maps type expressions t to (open)
types o/ (as discussed in Chapter 5, Section 5.2.1).

Alloc-maps and Closed Types Though representation functions j map type expressions t to open types o/ , the alloc-map \Psi  may only map locations to closed types (as
discussed in Section 4.4.2). For this reason, the definition of the k-approximation
of an alloc-map (shown below), uses the empty environment when interpreting the
open type j(\Psi (`)).

b\Psi cj;k def= { ` 7! b(j(t))ae;ck | \Psi (`) = t }
Well-Typed States A real machine state (r; m) is well-typed to approximation
k with respect to an alloc-map \Psi  (written (r; m) :j;k \Psi )if every allocated location
` contains a value of the right type -- i.e., the type that \Psi  says it should have --

126

to approximation k. Note that since values in the von Neumann model are vectors,
we have to fetch the contents of cell ` in memory m and construct a vector --!m(`)
before we can check that this value belongs to the type specified by \Psi .

(r; m) :j;k \Psi  def= dom(\Psi ) ` dom(m) ^

8j < k: 8` 2 dom(\Psi ):hj; (\Psi ; r; m); --!m(`)i 2 b\Psi (`)cj;k

Conventions The programs we are judging come from compilers that manage
their registers, stack frame, allocation heap, and so on using certain low-level conventions. There are convention invariants that each computation state must satisfy
(written stateconvention(r; m)), and other convention invariants that must be satisfied as a program steps from state to state (written extendconvention((r; m); (r0; m0))).
For instance, the spill area holds local variables that don't fit in registers and the
heap area holds values of mutable and immutable reference types. Each compiler
temporary (or "local variable") is represented either as a register or as a temporary
value in the spill area. The predicate stateconvention(r; m) requires that in machine state (r; m) the spill area is disjoint from the heap area; that both the heap
and spill area are readable and writable according to the safety policy; that the
temporary values in the spill area are laid out correctly in memory (e.g., memory
locations that store the contents of different local variables should be disjoint); and
so on. Meanwhile, extendconvention((r; m); (r0; m0)) requires, for instance, that certain registers remain unchanged as we step from state (r; m) to state (r0; m0). To
indicate the preservation of low-level convention invariants between machine states,
we write convention((r; m); (r0; m0)).

convention((r; m); (r0; m0)) def= stateconvention(r; m) ^ stateconvention(r0; m0)

^ extendconvention((r; m); (r0; m0))

Valid State Extension A safe program steps from state to state such as to preserve certain invariants facilitating the proof of safety. The extend-state relation (v)
specifies how a state may change during zero or more computation steps. Specifically, we can step from a state s that is well-typed to approximation k to a state s0
by modifying the registers and memory in any way that preserves the conventions
and leaves state s0 well-typed to approximation j <= k; the alloc-map may be extended, but it must leave the types of previously allocated locations unchanged to
approximation j.

(k; (\Psi ; r; m)) vj (j; (\Psi 0; r0; m0)) def=

j <= k ^ convention((r; m); (r0; m0)) ^
(8` 2 dom(\Psi ): b\Psi 0cj;j(`) = b\Psi cj;j(`)) ^
(r; m) :j;k \Psi  ^ (r0; m0) :j;j \Psi 0

127

n : : = 0 | 1 | 2 | * * *

o/ : : = top | bottom | int

| const n | var n
| readable | writable | executable
| amplify o/
| int< o/ | int= o/ | int> o/
| plus o/1 o/2 | times o/1 o/2 | modulo o/1 o/2
| intersect o/1 o/2 | union o/1 o/2
| singleton o/1 o/2 | apply o/1 o/2
| box o/ | ref o/ | codeptr o/
| rec o/ | forall o/ | exists o/

Figure 6.2: TML Type Constructors

The development of the rest of the semantic model of TML closely resembles
the presentation in Chapter 5. As in Chapter 5 we proceed by defining TML
pretypes, then the G"odel-numbering relation G, and then we construct TML types
by supplying the pretype constructors with appropriate representation functions
Gi. There are minor differences in most of the definitions since we must account
for closed versus open types, type environments, and the fact that types are now
sets of tuples of the form hk; (\Psi ; r; m); vi rather than tuples hk; \Psi ; vi as in previous
chapters. We say a closed TML type ' is valid if it is closed under state extension.
We say an open TML type o/ is valid if it is both nonexpansive and closed under
state extension. We prove these properties by defining approximate notions of each
property (e.g., nxupto and typeupto) and then showing that the property holds for
all k >= 0. The reader should refer to Appel et al. [ARSA04] for a presentation of
the semantic model of TML that more closely resembles our FPCC implementation
than what I have described in this section.

TML Type Constructors The full suite of TML type constructors is shown in
Figure 6.2; these constructors are described in detail by Swadi [Swa03]. Next, I'll
briefly describe some of the TML pretype constructors that we haven't seen before.

The TML pretypes defined below each take a representation function j and an
environment ae and return a closed TML type. As in Chapter 5, to distinguish

128

pretype constructors from type constructors, I mark the former with an overbar.

constjn def= *ae: { hk; s; vi | v(0) = n }
varjn def= *ae: { hk; s; vi | hk; s; vi 2 ae(n) }
writablej def= *ae: { hk; s; vi | 9n: hk; s; vi 2 (constjn)(ae) ^ writable(n) }
int<j o/ def= *ae: { hk; s; vi | 9n1; n2: hk; s; -!n1i 2 o/ (ae) ^

hk; s; vi 2 (constjn2)(ae) ^ n2 < n1 }

The type const n is the singleton integer type containing the number n; value v has
type const n if the first slot of the vector contains n. The type var n is the nth de
Bruijn index; value v has this type if it has the nth closed type in the environment
ae. A value v has type writable iff the safety policy permits updates at address v(0).
The type int< o/ is the type of all numeric values v such that v(0) is strictly less
than the number n1 of type o/ .

As before, ref o/ is the type ascribed to mutable reference cells that contain a
value of type o/ . A value v has type ref o/ if the first slot of the vector v contains a
location ` such that (1) the store typing \Psi  says that ` must contain a value of type
o/ for at least k - 1 steps, and (2) the contents of memory at location ` belong to
type o/ to approximation j for all j < k. Note that requirement (2) is missing from
the definition of the *M type ref o/ in Chapter 3 (see Figure 3.6) because types in
that model do not take a store (or memory) as an argument -- that is, they are
predicates on hk; \Psi ; vi rather than hk; \Psi ; S ; vi.

refjo/ def= *ae: { hk; (\Psi ; r; m); vi | b\Psi cj;k(v(0)) = bo/ (ae)ck ^

8j < k: hj; (\Psi ; r; m); -----!m(v(0))i 2 o/ (ae) }

The type codeptr o/ is the type of a first-order continuation, that is, an address
that is safe to jump to at any point in the future as long the register bank r0 at that
future point satisfies the precondition o/ .

codeptrjo/ def= *ae: { hk; s; vi | 8 \Psi 0; r0; m0; j <= k:

( (k; s) vj (j; (\Psi 0; r0; m0)) ^

r0(pc) = v(0) ^
hj; (\Psi 0; r0; m0); r0i 2 o/ (ae) )
=) safen(j; r0; m0) }

Vector Typings Given a value v, we would like to construct vector typings, written OE, that constrain each element in a vector v with a type. We define the TML
type singleton which is a vector typing that constrains exactly one element of a vector, leaving the type of every other element of the vector unconstrained. Singleton

129

vector pretypes are defined below; the type o/1 is meant to represent the index of
the element that must have the type o/2.

singletonjo/1o/2 def= *ae: { hk; s; vi | 9i: hk; s; -!i i 2 o/1(ae) ^ hk; s; --!v(i)i 2 o/2(ae) }
We can construct vector typings by composing two or more singleton vector typings
using the intersection type constructor (intersect). For example, if we have a vector
v such that v(0) : o/1 and v(1) : o/2, we describe the type of v using the following
vector typing:

intersect (singleton (const 0) o/1) (singleton (const 1) o/2)
I abbreviate the above vector typing to {0 : o/1; 1 : o/2}.

Instruction Typings Tan et al. [TASW04] show how to model instructions in
TML. Machine instructions can be viewed at many levels of abstraction. At the
lowest level, an instruction is just an integer n. At the next level, it is a relation
' on real machine states (r; m) and (r0; m0) -- I'll call these TML instructions. In
Section 6.2 we saw that we can relate integers n that encode machine instructions
to TML instructions ' using the decode relation. In TML, to express the fact that a
location ` contains an integer n that decodes to a TML instruction ', we define the
TML type instr('). The semantics of the corresponding pretype constructor instr is
as follows.

instrj ' def= *ae: { hk; s; vi | 9n: hk; s; vi 2 (box(int=(const n)))ae ^ decode(n; ') }
In the above definition, we require that code locations be of immutable reference
type in order to prohibit self-modifying code.

At higher levels of abstraction, machine instructions may be viewed as relations
on Hoare-logic style preconditions and postconditions, expressed in terms of types.
Informally, a TML instruction may be described by two vector typings OE1 and OE2,
where OE1 describes some sufficient precondition (in terms of types) necessary for the
safe execution of the instruction, and OE2 describes some guaranteed postcondition
that results from the execution of the instruction. For example, the precondition
OE1 and postcondition OE2 for the TML instruction add s1 s2 d are given by

OE1 = {s1 : int; s2 : int} " OE
OE2 = {s1 : int; s2 : int} " OE [d 7! int]);

where OE is a vector typing that does not specify a type for d -- I write d =2 dom(OE)
to denote this last condition. We require that s1 and s2 have integer types in
the precondition, and in the postcondition we extend OE by assigning d an integer

130

type. (For readability, I've used the infix notation " instead of intersect, the TML
intersection type constructor.)

In order to model control-flow instructions, we additionally need to know the
safety condition necessary for the jump target. This is specified by \Gamma  which maps
program code locations ` to the precondition OE that must be satisfied to guarantee
the safety of execution from `. Therefore, to describe a control-flow instruction we
need a map \Gamma  (whose domain contains all possible jump targets), as well as the
vector typings OE1 and OE2.

We formalize this last view of instructions using judgments of the form \Gamma ; ` `
{OE1} ' {OE2}. The TML instruction judgment \Gamma ; ` ` {OE1} ' {OE2} says that instruction
' at address ` is well-formed with respect to precondition OE1, postcondition OE2,
and the invariant map \Gamma . We include the instruction location ` in the instruction
judgment in order to be able to compute the destination address for pc-relative jump
instructions. The typing rule for the add instruction may be specified as follows.

d =2 dom(OE)
\Gamma ; ` ` {OE " {s1 : int; s2 : int}} add s1 s2 d {OE " {d : int}} TML-add

Notice that the postcondition in the above rule does not specify the type of s1 and
s2. The above formulation suffices because we can simply pick a OE that specifies
that s1 and s2 have type int without violating the precondition. Furthermore, in
the event that the destination register is the same as one of the source registers, say
d = s1 (as is the case in the instruction r3  r3 + 1), we choose a OE that specifies
the type of s2 but not of s1. This gives us the desired pre- and postconditions
without violating the requirement that OE should not specify a type for d (denoted
d =2 dom(OE)).

We have typing rules for other arithmetic, memory access, and control flow
instructions, but I will not describe them here. Each of these instruction typing
rules must be proved as a lemma. To prove the rules as lemmas, we define the
semantics of instruction judgments. Informally, the semantics must connect the
lower-level view of instructions as relations on machine states (r; m) and (r0; m0),
to the more abstract view of instructions as relations on \Gamma , OE1, and OE2. Tan and
Appel [TA04] describe the model of TML instruction judgments and show how
to prove various instruction typing rules as lemmas. They also define a typed
calculus of instructions with the goal of making it easy (in terms of proof reuse) to
add new instruction typing rules to the system. Their core calculus has rules for
reasoning about a sequence of instructions. One can extend the core calculus with
any instruction typing rule that has been proved as a lemma. As an example, we
may want to add the following typing rule for add which says that if s1 and s2 are
integers with values m and n then in the postcondition, d must be an integer equal
to m + n.

131

d =2 dom(OE)
\Gamma ; ` ` {OE " {s1 : int=(const m); s2 : int=(const n)}}

add s1 s2 d
{OE " {d : plus(const m)(const n)}}

TML-add0

Proving Type Safety Informally, the safety theorem we must prove is as follows.
If (1) program p is loaded at `0 with r0(pc) = `0,

(2) the initial state (r0; m0) satisfies the program precondition OE0, and
(3) the machine instructions in program p are well-typed,
then safe(r0; m0).

Machine instructions in program p are well-typed if all program code locations
are safe with respect to their preconditions. These preconditions are produced by
the certifying compiler which generates an LTAL program with typing annotations
for each instruction. The preconditions can be expressed using vector-typings \Gamma 
that map each program code location `i to the precondition for its safe execution
given by the type codeptr OEi.

\Gamma  = { `0 : codeptr OE0; `1 : codeptr OE1; : : : ; `n : codeptr OEn }
Since a program is a list of machine words, our proof obligation is now to show
that each of these words decodes to an instruction that satisfies the preconditions
specified by \Gamma . We use the decode prover of Michael and Appel to construct the
following vector-typing for the list of words p loaded at `0 in memory m.

\Delta (p) = { `0 : instr '0; `1 : instr '1; : : : ; `n : instr 'n }
We define the TML subtype (or sub-vector-typing) relation ae as follows.

o/1 aek o/2 def= 8ae; s; v: hk; s; vi 2 o/1(ae) =) hk; s; vi 2 o/2(ae)
o/1 ae o/2 def= 8k: o/1 aek o/2

Now the proof obligation that \Delta (p) respects the invariants in \Gamma  can be expressed
as \Delta (p) ae \Gamma . The proof of \Delta (p) ae \Gamma  proceeds by induction on the approximation
index k. See Tan et al. [TASW04] for a detailed description of the proof technique.

6.4 Related Work: Syntactic Approach to FPCC
Unlike the FPCC project at Princeton which takes a semantic approach to proving
program safety, more recent foundational PCC systems are based on the syntactic

132

P

S'
S
P' translate?
(evaluate) (step)

translate

Figure 6.3: Syntactic FPCC: Connecting TAL Evaluation to Real Machine Steps
approach. Hamid et al. [HST+02] were the first to demonstrate the syntactic approach to foundational PCC where one constructs proofs of program safety in two
steps. First, one proves the soundness of the typed assembly language as a syntactic
metatheorem [WF94]. This theorem says that a program in a well-typed state can
always take another step (progress), and that the execution of such a step results
in a well-typed state (preservation).

Next, one relates steps in the typed assembly language to steps of the real
machine. Specifically, one must define a translation from the TAL machine states
P to real machine states S, and then prove the following lemma: if a well-typed
TAL state P translates to a real machine state S, and P steps to P 0 according to
the TAL operational semantics, and S steps to S0 on the real machine, then P 0
translates to S0. Figure 6.3 due to Hamid et al. [HST+02] illustrates this lemma.

The typed assembly language mentioned above is designed with essentially the
same design goals as LTAL. For instance, it should be expressive enough to support
many different source language constructs and compiler optimizations. Also, each
TAL instruction should correspond to one real machine instruction so one can easily
prove that each TAL step corresponds to a real machine step. Hamid et al.'s syntactic FPCC system compiles source language programs to Featherweight Typed
Assembly Language (FTAL). They split the conventional "malloc" instruction into
two FTAL instructions that each map to a single real machine instruction. This, in
turn, requires that their type system be expressive enough to describe the machine
state even part way through the sequence of instructions that allocates on the heap.
FTAL is a simple typed assembly language that supports memory allocation, mutable references, and recursive types, but not quantified types. Their system targets
a toy subset of a real machine architecture. Proofs are encoded in the Calculus of
Inductive Constructions (CiC) [CH88, PM93] and checked using Coq [BBC+98].

Crary [Cra03] has recently extended Hamid et al.'s approach to a realistic architecture. Crary's system uses an assembly language called TAL Two (TALT), a

133

descendant of TALx86 [MCG+99, MWCG99]. While TALT is expressive enough to
serve as a target language for a type-preserving ML compiler, it must still use macro
instructions like "malloc." Consequently, there is a gap between TALT instructions
and real machine instructions. Crary's FPCC system targets the Intel IA32 architecture. Crary uses LF [HHP93] to encode proofs and the Twelf metatheorem
checker [PS99, Sch00b] to check them. The latter is a large and complex piece of
software, and using it to validate safety proofs increases the size of the TCB. The
pure LF checker used in our (semantic) FPCC system is simpler and smaller than
existing CiC checkers and the Twelf metatheorem checker.

134
Chapter 7
Semantics of a Region Calculus
All practical languages provide some mechanism for the reuse of memory, but the
model of mutable state that I've described in this thesis does not allow memory
to be reclaimed. Deallocation or recycling of memory implicitly allows memory
to be reused later, possibly at a different type. This is clearly at odds with the
type invariance principle I described in Chapter 1 which ensures that the types
of allocated locations are preserved. Type preservation is important because it
allows us to prove that the logical relations we've defined are Kripke monotone (see
Section 4.4.3). The problem is that in order to support memory reuse we must define
logical relations that allow memory cells to be reused at a different type and yet,
paradoxically, are Kripke monotone, that is, they ensure that types are preserved.

In this chapter, I'll show how one may go about constructing such a model. In
particular, I'll describe how to model a low-level lambda-calculus with primitives
for region-based memory management [TT94, TT97]. The central ideas underlying
the model described in this chapter were developed during discussions with David
Walker.

The main idea is as follows. First, in any given computation state s, I allow
each location ` to have more than one type -- for instance, ` may simultaneously
have the types ref o/1 at *1 and ref o/2 at *2, where *1 and *2 are the names of distinct
regions in which the location was allocated at some point during the computation
prior to reaching state s -- as long as, if X is the set of regions in which ` has been
allocated thus far, there is at most one region *i in X that is "live" in the current
state s.1 (Ahmed, Jia, and Walker [AJW03] also use live and dead predicates and
have a similar invariant on regions.) The point is to ensure that if ` has type
ref o/1 at *1 in the current state, it'll continue to have that type in all future states,
even after the region *1 has been deallocated. Second, I use a capability-based type
system [CWM99, WCM00, Wal01] (which keeps track of the set of live regions) to
statically check that a region is live when it's accessed. For instance, the typing rule

1A region is live if it's been allocated but not yet freed. Once a live region is freed, it's dead.

135

Values v : : = x | ` | h | unit | *(x1; : : : ; xn):e
Expressions e : : = let x = new(v1) at v2 in e |

let x = ! v in e | let v1 := v2 in e |
let newrgn x in e | let freergn v in e |
v(v1; : : : ; vn) | halt

Figure 7.1: Regions (*R): Syntax
for deferencing says that ! v has type o/ if and only if the value v has type ref o/ at *
and the region * is live.

7.1 Syntax
The language I consider is based on the Calculus of Capabilities [CWM99, WCM00,
Wal01], a continuation-passing-style language motivated by the goal of using regionbased memory management to certify the memory safety of object code. I'll discuss
only a simplified version of that language here. In particular, I won't show how
to model region polymorphism and quantified types; these are crucial features, but
they can be added to the model I present without too much difficulty.

The syntax of the language, which I call *R, is given in Figure 7.1. As before,
I use the metavariables x and ` to range over the countably infinite sets Var (of
variables) and Loc (of locations), respectively. Furthermore, I use the metavariable
h to range over a countably infinite set RegionHandle of region handles. Later I
will use the metavariable * to range over a countably infinite set of region names
RegionName. Informally, the crucial distinction between region handles h and region names * is that region handles may be reused once a region has been deallocated, while region names are never reused. Note that the syntax for *R does not
make use of region names. I'll discuss the use of region handles versus region names
when I describe the operational semantics below.

A term v is a value if it is a variable x, a location `, a region handle h, the constant
unit, or a function *(x1; : : : ; xn):e. The language includes terms for allocating (and
initializing) a new location in a specified region, dereferencing, update, creating a
new region, deallocating a region, and function application. I omit all types from
the syntax of *R (just as I did for *M ).

136

7.2 Operational Semantics
The small-step operational semantics for *R is given by the relation (S ; e) 7-!R
(S 0; e0) between abstract machine states. An abstract machine state (S ; e) is a pair
of a store S and a closed term e, but stores now have a more complicated structure.
A store S in *R is a finite map from region handles to regions. A region is a finite
map from locations to closed values.

Region = Loc fin! Val
Store = RegionHandle fin! Region

I shall assume that all stores are well-formed, that is, that there is no location `
that simultaneously belongs to more than one region in the store.

The reader may wonder why I've chosen to represent stores as a finite map
from region handles to regions rather than as a finite map from region names to
regions (which is the representation used by Walker et al. [WCM00, Wal01]). The
reason is that I want to keep the dynamic semantics completely free of region names.
The requirement that region names never be reused is a critical component (as I'll
explain in detail below) of the semantic model I wish to construct. However, on a von
Neumann machine there is no infinite supply of region names. Since my ultimate
goal is to construct a von Neumann model based on the ideas in this chapter, I
shall show that it is possible to make use of only (recyclable) region handles in the
dynamic semantics and restrict the use of (nonrecyclable) region names to the static
semantics.

The operational semantics for *R is given in Figure 7.2. When convenient, I
abbreviate S (h)(`) to S (h:`) and S [h 7! S (h) [` 7! v]] to S [h:` 7! v]. I write S \h
to denote a store that does not map h (that is, h =2 dom(S \h)), but is otherwise
equivalent to the store S .

In a language with region-based memory management, one must specify the
region in which to allocate a new cell. The declaration new(v) at h allocates a reference cell in the region with handle h and initializes the cell's contents to the value v.
The corresponding rule (RO-newat) checks that store S contains the specified region
handle h. It then extends that region in the store with a previously unallocated
location ` initialized to v. Note that the rule requires that the new location ` does
not occur in any existing region of the store; this guarantees the well-formedness
of the extended store. The rules for dereferencing and updating a location ` (see
RO-deref and RO-assign) check that there exists a region in the store that contains
the location. The rule for creating a new region (RO-newrgn) extends the store with
a region handle h that is not in current use, mapped to an empty region. The declaration freergn h deallocates the region with handle h. The corresponding rule (see
RO-freergn) checks that the store contains the region handle h mapped to some

137

h 2 dom(S ) 8h0: ` =2 dom(S (h0))
(S ; let x = new(v) at h in e) 7-!R (S [h:` 7! v]; e[`=x]) (RO-newat)

9h: (h 2 dom(S ) ^ ` 2 dom(S (h)))
(S ; let x = ! ` in e) 7-!R (S ; e[S (h:`)=x]) (RO-deref)

9h: (h 2 dom(S ) ^ ` 2 dom(S (h)))
(S ; let ` := v in e) 7-!R (S [h:` 7! v]; e) (RO-assign)

h =2 dom(S )
(S ; let newrgn x in e) 7-!R (S [h 7! {}]; e[h=x]) (RO-newrgn)

h 2 dom(S )
(S ; let freergn h in e) 7-!R (S \h; e) (RO-freergn)

(S ; (*(x1; : : : ; xn):e)v1; : : : ; vn) 7-!R (S ; e[v1; : : : ; vn=x1; : : : ; xn]) (RO-app)

(S ; halt) 7-!R (S ; unit) (RO-halt)
Figure 7.2: Regions (*R): Operational Semantics
region and removes the region and h from the store.

The specification of safety is exactly as for *M ; refer to Definition 3.1 (in Section 3.3.1) and replace all occurrences of 7-!M with 7-!R.

7.3 Semantic Model of Types
Types in *M were modeled as sets of tuples of the form hk; \Psi ; vi where k is an
approximation index, \Psi  is a store typing, and v is a value. But stores in *R are
more complicated than those in *M , and accordingly, the model of store typings is

138

also more complicated. There are a number of things that the semantic model must
keep track of as I shall explain next.

Regions are uniquely identified by region names *. A store typing \Psi  must keep
track of information about each region, live or dead. Hence, I shall model a store
typing \Psi  as a finite map from region names * to the appropriate information for
that region. Notice that since a store typing must keep track of information about
both live and dead regions, the domain of a store typing can never shrink.

There are three things we must keep track of for each region. First, we must
keep track of whether the region is live or dead . The second piece of information to
track is a region's handle. Specifically, when a new a region is allocated, the static
semantics (as we shall see) gives the region a fresh region name (i.e., a name that
has never been used before). Meanwhile, the dynamic semantics assigns the new
region a region handle h. We must keep track of the region handle h assigned to
each region * (so that we can, for instance, define the semantics of region handle
types handle (*) which I'll describe below). Third, for each location allocated in
the region, we must keep track of the (approximate) permissible update type of the
reference cell, just as we did for *M .

A region typing \Upsilon  is a finite map from locations to types. A store typing \Psi  is a
finite map from region names to tuples of the form (!; h; \Upsilon ), where the metavariable
! ranges over the set { live; dead }, h is a region handle, and \Upsilon  is a region typing.
The metalogical types of region typings, store typings, and types are as follows.

Type0 = Unit
RegionTypek = Loc fin! Typek
StoreTypek = RegionName fin! ({ live; dead } * RegionHandle * RegionTypek)
Typek+1 = StoreTypek * Val ! o

If \Psi (*) = (!; h; \Upsilon ) then status(\Psi (*)) denotes !; live(\Psi (*)) is true if and only if
! = live; dead(\Psi (*)) is true if and only if ! = dead ; hndl(\Psi (*)) denotes h; and
rgnty(\Psi (*)) denotes \Upsilon .

There are certain well-formedness constraints that have to be imposed on store
typings. The constraints may be better understood if I first explain how I intend
to model cell allocation as well as the allocation and deallocation of regions in the
semantics of *R. Consider a scenario where we have a current store typing \Psi  and
a location ` that has never been allocated in any region. It follows that ` does not
occur in any region in the current store typing \Psi . Now, suppose that we execute an
instruction that allocates a new cell -- say we pick ` -- to contain values of type o/1
in region *1. It must be the case that live(\Psi (*1)) -- that is, we cannot allocate in a
region that is dead or nonexistent. In the semantics, we update the store typing to
\Psi 0 which is identical to \Psi , except that rgnty(\Psi 0(*)) also maps ` to the appropriate
approximation of type o/1.

139

Next, suppose that *1 is freed. In the semantics, \Psi 0 is updated to \Psi 00 which is
identical to \Psi 0 except for the fact that dead(\Psi 00(*1)). Note that region *1 in the
current store typing \Psi 00 contains the location ` mapped (approximately) to type o/1.
Nonetheless, since dead(\Psi 00(*1)), one may now reallocate ` at a different type o/2 in
some other region *2 as long as live(\Psi 00(*2)). In the future, once *2 has been freed
(and marked dead ), ` may be reallocated again in a different region, possibly at a
different type, as long as every region in which ` was allocated up till that point is
dead . The recurring requirement in the above scenario is that each location ` may
belong to at most one live region in the store typing. Similary, we require that each
region handle h may be assigned to at most one live region in \Psi . A store typing
that satisfies these requirements is said to be well-formed.

Definition 7.1 (Well-formed Store Type)
A store typing \Psi  is well-formed if and only if there exists no location ` or region
handle h that belongs to multiple live regions in \Psi ; that is,

wellformed(\Psi ) def= 8`; *1; *2: ( ( (` 2 dom(\Psi (*1)) ^ ` 2 dom(\Psi (*2)))

. hndl(\Psi (*1)) = hndl(\Psi (*2)) )
^ *1 6= *2 )
=) (dead(\Psi (*1)) . dead(\Psi (*2)))

We've seen that a location may be added to a store typing multiple times --
intuitively, every time the location is (re)allocated -- as long as the well-formedness
of the store typing in preserved. To model *R we must require, in fact, that locations
never be removed from the store typing. This allows us to maintain the illusion that
reference types are (approximately) preserved, even when their regions are freed.
The requirement that locations never be removed from the store typing is enforced
by the extend-state relation (v) relation. Before I can specify the extend-state
relation, however, I must define the notion of the k-approximation of a type.

Definition 7.2 (Approx)
The k-approximation of a set is the subset of its elements whose index is less than
k; I also extend this notion pointwise to region typings and store typings:

bo/ ck def= { hj; \Psi ; vi | j < k ^ hj; \Psi ; vi 2 o/ }
b\Upsilon ck def= { (` 7! bo/ ck) | \Upsilon (`) = o/ }
b\Psi ck def= { (* 7! (!; h; b\Upsilon ck)) | \Psi (*) = (!; h; \Upsilon ) }

The extend-state relation (k; \Psi ) v (j; \Psi 0) ensures that store typings only grow
(in terms of both region names and the locations in those regions); that once a
region is dead , it cannot become live again; that the handle assigned to a region

140

never changes; and that the types of locations in all regions, live and dead, are
approximately preserved.

Definition 7.3 (State Extension)
A valid state extension is defined as follows:

(k; \Psi ) v (j; \Psi 0) def= j <= k ^

(8* 2 dom(\Psi ): * 2 dom(\Psi 0)

^ dead(\Psi (*)) =) dead(\Psi 0(*))
^ hndl(\Psi (*)) = hndl(\Psi 0(*))
^ (8` 2 dom(rgnty(\Psi (*))):

brgnty(\Psi (*))cj(`) = brgnty(\Psi 0(*))cj(`)))

One can easily prove that above extend-state relation is both reflexive and transitive.

In Chapter 3, to model mutable references, we had to ensure that *M types
were closed under state extension. The same is required of types in *R. A type o/
in *R is a set of tuples of the form hk; \Psi ; vi that is closed under state extension (see
Definition 3.4 in Section 3.3.3).

7.4 Reference, Region Handle, and Function Types
I shall now specify the semantics of types in *R. Note that the semantics of each
type have to be such that we can prove that the type is closed under valid state
extension.

A location ` has type ref o/ at * for k steps with respect to store typing \Psi  if the
region name * is in dom(\Psi ) -- that is, it doesn't matter whether * is live or dead ,
but it must not be nonexistent -- and if the region typing \Psi (*) says that ` will
contain a value of type o/ for at least k - 1 steps.

ref o/ at * def= {hk; \Psi ; ` i | brgnty(\Psi (*))ck(`) = bo/ ck}
Valid state extension (v) guarantees that the types of all locations in all regions are
approximately preserved, thus, allowing us to prove that ref o/ at * is a valid type.
Note that if the above definition required that * be live, we would not be able to
prove type(ref o/ at *).

A region handle h has type handle (*) if * is in dom(\Psi ) -- * may be live or dead
-- and if, according to \Psi , *'s region handle is equal to h.

handle (*) def= {hk; \Psi ; h i | hndl(\Psi (*)) = h}
Since state extension ensures that region handles are preserved, and since the above
definition does not require that * be live, we can easily show that handle (*) is a

141

valid type.

A function of the form *(x1; : : : ; xn):e in *R is assigned a type of the form
(C ; o/1; : : : ; o/n) ! unit, where C is a set of region names. The function (continuation,
to be precise) expects n arguments of types o/1 through o/n and requires that each
of the regions *i 2 C be live when the function is applied. Before I can formally
define the semantics of (C ; o/1; : : : ; o/n) ! unit, I need two auxiliary definitions.

First, I specify what it means for a store S to be well-typed to approximation
k with respect to a store typing \Psi  (written S :k \Psi ). Informally, S :k \Psi  holds if
and only if for every live region * in the store typing \Psi : *'s region handle h is
in dom(S ); the store region S (h) contains every location in *'s region typing \Upsilon ;
and the contents of these locations have the type that \Upsilon  says they should have to
approximation k.

Definition 7.4 (Well-typed Store)
A store S is defined to be well-typed to approximation k with respect to store typing
\Psi  as follows:

S :k \Psi  def= 8* 2 dom(\Psi ): 8h; \Upsilon : \Psi (*) = (live; h; \Upsilon ) =)

( h 2 dom(S ) ^

dom(\Upsilon ) ` dom(S (h)) ^
(8j < k: 8` 2 dom(\Upsilon ): hj; b\Psi cj; S (h:`)i 2 b\Upsilon ck(`)) )

Next, I define what it means for a closed expression e to be well-typed for k steps
with respect to store typing \Psi . I write e :k;\Psi  unit to denote the latter (since every
*R expression e has type unit). Intuitively, e :k;\Psi  unit says that in a state (S ; e) such
that S :k \Psi , term e behaves like an element of unit for k steps of computation. If
(S ; e) reaches an irreducible state (S 0; e0) in less than k steps, then it must be the
case that e0 is the value unit, and S 0 must be a store that is well-typed with respect
to a well-formed store typing \Psi 0 that is a valid extension of \Psi . Otherwise, (S ; e)
can take k steps without getting stuck -- that is, there exist S 0 and e0 such that
(S ; e) 7-!kR (S 0; e0).

Definition 7.5 (Expr : Type)
For any closed expression e, I define e :k;\Psi  unit as follows:

e :k;\Psi  unit def= 8j; S ; S 0; e0: (0 <= j < k ^ S :k \Psi 

^ (S ; e) 7-!jR (S 0; e0) ^ irred(S 0; e0))
=) 9\Psi 0: (k; \Psi ) v (k - j; \Psi 0) ^ wellformed(\Psi 0)

^ S 0 :k-j \Psi 0 ^ hk - j; \Psi 0; e0i 2 unit

142

The semantics of function types can now be defined as follows.

(C ; o/1; : : : ; o/n) ! unit def= {hk; \Psi ; *(x1; : : : ; xn):ei |

8v1; : : : ; vn; \Psi 0; j < k:

((k; \Psi ) v (j; \Psi 0) ^ wellformed(\Psi 0)

^ (8* 2 C : live(\Psi 0(*)))
^ hj; \Psi 0; v1i 2 o/1) ^ : : : ^ hj; \Psi 0; vni 2 o/n)
=) e[v1; : : : ; vn=x1; : : : ; xn] :j;\Psi 0 unit }

7.5 Judgments and Typing Rules
Thus far I have only dealt with closed terms as these are the ones that "step" at
run time. Now I turn to terms with free variables on which the static type-checking
rules operate. There are two kinds of type judgments in *R. The main typing
judgment has the form \Delta ; \Gamma  |=R e where \Delta  is a region map that maps used region
names to either live or dead , \Gamma  is a type environment that maps term variables to
types, and e is an expression. There is also a typing judgment for values that has
the form \Delta ; \Gamma  |=R v : o/ . A value environment oe is a mapping from term variables to
values.

Definition 7.6 (Semantics of Judgment)
For any region map \Delta  and store typing \Psi , I define \Delta  : \Psi  (read "\Delta  agrees with \Psi ")
as follows:

\Delta  : \Psi  def= dom(\Delta ) = dom(\Psi ) ^ (8* 2 dom(\Delta ): \Delta (*) = status(\Psi (*)))
For any type environment \Gamma  and value environment oe, oe :k;\Psi  \Gamma  (read "oe approximately obeys \Gamma ") is defined as follows:

oe :k;\Psi  \Gamma  def= 8x 2 dom(\Gamma ): oe(x) :k;\Psi  \Gamma (x)
The semantics of \Delta ; \Gamma  |= kR v : o/ and \Delta ; \Gamma  |= kR e (where RN (\Gamma )2 ` dom(\Delta ), F V (v) `
dom(\Gamma ), and F V (e) ` dom(\Gamma )) are defined as follows:

\Delta ; \Gamma  |= kR v : o/ def= 8oe; \Psi : wellformed(\Psi ) ^ \Delta  : \Psi  ^ oe :k;\Psi  \Gamma  =) hk; \Psi ; oe(v)i 2 o/
\Delta ; \Gamma  |= kR e def= 8oe; \Psi : wellformed(\Psi ) ^ \Delta  : \Psi  ^ oe :k;\Psi  \Gamma  =) oe(e) :k;\Psi  unit

I write \Delta ; \Gamma  |=R e if for all k >= 0 we have \Delta ; \Gamma  |= kR e. Finally, I write |=R e to mean
\Delta 0; \Gamma 0 |=M e for the empty region map \Delta 0 and the empty context \Gamma 0. The meanings
of \Delta ; \Gamma  |=R v : o/ and |=R v : o/ are analogous.

2RN (\Gamma ) denotes the set of region names that appear in the codomain of \Gamma 

143

\Delta ; \Gamma  |=R v : o/

\Delta ; \Gamma  |=R x : \Gamma (x) (RV-var) \Delta ; \Gamma  |=R unit : unit (RV-unit)
\Delta  <= \Delta 0 8*0 2 C : \Delta 0(*0) = live \Delta 0; \Gamma  [x1 7! o/1] : : : [xn 7! o/n] |=R e

\Delta ; \Gamma  |=R *(x1; : : : ; xn):e : (C ; o/1; : : : ; o/n) ! unit (RV-abs)

\Delta ; \Gamma  |=R e

\Delta ; \Gamma  |=R v1 : o/ \Delta ; \Gamma  |=R v2 : handle (*)
\Delta (*) = live \Delta ; \Gamma  [x 7! ref o/ at *] |=R e

\Delta ; \Gamma  |=R let x = new(v1) at v2 in e (R-newat)

\Delta ; \Gamma  |=R v : ref o/ at * \Delta (*) = live \Delta ; \Gamma  [x 7! o/ ] |=R e

\Delta ; \Gamma  |=R let x = ! v in e (R-deref)

\Delta ; \Gamma  |=R v1 : ref o/ at * \Delta ; \Gamma  |=R v2 : o/ \Delta (*) = live \Delta ; \Gamma  |=R e

\Delta ; \Gamma  |=R let v1 := v2 in e (R-assign)

\Delta  [* 7! live]; \Gamma  [x 7! handle (*)] |=R e * =2 dom(\Delta )

\Delta ; \Gamma  |=R let newrgn x in e (R-newrgn)

\Delta ; \Gamma  |=R v : handle (*) \Delta (*) = live \Delta  [* 7! dead ]; \Gamma  |=R e

*; \Gamma  |=R let freergn v in e (R-freergn)

\Delta ; \Gamma  |=R v : (C ; o/1; : : : ; o/n) ! unit \Delta ; \Gamma  |=R vi : o/i 8*0 2 C : \Delta (*0) = live

\Delta ; \Gamma  |=R v (v1; : : : ; vn) (R-app)

\Delta ; \Gamma  |=R halt (R-halt)
Figure 7.3: Regions (*R): Type-checking Lemmas

144

The typing rules for *R are given in Figure 7.3. I write \Gamma  [x 7! o/ ] to denote the
type environment that extends \Gamma  by mapping x to o/ where x =2 dom(\Gamma ). I write
\Delta  [* 7! !] to denote the type environment that either updates \Delta  (if * 2 dom(\Delta ))
or extends \Delta  (if * =2 dom(\Delta )) by mapping * to !. Notice that the typing rule
for abstraction (RV-abs) must ensure that the body of the function type checks at
some point in the future with respect to a future region map \Delta 0. This future region
map must be a valid extension of the current region map \Delta , written \Delta  <= \Delta 0. The
relation \Delta  <= \Delta 0 ensures that the region map only grows over time and that once a
region is dead it cannot become live again.

Definition 7.7 (Region Map Extension)
A valid region-map extension is defined as follows:

\Delta  <= \Delta 0 def= 8* 2 dom(\Delta ): * 2 dom(\Delta 0)

^ (\Delta (*) = dead =) \Delta 0(*) = dead )

Each of the *R typing rules can be proved as a lemma.

A program in *R is a closed expression that contains neither location symbols
` nor region handles h. Since we are not doing subject-reduction, we do not need
to type-check executing programs, which means that we do not need to type-check
locations and region handles.

Based on the above definitions, we can prove the desired safety theorem which
says that if |=R e, then given an arbitrary store S , machine state (S ; e) is safe (see
Theorem 3.8).

7.6 Discussion
In this chapter, I've described how to construct an indexed possible-worlds model
that supports region deallocation and yet is (at least in a technical sense) type
preserving. The central trick becomes apparent if we consider the semantics of
mutable reference types. The semantics of ref o/ at * does not say anything about
whether or not one can safely read or write the reference cell -- it simply says that if
we were to read from (or write to) the cell, we would get (or have to put in) a value
of type o/ . The task of checking whether a cell can be accessed without violating
memory safety is relegated to the typing rules for dereferencing and assignment.
These rules check if the appropriate capability is held, that is, if * is live according
to \Delta .

It is important to extend *R with type and region polymorphism which I have
not discussed in this chapter. Following the model of *R (extended with type
and region polymorphism), I conjecture that it will be possible to construct a von

145

Neumann model of a realistic low-level TAL with region-based memory management
primitives for use in a foundational PCC system.

146
Chapter 8
Conclusions and Future Work
A proof-carrying code infrastructure should not be specific to the target type system
of a particular compiler or source language. Furthermore, its safety guarantee should
not be contingent upon the assumption that such a complex, low-level type system
is sound. For these reasons, machine-checkable proofs of type soundness for real
machine languages are essential. Real languages have features for mutating state
that make it harder to prove safety. I have shown how to prove type soundness for a
language with mutable references and impredicative polymorphism by constructing
indexed Kripke logical relations based on the operational semantics of the language.
I have also shown how to apply this technique to a language with primitives for
region-based memory management.

There exist only two other models of languages with general references and
neither of these allow (impredicative) quantified types to be stored in mutable cells;
they also do not permit memory deallocation and reuse. These are Abramsky et al.'s
game semantics [AHM98] and Levy's possible-worlds model which employs categorytheoretic machinery [Lev02]. I've presented an indexed possible-worlds model of
types that is guided by the notion of approximations inherent in domain theory.
But the particular advantage of the indexed model is that it permits relatively
simple and direct proofs of type safety for a wide range of language features --
features that are usually hard to deal with because they lead to various forms
of circularity -- without the need to "import" large mathematical theories, such
as domain theory or category theory. These proofs are short enough to permit
implementation as machine-checked proofs in a simple higher-order logic. I have
described how we construct an indexed possible-worlds model for a von Neumann
machine, which allows us to prove type safety for a low-level TAL that can express
the constructs of a real source language (core ML) compiled by a real compiler
(derived from SML/NJ) to a real target machine (the Sparc). In this final chapter
I'll discuss an important direction for future research.

147

8.1 A PER Model
Informally, two expressions are operationally equivalent (also called observational
equivalence or contextual equivalence in the literature) if no program context can
distinguish them. Much work has been done to develop techniques for reasoning
about program equivalence [Mil77, MT89, MT91a, MT92, JM91, How89, How96,
PS93, RP95, Pit98, Pit00, Pit02]. As a result we have useful techniques for reasoning about operational equivalence in functional languages (e.g., Milner's context
lemma for typed *-calculus [Mil77]) as well as languages with side-effects such as dynamic allocation and mutation of first-order references. In particular, Pitts [Pit96]
has demonstrated the use of operationally-based logical relations to prove a context lemma for a higher-order language with assignable variables that store only
first-order values. In more recent work, he has extended the idea to languages with
first-order references, recursive functions, existential types and parametric polymorphism [Pit98, Pit00, Pit02]. However, there haven't been any operationally-based
techniques developed to date that permit reasoning about equivalence in the presence of general references, that is, references that can store other references, functions, quantified types, and so on. Hence, a useful direction for future research is to
extend the logical relations model described in this dissertation to permit reasoning
about observational equivalence as well as safety.

Appel and McAllester [AM01] showed how to extend their indexed model for
the simply typed *-calculus with recursive types (and no mutable state) to a partial equivalence relation (PER) model. A PER model allows one to reason about
operational approximation, a weaker notion than operational equivalence. A term
e1 operationally approximates a term e2 if and only if for any two observationally
equivalent program contexts C1 and C2 (written C1 ssobs C2), if C1[e1] reaches an irreducible state s1, then C2[e2] reaches an irreducible state s2 that is observationally
equivalent to s1. Thus, if e1 operationally approximates e2 and vice versa, then e1
and e2 are operationally equivalent.

Building a PER model for a language with mutable state (especially higherorder references) is not an easy task. In the rest of this section, I'll describe some
of the challenges. First, consider how one should model an evaluation context C.
In a functional language it suffices to model C as a value environment oe that maps
variables to values -- this is the "context" in which an open expression will be
evaluated. But in a language with mutable state, the context must also describe
the state. A review of the semantics of judgments \Gamma  |=M e : o/ in Chapter 3 shows us
how to pick an appropriate context in which to evaluate an open expression e. The
context consists of a value environment oe, a store typing \Psi , and a store S such that
oe satisfies \Gamma  with respect to \Psi  and S is well-typed with respect to \Psi . For the PER
model we'll have judgments of the form \Gamma  |= e1 <= e2 : o/ (read "e1 approximates e2
in o/ "). To define the semantics of such judgments, we need to pick an appropriate

148

5100
101

x x

102
103
104
105

S1 \Psi 1

{100 a int}

S2 \Psi 2

{100 a int}5100
101

102
103
104
105

\Gamma  = {x:ref int} s1 = {x a 100} s2 = {x a 100}

(a) Scenario 1: Identical Environments, Stores, Store Typings

5100
101

x x

102
103
104
105

S1 \Psi 1

{100 a int}

S2 \Psi 2

{105 a int}
100
101

102
103
104
105

\Gamma  = {x:ref int} s1 = {x a 100} s2 = {x a 105}

5

(b) Scenario 2: Related Environments, Stores, Store Typings

Figure 8.1: Observationally Equivalent Contexts
context C1 = (oe1; \Psi 1; S1) in which to evaluate e1, and a context C2 = (oe2; \Psi 2; S2)
in which to evaluate e2. Furthermore, we'll have to make sure that C1 and C2 are
observationally equivalent (denoted C1 ssobs C2).

This brings us to the second challenge which is the definition of C1 ssobs C2. I
won't define ssobs here. Instead, I'll characterize the desired definition by presenting
examples of pairs of observationally equivalent and inequivalent contexts. For each

149

of the examples that follow, assume that we wish to reason about the operational
equivalence of the expressions e1 and e2, where:

* e1 denotes let = x := (! x + 1) in x := (! x + 1)

* e2 denotes x := (! x + 2)
Also, in each example, let C1 = (oe1; \Psi 1; S1) denote the context in which we evaluate
e1 and let C2 = (oe2; \Psi 2; S2) denote the context in which we evaluate e2.

Scenario 1 Figure 8.1(a) illustrates contexts C1 = (oe1; \Psi 1; S1) and C2 = (oe2; \Psi 2; S2).
We wish to construct a model where ssobs is defined so that C1 ssobs C2 holds. This
is easy to do since C1 and C2 are identical. Furthermore, we must specify the semantics of \Gamma  |= e1 <= e2 : o/ so that it allows us to conclude that if C1 ssobs C2, then
the evaluation of C1[e1] and C2[e2] results in observationally equivalent contexts:
(oe1; \Psi 1; S1 [100 7! 7]) ssobs (oe2; \Psi 2; S2 [100 7! 7]).

Scenario 2 Consider the contexts C1 and C2 depicted in Figure 8.1(b). These
contexts are not identical but given a language that does not support equality testing
for references it is impossible to write a well-typed program that can distinguish
between them. Therefore, in a semantic model for such a language, C1 ssobs C2 holds.
Such a model would require some way of keeping track of the fact that location 100
in C1 is related to location 105 in C2. For this particular example, given the relation
R = { (100; 105) }, we can conclude that C1 ssobs C2 since \Psi 1(100) = \Psi 2(R(100))
and S1(100) = S2(R(100)).

Scenario 3 For the contexts C1 and C2 in Figure 8.2(a) reasoning about observational equivalence is harder due to aliasing. Nonetheless, the contexts are observationally equivalent: in both cases, variables x and z point to cells that contain
equivalent values, while variable y points to a cell whose contents point to the same
cell as variable x. Evaluating e1 and e2 in their respective contexts results in the
(observationally equivalent) contexts depicted in Figure 8.2(b). In a model that can
somehow keep track of how locations in C1 are related to locations in C2 (perhaps
using a relation R as in the previous example), one can conclude that C1 ssobs C2.

Scenario 4 The contexts depicted in Figure 8.3(a) are identical to those in Figure 8.2(a) except for the fact that in context C2 of Figure 8.3(a), the variable y points
to a cell whose contents point to the location aliased by z instead of x. Evaluating e1
and e2 in their respective contexts results in the contexts depicted in Figure 8.3(b)
-- I'll refer to these as C01 and C02. Clearly the latter are not observationally equivalent; for instance, the program ! (! y) can distinguish between them. Hence, our

150

{100 a int,

103 a ref int,

105 a int}

5100
101

x x

102
103
104
105

S1 \Psi 1

{100 a int,

102 a ref int,

105 a int}

S2 \Psi 2
100
101

102
103
104
105

\Gamma = {x:ref int ,

y:ref (ref int) ,z:

ref int }

s1 = {x a 100 ,y

a 102 ,

z a 105 }

s2 = {x a 105 ,y

a 103 ,

z a 100 }

5
yy
z z5

5

(a) Scenario 3: Before

{100 a int,

103 a ref int,

105 a int}

7100
101

x x

102
103
104
105

S'1 \Psi '1

{100 a int,

102 a ref int,

105 a int}

S'2 \Psi '2
100
101

102
103
104
105 7

yy
z z5

5

(b) Scenario 3: After
Figure 8.2: Observational Equivalence and Aliasing
model should conclude that neither of the two pairs of contexts in Figure 8.3 are
observationally equivalent.

This last conclusion is not entirely satisfactory, however. Imagine a scenario
where we know more about the program context in which e1 and e2 will be placed.

151

{100 a int,

103 a ref int,

105 a int}

5100
101

x x

102
103
104
105

S1 \Psi 1

{100 a int,

102 a ref int,

105 a int}

S2 \Psi 2
100
101

102
103
104
105

\Gamma = {x:ref int ,

y:ref (ref int) ,z:

ref int }

s1 = {x a 100 ,y

a 102 ,

z a 105 }

s2 = {x a 105 ,y

a 103 ,

z a 100 }

5
yy
z z5

5

(a) Scenario 4: Before

{100 a int,

103 a ref int,

105 a int}

7100
101

x x

102
103
104
105

S'1 \Psi '1

{100 a int,

102 a ref int,

105 a int}

S'2 \Psi '2
100
101

102
103
104
105 7

yy
z z5

5

(b) Scenario 4: After -- States Distinguishable Via y

Figure 8.3: Observationally Equivalent?
For instance, suppose that an optimizing compiler that wants to replace a program
fragment e1 with an observationally equivalent fragment e2 can guarantee that the
code to be executed after e1 (alternatively e2) will not dereference y. In such a
situation, it is safe to consider the contexts C01 and C02 observationally equivalent.

152

Alternatively, if we know that the code to be executed after e1 dereferences y, but
that it can only run safely for at most one step after that dereference, then it would
again be safe to consider C01 and C02 observationally equivalent.

Building a flexible model that can track such information is nontrivial. On the
one hand, we need a richer model of evaluation contexts than what I've informally
proposed above. On the other hand, more complicated contexts make it harder to
define both observational equivalence and the accessibility (or extend-state) relation
on worlds.

153
Bibliography
[AAV02] Amal Ahmed, Andrew W. Appel, and Roberto Virga. A stratified

semantics of general references embeddable in higher-order logic. In
IEEE Symposium on Logic in Computer Science (LICS), Copenhagen,
Denmark, pages 75-86, July 2002. 38, 46

[AAV03] Amal Ahmed, Andrew W. Appel, and Roberto Virga. An

indexed model of impredicative polymorphism and mutable references. Available at http:// www.cs.princeton.edu/,appel/
papers/impred.pdf, January 2003. 38

[Acz88] Peter Aczel. Non-Well-Founded Sets. Center for the Study of Language

and Information, Stanford University, 1988. 101

[AF00] Andrew W. Appel and Amy P. Felty. A semantic model of types and

machine instructions for proof-carrying code. In ACM Symposium on
Principles of Programming Languages (POPL), Boston, Massachusetts,
pages 243-253, January 2000. 7, 9, 15

[AHM98] Samson Abramsky, Kohei Honda, and Guy McCusker. A fully abstract

game semantics for general references. In IEEE Symposium on Logic in
Computer Science (LICS), Indianapolis, Indiana, pages 334-344, June
1998. 11, 38, 103, 147

[AJW03] Amal Ahmed, Limin Jia, and David Walker. Reasoning about hierarchical storage. In IEEE Symposium on Logic in Computer Science
(LICS), Ottawa, Canada, pages 33-44, June 2003. 135

[AM01] Andrew W. Appel and David McAllester. An indexed model of recursive types for foundational proof-carrying code. ACM Transactions on
Programming Languages and Systems, 23(5):657-683, September 2001.
9, 13, 46, 63, 85, 148

[AMSV02] Andrew W. Appel, Neophytos Michael, Aaron Stump, and Roberto

Virga. A trustworthy proof checker. In Iliano Cervesato, editor, Workshop on the Foundations of Computer Security, pages 37-48. DIKU,

154

BIBLIOGRAPHY 155

July 2002. diku.dk/publikationer/tekniske.rapporter/2002/02-12.pdf.
107

[And72] J. P. Anderson. Computer security technology planning study vols.

i and iii. Technical Report ESD-TR-73-51, HQ Electronic Systems
Division: Hanscom AFB, MA, Fort Washington, Pennsylvania, October
1972. 3

[App01] Andrew W. Appel. Foundational proof-carrying code. In IEEE Symposium on Logic in Computer Science (LICS), Boston, Massachusetts,
pages 247-258. IEEE, June 2001. 7

[ARSA04] Andrew W. Appel, Christopher D. Richards, Kedar N. Swadi, and Amal

Ahmed. A machine-checkable soundness proof for typed machine language. Submitted for publication, April 2004. 128

[AW02] Andrew W. Appel and Daniel C. Wang. JVM TCB: Measurements of

the trusted computing base of Java virtual machines. Technical Report
CS-TR-647-02, Princeton University, April 2002. 7, 123

[BBC+98] Bruno Barras, Samuel Boutin, Cristina Cornes, Judica"el Courant,

Yann Coscoy, David Delahaye, Daniel de Rauglaudre, Jean-Christophe
Filli^atre, Eduardo Gim'enez, Hugo Herbelin, G'erard Huet, , Henri
Laulh`ere, C'esar Mu~noz, Chetan Murthy, Catherine Parent-Vigouroux,
Patrick Loiseleur, Christine Paulin-Mohring, Amokrane Sa"ibi, and Benjamin Werner. The Coq Proof Assistant reference manual. Technical
report, INRIA, 1998. 106, 133

[BCP99] Kim B. Bruce, Luca Cardelli, and Benjamin C. Pierce. Comparing

object encodings. Information and Computation, 155(1-2):108-133,
November-December 1999. 36

[BM96] Jon Barwise and Lawrence Moss. Vicious Circles: On the Mathematics

of Non-wellfounded Phenomena. Cambridge University Press, 1996. 101

[CAB+86] R. L. Constable, S. F. Allen, H. M. Bromley, W. R. Cleaveland, J. F.

Cremer, R. W. Harper, D. J. Howe, T. B. Knoblock, N. P. Mendler,
P. Panangaden, J. T. Sasaki, and S. F. Smith. Implementing Mathematics with the Nuprl Proof Development System. Prentice Hall, Englewood
Cliffs, New Jersey, 1986. 4, 15

[Car97] Luca Cardelli. Type systems. In A. B. Tucker, editor, The Computer

Science and Engineering Handbook. CRC Press, Boca Raton, Florida,
1997. 4

BIBLIOGRAPHY 156
[CGW89] Thierry Coquand, Carl A. Gunter, and Glynn Winskel. Domain

theoretic models of polymorphism. Information and Computation,
81(2):123-167, 1989. 37

[CH88] Thierry Coquand and G'erard Huet. The calculus of constructions.

Information and Computation, 76(2/3):95-120, February/March 1988.
105, 106, 133

[Che04] Juan Chen. A Low-Level Typed Assembly Language with a MachineCheckable Soundness Proof. PhD thesis, Princeton University, June
2004. 121

[CLN+00] Christopher Colby, Peter Lee, George C. Necula, Fred Blau, Ken Cline,

and Mark Plesko. A certifying compiler for Java. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), Vancouver, British Columbia, Canada. ACM Press, June
2000. 8, 123, 124

[Cra03] Karl Crary. Toward a foundational typed assembly language. In ACM

Symposium on Principles of Programming Languages (POPL), New
Orleans, Louisiana, pages 198-212, January 2003. 133

[CWAF03] Juan Chen, Dinghao Wu, Andrew W. Appel, and Hai Fang. A provably

sound TAL for back-end optimization. In ACM SIGPLAN Conference
on Programming Language Design and Implementation (PLDI), San
Diego, California, pages 208-219. ACM Press, June 2003. 121, 122

[CWM99] Karl Crary, David Walker, and Greg Morrisett. Typed memory management in a calculus of capabilities. In ACM Symposium on Principles
of Programming Languages (POPL), San Antonio, Texas, pages 262-
275, January 1999. 135, 136

[DG71] P. Deutsch and C. A. Grant. A flexible measurement tool for software

systems. In Information Processing (Proceedings of the IFIP Congress),
pages 320-326, 1971. 3

[DMTW97] Allyn Dimock, Robert Muller, Franklyn Turbak, and J. B. Wells.

Strongly typed flow-directed representation transformations. In International Conference on Functional Programming (ICFP), Amsterdam,
The Netherlands, pages 85-98, June 1997. 5

[ES00a] 'Ulfar Erlingsson and Fred B. Schneider. IRM enforcement of java stack

inspection. In IEEE Symposium on Security and Privacy, pages 246-
255, Oakland, California, May 2000. 3

BIBLIOGRAPHY 157
[ES00b] 'Ulfar Erlingsson and Fred B. Schneider. SASI enforcement of security

policies: A retrospective. In WNSP: New Security Paradigms Workshop. ACM Press, 2000. 3

[ET99] David Evans and Andrew Twyman. Flexible policy-directed code safety.

In IEEE Security and Privacy, pages 32-45, Oakland, CA, May 1999.
3

[FJM+96] M. P. Fiore, A. Jung, E. Moggi, P. O'Hearn, J. Riecke, G. Rosolini,

and I. Stark. Domains and denotational semantics: History, accomplishments and open problems. Technical Report CSR-96-2, School of
Computer Science, The University of Birmingham, 1996. 30pp., available from http://www.cs.bham.ac.uk/. 37

[FKT01] Ian Foster, Carl Kesselman, and Steven Tuecke. The anatomy of the

Grid: Enabling scalable virtual organizations. International Journal of
Supercomputer Applications, 15(3):200-222, 2001. 1

[Gro02] Dan Grossman. Existential types for imperative languages. In European

Symp. on Programming (ESOP), pages 21-33, Grenoble, France, April
2002. 96, 99

[Gun92] Carl A. Gunter. Semantics of Programming Languages. MIT Press,

Cambridge, Massachusetts, 1992. 20

[Har96] Robert Harper. A note on: "A simplified account of polymorphic references" [Inform. Process. Lett. 51 (1994), no. 4, 201-206; MR 95f:68142].
Information Processing Letters, 57(1):15-16, 1996. 103

[HHP93] Robert Harper, Furio Honsell, and Gordon Plotkin. A framework for

defining logics. Journal of the ACM, 40(1):143-184, January 1993. 8,
105, 107, 134

[Hin75] K. Jaakko Hintikka. Impossible possible worlds vindicated. Journal of

Philosophical Logic, 4:475-484, 1975. 103

[HMS03] Kevin W. Hamlen, Greg Morrisett, and Fred B. Schneider. Computability classes for enforcement mechanisms. Technical Report TR 2003-
1908, Cornell University, August 2003. 3

[How89] Douglas J. Howe. Equality in lazy computation systems. In Proceedings

of the Fourth Annual Symposium of Logic in Computer Science, pages
198-203, Asilomar Conference Center, Pacific Grove, California, June
1989. IEEE Computer Society Press. 148

BIBLIOGRAPHY 158
[How96] Douglas J. Howe. Proving congruence of bisimulation in functional

programming languages. Information and Computation, 124(2):103-
112, 1996. 148

[HPW91] Paul Hudak, Simon Peyton Jones, and Philip Wadler. Report on the

programming language Haskell: Version 1.1. Technical report, Yale
University and Glasgow University, August 1991. 36

[HR98] Nevin C. Heintze and Jon G. Riecke. The SLam Calculus: Programming with secrecy and integrity. In ACM Symposium on Principles
of Programming Languages (POPL), San Diego, California, January
1998. 4

[HR00] Michael R. A. Huth and Mark D. Ryan. Logic in Computer Science:

Modelling and reasoning about systems. Cambridge University Press,
Cambridge, England, 2000. 26

[HST+02] Nadeem Hamid, Zhong Shao, Valery Trifonov, Stefan Monnier, and

Zhaozhong Ni. A syntactic approach to foundational proof-carrying
code. In IEEE Symposium on Logic in Computer Science (LICS),
Copenhagen, Denmark, pages 89-100, July 2002. 133

[Hug97] Dominic J. D. Hughes. Games and definability for System F. In IEEE

Symposium on Logic in Computer Science (LICS), Warsaw, Poland,
pages 76-86, June 1997. 103

[JM91] Trevor Jim and Albert R. Meyer. Full absraction and the context

lemma. In Takayasu Ito and Albert R. Meyer, editors, Theoretical
Aspects of Computer Software (TACS), volume 526 of Lecture Notes in
Computer Science, pages 131-151. Springer, 1991. 148

[Kri63] Saul A. Kripke. Semantical considerations on modal logic. In Proceedings of a Colloquium: Modal and Many Valued Logics, volume 16, pages
83-94, 1963. 25

[Lam71] Butler Lampson. Protection. In Proceedings of the 5th Symposium

on Information Sciences and Systems, pages 437-443, Princeton, New
Jersey, 1971. 3

[Lam77] Leslie Lamport. Proving the correctness of multiprocess programs.

IEEE Transactions on Software Engineering, SE-3:125-143, March
1977. 3

[Lea02] Christopher Adam League. A Type-Preserving Compiler Infrastructure.

PhD thesis, Yale University, May 2002. 36

BIBLIOGRAPHY 159
[Lev01] Paul Blain Levy. Call-by-Push-Value. Ph. D. dissertation, Queen Mary,

University of London, London, UK, March 2001. 101

[Lev02] Paul Blain Levy. Possible world semantics for general storage in call-byvalue. In Computer Science Logic, 16th International Workshop, CSL
2002 Proceedings, volume 2471 of Lecture Notes in Computer Science,
pages 232-246, Edinburgh, Scotland, UK, September 2002. Springer.
11, 38, 101, 103, 147

[LST03] Christopher League, Zhong Shao, and Valery Trifonov. Precision in

practice: A type-preserving Java compiler. In 12th International Conference on Compiler Construction (CC'03), April 2003. 8

[LY99] Tim Lindholm and Frank Yellin. The Java Virtual Machine Specification. Addison-Wesley, second edition, 1999. 3, 5

[MA00] Neophytos G. Michael and Andrew W. Appel. Machine instruction

syntax and semantics in higher-order logic. In 17th International Conference on Automated Deduction, June 2000. 8, 123, 124

[MCG+99] Greg Morrisett, Karl Crary, Neal Glew, Dan Grossman, Richard

Samuels, Frederick Smith, David Walker, Stephanie Weirich, and Steve
Zdancewic. TALx86: A realistic typed assembly language. In ACM
Workshop on Compiler Support for System Software, pages 25-35, Atlanta, GA, May 1999. 5, 134

[Mil77] Robin Milner. Fully abstract models of typed lambda calculi. Theoretical Computer Science, 4(1), 1977. 148

[Mit96] John C. Mitchell. Foundations for Programming Languages. MIT Press,

Cambridge, Massachusetts, 1996. 20, 33

[MMH96] Yasuhiko Minamide, Greg Morrisett, and Robert Harper. Typed closure conversion. In ACM Symposium on Principles of Programming
Languages (POPL), St. Petersburg Beach, Florida, pages 271-283, January 1996. 36, 37

[MP88] John C. Mitchell and Gordon D. Plotkin. Abstract types have existential type. ACM Transactions on Programming Languages and Systems,
10(3):470-502, July 1988. 36

[MPS86] David MacQueen, Gordon Plotkin, and Ravi Sethi. An ideal model for

recursive polymophic types. Information and Computation, 71(1/2):95-
130, 1986. 63

BIBLIOGRAPHY 160
[MT89] Ian A. Mason and Carolyn L. Talcott. Axiomatizing operational equivalence in the presence of side effects. In Proceedings of the Fourth Annual
Symposium of Logic in Computer Science, pages 284-293, Asilomar
Conference Center, Pacific Grove, California, June 1989. IEEE Computer Society Press. Extended version appeared as "Inferring the equivalence of functional programs that mutate data," Theoretical Computer
Science, 105(2):167-215, 9 November 1992. 148

[MT91a] Ian A. Mason and Carolyn L. Talcott. Equivalence in functional languages with effects. Journal of Functional Programming, 1(3):287-327,
1991. 148

[MT91b] Robin Milner and Mads Tofte. Co-induction in relational semantics.

Theoretical Computer Science, 87(1):209-220, 1991. 101

[MT92] Ian A. Mason and Carolyn L. Talcott. References, local variables and

operational reasoning. In IEEE Symposium on Logic in Computer Science (LICS), Santa Cruz, California, pages 186-197, June 1992. 148

[MWCG98] Greg Morrisett, David Walker, Karl Crary, and Neal Glew. From System F to typed assembly language. In ACM Symposium on Principles of
Programming Languages (POPL), San Diego, California, pages 85-97,
January 1998. 5

[MWCG99] Greg Morrisett, David Walker, Karl Crary, and Neal Glew. From System F to typed assembly language. ACM Transactions on Programming
Languages and Systems, 21(3):527-568, May 1999. 3, 5, 36, 37, 134

[Mye99] Andrew C. Myers. Practical mostly-static information flow control. In

ACM Symposium on Principles of Programming Languages (POPL),
San Antonio, Texas, pages 228-241. ACM Press, January 1999. 3

[Nac97] Carey Nachenberg. Computer virus-antivirus coevolution. Communications of the ACM, 40(1):46-51, January 1997. 3

[Nec97] George Necula. Proof-carrying code. In ACM Symposium on Principles of Programming Languages (POPL), Paris, France, pages 106-119.
ACM Press, January 1997. 6

[NL98a] George Necula and Peter Lee. The design and implementation of a certifying compiler. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), Montreal, Canada, pages
333 - 344, June 1998. 6, 7, 124

BIBLIOGRAPHY 161
[NL98b] George C. Necula and Peter Lee. Efficient representation and validation

of proofs. In IEEE Symposium on Logic in Computer Science (LICS),
Indianapolis, Indiana, June 1998. 124

[NR01] George C. Necula and S. P. Rahul. Oracle-based checking of untrusted

software. In ACM Symposium on Principles of Programming Languages
(POPL), London, England, pages 142-154. ACM Press, January 2001.
123, 124

[Ole82] Frank Joseph Oles. A Category-Theoretic Approach to the Semantics

of Programming Languages. Ph. D. dissertation, Syracuse University,
Syracuse, New York, August 1982. 101, 103

[Ole85] Frank Joseph Oles. Type algebras, functor categories, and block structure. In Maurice Nivat and John C. Reynolds, editors, Algebraic Methods in Semantics, pages 543-573. Cambridge University Press, Cambridge, England, 1985. 101, 103

[Ole97] Frank Joseph Oles. Functor categories and store shapes. In Peter W.

O'Hearn and Robert D. Tennent, editors, ALGOL-like Languages, Volume 2, pages 3-12. Birkh"auser, Boston, Massachusetts, 1997. 101, 103

[Par69] D. Park. Fixpoint induction and proofs of program properties. In

B. Meltzer and D. Michie, editors, Machine Intelligence, volume 5,
pages 59-78, Edinburgh, 1969. Edinburgh University Press. 101

[Par02] Manish Parashar, editor. Grid Computing - GRID 2002, Third International Workshop, Baltimore, Maryland, USA, November 18, 2002, Proceedings, volume 2536 of Lecture Notes in Computer Science. Springer,
2002. 1

[Per93] Jaroslav Peregrin. Possible worlds: A critical analysis. The Prague

Bulletin of Mathematical Linguistics, 59-60:9-21, 1993. 101

[Pie02] Benjamin C. Pierce. Types and Programming Languages. MIT Press,

2002. 20, 36

[Pit96] Andrew M. Pitts. Relational properties of domains. Information and

Computation, 127(2):66-90, 1996. 148

[Pit98] Andrew M. Pitts. Existential types: Logical relations and operational

equivalence. Lecture Notes in Computer Science, 1443:309-326, 1998.
104, 148

BIBLIOGRAPHY 162
[Pit00] Andrew M. Pitts. Parametric polymorphism and operational equivalence. Mathematical Structures in Computer Science, 10:321-359, 2000.
104, 148

[Pit02] Andrew M. Pitts. Operational semantics and program equivalence.

In G. Barthe, P. Dybjer, L. Pinto, and J. Saraiva, editors, Applied Semantics: Advanced Lectures, volume 2395 of Lecture Notes in Computer
Science, pages 378-412. Springer-Verlag, 2002. 104, 148

[PJHH+93] Simon L. Peyton Jones, Cordelia V. Hall, Kevin Hammond, Will Partain, and Philip Wadler. The Glasgow Haskell compiler: a technical
overview. In Proc. UK Joint Framework for Information Technology
(JFIT) Technical Conference, July 1993. 5

[PM93] Christine Paulin-Mohring. Inductive definitions in the system Coq;

rules and properties. In M. Bezem and J. F. Groote, editors, Proceedings of the International Conference on Typed Lambda Calculi and
Applications, volume 664 of Lecture Notes in Computer Science, pages
328-345. Springer-Verlag, 1993. 105, 106, 133

[PS93] Andrew M. Pitts and Ian D. B. Stark. Observable properties of higher

order functions that dynamically create local names, or: What's new?
In Andrzej M. Borzyszkowski and Stefan Sokolowski, editors, Mathematical Foundations of Computer Science, volume 711 of Lecture Notes
in Computer Science, pages 122-141, Berlin, 1993. Springer-Verlag.
101, 148

[PS99] Frank Pfenning and Carsten Sch"urmann. System description: Twelf

-- a meta-logical framework for deductive systems. In The 16th International Conference on Automated Deduction. Springer-Verlag, July
1999. 8, 105, 134

[RC91] Jonathan Rees and William Clinger. Revised4 report on the algorithmic

language Scheme. Lisp Pointers, 4(3):1-55, July-September 1991. 3

[Rey81] John C. Reynolds. The essence of Algol. In Jaco W. de Bakker and J. C.

van Vliet, editors, Algorithmic Languages, pages 345-372, Amsterdam,
1981. North-Holland. 101, 103

[Rey83] John C. Reynolds. Types, abstraction, and parametric polymorphism.

Information Processing, pages 513-523, 1983. 4

[RP95] Eike Ritter and Andrew M. Pitts. A fully abstract translation between

a lambda-calculus with reference types and Standard ML. In Mariangiola Dezani-Ciancaglini and Gordon D. Plotkin, editors, Typed Lambda

BIBLIOGRAPHY 163

Calculi and Applications (TLCA), Edinburgh, UK, volume 902 of Lecture Notes in Computer Science, pages 397-413. Springer, April 1995.
148

[SA95] Zhong Shao and Andrew W. Appel. A type-based compiler for Standard

ML. In ACM SIGPLAN Conference on Programming Language Design
and Implementation (PLDI), La Jolla, California, pages 116-129. ACM
Press, 1995. 5

[Sch00a] Fred B. Schneider. Enforceable security policies. ACM Transactions on

Information and Systems Security, 3(1):30-50, February 2000. 3

[Sch00b] Carsten Sch"urmann. Automating the Meta-Theory of Deductive Systems. Ph. D. thesis, Carnegie Mellon University, Pittsburgh, PA, 2000.
134

[Sma97] Christopher Small. MiSFIT: A tool for constructing safe extensible

C++ systems. In Proceedings of the Third USENIX Conference on
Object-Oriented Technologies, Portland, OR, June 1997. 3

[SP01] Eijiro Sumii and Benjamin C. Pierce. Logical relations for encryption.

In Computer Security Foundations Workshop, June 2001. To appear in
Journal of Computer Security. 4

[SS75] Jerome H. Saltzer and Michael D. Schroeder. The protection of information in computer systems. Proceedings of the IEEE, 63(9):1278-1308,
September 1975. 7

[Sta94] Ian D. B. Stark. Names and Higher-Order Functions. Ph. D. dissertation, University of Cambridge, Cambridge, England, December 1994.
101

[Swa03] Kedar N. Swadi. Typed Machine Language. PhD thesis, Princeton

University, November 2003. 96, 123, 128

[SWM00] Frederick Smith, David Walker, and Greg Morrisett. Alias types. In European Symp. on Programming (ESOP), pages 366-381, Berlin, March
2000. 9

[TA04] Gang Tan and Andrew W. Appel. A typed calculus for machine instructions and its semantics in higher-order logic. Submitted for publication,
February 2004. 123, 131

BIBLIOGRAPHY 164
[TASW04] Gang Tan, Andrew W. Appel, Kedar N. Swadi, and Dinghao Wu. Construction of a semantic model for a typed assembly language. In Bernhard Steffen and Giorgio Levi, editors, Fifth International Conference
on Verification, Model Checking, and Abstract Interpretation (VMCAI
'04), volume 2937 of LNCS, pages 30-43. Springer Verlag Lecture Notes
in Computer Science, January 2004. 123, 130, 132

[TG00] Robert D. Tennent and Dan R. Ghica. Abstract models of storage.

Higher-Order and Symbolic Computation, 13(1/2):119-129, 2000. 37

[TMC+96] D. Tarditi, G. Morrisett, P. Cheng, C. Stone, R. Harper, and P. Lee.

TIL: A type-directed optimizing compiler for ML. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), Philadephia, Pennsylvania, pages 181-192, May 1996.
5

[Tof90] Mads Tofte. Type inference for polymorphic references. Information

and Computation, 89:1-34, November 1990. 96, 103

[TT94] Mads Tofte and Jean-Pierre Talpin. Implementation of the typed

call-by-value *-calculus using a stack of regions. In ACM Symposium
on Principles of Programming Languages (POPL), Portland, Oregon,
pages 188-201, January 1994. 135

[TT97] Mads Tofte and Jean-Pierre Talpin. Region-based memory management. Information and Computation, 132(2):109-176, 1997. 135

[Vis00] Mahesh Viswanathan. Foundations for the Run-time Analysis of Software Systems. Ph. D. thesis, University of Pennsylvania, 2000. 3

[Wad89] Philip Wadler. Theorems for free! In ACM Symposium on Functional

Programming Languages and Computer Architecture (FPCA), London,
September 1989. 4, 99

[Wal01] David Walker. Typed Memory Management. Ph. D. thesis, Cornell

University, 2001. 9, 135, 136, 137

[WAS03] Dinghao Wu, Andrew W. Appel, and Aaron Stump. Foundational proof

checkers with small witnesses. In 5th ACM SIGPLAN International
Conference on Principles and Practice of Declarative Programming, August 2003. 107, 123, 124

[WCM00] David Walker, Karl Crary, and Greg Morrisett. Typed memory management in a calculus of capabilities. ACM Transactions on Programming
Languages and Systems, 22(4):701-771, May 2000. 135, 136, 137

BIBLIOGRAPHY 165
[WF94] Andrew K. Wright and Matthias Felleisen. A syntactic approach to type

soundness. Information and Computation, 115(1):38-94, 15 November
1994. 9, 133

[WLAG93] Robert Wahbe, Steven Lucco, Thomas Anderson, and Susan Graham.

Efficient software-based fault isolation. In Proceedings of the 14th ACM
Symposium on Operating Systems Principles (SOSP), pages 203-216,
December 1993. 3

[WM00] David Walker and Greg Morrisett. Alias types for recursive data structures. In Workshop on Types in Compilation, Montreal, Canada, September 2000. 9

[WS97] Mitchell Wand and Gregory T. Sullivan. Denotational semantics using

an operationally-based term model. In ACM Symposium on Principles of Programming Languages (POPL), Paris, France, pages 386-399,
January 1997. 104

[XP98] Hongwei Xi and Frank Pfenning. Eliminating array bound checking

through dependent types. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), Montreal, Canada,
pages 249-257, June 1998. 4

[XP99] Hongwei Xi and Frank Pfenning. Dependent types in practical programming. In ACM Symposium on Principles of Programming Languages
(POPL), San Antonio, Texas, pages 214-227, January 1999. 4