

Optimal Representations of Polymorphic Types with Subtyping

Alexander Aiken\Lambda  Edward L. Wimmersy Jens Palsbergz

Abstract
Many type inference and program analysis systems include notions of subtyping and parametric
polymorphism. When used together, these two features induce equivalences that allow types to be
simplified by eliminating quantified variables. Eliminating variables both improves the readability of
types and the performance of algorithms whose complexity depends on the number of type variables.
We present an algorithm for simplifying quantified types in the presence of subtyping and prove it
is sound and complete for non-recursive and recursive types. We also show that an extension of the
algorithm is sound but not complete for a type language with intersection and union types, as well as
for a language of constrained types.

1 Introduction
Contemporary type systems include a wide array of features, of which two of the most important are subtyping and parametric polymorphism. These two features are independently useful. Subtyping expresses
relationships between types of the form "type o/1 is less than type o/2". Such relationships are useful,
for example, in object-oriented type systems and in program analysis algorithms where a greatest (or
least) element is required. Parametric polymorphism allows a parameterized type inferred for a program
fragment to take on a different instance in every context where it is used. This feature has the advantage
that the same program can be used at many different types.

A number of type systems have been proposed that combine subtyping and polymorphism, among
other features. The intended purposes of these systems varies. A few examples are: studies of type systems
themselves [CW85, Cur90, AW93], proposals for type systems for object-oriented languages [EST95], and
program analysis systems used in program optimization [AWL94, HM94]. In short, the combination of
subtyping and polymorphism is useful, with a wide range of applications.

When taken together, subtyping and polymorphism induce equivalences on types that can be exploited
to simplify the representation of types. Our main technical result is that, in a simple type language with
a least type ? and greatest type ?, for any type oe there is another type oe0 that is equivalent to oe and
oe0 has the minimum number of quantified type variables. Thus, type simplification eliminates quantified
variables wherever possible. Eliminating variables is desirable for three reasons. First, many type inference algorithms have computational complexity that is sensitive (both theoretically and practically) to
the number of type variables. Second, eliminating variables makes types more readable. Third, simplification makes properties of types manifest that are otherwise implicit; in at least one case that we know

\Lambda Author's address: EECS Department, University of California at Berkeley, Berkeley, CA 94720-1776. Email:
aiken@cs.berkeley.edu. This work was supported by an NSF NYI award, CCR-9457812

yAuthor's address: IBM Almaden Research Center, 650 Harry Rd., San Jose, CA 95120-6099. Email:

wimmers@almaden.ibm.com

zAuthor's address: Department of Computer Science, Purdue University, West Lafayette, IN 47907. Email:

palsberg@cs.purdue.edu.

1

of, these "hidden" properties are exactly the information needed to justify compiler optimizations based
on type information [AWL94].

The basic idea behind variable elimination is best illustrated with an example. A few definitions are
needed first. Consider a simple type language defined by the following grammar:

o/ ::= ff j ? j ? j o/1 ! o/2
In this grammar, ff is a type variable. Following standard practice, we use ff; fi; : : : for type variables and
o/; o/ 0; o/1; o/2; : : : for types. The subtyping relation is a partial order _ on types, which is the least relation
satisfying

o/ _ o/
? _ o/

o/ _ ?
o/1 _ o/ 01 ^ o/2 _ o/ 02 , o/ 01 ! o/2 _ o/1 ! o/ 02

Quantified types are given by the grammar:

oe ::= o/ j 8ff:oe
For the moment, we rely on the reader's intuition about the meaning of quantified types. A formal
semantics of quantified types is presented in Section 2.

Consider the type 8ff:8fi:ff ! fi. Any function with this type takes an input of an arbitrary type ff
and produces an output of any (possibly distinct) arbitrary type fi. What functions have this type? The
output fi must be included in all possible types; there is only one such type ?. The input ff, however,
must include all possible types; there is only one such type ?. Thus, one might suspect that this type is
equivalent to ? !?. The only function with this type is the one that diverges for all possible inputs.

It turns out that, in fact, 8ff:8fi:ff ! fi j ? ! ? in the standard ideal model of types [MPS84]. As
argued above, the type with fewer variables is better for human readability, the speed of type inference,
and for the automatic exploitation of type information by a compiler. We briefly illustrate these three
claims.

The reasoning required to discover that 8ff:8fi:ff ! fi represents an everywhere-divergent function
is non-trivial. There is a published account illustrating how types inferred from ML programs (which
have polymorphism but no subtyping) can be used to detect non-terminating functions exactly as above
[Koe94]. The previous example is the simplest one possible; the problem of understanding types only
increases with the size of the type and expressiveness of the type language. The following example is
taken from the system of [AW93], a subtype inference system with polymorphism. In typing a term, the
inference algorithm in this system generates a system of subtyping constraints that must be satisfied.
The solution of the constraints gives the desired type. Constraints are generated as follows: If f has type
ff ! fi and x has type fl, then for an application f x to be well-typed it must be the case that fl _ ff.
Figure 1 shows the type generated for the divergent lambda term (*x:x x)(*x:x x). The type has the
form

8ff1; : : : ; ff8:(ff6=S)

Informally, the meaning of this type is ff6 for any assignment to the variables ff1; : : : ; ff8 that simultaneously satisfies all the constraints in S.

This type is equal to ?, a fact proven by our algorithm extended to handle constraints. The type
? is sound, since the term is divergent. This example illustrates both improved readability and the

2

8ff1: : : : 8ff8: ff6 =

8???????

???????!

??????????
????:

ff4 ! ff6 _ ff1 _ ff5 ! ff6

ff1 _ ff2 ! ff3
ff1 _ ff2 _ ff5 ! ff6

? _ ff3 _ ?
ff2 _ ff4 _ ff5 ! ff6
ff4 _ ff5 _ ff4

? _ ff6 _ ff3
ff4 ! ff6 _ ff7 _ ff1

ff3 _ ff8 _ ?

Figure 1: A quantified type of eight variables qualified by constraints.
possibility of more efficient inference. To use the polymorphic type 8ff1; : : : ; ffn:(o/ =S), the variables must
be instantiated and the constraints duplicated for each usage context. Eliminating variables simplifies
the representation, making this very expensive aspect of type inference less costly.

Finally, simplifying types can improve not only the speed but the quality of program analyses. For
example, the soft typing system of [AWL94] reduces the problem of identifying where runtime type checks
are unneeded in a program to testing whether certain type variables can be replaced by ? in a quantified
type. This is exactly the task performed by elimination of variables in quantified types.

Our main contribution is a variable elimination algorithm that is sound and complete (i.e., eliminates
as many variables as possible) for the simple type language defined above, as well as for a type language
with recursive types. We extend the algorithm to type languages with intersection and union types and
to type languages with subsidiary constraints. For these latter two cases, the techniques we present are
sound but not complete. Combining the completeness results for the simpler languages with examples
illustrating the incompleteness of the algorithm in the more expressive settings, we shed some light on
the sources of incompleteness.

The various algorithms are simple and efficient. Let n be the print size of the type and m be the
number of variables. Then the time complexity is O(mn) for the cases of simple and recursive types
and O(m2n) for the cases of systems with intersection, union, or constrained types. The algorithm
for simplifying quantified types with subsidiary constraints has been in use since 1993, but with the
exception of code documentation little has been written previously on the subject. The algorithm has
been implemented and used in Illyria1, the systems reported in [AW93], a large scale program analysis
system for the functional language FL [AWL94], and a general-purpose constraint-based program analysis
system [FA96]. These last two applications are by far the largest and best engineered. The quality of
these system depends on eliminating variables wherever possible.

Other recent systems based on constrained types have also pointed out the importance of variable
elimination. In [EST95], Eifrig, Smith, and Trifonov describe a variable elimination method similar, but
not identical too, the one in Section 7. Pottier gives a method that can eliminate redundant variables
from constraint sets [Pot96]. Both of these methods are heuristic; i.e., they are sound but not complete.
Constraint simplification is also a component of the systems described in [Kae92, Smi94]. It is not claimed
that either system performs complete constraint simplification.

Our focus in this paper is quite different. The question of variable elimination arises in any type

1The source code for the Illyria system and an interactive demo are available at URL
http://www.cs.berkeley.edu/~aiken/Illyria-demo.html.

3

system with polymorphism and subtyping, not just in systems with constrained types. Our purpose is
to explore the basic structure of this problem in the simplest settings and to understand what makes the
problem harder in the case of constrained types. To the best of our knowledge, we present the first sound
and complete algorithms for variable elimination in any type system.

Rather than work in a specific semantic domain, we state axioms that a semantic domain must satisfy
for our techniques to apply (Section 2). Section 3 gives the syntax for type expressions as well as their
interpretation in the semantic domain.

Section 4 proves the results for the case of simple type expressions, which are non-recursive types. For
quantified simple types, variable elimination produces an equivalent type with the minimum number of
quantified variables. Furthermore, all equivalent types with the minimum number of quantified variables
are ff-equivalent--they are identical up to the names and order of quantified variables.

The intuition behind the variable elimination procedure is easy to convey. Type variables may be
classed as monotonic (positive) or anti-monotonic (negative) based on their syntactic position in a type.
Intuitively, the main lemma shows that quantified variables that are solely monotonic can be eliminated in
favor of ?; quantified variables that are solely anti-monotonic can be eliminated in favor of ?. Section 4.2
proves that the strategy of eliminating either monotonic or anti-monotonic variables is complete for the
simple type language. Variables that are both monotonic and anti-monotonic cannot be eliminated.

Section 5 extends the basic variable elimination algorithm to a type language with recursive types.
The extended algorithm is again both sound and complete, but it is no longer the case that all equivalent
types with the minimum number of quantified variables are ff-equivalent.

Section 6 extends the algorithm to intersection and union types. This language is the first extension for
which the techniques are sound but not complete. Examples are given showing sources of incompleteness.
Finally, Section 7 extends the algorithm to a type language with subsidiary constraints, as in Figure 1.
This is the most general type language we consider. Section 8 concludes with a few remarks on related
work.

2 Semantic Domains
Rather than work with a particular semantic domain, we axiomatize the properties needed to prove the
corresponding theorems about eliminating quantified variables.

Definition 2.1 A semantic domain D = (D0; D1; _; u) satisfies the following properties:

1. D0 ` D1 or, more generally, there is monomorphism from D0 to D1.
2. a partial order on D1 denoted by _.
3. a minimal element ? 2 D0 such that ? _ x for all x 2 D1.
4. a maximal element ? 2 D0 such that x _ ? for all x 2 D1.
5. a binary operation ! on D0 such that if y1 _ x1 and x2 _ y2, then x1 ! x2 _ y1 ! y2.

Furthermore, ? ! ? 6= ? and ? ! ? 6= ?.

6. a greatest lower bound operation u on D1 such that if D ` D1, then uD is the greatest lower bound

(or glb) of D.

In addition, the semantic domain D may satisfy some (or all) of the following properties:

4

standard function types

If x1 ! x2 _ y1 ! y2, then y1 _ x1 and x2 _ y2.

standard glb types

If S0 ` D0 and x1 2 D0, then uS0 _ x1 iff 9x0 2 S0 s.t. x0 _ x1.

An unusual aspect of Definition 2.1 is that a domain is built from two sets D0 and D1. This structure
parallels the two distinct operations provided in the type language: function space t1 ! t2 and universal
quantification 8 : : : (see Section 3). These operations impose different requirements on the semantic
domain, so allowing D0 and D1 to be different provides more generality than requiring that they be the
same. In particular, since the 8 quantifier introduces a glb operation (and hence produces a value in D1)
and the ! operation can be performed only on elements of D0, the 8 quantifier cannot appear inside of a
! operation. If the semantic domain has the property that D0 = D1, then it supports 8 quantifiers inside
of the ! operation. It is worth noting that separating D0 and D1 not only generalizes but simplifies some
of our results.

The following two examples illustrate the most important features of semantic domains and are used
throughout the paper.

Example 2.2 (Minimal Semantic Model) Let D0 = D1 be the three element set f?; ? ! ?; ?g and
let _ be the partial order ? _ ? ! ? _ ?. In this domain, all function types are the same and this type
domain does little more than detect that something is a function. For all x; y 2 D, x ! y = ? ! ?. It is
easy to check that D satisfies all properties required of a semantic domain as well as standard glb types.
The only property missing is standard function types (e.g., because ? ! ? _ ? ! ?, but ? 6_ ?).

Example 2.3 (Standard Model) Let D0 be the set consisting of ? and ? and closed under the pairing
operation (denoted using the ! symbol). An obvious partial order is induced on D0. Let D1 consist of
all the non-empty, upward-closed subsets of D0. Intuitively, each element of D1 represents the glb of its
members. Define d0 _ d1 iff d0 ' d1. Note that there is an obvious inclusion mapping from D0 to D1 by
mapping each element of D0 to the upward-closure of the singleton set consisting of that element. It is
easy to see that D1 has standard glb types.

The construction of D1 from D0 used in Example 2.3 is a general procedure for building a D1. Given
a domain D0, the domain D1 can be defined to be the non-empty, upward-closed subsets of D0. Each
element of D1 represents the glb of its members.

3 Syntax
The first type language we consider has only type variables and function types. In this language, as in
all extensions we consider, quantification is shallow (occurs only at the outermost level).

Definition 3.1 Unquantified simple type expressions are generated by the grammar:

o/ ::= ff j ? j ? j o/1 ! o/2
where ff ranges over a family of type variables.

A quantified simple type expression has the form

8ff1 : : : 8ffn:o/
where ffi is a type variable for i = 1; : : : ; n and o/ is an unquantified simple type expression. The type o/
is called the body of the type.

5

Since n = 0 is a possibility in Definition 3.1, every unquantified simple type expression is also a
quantified simple type expression. In the sequel, we use oe for a quantified type expression (perhaps with
no quantifiers), and o/ for a type expression without quantifiers.

A type variable is free in a quantified type expression if it appears in the body but not in the list
of quantified variables. To give meaning to a quantified type, it is necessary to specify the meaning of
its free variables. An assignment ` : Vars ! D0 is a map from variables to the semantic domain. The
assignment `[ff  o/ ] is the assignment ` modified at point ff to return o/ .

An assignment is extended from variables to (quantified) simple type expressions as follows:

Definition 3.2

1. `(?) = ?
2. `(?) = ?
3. `(o/1 ! o/2) = `(o/1) ! `(o/2)
4. `(8ff:o/ ) = uf`[ff  x](o/ )jx 2 D0g

Note that unquantified simple type expressions are assigned meanings in D0 whereas quantified simple
type expressions typically have meanings in D1 but not in D0.

Proposition 3.3 `(8ff1 : : : 8ffn:o/ ) = uf`[ff1  x1 : : : ffn  xn](o/ ) j x1; : : : ; xn 2 D0g
Proof: Follows immediately from Definition 3.2. 2

Our results for eliminating variables in quantified types hinge on knowledge about when two type
expressions have the same meaning in the semantic domain. However, because type expressions may
have free variables, the notion of equality must also take into account possible assignments to those free
variables. We say that two quantified type expressions oe1 and oe2 are equivalent, written oe1 j oe2, if for
all assignments `, we have `(oe1) = `(oe2).

4 Simple Type Expressions
This section presents an algorithm for eliminating quantified type variables in simple type expressions
and proves that the algorithm is sound and complete. The following definition formalizes what it means
to correctly eliminate as many variables from a type as possible:

Definition 4.1 A type expression oe is irredundant if for all oe0 such that oe0 j oe, it is the case that oe has
no more quantified variables than oe0.

In general, irredundant types are not unique. It is easy to show that renaming quantified variables
does not change the meaning of a type, provided we observe the usual rules of capture. Thus, 8ff:oe j
8fi:oe[ff  fi] provided that fi does not occur in oe. It is also true that types distinguished only by the
order of quantified variables are equivalent. That is, 8ff:8fi:oe j 8fi:8ff:oe. Our main result is that for
every type there is a unique (up to renaming and reordering of bound variables) irredundant type that
is equivalent.

Since equivalence (j) is a semantic notion, irredundancy is also semantic in nature and cannot be
determined by a trivial examination of syntax. The key question is: Under what circumstances can a

6

type 8ff:o/ be replaced by some type o/ [ff  o/ 0] (for some type expression o/ 0 not containing ff)? In one
direction we have

`(8ff:o/ ) _ `[ff  o/ 0](o/ ) = `(o/ [ff  o/ 0])

Then, using Definition 3.2, it follows that

8ff:o/ j o/ [ff  o/ 0]
if and only if for all assignments `

8d 2 D0: `(o/ [ff  o/ 0]) _ `[ff  d](o/ )
In other words, a type oe = 8ff:o/ is equivalent to o/ [ff  o/ 0] whenever for all assignments `, we have
`(o/ [ff  o/ 0]) is the minimal element of the set f`[ff  x](o/ )jx 2 D0g to which the glb operation is applied
in computing oe's meaning under `.

The difficulty in computing irredundant types is that the function-space constructor ! is antimonotonic in its first position. That is, o/1 _ o/2 implies that o/1 ! o/ * o/2 ! o/ . Thus, determining
the minimal element of a greatest lower bound computation may require maximizing or minimizing a
variable, depending on whether the type is monotonic or anti-monotonic in that variable. Intuitively, to
eliminate as many variables as possible, variables in anti-monotonic positions should be set to ?, while
others in monotonic positions should be set to ?. We define functions Pos and Neg that compute a type's
set of monotonic and anti-monotonic variables, respectively.

Definition 4.2 Pos and Neg are defined as follows:

Pos(ff) = fffg
Pos(o/1 ! o/2) = Neg(o/1) [ Pos(o/2)

Pos(?) = ;
Pos(?) = ;

Neg(ff) = ;
Neg(o/1 ! o/2) = Pos(o/1) [ Neg(o/2)

Neg(?) = ;
Neg(?) = ;

As an example, for the type ff ! fi we have

Pos(ff ! fi) = ffig
Neg(ff ! fi) = fffg

The following lemma shows that Pos and Neg correctly characterize variables in monotonic and antimonotonic positions respectively.

Lemma 4.3 Let d1; d2 2 D0 where d1 _ d2. Let ` be any assignment.

1. If ff 62 Pos(o/ ), then `[ff  d2](o/ ) _ `[ff  d1](o/ ).
2. If ff 62 Neg(o/ ), then `[ff  d1](o/ ) _ `[ff  d2](o/ ).

7

Proof: This proof is an easy induction on the structure of o/ .

ffl If o/ =? or o/ = ?, then `[ff  d1](o/ ) = `(o/ ) = `[ff  d2](o/ ), so both (1) and (2) hold.
ffl If o/ = ff, then ff 2 Pos(ff), so (1) holds vacuously. For (2), we have

`[ff  d1](ff) = d1 _ d2 = `[ff  d2](ff)

ffl Let o/ = o/1 ! o/2. We prove only (1), as the proof for (2) is symmetric. So assume that ff 62 Pos(o/ ).

By the definition of Pos, we know

ff 62 Neg(o/1) [ Pos(o/2)
Applying the lemma inductively to o/1 and o/2, we have

`[ff  d1](o/1) _ `[ff  d2](o/1)
`[ff  d2](o/2) _ `[ff  d1](o/2)

Combining these two lines using axiom 5 of a semantic domain (Definition 2.1) it follows that

`[ff  d2](o/1 ! o/2) _ `[ff  d1](o/1 ! o/2)
which proves the result.
2

Corollary 4.4

1. If ff 62 Pos(o/ ), then `(o/ [ff  ?]) _ `(o/ ) _ `(o/ [ff ?]) holds for all assignments `.
2. If ff 62 Neg(o/ ), then `(o/ [ff ?]) _ `(o/ ) _ `(o/ [ff  ?]) holds for all assignments `.

4.1 Variable Elimination
Our algorithm for eliminating variables from quantified types is based on the computation of Pos and
Neg. Before presenting the variable elimination procedure, we extend Pos and Neg to quantified types:

Pos(8ff:oe) = Pos(oe) \Gamma  fffg
Neg(8ff:oe) = Neg(oe) \Gamma  fffg

The following lemma gives sufficient conditions for a variable to be eliminated.
Lemma 4.5 If oe is a quantified simple type expression, then

ff 62 Neg(oe) ) 8ff:oe j oe[ff  ?]

ff 62 Pos(oe) ) 8ff:oe j oe[ff  ?]

8

Proof: Assume first that 8ff:oe = 8ff:o/ where o/ is an unquantified simple type expression and that
ff 62 Neg(o/ ). Note that

`(8ff:o/ )
= uf`[ff  x](o/ )jx 2 D0g
_ `[ff  ?](o/ ) since ? is a possible choice for x
= `(o/ [ff  ?])
= uf`[ff  x](o/ [ff  ?])jx 2 D0g since ff does not occur in o/ [ff  ?]
_ uf`[ff  x](o/ )jx 2 D0g by part 2 of Corollary 4.4
= `(8ff:o/ )

Therefore, `(8ff:o/ ) = `(o/ [ff  ?]) for all assignments `. For the general (quantified) case 8ff1; : : : ; ffn:o/ ,
observe that any variable ffi for 1 ^ i ^ n can be moved to the innermost position of the type by a
sequence of bound variable interchanges and renamings, at which point the reasoning for the base case
above can be applied. The proof for the second statement (ff 62 Pos(oe)) is symmetric. 2

We are interested in quantified types for which as many variables have been eliminated using the
conditions of Lemma 4.5 as possible. Returning to our canonical example,

8ff:8fi:ff ! fi
j 8fi:? ! fi since ff 62 Pos(8fi:ff ! fi)
j ? ! ? since ff 62 Neg(? ! fi)

Definition 4.6 A quantified simple type expression oe is reduced if

ffl oe is unquantified; or

ffl oe = 8ff:oe0 and furthermore ff 2 Pos(oe0) ^ ff 2 Neg(oe0) and oe0 is reduced.

Note that the property of being reduced is distinct from the property of being irredundant. "Reduced"
is a syntactic notion and does not depend on the semantic domain. Irredundancy is a semantic notion,
because it involves testing the expression's meaning against the meaning of other type expressions.

Procedure 4.7 (Variable Elimination Procedure (VEP)) Given a quantified type expression
8ff1 : : : 8ffn:o/ , compute the sets Pos(o/ ) and Neg(o/ ). Let V EP (8ff1 : : : 8ffn:o/ ) be the type obtained by:

1. dropping any quantified variable not used in o/ ,

2. setting any quantified variable ff where ff 62 Pos(8ff1 : : : 8ffn:o/ ) to ?,
3. setting any quantified variable ff where ff 62 Neg(8ff1 : : : 8ffn:o/ ) to ?,
4. and retaining any other quantified variable.
Theorem 4.8 Let oe be any quantified simple type expression. Then oe j V EP (oe) and V EP (oe) is
reduced.

Proof: Equivalence follows easily from Lemma 4.5. To see that V EP (oe) is reduced, observe that any
quantified variable not satisfying conditions (1)-(3) of the Variable Elimination Procedure must occur
both positively and negatively in the body of oe. 2

A few remarks on the Variable Elimination Procedure are in order. The algorithm can be implemented
very efficiently. Two passes over the structure of the type are needed: one to compute the Pos and Neg sets
(which can be done using a using a hash-table or bit-vector implementation of sets) and another to perform
any substitutions. In addition, the algorithm need only be applied once, as V EP (V EP (oe)) = V EP (oe).

9

Theorem 4.9 Every irredundant simple type expression is reduced.
Proof: Let oe be an irredundant simple type expression. Since oe is irredundant, V EP (oe) has at least
as many quantified variables as oe. Therefore V EP (oe) = oe; i.e., the Variable Elimination Procedure does
not remove any variables from oe. Since V EP (oe) is reduced, oe is a reduced simple type expression. 2

4.2 Completeness
If oe is a quantified simple type expression, then V EP (oe) is an equivalent reduced simple type expression,
possibly with fewer quantified variables. In this section, we address whether additional quantified variables
can be eliminated from a reduced type. In other words, is a reduced simple type expression irredundant?
We show that if the semantic domain D has standard function types (Definition 2.1) then every reduced
simple type expression is irredundant (Theorem 4.22).

For semantic domains with standard function types, the Variable Elimination Procedure is complete
in the sense that no other algorithm can eliminate more quantified variables and preserve equivalence.
The completeness proof shows that whenever two reduced types are equivalent, then they are syntactically
identical, up to renamings and reorderings of quantified variables.

To simplify the presentation that follows, we introduce some new notation and terminology. By
analogy with the ff-reduction of the lambda calculus, two quantified simple type expressions are ffequivalent iff either can be obtained from the other by a series of reorderings or capture-avoiding renamings
of quantified variables. We sometimes use the notation 8fff1; : : : ; ffng:o/ to denote 8ff1 : : : 8ffn:o/ . Using
a set instead of an ordered list involves no loss of generality since duplicates never occur in reduced
expressions and variable order can be permuted freely.

4.3 Constraint Systems
Proving completeness requires a detailed comparison of the syntactic structure of equivalent reduced
types. This comparison is more intricate than might be expected; in addition, in the sequel we perform a
similar analysis to prove that variable elimination is complete for recursive types. This section develops
the technical machinery at the heart of both completeness proofs.

Definition 4.10 A system of constraints is a set of inclusion relations between unquantified simple type
expressions f: : : s _ t : : :g. A solution of the constraints is any assignment ` such that `(s) _ `(t) holds
for all constraints s _ t in the set.

Definition 4.11 gives an algorithm B that compares two unquantified simple type expressions t1 and
t2. The comparison is expressed in terms of constraints; the function B transforms a constraint t1 _ t2
into a system of constraints on the variables of t1 and t2. Intuitively, B(ft1 _ t2g) summarizes what must
be true about the variables of the two types whenever the relationship t1 _ t2 holds.

Definition 4.11 Let S be a set of constraints. B(S) is a set of constraints defined by the following rules.
These clauses are to be applied in order with the earliest one that applies taking precedence.

1. B(;) = ;
2. B(ft _ tg [ S) = B(S).
3. B(fs1 ! s2 _ t1 ! t2g [ S) = B(ft1 _ s1; s2 _ t2g [ S).

10

4. Otherwise, B(fs _ tg [ S) = fs _ tg [ B(S).
Lemma 4.12 Let S be a system of constraints. If D is a semantic domain with standard function types,
then every solution of S is a solution of B(S).

Proof: Let the complexity of S be the pair (number of ! symbols in S, number of constraints in S).
Complexity is ordered lexicographically, so (i; j) ! (i0; j0) if i ! i0 or i = i0 and j ! j0. The result is
proven by induction on the complexity of S, with one case for each clause in the definition of B:

1. B(;) = ;. The result clearly holds.
2. Since any assignment is a solution of t _ t, any solution ` of ft _ tg [ S is also a solution of S. By

induction, ` is a solution of B(S).

3. Let ` be a solution of fs1 ! s2 _ t1 ! t2g [ S. Since the domain has standard function types,

it follows that ` is also a solution of ft1 _ s1; s2 _ t2g [ S. By induction, ` is a solution of
B(ft1 _ s1; s2 _ t2g [ S).

4. In the final case, by induction every solution of S is a solution of B(S). Therefore all solutions of

fs _ tg [ S are solutions of fs _ tg [ B(S).

2

The completeness proof uses an analysis of the constraints B(ft1 _ t2g) where t1 and t2 are the
bodies of reduced equivalent types. Observe that if t1 and t2 differ only in the names of variables, then
B(ft1 _ t2g) is a system of constraints between variables. Furthermore, it turns out that if t1 and t2 are
actually renamings of each other (and if t1 and t2 are the bodies of reduced equivalent types) then the
constraints B(ft1 _ t2g) define this renaming in both directions. Proving this claim is a key step in the
proof. This discussion motivates the following definition:

Definition 4.13 A system S of constraints is (V1; V2)-convertible iff V1; V2 are disjoint sets of variables
and there is a bijection f from V1 to V2 such that S = fff _ f (ff)jff 2 V1g [ ff (ff) _ ffjff 2 V1g

Example 4.14 For example, let S be the system of constraints

ff _ fl fl _ ff

fi _ ffi ffi _ fi

Let V1 = fff; fig; V2 = ffl; ffig, and define f : V1 ! V2 such that f (ff) = fl; f (fi) = ffi. It is easy to check
that S is (V1; V2)-convertible.

The idea behind Definition 4.13 is that if two reduced types 8V1:o/1 and 8V2:o/2 are ff-convertible, then
B(fo/1 _ o/2g) is a (V1; V2)-convertible system of constraints (provided V1 and V2 are disjoint). It is easiest
to prove this fact by first introducing an alternative characterization of convertible constraint systems,
which is given in the following technical definition and lemma.

Definition 4.15 A system of constraints fs1 _ t1; : : : ; sn _ tng is (V1; V2)-miniscule iff the following all
hold:

1. V1 and V2 are disjoint sets of variables.

11

2. for all i ^ n, at most one of si and ti is a ! expression.
3. for all i ^ n, si and ti are different expressions.
4. for each v 2 V1 [ V2, there exists i ^ n such that v 2 Pos(si) [ Neg(ti)
5. for each v 2 V1 [ V2, there exists i ^ n such that v 2 Neg(si) [ Pos(ti)
6. for every assignment ` there is a assignment `0 such that `(v) = `0(v) for all v 62 V1 and

`0(si) _ `0(ti) holds for all i ^ n.

7. for every assignment ` there is a assignment `0 such that `(v) = `0(v) for all v 62 V2 and

`0(ti) _ `0(si) holds for all i ^ n. (Note the reverse order of ti and si.)

Lemma 4.16 A system of constraints is (V1; V2)-miniscule iff it is (V1; V2)-convertible.
Proof: It is easy to check that any (V1; V2)-convertible system of constraints is (V1; V2)-miniscule.

To prove the converse, let `0 be the assignment that assigns ? to every variable, let `1 be the
assignment that assigns ? to every variable, and let S be a (V1; V2)-miniscule system of constraints.
The first step is to show that no ! expressions can occur in S. It is easy to check that if we reverse
all inequalities we get a (V2; V1)-miniscule system of constraints. Thus, by symmetry, to show that !
cannot occur in S it suffices to show that ! cannot occur in any upper bound in S.

For the sake of obtaining a contradiction, assume that si _ t0i ! t00i 2 S. We show that each of the
four possible forms for si is impossible.

1. s0i ! s00i _ t0i ! t00i is ruled out by Property 2 of Definition 4.15.
2. ? _ t0i ! t00i is ruled out by Property 7 of Definition 4.15, since no assignment satisfies t0i ! t00i _ ?.
3. ? _ t0i ! t00i is ruled out by Property 6 of Definition 4.15, since no assignment satisfies ? _ t0i ! t00i .
4. If v is a variable not in V1, let ` = `1. Then Property 6 of Definition 4.15 is violated because for

all `0 that agree with ` off of V1, we have `0(v) = `(v) = `1(v) = ? 6_ `0(t0i ! t00i ).

If v 2 V1, let ` = `0. Note that v 62 V2 since V1 and V2 are disjoint. Then Property 7 of
Definition 4.15 is violated because for all `0 that agree with ` off of V2, we have `0(t0i ! t00i ) 6_ ? =
`0(v) = `(v) = `0(v).

This completes the proof that ! cannot occur in S.

The next step is to show that ? cannot occur in S. By symmetry it suffices to show that ? cannot
occur as an upper bound in S. There are three cases to consider.

1. ? _ ? is ruled out by Property 3 in Definition 4.15.
2. ? _ ? is ruled out by Property 6 in Definition 4.15 since no assignment satisfies ? _ ?.
3. Consider v ^ ? where v is a variable. If v 62 V1, let ` = `1. Then Property 6 in Definition 4.15 is

violated since for all `0 that agree with ` off of V1, we have that `0(v) = `(v) = `1(v) = ? 6_ ? =
`0(?).

If v 2 V1, a complex case argument is needed because Property 6 is not directly violated. By
Property 5 of Definition 4.15, there is a constraint s0 _ v in S. There are four possible cases for s0:

12

(a) s0 = ?. In this case, ? _ v _ ? is in S and hence Property 7 is violated by taking ` = `1.
(b) s0 = ?. In this case, ? _ v _ ? violates Property 6 since it is never satisfied by any assignment.

(c) s0 = v0 2 V1. In this case, v0 = v is ruled out by Property 3. So we may assume that v0 and v

are different variables. Property 7 is violated by taking ` = `0[v  ?] since if `0 agrees with
` off of V2 the constraint v _ v0 is violated since `0(v) = `(v) = ? 6_ ? = `(v0) = `0(v0).

(d) s0 = v0 62 V1. In this case, v0 _ v _ ? violates Property 6 by taking ` = `1 since `(v0) = ?.

This proves that ? cannot occur as an upper bound in S. By symmetry, ? cannot occur as a lower
bound in S, and hence ? cannot occur anywhere in S. An analogous argument shows that ? can not
occur anywhere in S either.

Thus, every element of S is of the form v0 _ v00 for variables v0; v00. We now show that v0; v00 2 V1 [ V2.
Suppose that v0 62 V1 [ V2. If v00 2 V1, then Property 7 is violated by taking ` = `0[v00  ?] since for all
`0 that agree with ` off of V2, we have that `0(v00) = `(v00) = ? 6_ ? = `(v0) = `0(v0). If v00 62 V1, then
Property 6 is violated by taking ` = `0[v0  ?] since for all `0 that agree with ` off of V1, we have that
`0(v0) = `(v0) = ? 6_ ? = `(v00) = `0(v00). Therefore, the supposition that v0 62 V1 [ V2 is false and it
follows that v0 2 V1 [ V2. A similar argument shows that v00 2 V1 [ V2.

If both v0 and v00 are in V1, then Property 7 is violated by taking ` = `0[v00  ?] since for all `0 that
agree with ` off of V2, we have that `0(v00) = `(v00) = ? 6_ ? = `(v0) = `0(v0). This shows that not both
v0 and v00 are in V1. A symmetric argument shows that not both v0 and v00 are in V2. Thus, it follows
that for every constraint si _ ti in S, either si 2 V1 and ti 2 V2 or si 2 V2 and ti 2 V1.

Next we show that if v0 _ v1 _ v2, then v0 = v2. First assume that v1 2 V1. If v0 and v2 are different
variables, then Property 6 is violated by taking ` = `0[v0  ?] since for all `0 that agree with ` off of V1,
we have that `0(v0) = `(v0) = ? 6_ ? = `(v2) = `0(v2). Hence, in the case that v1 2 V1, it follows that
v0 = v2. A similar argument shows that if v1 2 V2, then v0 = v2.

The next goal is to show that for every v1 2 V1, there exists a unique v2 2 V2 such that v1 _ v2 is
in S. By Property 4, there is at least one such v2. Let v02 be any variable such that v1 _ v02 is in S. By
Property 5, there is a v0 such that v0 _ v1 is in S. It follows that v2 = v0 = v02 which proves that v2 is
unique.

Define a function f mapping V1 to V2 so that v1 _ f (v1) is in S. By Property 5, for any v1 2 V1,
there is a v0 such that v0 _ v1 is in S. It follows that v0 = f (v1). This proves that S ` fff _ f (ff)jff 2
V1g [ ff (ff) _ ffjff 2 V1g. Since every constraint in S has the form v0 _ v00 where either v0 or v00 is in
V1 and since the upper and lower bounds are unique (because v0 _ v1 _ v2 2 S implies that v0 = v2), it
follows that there are no extra elements of S. Therefore, S = fff _ f (ff)jff 2 V1g [ ff (ff) _ ffjff 2 V1g.
Thus S is (V1; V2)-convertible as desired. 2

4.4 From Constraints to Completeness
The definitions and lemmas of Section 4.3 are the building blocks of the completeness proof. Before
finally presenting the proof, we need one last definition:

Definition 4.17 Two simple type expressions 8V1:o/1 and 8V2:o/2 are compatible iff 8V1:o/1 and 8V2:o/2 are
equivalent reduced simple type expressions such that V1 and V2 are disjoint and no variable in V1 occurs
in o/2 and no variable in V2 occurs in o/1.

The important part of the definition of compatibility is that the type expressions are reduced and
equivalent. The conditions regarding quantified variables are there merely to simplify proofs. There is

13

no loss of generality because ff-conversion can be applied to convert any two equivalent reduced type
expressions into compatible expressions.

Lemma 4.18 Let 8V1:o/1 and 8V2:o/2 be compatible type expressions. If the semantic domain has standard
function types and standard glb types, then B(fo/1 _ o/2g) is a (V1; V2)-miniscule system of constraints.

Proof: Let B(fo/1 _ o/2g) = fs1 _ t1; : : : ; sn _ tng. We prove that the conditions in Definition 4.15 all
hold:

1. By compatibility V1 and V2 are disjoint sets of variables.
2. By Part 3 of Definition 4.11 at most one of si and ti is a ! expression.
3. For all i ^ n, si and ti are different expressions by Part 2 of Definition 4.11.
4. After a number of applications of B, the intermediate result for the calculation of B(fo/1 _ o/2g) is

of the form:

fs01 _ t01; : : : ; s0k _ t0kg [ B(fs0k+1 _ t0k+1; : : : ; s0m _ t0mg :

It is sufficient to show that

(a) for all v 2 V1 [ V2, there is an i ^ m such that v 2 Pos(s0i) [ Neg(t0i), and
(b) if, for some i ^ m, we have s0i = t0i, then s0i; t0i contain no variables.

We proceed by induction on the number of steps needed to compute B(fo/1 _ o/2g). In the base
case, consider B(fo/1 _ o/2g). The result follows from the observations that o/1; o/2 are reduced, and
that V1; V2 are disjoint. In the induction step, each of the four cases from the definition of B follow
immediately from the induction hypothesis.

5. Proof similar to the previous step.
6. Let ` be any assignment. We must show that there is an assignment `0 such that `(v) = `0(v)

for all v 62 V1 and `0(si) _ `0(ti) holds for all i ^ n. Since `(8V1:o/1) _ `(8V2:o/2), it follows that
`(8V1:o/1) _ `(o/2). Since the semantic domain has standard glb types, it follows that `0(o/1) _ `(o/2)
holds for some `0 that agrees with ` except possibly on V1. Since no variable in V1 occurs in o/2, we
know `0(o/1) _ `0(o/2). By Lemma 4.12, it follows that `0 is a solution to B(fo/1 _ o/2g).

7. To show that for every assignment ` there is an assignment `0 such that `(v) = `0(v) for all v 62 V2

and `0(ti) _ `0(si) holds for all i ^ n, reverse the roles of o/1 and o/2. This argument relies on the fact
that B(fo/2 _ o/1g) can be obtained from B(fo/1 _ o/2g) by reversing the direction of the _ symbol.

2
One final technical lemma is required before we can show that the variable elimination procedure is
complete. The intuition behind Lemma 4.19 is that if B(fo/1 _ o/2g) is a (V1; V2)-convertible system of
constraints with bijection f (recall Definition 4.13), then B(fo/1 _ f (o/2)g) = ;. This intuition is not quite
correct, because there may be variables in o/1 or o/2 that are not in V1 [ V2. In the following lemma, vars(t)
is the set of variables appearing in t.

Lemma 4.19 Assume that

1. B(S) is a subset of a (V1; V2)-convertible system of constraints with bijection f from V1 to V2.

14

2. For each constraint s _ t 2 S, we have vars(s) " vars(t) " (V1 [ V2) = ;. In other words, any

variables common to s and t are not in V1 [ V2.

Define

F (x) = ( f (x) if x 2 V1x otherwise

We extend F from variables to terms in the usual way. Define

S0 = fF (t) _ F (t0)jt _ t0 2 Sg
The claim is that B(S0) = ;.
Proof: The proof is by induction on the complexity of S, as defined in the proof of Lemma 4.12.

ffl S = ;: Then S0 = ; and B(;) = ;.
ffl S = ft _ tg [ S1. By assumption (2), vars(t) " (V1 [ V2) = ;. By the definition of F it follows that

F (t) = t. Using the definition of B, it is easy to see that because S satisfies assumptions (1) and
(2) with bijection f that S1 also satisfies assumptions (1) and (2) with the same bijection f . Now
we have ;

= B(S01) by induction
= B(ft _ tg [ S01) definition of B
= B(fF (t) _ F (t)g [ S01) F (t) = t
= B(S0)

ffl S = ft1 ! t2 _ s1 ! s2g [ S1. Let T = fs1 _ t1; t2 _ s2g [ S1.

Using the definition of B, it is easy to check that T satisfies conditions (1) and (2) using the bijection
f . By induction B(T 0) = ;. Then

;
= B(fF (s1) _ F (t1); F (t2) _ F (s2)g [ S01) by induction
= B(fF (t1) ! F (t2) _ F (s1) ! F (s2)g [ S01) definition of B
= B(fF (t1 ! t2) _ F (s1 ! s2)g [ S01) definition of F
= B(S0)

ffl S = fs _ tg [ S1 and no previous case applies. Then B(S) = fs _ tg [ B(S1). Since B(S) is

a subset of a (V1; V2)-convertible system of constraints, it follows that s = ff and t = fi for some
distinct variables ff and fi and that either F (ff) = fi and F (fi) = fi or F (ff) = ff and F (fi) = ff.
The rest is similar to the case for t _ t above.

2
We are now ready to state and prove the first of the major theorems concerning completeness.

Theorem 4.20 If the semantic domain has standard function types and standard glb types, then any
two reduced quantified simple type expressions are equivalent iff they are ff-equivalent.

15

Proof: The if-direction is clear and does not even require that the semantic domain have standard
function types. To prove the only-if direction, let oe0 and oe00 be two reduced quantified simple type
expressions. If necessary, ff-convert oe0 to oe1 = 8V1:o/1 and ff-convert oe00 to oe2 = 8V2:o/2 so that oe1 and oe2
are compatible. It suffices to show that oe1 and oe2 are ff-equivalent.

By Lemma 4.18, B(fo/1 _ o/2g) is a (V1; V2)-miniscule system of constraints. By Lemma 4.16, B(fo/1 _
o/2g) is a (V1; V2)-convertible system of constraints; let f be corresponding bijection mapping variables in
V1 to V2. Define

F (x) = ( f (x) if x 2 V1x otherwise

Because oe1 and oe2 are compatible, vars(o/1) " vars(o/2) " (V1 [ V2) = ;. Then, by Lemma 4.19, we have

B(fF (o/1) _ F (o/2)g) = ;
Since F is the identity on o/2 it follows that

B(fF (o/1) _ o/2g) = ;
from which it follows by the definition of B that o/2 = F (o/1). This shows that oe1 and oe2 are ff-equivalent
as desired.

2

Corollary 4.21 If the semantic domain has standard function types, then no two different unquantified
simple type expressions are equivalent.

Proof: Given a semantic domain D construct another semantic domain D0 such that D0 = D00 and
D0 has standard glb types using the construction in Example 2.3. Using the semantic domain D0 suffices
because the meaning of an unquantified type expression is always an element of D0 and D00 = D0. If o/ and
o/ 0 are equivalent, unquantified simple type expressions, then they are reduced and hence ff-equivalent by
Theorem 4.20. But since they have no quantifiers, ff-equivalence implies that o/ = o/ 0. 2

Finally, the following theorem states our main result.

Theorem 4.22 If the semantic domain has standard function types and standard glb types, then a
simple type expression is reduced iff it is irredundant.

Proof: The if direction follows from Theorem 4.9. To prove the only-if direction, let oe be a reduced
simple type expression with the goal of proving that oe is irredundant. Let oe0 be an irredundant type
that is equivalent to oe. (Such a oe0 can always be found by picking it to be a type expression equivalent
to oe with the smallest possible number of quantified variables.) By Theorem 4.9, oe0 is reduced. By
Theorem 4.20, oe is ff-equivalent to oe0. Therefore, it follows that oe and oe0 have the same number of
quantified variables. Hence, oe is irredundant as desired. 2

Theorem 4.22 shows that a syntactic test (reduced) is equivalent to a semantic test (irredundant).
Theorem 4.22 requires that the semantic domain has standard function types. The following examples
show that this assumption is necessary.

Example 4.23 Consider the minimal semantic domain (Example 2.2). It is clear that 8ff:(ff ! ff) j
(? ! ?) in the minimal semantic domain. Therefore, 8ff:(ff ! ff) is reduced but not irredundant.

16

Example 4.24 In the semantic domain used in [AW93], x ! ? = y ! ? regardless of the values of x
and y, because if the answer can be anything (i.e., ?), it does not matter what the domain is. In this
case, 8ff:((ff ! ff) ! ?) j ? ! ?. Thus, 8ff:((ff ! ff) ! ?) is not irredundant even though it is
reduced.

Theorem 4.25 shows that the Variable Elimination Procedure (Procedure 4.7) is complete provided
that the semantic domain has standard function types.

Theorem 4.25 Let oe be a quantified simple type expression. If the semantic domain has standard
function types and standard glb types, then V EP (oe) is an irredundant simple type expression equivalent
to oe.

Proof: Follows easily from Theorem 4.8 and Theorem 4.22. 2

To summarize, for simple type expressions the Variable Elimination Procedure that removes quantified
variables occurring positively or negatively in a type produces an equivalent type with the minimum
number of quantified variables. Furthermore, this type is unique up to the renaming and order of
quantified variables.

A good feature of Theorem 4.25 is that the irredundant type expression produced by the Variable
Elimination Procedure has no more arrows than the original type expression. This need not be the case
if the semantic domain does not have standard function types.

Example 4.26 Let D0 = D1 = f?; ? ! ?; x; ? ! ?; ? ! ?; ? ! ?; ?g where x is a function type,
? ! ? is less than x, and x is less than the other three function types.

Let the set of type expressions be ? and ? closed under !. For this domain, we define the ! operator
as follows. The four possibilities for combining ? and ? using ! map to the corresponding elements
of D0. For all other types y0 ! y1, either y1 or y2 (or both) is a function type. If either y0 or y1 is a
function type, define y0 ! y1 = x.

In this domain `(8ff:(ff ! ff)) = x for all assignments `. This follows because x _ ? ! ? and
x _ ? ! ? and for any other y ! y, we have `(y ! y) = x (e.g., `((? ! ?) ! (? ! ?)) = x). Now
we have that 8ff:(ff ! ff) j (? ! ?) ! ? and, in fact, the quantified type is equivalent to exactly those
unquantified types with a function type in one or both of the domain or range. Even though 8ff:(ff ! ff)
has only one arrow, every irredundant type expression equivalent to 8ff:(ff ! ff) has at least two arrows.

5 Recursive Type Expressions
This section extends the basic variable elimination algorithm to a type language with recursive types.
The proofs of soundness and completeness parallel the structure of the corresponding proofs for the
non-recursive case.

New issues arise in two areas. First, there is new syntax for recursive type equations, which requires
corresponding extensions to the syntax-based algorithms (Pos, Neg, and B). Second, two new conditions
on the semantic domain are needed. Roughly speaking, the two conditions are (a) that recursive equations
have solutions in the semantic domain (which is needed to give meaning to recursive type expressions)
and (b) that the ordering _ satisfies a continuity property (which is required to guarantee correctness of
the Pos and Neg computations). It is surprising that condition (b) is needed not just for completeness,
but even for soundness. Fortunately, standard models of recursive types (including the ideal model and
regular trees) satisfy both conditions.

17

5.1 Preliminaries
We begin by defining a type language with recursive types. We first require the technical notion of a
contractive equation.

Definition 5.1 Let ffi1; : : : ; ffin be distinct type variables and let o/1; : : : ; o/n be unquantified simple type
expressions. A variable ff is contractive in an equation ffi1 = o/1 if every occurrence of ff in o/1 is inside a
constructor (such as !). A system of equations

ffi1 = o/1 ^ : : : ^ ffin = o/n
is contractive iff each ffii is contractive in every equation of the system.

Contractiveness is a standard technical condition in systems with recursive types [MPS84]. Contractiveness is necessary for equations to have unique solutions (e.g., an equation such as ffi = ffi may have
many solutions). The results of this section only apply to systems of contractive equations.

Definition 5.2 An (unquantified) recursive type expression is of the form: o/ =E where E is a set of
contractive equations and o/ is an unquantified simple type expression.

Throughout this section, we use ffi; ffi1; ffi0; : : : for the defined variables that are given definitions in the
set of equations E, and we use ff; ff0; ff1; : : : to indicate the regular variables, i.e., those that are not given
definitions. To give meaning to recursive type expressions, the equations in a recursive type must have
solutions in the semantic domain. The following definition formalizes this requirement.

Definition 5.3 A semantic domain has contractive solutions iff for every contractive system E of equations

ffi1 = o/1 ^ : : : ^ ffin = o/n

and for every assignment `, there exists a unique assignment `E such that:

1. `E(ff) = `(ff) for all ff 62 fffi1; : : : ; ffing
2. `E(ffii) = `E(o/i) for all i = 1; : : : ; n.
Note that Definition 5.3 is well formed because assignments are applied only to unquantified simple type
expressions, an operation that already has meaning (see Definition 3.2).

Lemma 5.4 Let E and E0 be contractive systems of equations and assume the semantic domain has
contractive solutions.

1. Let ` be an assignment to all variables in E and E0. If E0 ` E, then (`E)E

0 = `E.

2. If E does not mention variables ff1; : : : ; ffm, then (`[ff1  d1; : : : ; ffm  dm])E = `E[ff1 

d1; : : : ; ffm  dm]

Proof:

1. Immediate from the uniqueness of `E.
2. By repeated applications, it suffices to consider the case m = 1. If fi is not defined by E, it is easy

to see that `E[ff1  d1](fi) = `[ff1  d1](fi). If ffi = o/ is a definition in E, then `E[ff1  d1](ffi)
= `E(ffi) = `E(o/ ) = `E[ff  d1](o/ ). By uniqueness of (`[ff1  d1])E, it follows that (`[ff1  d1])E =
`E[ff1  d1].

18

2

An assignment is extended to (quantified) recursive type expressions as follows:

Definition 5.5

1. `(o/ =E) = `E(o/ ) for any unquantified simple type expression o/ .
2. `(8ff:o/ =E) = uf`[ff  x](o/ =E)jx 2 D0g

Just as for simple type expressions, every unquantified simple type expression is assigned a meaning
in D0 whereas quantified simple type expressions typically have meanings that are in D1 but not in D0.
Lemma 5.6 shows that if a domain has contractive solutions, then definitions of "unused" variables can
be dropped.

Lemma 5.6 Assume the domain has contractive solutions. Let E by a set of equations and let E0 ` E.
Assume that whenever a defined variable ffi of E occurs in o/0=E0, then ffi is a defined variable of E0. Then
o/0=E j o/0=E0.

Proof: Let ffi1; : : : ; ffim be the variables defined by E but not E0. Then we have:

`(o/0=E)
= `E(o/0)
= (`E)E

0(o/

0) by part 1 of Lemma 5.4, since E0 ` E

= `[ffi1  `E(ffi1); : : : ; ffim  `E(ffim)]E

0 (o/

0)

= `E

0[ffi

1  `E(ffi1); : : : ; ffim  `E(ffim)](o/0) by part 2 of Lemma 5.4

= `E

0(o/

0) since ffi1; : : : ; ffim do not appear in o/0

= `(o/0=E0)

2
Surprisingly, even though contractive solutions guarantee that equations have unique solutions, this is
not sufficient for soundness of the Variable Elimination Procedure. The crux of the problem is found in the
reasoning that justifies using Pos and Neg as the basis for replacing variables by ? or ? (Lemma 4.3). The
Pos and Neg algorithms traverse a type expression to compute the set of positive and negative variables
of the expression. In the case of recursive types, Pos and Neg can be regarded as using finite unfoldings
of the recursive equations. We must ensure that these finite approximations correctly characterize the
limit, which is the "infinite" unfolding of the equations. Readers familiar with denotational semantics
will recognize this requirement as a kind of continuity property. Definition 5.8 defines type continuity,
which formalizes the appropriate condition. Later in this section we give an example showing that type
continuity is in fact necessary.

Definition 5.7 A definable operator is a function F : D0 ! D0 such that there is a recursive type
expression o/0= Vmi=1 ffii = o/i, an assignment `, and a (regular) variable ff such that o/0 6= ff, ff is contractive
in all equations, and

F (d) = `[ff  d](o/0=

m^

i=1

ffii = o/i)

holds for all d 2 D0.
Definition 5.8 A semantic domain D has type-continuity iff for every monotonic, definable operator F
and every d0; d00 2 D0,

(F (d00) = d00 ^ F (d0) _ d0) ) d00 _ d0

19

The minimal semantic model (Example 2.2) has contractive solutions, type continuity, and standard
glb types, but it lacks standard function types. The standard semantic model (Example 2.3) has standard
glb types and standard function types but lacks contractive solutions (e.g., because the equation ffi = ffi ! ffi
has no solution). The standard model does have type continuity, but without contractive solutions type
continuity is not very interesting; for the standard model, the only monotonic definable operators with
a fixed point are constant functions. The standard semantic model can be extended to the usual regular
tree model to provide contractive solutions without sacrificing the other properties.

Lemma 5.9 The usual semantic domain of regular trees has contractive solutions, standard glb types,
standard function types, and type continuity.

Proof: We briefly sketch the usual semantic domain D0 of regular trees. This discussion is not intended
to give a detailed construction of the domain, but rather to highlight the important features. As usual,
D1 consists of the non-empty upward closed subsets of D0. Therefore, the semantic domain has standard
glb types.

A finite or infinite tree is regular if it has only a finite number of subtrees. The set D0 consists of the
regular trees built from ? and ? using the ! operator. Thus, ? and ? are elements of D0 and every
other element x of D0 is equal to x0 ! x00 for some x0; x00 2 D0. Furthermore, x0 and x00 are unique. It is
well-known that such a domain has contractive solutions [Cou79].

Let x _0 y hold for all x; y 2 D0. Let x _i+1 y hold iff x = ? or y = ? or x = x0 ! x00 and
y = y0 ! y00 and x00 _i y00 and y0 _i x0. Notice that _i+1`_i. Then x _ y holds iff x _i y holds for all
i * 0 [AC93].

First we check that _ has standard function types.

x0 ! x00 _ y0 ! y00
, 8i(x0 ! x00 _i+1 y0 ! y00)
, 8i(x00 _i y00 and y0 _i x0)
, 8i(x00 _i y00) and 8i(y0 _i x0)
, x00 _ y00 and y0 _ x0

Thus _ has standard function types.

Next we check that D0 has type continuity. Let x =i y stand for x _i y and y _i x. Let F be a
definable monotonic operator. For any x; y 2 D0,

F i(x) =i F i(y)
This fact follows by induction on i, using the fact that F is definable by a system of equations contractive
in F 's argument. To see this, note that in the base case F 0(x) =0 F 0(y), since every value is =0 to every
other value. Recall that =i means equal to depth i (where depth is the number of nested constructors)
and that F (z) is equivalent to a system of equations with occurrences of z embedded inside at least one
constructor (contractiveness). Therefore, for the inductive step, it suffices to note that if F i(x) =i F i(y)
(i.e., equal to a depth of i constructors) then F (F i(x)) =i+1 F (F i(y)) (i.e., equal to a depth of i + 1
constructors).

Let d0 and d00 be elements of D0 such that F (d00) = d00 and F (d0) _ d0. It is easy to see by induction
that F i(d00) = d00 and, using monotonicity of F , that F i(d0) _ d0. Therefore, we have

d00 = F i(d00) =i F i(d0) _ d0
for all i. Hence, d00 _i d0 holds for all i. By definition of _, it follows that d00 _ d0 and we conclude that
the domain has type continuity. 2

20

5.2 Soundness
In this section, we extend variable elimination to recursive types. The first step is to extend Pos and Neg
to include defined variables (recall defined variables are denoted by ffi):

Definition 5.10 Pos0 and Neg0 are sets of variables such that

1. If ff is not defined in E, then Pos0(ff=E) = fffg and Neg0(ff=E) = ;.
2. If ffi = o/ is in E, then Pos0(ffi=E) = Pos0(o/ =E) [ fffig and Neg0(ffi=E) = Neg0(o/ =E).
3. Pos0(?=E) = Neg0(?=E) = ;
4. Pos0(?=E) = Neg0(?=E) = ;
5. Pos0(o/1 ! o/2=E) = Pos0(o/2=E) [ Neg0(o/1=E)

and Neg0(o/1 ! o/2=E) = Neg0(o/2=E) [ Pos0(o/1=E)

Let D be the set of E's defined variables. Then Pos(o/ =E) = Pos0(o/ =E) \Gamma  D and Neg(o/ =E) = Neg0(o/ =E) \Gamma 
D.

Note that Pos and Neg exclude defined variables while Pos0 and Neg0 include defined variables. Many
functions satisfy these equations. For example, choosing

Pos(ffi=ffi = ffi ! ffi) = Neg(ffi=ffi = ffi ! ffi) = fff4; ff29g
satisfies the equations, but the least solution is

Pos(ffi=ffi = ffi ! ffi) = Neg(ffi=ffi = ffi ! ffi) = ;
Our results apply to the least solutions of the equations. It is easy to construct the least sets for Pos and
Neg by adding variables only as necessary to satisfy the clauses of Definition 5.10.

At this point we digress to discuss the complexity of computing Pos and Neg sets for recursive types.
Let the print representation of a system of type equations have size n and let the system have m type
variables. Observe that the problem can be factored into m independent subproblems, one for each type
variable. Focusing on a single variable ff, the problem is to compute two bits for each subexpression E:
whether ff 2 Pos0(E) and whether ff 2 Neg0(E). This subproblem can be solved in time linear in n, so to
solve all m subproblems is O(mn).

We now explain how to decide ff 2 Pos0(E) and ff 2 Neg0(E) for every subexpression E in linear time.
Define a graph with one node for each subexpression of the type and the associated system of equations.
The graph has the following directed edges:

ffl There is an edge from each node for X ! Y to the node for X. These edges are called crossing

edges.

ffl There is an edge from each node for X ! Y to the node for Y .
ffl For each node for ffi there is an edge to the node for E where ffi = E is an equation of the system.

21

This graph has O(n) nodes and O(n) edges.

Let a be the node for variable ff and let b be the node for some expression B. Assume there is a
path from b to a in the graph. A path with an even number of crossings is positive; a path with an odd
number of crossings is negative. It is easy to show ff 2 Pos0(B) if there is a positive path from b to a and
ff 2 Neg0(B) if there is a negative path from b to a.

To compute the property for every subexpression efficiently, we reverse all the edges in the graph
and perform a modified depth-first search from a, marking each node along the way as either positive
or negative or both according to the marks of its predecessor and whether the edge being traversed is a
crossing. Each edge may be visited at most twice (once for a positive path and once for a negative path)
so the overall complexity is linear. This concludes the discussion of the complexity of computing Pos and
Neg sets.

The following relationship between defined and regular variables is easy to show using Definition 5.10.
The intuition is that if ff is positive (resp. negative) in the definition of ffi, then ff is positive (resp.
negative) in any position where ffi appears positively, and negative (resp. positive) in any position where
ffi appears negatively.

Lemma 5.11 If ff 2 Pos0(ffi=E) then

ffi 2 Neg0(o/ =E) ) ff 2 Neg0(o/ =E)

ffi 2 Pos0(o/ =E) ) ff 2 Pos0(o/ =E)

If ff 2 Neg0(ffi=E) then

ffi 2 Neg0(o/ =E) ) ff 2 Pos0(o/ =E)

ffi 2 Pos0(o/ =E) ) ff 2 Neg0(o/ =E)

Lemma 5.12 Let o/ be a recursive type expression and let d1; d2 2 D0 where d1 _ d2. Let ` be any
assignment. If the semantic domain has contractive solutions and type continuity, then

1. if ff 62 Pos(o/ ), then `[ff  d2](o/ ) _ `[ff  d1](o/ ).
2. if ff 62 Neg(o/ ), then `[ff  d1](o/ ) _ `[ff  d2](o/ ).

Proof: Let o/ = o/0=E. The result is proven by induction on the number of equations in E with a
sub-induction on the structure of o/0. The sub-induction on o/0's structure proceeds as in Lemma 4.3. The
interesting case is the new base case where o/0 is a defined variable ffi1 with ffi1 = o/1 in E.

Assume o/ = ffi1=E where ffi1 = o/1 is an equation in E. If ff 2 Pos(ffi1=E) and ff 2 Neg(ffi1=E), then
the result is vacuously true. If ff 62 Pos(ffi1=E) and ff 62 Neg(ffi1=E), then let E0 be those equations in E
that do not contain ff and do not (recursively) refer to a defined variable that contains ff in its definition.
Using Lemma 5.6, it can be shown that ffi1=E0 j ffi1=E, so it suffices to prove the result for ffi1=E0. Notice
that ff does not occur in ffi1=E0. It is easy to check that `[ff  d](ffi1=E0) = `(ffi1=E0) holds for all d 2 D0
and the result follows.

Assume ff 62 Pos(ffi1=E) and ff 2 Neg(ffi1=E). We claim ffi1 62 Neg0(o/1=E). To see this, note that

ffi1 2 Neg0(o/1=E) ^ ff 2 Neg0(ffi1=E)
) ff 2 Pos0(o/1=E) by Lemma 5.11
) ff 2 Pos0(ffi1=E) by Definition 5.10
) ff 2 Pos(ffi1=E) by Definition 5.10

22

which violates the assumption ff 62 Pos(ffi1=E). Therefore ffi1 62 Neg0(o/1=E). Let E0 be E with the equation
ffi1 = o/1 deleted. Now

ffi1 62 Neg0(o/1=E)
) ffi1 62 Neg0(o/1=E0) see below
) ffi1 62 Neg(o/1=E0) since Neg(o/1=E0) ` Neg0(o/1=E0)

The second line follows because deleting equations from E can only decrease the least solutions of the
equations for Pos0 and Neg0.

Fix an assignment `. For each d0 2 D0, define Fd0 (d) = `[ff  d0][ffi1  d](o/1=E0). It is clear that Fd0
is a definable operator. By the induction hypothesis, Fd0 is a monotonic operator. It is easy to see that
ff 62 Pos(o/1=E0), so it also follows from the induction hypothesis that F is anti-monotonic in its subscript.
More formally, if d1 _ d2, then Fd2 (d) _ Fd1 (d) holds for every d 2 D0.

Define a function h on D0 by

h(d0) = `[ff  d0](ffi1=E)

Now we haveF

d0 (h(d0))
= `[ff  d0][ffi1  h(d0)](o/1=E0)

= (`[ff  d0][ffi1  h(d0)])E

0 (o/

1)

= ((`[ff  d0]E)E

0(o/

1) by Definition 5.3

= (`[ff  d0])E(o/1) by part 1 of Lemma 5.4, since E0 ` E

= (`[ff  d0])E(ffi1)
= `[ff  d0](ffi1=E)
= h(d0)
Thus, Fd0 (h(d0)) = h(d0) holds for every d0 2 D0. Let d1 _ d2. Fd2 (h(d2)) = h(d2). Fd2 (h(d1)) _
Fd1 (h(d1)) = h(d1). By type continuity, h(d2) _ h(d1) which is the desired result.

If ff 2 Pos(ffi1=E) and ff 62 Neg(ffi1=E), then the proof is omitted since it is similar to the case where
ff 62 Pos(ffi1=E) and ff 2 Neg(ffi1=E). Like the previous case, F is monotonic in its argument; unlike the
previous case, F is monotonic in its subscript. 2

Corollary 5.13 Assume the semantic domain has type continuity and contractive solutions.

1. If ff 62 Pos(o/ =E), then `((o/ =E)[ff  ?]) _ `(o/ =E) _ `((o/ =E)[ff ?]) holds for all assignments `.
2. If ff 62 Neg(o/ =E), then `((o/ =E)[ff  ?]) _ `(o/ =E) _ `((o/ =E)[ff  ?]) holds for all assignments `.

The rest of the soundness results proceed as before. In particular, the Variable Elimination Procedure
remains unaffected, except that it uses the new definitions of Pos and Neg. Just as in Section 4, we extend
Pos and Neg:

Pos(8ff:oe) = Pos(oe) \Gamma  fffg
Neg(8ff:oe) = Neg(oe) \Gamma  fffg

Lemma 5.14 If oe is a quantified recursive type expression and the semantic domain has type continuity
and contractive solutions, then

ff 62 Neg(oe) ) 8ff:oe j oe[ff  ?]

ff 62 Pos(oe) ) 8ff:oe j oe[ff  ?]

23

Proof: Same as the proof for Lemma 4.5. 2
Example 5.15 Let oe = (ffi3 ! ffi3) ! (ffi2 ! ffi1)=ffi1 = ff1 ! ffi1 ^ ffi2 = ff2 ! ffi2 ^ ffi3 = ff3 ! ffi3. Note that
Pos(oe) = fff2; ff3g and Neg(oe) = fff1; ff3g. Assuming that the semantic domain has contractive solutions
and type continuity, Lemma 5.14 allows us to conclude that

8ff18ff28ff3:((ffi3 ! ffi3) ! (ffi2 ! ffi1)= ffi1 = ff1 ! ffi1 ^ ffi2 = ff2 ! ffi2 ^ ffi3 = ff3 ! ffi3)
j 8ff3:((ffi3 ! ffi3) ! (ffi2 ! ffi1)= ffi1 = ? ! ffi1 ^ ffi2 = ? ! ffi2 ^ ffi3 = ff3 ! ffi3)

The next example shows that the assumption of type continuity is needed in the proof of Lemma 5.14.
Example 5.16 Consider the type expression 8ff:(ffi=ffi = ff ! ffi). If Lemma 5.14 holds, then we have

ffi=ffi = ? ! ffi
j 8ff:(ffi=ffi = ff ! ffi) by Lemma 5.14
_ (ffi=ffi = ? ! ffi) since ? is an instance of ff

Let ffi0 = ? ! ffi0 and ffi1 = ? ! ffi1 be elements of the semantic domain. Any semantic domain in which
it is not the case that ffi0 _ ffi1 serves as a counterexample to the conclusion of Lemma 5.14.

Take the semantic domain to be the set of regular trees and define x _00 y to hold iff x = y. Let
x _0i+1 y hold iff x = ?, y = ?, or 9x1; x2; y1; y2(x = x1 ! x2 ^ y = y1 ! y2 ^ y1 _0i x1 ^ x2 _0i y2). Let
x _0 y hold iff x _0i y for some i. Next, notice that ffi0 _0i+1 ffi1 iff ? ! ffi0 _0i+1 ? ! ffi1 iff ? _0i ?^ffi0 _0i ffi1.
It is easy to see by induction that ffi0 6_0i ffi1 is true for all i. Hence, ffi0 6_0 ffi1. Thus, the conclusion of
Lemma 5.14 does not hold for this semantic domain.

This semantic domain has contractive solutions, standard function types, and standard glb types.
What it lacks is type continuity, and it is instructive to see why. Consider the two definable operators:

F?(d) = [ff  d](?! ff)
F?(d) = [ff  d](? ! ff)

Let ? ! ? ! : : : be the infinite regular tree where ? appears in the domain of every "!". Observe that

F?(? ! ? ! : : :) = ? ! ? ! : : :
Note that for all d we have F?(d) _0 F?(d). In particular,

F?(? ! ? ! : : :) _0 F?(? ! ? ! : : :) = ? ! ? ! : : :
If the domain had type continuity, it would follow that

? ! ? ! : : : _0 ? ! ? ! : : :
As shown above, this relation does not hold, so therefore the domain does not have type continuity.

As discussed at the beginning of this section, type continuity is needed to guarantee that the finite
computation performed by Pos and Neg is consistent with the orderings on all finite and infinite trees.
Example 5.16 shows how the problem arises when x 6_0 y, but x _i y for all i (where _i is the relation
used in Lemma 5.9 to define the usual ordering on regular trees). Thus, in contrast to the case of simple
expressions where no additional assumptions on the semantic domain are needed for soundness, type
continuity is needed to prove soundness for recursive type expressions.

24

Theorem 5.17 Let oe be any quantified recursive type expression. If the semantic domain has type continuity and contractive solutions, then oe j V EP (oe) and V EP (oe) is a reduced recursive type expression.

Proof: Follows easily from Lemma 5.14. 2
Theorem 5.18 If the semantic domain has type continuity and contractive solutions, then every irredundant recursive type expression is reduced.

Proof: Same as the proof of Theorem 4.9. 2

5.3 Completeness
In this section, we face concerns similar to those found in Section 4.3.

Definition 5.19 Let S be a set of unquantified constraints. Define B(S) to be the smallest set of
constraints such that the following all hold. These clauses are to be applied in order, with the earliest
one that applies taking precedence.

1. B(;) = ;
2. If t is ?, ?, or a regular variable, then B(ft=E _ t=E0g [ S) = B(S).
3. B(fs1 ! s2=E _ t1 ! t2=E0g [ S) = B(ft1=E0 _ s1=E; s2=E _ t2=E0g [ S).
4. If ffi = o/ is in E, then B(fffi=E _ tg [ S) = B(fo/ =E _ tg [ S).
5. If ffi = o/ is in E0, then B(fs _ ffi=E0g [ S) = B(fs _ o/ =E0g [ S).
6. Otherwise, B(fs=E _ t=E0g [ S) = fs _ tg [ B(S).
Lemma 5.20 Assume that D is a semantic domain with contractive solutions, standard function types,
and standard glb types. If ` is a solution of ft1=E _ t2=E0g, then it is a solution of B(ft1=E _ t2=E0g).

Proof: The proof is very similar to the proof of Lemma 4.12 and so is omitted. The most important
new case is Part 6 of Definition 5.19. In this clause, note that s and t must be regular variables of E and
E0 respectively. Thus B(S) does not mention any defined variables. This observation is needed to show
that if `E(t1) _ `E

0(t

2) then ` is a solution of B(ft1=E _ t2=E0g). 2

Lemma 5.21 Let 8V1:o/1=E1 and 8V2:o/2=E2 be compatible recursive type expressions. If the semantic
domain has contractive solutions, standard function types, and standard glb types, then B(fo/1=E1 _
o/2=E2g) is a (V1; V2)-miniscule system of constraints.

Proof: Let B(fo/1=E1 _ o/2=E2g) = fs1 _ t1; : : : ; sn _ tng. We show that B(fo/1=E1 _ o/2=E2g) satisfies
the conditions of Definition 4.15.

1. By compatibility V1 and V2 are disjoint sets of variables.
2. By Part 3 of Definition 5.19 at most one of si and ti is a ! expression.
3. Consider a constraint t _ t. Constraints of the form ? _ ?, ? _ ?, and ff _ ff are eliminated by

Part 2 of Definition 5.19, constraints t ! t0 _ t ! t0 are eliminated by Part 3, and constraints ffi _ ffi
are eliminated by Parts 4 and 5. Therefore, for all t, we have t _ t is not in B(fo/1=E1 _ o/2=E2g).

25

4. Same as Part 4 of the proof of Lemma 4.18 (but using Definition 5.19).
5. Proof similar to the previous step.
6. Let ` be any assignment. We must show that there is an assignment `0 such that `(v) = `0(v) for

all v 62 V1 and `0(si) _ `0(ti) holds for all i ^ n. Since

`(8V1:o/1=E1) _ `(8V2:o/2=E2);
it follows that

`(8V1:o/1=E1) _ `(o/2=E2):

Since the semantic domain has standard glb types, it follows that `0(o/1=E1) _ `(o/2=E2) holds for
some `0 that agrees with ` except possibly on V1. Since no variable in V1 occurs in o/2=E2, we know
`0(o/1=E1) _ `0(o/2=E2). By Lemma 5.20, it follows that `0 is a solution to B(o/1=E1 _ o/2=E2).

7. Similar to the previous step with the roles of o/1 and o/2 reversed.
2

Theorem 5.22 If the semantic domain has contractive solutions, standard glb types, and standard
function types, then any two reduced recursive type expressions have the same number of quantified
variables.

Proof: Let oe0 and oe00 be two reduced recursive type expressions. If necessary, ff-convert oe0 to oe1 =
8V1:o/1=E and ff-convert oe00 to oe2 = 8V2:o/2=E0 in such a way that oe1 and oe2 are (V1; V2) compatible. By
Lemma 5.21, B(o/1=E _ o/2=E0) is a (V1; V2)-miniscule system of constraints. By Lemma 4.16, B(o/1=E _
o/2=E0) is a (V1; V2)-convertible system of constraints, which implies that jV1j = jV2j. 2

Unlike the case of simple expressions, two equivalent reduced types need not be ff-equivalent. For
example, consider a semantic domain that has contractive solutions. Let ffi0 = ffi0 ! ffi0 and ffi1 = (ffi1 !
ffi1) ! (ffi1 ! ffi1). These two types exist since the domain has contractive solutions. By substituting
(ffi0 ! ffi0) in for ffi0, we obtain ffi0 = (ffi0 ! ffi0) ! (ffi0 ! ffi0). Since the domain has contractive solutions,
it follows that ffi0 = ffi1. Clearly, the type expressions ffi0=ffi0 = ffi0 ! ffi0 and ffi1=ffi1 = (ffi1 ! ffi1) ! (ffi1 ! ffi1)
are not ff-equivalent.

Theorem 5.23 If the semantic domain has contractive solutions, type continuity, standard function
types, and standard glb types, then a recursive type expression is reduced iff it is irredundant.

Proof: The if-direction follows from Theorem 5.18. To prove the only-if direction, let oe be a reduced
recursive type expression with the goal of proving that oe is irredundant. Let oe0 be an irredundant
recursive type expression that is equivalent to oe. (Such a oe0 can always be found by picking it to
be a type expression equivalent to oe with the smallest possible number of quantified variables.) By
Theorem 5.18, oe0 is reduced. By Theorem 5.22, oe and oe0 have the same number of quantified variables.
Hence, oe is irredundant as desired. 2

Theorem 5.24 Let oe be quantified recursive type expression. If the semantic domain has contractive solutions, type continuity, standard glb types, and standard function types, then V EP (oe) is an irredundant
recursive type expression equivalent to oe.

Proof: Follows easily from Theorem 5.17 and Theorem 5.23. 2

26

6 Intersection and Union Types
In this section we extend our results to type languages with union and intersection types. This is the first
point at which the technique of eliminating variables that appear solely in monotonic or anti-monotonic
positions is sound but not complete.

6.1 Preliminaries
As a first step union and intersection types are added to simple type expressions.

Definition 6.1 Extended type expressions are generated by the grammar

o/ ::= ff j ? j ? j o/1 + o/2 j o/1 \Delta  o/2 j o/1 ! o/2
Extended quantified types are adapted in the obvious way to use extended type expressions instead of
simple type expressions. The operations + and \Delta  are interpreted as least-upper bound and greatest-lower
bound, respectively. To give meaning to extended type expressions an assumption is needed about the
upper and lower bounds that exist in the domain.

Definition 6.2 A semantic domain D = (D0; D1; _; u) has standard upper and lower bounds if every
pair of elements o/1; o/2 2 D0 have a least upper bound o/1 t o/2 and a greatest lower bound o/1 u o/2 in D0.

Note that requiring o/1 u o/2 exist is different from having standard glb types, as standard glb types are
glb's of (potentially) infinite sets in D1. The following lemma shows that natural domains have standard
upper and lower bounds.

Lemma 6.3 Assume that for every x 2 D0 it is the case that x = ?, x = ?, or x = x1 ! x2 for some
x1 and x2. If D0 has standard function types, then the domain has standard upper and lower bounds.

Proof: We must show that x t y and x u y exist for all x; y 2 D0. It is easy to check that the following
equations cover all possibilities:

? t x = ? x t ? = ?
? t x = x x t ? = x
? u x = ? x u ? = ?
? u x = x x u ? = x
x1 ! y1 t x2 ! y2 = x1 u x2 ! y1 t y2 x1 ! y1 u x2 ! y2 = x1 t x2 ! y1 u y2

The eight equations on the first four lines are easy to verify. To justify the equation x1 ! y1 t x2 ! y2 =
x1 u x2 ! y1 t y2, note that

x1 u x2 _ x1
x1 u x2 _ x2

y1 _ y1 t y2
y2 _ y1 t y2

from which it follows that x1 u x2 ! y1 t y2 is an upper bound of both x1 ! y1 and x2 ! y2. Let a ! b
be any other upper bound of x1 ! y1 and x2 ! y2. Since the domain has standard function types, we

27

have a _ x1 and a _ x2, so a _ x1 u x2. Similarly y1 t y2 _ b. Therefore, x1 u x2 ! y1 t y2 is the least
upper bound. The justification of the last equation is symmetric. 2

It follows immediately from Lemma 6.3 that the Standard Model (Example 2.3) and Regular Tree
Model (Lemma 5.9) both have standard upper and lower bounds.

Given an assignment `, the meanings of the new type operations are:

`(o/1 + o/2) = `(o/1) t `(o/2)

`(o/1 \Delta  o/2) = `(o/1) u `(o/2)

6.2 Soundness for Non-Recursive Types
We first extend Pos and Neg to include the new operations.

Pos(o/1 + o/2) = Pos(o/1) [ Pos(o/2)

Pos(o/1 \Delta  o/2) = Pos(o/1) [ Pos(o/2)
Neg(o/1 + o/2) = Neg(o/1) [ Neg(o/2)

Neg(o/1 \Delta  o/2) = Neg(o/1) [ Neg(o/2)

We can now restate the basic lemma needed to prove soundness for the non-recursive case.
Lemma 6.4 Let o/ be any extended simple type expression. Let d1; d2 2 D0 where d1 _ d2. If the
domain has standard upper and lower bounds, then

1. If ff 62 Pos(o/ ), then `(o/ [ff  d2]) _ `(o/ [ff  d1]) holds for all assignments `.
2. If ff 62 Neg(o/ ), then `(o/ [ff  d1]) _ `(o/ [ff  d2]) holds for all assignments `.
Proof: This proof is by induction on the structure of o/ and is an easy extension of the proof of
Lemma 4.3. Let d1; d2 2 D0 where d1 _ d2, and let ` be any assignment. There are two new cases:

ffl Let o/ = o/1 + o/2. Assume ff 62 Pos(o/ ). By the definition of Pos, we know

ff 62 Pos(o/1) [ Pos(o/2)
and therefore

`[ff  d2](o/1) _ `[ff  d1](o/1)
`[ff  d2](o/2) _ `[ff  d1](o/2)

follow by induction. The relationships still hold if the right-hand sides are made larger, so

`[ff  d2](o/1) _ `[ff  d1](o/1) t `[ff  d1](o/2)
`[ff  d2](o/2) _ `[ff  d1](o/1) t `[ff  d1](o/2)

Combining these two inequalities we get

`[ff  d2](o/1) t `[ff  d2](o/2) _ `[ff  d1](o/1) t `[ff  d1](o/2)
The proof for the subcase ff 62 Neg(o/ ) is similar.

28

ffl Let o/ = o/1 \Delta  o/2. This case is very similar to the previous one, with u substituted for t.
2

An inspection of the results from Section 4.1 shows that the proofs of Lemma 4.5 and Theorem 4.8
depend only on Lemma 4.3 and not on a particular language of type expressions. Therefore, by Lemma 6.4,
it is immediate that Procedure 4.7 is a sound variable elimination procedure for extended simple types
in domains with standard upper and lower bounds.

While variable elimination is sound for extended simple type expressions, it is not complete.

Example 6.5 In either the Standard Model or Regular Tree Model we have

8ff:(ff ! ff) + ? j ?
Clearly, the first type is reduced and not irredundant.
Similarly, 8ff:(ff ! ff)\Delta  ?j ?. In general, the Pos and Neg computations overestimate the set of positive
and negative variables for expressions o/1 + o/2 where `(o/1) _ `(o/2) for all ` (and similarly for \Delta ).

A subtler source of incompleteness arises from interaction between universal quantification and unions
and intersections.

Example 6.6

8ff; fi:ff \Delta  fi ! ff \Delta  fi
= uf`[ff  x1; fi  x2](ff \Delta  fi ! ff \Delta  fi)jx1; x2 2 D0g by Proposition 3.3
= ufx1 u x2 ! x1 u x2)jx1; x2 2 D0g
= ufx ! xjx 2 D0g since fx1 u x2jx1; x2 2 D0g = D0
= 8ff:ff ! ff

Note that there is no explicit relationship between ff and fi in the type. The relationship follows from
the fact that the variables are always used together and the universal quantification.

6.3 Improvements
We do not know a complete version of the Variable Elimination Procedure in the presence of union
and intersection types. In this section we briefly illustrate some heuristic improvements that have been
useful in practice [AM91, FA96]. As illustrated in Section 6.2, redundant intersections and unions are a
significant source of incompleteness. This suggests the following procedure:

Procedure 6.7 (Extended Variable Elimination Procedure (EVEP)) Let oe be an extended quantified type.

1. Let oe1 be the result of replacing any subexpression o/1 + o/2 in oe by o/2 if `(o/1) _ `(o/2) for all

assignments `.

2. Let oe2 be the result of replacing any subexpression o/1 \Delta  o/2 in oe0 by o/2 if `(o/2) _ `(o/1) for all

assignments `.

3. Let oe3 = V EP (oe2).
4. Halt if no variables are eliminated in (3); the result is oe3. Repeat (1)-(3) on oe3 otherwise.

29

Note that deciding whether a type is equivalent to ? or ? in all assignments is not necessarily easy,
depending on the expressiveness of the type language under consideration.

The interesting aspect of Procedure 6.7 is that iterating the elimination of intersections, unions, and
variables is necessary, as the following example shows:

8ff; fi:fi ! (ff \Delta  fi)
j 8fi:fi ! (? \Delta fi) since ff is not negative
j 8fi:fi !? since ? \Delta o/ =?
j ? !? since fi is not positive

Since each iteration but the last of the Extended Variable Elimination Procedure eliminates at least
one variable, the complexity is at worst the product of the number of quantified variables O(m) and the
cost of recomputing the Pos and Neg sets O(mn), for a total cost of O(m2n).2

6.4 Soundness and Incompleteness for Recursive Types
In this section we consider extended recursive types.
Definition 6.8 An extended recursive type has the form

o/ = ^

1^i^n

ffii = o/i

where the equations are contractive and o/; o/1; : : : ; o/n are extended type expressions.

It will come as no surprise that, in addition to standard upper and lower bounds, the domain must
have contractive solutions and type continuity for variable elimination to be sound for extended recursive
types. An inspection of the statement and proof of Lemma 5.12 shows that it does not depend on
a particular definition of type, but only on type continuity and soundness of the non-recursive case.
Thus, adding the hypothesis that the domain has standard upper and lower bounds to Lemma 5.12, and
substituting Lemma 6.4 for Lemma 4.3 in the proof of the lemma, gives a proof of soundness for variable
elimination on extended recursive types.

Because extended simple types are a subset of the extended recursive types and the VEP is incomplete
for extended simple types, it follows that variable elimination is incomplete for extended recursive types.

7 Constrained Type Expressions
This section presents results for types with polymorphism and subtyping constraints, which is also called
bounded polymorphism or constrained types. This language is the most general that we consider.

7.1 Preliminaries
We begin by defining a type language with subsidiary subtyping constraints.

2This corrects a rather vague and misleading analysis for this case in the original version of this paper.

30

Definition 7.1 An (unquantified) constrained type expression has the form o/0=C where C is a set of
constraints of the form

o/1 _ o/ 01
: : : : : :

o/n _ o/ 0n

where o/i and o/ 0i are unquantified simple type expressions for all 1 ^ i ^ n.
Unlike the case of recursive types, note that Definition 7.1 makes no distinction between "regular" and
"defined" variables--all variables are regular.

Definition 7.2 Let ` be any assignment. Then

1. `(o/ =C) = `(o/ ) provided that ` is a solution of C.

2. `(8ff1; : : : ; ffn:o/ =C) =

uf`[ff1  x1; : : : ; ffn  xn](o/ =C)jx1; : : : ; xn 2 D0 and `[ff1  x1; : : : ; ffn  xn] is a solution of Cg

The meaning of an unquantified constrained type o/ =C under assignment ` is undefined unless ` is
a solution of C. Furthermore, the u operation in the meaning of a quantified constrained type under
assignment ` is restricted to those modifications of ` that satisfy the constraints. It is easy to see that
constrained types are a generalization of recursive types, because any recursive type

8ff1; : : : ; ffm:o/ = ffi1 = o/1 ! o/ 01 ^ : : : ^ ffin = o/n ! o/ 0n
can be written as a constrained type

8ff1; : : : ; ffm:o/ = ffi1 _ o/1 ! o/ 01 ^ ffi1 * o/1 ! o/ 01 ^ : : : ^ ffin _ o/n ! o/ 01 ^ ffin * o/n ! o/ 01
It is also worth noting that it is well-defined for a quantified constrained type to have an inconsistent
system of constraints. For example, if C = ? _ ff _ ?, then

`(8ff:o/ =C)
= uf`[ff  x](o/ =C)jx 2 D0 and `[ff  x] is a solution of Cg
= ufg
= ?

An important feature of constrained types is that the constraints may have multiple lower (or upper)
bounds for a single variable, such as

o/1 ! o/2 _ ff ^ o/3 ! o/4 _ ff ^ fi _ fl ^ fi _ o/5 ! o/6
In any solution of these constraints, ff must be an upper bound of o/1 ! o/2 and o/3 ! o/4, and fi must be
a lower bound of fl and o/5 ! o/6.

To give algorithms for eliminating quantified variables from constrained types, it is necessary to
characterize the solutions of constraints. To minimize the number of new concepts needed to explain
the algorithms in the case of constrained types, we build on the results of Section 5 by characterizing
solutions of constraints in terms of equations.

31

Definition 7.3 A system C of constraints is closed iff

o/1 _ ff 2 C ^ ff _ o/2 2 C ) o/1 _ o/2 2 C

o/1 ! o/2 _ o/3 ! o/4 2 C ) o/3 _ o/1 2 C ^ o/2 _ o/4 2 C

A closed system C is consistent iff ? _ ? 62 C.

Definition 7.3 is taken from [EST95]. Intuitively, closing a system of constraints C is equivalent to
solving C, and if the closed system has no inconsistent constraints, then it has solutions. Instead of
asserting that closed consistent systems have solutions directly, we characterize those solutions in terms
of equations.

Definition 7.4 Let C be a closed consistent system of constraints. Let the variables of C be ffi1; : : : ; ffin.
For each variable ffii appearing in C, define

LCffii = ? + \Sigma fo/ jo/ _ ffii 2 C and if o/ is a variable ffij; then j ! ig
U Cffii = ? \Delta  \Pi fo/ jo/ * ffii 2 C and if o/ is a variable ffij; then j ! ig

Let ff1; : : : ; ffn be fresh variables. Define a system of equations EC for C:^

1^i^n

ffii = LCffii + (ffi \Delta  U Cffii )

The intuition behind Definition 7.4 is that any solution for the equation for ffii ranges between LCffi

i (whenff

i = ?) and U Cffii (when ffi = ?). For example, consider the system C of constraints

ffi1 _ ffi2 ^ ? ! ? _ ffi1 ^ ffi1 _ ? ! ?
Closing this system gives

ffi1 _ ffi2 ^ ? ! ? _ ffi1 ^ ffi1 _ ? ! ? ^ ? ! ? _ ffi2 ^ ? ! ? _ ? ! ? ^ ? _ ?
which is consistent. The equations EC are

ffi1 = (? ! ?) + (ff1 \Delta  (? ! ?))
ffi2 = ((? ! ?) + ffi1) + (ff2 \Delta  ?)

This example shows that the equations EC are not necessarily contractive, since ffi1 appears outside of a
constructor in the equation for ffi2. However, EC is always equivalent to a contractive system of equations.

Lemma 7.5 Let EC be a system of equations for a closed consistent system of constraints C. Then
there is a system of constraints E0C that is contractive such that EC and E0C have the same solutions.

Proof: Examination of Lffii and Uffii in Definition 7.4 shows that if ffij occurs outside of a ! expression
in the equation for ffii, then j ! i. We show by induction on i how to construct a contractive equation
for ffii. The equation for ffi1 has no variable ffik outside of a ! expression, so the equation for ffi1 is
already contractive. Assume that ffi1; : : : ; ffii\Gamma 1 have contractive equations. Any variable ffij outside of a !

32

expression in the equation for ffii can be eliminated by substituting the right-hand side of an equation for
ffij. Because j ! i, we can choose a contractive equation for ffij, in which case the resulting equation for
ffii is also contractive. 2

Applying Lemma 7.5 to the example system of equations above, the contractive system is

ffi1 = (? ! ?) + (ff1 \Delta  (? ! ?))
ffi2 = ((? ! ?) + (? ! ?) + (ff1 \Delta  (? ! ?))) + (ff2 \Delta  ?)

Definition 7.6 A domain is adequate if

1. the domain has contractive solutions,
2. the domain has standard upper and lower bounds,
3. and for any consistent closed system C of constraints over ffi1; : : : ; ffin,

` is a solution of C , 9`0: `0 is a solution of EC and 81 ^ i ^ n: `(ffii) = `0(ffii)

Lemma 7.7 In an adequate domain, closed consistent systems of constraints have solutions.
Proof: By Part 3 of Definition 7.6, a closed consistent system C has solutions iff EC has solutions. By
Lemma 7.5, EC is equivalent to a contractive system of equations. By Part 1 of Definition 7.6, contractive
equations always have solutions in an adequate domain. 2

A construction of an adequate domain is given in [AW93]. A solution procedure for constraints over
regular trees is given in [PO95].

7.2 Soundness
The equivalence between constraints and equations in an adequate domain suggests that variable elimination can be performed by first translating from constraints to equations, applying the results of Section 6.4
to eliminate variables, and then translating back (if desired) to constraints. We can improve on this procedure with a modified Extended Variable Elimination Procedure that takes advantage of the structure
of constraint systems.

Procedure 7.8 Let oe = 8ffi1; : : : ; ffin:o/ =C be a quantified constrained type. Let

oe0 = 8ff1; : : : ; ffn:o/ =EC
be the corresponding extended quantified type. Perform the following steps on oe0:

1. Let oe1 be the result of replacing any subexpression o/1 + o/2 in oe0 by o/2 if `(o/1) _ `(o/2) for all

assignments `. In particular, if any equation of EC has the form

ffii = LCffii + ? \Delta  U Cffii
then replace the equation by

ffii = U Cffii

since `(LCffi

i) _ `(U

Cffi

i ) for any solution ` of the constraints.

33

2. Let oe2 be the result of replacing any subexpression o/1 \Delta  o/2 in oe0 by o/2 if `(o/2) _ `(o/1) for all

assignments `. In particular, if any equation of EC has the form

ffii = LCffii + ? \Delta  U Cffii
then replace the equation by

ffii = LCffii

3. Let oe3 = V EP (oe2).
4. Halt if no variables are eliminated in (3); the result is oe3. Repeat (1)-(3) on oe3 otherwise.
Example 7.9 Consider the type

8ffi1; ffi2: ffi1 ! ffi2= ffi1 _ ffi2

The extended quantified type is

8ff1; ff2:ffi1 ! ffi2=E where E is (ffi1 = ? + ff1 \Delta  ffi2 ^ ffi2 = ? + ff2 \Delta  ?) :
Now Pos(ffi1 ! ffi2=E) = fff2g and Neg(ffi1 ! ffi2=E) = fff1; ff2g. Thus ff1 can be set to ?; performing this
substitution and simplifying gives:

8ff2:ffi1 ! ffi2= ffi1 = ffi2 ^ ffi2 = ff2
Substituting ff2 for the other variables gives:

8ff2:ff2 ! ff2
Soundness is easy to prove for the procedure given above.
Lemma 7.10 Let oe = 8ffi1; : : : ; ffin:o/ =C and assume that C is closed and consistent. If the domain is
adequate and has type continuity, then Procedure 7.8 is sound for oe.

Proof: Follows from Definition 7.6 and Lemma 5.12. 2

We note that it is easy to give an algorithm that implements the effect of Procedure 7.8 on the
constraints directly, without requiring translations to and from equations.

8 Conclusions
Polymorphic types with subtyping have rich structure. In this paper, we have shown that for simple
non-recursive types and recursive types, it is possible to compute an optimal representation of a polymorphic type in the sense that no other equivalent type has fewer quantified variables. Thus, the optimal
representation can be interpreted as having the minimum polymorphism needed to express the type.

In more complex type languages, in particular in languages with union and intersection types, the
same methods are sound but incomplete. The completeness results for the simpler type languages show
that the source of incompleteness is in fact union and intersection types in these languages. The problem
of whether there is a sound and complete variable elimination procedure for languages with intersection
and union types remains open.

We have also given a sound variable elimination procedure for polymorphic constrained types. Variable
elimination is critically important in implementations of type systems using constrained types [FA96],
and in fact the desire to better understand variable elimination in this setting was the original motivation
for this work. However, the problem of whether there is a sound and complete procedure for eliminating
variables in polymorphic constrained types also remains open.

34

References
[AC93] Roberto M. Amadio and Luca Cardelli. Subtyping recursive types. ACM Transactions on

Programming Languages and Systems, 15(4):575-631, 1993. Also in Proc. POPL'91.

[AM91] A. Aiken and B. Murphy. Implementing regular tree expressions. In Proceedings of the 1991

Conference on Functional Programming Languages and Computer Architecture, pages 427-447,
August 1991.

[AW93] A. Aiken and E. Wimmers. Type inclusion constraints and type inference. In Proceedings of

the 1993 Conference on Functional Programming Languages and Computer Architecture, pages
31-41, Copenhagen, Denmark, June 1993.

[AWL94] A. Aiken, E. Wimmers, and T.K. Lakshman. Soft typing with conditional types. In TwentyFirst Annual ACM Symposium on Principles of Programming Languages, pages 163-173, Portland, Oregon, January 1994.

[Cou79] Bruno Courcelle. Infinite trees in normal form and recursive equations having a unique solution.

Mathematical Systems Theory, 13:131-180, 1979.

[Cur90] Pavel Curtis. Constrained quantification in polymorphic type analysis. Technical Report CSL90-1, Xerox Parc, February 1990.

[CW85] L. Cardelli and P. Wegner. On understanding types, data abstraction and polymorphism.

Computing Surverys, 17(4):471-522, December 1985.

[EST95] J. Eifrig, S. Smith, and V. Trifonov. Sound polymorphic type inference for objects. In OOPSLA

'96, 1995.

[FA96] M. F"ahndrich and A. Aiken. Making set-constraint program analyses scale. In CP96 Workshop

on Set Constraints, August 1996.

[HM94] Fritz Henglein and Christian Mossin. Polymorphic binding-time analysis. In Donald Sannella,

editor, Proceedings of European Symposium on Programming, volume 788 of Lecture Notes in
Computer Science, pages 287-301. Springer-Verlag, April 1994.

[Kae92] Stefan Kaes. Type inference in the presence of overloading, subtyping and recursive types. In

1992 ACM Conference on Lisp and Functional Programming. San Francisco, California. LISP
Pointers V, 1, pages 193-204, June 1992.

[Koe94] A. Koenig. An anecdote about ML type inference. In Proceedings of the USENIX 1994 Symposium on Very High Level Languages, October 1994.

[MPS84] D. MacQueen, G. Plotkin, and R. Sethi. An ideal model for recursive polymophic types. In

Eleventh Annual ACM Symposium on Principles of Programming Languages, pages 165-174,
January 1984.

[PO95] J. Palsberg and P. O'Keefe. A type system equivalent to flow analysis. ACM Transactions

on Programming Languages and Systems, 17(4):576-599, July 1995. Preliminary version in
Proc. POPL'95, 22nd Annual SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, pages 367-378, San Francisco, California, January 1995.

35

[Pot96] F. Pottier. Simplifying subtyping constraints. In Proceedings of the 1996 ACM SIGPLAN

International Conference on Functional Programming, pages 122-133, May 1996.

[Smi94] Geoffrey S. Smith. Principal type schemes for functional programs with overloading and subtyping. Science of Computer Programming, 23:197-226, 1994.

36