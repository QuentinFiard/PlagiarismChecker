

Programming with Proofs and Explicit Contexts

[Extended Abstract]
Brigitte PientkaSchool of Computer Science

McGill UniversityMontreal, Canada
bpientka@cs.mcgill.ca

Joshua DunfieldSchool of Computer Science

McGill UniversityMontreal, Canada
joshua@cs.mcgill.ca

ABSTRACT
This paper explores a new point in the design space of
functional programming: functional programming with dependently-typed higher-order data structures described in
the logical framework LF. This allows us to program with
proofs as higher-order data. We present a decidable bidirectional type system that distinguishes between dependentlytyped data and computations. To support reasoning about
open data, our foundation makes contexts explicit. This
provides us with a concise characterization of open data,
which is crucial to elegantly describe proofs. In addition,
we present an operational semantics for this language based
on higher-order pattern matching for dependently typed objects. Based on this development, we prove progress and
preservation.

Categories and Subject Descriptors
D.3.1 [Programming Languages]: Formal Definitions and
Theory

General Terms
Theory, Languages

Keywords
Type theory, Dependent types, Logical frameworks

1. INTRODUCTION

Various forms of dependent types have found their way
into mainstream functional programming languages to
allow programmers to express stronger properties about
their programs [2, 16, 26, 29]. In this paper, we explore a
new point in the design space of functional programming
with dependent types where we can analyze and manipulate
dependently-typed higher-order data described in the logical framework LF [9]. LF provides a rich meta-language for
describing formal systems defined by axioms and inference

Permission to make digital or hard copies of all or part of this work forpersonal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copiesbear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specificpermission and/or a fee.
PPDP'08, July 16-18, 2008, Valencia, Spain.Copyright 2008 ACM 978-1-60558-117-0/08/07 ...$5.00.

rules (such as a type system, a logic, etc.) together with
proofs within these systems (such as a typing derivation, a
proof of a proposition, etc.). Its strength and elegance comes
from supporting encodings based on higher-order abstract
syntax (HOAS), in which binders in the object language are
represented as binders in the meta-language. For example,
the formula 8x:(x = 1) oe ~(x = 0) is represented as
forall *x. (eq x (Suc Zero)) imp (not (eq x Zero)).
This simple, but powerful idea avoids the need to implement common and tricky machinery for variables, such as
capture-avoiding substitution and renaming.

However, implementing and verifying proofs about HOAS
encodings has been notoriously difficult. There are two distinct challenges. First, encodings based on HOAS require us
to recursively traverse binders and describe open data objects within a context. Second, dependent types add another
degree of complexity: data objects themselves can refer to
types and the structure of types can be observed.

Programming with HOAS has recently received widespread
attention, although most work has focused on the simplytyped setting [5, 10, 21, 25]. Only a few approaches have
been considered in the dependently-typed setting. Despeyroux and Leleu [3, 4] extended previous work by Despeyroux et al. [5] which provided a type-theoretic foundation
for primitive recursive programming with HOAS. The Delphin language [23] extends these ideas to provide general
recursion over HOAS encodings as well as dependent types.

In this paper, we present an alternative to these approaches,
extending the first author's previous work on programming
with HOAS encodings in the simply-typed setting [21] to
dependent types. As in that work, we use contextual modal
types [15] to separate HOAS data from computations about
them. Open data M is characterized by the contextual
modal type A[\Psi ] where M has type A in the context \Psi .
The object M is closed with respect to the context \Psi , so M
can refer to variables declared in \Psi . For example, the object eq x (Suc Zero) has type o[x:nat] (where o describes
propositions). Since we want to allow recursion over open
data and the local context \Psi  associated with the type A
may grow, our foundation supports context variables, which
allow us to abstract over contexts. Just as types classify
terms, and kinds classify types, we use context schemas to
classify and characterize contexts.

In this paper, we revisit the key concepts from the simplytyped setting [21] and generalize them to dependent types.
While extending the data language with dependent types follows from previous work [15], the generalization of context
schemas to dependent types and, especially, the integration

of dependently typed higher-order data into the computation language are novel. Our discussion will highlight the
fact that the simply-typed foundation scales nicely to the
setting of dependent types. This lays the foundation for
programming with proofs and explicit contexts. Inductive
proofs about formal systems can be implemented as recursive functions, and case analysis in the inductive proof corresponds to analyzing dependently-typed higher-order data
via pattern matching. We call this language Beluga.

We make the following contributions. First, we present
a syntax-directed decidable type system for dependentlytyped open data. Our presentation only admits data objects in canonical form because only those represent meaningful data. This follows the ideas of Watkins et al.[28] and
Nanevski et al.[15]. By cleanly separating the data language
from the computation language, exotic terms that do not
represent legal data objects are prevented. Our framework
supports explicit context variables to abstract over the concrete context and parameterizes computations by contexts,
classified by context schemas. While context schemas have
been present in the simply-typed setting, characterizing contexts in the presence of dependent types is more complex.

Second, we present a type system for computation that allows recursion and pattern matching on dependently-typed
open data. This type system is also syntax-directed and decidable. It allows dependent types, but only types indexed
by data objects, not arbitrary, possibly recursive computations. Because data objects are in canonical form, equality between two data objects is easily decided by syntactic
equality. This is crucial to achieve a decidable type system. The language we describe is intended as an internal
language, into which a source level language will be compiled. It clearly distinguishes between implicit data objects
that occur in a dependent type and may be kept implicit
in the actual source program, and explicit data objects that
are recursively analyzed with higher-order pattern matching [13, 17] and are explicit in the source program. Intuitively, implicit data arguments are the index objects that
are reconstructed when translating a source language to this
internal language. In addition, our type system is unique in
that constraints due to dependent types are resolved eagerly
during type checking using higher-order pattern unification,
leading to an elegant decidable algorithm.

Finally, we present a small-step operational semantics based
on higher-order pattern matching for dependently-typed objects [17, 22], and prove progress and preservation for our
language with respect to this semantics.

This paper is a first important step in laying the typetheoretic foundation for programming with proofs and explicit contexts. Our foundation ensures that contexts are
well-formed according to a user-specified schema, and we
have formulated a coverage checking algorithm [6] for dependently-typed open data. At this point, the only missing
piece is to verify that a given function terminates--we leave
this for a separate paper. As such, our work may be thought
of as an alternative to Twelf [19], an implementation of the
logical framework LF [9] in which proofs about formal systems are encoded via relations, and to Delphin [23] (which,
like our system, implements proofs via functions).

2. MOTIVATION

To motivate the problem, we consider a program that
counts the free occurrences of some variable x in a formula.

For example, the formula 8y:(x = y) oe (suc y = suc x)
has two free occurrences of x. The data language here is
first-order logic with quantification over natural numbers.
We begin by defining a type o for propositions and we use
higher-order abstract syntax to model the binder in the universal quantifier.

nat : type .
Zero: nat.
Suc : nat ! nat.

o : type .
eq : nat ! nat ! o.
imp : o ! o ! o.
forall: (nat ! o) ! o.

2.1 Counting free variable occurrences

We will approach this problem top-down and first consider
the function cntV which will recursively analyze formulas
using pattern matching. When it reaches the proposition
eq, it will call a second function cntVN. The modal type
o[x:nat, y:nat] describes a formula that can refer to the
variables x and y. One element of this type is the formula
((eq x y) imp (eq (Suc x) (Suc y))).

When analyzing a formula with a universal quantifier, the
set of free variables grows. Hence, we need to abstract over
the contexts in which the formula makes sense. Context variables  provide this functionality. The function cntV takes
a context  of natural numbers, a formula f, and returns
an integer. Just as types classify data objects and kinds
classify types, we introduce schemas to classify contexts. In
the type declaration for the function cntV we say that the
context variable  has the schema (nat)

*, meaning that 

stands for a data-level context x1:nat,: : :,xn:nat.

ctx schema natCtx = (nat)

*

rec cntV : \Pi  :natCtx.o[,x:nat] ! nat[.] =
\Lambda   ) fn f ) case f of

box(,x. imp U[id,x] W[id,x]) )

add (cntV de box(,x. U[id,x]))

(cntV de box(,x. W[id,x]))
| box(,x. forall(*y.U[id,x,y])) )

cntVd,y:nate box(,y,x. U[id,x,y])
| box(,x. eq U[id,x] V[id, x]) )

add (cntVN de box(,x.U[id,x]))

(cntVN de box(,x.V[id,x]))

The function cntV is built by a context abstraction \Lambda  
that introduces the context variable  and binds every occurrence of  in the body. Next, we introduce the computation-level variable f which has type o[,x:nat]. In the
body of the function cntV we case-analyze objects of type
o[,x:nat]. The box construct separates data from computations.

When we encounter an object built from a constructor
eq, imp, or forall, we need to access the subexpression(s)
underneath. Pattern variables are characterized by a closure
U[oe] consisting of a contextual variable U and a postponed
substitution oe. As soon as we know what the contextual
variable stands for, we apply the substitution oe. In the
example, the postponed substitution associated with U is
the identity substitution which essentially corresponds to ffrenaming. We write id for the identity substitution with
domain . Intuitively, one may think of the substitution
associated with contextual variables occurring in patterns
as a list of variables which may occur in the hole. In the
data object U[id], for example, the contextual variable U
can be instantiated with any formula that is either closed

(i.e. it does not refer to any bound variable listed in the
context ) or contains a bound variable from the context .
Since we want to allow subformulas to refer to all variables
in (, x:nat), we write U[id, x]. We use capital letters
for meta-variables.

In the first case for imp we recursively analyze the subformulas described by U[id,x] and W[id,x]. The context 
is the same, so we pass it (explicitly) in the recursive calls.

In the case for box(,x. forall (*y.W[id,x,y])), we
analyze the formula W[id,x,y] under the assumption that
y is a natural number. To do this, we pass an extended
context (,y:nat) to cntV.

Finally, for eq, we call cntVN to count the occurrences of x
in the natural numbers U[id,x] and V[id, x], explicitly
passing the context . The function cntVN counts the occurrences of a variable x in an object of type nat[,x:nat].

rec cntVN : \Pi  :natCtx.nat[,x:nat] ! nat[.] =
\Lambda   ) fn n ) case n of

box(,x. x) ) box( . Suc Z)
| box(,x. p[id]) ) box( . Z)
| box(,x. Zero) ) box( . Z)
| box(,x. Suc U[id,x]) )

cntVN de box(,x. U[id,x])

The first two cases are the interesting ones. The pattern box(,x. x) matches an occurrence of x. The second
pattern, box(,x. p[id]), matches a variable that is not x
and occurs in . For this case, we use a parameter variable p
(the small letter distinguishes it from a meta-variable). This
represents a bound data-level variable. The substitution id
associated with p characterizes the possible instantiations
of p. This allows us to write a generic base case where we
encounter a parameter from the context that  stands for.
This combination of explicit context variables and parameter
variables to describe generic base cases is unique to our work.
Comparison and explicit pattern matching for variables are
features typically associated with nominal systems [7, 27].
However, unlike nominal systems, variable names here are
not global, but local and subject to ff-renaming.

In Twelf [19], one can write a relation that counts variable
occurrences, but there is no generic base case for counting
variables in a natural number. Instead, one dynamically
adds the appropriate base case for every variable introduced
when traversing a universal quantifier.

2.2 Example: Programming with proofs

We illustrate the idea of programming with proofs by
considering bracket abstraction, a key lemma that arises in
the translation of natural deduction proofs to Hilbert-style
proofs. For this discussion we concentrate on the fragment
consisting of implications. This example has been extensively discussed in the literature [18, 23] and so highlights
the differences between approaches. This example again
uses explicit context variables and parameter variables. The
Hilbert-style axiomatization can be formalized as follows:

hil : o ! type .
k : hil (A imp (B imp A)).
s : hil ((A imp (B imp C)) imp

((A imp B) imp (A imp C))).
mp : hil (A imp B) ! hil A ! hil B.

We omit leading \Pi s from the types when they can be
reconstructed, as is common practice in Twelf [19].

The bracket abstraction lemma states that a derivation
D of hil B that depends on the hypothesis x:hil A can be
translated into a derivation E of hil (A imp B) that does
not refer to the hypothesis x:

Lemma (Bracket abstraction)
If D :: \Gamma ; x:hil A ` hil B then E : \Gamma  ` hil (A imp B)

The context \Gamma  has the form xn:hil An; : : : ; x1:hil A1, and
the proof follows by induction on the derivation D. There
are four base cases. Two arise from the constants k and
s, but we concentrate on the other two cases, which arise
from using an assumption in \Gamma ; x:hil A: we could have used
the assumption x:hil A, or an assumption xi:Ai from \Gamma , to
prove hil B.

Explicit contexts allow us to easily characterize the lemma
as a dependent type, and implement the inductive proof as a
recursive program using pattern matching. Moreover, every
case in the informal proof directly corresponds to a case in
our recursive program. As a first step, we characterize the
context \Gamma  with a context schema:

ctx schema hilCtx = (all A:o. hil A)

*.

This schema describes contexts xn:hil An; : : : ; x1:hil A1.
Next, we represent the lemma as a dependent type. The
recursive function that realizes this type describes the proof
transformation on Hilbert derivations. Implicit data objects
that characterize index objects occurring in a dependent
type are introduced with \Pi 

2, but we omit these implicit

type arguments from computations and from data for readability, since we expect them to be reconstructed in practice.

rec ded: \Pi  fl:hilCtx.\Pi 

2A:o[fl] \Pi 2B:o[fl].

(hil B[idfl])[fl, x:hil A[idfl]]
! (hil (A[idfl] imp B[idfl]))[fl] =
\Lambda  fl ) fn D )
case D of

box(fl, x. k) ) box(fl. mp k k)
| box(fl, x. s) ) box(fl. mp k s)
| box(fl, x. x) ) box(fl. mp (mp s k) k)
| box(fl, x. p[idfl]) ) box(fl. mp k p[idfl])
| box(fl, x. mp D1[idfl, x] D2[idfl, x]) )

let

box(fl. E1[idfl]) = ded dfle box(fl,x. D1[idfl,x])
box(fl. E2[idfl]) = ded dfle box(fl,x. D2[idfl,x])
in

box(fl. mp (mp s E1[idfl]) E2[idfl])
end

We analyze Hilbert-style derivations by pattern matching
on D, which describes an object of type hil B[idfl] in the
context (fl, x:hil A[idfl]). Intuitively, we can construct
all derivations of the appropriate type by either using one of
the constructors or an element from the context. This gives
rise to the first two cases: either we have used the specific
assumption x, or we have used one of the assumptions in fl.
To describe this last generic variable case, we again use a
parameter variable.

The other base cases are straightforward, so we concentrate on the last case where we use modus ponens. To pattern match on derivations constructed using the constant mp,
we describe the subderivations using meta-variables D1[idfl]
and D2[idfl] for which higher-order pattern matching will
find appropriate instantiations during runtime. The appeal
to the induction hypothesis corresponds to the recursive call
to the function ded. We first pass to this function the context

fl by context application, and then the derivation described
by box(fl,x. D1[idfl, x]).

2.3 Summary of key ideas

We summarize here the five key ideas underlying our work:
First, we separate data from computations via the modality
box. Second, every data object is closed with respect to a
local context. For example, box(x. eq x z) denotes an object of type o[x:nat], i.e. a proposition that may contain
the variable x. The box-construct introduces the bound variables x. Third, we allow context variables  and abstract
over them on the computation level. This is necessary since
the concrete bound variables occurring in a data object are
only exposed when we recursively traverse a binder, and
the context describing these variables may grow. More importantly, this allows us to program with explicit contexts
and capture more invariants. Fourth, we support pattern
matching on higher-order data using meta-variables and,
importantly, parameter variables. While meta-variables allow us to deconstruct arbitrary objects with binders, parameter variables allow us to manipulate names of bound
variables directly in computation. Finally, we support dependent types using the type \Pi 

2u::A[\Psi ]:o/, and we clearly

distinguish implicit data objects occurring as index objects
in data-level types from explicit data objects that can be
analyzed by pattern matching.

3. DATA-LEVEL TERMS AND CONTEXTS

We begin by describing the data layer of our dependentlytyped intermediate language. We support the full logical
framework LF together with \Sigma -types. Our data layer closely
follows contextual modal type theory [15], extended with
parameter variables and context variables [21], and finally
with dependent pairs and projections1.

Kinds K ::= type | \Pi x:A:K
Atomic types P ::= a M1 : : : Mn
Types A; B ::= P | \Pi x:A:B | \Sigma x:A:B
Normal terms M; N ::= *x: M | (M; N) | R
Neutral terms R ::= c | x | u[oe] | p[oe]

| R N | projkR
Substitutions oe; ae ::= * | oe ; M | oe ; R | id

We only characterize normal terms since only these are meaningful in the logical framework, following Watkins et al. [28]
and Nanevski et al. [15]. This is achieved by distinguishing
between normal terms M and neutral terms R. While the
syntax only guarantees that terms N contain no fi-redexes,
the typing rules will also guarantee that all well-typed terms
are fully j-expanded.

We distinguish between four kinds of variables in our theory: Ordinary bound variables are used to represent datalevel binders and are bound by *-abstraction. Contextual
variables stand for open objects, and include meta-variables
u that represent general open objects and parameter variables p that can only be instantiated with an ordinary bound
variable. Contextual variables are introduced in computationlevel case expressions, and can be instantiated via pattern
matching. They are associated with a postponed substitu1Prior work also considered substitution variables. Although our theory extends to substitution variables, we omitthem here to make the presentation compact and focus on

aspects related to dependent types.

tion oe thereby representing a closure. This substitution precisely characterizes the dependencies we allow when instantiating the meta-variable with an open term. Our intention
is to apply oe as soon as we know which term the contextual
variable should stand for. The domain of oe thus describes
the free variables of the object the contextual variable stands
for, and the type system statically guarantees this.

Substitutions oe are built of either normal terms (in oe ; M)
or atomic terms (in oe ; R). The two forms are necessary
since not every neutral term is also a normal term. Only
neutral terms of atomic type are in fact normal. We do not
make the domain of the substitutions explicit, which simplifies the theoretical development and avoids having to rename the domain of a given substitution oe. We also require
a first-class notion of identity substitution id. Data-level
substitutions, as defined operations on data-level terms, are
written [oe]N.

While contextual variables are declared in a meta-level
context \Delta , ordinary bound variables are declared in a datalevel context \Psi . Our foundation supports context variables
 which allow us to reason abstractly with contexts. Context variables are declared in \Omega . Unlike previous uses of
context variables [12], a context may contain at most one
context variable. In the same way that types classify objects, and kinds classify types, we introduce the notion of a
schema W that classifies contexts \Psi .

Context variables ; OE
Contexts \Psi ; \Phi  ::= * |  | \Psi ; x:A
Meta-contexts \Delta  ::= * | \Delta ; u::A[\Psi ] | \Delta ; p::A[\Psi ]
Schema contexts \Omega  ::= * | \Omega ; ::W

Element types eA ::= \Pi x:A: eA | a N1 : : : Nn
Schema elements F ::= all x1:fB1; : : : ; xn: fBn:

\Sigma y1:fA1; : : : ; yk:fAk: eA
Schemas W ::= (F1 + * * * + Fn)

*

As the earlier example illustrated, contexts play an important part in programming with open data objects, and
contexts, which are explicitly constructed at the computation level, belong to a specific context schema. For example,
the schema (nat)

* represented contexts of the form x1:nat,

: : :, xn:nat, and the schema all A:o. hil A characterized
the context \Gamma  consisting of assumptions x:hil A. In general,
we allow an even richer form of contexts to be captured.
Consider how the schema of the context \Gamma  will change when
we extend the Hilbert-style calculus with universal quantifiers. In this case, we must also consider assumptions about
possible parameters introduced when we traverse a universal
quantifier. On paper, we may write the following to characterize this context:

Hilbert Contexts \Gamma  ::= * | \Gamma ; a:nat | \Gamma ; x:hil A
We provide + to denote a choice of possible elements in a
context. Hence we would modify our schema for Hilbert
contexts as follows:

ctx schema hilCtx = nat + all A:o. hil A.
Context schemas are built of elements F1; : : : Fn, each of
which must have the form all e\Phi :\Sigma e\Psi : eA where e\Phi  and e\Psi  are
\Sigma -free contexts, i.e. x1:fB1; : : : xk: fBk. In other words, the element is of \Sigma \Pi -type, where we first introduce some \Sigma -types,
followed by pure \Pi -types. We disallow arbitrary mixing of
\Sigma  and \Pi . This restriction makes it easier to describe the

possible terms of this type, which is a crucial step towards
ensuring coverage [6].

Schemas resemble Sch"urmann's worlds [24], but while similar in spirit, we use dependent pairs to express the relationship between multiple objects in a context. While worlds
impose a similar \Sigma \Pi -structure, schemas differ from worlds
in the sense that schemas are pure. They only keep track
of assumptions about binders occurring in a data object of
type A. This is unlike worlds as realized in Twelf [19], which
also track dynamic computation-level extensions.

3.1 Data-level typing

In this section, we present a bidirectional type system for
data-level terms. We assume that type constants and object
constants are declared in a signature \Sigma , which we suppress
since it is the same throughout a typing derivation. However, we will keep in mind that all typing judgments have
access to a well-formed signature. Typing is defined via the
following judgments:

\Omega ; \Delta ; \Psi  ` M ( A Check normal object M against A
\Omega ; \Delta ; \Psi  ` R ) A Synthesize A for neutral object R
\Omega ; \Delta ; \Phi  ` oe ( \Psi  Check oe against context \Psi 

For readability, we omit \Omega  in the subsequent development
since it is constant; we also assume that \Delta  and \Psi  are wellformed. First, the typing rules for objects.

Data-level normal terms

\Delta ; \Psi ; x:A ` M ( B
\Delta ; \Psi  ` *x: M ( \Pi x:A:B \Pi I

\Delta ; \Psi  ` M1 ( A1 \Delta ; \Psi  ` M2 ( [M1=x]aA1A2

\Delta ; \Psi  ` (M1; M2) ( \Sigma x:A1:A2 \Sigma I

\Delta ; \Psi  ` R ) P

0 P 0 = P

\Delta ; \Psi  ` R ( P turn
Data-level neutral terms

x:A 2 \Psi 
\Delta ; \Psi  ` x ) A var

c:A 2 \Sigma 
\Delta ; \Psi  ` c ) A con

u::A[\Phi ] 2 \Delta  \Delta ; \Psi  ` oe ( \Phi 

\Delta ; \Psi  ` u[oe] ) [oe]a\Phi A mvar

p::A[\Phi ] 2 \Delta  \Delta ; \Psi  ` oe ( \Phi 

\Delta ; \Psi  ` p[oe] ) [oe]a\Phi A

param

\Delta ; \Psi  ` R ) \Pi x:A:B \Delta ; \Psi  ` N ( A

\Delta ; \Psi  ` R N ) [N=x]aAB \Pi E

\Delta ; \Psi  ` R ) \Sigma x:A1:A2

\Delta ; \Psi  ` proj1R ) A1 \Sigma E1

\Delta ; \Psi  ` R ) \Sigma x:A1:A2
\Delta ; \Psi  ` proj2R ) [proj1R=x]aA1A2 \Sigma E

2

Data-level substitutions

\Delta ; \Psi  ` * ( * \Delta ; ; \Psi  ` id ( 
\Delta ; \Psi  ` oe ( \Phi  \Delta ; \Psi  ` R ) A

0 [oe]a\Phi A = A0

\Delta ; \Psi  ` (oe ; R) ( (\Phi ; x:A)
\Delta ; \Psi  ` oe ( \Phi  \Delta ; \Psi  ` M ( [oe]a\Phi A

\Delta ; \Psi  ` (oe ; M) ( (\Phi ; x:A)

We assume that data level type constants a together with
constants c have been declared in a signature. We will tacitly rename bound variables, and maintain that contexts and
substitutions declare no variable more than once. Note that
substitutions oe are defined only on ordinary variables x, not
on modal variables u. We also require the usual conditions
on bound variables. For example, in the rule \Pi I the bound
variable x must be new and cannot already occur in the context \Psi . This can always be achieved via ff-renaming. The
typing rules for data-level neutral terms rely on hereditary
substitutions that preserve canonical forms [15, 28].

The idea is to define a primitive recursive functional that
always returns a canonical object. In places where the ordinary substitution would construct a redex (*y: M) N we
must continue, substituting N for y in M. Since this could
again create a redex, we must continue and hereditarily substitute and eliminate potential redexes. Hereditary substitution can be defined recursively, considering both the structure of the term to which the substitution is applied and the
type of the object being substituted. Hence we annotate
the substitution with the type of the argument being substituted. We also indicate with the superscript a that the
substitution is applied to a type. We give the definition of
hereditary substitutions in the appendix.

Finally, we define context checking.

Context \Psi  checks against a schema W : \Omega  ` \Psi  ( W

for some k

\Omega ; \Delta ; \Psi  ` B 2 Fk \Omega ; \Delta  ` \Psi  ( (F1 + * * * + Fn)

*

\Omega ; \Delta  ` \Psi ; x:B ( (F1 + * * * + Fn)

*

::W 2 \Omega 
\Omega ; \Delta  `  ( W \Omega ; \Delta  ` * ( W

To verify that a context \Psi  belongs to a schema W = (F1 +

* * * + Fn)

*, we check that for every declaration Bi in the

context \Psi , there exists a k s.t. Bi is an instance of a schema
element Fk = all e\Phi :\Sigma y1: eA1; : : : ; yj: eAj: eA. This means we
must find an instantiation oe for all the variables in e\Phi  s.t.
[oe]ae\Phi (\Sigma y1: eA1; : : : ; yj: eAj: eA) is equal to Bi. This is done in
practice by higher-order pattern matching.

Theorem 1 (Decidability of Typechecking).
All judgments in the contextual modal type theory are decidable.

Proof. The typing judgments are syntax-directed and
therefore clearly decidable assuming hereditary substitution
is decidable.

3.2 Substitution operations

The different variables (ordinary variables x, context variables , and contextual variables u[oe] and p[oe]) give rise to
different substitution operations. We already remarked on
the hereditary substitution operation for ordinary variables
x and we give its definition in the appendix. The remaining substitution operations do not require any significant
changes from earlier work [15, 21] to handle dependent types
and we revisit them in this section.

Substitution for context variables
If we encounter a context variable , we simply replace it
with the context \Psi . This is possible because context variables occur only in leftmost position. When we substitute

some context \Psi  for  in the context (; \Phi ), the context \Psi 
cannot depend on \Phi . This would not hold if we allowed
contexts of the form (\Phi ; ).

Data-level context
[[\Psi =]](*) = *
[[\Psi =]](\Phi ; x:A) = (\Phi 0; x:A0) if x =2 V(\Phi 0) and [[\Psi =]]A = A0

and [[\Psi =]]\Phi  = \Phi 0
[[\Psi =]]() = \Psi 
[[\Psi =]](OE) = OE if OE 6= 

When we apply the substitution [[\Psi =]] to the context \Phi ; x:A,
we apply the substitution to the type A, yielding some new
type A

0, and to the context \Phi , yielding some new context \Phi 0.

Applying the substitution to the type A is necessary in the
dependently-typed setting, since A may contain terms and
in particular identity substitutions id. When we replace 
with \Psi  in the substitution id, we unfold the identity substitution. Expansion of the identity substitution is defined
by the operation id(\Psi ) for valid contexts \Psi :

id(*) = *
id(\Psi ; x:A) = id(\Psi ) ; x
id() = id

Lemma 1 (Unfolding identity substitution).
If id(\Psi ) = oe then \Delta ; \Psi ; \Psi 

0 ` oe ( \Psi .

Proof. By induction on the structure of \Psi .
When we combine \Phi 

0 and the declaration x:A0 to yield a

new context, we must ensure that x is not already declared in
\Phi 

0. This can always be achieved by appropriately renaming

bound variable occurrences. We write V(\Phi 

0) for the set of

variables declared in \Phi 

0. The rest of the definition is mostly

straightforward.

Theorem 2 (Substitution for context variables).
If \Omega ; ::W; \Omega 

0; \Delta ; \Phi  ` J and \Omega  ` \Psi  ( W

then \Omega ; \Omega 

0; [[\Psi =]]\Delta ; [[\Psi =]](\Phi ) ` [[\Psi =]]J.

Proof. By induction on the first derivation using Lemma
1.

Contextual substitution for contextual variables
Substitution for contextual variables is a little more difficult, but is essentially similar to Pientka [21]. We can think
of u[oe] as a closure where, as soon as we know which term
u should stand for, we can apply oe to it. The typing will
ensure that the type of M and the type of u agree, i.e. we
can replace u of type A[\Psi ] with a normal term M if M has
type A in the context \Psi . Because of ff-conversion, the variables substituted at different occurrences of u may differ,
and we write the contextual substitution as [[ ^\Psi :M=u]](N),

[[ ^\Psi :M=u]](R), and [[ ^\Psi :M=u]](oe), where ^\Psi  binds all free variables in M. Applying [[ ^\Psi :M=u]] to the closure u[oe] first obtains the simultaneous substitution oe

0 = [[ ^\Psi :M=u]]oe, but instead of returning M[oe

0], it eagerly applies oe0 to M. Similar

ideas apply to parameter substitutions, which are written as
[[ ^\Psi :x=p]](M), [[ ^\Psi :x=p]](R), and [[ ^\Psi :x=p]](oe). Parameter substitution could not be achieved with the previous definition
of contextual substitution for meta-variables, since it only
allows us to substitute a normal term for a meta-variable,
and x is only normal if it is of atomic type. We give its
definition in the appendix.

Finally, we will rely in the subsequent development on simultaneous contextual substitutions, built of either metavariables, (`; ^\Psi :M=u), or parameter variables, (`; ^\Psi :x=p).
The judgment \Delta  ` ` ( \Delta 

0 checks that the contextual substitution ` maps contextual variables from \Delta 

0 to the contextual variables in \Delta .

Simultaneous contextual substitution

\Delta  ` * ( *

\Delta  ` ` ( \Delta 

0 \Delta ; [[`]]\Psi  ` M ( [[`]]A

\Delta  ` (`; ^\Psi :M=u) ( \Delta 

0; u::A[\Psi ]

\Delta  ` ` ( \Delta 

0 \Delta ; [[`]]\Psi  ` x ) A0 A0 = [[`]]A

\Delta  ` (`; ^\Psi :x=p) ( \Delta 

0; p::A[\Psi ]

4. COMPUTATION-LEVEL EXPRESSIONS

We cleanly separate the data level from the computation
level, which describes programs operating on data. Computations analyze data of type A[\Psi ], which denotes an object
of type A that may contain the variables specified in \Psi . To
allow quantification over context variables , we introduce
the type \Pi :W:o/ and context abstraction \Lambda :e. We write
! for computation-level functions.

As mentioned earlier, the language we describe in this section may be thought of as an internal language into which
source level programs will be compiled. The extension to dependent types is novel in that we clearly distinguish between
(1) implicit data objects which occur in a type as index and
are kept implicit in the source program and (2) explicit data
objects which are analyzed recursively by pattern matching. The intuition is that implicit arguments can be reconstructed when translating source programs to our intermediate representation. We introduce abstraction over implicit
data objects occurring in a dependent type A on the computation level using the dependent type \Pi 

2u::A[\Psi ]:o/. Moreover, we require that patterns occurring in the branches of
case expressions are annotated with types, since the type of
each pattern need not be identical to the type of the expression being case analyzed in the dependently-typed setting.
We expect that these annotations can be reconstructed during the compilation from source programs to this intermediate language.

Types o/ ::= A[\Psi ] | o/1 ! o/2 | \Pi ::W:o/ | \Pi 

2u::A[\Psi ]:o/

Expressions e ::= i | rec f:e | fn y:e | \Lambda :e | *

2u: e

(checked) | box( ^\Psi : M) | case i of bs
Expressions i ::= y | i e | i d\Psi e | i d ^\Psi :Me | (e : o/ )

(synth.)

Branch b ::= \Pi \Delta :box( ^\Psi : M) : A[\Psi ] 7! e
Branches bs ::= * | (b | bs)
Contexts \Gamma  ::= * | \Gamma ; y:o/

We will enforce that all context variables are bound by \Lambda -
abstractions. To support ff-renaming of ordinary bound
variables, we write box( ^\Psi : M) where ^\Psi  is a list of variables
that can possibly occur in M. Index objects of dependent
types are introduced by *

2u: e of type \Pi 2u::A[\Psi ]:o/ . In other

words, index objects are characterized by contextual variables. i d ^\Psi :Me describes the application of an index argument to an expression. The contextual variables in branches
b, declared in \Delta , are instantiated using higher-order pattern
matching. We only consider patterns `a la Miller [14] where
meta-variables that are subject to instantiation must be applied to a distinct set of bound variables. In our setting,
this means all contextual variables must be associated with
a substitution such as x\Phi (1)=x1; : : : ; x\Phi (n)=xn. This fragment is decidable and has efficient algorithms for pattern
matching [20, 22].

Patterns in case expressions are annotated with their types,
since in the dependently-typed setting, the type of each pattern need not be identical to the type of the expression being
analyzed.

4.1 Computation-level typing

We describe computation-level typing using the following
judgments:

\Omega ; \Delta ; \Gamma  ` e ( o/ e checks against o/
\Omega ; \Delta ; \Gamma  ` i ) o/ i synthesizes o/
\Omega ; \Delta ; \Gamma  ` b (o/0 o/ branch b checks against o/,

when case-analyzing a o/

0

The rules are given in Figure 1. The names of computationlevel rules are written with a line above to distinguish them
from the names of data-level rules, which are underlined.
There are two interesting rules. The first is turn. In this
rule we check that the computation-level types o/ and o/

0 are

equal. At the data level, we only characterize canonical
forms, so equality between two dependent types A and A

0

is simply syntactic equality. Hence, equality between two
computation-level types is also just syntactic equality. This
is in stark contrast to dependently-typed languages such
as Cayenne [1] and Epigram [11] that allow computations
within the index objects of dependent types. In these systems, we cannot simply compare two types syntactically, but
must evaluate the index arguments first, before comparing
the final values. Even weaker dependently-typed systems
such as DML [29], where types are indexed by a decidable
constraint domain such as integers with linear inequalities,
need efficient constraint solvers to decide type equality.

The second interesting rule in the bidirectional type checking algorithm is the one for branches, since the type Ak[\Psi k]
of each of the patterns must be considered equal to the type
A[\Psi ], the type of the expression we analyze by cases. In
some approaches to dependently typed programming [29],
branches are checked under certain equality constraints. Instead we propose here to solve these constraints eagerly using higher-order pattern unification [14]. Hence, we restrict
the contextual variables u[oe] that occur in patterns to be
higher-order patterns, i.e. the substitution oe is simply a renaming substitution. Higher-order pattern unification is decidable, so unification of the contexts and types is decidable.
For a formal description of a higher-order pattern unification
algorithm for contextual variables, see Pientka [20].

We use the judgment \Omega ; \Delta  ` A := Ak = (`; \Delta 

0) to describe

higher-order pattern unification for types. \Delta  describes all
the meta-variables occurring in types A and Ak. The result
of unifying A and Ak is a contextual substitution ` that
maps the meta-variables in \Delta  to the meta-variables in \Delta 

0

s.t. [[`]]A is equal to [[`]]Ak. This operation can be extended
to unify contexts \Psi  and \Psi k.

Unlike the simply-typed setting, where it is natural to
require linearity, i.e. that every contextual variable in a pattern occurs only once, we cannot enforce a similar condition
in the dependently-typed setting, because the object may
become ill-typed. To illustrate, consider pattern matching
against the Hilbert derivation box(. mp k D[id]). After reconstructing the omitted implicit arguments, we get

box(. mp A[id] (A[id] imp B[id]) k D[id]). It is clear
that enforcing linearity in dependently-typed patterns is impossible.

Let us now return to the rule for branches. Branches b
have the form \Pi \Delta :box( ^\Psi : M) 7! e where \Delta  contains all the
contextual variables introduced and occurring in the guard
box( ^\Psi : M). We concentrate here on the last rule for checking
the pattern in a case expression. After typing the pattern in
the case expression, we unify the type of the subject of the
case expression with the type of the pattern. First, however,
we must unify the context \Psi  with the context \Psi i of the pattern. Finally, we apply the result of higher-order unification
` to the body of the branch and check that it is well-typed.

This approach will simplify the preservation and progress
proof. It is also closer to a realistic implementation, which
would support early failure and indicate the offending branch.

Theorem 3 (Decidability of Typechecking).
Computation-level typechecking is decidable.

Proof. The typing rules are syntax-directed. Computationlevel types are in canonical form, so the equality in rule turn
is syntactic equality. Moreover, higher-order pattern matching is decidable. Thus, typechecking is decidable.

Finally, we briefly remark on computation-level substitutions. There are four varieties: [e=x]e

0 describes the substitution of the computation-level expression e for x in the
computation-level expression e

0. This operation is straightforward and capture-avoiding in the case of functions fn y:e.
It does not affect data-level terms, since the computationlevel variable x cannot occur in them.

[[\Psi =]](e) extends the previous definition of context substitution to the computation level. It is capture-avoiding in
the case for context abstraction, and is propagated to the
data level.

The last two varieties, [[`]](e) and [[ ^\Psi :M=u]](e), extend the
previous contextual substitution operation to the computation level in a straightforward manner. We ensure it is
capture-avoiding in *

2-abstraction and in branches of case

expressions.

4.2 Operational semantics

Next, we define a small-step evaluation judgment:

e evaluates in one step to e

0 e -! e0

Branch b matches box( ^\Psi : M) and steps to e

0

(box( ^\Psi : M) : A[\Psi ] := b) -! e

0

In the presence of full LF we cannot erase type information
completely during evaluation, since not all implicit type arguments can be uniquely determined. In the simply-typed
setting, the patterns in the branches of a case expression
must have the same type as the case expression's subject.
However, with dependent typing, the patterns may have different types. Hence, we first match against the pattern's
type before matching against the pattern itself, to ensure
that the types of the subject and pattern agree. Thus, we
must translate the computational language into one where
type annotations of the form (e : o/ ) are erased but all expressions of type A[\Psi ], in particular patterns in branches,
carry their corresponding type. We denote this translation
by |e| and |i| for checked and synthesizing expressions, respectively2.

2Technically, this erasure is type-directed and annotates also

Expression e checks against type o/

\Omega ; \Delta ; \Gamma ; f:o/ ` e ( o/
\Omega ; \Delta ; \Gamma  ` rec f:e ( o/ rec

\Omega ; :W ; \Delta ; \Gamma  ` e ( o/
\Omega ; \Delta ; \Gamma  ` \Lambda :e ( \Pi :W:o/ \Pi I

\Omega ; \Delta ; \Gamma ; y:o/1 ` e ( o/2
\Omega ; \Delta ; \Gamma  ` fn y:e ( o/1 ! o/2 !I

\Omega ; \Delta ; u::A[\Psi ]; \Gamma  ` e ( o/
\Omega ; \Delta ; \Gamma  ` *

2u: e ( \Pi 2u::A[\Psi ]:o/ \Pi 

2I \Omega ; \Delta ; \Psi  ` M ( A\Omega ; \Delta ; \Gamma  ` box( ^\Psi : M) ( A[\Psi ] box

\Omega ; \Delta ; \Gamma  ` i ) A[\Psi ] for all k \Omega ; \Delta ; \Gamma  ` bk (A[\Psi ] o/

\Omega ; \Delta ; \Gamma  ` case i of b1 | : : : | bn ( o/ case

\Delta ; \Gamma  ` i ) o/

0 \Omega ; \Delta  ` o/ 0 = o/

\Omega ; \Delta ; \Gamma  ` i ( o/ turn

Expression i synthesizes type o/

\Omega ; \Delta ; \Gamma  ` e ( o/
\Omega ; \Delta ; \Gamma  ` (e : o/ ) ) o/ anno

y:o/ 2 \Gamma 
\Omega ; \Delta ; \Gamma  ` y ) o/ var

\Omega ; \Delta ; \Gamma  ` i ) o/2 ! o/ \Omega ; \Delta ; \Gamma  ` e ( o/2

\Omega ; \Delta ; \Gamma  ` i e ) o/ !E

\Omega ; \Delta ; \Gamma  ` i ) \Pi :W:o/ \Omega ; \Delta  ` \Psi  ( W

\Omega ; \Delta ; \Gamma  ` i d\Psi e ) [[\Psi =]]o/ \Pi E

\Omega ; \Delta ; \Gamma  ` i ) \Pi 

2u::A[\Psi ]:o/ \Omega ; \Delta ; \Psi  ` M ( A

\Omega ; \Delta ; \Gamma  ` i d ^\Psi :Me ) [[ ^\Psi :M=u]]o/ \Pi 

2E

Body ek checks against type o/, assuming the value cased upon has type A[\Psi ]

\Omega ; \Delta k; \Psi k ` Mk ( Ak

\Omega ; \Delta ; \Delta k ` \Psi  := \Psi k=(`1; \Delta 

0)

\Omega ; \Delta 

0 ` [[`1]]A := [[`1]]Ak = (`2; \Delta 00)

\Omega ; \Delta 

00; [[`2]][[`1]]\Gamma  ` [[`2]][[`1]]ek ( [[`2]][[`1]]o/

\Omega ; \Delta ; \Gamma  ` \Pi \Delta k:box( ^\Psi : Mk) : Ak[\Psi k] 7! ek (A[\Psi ] o/

Figure 1: Computation-level typing rules
Otherwise, the semantics is straightforward. In function
application, values for program variables are propagated by
computation-level substitution. Instantiations for context
variables are propagated by applying a concrete context \Psi 
to a context abstraction \Lambda :e. Index arguments are propagated in (*

2u: e) d ^\Psi :Me by replacing u with the concrete

data object ^\Psi :M.

Evaluation in branches relies on higher-order pattern matching against data-level terms to instantiate the contextual
variables occurring in a branch. Data-level instantiations are
propagated via simultaneous contextual substitution. We
write box( ^\Psi : M):A[\Psi ] 6 := \Pi \Delta 1:box( ^\Psi : M1):A1[\Psi 1] to mean

that higher-order pattern matching between box( ^\Psi : M1) and
box( ^\Psi : M) failed, i.e. there exists no instantiation for the
contextual variables in \Delta 1 that makes these terms equal.

We assume that box(\Psi : M) does not contain any metavariables, i.e. it is closed, and that its type A[\Psi ] is known.
Because of dependent types in \Psi k we must first match \Psi 
against \Psi k, and then proceed to match M against Mk.

Before we prove type safety for our dependently-typed
functional language with higher-order abstract syntax, we
briefly discuss the issue of coverage. To prove progress, we
must validate that patterns in case expressions are exhaustive, i.e. that all possible cases are covered. In the first-order
setting this is typically straightforward. Given a datatype
nat of natural numbers with constructors Zero and Suc, the
set of patterns Z = {Zero; Suc u} covers the type nat. However, in the higher-order setting we have open terms that

the object ^\Psi :M in i d ^\Psi :Me with its corresponding type.This is necessary since contextual substitution is defined recursively on the structure of this type (see definition of con-textual substitution in the appendix). For conciseness we
omit this type here.

can depend on assumptions. Intuitively, given a type A[\Psi ]
we can generate a set of patterns by generating patterns
for type A and in addition elements from \Psi . To generate all possible elements covering \Psi , we must inspect its
shape. If \Psi  = ; x1:A1; : : : ; xn:An, then we generate cases
for x1; : : : ; xn along with a general parameter case, p[id].
For example, given a type nat[,x:nat] the set of patterns
Z = {p[id], x, Zero, Suc u[id]} covers all elements of
this type. For a detailed discussion of coverage for higherorder data of type A[\Psi ], see Dunfield and Pientka [6]. Here,
we simply assume that patterns cover all cases. First we
state and prove a canonical forms lemma.

Lemma 2 (Canonical Forms).
(1) If i is a value and *; *; * ` i ) o/ ! o/

0

then |i| = fn y:|e

0| and *; *; y:o/ ` e0 ( o/ 0.

(2) If i is a value and *; *; * ` i ) A[\Psi ] then

|i| = (box( ^\Psi : M) : A[\Psi ]) and *; *; * ` box( ^\Psi : M) ( A[\Psi ].

(3) If i is a value and *; *; * ` i ) \Pi 

2u::A[\Psi ]:o/

then |i| = *

2u: |e0| and *; u::A[\Psi ]; * ` e0 ( o/.

Proof. By induction on the typing derivation.
Theorem 4 (Preservation and Progress).
(1) If *; *; * ` e ( o/ and e coverage checks then either e

is a value or there exists e

0 such that |e| -! |e0| and

*; *; * ` e

0 ( o/.

(2) If *; *; * ` i ) o/ and i coverage checks then either i

is a value or there exists i

0 such that |i| -! |i0| and

*; *; * ` i

0 ) o/.

Proof. By induction on the given typing derivation, using Lemma 2, the obvious substitution properties, and coverage [6] as needed.

Evaluation of computations:

rec f:e -! [rec f:e=f]e (fn y:e) v -! [v=y]e (*

2u: e) d ^\Psi :Me -! [[ ^\Psi :M=u]]e

i1 -! i

01

i1 e2 -! i

01 e2

e2 -! e

02

v e2 -! v e

02 i -! i

0

i d\Psi e -! i

0 d\Psi e (\Lambda :e) d\Psi e -! [[\Psi =]]e i -! i

0

case i of bs -! case i

0 of bs

(box( ^\Psi : M):A[\Psi ]) 6 := (\Pi \Delta 1:box( ^\Psi : M1):A1[\Psi 1]) b = \Pi \Delta 1:box( ^\Psi : M1):A1[\Psi 1] 7! e1

(case (box( ^\Psi : M):A[\Psi ]) of b | bs) -! case (box( ^\Psi : M):A[\Psi ]) of bs

(box( ^\Psi : M):A[\Psi ]) := (\Pi \Delta :box( ^\Psi : M1):A1[\Psi 1]) = ` b = \Pi \Delta :box( ^\Psi : M1):A1[\Psi 1] 7! e1

(case (box( ^\Psi : M):A[\Psi ]) of b | bs) -! [[`]]e1

Evaluation of branch:

\Delta  ` \Psi k := \Psi  = (`1; \Delta 1) \Delta 1; \Psi  ` A := [[`1]]Ak = (`2; \Delta 2) ` = [[`2]]`1 \Delta 2; \Psi  ` M := [[`]]Mk = (`3; *)

(box( ^\Psi : M) : A[\Psi ] := \Pi \Delta :box( ^\Psi : Mk) : Ak[\Psi k]) = [[`3]]`

Figure 2: Operational semantics

5. RELATED WORK

Implementing proofs about HOAS encodings is an ambitious project. One approach is realized in Twelf [19], an
implementation of the logical framework LF where inductive
proofs are implemented as relations between derivations and
the fact that relations constitute total functions is verified
separately. While the logical framework LF itself is wellunderstood and has a small type-theoretic core, the external
checkers guaranteeing totality of the implemented relations
still remain mysterious to many users. Moreover, how to
automate induction proofs about LF signatures and develop
such proofs interactively has remained a major problem despite the seminal groundwork laid in Sch"urmann's dissertation [24]. An alternative approach to proving properties
about HOAS encodings is based on generic judgments [8]
and realized in the system Abella. This approach enhances
intuitionistic logic with generic judgments, which allow for
recursive definitions and induction over natural numbers.
Contexts are explicit, and the user needs to explicitly manage and prove properties about contexts. This is a powerful
approach grounded in proof theory. In contrast, we aim for
a type-theoretic approach for programming with proofs and
explicit contexts. In particular, we characterize contexts
type-theoretically using context schemas. A potential advantage of our approach is that we use the same functional
paradigm of writing programs and writing proofs, and hence
they can live within the same language.

Enriching functional programming with dependently-typed
higher-order data structures is a longstanding open problem and is presently receiving widespread attention. Most
closely related to our work is Delphin [23], a dependentlytyped functional programming language that supports HOAS
encodings. However, our theoretical approach differs substantially. Most of these differences arise because we build
our type-theoretical foundation on contextual modal types
where A[\Psi ] denotes an object M of type A in a context \Psi .
This means that the object M can refer to the variables declared in \Psi . Every data object is therefore locally closed.
Moreover, the context \Psi  is explicit. An important consequence is that, when pattern matching against data objects

of type A[\Psi ], it is easy to understand intuitively when all
cases are covered. A set of patterns is exhaustive if it contains all constructors of type A together with all the variables from \Psi . Furthermore, the power of context variables
allows us to capture more general invariants about our programs. In Delphin, contexts are implicit and there are no
context variables. This has several consequences. For example, the whole function and all its arguments are executed in
a global context. This is less precise and can express fewer
properties on individual data objects. Thus, one cannot express that the first argument of a function is closed, while
its second argument may not be (see the cntV example).

Despeyroux et al. [5] presented a type-theoretic foundation for programming with HOAS that supports primitive
recursion. To separate data from computation, they introduced modal types 2A that can be injected into computation. However, data is always closed and can only be analyzed by a primitive recursive iterator. Despeyroux and
Leleu [3, 4] extended this work to dependent types.

In recent years, various forms of dependent types have
found their way into mainstream functional programming
to allow programmers to express stronger properties about
their programs. Generalized algebraic datatypes [2, 16, 26]
can index types by other types and have entered mainstream
languages such as Haskell. The Dependent ML approach [29]
uses indexed types with a fixed set of constraint domains,
such as integers with linear inequalities, for which efficient
decision procedures exist. However, all these systems lack
the power to manipulate and analyze higher-order data.
Moreover, they do not support user-defined index domains.

Finally, there have been several proposals in the functional
programming community to allow full dependent types in
languages such as Cayenne [1] and Epigram [11]. Neither of
these supports HOAS encodings. Moreover, their approach
to allowing a user-defined index domain for dependent types
is quite different: types can be indexed with arbitrary computations. This is problematic since equality between two
types is not simple syntactic equality. Instead, one must first
evaluate index arguments. To ensure termination and hence
decidability of type checking, Cayenne imposes a heuristic,
while Epigram only allows index objects defined by wellfounded recursion. This approach violates the idea that type
checking should be independent of the operational semantics, and may be costly.

6. CONCLUSION

We have presented an intermediate language for programming with dependently-typed higher-order data. This paper extends the first author's simply-typed work [21] to the
dependently-typed setting and lays the foundation for programming with proofs. Our framework distinguishes between implicit data objects that occur in a dependent type
and explicit data objects that are recursively analyzed with
higher-order pattern matching. We have omitted first-class
substitutions from our presentation, a concept present in the
simply-typed framework [21], in order to concentrate on the
issues related to dependent types, but there is no inherent
difficulty in adding them.

When contexts are implicit, as in Twelf and Delphin, implicit world subsumption allows one to elegantly write structured proofs involving lemmas. In our work, we have explicit
contexts. We plan to explore an explicit notion of schema
subsumption, along with existential quantification over contexts, which should be even more flexible and expressive.

We are in the process of completing an implementation of
a type checker and interpreter for the internal language described in this paper. However, to make Beluga practical, we
plan to address two important questions in the near future.
First, we need to reconstruct implicit data objects occurring in computations and data. This follows similar ideas
as employed in Twelf [19]. Second, we aim to reconstruct
typing annotations at the branches of case expressions. In
the long term, we plan to consider the issue of termination
checking to ensure that the implemented functions actually
do correspond to inductive proofs.

References

[1] L. Augustsson. Cayenne--a language with dependent

types. In 3rd International Conference on Functional
Programming (ICFP '98), pages 239-250. ACM, 1998.

[2] J. Cheney and R. Hinze. First-class phantom types.

Technical Report CUCIS TR2003-1901, Cornell University, 2003.

[3] J. Despeyroux and P. Leleu. Recursion over objects of

functional type. Mathematical Structures in Computer
Science, 11(4):555-572, 2001.

[4] J. Despeyroux and P. Leleu. Primitive recursion for

higher order abstract syntax with dependent types. In
International Workshop on Intuitionistic Modal Logics
and Applications (IMLA), 1999.

[5] J. Despeyroux, F. Pfenning, and C. Sch"urmann. Primitive recursion for higher-order abstract syntax. In Proceedings of the Third International Conference on Typed
Lambda Calculus and Applications (TLCA'97), pages
147-163. Springer, 1997. Extended version available
as Technical Report CMU-CS-96-172, Carnegie Mellon
University.

[6] J. Dunfield and B. Pientka. Case analysis of higherorder data. In International Workshop on Logical
Frameworks and Meta-Languages: Theory and Practice

(LFMTP'08), Electronic Notes in Theoretical Computer Science (ENTCS). Elsevier, June 2008.

[7] M. Gabbay and A. Pitts. A new approach to abstract

syntax involving binders. In G. Longo, editor, Proceedings of the 14th Annual Symposium on Logic in Computer Science (LICS'99), pages 214-224. IEEE Computer Society Press, 1999.

[8] A. Gacek, D. Miller, and G. Nadathur. Combining

generic judgments with recursive definitions. In F. Pfenning, editor, 23rd Symposium on Logic in Computer
Science. IEEE Computer Society Press, 2008.

[9] R. Harper, F. Honsell, and G. Plotkin. A framework

for defining logics. Journal of the ACM, 40(1):143-184,
January 1993.

[10] D. R. Licata, N. Zeilberger, and R. Harper. Focusing

on binding and computation. In F. Pfenning, editor,
23rd Symposium on Logic in Computer Science. IEEE
Computer Society Press, 2008.

[11] C. McBride and J. McKinna. The view from the

left. Journal of Functional Programming, 14(1):69-111,
2004.

[12] A. McCreight and C. Sch"urmann. A meta-linear logical

framework. In 4th International Workshop on Logical
Frameworks and Meta-Languages (LFM'04), 2004.

[13] D. Miller. Unification of simply typed lambda-terms as

logic programming. In Eighth International Logic Programming Conference, pages 255-269, Paris, France,
June 1991. MIT Press.

[14] D. Miller. A logic programming language with lambdaabstraction, function variables, and simple unification.
Journal of Logic and Computation, 1(4):497-536, 1991.

[15] A. Nanevski, F. Pfenning, and B. Pientka. Contextual

modal type theory. ACM Transactions on Computational Logic, 9(3), 2008.

[16] S. Peyton Jones, D. Vytiniotis, S. Weirich, and

G. Washburn. Simple unification-based type inference
for GADTs. In 11th ACM SIGPLAN Int'l Conference
on Functional Programming (ICFP '06), pages 50-61,
Sept. 2006.

[17] F. Pfenning. Unification and anti-unification in the Calculus of Constructions. In Sixth Annual IEEE Symposium on Logic in Computer Science, pages 74-85, Amsterdam, The Netherlands, July 1991.

[18] F. Pfenning. Logical frameworks. In A. Robinson and

A. Voronkov, editors, Handbook of Automated Reasoning, pages 1063-1147. Elsevier, 2001.

[19] F. Pfenning and C. Sch"urmann. System description:

Twelf -- a meta-logical framework for deductive systems. In H. Ganzinger, editor, Proceedings of the
16th International Conference on Automated Deduction
(CADE-16), pages 202-206. Springer LNAI 1632, 1999.

[20] B. Pientka. Tabled higher-order logic programming.

PhD thesis, Department of Computer Science, Carnegie
Mellon University, 2003. CMU-CS-03-185.

[21] B. Pientka. A type-theoretic foundation for programming with higher-order abstract syntax and firstclass substitutions. In 35th Annual ACM SIGPLANSIGACT Symposium on Principles of Programming
Languages (POPL'08), pages 371-382. ACM, 2008.

[22] B. Pientka and F. Pfenning. Optimizing higher-order

pattern unification. In F. Baader, editor, 19th International Conference on Automated Deduction, Miami,
USA, Lecture Notes in Artificial Intelligence (LNAI)
2741, pages 473-487. Springer-Verlag, 2003.

[23] A. Poswolsky and C. Sch"urmann. Practical programming with higher-order encodings and dependent types.
In Proceedings of the 17th European Symposium on Programming (ESOP '08), Mar. 2008.

[24] C. Sch"urmann. Automating the Meta Theory of Deductive Systems. PhD thesis, Department of Computer
Science, Carnegie Mellon University, 2000. CMU-CS00-146.

[25] C. Sch"urmann, A. Poswolsky, and J. Sarnat. The rcalculus. Functional programming with higher-order encodings. In P. Urzyczyn, editor, Proceedings of the 7th
International Conference on Typed Lambda Calculi and
Applications (TLCA'05), volume 3461 of Lecture Notes
in Computer Science, pages 339-353. Springer, 2005.

[26] T. Sheard and E. Pasalic. Meta-programming with

built-in type equality. In Int'l Workshop on Logical Frameworks and Meta-languages (LFM '04), pages
106-124, 2004.

[27] M. R. Shinwell, A. M. Pitts, and M. J. Gabbay.

FreshML: programming with binders made simple. In
8th International Conference on Functional Programming (ICFP'03), pages 263-274, New York, NY, USA,
2003. ACM Press.

[28] K. Watkins, I. Cervesato, F. Pfenning, and D. Walker.

A concurrent logical framework I: Judgments and properties. Technical Report CMU-CS-02-101, Department
of Computer Science, Carnegie Mellon University, 2002.

[29] H. Xi and F. Pfenning. Dependent types in practical programming. In 26th ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages
(POPL'99), pages 214-227. ACM Press, 1999.

APPENDIXOrdinary substitution
In the definition for ordinary data-level substitutions, we
need to be careful because the only meaningful data-level
terms are those in canonical form. To ensure that substitution preserves canonical form, we use a technique pioneered
by Watkins et al. [28] and described in detail in Nanevski
et al. [15]. The idea is to define hereditary substitution as a
primitive recursive functional that always returns a canonical object.

In the formal development, it is simpler if we can stick
to non-dependent types. We therefore first define type approximations ff and an erasure operation ()

- that removes

dependencies. Before applying any hereditary substitution

Data-level normal terms
[M=x]nff(*y: N) = *y: N0 where N0 = [M=x]nff(N)

choosing y 62 FV(M), and y 6= x

[M=x]nff(M1; M2) = (N1; N2) if [M=x]nff(M1) = N1

and [M=x]nff(M2) = N2

[M=x]nff(R) = M0 if [M=x]rff(R) = M0 : ff0
[M=x]nff(R) = R0 if [M=x]rff(R) = R0
[M=x]nff(N) fails otherwise

Data-level neutral terms
[M=x]rff(x) = M : ff
[M=x]rff(y) = y if y 6= x
[M=x]rff(u[oe]) = u[oe0] where oe0 = [M=x]sff(oe)
[M=x]rff(p[oe]) = p[oe0] where oe0 = [M=x]sff(oe)
[M=x]rff(R N) = R0 N0 where R0 = [M=x]rff(R)

and N0 = [M=x]nff(N)
[M=x]rff(R N) = M00 : fi

if [M=x]rff(R) = *y: M0 :ff1 ! fi where
ff1 ! fi <= ff and N0 = [M=x]nff(N)
and M00 = [N0=y]nff1(M0)

[M=x]rff(proji R) = Ni : ffi if [M=x]rff(R) = (N1; N2):ff1*ff2

[M=x]rff(proji R) = proji R0 if [M=x]rff(R) = R0
[M=x]rff(R) fails otherwise

Data-level substitutions
[M=x]sff(*) = *
[M=x]sff(oe ; N) = (oe0 ; N0) where oe0 = [M=x]sff(oe)

and N0 = [M=x]nff(N)
[M=x]sff(oe ; R) = (oe0 ; R0) if [M=x]rff(R) = R0

and oe0 = [M=x]sff(oe)

[M=x]sff(oe ; R) = (oe0 ; M0) if [M=x]rff(R) = M0 : ff0

and oe0 = [M=x]sff(oe)[M=x]s
ff(id) = id[M=x]s
ff(oe) fails otherwise

Figure 3: Ordinary substitution

[M=x]aA(B) we first erase dependencies to obtain ff = A

-

and then carry out the hereditary substitution formally as
[M=x]aff(B). A similar convention applies to the other forms
of hereditary substitutions. Types relate to type approximations via an erasure operation ()

- which we overload to

work on types.

Type approximations ff; fi ::= a | ff ! fi | ff * fi

(a N1 : : : Nn)

- = a

(\Pi x:A : : : B)

- = A- ! B-

(\Sigma x:A : : : B)

- = A- * B-

We can define [M=x]nff(N), [M=x]rff(R), and [M=x]sff(oe) by
nested induction, first on the structure of the type approximation ff and second on the structure of the objects N, R
and oe. In other words, we either go to a smaller type approximation (in which case the objects can become larger),
or the type approximation remains the same and the objects become smaller. The following hereditary substitution
operations are defined in Figure 3.

[M=x]nff(N) = N

0 Normal terms N

[M=x]rff(R) = R

0 or M0 : ff0 Neutral terms R

[M=x]sff(oe) = oe

0 Substitutions oe

We write ff <= fi and ff < fi if ff occurs in fi (as a proper

subexpression in the latter case). If the original term is not
well-typed, a hereditary substitution, though terminating,
cannot always return a meaningful term. We formalize this
as failure to return a result. However, on well-typed terms,
hereditary substitution will always return well-typed terms.
This substitution operation can be extended to types for
which we write [M=x]aff(A).

Theorem 5 (Termination).
[M=x]

*ff( ) where * = {n; r; s; a} terminates, either by returning a result or failing after a finite number of steps.

Theorem 6 (Hereditary Substitution Principles).
If \Delta ; \Psi  ` M ( A and \Delta ; \Psi ; x:A; \Psi 

0 ` J then

\Delta ; \Psi ; [M=x]

*ff\Psi 0 ` [M=x]*ff(J) where * = {n; r; s; a}.

Building on Nanevski et al. [15], we can also define simultaneous substitution [oe]n_(M) (respectively [oe]r_(R) and

[oe]s_(oe)). We write _ for the context approximation of \Psi 
which is defined using the erasure operation ()

-.

(*)

- = *

()

- = 

(\Psi ; x:A)

- = (\Psi )-; x:(A)-

Substitution for contextual variables
Substitutions for contextual variables are a little more difficult. We have two kinds of contextual variables: metavariables u and parameter variables p [21].

Contextual substitution for meta-variables.

We define the contextual substitution operations for normal object, neutral objects and substitutions as follows.

[[ ^\Psi :M=u]]nff[ _](N) = N

0 Normal terms N

[[ ^\Psi :M=u]]rff[ _](R) = R

0 or M0 : ff0 Neutral terms R

[[ ^\Psi :M=u]]sff[ _](oe) = oe

0 Substitutions oe

As mentioned earlier, u[oe] represents a closure where, as
soon as we know which term u should stand for, we can apply
oe to it. Because of ff-conversion, the variables substituted
at different occurrences of u may differ, and we write ^\Psi :M
to allow for necessary ff-renaming. The contextual substitution is indexed with the type of u. This typing annotation
is necessary since we apply the substitution oe hereditarily
once we know which term u represents, and hereditary substitution requires the type to ensure termination.

We define the operations in Figure 4. Note that applying
[[ ^\Psi :M=u]]rff[ _] to the closure u[oe] first obtains the simultaneous substitution oe

0 = [[ ^\Psi :M=u]]s

ff[ _]oe, but instead of returning M[oe

0], it eagerly applies oe0 to M. However, before

that we recover its domain with [oe

0= _]. To ensure that we

always return a normal object as a result of contextual substitution, we resort to ordinary hereditary substitution. For
a thorough explanation, see Nanevski et al. [15].

Contextual substitution for parameter variables.

Contextual substitution for parameter variables (Figure 5)
follows similar principles, but substitutes an ordinary variable for a parameter variable. We write parameter substitutions as [[ ^\Psi :x=p]]

*

ff[ _], where * 2 {n; r; s; a}. When we encounter a parameter variable p[oe], we replace p with the

Data-level normal terms
[[ ^\Psi :M=u]]nff[ _](*y: N) = *y: N0 where [[ ^\Psi :M=u]]nff[ _]N = N0
[[ ^\Psi :M=u]]nff[ _](N1; N2) = (N01; N02)

where [[ ^\Psi :M=u]]nff[ _](N1) = N01 and [[ ^\Psi :M=u]]nff[ _](N2) = N02

[[ ^\Psi :M=u]]nff[ _](R) = R0 where [[ ^\Psi :M=u]]rff[ _](R) = R0
[[ ^\Psi :M=u]]nff[ _](R) = M0where [[ ^\Psi :M=u]]rff[ _](R) = M0 : fi
[[ ^\Psi :M=u]]nff[ _](N) fails otherwise

Data-level neutral terms
[[ ^\Psi :M=u]]rff[ _](x) = x
[[ ^\Psi :M=u]]rff[ _](u[oe]) = N : ff where [[ ^\Psi :M=u]]sff[ _]oe = oe0

and [oe0= _]n_M = N
[[ ^\Psi :M=u]]rff[ _](u0[oe]) = u0[oe0] where [[ ^\Psi :M=u]]sff[ _]oe = oe0

choosing u0 6= u

[[ ^\Psi :M=u]]rff[ _](p[oe]) = p[oe0] where [[ ^\Psi :M=u]]sff[ _]oe = oe0
[[ ^\Psi :M=u]]rff[ _](R N) = (R0 N0) where [[ ^\Psi :M=u]]rff[ _]R = R0

and [[ ^\Psi :M=u]]nff[ _](N) = N0
[[ ^\Psi :M=u]]rff[ _](R N) = M0 : ff2

if [[ ^\Psi :M=u]]rff[ _]R = *x: M0 : ff1 ! ff2 for ff1 ! ff2 <= ff[ _]

and [[ ^\Psi :M=u]]nff[ _](N) = N0 and [N0=x]nff1(M0) = M0

[[ ^\Psi :M=u]]rff[ _](projiR) = projiR0 if [[ ^\Psi :M=u]]rff[ _](R) = R0
[[ ^\Psi :M=u]]rff[ _](projiR) = Mi : ffi

if [[ ^\Psi :M=u]]rff[ _](R) = (M1; M2) : ff1 * ff2

[[ ^\Psi :M=u]]rff[ _](R) fails otherwise

Figure 4: Substitution for meta-variables
[[ ^\Psi :x=p]]rff[ _](p[oe]) = M : ff if [[ ^\Psi :x=p]]sff[ _]oe = oe0

and [oe0= _]r_x = M : ff

[[ ^\Psi :x=p]]rff[ _](p[oe]) = R if [[ ^\Psi :x=p]]sff[ _]oe = oe0

and [oe0= _]r_x = R

[[ ^\Psi :x=p]]rff[ _](p0[oe]) = p0[oe0] where [[ ^\Psi :x=p]]sff[ _]oe = oe0

Figure 5: Substitution for parameter variables

ordinary variable x and apply the substitution [[ ^\Psi :x=p]]sff[ _]
to oe obtaining a substitution oe

0. Instead of returning a

closure x[oe

0] as the final result we apply oe0 to the ordinary

variable x. This may again yield a normal term, so we must
ensure that contextual substitution for parameter variables
preserves normal forms.

Theorem 7 (Termination).
[[ ^\Psi :M=u]]

*

ff[_OE]( ) and [[ ^\Psi :x=p]]

*
ff[_OE]( ) where * 2 {n; r; s; a} ter-minate, either by returning a result or failing after a finite

number of steps.

Theorem 8 (Contextual Substitution Principles).

1. If \Delta 1; \Phi  ` M ( A and \Delta 1; u::A[\Phi ]; \Delta 2; \Psi  ` J then

\Delta 1; [[ ^\Psi :M=u]]

*

ff[_OE]\Delta 2; [[ ^\Psi :M=u]]

*
ff[_OE]\Psi  ` [[ ^\Psi :M=u]]

*
ff[_OE]J

where * = {n; r; s; a}.

2. If \Delta 1; \Phi  ` x ) A and \Delta 1; p::A[\Phi ]; \Delta 2; \Psi  ` J then

\Delta 1; [[ ^\Psi :x=p]]

*

ff[_OE]\Delta 2; [[ ^\Psi :x=p]]

*
ff[_OE]\Psi  ` [[ ^\Psi :x=p]]

*
ff[_OE]J

where * = {n; r; s; a}.