

The SLam Calculus: Programming with Secrecy and Integrity

Nevin Heintze
Bell Laboratories
Lucent Technologies
700 Mountain Avenue
Murray Hill, NJ 07974 USA

nch@bell-labs.com

Jon G. Riecke
Bell Laboratories
Lucent Technologies
700 Mountain Avenue
Murray Hill, NJ 07974 USA
riecke@bell-labs.com

Abstract
The SLam calculus is a typed l-calculus that maintains security in-formation as well as type information. The type system propagates
security information for each object in four forms: the object's cre-ators and readers, and the object's indirect creators and readers (i.e.,
those agents who, through flow-of-control or the actions of otheragents, can influence or be influenced by the content of the object).
We prove that the type system prevents security violations and givesome examples of its power.

1 Introduction
How do we build a system that manipulates and stores informa-tion whose secrecy and integrity must be preserved? The information might, for example, contain employee salaries, tax infor-mation or social security numbers, or it might involve data whose
integrity is essential to global system security, such as the UNIXTM
/etc/passwd file or a database of public keys.One solution is to provide a secure persistent store that controls

access to each location in the store, e.g., it might maintain accesscontrol lists that specify who may read and write each location.
This only addresses part of the problem: it does not trace the secu-rity of information through computation. For example, a privileged
user can write a program that reads a secret location and copies itscontents to a public location. Trust is central to the usability of this
system: if one user shares secrets with others, he or she must trusttheir intentions. He or she must also trust their competence, since
they may release secrets accidentally as a result of a programmingerror.

There is an alternative to a secure persistent store: we can as-sociate security with data objects instead of locations, and track
security through computation at runtime. To do this, each objectmust come equipped with security information that specifies access rights, i.e., a capability. However, this is not enough. Wemust also track the flow of information as we build new objects
from old. For example, if we have a secret string and concatenate itwith another string, then we must also treat the new string as secret.
Such a scheme has two problems. First, explicitly tracing securityinformation through computation is very expensive. Second, the
system must guarantee that security information is not forged.

We can address these two problems by annotating programswith information flow levels, and using a static analysis system that
rejects programs that might leak information. For example, we canview a program as a black box so that its output is at least as secret as each of its inputs. Similarly, we can view program output ashaving no higher integrity than each of its inputs.

This approach of tracing information flow has been thoroughlyexplored in the security literature [3, 4, 6, 7, 8]. Unfortunately, in
classic information flow systems, data quickly floats to the high-est level of security. For example, consider a program that takes
as input a string x representing a user id and another string y rep-resenting the user's password, and whose output is some object

zbuilt from
x and y. Then the security level of the entire object
z must be the security level appropriate for user passwords, eventhough the password information may be only a small component

of z.In this paper, we show that a programming language can provide finer grained control of security. The vehicle of study is a corefunctional programming language called the Secure Lambda Calculus (or SLam calculus). We focus on the role of strong statictyping. We assume that all programs are compiled with a trusted
compiler that enforces our type discipline, i.e., there are no "back-doors" for inserting and executing unchecked code and there are
no operations for direct access and modification of raw memorylocations.

The types of the SLam calculus mingle security informationwith type information. This feature allows more accurate and flexible security information, in that we can attach different levels ofsecurity to the different components of an object. For instance, in
the /etc/passwd list, password hashes might come with highersecurity than other components of the records. The security information takes four forms: readers, creators, indirect readers andindirect creators. Intuitively, an agent must be a reader of an object
in order to inspect the object's contents. An agent is a creator of anyobject it constructs. An agent is an indirect reader of an object if it
may be influenced by the object's contents. An agent is an indirectcreator of an object if it may influence the object's construction.
For example, consider the statement

if (x > 25) then y:=1 else y:=2
Here, partial information about x is available via variable y. Ifagent A can read

y but not x, then A can still find out partial infor-mation about
x and so A is an indirect reader of x. If the statementitself were executed by agent B, then B would require read access

to x. B would also be a creator of y's content. Moreover, if x wascreated by a third agent C, then C would be an indirect creator of
y's content.Readers and indirect readers together specify an object's secrecy (who finds out about the object), whereas creators and indirect creators specify integrity (who is responsible for the object).Readers and creators together capture access control, while indirect
readers and indirect creators capture information flow. In conjunc-tion with higher-order functions and a rich underlying type structure (e.g., records, sums), these four security forms provide a flexi-ble basis for controlled sharing and distribution of information. For
example, higher-order functions can be used to build up complexcapabilities. In our system, the ability to read a function is the right
to apply it. By specifying the set of readers and/or indirect readersof these functions, we can additionally restrict the capability so that
it can only be shared by a specified group of agents.Incorporating both access control and information flow in the
type system adds flexibility. To illustrate the utility of having both,suppose we have just two security levels,

H (high security) and L(low security), and a type called
users that is a list containingstrings whose direct readers are
H, and whose indirect readers are
L. If we ignore direct and indirect creators, and write direct read-ers before indirect readers, the type definition (in a ML-style syntax [11]) might look like

type users = (list (string,(H,L)),(L,L))
Now suppose we want to look up names in a value of type users,and return

true if the name is in the list. We might write the codeas follows:

fun lookup ([]:users) name =

false:(bool,(L,L))
| lookup ((x::tail):users) name =

if x = name

then true:(bool,(L,L))
else lookup tail name

Our type system guarantees that only high-security agents can writethe

lookup function, or indeed any code that branches on thevalues of the strings in the list. Low-security agents can call the

lookup function, but cannot get direct access to the strings heldin the list. Information flows from the strings into the boolean output, but since we have labeled the indirect readers of the strings tobe low security, the program is type correct.

Direct readers determine how much of an object is revealedto indirect readers. (Of course, no one can reveal information to
agents who are not indirect readers.) At one extreme, a direct readercan reveal everything about an object to the indirect readers. If an
agent is an indirect reader of an object but not a direct reader, thenany information that agent finds out about that object must be via a
direct reader.To simplify the presentation, we describe the SLam calculus
in stages. In Section 2, we define the purely functional core of theSLam calculus, restricting the security properties to direct and indirect readers. The operational semantics explicitly checks for secu-rity errors. We prove a type soundness result: well-typed programs
never cause security errors, and hence the run-time security checksmay be omitted. We also prove a "noninterference" theorem for
indirect readers and creators. Borrowing ideas from Reynolds [18],we prove the noninterference theorem using denotational semantics and logical relations. This style of proof, while common inthe languages literature, is novel to the security world. We believe
the proof technique carries over to the extensions of the basic cal-culus. Sections 3 and 4 extend the core calculus with assignments
(using an effects-style extension to the type system [20]), concur-rency, and integrity. Sections 5 and 6 conclude the paper with a
discussion of other work and limitations of the system.

2 The Purely Functional SLam Calculus
We illustrate the core ideas of our calculus using a language withfunctions, recursion, tuples, and sums, restricting the security properties to direct and indirect readers. We extend our treatment to a

language with assignment and concurrency in Section 3, and to cre-ators and indirect creators in Section 4.
2.1 Types and terms
The types of the SLam calculus essentially comprise those of amonomorphic type system--with products, sums, and functions--

in which each type is annotated with security properties. (We couldadd other primitive types such as booleans, integers and strings--
and will do so in examples--but the essential typing properties arealready covered by sums and products.) Define security properties
k, types t, and secure types s by the grammar

k ::= (r;ir)

t ::= unit j (s + s) j (s \Theta  s) j (s ! s)
s ::= (t;k)

where r (readers) and ir (indirect readers) range over some collec-tion S of basic security descriptions with ordering

v, and securityproperties
(r;ir) satisfy ir v r. In other words, r should be morerestrictive (it represents a smaller set of agents) than ir. We assume

(S;v) is a lattice (i.e., a partially ordered set with meets, joins, atop element

? and bottom element ?). Higher in the lattice means"more secure";

? is the most secure element. Intuitively, each ele-ment of S represents a set of agents or users; for this reason we refer

to elements of S as security groups. For example, a simple multi-level security system might have security descriptions L (low), M
(medium) and H (high), with ordering L v M v H, where L = ?and H

= ?. Alternatively, a UNIX-like security system could bebuilt from a lattice S of sets of users ordered by superset.

For the purposes of presenting our static type system, we as-sume that S is static. This assumption is unrealistic in practice: new
users can be added to a system, or users may have their privilegesrevoked. We briefly discuss this issue in Section 6.

The SLam calculus is a call-by-value language, and hence termscontain a set of values that represent terminated computations. The
sets of basic values and values are defined by the grammar

bv ::= () j (inji v) j hv;vi j (lx : s: e)

v ::= bvk

The security properties on values describe which agents may readthe object, and which agents may indirectly depend on the value.
The terms of the SLam calculus are given by the grammar

e ::= x j v j (inji e)k j he;eik j (e e)r j (proji e)r j

(protectir e) j (u f : s: e) j
(case e of inj1(x): e j inj2(x): e)r

The term (u f : s: e) defines a recursive function, and (protectir e)increases the security property of a term. Bound and free variables
are defined in the usual way: variables may be bound by l, u, and
case.Notice that the destructors--application, projection, and case--

come labeled with a security group r. This group represents thesecurity group of the programmer of that code. The annotations
appear on terms for entirely technical reasons: with the operationalsemantics given in the next section, terms with mixed annotations
arise when code written by different programmers gets mixed to-gether. For example,

root can write a function

f = (lx : (t;(?;?)): body with root annotations)(?;?):
that can be run by anyone; once called, the function's body accessesfiles and data structures as

root, i.e., has "setuid" behavior. Anyuser can write an application

( f v)r, because ? v r, but the body

can access data that r cannot access. Mixed annotations arise whensuch applications are reduced: when v is substituted for x in body,
the result might contain r and root annotations.A compiler for the SLam calculus must check that the annotations on programs are consistent with the programmer's security.For example, the compiler must prevent arbitrary users from writing programs with destructors annotated with root.

2.2 Operational semantics
The relation e ! e0 represents a single atomic action taken by anagent. The definition uses structured operational semantics [16] via

evaluation contexts [9]. The set of evaluation contexts is given by

E ::= [\Delta ] j (E e)r j (v E)r j (proji E)r j (inji E)k j

hE;eik j hv;Eik j (protectir E) j
(case E of inj1(x): e1 j inj2(x): e2)r

This defines a left-to-right, call-by-value, deterministic reductionstrategy.

The basic rules for the operational semantics appear in Table 1.These rules reduce simple redexes. They lift to arbitrary terms via

e ! e0E
[e] ! E[e0]

In the rules of Table 1, we use an operation for increasing the secu-rity properties on terms: given k

= (r;ir), the expression k ffl ir0 isthe security property
(r t ir0;ir t ir0). Abusing notation, we extendthis operation to values: bv

k ffl ir denotes the value bvkfflir.Note that the operational semantics is essentially untyped: the

types on bound variables, upon which the type checking rules ofthe next section depend, are ignored during reduction. The security
properties on values and destructors are, of course, checked duringreduction; this corresponds to checking, for instance, that the argument to a projection is a pair and not, say, a function abstraction.To see how programs can get stuck at security errors, suppose the
security lattice has two elements L and H, with L ^ H. Let

bool = (unit;(L;L)) + (unit;(L;L))
truek = (inj1 ()(L

;L))k : (bool;k)false

k = (inj2 ()(L;L))k : (bool;k)

and let (if e1 then e2 else e3)r abbreviate the term

(case e1 of inj1(x): e2 j inj2(x): e3)r
where x is a variable not occurring in e2 or e3. Then the term

(if true(H

;H) then true(L;L) else false(L;L))L

cannot be reduced: the programmer of the if-then-else code doesnot have the permissions to branch on the high-security boolean.

After a value has been destructed, the indirect readers of thevalue are used to increase the secrecy of the result (via

protect).This tracks information flow from the destructed value to the result.

For instance, if L is changed to H on the if-then-else statement inthe above example, then the following reductions are permitted:

(if true(H

;H) then true(L;L) else false(L;L))H! (protect

H true(L;L))
! true(H

;H)

This tracks the flow of information from the test to the result. Wecould also change the indirect reader annotation on the boolean test:

(if true(H;L) then true(L;L) else false(L;L))H

! (protectL true(L;L))
! true(L;L)

In this case, only a high-security direct reader can test the boolean,but information about the test is revealed to low-security agents.

2.3 Type system
The type system of the SLam calculus appears in Tables 2 and 3.The system includes subtyping and the subsumption rule. The subtyping rules in Table 2 start from lifting the v relation on securitygroups to the

^ relation on security properties. Define

(r;ir) ^ (r0;ir0) iff r v r0;ir v ir0:
The subtyping rules formalize the idea that one may always in-crease the security property of a value.

The typing rules appear in Table 3. We use \Gamma  to denote typingcontexts, i.e., finite partial maps from variables to secure types, and
/0 to denote the empty context. Abusing notation, we write (t;k)fflirto denote the secure type

(t;k ffl ir). The rules for type-checkingconstructors are straightforward. For type-checking destructors, the

rules guarantee that the destructor has the permission to destruct thevalue (apply a function, project from a pair, or branch on a sum).
For instance, recall the term

(if true(H;H) then true(L;L) else false(L;L))L
from the previous section which could not be reduced by the oper-ational semantics. This term cannot be typed with our rules. The
type rules track information flow in a manner analogous to the op-erational semantics. For instance, the type of the term

(if true(H

;H) then true(L;L) else false(L;L))H

from the previous section is (bool;(H;H)).The type system satisfies Subject Reduction and Progress (see

Appendix for proofs).
Theorem 2.1 (Subject Reduction) Suppose /0 ` e : s and e ! e0.Then /0

` e0 : s.

Theorem 2.2 (Progress) Suppose /0 ` e : s and e is not a value.Then there is a reduction e

! e0.

These theorems show that, for well-typed, closed expressions, thesecurity checks in the operational semantics are redundant.

It follows from subject reduction and progress that our type sys-tem enforces reader security. Consider an object O created with
reader annotation r. We wish to establish that, for well-typed pro-grams, the only agents who can read this object are those specified
by r. Now, consider the operational semantics. By inspection, theoperational semantics ensures two properties of reader annotations:

ffl Once an object is created, the only way for its reader an-notation to change is via

protect, but this only increasessecurity, i.e., sets more restrictive access to the object.

ffl If an agent attempts to read an object and the current readerannotation does not allow the agent to perform the read, then

the operational semantics will "get stuck."
Hence, the operational semantics ensures that if an agent not spec-ified by r (the initial annotation on O) ever attempts to read O, then

reduction will get stuck. But subject reduction and progress showthat well-typed programs never get stuck. It follows that our type
system enforces reader security.A similar kind of argument could be used to show that our type
system enforces indirect reader security. Such an argument wouldrely upon the following claim: if an agent not specified by ir (the
initial indirect reader annotation on O) ever attempts to find outinformation about O, then reduction will get stuck. While the operational semantics contains information-flow aspects, the claim iscertainly not self-evident by inspection of the reduction rules (as
was the case for (direct) readers).

Table 1: Operational Semantics.
((lx : s:e)r;ir v)r0 ! (protectir e[v=x]) if r v r0
(proji hv1;v2i(r

;ir))r0 ! (protectir vi) if r v r

0

(case (inji v)(r;ir) of inj1(x): e1 j inj2(x): e2)r0 ! (protectir ei[v=x]) if r v r0
(u f : s:e) ! e[(lx : s1:((u f : s: e) x)r)(r;ir)= f ] if s = (s1 ! s2;(r;ir))
(protectir v) ! vffl ir

Table 2: Subtyping Rules for Pure Functional Language.
s1 ^ s2 s2 ^ s3s

1 ^ s3

k ^ k0
(unit;k) ^ (unit;k0)

k ^ k0 s1 ^ s01 s2 ^ s02
((s1 + s2);k) ^ ((s01 + s02);k0) k

^ k0 s1 ^ s01 s2 ^ s02
((s1 \Theta  s2);k) ^ ((s01 \Theta  s02);k0)

k ^ k0 s01 ^ s1 s2 ^ s02
((s1 ! s2);k) ^ ((s01 ! s02);k0)

Table 3: Typing Rules for Pure Functional Language.
[Var] \Gamma ;x : s ` x : s [Unit] \Gamma  ` ()k : (unit;k)
[Sub] \Gamma  ` e : s s ^ s

0

\Gamma  ` e : s0 [Rec] \Gamma 

; f : s ` e : s\Gamma 
` (u f : s: e) : s s is a function type

[Lam] \Gamma ;x : s1 ` e : s2\Gamma  ` (lx : s1: e)k : (s1 ! s2;k) [App] \Gamma  ` e : (s1 ! s2;(r;ir)) \Gamma  ` e

0 : s1

\Gamma  ` (e e0)r0 : s2 ffl ir r v r

0

[Pair] \Gamma  ` e1 : s1 \Gamma  ` e2 : s2\Gamma  ` he1;e2ik : (s1 \Theta  s2;k) [Proj] \Gamma  ` e : (s1 \Theta  s2;(r;ir))\Gamma  ` (proji e)r

0 : si ffl ir r v r

0

[Inj] \Gamma  ` e : si\Gamma  ` (inji e)k : (s1 + s2;k) [Protect] \Gamma  ` e : s\Gamma  ` (protectir e) : s ffl ir

[Case] \Gamma  ` e : (s1 + s2;(r;ir)) \Gamma ;x : s1 ` e1 : s \Gamma ;x : s2 ` e2 : s\Gamma  ` (case e of inj1(x): e1 j inj2(x): e2)r

0 : s ffl ir r v r

0

Instead, we employ a more direct argument of indirect readersecurity. We show that if x is a high security variable (with respect
to indirect readers) and e is a low security expression that containsx, then no matter what value we give to x, the resulting evaluation
of e does not change (assuming it terminates). More generally, weshow that if an expression e of low security has a high security subexpression, then we can arbitrarily change the high security sub-expression without changing the value of e. This property, called
"noninterference" in the security literature, states that high securitysubexpressions cannot interfere with low security contexts.

The statement of noninterference for the SLam calculus re-quires two technical conditions, both of which arise from the fact
that the only base type in the language is the trivial type unit.First, since the language contains function expressions--which cannot be checked meaningfully for equality--the theorem only con-siders terms of ground types, i.e., those types containing only
unit, sums, and products. For instance, (bool;k) is a groundtype but

((bool;k) ! (bool;k);k) is not. Second, values con-structed from

unit, sums, and products may contain componentswith different security annotations. For example, consider

((bool;(H;H)) \Theta  (bool;(H;H));(L;L)):
Clearly it is acceptable for the high security components of a valueto depend on a high security variable x; however it is not acceptable for the low security components to depend on high securityx. To simplify the statement of non-interference, we further restrict attention to transparent types whose security properties donot increase as we descend into the type structure (a formal definition of transparent types appears in the Appendix). For instance,the above type is not transparent, but the type

((bool;(L;L)) +
(bool;(L;L));(H;H)) is transparent.To formally state the noninterference property, we use contexts:

C[\Delta ] denotes a context (expression with a hole in it); C[e] denotes theexpression obtained by filling context C

[\Delta ] with expression e. Wealso define a special equivalence relation to factor out termination

issues: e ' e0 if whenever both expressions halt at values, the values(when stripped of security information) are identical.

Theorem 2.3 (Noninterference) Suppose /0 ` e;e0 : (t;(r;ir)) and/0

` C[e] : (t0;(r0;ir0)), t0 is a transparent ground type and ir 6v ir0.Then C

[e] ' C[e0].

For simplicity, we have restricted this theorem to closed terms e; itcan be generalized to open terms. The proof uses a denotational semantics of the language and a logical-relations-style argument; theAppendix gives a sketch. The proof is particularly simple, especially when compared with other proofs based on direct reasoningwith the operational semantics (cf. [23]). The proof method can
also be extended to more complicated type systems, including oneswith recursive types (see [15] for the necessary foundations).

Notice that Noninterference Theorem requires both expressionsto halt. This reveals a problem with the type system: it is vulnerable to timing attacks, i.e., it does not protect the execution time ofcomputations and termination/nontermination properties. For example, suppose we have an external observer who can simply testwhether a program has terminated. Then we could write

let fun haltIfTrue x:(bool,(H,H)) =

if x then ():(unit,(H,H))

else haltIfTrue x
in haltIfTrue secretBool;

true:(bool,(L,L))
end

(taking some liberties with syntax) and the observer could discoverpartial information about the value of

secretBool. The problemis worse if the observer has a timer. For example, consider the term

let fun i = if (i = 0) then ()

else f(i-1)
in f secretValue:(int,(H,H))
end

in an extension of the SLam calculus with an integer base type. Anobserver can get some information about

secretValue simplyby timing the computation. If we add a
getTime primitive to thecalculus, this covert channel becomes observable and usable in the

calculus; we can then write

let val t1 : (int,(L,L)) = getTime()

val tmp = if secureBool:(bool,(H,H))

then longComp
else shortComp
val t2 : (int,(L,L)) = getTime()
val insecureBool : (bool,(L,L)) =

((t2 - t1) > timeForShortComp)
in insecureBool
end

where longComp is some computation that takes longer than acomputation

shortComp. Here the contents of secureBoolare leaked to

insecureBool. The vulnerability here is depen-dent on the accuracy of the

getTime primitive, latency issues andscheduling properties, and can be controlled by restricting access

to primitives such as getTime and restricting the ability of exter-nal observers. Depending on the nature of the secret information,
however, even a very low-rate covert channel can be disastrous,e.g., a DES key can be leaked in about a minute over a 1 bit/second
channel.We remark that our type system could be modified to reduce
exposure to timing attacks. The critical rule is the case rule: ourcurrent rule ensures that if the expression tested by the case statement has high security, then any value produced by either arm ofthe case statement must have high (indirect) security. To address
timing attacks, we need to protect not just values returned by thearms of the case statement, but also values returned by all future
computation. One approach is to introduce a notion of "the cur-rent security context of the computation", and propagate this in the
rules of the type system. The type system described in the nextsection employs this idea. Another approach is to force both of a
case statement to take the same time an space resources by addingtimeout mechanisms and various padding operations. Still another
approach may be found in [19, 21], which in our system would es-sentially correspond to restricting case statements so that the test
expression of the case statement has low (?) security.

3 Assignment and Concurrency
The calculus in the previous section is single threaded and side-effect free. This is inadequate to model the behavior of a collection
of agents that execute concurrently and interact, e.g., via a sharedstore or file system. To model such a system, we extend the basic
calculus with assignment (via ML-style reference cells), generalizeevaluation to a multi-process setting, and add a "spawn" operation
to create new processes.The type system of a language with concurrency and side effects must be carefully designed: a na"ive adaptation of the purelyfunctional system is not sufficient. In fact, problems even arise
with side effects alone. The problem lies in the sequencing of ex-pressions (sequencing

(M;N) in the calculus can be programmedas
((ld : s: N) M)?, where d is a fresh "dummy" variable). Unlikethe purely functional case, where the sequencing of two expressions communicates only termination behavior across the bound-ary, the sequencing of side-effecting expressions can communicate
data. Consider, for instance, the term

Figure 1: Leakage of information in the concurrency setting.
P1: let fun loop1() =

if secretBool

orelse (!killFlag)
then ()
else loop1()
in loop1();

if not(!killFlag)

then insecureBool := true
else ();
killFlag := true
end

P2: let fun loop2() =

if not(secretBool)

orelse (!killFlag)
then ()
else loop2()
in loop2();

if not(!killFlag)

then insecureBool := false
else ();
killFlag := true
end

if secretBool:(bool,(H,H))

then insecureBool:= true:(bool,(L,L));

secretBool
else insecureBool:= false:(bool,(L,L));

secretBool

Assuming the if is of high security, the type of the expression isa high-security boolean. Nevertheless, the side effect has leaked

out the value of secretBool. The operational semantics and thetype system must therefore track such information flow from the
destruction of values to side effects.Concurrency raises other, more difficult issues. It is well documented that the notion of noninterference itself is problematic in aconcurrent setting (see, e.g., [10]). To recap the problem, consider
a system with three agents A, B and C, and suppose that there issome variable

x that contains information that should be kept se-cret from agent C. The first agent, A, generates a random number,

and puts it into a variable tmp that everyone can read. Agent Bwaits for some time and then copies the contents of

x into tmp.Agent C reads
tmp and immediately terminates. Although C can-not tell that it has captured the contents of

x or some random value,information about
x has been leaked. If this interaction is repeated,then C can determine

x to a high degree of certainty. However, ifwe use a standard set-of-behaviors semantics for this system, then

we find that the set of behaviors of C (in particular, the values Cgenerates) is independent of the initial value of

x. Hence, if a stan-dard concurrency semantics is employed, we might conclude that

the system is secure.A second issue is closely related to the issue of timing attacks
discussed in the previous section. In that section, we justified ignor-ing timing attacks by viewing them as external to the system (we
excluded getTime from that calculus). In a concurrent setting,however, ignoring timing attacks can cause serious security holes,
because, in a calculus with concurrent communicating processes,the ability to "time" other processes is implicit. To see this, it is
helpful to consider a version of the main example from [19]. In theexample, we run complementary versions of the looping example
from Section 2.3 in parallel, one of which loops if a secret is true,and the other loops if the secret is false. If the first loop terminates,
the process leaks true, and if the second terminates, the processleaks

false. We can even force the entire system to terminateby killing both processes if either loop terminates. Specifically, we

can write processes P1 and P2 in Figure 1 (using a syntax similar tothat of Standard ML [11]), where the global variable

killFlagis initially
false. The value insecureBool is ready when
killFlag becomes true. To summarize, timing-style attacks in aconcurrent setting are part of the system: it does not seem reasonable to analyze the security of a concurrent setting without takingthem into account.1

1In fact, while the attack detailed above is clearly a generalization of the notion

3.1 Types and terms
To construct the enhanced language, we first extend the definitionof basic values bv and expressions e by

bv ::= ls j :::

e ::= (refs e)k j (e := e)r j (!e)r j (spawnir e)k j :::

where ls is a location (we assume an infinite sequence of locationsat each type s; whenever a new location is needed, we use the next

available location in the sequence). We modify the definition oftypes t to include reference types and change arrow types so that
they carry a latent "effect" ir, representing a lower bound on thesecurity of cells that may be written when the function is executed:

k ::= (r;ir)

t ::= unit j (s + s) j (s \Theta  s) j (s ir\Gamma ! s) j (ref s)

3.2 Operational semantics
The operational semantics of the enhanced language uses the samebasic style as for the purely functional case, with rewrite rules for

redexes and evaluation contexts to denote the position of redexes.The notion of evaluation contexts is a simple extension of the previous definition:

E ::= (refs E)k j (E := e)r j (v := E)r j (!E)r j :::
The semantics must now keep track of three new pieces of in-formation. First, since there are multiple processes and not a single

term, we must keep track of the current form of each process. Thus,the configuration of the system contains a list of processes. Second,
each process must keep track of the security levels of previouslydestructed values, so that side effects can be appropriately coerced.
For instance, in reducing the term

if secretBool:(bool,(H,H))

then insecureBool:= true:(bool,(L,L));

secretBool
else insecureBool:= false:(bool,(L,L));

secretBool

the rules will track the information flow H from secretBool tothe values stored in the reference cell

insecureBool. Third, thesemantics must keep track of the values of the locations via a state,

a finite partial function from typed locations ls to values.The basic rewrite rules for the enhanced language are found in
Table 4. Specifically, the rules defines a reduction relation

((ir1;e1);:::;(irn;en);s) ) ((ir01;e01);:::;(ir0n+k;e0n+k);s0)
of timing attack in the sequential setting, it is not clear the phrase "timing attack" isappropriate.

Table 4: Operational Semantics for Effects.
(ir0;((lx : s: e)r;ir v)r0 ) ! (ir t ir0;(protectir e[v=x])) if r v r0
(ir0;(proji hv1;v2ir

;ir)r

0 ) ! (ir t ir0;(protectir vi)) if r v r0

(ir0;(case (inji v)r;ir of inj1(x): e1 j inj2(x): e2)r0) ! (ir t ir0;(protectir ei[v=x])) if r v r0
(ir0;(protectir v)) ! (ir0;v ffl ir)

(ir;e) ! (ir0;e0)
(:::;(ir;E[e]);:::;s) ) (:::;(ir0;E[e0]);:::;s)

(:::;(ir0;E[(spawnir e)k]);:::;s) ) (:::;(ir t ir0;e);(ir0;E[()k]);:::;s)
(:::;(ir0;E[(refs v)k]);:::;s) ) (:::;(ir0;E[lsk]);:::;s[ls 7! v ffl ir0]) if ls 62 dom(s)
(:::;(ir0;E[(ls(r

;ir) := v)r

0 ]);:::;s) ) (:::;(ir0;E[v]);:::;s[ls 7! v ffl ir0]) if r v r0

(:::;(ir0;E[(!ls(r

;ir))r

0 ]);:::;s) ) (:::;(ir0;E[s(ls) ffl ir]);::: ;s) if r v r0

Table 5: Typing Rules for Effects.
[Sub] \Gamma  `ir e : s s ^ s

0

\Gamma  `ir e : s0

[Var] \Gamma ;x : s `ir x : s
[Unit] \Gamma  `ir ()k : (unit;k)

[Lam] \Gamma ;x : s1 `ir

0 e : s2

\Gamma  `ir (lx : s1: e)k : (s1 ir

0\Gamma ! s2;k)

[Pair] \Gamma  `ir e1 : s1 \Gamma  `ir e2 : s2\Gamma  `ir he1;e2ik : (s1 \Theta  s2;k)
[Inj] \Gamma  `ir e : si\Gamma  `ir (inji e)k : (s1 + s2;k)
[App] \Gamma  `ir

0 e : (s1 ir

0\Gamma ! s2;(r;ir)) \Gamma  `ir

0 e0 : s1\Gamma 

`ir0 (e e0)r0 : s2 ffl ir r v r

0; ir v ir0

[Proj] \Gamma  `ir

0 e : (s1 \Theta  s2;(r;ir))\Gamma 

`ir0 (proji e)r0 : si ffl ir r v r

0; ir v ir0

[Case] \Gamma  `ir

0 e : (s1 + s2;(r;ir)) \Gamma ;x : s1 `ir0 e1 : s \Gamma ;x : s2 `ir0 e2 : s\Gamma 

`ir0 (case e of inj1(x): e1 j inj2(x): e2)r0 : s ffl ir r v r

0; ir v ir0

[Protect] \Gamma  `ir

0 e : s\Gamma 

`ir0 (protectir e) : s ffl ir r v r

0; ir v ir0

[Spawn] \Gamma  `ir e : s\Gamma  `ir

0 (spawnir e)k : (unit;k) ir

0 v ir

[Loc] \Gamma  `ir0 lsk : (ref s;k)
[Ref] \Gamma  `ir

0 e : s\Gamma 

`ir0 (refs e)k : (ref s;k) (s ffl ir

0) = s

[Assign] \Gamma  `ir

0 e1 : (ref s;(r;ir)) \Gamma  `ir0 e2 : s\Gamma 

`ir0 (e1 := e2)r0 : s r v r

0; (s ffl ir0) = s

[Deref] \Gamma  `ir

0 e : (ref s;(r;ir))\Gamma 

`ir0 (!e)r0 : s ffl ir r v r

0

where s;s0 are states. The first four rules define the relation !, re-ductions for purely functional redexes. These reductions are lifted
to general configurations of the form ((ir1;e1);:::;(irn;en);s) withevaluation contexts. The rules for assignments, dereferencing, and
process creation are non-local rules that are specified directly onconfigurations.

3.3 Type system
Subtyping in the system with effects is exactly the same as before,except that the rule for function types now becomes

k ^ k0 s01 ^ s1 s2 ^ s02
((s1 ir\Gamma ! s2);k) ^ ((s01 ir\Gamma ! s02);k0)

and the rule for reference types is

k ^ k0
(ref s;k) ^ (ref s;k0)

Note that subtyping on reference types only affects top-level secu-rity properties, i.e., subtyping is invariant on reference types. This
restriction follows the standard subtyping rule for references [5,23].

Table 5 presents the typing rules for the extended calculus. Thistype system is essentially the previous system with an effect system
layered over the top of it in the style of [20]. This effect systemtracks potential information leakage/dependency that may be introduced by reference cells. Each context carries with it a securitygroup ir that is a lower bound on the security of the reference cells
that may be written in that context; as expected, this security groupis carried over onto arrow types. Only

spawn terms may changethe security context, and only then by increasing the context.

Analogs of the Subject Reduction Theorem 2.1 and ProgressTheorem 2.2 can be established for this system; the proofs are quite
similar to the proofs in the Appendix.
Theorem 3.1 (Subject Reduction) Suppose s is well-typed. Sup-pose that for all i, /0

`iri ei : si, and

((ir1;e1);:::;(irn;en);s) ) ((ir01;e01);:::;(ir0n+k;e0n+k);s0):
Then

ffl s0 is well-typed;
ffl For all 1 ^ i ^ n, /0 `ir0i e0i : si; and

ffl For all i * (n + 1), there is an si such that /0 `ir0i e0i : si.
Theorem 3.2 (Progress) Suppose s is well-typed. Suppose thatfor all i, /0

`iri ei : si, and ((ir1;e1);:::;(irn;en);s). If ei is not avalue, then there is a reduction

((ir1;e1);:::;(irn;en);s) ) ((ir01;e01);:::;(ir0n+k;e0n+k);s0):
We have not proved a noninterference theorem for the concurrentsetting because, as mentioned earlier, the notion is unclear in the
concurrency setting. Noninterference should, at the very least, guar-antee that the set of possible values of low-security objects is independent of the initial values of high-security objects.We might, however, expect more from a proof of noninterference. Ideally, we would like to rule out timing attacks: low-security observers should not be able to get and use information
about the values of high-security objects through watching termi-nation/nontermination or the timing behavior of programs. This
raises an interesting issue: what is the notion of an "observer" inthis setting? Suppose we consider observers to be internal to the

system--that is, observers are simply processes running in paral-lel. If observers are internal, we conjecture that our system is secure. Intuitively, processes may only communicate through ref-erence cells, and all writes to reference cells are protected by the
current security context (see the operational rule for := in Table 4and the corresponding type rule

[Assign] in Table 5). For instance,the example of Figure 1 does not type check in our calculus. A

simpler example can be made by modifying the looping examplefrom the previous section:

let fun haltIfTrue x:(bool,(H,H)) =

if x then ():(unit,(H,H))

else haltIfTrue x
in haltIfTrue secretBool;

y := true
end

For this term to type check, we must use the H context (i.e., with Hon the

`), and so the type of y must be (ref(bool,(H,H)),k).Only high-security agents may therefore branch on the value held

in y.For external observers, i.e., those that can observe the final answers of processes or simply the termination behavior of those pro-cesses, our system is not secure. For instance, the term

let fun haltIfTrue x:(bool,(H,H)) =

if x then ():(unit,(H,H))

else haltIfTrue x
in haltIfTrue secretBool;

true:(bool,(L,L))
end

from the last section still type checks in the H context. From thepoint of view of internal observers, this expression is secure, since

the value true:(bool,(L,L)) is not communicated to anyother process in the system. From the point of view of external
observers, however, the expression is not secure: we should makethe type of the expression be

(bool,(H,H)). We conjecture thatthe type system can be easily modified to address this issue.

The distinction between external and internal observers is fa-miliar in the security world. The Spi calculus of [2], for instance,
assumes that observers of protocols are those processes that can beprogrammed in the Spi calculus itself. Of course, this limits what
observers can do, but it also makes precise the underlying assump-tions of the model.

4 Integrity
We now sketch how to add integrity to the basic calculus of Sec-tion 2 and the extended calculus of Section 3, using the concepts
of creators and indirect creators. Recall that creators track theagents that directly built the value, whereas indirect creators track
the agents that may have influence over the eventual choice of avalue.

Creators and indirect creators are drawn from the same under-lying hierarchy of security groups as readers and indirect readers.
High integrity is modeled by points near the top of the hierarchy,low integrity by points near the bottom. But there is a twist with respect to subtyping. Recall that for readers, one may always restrictaccess to a value, e.g., change the reader annotation to a higher
security group. For creators, it works just the opposite way: onemay always weaken the integrity of a value, e.g., change the creator
annotation to a lower security group.Security properties now incorporate creator and indirect creator
information:

k ::= (r;ir;c;ic):

The variables r, ir, c and ic range over security groups; we maintainthe invariant that ic

v c. Subsumption for k becomes

(r;ir;c;ic) ^ (r0;ir0;c0;ic0)iff r
v r0, ir v ir0, c0 v c, and ic0 v ic

which formalizes the intuition that one may always weaken the in-tegrity of a value. The definition of

ffl must also be extended to thenew context:

(r;ir;c;ic) ffl (ir0;ic0) = (r t ir0;ir t ir0;c u ic0;ic u ic0):
We extend the operation ffl as well to values and types in the straight-forward manner.

The operational semantics must now track indirect creators. Forexample, the rule for

case becomes

(case (injj v)r;ir;c;ic of inj1(x): e1 j inj2(x): e2)r0

! (protectir;icur0 e j[v=x]) if r v r0

Note that the protect operation must take into account indirectcreators. The rule registers the reader r

0 of the injected value as an

indirect creator of the result of the computation. Typing rules thatinvolve the

ffl operation must be modified. For example, the caserule becomes

\Gamma  ` e : (s1 + s2;(r;ir;c;ic)) r v r0\Gamma 

;x : s1 ` e1 : s \Gamma ;x : s2 ` e2 : s\Gamma 
` (case e of inj1(x): e1 j inj2(x): e2)r0 : s ffl (ir;ic u r0)

We have proven Subject Reduction and Progress Theorems analo-gous to Theorems 2.1 and 2.2 for this system. We can also prove
a security result for indirect creators that is analogous to Theo-rem 2.3:

Theorem 4.1 (Noninterference) Suppose /0 ` e;e0 : (t;(r;ir;c;ic)).Suppose also that /0

` C[e] : (t0;(r0;ir0;c0;ic0)), t0 is a transparentground type and ir
6v ir0 and ic0 6v ic. Then C[e] ' C[e0].

Intuitively, if the indirect creators of the subexpression e do not in-clude that of the entire computation, then e cannot influence the

result of the computation. The proofs of these results use the tech-niques established in the Appendix.

Creators and indirect creators can also be added to the calculusof Section 3. Recall that in the case of readers, the type system
must guarantee that information does not leak out via side effects.A similar property must be guaranteed in the case of creators: we
must make sure that indirect creators of the computation are carriedover onto the values written in reference cells. Therefore, judgements \Gamma  `ir e : s must be changed to \Gamma  `ir;ic e : s, where ic is alower bound on the integrity of values that may be written to reference cells in the evaluation of e. As before, indirect information isplaced over

! to represent the latent effects of a computation. Thetype-checking rules for abstraction and application thus become

[Lam] \Gamma ;x : s1 `ir

0;ic0 e : s2

\Gamma  `ir;ic (lx : s1: e)k : (s1 ir

0

;ic0\Gamma ! s2;k)

[App] \Gamma  `ir

0;ic0 e : (s1 ir

0

;ic0\Gamma ! s2;(r;ir;c;ic))

\Gamma  `ir0;ic0 e0 : s1\Gamma 
`ir0;ic0 (e e0)r0 : s2 ffl (ir;ic u r0)

r v r0ir

v ir0ic
0 v ic

We have proven Subject Reduction and Progress Theorems for thissystem; the proofs follow the structure of the proofs in the Appendix for the pure case.

5 Related Work
Our work is certainly not the first to use a static system or program-ming language framework for security. Other work addresses pure
and modified information-flow models, and type systems for othersecurity problems.

Work on information flow reaches back to Denning's work [6,7] in the mid 1970s, and has been implemented in a variety of
contexts (e.g., the interpreter for Perl 5.0 can be put into a spe-cial dynamic "taint checking" mode which tracks information flow
and rejects programs that may reveal secret information.) Moremodern treatments reformulate Denning's system in a static type
system. For instance, Volpano, Smith and Irvine [23] provide onesuch reformulation for the simple language of "while" programs,
and prove a version of the noninterference theorem. More recentwork of Volpano and Smith [22] extends the language with firstorder procedures; the types are similar to the types in Section 3,where annotations for the latent effect of a function are part of the
type (written above the ! in our types). Volpano and Smith alsoconsider covert flows in the language of "while" programs with exceptions [21], and explore the example of Figure 1 in the languagewith nondeterminism [19]. Covert flows and the example of Figure 1 are eliminated by the same restriction: the tests and bodiesof "while" loops must be of lowest security. In both cases, they
prove the system is correct with a modification of the noninterfer-ence theorem: if a low-security program halts, then starting it in
any state with different values for the high-security variables alsohalts, and produces the same low-security outputs. Our noninterference theorems are weaker: they say only that if both programs halt,they produce the same low-security outputs. On the other hand, the
practicality of the restrictions on "while" loops is unclear.Others have considered means to alleviate the problems with
information flow. Myers and Liskov [13], for instance, describe asystem which tracks information flow, but where agents may "declassify" information that they own. Ownership corresponds quiteclosely to our notion of direct reader: only direct readers may reveal
information. In fact, one may build "declassify" operations fromthe primitives of the SLam calculus relatively straightforwardly by
induction on types. Nothing seems to be known, however, aboutthe formal properties of the system: rough ideas of the typing rules
are given, but no correctness theorems are stated or proved.There are other type systems for security. For example, Abadi's
type system for the Spi calculus is used to reason about proto-cols [1, 2]. Type systems have been also used for the related problem of reasoning about trustworthiness of data. For instance, [14]introduces a calculus in which one can explicitly annotate expressions as trusted or distrusted and check their trust/distrust status;this system enforces consistent use of these annotations, although
one can freely coerce from trusted to distrusted and vice-versa.Concurrency issues were first addressed by [4], although there appear to be some difficulties with that approach--see [23].There are two main novelties of our work. First, we consider the
purely functional language in isolation, and then extend it to sideeffects and concurrency. The type rules are less restrictive in the
purely functional case than in the full language, so programmingin the pure subset can lead to cleaner programs. Second, the type
system combines both access control and information flow in a lan-guage with higher-order functions and data structures, and studies
the system formally. These elements are essential for a develop-ment of practical languages that provide mechanisms for security,
and introduce a number of new technical issues that have not beenpreviously addressed.

6 Discussion
We view the SLam calculus as a first step towards providing a lan-guage basis for secure systems programming. It deals with the
essence of computing with secure information, but a number of im-portant issues remain. First, as with many other security systems,
the SLam calculus relies on a TCB (trusted computer base): trustedtype-checking, compilation, and runtime infrastructure. A failure
in any of these components potentially breaks the entire securitysystem. It would be possible to factor out some of the critical components by moving to a bytecode/bytecode-verifier organization (`ala Java), although the benefits of doing so are unclear.

Second, the type system we have presented is monomorphic.Clearly this is too restrictive: we need to be able to write code that
behaves uniformly over a variety of security groups (e.g., in writinga generic string editing/searching package). We are currently investigating two approaches to this problem: parametric security typesand a notion of "type dynamic" for security types. The former involves bounded quantification, and it is not clear we can computeconcise, intuitive representations of types; the latter involves runtime overheads.Third, our type system is static, but security changes dynamically. For instance, in a file system, the files that one can read todaywill probably be different from those one can read tomorrow. How
can we accommodate new files, new objects, new cells, new agents,and changing security groups? We plan to address these issues using a dynamically typed object manager. The basic idea is thataccess to shared objects is via the object manager; although each
program is statically typed, a program's interface to the object man-ager is via dynamic types (at runtime, a dynamically typed object
returned from the object manager must be unpacked and its secu-rity properties checked before the raw object it contains is passed
to the internals of the program).Fourth, any practical language based on the SLam calculus must
provide ways to reduce the amount of type information that mustbe specified by a programmer; the core SLam calculus is an explicitly typed calculus. Can we perform effective type reconstruction?What kinds of language support should we provide? For example,
it would be useful to introduce a statically scoped construct thatdefines a default security group for all objects created in its scope,
i.e., like UNIX's umask.We are investigating these and other issues in the context of an
implementation of our type system for Java. While many of theappropriate typing rules for Java can be adapted easily from the
SLam calculus, some new issues arise from exceptions, break,
continue, return, and instanceOf. The implementation isjoint work with Philip Wickline.

It would also be interesting to investigate other static analy-sis techniques to determine information flow. For instance, in the
language with side effects, the only time the security context maychange is in a

spawn expression. This may be too restrictive inpractice: statements that are executed before, say, a secure

casestatement need not restrict information flow so much. Abstract interpretation or set-based analyses might prove helpful here.

Acknowledgements: We thank Kathleen Fisher, Geoffrey Smith,Ramesh Subrahmanyam, Dennis Volpano, Philip Wickline, and the
anonymous referees for helpful comments.

References

[1] M. Abadi. Secrecy by typing in security protocols. In The-oretical Aspects of Computer Software: Third International

Symposium, volume 1281 of Lect. Notes in Computer Sci.Springer-Verlag, 1997.

[2] M. Abadi and A. D. Gordon. A calculus for cryptographicprotocols: The spi calculus. In Proceedings of the 4th

ACM Conference on Computer and Communications Secu-rity, pages 36-47, 1997.

[3] G. Andrews and R. Reitman. An axiomatic approach to in-formation flow in programs. ACM Trans. Programming Languages and Systems, 2(1):56-76, 1980.
[4] J. Ban^atre, C. Bryce, and D. L. Met'ayer. Compile-time de-tection of information flow in sequential programs. In European Symposium on Research in Computer Security, number875 in Lect. Notes in Computer Sci., pages 55-73. SpringerVerlag, 1994.
[5] L. Cardelli. Amber. In Combinators and functional pro-gramming languages, Proceedings of the 13th Summer School

of the LITP, volume 242 of Lect. Notes in Computer Sci.Springer-Verlag, 1986.

[6] D. Denning. Secure Information Flow in Computer Systems.PhD thesis, Purdue University, 1975.
[7] D. Denning. A lattice model of secure information flow. Com-mun. ACM, 19(5):236-242, 1976.
[8] D. Denning and P. Denning. Certification of programs for se-cure information flow. Commun. ACM, 20(7):504-513, 1977.
[9] M. Felleisen. The theory and practice of first-class prompts.In Conference Record of the Fifteenth Annual ACM Symposium on Principles of Programming Languages, pages 180-190. ACM, 1988.

[10] D. McCullough. Noninterference and the composability ofsecurity properties. In 1988 IEEE Symposium on Security and

Privacy, pages 177-186, 1988.
[11] R. Milner, M. Tofte, R. Harper, and D. MacQueen. The Defi-nition of Standard ML (Revised). MIT Press, 1997.

[12] J. C. Mitchell. Foundations for Programming Languages.MIT Press, 1996.
[13] A. C. Myers and B. Liskov. A decentralized model for infor-mation flow control. In Proceedings of the Sixteenth ACM

Symposium on Operating Systems Principles. ACM Press,1997.

[14] J. Palsberg and P. O/rbaek. Trust in the l-calculus. In Proceed-ings of the 1995 Static Analysis Symposium, number 983 in

Lect. Notes in Computer Sci. Springer-Verlag, 1995.
[15] A. M. Pitts. Relational properties of domains. Informationand Computation, 127:66-90, 1996.

[16] G. D. Plotkin. A structural approach to operational seman-tics. Technical Report DAIMI FN-19, Aarhus Univ., Computer Science Dept., Denmark, 1981.
[17] G. D. Plotkin. (Towards a) logic for computable functions.Unpublished manuscript, CSLI Summer School Notes, 1985.

[18] J. C. Reynolds. Types, abstraction and parametric polymor-phism. In R. E. A. Mason, editor, Information Processing 83,

pages 513-523. North Holland, Amsterdam, 1983.
[19] G. Smith and D. Volpano. Secure information flow in a multi-threaded imperative language. In Conference Record of the

Twenty-Fifth Annual ACM Symposium on Principles of Pro-gramming Languages. ACM, 1998.

[20] J.-P. Talpin and P. Jouvelot. Polymorphic type, region andeffect inference. Journal of Functional Programming, 2:245-

271, 1992.
[21] D. Volpano and G. Smith. Eliminating covert flows with mini-mum typings. In Proceedings of the Tenth IEEE Computer Security Foundations Workshop. IEEE Computer Society, 1997.
[22] D. Volpano and G. Smith. A type-based approach to programsecurity. In TAPSOFT'97: Theory and Practice of Software

Development, volume 1214 of Lect. Notes in Computer Sci.Springer-Verlag, 1997.

[23] D. Volpano, G. Smith, and C. Irvine. A sound type system forsecure flow analysis. Journal of Computer Security, 4(3):1-

21, 1996.

A Proofs for Pure Functional Language with Secrecy
A.1 Basic Facts
Proposition A.1 Suppose s1 ^ s2 and ir1 v ir2. Then s1 ffl ir1 ^s

2 ffl ir2.

Proposition A.2 For any secrecy property k and type s,

1. k ffl ir ffl ir0 = k ffl ir0 ffl ir.
2. s ffl ir ffl ir0 = s ffl ir0 ffl ir.

A.2 Substitution Lemma
Lemma A.3 If \Gamma  ` v : s0 and \Gamma ;x : s0 ` e : s, then \Gamma  ` e[v=x] : s.

Proof: By induction on the proof of \Gamma ;x : s0 ` e : s. We considera few of the most representative cases and leave the others to the
reader.

1. \Gamma ;x : s0 ` y : s where y 6= x. Obvious.
2. \Gamma ;x : s0 ` x : s where s = s0. Since e[v=x] = v, we are done.
3. \Gamma ;x : s0 ` (ly : s1: e0)k : (s1 ! s2;k), where \Gamma ;x : s0;y : s1 `e

0 : s2 and y 6= x. By induction, \Gamma ;y : s1 ` e0[v=x] : s2. Thus,

by rule [Lam],

\Gamma  ` (ly : s1: e0)k[v=x] : s
as desired.
This completes the induction and hence the proof.

A.3 Subject Reduction Theorem
Lemma A.4 Suppose /0 ` ea : sa, and ea ! eb. Then /0 ` eb : sa.

Proof: By cases depending on the reduction rule used. We give afew representative cases.

1. ((lx : s1: e)r;ir v)r0 ! (protectir0 e[v=x]). By assumption,/0

` ea : sa. Since ea is ((lx : s1: e)r;ir v)r0 , this derivationmust end in a (possibly empty) series of

[Sub] applicationsthat are immediately preceded by an application of

[App].Hence there exists some s
0a ^ sa and a derivation /0 ` ea : s0a

whose last rule application is [App]. By inspection of [App],there exist derivations for

/0 ` (lx : s1: e)r;ir : (s01 ! s02;r00;ir00)/0

` v : s01where r
00 v r0 and s02 ffl ir00 = s0a ^ sa

The derivation /0 ` (lx : s1: e)r;ir : (s01 ! s02;r00;ir00) must endin a (possibly empty) series of

[Sub] applications that are im-mediately preceded by an application of

[Abs]. Hence thereexists an s

3 where s3 ^ (s

01 ! s02;r00;ir00), and a derivation

/0 ` (lx : s1: e)r;ir : s3 whose last rule is [Abs]. By the [Abs]rule, there is a derivation:

x : s1 ` e : s2where s

3 = (s1 ! s2;r;ir)

Now, s3 = (s1 ! s2;r;ir) ^ (s01 ! s02;r00;ir00) implies that:

s01 ^ s1s

2 ^ s

02

ir v ir00

Combining s01 ^ s1 with /0 ` v : s01 implies /0 ` v : s1 by the
[Sub] rule. Hence we have x : s1 ` e : s2 and /0 ` v : s1, and soby the Substitution Lemma,

/0 ` e[v=x] : s2:
By the [Protect] rule, /0 ` (protectir e[v=x]) : s2 ffl ir. Now,s

2 ^ s

02 and ir v ir00 and so by Proposition A.1,

s2 ffl ir ^ s02 ffl ir00 = s0a ^ sa
Hence, by (Sub), /0 ` (protectir e[v=x]) : sa.
2. (proji hv1;v2i(r

;ir))r

0 ! (protectir vi), where r v r0. Because /0 ` ea : sa, there must exist s0a ^ sa and a derivation/0

` (proji hv1;v2i(r

;ir))r

0 : s0a whose last rule application is

[Pro j]. By the [Pro j] rule:

/0 ` hv1;v2i(r

;ir) : (s

01 \Theta  s02;(r00;ir00))

where s0i ffl ir00 = s0a ^ sa and r00 v r0

Since /0 ` hv1;v2i(r

;ir) : (s

01 \Theta  s02;(r00;ir00)), there is a derivation of /0 ` hv1;v2i(r

;ir) : s3 ending in a use of the (Pair) rule,such that s

3 ^ (s

01 \Theta  s02;(r00;ir00)). From the (Pair) rule we

have derivations:

/0 ` v1 : s1/0

` v2 : s2where s

3 = (s1 \Theta  s2;(r;ir))

and so by the [Protect] rule, /0 ` (protectir vi) : si ffl ir.Since s

3 = (s1 \Theta  s2;(r;ir)) ^ (s

01 \Theta  s02;(r00;ir00)),

s1 ^ s01s

2 ^ s

02

ir v ir00

Hence si ffl ir ^ s0i ffl ir00 = s0a ^ sa by Proposition A.1, and so/0

` (protectir vi) : sa by (Sub).

3. (protectir ()k) ! ()kfflir. Since /0 ` ea : sa, there existss

0a ^ sa and a derivation /0 ` (protectir ()k) : s0a whose last

rule is [Protect]. Hence, there is derivation

/0 ` ()k : swhere s

ffl ir = s0a ^ sa

The derivation of /0 ` ()k : s must consist of an application ofthe

[Unit] rule followed by some number of applications of
[Sub]. Hence (unit;k) ^ s. Now, applying the [Unit] ruleto

()kfflir gives:

/0 ` ()kfflir : (unit;k ffl ir)
Since (unit;k ffl ir) = (unit;k) ffl ir and (unit;k) ^ s, itfollows from Proposition A.1 that

(unit;k ffl ir) ^ s ffl ir =s
0a ^ sa. Hence, /0 ` ()k

fflir : sa by [Sub].

This concludes the case analysis and hence the proof.
Theorem 2.1 (Subject Reduction) Suppose /0 ` e : s and e ! e0.Then /0

` e0 : s.

Proof: Note that e = E[e1], where e1 ! e2 via one of the rules inTable 1, and e

0 = E[e2]. A simple induction on evaluation contexts,

using Lemma A.4, completes the proof.

A.4 Progress Theorem
Theorem 2.2 (Progress) Suppose /0 ` e : s and e is not a value.Then there is a reduction e

! e0.

Proof: Suppose, by way of contradiction, that there is no reductionof e. Then it must be the case that e

= E[e0], /0 ` e0 : s0 for somes

0, and e0 has one of the following forms:

1. e0 = (v v0)r.

2. e0 = (proji v)r.
3. e0 = (case v of inj1(x): e1 j inj2(x): e2)r.
We consider the first case and leave the others to the reader. Sincee

0 is well-typed,

s00 ^ s0/0

` (v v0)r : s00/0
` v : (s1 ! s00;(r2;ir2))/0
` v : s1

and r2 v r. Note that v must have the form (lx : s1: e00)(r1

;ir1), sinceit has a functional type (this can be seen by an easy induction on

typing derivations).This gives us enough room to complete the proof. By rule

[Abs],we know

(s1 ! s0;(r1;ir1)) ^ (s01 ! s00;(r2;ir2))/0

`ir (lx : s1: e00)(r1;ir1) : (s1 ! s0;(r1;ir1))
x : s1 `ir0 e00 : s0

It follows that r1 v r2 v r, and so the application reduction ruleapplies. This contradicts the initial assumption that there is no reduction of e, so there must be a reduction of the term.

A.5 Noninterference
We can assign a standard denotational semantics to the language byadopting the partial function model of [17]. Define the meaning of

a type expression s, denoted [[s]], by

[[(unit;(r;ir))]] = f\Lambda g

[[(s +t;(r;ir))]] = ([[s]] + [[t]])
[[(s \Theta t;(r;ir))]] = ([[s]] \Theta  [[t]])
[[(s ! t;(r;ir))]] = ([[s]] !p [[t]])

where (D !p E) is the set of partial continuous functions from Dto E. Note that this semantics ignores the security properties.

The meaning of terms is a partial function. If \Gamma  = x1 : t1;:::;xn :t
n is a typing context then [[\Gamma ]] = [[t1]] \Theta  ::: \Theta  [[tn]]. (The order isnot important here, as we could rely on some fixed ordering of

xi : ti pairs.) In the case that \Gamma  is empty, [[\Gamma ]] is the unit objectunit. For an environment h

2 j[[\Gamma ]]j, write h(x) for the projectionto the component corresponding to variable x, and h

[x 7! d] for theenvironment in which the x component is extended (or overwritten)

to d. The definition of the meaning function on terms, like that oftypes, ignores the security properties; similar definitions may be
found in, say, [17]. The model is adequate for observing the finalanswers of programs:

Theorem A.5 (Plotkin) For any typing judgement /0 ` M : s andany environment h,

[[/0 ` M : s]]h is defined iff M !\Lambda  v for somevalue v.

Our proof of noninterference uses logical relations (see [12] forother uses of logical relations). Define R to be a family of relations
indexed by secure types and indirect readers ir where

1. If s = (t;(r;ir)) and ir 6v ir0, then Rsir0 = f(d;e) j d;e 2 [[s]]g.
2. If t = (unit;(r;ir)) and ir v ir0, then Rsir0 = f(\Lambda ;\Lambda )g.
3. If t = (s1 + s2;(r;ir)) and ir v ir0, then

Rsir0 = f(inji(d);inji(e)) j (d;e) 2 Rsiir0;i = 1;2g:

4. If s = (s1 \Theta  s2;(r;ir)) and ir v ir0, then

Rsir0 = f(hd1;e1i;hd2;e2i) j (di;ei) 2 Rsifflirir0 g:

5. If s = (s1 ! s2;(r;ir)) and ir v ir0, then

Rsir0 = f( f ;g) j if (d;e) 2 Rs1ir0, then ( f (d);g(e)) 2 Rs2fflirir0 g:
Here, ( f (d);g(e)) 2 Rsir0 means that if f (d) and g(e) are defined,
then ( f (d);g(e)) 2 Rsir0 . Intuitively, the ir0 index specifies the secrecy group of an indirect reader of group ir0. When the secrecygroup ir

0 is not above the group of the type itself, the indirect

reader does not have permission to find out any information aboutthe value.

Proposition A.6 1. Each Rsir is directed complete. That is, if

f(di;ei) j i 2 Ig ` Rsir is a directed set, then (F di;Fei) 2 Rsir.

2. If s ^ s0, then Rsir ` Rs

0

ir.

Proof: By induction on types.

Theorem A.7 Suppose \Gamma  ` e : s and h;h0 2 [[\Gamma ]]. Suppose that for
all x : s0 2 \Gamma , (h(x);h0(x)) 2 Rs

0

ir0. Then ([[\Gamma  ` e : s]]h;[[\Gamma  ` e : s]]h

0) 2

Rsir0 .

Proof: By induction on the proof of \Gamma  ` e : s.
Suppose s is a type. Then s is transparent at security property kif

1. s = (unit;k0) and k0 ^ k;
2. s = (s1 + s2;k0), k0 ^ k, and s1;s2 are transparent at securityproperty k;

3. s = (s1 \Theta  s2;k0), k0 ^ k, and s1;s2 are transparent at securityproperty k; or
4. s = (s1 ! s2;k0), k0 ^ k, and s1;s2 are transparent at securityproperty k.
s = (t;k) is transparent if s is transparent at k.
Lemma A.8 Suppose s = (t;(r;ir)) is a ground type, transparentat

(r0;ir0). If ( f1; f2) 2 Rsir0, then f1 = f2.

Proof: By induction on t. The base case, when t = unit, is ob-vious. When t

= (s1 + s2;(r;ir)), since ir v ir0, it follows from thedefinition of Rs

ir0 that f j = (inji e j) for some i and (e1;e2) 2 Rs

iir

0.By induction, e

1 = e2. Thus, f1 = f2.When t = (s

1 \Theta  s2;(r;ir)), it follows from the definition of Rsir0

that f j = \Omega d j;e jff and (d1;d2) 2 Rs1fflirir0 and (e1;e2) 2 Rs2fflirir0 . Notethat s

1 ffl ir = (t1;(r1;ir1)) ffl ir = (t1;(r1 t ir;ir1 t ir)) and similarlyfor s
2 fflir = (t2;(r2;ir2))fflir. Since ir1 v ir, (ir1 tir) = ir v ir

0, and

similarly (ir2 t ir) v ir0. Thus, by induction, d1 = d2 and e1 = e2,which proves that f

1 = f2 as desired.

Theorem 2.3 (Noninterference) Suppose /0 ` e;e0 : (t;(r;ir)) and/0

` C[e] : (t0;(r0;ir0)), t0 is a transparent ground type and ir 6v ir0.Then C

[e] ' C[e0].

Proof: To simplify notation, let unit stand for the least secureunit type

(unit;(?;?)) (with lowest security) and () : unit de-note the least secure value of type

unit. Consider the open term

y : (unit ! s;(?;?)) ` C[(y ())?] : s0
It is easy to see that this is a well-formed typing judgement. Con-sider any /0

` ei : s for i = 1;2. Let

di = [[/0 ` (lx : unit: ei)(?

;?) : (unit ! s;(?;?))]]:

It is easy to show that (d1;d2) 2 R(unit

!s;(?;?))ir

0 , since ir 6v ir0.Let

fi = [[y : (unit ! s;(?;?)) ` C[(y ())?] : s0]][x 7! di]:
By Theorem A.7,

( f1; f2) 2 Rs

0ir

0:

If f1; f2 are defined, then by Lemma A.8, f1 = f2. When fi isdefined, it is simple to show that there is a value v

i such that fi =[[/0 ` v
i : s

0]]. Since v1 ' v2, we are done.

23 October 1997