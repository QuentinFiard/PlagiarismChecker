

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

1
Unify and Conquer (Garbage, Updating, Aliasing, ...)in Functional Languages

March, 1990
Henry G. Baker

Nimble Computer Corporation, Encino, CA  91436
1.  Abstract
Type inference is the process by which an expression in anuntyped computer language such as the lambda-calculus,
Lisp, or a functional language can be assigned a static datatype in order to improve the code generated by a compiler.
Storage use inference is the process by which a program ina computer language can be statically analyzed to model its
run-time behavior, particularly the containment and sharingrelations among its run-time data structures.  The
information generated by storage use information can alsobe used to improve the code generated by a compiler,
because knowledge of the containment and sharingrelations of run-time data structures allows for methods of
storage allocation and deallocation which are cheaper thangarbage-collected heap storage and allows for the in-place
updating of functional aggregates.
Type inference and storage use inference have traditionallybeen considered orthogonal processes, with separate

traditions and literature.  However, we show in this paperthan this separation may be a mistake, because the bestknown and best-understood of the type inferencingalgorithms--Milner's unification method for ML--already
generates valuable sharing and containment informationwhich is then unfortunately discarded.  We show that this
sharing information is already generated by standardunification algorithms with no additional overhead during
unification; however, there is some additional worknecessary to extract this information.  We have not yet
precisely characterized the resolving power of this sharingand containment information, but we believe that it is
similar to that generated by researchers using othertechniques.  However, our scheme seems to only work for
functional languages like pure Lisp.
The unification of type and storage inferencing yields newinsights into the meaning of "aggregate type", which

should prove valuable in the design of future type systems.
This work was supported in part by the U.S. Department of Energy Contract#DE-AC03-88ER80663
Copyright (C) 1990 by the Association for Computing Machinery, Inc.Permission to make digital or hard copies of part or all of this work for personal
or classroom use is granted without fee provided that copies are not made ordistributed for profit or direct commercial advantage and that copies show this
notice on the first page or initial screen of a display along with the full citation.Copyrights for components of this work owned by others than ACM must be
honored.  Abstracting with credit is permitted.  To copy otherwise, to republish,to post on servers, to redistribute to lists, or to use any component of this work
in other works whether directly or by incorporation via a link, requires priorspecific permission and/or a fee.  Permissions may be requested from
Publications Dept, ACM Inc., 1515 Broadway, New York, NY 10036 USA, fax+1 (212) 869-0481, or permissions@acm.org.

2.  Introduction
One of the major goals of modern higher-level languagesystems is the efficient allocation and deallocation of
complex data structures.  This goal has becomeincreasingly important with the rise in popularity of
object-oriented, functional and persistent programmingparadigms.  Typical techniques for implementing objectoriented programming paradigms involve the use offunctions in the form of functional closures to simulate,
and hide the details of, traditional data structures.  Thestorage for these objects must be efficiently managed by
the language, because this storage is not explicitly visibleto the programmer.  Functional languages require in
addition the efficient implementation of lazy evaluation andfunctional updating of aggregates.  Incorporating
persistence into a system adds complexity to theimplementation, because many ad hoc techniques of
storage management which are acceptable for internalstorage such as simply abandoning an address space, are no
longer acceptable for persistent languages.  Thesedevelopments are all pushing programming systems in
roughly the same direction--the employment of a garbage-collected heap.

Since the invention of garbage-collected heaps with thefirst implementation of the Lisp language, there has been
an enormous amount of progress in garbage-collectionalgorithms, whether using a form of tracing (mark/sweep
or copying), or some form of reference counting.  Thestate-of-the-art garbage-collected heap offers some sort of
generational collection [Lieberman83,Moon84,Ungar84],which provides for efficiency and responsiveness which is
refreshing to those of us from an earlier era.  If the systemrequires hard real-time response instead of excellent
stochastic response, then the heap will offer some sort ofincremental collection technique [Baker78,Appel88].

Nevertheless, garbage collection--or more generally--storage allocation and deallocation--remains a bottleneck
in most high-level programming languages.  The U.S.Department of Defense refuses to require garbage collection
in its standard language--Ada [Ada83]--because it fearsthat implementations incorporating garbage collection will
not be capable of meeting mission-critical time constraints("[garbage collection] is rather costly and cannot be used
effectively for real time systems, since it may occurunpredictably at critical times" [Ichbiah79,p.6-4]).

After many years of research into storage managementtechniques, it is still true that a clever programmer can

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

2
handle allocation and deallocation more efficiently than thegeneral purpose mechanisms used in higher level
languages.  Many researchers have treated this fact as a clueto the further improvement of storage management
performance.  These researchers have concluded that theprogrammer can do better, because he can see the global
picture of what is going on in the program, whereas therun-time system can see only incrementally what is going
on [Schwartz75, Muchnick76, Barth77, Steele78,Muchnick81, Pleban81, Hudak85, Ruggieri87, Chase87,
Ruggieri88, Hederman88, Inoue88, Horowitz89, Jones89].
Therefore, in order to further improve performance instorage management, there has been some research

attempting to gather more static information in order toreduce the cost of allocation and deallocation at run-time,
and in order to implement "in-place" updating of aggregatesin functional programming languages [Schwartz75,
Hudak85, Bloss89].  We call the process of staticallyextracting information from a program about the run-time
behavior of its storage management storage useinferencing, through an analogy with the extraction of
datatype information statically through type inferencing.
Whereas the general thrust of type inferencing is thedetermination of the set of run-time values which could

inhabit storage cells--these types are usually independentof one another--the general thrust of storage use
inferencing is the determination of the relations among therun-time values which could inhabit the storage cells.  If
there were no relationships among the values in differentstorage cells, then there would be no sharing and no
containment between data structures, and hence noproblems in allocation, deallocation or updating.

The most common method for representing storage userelationships for static analysis has involved some sort of
graph structure, which is a finite structure representing thepossibly infinite set of storage relations which could occur
at run-time for a program [Muchnick81, Jones82,Ruggieri87, Chase87, Hederman88, Larus89].  The exact
nature of the approximations used has been the subject ofseveral papers.  Some of these representations and
algorithms are on the verge of becoming elegant, at leastfor functional languages [Chase87].

The other great tradition in static analysis for untypedlanguages has been type inferencing.  Type inferencing is
the process whereby proper type declarations are obtainedby a mechanical process from a program which neglected
to use them [Milner78, Suzuki81, Mitchell84, Wand84,Boehm86, Peyton-Jones87, Wand89, Baker90].  If we
consider a legal program which has complete declarations,and then strip these declarations out, we can measure the
capabilities of the type inference system to put them back.If no unique set of declarations can be inferred, we have a
problem with the type system itself, whereas if a uniqueset of declarations exists, but the inferencing algorithm
cannot always find it, then we have a problem with theinferencer.

The major problem in type inferencing has been how todeal with polymorphism, where the typing of a function

symbol or value symbol is different in different contexts.Polymorphism is of great practical concern due to the
success of object-oriented systems, which routinelymanipulate higher-order objects such as function-producing
functions, and these functions may have to deal with manydifferent types.

The most successful type inferencing algorithm in usetoday is Milner's unification algorithm which can handle a
certain amount of polymorphism.  Probably the bestexposition of this algorithm for our purposes is given in
[Aho86,p.364], because it gives a unification algorithm forthe type inferencing method in the section just following
[Aho86,p.376].  Rather than give a detailed explanation ofthis algorithm which is better covered in that reference, we
will make a few observations about how and why it works.
Unification is a process whereby a number of objects arefirst assumed to be distinct, and it is later discovered that

some of them are actually identical.  In the case of typeinference, distinct mathematical variables are proposed for
each program variable and temporary within a program,where the mathematical variables will each denote an
unknown "type".  Using the knowledge of the primitivesof the programming language, we can prove that many of
these variables are not distinct after all, but identical.Complications arise when higher-order types (functionals,
data structures) are involved, because determining the"identity" of two types now involves a matching process.

Crucial to the success of Milner's polymorphic typeinferencing process is the fact that when a polymorphic
function type is to be represented, a fresh new copy of thatfunction type is constructed (the exact semantics of "fresh
new copy" are important to us and will be discussed later).Since the new copy is distinct from other instances of the
function type, the type inferred in this instance can bedifferent from that inferred in other instances.

We claim that this copying process is functionallyidentical to procedure integration ("inlining", "betasubstitution"), so far as the type inferencing algorithm isconcerned, although it is not so computationally intensive
as actual inlining.  Thus, the Milner-style inferencing isstill not "really" polymorphic, because the different
instances of the function are no longer the "same"function.

We should not have to duplicate these remarks for datastructures in functional languages, due to the ability of
functional closures to simulate data structures.  However,we will, because we are vitally interested in the detailed
mechanics of type inferencing for data structures.
Data structures such as a Lisp-like pair are treated in afashion similar to functions by Milner's type inference

algorithm.  Whenever a pair is constructed or used, itposits the possibility of a new pair--never before seen--
and then utilizes other constraints to force identity whenidentity cannot be denied.

We now begin to see the possibility of using Milner-styletype inferencing to determine sharing and containment
relationships.  Each new pair type node constructed during

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

3
the execution of Milner-style type inferencing starts out byrepresenting a separate (disjoint) set of run-time nodes.  It
is only when other constraints force two of these nodes tobe the same (i.e., the sets potentially overlap), that the
nodes are identified.  Therefore, at the end of Milner-styletype inferencing, the nodes which are not unified together
represent disjoint sets of run-time nodes, assuming that wehave seen the entire program.  This last assumption is
crucial, since unification starts out assuming thateverything is different, and moves monotonically toward
sameness.  The only thing standing between a givenprogram and universal oneness is the lack of any more
constraints to apply.
Milner-style type inferencing therefore gives us thefollowing very important information: each distinct

datatype node represents a set of runtime nodes, whichcannot be distinguished by the current level of analysis.
Datatype nodes which are distinct represent disjoint sets ofruntime nodes, while datatype nodes which are unified
represent overlapping sets of runtime nodes.  Milner-styletype inferencing therefore defines a particular level of
sharing and containment information which can be gottenrelatively cheaply, but is still quite helpful in solving
allocation and updating problems.  For example, we showlater that Milner-style type inferencing can infer that the
top level of the result of Lisp's append function does notshare with the top level of the first argument to 

append.

3.  Insight into our Milner-style type-cum-storage-use analysis

Researchers in storage use inference have been forced tomake approximations in the detail of their analysis in order
to ensure that the analysis terminates within a reasonableperiod of time.  One of the most common approximations
in their analysis has been the classification of all runtimeobjects allocated by a particular "allocation site" within a
program as being equivalent, because they were allocatedby the same piece of program text--the birthplace
[Ruggieri87, Chase87, Hederman88, Larus89].  However,this notion is not completely well-defined, because if one
shifts one's attention to the allocation subroutine itself,then all nodes would be equivalent, and the analysis would
become worthless.  Our interpretation of this notion is thatthe allocation subroutine is always procedurally integrated
(inlined), so that allocation points and program texts are ina one-to-one correspondence.

Consider, for example, a Lisp-like pair datatype.  Inmaking a distinction among the pairs that occur at runtime within a program based on where in the program textthe pair was allocated, we are creating a new set of
"datatypes" which is a refinement of the standard set ofdatatypes.  We thus have pair

1, pair2, pair3, etc., asatomic datatypes, where the only difference between them

is their birthplace.  While this refined type system is largerthan the original type system due to the additional
distinctions, it is still tractable if the original type systemwas.  This is because the program text is finite, and

therefore the refined type system cannot be that muchbigger than the original type system.
A similar approximation is made with respect to functions.While different levels of recursion can represent
substantially different situations to be modeled, we areforced to curtail this type of excursion, else our analysis
will become paralysis.  Therefore, we utilize the same"textual" approach to approximation for functions that we
used for data structures: if two functions share the sametext but are different closures (i.e., the function text was
closed with the values of its free variables at differentexecution times), then they are still the same "function", at
least so far as our static modeling goes.  Note that thisapproximation is not quite as restrictive as it appears,
because we can always perform procedure integration(inlining) before starting our static analysis, after which
each instance of the original procedure will be handledcompletely independently.

From an implementation point of view, this tagging ofobjects with their textual birthplace is not such a bad idea.
After all, a compiler must choose a particular machine codeexpansion for each birthplace, so there is some possibility
that different birthplaces can be handled differently.  Ifsubsequently this information can be utilized to optimize
deallocation or in-place updating, then this birthplacedistinction among datatypes was worthwhile.  Conversely,
it would be a lot of work for a compiler to make any finerdistinction than birthplaces, because it would involve
additional parametrization and branching in the allocationcode.  Finally, birthplace tagging seems to be a good
approximation to what expert programmers do when theyimplement more intelligent allocation/deallocation than
automatic garbage collection.
The subdivision of standard datatypes created by ourbirthplace tagging can be considered to produce distinct

types, even though the same operations can be performedon them.  Therefore, we have a new form of
polymorphism which, if expressed as truly distinct types,cannot be handled by traditional Milner-style type
inferencing algorithms.  This is because while the programwithout birthplace tagging may be uniquely typed, the
program with birthplace tagging may require the ability tohandle sets of types.  For example, the expression
(if ... then pair1 else pair2) has the single type "pair"before tagging, but the 

set of types {"pair1","pair2"} aftertagging.  Suzuki has elegantly extended Milner-style type

inferencing to deal with such a situation in Smalltalk[Suzuki81], while the Russell compiler [Boehm86] utilizes
another style of type inferencing with union types.
(We have attempted to model birthplace tagging using Adaderived types [Ada83], without success.  While derived

types in Ada are essentially copies of a type and all of itsoperations, Ada forces all derivations of a type to use the
same storage collection, which removes the verydistinction we were trying to make!)

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

4
4.  An example
We will now show an example of how Milner-style typeinference unwittingly produces sharing information.
Consider the pure Lisp function append:
(defun append (x y)
  (if (null x) y
      (cons (car x) (append (cdr x) y))))

We would like to perform traditional Milner-style typeinference on 

append.  However, since pure Lisp has nostandard type system, we give it a quasi-ML type system

(as in [Wand84]), in which lists, for example, havearbitrary length, but all list elements must be of the same
type.  We must first assign types to the primitiveconstants in the program--namely 

if, null, cons,
car, cdr (we indicate the type of an expression by thenotation "<expression> : <type>", as in ML).

if: boolean x 'E x 'E o"" 'E ; 'E is a type variable.
null: list('A) o"" boolean ; 'A is a type variable.
cons: 'B x list('B) o"" list('B) ; 'B is a type variable.
car: list('C) o"" 'C ; 'C is a type variable.
cdr: list('D) o"" list('D) ; 'D is a type variable.

A possible sequence of type inferences is as follows:

x: list('A) ; from null(x)
'A = 'C = 'D ; from (car x), (cdr x)
(car x): 'A
(cdr x): list('A)
(append (cdr x) y): list('A) ; from defn of cons
y: list('A)
append: list('A) x list('A) o"" list('A)

Thus, append takes two argument lists and returns aresult list and all three lists must have the same element
type.  This example shows traditional Milner-style typeassignment at its best.  We now look more carefully at the
data structures created during the process of unification.Here we assume a "fast" unification algorithm similar to
that found in [Aho86,p.376].  The important thing is thatall variables 'Z share the same node, and that nodes like
"list('Z)" are not necessarily the same, and start out being(usually) different.

We now redefine the types of the primitive functions,being more careful about different instances of nodes like
"list('Z)".  We distinguish these differences by means ofsubscripts.  It is vitally important, however, that the
instances are subscripted in accordance with the sharingsemantics of the functions being typed, as we shall later
see.

if: boolean x 'E x 'E o"" 'E ; no change
null: list1('A) o"" boolean
cons: 'B x list2('B) o"" list2('B)
car: list3('C) o"" 'C
cdr: list4('D) o"" list4('D)

Now, when we do Milner-style unification, we can see the different instances getting unified.

y: 'E ; from (if ...)
x: list1('A) ; from (null x)
list3('C) = list1('A) ; from (car x)
'C = 'A
list4('D) = list1('A) ; from (cdr x)
'D = 'A
'B = 'C ; from (cons ...)
(append ...): list2('B) ; from (cons ...)
'E = list2('B) ; from (if ...) and result

To summarize:
'A = 'B = 'C = 'D
x: list1('A) = list3('C) = list4('D)
y: 'E = list2('B)
append: list1('A) x list2('A) o"" list2('A)

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

5
As before, append takes as arguments two lists of thesame type of elements, and returns a list of the same type
of elements as its arguments.  In addition, we know thatthe result of 

append must share with its second argument(even if it only shares the empty list 

nil), and may alsoshare with its first argument if the first argument were

sharing with the second argument already, as in

(let ((x '(a b c)))
  (append x x))

Thus we have shown is that while the types of thearguments and the results of the 

append function are allisomorphic, the result of 
append cannot contain cellsfrom the top level of its first argument, unless the first and

the second arguments were already sharing, based onconstraints from outside of the 

append function.

Why did we type cdr as list4('D)o""list4('D)instead of as 

list4('D)o""list5('D) ?  The reason isthat 
cdr doesn't just give a copy of the rest of the list, itgives the rest of the list.  In other words, the type of

cdr(cons(x,y)) cannot be an isomorphic copy of thetype of 

y , but must be the type of y  itself.  In therelatively simple type system given here, this can only be

arranged by making the type of the result of cdr identicalto the type of its argument.  (Note that the type of
car(cons(x,y)) is already identical to the type of x).

Unfortunately, this means that we cannot distinguishd i f f e r e n t   c e l l s   i n   t h e   s i m p l e   l i s t
cons(1,cons(2,cons(3,nil))), because they allhave identical types.

A curious feature of our ML-style type system is that nilis the polymorphic generator of new lists.  In other words,
since cons produces the type of its second argument, theonly way to introduce a new list type is by using 

nil.

(Another type system might type c o n s  as
'Ax'Bo""pair('A,'B), car as pair('C,'D)o""'C,and 

cdr as pair('E,'F)o""'F.  Such a type systemwould also satisfy the requirements that the type of

car(cons(x,y)) is identically the same as the type of
x and the type of cdr(cons(x,y)) is identical to thetype of 

y, and thereby distinguish the different cells in
cons(1,cons(2,cons(3,nil))), but this typesystem could not handle lists of indefinite length, because

lists of different lengths could no longer be unified.  Thus,the limitations of the type system itself reduce the
potential resolution for our storage use inferencing.)
We can make the unification algorithm for sharing evenmore obvious (but less efficient and no more powerful), by

including an additional location variable in addition to thetype variables.  In other words, we define the primitive
functions as follows:

if: boolean x 'E x 'E
null: list('A,'L1) o"" boolean
cons: 'B x list('B,'L2) o"" list('B,'L2)
car: list('C,'L3) o"" 'C
cdr: list('D,'L4) o"" list('D,'L4)

Having done this, we perform traditional Milner-style type inference using unification to produce the following typing:

'A = 'B = 'C = 'D
'L1 = 'L3 = 'L4
'E = list('A,'L1)
append: list('A,'L1) x list('A,'L2) o"" list('A,'L2)

We must now provide an interpretation for these locationvariables.  A location variable ranges over all locations.
Two location variables may share if they are unifiedtogether.  Our typing of the 

append program aboveprovides the most general unifier this program, hence the

most general typing.  There may still be sharing betweenthe first argument to 

append and the result, but thissharing would not be caused by 

append itself, but wouldbe the result of some other constraint outside of 

append.

Where are the location constants?  Presumably, locationconstants would be individual locations, or at least classes

of locations, all of whom were allocated by the sametextual program statement.  However, such an
approximation cannot be handled by the simple non-state-based type inference system of ML, because different
conses would yield different location constants, whichcould not be unified.  This means, for example, that it
would be impossible to unify the two arms of theconditional 

(if x (cons 3 4) (cons 3 4)).However, by leaving the locations in the form of location

variables, we lose resolution, because we can no longertrack the different allocations separately, but we can still do
unification.
One consequence of this unification approach to sharing isthat in order to get the best information, we must use a

more complex typing scheme, which allows for unions oftypes, and thus can handle the two arms of the above
conditional correctly.  [Suzuki81] describes such anapproach, which should be able to handle the situation
where the location constants for each allocation are arepresentation of location within the program text where
the allocation is made.
5.  Soundness
We do not yet have a proof of soundness for our scheme,but we do have some observations.  Due to the nature of
static typing, two objects cannot share unless they haveidentical or isomorphic types, a fact which has been used
by compilers for years [Ada83].  Since our scheme

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

6
produces only information of the form "x may share withy" and not "x must share with y", we need only show that
if "x may share with y" at run-time, then x and y will beassigned the same identical type.  Since the accurate
determination of "x may share with y at run-time" isundecidable, we will compute a conservative
approximation to this relationship.  Therefore, we needonly prove that if x and y have different (isomorphic but
not identical) types, then x cannot share with y at run-time.

A lemma is needed which shows that for our scheme to gowrong, the type inference system must assume that a copy
will be made, when in fact a value will actually be passeduncopied, and the result becomes an undetected alias.  Such
situations arise in several cases.  Cells which are returnedto the free list and reallocated may indeed "share", but this
situation does not cause problems because it is no longerthe "same" cell--only its storage was reused.  Similarly,
in-place aggregate updating can also result in undetectedsharing, but this situation is identical to the previous one,
except that we never bothered to return the object to thefree list and reallocate it.

However, there are more interesting cases to consider.Lisp's 

intern function, for example, either returns its

argument or another symbol with the same "print-name";however, it does not create any new symbols.  Proper
typing requires that all symbols become aliased, since it isimpossible to precisely model the sharing semantics of
intern using simple types.  The use of "memoization"to "cache" function values--a legitimate optimization in
functional languages--offers a similar opportunity to avoidmaking copies, and thereby cause an undetected alias.
Goto suggests the use of "hash consing" [Goto74] toimplement data structures in functional languages so that
the recursive equal function no longer has to recurse.Hash consing always produces the unique value with a
particular set of selectors (e.g., car and cdr), so it alwaysproduces a unique representation for every structured value,
no matter how complex.  In such a system "copying" hasno meaning, since a copy operation will always return the
same (pointer) value, and therefore there is a possibilitythat our scheme can "go wrong" in this case.  The intuitive
"fix" in all of these cases is to match the run-timesemantics with an appropriate version of "fresh new copy"
in the Milner-style type inference algorithm.  In suchcases, "stale" might be better than "fresh".

Complications such as these have so far kept us from aproof of soundness.

6.  Applications
Our scheme can reclaim all of the garbage from quicksort [Inoue88], if one correctly types the polymorphic recursivefunction 

qs, below.  Traditional ML type inference cannot do this, but ML+ [Kfoury88] should be able to.

(defun qs(x)
  ; qs: list1(integer)o""list2(integer)
  (if (null x) nil
    (append (qs1 (low (cdr x) (car x))) ; append defined above.
            (cons (car x)
                  (qs2 (high (cdr x) (car x)))))))

(defun high(x i)
  ; high: list3(integer) x integero""list4(integer)
  (cond ((null x) nil)
        ((< (car x) i) (high (cdr x) i))
        (t (cons (car x) (high (cdr x) i)))))

(defun low(x i)
  ; low: list5(integer) x integero""list6(integer)
  (cond ((null x) nil)
        ((>= (car x) i) (low (cdr x) i))
        (t (cons (car x) (low (cdr x) i)))))

This can be done because our typing shows that qs, high and low all copy their arguments, and hence their results do notshare with their arguments.  Since the intermediate results from calling 

low, high and qs1 do not share with the result of
qs, they can all be garbage collected by qs before it returns.

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

7
Our scheme can do destructive aggregate updating [Bloss89].

upd: seq1('E) x integer x 'E o"" seq2('E)
; upd(a,i,x) = a', s.t. a'[i]=x and a'[j]=a[j], jz'i.

(defun ntimesx(n x)
  ; Create a new array of length n initialized to x.
  ; ntimesx: integer x 'E o"" seq('E)
  (labels
    ((init (a i x)
       ; init: seq3('E) x integer x 'E o"" seq4('E)
       (if (zerop i) a
         (init (upd a i x) (1- i) x))))
    (init (make-array n) (1- n) x)))

We can destructive updates to a, and hence avoid O(n2) behavior, because a doesn't share with anything else.
We do not claim that the storage structure created by Milner-style type inference is ideal for answering all such questions,but that it does have the appropriate information content.  This insight should lead to modified versions of Milner-style type

inference in which better storage structures are built.

7.  Comparison with other techniques
Our method produces information about the possibility ofa pointer in one "type" (set of objects) pointing to an
object in another "type" at run-time.  It does this byrepresenting these sets as distinct objects which can point
to one another.  In this way, our method is analogous tothe graph structures used by some researchers to represent
sharing and containment information [Ruggieri87,Chase87].  Insofar as these researchers have deviated from
our assumption of putting textual birthplaces in a 1-1correspondence with sets of run-time objects, they can
obtain more powerful results, because such deviationsallow finer distinctions to be made among the various runtime objects than does our representation [Chase87,Larus89].  However, it is very difficult to characterize these
finer distinctions, because they attempt to separately track,for example, the objects created at different levels of a
recursion which can be unbounded, and therefore mostresearchers require that the analysis be cut off at some
finite arbitrary limit (e.g., "k-limited" [Jones79]) in orderto guarantee that the analysis will terminate.  We believe
that while separately tracking such objects is required toprove the correctness of some pointer-manipulating
programs [Pleban81, Mason86], this tracking is toodifficult and too expensive to include as a standard
optimizing technique within a compiler.  Furthermore, aprogrammer can often obtain the same results himself by
explicitly instructing the compiler to "inline" the recursivefunction k times before our analysis is performed.

Chase [Chase87] also extends the graphical technique tohandle certain kinds of side-effects, and is therefore more
powerful than our technique, which is restricted tofunctional languages.  However, the introduction of sideeffects greatly clutters his model, and increases thecomputational demands of his analysis.

Researchers have also used explicit sets and set operationsto compute sharing and containment information

[Schwartz75, Inoue88], but we believe that our analysissubsumes theirs.
For the aggregate update problem, graphical analyses andstatic reference count analyses [Barth77, Hudak86,
Hederman88] are complementary, in the sense that staticreference counting can sometimes produce sharper
information than any level of graphical analysis (e.g., on"sorting" and "swapping" programs [Hedermann88]), and
vice versa.  Therefore, one could perform a static referencecount analysis in addition to our analysis and gain sharper
information.
8.  Complexity
The complexity of our analysis should be essentially thesame as that for Milner-style type inferencing, which has
been shown to be exponential [Kanellakis89][Mairson90].However, since this type inferencer has been in use for a
decade with few complaints about its speed, we assumethat its worst case behavior is rare, although Mairson
[Mairson90] shows a 5-line ML example which after 2minutes of processor time, 60 megabytes of memory, and
173 printed pages of output, was still not typed!  If weimprove the resolution of the inference by using Suzukistyle type inference [Suzuki81], then the complexity willgrow, since Suzuki requires an additional transitive closure
operation whose size is on the order of the size of theprogram text, and the Warshall transitive closure algorithm
[Baase78] (the most efficient "real" algorithm) is of cubiccomplexity.

9.  Conclusions
Unification has been used by Milner and others forautomatically inferring datatypes in a compiler for a
programming language.  Fast algorithms for unificationutilize clever "structure-sharing" algorithms to obtain their
efficiency.
Graphs of various sorts have been used by manyresearchers in order to statically determine at compile time

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

8
some of the sharing properties of structures created at run-time [Chase87, Ruggieri87, Hederman88, Larus89].  These
graphs are used for purposes such as detectingopportunities for in-place updating in functional languages,
detecting opportunities for converting heap allocation intostack or static allocation, detecting aliases which interfere
with traditional optimizations, and detecting dependenciesduring parallelization.

We have shown that the clever structure-sharing unificationalgorithms for Milner-style type inference already produce
sharing information, which can then be used for theindicated storage use optimizations.  Alternatively, we can
make storage aliasing explicit during the unificationalgorithm, in order to extract even more sharing
information.
Using this insight, we have developed an elegant algorithmwhich performs type inferencing and sharing inferencing at

the same time.  This algorithm is powerful enough tohandle most of the storage use problems for which
graphical techniques have been advocated.
We discovered the unification method of sharinginferencing while we were studying the implementation of

Milner-style type inferencing described in [Aho86,p.364],and simultaneously studying the "storage containment
graphs" of David Chase [Chase87].  Both of thesealgorithms compute similar structures!  An additional
insight came from the observations of several researchers[Jones79, Pleban81, Larus89, Inoue88], that the alias
problem can be solved by describing the possible pointerpaths as regular expressions, which have nice closure
properties under intersection, union and complement.Since storage containment graphs (and other similar finite
graphs defined by other researchers) are essentially non-deterministic finite state machines for recognizing these
regular expressions, and since unification can be seen[Aho86,p.388] as a finite-state automaton equivalence
tester, it seemed possible to solve all of these problemswith the same machinery.

The information produced by our analysis is essentiallyequivalent to the information produced by the analysis of
[Inoue88] for "pure" (functional) Lisp, except that ouralgorithm is a good deal simpler and easier to understand
than theirs.  Since the information is equivalent, thestorage use optimizations they perform should also be
implementable using our algorithm.
Our analysis does not easily extend to non-functionallanguages, because it is much more difficult to capture the

realm of sharing and containment relations that could occurduring run-time by using static analysis on programs
which can alter such relationships through assignment.Chase addresses this more general problem [Chase87].
However, the complexity of his analysis for non-functionallanguages may make it impractical, while our analysis is
certainly practical for functional languages, because mostimplementations are already unwittingly doing it--as we
have shown!

10.  Acknowledgements
We are indebted to the reviewers for their help inimproving this paper--especially to those who pointed out
embarrassing errors in the first draft.  We are also indebtedto the U.S. Department of Energy for their support of this
research (Contract #DE-AC03-88ER80663), and to DavidChase for his patient explanation of his thesis work to me.
Finally, we are indebted to Andrew Appel and Peter Lee,who told us about the elegance of ML type inference.

11.  References

Ada.  Reference Manual for the Ada(R) ProgrammingLanguage.  American National Standards Institute, New

York, 1983.Aho, A.V., Sethi, R., and Ullman, J.D.  Compilers:
Principles, Techniques, and Tools.  Addision-Wesley,Reading, MA, 1986.
Appel, A.W., Ellis, J.R., and Li, K.  "Real-time concurrentgarbage collection on stock multiprocessors".

SIGPLAN PLDI, June, 1988.Baase, S.  Computer Algorithms: Introduction to Design
and Analysis.  Addison-Wesley, Reading, MA, 1978.Baker, H.G.  "List processing in real time on a serial
computer".  CACM 21,4 (April 1978),280-294.Baker, H.G.  "The Nimble Type Inferencer for Common
Lisp-84".  Nimble Computer Corporation, 1990, inpreparation.
Barth, J.M.  "Shifting garbage collection overhead tocompile time".  CACM 20,7 (July 1977),513-518.
Bloss, A.  "Update Analysis and the EfficientImplementation of Functional Aggregates".  4'th

ACM/IFIP Conf. on Funct. Prog. and Comp. Arch.,London, Sept. 1989, 26-38.
Boehm, H.-J., and Demers, A.  "Implementing Russell".ACM Sigplan '86 Symp. on Compiler Constr., Sigplan

Notices 21,7 (July 1986),186-195.Chase, David R.  Garbage Collection and Other
Optimizations.  Ph.D. Thesis, Rice University, August,1987.
Goto, Eiichi.  "Monocopy and Associative Algorithms in anExtended Lisp".  Info. Sci. Lab., Univ. of Tokyo, 1974.
Hederman, Lucy.  Compile Time Garbage Collection.  M.S.Thesis, Rice Univ. Comp. Sci. Dept., Sept. 1988.
Horowitz, S., Pfeiffer, P., and Reps, T.  "DependenceAnalysis for Pointer Variables".  ACM Sigplan '89

Conf. on Prog. Lang. Design and Impl., SigplanNotices 24,7 (July 1989),28-40.
Hudak, P., and Bloss, A.  "The aggregate update problem infunctional programming systems".  12'th ACM POPL,

January, 1985.Hudak, P.  "A Semantic Model of Reference Counting and
its Abstraction".  1986 ACM Lisp and FunctionalProgramming Conference, Cambridge, MA,351-363.
Ichbiah, J.D., et al.  "Rationale for the Design of the AdaProgramming Language".  ACM Sigplan Notices 14,6

(June 1979), Part B.

Revision of paper in Proc. 1990 ACM Conf. on Lisp and Functional Programming, Nice, France, June 1990, 218-226.

9
Inoue, K, Seki, H., and Yagi, H.  "Analysis of functionalprograms to detect run-time garbage cells".  A C M

TOPLAS 10,4 (Oct. 1988), 555-578.Jones, N.D., and Muchnick, S.S.  "Flow Analysis and
Optimization of Lisp-like Structures".  6'th ACMPOPL, Jan. 1979,244-256.
Jones, N.D., and Muchnick, S.S.  "A flexible approach tointerprocedural data flow analysis and programs with

recursive data structures".  9'th ACM POPL, 1982,66-74.
Jones, S.B., and Le Metayer, D.  "Compile-time garbagecollection by sharing analysis".  ACM Func. Prog.

Langs. and Comp. Arch. (FPCA), 1989, 54-74.Kanellakis, P.C., and Mitchell, J.C.  "Polymorphic
unification and ML typing".  16'th ACM POPL,Jan. 1989,105-115.
Kfoury, A.J., Tiuryn, J., and Urzyczyn, P.  "A ProperExtension of ML with an Effective Type-Assignment".

Proc. 15'th ACM POPL, Jan. 1988,58-69.Larus, James Richard.  Restructuring Symbolic Programs
for Concurrent Execution on Multiprocessors.  Ph.D.Thesis, UC Berkeley, also published as Rep. No.
UCB/CSD/89/502, May, 1989.Lieberman, H., and Hewitt, C.  "A real-time garbage
collector based on the lifetime of objects".  CACM 26,6(June 1983),419-429.
Mairson, H.G.  "Deciding ML Typability is Complete forDeterministic Exponential Time".  17'th ACM POPL,

January 1990, 382-401.Mason, Ian A.  The Semantics of Destructive Lisp.  Center
for the Study of Language and Information, Stanford,1986.
Milner, R.  "A theory of type polymorphism inprogramming".  JCSS 17,3 (1978),348-375.
Mitchell, J.C.  "Coercion and Type Inference".  11'th ACMPOPL, 1984, 175-185.
Moon, D.  "Garbage collection in a large Lisp system".ACM Lisp and Functional Programming Conf.,

1984,235-246.Muchnik, S. S., and Jones, N.D.  "Binding time
optimizations in programming languages: somethoughts toward the design of an ideal language".  ACM
POPL, 1976.Muchnik, S., and Jones, N.  "Flow analysis and
optimization of LISP-like structures".  In ProgramFlow Analysis: Theory and Applications, by the same
authors, Prentice-Hall, Englewood Cliffs, NJ, 1981.Peyton-Jones, S.L.  The Implementation of Functional
Programming Languages.  Prentice-Hall, NY, 1987.Pleban, Uwe F.  Preexecution Analysis Based on
Denotational Semantics.  Ph.D. Thesis, University ofKansas, 1981.
Ruggieri, Christina.  Dynamic Memory AllocationTechniques Based on the Lifetimes of Objects.  Ph.D.

Thesis, Purdue University, August, 1987.Ruggieri, C. and Murtagh, T.  "Lifetime analysis of
dynamically allocated objects".  15'th ACM POPL,January, 1988.
Schwartz, J.T.  "Optimization of very high level languages,Part II: Deducing relationships of inclusion and

membership".  Computer Languages 1,3 (1975),197-218.
Steele, G.L., Jr.  Rabbit: A compiler for Scheme.  AIMemo 474, MIT, May 1978.
Suzuki, N.  "Inferring types in Smalltalk".  8'th ACMPOPL, 1981,p.187-199.
Ungar, D.  "Generation scavenging: A non-disruptive highperformance storage reclamation algorithm".  ACM

Software Eng. Symp. on Prac. Software Dev. Envs.,SIGPLAN Notices 19,5 (May 1984),157-167.
Wand, M.  "A Semantic Prototyping System".  Proc. ofACM Sigplan '84 Symp. on Compiler Constr., Sigplan

Notices 19,6 (June 1984),213-221.Wand, M., and O'Keefe, P.  "On the Complexity of Type
Inference with Coercion".  ACM Func. Prog. Langs.and Comp. Arch. (FPCA), 1989, 293-297.