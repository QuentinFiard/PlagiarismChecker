

Proving the

John Hughes

Correctness of Reactive Systems

Using Sized Types

Lars Pareto* Amr Sabry"
Department of Computer Science

Chalmers University

41296 Goteborg

{ rjmh, pareto, sabry

Abstract
We have designed and implemented a type-based analysis
for proving some baaic properties of reactive systems. The

analysis manipulates rich type expressions that contain information about the sizes of recursively defined data structures. Sized types are useful for detecting deadlocks, nontermination, and other errors in embedded programs. To
establish the soundness of the analysis we have developed

an appropriate semantic model of sized types.

1 Embedded Functional Programs
In a reactive system, the control software must continuously react to inputs from the environment. We distinguish a class of systems where the embedded programs can
be naturally expressed as functional programs manipulating streams. This class of programs appears to be large

enough for many purposes [2] and is the core of more expressive formalisms that accommodate asynchronous events,

non-determinism, etc.

The fundamental criterion for the correctness of programs embedded in reactive systems is Jwene.ss. Indeed,

before considering the properties of the output, we must ensure that there is some output in the first place: the program
must continuous] y react to the input streams by producing

elements on the output streams. This latter property may
fail in various ways:

e the computation of a stream element may depend on

itself creating a "black hole," or

e the computation of one of the output streams may

demand elements from some input stream at different
rates, which requires unbounded buffering, or

o the computation of a stream element may exhaust the

physical resources of the machine or even diverge.

" Supported by NUTEK (Swedish National Board for InrILIst rid
and Technical Development ) grant 5321-93-2833.

Permission to make digitallhard copies of all or part of this material forpersonal or classroom use is granted without fee provided that the copies
are not made or distributed for profit or commercial advantage, the copyright notice, the title of the publication and its date appear, and notice is
given that copyright is by permission of the ACM, Inc. To copy otherwise,
to republish, to post on servers or to redktribute to lists, requires specific

permission andlor fee.

POPL '96, St. Petersburg FLA USA@ 1996 ACM 0.89791 -769_3/95/01 . .$3.5f)

}(Qcs, chalmers. se

To support the use of high-level functional languages
in embedded systems we have developed an analysis that
checks the fundamental correctness property of an embedded functional program, t. e., that the computation of each
stream element terminates. The main component of our

analysis is a (non-standard) type system that can express
bounds on the sizes of recursive data structures. Experience
with the implementation indicates that the system works
remarkably well for small but realistic programs.

The next section motivates the use of sized types for
reasoning about reactive systems. Section 3 introduces the
syntax and semantics of a small functional language with
sized types. The next two sections present the type inference
rules, establish their soundness wit h respect to our semantic
model of types, and give some examples that illustrate some
of their strengths and weaknesses. Sections 6 and 7 deal
wit h the details of the implementation and our experience
in using it. Before concluding we review related work.

2 Sized Types
Various basic properties of reactive systems can be established using a notion of "sized types." We informally motivate this notion and its use in reasoning about stream computations using some examples.

2.1 Productivity
In a conventional lazy functional language, the dat atype of
streams of natural numbers would be defined as:

data ST = Mk NAT ST.
The declaration introduces a new constructor M k which,
given a natural number and a stream produces a new stream,

t.e., it has type NAT + ST + ST. Two sample programs
that use this datatype are:

head (Mkns) = n of type ST -+ NAT

tuzl(Mkns) = S of type ST + ST

A more interesting program is:

letrec ones = Mk 1 ones in ones
which computes an infinite stream of 1`s. In other words,
for any natural number Z, a request for the first i elements

410

of the stream is guaranteed to be processed in finite time:

theprogram isproduckve [5,17].

A slight modification of the program to:

Ietrec ones' = Mkl (tadones') in ones'
is not productive; it cannot compute the first i elements of

the stream for any i > 1. To understand the problem, Wsume that after unfolding the recursion i times, we obtain a
stream s with i + 1 elements. The recursive call then computes (tads) which has i elements and adds one element to
produce a stream that has i + 1 elements: each recursive call
is attempting to construct a stream with no more elements
than the previous call and no new elements are added to the
stream after the first one.

Our intuitive analysis of the behavior of the programs
can be formalised using a (non-standard) type system. The

system includes a new family of types ST' (streams with at
least i elements), which can express the more informative

type Vi. NAT -i ST; + ST ~+1 for the constructor M k. Consequently, for the previous programs, we get the intuitive

types Vi. STi+l -i NAT and Vi. ST'+l 4 ST' for head and

tad respectively. The type of ones is Vi. ST' which indicates
that it is a stream with an infinite number of elements. The
program ones' is (rightly) rejected.

2.2 Memory Leaks
Using sized types, we can not only guarantee that some
streams are productive, but also establish that some functions are unsafe w their computation requires unbounded
space. For example, consider the program:

Ietrec jil (Mk nl (Mk n, s)) = Mk (avgm nz) (fits)
in Js.stream-add (fits) (fil (jil s))

The function fil represents an idealised digital filter and
should have type Vi.ST2i ~ ST' since it requires two elements from its input stream to compute one element of its
output stream. Using the following diagram, we can informally calculate lower bounde on the sizes of all the streams
used in the program:

The figure reveals that for every i output elements, we need
4i input elements. These latter elements are all consumed

along the bottom path. However only 2i elements are consumed along the top path and the remaining 2i elements
must be buffered. The size information reveals that the program would be unsafe in a reactive system as it is impossible
to implement a buffer of size 2i for all i.

2.3 Termination
In the above example, we claimed that the type of jd is
b'i. ST2' -+ STi. In other words, we claimed that given 2

elements, the function jil is gum-anteed to produce one element in finite time. By inspection of the definition of jil it

is apparent that such a claim can only be justified if we can
prove that the function avg terminates!

In general we might have to prove that an arbitrary function of the natural numbers terminates. To this end our
system must include approximations NAT~ to the datatype

NAT of natural numbers. Intuitively an approximation NAT;
represents numbers with at most i constructors. 1 Using this
new family of sized types, we can prove that the type of aug
is Vkl.N-&'rZ~ -+ NATZt + NATk+t. Not only does such a

type guarantee the termination of the function, but it also
provides useful information.

3 Syntax & Semantics
For the purpose of presentation, we restrict our attention to
a small prototypical lazy functional language,

3.1 Syntax
A program consists of a number of global declarations of
user-defined datatypes followed by a term. We distinguish
two kinds of datatype declarations:

data D~ = Conlfi+. ..+ Conm~
codata D~ = Conl~+. ..+ Conmfi

Each declaration introduces a datatype name D possibly
parametrised by a vector of type variables F. The right
hand side of the declaration introduces a number of term
constructors for the dat at ype Con 1, ..., Con ~ and specifies
the types of their arguments. For example, possible declarations for natural numbers, streams, and lists are:

data NAT = Zero + Succ NAT
data FSTREAM t = FMk t (FSTREAM t)
codata STREAM t = Mk t (STREAM t)

data LIST t = Nil + Cons t (LIST t)
codata ILIST t = lNil + lCons t (ILIST t)

Intuitively a data declaration signals that the user is interested in the finzte elements of the datatype. In contra& a

codata declaration signals that the user is also interested in
the injhute elements of the datatype. Thus NAT is the set
of natural numbers, FSTREAM is the set of all finite streams

(the empty set!), STREAM is the set of all finite and infinite
streams, LIST is the set of all finite lists, and ILIST is the

set of all finite and infinite lists.

With each datatype name, e.g., NAT or STREAM, our
system associates a family of types, e.g., NATO, NAT1, . . . .

NATO or STREAMO t,STREAM1 t,....STREAMU t.The types
with natural indices represent the elements of the datatype
with the given size bound. The types with the special index w represent the `[limit" of the natural approximations.
For example, the type NATS represents the natural numbers

{O, 1,2} and NATti represents the entire set of natural numbers. Similarly the type STREAM3 t represents all streams
with at least 3 elements of type t and STREAMti trepresents

all infinite (productive) streams with elements of type t.

1During our current experiments, we use the inductive definition of
the natural numbers (built from Oand Succ) and prove the terminationof arithmetic functions, e.g., addition, from basic principles. In future

versions of the system, we intend to provide a library of the common
arithmetic functions with their appropriate types.

411

The precise set of type expressions is inductively generated over infinite sets of dat atype names D, type variables
t G 7'Var and size variables i c 5'VaK

ff ::= Vt.a I via / 7- (Type Schemes)

T ::= tlT+Tl Dsfi[Dsfil D@7ii [mm

In addition to the usual quantification over type variables,

type schemes may quantify over size variables. Type expressions T include type variables, function types, and indexed

datatype names.

The size indices S can either be the special index w or
some function of size variables. To get precise types, it is

tempting to allow arbitrary functions of size variables. For
example a precise type for factorial would be Vi. NAT? -+
NAT;!. However to get a workable system we will restrict
ourselves to linear relationships among size variables.

Restriction 3.1 The size indices can only be linear functions of the st.ze varaables:

S::= 71 GN[i[S+Sln*S
Thus the best type we can express for the factorzal function
is Vi. NATi -+ NATti.

Finally, the set of terms is inductively generated over
infinite sets of variables z E Var, and constructors Con &

Con:

M ::= iz[Az. MI MM ICon M.. .M

[ case Mof(P+iW) . ..(P+M)
\ letrec . = M in M

P ::= Conxl . ..xn (Patterns)
The full language also allows mutually recursive definitions
but we do not consider them in the remainder of this paper. We require that the patterns in a case-expression are
exhaustive. The language has more context-sensitive restrictions that will be introduced and motivated during the development of the semantics.

3.2 Semantics of Expressions
We specify the semantics of the terms using a conventional

denotational model. The universe U of denotations is isomorphic to the (coalesced) sum of the following domains: z

UJEConL@ [UJ+U]@ [UJx UJ]L@ [lLJ-+UJ]L
The domain ConL is the flat domain of constructors. The

definitions of the domain operations 1 (lifting), + (separated
sum), @ (coalesced sum), x (cartesian product), and +

(continuous function space) are standard. We will use nary pro ducts as abbreviations of sequences of binary ones.
The symbol ~ denotes the approximation ordering on the
universe of values. Given the universe of values, the semantic
function & that maps a term, and an environment to an

element of U. Environments map variables to denotations.

2Most semantic models of types include an element wrong that
formalises run-time errors. We exclude this element from our universe

of values because our type system rejects strictly more expressions
than a conventional one, t. e., i t cannot accept any expression whose
evaluation causes rumtime errors.

Figure 1: Sample Semantic Types
Definition 3.1 (Meaning Function E) The dejinztzon is

st andard:3

&: MxEnv -+ U

Env : Vam -+ U

E[(CorI M, .Mn)]p = (Con, EIMl]p,. . . . E[M~]p)

E[z]p = p(z)
E[(Xz.M)]p = f e ~ -+ UJ]

where f(u) = E[M]p[u/z]
E[(M N)jp = app(EIMllp, E[iV]p)
Euletrec z = M in N]p = E[N]p[u/z] where

u = U,>. mi(f, ~)

and f(~) = &[ M]p[u/z]

app:UJx UJ + U

{

f(u) tf f 6 [u -+ u]ww(f,u) = ~

o th erwzs e

w" (f, U) = Uapp'+' (~, u) = j(app'(f, u))

3.3 The Universe of Types

A type is a subset of U with special properties. To motivate these special properties we examine the meaning of the

stream ones. According to the semantics in the previous
section, the denotation of the stream of 1`s is the limit of
the following chain:

ones =1 C STO

u (Mk,l, L) C STO, ST1
L! (Mk, l,(Mk, l, l)) G STO, ST1, STz

. . . . . .

In a conventional semantics for types, there would be one
set corresponding to the stream dat at ype, and this set would
include all the elements that appear in the chain. For our
purposes, we have a family of sets corresponding to each of

the types STi, and each set only contains part of the chain.

For example the set ST' must not include 1 or (M k, 1, 1)

as we cannot compute the second element of either of these
streams in finite time.

A consequence of this property is that not all types include 1, which immediately invalidates the standard seman3In the definition, we onut the clause for case-expressions as well
ss the explicit isomorphisms mapping elements of the summands into
the universe and vice-versa.

412

tics of types based on ideals [11, 12], or intervals [3].4 In
contrast to these systems, we define the universe of types
UJT to be the collection of all upward-closed subsets of U.

A set ~ is upward-closed if whenever z G `7_ then for every

y 2 z, we have y G T. For example Figure 1 illustrate both

the approximations to the data and codata declarations of
natural numbers.

Proposition 3.1 The unwerse of types UT is a complete

latttce ordered by the subset relation; the least upper bound
operation is the set-theoretic union, and the greatest lower
bound operation is the set-theoretic intersection.

In order to give a semantics to type expressions we must
associate an upward-closed set with each type expression in
the language. For composite type expressions, e.g., functions, sums, and products, we introduce corresponding type
operations on the universe of types: H , q , and q The
set `T1 *'T~ is defined to be {(O, U) I u 6 `T1}U{(l, U) [ u ~

r,}. The operation q is the regular cartesian product. The set `T1 B Tz is defined to be {j G U I Vx G

`TI. app(i, x) G `T,}.

3.4 Continuity and Ordinals
Given the precise definition of the universe of types and its

associated operations, we can now study the semantics of
user-defied datatypes. To motivate the definitions we will
first examine the semantics of the following three datatypes:

data NAT = Zero + Succ NAT
codata ST = Mk NAT ST
data SP tltz = Null

+ Put t2 (SP tlt2)
+ Get (t]-+ (SP t]tz))

The first two datatypes should be familiar. The datatype

SP is the datatype of stream processors from the Fudgets
library [6]. This datatype describes three kinds of stream

processors:

1. the N UII processor,
2. the processor (Put tz (SP tlt~))that can output an

element of type tz and then becomes a new stream
processor, and

3. the processor (Get (tl-+ (SP tl tz)))that expects a

value of type tI and then becomes a new stream processor.

For each datatype D we must associate a set with each of
its approximations O, 1,2, . . . and w. The conventional way

of explaining the meaning of recursive datatype declarations
is by taking the fixed point of a functional over the universe

of types. The functional are easily derivable from the declarations using a function `D whose definition is omitted.

D[NAT] = F.

~[sT] = F.
D[SP] `TI `Tz = Fp

4Semantic models based on retracts [16] are not appropriate for another reason, they do not support the form of implicit polymorphism
common in the programming languages that we are using.

where:

F.(T) =

F.(T) =
FP(T) =

{Zero} q ({ Succ} H `T)

{Mk}~N'xr~'T
{Null}

q ({Put} E I-2 q T)
H ({Get} H ('T] B T))

We can now calculate for each datatype the meaning of
its approximations O, 1,2, . . . in a straightforward manner.

Simply put, the meaning of the ith approximation to D is
the i-fold application of the functional D[D] to either the
bottom element (fJ) or the top element (U.J)of the lattice of
types. The choice of the initial element depends on whether
the datatype was declared as a data or codata. Thus the
meaning of NATZ is (ignoring injections and tags):

F;(o) =

----

.
.--
----

=

Fn(Fn(0))
F.({Zero} q ({ SUCC} lXl 0))
Fn({Zero} QI 0)
Fn({Zero})
{Zero} q ({ Succ} H {Zero})

{Zero, (Succ, Zero)}

We invite the reader to trace the calculation of F; (W) which
is the meaning of ST2.

At this point, one might expect that the meaning of the
wth approximation to the datatype is simply the least (for

data) or greatest (for codata) fixed point of the corresponding functional. However in a complete lattice such as our lattice of types, the fixed point of a functional F is calculated

as follows:

1.

2.

3.

If the functional F is not monotone, then the limit
may not exist.

If the functional F is monotone but not continuous,
then the least fixed point of F is F&(0) for some ordinal

6 where [4:p. 106, Ex. 4.13]:

FO(u) = UFi+l (u) = F(F'(u))
FA (u) = Uj<~ FJ (u) (A is a limit ordinal)
The greatest fixed point is calculated by a similar argument using the dual lattice.

If the functional F is continuous then the ordinal 6 in
the previous case is the first limit ordinal w.

In other words we should not expect the meaning of the
wth approximation to coincide with the least or greatest

fixed point of F unless F is continuous. In our running
examples, the two functional F. and Fs are indeed continuous and the meanings of NAT. and ST" can be computed

as lJ~<U Fj (0) and ok<. F: (UJ) respectively.

In contrast the functional Fp is monotone but not continuous and its wth approximation does not correspond to its
least fixed point. This rather technical point has important

practical consequences.

Example: Consider the term:

413

letrec rid n = case n of

Zero -+ Null
Succ p + Put p (ridp)
in Get (An. rid n)

which represents a stream processor that when given a number n, outputs n elements and then becomes the Null processor. Although the evaluation of the stream processor clearly
terminates when given an argument of type NATW, our system cannot handle such a term w the following argument
shows.

First we note that in our example the stream processors
manipulate natural numb ers so the types oft he construct ors

are as follows (where we abbreviate (SPi NAT. NATO) as
SPNi).

Null :: `v'i. SPNi+I

Put :: Vi.NATu 4 SPNi -+ SPN,+I

Get :: Vi. (NATti -+ SPN, ) + SPN,+I

Given these types, we note that the meaning of SPNI =
{Null}. In general the meaning of SPNi is the set of stream
processors that terminate after at most (i - 1) Put and Get
operations. The set SPNW is the union of all the sets SPN?. In
other words it is the set of processes that terminate within

a fixed number of operations regardless oj the inputs they
recetve. Clearly (Get (An.rid n)) is not in the set SPN".
On the other hand for each n c NATU, (d n) is in SPNW.
It follows that (Get (Jn. rid n)) is in SPNU+I. Because the
functional Fp is not continuous SPNU+I is not identical to

SPNU. k%!

We now have a few alternatives:
1. Allow the declaration of the datatype SP and accept

the term (Get (An. rid n)). This means that we must
be prepared to handle indices that range over ordinals.

2. Allow the declaration of the datat ype SP but reject

any programs that would require ordinal indices, t. e.,
reject the term (Get (An. rid n)).

3. Reject the declaration of the datatype SP because it

defines a non-continuous functional.

For simplicity reasons, we have opted for the third alternative. This choice demands that we find simple syntactic
criteria that ensure that all datatype declarations yield continuous functional. We begin by identifying the problematic positions in a declaration.

Definition 3.2 A type expression T occurs in a non-U-continuous poszt%on af:

(Ul) -r occurs in either argument to --) ,
(U2) T occuTs m an argument to a codata name, or

(U3) r occurs in argument r~ to a data name D and r,

occurs m a non-~-continuous posttton in the right hand
szde oj the declaration of D.

Samilary a type expression T occurs in a non-0-continuous
positaon %f:

(11) T occurs in the left argument to +,

(12) r occurs in argument r% to a data or codata name and

ri OCCUTS m a non-~-continuous position in the rzght

hand side of the declar-atton of the name.

The restriction on datatype declarations is now simple.
Restriction 3.2 In a data declaration the declared type

cannot occur in a non-U-continuous poshon. In a codata
declaration the declared type cannot occur in a non-~- continuous posxtzon.

We can easily verify our previous claims regarding the
continuity of NAT, ST, and SP. For more interesting examples, consider the following declarations:

data ORD = Zero

+ Succ ORD
+ Lim (STREAM ORD)
data TREE t = Leaf t + Node (LIST (TREE t))

data LIST t = Nil + Cons t (LIST t)

In the first declaration, ORD occurs as an argument to a

codat a name thus violating condition (U2) above. Indeed

ORD k a canonical non-continuous type. In the declaration
of TREE, the declared type (TREE t)is passed as an argument to LIST potentially violating condition (U3). To ensure

that the condition is not violated we check that t does not
occur in non-LJ-continuous position in the right hand side of
the declaration of LIST. Although ORD and SP are not accepted when declared as data, they would be accepted when

declared as codata. This means that although we cannot
reason about the termination of stream processors, we can
prove that they do not deadlock.

The major consequence of our restriction is that we can
now treat all `(infinite" sizes as identical to w. In other
words, we can use identities like w = w + 1 when reasoning

about programs.

3.5 Semantics of Types
We can now speci~ the precise semantics of type expressions.

Definition 3.3 (Type Semantics) The jlnctton Z maps

a type expression and two environments @ and ~ to a semantic type:

Z:ux Envlx Env2 + UT

Envl : TVar + UT

Env2 : SVar + N

where in the last J clauses 1 n the value of the size expression
S in the environment ~ and F is the functional comespondmg to the datatype name D, ?.e., F = D[D] ~[rk]~~.

414

Proposition 3.2 The function Z is well-defined.
Proof Sketch. It is easy to verify that each of the type
constructors q , q , and ~ maps upward-closed sets to
upward-closed sets. q

3.6 Testing for 1
A major property of our semantic model is that it is possible
to test whether 1 is included in a type, which is crucial if we

are to reject programs that may diverge. Given that types
are upward-closed sets, the test of whether a type 7 includes

1. is quite simple: 1 G ~ if and only if -r = U. We define
two mutually recursive predicates empty and all that decide
whether the denotation of type expression -r is the empty
set or the universe u respectively:

all (Do)
all (7-I + m)

empty (Do)
empty (71 -+ m)

notempty (Ds)
notempty (D")
notempty (T1 + 72)

if all (~z) or empty (_rI)
if empty (-r~) and notempty (T1)

if notempty (m) or empty (-n)
The predicates are sound (but not complete) with respect
to our semantic model.

3.7 w-Types
When a value is too large for its size to be expressed in our
restricted language, we give it a size of w. For example,

the type we can actually give factorial is Vi.NAT, -+ NAT@.
But now we face a problem if we want to compute further with the result. Suppose for example we want to type
factorial (factor?al n). To type the outer application of factorial we need to give it the type NATti + NATti, instantiating i to w as it were. But our size variables range only

over naturals, so it is not valid to do so! Yet in this case the
result is clearly sound.

Our goal then is to extend the system to allow the instantiation of size variables to w. To this end, let us define
substitution of w for a size variable i. The interesting cases

are:

Ds [w/i] = { Do if i G FV(S)Ds otherwise
Ds[w/z] = { D" if i G IW(S)Ds otherwise
Thus we simpli~ sizes involving w directly to w; this is justified since our size expressions can only express strictly monotonic functions of their free variables.

We immediately encounter a problem: it is not always
sound to instantiate size variables to w. For example, suppose f has the type Vi. STREAM" NAT, + UNIT. Then we
know that f terminates for every bounded sequence. But

to give f the type STREAM" NATW ~ UNIT we must show
that it terminates for ever-y sequence. This need not be the
case: consider the function that searches for the first element
whose value is less than its position in the stream.

We aim therefore to find syntactic conditions on types
that guarantee that our proposed extension is sound. Let
Ti be a type expression indexed by a size variable i and abbreviate n~ [w/i] as TW. We want to guarantee that (Vi.ni) D
no. Or semantically speaking we want to guarantee that

(n; ~,) ~ rti. If this is the case we say m, is w-in.tantzable.

We say rri is monotonic if i < j implies r~ ~ -irJ, and

anti-monotonic in the dual case. These can be recognised
easily: ni is monotonic if i only occurs positively, and antimonotonic if i only occurs negatively. The definitions of
positive and negative occurrences are as usual, with the extension that an occurrence in the size of a data type is considered positive, and an occurrence in the size of a codata

type is considered negative.

Clearly monotonic types are w-instantiable, because the
w instance is bigger than all the finite ones, but this is hardly

interesting. More interesting are the anti-monotonic examples, such as STREAM; BOOL, or those which are mixed, such

as STREAM; NATi or NATi -+ NATz,. Monotonicity is much
too strong a condition to impose. We will therefore define a
slightly stronger condition than w-instantiability, which we
can use successfully as an induction hypothesis.

Definition 3,4 An indexed type r, is w-undershooting zfUi fljzi Tf G ~ti ~l~ew~seT;

u w-overshooting if ~~ cuin,>,~~.

Intuitively, while w-instantiability says that the sequence
of nis "tends below" TU, w-undershooting says that the same
holds for every suffix of that sequence. Clearly:

o w-undershooting types are w-instantiable,
m monotonic types are w-undershooting. The converse

is not necessarily y true: for example STREAMi B 00L is
w-undershooting even though it is not monotonic,

l anti-monotonic types are w-overshooting. Again the

converse is not true: NATi is w-overshooting but it is
not anti-monotonic,

l constant types, e.g., the set cent aining Zero, type variables, and the datatype UNIT are w-undershooting and
w-overshooting, and

o sums and products of w-overshooting and undershooting types are respectively w-overshooting and undershooting.

These definitions were motivated by the following result.

Proposition 3.3 If z% is w-overshooting and T; is w-undershooting, then Xi ~ n: is w-undershooting.

proof. We show that if f c (J, flj ~, rj ~ nj then f E
nti ~ nj. Take an arbitrary z E mm: we must show that

f z ~ m:. But n, is w-overshooting, so z c nj ~,= TJ for some

in. We also know f G fl ~kit XJ ~~~ for some if. SO f x G

17j2ma~~,.,tf~ n;, and therefore since m; is w-undershooting
we have f x~r~.~

Thus to check that a function type is w-instantiable, we
need only check that its argument types are w-overshooting

and its result type is w-undershooting. For example, NATZ ~
NAT2, and NAT, + STREAM' t-+t are both w-inst antiable.

415

`r, D `r: (i in covariant position) ~~ D ~j (j in contravariant position)

DkTl . .. TnDDk T. . ..'&

Figure 2: The subtyping relation
One might expect a dual result to hold for w-overshooting
function types, but it does not. The type NAT. -+ NAT i is
not w-overshooting since (Ji (lj ~~(NAT. + NATi) is the set

of all bounded functions, but NAT. -+ NAT. also contains

the unbounded ones. We settle for anti-monotonicity as a
sufficient condition for function types to be u-overshooting;
it is possible to weaken the requirement for function types

with finite domains, but we do not consider it worthwhile to

do SO.

It remains to find general conditions for data and codata types to have these properties. Let F, be the functional
on types which is iterated to define the semantics of the data
or codata type in question. This functional F, can very well

depend on i: for example if the type is STREAM' NAT; then
F;(7) = {Mk} Rl NAT, El ~. All F~ expressible in our language have the following property which is needed to prove

Proposition 3.5.

Lemma 3.4 Fi(X) fl Fj(Y) = F;(X n Y) n FI(X n Y).

Let #i be a size expression possibly involving i. Then ~
is either constant or strictly monotonic. We can prove the

following propositions.

Proposition 3.5 For any famzly of types n,, %f:

xi u-undershooting amplzes Fi (ni) w-undershooting
then F?' (0), F$i (U), Uj F:(0) and nJ F! (U) are also wundershootmg.

Proposition 3.6 For any famzly of types r,, zf:

n, w-overshooting impltes FL (n, ) u-overshooting
then F~; (0) and l_J7F; (0) are atso w-overshooting.

These results give us a simple way to check that a data
or codata type is w-undershooting, or that a data type is
w-overshooting. The size is irrelevant; we simply check that

all components have the same property, assuming that recursive occurrences of the data or codata type have it. For
example, NAT~ and LIST, NAT, are both w-over- and -undershooting, as is any other type built only from data types.

Likewise STREAM' NAT ~ is w-undershooting, but we cannot
conclude that it is w-overshooting. And indeed it is not

Muinjz$STREAMJ NATj is the set of productive streamswhose elements are eventually less than their position in the
stream, which is not a superset of STREAM" NATti, the set of

all productive streams. We fall back on anti-monotonicity as
a sufficient condition for a co dat a type to be w-overshooting,

and we doubt that any much weaker condition can be found.

4 Type System

Before presenting the type inference rules, we present a subtype relation crl D UJ. The motivation is that since we
infer bounds on sizes, it should always be possible to relax the current bound to a less accurate one. Without

such flexibility it would be impossible to type programs like

(if M then s else (Mk 1 s)), as the two branches would
have sizes that differ by 1.

The relation D is defined in Figure 2. It is straightforward to show that the semantic count erp art of the subt yping
relation is the subset relation.

Lemma 4.1 If al D 02 then for all environments ,B and ~,
qal],6'7 G qm]B7.

The main innovation in our type inference system is the
rule for typing recursive declarations. Before presenting the

entire set of rules, we first discuss a simple version of the

letrec rule that does not include the generalisation of free
type variables. The type environment r maps variables and
constructors to type expressions:

all (-r[O/i])
r t- k.kf: vz.7 + di+ I/Zl

ru{Z,b'i.T}&~:T~ ` `

r E (letrec z = M in N) : T1 i @ Fv(r)

The rule hae three premises. The main one (in the middle)
states that a functional defining a recursive value ought to
make progress at each recursive call by producing values of

the "next" size. Depending on whether the size variable i indexes a data declaration or a codata declaration, the "next" size could be a bigger or smaller set respectively. Thus

the same typing rule can be used to both prove that computations using data objects terminate and computations

using codata objects are productive. The first premise (the

"bottom check" ) ensures that we can start the iteration of

416

(Var) `u{x'71}k M:T' (Abs) r+~:rl +72ru{~:a}k~:a r + (XMVf) : `n + 72 r E N : " (App)rtMN:~z

r+ c.n, ~con `con)
rkM:Tl &pat (~z, Tl) : r, rurzt Mi:72

r+case Mof(Pl+Ml). ..(Pn +Mn):~J `z c `l""n}) (Case)

;:::::;] "n")

rEM:'J t f2 Fv(r)

r t- M: w.g (Gen)

:::::;] "n'")

r+kf:~ i g `v(r) (GenS)

rFM:v2.cJ

rt-M:lT~ " D `2 (Coer) r t M : Vi.rr~

rkM:u. rl-M:7r. Ti is w-undershooting (u)

all (T II)/z]) r ~ k.~~: Vi.T -+ T[i+ I/i] r u {X: Vi~.V~.T} ~ N: T1

r 1- (letrec z = M in ~) : T]

i @ w(r), I,Z g ~v(T)\~v(r) (Ret)

Figure 3: Rules for Type Inference

the functional in the first place. The last one concludes (using an implicit induction principle) that the recursive object
can be safely used at any size.

To motivate the importance of the "bottom check" we

present the following example which illustrates that the rule
becomes unsound if we omit it.

Example: Consider the term:

s = if head s

then Mk True s
else Mk False s

It is easy to verify that the program diverges (z. e., the stream
s is not productive). However assuming that s is of type

ST;+*, the right hand side is of type ST'+2. In other words,
the functional is making progress at each recursive call as
required by the main premise of the letrec rule. The failure of the "bottom check" (1 @ ST1 ) guarantees that the
program would be correctly rejected. n

The rules for type inference are in Figure 3. The rules
for variables, procedures, applications, constructors, generalisation and instantiation of type variables do not exploit
nor affect the sizes and are standard. The notation ~Con
refers to the type of the constructor Con as inferred from

the corresponding datatype declaration. The rule for caseexpressions uses an auxiliary judgement defined as follows:

ZnSt(CTCon)=T( +...~~~+~
l-Pat ((con zl. ..zn)r):): {xl :T{,...,~n :~k}

where inst provides a generic instance of a type scheme.

The rest of the inference rules rely on the size annotations. First we can generalise and instantiate size variables
in the natural way as in (GenS) and (InstS) respectively.

Second we can coerce any type to a less precise type by
relaxing the bounde on the sizes (Coer). Third we can instantiate size variables that index w-undershooting type expressions to w. Finally when typing recursive declarations

(Ret), we must ensure that the resulting computations are
terminating and/or productive.

The main technical result of the paper is the soundness
of the type system.

Theorem 4.2 (Type Soundness) If we can prove that M

has type u, then the denotation of M is indeed an element

of the type denoted by c.

Proof. The proof proceeds by induction on the height of
the type derivation and proceeds by case analysis on the

last rule. The inductive hypothesis states that:

If r + M : a then for all p, ,6, ~ such that the
relation IR(17,p, ~, -y) holds, &[M]p c Z[u]@~.

The relation R is defined as:

iqr, p, p, ~) if V{Z: CT} ~ r.g[~]p E z[a]p~.
Most of the cases in the proof are standard. The subtyping
case follows by Lemma 4.1. The soundness of the typing

rule for the case-expression requires that that the patterns

are exhaustive. The soundness of the w-instantiation rule
was sketched in Section 3.7. We present the let rec case in

detail:

Assume r E (letrec % = Jf in IV) : T, and I-@, p, ~, 7)
for some p, ,8, and ~. We want to show that:

&[(letrec z = M in N)]p = s[N]p[u/z]

where u = l-i~f'~(l),

and ~ = i$[kE. M]p
G Z[T1]67

By the inductive hypothesis, we get:

f = `qk.qp

G Z~i.7 + ~[i + l/i]]/3~
6 nk z[7],B7[k/i] El ~WJ7[~ -+ 1/4 (*)

We now claim that:

VI%G N.fk (1) e z[T]p~[k/i] (t)

417

Modulo the obligation to prove the claim (t), we can establish our result as follows. Let u = LIk fk (1), then:

u g f~(J-) for all k
.'. u E z[T]p~[k/i] for all k, since

types are upward closed

.". u 6 nk T[T],@y[k/i]
.. ~(r u {Z, Vi. T}, P[U/Z]) p,~)
.". &[N]g+4/z] c qhlnh inductive hypothesis

To complete the argument we must prove our claim (t).
The proof proceeds by induction on k. If k = O then the
claim reduces to 1 G zllr16-d O/ii which is an immediate
consequence of the botto~ "ch~ck.

f' (J-) ~ ~[~lP7[~/4
.'. f(.f' (1)) E 417-]@y[j+ I/i]

Ea

Ifk=j+l then:

induct ive hypothesis

property (*) and

definition of ~

5 Using the Type System
Before talking about the actual implementation, we will attempt to gain some intuition about the strengths and weaknesses of our system using some small examples.

5.1 Primitive Recursion: Reverse
Our system is strong enough to prove termination or productivity of functions in primitive recursive form. For example,

assuming that the append function for lists can be given the
type (cf. Section 6):

append:: Vij.Vt. LHT% t
we can prove that the naive

as follows:

-i LISTJ+I t -+ LIST,+j t

reverse function can be typed

reverse :: Vi. Vt. L1sT~ t 4 LIST, t
Tevers e xs =

case xs of

Nil + Nil
Cons y ys + append (~eweme ys) (Cons y Nil)

The derivation of the type proceeds as follows:

0
e

e
e
e

e

a

Assume reverse :: LIST, t + LISTi t.
Assume m :: LIST,+] t.

Check that the Nil branch has type LISTL+l t (direct).
Assume y :: t and ys :: LIST; t.
Conclude reverse ys :: LISTi t.

Conclude (Cons y Nil) :: LIST~ t (not LIST1 t as you
might expect -- it has two constructors).

Instantiate the type of append, and conclude that:

append (Teve~se YS) (Cons y Nil) :: LIST,+] t
asrequired. Notice that if we had given append a less
precise type, omitting the f+ 1`, we would have been
unable to draw this conclusion.

e

*
5.2

The right hand side of reverse's definition has the type

LIST~+I t + LIST,+l t which satisfies the main premise
of the typing rule for recursion.

The bottom check: verify all (LISTO t -i LISTO t). It
holds because empty (LISTO t) holds.

Ackerman's Function
Indeed, any function defined by a primitive recursion scheme
is accepted by our type system. This includes higher-order

primitive recursion, so in particular we can type Ackerman's
fimction. But we are obliged to rewrite it in primitive recursive form.

Consider first the usual first-order definition:

ackxy =

case x of

Zero -+ Succ y
Succ z' 4 case y of

Zero ~ ack z' (Succ Zero)
Succ y' + ockz' (ack z y')

We cannot type this recursion as it stands because there
is no argument which gets smaller in every recursive call. We
have to reformulate the definition, so that it corresponds to

the structure of a termination proof. Ackerman's function
can be proved terminating by a double induction, first on
z, and then, for a fixed z, on y. We therefore re-express it
using two recursive functions, one recurring on x, and the
other (higher-order) recurring on y.

ack z = case x of

Zero -+ Succ
Succ z' + h (ack z')
hfy= caseyof

Zero -+ ~ (Succ Zero)
SUCC y' ~ ~ (h f y')

These definitions can be given the types:

ack :: Vk.NAT~ + NAT. ~ NAT.

h :: Vk. (NATti --+ NATti) + NATk + NATO

Of course, since our size expressions can only express
linear functions we cannot do better than give the result a

size w. Notice that in order to type the application of h in

ack, we have to instantiate k to w.

5.3 Shuffling Lists
If we could only accept definitions in primitive recursive
form, our type system would not be very interesting. The
following example shows that we can accept a wider class of

definitions. It defines a function that "shuffles" a list:

shuf)le xs z

case xs of

Nil+ Nil
Cons z m` -+ Cons z (shuffle (reverse XS' ))

This definition is not in primitive recursive form because
the argument of the recursive call of shufie is not m`. But
it is the same size as zs', and the type of reverse is strong

enough to tell us that. We can therefore give shujj'le the

type:

shufj7e :: Vi.'dt. bs'ri t + LISTi t

which is accepted by our system.

418

5.4 A Problem: Accumulating Parameters
We showed above how to typecheck naike r-ever-se, but in
reality of course we want to use the efficient linear definition
with an accumulating parameter:

reverse xs = rev xs Nil

rev xs ys = case xs of

Nil + ys

Cons z 3s' + rev zs' (Cons z ys)

The types we would like to give these definitions are:

rev ers e :: Vi. Vt. LIsTi t + LIST, t

rev :: Vij.Vt.LrsT, t + LISTJ+I t+ LIsTi+j t

Unfortunately this type for rev is not accepted by our
system! To see why, we trace through the typing of rev:

l Assume rev :: LIST~ t + LISTj+I t + LISTi+l t.
l Assume m :: LIST;+l t and ys :: LIST3+I t.
l In the Cons branch, assume xs' :: LCST~ t.
l Conclude (Cons z ys) :: LISTJ+Z t
l NOW the application of rev is well-typed only if ~ + 2<

j +1! This constraint is unsatisfiable and the program
is rejected.

These definitions can be typed, but only SS:

reverse :: `#i. Vt. LIsT~ t -+ LISTti t

rev :: Vi. Vt.L1sT, t-+ LISTU t-+LISTti t

But with this type for reverse, the definition of shufle above
cannot be typed!

The solution seems to be to allow a limited form of polymorphic recursion: over sizes, but not types. Thus when

typing the body of rev, we would assume the typing:

rev :: Vj. LIST~ t -+ LISTj+l t + LIST~+j t
and then type the recursive call by instantiating 1 toj + 1.
The type of the result, LISTi+J+I t, matches the i + 1st
instance of the declared type of rev, and typechecking would

therefore succeed.

We plan to extend our implementation to allow this kind
of polymorphic recursion. It is necessary to do so: similar

problems will arise whenever an accumulating parameter is
used, and this is an important programming technique which

we must be able to type accurately.

5.5 Array Bounds Check
Our sized types can also be used to guarantee that array
indices are never out of bounds. We view an array as a

function from indices to contents. For example an array oft
with 6 elements has type NAT 6 + t.Our type system guarantees that an array with this type has at least 6 elements
and is accessed with indices which are less than 6.

6 Implementation
To get an algorithm asserting type correctness of programs,
we must complement our deduction rules rules with a proof
strategy. If we want type inference, our algorithm must

include an equation system solver. If we want subtype inference, it must solve systems of inequations.

We distinguish type inference algorithms from those for
type checking in that the latter rely on type annotations and

do not address minimality of a typing.

We have implemented a type checker for our sized type
system. It requires all let-bound variables of a program to

be annotated with sized type signatures, but infers the types
for all other expressions.

Its proof strategy is simple. Uses of (Var), (Abs), (App),
(Con), (Case) and (Ret) are structurally determined by the
program. Other rules are used as follows:

(Inst),(InstS) Are used together with (Var) and (Con).
(Gen),(GenS) Are used at (Letrec) and at the topmost

expression.

(Coer) Is used at (App), (Con) and (Case).
The systems of inequations arising in our type system are
predicates of the form

V;.(SISS~A..ASn5SA)
where sj ,s$ are size expressions. Such a constraint system is
said to be solvable if there exists a substitution under which

the system holds.

In general, the above constraint system formulation is
not the only conceivable one. Nothing in our semantic model
stops us from using arbitrarily complicated constraint languages. The restriction lies in our abilities to solve the corresponding constraint systems.

Our work does not address the problem of constraint
solving. Instead, we exploit recent developments in constraint solving technology via the omega calculator [9, 13].

The formulation of our constraint systems is to a large extent determined by the capabilities of the omega calculator.

The reason for implementing a type checker rather than
a type inference algorithm is twofold:

First, if we want to do type inference, a minimal type
must exist for every typeable program. It is easy to formulate a constraint language for which this does not hold.

Furthermore, as we suggested above, the prospects of constraint solving strongly depend on the expressiveness of our
constraint language. If our constraint language is too powerful, the type inference algorithm will be hopelessly incomplete. Finding the right compromise might be tedious, so

one of our design choices is to let the constraint language
reflect the best available constraint solver regardless if the
language can express minimal types or not.

Second, inference for the (Letrec) rule is tricky. In the
general case we have to solve an equation system with functions of size variables w unknowns, the solution has to respect our constraint language and it must be minimal. By
letting the programmer introduce the unknown function using a type signature, these problems disappear. Although
initial experiments with letrec-inference looked promising

we found the additional complications too distracting to be
worthwhile.

419

6.1 Technical overview Size inference
There are three major steps in the algorithm:

Hindley Milner Inference We check that the program is

type correct in terms of ordinary types.

Size Inference We typecheck the program with our sized

type system under the assumption that all type signatures are correct.

Constraint solving We solve all the constraints and verify

that our inferred types match the type signatures.

The result of the algorithm is the syntax tree annotated with
sized types and a set of error messages. The first is useful
in interpreting the latter.

6.2 Example
We proceed through the algorithm step by step and examine

the typechecking of the append function on lists.

letrec

app : : f orall k 1 a. Llst#k a -> Lie.t#l+i ~ -> List#k+l aapp

xs ys = case xs of

N,l -> ys

Cons x xs -> Cons a (app x. ys)
in app

We will refer to the nodes of the syntax tree using the names
in the figure below. We write e.a for the annotation a of

node e.

Hindley Milner inference
The first step is to do standard (Hindley Milner) type inference. We motivate this as follows. The erasare 5 of a sized
type scheme o is defined by dropping the size quantifiers and
size variabl~s from a to get an ordinary type. This notion
extends to r and r t- e: o-. Now, if we erme every judgement
in a sized proof tree, then we get a Hindley Milner proof

tree.

During inference, we annotate every node of the syntax
tree with its Hindley Milner type e. hm. For the subtree elo
of our example we get

elo. hm = LISTCX -+ LISTOj

eu. hrn = LIST a -+ LIST a -+ LIST a
els. hm = LISTa

The next step is size inference. First we extend our ordinary types to sized types: A fresh size variable is added to

every type constructor of the type annotations. We refer

to the sized type annotations as e.sz which for our example
becomes:

elo.sz = LISTkQo a + LISTk ZI a

e32.sz = LISTMZ a + LISTW3 a + LISTk~4 (2
els. sz = LISTM a

Then, we infer our sized types: We traverse the syntax
tree and collect equalzty constraints on our extended types
to make them appear as in the corresponding proof tree.

Consider the typing rule for (App):

rkitf:rl+'m rt-fv:T1

To make our syntax tree annotations match this rule we
must unify the codomain type of el~ .SZ with the type elo. sz.

Hence we get:

LISTk20 a -i LISTk21 a = Listkzz a -+ LIsTkz4 a
at the node elo. As we coerce at (App) we add an inequality
rather than an equality between the domain type of eI z and

the type of els :

The nodes elz and els are both variables so we expect a
lookup in r possibly followed by an instantiation with fresh
variables. At both nodes the type environment r includes:

{ZS: !$15, a'p~: LISTk,o a-+ LISTk3,+, a-+ LISTk30+k,, (1}
so we will simply unify elj .SZ and e13.SZ with the corresponding types in R

LISTk30 a + LISTk31+l o! + LISTk30+k31 a =
LISTk22 a + LISTkZ3 a + LISTW a

LISTk15 a = LISTkM a

The typing of constructors, case expressions and lambda
expressions are all variations on the same theme and we do
not consider their details. More interesting is letrec. First
recall its typing rule:

all (r[O/i])
i fz m(r), R g FV(T)\FV(r)
r t- XZ. M : vi.'r + T[i+ I/i] r u {z : `W7.T} t- N :7-1

r t- (letrec z = M' in N) : TI

Note that the letrec rule has a built in (Gen) rule. To understand the strategy of the algorithm, we must consider some

general properties of subtype inference: Whenever a constrained type is generalised we must capture its constraints.

At instantiation, the captured constraints are added to the
constraint set of the typing instantiating it. Now, if we
simplify our constraints before generalisation, we will avoid

unnecessary constraint inst antiations. This is a good thing

as constraint manipulation is costly. Although many polymorphic subtype systems have expression forms for bounded

quantification, for example u where C where C is a constraint system [I], our type system does not. As a consequence, simplification must eliminate all constraints, otherwise we can not express the type.

420

The (Letrec) rule for the implementation has a slightly different appearance than the deduction rule:

ru{x:r}+itf:r' I'U{x:x.sia]t N:r,

r t- (letrec z = M in IV) : m

T--T' = instjft)

ft = Vi. Vk.V~.T -+ r~+'/,]
`di.v~.'di.T = Z.Sig

au = (c, Fv(r), T + 7-', ft)

Here inst is the polymorphic instantiation function, using
fresh variables for all quantifiers. It is used to instantiate

ft which is the type scheme used to type the recursion approximator. Note that this formulation of letrec has fused

the uses of (Gen) and (Lambda) for the approximator judgement into the rule. The type scheme ft represents the type
family used in our induction proof. It is defined using the

type signature x.sig of the variable x.

The most striking differences of the (Letrec) deduction
rule vs. its implementation is the missing conditions for bottom check and generalisation. The reason is simple - they

are not checked during size inference. Instead we build an

annotation assumption aa, which encapsulates everything
needed to check these conditions later. An annotation assumption contains: The set of coercions C collected during

the proof of i14, the free variables of r, the inferred type
for the recursion approximator and the correspondhg type
created from the type signature. We will come back to the
proofs of annotation assumptions.

Another major difference is that the type signature z. sig
is used in the typing of the term N. Hereby, we can continue
the inference process assuming that any error lies in the
implementation of the function failing to type, not in its

specification.

Our little example gives us the following annotation assumption, here updated with the solution to the system of
equalities.

(C, 0, t',s) where
c = {LISTklo+la -+ LISTWY -i LISTWW <

LISTkM+Id -+ LISTkz5+ld + LISTkz4+]+kz5a',
LISTk24+1CY' -+ LISThZ5+Id + LISTkz4+l+kz5d <
LISTk~o+Ick + LISTk4a + LISTMCY,

LISTkIoCI ~ LISTkMCY, LlsTk4a < LISTkz5+l a',
Cu<a', LISTk~4+kz5cl < LISTWCY,

LISTk28+1~ < LISTk6CU, LISThACY < LISTk@}

i? = (LISTk24CY' + LISTkZ5+IO! + LIsTk24+k25cv') -+

LISTklo+la -i LISTk4a + LISTMCI

s = v/C~.b'U.(LISTk U + LIsT~+la -+ LISTk+~a) 4

LISTk+l U -+ LrsT~+la + LIsTk+l+la

Note that the first two constraints form an equality on types.

Type equalities added at letrec nodes occasionally involve
equalities on size expressions. We use the constraint solving

pass to handle such equations. There are six other constraints, two for the alternatives in the case rule, two for

the constructor arguments and one for each of the two other

applications.

Constraint solving
The constraint systems emerging from our proofs are linear
inequalities on natural numbers. The core of our constraint
solving pass is the omega calculator [9, 13], a tool for manipulating Presburger formulas. Given a constraint system
of integer linear inequations it solves the system and rejects
it if unsolvable. The constraint solving pass has 7 stages:

Translation Coercions between types are translated to size

constraints using a straightforward implementation of
the relation D.

Omega test The omega tester either rejects a constraint

system or presents a solution to it. A solution consists
of a substitution and a simplified constraint system

which -in the ideal case- will be empty.

Simplification From our experience, the elimination of redundant constraints in the omega tester needs to be
completed with some simple heuristics.

Substitution The resulting substitution is applied to all

annotation assumptions.

Annotation check To prove that an assumption about an

annotation is correct we unify the type signature with
the (pseudo) inferred type, then generalise all variables
of the latter with respect to the saved free variables and
finally check that the two type schemes are identical.

Bottom check Finally, we bottom check the annotation

using a straightforward implementation of the predicate all.

There are three possible origins for a constraint. Most are
due to the coercions during size inference but some are due
to type equivalences. The annotation check equates the

body of the annotation with the inferred type by adding
two dual coercions to the type constraints. Finally, as our
constrained size variables range over naturals rather than
integers, we must constrain them to be positive if they are

to be solved by the omega calculator.

Let us return to our example. We had 8 coercions in
our annotation assumptions, two of them were due to the
equivalence in letrec. To equate the annotation with the
inferred type we add another two. Translating this set gives

us 23 constraints over 8 size variables i.e. 31 constraints in
all:

{O<= k24, O<= klO, O<= k25, O<= k4,

O <= k6, O <= k28J O<=k, 0 <=1,
k24+l<=k10+l, , k25+l<=k4

k6 <= k24 + 1 + k25
k10+l<=k24+l, k4<=k25+l

k24+l+k25<=lc6, k4<=l+1

k10 <= k24, k4 <= k25 + 1
k24 + k25 <= k28, k28 + 1 <= k6

k4<=k6, k<=k24, li-l<=k25+l

k24+k25<=k+l, klO+l<=k+l
k+l+J<=k6, k24<=k, k25i-1<=1-tl
k+l<=k24+k25, k+l<=klO+l
l+l<=k4, k6<=k+l+l}

From this constraint system the omega calculator derives
the following solution:

[k, 1>k, k, 1, 1+1, k+l+l, k+l / k,l, k24, klO, k25, k4, k6, k28]

421

Applied to our annotation assumption we get

(C, O,t', s) where

C' is the solved constraint system
t' =( LIsT~d +LISTL+Id -+ LIST~+iQ') +

LIST~+ICI + LISTl+Ia + LIST~+l+IQ

.S= Vkl.Va.(L1sT~a ~ LIST1+la -+ LIST~+~a) -+

L1s'r~+la ~ Lrs'rl+la -+ LIST~+I+la

As there are no free variables captured by our annotation
assumption we generalise all size variables in t' i.e. k, 1which
are the same as in the signature. Hence we are finished with
the annotation check. Remaining is the bottom check. The

O-instantiated type is

LISTOG -+ LISTl+la -+ LISTia
for which the bottom check holds as the domain type is

empty.

7 Using the Implementation
The concrete syntax of our language is similar to the syntax
of Haskell [7]. To express our richer set of type expressions,
we use $ to refer to w and # to index both data and codata

declaration names.

7.1 Modularity
As with all type-based analyses, our analysis need not manipulate the entire program at once. It is possible to analyse modules separately and summarise the types of their

exported functions in an interface file. Future uses of the
functions in the module need only look up the types in the
interface file. We have implemented such a rudimentary
module system which we illustrate with a small example.

Assume that the modules Nat and Stream include definitions of typical functions like add, tail, and zap Wtth. At
some previous time, the system has checked the contents of

these modules, and summarised the types of their top level

definitions in an interface file:

add :: Vij.NAT, ,-+ NATj H NATt+j

tad :: bt.Va'.ST%+~a + ST'CY
Zlp With :: vi.va'py.(a -+ /3+7)+

ST%CY+ STi,6 -+ STiy

Then we can write the following module:
---------------------------------------------------------------
module Fib where

import Nat -- defines addimport Stream -- def inei? tall, zipWith

surnl :: f orall k. Str.am#k Nat$ -> Stream#k Nat$ -> Stream#k Nat$suml = zipWith add
fibl :: forall k. Stream#k Nat$fibl =

Mk O (Mk 1 (suml fibl (tall fibl)))

f ib2 :: f orall k. Stream#k Nat$
fib2' :: f orall k. Stream#k Nat$

fib2 = Mk O fib2'
flb2p = Mk 1 (suml fib2 fib2')

---------------------------------------------------------------

Figure 4: Finite impulse response filter
When processing the module, jib 1 is rejected as the system
can not prove that the application (tad jib) will succeed.

This is because the structure of the definition does not match
the structure of the termination proof for fibl. Rewriting the
example using two mutually recursive definitions as in jib2
produces a program that our system accepts.

7.2 Correctness of A Digital Filter
Digital filters are often implemented as a weighted sum of
the n last samples of the input signal. Figure 4 illustrates
such a filter whose implementation in our language is:

---------------------------------------------------------------
module Filter where

Import Stremn -- defines tail, map, zipWith
import Nat -- defines add, mu12, mu16, mu19

suml :: f orall k .f orall a b. Stream#k Nat#a -> Stre.am#k Nat#b

-> Stream#k Nat#a+b
suml = zipWlth add

20 :: f orall k .f orall a. Stream#k+3 a -> Stream#k a
ZI :: forall k. forall a. Stream#k+2 a -> Stream#k a
22 :: forall k. forall a. Streamtik+l a -> Stream#k a
23 :: forall k. forall a. Stream#k a -> Stream#k a

20 = \x -> tail (tail (tail z))
21 = \x -> tail(tall x)
22 = tall
z3=\x->x

a2 :: f orall k 1. Stream#k Nat#l -> Straam#k Nat#2*l
a6 :: f mall k 1.Stream#k Nat#l -> Stream#k Nat#6*l
a9 :: f orall k 1. Stream#k Nat#l -> Stream#k Nat#9*l

a2 = map mu12
a6 = map mu16
a9 = map mu19

fir :: f orall k 1. Stream#k+3 Nat#l -> Stream#k Nat#18*l
fir = \i -> (suml (a2 (23 i))

(suml (a6 (Z2 l))

(suml (a9 (z1 i))
(20 1))))
---------------------------------------------------------------

Our system accepts the program. The type off ir establishes several points. First the output stream is productive.

Second the elements of the output stream are bounded to
be no more than 18 times larger than the elements in the
input stream. Finally the program will not work unless the

environment supplies at least three elements of the input
stream.

8 Related Work
The formal notion of productivity is due to Sijtsma [17]. He
presents a calculus for proving the productivity y of recursive

422

definitions of streams but no automatic analysis. The closest

analyses to ours are two recent ones for the estimation of execution times in parallel languages [8, 14]. Both our system
and Reist ad and Gifford's [14] include similar notions of size

and subtyping but nevertheless differ significantly regarding our two main technical contributions. First, our system

is the only one that includes a semantic interpretation of
the sizes and a proof of soundness. Second, the languages
support ed by the two systems are different. Reist ad and

Gifford's system can handle imperative constructs but not
user-defined recursive procedures. From our experience, the

extension to user-defined recursive procedures is a maJor one
that affects the entire system. In contrast the extension to
imperative constructs appears to be straightforward.

Our system is also related to several approaches for the
formal development of reactive systems using synchronous

languages, temporal logics, process calculi, etc [10]. Our
system is distinguished by two major properties: productivity y and modularity. Indeed in a recent comparison of 18
formal methods for the development of a simple production

cell [1O], only 6 or 7 implementors could prove the liveness

(productivity) of the production cell and only 3 or 4 used a
modular solution. Furthermore only 1 system (Fo CUS) combined a proof of liveness with a modular solution but only
for the speczjicatzon of the program and not for the actual

executable code.

On the mathematical side, our approximations to sizes
of recursive data structures are apparently related to some
hierarchies of recursive functions [15] though the connection
is not evident at this point.

9 Conclusion
We have designed and implemented an analysis that guarantees termination and Iiveness of embedded functional programs. Moreover our analysis can sometimes detect space
leaks.

Our immediate goal is to use the analysis to reason about
realistic reactive systems written in realistic functional languages for real-time programming [2, 18].

The analysis is based on a new notion of sized types and
its associated semantic model which we expect to be applicable in other contexts such as array bounds checking. We

believe the same theory and type checking technology can
be applied to other programming languages and extended
to verify bounds on the run times of computations.

Our longer term goals are to integrate the analysis with
a complete compiler so that it can yield more concrete information about the run-time behavior of programs.

References

[1]

[2]
[3]

AIKEN, A. S., AND WIMMERS, E. L. Type inclusion constraints and type inference. In Functional Programming @ Computer Architecture (June 1993), ACM
Press, pp. 31-41.

BROY, M., ET AL. The design of distributed systems--

an introduction to Focus. Tech. Rep. SFB-Bericht Nr.

342/2-2/92 A, Technische Universitat Munchen, 1992.

CARTWRIC~T, R. Types as intervals. Tech. Rep. TRS4-
5, Rice University, 1984.

[4]
[5]

[6]

[7]
[8]

[9]
[10]

[11]
[12]

[13]

[14]

[15]

[16]
[17]

[18]

DAVEY, B. A., AND PRIESTLEY, H. A. Introduction to
Lattzces and Order. Cambridge University Press, 1990.

DLJKSTRA, E. W. On the productivity of recursive definitions. Personal not e E WD 749, University of Texas

at Austin, 1980.

HALL~REN, T., AND CARLSSON, M. Programming with
Fudgets. In Advanced Functional Programmmg (1995),
J. Jeuring and E. Meijer, Eds., Springer Verlag, LNCS

925, pp. 137-182.

HUDAK, P., PEYTON JONES, S., AND WADLEFL, P. Report on the programming language Haskell, a non-strict
purely functional language (version 1.2). Szgplan Notices (1992).

HUELSBERGEN, L., LARUS, J. R., AND AIKEN,
A. Using the run-time sizes of data structures to
guide parallel-thread creation. In Proceedings of the

ACM Conference on Lisp and Functional Prograrnmmg
(1994), pp. 79-90.

KELLY, W., ET AL. The Omega Library (version 0.91):

Interface Guzde. University of Maryland at College
Park, 1995.

LEWERENTZ, C., AND LINDNER, T. Formal Development of Reactive Systems: G'ase Study Production

Cell. Lecture Notes in Computer Science 891. SpringerVerlag, 1995.

MACQUEEN, D., PLOTKIN, G., AND SETHI, R. An
ideal model for recursive polymorphic types. Znformution and Control 71, 1/2 (1986), 95-130.

MAC QUEEN, D., AND SETHI, R. A semantic model of
types for applicative languages. In Proceedings of the

ACM Conference on Lasp and Functional Programmmg

(1982), pp. 243-252.

PUGH, W. The Omega test: .4 fast and practical integer programming algorithm for dependence analysis.

Communications of the ACM 8 (1992), 102-114.

REIDSTAD, B., AND GIFFORD, D. K. Static dependent
costs for estimating execution time. In Proceedings of

the ACM Conference on Ltsp and Functional Programmmg (1994), pp. 65-78.

ROYER, J. S., AND CASE, J. Subrecurswe Programming Systems: Complexity and Succinctness. Boston:

Birkhauser, 1994.

SCOTT, D. Data types as lattices. SIAM Journal on

Computmg 5, 3 (1976), 522-587.

SIJTSMA, B. On the productivity of recursive list definitions. ACM Thansactaons on Programming Languages

and Systems 11, 4 (1989), 633-649.

TRUVE, S. A new H for real-time programming. Unpublished Manuscript, 1995.

423